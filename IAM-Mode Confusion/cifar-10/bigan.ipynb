{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7f45001a8278>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# #指定使用那块GUP训练\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "config = tf.ConfigProto()\n",
    "# 设置最大占有GPU不超过显存的70%\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7 \n",
    "# # 重点：设置动态分配GPU\n",
    "config.gpu_options.allow_growth = True\n",
    "# 创建session时\n",
    "tf.Session(config=config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Sequential(\n",
      "  (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (5): ReLU()\n",
      "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (9): ReLU()\n",
      "  (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (14): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (16): ReLU()\n",
      "  (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (19): ReLU()\n",
      "  (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (21): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (22): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (23): ReLU()\n",
      "  (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 8192)              827392    \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 3)         1731      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 32, 3)         0         \n",
      "=================================================================\n",
      "Total params: 1,051,267\n",
      "Trainable params: 1,050,883\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               409700    \n",
      "=================================================================\n",
      "Total params: 799,908\n",
      "Trainable params: 799,012\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:1 [D loss: 0.964462, acc: 37.50%] [G loss: 8.577759]\n",
      "epoch:0 step:2 [D loss: 0.201850, acc: 90.62%] [G loss: 9.260620]\n",
      "epoch:0 step:3 [D loss: 0.096309, acc: 96.88%] [G loss: 8.171257]\n",
      "epoch:0 step:4 [D loss: 0.126112, acc: 96.88%] [G loss: 7.489373]\n",
      "epoch:0 step:5 [D loss: 0.074383, acc: 97.66%] [G loss: 7.229850]\n",
      "epoch:0 step:6 [D loss: 0.238366, acc: 89.06%] [G loss: 9.996765]\n",
      "epoch:0 step:7 [D loss: 1.133828, acc: 52.34%] [G loss: 13.831806]\n",
      "epoch:0 step:8 [D loss: 0.682707, acc: 87.50%] [G loss: 12.374109]\n",
      "epoch:0 step:9 [D loss: 0.466773, acc: 88.28%] [G loss: 9.828083]\n",
      "epoch:0 step:10 [D loss: 0.063870, acc: 98.44%] [G loss: 7.730422]\n",
      "epoch:0 step:11 [D loss: 0.094764, acc: 98.44%] [G loss: 7.158998]\n",
      "epoch:0 step:12 [D loss: 0.203022, acc: 92.97%] [G loss: 8.476723]\n",
      "epoch:0 step:13 [D loss: 0.309770, acc: 89.84%] [G loss: 6.754344]\n",
      "epoch:0 step:14 [D loss: 0.076388, acc: 96.88%] [G loss: 6.062761]\n",
      "epoch:0 step:15 [D loss: 0.054439, acc: 98.44%] [G loss: 6.016621]\n",
      "epoch:0 step:16 [D loss: 0.062615, acc: 99.22%] [G loss: 5.247777]\n",
      "epoch:0 step:17 [D loss: 0.067494, acc: 99.22%] [G loss: 5.985353]\n",
      "epoch:0 step:18 [D loss: 0.076003, acc: 96.88%] [G loss: 7.343798]\n",
      "epoch:0 step:19 [D loss: 0.111548, acc: 96.09%] [G loss: 8.465192]\n",
      "epoch:0 step:20 [D loss: 0.192634, acc: 91.41%] [G loss: 11.072361]\n",
      "epoch:0 step:21 [D loss: 0.078087, acc: 97.66%] [G loss: 12.202175]\n",
      "epoch:0 step:22 [D loss: 0.890782, acc: 57.81%] [G loss: 14.205663]\n",
      "epoch:0 step:23 [D loss: 0.241230, acc: 92.19%] [G loss: 17.844269]\n",
      "epoch:0 step:24 [D loss: 0.029196, acc: 99.22%] [G loss: 16.673889]\n",
      "epoch:0 step:25 [D loss: 0.011755, acc: 100.00%] [G loss: 14.152716]\n",
      "epoch:0 step:26 [D loss: 0.047832, acc: 98.44%] [G loss: 10.718410]\n",
      "epoch:0 step:27 [D loss: 0.073156, acc: 97.66%] [G loss: 8.304892]\n",
      "epoch:0 step:28 [D loss: 0.079216, acc: 98.44%] [G loss: 7.851063]\n",
      "epoch:0 step:29 [D loss: 0.055044, acc: 98.44%] [G loss: 6.631959]\n",
      "epoch:0 step:30 [D loss: 0.188424, acc: 92.19%] [G loss: 7.880591]\n",
      "epoch:0 step:31 [D loss: 0.217252, acc: 91.41%] [G loss: 6.644576]\n",
      "epoch:0 step:32 [D loss: 0.031898, acc: 100.00%] [G loss: 7.688340]\n",
      "epoch:0 step:33 [D loss: 0.910407, acc: 64.06%] [G loss: 11.943401]\n",
      "epoch:0 step:34 [D loss: 0.602911, acc: 77.34%] [G loss: 15.643240]\n",
      "epoch:0 step:35 [D loss: 0.138110, acc: 94.53%] [G loss: 14.961622]\n",
      "epoch:0 step:36 [D loss: 0.066293, acc: 99.22%] [G loss: 12.277725]\n",
      "epoch:0 step:37 [D loss: 0.039518, acc: 99.22%] [G loss: 8.755362]\n",
      "epoch:0 step:38 [D loss: 0.074102, acc: 98.44%] [G loss: 5.981811]\n",
      "epoch:0 step:39 [D loss: 0.057173, acc: 100.00%] [G loss: 4.123762]\n",
      "epoch:0 step:40 [D loss: 0.391149, acc: 85.16%] [G loss: 6.597692]\n",
      "epoch:0 step:41 [D loss: 0.046851, acc: 99.22%] [G loss: 6.704611]\n",
      "epoch:0 step:42 [D loss: 0.030491, acc: 100.00%] [G loss: 8.356807]\n",
      "epoch:0 step:43 [D loss: 0.085438, acc: 98.44%] [G loss: 7.491024]\n",
      "epoch:0 step:44 [D loss: 0.015812, acc: 100.00%] [G loss: 7.869354]\n",
      "epoch:0 step:45 [D loss: 0.055193, acc: 98.44%] [G loss: 6.806867]\n",
      "epoch:0 step:46 [D loss: 0.060244, acc: 98.44%] [G loss: 5.603074]\n",
      "epoch:0 step:47 [D loss: 0.078927, acc: 96.09%] [G loss: 6.163864]\n",
      "epoch:0 step:48 [D loss: 0.081482, acc: 97.66%] [G loss: 5.591567]\n",
      "epoch:0 step:49 [D loss: 0.406898, acc: 87.50%] [G loss: 7.853653]\n",
      "epoch:0 step:50 [D loss: 0.253169, acc: 91.41%] [G loss: 9.378589]\n",
      "epoch:0 step:51 [D loss: 0.242206, acc: 89.84%] [G loss: 9.809464]\n",
      "epoch:0 step:52 [D loss: 0.483978, acc: 84.38%] [G loss: 11.382355]\n",
      "epoch:0 step:53 [D loss: 0.426525, acc: 81.25%] [G loss: 11.391619]\n",
      "epoch:0 step:54 [D loss: 0.469060, acc: 82.81%] [G loss: 10.250130]\n",
      "epoch:0 step:55 [D loss: 0.086076, acc: 98.44%] [G loss: 8.954874]\n",
      "epoch:0 step:56 [D loss: 0.188618, acc: 93.75%] [G loss: 7.792640]\n",
      "epoch:0 step:57 [D loss: 0.049746, acc: 99.22%] [G loss: 6.305385]\n",
      "epoch:0 step:58 [D loss: 0.153895, acc: 95.31%] [G loss: 6.974374]\n",
      "epoch:0 step:59 [D loss: 0.105840, acc: 97.66%] [G loss: 6.419300]\n",
      "epoch:0 step:60 [D loss: 0.051732, acc: 99.22%] [G loss: 6.585021]\n",
      "epoch:0 step:61 [D loss: 0.102157, acc: 96.88%] [G loss: 6.047557]\n",
      "epoch:0 step:62 [D loss: 0.145876, acc: 93.75%] [G loss: 5.965782]\n",
      "epoch:0 step:63 [D loss: 0.226432, acc: 92.97%] [G loss: 8.837364]\n",
      "epoch:0 step:64 [D loss: 0.038601, acc: 100.00%] [G loss: 9.683502]\n",
      "epoch:0 step:65 [D loss: 0.051922, acc: 100.00%] [G loss: 8.664700]\n",
      "epoch:0 step:66 [D loss: 0.158622, acc: 93.75%] [G loss: 8.440456]\n",
      "epoch:0 step:67 [D loss: 0.146990, acc: 96.09%] [G loss: 7.522454]\n",
      "epoch:0 step:68 [D loss: 0.267033, acc: 90.62%] [G loss: 10.351435]\n",
      "epoch:0 step:69 [D loss: 0.107536, acc: 94.53%] [G loss: 9.014438]\n",
      "epoch:0 step:70 [D loss: 0.116626, acc: 96.88%] [G loss: 7.648023]\n",
      "epoch:0 step:71 [D loss: 0.079151, acc: 98.44%] [G loss: 8.749779]\n",
      "epoch:0 step:72 [D loss: 0.229166, acc: 90.62%] [G loss: 7.356759]\n",
      "epoch:0 step:73 [D loss: 0.097963, acc: 97.66%] [G loss: 6.174660]\n",
      "epoch:0 step:74 [D loss: 0.136305, acc: 95.31%] [G loss: 5.610430]\n",
      "epoch:0 step:75 [D loss: 0.280639, acc: 91.41%] [G loss: 5.786757]\n",
      "epoch:0 step:76 [D loss: 0.108077, acc: 96.88%] [G loss: 6.669213]\n",
      "epoch:0 step:77 [D loss: 0.073188, acc: 97.66%] [G loss: 6.397108]\n",
      "epoch:0 step:78 [D loss: 0.084648, acc: 98.44%] [G loss: 6.114362]\n",
      "epoch:0 step:79 [D loss: 0.077928, acc: 98.44%] [G loss: 5.369676]\n",
      "epoch:0 step:80 [D loss: 0.164437, acc: 93.75%] [G loss: 6.869816]\n",
      "epoch:0 step:81 [D loss: 0.069978, acc: 96.88%] [G loss: 6.170531]\n",
      "epoch:0 step:82 [D loss: 0.022539, acc: 100.00%] [G loss: 5.747624]\n",
      "epoch:0 step:83 [D loss: 0.033022, acc: 100.00%] [G loss: 6.224015]\n",
      "epoch:0 step:84 [D loss: 0.044548, acc: 100.00%] [G loss: 5.854909]\n",
      "epoch:0 step:85 [D loss: 0.079594, acc: 98.44%] [G loss: 4.839767]\n",
      "epoch:0 step:86 [D loss: 0.083281, acc: 97.66%] [G loss: 6.095111]\n",
      "epoch:0 step:87 [D loss: 0.042236, acc: 100.00%] [G loss: 5.139453]\n",
      "epoch:0 step:88 [D loss: 0.095206, acc: 95.31%] [G loss: 6.265277]\n",
      "epoch:0 step:89 [D loss: 0.017100, acc: 100.00%] [G loss: 6.110455]\n",
      "epoch:0 step:90 [D loss: 0.026094, acc: 100.00%] [G loss: 5.664912]\n",
      "epoch:0 step:91 [D loss: 0.040163, acc: 100.00%] [G loss: 5.639493]\n",
      "epoch:0 step:92 [D loss: 0.049797, acc: 99.22%] [G loss: 4.474156]\n",
      "epoch:0 step:93 [D loss: 0.055862, acc: 98.44%] [G loss: 5.802105]\n",
      "epoch:0 step:94 [D loss: 0.081352, acc: 99.22%] [G loss: 4.936361]\n",
      "epoch:0 step:95 [D loss: 0.135531, acc: 96.09%] [G loss: 7.346703]\n",
      "epoch:0 step:96 [D loss: 0.148642, acc: 92.97%] [G loss: 9.613731]\n",
      "epoch:0 step:97 [D loss: 0.033627, acc: 100.00%] [G loss: 8.882006]\n",
      "epoch:0 step:98 [D loss: 0.072454, acc: 97.66%] [G loss: 7.110559]\n",
      "epoch:0 step:99 [D loss: 0.053957, acc: 98.44%] [G loss: 6.588310]\n",
      "epoch:0 step:100 [D loss: 0.060342, acc: 99.22%] [G loss: 5.019091]\n",
      "epoch:0 step:101 [D loss: 0.484112, acc: 78.12%] [G loss: 8.101994]\n",
      "epoch:0 step:102 [D loss: 0.326510, acc: 89.06%] [G loss: 9.168894]\n",
      "epoch:0 step:103 [D loss: 0.686009, acc: 81.25%] [G loss: 7.590197]\n",
      "epoch:0 step:104 [D loss: 0.059745, acc: 98.44%] [G loss: 7.500373]\n",
      "epoch:0 step:105 [D loss: 0.064602, acc: 99.22%] [G loss: 6.631868]\n",
      "epoch:0 step:106 [D loss: 0.083014, acc: 97.66%] [G loss: 5.705132]\n",
      "epoch:0 step:107 [D loss: 0.045269, acc: 99.22%] [G loss: 5.278929]\n",
      "epoch:0 step:108 [D loss: 0.035803, acc: 100.00%] [G loss: 6.045332]\n",
      "epoch:0 step:109 [D loss: 0.013875, acc: 100.00%] [G loss: 5.215003]\n",
      "epoch:0 step:110 [D loss: 0.086865, acc: 98.44%] [G loss: 6.081494]\n",
      "epoch:0 step:111 [D loss: 0.031706, acc: 100.00%] [G loss: 4.079324]\n",
      "epoch:0 step:112 [D loss: 0.080216, acc: 97.66%] [G loss: 4.899866]\n",
      "epoch:0 step:113 [D loss: 0.136168, acc: 97.66%] [G loss: 4.830020]\n",
      "epoch:0 step:114 [D loss: 0.093323, acc: 96.88%] [G loss: 4.537462]\n",
      "epoch:0 step:115 [D loss: 0.298624, acc: 85.94%] [G loss: 7.838752]\n",
      "epoch:0 step:116 [D loss: 0.205526, acc: 89.06%] [G loss: 6.790239]\n",
      "epoch:0 step:117 [D loss: 0.108938, acc: 98.44%] [G loss: 5.328948]\n",
      "epoch:0 step:118 [D loss: 0.068719, acc: 99.22%] [G loss: 5.252231]\n",
      "epoch:0 step:119 [D loss: 0.111340, acc: 96.88%] [G loss: 5.060002]\n",
      "epoch:0 step:120 [D loss: 0.138142, acc: 94.53%] [G loss: 4.409801]\n",
      "epoch:0 step:121 [D loss: 0.280706, acc: 89.06%] [G loss: 7.321365]\n",
      "epoch:0 step:122 [D loss: 0.090395, acc: 96.88%] [G loss: 5.296739]\n",
      "epoch:0 step:123 [D loss: 0.153747, acc: 94.53%] [G loss: 5.574801]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:124 [D loss: 0.104793, acc: 96.88%] [G loss: 4.176692]\n",
      "epoch:0 step:125 [D loss: 0.047242, acc: 99.22%] [G loss: 4.208336]\n",
      "epoch:0 step:126 [D loss: 0.080829, acc: 97.66%] [G loss: 5.052876]\n",
      "epoch:0 step:127 [D loss: 0.113743, acc: 97.66%] [G loss: 4.748745]\n",
      "epoch:0 step:128 [D loss: 0.308571, acc: 86.72%] [G loss: 7.432187]\n",
      "epoch:0 step:129 [D loss: 0.085200, acc: 98.44%] [G loss: 7.713721]\n",
      "epoch:0 step:130 [D loss: 0.034524, acc: 100.00%] [G loss: 6.342452]\n",
      "epoch:0 step:131 [D loss: 0.134647, acc: 95.31%] [G loss: 5.987045]\n",
      "epoch:0 step:132 [D loss: 0.622276, acc: 80.47%] [G loss: 9.078184]\n",
      "epoch:0 step:133 [D loss: 0.035613, acc: 99.22%] [G loss: 10.728908]\n",
      "epoch:0 step:134 [D loss: 0.039746, acc: 96.88%] [G loss: 9.740320]\n",
      "epoch:0 step:135 [D loss: 0.064414, acc: 99.22%] [G loss: 5.785068]\n",
      "epoch:0 step:136 [D loss: 0.137718, acc: 94.53%] [G loss: 6.378257]\n",
      "epoch:0 step:137 [D loss: 0.114570, acc: 93.75%] [G loss: 6.301042]\n",
      "epoch:0 step:138 [D loss: 0.325369, acc: 85.16%] [G loss: 7.018810]\n",
      "epoch:0 step:139 [D loss: 0.361353, acc: 88.28%] [G loss: 7.142104]\n",
      "epoch:0 step:140 [D loss: 0.816214, acc: 67.97%] [G loss: 7.591220]\n",
      "epoch:0 step:141 [D loss: 0.335241, acc: 87.50%] [G loss: 9.086508]\n",
      "epoch:0 step:142 [D loss: 0.445601, acc: 85.16%] [G loss: 9.639193]\n",
      "epoch:0 step:143 [D loss: 0.877565, acc: 61.72%] [G loss: 9.512446]\n",
      "epoch:0 step:144 [D loss: 0.115788, acc: 99.22%] [G loss: 8.157487]\n",
      "epoch:0 step:145 [D loss: 0.318114, acc: 89.84%] [G loss: 8.052428]\n",
      "epoch:0 step:146 [D loss: 0.224469, acc: 91.41%] [G loss: 7.070235]\n",
      "epoch:0 step:147 [D loss: 0.152424, acc: 95.31%] [G loss: 6.992942]\n",
      "epoch:0 step:148 [D loss: 0.090397, acc: 96.88%] [G loss: 5.195603]\n",
      "epoch:0 step:149 [D loss: 0.203757, acc: 93.75%] [G loss: 5.807826]\n",
      "epoch:0 step:150 [D loss: 0.169734, acc: 93.75%] [G loss: 5.534910]\n",
      "epoch:0 step:151 [D loss: 0.089999, acc: 98.44%] [G loss: 5.626218]\n",
      "epoch:0 step:152 [D loss: 0.072878, acc: 100.00%] [G loss: 5.905269]\n",
      "epoch:0 step:153 [D loss: 0.229737, acc: 91.41%] [G loss: 8.314131]\n",
      "epoch:0 step:154 [D loss: 0.052292, acc: 98.44%] [G loss: 8.029402]\n",
      "epoch:0 step:155 [D loss: 0.093948, acc: 96.88%] [G loss: 6.709117]\n",
      "epoch:0 step:156 [D loss: 0.048729, acc: 99.22%] [G loss: 6.263990]\n",
      "epoch:0 step:157 [D loss: 0.041837, acc: 100.00%] [G loss: 5.834686]\n",
      "epoch:0 step:158 [D loss: 0.075934, acc: 98.44%] [G loss: 6.622141]\n",
      "epoch:0 step:159 [D loss: 0.062542, acc: 98.44%] [G loss: 4.951510]\n",
      "epoch:0 step:160 [D loss: 0.146242, acc: 94.53%] [G loss: 5.605406]\n",
      "epoch:0 step:161 [D loss: 0.175756, acc: 93.75%] [G loss: 7.795002]\n",
      "epoch:0 step:162 [D loss: 0.093558, acc: 97.66%] [G loss: 7.589923]\n",
      "epoch:0 step:163 [D loss: 0.197584, acc: 92.97%] [G loss: 6.310405]\n",
      "epoch:0 step:164 [D loss: 0.183439, acc: 92.97%] [G loss: 6.135365]\n",
      "epoch:0 step:165 [D loss: 0.202089, acc: 92.19%] [G loss: 7.568233]\n",
      "epoch:0 step:166 [D loss: 0.119781, acc: 97.66%] [G loss: 7.878708]\n",
      "epoch:0 step:167 [D loss: 0.234041, acc: 89.84%] [G loss: 8.474871]\n",
      "epoch:0 step:168 [D loss: 0.084713, acc: 99.22%] [G loss: 8.289751]\n",
      "epoch:0 step:169 [D loss: 0.053678, acc: 100.00%] [G loss: 8.187433]\n",
      "epoch:0 step:170 [D loss: 0.080528, acc: 99.22%] [G loss: 7.629153]\n",
      "epoch:0 step:171 [D loss: 0.039403, acc: 100.00%] [G loss: 7.164960]\n",
      "epoch:0 step:172 [D loss: 0.085529, acc: 97.66%] [G loss: 6.382500]\n",
      "epoch:0 step:173 [D loss: 0.039961, acc: 100.00%] [G loss: 5.675920]\n",
      "epoch:0 step:174 [D loss: 0.020666, acc: 100.00%] [G loss: 5.501420]\n",
      "epoch:0 step:175 [D loss: 0.057421, acc: 99.22%] [G loss: 5.745115]\n",
      "epoch:0 step:176 [D loss: 0.050677, acc: 98.44%] [G loss: 6.544582]\n",
      "epoch:0 step:177 [D loss: 0.029214, acc: 100.00%] [G loss: 7.267092]\n",
      "epoch:0 step:178 [D loss: 0.056822, acc: 98.44%] [G loss: 7.028785]\n",
      "epoch:0 step:179 [D loss: 0.028389, acc: 100.00%] [G loss: 6.767335]\n",
      "epoch:0 step:180 [D loss: 0.020247, acc: 100.00%] [G loss: 5.880984]\n",
      "epoch:0 step:181 [D loss: 0.094709, acc: 97.66%] [G loss: 8.252234]\n",
      "epoch:0 step:182 [D loss: 0.125118, acc: 94.53%] [G loss: 7.767475]\n",
      "epoch:0 step:183 [D loss: 0.028632, acc: 99.22%] [G loss: 7.222866]\n",
      "epoch:0 step:184 [D loss: 0.020141, acc: 99.22%] [G loss: 8.160065]\n",
      "epoch:0 step:185 [D loss: 0.016868, acc: 100.00%] [G loss: 7.276587]\n",
      "epoch:0 step:186 [D loss: 0.040096, acc: 100.00%] [G loss: 6.794051]\n",
      "epoch:0 step:187 [D loss: 0.104432, acc: 96.09%] [G loss: 7.107803]\n",
      "epoch:0 step:188 [D loss: 0.048703, acc: 99.22%] [G loss: 8.294187]\n",
      "epoch:0 step:189 [D loss: 0.034781, acc: 99.22%] [G loss: 7.510013]\n",
      "epoch:0 step:190 [D loss: 0.097368, acc: 97.66%] [G loss: 7.784691]\n",
      "epoch:0 step:191 [D loss: 0.057794, acc: 99.22%] [G loss: 6.450608]\n",
      "epoch:0 step:192 [D loss: 0.076052, acc: 97.66%] [G loss: 7.221583]\n",
      "epoch:0 step:193 [D loss: 0.029020, acc: 99.22%] [G loss: 5.943906]\n",
      "epoch:0 step:194 [D loss: 0.027124, acc: 100.00%] [G loss: 6.019966]\n",
      "epoch:0 step:195 [D loss: 0.046223, acc: 98.44%] [G loss: 6.530646]\n",
      "epoch:0 step:196 [D loss: 0.016072, acc: 100.00%] [G loss: 7.942210]\n",
      "epoch:0 step:197 [D loss: 0.101770, acc: 98.44%] [G loss: 8.093521]\n",
      "epoch:0 step:198 [D loss: 0.039442, acc: 98.44%] [G loss: 10.798530]\n",
      "epoch:0 step:199 [D loss: 0.007428, acc: 100.00%] [G loss: 11.034802]\n",
      "epoch:0 step:200 [D loss: 0.013096, acc: 100.00%] [G loss: 9.280274]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:41: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:43: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:201 [D loss: 0.009775, acc: 100.00%] [G loss: 8.866455]\n",
      "epoch:0 step:202 [D loss: 0.027835, acc: 99.22%] [G loss: 8.200853]\n",
      "epoch:0 step:203 [D loss: 0.007760, acc: 100.00%] [G loss: 6.857044]\n",
      "epoch:0 step:204 [D loss: 0.011092, acc: 100.00%] [G loss: 6.322666]\n",
      "epoch:0 step:205 [D loss: 0.014006, acc: 100.00%] [G loss: 6.771607]\n",
      "epoch:0 step:206 [D loss: 0.049244, acc: 98.44%] [G loss: 7.098555]\n",
      "epoch:0 step:207 [D loss: 0.030572, acc: 99.22%] [G loss: 8.366034]\n",
      "epoch:0 step:208 [D loss: 0.050526, acc: 99.22%] [G loss: 7.444303]\n",
      "epoch:0 step:209 [D loss: 0.033283, acc: 100.00%] [G loss: 6.364599]\n",
      "epoch:0 step:210 [D loss: 0.028155, acc: 100.00%] [G loss: 7.622428]\n",
      "epoch:0 step:211 [D loss: 0.010618, acc: 100.00%] [G loss: 7.261273]\n",
      "epoch:0 step:212 [D loss: 0.012031, acc: 100.00%] [G loss: 7.434653]\n",
      "epoch:0 step:213 [D loss: 0.045295, acc: 98.44%] [G loss: 6.396844]\n",
      "epoch:0 step:214 [D loss: 0.050258, acc: 99.22%] [G loss: 5.163322]\n",
      "epoch:0 step:215 [D loss: 0.030012, acc: 100.00%] [G loss: 5.704224]\n",
      "epoch:0 step:216 [D loss: 0.018361, acc: 100.00%] [G loss: 5.362797]\n",
      "epoch:0 step:217 [D loss: 0.024854, acc: 99.22%] [G loss: 5.507113]\n",
      "epoch:0 step:218 [D loss: 0.118193, acc: 97.66%] [G loss: 6.997861]\n",
      "epoch:0 step:219 [D loss: 0.042584, acc: 99.22%] [G loss: 8.000343]\n",
      "epoch:0 step:220 [D loss: 0.058650, acc: 96.88%] [G loss: 7.849775]\n",
      "epoch:0 step:221 [D loss: 0.015769, acc: 100.00%] [G loss: 7.227980]\n",
      "epoch:0 step:222 [D loss: 0.082381, acc: 97.66%] [G loss: 8.382380]\n",
      "epoch:0 step:223 [D loss: 0.020291, acc: 100.00%] [G loss: 9.465622]\n",
      "epoch:0 step:224 [D loss: 0.059372, acc: 97.66%] [G loss: 8.548094]\n",
      "epoch:0 step:225 [D loss: 0.067409, acc: 98.44%] [G loss: 8.131899]\n",
      "epoch:0 step:226 [D loss: 0.178871, acc: 94.53%] [G loss: 8.979568]\n",
      "epoch:0 step:227 [D loss: 0.016731, acc: 100.00%] [G loss: 10.607012]\n",
      "epoch:0 step:228 [D loss: 0.158213, acc: 90.62%] [G loss: 10.222192]\n",
      "epoch:0 step:229 [D loss: 0.192524, acc: 92.97%] [G loss: 8.830219]\n",
      "epoch:0 step:230 [D loss: 0.565080, acc: 81.25%] [G loss: 10.036822]\n",
      "epoch:0 step:231 [D loss: 0.922923, acc: 72.66%] [G loss: 15.908977]\n",
      "epoch:0 step:232 [D loss: 0.023985, acc: 100.00%] [G loss: 14.967237]\n",
      "epoch:0 step:233 [D loss: 0.101795, acc: 96.09%] [G loss: 14.031074]\n",
      "epoch:0 step:234 [D loss: 0.028480, acc: 99.22%] [G loss: 13.602489]\n",
      "epoch:0 step:235 [D loss: 0.044867, acc: 99.22%] [G loss: 12.553642]\n",
      "epoch:0 step:236 [D loss: 0.161790, acc: 93.75%] [G loss: 10.612301]\n",
      "epoch:0 step:237 [D loss: 0.111308, acc: 96.88%] [G loss: 11.820414]\n",
      "epoch:0 step:238 [D loss: 0.085204, acc: 98.44%] [G loss: 8.779076]\n",
      "epoch:0 step:239 [D loss: 0.170458, acc: 97.66%] [G loss: 8.104485]\n",
      "epoch:0 step:240 [D loss: 1.585166, acc: 48.44%] [G loss: 12.116292]\n",
      "epoch:0 step:241 [D loss: 1.339408, acc: 78.12%] [G loss: 9.750149]\n",
      "epoch:0 step:242 [D loss: 0.379936, acc: 83.59%] [G loss: 6.354801]\n",
      "epoch:0 step:243 [D loss: 0.473076, acc: 80.47%] [G loss: 8.154434]\n",
      "epoch:0 step:244 [D loss: 0.397460, acc: 84.38%] [G loss: 6.209341]\n",
      "epoch:0 step:245 [D loss: 0.984521, acc: 67.19%] [G loss: 4.295177]\n",
      "epoch:0 step:246 [D loss: 0.231941, acc: 92.97%] [G loss: 5.002001]\n",
      "epoch:0 step:247 [D loss: 0.208908, acc: 94.53%] [G loss: 3.794541]\n",
      "epoch:0 step:248 [D loss: 0.844400, acc: 57.03%] [G loss: 6.145239]\n",
      "epoch:0 step:249 [D loss: 0.373853, acc: 85.16%] [G loss: 6.886850]\n",
      "epoch:0 step:250 [D loss: 0.282714, acc: 85.94%] [G loss: 6.097054]\n",
      "epoch:0 step:251 [D loss: 0.185339, acc: 94.53%] [G loss: 5.630663]\n",
      "epoch:0 step:252 [D loss: 0.152001, acc: 95.31%] [G loss: 4.564579]\n",
      "epoch:0 step:253 [D loss: 0.213937, acc: 95.31%] [G loss: 4.015168]\n",
      "epoch:0 step:254 [D loss: 0.241015, acc: 90.62%] [G loss: 4.696856]\n",
      "epoch:0 step:255 [D loss: 0.229076, acc: 92.19%] [G loss: 5.438576]\n",
      "epoch:0 step:256 [D loss: 0.100658, acc: 98.44%] [G loss: 5.601267]\n",
      "epoch:0 step:257 [D loss: 0.086914, acc: 97.66%] [G loss: 5.970733]\n",
      "epoch:0 step:258 [D loss: 0.317415, acc: 89.06%] [G loss: 8.443086]\n",
      "epoch:0 step:259 [D loss: 0.382163, acc: 86.72%] [G loss: 7.319901]\n",
      "epoch:0 step:260 [D loss: 0.287704, acc: 84.38%] [G loss: 8.742329]\n",
      "epoch:0 step:261 [D loss: 0.241565, acc: 91.41%] [G loss: 7.963749]\n",
      "epoch:0 step:262 [D loss: 0.212766, acc: 92.19%] [G loss: 6.510891]\n",
      "epoch:0 step:263 [D loss: 0.407871, acc: 80.47%] [G loss: 7.512731]\n",
      "epoch:0 step:264 [D loss: 0.188185, acc: 91.41%] [G loss: 6.988809]\n",
      "epoch:0 step:265 [D loss: 0.359322, acc: 80.47%] [G loss: 9.209230]\n",
      "epoch:0 step:266 [D loss: 0.091903, acc: 98.44%] [G loss: 11.479105]\n",
      "epoch:0 step:267 [D loss: 0.035136, acc: 99.22%] [G loss: 9.947510]\n",
      "epoch:0 step:268 [D loss: 0.143277, acc: 92.97%] [G loss: 9.231911]\n",
      "epoch:0 step:269 [D loss: 0.095784, acc: 97.66%] [G loss: 7.778376]\n",
      "epoch:0 step:270 [D loss: 0.127200, acc: 96.88%] [G loss: 7.616675]\n",
      "epoch:0 step:271 [D loss: 0.081518, acc: 99.22%] [G loss: 8.270975]\n",
      "epoch:0 step:272 [D loss: 0.053161, acc: 100.00%] [G loss: 8.614552]\n",
      "epoch:0 step:273 [D loss: 0.126806, acc: 97.66%] [G loss: 8.290802]\n",
      "epoch:0 step:274 [D loss: 0.070092, acc: 99.22%] [G loss: 8.964060]\n",
      "epoch:0 step:275 [D loss: 0.045886, acc: 100.00%] [G loss: 10.355585]\n",
      "epoch:0 step:276 [D loss: 0.054975, acc: 100.00%] [G loss: 9.523607]\n",
      "epoch:0 step:277 [D loss: 0.094549, acc: 99.22%] [G loss: 9.957726]\n",
      "epoch:0 step:278 [D loss: 0.024450, acc: 100.00%] [G loss: 10.583454]\n",
      "epoch:0 step:279 [D loss: 0.035000, acc: 100.00%] [G loss: 8.880443]\n",
      "epoch:0 step:280 [D loss: 0.039770, acc: 100.00%] [G loss: 8.839508]\n",
      "epoch:0 step:281 [D loss: 0.081841, acc: 98.44%] [G loss: 8.540642]\n",
      "epoch:0 step:282 [D loss: 0.046005, acc: 100.00%] [G loss: 9.232028]\n",
      "epoch:0 step:283 [D loss: 0.079984, acc: 98.44%] [G loss: 10.109238]\n",
      "epoch:0 step:284 [D loss: 0.078424, acc: 100.00%] [G loss: 11.373368]\n",
      "epoch:0 step:285 [D loss: 0.043730, acc: 100.00%] [G loss: 10.657175]\n",
      "epoch:0 step:286 [D loss: 0.053641, acc: 100.00%] [G loss: 9.958330]\n",
      "epoch:0 step:287 [D loss: 0.044852, acc: 100.00%] [G loss: 9.918909]\n",
      "epoch:0 step:288 [D loss: 0.035705, acc: 100.00%] [G loss: 10.418789]\n",
      "epoch:0 step:289 [D loss: 0.032761, acc: 100.00%] [G loss: 11.068723]\n",
      "epoch:0 step:290 [D loss: 0.059934, acc: 100.00%] [G loss: 11.304238]\n",
      "epoch:0 step:291 [D loss: 0.048141, acc: 100.00%] [G loss: 12.406507]\n",
      "epoch:0 step:292 [D loss: 0.100281, acc: 98.44%] [G loss: 12.567986]\n",
      "epoch:0 step:293 [D loss: 0.043161, acc: 100.00%] [G loss: 10.973457]\n",
      "epoch:0 step:294 [D loss: 0.051181, acc: 100.00%] [G loss: 11.378221]\n",
      "epoch:0 step:295 [D loss: 0.067512, acc: 99.22%] [G loss: 8.982002]\n",
      "epoch:0 step:296 [D loss: 0.019224, acc: 100.00%] [G loss: 10.167438]\n",
      "epoch:0 step:297 [D loss: 0.032173, acc: 100.00%] [G loss: 9.816439]\n",
      "epoch:0 step:298 [D loss: 0.027115, acc: 100.00%] [G loss: 9.448377]\n",
      "epoch:0 step:299 [D loss: 0.036315, acc: 100.00%] [G loss: 8.628263]\n",
      "epoch:0 step:300 [D loss: 0.037794, acc: 100.00%] [G loss: 8.316550]\n",
      "epoch:0 step:301 [D loss: 0.044916, acc: 100.00%] [G loss: 8.139884]\n",
      "epoch:0 step:302 [D loss: 0.498779, acc: 83.59%] [G loss: 9.844127]\n",
      "epoch:0 step:303 [D loss: 0.656351, acc: 89.06%] [G loss: 12.618736]\n",
      "epoch:0 step:304 [D loss: 0.090559, acc: 97.66%] [G loss: 12.801556]\n",
      "epoch:0 step:305 [D loss: 0.087212, acc: 99.22%] [G loss: 11.761596]\n",
      "epoch:0 step:306 [D loss: 0.126966, acc: 95.31%] [G loss: 11.772483]\n",
      "epoch:0 step:307 [D loss: 0.084666, acc: 98.44%] [G loss: 11.939247]\n",
      "epoch:0 step:308 [D loss: 0.031600, acc: 100.00%] [G loss: 11.290951]\n",
      "epoch:0 step:309 [D loss: 0.054647, acc: 98.44%] [G loss: 9.250246]\n",
      "epoch:0 step:310 [D loss: 0.115490, acc: 97.66%] [G loss: 7.302087]\n",
      "epoch:0 step:311 [D loss: 0.037011, acc: 100.00%] [G loss: 6.868556]\n",
      "epoch:0 step:312 [D loss: 0.048139, acc: 98.44%] [G loss: 7.615098]\n",
      "epoch:0 step:313 [D loss: 0.034628, acc: 100.00%] [G loss: 6.495838]\n",
      "epoch:0 step:314 [D loss: 0.121149, acc: 95.31%] [G loss: 6.167637]\n",
      "epoch:0 step:315 [D loss: 0.029783, acc: 100.00%] [G loss: 5.648466]\n",
      "epoch:0 step:316 [D loss: 0.583898, acc: 80.47%] [G loss: 10.522123]\n",
      "epoch:0 step:317 [D loss: 0.035939, acc: 100.00%] [G loss: 12.117311]\n",
      "epoch:0 step:318 [D loss: 0.193948, acc: 89.06%] [G loss: 8.536144]\n",
      "epoch:0 step:319 [D loss: 0.057495, acc: 99.22%] [G loss: 9.032645]\n",
      "epoch:0 step:320 [D loss: 0.514505, acc: 81.25%] [G loss: 11.016272]\n",
      "epoch:0 step:321 [D loss: 1.153654, acc: 71.88%] [G loss: 13.173634]\n",
      "epoch:0 step:322 [D loss: 0.607382, acc: 86.72%] [G loss: 10.447787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:323 [D loss: 0.690282, acc: 85.16%] [G loss: 10.476659]\n",
      "epoch:0 step:324 [D loss: 0.174807, acc: 89.84%] [G loss: 8.902659]\n",
      "epoch:0 step:325 [D loss: 0.125443, acc: 96.88%] [G loss: 9.083396]\n",
      "epoch:0 step:326 [D loss: 0.134767, acc: 96.09%] [G loss: 5.660135]\n",
      "epoch:0 step:327 [D loss: 0.157238, acc: 97.66%] [G loss: 3.992035]\n",
      "epoch:0 step:328 [D loss: 0.302833, acc: 87.50%] [G loss: 4.027954]\n",
      "epoch:0 step:329 [D loss: 0.277134, acc: 85.16%] [G loss: 3.507133]\n",
      "epoch:0 step:330 [D loss: 0.684148, acc: 61.72%] [G loss: 4.765267]\n",
      "epoch:0 step:331 [D loss: 0.102271, acc: 98.44%] [G loss: 6.989158]\n",
      "epoch:0 step:332 [D loss: 0.746675, acc: 66.41%] [G loss: 6.050913]\n",
      "epoch:0 step:333 [D loss: 1.720237, acc: 50.00%] [G loss: 4.723621]\n",
      "epoch:0 step:334 [D loss: 0.230661, acc: 92.19%] [G loss: 8.608854]\n",
      "epoch:0 step:335 [D loss: 0.310943, acc: 85.94%] [G loss: 8.354362]\n",
      "epoch:0 step:336 [D loss: 0.317709, acc: 82.81%] [G loss: 6.236565]\n",
      "epoch:0 step:337 [D loss: 0.705252, acc: 70.31%] [G loss: 4.996710]\n",
      "epoch:0 step:338 [D loss: 0.063425, acc: 99.22%] [G loss: 6.494442]\n",
      "epoch:0 step:339 [D loss: 3.061244, acc: 7.81%] [G loss: 7.061598]\n",
      "epoch:0 step:340 [D loss: 0.344765, acc: 88.28%] [G loss: 7.825496]\n",
      "epoch:0 step:341 [D loss: 1.370442, acc: 51.56%] [G loss: 8.277945]\n",
      "epoch:0 step:342 [D loss: 1.075322, acc: 71.09%] [G loss: 8.125566]\n",
      "epoch:0 step:343 [D loss: 0.396108, acc: 75.78%] [G loss: 9.001871]\n",
      "epoch:0 step:344 [D loss: 0.414723, acc: 82.03%] [G loss: 7.116699]\n",
      "epoch:0 step:345 [D loss: 0.408381, acc: 80.47%] [G loss: 5.475499]\n",
      "epoch:0 step:346 [D loss: 0.161519, acc: 95.31%] [G loss: 4.942505]\n",
      "epoch:0 step:347 [D loss: 0.234960, acc: 92.19%] [G loss: 4.306963]\n",
      "epoch:0 step:348 [D loss: 0.285596, acc: 91.41%] [G loss: 3.931332]\n",
      "epoch:0 step:349 [D loss: 0.082521, acc: 99.22%] [G loss: 4.936691]\n",
      "epoch:0 step:350 [D loss: 0.086482, acc: 98.44%] [G loss: 4.385475]\n",
      "epoch:0 step:351 [D loss: 0.118185, acc: 99.22%] [G loss: 3.467358]\n",
      "epoch:0 step:352 [D loss: 0.092568, acc: 97.66%] [G loss: 3.771747]\n",
      "epoch:0 step:353 [D loss: 0.230690, acc: 93.75%] [G loss: 2.747798]\n",
      "epoch:0 step:354 [D loss: 0.162613, acc: 96.09%] [G loss: 3.568465]\n",
      "epoch:0 step:355 [D loss: 0.337684, acc: 83.59%] [G loss: 3.955942]\n",
      "epoch:0 step:356 [D loss: 0.067866, acc: 100.00%] [G loss: 4.431588]\n",
      "epoch:0 step:357 [D loss: 0.139755, acc: 96.88%] [G loss: 3.546222]\n",
      "epoch:0 step:358 [D loss: 0.068089, acc: 100.00%] [G loss: 3.816457]\n",
      "epoch:0 step:359 [D loss: 0.198274, acc: 92.97%] [G loss: 4.227912]\n",
      "epoch:0 step:360 [D loss: 0.137252, acc: 97.66%] [G loss: 3.313523]\n",
      "epoch:0 step:361 [D loss: 0.534318, acc: 77.34%] [G loss: 4.234217]\n",
      "epoch:0 step:362 [D loss: 0.061312, acc: 100.00%] [G loss: 5.607092]\n",
      "epoch:0 step:363 [D loss: 0.144086, acc: 97.66%] [G loss: 3.849189]\n",
      "epoch:0 step:364 [D loss: 0.277144, acc: 91.41%] [G loss: 2.663768]\n",
      "epoch:0 step:365 [D loss: 0.615274, acc: 68.75%] [G loss: 2.039526]\n",
      "epoch:0 step:366 [D loss: 0.115560, acc: 96.88%] [G loss: 3.186615]\n",
      "epoch:0 step:367 [D loss: 0.127906, acc: 97.66%] [G loss: 2.995855]\n",
      "epoch:0 step:368 [D loss: 0.346354, acc: 88.28%] [G loss: 3.745298]\n",
      "epoch:0 step:369 [D loss: 1.458920, acc: 50.00%] [G loss: 1.390928]\n",
      "epoch:0 step:370 [D loss: 1.190325, acc: 47.66%] [G loss: 1.379165]\n",
      "epoch:0 step:371 [D loss: 0.642583, acc: 72.66%] [G loss: 3.222954]\n",
      "epoch:0 step:372 [D loss: 0.632711, acc: 71.88%] [G loss: 2.373842]\n",
      "epoch:0 step:373 [D loss: 0.099237, acc: 99.22%] [G loss: 4.893449]\n",
      "epoch:0 step:374 [D loss: 2.888315, acc: 11.72%] [G loss: 4.210946]\n",
      "epoch:0 step:375 [D loss: 0.737225, acc: 78.12%] [G loss: 6.507649]\n",
      "epoch:0 step:376 [D loss: 0.425818, acc: 80.47%] [G loss: 5.850743]\n",
      "epoch:0 step:377 [D loss: 0.143365, acc: 97.66%] [G loss: 7.334037]\n",
      "epoch:0 step:378 [D loss: 0.161735, acc: 96.09%] [G loss: 7.189554]\n",
      "epoch:0 step:379 [D loss: 0.576493, acc: 69.53%] [G loss: 5.273174]\n",
      "epoch:0 step:380 [D loss: 0.264699, acc: 95.31%] [G loss: 4.075636]\n",
      "epoch:0 step:381 [D loss: 0.071781, acc: 100.00%] [G loss: 4.264643]\n",
      "epoch:0 step:382 [D loss: 0.103632, acc: 99.22%] [G loss: 3.852519]\n",
      "epoch:0 step:383 [D loss: 0.900566, acc: 53.91%] [G loss: 2.610152]\n",
      "epoch:0 step:384 [D loss: 0.193279, acc: 97.66%] [G loss: 2.868433]\n",
      "epoch:0 step:385 [D loss: 0.898910, acc: 46.09%] [G loss: 2.348998]\n",
      "epoch:0 step:386 [D loss: 0.354412, acc: 87.50%] [G loss: 5.194603]\n",
      "epoch:0 step:387 [D loss: 0.246285, acc: 89.06%] [G loss: 4.205997]\n",
      "epoch:0 step:388 [D loss: 0.152239, acc: 96.88%] [G loss: 6.419481]\n",
      "epoch:0 step:389 [D loss: 0.680981, acc: 64.84%] [G loss: 3.160923]\n",
      "epoch:0 step:390 [D loss: 1.067736, acc: 46.09%] [G loss: 3.564459]\n",
      "epoch:0 step:391 [D loss: 0.047000, acc: 100.00%] [G loss: 5.132647]\n",
      "epoch:0 step:392 [D loss: 0.294233, acc: 89.84%] [G loss: 3.413681]\n",
      "epoch:0 step:393 [D loss: 0.398733, acc: 85.16%] [G loss: 2.347139]\n",
      "epoch:0 step:394 [D loss: 0.580519, acc: 63.28%] [G loss: 4.247969]\n",
      "epoch:0 step:395 [D loss: 0.111453, acc: 96.88%] [G loss: 5.329088]\n",
      "epoch:0 step:396 [D loss: 0.193462, acc: 94.53%] [G loss: 4.212804]\n",
      "epoch:0 step:397 [D loss: 0.231338, acc: 93.75%] [G loss: 3.951797]\n",
      "epoch:0 step:398 [D loss: 0.778183, acc: 66.41%] [G loss: 2.128083]\n",
      "epoch:0 step:399 [D loss: 1.663922, acc: 37.50%] [G loss: 2.812471]\n",
      "epoch:0 step:400 [D loss: 1.286505, acc: 53.91%] [G loss: 2.434825]\n",
      "epoch:0 step:401 [D loss: 0.513187, acc: 75.00%] [G loss: 3.615969]\n",
      "epoch:0 step:402 [D loss: 0.325459, acc: 85.16%] [G loss: 3.116921]\n",
      "epoch:0 step:403 [D loss: 0.784381, acc: 64.84%] [G loss: 3.773205]\n",
      "epoch:0 step:404 [D loss: 1.293872, acc: 50.00%] [G loss: 3.858881]\n",
      "epoch:0 step:405 [D loss: 0.748363, acc: 66.41%] [G loss: 3.137061]\n",
      "epoch:0 step:406 [D loss: 1.913985, acc: 21.88%] [G loss: 2.886027]\n",
      "epoch:0 step:407 [D loss: 1.404182, acc: 30.47%] [G loss: 2.671729]\n",
      "epoch:0 step:408 [D loss: 1.903365, acc: 19.53%] [G loss: 2.753757]\n",
      "epoch:0 step:409 [D loss: 1.192265, acc: 33.59%] [G loss: 3.180223]\n",
      "epoch:0 step:410 [D loss: 0.400317, acc: 85.94%] [G loss: 3.680664]\n",
      "epoch:0 step:411 [D loss: 1.116037, acc: 40.62%] [G loss: 3.173025]\n",
      "epoch:0 step:412 [D loss: 0.438959, acc: 82.03%] [G loss: 3.811641]\n",
      "epoch:0 step:413 [D loss: 0.490749, acc: 75.78%] [G loss: 3.535174]\n",
      "epoch:0 step:414 [D loss: 0.401352, acc: 81.25%] [G loss: 3.106131]\n",
      "epoch:0 step:415 [D loss: 0.455297, acc: 80.47%] [G loss: 2.989763]\n",
      "epoch:0 step:416 [D loss: 0.243622, acc: 92.19%] [G loss: 2.946798]\n",
      "epoch:0 step:417 [D loss: 0.252514, acc: 92.19%] [G loss: 2.925866]\n",
      "epoch:0 step:418 [D loss: 0.385995, acc: 83.59%] [G loss: 2.702806]\n",
      "epoch:0 step:419 [D loss: 0.513256, acc: 78.91%] [G loss: 2.608838]\n",
      "epoch:0 step:420 [D loss: 0.571837, acc: 73.44%] [G loss: 2.793132]\n",
      "epoch:0 step:421 [D loss: 0.257900, acc: 93.75%] [G loss: 3.312386]\n",
      "epoch:0 step:422 [D loss: 0.488220, acc: 77.34%] [G loss: 3.421597]\n",
      "epoch:0 step:423 [D loss: 0.186997, acc: 96.09%] [G loss: 3.461919]\n",
      "epoch:0 step:424 [D loss: 0.095563, acc: 99.22%] [G loss: 4.143810]\n",
      "epoch:0 step:425 [D loss: 0.418242, acc: 81.25%] [G loss: 3.118558]\n",
      "epoch:0 step:426 [D loss: 0.218439, acc: 93.75%] [G loss: 3.048394]\n",
      "epoch:0 step:427 [D loss: 0.503114, acc: 82.03%] [G loss: 2.612261]\n",
      "epoch:0 step:428 [D loss: 0.487647, acc: 76.56%] [G loss: 2.156836]\n",
      "epoch:0 step:429 [D loss: 0.718133, acc: 61.72%] [G loss: 1.835503]\n",
      "epoch:0 step:430 [D loss: 0.789005, acc: 57.81%] [G loss: 2.372449]\n",
      "epoch:0 step:431 [D loss: 1.218336, acc: 34.38%] [G loss: 1.922236]\n",
      "epoch:0 step:432 [D loss: 0.748213, acc: 59.38%] [G loss: 2.336278]\n",
      "epoch:0 step:433 [D loss: 0.190247, acc: 92.97%] [G loss: 4.100967]\n",
      "epoch:0 step:434 [D loss: 0.571386, acc: 75.00%] [G loss: 2.380490]\n",
      "epoch:0 step:435 [D loss: 1.459599, acc: 21.88%] [G loss: 1.960245]\n",
      "epoch:0 step:436 [D loss: 1.154102, acc: 34.38%] [G loss: 2.931512]\n",
      "epoch:0 step:437 [D loss: 0.374117, acc: 86.72%] [G loss: 3.711093]\n",
      "epoch:0 step:438 [D loss: 2.027660, acc: 13.28%] [G loss: 3.061317]\n",
      "epoch:0 step:439 [D loss: 0.753862, acc: 67.19%] [G loss: 4.998986]\n",
      "epoch:0 step:440 [D loss: 0.636336, acc: 75.78%] [G loss: 4.562115]\n",
      "epoch:0 step:441 [D loss: 0.781688, acc: 64.84%] [G loss: 4.599729]\n",
      "epoch:0 step:442 [D loss: 0.488909, acc: 81.25%] [G loss: 4.095153]\n",
      "epoch:0 step:443 [D loss: 0.198628, acc: 93.75%] [G loss: 4.495130]\n",
      "epoch:0 step:444 [D loss: 0.192885, acc: 94.53%] [G loss: 3.787008]\n",
      "epoch:0 step:445 [D loss: 0.210519, acc: 92.97%] [G loss: 4.351738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:446 [D loss: 0.329684, acc: 89.06%] [G loss: 3.092797]\n",
      "epoch:0 step:447 [D loss: 0.246302, acc: 90.62%] [G loss: 3.428853]\n",
      "epoch:0 step:448 [D loss: 0.261201, acc: 89.84%] [G loss: 3.356706]\n",
      "epoch:0 step:449 [D loss: 0.337437, acc: 88.28%] [G loss: 3.397744]\n",
      "epoch:0 step:450 [D loss: 0.407793, acc: 85.94%] [G loss: 3.484304]\n",
      "epoch:0 step:451 [D loss: 0.113316, acc: 96.88%] [G loss: 3.901355]\n",
      "epoch:0 step:452 [D loss: 0.196812, acc: 96.88%] [G loss: 3.640643]\n",
      "epoch:0 step:453 [D loss: 0.215522, acc: 95.31%] [G loss: 3.838968]\n",
      "epoch:0 step:454 [D loss: 0.300255, acc: 87.50%] [G loss: 3.253419]\n",
      "epoch:0 step:455 [D loss: 0.560695, acc: 75.00%] [G loss: 3.154208]\n",
      "epoch:0 step:456 [D loss: 0.299448, acc: 88.28%] [G loss: 3.288639]\n",
      "epoch:0 step:457 [D loss: 0.174989, acc: 96.09%] [G loss: 3.393261]\n",
      "epoch:0 step:458 [D loss: 0.418349, acc: 83.59%] [G loss: 3.383468]\n",
      "epoch:0 step:459 [D loss: 0.304776, acc: 86.72%] [G loss: 3.932817]\n",
      "epoch:0 step:460 [D loss: 0.672255, acc: 67.97%] [G loss: 4.508027]\n",
      "epoch:0 step:461 [D loss: 0.935617, acc: 58.59%] [G loss: 3.697670]\n",
      "epoch:0 step:462 [D loss: 0.356639, acc: 85.94%] [G loss: 3.786706]\n",
      "epoch:0 step:463 [D loss: 0.740677, acc: 62.50%] [G loss: 3.250154]\n",
      "epoch:0 step:464 [D loss: 0.656967, acc: 70.31%] [G loss: 3.606123]\n",
      "epoch:0 step:465 [D loss: 1.336063, acc: 31.25%] [G loss: 3.243877]\n",
      "epoch:0 step:466 [D loss: 0.873766, acc: 53.12%] [G loss: 3.430775]\n",
      "epoch:0 step:467 [D loss: 1.041461, acc: 55.47%] [G loss: 3.626098]\n",
      "epoch:0 step:468 [D loss: 0.326823, acc: 88.28%] [G loss: 3.551548]\n",
      "epoch:0 step:469 [D loss: 0.585925, acc: 68.75%] [G loss: 2.989328]\n",
      "epoch:0 step:470 [D loss: 0.423773, acc: 82.81%] [G loss: 3.353867]\n",
      "epoch:0 step:471 [D loss: 0.491295, acc: 74.22%] [G loss: 3.598879]\n",
      "epoch:0 step:472 [D loss: 0.630993, acc: 68.75%] [G loss: 3.442267]\n",
      "epoch:0 step:473 [D loss: 0.344164, acc: 90.62%] [G loss: 2.886116]\n",
      "epoch:0 step:474 [D loss: 0.461634, acc: 77.34%] [G loss: 3.770744]\n",
      "epoch:0 step:475 [D loss: 0.610446, acc: 64.84%] [G loss: 3.531119]\n",
      "epoch:0 step:476 [D loss: 0.422864, acc: 84.38%] [G loss: 3.318981]\n",
      "epoch:0 step:477 [D loss: 0.250607, acc: 92.97%] [G loss: 4.956897]\n",
      "epoch:0 step:478 [D loss: 0.151930, acc: 96.88%] [G loss: 3.901327]\n",
      "epoch:0 step:479 [D loss: 0.263337, acc: 91.41%] [G loss: 3.897449]\n",
      "epoch:0 step:480 [D loss: 0.507029, acc: 75.78%] [G loss: 4.307600]\n",
      "epoch:0 step:481 [D loss: 0.763666, acc: 56.25%] [G loss: 2.974517]\n",
      "epoch:0 step:482 [D loss: 0.412141, acc: 81.25%] [G loss: 3.356790]\n",
      "epoch:0 step:483 [D loss: 0.250564, acc: 93.75%] [G loss: 3.355553]\n",
      "epoch:0 step:484 [D loss: 0.087269, acc: 100.00%] [G loss: 5.269331]\n",
      "epoch:0 step:485 [D loss: 0.186545, acc: 96.88%] [G loss: 3.348804]\n",
      "epoch:0 step:486 [D loss: 0.387627, acc: 85.16%] [G loss: 3.125139]\n",
      "epoch:0 step:487 [D loss: 0.170066, acc: 96.09%] [G loss: 4.189171]\n",
      "epoch:0 step:488 [D loss: 0.171981, acc: 96.09%] [G loss: 3.698831]\n",
      "epoch:0 step:489 [D loss: 0.548425, acc: 77.34%] [G loss: 3.068411]\n",
      "epoch:0 step:490 [D loss: 0.430424, acc: 84.38%] [G loss: 3.327837]\n",
      "epoch:0 step:491 [D loss: 0.585031, acc: 74.22%] [G loss: 3.683423]\n",
      "epoch:0 step:492 [D loss: 0.056629, acc: 100.00%] [G loss: 4.637390]\n",
      "epoch:0 step:493 [D loss: 0.247762, acc: 91.41%] [G loss: 3.016381]\n",
      "epoch:0 step:494 [D loss: 0.758370, acc: 62.50%] [G loss: 2.553902]\n",
      "epoch:0 step:495 [D loss: 0.471247, acc: 82.03%] [G loss: 3.204936]\n",
      "epoch:0 step:496 [D loss: 0.509284, acc: 71.88%] [G loss: 2.996649]\n",
      "epoch:0 step:497 [D loss: 0.481375, acc: 73.44%] [G loss: 3.354739]\n",
      "epoch:0 step:498 [D loss: 0.331683, acc: 88.28%] [G loss: 3.190399]\n",
      "epoch:0 step:499 [D loss: 0.638920, acc: 71.09%] [G loss: 4.033472]\n",
      "epoch:0 step:500 [D loss: 0.952795, acc: 67.19%] [G loss: 2.687166]\n",
      "epoch:0 step:501 [D loss: 0.806907, acc: 59.38%] [G loss: 3.431089]\n",
      "epoch:0 step:502 [D loss: 0.539208, acc: 77.34%] [G loss: 4.380643]\n",
      "epoch:0 step:503 [D loss: 0.696154, acc: 68.75%] [G loss: 4.597695]\n",
      "epoch:0 step:504 [D loss: 0.151435, acc: 96.88%] [G loss: 5.917993]\n",
      "epoch:0 step:505 [D loss: 0.218160, acc: 94.53%] [G loss: 5.368993]\n",
      "epoch:0 step:506 [D loss: 0.211166, acc: 95.31%] [G loss: 4.910901]\n",
      "epoch:0 step:507 [D loss: 0.154486, acc: 96.88%] [G loss: 5.095579]\n",
      "epoch:0 step:508 [D loss: 0.355876, acc: 85.94%] [G loss: 4.455926]\n",
      "epoch:0 step:509 [D loss: 0.155157, acc: 96.09%] [G loss: 5.386154]\n",
      "epoch:0 step:510 [D loss: 0.181984, acc: 95.31%] [G loss: 4.239171]\n",
      "epoch:0 step:511 [D loss: 0.201410, acc: 97.66%] [G loss: 4.577442]\n",
      "epoch:0 step:512 [D loss: 0.217764, acc: 94.53%] [G loss: 4.275352]\n",
      "epoch:0 step:513 [D loss: 0.160752, acc: 98.44%] [G loss: 4.578580]\n",
      "epoch:0 step:514 [D loss: 0.200338, acc: 96.88%] [G loss: 3.681324]\n",
      "epoch:0 step:515 [D loss: 0.111711, acc: 98.44%] [G loss: 4.703905]\n",
      "epoch:0 step:516 [D loss: 0.163728, acc: 96.09%] [G loss: 4.899821]\n",
      "epoch:0 step:517 [D loss: 0.262691, acc: 91.41%] [G loss: 3.611164]\n",
      "epoch:0 step:518 [D loss: 0.403854, acc: 85.94%] [G loss: 2.791308]\n",
      "epoch:0 step:519 [D loss: 1.125662, acc: 50.00%] [G loss: 3.596480]\n",
      "epoch:0 step:520 [D loss: 0.516288, acc: 71.09%] [G loss: 3.864667]\n",
      "epoch:0 step:521 [D loss: 0.219711, acc: 93.75%] [G loss: 4.451644]\n",
      "epoch:0 step:522 [D loss: 0.253601, acc: 94.53%] [G loss: 3.492594]\n",
      "epoch:0 step:523 [D loss: 0.414511, acc: 90.62%] [G loss: 2.724623]\n",
      "epoch:0 step:524 [D loss: 0.817786, acc: 56.25%] [G loss: 2.338936]\n",
      "epoch:0 step:525 [D loss: 0.416009, acc: 75.00%] [G loss: 2.884739]\n",
      "epoch:0 step:526 [D loss: 0.528941, acc: 74.22%] [G loss: 2.256706]\n",
      "epoch:0 step:527 [D loss: 1.375902, acc: 28.91%] [G loss: 2.636105]\n",
      "epoch:0 step:528 [D loss: 0.638002, acc: 63.28%] [G loss: 2.919189]\n",
      "epoch:0 step:529 [D loss: 0.618358, acc: 68.75%] [G loss: 1.907259]\n",
      "epoch:0 step:530 [D loss: 0.920643, acc: 44.53%] [G loss: 1.950850]\n",
      "epoch:0 step:531 [D loss: 0.977313, acc: 44.53%] [G loss: 1.915160]\n",
      "epoch:0 step:532 [D loss: 0.786383, acc: 55.47%] [G loss: 1.859508]\n",
      "epoch:0 step:533 [D loss: 0.833901, acc: 56.25%] [G loss: 2.289613]\n",
      "epoch:0 step:534 [D loss: 1.329023, acc: 25.78%] [G loss: 1.799647]\n",
      "epoch:0 step:535 [D loss: 1.020681, acc: 37.50%] [G loss: 1.665257]\n",
      "epoch:0 step:536 [D loss: 1.221987, acc: 28.91%] [G loss: 2.006717]\n",
      "epoch:0 step:537 [D loss: 1.173001, acc: 32.81%] [G loss: 1.835413]\n",
      "epoch:0 step:538 [D loss: 0.983782, acc: 47.66%] [G loss: 2.332424]\n",
      "epoch:0 step:539 [D loss: 0.788525, acc: 47.66%] [G loss: 2.114442]\n",
      "epoch:0 step:540 [D loss: 0.656113, acc: 59.38%] [G loss: 2.518885]\n",
      "epoch:0 step:541 [D loss: 0.882423, acc: 57.81%] [G loss: 2.502435]\n",
      "epoch:0 step:542 [D loss: 0.688123, acc: 65.62%] [G loss: 2.735579]\n",
      "epoch:0 step:543 [D loss: 0.861715, acc: 57.81%] [G loss: 2.423501]\n",
      "epoch:0 step:544 [D loss: 0.658182, acc: 67.19%] [G loss: 3.107697]\n",
      "epoch:0 step:545 [D loss: 0.624325, acc: 64.84%] [G loss: 2.994525]\n",
      "epoch:0 step:546 [D loss: 0.617090, acc: 71.09%] [G loss: 2.897815]\n",
      "epoch:0 step:547 [D loss: 0.607732, acc: 69.53%] [G loss: 3.023569]\n",
      "epoch:0 step:548 [D loss: 0.492270, acc: 75.78%] [G loss: 2.994101]\n",
      "epoch:0 step:549 [D loss: 0.577913, acc: 75.78%] [G loss: 3.029277]\n",
      "epoch:0 step:550 [D loss: 0.389386, acc: 84.38%] [G loss: 3.577121]\n",
      "epoch:0 step:551 [D loss: 0.427318, acc: 87.50%] [G loss: 3.837145]\n",
      "epoch:0 step:552 [D loss: 0.682823, acc: 61.72%] [G loss: 2.675222]\n",
      "epoch:0 step:553 [D loss: 0.599518, acc: 71.09%] [G loss: 2.976676]\n",
      "epoch:0 step:554 [D loss: 0.360128, acc: 86.72%] [G loss: 3.261481]\n",
      "epoch:0 step:555 [D loss: 0.283824, acc: 91.41%] [G loss: 3.809326]\n",
      "epoch:0 step:556 [D loss: 0.411712, acc: 82.03%] [G loss: 3.075671]\n",
      "epoch:0 step:557 [D loss: 0.315855, acc: 87.50%] [G loss: 3.279710]\n",
      "epoch:0 step:558 [D loss: 0.365921, acc: 86.72%] [G loss: 3.064311]\n",
      "epoch:0 step:559 [D loss: 0.483951, acc: 86.72%] [G loss: 3.484550]\n",
      "epoch:0 step:560 [D loss: 0.335006, acc: 85.94%] [G loss: 3.406871]\n",
      "epoch:0 step:561 [D loss: 0.171900, acc: 96.09%] [G loss: 4.141501]\n",
      "epoch:0 step:562 [D loss: 0.421074, acc: 86.72%] [G loss: 3.538610]\n",
      "epoch:0 step:563 [D loss: 0.401170, acc: 82.81%] [G loss: 3.173110]\n",
      "epoch:0 step:564 [D loss: 0.237105, acc: 95.31%] [G loss: 3.268550]\n",
      "epoch:0 step:565 [D loss: 0.441544, acc: 79.69%] [G loss: 3.201843]\n",
      "epoch:0 step:566 [D loss: 0.373221, acc: 85.94%] [G loss: 3.579390]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:567 [D loss: 0.135263, acc: 96.88%] [G loss: 4.316226]\n",
      "epoch:0 step:568 [D loss: 0.392663, acc: 85.94%] [G loss: 3.183063]\n",
      "epoch:0 step:569 [D loss: 0.294110, acc: 89.84%] [G loss: 3.189139]\n",
      "epoch:0 step:570 [D loss: 0.188385, acc: 94.53%] [G loss: 3.701329]\n",
      "epoch:0 step:571 [D loss: 0.260253, acc: 90.62%] [G loss: 3.267402]\n",
      "epoch:0 step:572 [D loss: 0.444429, acc: 84.38%] [G loss: 3.053153]\n",
      "epoch:0 step:573 [D loss: 0.273221, acc: 90.62%] [G loss: 3.190565]\n",
      "epoch:0 step:574 [D loss: 0.223450, acc: 92.19%] [G loss: 3.681097]\n",
      "epoch:0 step:575 [D loss: 0.989753, acc: 49.22%] [G loss: 2.733377]\n",
      "epoch:0 step:576 [D loss: 0.509875, acc: 75.00%] [G loss: 2.875216]\n",
      "epoch:0 step:577 [D loss: 0.245173, acc: 91.41%] [G loss: 2.584823]\n",
      "epoch:0 step:578 [D loss: 0.515883, acc: 73.44%] [G loss: 2.670859]\n",
      "epoch:0 step:579 [D loss: 0.429765, acc: 78.91%] [G loss: 2.426860]\n",
      "epoch:0 step:580 [D loss: 0.547163, acc: 75.78%] [G loss: 1.497206]\n",
      "epoch:0 step:581 [D loss: 0.805299, acc: 60.94%] [G loss: 2.274591]\n",
      "epoch:0 step:582 [D loss: 0.884737, acc: 52.34%] [G loss: 2.010143]\n",
      "epoch:0 step:583 [D loss: 1.495916, acc: 35.16%] [G loss: 2.055338]\n",
      "epoch:0 step:584 [D loss: 0.831043, acc: 59.38%] [G loss: 1.910864]\n",
      "epoch:0 step:585 [D loss: 0.226191, acc: 92.19%] [G loss: 2.915237]\n",
      "epoch:0 step:586 [D loss: 0.281555, acc: 89.06%] [G loss: 2.830303]\n",
      "epoch:0 step:587 [D loss: 0.563022, acc: 72.66%] [G loss: 2.270960]\n",
      "epoch:0 step:588 [D loss: 0.405616, acc: 82.03%] [G loss: 2.081859]\n",
      "epoch:0 step:589 [D loss: 0.592912, acc: 68.75%] [G loss: 2.283153]\n",
      "epoch:0 step:590 [D loss: 0.604563, acc: 66.41%] [G loss: 2.395407]\n",
      "epoch:0 step:591 [D loss: 1.098421, acc: 36.72%] [G loss: 1.813665]\n",
      "epoch:0 step:592 [D loss: 0.424559, acc: 81.25%] [G loss: 2.280927]\n",
      "epoch:0 step:593 [D loss: 0.304599, acc: 89.84%] [G loss: 2.471139]\n",
      "epoch:0 step:594 [D loss: 0.367699, acc: 82.03%] [G loss: 2.875324]\n",
      "epoch:0 step:595 [D loss: 0.333066, acc: 85.94%] [G loss: 1.543144]\n",
      "epoch:0 step:596 [D loss: 0.828724, acc: 55.47%] [G loss: 2.940179]\n",
      "epoch:0 step:597 [D loss: 0.296446, acc: 86.72%] [G loss: 3.315664]\n",
      "epoch:0 step:598 [D loss: 0.224116, acc: 96.09%] [G loss: 3.176188]\n",
      "epoch:0 step:599 [D loss: 0.340333, acc: 81.25%] [G loss: 2.630344]\n",
      "epoch:0 step:600 [D loss: 0.093495, acc: 99.22%] [G loss: 3.186930]\n",
      "epoch:0 step:601 [D loss: 0.474215, acc: 80.47%] [G loss: 2.052579]\n",
      "epoch:0 step:602 [D loss: 0.170301, acc: 97.66%] [G loss: 2.622594]\n",
      "epoch:0 step:603 [D loss: 0.543609, acc: 70.31%] [G loss: 3.337408]\n",
      "epoch:0 step:604 [D loss: 1.474887, acc: 47.66%] [G loss: 2.633071]\n",
      "epoch:0 step:605 [D loss: 0.454285, acc: 78.91%] [G loss: 2.700466]\n",
      "epoch:0 step:606 [D loss: 0.274744, acc: 92.97%] [G loss: 3.008453]\n",
      "epoch:0 step:607 [D loss: 0.139282, acc: 99.22%] [G loss: 3.190259]\n",
      "epoch:0 step:608 [D loss: 0.163044, acc: 98.44%] [G loss: 3.228769]\n",
      "epoch:0 step:609 [D loss: 0.255283, acc: 94.53%] [G loss: 2.457114]\n",
      "epoch:0 step:610 [D loss: 0.210077, acc: 96.88%] [G loss: 3.000681]\n",
      "epoch:0 step:611 [D loss: 0.328395, acc: 86.72%] [G loss: 3.099205]\n",
      "epoch:0 step:612 [D loss: 0.254932, acc: 92.97%] [G loss: 2.981712]\n",
      "epoch:0 step:613 [D loss: 0.539868, acc: 75.00%] [G loss: 3.556363]\n",
      "epoch:0 step:614 [D loss: 0.362196, acc: 82.03%] [G loss: 3.413575]\n",
      "epoch:0 step:615 [D loss: 0.106842, acc: 96.09%] [G loss: 3.608576]\n",
      "epoch:0 step:616 [D loss: 0.259531, acc: 92.19%] [G loss: 3.118380]\n",
      "epoch:0 step:617 [D loss: 0.121850, acc: 99.22%] [G loss: 3.827715]\n",
      "epoch:0 step:618 [D loss: 0.362690, acc: 87.50%] [G loss: 2.558450]\n",
      "epoch:0 step:619 [D loss: 0.293554, acc: 91.41%] [G loss: 3.508818]\n",
      "epoch:0 step:620 [D loss: 0.150555, acc: 96.88%] [G loss: 3.675267]\n",
      "epoch:0 step:621 [D loss: 0.232284, acc: 93.75%] [G loss: 2.646098]\n",
      "epoch:0 step:622 [D loss: 0.197425, acc: 92.19%] [G loss: 3.592877]\n",
      "epoch:0 step:623 [D loss: 0.186615, acc: 96.88%] [G loss: 3.103860]\n",
      "epoch:0 step:624 [D loss: 0.380496, acc: 85.94%] [G loss: 2.576498]\n",
      "epoch:0 step:625 [D loss: 0.396091, acc: 89.06%] [G loss: 3.019264]\n",
      "epoch:0 step:626 [D loss: 0.153414, acc: 96.88%] [G loss: 3.459528]\n",
      "epoch:0 step:627 [D loss: 0.329655, acc: 89.84%] [G loss: 2.662014]\n",
      "epoch:0 step:628 [D loss: 0.369198, acc: 85.16%] [G loss: 3.722016]\n",
      "epoch:0 step:629 [D loss: 0.446214, acc: 79.69%] [G loss: 2.604269]\n",
      "epoch:0 step:630 [D loss: 0.308396, acc: 87.50%] [G loss: 2.405458]\n",
      "epoch:0 step:631 [D loss: 0.287782, acc: 90.62%] [G loss: 2.467919]\n",
      "epoch:0 step:632 [D loss: 0.700977, acc: 69.53%] [G loss: 2.431424]\n",
      "epoch:0 step:633 [D loss: 0.544269, acc: 76.56%] [G loss: 1.779223]\n",
      "epoch:0 step:634 [D loss: 0.445553, acc: 74.22%] [G loss: 2.826608]\n",
      "epoch:0 step:635 [D loss: 0.199454, acc: 96.88%] [G loss: 2.613357]\n",
      "epoch:0 step:636 [D loss: 0.688916, acc: 63.28%] [G loss: 2.603470]\n",
      "epoch:0 step:637 [D loss: 1.004766, acc: 54.69%] [G loss: 2.064814]\n",
      "epoch:0 step:638 [D loss: 1.332880, acc: 48.44%] [G loss: 1.547927]\n",
      "epoch:0 step:639 [D loss: 0.595620, acc: 71.09%] [G loss: 1.777828]\n",
      "epoch:0 step:640 [D loss: 0.850960, acc: 49.22%] [G loss: 1.924492]\n",
      "epoch:0 step:641 [D loss: 1.096348, acc: 32.81%] [G loss: 1.446585]\n",
      "epoch:0 step:642 [D loss: 0.505181, acc: 80.47%] [G loss: 2.005068]\n",
      "epoch:0 step:643 [D loss: 1.292682, acc: 19.53%] [G loss: 1.541071]\n",
      "epoch:0 step:644 [D loss: 0.709030, acc: 57.81%] [G loss: 1.748485]\n",
      "epoch:0 step:645 [D loss: 1.256361, acc: 32.03%] [G loss: 1.525553]\n",
      "epoch:0 step:646 [D loss: 0.689475, acc: 53.91%] [G loss: 2.472226]\n",
      "epoch:0 step:647 [D loss: 0.953389, acc: 45.31%] [G loss: 2.080459]\n",
      "epoch:0 step:648 [D loss: 0.809742, acc: 61.72%] [G loss: 2.064123]\n",
      "epoch:0 step:649 [D loss: 1.311074, acc: 42.19%] [G loss: 3.189711]\n",
      "epoch:0 step:650 [D loss: 0.752785, acc: 63.28%] [G loss: 2.780774]\n",
      "epoch:0 step:651 [D loss: 0.975044, acc: 52.34%] [G loss: 2.192993]\n",
      "epoch:0 step:652 [D loss: 0.767772, acc: 68.75%] [G loss: 2.628513]\n",
      "epoch:0 step:653 [D loss: 0.509258, acc: 76.56%] [G loss: 2.922494]\n",
      "epoch:0 step:654 [D loss: 0.603436, acc: 75.00%] [G loss: 3.279376]\n",
      "epoch:0 step:655 [D loss: 0.623486, acc: 67.19%] [G loss: 3.730625]\n",
      "epoch:0 step:656 [D loss: 0.832881, acc: 59.38%] [G loss: 2.692176]\n",
      "epoch:0 step:657 [D loss: 0.572640, acc: 77.34%] [G loss: 3.439242]\n",
      "epoch:0 step:658 [D loss: 0.373586, acc: 90.62%] [G loss: 4.945542]\n",
      "epoch:0 step:659 [D loss: 0.346908, acc: 86.72%] [G loss: 4.640520]\n",
      "epoch:0 step:660 [D loss: 0.545069, acc: 81.25%] [G loss: 3.316658]\n",
      "epoch:0 step:661 [D loss: 0.358948, acc: 82.81%] [G loss: 4.254263]\n",
      "epoch:0 step:662 [D loss: 0.318567, acc: 93.75%] [G loss: 4.528149]\n",
      "epoch:0 step:663 [D loss: 0.180599, acc: 96.88%] [G loss: 3.393756]\n",
      "epoch:0 step:664 [D loss: 0.275135, acc: 92.97%] [G loss: 3.178557]\n",
      "epoch:0 step:665 [D loss: 0.236713, acc: 93.75%] [G loss: 3.247651]\n",
      "epoch:0 step:666 [D loss: 0.564939, acc: 81.25%] [G loss: 3.018669]\n",
      "epoch:0 step:667 [D loss: 0.301601, acc: 92.19%] [G loss: 3.238655]\n",
      "epoch:0 step:668 [D loss: 0.174156, acc: 96.09%] [G loss: 3.756150]\n",
      "epoch:0 step:669 [D loss: 0.534907, acc: 83.59%] [G loss: 2.442406]\n",
      "epoch:0 step:670 [D loss: 0.519404, acc: 75.00%] [G loss: 3.013567]\n",
      "epoch:0 step:671 [D loss: 0.123942, acc: 96.09%] [G loss: 3.276904]\n",
      "epoch:0 step:672 [D loss: 0.261077, acc: 89.06%] [G loss: 2.510207]\n",
      "epoch:0 step:673 [D loss: 0.482147, acc: 78.91%] [G loss: 2.413046]\n",
      "epoch:0 step:674 [D loss: 0.230334, acc: 94.53%] [G loss: 2.709131]\n",
      "epoch:0 step:675 [D loss: 0.227344, acc: 93.75%] [G loss: 2.981383]\n",
      "epoch:0 step:676 [D loss: 0.181539, acc: 95.31%] [G loss: 3.053202]\n",
      "epoch:0 step:677 [D loss: 0.664363, acc: 67.97%] [G loss: 2.618625]\n",
      "epoch:0 step:678 [D loss: 0.213245, acc: 94.53%] [G loss: 2.803250]\n",
      "epoch:0 step:679 [D loss: 0.248986, acc: 96.09%] [G loss: 2.543345]\n",
      "epoch:0 step:680 [D loss: 0.559991, acc: 78.12%] [G loss: 2.295166]\n",
      "epoch:0 step:681 [D loss: 0.326777, acc: 90.62%] [G loss: 2.699094]\n",
      "epoch:0 step:682 [D loss: 1.745552, acc: 27.34%] [G loss: 1.991719]\n",
      "epoch:0 step:683 [D loss: 0.571398, acc: 75.00%] [G loss: 2.062221]\n",
      "epoch:0 step:684 [D loss: 0.272098, acc: 92.97%] [G loss: 3.246918]\n",
      "epoch:0 step:685 [D loss: 0.367544, acc: 82.03%] [G loss: 2.389599]\n",
      "epoch:0 step:686 [D loss: 0.667725, acc: 64.84%] [G loss: 1.956992]\n",
      "epoch:0 step:687 [D loss: 0.793450, acc: 58.59%] [G loss: 1.772582]\n",
      "epoch:0 step:688 [D loss: 0.412687, acc: 82.81%] [G loss: 2.601596]\n",
      "epoch:0 step:689 [D loss: 0.470299, acc: 79.69%] [G loss: 2.532008]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:690 [D loss: 0.650168, acc: 66.41%] [G loss: 2.181650]\n",
      "epoch:0 step:691 [D loss: 0.899543, acc: 57.03%] [G loss: 2.292404]\n",
      "epoch:0 step:692 [D loss: 0.961685, acc: 49.22%] [G loss: 2.381391]\n",
      "epoch:0 step:693 [D loss: 0.794569, acc: 67.97%] [G loss: 2.556318]\n",
      "epoch:0 step:694 [D loss: 0.505007, acc: 81.25%] [G loss: 3.068858]\n",
      "epoch:0 step:695 [D loss: 1.032258, acc: 44.53%] [G loss: 2.738152]\n",
      "epoch:0 step:696 [D loss: 0.661332, acc: 67.97%] [G loss: 3.091466]\n",
      "epoch:0 step:697 [D loss: 1.011876, acc: 49.22%] [G loss: 2.620969]\n",
      "epoch:0 step:698 [D loss: 0.730079, acc: 64.84%] [G loss: 4.070917]\n",
      "epoch:0 step:699 [D loss: 0.657424, acc: 66.41%] [G loss: 3.673080]\n",
      "epoch:0 step:700 [D loss: 1.075460, acc: 55.47%] [G loss: 3.031520]\n",
      "epoch:0 step:701 [D loss: 0.689184, acc: 69.53%] [G loss: 3.402924]\n",
      "epoch:0 step:702 [D loss: 0.620831, acc: 70.31%] [G loss: 3.598256]\n",
      "epoch:0 step:703 [D loss: 0.449468, acc: 82.03%] [G loss: 3.263234]\n",
      "epoch:0 step:704 [D loss: 0.644446, acc: 65.62%] [G loss: 3.334735]\n",
      "epoch:0 step:705 [D loss: 0.340410, acc: 87.50%] [G loss: 2.922571]\n",
      "epoch:0 step:706 [D loss: 0.341239, acc: 88.28%] [G loss: 3.441671]\n",
      "epoch:0 step:707 [D loss: 0.275762, acc: 90.62%] [G loss: 3.231680]\n",
      "epoch:0 step:708 [D loss: 0.251408, acc: 89.84%] [G loss: 3.456878]\n",
      "epoch:0 step:709 [D loss: 0.157484, acc: 96.88%] [G loss: 3.495623]\n",
      "epoch:0 step:710 [D loss: 0.230064, acc: 94.53%] [G loss: 2.914245]\n",
      "epoch:0 step:711 [D loss: 0.701571, acc: 65.62%] [G loss: 2.360507]\n",
      "epoch:0 step:712 [D loss: 0.220632, acc: 94.53%] [G loss: 3.286004]\n",
      "epoch:0 step:713 [D loss: 0.235030, acc: 93.75%] [G loss: 3.587701]\n",
      "epoch:0 step:714 [D loss: 0.524648, acc: 71.88%] [G loss: 2.534791]\n",
      "epoch:0 step:715 [D loss: 0.267018, acc: 92.97%] [G loss: 3.629736]\n",
      "epoch:0 step:716 [D loss: 0.214532, acc: 93.75%] [G loss: 3.798685]\n",
      "epoch:0 step:717 [D loss: 0.270486, acc: 87.50%] [G loss: 3.068810]\n",
      "epoch:0 step:718 [D loss: 0.472326, acc: 75.00%] [G loss: 2.860307]\n",
      "epoch:0 step:719 [D loss: 0.140741, acc: 97.66%] [G loss: 4.025976]\n",
      "epoch:0 step:720 [D loss: 0.332677, acc: 90.62%] [G loss: 2.817554]\n",
      "epoch:0 step:721 [D loss: 0.931454, acc: 53.12%] [G loss: 2.275058]\n",
      "epoch:0 step:722 [D loss: 0.329990, acc: 88.28%] [G loss: 3.155194]\n",
      "epoch:0 step:723 [D loss: 1.127069, acc: 38.28%] [G loss: 2.011615]\n",
      "epoch:0 step:724 [D loss: 0.214310, acc: 95.31%] [G loss: 3.202232]\n",
      "epoch:0 step:725 [D loss: 0.405989, acc: 82.03%] [G loss: 3.463582]\n",
      "epoch:0 step:726 [D loss: 0.728936, acc: 64.06%] [G loss: 2.537330]\n",
      "epoch:0 step:727 [D loss: 0.160136, acc: 96.88%] [G loss: 4.422670]\n",
      "epoch:0 step:728 [D loss: 1.542803, acc: 41.41%] [G loss: 2.228801]\n",
      "epoch:0 step:729 [D loss: 1.535519, acc: 35.16%] [G loss: 2.331412]\n",
      "epoch:0 step:730 [D loss: 0.477514, acc: 80.47%] [G loss: 3.346623]\n",
      "epoch:0 step:731 [D loss: 0.958960, acc: 50.00%] [G loss: 2.643420]\n",
      "epoch:0 step:732 [D loss: 0.935052, acc: 50.78%] [G loss: 2.837947]\n",
      "epoch:0 step:733 [D loss: 0.752918, acc: 64.06%] [G loss: 3.085189]\n",
      "epoch:0 step:734 [D loss: 0.970125, acc: 42.97%] [G loss: 2.727788]\n",
      "epoch:0 step:735 [D loss: 0.627920, acc: 67.97%] [G loss: 3.739037]\n",
      "epoch:0 step:736 [D loss: 0.649691, acc: 71.09%] [G loss: 3.002237]\n",
      "epoch:0 step:737 [D loss: 0.598651, acc: 67.19%] [G loss: 2.980512]\n",
      "epoch:0 step:738 [D loss: 1.136684, acc: 42.19%] [G loss: 2.745469]\n",
      "epoch:0 step:739 [D loss: 0.633639, acc: 67.97%] [G loss: 2.556866]\n",
      "epoch:0 step:740 [D loss: 0.175727, acc: 96.09%] [G loss: 3.875049]\n",
      "epoch:0 step:741 [D loss: 0.458528, acc: 78.12%] [G loss: 3.477840]\n",
      "epoch:0 step:742 [D loss: 0.822438, acc: 62.50%] [G loss: 2.029588]\n",
      "epoch:0 step:743 [D loss: 0.304762, acc: 89.06%] [G loss: 2.899015]\n",
      "epoch:0 step:744 [D loss: 0.279414, acc: 92.97%] [G loss: 3.300371]\n",
      "epoch:0 step:745 [D loss: 0.161546, acc: 96.88%] [G loss: 3.235783]\n",
      "epoch:0 step:746 [D loss: 0.198421, acc: 95.31%] [G loss: 3.098213]\n",
      "epoch:0 step:747 [D loss: 0.266896, acc: 92.19%] [G loss: 3.453989]\n",
      "epoch:0 step:748 [D loss: 0.253676, acc: 92.19%] [G loss: 2.815905]\n",
      "epoch:0 step:749 [D loss: 0.396316, acc: 82.03%] [G loss: 3.671954]\n",
      "epoch:0 step:750 [D loss: 0.224504, acc: 92.97%] [G loss: 3.929219]\n",
      "epoch:0 step:751 [D loss: 0.231315, acc: 92.97%] [G loss: 3.963146]\n",
      "epoch:0 step:752 [D loss: 0.188815, acc: 96.09%] [G loss: 3.634018]\n",
      "epoch:0 step:753 [D loss: 0.402066, acc: 85.16%] [G loss: 3.247862]\n",
      "epoch:0 step:754 [D loss: 0.279818, acc: 89.06%] [G loss: 2.659512]\n",
      "epoch:0 step:755 [D loss: 0.224310, acc: 93.75%] [G loss: 3.668354]\n",
      "epoch:0 step:756 [D loss: 0.161298, acc: 96.88%] [G loss: 4.406155]\n",
      "epoch:0 step:757 [D loss: 0.179249, acc: 93.75%] [G loss: 3.309676]\n",
      "epoch:0 step:758 [D loss: 0.217165, acc: 94.53%] [G loss: 3.386241]\n",
      "epoch:0 step:759 [D loss: 0.271234, acc: 91.41%] [G loss: 2.976773]\n",
      "epoch:0 step:760 [D loss: 0.239199, acc: 90.62%] [G loss: 4.728748]\n",
      "epoch:0 step:761 [D loss: 0.071487, acc: 99.22%] [G loss: 4.097342]\n",
      "epoch:0 step:762 [D loss: 0.414207, acc: 85.16%] [G loss: 2.592979]\n",
      "epoch:0 step:763 [D loss: 0.221689, acc: 94.53%] [G loss: 3.257314]\n",
      "epoch:0 step:764 [D loss: 0.468116, acc: 78.12%] [G loss: 4.272146]\n",
      "epoch:0 step:765 [D loss: 0.683377, acc: 64.06%] [G loss: 2.867948]\n",
      "epoch:0 step:766 [D loss: 0.196535, acc: 92.19%] [G loss: 3.105387]\n",
      "epoch:0 step:767 [D loss: 0.283129, acc: 89.06%] [G loss: 3.123001]\n",
      "epoch:0 step:768 [D loss: 0.135507, acc: 97.66%] [G loss: 3.470066]\n",
      "epoch:0 step:769 [D loss: 0.511557, acc: 75.78%] [G loss: 2.268065]\n",
      "epoch:0 step:770 [D loss: 0.532159, acc: 77.34%] [G loss: 2.326208]\n",
      "epoch:0 step:771 [D loss: 0.676892, acc: 60.16%] [G loss: 3.652926]\n",
      "epoch:0 step:772 [D loss: 0.544640, acc: 67.97%] [G loss: 3.097126]\n",
      "epoch:0 step:773 [D loss: 0.901712, acc: 51.56%] [G loss: 2.675262]\n",
      "epoch:0 step:774 [D loss: 0.346490, acc: 88.28%] [G loss: 3.272114]\n",
      "epoch:0 step:775 [D loss: 0.604113, acc: 71.09%] [G loss: 3.213440]\n",
      "epoch:0 step:776 [D loss: 0.293453, acc: 92.19%] [G loss: 3.146302]\n",
      "epoch:0 step:777 [D loss: 0.537965, acc: 78.91%] [G loss: 3.685597]\n",
      "epoch:0 step:778 [D loss: 0.272754, acc: 91.41%] [G loss: 4.085674]\n",
      "epoch:0 step:779 [D loss: 0.330609, acc: 89.06%] [G loss: 3.068663]\n",
      "epoch:0 step:780 [D loss: 1.065656, acc: 37.50%] [G loss: 2.356346]\n",
      "epoch:0 step:781 [D loss: 0.179146, acc: 95.31%] [G loss: 3.654401]\n",
      "epoch:1 step:782 [D loss: 0.074380, acc: 98.44%] [G loss: 4.713675]\n",
      "epoch:1 step:783 [D loss: 0.101879, acc: 98.44%] [G loss: 3.682463]\n",
      "epoch:1 step:784 [D loss: 0.191841, acc: 96.88%] [G loss: 3.580446]\n",
      "epoch:1 step:785 [D loss: 0.329691, acc: 87.50%] [G loss: 3.017872]\n",
      "epoch:1 step:786 [D loss: 0.330480, acc: 86.72%] [G loss: 2.980099]\n",
      "epoch:1 step:787 [D loss: 0.236627, acc: 91.41%] [G loss: 3.893485]\n",
      "epoch:1 step:788 [D loss: 0.102950, acc: 99.22%] [G loss: 3.425920]\n",
      "epoch:1 step:789 [D loss: 0.056182, acc: 100.00%] [G loss: 3.308199]\n",
      "epoch:1 step:790 [D loss: 0.300417, acc: 88.28%] [G loss: 2.575033]\n",
      "epoch:1 step:791 [D loss: 0.050964, acc: 100.00%] [G loss: 3.332076]\n",
      "epoch:1 step:792 [D loss: 0.522710, acc: 67.19%] [G loss: 3.680806]\n",
      "epoch:1 step:793 [D loss: 0.874975, acc: 64.06%] [G loss: 2.481141]\n",
      "epoch:1 step:794 [D loss: 0.051218, acc: 100.00%] [G loss: 3.772488]\n",
      "epoch:1 step:795 [D loss: 0.314410, acc: 88.28%] [G loss: 2.788672]\n",
      "epoch:1 step:796 [D loss: 0.052357, acc: 100.00%] [G loss: 3.656031]\n",
      "epoch:1 step:797 [D loss: 0.310315, acc: 86.72%] [G loss: 3.018126]\n",
      "epoch:1 step:798 [D loss: 0.150099, acc: 96.88%] [G loss: 3.503696]\n",
      "epoch:1 step:799 [D loss: 0.996570, acc: 53.91%] [G loss: 3.412318]\n",
      "epoch:1 step:800 [D loss: 0.334684, acc: 84.38%] [G loss: 2.549864]\n",
      "epoch:1 step:801 [D loss: 0.323959, acc: 82.03%] [G loss: 2.866670]\n",
      "epoch:1 step:802 [D loss: 0.358999, acc: 82.81%] [G loss: 3.638551]\n",
      "epoch:1 step:803 [D loss: 0.115862, acc: 99.22%] [G loss: 2.826071]\n",
      "epoch:1 step:804 [D loss: 0.214244, acc: 92.97%] [G loss: 2.984234]\n",
      "epoch:1 step:805 [D loss: 0.401724, acc: 85.94%] [G loss: 2.326702]\n",
      "epoch:1 step:806 [D loss: 0.376524, acc: 85.94%] [G loss: 2.346540]\n",
      "epoch:1 step:807 [D loss: 1.103295, acc: 52.34%] [G loss: 1.814386]\n",
      "epoch:1 step:808 [D loss: 1.276616, acc: 52.34%] [G loss: 2.367991]\n",
      "epoch:1 step:809 [D loss: 0.343599, acc: 82.81%] [G loss: 2.549994]\n",
      "epoch:1 step:810 [D loss: 0.646997, acc: 68.75%] [G loss: 2.875768]\n",
      "epoch:1 step:811 [D loss: 1.216678, acc: 46.09%] [G loss: 2.249395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:812 [D loss: 1.186977, acc: 51.56%] [G loss: 2.940533]\n",
      "epoch:1 step:813 [D loss: 0.970490, acc: 56.25%] [G loss: 2.096497]\n",
      "epoch:1 step:814 [D loss: 1.796563, acc: 21.09%] [G loss: 1.630737]\n",
      "epoch:1 step:815 [D loss: 1.169629, acc: 35.16%] [G loss: 1.826410]\n",
      "epoch:1 step:816 [D loss: 0.807315, acc: 64.06%] [G loss: 2.195031]\n",
      "epoch:1 step:817 [D loss: 0.492589, acc: 77.34%] [G loss: 2.620430]\n",
      "epoch:1 step:818 [D loss: 1.428787, acc: 35.16%] [G loss: 1.597685]\n",
      "epoch:1 step:819 [D loss: 0.750977, acc: 57.03%] [G loss: 1.981343]\n",
      "epoch:1 step:820 [D loss: 1.152339, acc: 34.38%] [G loss: 1.641848]\n",
      "epoch:1 step:821 [D loss: 1.373085, acc: 22.66%] [G loss: 1.619589]\n",
      "epoch:1 step:822 [D loss: 0.976191, acc: 42.19%] [G loss: 1.554433]\n",
      "epoch:1 step:823 [D loss: 0.974031, acc: 47.66%] [G loss: 1.871453]\n",
      "epoch:1 step:824 [D loss: 0.855231, acc: 49.22%] [G loss: 2.065161]\n",
      "epoch:1 step:825 [D loss: 0.668700, acc: 64.06%] [G loss: 2.213272]\n",
      "epoch:1 step:826 [D loss: 0.750349, acc: 57.03%] [G loss: 2.216262]\n",
      "epoch:1 step:827 [D loss: 0.668575, acc: 67.19%] [G loss: 2.281266]\n",
      "epoch:1 step:828 [D loss: 0.721991, acc: 57.03%] [G loss: 2.119761]\n",
      "epoch:1 step:829 [D loss: 0.665716, acc: 57.03%] [G loss: 2.389386]\n",
      "epoch:1 step:830 [D loss: 0.553092, acc: 72.66%] [G loss: 2.625321]\n",
      "epoch:1 step:831 [D loss: 0.579644, acc: 68.75%] [G loss: 2.308618]\n",
      "epoch:1 step:832 [D loss: 0.613425, acc: 71.88%] [G loss: 2.490999]\n",
      "epoch:1 step:833 [D loss: 0.539878, acc: 71.09%] [G loss: 2.476468]\n",
      "epoch:1 step:834 [D loss: 0.458377, acc: 80.47%] [G loss: 2.971364]\n",
      "epoch:1 step:835 [D loss: 0.461313, acc: 77.34%] [G loss: 2.889879]\n",
      "epoch:1 step:836 [D loss: 0.790292, acc: 59.38%] [G loss: 2.450928]\n",
      "epoch:1 step:837 [D loss: 0.788450, acc: 50.78%] [G loss: 2.679245]\n",
      "epoch:1 step:838 [D loss: 0.602629, acc: 68.75%] [G loss: 2.740390]\n",
      "epoch:1 step:839 [D loss: 0.610701, acc: 69.53%] [G loss: 3.301671]\n",
      "epoch:1 step:840 [D loss: 0.542983, acc: 68.75%] [G loss: 3.134058]\n",
      "epoch:1 step:841 [D loss: 0.603236, acc: 71.88%] [G loss: 2.875112]\n",
      "epoch:1 step:842 [D loss: 0.474466, acc: 78.91%] [G loss: 3.387304]\n",
      "epoch:1 step:843 [D loss: 0.339273, acc: 89.06%] [G loss: 3.441116]\n",
      "epoch:1 step:844 [D loss: 0.325876, acc: 90.62%] [G loss: 3.450334]\n",
      "epoch:1 step:845 [D loss: 0.612611, acc: 68.75%] [G loss: 2.750472]\n",
      "epoch:1 step:846 [D loss: 0.753749, acc: 51.56%] [G loss: 2.353882]\n",
      "epoch:1 step:847 [D loss: 0.666316, acc: 64.84%] [G loss: 2.623035]\n",
      "epoch:1 step:848 [D loss: 0.296585, acc: 91.41%] [G loss: 3.292230]\n",
      "epoch:1 step:849 [D loss: 0.401028, acc: 82.03%] [G loss: 2.934508]\n",
      "epoch:1 step:850 [D loss: 0.437566, acc: 82.81%] [G loss: 2.740801]\n",
      "epoch:1 step:851 [D loss: 0.534527, acc: 73.44%] [G loss: 3.567486]\n",
      "epoch:1 step:852 [D loss: 0.867161, acc: 51.56%] [G loss: 2.116402]\n",
      "epoch:1 step:853 [D loss: 0.347771, acc: 89.06%] [G loss: 2.956926]\n",
      "epoch:1 step:854 [D loss: 0.580200, acc: 77.34%] [G loss: 2.268445]\n",
      "epoch:1 step:855 [D loss: 0.451325, acc: 84.38%] [G loss: 2.417888]\n",
      "epoch:1 step:856 [D loss: 0.852282, acc: 57.03%] [G loss: 2.534470]\n",
      "epoch:1 step:857 [D loss: 0.855796, acc: 55.47%] [G loss: 2.076101]\n",
      "epoch:1 step:858 [D loss: 0.691618, acc: 60.94%] [G loss: 2.053045]\n",
      "epoch:1 step:859 [D loss: 0.660004, acc: 55.47%] [G loss: 1.829018]\n",
      "epoch:1 step:860 [D loss: 0.957900, acc: 46.88%] [G loss: 1.796094]\n",
      "epoch:1 step:861 [D loss: 0.519536, acc: 80.47%] [G loss: 1.966872]\n",
      "epoch:1 step:862 [D loss: 0.569427, acc: 71.09%] [G loss: 1.653871]\n",
      "epoch:1 step:863 [D loss: 1.016844, acc: 34.38%] [G loss: 1.634192]\n",
      "epoch:1 step:864 [D loss: 0.393495, acc: 90.62%] [G loss: 2.422245]\n",
      "epoch:1 step:865 [D loss: 0.477534, acc: 73.44%] [G loss: 2.257099]\n",
      "epoch:1 step:866 [D loss: 0.584242, acc: 69.53%] [G loss: 2.053356]\n",
      "epoch:1 step:867 [D loss: 0.508546, acc: 71.88%] [G loss: 1.760139]\n",
      "epoch:1 step:868 [D loss: 0.936717, acc: 48.44%] [G loss: 1.426483]\n",
      "epoch:1 step:869 [D loss: 0.679684, acc: 61.72%] [G loss: 1.924299]\n",
      "epoch:1 step:870 [D loss: 0.799593, acc: 53.91%] [G loss: 1.383917]\n",
      "epoch:1 step:871 [D loss: 0.901253, acc: 53.91%] [G loss: 1.228699]\n",
      "epoch:1 step:872 [D loss: 0.664271, acc: 60.94%] [G loss: 1.837595]\n",
      "epoch:1 step:873 [D loss: 0.722086, acc: 58.59%] [G loss: 1.632346]\n",
      "epoch:1 step:874 [D loss: 0.706568, acc: 54.69%] [G loss: 1.638314]\n",
      "epoch:1 step:875 [D loss: 0.337494, acc: 92.97%] [G loss: 2.307426]\n",
      "epoch:1 step:876 [D loss: 1.086244, acc: 35.16%] [G loss: 1.180655]\n",
      "epoch:1 step:877 [D loss: 0.858919, acc: 46.09%] [G loss: 1.486554]\n",
      "epoch:1 step:878 [D loss: 1.058685, acc: 35.94%] [G loss: 1.539003]\n",
      "epoch:1 step:879 [D loss: 1.163854, acc: 36.72%] [G loss: 1.106365]\n",
      "epoch:1 step:880 [D loss: 0.969671, acc: 39.84%] [G loss: 1.339806]\n",
      "epoch:1 step:881 [D loss: 1.014756, acc: 28.91%] [G loss: 1.206871]\n",
      "epoch:1 step:882 [D loss: 1.212296, acc: 21.09%] [G loss: 1.318949]\n",
      "epoch:1 step:883 [D loss: 0.569441, acc: 66.41%] [G loss: 1.768277]\n",
      "epoch:1 step:884 [D loss: 0.927391, acc: 43.75%] [G loss: 1.586647]\n",
      "epoch:1 step:885 [D loss: 0.804386, acc: 51.56%] [G loss: 1.866359]\n",
      "epoch:1 step:886 [D loss: 0.640939, acc: 65.62%] [G loss: 1.939267]\n",
      "epoch:1 step:887 [D loss: 0.739152, acc: 57.81%] [G loss: 1.827783]\n",
      "epoch:1 step:888 [D loss: 0.818217, acc: 48.44%] [G loss: 2.028370]\n",
      "epoch:1 step:889 [D loss: 0.767519, acc: 59.38%] [G loss: 2.290173]\n",
      "epoch:1 step:890 [D loss: 0.719201, acc: 58.59%] [G loss: 2.406740]\n",
      "epoch:1 step:891 [D loss: 0.673675, acc: 64.06%] [G loss: 2.687364]\n",
      "epoch:1 step:892 [D loss: 0.685164, acc: 60.94%] [G loss: 2.459594]\n",
      "epoch:1 step:893 [D loss: 0.642235, acc: 68.75%] [G loss: 2.420166]\n",
      "epoch:1 step:894 [D loss: 0.668047, acc: 63.28%] [G loss: 2.252053]\n",
      "epoch:1 step:895 [D loss: 0.696503, acc: 60.94%] [G loss: 2.364476]\n",
      "epoch:1 step:896 [D loss: 0.715472, acc: 53.12%] [G loss: 2.301177]\n",
      "epoch:1 step:897 [D loss: 0.629388, acc: 65.62%] [G loss: 2.870713]\n",
      "epoch:1 step:898 [D loss: 0.808097, acc: 48.44%] [G loss: 1.812987]\n",
      "epoch:1 step:899 [D loss: 0.550674, acc: 75.00%] [G loss: 2.294832]\n",
      "epoch:1 step:900 [D loss: 0.505088, acc: 76.56%] [G loss: 2.451488]\n",
      "epoch:1 step:901 [D loss: 0.666916, acc: 72.66%] [G loss: 2.445113]\n",
      "epoch:1 step:902 [D loss: 0.559150, acc: 73.44%] [G loss: 2.649906]\n",
      "epoch:1 step:903 [D loss: 0.439379, acc: 82.03%] [G loss: 2.078959]\n",
      "epoch:1 step:904 [D loss: 0.535306, acc: 70.31%] [G loss: 2.378233]\n",
      "epoch:1 step:905 [D loss: 0.495598, acc: 81.25%] [G loss: 2.399401]\n",
      "epoch:1 step:906 [D loss: 0.460088, acc: 84.38%] [G loss: 2.749060]\n",
      "epoch:1 step:907 [D loss: 0.792650, acc: 57.81%] [G loss: 2.093384]\n",
      "epoch:1 step:908 [D loss: 0.431346, acc: 79.69%] [G loss: 2.301457]\n",
      "epoch:1 step:909 [D loss: 0.506495, acc: 80.47%] [G loss: 2.477986]\n",
      "epoch:1 step:910 [D loss: 0.600854, acc: 68.75%] [G loss: 2.300770]\n",
      "epoch:1 step:911 [D loss: 0.599176, acc: 67.97%] [G loss: 1.890826]\n",
      "epoch:1 step:912 [D loss: 0.557381, acc: 75.00%] [G loss: 2.056666]\n",
      "epoch:1 step:913 [D loss: 0.423067, acc: 79.69%] [G loss: 2.780059]\n",
      "epoch:1 step:914 [D loss: 0.360266, acc: 86.72%] [G loss: 2.117517]\n",
      "epoch:1 step:915 [D loss: 0.173090, acc: 99.22%] [G loss: 2.789019]\n",
      "epoch:1 step:916 [D loss: 0.576496, acc: 75.78%] [G loss: 2.147847]\n",
      "epoch:1 step:917 [D loss: 0.748574, acc: 57.81%] [G loss: 1.994367]\n",
      "epoch:1 step:918 [D loss: 0.218653, acc: 96.88%] [G loss: 2.457019]\n",
      "epoch:1 step:919 [D loss: 0.611030, acc: 67.19%] [G loss: 1.721187]\n",
      "epoch:1 step:920 [D loss: 0.705016, acc: 55.47%] [G loss: 1.850985]\n",
      "epoch:1 step:921 [D loss: 0.718736, acc: 57.81%] [G loss: 1.793801]\n",
      "epoch:1 step:922 [D loss: 0.918934, acc: 39.84%] [G loss: 1.589042]\n",
      "epoch:1 step:923 [D loss: 0.458230, acc: 81.25%] [G loss: 2.251102]\n",
      "epoch:1 step:924 [D loss: 0.633606, acc: 61.72%] [G loss: 1.993815]\n",
      "epoch:1 step:925 [D loss: 1.192980, acc: 25.00%] [G loss: 1.928200]\n",
      "epoch:1 step:926 [D loss: 0.761247, acc: 53.91%] [G loss: 1.263276]\n",
      "epoch:1 step:927 [D loss: 1.101006, acc: 29.69%] [G loss: 1.799258]\n",
      "epoch:1 step:928 [D loss: 0.676329, acc: 60.94%] [G loss: 2.112895]\n",
      "epoch:1 step:929 [D loss: 0.840388, acc: 51.56%] [G loss: 1.752862]\n",
      "epoch:1 step:930 [D loss: 0.989454, acc: 32.81%] [G loss: 1.952616]\n",
      "epoch:1 step:931 [D loss: 1.111974, acc: 32.81%] [G loss: 1.884570]\n",
      "epoch:1 step:932 [D loss: 0.651789, acc: 62.50%] [G loss: 1.878501]\n",
      "epoch:1 step:933 [D loss: 0.657633, acc: 64.06%] [G loss: 1.869313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:934 [D loss: 0.680030, acc: 60.16%] [G loss: 2.080988]\n",
      "epoch:1 step:935 [D loss: 0.808259, acc: 49.22%] [G loss: 2.046208]\n",
      "epoch:1 step:936 [D loss: 0.761326, acc: 58.59%] [G loss: 1.868545]\n",
      "epoch:1 step:937 [D loss: 0.663035, acc: 64.06%] [G loss: 2.441622]\n",
      "epoch:1 step:938 [D loss: 0.740093, acc: 53.12%] [G loss: 1.981180]\n",
      "epoch:1 step:939 [D loss: 0.533519, acc: 75.78%] [G loss: 2.419231]\n",
      "epoch:1 step:940 [D loss: 0.776667, acc: 46.88%] [G loss: 2.161094]\n",
      "epoch:1 step:941 [D loss: 0.642859, acc: 64.84%] [G loss: 1.879309]\n",
      "epoch:1 step:942 [D loss: 0.582504, acc: 73.44%] [G loss: 2.289718]\n",
      "epoch:1 step:943 [D loss: 0.587755, acc: 71.09%] [G loss: 1.964371]\n",
      "epoch:1 step:944 [D loss: 0.611821, acc: 64.06%] [G loss: 2.110232]\n",
      "epoch:1 step:945 [D loss: 0.466435, acc: 83.59%] [G loss: 2.244086]\n",
      "epoch:1 step:946 [D loss: 0.401710, acc: 89.06%] [G loss: 2.120112]\n",
      "epoch:1 step:947 [D loss: 0.516599, acc: 75.00%] [G loss: 2.083735]\n",
      "epoch:1 step:948 [D loss: 0.498624, acc: 74.22%] [G loss: 2.306146]\n",
      "epoch:1 step:949 [D loss: 0.426124, acc: 82.03%] [G loss: 2.619293]\n",
      "epoch:1 step:950 [D loss: 0.390345, acc: 89.06%] [G loss: 2.570183]\n",
      "epoch:1 step:951 [D loss: 0.447143, acc: 82.03%] [G loss: 2.623621]\n",
      "epoch:1 step:952 [D loss: 0.466464, acc: 83.59%] [G loss: 2.074436]\n",
      "epoch:1 step:953 [D loss: 0.456060, acc: 81.25%] [G loss: 2.143963]\n",
      "epoch:1 step:954 [D loss: 0.588682, acc: 71.09%] [G loss: 1.766120]\n",
      "epoch:1 step:955 [D loss: 0.402548, acc: 86.72%] [G loss: 1.902846]\n",
      "epoch:1 step:956 [D loss: 0.640976, acc: 66.41%] [G loss: 1.816189]\n",
      "epoch:1 step:957 [D loss: 0.686322, acc: 60.94%] [G loss: 1.649905]\n",
      "epoch:1 step:958 [D loss: 0.559452, acc: 77.34%] [G loss: 2.242087]\n",
      "epoch:1 step:959 [D loss: 0.593247, acc: 71.09%] [G loss: 1.978361]\n",
      "epoch:1 step:960 [D loss: 0.441587, acc: 82.03%] [G loss: 2.093835]\n",
      "epoch:1 step:961 [D loss: 0.728049, acc: 57.03%] [G loss: 1.560047]\n",
      "epoch:1 step:962 [D loss: 0.822760, acc: 49.22%] [G loss: 2.018730]\n",
      "epoch:1 step:963 [D loss: 0.517187, acc: 73.44%] [G loss: 2.049673]\n",
      "epoch:1 step:964 [D loss: 0.589175, acc: 72.66%] [G loss: 1.942227]\n",
      "epoch:1 step:965 [D loss: 0.621679, acc: 69.53%] [G loss: 2.118052]\n",
      "epoch:1 step:966 [D loss: 0.599730, acc: 70.31%] [G loss: 2.078741]\n",
      "epoch:1 step:967 [D loss: 0.669526, acc: 63.28%] [G loss: 1.808077]\n",
      "epoch:1 step:968 [D loss: 0.930005, acc: 41.41%] [G loss: 0.951800]\n",
      "epoch:1 step:969 [D loss: 0.795988, acc: 42.97%] [G loss: 1.265877]\n",
      "epoch:1 step:970 [D loss: 0.818505, acc: 51.56%] [G loss: 1.386606]\n",
      "epoch:1 step:971 [D loss: 1.112782, acc: 25.00%] [G loss: 1.159542]\n",
      "epoch:1 step:972 [D loss: 1.096047, acc: 35.16%] [G loss: 1.391875]\n",
      "epoch:1 step:973 [D loss: 1.144760, acc: 32.03%] [G loss: 1.521361]\n",
      "epoch:1 step:974 [D loss: 0.910234, acc: 46.88%] [G loss: 1.925380]\n",
      "epoch:1 step:975 [D loss: 0.995429, acc: 32.81%] [G loss: 1.528774]\n",
      "epoch:1 step:976 [D loss: 0.859619, acc: 49.22%] [G loss: 2.424216]\n",
      "epoch:1 step:977 [D loss: 0.633561, acc: 67.19%] [G loss: 2.618836]\n",
      "epoch:1 step:978 [D loss: 0.807726, acc: 55.47%] [G loss: 2.257353]\n",
      "epoch:1 step:979 [D loss: 0.787841, acc: 57.81%] [G loss: 2.337413]\n",
      "epoch:1 step:980 [D loss: 0.748562, acc: 56.25%] [G loss: 2.217493]\n",
      "epoch:1 step:981 [D loss: 0.609467, acc: 65.62%] [G loss: 2.563708]\n",
      "epoch:1 step:982 [D loss: 0.514094, acc: 78.91%] [G loss: 3.052759]\n",
      "epoch:1 step:983 [D loss: 0.614716, acc: 71.09%] [G loss: 2.703370]\n",
      "epoch:1 step:984 [D loss: 0.489807, acc: 77.34%] [G loss: 2.657573]\n",
      "epoch:1 step:985 [D loss: 0.566582, acc: 71.09%] [G loss: 2.540038]\n",
      "epoch:1 step:986 [D loss: 0.650799, acc: 61.72%] [G loss: 2.404543]\n",
      "epoch:1 step:987 [D loss: 0.467239, acc: 78.12%] [G loss: 2.921198]\n",
      "epoch:1 step:988 [D loss: 0.557988, acc: 75.78%] [G loss: 1.944381]\n",
      "epoch:1 step:989 [D loss: 0.636764, acc: 71.09%] [G loss: 2.214202]\n",
      "epoch:1 step:990 [D loss: 0.435371, acc: 84.38%] [G loss: 2.551817]\n",
      "epoch:1 step:991 [D loss: 0.299075, acc: 93.75%] [G loss: 2.727646]\n",
      "epoch:1 step:992 [D loss: 0.546787, acc: 72.66%] [G loss: 2.397573]\n",
      "epoch:1 step:993 [D loss: 0.515733, acc: 78.12%] [G loss: 2.030524]\n",
      "epoch:1 step:994 [D loss: 0.503871, acc: 80.47%] [G loss: 2.091061]\n",
      "epoch:1 step:995 [D loss: 0.297790, acc: 85.94%] [G loss: 2.384886]\n",
      "epoch:1 step:996 [D loss: 0.654155, acc: 64.06%] [G loss: 1.878150]\n",
      "epoch:1 step:997 [D loss: 0.996462, acc: 39.84%] [G loss: 1.483578]\n",
      "epoch:1 step:998 [D loss: 0.741724, acc: 57.81%] [G loss: 1.477402]\n",
      "epoch:1 step:999 [D loss: 0.530490, acc: 72.66%] [G loss: 2.067361]\n",
      "epoch:1 step:1000 [D loss: 1.142704, acc: 26.56%] [G loss: 1.710313]\n",
      "epoch:1 step:1001 [D loss: 0.610332, acc: 63.28%] [G loss: 1.928312]\n",
      "epoch:1 step:1002 [D loss: 0.641702, acc: 65.62%] [G loss: 1.482611]\n",
      "epoch:1 step:1003 [D loss: 0.809942, acc: 52.34%] [G loss: 1.977802]\n",
      "epoch:1 step:1004 [D loss: 0.987397, acc: 35.16%] [G loss: 1.974491]\n",
      "epoch:1 step:1005 [D loss: 0.650550, acc: 64.06%] [G loss: 1.458217]\n",
      "epoch:1 step:1006 [D loss: 0.764837, acc: 53.12%] [G loss: 1.852294]\n",
      "epoch:1 step:1007 [D loss: 0.602461, acc: 64.06%] [G loss: 2.274559]\n",
      "epoch:1 step:1008 [D loss: 1.132097, acc: 28.12%] [G loss: 1.640702]\n",
      "epoch:1 step:1009 [D loss: 0.999805, acc: 28.12%] [G loss: 1.823952]\n",
      "epoch:1 step:1010 [D loss: 0.639043, acc: 60.94%] [G loss: 2.227179]\n",
      "epoch:1 step:1011 [D loss: 0.557911, acc: 67.97%] [G loss: 2.197075]\n",
      "epoch:1 step:1012 [D loss: 0.666200, acc: 57.81%] [G loss: 2.310331]\n",
      "epoch:1 step:1013 [D loss: 0.906818, acc: 40.62%] [G loss: 2.083738]\n",
      "epoch:1 step:1014 [D loss: 0.691547, acc: 52.34%] [G loss: 2.400500]\n",
      "epoch:1 step:1015 [D loss: 0.788159, acc: 53.91%] [G loss: 2.463184]\n",
      "epoch:1 step:1016 [D loss: 0.670877, acc: 55.47%] [G loss: 2.549520]\n",
      "epoch:1 step:1017 [D loss: 0.523135, acc: 71.88%] [G loss: 2.353332]\n",
      "epoch:1 step:1018 [D loss: 0.473428, acc: 78.12%] [G loss: 2.812438]\n",
      "epoch:1 step:1019 [D loss: 0.574947, acc: 67.97%] [G loss: 2.556440]\n",
      "epoch:1 step:1020 [D loss: 0.503740, acc: 75.00%] [G loss: 2.632578]\n",
      "epoch:1 step:1021 [D loss: 0.580198, acc: 71.88%] [G loss: 2.405727]\n",
      "epoch:1 step:1022 [D loss: 0.644947, acc: 64.84%] [G loss: 2.605881]\n",
      "epoch:1 step:1023 [D loss: 0.463305, acc: 77.34%] [G loss: 2.913844]\n",
      "epoch:1 step:1024 [D loss: 0.439690, acc: 78.12%] [G loss: 2.891302]\n",
      "epoch:1 step:1025 [D loss: 0.526147, acc: 75.00%] [G loss: 2.615746]\n",
      "epoch:1 step:1026 [D loss: 0.539843, acc: 68.75%] [G loss: 2.598353]\n",
      "epoch:1 step:1027 [D loss: 0.445476, acc: 80.47%] [G loss: 2.497694]\n",
      "epoch:1 step:1028 [D loss: 0.702983, acc: 59.38%] [G loss: 1.924722]\n",
      "epoch:1 step:1029 [D loss: 0.350884, acc: 91.41%] [G loss: 2.332018]\n",
      "epoch:1 step:1030 [D loss: 0.585282, acc: 68.75%] [G loss: 1.807343]\n",
      "epoch:1 step:1031 [D loss: 0.515152, acc: 75.78%] [G loss: 1.804041]\n",
      "epoch:1 step:1032 [D loss: 0.476187, acc: 78.91%] [G loss: 1.974779]\n",
      "epoch:1 step:1033 [D loss: 0.513721, acc: 75.78%] [G loss: 1.769969]\n",
      "epoch:1 step:1034 [D loss: 0.848077, acc: 41.41%] [G loss: 1.460711]\n",
      "epoch:1 step:1035 [D loss: 0.703026, acc: 57.81%] [G loss: 1.539539]\n",
      "epoch:1 step:1036 [D loss: 0.470943, acc: 80.47%] [G loss: 1.677458]\n",
      "epoch:1 step:1037 [D loss: 0.706314, acc: 56.25%] [G loss: 1.578391]\n",
      "epoch:1 step:1038 [D loss: 0.362219, acc: 89.06%] [G loss: 1.675879]\n",
      "epoch:1 step:1039 [D loss: 0.906863, acc: 41.41%] [G loss: 1.232354]\n",
      "epoch:1 step:1040 [D loss: 0.875741, acc: 38.28%] [G loss: 1.007897]\n",
      "epoch:1 step:1041 [D loss: 0.516424, acc: 72.66%] [G loss: 1.501661]\n",
      "epoch:1 step:1042 [D loss: 1.006606, acc: 25.78%] [G loss: 0.967465]\n",
      "epoch:1 step:1043 [D loss: 0.835921, acc: 43.75%] [G loss: 1.062763]\n",
      "epoch:1 step:1044 [D loss: 1.138701, acc: 34.38%] [G loss: 1.241956]\n",
      "epoch:1 step:1045 [D loss: 0.594961, acc: 69.53%] [G loss: 1.736188]\n",
      "epoch:1 step:1046 [D loss: 1.031743, acc: 32.81%] [G loss: 1.399739]\n",
      "epoch:1 step:1047 [D loss: 1.001660, acc: 39.06%] [G loss: 1.830223]\n",
      "epoch:1 step:1048 [D loss: 0.594993, acc: 72.66%] [G loss: 2.071937]\n",
      "epoch:1 step:1049 [D loss: 0.712021, acc: 60.16%] [G loss: 2.188026]\n",
      "epoch:1 step:1050 [D loss: 0.965595, acc: 46.88%] [G loss: 2.067062]\n",
      "epoch:1 step:1051 [D loss: 0.801349, acc: 57.03%] [G loss: 2.075718]\n",
      "epoch:1 step:1052 [D loss: 0.596902, acc: 72.66%] [G loss: 2.751978]\n",
      "epoch:1 step:1053 [D loss: 0.540261, acc: 73.44%] [G loss: 2.548415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1054 [D loss: 0.659559, acc: 67.19%] [G loss: 2.384866]\n",
      "epoch:1 step:1055 [D loss: 0.586241, acc: 77.34%] [G loss: 2.331919]\n",
      "epoch:1 step:1056 [D loss: 0.734452, acc: 59.38%] [G loss: 2.740258]\n",
      "epoch:1 step:1057 [D loss: 0.563490, acc: 79.69%] [G loss: 2.640947]\n",
      "epoch:1 step:1058 [D loss: 0.563599, acc: 70.31%] [G loss: 3.033145]\n",
      "epoch:1 step:1059 [D loss: 0.584300, acc: 67.97%] [G loss: 2.819047]\n",
      "epoch:1 step:1060 [D loss: 0.520054, acc: 80.47%] [G loss: 2.791295]\n",
      "epoch:1 step:1061 [D loss: 0.590991, acc: 71.88%] [G loss: 2.783017]\n",
      "epoch:1 step:1062 [D loss: 0.460074, acc: 82.81%] [G loss: 2.759107]\n",
      "epoch:1 step:1063 [D loss: 0.363867, acc: 85.94%] [G loss: 3.091186]\n",
      "epoch:1 step:1064 [D loss: 0.391322, acc: 83.59%] [G loss: 2.776582]\n",
      "epoch:1 step:1065 [D loss: 0.390672, acc: 88.28%] [G loss: 2.664853]\n",
      "epoch:1 step:1066 [D loss: 0.407584, acc: 84.38%] [G loss: 2.313704]\n",
      "epoch:1 step:1067 [D loss: 0.302544, acc: 90.62%] [G loss: 2.578335]\n",
      "epoch:1 step:1068 [D loss: 0.335711, acc: 87.50%] [G loss: 3.033558]\n",
      "epoch:1 step:1069 [D loss: 0.247796, acc: 94.53%] [G loss: 2.558350]\n",
      "epoch:1 step:1070 [D loss: 0.480549, acc: 83.59%] [G loss: 2.665084]\n",
      "epoch:1 step:1071 [D loss: 0.328228, acc: 89.06%] [G loss: 2.307926]\n",
      "epoch:1 step:1072 [D loss: 0.699462, acc: 65.62%] [G loss: 1.552806]\n",
      "epoch:1 step:1073 [D loss: 0.505160, acc: 74.22%] [G loss: 2.694548]\n",
      "epoch:1 step:1074 [D loss: 0.411341, acc: 82.81%] [G loss: 2.231930]\n",
      "epoch:1 step:1075 [D loss: 0.504547, acc: 74.22%] [G loss: 2.202412]\n",
      "epoch:1 step:1076 [D loss: 0.452340, acc: 83.59%] [G loss: 2.120229]\n",
      "epoch:1 step:1077 [D loss: 0.583292, acc: 72.66%] [G loss: 1.817272]\n",
      "epoch:1 step:1078 [D loss: 0.672644, acc: 60.94%] [G loss: 1.905174]\n",
      "epoch:1 step:1079 [D loss: 0.556830, acc: 77.34%] [G loss: 2.109948]\n",
      "epoch:1 step:1080 [D loss: 0.872684, acc: 45.31%] [G loss: 1.809806]\n",
      "epoch:1 step:1081 [D loss: 0.589075, acc: 65.62%] [G loss: 2.317062]\n",
      "epoch:1 step:1082 [D loss: 0.586244, acc: 71.09%] [G loss: 1.921049]\n",
      "epoch:1 step:1083 [D loss: 0.985012, acc: 44.53%] [G loss: 2.231467]\n",
      "epoch:1 step:1084 [D loss: 0.804698, acc: 53.91%] [G loss: 1.894935]\n",
      "epoch:1 step:1085 [D loss: 0.738206, acc: 65.62%] [G loss: 1.930698]\n",
      "epoch:1 step:1086 [D loss: 1.088973, acc: 33.59%] [G loss: 1.647351]\n",
      "epoch:1 step:1087 [D loss: 0.906667, acc: 41.41%] [G loss: 1.657390]\n",
      "epoch:1 step:1088 [D loss: 1.220395, acc: 21.88%] [G loss: 1.920595]\n",
      "epoch:1 step:1089 [D loss: 0.855152, acc: 46.88%] [G loss: 1.809065]\n",
      "epoch:1 step:1090 [D loss: 0.779956, acc: 53.12%] [G loss: 1.614833]\n",
      "epoch:1 step:1091 [D loss: 0.786235, acc: 45.31%] [G loss: 2.055719]\n",
      "epoch:1 step:1092 [D loss: 0.703092, acc: 64.84%] [G loss: 2.128165]\n",
      "epoch:1 step:1093 [D loss: 0.862027, acc: 41.41%] [G loss: 1.911591]\n",
      "epoch:1 step:1094 [D loss: 0.797596, acc: 43.75%] [G loss: 1.661876]\n",
      "epoch:1 step:1095 [D loss: 0.834088, acc: 40.62%] [G loss: 1.859491]\n",
      "epoch:1 step:1096 [D loss: 0.675409, acc: 64.06%] [G loss: 1.727426]\n",
      "epoch:1 step:1097 [D loss: 0.708456, acc: 57.81%] [G loss: 1.828458]\n",
      "epoch:1 step:1098 [D loss: 0.755489, acc: 46.09%] [G loss: 1.827947]\n",
      "epoch:1 step:1099 [D loss: 0.586494, acc: 70.31%] [G loss: 1.962151]\n",
      "epoch:1 step:1100 [D loss: 0.541371, acc: 75.00%] [G loss: 2.034878]\n",
      "epoch:1 step:1101 [D loss: 0.848785, acc: 50.78%] [G loss: 1.467494]\n",
      "epoch:1 step:1102 [D loss: 0.762744, acc: 50.78%] [G loss: 1.691819]\n",
      "epoch:1 step:1103 [D loss: 0.482802, acc: 78.91%] [G loss: 2.088017]\n",
      "epoch:1 step:1104 [D loss: 0.592413, acc: 65.62%] [G loss: 2.292512]\n",
      "epoch:1 step:1105 [D loss: 0.623462, acc: 61.72%] [G loss: 1.749603]\n",
      "epoch:1 step:1106 [D loss: 0.687249, acc: 57.81%] [G loss: 1.492141]\n",
      "epoch:1 step:1107 [D loss: 0.766807, acc: 48.44%] [G loss: 1.833252]\n",
      "epoch:1 step:1108 [D loss: 0.552092, acc: 75.00%] [G loss: 1.819813]\n",
      "epoch:1 step:1109 [D loss: 0.484334, acc: 76.56%] [G loss: 2.029090]\n",
      "epoch:1 step:1110 [D loss: 0.461249, acc: 83.59%] [G loss: 2.248824]\n",
      "epoch:1 step:1111 [D loss: 0.658558, acc: 68.75%] [G loss: 2.114310]\n",
      "epoch:1 step:1112 [D loss: 0.823479, acc: 53.12%] [G loss: 1.523094]\n",
      "epoch:1 step:1113 [D loss: 0.647801, acc: 64.84%] [G loss: 1.888080]\n",
      "epoch:1 step:1114 [D loss: 0.541591, acc: 72.66%] [G loss: 1.821730]\n",
      "epoch:1 step:1115 [D loss: 0.635453, acc: 63.28%] [G loss: 1.748107]\n",
      "epoch:1 step:1116 [D loss: 0.757215, acc: 55.47%] [G loss: 1.383700]\n",
      "epoch:1 step:1117 [D loss: 0.558360, acc: 75.00%] [G loss: 1.733156]\n",
      "epoch:1 step:1118 [D loss: 0.981258, acc: 39.06%] [G loss: 1.343897]\n",
      "epoch:1 step:1119 [D loss: 0.773384, acc: 52.34%] [G loss: 1.796789]\n",
      "epoch:1 step:1120 [D loss: 0.652046, acc: 60.94%] [G loss: 1.772487]\n",
      "epoch:1 step:1121 [D loss: 0.804266, acc: 46.09%] [G loss: 1.588109]\n",
      "epoch:1 step:1122 [D loss: 0.672920, acc: 57.03%] [G loss: 1.900790]\n",
      "epoch:1 step:1123 [D loss: 0.759489, acc: 57.81%] [G loss: 1.550688]\n",
      "epoch:1 step:1124 [D loss: 0.680544, acc: 54.69%] [G loss: 2.047452]\n",
      "epoch:1 step:1125 [D loss: 0.750042, acc: 53.91%] [G loss: 1.552989]\n",
      "epoch:1 step:1126 [D loss: 0.722667, acc: 55.47%] [G loss: 1.914820]\n",
      "epoch:1 step:1127 [D loss: 0.809253, acc: 42.19%] [G loss: 1.588145]\n",
      "epoch:1 step:1128 [D loss: 0.598918, acc: 68.75%] [G loss: 1.889806]\n",
      "epoch:1 step:1129 [D loss: 0.632476, acc: 67.19%] [G loss: 2.085836]\n",
      "epoch:1 step:1130 [D loss: 0.512167, acc: 78.91%] [G loss: 2.246921]\n",
      "epoch:1 step:1131 [D loss: 0.727472, acc: 55.47%] [G loss: 2.025181]\n",
      "epoch:1 step:1132 [D loss: 0.737172, acc: 49.22%] [G loss: 2.023629]\n",
      "epoch:1 step:1133 [D loss: 0.728620, acc: 58.59%] [G loss: 2.220076]\n",
      "epoch:1 step:1134 [D loss: 0.577339, acc: 70.31%] [G loss: 2.096833]\n",
      "epoch:1 step:1135 [D loss: 0.676875, acc: 64.06%] [G loss: 2.132662]\n",
      "epoch:1 step:1136 [D loss: 0.781128, acc: 51.56%] [G loss: 1.892144]\n",
      "epoch:1 step:1137 [D loss: 0.548359, acc: 74.22%] [G loss: 2.225023]\n",
      "epoch:1 step:1138 [D loss: 0.556574, acc: 67.97%] [G loss: 2.183635]\n",
      "epoch:1 step:1139 [D loss: 0.740079, acc: 62.50%] [G loss: 1.619653]\n",
      "epoch:1 step:1140 [D loss: 0.781911, acc: 53.91%] [G loss: 1.816463]\n",
      "epoch:1 step:1141 [D loss: 0.643436, acc: 65.62%] [G loss: 1.753402]\n",
      "epoch:1 step:1142 [D loss: 0.689463, acc: 61.72%] [G loss: 2.013402]\n",
      "epoch:1 step:1143 [D loss: 0.888429, acc: 41.41%] [G loss: 1.648040]\n",
      "epoch:1 step:1144 [D loss: 0.842038, acc: 49.22%] [G loss: 1.658088]\n",
      "epoch:1 step:1145 [D loss: 0.600654, acc: 69.53%] [G loss: 1.817607]\n",
      "epoch:1 step:1146 [D loss: 0.575854, acc: 70.31%] [G loss: 2.015460]\n",
      "epoch:1 step:1147 [D loss: 0.836951, acc: 41.41%] [G loss: 1.700585]\n",
      "epoch:1 step:1148 [D loss: 0.562272, acc: 78.12%] [G loss: 1.687831]\n",
      "epoch:1 step:1149 [D loss: 0.532374, acc: 74.22%] [G loss: 1.745601]\n",
      "epoch:1 step:1150 [D loss: 0.645364, acc: 67.19%] [G loss: 1.563650]\n",
      "epoch:1 step:1151 [D loss: 0.896928, acc: 41.41%] [G loss: 1.510631]\n",
      "epoch:1 step:1152 [D loss: 0.828355, acc: 51.56%] [G loss: 1.512265]\n",
      "epoch:1 step:1153 [D loss: 0.594852, acc: 69.53%] [G loss: 1.640349]\n",
      "epoch:1 step:1154 [D loss: 0.720229, acc: 55.47%] [G loss: 1.654158]\n",
      "epoch:1 step:1155 [D loss: 0.780131, acc: 56.25%] [G loss: 1.372480]\n",
      "epoch:1 step:1156 [D loss: 0.600276, acc: 70.31%] [G loss: 1.657627]\n",
      "epoch:1 step:1157 [D loss: 0.484669, acc: 80.47%] [G loss: 1.540673]\n",
      "epoch:1 step:1158 [D loss: 0.600604, acc: 68.75%] [G loss: 1.830182]\n",
      "epoch:1 step:1159 [D loss: 0.573226, acc: 71.88%] [G loss: 1.708155]\n",
      "epoch:1 step:1160 [D loss: 0.850375, acc: 50.78%] [G loss: 1.376721]\n",
      "epoch:1 step:1161 [D loss: 1.012997, acc: 34.38%] [G loss: 1.892502]\n",
      "epoch:1 step:1162 [D loss: 0.767418, acc: 60.16%] [G loss: 2.154443]\n",
      "epoch:1 step:1163 [D loss: 0.695734, acc: 64.06%] [G loss: 1.893167]\n",
      "epoch:1 step:1164 [D loss: 0.860944, acc: 44.53%] [G loss: 1.926495]\n",
      "epoch:1 step:1165 [D loss: 0.578648, acc: 78.91%] [G loss: 2.280064]\n",
      "epoch:1 step:1166 [D loss: 0.555361, acc: 70.31%] [G loss: 2.143319]\n",
      "epoch:1 step:1167 [D loss: 0.534446, acc: 70.31%] [G loss: 2.112912]\n",
      "epoch:1 step:1168 [D loss: 0.635816, acc: 65.62%] [G loss: 2.125139]\n",
      "epoch:1 step:1169 [D loss: 0.749972, acc: 60.16%] [G loss: 1.765465]\n",
      "epoch:1 step:1170 [D loss: 0.529354, acc: 73.44%] [G loss: 2.070963]\n",
      "epoch:1 step:1171 [D loss: 0.896623, acc: 42.97%] [G loss: 2.005872]\n",
      "epoch:1 step:1172 [D loss: 0.823119, acc: 46.88%] [G loss: 1.907828]\n",
      "epoch:1 step:1173 [D loss: 0.669489, acc: 64.06%] [G loss: 2.266483]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1174 [D loss: 0.522573, acc: 78.91%] [G loss: 2.437928]\n",
      "epoch:1 step:1175 [D loss: 0.643589, acc: 62.50%] [G loss: 2.088871]\n",
      "epoch:1 step:1176 [D loss: 0.659887, acc: 68.75%] [G loss: 2.338390]\n",
      "epoch:1 step:1177 [D loss: 0.589583, acc: 71.09%] [G loss: 2.189750]\n",
      "epoch:1 step:1178 [D loss: 0.612311, acc: 67.19%] [G loss: 2.248843]\n",
      "epoch:1 step:1179 [D loss: 0.537834, acc: 70.31%] [G loss: 2.763299]\n",
      "epoch:1 step:1180 [D loss: 0.424142, acc: 84.38%] [G loss: 2.544649]\n",
      "epoch:1 step:1181 [D loss: 0.469422, acc: 78.12%] [G loss: 2.953640]\n",
      "epoch:1 step:1182 [D loss: 0.451892, acc: 84.38%] [G loss: 2.544930]\n",
      "epoch:1 step:1183 [D loss: 0.331207, acc: 94.53%] [G loss: 3.017983]\n",
      "epoch:1 step:1184 [D loss: 0.413875, acc: 89.06%] [G loss: 2.622726]\n",
      "epoch:1 step:1185 [D loss: 0.281241, acc: 96.09%] [G loss: 2.793485]\n",
      "epoch:1 step:1186 [D loss: 0.265131, acc: 94.53%] [G loss: 2.793150]\n",
      "epoch:1 step:1187 [D loss: 0.350204, acc: 92.19%] [G loss: 2.819683]\n",
      "epoch:1 step:1188 [D loss: 0.395218, acc: 89.06%] [G loss: 2.197175]\n",
      "epoch:1 step:1189 [D loss: 0.282853, acc: 92.19%] [G loss: 2.075140]\n",
      "epoch:1 step:1190 [D loss: 0.402466, acc: 85.94%] [G loss: 2.043782]\n",
      "epoch:1 step:1191 [D loss: 0.427111, acc: 82.81%] [G loss: 1.658885]\n",
      "epoch:1 step:1192 [D loss: 0.475273, acc: 78.91%] [G loss: 2.245063]\n",
      "epoch:1 step:1193 [D loss: 0.255474, acc: 96.09%] [G loss: 3.038869]\n",
      "epoch:1 step:1194 [D loss: 0.255221, acc: 94.53%] [G loss: 2.479949]\n",
      "epoch:1 step:1195 [D loss: 0.530542, acc: 77.34%] [G loss: 1.581105]\n",
      "epoch:1 step:1196 [D loss: 0.280761, acc: 96.09%] [G loss: 1.958206]\n",
      "epoch:1 step:1197 [D loss: 0.489424, acc: 78.12%] [G loss: 2.126225]\n",
      "epoch:1 step:1198 [D loss: 0.351958, acc: 89.06%] [G loss: 1.827065]\n",
      "epoch:1 step:1199 [D loss: 0.725685, acc: 57.81%] [G loss: 1.378691]\n",
      "epoch:1 step:1200 [D loss: 0.530079, acc: 76.56%] [G loss: 1.652163]\n",
      "epoch:1 step:1201 [D loss: 0.551073, acc: 69.53%] [G loss: 1.859753]\n",
      "epoch:1 step:1202 [D loss: 0.589866, acc: 73.44%] [G loss: 1.666276]\n",
      "epoch:1 step:1203 [D loss: 0.699778, acc: 54.69%] [G loss: 1.159910]\n",
      "epoch:1 step:1204 [D loss: 1.220864, acc: 23.44%] [G loss: 1.004591]\n",
      "epoch:1 step:1205 [D loss: 0.257895, acc: 91.41%] [G loss: 2.391223]\n",
      "epoch:1 step:1206 [D loss: 0.775966, acc: 55.47%] [G loss: 1.298997]\n",
      "epoch:1 step:1207 [D loss: 0.659461, acc: 65.62%] [G loss: 1.556666]\n",
      "epoch:1 step:1208 [D loss: 0.726318, acc: 55.47%] [G loss: 0.926090]\n",
      "epoch:1 step:1209 [D loss: 0.992754, acc: 32.03%] [G loss: 1.244168]\n",
      "epoch:1 step:1210 [D loss: 0.924389, acc: 39.84%] [G loss: 1.065842]\n",
      "epoch:1 step:1211 [D loss: 1.358988, acc: 16.41%] [G loss: 1.323701]\n",
      "epoch:1 step:1212 [D loss: 1.141539, acc: 29.69%] [G loss: 1.402253]\n",
      "epoch:1 step:1213 [D loss: 1.017989, acc: 32.03%] [G loss: 1.367268]\n",
      "epoch:1 step:1214 [D loss: 0.651152, acc: 63.28%] [G loss: 2.195569]\n",
      "epoch:1 step:1215 [D loss: 0.675306, acc: 63.28%] [G loss: 2.257693]\n",
      "epoch:1 step:1216 [D loss: 0.797542, acc: 53.91%] [G loss: 2.197607]\n",
      "epoch:1 step:1217 [D loss: 0.832212, acc: 48.44%] [G loss: 2.632717]\n",
      "epoch:1 step:1218 [D loss: 0.638675, acc: 69.53%] [G loss: 2.791773]\n",
      "epoch:1 step:1219 [D loss: 0.715997, acc: 53.91%] [G loss: 2.880256]\n",
      "epoch:1 step:1220 [D loss: 0.598166, acc: 64.06%] [G loss: 3.203000]\n",
      "epoch:1 step:1221 [D loss: 0.391795, acc: 80.47%] [G loss: 3.015228]\n",
      "epoch:1 step:1222 [D loss: 0.588252, acc: 68.75%] [G loss: 3.102947]\n",
      "epoch:1 step:1223 [D loss: 0.331913, acc: 92.19%] [G loss: 2.771213]\n",
      "epoch:1 step:1224 [D loss: 0.295873, acc: 96.88%] [G loss: 2.565969]\n",
      "epoch:1 step:1225 [D loss: 0.598533, acc: 71.88%] [G loss: 2.153656]\n",
      "epoch:1 step:1226 [D loss: 0.400974, acc: 85.94%] [G loss: 2.965770]\n",
      "epoch:1 step:1227 [D loss: 0.401985, acc: 81.25%] [G loss: 2.369706]\n",
      "epoch:1 step:1228 [D loss: 0.451125, acc: 83.59%] [G loss: 2.537779]\n",
      "epoch:1 step:1229 [D loss: 0.456838, acc: 80.47%] [G loss: 2.210051]\n",
      "epoch:1 step:1230 [D loss: 0.273322, acc: 88.28%] [G loss: 2.210221]\n",
      "epoch:1 step:1231 [D loss: 0.625537, acc: 74.22%] [G loss: 2.466443]\n",
      "epoch:1 step:1232 [D loss: 0.453236, acc: 83.59%] [G loss: 2.177694]\n",
      "epoch:1 step:1233 [D loss: 0.416224, acc: 86.72%] [G loss: 2.247539]\n",
      "epoch:1 step:1234 [D loss: 0.614143, acc: 68.75%] [G loss: 2.595805]\n",
      "epoch:1 step:1235 [D loss: 0.385655, acc: 91.41%] [G loss: 2.403339]\n",
      "epoch:1 step:1236 [D loss: 0.589144, acc: 70.31%] [G loss: 2.481679]\n",
      "epoch:1 step:1237 [D loss: 0.454989, acc: 83.59%] [G loss: 2.437444]\n",
      "epoch:1 step:1238 [D loss: 0.402212, acc: 90.62%] [G loss: 1.947945]\n",
      "epoch:1 step:1239 [D loss: 0.411726, acc: 82.81%] [G loss: 1.963003]\n",
      "epoch:1 step:1240 [D loss: 0.665068, acc: 64.84%] [G loss: 2.124161]\n",
      "epoch:1 step:1241 [D loss: 0.448777, acc: 84.38%] [G loss: 2.135587]\n",
      "epoch:1 step:1242 [D loss: 0.553192, acc: 68.75%] [G loss: 1.976213]\n",
      "epoch:1 step:1243 [D loss: 0.496834, acc: 77.34%] [G loss: 2.036342]\n",
      "epoch:1 step:1244 [D loss: 0.639310, acc: 64.84%] [G loss: 1.891750]\n",
      "epoch:1 step:1245 [D loss: 0.651114, acc: 60.16%] [G loss: 1.810911]\n",
      "epoch:1 step:1246 [D loss: 0.719489, acc: 51.56%] [G loss: 1.967025]\n",
      "epoch:1 step:1247 [D loss: 1.003914, acc: 37.50%] [G loss: 2.087331]\n",
      "epoch:1 step:1248 [D loss: 0.603722, acc: 64.06%] [G loss: 1.919086]\n",
      "epoch:1 step:1249 [D loss: 0.341551, acc: 93.75%] [G loss: 2.618055]\n",
      "epoch:1 step:1250 [D loss: 0.680369, acc: 60.16%] [G loss: 1.869378]\n",
      "epoch:1 step:1251 [D loss: 0.607742, acc: 72.66%] [G loss: 2.099054]\n",
      "epoch:1 step:1252 [D loss: 0.761046, acc: 48.44%] [G loss: 1.643155]\n",
      "epoch:1 step:1253 [D loss: 0.490332, acc: 78.12%] [G loss: 1.881877]\n",
      "epoch:1 step:1254 [D loss: 0.582482, acc: 68.75%] [G loss: 1.795588]\n",
      "epoch:1 step:1255 [D loss: 0.628849, acc: 71.88%] [G loss: 1.759991]\n",
      "epoch:1 step:1256 [D loss: 0.540705, acc: 76.56%] [G loss: 1.806790]\n",
      "epoch:1 step:1257 [D loss: 0.659343, acc: 67.19%] [G loss: 1.554886]\n",
      "epoch:1 step:1258 [D loss: 0.333658, acc: 93.75%] [G loss: 2.274043]\n",
      "epoch:1 step:1259 [D loss: 0.519623, acc: 76.56%] [G loss: 2.359126]\n",
      "epoch:1 step:1260 [D loss: 0.327820, acc: 92.97%] [G loss: 2.226884]\n",
      "epoch:1 step:1261 [D loss: 0.381696, acc: 85.94%] [G loss: 2.301916]\n",
      "epoch:1 step:1262 [D loss: 0.766282, acc: 60.16%] [G loss: 1.708542]\n",
      "epoch:1 step:1263 [D loss: 0.597150, acc: 67.19%] [G loss: 2.150993]\n",
      "epoch:1 step:1264 [D loss: 0.382370, acc: 89.06%] [G loss: 1.987056]\n",
      "epoch:1 step:1265 [D loss: 0.455594, acc: 79.69%] [G loss: 2.341114]\n",
      "epoch:1 step:1266 [D loss: 0.451507, acc: 78.91%] [G loss: 2.423467]\n",
      "epoch:1 step:1267 [D loss: 0.571493, acc: 67.19%] [G loss: 2.004678]\n",
      "epoch:1 step:1268 [D loss: 0.338290, acc: 91.41%] [G loss: 2.781720]\n",
      "epoch:1 step:1269 [D loss: 0.279109, acc: 93.75%] [G loss: 2.654747]\n",
      "epoch:1 step:1270 [D loss: 0.400627, acc: 86.72%] [G loss: 2.047903]\n",
      "epoch:1 step:1271 [D loss: 0.770070, acc: 60.94%] [G loss: 2.504487]\n",
      "epoch:1 step:1272 [D loss: 0.538521, acc: 69.53%] [G loss: 2.623032]\n",
      "epoch:1 step:1273 [D loss: 0.256063, acc: 97.66%] [G loss: 2.944531]\n",
      "epoch:1 step:1274 [D loss: 0.384718, acc: 89.84%] [G loss: 2.258813]\n",
      "epoch:1 step:1275 [D loss: 0.325011, acc: 89.06%] [G loss: 2.532906]\n",
      "epoch:1 step:1276 [D loss: 0.379533, acc: 92.97%] [G loss: 2.036288]\n",
      "epoch:1 step:1277 [D loss: 0.470286, acc: 82.81%] [G loss: 2.121292]\n",
      "epoch:1 step:1278 [D loss: 0.445485, acc: 81.25%] [G loss: 1.893038]\n",
      "epoch:1 step:1279 [D loss: 0.380839, acc: 84.38%] [G loss: 2.125511]\n",
      "epoch:1 step:1280 [D loss: 0.434587, acc: 84.38%] [G loss: 2.623114]\n",
      "epoch:1 step:1281 [D loss: 0.565660, acc: 70.31%] [G loss: 2.352294]\n",
      "epoch:1 step:1282 [D loss: 0.446691, acc: 82.03%] [G loss: 1.713675]\n",
      "epoch:1 step:1283 [D loss: 0.631171, acc: 69.53%] [G loss: 2.001742]\n",
      "epoch:1 step:1284 [D loss: 0.389872, acc: 82.81%] [G loss: 2.538962]\n",
      "epoch:1 step:1285 [D loss: 0.439074, acc: 84.38%] [G loss: 2.045192]\n",
      "epoch:1 step:1286 [D loss: 0.278040, acc: 90.62%] [G loss: 2.416207]\n",
      "epoch:1 step:1287 [D loss: 0.385356, acc: 91.41%] [G loss: 2.511883]\n",
      "epoch:1 step:1288 [D loss: 0.300276, acc: 92.19%] [G loss: 2.522688]\n",
      "epoch:1 step:1289 [D loss: 0.995741, acc: 41.41%] [G loss: 1.435204]\n",
      "epoch:1 step:1290 [D loss: 0.151668, acc: 94.53%] [G loss: 3.199534]\n",
      "epoch:1 step:1291 [D loss: 0.230142, acc: 94.53%] [G loss: 2.466598]\n",
      "epoch:1 step:1292 [D loss: 0.267539, acc: 89.84%] [G loss: 2.315136]\n",
      "epoch:1 step:1293 [D loss: 0.586129, acc: 71.88%] [G loss: 2.059139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1294 [D loss: 0.302297, acc: 90.62%] [G loss: 2.629499]\n",
      "epoch:1 step:1295 [D loss: 0.552079, acc: 75.00%] [G loss: 2.417612]\n",
      "epoch:1 step:1296 [D loss: 0.087986, acc: 99.22%] [G loss: 3.789094]\n",
      "epoch:1 step:1297 [D loss: 0.142687, acc: 99.22%] [G loss: 3.059877]\n",
      "epoch:1 step:1298 [D loss: 0.078097, acc: 100.00%] [G loss: 3.630016]\n",
      "epoch:1 step:1299 [D loss: 0.453249, acc: 78.91%] [G loss: 1.844170]\n",
      "epoch:1 step:1300 [D loss: 1.197562, acc: 21.88%] [G loss: 1.545592]\n",
      "epoch:1 step:1301 [D loss: 0.048849, acc: 100.00%] [G loss: 3.452385]\n",
      "epoch:1 step:1302 [D loss: 0.318353, acc: 87.50%] [G loss: 2.767503]\n",
      "epoch:1 step:1303 [D loss: 0.159995, acc: 98.44%] [G loss: 3.067562]\n",
      "epoch:1 step:1304 [D loss: 0.339796, acc: 89.84%] [G loss: 2.871052]\n",
      "epoch:1 step:1305 [D loss: 0.247662, acc: 89.06%] [G loss: 3.574394]\n",
      "epoch:1 step:1306 [D loss: 0.225145, acc: 96.88%] [G loss: 2.504097]\n",
      "epoch:1 step:1307 [D loss: 0.072170, acc: 100.00%] [G loss: 3.653375]\n",
      "epoch:1 step:1308 [D loss: 0.284867, acc: 92.97%] [G loss: 2.530557]\n",
      "epoch:1 step:1309 [D loss: 0.195360, acc: 97.66%] [G loss: 2.776361]\n",
      "epoch:1 step:1310 [D loss: 0.793056, acc: 62.50%] [G loss: 2.322132]\n",
      "epoch:1 step:1311 [D loss: 0.696579, acc: 69.53%] [G loss: 2.462521]\n",
      "epoch:1 step:1312 [D loss: 0.595371, acc: 68.75%] [G loss: 2.089694]\n",
      "epoch:1 step:1313 [D loss: 0.514557, acc: 71.09%] [G loss: 3.112145]\n",
      "epoch:1 step:1314 [D loss: 0.418533, acc: 79.69%] [G loss: 2.446804]\n",
      "epoch:1 step:1315 [D loss: 0.285081, acc: 91.41%] [G loss: 2.531246]\n",
      "epoch:1 step:1316 [D loss: 0.444299, acc: 78.12%] [G loss: 2.697425]\n",
      "epoch:1 step:1317 [D loss: 0.510535, acc: 75.78%] [G loss: 2.222825]\n",
      "epoch:1 step:1318 [D loss: 0.251152, acc: 92.19%] [G loss: 2.626137]\n",
      "epoch:1 step:1319 [D loss: 1.004488, acc: 45.31%] [G loss: 2.003318]\n",
      "epoch:1 step:1320 [D loss: 0.918929, acc: 48.44%] [G loss: 1.798904]\n",
      "epoch:1 step:1321 [D loss: 0.599656, acc: 67.97%] [G loss: 2.382383]\n",
      "epoch:1 step:1322 [D loss: 0.613273, acc: 63.28%] [G loss: 1.916548]\n",
      "epoch:1 step:1323 [D loss: 0.589682, acc: 70.31%] [G loss: 1.774230]\n",
      "epoch:1 step:1324 [D loss: 0.797008, acc: 60.94%] [G loss: 1.516031]\n",
      "epoch:1 step:1325 [D loss: 0.658079, acc: 61.72%] [G loss: 1.945085]\n",
      "epoch:1 step:1326 [D loss: 1.122414, acc: 39.06%] [G loss: 1.456892]\n",
      "epoch:1 step:1327 [D loss: 0.390154, acc: 84.38%] [G loss: 1.867140]\n",
      "epoch:1 step:1328 [D loss: 0.706408, acc: 63.28%] [G loss: 1.847985]\n",
      "epoch:1 step:1329 [D loss: 0.652926, acc: 66.41%] [G loss: 1.734303]\n",
      "epoch:1 step:1330 [D loss: 0.337528, acc: 91.41%] [G loss: 2.210140]\n",
      "epoch:1 step:1331 [D loss: 1.280444, acc: 32.81%] [G loss: 1.241340]\n",
      "epoch:1 step:1332 [D loss: 0.516135, acc: 78.12%] [G loss: 1.711024]\n",
      "epoch:1 step:1333 [D loss: 0.250993, acc: 96.09%] [G loss: 2.432217]\n",
      "epoch:1 step:1334 [D loss: 0.407801, acc: 76.56%] [G loss: 1.852118]\n",
      "epoch:1 step:1335 [D loss: 0.438940, acc: 81.25%] [G loss: 1.846848]\n",
      "epoch:1 step:1336 [D loss: 0.653233, acc: 66.41%] [G loss: 1.607513]\n",
      "epoch:1 step:1337 [D loss: 0.322474, acc: 91.41%] [G loss: 2.841850]\n",
      "epoch:1 step:1338 [D loss: 0.310666, acc: 85.16%] [G loss: 2.734597]\n",
      "epoch:1 step:1339 [D loss: 0.736013, acc: 56.25%] [G loss: 2.220909]\n",
      "epoch:1 step:1340 [D loss: 0.633663, acc: 72.66%] [G loss: 2.456234]\n",
      "epoch:1 step:1341 [D loss: 0.409905, acc: 81.25%] [G loss: 2.743071]\n",
      "epoch:1 step:1342 [D loss: 0.499099, acc: 72.66%] [G loss: 2.825719]\n",
      "epoch:1 step:1343 [D loss: 0.598116, acc: 70.31%] [G loss: 2.276836]\n",
      "epoch:1 step:1344 [D loss: 0.100460, acc: 100.00%] [G loss: 3.894353]\n",
      "epoch:1 step:1345 [D loss: 0.602009, acc: 71.88%] [G loss: 2.887043]\n",
      "epoch:1 step:1346 [D loss: 0.340697, acc: 88.28%] [G loss: 2.316321]\n",
      "epoch:1 step:1347 [D loss: 0.414959, acc: 82.81%] [G loss: 2.217072]\n",
      "epoch:1 step:1348 [D loss: 1.230968, acc: 31.25%] [G loss: 1.835407]\n",
      "epoch:1 step:1349 [D loss: 0.154410, acc: 97.66%] [G loss: 3.085627]\n",
      "epoch:1 step:1350 [D loss: 0.383343, acc: 84.38%] [G loss: 2.894462]\n",
      "epoch:1 step:1351 [D loss: 0.345020, acc: 83.59%] [G loss: 2.543604]\n",
      "epoch:1 step:1352 [D loss: 0.867638, acc: 53.12%] [G loss: 2.341436]\n",
      "epoch:1 step:1353 [D loss: 0.343966, acc: 85.94%] [G loss: 1.954372]\n",
      "epoch:1 step:1354 [D loss: 1.633589, acc: 21.09%] [G loss: 1.731097]\n",
      "epoch:1 step:1355 [D loss: 0.825478, acc: 53.12%] [G loss: 1.606688]\n",
      "epoch:1 step:1356 [D loss: 0.371867, acc: 87.50%] [G loss: 2.352388]\n",
      "epoch:1 step:1357 [D loss: 0.608191, acc: 69.53%] [G loss: 2.729204]\n",
      "epoch:1 step:1358 [D loss: 0.277248, acc: 91.41%] [G loss: 3.075120]\n",
      "epoch:1 step:1359 [D loss: 0.421798, acc: 78.91%] [G loss: 2.362698]\n",
      "epoch:1 step:1360 [D loss: 0.836000, acc: 51.56%] [G loss: 1.977389]\n",
      "epoch:1 step:1361 [D loss: 0.626064, acc: 67.97%] [G loss: 2.406219]\n",
      "epoch:1 step:1362 [D loss: 0.503675, acc: 76.56%] [G loss: 2.894714]\n",
      "epoch:1 step:1363 [D loss: 0.553063, acc: 75.00%] [G loss: 2.833703]\n",
      "epoch:1 step:1364 [D loss: 0.358852, acc: 89.84%] [G loss: 2.905623]\n",
      "epoch:1 step:1365 [D loss: 0.805337, acc: 50.00%] [G loss: 2.004654]\n",
      "epoch:1 step:1366 [D loss: 1.517389, acc: 20.31%] [G loss: 2.045614]\n",
      "epoch:1 step:1367 [D loss: 0.701857, acc: 58.59%] [G loss: 2.310761]\n",
      "epoch:1 step:1368 [D loss: 0.484580, acc: 77.34%] [G loss: 2.383031]\n",
      "epoch:1 step:1369 [D loss: 0.598588, acc: 64.06%] [G loss: 2.173391]\n",
      "epoch:1 step:1370 [D loss: 0.641105, acc: 62.50%] [G loss: 1.823295]\n",
      "epoch:1 step:1371 [D loss: 0.708912, acc: 62.50%] [G loss: 2.102667]\n",
      "epoch:1 step:1372 [D loss: 0.289567, acc: 89.84%] [G loss: 3.012389]\n",
      "epoch:1 step:1373 [D loss: 0.419894, acc: 85.16%] [G loss: 3.045150]\n",
      "epoch:1 step:1374 [D loss: 0.365822, acc: 88.28%] [G loss: 2.980616]\n",
      "epoch:1 step:1375 [D loss: 0.280152, acc: 92.97%] [G loss: 2.609094]\n",
      "epoch:1 step:1376 [D loss: 0.253709, acc: 89.84%] [G loss: 2.479754]\n",
      "epoch:1 step:1377 [D loss: 0.560090, acc: 71.88%] [G loss: 2.132995]\n",
      "epoch:1 step:1378 [D loss: 0.264138, acc: 91.41%] [G loss: 3.139726]\n",
      "epoch:1 step:1379 [D loss: 0.547486, acc: 74.22%] [G loss: 2.235856]\n",
      "epoch:1 step:1380 [D loss: 0.311001, acc: 87.50%] [G loss: 2.439814]\n",
      "epoch:1 step:1381 [D loss: 0.383658, acc: 85.16%] [G loss: 2.833380]\n",
      "epoch:1 step:1382 [D loss: 0.250861, acc: 91.41%] [G loss: 2.728649]\n",
      "epoch:1 step:1383 [D loss: 0.614988, acc: 64.06%] [G loss: 2.689538]\n",
      "epoch:1 step:1384 [D loss: 0.617967, acc: 65.62%] [G loss: 2.190340]\n",
      "epoch:1 step:1385 [D loss: 0.374468, acc: 84.38%] [G loss: 3.072498]\n",
      "epoch:1 step:1386 [D loss: 0.175337, acc: 97.66%] [G loss: 3.076144]\n",
      "epoch:1 step:1387 [D loss: 0.365360, acc: 86.72%] [G loss: 2.830462]\n",
      "epoch:1 step:1388 [D loss: 0.274982, acc: 94.53%] [G loss: 2.733102]\n",
      "epoch:1 step:1389 [D loss: 0.778719, acc: 54.69%] [G loss: 1.906867]\n",
      "epoch:1 step:1390 [D loss: 0.327668, acc: 90.62%] [G loss: 2.733378]\n",
      "epoch:1 step:1391 [D loss: 0.627357, acc: 66.41%] [G loss: 2.014465]\n",
      "epoch:1 step:1392 [D loss: 0.743423, acc: 56.25%] [G loss: 1.994486]\n",
      "epoch:1 step:1393 [D loss: 0.872805, acc: 53.12%] [G loss: 1.425080]\n",
      "epoch:1 step:1394 [D loss: 0.465832, acc: 81.25%] [G loss: 1.822926]\n",
      "epoch:1 step:1395 [D loss: 1.247440, acc: 28.12%] [G loss: 1.763542]\n",
      "epoch:1 step:1396 [D loss: 0.742599, acc: 63.28%] [G loss: 1.757136]\n",
      "epoch:1 step:1397 [D loss: 0.752430, acc: 58.59%] [G loss: 1.783614]\n",
      "epoch:1 step:1398 [D loss: 1.141130, acc: 31.25%] [G loss: 1.163089]\n",
      "epoch:1 step:1399 [D loss: 0.791874, acc: 50.00%] [G loss: 1.259480]\n",
      "epoch:1 step:1400 [D loss: 0.582814, acc: 67.19%] [G loss: 1.746372]\n",
      "epoch:1 step:1401 [D loss: 1.076087, acc: 45.31%] [G loss: 1.442201]\n",
      "epoch:1 step:1402 [D loss: 1.097789, acc: 39.84%] [G loss: 1.406902]\n",
      "epoch:1 step:1403 [D loss: 1.034422, acc: 39.06%] [G loss: 1.567849]\n",
      "epoch:1 step:1404 [D loss: 1.282493, acc: 12.50%] [G loss: 1.256481]\n",
      "epoch:1 step:1405 [D loss: 0.645884, acc: 61.72%] [G loss: 2.044159]\n",
      "epoch:1 step:1406 [D loss: 0.875310, acc: 47.66%] [G loss: 2.070057]\n",
      "epoch:1 step:1407 [D loss: 0.915813, acc: 42.19%] [G loss: 2.345119]\n",
      "epoch:1 step:1408 [D loss: 0.647960, acc: 64.84%] [G loss: 2.485000]\n",
      "epoch:1 step:1409 [D loss: 0.682587, acc: 65.62%] [G loss: 2.250495]\n",
      "epoch:1 step:1410 [D loss: 0.558636, acc: 74.22%] [G loss: 2.899668]\n",
      "epoch:1 step:1411 [D loss: 0.352865, acc: 87.50%] [G loss: 2.786170]\n",
      "epoch:1 step:1412 [D loss: 0.490515, acc: 76.56%] [G loss: 2.460973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1413 [D loss: 0.558835, acc: 76.56%] [G loss: 2.555534]\n",
      "epoch:1 step:1414 [D loss: 0.362379, acc: 85.16%] [G loss: 2.526255]\n",
      "epoch:1 step:1415 [D loss: 0.583520, acc: 75.00%] [G loss: 2.196483]\n",
      "epoch:1 step:1416 [D loss: 0.362463, acc: 90.62%] [G loss: 2.231753]\n",
      "epoch:1 step:1417 [D loss: 0.419730, acc: 88.28%] [G loss: 2.409396]\n",
      "epoch:1 step:1418 [D loss: 1.003443, acc: 47.66%] [G loss: 1.785563]\n",
      "epoch:1 step:1419 [D loss: 0.633004, acc: 68.75%] [G loss: 1.585541]\n",
      "epoch:1 step:1420 [D loss: 0.789183, acc: 56.25%] [G loss: 1.598023]\n",
      "epoch:1 step:1421 [D loss: 0.906819, acc: 53.12%] [G loss: 1.505697]\n",
      "epoch:1 step:1422 [D loss: 0.978431, acc: 31.25%] [G loss: 1.401473]\n",
      "epoch:1 step:1423 [D loss: 0.853654, acc: 46.88%] [G loss: 1.681960]\n",
      "epoch:1 step:1424 [D loss: 0.754469, acc: 57.03%] [G loss: 1.612690]\n",
      "epoch:1 step:1425 [D loss: 0.714322, acc: 57.03%] [G loss: 1.643658]\n",
      "epoch:1 step:1426 [D loss: 0.842883, acc: 43.75%] [G loss: 1.813452]\n",
      "epoch:1 step:1427 [D loss: 1.201376, acc: 21.09%] [G loss: 1.373829]\n",
      "epoch:1 step:1428 [D loss: 0.728242, acc: 53.91%] [G loss: 1.519928]\n",
      "epoch:1 step:1429 [D loss: 0.693739, acc: 58.59%] [G loss: 1.560811]\n",
      "epoch:1 step:1430 [D loss: 1.102903, acc: 26.56%] [G loss: 1.402231]\n",
      "epoch:1 step:1431 [D loss: 0.994788, acc: 25.78%] [G loss: 1.400489]\n",
      "epoch:1 step:1432 [D loss: 0.750021, acc: 54.69%] [G loss: 1.591120]\n",
      "epoch:1 step:1433 [D loss: 0.972061, acc: 26.56%] [G loss: 1.301459]\n",
      "epoch:1 step:1434 [D loss: 0.713259, acc: 55.47%] [G loss: 1.350537]\n",
      "epoch:1 step:1435 [D loss: 0.958488, acc: 28.91%] [G loss: 1.394546]\n",
      "epoch:1 step:1436 [D loss: 0.742024, acc: 48.44%] [G loss: 1.806309]\n",
      "epoch:1 step:1437 [D loss: 0.599329, acc: 68.75%] [G loss: 1.790988]\n",
      "epoch:1 step:1438 [D loss: 0.805634, acc: 44.53%] [G loss: 1.561337]\n",
      "epoch:1 step:1439 [D loss: 0.665657, acc: 63.28%] [G loss: 1.596091]\n",
      "epoch:1 step:1440 [D loss: 1.017557, acc: 38.28%] [G loss: 1.721632]\n",
      "epoch:1 step:1441 [D loss: 0.572438, acc: 73.44%] [G loss: 1.865937]\n",
      "epoch:1 step:1442 [D loss: 0.648066, acc: 61.72%] [G loss: 1.836279]\n",
      "epoch:1 step:1443 [D loss: 0.849388, acc: 45.31%] [G loss: 1.572206]\n",
      "epoch:1 step:1444 [D loss: 0.645504, acc: 64.84%] [G loss: 1.543542]\n",
      "epoch:1 step:1445 [D loss: 0.892127, acc: 41.41%] [G loss: 1.568652]\n",
      "epoch:1 step:1446 [D loss: 0.998526, acc: 27.34%] [G loss: 1.477158]\n",
      "epoch:1 step:1447 [D loss: 0.892472, acc: 46.09%] [G loss: 1.724589]\n",
      "epoch:1 step:1448 [D loss: 0.545217, acc: 78.91%] [G loss: 2.203850]\n",
      "epoch:1 step:1449 [D loss: 0.886626, acc: 40.62%] [G loss: 1.872059]\n",
      "epoch:1 step:1450 [D loss: 0.641171, acc: 64.06%] [G loss: 1.937765]\n",
      "epoch:1 step:1451 [D loss: 0.908721, acc: 38.28%] [G loss: 1.778398]\n",
      "epoch:1 step:1452 [D loss: 0.717813, acc: 57.81%] [G loss: 2.056261]\n",
      "epoch:1 step:1453 [D loss: 0.613406, acc: 68.75%] [G loss: 2.178466]\n",
      "epoch:1 step:1454 [D loss: 0.691473, acc: 58.59%] [G loss: 2.082868]\n",
      "epoch:1 step:1455 [D loss: 0.666811, acc: 59.38%] [G loss: 2.262580]\n",
      "epoch:1 step:1456 [D loss: 0.564374, acc: 74.22%] [G loss: 2.203246]\n",
      "epoch:1 step:1457 [D loss: 0.570404, acc: 69.53%] [G loss: 2.578418]\n",
      "epoch:1 step:1458 [D loss: 0.563036, acc: 74.22%] [G loss: 2.556902]\n",
      "epoch:1 step:1459 [D loss: 0.500002, acc: 76.56%] [G loss: 2.257131]\n",
      "epoch:1 step:1460 [D loss: 0.437538, acc: 78.91%] [G loss: 2.361034]\n",
      "epoch:1 step:1461 [D loss: 0.363783, acc: 87.50%] [G loss: 2.407289]\n",
      "epoch:1 step:1462 [D loss: 0.429371, acc: 86.72%] [G loss: 2.706020]\n",
      "epoch:1 step:1463 [D loss: 0.458964, acc: 83.59%] [G loss: 2.185239]\n",
      "epoch:1 step:1464 [D loss: 0.392941, acc: 89.06%] [G loss: 2.110445]\n",
      "epoch:1 step:1465 [D loss: 0.217431, acc: 93.75%] [G loss: 2.574450]\n",
      "epoch:1 step:1466 [D loss: 0.651881, acc: 61.72%] [G loss: 2.230612]\n",
      "epoch:1 step:1467 [D loss: 0.280160, acc: 95.31%] [G loss: 2.661565]\n",
      "epoch:1 step:1468 [D loss: 0.271835, acc: 90.62%] [G loss: 2.489074]\n",
      "epoch:1 step:1469 [D loss: 0.585478, acc: 66.41%] [G loss: 2.042828]\n",
      "epoch:1 step:1470 [D loss: 0.303125, acc: 92.19%] [G loss: 2.420535]\n",
      "epoch:1 step:1471 [D loss: 0.201252, acc: 96.09%] [G loss: 2.407925]\n",
      "epoch:1 step:1472 [D loss: 0.547647, acc: 74.22%] [G loss: 1.973668]\n",
      "epoch:1 step:1473 [D loss: 0.248447, acc: 93.75%] [G loss: 2.414051]\n",
      "epoch:1 step:1474 [D loss: 0.661651, acc: 62.50%] [G loss: 1.675864]\n",
      "epoch:1 step:1475 [D loss: 0.527286, acc: 76.56%] [G loss: 2.188093]\n",
      "epoch:1 step:1476 [D loss: 0.525401, acc: 76.56%] [G loss: 1.916986]\n",
      "epoch:1 step:1477 [D loss: 0.477427, acc: 82.03%] [G loss: 1.774663]\n",
      "epoch:1 step:1478 [D loss: 0.384620, acc: 86.72%] [G loss: 2.043232]\n",
      "epoch:1 step:1479 [D loss: 0.616037, acc: 71.88%] [G loss: 1.712355]\n",
      "epoch:1 step:1480 [D loss: 0.818918, acc: 46.88%] [G loss: 1.342474]\n",
      "epoch:1 step:1481 [D loss: 0.274023, acc: 94.53%] [G loss: 2.140550]\n",
      "epoch:1 step:1482 [D loss: 0.640067, acc: 64.84%] [G loss: 1.864996]\n",
      "epoch:1 step:1483 [D loss: 0.300593, acc: 89.06%] [G loss: 2.559265]\n",
      "epoch:1 step:1484 [D loss: 0.650568, acc: 62.50%] [G loss: 2.252208]\n",
      "epoch:1 step:1485 [D loss: 0.328681, acc: 87.50%] [G loss: 3.320246]\n",
      "epoch:1 step:1486 [D loss: 1.557032, acc: 12.50%] [G loss: 1.846987]\n",
      "epoch:1 step:1487 [D loss: 0.685898, acc: 61.72%] [G loss: 1.700621]\n",
      "epoch:1 step:1488 [D loss: 0.715500, acc: 60.16%] [G loss: 2.399238]\n",
      "epoch:1 step:1489 [D loss: 0.358921, acc: 85.94%] [G loss: 2.908660]\n",
      "epoch:1 step:1490 [D loss: 1.001207, acc: 45.31%] [G loss: 1.954766]\n",
      "epoch:1 step:1491 [D loss: 0.480917, acc: 75.78%] [G loss: 2.276089]\n",
      "epoch:1 step:1492 [D loss: 0.511340, acc: 71.88%] [G loss: 2.231014]\n",
      "epoch:1 step:1493 [D loss: 0.425283, acc: 82.81%] [G loss: 2.233386]\n",
      "epoch:1 step:1494 [D loss: 0.579004, acc: 65.62%] [G loss: 1.885616]\n",
      "epoch:1 step:1495 [D loss: 0.495306, acc: 77.34%] [G loss: 2.238185]\n",
      "epoch:1 step:1496 [D loss: 0.420895, acc: 80.47%] [G loss: 1.775649]\n",
      "epoch:1 step:1497 [D loss: 0.383556, acc: 89.06%] [G loss: 1.859780]\n",
      "epoch:1 step:1498 [D loss: 0.339341, acc: 91.41%] [G loss: 1.951980]\n",
      "epoch:1 step:1499 [D loss: 0.337313, acc: 89.06%] [G loss: 2.374797]\n",
      "epoch:1 step:1500 [D loss: 0.510381, acc: 76.56%] [G loss: 1.876718]\n",
      "epoch:1 step:1501 [D loss: 0.350977, acc: 90.62%] [G loss: 2.123628]\n",
      "epoch:1 step:1502 [D loss: 0.184307, acc: 96.09%] [G loss: 2.444328]\n",
      "epoch:1 step:1503 [D loss: 0.421853, acc: 82.81%] [G loss: 2.076318]\n",
      "epoch:1 step:1504 [D loss: 0.185325, acc: 96.88%] [G loss: 2.811746]\n",
      "epoch:1 step:1505 [D loss: 0.197553, acc: 94.53%] [G loss: 2.342328]\n",
      "epoch:1 step:1506 [D loss: 0.168378, acc: 98.44%] [G loss: 2.541682]\n",
      "epoch:1 step:1507 [D loss: 0.247603, acc: 91.41%] [G loss: 2.905743]\n",
      "epoch:1 step:1508 [D loss: 0.331633, acc: 87.50%] [G loss: 2.288949]\n",
      "epoch:1 step:1509 [D loss: 0.441060, acc: 79.69%] [G loss: 2.464380]\n",
      "epoch:1 step:1510 [D loss: 0.286068, acc: 90.62%] [G loss: 3.473581]\n",
      "epoch:1 step:1511 [D loss: 0.928282, acc: 46.88%] [G loss: 2.334633]\n",
      "epoch:1 step:1512 [D loss: 0.203916, acc: 93.75%] [G loss: 4.124866]\n",
      "epoch:1 step:1513 [D loss: 0.408566, acc: 83.59%] [G loss: 2.904940]\n",
      "epoch:1 step:1514 [D loss: 0.334830, acc: 89.06%] [G loss: 3.088792]\n",
      "epoch:1 step:1515 [D loss: 0.409904, acc: 84.38%] [G loss: 3.429107]\n",
      "epoch:1 step:1516 [D loss: 0.240914, acc: 94.53%] [G loss: 3.689077]\n",
      "epoch:1 step:1517 [D loss: 0.400579, acc: 83.59%] [G loss: 2.531960]\n",
      "epoch:1 step:1518 [D loss: 0.410671, acc: 84.38%] [G loss: 2.372105]\n",
      "epoch:1 step:1519 [D loss: 0.349187, acc: 89.06%] [G loss: 2.440157]\n",
      "epoch:1 step:1520 [D loss: 0.294711, acc: 88.28%] [G loss: 2.604879]\n",
      "epoch:1 step:1521 [D loss: 0.638316, acc: 68.75%] [G loss: 1.906664]\n",
      "epoch:1 step:1522 [D loss: 0.166239, acc: 99.22%] [G loss: 2.748656]\n",
      "epoch:1 step:1523 [D loss: 0.410890, acc: 82.81%] [G loss: 2.381103]\n",
      "epoch:1 step:1524 [D loss: 0.366932, acc: 88.28%] [G loss: 2.662169]\n",
      "epoch:1 step:1525 [D loss: 0.148430, acc: 97.66%] [G loss: 3.156023]\n",
      "epoch:1 step:1526 [D loss: 0.374880, acc: 85.16%] [G loss: 2.339411]\n",
      "epoch:1 step:1527 [D loss: 0.257287, acc: 92.97%] [G loss: 2.345625]\n",
      "epoch:1 step:1528 [D loss: 1.210312, acc: 31.25%] [G loss: 2.813812]\n",
      "epoch:1 step:1529 [D loss: 0.071883, acc: 99.22%] [G loss: 3.268042]\n",
      "epoch:1 step:1530 [D loss: 0.417954, acc: 82.81%] [G loss: 3.424531]\n",
      "epoch:1 step:1531 [D loss: 1.243252, acc: 50.00%] [G loss: 2.930201]\n",
      "epoch:1 step:1532 [D loss: 0.599333, acc: 71.88%] [G loss: 2.082177]\n",
      "epoch:1 step:1533 [D loss: 0.474210, acc: 78.12%] [G loss: 3.082209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1534 [D loss: 0.225210, acc: 92.97%] [G loss: 3.424456]\n",
      "epoch:1 step:1535 [D loss: 0.339166, acc: 88.28%] [G loss: 3.167668]\n",
      "epoch:1 step:1536 [D loss: 0.281903, acc: 90.62%] [G loss: 3.316717]\n",
      "epoch:1 step:1537 [D loss: 0.757365, acc: 57.81%] [G loss: 2.752157]\n",
      "epoch:1 step:1538 [D loss: 0.254204, acc: 95.31%] [G loss: 2.592047]\n",
      "epoch:1 step:1539 [D loss: 0.867738, acc: 53.12%] [G loss: 3.184410]\n",
      "epoch:1 step:1540 [D loss: 0.387978, acc: 82.81%] [G loss: 3.059098]\n",
      "epoch:1 step:1541 [D loss: 0.863113, acc: 52.34%] [G loss: 3.123936]\n",
      "epoch:1 step:1542 [D loss: 0.637002, acc: 65.62%] [G loss: 2.713050]\n",
      "epoch:1 step:1543 [D loss: 0.474302, acc: 81.25%] [G loss: 2.785487]\n",
      "epoch:1 step:1544 [D loss: 0.355305, acc: 85.16%] [G loss: 3.221559]\n",
      "epoch:1 step:1545 [D loss: 0.531676, acc: 74.22%] [G loss: 3.231367]\n",
      "epoch:1 step:1546 [D loss: 0.186474, acc: 94.53%] [G loss: 3.460934]\n",
      "epoch:1 step:1547 [D loss: 0.235752, acc: 93.75%] [G loss: 2.931675]\n",
      "epoch:1 step:1548 [D loss: 0.327675, acc: 88.28%] [G loss: 3.040829]\n",
      "epoch:1 step:1549 [D loss: 0.213889, acc: 95.31%] [G loss: 2.824250]\n",
      "epoch:1 step:1550 [D loss: 1.082037, acc: 40.62%] [G loss: 2.895256]\n",
      "epoch:1 step:1551 [D loss: 0.199991, acc: 96.88%] [G loss: 2.849572]\n",
      "epoch:1 step:1552 [D loss: 0.174633, acc: 94.53%] [G loss: 2.712469]\n",
      "epoch:1 step:1553 [D loss: 0.315329, acc: 86.72%] [G loss: 2.191044]\n",
      "epoch:1 step:1554 [D loss: 0.673303, acc: 63.28%] [G loss: 2.118868]\n",
      "epoch:1 step:1555 [D loss: 0.200447, acc: 96.88%] [G loss: 2.540081]\n",
      "epoch:1 step:1556 [D loss: 0.472475, acc: 80.47%] [G loss: 1.819306]\n",
      "epoch:1 step:1557 [D loss: 0.568989, acc: 70.31%] [G loss: 1.826874]\n",
      "epoch:1 step:1558 [D loss: 2.217921, acc: 3.91%] [G loss: 2.269209]\n",
      "epoch:1 step:1559 [D loss: 0.808811, acc: 56.25%] [G loss: 1.369967]\n",
      "epoch:1 step:1560 [D loss: 0.277281, acc: 96.09%] [G loss: 2.083505]\n",
      "epoch:1 step:1561 [D loss: 1.110545, acc: 25.00%] [G loss: 1.954083]\n",
      "epoch:1 step:1562 [D loss: 1.040940, acc: 31.25%] [G loss: 1.904898]\n",
      "epoch:2 step:1563 [D loss: 0.799152, acc: 54.69%] [G loss: 1.898282]\n",
      "epoch:2 step:1564 [D loss: 0.789845, acc: 50.78%] [G loss: 2.145687]\n",
      "epoch:2 step:1565 [D loss: 0.815358, acc: 52.34%] [G loss: 2.545819]\n",
      "epoch:2 step:1566 [D loss: 0.614467, acc: 64.84%] [G loss: 2.968265]\n",
      "epoch:2 step:1567 [D loss: 0.543576, acc: 75.00%] [G loss: 3.493735]\n",
      "epoch:2 step:1568 [D loss: 0.540788, acc: 71.88%] [G loss: 2.741521]\n",
      "epoch:2 step:1569 [D loss: 0.650126, acc: 63.28%] [G loss: 2.731017]\n",
      "epoch:2 step:1570 [D loss: 0.527151, acc: 74.22%] [G loss: 2.884346]\n",
      "epoch:2 step:1571 [D loss: 0.245892, acc: 93.75%] [G loss: 3.463997]\n",
      "epoch:2 step:1572 [D loss: 0.314785, acc: 89.06%] [G loss: 2.864500]\n",
      "epoch:2 step:1573 [D loss: 0.466661, acc: 75.78%] [G loss: 2.616410]\n",
      "epoch:2 step:1574 [D loss: 0.432660, acc: 85.16%] [G loss: 2.274189]\n",
      "epoch:2 step:1575 [D loss: 0.296085, acc: 86.72%] [G loss: 2.371221]\n",
      "epoch:2 step:1576 [D loss: 0.364646, acc: 85.94%] [G loss: 2.602503]\n",
      "epoch:2 step:1577 [D loss: 0.209256, acc: 95.31%] [G loss: 2.546054]\n",
      "epoch:2 step:1578 [D loss: 1.310464, acc: 23.44%] [G loss: 1.663720]\n",
      "epoch:2 step:1579 [D loss: 0.589624, acc: 69.53%] [G loss: 1.669804]\n",
      "epoch:2 step:1580 [D loss: 0.680265, acc: 61.72%] [G loss: 1.549354]\n",
      "epoch:2 step:1581 [D loss: 0.520877, acc: 71.88%] [G loss: 1.753332]\n",
      "epoch:2 step:1582 [D loss: 0.591790, acc: 70.31%] [G loss: 1.954819]\n",
      "epoch:2 step:1583 [D loss: 0.864364, acc: 52.34%] [G loss: 1.604747]\n",
      "epoch:2 step:1584 [D loss: 0.916665, acc: 45.31%] [G loss: 2.002170]\n",
      "epoch:2 step:1585 [D loss: 0.841986, acc: 48.44%] [G loss: 2.228812]\n",
      "epoch:2 step:1586 [D loss: 1.016347, acc: 30.47%] [G loss: 2.213354]\n",
      "epoch:2 step:1587 [D loss: 0.792500, acc: 47.66%] [G loss: 2.394506]\n",
      "epoch:2 step:1588 [D loss: 1.435009, acc: 21.88%] [G loss: 2.445731]\n",
      "epoch:2 step:1589 [D loss: 0.569650, acc: 71.88%] [G loss: 3.184728]\n",
      "epoch:2 step:1590 [D loss: 0.570532, acc: 70.31%] [G loss: 2.762394]\n",
      "epoch:2 step:1591 [D loss: 0.612880, acc: 64.84%] [G loss: 2.972579]\n",
      "epoch:2 step:1592 [D loss: 0.366046, acc: 84.38%] [G loss: 3.142128]\n",
      "epoch:2 step:1593 [D loss: 0.544122, acc: 73.44%] [G loss: 3.101491]\n",
      "epoch:2 step:1594 [D loss: 0.292851, acc: 91.41%] [G loss: 3.025510]\n",
      "epoch:2 step:1595 [D loss: 0.198003, acc: 94.53%] [G loss: 3.278244]\n",
      "epoch:2 step:1596 [D loss: 0.200853, acc: 97.66%] [G loss: 2.702988]\n",
      "epoch:2 step:1597 [D loss: 0.349886, acc: 89.84%] [G loss: 2.170020]\n",
      "epoch:2 step:1598 [D loss: 0.440711, acc: 81.25%] [G loss: 1.997633]\n",
      "epoch:2 step:1599 [D loss: 0.557283, acc: 72.66%] [G loss: 1.653977]\n",
      "epoch:2 step:1600 [D loss: 0.452014, acc: 81.25%] [G loss: 1.653207]\n",
      "epoch:2 step:1601 [D loss: 0.575928, acc: 67.19%] [G loss: 1.861662]\n",
      "epoch:2 step:1602 [D loss: 0.190538, acc: 95.31%] [G loss: 2.298359]\n",
      "epoch:2 step:1603 [D loss: 0.759491, acc: 54.69%] [G loss: 1.683407]\n",
      "epoch:2 step:1604 [D loss: 0.490734, acc: 75.78%] [G loss: 1.644033]\n",
      "epoch:2 step:1605 [D loss: 0.334268, acc: 96.88%] [G loss: 1.818786]\n",
      "epoch:2 step:1606 [D loss: 2.474188, acc: 3.91%] [G loss: 1.559016]\n",
      "epoch:2 step:1607 [D loss: 1.164034, acc: 45.31%] [G loss: 1.876801]\n",
      "epoch:2 step:1608 [D loss: 0.360576, acc: 92.19%] [G loss: 2.004676]\n",
      "epoch:2 step:1609 [D loss: 1.105718, acc: 32.81%] [G loss: 2.043903]\n",
      "epoch:2 step:1610 [D loss: 0.606407, acc: 67.19%] [G loss: 2.255651]\n",
      "epoch:2 step:1611 [D loss: 0.579058, acc: 68.75%] [G loss: 2.564000]\n",
      "epoch:2 step:1612 [D loss: 0.412081, acc: 82.03%] [G loss: 2.122541]\n",
      "epoch:2 step:1613 [D loss: 0.496427, acc: 79.69%] [G loss: 2.384076]\n",
      "epoch:2 step:1614 [D loss: 0.546583, acc: 69.53%] [G loss: 2.315306]\n",
      "epoch:2 step:1615 [D loss: 0.428162, acc: 85.94%] [G loss: 2.611475]\n",
      "epoch:2 step:1616 [D loss: 0.825692, acc: 56.25%] [G loss: 2.349396]\n",
      "epoch:2 step:1617 [D loss: 0.361054, acc: 87.50%] [G loss: 2.627338]\n",
      "epoch:2 step:1618 [D loss: 0.601664, acc: 65.62%] [G loss: 2.468243]\n",
      "epoch:2 step:1619 [D loss: 0.704810, acc: 62.50%] [G loss: 2.282910]\n",
      "epoch:2 step:1620 [D loss: 0.550586, acc: 71.88%] [G loss: 2.401211]\n",
      "epoch:2 step:1621 [D loss: 0.738822, acc: 60.94%] [G loss: 2.058351]\n",
      "epoch:2 step:1622 [D loss: 0.842300, acc: 46.88%] [G loss: 2.245225]\n",
      "epoch:2 step:1623 [D loss: 0.589589, acc: 67.19%] [G loss: 2.116448]\n",
      "epoch:2 step:1624 [D loss: 0.592667, acc: 65.62%] [G loss: 2.171831]\n",
      "epoch:2 step:1625 [D loss: 0.484072, acc: 75.00%] [G loss: 2.319570]\n",
      "epoch:2 step:1626 [D loss: 0.869322, acc: 47.66%] [G loss: 2.180212]\n",
      "epoch:2 step:1627 [D loss: 0.608821, acc: 65.62%] [G loss: 2.148288]\n",
      "epoch:2 step:1628 [D loss: 0.545847, acc: 74.22%] [G loss: 2.476252]\n",
      "epoch:2 step:1629 [D loss: 0.603793, acc: 74.22%] [G loss: 2.045863]\n",
      "epoch:2 step:1630 [D loss: 0.553266, acc: 68.75%] [G loss: 2.469885]\n",
      "epoch:2 step:1631 [D loss: 0.746927, acc: 50.78%] [G loss: 1.989197]\n",
      "epoch:2 step:1632 [D loss: 0.584668, acc: 67.19%] [G loss: 1.830498]\n",
      "epoch:2 step:1633 [D loss: 0.216796, acc: 95.31%] [G loss: 2.581190]\n",
      "epoch:2 step:1634 [D loss: 0.682528, acc: 60.16%] [G loss: 1.688198]\n",
      "epoch:2 step:1635 [D loss: 0.381652, acc: 88.28%] [G loss: 2.063914]\n",
      "epoch:2 step:1636 [D loss: 0.501192, acc: 78.91%] [G loss: 2.059610]\n",
      "epoch:2 step:1637 [D loss: 0.938340, acc: 35.94%] [G loss: 2.064708]\n",
      "epoch:2 step:1638 [D loss: 0.428693, acc: 82.03%] [G loss: 2.709893]\n",
      "epoch:2 step:1639 [D loss: 0.209128, acc: 96.09%] [G loss: 3.333455]\n",
      "epoch:2 step:1640 [D loss: 0.318936, acc: 93.75%] [G loss: 2.403393]\n",
      "epoch:2 step:1641 [D loss: 0.449008, acc: 75.00%] [G loss: 2.659681]\n",
      "epoch:2 step:1642 [D loss: 0.181030, acc: 96.88%] [G loss: 3.147028]\n",
      "epoch:2 step:1643 [D loss: 0.574884, acc: 64.06%] [G loss: 2.175177]\n",
      "epoch:2 step:1644 [D loss: 0.362518, acc: 90.62%] [G loss: 2.332068]\n",
      "epoch:2 step:1645 [D loss: 0.356419, acc: 86.72%] [G loss: 1.989901]\n",
      "epoch:2 step:1646 [D loss: 0.610092, acc: 68.75%] [G loss: 2.054501]\n",
      "epoch:2 step:1647 [D loss: 0.684054, acc: 59.38%] [G loss: 2.115407]\n",
      "epoch:2 step:1648 [D loss: 0.478641, acc: 78.91%] [G loss: 2.299360]\n",
      "epoch:2 step:1649 [D loss: 0.355859, acc: 90.62%] [G loss: 1.965360]\n",
      "epoch:2 step:1650 [D loss: 0.543494, acc: 75.78%] [G loss: 2.395881]\n",
      "epoch:2 step:1651 [D loss: 0.664725, acc: 59.38%] [G loss: 1.620045]\n",
      "epoch:2 step:1652 [D loss: 0.519122, acc: 72.66%] [G loss: 2.214428]\n",
      "epoch:2 step:1653 [D loss: 1.473554, acc: 13.28%] [G loss: 1.093176]\n",
      "epoch:2 step:1654 [D loss: 0.718655, acc: 58.59%] [G loss: 1.561843]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1655 [D loss: 1.000913, acc: 38.28%] [G loss: 1.559957]\n",
      "epoch:2 step:1656 [D loss: 1.438326, acc: 10.16%] [G loss: 0.891245]\n",
      "epoch:2 step:1657 [D loss: 0.914127, acc: 42.97%] [G loss: 1.307829]\n",
      "epoch:2 step:1658 [D loss: 0.866759, acc: 39.84%] [G loss: 1.721390]\n",
      "epoch:2 step:1659 [D loss: 0.794930, acc: 55.47%] [G loss: 1.507845]\n",
      "epoch:2 step:1660 [D loss: 0.481974, acc: 76.56%] [G loss: 2.583265]\n",
      "epoch:2 step:1661 [D loss: 0.627393, acc: 62.50%] [G loss: 2.056846]\n",
      "epoch:2 step:1662 [D loss: 1.262634, acc: 17.19%] [G loss: 1.660726]\n",
      "epoch:2 step:1663 [D loss: 0.702339, acc: 55.47%] [G loss: 1.851111]\n",
      "epoch:2 step:1664 [D loss: 0.951123, acc: 42.97%] [G loss: 2.676247]\n",
      "epoch:2 step:1665 [D loss: 0.435505, acc: 80.47%] [G loss: 3.413062]\n",
      "epoch:2 step:1666 [D loss: 0.818154, acc: 55.47%] [G loss: 2.708099]\n",
      "epoch:2 step:1667 [D loss: 0.624802, acc: 61.72%] [G loss: 2.794987]\n",
      "epoch:2 step:1668 [D loss: 0.347134, acc: 88.28%] [G loss: 2.401436]\n",
      "epoch:2 step:1669 [D loss: 0.450398, acc: 84.38%] [G loss: 2.659356]\n",
      "epoch:2 step:1670 [D loss: 0.488059, acc: 71.88%] [G loss: 2.360680]\n",
      "epoch:2 step:1671 [D loss: 0.396879, acc: 86.72%] [G loss: 2.618184]\n",
      "epoch:2 step:1672 [D loss: 0.870632, acc: 41.41%] [G loss: 1.526231]\n",
      "epoch:2 step:1673 [D loss: 0.356524, acc: 85.94%] [G loss: 2.674417]\n",
      "epoch:2 step:1674 [D loss: 0.720383, acc: 56.25%] [G loss: 2.417733]\n",
      "epoch:2 step:1675 [D loss: 0.413315, acc: 82.81%] [G loss: 2.241585]\n",
      "epoch:2 step:1676 [D loss: 0.430538, acc: 86.72%] [G loss: 2.203631]\n",
      "epoch:2 step:1677 [D loss: 1.015272, acc: 32.03%] [G loss: 2.037660]\n",
      "epoch:2 step:1678 [D loss: 0.451485, acc: 82.03%] [G loss: 2.857947]\n",
      "epoch:2 step:1679 [D loss: 0.276496, acc: 90.62%] [G loss: 2.837341]\n",
      "epoch:2 step:1680 [D loss: 0.454637, acc: 77.34%] [G loss: 2.396481]\n",
      "epoch:2 step:1681 [D loss: 0.247227, acc: 92.97%] [G loss: 2.406980]\n",
      "epoch:2 step:1682 [D loss: 0.386330, acc: 85.94%] [G loss: 2.807625]\n",
      "epoch:2 step:1683 [D loss: 0.217982, acc: 94.53%] [G loss: 2.310249]\n",
      "epoch:2 step:1684 [D loss: 0.359517, acc: 86.72%] [G loss: 2.662351]\n",
      "epoch:2 step:1685 [D loss: 0.427648, acc: 73.44%] [G loss: 2.090782]\n",
      "epoch:2 step:1686 [D loss: 0.881349, acc: 50.78%] [G loss: 1.501188]\n",
      "epoch:2 step:1687 [D loss: 0.233500, acc: 94.53%] [G loss: 1.900787]\n",
      "epoch:2 step:1688 [D loss: 0.205607, acc: 96.09%] [G loss: 2.850970]\n",
      "epoch:2 step:1689 [D loss: 0.250437, acc: 96.09%] [G loss: 2.419388]\n",
      "epoch:2 step:1690 [D loss: 0.172665, acc: 95.31%] [G loss: 2.415884]\n",
      "epoch:2 step:1691 [D loss: 0.336223, acc: 90.62%] [G loss: 2.827042]\n",
      "epoch:2 step:1692 [D loss: 0.250372, acc: 92.97%] [G loss: 3.572387]\n",
      "epoch:2 step:1693 [D loss: 0.122522, acc: 97.66%] [G loss: 2.706300]\n",
      "epoch:2 step:1694 [D loss: 0.401595, acc: 82.81%] [G loss: 2.220303]\n",
      "epoch:2 step:1695 [D loss: 0.368671, acc: 82.03%] [G loss: 2.565477]\n",
      "epoch:2 step:1696 [D loss: 0.759599, acc: 55.47%] [G loss: 1.792431]\n",
      "epoch:2 step:1697 [D loss: 0.452964, acc: 71.09%] [G loss: 2.295894]\n",
      "epoch:2 step:1698 [D loss: 0.103626, acc: 99.22%] [G loss: 3.576661]\n",
      "epoch:2 step:1699 [D loss: 0.259922, acc: 96.09%] [G loss: 2.551510]\n",
      "epoch:2 step:1700 [D loss: 0.154372, acc: 99.22%] [G loss: 3.406890]\n",
      "epoch:2 step:1701 [D loss: 0.218067, acc: 94.53%] [G loss: 2.475535]\n",
      "epoch:2 step:1702 [D loss: 0.096840, acc: 99.22%] [G loss: 2.972009]\n",
      "epoch:2 step:1703 [D loss: 0.171771, acc: 96.88%] [G loss: 3.042118]\n",
      "epoch:2 step:1704 [D loss: 0.557266, acc: 71.09%] [G loss: 2.101707]\n",
      "epoch:2 step:1705 [D loss: 0.771598, acc: 48.44%] [G loss: 1.800481]\n",
      "epoch:2 step:1706 [D loss: 0.458611, acc: 78.12%] [G loss: 2.172418]\n",
      "epoch:2 step:1707 [D loss: 0.531849, acc: 68.75%] [G loss: 2.310093]\n",
      "epoch:2 step:1708 [D loss: 0.064856, acc: 99.22%] [G loss: 3.569518]\n",
      "epoch:2 step:1709 [D loss: 0.816917, acc: 55.47%] [G loss: 1.804139]\n",
      "epoch:2 step:1710 [D loss: 1.092064, acc: 41.41%] [G loss: 1.764255]\n",
      "epoch:2 step:1711 [D loss: 0.628060, acc: 64.84%] [G loss: 1.707446]\n",
      "epoch:2 step:1712 [D loss: 0.649099, acc: 67.97%] [G loss: 2.260255]\n",
      "epoch:2 step:1713 [D loss: 0.726902, acc: 58.59%] [G loss: 1.885411]\n",
      "epoch:2 step:1714 [D loss: 0.243209, acc: 89.84%] [G loss: 2.733122]\n",
      "epoch:2 step:1715 [D loss: 1.007643, acc: 38.28%] [G loss: 1.896300]\n",
      "epoch:2 step:1716 [D loss: 0.756920, acc: 58.59%] [G loss: 2.050272]\n",
      "epoch:2 step:1717 [D loss: 0.274655, acc: 91.41%] [G loss: 2.679827]\n",
      "epoch:2 step:1718 [D loss: 0.539103, acc: 71.88%] [G loss: 2.569951]\n",
      "epoch:2 step:1719 [D loss: 0.742567, acc: 50.78%] [G loss: 2.398953]\n",
      "epoch:2 step:1720 [D loss: 0.251509, acc: 93.75%] [G loss: 2.998311]\n",
      "epoch:2 step:1721 [D loss: 0.541136, acc: 73.44%] [G loss: 2.680697]\n",
      "epoch:2 step:1722 [D loss: 0.290915, acc: 89.84%] [G loss: 2.902249]\n",
      "epoch:2 step:1723 [D loss: 0.132674, acc: 98.44%] [G loss: 3.284877]\n",
      "epoch:2 step:1724 [D loss: 0.149528, acc: 97.66%] [G loss: 2.885522]\n",
      "epoch:2 step:1725 [D loss: 0.133463, acc: 96.09%] [G loss: 2.986730]\n",
      "epoch:2 step:1726 [D loss: 0.538545, acc: 67.19%] [G loss: 2.613626]\n",
      "epoch:2 step:1727 [D loss: 0.129604, acc: 95.31%] [G loss: 2.635372]\n",
      "epoch:2 step:1728 [D loss: 0.215795, acc: 94.53%] [G loss: 3.299983]\n",
      "epoch:2 step:1729 [D loss: 0.244505, acc: 95.31%] [G loss: 2.468809]\n",
      "epoch:2 step:1730 [D loss: 0.131419, acc: 99.22%] [G loss: 2.941173]\n",
      "epoch:2 step:1731 [D loss: 0.196256, acc: 94.53%] [G loss: 3.344841]\n",
      "epoch:2 step:1732 [D loss: 0.028065, acc: 100.00%] [G loss: 3.868684]\n",
      "epoch:2 step:1733 [D loss: 0.084288, acc: 98.44%] [G loss: 3.421390]\n",
      "epoch:2 step:1734 [D loss: 0.401728, acc: 76.56%] [G loss: 2.720803]\n",
      "epoch:2 step:1735 [D loss: 0.728500, acc: 53.91%] [G loss: 1.818781]\n",
      "epoch:2 step:1736 [D loss: 0.246764, acc: 92.97%] [G loss: 3.679586]\n",
      "epoch:2 step:1737 [D loss: 0.171267, acc: 96.09%] [G loss: 2.981182]\n",
      "epoch:2 step:1738 [D loss: 0.250490, acc: 95.31%] [G loss: 3.099968]\n",
      "epoch:2 step:1739 [D loss: 0.633926, acc: 67.97%] [G loss: 2.407601]\n",
      "epoch:2 step:1740 [D loss: 0.187753, acc: 96.88%] [G loss: 2.552440]\n",
      "epoch:2 step:1741 [D loss: 0.248970, acc: 91.41%] [G loss: 3.156074]\n",
      "epoch:2 step:1742 [D loss: 0.146459, acc: 98.44%] [G loss: 2.841110]\n",
      "epoch:2 step:1743 [D loss: 0.942140, acc: 49.22%] [G loss: 2.250583]\n",
      "epoch:2 step:1744 [D loss: 0.494505, acc: 79.69%] [G loss: 1.726258]\n",
      "epoch:2 step:1745 [D loss: 1.372063, acc: 17.97%] [G loss: 2.162568]\n",
      "epoch:2 step:1746 [D loss: 0.477021, acc: 74.22%] [G loss: 3.455921]\n",
      "epoch:2 step:1747 [D loss: 1.114125, acc: 50.00%] [G loss: 2.297478]\n",
      "epoch:2 step:1748 [D loss: 0.675788, acc: 59.38%] [G loss: 2.618051]\n",
      "epoch:2 step:1749 [D loss: 0.906238, acc: 50.78%] [G loss: 2.619616]\n",
      "epoch:2 step:1750 [D loss: 0.912416, acc: 43.75%] [G loss: 2.868726]\n",
      "epoch:2 step:1751 [D loss: 0.761353, acc: 54.69%] [G loss: 3.157892]\n",
      "epoch:2 step:1752 [D loss: 1.078130, acc: 38.28%] [G loss: 2.448073]\n",
      "epoch:2 step:1753 [D loss: 0.515102, acc: 77.34%] [G loss: 3.593749]\n",
      "epoch:2 step:1754 [D loss: 0.753708, acc: 55.47%] [G loss: 3.022411]\n",
      "epoch:2 step:1755 [D loss: 1.060663, acc: 30.47%] [G loss: 2.571896]\n",
      "epoch:2 step:1756 [D loss: 0.790320, acc: 48.44%] [G loss: 2.309698]\n",
      "epoch:2 step:1757 [D loss: 0.400940, acc: 87.50%] [G loss: 2.397147]\n",
      "epoch:2 step:1758 [D loss: 0.471704, acc: 83.59%] [G loss: 2.454404]\n",
      "epoch:2 step:1759 [D loss: 1.192662, acc: 23.44%] [G loss: 2.469823]\n",
      "epoch:2 step:1760 [D loss: 0.637131, acc: 62.50%] [G loss: 2.310713]\n",
      "epoch:2 step:1761 [D loss: 0.737490, acc: 56.25%] [G loss: 2.401556]\n",
      "epoch:2 step:1762 [D loss: 0.603005, acc: 67.19%] [G loss: 2.622782]\n",
      "epoch:2 step:1763 [D loss: 0.378845, acc: 86.72%] [G loss: 2.474232]\n",
      "epoch:2 step:1764 [D loss: 0.616080, acc: 66.41%] [G loss: 1.989061]\n",
      "epoch:2 step:1765 [D loss: 0.703351, acc: 60.16%] [G loss: 1.946491]\n",
      "epoch:2 step:1766 [D loss: 0.349579, acc: 86.72%] [G loss: 2.132432]\n",
      "epoch:2 step:1767 [D loss: 0.884055, acc: 47.66%] [G loss: 1.602732]\n",
      "epoch:2 step:1768 [D loss: 0.674091, acc: 61.72%] [G loss: 1.671649]\n",
      "epoch:2 step:1769 [D loss: 0.326555, acc: 92.19%] [G loss: 2.336027]\n",
      "epoch:2 step:1770 [D loss: 0.651116, acc: 61.72%] [G loss: 1.833595]\n",
      "epoch:2 step:1771 [D loss: 1.181182, acc: 20.31%] [G loss: 1.936149]\n",
      "epoch:2 step:1772 [D loss: 0.619333, acc: 63.28%] [G loss: 2.012320]\n",
      "epoch:2 step:1773 [D loss: 0.808107, acc: 48.44%] [G loss: 1.772770]\n",
      "epoch:2 step:1774 [D loss: 0.426921, acc: 85.16%] [G loss: 2.178833]\n",
      "epoch:2 step:1775 [D loss: 0.509246, acc: 76.56%] [G loss: 2.454155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1776 [D loss: 0.530975, acc: 75.00%] [G loss: 2.500702]\n",
      "epoch:2 step:1777 [D loss: 0.310153, acc: 92.19%] [G loss: 2.209761]\n",
      "epoch:2 step:1778 [D loss: 0.365550, acc: 85.16%] [G loss: 2.231650]\n",
      "epoch:2 step:1779 [D loss: 0.674275, acc: 57.81%] [G loss: 2.257884]\n",
      "epoch:2 step:1780 [D loss: 1.298324, acc: 28.91%] [G loss: 2.011180]\n",
      "epoch:2 step:1781 [D loss: 0.727897, acc: 57.81%] [G loss: 2.147085]\n",
      "epoch:2 step:1782 [D loss: 0.439370, acc: 82.03%] [G loss: 2.769049]\n",
      "epoch:2 step:1783 [D loss: 0.665273, acc: 62.50%] [G loss: 2.195546]\n",
      "epoch:2 step:1784 [D loss: 1.013649, acc: 32.81%] [G loss: 2.480700]\n",
      "epoch:2 step:1785 [D loss: 0.750341, acc: 56.25%] [G loss: 2.226295]\n",
      "epoch:2 step:1786 [D loss: 0.451860, acc: 82.81%] [G loss: 2.390316]\n",
      "epoch:2 step:1787 [D loss: 0.847983, acc: 49.22%] [G loss: 2.687777]\n",
      "epoch:2 step:1788 [D loss: 0.780550, acc: 53.12%] [G loss: 2.925605]\n",
      "epoch:2 step:1789 [D loss: 0.590659, acc: 70.31%] [G loss: 2.567087]\n",
      "epoch:2 step:1790 [D loss: 0.355623, acc: 86.72%] [G loss: 3.136186]\n",
      "epoch:2 step:1791 [D loss: 1.153997, acc: 35.94%] [G loss: 2.642308]\n",
      "epoch:2 step:1792 [D loss: 0.671952, acc: 62.50%] [G loss: 2.385837]\n",
      "epoch:2 step:1793 [D loss: 0.478977, acc: 78.12%] [G loss: 2.899256]\n",
      "epoch:2 step:1794 [D loss: 0.703217, acc: 56.25%] [G loss: 3.034377]\n",
      "epoch:2 step:1795 [D loss: 0.472679, acc: 81.25%] [G loss: 3.163225]\n",
      "epoch:2 step:1796 [D loss: 0.604107, acc: 66.41%] [G loss: 2.776941]\n",
      "epoch:2 step:1797 [D loss: 0.718774, acc: 58.59%] [G loss: 2.031978]\n",
      "epoch:2 step:1798 [D loss: 0.217901, acc: 94.53%] [G loss: 2.855439]\n",
      "epoch:2 step:1799 [D loss: 0.356454, acc: 86.72%] [G loss: 2.762744]\n",
      "epoch:2 step:1800 [D loss: 0.474954, acc: 82.03%] [G loss: 2.290432]\n",
      "epoch:2 step:1801 [D loss: 0.490433, acc: 78.91%] [G loss: 2.789021]\n",
      "epoch:2 step:1802 [D loss: 0.333098, acc: 83.59%] [G loss: 3.101854]\n",
      "epoch:2 step:1803 [D loss: 0.656579, acc: 64.06%] [G loss: 2.167240]\n",
      "epoch:2 step:1804 [D loss: 0.417732, acc: 80.47%] [G loss: 1.956818]\n",
      "epoch:2 step:1805 [D loss: 0.636402, acc: 68.75%] [G loss: 1.780389]\n",
      "epoch:2 step:1806 [D loss: 0.331949, acc: 86.72%] [G loss: 2.166189]\n",
      "epoch:2 step:1807 [D loss: 0.487404, acc: 74.22%] [G loss: 2.294347]\n",
      "epoch:2 step:1808 [D loss: 0.604502, acc: 64.84%] [G loss: 2.411323]\n",
      "epoch:2 step:1809 [D loss: 0.648489, acc: 63.28%] [G loss: 3.283172]\n",
      "epoch:2 step:1810 [D loss: 1.260385, acc: 34.38%] [G loss: 2.431685]\n",
      "epoch:2 step:1811 [D loss: 0.625349, acc: 66.41%] [G loss: 2.991987]\n",
      "epoch:2 step:1812 [D loss: 0.912312, acc: 47.66%] [G loss: 2.475348]\n",
      "epoch:2 step:1813 [D loss: 0.652258, acc: 64.06%] [G loss: 2.211697]\n",
      "epoch:2 step:1814 [D loss: 0.717038, acc: 54.69%] [G loss: 2.542348]\n",
      "epoch:2 step:1815 [D loss: 0.666843, acc: 64.06%] [G loss: 2.304486]\n",
      "epoch:2 step:1816 [D loss: 0.744342, acc: 52.34%] [G loss: 2.839831]\n",
      "epoch:2 step:1817 [D loss: 0.623038, acc: 66.41%] [G loss: 2.797390]\n",
      "epoch:2 step:1818 [D loss: 0.641354, acc: 64.84%] [G loss: 2.626172]\n",
      "epoch:2 step:1819 [D loss: 0.797981, acc: 53.91%] [G loss: 2.412368]\n",
      "epoch:2 step:1820 [D loss: 0.654367, acc: 61.72%] [G loss: 2.491296]\n",
      "epoch:2 step:1821 [D loss: 0.592511, acc: 67.19%] [G loss: 2.224701]\n",
      "epoch:2 step:1822 [D loss: 0.751327, acc: 58.59%] [G loss: 2.303684]\n",
      "epoch:2 step:1823 [D loss: 0.673543, acc: 61.72%] [G loss: 2.278809]\n",
      "epoch:2 step:1824 [D loss: 0.563296, acc: 71.09%] [G loss: 2.543238]\n",
      "epoch:2 step:1825 [D loss: 0.807445, acc: 49.22%] [G loss: 1.987631]\n",
      "epoch:2 step:1826 [D loss: 0.883804, acc: 45.31%] [G loss: 1.978250]\n",
      "epoch:2 step:1827 [D loss: 0.505608, acc: 73.44%] [G loss: 2.761103]\n",
      "epoch:2 step:1828 [D loss: 0.699005, acc: 57.03%] [G loss: 2.395151]\n",
      "epoch:2 step:1829 [D loss: 1.271656, acc: 22.66%] [G loss: 1.752611]\n",
      "epoch:2 step:1830 [D loss: 0.666582, acc: 57.81%] [G loss: 2.491139]\n",
      "epoch:2 step:1831 [D loss: 0.638438, acc: 64.84%] [G loss: 2.307426]\n",
      "epoch:2 step:1832 [D loss: 0.718812, acc: 52.34%] [G loss: 2.924184]\n",
      "epoch:2 step:1833 [D loss: 0.641003, acc: 64.84%] [G loss: 2.350814]\n",
      "epoch:2 step:1834 [D loss: 0.602326, acc: 68.75%] [G loss: 2.475677]\n",
      "epoch:2 step:1835 [D loss: 0.495128, acc: 75.78%] [G loss: 3.267897]\n",
      "epoch:2 step:1836 [D loss: 0.376817, acc: 86.72%] [G loss: 3.105547]\n",
      "epoch:2 step:1837 [D loss: 0.512037, acc: 73.44%] [G loss: 2.923887]\n",
      "epoch:2 step:1838 [D loss: 0.434238, acc: 82.81%] [G loss: 2.679806]\n",
      "epoch:2 step:1839 [D loss: 0.505318, acc: 78.91%] [G loss: 2.474735]\n",
      "epoch:2 step:1840 [D loss: 0.720065, acc: 57.81%] [G loss: 1.899461]\n",
      "epoch:2 step:1841 [D loss: 0.533407, acc: 71.09%] [G loss: 2.114264]\n",
      "epoch:2 step:1842 [D loss: 0.568256, acc: 71.88%] [G loss: 2.180632]\n",
      "epoch:2 step:1843 [D loss: 0.372326, acc: 87.50%] [G loss: 2.483452]\n",
      "epoch:2 step:1844 [D loss: 0.804422, acc: 53.91%] [G loss: 1.743301]\n",
      "epoch:2 step:1845 [D loss: 0.637465, acc: 64.06%] [G loss: 1.821034]\n",
      "epoch:2 step:1846 [D loss: 0.782369, acc: 51.56%] [G loss: 1.746372]\n",
      "epoch:2 step:1847 [D loss: 0.772087, acc: 55.47%] [G loss: 1.603822]\n",
      "epoch:2 step:1848 [D loss: 1.373548, acc: 13.28%] [G loss: 1.490051]\n",
      "epoch:2 step:1849 [D loss: 0.734393, acc: 53.91%] [G loss: 1.707294]\n",
      "epoch:2 step:1850 [D loss: 0.993557, acc: 39.84%] [G loss: 1.474487]\n",
      "epoch:2 step:1851 [D loss: 0.918354, acc: 30.47%] [G loss: 1.795551]\n",
      "epoch:2 step:1852 [D loss: 0.599535, acc: 70.31%] [G loss: 2.724385]\n",
      "epoch:2 step:1853 [D loss: 0.780207, acc: 50.78%] [G loss: 2.311017]\n",
      "epoch:2 step:1854 [D loss: 0.742273, acc: 56.25%] [G loss: 1.964199]\n",
      "epoch:2 step:1855 [D loss: 0.801789, acc: 52.34%] [G loss: 2.062728]\n",
      "epoch:2 step:1856 [D loss: 0.774066, acc: 54.69%] [G loss: 2.215677]\n",
      "epoch:2 step:1857 [D loss: 0.575704, acc: 69.53%] [G loss: 2.410475]\n",
      "epoch:2 step:1858 [D loss: 0.952446, acc: 35.94%] [G loss: 2.054284]\n",
      "epoch:2 step:1859 [D loss: 0.458067, acc: 81.25%] [G loss: 3.081243]\n",
      "epoch:2 step:1860 [D loss: 0.462506, acc: 78.12%] [G loss: 2.873274]\n",
      "epoch:2 step:1861 [D loss: 0.401165, acc: 85.94%] [G loss: 3.057415]\n",
      "epoch:2 step:1862 [D loss: 0.569181, acc: 67.97%] [G loss: 2.714930]\n",
      "epoch:2 step:1863 [D loss: 0.583539, acc: 69.53%] [G loss: 2.850750]\n",
      "epoch:2 step:1864 [D loss: 0.617701, acc: 67.97%] [G loss: 2.472663]\n",
      "epoch:2 step:1865 [D loss: 0.673773, acc: 67.97%] [G loss: 2.288956]\n",
      "epoch:2 step:1866 [D loss: 0.664602, acc: 65.62%] [G loss: 2.418997]\n",
      "epoch:2 step:1867 [D loss: 0.838485, acc: 39.84%] [G loss: 2.069577]\n",
      "epoch:2 step:1868 [D loss: 0.491047, acc: 77.34%] [G loss: 2.630825]\n",
      "epoch:2 step:1869 [D loss: 0.669927, acc: 61.72%] [G loss: 2.481697]\n",
      "epoch:2 step:1870 [D loss: 0.522690, acc: 78.12%] [G loss: 2.819733]\n",
      "epoch:2 step:1871 [D loss: 0.644832, acc: 65.62%] [G loss: 2.399464]\n",
      "epoch:2 step:1872 [D loss: 0.639490, acc: 60.16%] [G loss: 1.918246]\n",
      "epoch:2 step:1873 [D loss: 0.695609, acc: 56.25%] [G loss: 2.141135]\n",
      "epoch:2 step:1874 [D loss: 0.503520, acc: 78.91%] [G loss: 2.397629]\n",
      "epoch:2 step:1875 [D loss: 0.725447, acc: 56.25%] [G loss: 2.204484]\n",
      "epoch:2 step:1876 [D loss: 0.752443, acc: 53.12%] [G loss: 1.795646]\n",
      "epoch:2 step:1877 [D loss: 1.083092, acc: 24.22%] [G loss: 1.853088]\n",
      "epoch:2 step:1878 [D loss: 0.609099, acc: 70.31%] [G loss: 2.131057]\n",
      "epoch:2 step:1879 [D loss: 0.776829, acc: 53.12%] [G loss: 1.905912]\n",
      "epoch:2 step:1880 [D loss: 0.576975, acc: 67.19%] [G loss: 2.170084]\n",
      "epoch:2 step:1881 [D loss: 0.624125, acc: 68.75%] [G loss: 1.906083]\n",
      "epoch:2 step:1882 [D loss: 1.116693, acc: 36.72%] [G loss: 1.956119]\n",
      "epoch:2 step:1883 [D loss: 0.859586, acc: 44.53%] [G loss: 1.902343]\n",
      "epoch:2 step:1884 [D loss: 1.014680, acc: 25.78%] [G loss: 1.464030]\n",
      "epoch:2 step:1885 [D loss: 0.640415, acc: 64.84%] [G loss: 2.166873]\n",
      "epoch:2 step:1886 [D loss: 0.865745, acc: 39.06%] [G loss: 1.791674]\n",
      "epoch:2 step:1887 [D loss: 0.888147, acc: 42.19%] [G loss: 2.003246]\n",
      "epoch:2 step:1888 [D loss: 0.846413, acc: 42.19%] [G loss: 1.692171]\n",
      "epoch:2 step:1889 [D loss: 0.625204, acc: 64.84%] [G loss: 1.773177]\n",
      "epoch:2 step:1890 [D loss: 0.668206, acc: 58.59%] [G loss: 1.644258]\n",
      "epoch:2 step:1891 [D loss: 0.836984, acc: 39.06%] [G loss: 1.692627]\n",
      "epoch:2 step:1892 [D loss: 0.480769, acc: 83.59%] [G loss: 2.228431]\n",
      "epoch:2 step:1893 [D loss: 0.875623, acc: 38.28%] [G loss: 1.730870]\n",
      "epoch:2 step:1894 [D loss: 0.705351, acc: 58.59%] [G loss: 1.858773]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1895 [D loss: 0.507333, acc: 78.12%] [G loss: 2.030005]\n",
      "epoch:2 step:1896 [D loss: 0.570044, acc: 72.66%] [G loss: 1.868463]\n",
      "epoch:2 step:1897 [D loss: 0.709907, acc: 58.59%] [G loss: 1.737267]\n",
      "epoch:2 step:1898 [D loss: 0.586258, acc: 72.66%] [G loss: 1.784458]\n",
      "epoch:2 step:1899 [D loss: 0.469981, acc: 82.81%] [G loss: 2.227607]\n",
      "epoch:2 step:1900 [D loss: 0.387090, acc: 89.06%] [G loss: 2.387692]\n",
      "epoch:2 step:1901 [D loss: 0.500064, acc: 72.66%] [G loss: 1.717465]\n",
      "epoch:2 step:1902 [D loss: 0.617401, acc: 65.62%] [G loss: 2.415792]\n",
      "epoch:2 step:1903 [D loss: 0.441177, acc: 80.47%] [G loss: 2.111396]\n",
      "epoch:2 step:1904 [D loss: 0.368623, acc: 90.62%] [G loss: 2.240770]\n",
      "epoch:2 step:1905 [D loss: 0.589440, acc: 65.62%] [G loss: 1.874312]\n",
      "epoch:2 step:1906 [D loss: 0.606031, acc: 68.75%] [G loss: 1.994035]\n",
      "epoch:2 step:1907 [D loss: 0.647936, acc: 65.62%] [G loss: 1.852715]\n",
      "epoch:2 step:1908 [D loss: 0.408973, acc: 89.06%] [G loss: 2.384677]\n",
      "epoch:2 step:1909 [D loss: 0.775076, acc: 55.47%] [G loss: 1.821892]\n",
      "epoch:2 step:1910 [D loss: 0.680624, acc: 59.38%] [G loss: 1.687785]\n",
      "epoch:2 step:1911 [D loss: 0.569302, acc: 72.66%] [G loss: 2.200645]\n",
      "epoch:2 step:1912 [D loss: 0.338755, acc: 90.62%] [G loss: 2.610605]\n",
      "epoch:2 step:1913 [D loss: 0.763790, acc: 53.91%] [G loss: 1.536602]\n",
      "epoch:2 step:1914 [D loss: 0.668336, acc: 64.84%] [G loss: 1.854518]\n",
      "epoch:2 step:1915 [D loss: 0.541048, acc: 72.66%] [G loss: 2.076653]\n",
      "epoch:2 step:1916 [D loss: 0.935332, acc: 37.50%] [G loss: 1.871778]\n",
      "epoch:2 step:1917 [D loss: 0.685305, acc: 57.81%] [G loss: 2.055961]\n",
      "epoch:2 step:1918 [D loss: 0.912907, acc: 36.72%] [G loss: 1.820993]\n",
      "epoch:2 step:1919 [D loss: 0.805304, acc: 50.78%] [G loss: 1.894224]\n",
      "epoch:2 step:1920 [D loss: 0.886777, acc: 42.97%] [G loss: 1.752441]\n",
      "epoch:2 step:1921 [D loss: 0.985508, acc: 32.81%] [G loss: 1.791739]\n",
      "epoch:2 step:1922 [D loss: 0.760903, acc: 53.91%] [G loss: 1.754498]\n",
      "epoch:2 step:1923 [D loss: 0.878467, acc: 37.50%] [G loss: 1.901685]\n",
      "epoch:2 step:1924 [D loss: 0.665936, acc: 60.16%] [G loss: 2.281734]\n",
      "epoch:2 step:1925 [D loss: 0.678461, acc: 62.50%] [G loss: 1.874152]\n",
      "epoch:2 step:1926 [D loss: 0.801590, acc: 47.66%] [G loss: 2.085156]\n",
      "epoch:2 step:1927 [D loss: 0.490733, acc: 79.69%] [G loss: 2.047919]\n",
      "epoch:2 step:1928 [D loss: 0.681506, acc: 65.62%] [G loss: 1.795349]\n",
      "epoch:2 step:1929 [D loss: 0.348955, acc: 85.94%] [G loss: 2.609972]\n",
      "epoch:2 step:1930 [D loss: 0.645014, acc: 57.03%] [G loss: 1.768404]\n",
      "epoch:2 step:1931 [D loss: 0.715330, acc: 56.25%] [G loss: 1.972228]\n",
      "epoch:2 step:1932 [D loss: 0.403547, acc: 87.50%] [G loss: 2.608592]\n",
      "epoch:2 step:1933 [D loss: 0.603273, acc: 64.06%] [G loss: 2.294222]\n",
      "epoch:2 step:1934 [D loss: 0.606092, acc: 67.19%] [G loss: 2.022793]\n",
      "epoch:2 step:1935 [D loss: 0.475322, acc: 85.16%] [G loss: 2.347481]\n",
      "epoch:2 step:1936 [D loss: 0.562008, acc: 71.88%] [G loss: 2.360434]\n",
      "epoch:2 step:1937 [D loss: 0.968950, acc: 32.81%] [G loss: 1.502949]\n",
      "epoch:2 step:1938 [D loss: 0.595626, acc: 71.09%] [G loss: 2.239033]\n",
      "epoch:2 step:1939 [D loss: 0.315808, acc: 89.06%] [G loss: 2.184184]\n",
      "epoch:2 step:1940 [D loss: 0.395802, acc: 88.28%] [G loss: 2.290236]\n",
      "epoch:2 step:1941 [D loss: 0.501216, acc: 78.91%] [G loss: 1.993998]\n",
      "epoch:2 step:1942 [D loss: 0.405298, acc: 87.50%] [G loss: 2.201238]\n",
      "epoch:2 step:1943 [D loss: 0.606085, acc: 69.53%] [G loss: 1.532607]\n",
      "epoch:2 step:1944 [D loss: 1.057038, acc: 32.81%] [G loss: 1.725396]\n",
      "epoch:2 step:1945 [D loss: 0.773424, acc: 57.03%] [G loss: 1.743043]\n",
      "epoch:2 step:1946 [D loss: 0.621168, acc: 67.19%] [G loss: 2.037453]\n",
      "epoch:2 step:1947 [D loss: 0.948282, acc: 36.72%] [G loss: 1.914250]\n",
      "epoch:2 step:1948 [D loss: 0.505290, acc: 76.56%] [G loss: 1.971635]\n",
      "epoch:2 step:1949 [D loss: 0.577148, acc: 71.09%] [G loss: 2.412086]\n",
      "epoch:2 step:1950 [D loss: 0.736467, acc: 60.16%] [G loss: 1.965481]\n",
      "epoch:2 step:1951 [D loss: 0.434856, acc: 84.38%] [G loss: 2.128810]\n",
      "epoch:2 step:1952 [D loss: 0.795835, acc: 52.34%] [G loss: 2.024823]\n",
      "epoch:2 step:1953 [D loss: 0.634566, acc: 64.84%] [G loss: 1.981159]\n",
      "epoch:2 step:1954 [D loss: 0.861129, acc: 46.88%] [G loss: 1.793226]\n",
      "epoch:2 step:1955 [D loss: 0.655436, acc: 64.06%] [G loss: 1.760033]\n",
      "epoch:2 step:1956 [D loss: 0.720676, acc: 53.12%] [G loss: 1.708935]\n",
      "epoch:2 step:1957 [D loss: 0.765056, acc: 53.91%] [G loss: 1.811946]\n",
      "epoch:2 step:1958 [D loss: 0.478330, acc: 78.91%] [G loss: 1.986994]\n",
      "epoch:2 step:1959 [D loss: 0.904697, acc: 34.38%] [G loss: 1.474669]\n",
      "epoch:2 step:1960 [D loss: 0.930953, acc: 39.84%] [G loss: 1.564282]\n",
      "epoch:2 step:1961 [D loss: 0.750453, acc: 52.34%] [G loss: 1.993286]\n",
      "epoch:2 step:1962 [D loss: 0.900120, acc: 42.19%] [G loss: 2.120121]\n",
      "epoch:2 step:1963 [D loss: 1.135376, acc: 23.44%] [G loss: 1.678371]\n",
      "epoch:2 step:1964 [D loss: 0.832473, acc: 42.97%] [G loss: 1.975270]\n",
      "epoch:2 step:1965 [D loss: 0.847277, acc: 48.44%] [G loss: 2.399371]\n",
      "epoch:2 step:1966 [D loss: 0.636489, acc: 64.06%] [G loss: 2.313265]\n",
      "epoch:2 step:1967 [D loss: 0.741399, acc: 52.34%] [G loss: 2.144273]\n",
      "epoch:2 step:1968 [D loss: 0.449615, acc: 82.81%] [G loss: 2.583378]\n",
      "epoch:2 step:1969 [D loss: 0.887420, acc: 46.88%] [G loss: 1.718490]\n",
      "epoch:2 step:1970 [D loss: 1.056291, acc: 19.53%] [G loss: 1.533959]\n",
      "epoch:2 step:1971 [D loss: 0.668393, acc: 57.81%] [G loss: 1.766650]\n",
      "epoch:2 step:1972 [D loss: 0.693052, acc: 60.94%] [G loss: 2.250119]\n",
      "epoch:2 step:1973 [D loss: 0.856512, acc: 46.88%] [G loss: 1.955880]\n",
      "epoch:2 step:1974 [D loss: 0.860089, acc: 48.44%] [G loss: 2.308474]\n",
      "epoch:2 step:1975 [D loss: 0.516847, acc: 75.78%] [G loss: 2.441566]\n",
      "epoch:2 step:1976 [D loss: 0.638495, acc: 60.16%] [G loss: 2.431736]\n",
      "epoch:2 step:1977 [D loss: 0.711324, acc: 60.94%] [G loss: 2.140725]\n",
      "epoch:2 step:1978 [D loss: 0.903420, acc: 36.72%] [G loss: 1.824812]\n",
      "epoch:2 step:1979 [D loss: 0.930971, acc: 29.69%] [G loss: 1.972021]\n",
      "epoch:2 step:1980 [D loss: 0.674151, acc: 64.06%] [G loss: 1.855579]\n",
      "epoch:2 step:1981 [D loss: 0.706435, acc: 56.25%] [G loss: 2.273896]\n",
      "epoch:2 step:1982 [D loss: 0.679636, acc: 61.72%] [G loss: 2.085077]\n",
      "epoch:2 step:1983 [D loss: 0.666001, acc: 59.38%] [G loss: 2.312150]\n",
      "epoch:2 step:1984 [D loss: 0.880893, acc: 40.62%] [G loss: 1.909763]\n",
      "epoch:2 step:1985 [D loss: 0.534492, acc: 75.00%] [G loss: 2.334929]\n",
      "epoch:2 step:1986 [D loss: 0.806392, acc: 50.78%] [G loss: 1.736780]\n",
      "epoch:2 step:1987 [D loss: 0.553832, acc: 75.00%] [G loss: 2.094497]\n",
      "epoch:2 step:1988 [D loss: 0.484889, acc: 84.38%] [G loss: 2.430044]\n",
      "epoch:2 step:1989 [D loss: 0.573924, acc: 71.09%] [G loss: 2.005241]\n",
      "epoch:2 step:1990 [D loss: 0.727605, acc: 55.47%] [G loss: 2.242227]\n",
      "epoch:2 step:1991 [D loss: 0.689908, acc: 61.72%] [G loss: 1.848360]\n",
      "epoch:2 step:1992 [D loss: 0.882060, acc: 36.72%] [G loss: 1.784743]\n",
      "epoch:2 step:1993 [D loss: 0.819966, acc: 46.88%] [G loss: 2.183494]\n",
      "epoch:2 step:1994 [D loss: 0.532393, acc: 71.88%] [G loss: 2.573867]\n",
      "epoch:2 step:1995 [D loss: 0.623263, acc: 66.41%] [G loss: 2.201144]\n",
      "epoch:2 step:1996 [D loss: 0.507173, acc: 77.34%] [G loss: 2.379408]\n",
      "epoch:2 step:1997 [D loss: 0.522422, acc: 70.31%] [G loss: 2.430540]\n",
      "epoch:2 step:1998 [D loss: 0.561399, acc: 71.09%] [G loss: 2.637109]\n",
      "epoch:2 step:1999 [D loss: 0.819164, acc: 53.12%] [G loss: 1.918698]\n",
      "epoch:2 step:2000 [D loss: 0.657696, acc: 65.62%] [G loss: 2.449255]\n",
      "epoch:2 step:2001 [D loss: 0.500285, acc: 75.78%] [G loss: 2.548458]\n",
      "epoch:2 step:2002 [D loss: 0.793782, acc: 43.75%] [G loss: 1.810167]\n",
      "epoch:2 step:2003 [D loss: 0.864878, acc: 38.28%] [G loss: 1.624304]\n",
      "epoch:2 step:2004 [D loss: 1.099247, acc: 30.47%] [G loss: 1.581907]\n",
      "epoch:2 step:2005 [D loss: 0.936038, acc: 43.75%] [G loss: 1.566455]\n",
      "epoch:2 step:2006 [D loss: 0.990144, acc: 30.47%] [G loss: 1.697033]\n",
      "epoch:2 step:2007 [D loss: 0.866769, acc: 47.66%] [G loss: 1.763294]\n",
      "epoch:2 step:2008 [D loss: 0.571222, acc: 67.97%] [G loss: 1.932264]\n",
      "epoch:2 step:2009 [D loss: 0.720279, acc: 55.47%] [G loss: 2.016963]\n",
      "epoch:2 step:2010 [D loss: 0.850294, acc: 41.41%] [G loss: 1.640846]\n",
      "epoch:2 step:2011 [D loss: 0.536167, acc: 78.91%] [G loss: 2.091243]\n",
      "epoch:2 step:2012 [D loss: 0.604763, acc: 67.19%] [G loss: 2.340086]\n",
      "epoch:2 step:2013 [D loss: 0.872453, acc: 48.44%] [G loss: 2.050815]\n",
      "epoch:2 step:2014 [D loss: 0.666494, acc: 61.72%] [G loss: 2.288158]\n",
      "epoch:2 step:2015 [D loss: 0.781629, acc: 44.53%] [G loss: 1.952272]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2016 [D loss: 0.699524, acc: 53.12%] [G loss: 1.985608]\n",
      "epoch:2 step:2017 [D loss: 0.595471, acc: 66.41%] [G loss: 2.436376]\n",
      "epoch:2 step:2018 [D loss: 0.629710, acc: 60.16%] [G loss: 2.478146]\n",
      "epoch:2 step:2019 [D loss: 0.756554, acc: 49.22%] [G loss: 2.278816]\n",
      "epoch:2 step:2020 [D loss: 0.605964, acc: 68.75%] [G loss: 2.149347]\n",
      "epoch:2 step:2021 [D loss: 0.663019, acc: 61.72%] [G loss: 2.405919]\n",
      "epoch:2 step:2022 [D loss: 0.684735, acc: 58.59%] [G loss: 2.509088]\n",
      "epoch:2 step:2023 [D loss: 0.666655, acc: 57.81%] [G loss: 2.167930]\n",
      "epoch:2 step:2024 [D loss: 0.549504, acc: 71.88%] [G loss: 2.573197]\n",
      "epoch:2 step:2025 [D loss: 0.790943, acc: 48.44%] [G loss: 1.893639]\n",
      "epoch:2 step:2026 [D loss: 0.786087, acc: 45.31%] [G loss: 2.094442]\n",
      "epoch:2 step:2027 [D loss: 0.635787, acc: 65.62%] [G loss: 2.177381]\n",
      "epoch:2 step:2028 [D loss: 0.665422, acc: 60.94%] [G loss: 2.117342]\n",
      "epoch:2 step:2029 [D loss: 0.500612, acc: 78.91%] [G loss: 2.253088]\n",
      "epoch:2 step:2030 [D loss: 0.612723, acc: 67.19%] [G loss: 2.162377]\n",
      "epoch:2 step:2031 [D loss: 0.692430, acc: 59.38%] [G loss: 2.160489]\n",
      "epoch:2 step:2032 [D loss: 0.714493, acc: 56.25%] [G loss: 2.096169]\n",
      "epoch:2 step:2033 [D loss: 0.775931, acc: 47.66%] [G loss: 1.884327]\n",
      "epoch:2 step:2034 [D loss: 0.587103, acc: 68.75%] [G loss: 2.273743]\n",
      "epoch:2 step:2035 [D loss: 0.537715, acc: 78.12%] [G loss: 2.487171]\n",
      "epoch:2 step:2036 [D loss: 0.688349, acc: 59.38%] [G loss: 1.949617]\n",
      "epoch:2 step:2037 [D loss: 0.893179, acc: 46.09%] [G loss: 1.771298]\n",
      "epoch:2 step:2038 [D loss: 0.499414, acc: 81.25%] [G loss: 2.495466]\n",
      "epoch:2 step:2039 [D loss: 0.488873, acc: 79.69%] [G loss: 1.861758]\n",
      "epoch:2 step:2040 [D loss: 0.902721, acc: 34.38%] [G loss: 1.545107]\n",
      "epoch:2 step:2041 [D loss: 0.985117, acc: 32.03%] [G loss: 1.687149]\n",
      "epoch:2 step:2042 [D loss: 0.650607, acc: 66.41%] [G loss: 1.897066]\n",
      "epoch:2 step:2043 [D loss: 0.628532, acc: 60.94%] [G loss: 1.782529]\n",
      "epoch:2 step:2044 [D loss: 0.592944, acc: 68.75%] [G loss: 2.044439]\n",
      "epoch:2 step:2045 [D loss: 0.598074, acc: 64.06%] [G loss: 1.641754]\n",
      "epoch:2 step:2046 [D loss: 0.521078, acc: 74.22%] [G loss: 2.084402]\n",
      "epoch:2 step:2047 [D loss: 1.150784, acc: 25.78%] [G loss: 1.601995]\n",
      "epoch:2 step:2048 [D loss: 0.548106, acc: 71.88%] [G loss: 2.083726]\n",
      "epoch:2 step:2049 [D loss: 0.673419, acc: 58.59%] [G loss: 2.147121]\n",
      "epoch:2 step:2050 [D loss: 0.695084, acc: 57.81%] [G loss: 1.457644]\n",
      "epoch:2 step:2051 [D loss: 0.868125, acc: 46.09%] [G loss: 1.863891]\n",
      "epoch:2 step:2052 [D loss: 0.700404, acc: 57.81%] [G loss: 2.194619]\n",
      "epoch:2 step:2053 [D loss: 0.801011, acc: 48.44%] [G loss: 1.729062]\n",
      "epoch:2 step:2054 [D loss: 0.768099, acc: 55.47%] [G loss: 1.787775]\n",
      "epoch:2 step:2055 [D loss: 0.905717, acc: 32.81%] [G loss: 1.758921]\n",
      "epoch:2 step:2056 [D loss: 0.976745, acc: 28.12%] [G loss: 1.761173]\n",
      "epoch:2 step:2057 [D loss: 0.906386, acc: 34.38%] [G loss: 1.816428]\n",
      "epoch:2 step:2058 [D loss: 0.706521, acc: 60.94%] [G loss: 1.854059]\n",
      "epoch:2 step:2059 [D loss: 0.768954, acc: 53.12%] [G loss: 2.208141]\n",
      "epoch:2 step:2060 [D loss: 0.700464, acc: 57.03%] [G loss: 2.161884]\n",
      "epoch:2 step:2061 [D loss: 0.771932, acc: 49.22%] [G loss: 2.038500]\n",
      "epoch:2 step:2062 [D loss: 0.810232, acc: 43.75%] [G loss: 1.896166]\n",
      "epoch:2 step:2063 [D loss: 0.768723, acc: 53.12%] [G loss: 1.883347]\n",
      "epoch:2 step:2064 [D loss: 0.752229, acc: 50.78%] [G loss: 2.061621]\n",
      "epoch:2 step:2065 [D loss: 0.613354, acc: 68.75%] [G loss: 2.181657]\n",
      "epoch:2 step:2066 [D loss: 0.681054, acc: 59.38%] [G loss: 2.045796]\n",
      "epoch:2 step:2067 [D loss: 0.714980, acc: 55.47%] [G loss: 2.065036]\n",
      "epoch:2 step:2068 [D loss: 0.545856, acc: 76.56%] [G loss: 2.010228]\n",
      "epoch:2 step:2069 [D loss: 0.606230, acc: 62.50%] [G loss: 2.311219]\n",
      "epoch:2 step:2070 [D loss: 0.692620, acc: 53.12%] [G loss: 1.887624]\n",
      "epoch:2 step:2071 [D loss: 0.603853, acc: 69.53%] [G loss: 2.112385]\n",
      "epoch:2 step:2072 [D loss: 0.793066, acc: 45.31%] [G loss: 2.123407]\n",
      "epoch:2 step:2073 [D loss: 0.897396, acc: 45.31%] [G loss: 1.730744]\n",
      "epoch:2 step:2074 [D loss: 0.591980, acc: 68.75%] [G loss: 2.093348]\n",
      "epoch:2 step:2075 [D loss: 0.858118, acc: 44.53%] [G loss: 1.729855]\n",
      "epoch:2 step:2076 [D loss: 0.822827, acc: 46.88%] [G loss: 2.167520]\n",
      "epoch:2 step:2077 [D loss: 0.622889, acc: 63.28%] [G loss: 2.187019]\n",
      "epoch:2 step:2078 [D loss: 0.872653, acc: 44.53%] [G loss: 2.157320]\n",
      "epoch:2 step:2079 [D loss: 0.777967, acc: 50.78%] [G loss: 1.864806]\n",
      "epoch:2 step:2080 [D loss: 0.522339, acc: 74.22%] [G loss: 2.446451]\n",
      "epoch:2 step:2081 [D loss: 0.545970, acc: 70.31%] [G loss: 2.032332]\n",
      "epoch:2 step:2082 [D loss: 0.642952, acc: 67.97%] [G loss: 2.081442]\n",
      "epoch:2 step:2083 [D loss: 0.492940, acc: 79.69%] [G loss: 2.312347]\n",
      "epoch:2 step:2084 [D loss: 0.655455, acc: 60.94%] [G loss: 2.027312]\n",
      "epoch:2 step:2085 [D loss: 0.741260, acc: 55.47%] [G loss: 1.830836]\n",
      "epoch:2 step:2086 [D loss: 0.783324, acc: 44.53%] [G loss: 2.069871]\n",
      "epoch:2 step:2087 [D loss: 0.559560, acc: 70.31%] [G loss: 2.204962]\n",
      "epoch:2 step:2088 [D loss: 0.841834, acc: 43.75%] [G loss: 1.895241]\n",
      "epoch:2 step:2089 [D loss: 0.458922, acc: 78.91%] [G loss: 2.587926]\n",
      "epoch:2 step:2090 [D loss: 0.848367, acc: 45.31%] [G loss: 1.597233]\n",
      "epoch:2 step:2091 [D loss: 0.846687, acc: 39.84%] [G loss: 1.955898]\n",
      "epoch:2 step:2092 [D loss: 0.542965, acc: 76.56%] [G loss: 2.134636]\n",
      "epoch:2 step:2093 [D loss: 0.642290, acc: 62.50%] [G loss: 2.035697]\n",
      "epoch:2 step:2094 [D loss: 0.973127, acc: 32.81%] [G loss: 1.573301]\n",
      "epoch:2 step:2095 [D loss: 0.557233, acc: 72.66%] [G loss: 2.451773]\n",
      "epoch:2 step:2096 [D loss: 0.691649, acc: 60.16%] [G loss: 1.945365]\n",
      "epoch:2 step:2097 [D loss: 1.048837, acc: 29.69%] [G loss: 1.717544]\n",
      "epoch:2 step:2098 [D loss: 0.649056, acc: 65.62%] [G loss: 2.062807]\n",
      "epoch:2 step:2099 [D loss: 0.811826, acc: 47.66%] [G loss: 1.940361]\n",
      "epoch:2 step:2100 [D loss: 0.861898, acc: 45.31%] [G loss: 1.916015]\n",
      "epoch:2 step:2101 [D loss: 0.669661, acc: 60.16%] [G loss: 2.400080]\n",
      "epoch:2 step:2102 [D loss: 0.552622, acc: 73.44%] [G loss: 2.897313]\n",
      "epoch:2 step:2103 [D loss: 0.520115, acc: 75.00%] [G loss: 3.011442]\n",
      "epoch:2 step:2104 [D loss: 0.618274, acc: 67.19%] [G loss: 2.670843]\n",
      "epoch:2 step:2105 [D loss: 0.432063, acc: 80.47%] [G loss: 2.679202]\n",
      "epoch:2 step:2106 [D loss: 0.654360, acc: 67.97%] [G loss: 1.989226]\n",
      "epoch:2 step:2107 [D loss: 0.671300, acc: 60.94%] [G loss: 2.213120]\n",
      "epoch:2 step:2108 [D loss: 0.715124, acc: 64.06%] [G loss: 1.890526]\n",
      "epoch:2 step:2109 [D loss: 0.944625, acc: 42.97%] [G loss: 1.700390]\n",
      "epoch:2 step:2110 [D loss: 1.016631, acc: 35.94%] [G loss: 1.606238]\n",
      "epoch:2 step:2111 [D loss: 0.804422, acc: 44.53%] [G loss: 2.127522]\n",
      "epoch:2 step:2112 [D loss: 0.587438, acc: 71.88%] [G loss: 1.932706]\n",
      "epoch:2 step:2113 [D loss: 0.579083, acc: 71.88%] [G loss: 2.560354]\n",
      "epoch:2 step:2114 [D loss: 0.935962, acc: 32.03%] [G loss: 1.626191]\n",
      "epoch:2 step:2115 [D loss: 0.759325, acc: 53.91%] [G loss: 1.612782]\n",
      "epoch:2 step:2116 [D loss: 0.541051, acc: 70.31%] [G loss: 2.002688]\n",
      "epoch:2 step:2117 [D loss: 0.595933, acc: 67.97%] [G loss: 2.578724]\n",
      "epoch:2 step:2118 [D loss: 0.759567, acc: 50.78%] [G loss: 1.759569]\n",
      "epoch:2 step:2119 [D loss: 0.736207, acc: 53.12%] [G loss: 1.826022]\n",
      "epoch:2 step:2120 [D loss: 0.768783, acc: 51.56%] [G loss: 1.672675]\n",
      "epoch:2 step:2121 [D loss: 0.868562, acc: 40.62%] [G loss: 1.620347]\n",
      "epoch:2 step:2122 [D loss: 0.719763, acc: 50.78%] [G loss: 1.809349]\n",
      "epoch:2 step:2123 [D loss: 0.647066, acc: 60.16%] [G loss: 2.074255]\n",
      "epoch:2 step:2124 [D loss: 0.685223, acc: 56.25%] [G loss: 1.947778]\n",
      "epoch:2 step:2125 [D loss: 0.742889, acc: 46.09%] [G loss: 1.533958]\n",
      "epoch:2 step:2126 [D loss: 0.590376, acc: 69.53%] [G loss: 1.920115]\n",
      "epoch:2 step:2127 [D loss: 0.619799, acc: 67.19%] [G loss: 1.800585]\n",
      "epoch:2 step:2128 [D loss: 0.765767, acc: 49.22%] [G loss: 1.696181]\n",
      "epoch:2 step:2129 [D loss: 0.398377, acc: 88.28%] [G loss: 2.207170]\n",
      "epoch:2 step:2130 [D loss: 0.687011, acc: 60.94%] [G loss: 1.536061]\n",
      "epoch:2 step:2131 [D loss: 0.759780, acc: 53.91%] [G loss: 1.569525]\n",
      "epoch:2 step:2132 [D loss: 0.617483, acc: 63.28%] [G loss: 1.647271]\n",
      "epoch:2 step:2133 [D loss: 0.922855, acc: 53.12%] [G loss: 1.409788]\n",
      "epoch:2 step:2134 [D loss: 0.620431, acc: 62.50%] [G loss: 1.569062]\n",
      "epoch:2 step:2135 [D loss: 0.596071, acc: 68.75%] [G loss: 1.795399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2136 [D loss: 1.060395, acc: 23.44%] [G loss: 1.565864]\n",
      "epoch:2 step:2137 [D loss: 0.837036, acc: 40.62%] [G loss: 1.766353]\n",
      "epoch:2 step:2138 [D loss: 0.812758, acc: 48.44%] [G loss: 1.949775]\n",
      "epoch:2 step:2139 [D loss: 0.737597, acc: 53.12%] [G loss: 1.951540]\n",
      "epoch:2 step:2140 [D loss: 0.711581, acc: 57.81%] [G loss: 1.967033]\n",
      "epoch:2 step:2141 [D loss: 0.606376, acc: 66.41%] [G loss: 2.165925]\n",
      "epoch:2 step:2142 [D loss: 0.592740, acc: 67.19%] [G loss: 2.019834]\n",
      "epoch:2 step:2143 [D loss: 0.827245, acc: 44.53%] [G loss: 1.739412]\n",
      "epoch:2 step:2144 [D loss: 0.780951, acc: 46.88%] [G loss: 1.732163]\n",
      "epoch:2 step:2145 [D loss: 0.711131, acc: 56.25%] [G loss: 1.948963]\n",
      "epoch:2 step:2146 [D loss: 0.613881, acc: 65.62%] [G loss: 1.835042]\n",
      "epoch:2 step:2147 [D loss: 0.847559, acc: 47.66%] [G loss: 1.740481]\n",
      "epoch:2 step:2148 [D loss: 0.953185, acc: 32.81%] [G loss: 1.548995]\n",
      "epoch:2 step:2149 [D loss: 0.725738, acc: 53.12%] [G loss: 1.892849]\n",
      "epoch:2 step:2150 [D loss: 0.880916, acc: 38.28%] [G loss: 1.665873]\n",
      "epoch:2 step:2151 [D loss: 0.726001, acc: 59.38%] [G loss: 1.815384]\n",
      "epoch:2 step:2152 [D loss: 0.715651, acc: 50.78%] [G loss: 2.212815]\n",
      "epoch:2 step:2153 [D loss: 0.594026, acc: 68.75%] [G loss: 2.158861]\n",
      "epoch:2 step:2154 [D loss: 0.654570, acc: 63.28%] [G loss: 1.707015]\n",
      "epoch:2 step:2155 [D loss: 0.732336, acc: 46.09%] [G loss: 1.806841]\n",
      "epoch:2 step:2156 [D loss: 0.618832, acc: 71.88%] [G loss: 2.037790]\n",
      "epoch:2 step:2157 [D loss: 0.817446, acc: 42.97%] [G loss: 1.673354]\n",
      "epoch:2 step:2158 [D loss: 0.499301, acc: 73.44%] [G loss: 2.274843]\n",
      "epoch:2 step:2159 [D loss: 0.727684, acc: 56.25%] [G loss: 1.941210]\n",
      "epoch:2 step:2160 [D loss: 0.692856, acc: 60.94%] [G loss: 1.901935]\n",
      "epoch:2 step:2161 [D loss: 0.511991, acc: 77.34%] [G loss: 2.336189]\n",
      "epoch:2 step:2162 [D loss: 0.583639, acc: 70.31%] [G loss: 2.097045]\n",
      "epoch:2 step:2163 [D loss: 0.638329, acc: 67.19%] [G loss: 2.270673]\n",
      "epoch:2 step:2164 [D loss: 0.781343, acc: 46.88%] [G loss: 1.958743]\n",
      "epoch:2 step:2165 [D loss: 0.684610, acc: 62.50%] [G loss: 1.815710]\n",
      "epoch:2 step:2166 [D loss: 0.588793, acc: 67.97%] [G loss: 2.109569]\n",
      "epoch:2 step:2167 [D loss: 0.743499, acc: 57.81%] [G loss: 1.690465]\n",
      "epoch:2 step:2168 [D loss: 0.714153, acc: 57.03%] [G loss: 2.005927]\n",
      "epoch:2 step:2169 [D loss: 0.716535, acc: 46.88%] [G loss: 1.735792]\n",
      "epoch:2 step:2170 [D loss: 0.707695, acc: 61.72%] [G loss: 1.865947]\n",
      "epoch:2 step:2171 [D loss: 0.799370, acc: 42.97%] [G loss: 1.894987]\n",
      "epoch:2 step:2172 [D loss: 0.578400, acc: 64.06%] [G loss: 1.980118]\n",
      "epoch:2 step:2173 [D loss: 0.583268, acc: 69.53%] [G loss: 1.956892]\n",
      "epoch:2 step:2174 [D loss: 0.690489, acc: 60.16%] [G loss: 1.859516]\n",
      "epoch:2 step:2175 [D loss: 0.895833, acc: 39.06%] [G loss: 1.677622]\n",
      "epoch:2 step:2176 [D loss: 0.709139, acc: 56.25%] [G loss: 1.649017]\n",
      "epoch:2 step:2177 [D loss: 0.671731, acc: 64.06%] [G loss: 1.929718]\n",
      "epoch:2 step:2178 [D loss: 0.617644, acc: 65.62%] [G loss: 1.950708]\n",
      "epoch:2 step:2179 [D loss: 0.866482, acc: 42.19%] [G loss: 1.683957]\n",
      "epoch:2 step:2180 [D loss: 0.892243, acc: 32.03%] [G loss: 1.589326]\n",
      "epoch:2 step:2181 [D loss: 0.639234, acc: 62.50%] [G loss: 1.910903]\n",
      "epoch:2 step:2182 [D loss: 0.666046, acc: 60.16%] [G loss: 1.929436]\n",
      "epoch:2 step:2183 [D loss: 0.635733, acc: 60.16%] [G loss: 1.930448]\n",
      "epoch:2 step:2184 [D loss: 0.738529, acc: 55.47%] [G loss: 1.930549]\n",
      "epoch:2 step:2185 [D loss: 0.669710, acc: 64.06%] [G loss: 2.087481]\n",
      "epoch:2 step:2186 [D loss: 0.628763, acc: 65.62%] [G loss: 1.946428]\n",
      "epoch:2 step:2187 [D loss: 0.735328, acc: 51.56%] [G loss: 1.810159]\n",
      "epoch:2 step:2188 [D loss: 0.899969, acc: 40.62%] [G loss: 1.753984]\n",
      "epoch:2 step:2189 [D loss: 0.682530, acc: 58.59%] [G loss: 1.852497]\n",
      "epoch:2 step:2190 [D loss: 0.783808, acc: 49.22%] [G loss: 1.843500]\n",
      "epoch:2 step:2191 [D loss: 0.723295, acc: 60.16%] [G loss: 2.238100]\n",
      "epoch:2 step:2192 [D loss: 0.614321, acc: 63.28%] [G loss: 1.875768]\n",
      "epoch:2 step:2193 [D loss: 0.828072, acc: 42.97%] [G loss: 1.833977]\n",
      "epoch:2 step:2194 [D loss: 0.920778, acc: 42.19%] [G loss: 1.679029]\n",
      "epoch:2 step:2195 [D loss: 0.761057, acc: 52.34%] [G loss: 1.907404]\n",
      "epoch:2 step:2196 [D loss: 0.626980, acc: 61.72%] [G loss: 1.988900]\n",
      "epoch:2 step:2197 [D loss: 0.652827, acc: 60.94%] [G loss: 1.695605]\n",
      "epoch:2 step:2198 [D loss: 0.621610, acc: 65.62%] [G loss: 1.918560]\n",
      "epoch:2 step:2199 [D loss: 0.784336, acc: 46.09%] [G loss: 1.959736]\n",
      "epoch:2 step:2200 [D loss: 0.701017, acc: 60.16%] [G loss: 2.246678]\n",
      "epoch:2 step:2201 [D loss: 0.675898, acc: 60.16%] [G loss: 1.690857]\n",
      "epoch:2 step:2202 [D loss: 0.739582, acc: 50.00%] [G loss: 2.209919]\n",
      "epoch:2 step:2203 [D loss: 0.705728, acc: 57.81%] [G loss: 2.153759]\n",
      "epoch:2 step:2204 [D loss: 0.893475, acc: 42.97%] [G loss: 1.847491]\n",
      "epoch:2 step:2205 [D loss: 0.638809, acc: 60.16%] [G loss: 2.123584]\n",
      "epoch:2 step:2206 [D loss: 0.684696, acc: 57.81%] [G loss: 2.028428]\n",
      "epoch:2 step:2207 [D loss: 0.885514, acc: 38.28%] [G loss: 1.644627]\n",
      "epoch:2 step:2208 [D loss: 0.753040, acc: 52.34%] [G loss: 1.789163]\n",
      "epoch:2 step:2209 [D loss: 0.715036, acc: 57.03%] [G loss: 1.934481]\n",
      "epoch:2 step:2210 [D loss: 0.782030, acc: 47.66%] [G loss: 1.979964]\n",
      "epoch:2 step:2211 [D loss: 0.725059, acc: 52.34%] [G loss: 2.128739]\n",
      "epoch:2 step:2212 [D loss: 0.709730, acc: 62.50%] [G loss: 1.899853]\n",
      "epoch:2 step:2213 [D loss: 0.734272, acc: 57.03%] [G loss: 1.897083]\n",
      "epoch:2 step:2214 [D loss: 0.772277, acc: 46.09%] [G loss: 1.693210]\n",
      "epoch:2 step:2215 [D loss: 0.680200, acc: 59.38%] [G loss: 2.168486]\n",
      "epoch:2 step:2216 [D loss: 0.732985, acc: 55.47%] [G loss: 1.729638]\n",
      "epoch:2 step:2217 [D loss: 0.597193, acc: 69.53%] [G loss: 1.862349]\n",
      "epoch:2 step:2218 [D loss: 0.940772, acc: 36.72%] [G loss: 1.526627]\n",
      "epoch:2 step:2219 [D loss: 0.724804, acc: 53.91%] [G loss: 1.756317]\n",
      "epoch:2 step:2220 [D loss: 0.709186, acc: 57.81%] [G loss: 2.086858]\n",
      "epoch:2 step:2221 [D loss: 0.535341, acc: 78.12%] [G loss: 2.140261]\n",
      "epoch:2 step:2222 [D loss: 0.613933, acc: 67.19%] [G loss: 1.889202]\n",
      "epoch:2 step:2223 [D loss: 0.683371, acc: 66.41%] [G loss: 2.111757]\n",
      "epoch:2 step:2224 [D loss: 0.670530, acc: 63.28%] [G loss: 1.868342]\n",
      "epoch:2 step:2225 [D loss: 0.599349, acc: 67.97%] [G loss: 2.248412]\n",
      "epoch:2 step:2226 [D loss: 0.652722, acc: 71.09%] [G loss: 2.120613]\n",
      "epoch:2 step:2227 [D loss: 0.607548, acc: 64.06%] [G loss: 2.257278]\n",
      "epoch:2 step:2228 [D loss: 0.619010, acc: 65.62%] [G loss: 2.008594]\n",
      "epoch:2 step:2229 [D loss: 0.868552, acc: 38.28%] [G loss: 2.085570]\n",
      "epoch:2 step:2230 [D loss: 0.669609, acc: 61.72%] [G loss: 2.363304]\n",
      "epoch:2 step:2231 [D loss: 0.687187, acc: 63.28%] [G loss: 2.377579]\n",
      "epoch:2 step:2232 [D loss: 0.932748, acc: 44.53%] [G loss: 1.632218]\n",
      "epoch:2 step:2233 [D loss: 0.841606, acc: 47.66%] [G loss: 1.687698]\n",
      "epoch:2 step:2234 [D loss: 0.734071, acc: 50.78%] [G loss: 2.023631]\n",
      "epoch:2 step:2235 [D loss: 0.715488, acc: 56.25%] [G loss: 2.008909]\n",
      "epoch:2 step:2236 [D loss: 0.715991, acc: 60.94%] [G loss: 2.084120]\n",
      "epoch:2 step:2237 [D loss: 0.594814, acc: 69.53%] [G loss: 2.166436]\n",
      "epoch:2 step:2238 [D loss: 0.776913, acc: 50.00%] [G loss: 1.930510]\n",
      "epoch:2 step:2239 [D loss: 0.776268, acc: 49.22%] [G loss: 1.822400]\n",
      "epoch:2 step:2240 [D loss: 0.698343, acc: 55.47%] [G loss: 1.783337]\n",
      "epoch:2 step:2241 [D loss: 0.845867, acc: 42.97%] [G loss: 1.550679]\n",
      "epoch:2 step:2242 [D loss: 0.739100, acc: 51.56%] [G loss: 1.699225]\n",
      "epoch:2 step:2243 [D loss: 0.701136, acc: 60.16%] [G loss: 1.845065]\n",
      "epoch:2 step:2244 [D loss: 0.813646, acc: 49.22%] [G loss: 1.931493]\n",
      "epoch:2 step:2245 [D loss: 0.646555, acc: 68.75%] [G loss: 1.913011]\n",
      "epoch:2 step:2246 [D loss: 0.761748, acc: 51.56%] [G loss: 1.676414]\n",
      "epoch:2 step:2247 [D loss: 0.606464, acc: 67.97%] [G loss: 2.123867]\n",
      "epoch:2 step:2248 [D loss: 0.827759, acc: 45.31%] [G loss: 1.785690]\n",
      "epoch:2 step:2249 [D loss: 0.617460, acc: 70.31%] [G loss: 1.908903]\n",
      "epoch:2 step:2250 [D loss: 0.750440, acc: 52.34%] [G loss: 1.670212]\n",
      "epoch:2 step:2251 [D loss: 0.896583, acc: 35.94%] [G loss: 1.683968]\n",
      "epoch:2 step:2252 [D loss: 0.684830, acc: 56.25%] [G loss: 1.896089]\n",
      "epoch:2 step:2253 [D loss: 0.789331, acc: 52.34%] [G loss: 1.869252]\n",
      "epoch:2 step:2254 [D loss: 0.802437, acc: 46.88%] [G loss: 1.657747]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2255 [D loss: 0.696886, acc: 56.25%] [G loss: 1.885298]\n",
      "epoch:2 step:2256 [D loss: 0.922771, acc: 37.50%] [G loss: 1.596124]\n",
      "epoch:2 step:2257 [D loss: 0.715226, acc: 57.81%] [G loss: 1.932144]\n",
      "epoch:2 step:2258 [D loss: 0.748242, acc: 45.31%] [G loss: 1.757465]\n",
      "epoch:2 step:2259 [D loss: 0.726331, acc: 47.66%] [G loss: 1.659098]\n",
      "epoch:2 step:2260 [D loss: 0.730654, acc: 53.91%] [G loss: 1.947443]\n",
      "epoch:2 step:2261 [D loss: 0.642742, acc: 67.19%] [G loss: 2.192887]\n",
      "epoch:2 step:2262 [D loss: 0.663370, acc: 61.72%] [G loss: 1.915387]\n",
      "epoch:2 step:2263 [D loss: 0.669505, acc: 60.94%] [G loss: 1.720595]\n",
      "epoch:2 step:2264 [D loss: 0.648342, acc: 65.62%] [G loss: 1.780974]\n",
      "epoch:2 step:2265 [D loss: 0.631190, acc: 64.84%] [G loss: 1.916208]\n",
      "epoch:2 step:2266 [D loss: 0.857289, acc: 42.19%] [G loss: 1.709946]\n",
      "epoch:2 step:2267 [D loss: 0.733746, acc: 53.12%] [G loss: 1.781200]\n",
      "epoch:2 step:2268 [D loss: 0.738124, acc: 53.12%] [G loss: 1.694328]\n",
      "epoch:2 step:2269 [D loss: 0.750871, acc: 50.00%] [G loss: 1.693808]\n",
      "epoch:2 step:2270 [D loss: 0.758985, acc: 53.91%] [G loss: 1.818879]\n",
      "epoch:2 step:2271 [D loss: 0.804211, acc: 42.97%] [G loss: 1.501700]\n",
      "epoch:2 step:2272 [D loss: 0.724254, acc: 49.22%] [G loss: 1.876991]\n",
      "epoch:2 step:2273 [D loss: 0.649823, acc: 64.06%] [G loss: 1.876141]\n",
      "epoch:2 step:2274 [D loss: 0.758893, acc: 46.09%] [G loss: 1.666234]\n",
      "epoch:2 step:2275 [D loss: 0.714468, acc: 50.00%] [G loss: 1.875416]\n",
      "epoch:2 step:2276 [D loss: 0.650619, acc: 64.06%] [G loss: 1.837607]\n",
      "epoch:2 step:2277 [D loss: 0.675136, acc: 58.59%] [G loss: 2.001976]\n",
      "epoch:2 step:2278 [D loss: 0.675023, acc: 58.59%] [G loss: 1.806455]\n",
      "epoch:2 step:2279 [D loss: 0.632824, acc: 62.50%] [G loss: 1.938488]\n",
      "epoch:2 step:2280 [D loss: 0.647939, acc: 69.53%] [G loss: 1.694401]\n",
      "epoch:2 step:2281 [D loss: 0.477502, acc: 86.72%] [G loss: 2.114841]\n",
      "epoch:2 step:2282 [D loss: 0.716657, acc: 57.03%] [G loss: 1.750422]\n",
      "epoch:2 step:2283 [D loss: 0.780422, acc: 55.47%] [G loss: 1.592093]\n",
      "epoch:2 step:2284 [D loss: 0.750312, acc: 53.12%] [G loss: 1.930956]\n",
      "epoch:2 step:2285 [D loss: 0.826929, acc: 44.53%] [G loss: 1.603114]\n",
      "epoch:2 step:2286 [D loss: 0.730113, acc: 53.12%] [G loss: 1.739222]\n",
      "epoch:2 step:2287 [D loss: 0.638501, acc: 65.62%] [G loss: 2.068121]\n",
      "epoch:2 step:2288 [D loss: 0.704266, acc: 57.81%] [G loss: 1.770844]\n",
      "epoch:2 step:2289 [D loss: 0.685428, acc: 52.34%] [G loss: 1.792851]\n",
      "epoch:2 step:2290 [D loss: 0.676591, acc: 69.53%] [G loss: 1.691128]\n",
      "epoch:2 step:2291 [D loss: 0.712248, acc: 45.31%] [G loss: 1.998035]\n",
      "epoch:2 step:2292 [D loss: 0.621980, acc: 63.28%] [G loss: 1.880903]\n",
      "epoch:2 step:2293 [D loss: 0.588703, acc: 72.66%] [G loss: 1.996456]\n",
      "epoch:2 step:2294 [D loss: 0.895566, acc: 39.84%] [G loss: 1.713616]\n",
      "epoch:2 step:2295 [D loss: 0.619136, acc: 69.53%] [G loss: 1.831809]\n",
      "epoch:2 step:2296 [D loss: 0.877920, acc: 34.38%] [G loss: 1.598259]\n",
      "epoch:2 step:2297 [D loss: 0.654327, acc: 59.38%] [G loss: 1.930959]\n",
      "epoch:2 step:2298 [D loss: 0.703396, acc: 56.25%] [G loss: 1.771629]\n",
      "epoch:2 step:2299 [D loss: 0.877693, acc: 41.41%] [G loss: 1.686266]\n",
      "epoch:2 step:2300 [D loss: 0.747505, acc: 51.56%] [G loss: 1.721558]\n",
      "epoch:2 step:2301 [D loss: 0.678513, acc: 55.47%] [G loss: 1.863458]\n",
      "epoch:2 step:2302 [D loss: 0.762902, acc: 53.91%] [G loss: 1.519481]\n",
      "epoch:2 step:2303 [D loss: 0.794686, acc: 46.88%] [G loss: 1.996654]\n",
      "epoch:2 step:2304 [D loss: 0.780204, acc: 46.09%] [G loss: 1.841401]\n",
      "epoch:2 step:2305 [D loss: 0.818303, acc: 39.06%] [G loss: 1.771214]\n",
      "epoch:2 step:2306 [D loss: 0.856369, acc: 41.41%] [G loss: 1.659583]\n",
      "epoch:2 step:2307 [D loss: 0.722463, acc: 56.25%] [G loss: 1.924524]\n",
      "epoch:2 step:2308 [D loss: 0.779925, acc: 50.78%] [G loss: 1.826776]\n",
      "epoch:2 step:2309 [D loss: 0.710113, acc: 57.81%] [G loss: 1.999375]\n",
      "epoch:2 step:2310 [D loss: 0.664336, acc: 64.06%] [G loss: 1.928195]\n",
      "epoch:2 step:2311 [D loss: 0.631635, acc: 69.53%] [G loss: 2.244403]\n",
      "epoch:2 step:2312 [D loss: 0.788949, acc: 45.31%] [G loss: 1.925765]\n",
      "epoch:2 step:2313 [D loss: 0.742355, acc: 52.34%] [G loss: 1.807832]\n",
      "epoch:2 step:2314 [D loss: 0.576240, acc: 73.44%] [G loss: 1.980137]\n",
      "epoch:2 step:2315 [D loss: 0.727790, acc: 57.81%] [G loss: 1.881039]\n",
      "epoch:2 step:2316 [D loss: 0.832530, acc: 42.19%] [G loss: 1.683488]\n",
      "epoch:2 step:2317 [D loss: 0.643745, acc: 62.50%] [G loss: 2.015637]\n",
      "epoch:2 step:2318 [D loss: 0.597147, acc: 67.19%] [G loss: 2.055995]\n",
      "epoch:2 step:2319 [D loss: 0.714126, acc: 58.59%] [G loss: 1.815174]\n",
      "epoch:2 step:2320 [D loss: 0.744606, acc: 51.56%] [G loss: 1.657083]\n",
      "epoch:2 step:2321 [D loss: 0.876651, acc: 34.38%] [G loss: 1.519635]\n",
      "epoch:2 step:2322 [D loss: 0.820457, acc: 50.78%] [G loss: 1.707059]\n",
      "epoch:2 step:2323 [D loss: 0.777147, acc: 50.00%] [G loss: 1.873421]\n",
      "epoch:2 step:2324 [D loss: 0.720126, acc: 55.47%] [G loss: 1.859989]\n",
      "epoch:2 step:2325 [D loss: 0.801547, acc: 39.06%] [G loss: 1.728804]\n",
      "epoch:2 step:2326 [D loss: 0.652442, acc: 64.06%] [G loss: 1.874767]\n",
      "epoch:2 step:2327 [D loss: 0.773321, acc: 42.19%] [G loss: 1.693762]\n",
      "epoch:2 step:2328 [D loss: 0.633040, acc: 60.94%] [G loss: 1.915013]\n",
      "epoch:2 step:2329 [D loss: 0.763173, acc: 52.34%] [G loss: 1.698456]\n",
      "epoch:2 step:2330 [D loss: 0.746521, acc: 50.78%] [G loss: 1.753101]\n",
      "epoch:2 step:2331 [D loss: 0.868744, acc: 37.50%] [G loss: 1.752958]\n",
      "epoch:2 step:2332 [D loss: 0.751756, acc: 49.22%] [G loss: 1.638242]\n",
      "epoch:2 step:2333 [D loss: 0.733350, acc: 51.56%] [G loss: 1.856601]\n",
      "epoch:2 step:2334 [D loss: 0.773485, acc: 44.53%] [G loss: 1.773211]\n",
      "epoch:2 step:2335 [D loss: 0.754312, acc: 50.00%] [G loss: 1.771750]\n",
      "epoch:2 step:2336 [D loss: 0.701578, acc: 57.03%] [G loss: 1.669647]\n",
      "epoch:2 step:2337 [D loss: 0.686013, acc: 60.94%] [G loss: 1.858136]\n",
      "epoch:2 step:2338 [D loss: 0.739289, acc: 52.34%] [G loss: 1.846810]\n",
      "epoch:2 step:2339 [D loss: 0.748432, acc: 53.12%] [G loss: 1.840062]\n",
      "epoch:2 step:2340 [D loss: 0.591863, acc: 67.97%] [G loss: 2.024934]\n",
      "epoch:2 step:2341 [D loss: 0.777976, acc: 47.66%] [G loss: 1.543313]\n",
      "epoch:2 step:2342 [D loss: 0.669723, acc: 60.16%] [G loss: 1.873404]\n",
      "epoch:2 step:2343 [D loss: 0.596088, acc: 66.41%] [G loss: 1.910757]\n",
      "epoch:3 step:2344 [D loss: 0.609087, acc: 69.53%] [G loss: 1.847233]\n",
      "epoch:3 step:2345 [D loss: 0.671871, acc: 63.28%] [G loss: 1.682879]\n",
      "epoch:3 step:2346 [D loss: 0.560400, acc: 71.88%] [G loss: 1.733991]\n",
      "epoch:3 step:2347 [D loss: 0.696963, acc: 60.94%] [G loss: 1.816189]\n",
      "epoch:3 step:2348 [D loss: 0.784294, acc: 49.22%] [G loss: 1.580439]\n",
      "epoch:3 step:2349 [D loss: 0.725424, acc: 50.00%] [G loss: 1.657432]\n",
      "epoch:3 step:2350 [D loss: 0.817696, acc: 44.53%] [G loss: 1.665010]\n",
      "epoch:3 step:2351 [D loss: 0.653410, acc: 62.50%] [G loss: 1.793645]\n",
      "epoch:3 step:2352 [D loss: 0.824724, acc: 39.06%] [G loss: 1.667289]\n",
      "epoch:3 step:2353 [D loss: 0.832861, acc: 41.41%] [G loss: 1.704025]\n",
      "epoch:3 step:2354 [D loss: 0.637331, acc: 64.06%] [G loss: 1.783415]\n",
      "epoch:3 step:2355 [D loss: 0.705828, acc: 57.81%] [G loss: 1.536366]\n",
      "epoch:3 step:2356 [D loss: 0.661997, acc: 61.72%] [G loss: 1.805074]\n",
      "epoch:3 step:2357 [D loss: 0.913991, acc: 32.03%] [G loss: 1.618894]\n",
      "epoch:3 step:2358 [D loss: 0.685405, acc: 57.03%] [G loss: 1.733691]\n",
      "epoch:3 step:2359 [D loss: 0.763480, acc: 46.88%] [G loss: 1.479100]\n",
      "epoch:3 step:2360 [D loss: 0.698463, acc: 54.69%] [G loss: 1.576890]\n",
      "epoch:3 step:2361 [D loss: 0.753431, acc: 46.88%] [G loss: 1.860840]\n",
      "epoch:3 step:2362 [D loss: 0.752061, acc: 57.81%] [G loss: 1.678188]\n",
      "epoch:3 step:2363 [D loss: 0.705162, acc: 60.94%] [G loss: 1.792276]\n",
      "epoch:3 step:2364 [D loss: 0.683040, acc: 58.59%] [G loss: 1.713074]\n",
      "epoch:3 step:2365 [D loss: 0.732080, acc: 53.91%] [G loss: 1.841787]\n",
      "epoch:3 step:2366 [D loss: 0.692019, acc: 56.25%] [G loss: 1.755942]\n",
      "epoch:3 step:2367 [D loss: 0.705746, acc: 58.59%] [G loss: 1.665600]\n",
      "epoch:3 step:2368 [D loss: 0.864686, acc: 29.69%] [G loss: 1.755965]\n",
      "epoch:3 step:2369 [D loss: 0.827530, acc: 37.50%] [G loss: 1.629552]\n",
      "epoch:3 step:2370 [D loss: 0.786540, acc: 44.53%] [G loss: 1.698663]\n",
      "epoch:3 step:2371 [D loss: 0.732463, acc: 49.22%] [G loss: 1.758497]\n",
      "epoch:3 step:2372 [D loss: 0.637078, acc: 66.41%] [G loss: 1.796035]\n",
      "epoch:3 step:2373 [D loss: 0.730634, acc: 46.88%] [G loss: 1.966806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2374 [D loss: 0.791418, acc: 45.31%] [G loss: 1.575663]\n",
      "epoch:3 step:2375 [D loss: 0.677819, acc: 57.03%] [G loss: 1.801640]\n",
      "epoch:3 step:2376 [D loss: 0.705990, acc: 57.81%] [G loss: 1.853067]\n",
      "epoch:3 step:2377 [D loss: 0.669029, acc: 58.59%] [G loss: 1.816621]\n",
      "epoch:3 step:2378 [D loss: 0.710774, acc: 48.44%] [G loss: 1.767118]\n",
      "epoch:3 step:2379 [D loss: 0.609775, acc: 65.62%] [G loss: 2.324003]\n",
      "epoch:3 step:2380 [D loss: 0.560753, acc: 73.44%] [G loss: 2.051232]\n",
      "epoch:3 step:2381 [D loss: 0.734786, acc: 56.25%] [G loss: 1.976938]\n",
      "epoch:3 step:2382 [D loss: 0.520374, acc: 77.34%] [G loss: 2.171713]\n",
      "epoch:3 step:2383 [D loss: 0.640998, acc: 63.28%] [G loss: 1.887638]\n",
      "epoch:3 step:2384 [D loss: 0.638338, acc: 62.50%] [G loss: 1.810298]\n",
      "epoch:3 step:2385 [D loss: 0.664868, acc: 61.72%] [G loss: 1.873931]\n",
      "epoch:3 step:2386 [D loss: 0.559413, acc: 75.00%] [G loss: 1.851566]\n",
      "epoch:3 step:2387 [D loss: 0.611867, acc: 67.97%] [G loss: 2.157938]\n",
      "epoch:3 step:2388 [D loss: 0.615341, acc: 63.28%] [G loss: 1.888167]\n",
      "epoch:3 step:2389 [D loss: 0.572420, acc: 68.75%] [G loss: 1.895071]\n",
      "epoch:3 step:2390 [D loss: 0.563570, acc: 72.66%] [G loss: 1.920252]\n",
      "epoch:3 step:2391 [D loss: 0.382342, acc: 86.72%] [G loss: 2.063565]\n",
      "epoch:3 step:2392 [D loss: 0.608063, acc: 61.72%] [G loss: 1.829005]\n",
      "epoch:3 step:2393 [D loss: 0.494745, acc: 78.12%] [G loss: 1.958165]\n",
      "epoch:3 step:2394 [D loss: 0.525472, acc: 72.66%] [G loss: 1.926096]\n",
      "epoch:3 step:2395 [D loss: 0.594045, acc: 67.97%] [G loss: 1.740244]\n",
      "epoch:3 step:2396 [D loss: 0.736844, acc: 51.56%] [G loss: 1.804353]\n",
      "epoch:3 step:2397 [D loss: 0.524831, acc: 74.22%] [G loss: 2.086182]\n",
      "epoch:3 step:2398 [D loss: 0.660005, acc: 63.28%] [G loss: 2.088043]\n",
      "epoch:3 step:2399 [D loss: 1.024732, acc: 38.28%] [G loss: 1.672012]\n",
      "epoch:3 step:2400 [D loss: 0.739938, acc: 53.12%] [G loss: 2.462735]\n",
      "epoch:3 step:2401 [D loss: 0.723861, acc: 56.25%] [G loss: 2.127812]\n",
      "epoch:3 step:2402 [D loss: 0.559115, acc: 71.88%] [G loss: 2.038568]\n",
      "epoch:3 step:2403 [D loss: 0.844659, acc: 45.31%] [G loss: 1.846059]\n",
      "epoch:3 step:2404 [D loss: 0.711787, acc: 56.25%] [G loss: 1.928699]\n",
      "epoch:3 step:2405 [D loss: 0.647360, acc: 64.06%] [G loss: 1.737696]\n",
      "epoch:3 step:2406 [D loss: 0.732690, acc: 57.81%] [G loss: 1.813419]\n",
      "epoch:3 step:2407 [D loss: 0.718312, acc: 52.34%] [G loss: 2.046940]\n",
      "epoch:3 step:2408 [D loss: 0.669563, acc: 58.59%] [G loss: 1.911016]\n",
      "epoch:3 step:2409 [D loss: 0.809015, acc: 46.09%] [G loss: 1.635531]\n",
      "epoch:3 step:2410 [D loss: 1.015991, acc: 35.94%] [G loss: 1.468178]\n",
      "epoch:3 step:2411 [D loss: 0.876155, acc: 42.97%] [G loss: 1.810181]\n",
      "epoch:3 step:2412 [D loss: 0.753958, acc: 51.56%] [G loss: 1.706028]\n",
      "epoch:3 step:2413 [D loss: 0.906775, acc: 40.62%] [G loss: 1.661915]\n",
      "epoch:3 step:2414 [D loss: 0.831265, acc: 42.97%] [G loss: 1.787739]\n",
      "epoch:3 step:2415 [D loss: 0.769964, acc: 46.88%] [G loss: 1.970225]\n",
      "epoch:3 step:2416 [D loss: 0.747671, acc: 48.44%] [G loss: 1.822815]\n",
      "epoch:3 step:2417 [D loss: 0.644326, acc: 67.97%] [G loss: 1.859443]\n",
      "epoch:3 step:2418 [D loss: 0.723425, acc: 59.38%] [G loss: 2.071810]\n",
      "epoch:3 step:2419 [D loss: 0.820921, acc: 47.66%] [G loss: 1.638376]\n",
      "epoch:3 step:2420 [D loss: 0.823640, acc: 42.97%] [G loss: 1.678320]\n",
      "epoch:3 step:2421 [D loss: 0.711838, acc: 46.88%] [G loss: 1.791959]\n",
      "epoch:3 step:2422 [D loss: 0.713192, acc: 57.03%] [G loss: 1.736021]\n",
      "epoch:3 step:2423 [D loss: 0.611033, acc: 67.19%] [G loss: 2.045264]\n",
      "epoch:3 step:2424 [D loss: 0.682498, acc: 55.47%] [G loss: 1.715395]\n",
      "epoch:3 step:2425 [D loss: 0.677525, acc: 60.94%] [G loss: 1.673343]\n",
      "epoch:3 step:2426 [D loss: 0.697121, acc: 59.38%] [G loss: 1.842490]\n",
      "epoch:3 step:2427 [D loss: 0.776611, acc: 48.44%] [G loss: 1.761759]\n",
      "epoch:3 step:2428 [D loss: 0.704215, acc: 52.34%] [G loss: 1.857429]\n",
      "epoch:3 step:2429 [D loss: 0.653682, acc: 59.38%] [G loss: 1.529028]\n",
      "epoch:3 step:2430 [D loss: 0.737725, acc: 60.16%] [G loss: 1.741561]\n",
      "epoch:3 step:2431 [D loss: 0.909606, acc: 35.16%] [G loss: 1.496592]\n",
      "epoch:3 step:2432 [D loss: 0.757921, acc: 44.53%] [G loss: 1.562640]\n",
      "epoch:3 step:2433 [D loss: 0.761348, acc: 53.91%] [G loss: 1.753253]\n",
      "epoch:3 step:2434 [D loss: 0.737419, acc: 49.22%] [G loss: 1.616677]\n",
      "epoch:3 step:2435 [D loss: 0.615616, acc: 69.53%] [G loss: 1.493599]\n",
      "epoch:3 step:2436 [D loss: 0.718453, acc: 53.91%] [G loss: 1.670167]\n",
      "epoch:3 step:2437 [D loss: 1.105558, acc: 21.09%] [G loss: 1.329537]\n",
      "epoch:3 step:2438 [D loss: 0.737367, acc: 46.09%] [G loss: 1.480724]\n",
      "epoch:3 step:2439 [D loss: 0.691797, acc: 62.50%] [G loss: 1.514482]\n",
      "epoch:3 step:2440 [D loss: 0.811553, acc: 36.72%] [G loss: 1.468145]\n",
      "epoch:3 step:2441 [D loss: 0.749300, acc: 50.00%] [G loss: 1.462667]\n",
      "epoch:3 step:2442 [D loss: 0.759337, acc: 53.12%] [G loss: 1.727808]\n",
      "epoch:3 step:2443 [D loss: 0.770501, acc: 44.53%] [G loss: 1.611533]\n",
      "epoch:3 step:2444 [D loss: 0.844760, acc: 40.62%] [G loss: 1.532184]\n",
      "epoch:3 step:2445 [D loss: 0.617266, acc: 62.50%] [G loss: 1.809587]\n",
      "epoch:3 step:2446 [D loss: 0.617209, acc: 69.53%] [G loss: 1.766754]\n",
      "epoch:3 step:2447 [D loss: 0.824360, acc: 41.41%] [G loss: 1.414918]\n",
      "epoch:3 step:2448 [D loss: 0.859534, acc: 40.62%] [G loss: 1.609659]\n",
      "epoch:3 step:2449 [D loss: 0.748124, acc: 50.78%] [G loss: 1.767266]\n",
      "epoch:3 step:2450 [D loss: 0.744627, acc: 52.34%] [G loss: 1.627857]\n",
      "epoch:3 step:2451 [D loss: 0.591750, acc: 70.31%] [G loss: 1.741764]\n",
      "epoch:3 step:2452 [D loss: 0.682139, acc: 60.94%] [G loss: 1.653147]\n",
      "epoch:3 step:2453 [D loss: 0.786049, acc: 49.22%] [G loss: 1.610138]\n",
      "epoch:3 step:2454 [D loss: 0.600827, acc: 65.62%] [G loss: 1.783476]\n",
      "epoch:3 step:2455 [D loss: 0.729985, acc: 57.81%] [G loss: 1.743657]\n",
      "epoch:3 step:2456 [D loss: 0.819491, acc: 42.19%] [G loss: 1.574548]\n",
      "epoch:3 step:2457 [D loss: 0.797328, acc: 41.41%] [G loss: 1.586810]\n",
      "epoch:3 step:2458 [D loss: 0.753375, acc: 53.12%] [G loss: 1.886454]\n",
      "epoch:3 step:2459 [D loss: 0.697357, acc: 60.16%] [G loss: 1.751590]\n",
      "epoch:3 step:2460 [D loss: 0.884343, acc: 33.59%] [G loss: 1.514840]\n",
      "epoch:3 step:2461 [D loss: 0.707962, acc: 56.25%] [G loss: 1.908682]\n",
      "epoch:3 step:2462 [D loss: 0.792232, acc: 42.97%] [G loss: 1.626906]\n",
      "epoch:3 step:2463 [D loss: 0.654775, acc: 60.94%] [G loss: 1.892787]\n",
      "epoch:3 step:2464 [D loss: 0.561603, acc: 71.09%] [G loss: 2.064822]\n",
      "epoch:3 step:2465 [D loss: 0.642887, acc: 67.19%] [G loss: 1.841380]\n",
      "epoch:3 step:2466 [D loss: 0.633632, acc: 62.50%] [G loss: 1.892204]\n",
      "epoch:3 step:2467 [D loss: 0.669138, acc: 56.25%] [G loss: 1.853886]\n",
      "epoch:3 step:2468 [D loss: 0.645477, acc: 61.72%] [G loss: 1.716718]\n",
      "epoch:3 step:2469 [D loss: 0.755629, acc: 48.44%] [G loss: 1.706760]\n",
      "epoch:3 step:2470 [D loss: 0.679181, acc: 60.94%] [G loss: 1.593949]\n",
      "epoch:3 step:2471 [D loss: 0.730721, acc: 52.34%] [G loss: 1.905704]\n",
      "epoch:3 step:2472 [D loss: 0.849433, acc: 44.53%] [G loss: 1.743903]\n",
      "epoch:3 step:2473 [D loss: 0.738079, acc: 49.22%] [G loss: 1.513615]\n",
      "epoch:3 step:2474 [D loss: 0.715105, acc: 52.34%] [G loss: 1.651036]\n",
      "epoch:3 step:2475 [D loss: 0.772460, acc: 53.91%] [G loss: 1.557974]\n",
      "epoch:3 step:2476 [D loss: 0.722630, acc: 53.91%] [G loss: 1.413170]\n",
      "epoch:3 step:2477 [D loss: 0.740693, acc: 50.78%] [G loss: 1.681070]\n",
      "epoch:3 step:2478 [D loss: 0.732405, acc: 54.69%] [G loss: 1.648325]\n",
      "epoch:3 step:2479 [D loss: 0.664816, acc: 62.50%] [G loss: 1.795455]\n",
      "epoch:3 step:2480 [D loss: 0.774844, acc: 44.53%] [G loss: 1.521432]\n",
      "epoch:3 step:2481 [D loss: 0.640235, acc: 71.09%] [G loss: 1.618675]\n",
      "epoch:3 step:2482 [D loss: 0.697501, acc: 56.25%] [G loss: 1.538327]\n",
      "epoch:3 step:2483 [D loss: 0.772075, acc: 48.44%] [G loss: 1.554237]\n",
      "epoch:3 step:2484 [D loss: 0.610895, acc: 65.62%] [G loss: 1.698439]\n",
      "epoch:3 step:2485 [D loss: 0.771025, acc: 50.78%] [G loss: 1.554978]\n",
      "epoch:3 step:2486 [D loss: 0.873373, acc: 37.50%] [G loss: 1.619306]\n",
      "epoch:3 step:2487 [D loss: 0.747336, acc: 49.22%] [G loss: 1.492612]\n",
      "epoch:3 step:2488 [D loss: 0.704366, acc: 55.47%] [G loss: 1.693726]\n",
      "epoch:3 step:2489 [D loss: 0.593895, acc: 70.31%] [G loss: 1.910457]\n",
      "epoch:3 step:2490 [D loss: 0.704867, acc: 61.72%] [G loss: 1.598248]\n",
      "epoch:3 step:2491 [D loss: 0.728112, acc: 49.22%] [G loss: 1.537108]\n",
      "epoch:3 step:2492 [D loss: 0.650679, acc: 64.06%] [G loss: 1.612307]\n",
      "epoch:3 step:2493 [D loss: 0.638230, acc: 64.84%] [G loss: 1.583004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2494 [D loss: 0.638685, acc: 68.75%] [G loss: 1.720450]\n",
      "epoch:3 step:2495 [D loss: 0.731099, acc: 55.47%] [G loss: 1.710160]\n",
      "epoch:3 step:2496 [D loss: 0.827323, acc: 40.62%] [G loss: 1.508269]\n",
      "epoch:3 step:2497 [D loss: 0.765178, acc: 47.66%] [G loss: 1.538895]\n",
      "epoch:3 step:2498 [D loss: 0.713327, acc: 51.56%] [G loss: 1.632168]\n",
      "epoch:3 step:2499 [D loss: 0.835766, acc: 39.84%] [G loss: 1.654381]\n",
      "epoch:3 step:2500 [D loss: 0.845456, acc: 39.06%] [G loss: 1.514583]\n",
      "epoch:3 step:2501 [D loss: 0.890860, acc: 39.06%] [G loss: 1.713381]\n",
      "epoch:3 step:2502 [D loss: 0.779051, acc: 48.44%] [G loss: 1.662686]\n",
      "epoch:3 step:2503 [D loss: 0.775919, acc: 48.44%] [G loss: 1.512012]\n",
      "epoch:3 step:2504 [D loss: 0.714731, acc: 53.12%] [G loss: 1.985253]\n",
      "epoch:3 step:2505 [D loss: 0.705620, acc: 52.34%] [G loss: 1.681502]\n",
      "epoch:3 step:2506 [D loss: 0.699973, acc: 48.44%] [G loss: 1.641379]\n",
      "epoch:3 step:2507 [D loss: 0.709615, acc: 55.47%] [G loss: 1.762171]\n",
      "epoch:3 step:2508 [D loss: 0.717125, acc: 54.69%] [G loss: 1.772222]\n",
      "epoch:3 step:2509 [D loss: 0.734636, acc: 51.56%] [G loss: 1.747481]\n",
      "epoch:3 step:2510 [D loss: 0.657389, acc: 65.62%] [G loss: 1.830160]\n",
      "epoch:3 step:2511 [D loss: 0.690784, acc: 57.81%] [G loss: 1.945956]\n",
      "epoch:3 step:2512 [D loss: 0.690606, acc: 55.47%] [G loss: 1.803212]\n",
      "epoch:3 step:2513 [D loss: 0.726479, acc: 57.81%] [G loss: 1.832998]\n",
      "epoch:3 step:2514 [D loss: 0.645919, acc: 64.84%] [G loss: 1.867160]\n",
      "epoch:3 step:2515 [D loss: 0.636757, acc: 65.62%] [G loss: 1.738329]\n",
      "epoch:3 step:2516 [D loss: 0.778528, acc: 46.88%] [G loss: 1.558372]\n",
      "epoch:3 step:2517 [D loss: 0.667805, acc: 63.28%] [G loss: 1.776207]\n",
      "epoch:3 step:2518 [D loss: 0.726559, acc: 54.69%] [G loss: 1.695715]\n",
      "epoch:3 step:2519 [D loss: 0.797401, acc: 45.31%] [G loss: 1.552195]\n",
      "epoch:3 step:2520 [D loss: 0.776213, acc: 39.06%] [G loss: 1.683236]\n",
      "epoch:3 step:2521 [D loss: 0.755101, acc: 48.44%] [G loss: 1.706762]\n",
      "epoch:3 step:2522 [D loss: 0.743623, acc: 49.22%] [G loss: 1.561843]\n",
      "epoch:3 step:2523 [D loss: 0.769203, acc: 45.31%] [G loss: 1.646560]\n",
      "epoch:3 step:2524 [D loss: 0.762989, acc: 46.88%] [G loss: 1.683861]\n",
      "epoch:3 step:2525 [D loss: 0.698021, acc: 58.59%] [G loss: 1.685898]\n",
      "epoch:3 step:2526 [D loss: 0.827629, acc: 41.41%] [G loss: 1.612946]\n",
      "epoch:3 step:2527 [D loss: 0.837577, acc: 38.28%] [G loss: 1.575546]\n",
      "epoch:3 step:2528 [D loss: 0.876981, acc: 29.69%] [G loss: 1.594517]\n",
      "epoch:3 step:2529 [D loss: 0.762585, acc: 40.62%] [G loss: 1.587631]\n",
      "epoch:3 step:2530 [D loss: 0.773675, acc: 49.22%] [G loss: 1.647169]\n",
      "epoch:3 step:2531 [D loss: 0.670429, acc: 58.59%] [G loss: 1.658457]\n",
      "epoch:3 step:2532 [D loss: 0.622722, acc: 68.75%] [G loss: 1.649681]\n",
      "epoch:3 step:2533 [D loss: 0.670481, acc: 55.47%] [G loss: 1.833481]\n",
      "epoch:3 step:2534 [D loss: 0.652875, acc: 62.50%] [G loss: 1.678156]\n",
      "epoch:3 step:2535 [D loss: 0.752197, acc: 45.31%] [G loss: 1.586169]\n",
      "epoch:3 step:2536 [D loss: 0.628615, acc: 64.06%] [G loss: 1.710958]\n",
      "epoch:3 step:2537 [D loss: 0.729368, acc: 50.00%] [G loss: 1.601329]\n",
      "epoch:3 step:2538 [D loss: 0.693111, acc: 55.47%] [G loss: 1.492795]\n",
      "epoch:3 step:2539 [D loss: 0.759024, acc: 43.75%] [G loss: 1.530198]\n",
      "epoch:3 step:2540 [D loss: 0.732600, acc: 52.34%] [G loss: 1.839432]\n",
      "epoch:3 step:2541 [D loss: 0.611411, acc: 64.84%] [G loss: 1.865065]\n",
      "epoch:3 step:2542 [D loss: 0.772491, acc: 50.00%] [G loss: 1.772041]\n",
      "epoch:3 step:2543 [D loss: 0.697930, acc: 54.69%] [G loss: 1.777567]\n",
      "epoch:3 step:2544 [D loss: 0.718417, acc: 58.59%] [G loss: 1.749792]\n",
      "epoch:3 step:2545 [D loss: 0.761728, acc: 50.00%] [G loss: 1.661497]\n",
      "epoch:3 step:2546 [D loss: 0.673448, acc: 58.59%] [G loss: 1.791832]\n",
      "epoch:3 step:2547 [D loss: 0.610447, acc: 67.19%] [G loss: 1.834507]\n",
      "epoch:3 step:2548 [D loss: 0.825797, acc: 42.97%] [G loss: 1.530700]\n",
      "epoch:3 step:2549 [D loss: 0.777922, acc: 44.53%] [G loss: 1.728318]\n",
      "epoch:3 step:2550 [D loss: 0.729737, acc: 47.66%] [G loss: 1.724186]\n",
      "epoch:3 step:2551 [D loss: 0.736851, acc: 49.22%] [G loss: 1.728108]\n",
      "epoch:3 step:2552 [D loss: 0.727455, acc: 53.12%] [G loss: 1.718031]\n",
      "epoch:3 step:2553 [D loss: 0.725091, acc: 57.81%] [G loss: 1.889020]\n",
      "epoch:3 step:2554 [D loss: 0.656406, acc: 66.41%] [G loss: 1.759273]\n",
      "epoch:3 step:2555 [D loss: 0.726376, acc: 52.34%] [G loss: 1.801045]\n",
      "epoch:3 step:2556 [D loss: 0.760668, acc: 50.78%] [G loss: 1.688497]\n",
      "epoch:3 step:2557 [D loss: 0.747563, acc: 50.00%] [G loss: 1.778605]\n",
      "epoch:3 step:2558 [D loss: 0.718528, acc: 51.56%] [G loss: 1.729982]\n",
      "epoch:3 step:2559 [D loss: 0.751419, acc: 50.00%] [G loss: 1.652825]\n",
      "epoch:3 step:2560 [D loss: 0.731269, acc: 48.44%] [G loss: 1.638766]\n",
      "epoch:3 step:2561 [D loss: 0.680451, acc: 60.16%] [G loss: 1.723514]\n",
      "epoch:3 step:2562 [D loss: 0.644958, acc: 67.19%] [G loss: 1.721931]\n",
      "epoch:3 step:2563 [D loss: 0.787398, acc: 41.41%] [G loss: 1.604517]\n",
      "epoch:3 step:2564 [D loss: 0.723641, acc: 53.12%] [G loss: 1.665782]\n",
      "epoch:3 step:2565 [D loss: 0.787153, acc: 41.41%] [G loss: 1.421116]\n",
      "epoch:3 step:2566 [D loss: 0.572460, acc: 76.56%] [G loss: 1.679453]\n",
      "epoch:3 step:2567 [D loss: 0.654525, acc: 57.03%] [G loss: 1.604160]\n",
      "epoch:3 step:2568 [D loss: 0.717685, acc: 54.69%] [G loss: 1.521000]\n",
      "epoch:3 step:2569 [D loss: 0.780457, acc: 46.88%] [G loss: 1.339170]\n",
      "epoch:3 step:2570 [D loss: 0.624193, acc: 66.41%] [G loss: 1.656246]\n",
      "epoch:3 step:2571 [D loss: 0.708700, acc: 51.56%] [G loss: 1.633844]\n",
      "epoch:3 step:2572 [D loss: 0.657739, acc: 63.28%] [G loss: 1.608033]\n",
      "epoch:3 step:2573 [D loss: 0.862602, acc: 31.25%] [G loss: 1.438067]\n",
      "epoch:3 step:2574 [D loss: 0.799383, acc: 44.53%] [G loss: 1.605027]\n",
      "epoch:3 step:2575 [D loss: 0.684923, acc: 55.47%] [G loss: 1.733654]\n",
      "epoch:3 step:2576 [D loss: 0.656707, acc: 61.72%] [G loss: 1.739701]\n",
      "epoch:3 step:2577 [D loss: 0.712351, acc: 52.34%] [G loss: 1.975903]\n",
      "epoch:3 step:2578 [D loss: 0.635712, acc: 61.72%] [G loss: 1.962742]\n",
      "epoch:3 step:2579 [D loss: 0.829253, acc: 47.66%] [G loss: 1.831957]\n",
      "epoch:3 step:2580 [D loss: 0.629186, acc: 65.62%] [G loss: 2.166524]\n",
      "epoch:3 step:2581 [D loss: 0.645529, acc: 64.84%] [G loss: 1.906334]\n",
      "epoch:3 step:2582 [D loss: 0.632653, acc: 64.84%] [G loss: 2.150756]\n",
      "epoch:3 step:2583 [D loss: 0.651618, acc: 59.38%] [G loss: 2.062742]\n",
      "epoch:3 step:2584 [D loss: 0.614867, acc: 66.41%] [G loss: 2.118978]\n",
      "epoch:3 step:2585 [D loss: 0.689980, acc: 60.16%] [G loss: 1.680514]\n",
      "epoch:3 step:2586 [D loss: 0.654497, acc: 62.50%] [G loss: 1.786734]\n",
      "epoch:3 step:2587 [D loss: 0.655682, acc: 64.84%] [G loss: 1.795762]\n",
      "epoch:3 step:2588 [D loss: 0.677527, acc: 58.59%] [G loss: 1.661296]\n",
      "epoch:3 step:2589 [D loss: 0.741132, acc: 51.56%] [G loss: 1.819422]\n",
      "epoch:3 step:2590 [D loss: 0.593200, acc: 65.62%] [G loss: 1.685542]\n",
      "epoch:3 step:2591 [D loss: 0.717754, acc: 60.16%] [G loss: 1.467749]\n",
      "epoch:3 step:2592 [D loss: 0.743992, acc: 48.44%] [G loss: 1.523070]\n",
      "epoch:3 step:2593 [D loss: 0.664609, acc: 64.06%] [G loss: 1.719662]\n",
      "epoch:3 step:2594 [D loss: 0.783540, acc: 46.88%] [G loss: 1.497476]\n",
      "epoch:3 step:2595 [D loss: 0.756760, acc: 46.88%] [G loss: 1.704368]\n",
      "epoch:3 step:2596 [D loss: 0.726939, acc: 53.91%] [G loss: 1.527189]\n",
      "epoch:3 step:2597 [D loss: 0.751120, acc: 48.44%] [G loss: 1.642493]\n",
      "epoch:3 step:2598 [D loss: 0.889724, acc: 32.81%] [G loss: 1.558070]\n",
      "epoch:3 step:2599 [D loss: 0.693004, acc: 59.38%] [G loss: 1.514848]\n",
      "epoch:3 step:2600 [D loss: 0.783870, acc: 42.19%] [G loss: 1.672865]\n",
      "epoch:3 step:2601 [D loss: 0.718600, acc: 52.34%] [G loss: 1.693479]\n",
      "epoch:3 step:2602 [D loss: 0.759013, acc: 47.66%] [G loss: 1.699173]\n",
      "epoch:3 step:2603 [D loss: 0.705837, acc: 52.34%] [G loss: 1.777717]\n",
      "epoch:3 step:2604 [D loss: 0.705923, acc: 53.12%] [G loss: 1.766394]\n",
      "epoch:3 step:2605 [D loss: 0.744310, acc: 52.34%] [G loss: 1.701920]\n",
      "epoch:3 step:2606 [D loss: 0.759314, acc: 48.44%] [G loss: 1.632930]\n",
      "epoch:3 step:2607 [D loss: 0.688780, acc: 60.16%] [G loss: 1.964355]\n",
      "epoch:3 step:2608 [D loss: 0.660419, acc: 60.16%] [G loss: 1.835934]\n",
      "epoch:3 step:2609 [D loss: 0.714901, acc: 58.59%] [G loss: 1.736206]\n",
      "epoch:3 step:2610 [D loss: 0.895407, acc: 35.16%] [G loss: 1.606348]\n",
      "epoch:3 step:2611 [D loss: 0.729381, acc: 50.00%] [G loss: 1.820815]\n",
      "epoch:3 step:2612 [D loss: 0.776163, acc: 50.00%] [G loss: 1.702850]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2613 [D loss: 0.754933, acc: 50.00%] [G loss: 1.720773]\n",
      "epoch:3 step:2614 [D loss: 0.680608, acc: 61.72%] [G loss: 1.718285]\n",
      "epoch:3 step:2615 [D loss: 0.716600, acc: 56.25%] [G loss: 1.668845]\n",
      "epoch:3 step:2616 [D loss: 0.781848, acc: 42.97%] [G loss: 1.619317]\n",
      "epoch:3 step:2617 [D loss: 0.641143, acc: 67.97%] [G loss: 1.708161]\n",
      "epoch:3 step:2618 [D loss: 0.753887, acc: 46.88%] [G loss: 1.746243]\n",
      "epoch:3 step:2619 [D loss: 0.690781, acc: 57.81%] [G loss: 1.800078]\n",
      "epoch:3 step:2620 [D loss: 0.743505, acc: 48.44%] [G loss: 1.633180]\n",
      "epoch:3 step:2621 [D loss: 0.726037, acc: 50.78%] [G loss: 1.690335]\n",
      "epoch:3 step:2622 [D loss: 0.742383, acc: 50.78%] [G loss: 1.610277]\n",
      "epoch:3 step:2623 [D loss: 0.712393, acc: 48.44%] [G loss: 1.794411]\n",
      "epoch:3 step:2624 [D loss: 0.752534, acc: 47.66%] [G loss: 1.648896]\n",
      "epoch:3 step:2625 [D loss: 0.750131, acc: 52.34%] [G loss: 1.661862]\n",
      "epoch:3 step:2626 [D loss: 0.695343, acc: 56.25%] [G loss: 1.748366]\n",
      "epoch:3 step:2627 [D loss: 0.783588, acc: 42.19%] [G loss: 1.623343]\n",
      "epoch:3 step:2628 [D loss: 0.720594, acc: 53.12%] [G loss: 1.726666]\n",
      "epoch:3 step:2629 [D loss: 0.627029, acc: 66.41%] [G loss: 1.713249]\n",
      "epoch:3 step:2630 [D loss: 0.733270, acc: 50.00%] [G loss: 1.606351]\n",
      "epoch:3 step:2631 [D loss: 0.703093, acc: 56.25%] [G loss: 1.769313]\n",
      "epoch:3 step:2632 [D loss: 0.734336, acc: 49.22%] [G loss: 1.722148]\n",
      "epoch:3 step:2633 [D loss: 0.692390, acc: 53.12%] [G loss: 1.695565]\n",
      "epoch:3 step:2634 [D loss: 0.776602, acc: 48.44%] [G loss: 1.713179]\n",
      "epoch:3 step:2635 [D loss: 0.714846, acc: 59.38%] [G loss: 1.688449]\n",
      "epoch:3 step:2636 [D loss: 0.762533, acc: 49.22%] [G loss: 1.628922]\n",
      "epoch:3 step:2637 [D loss: 0.701563, acc: 55.47%] [G loss: 1.676950]\n",
      "epoch:3 step:2638 [D loss: 0.629966, acc: 62.50%] [G loss: 1.761013]\n",
      "epoch:3 step:2639 [D loss: 0.701325, acc: 53.12%] [G loss: 1.754807]\n",
      "epoch:3 step:2640 [D loss: 0.652831, acc: 65.62%] [G loss: 1.808310]\n",
      "epoch:3 step:2641 [D loss: 0.723897, acc: 52.34%] [G loss: 1.732141]\n",
      "epoch:3 step:2642 [D loss: 0.589611, acc: 69.53%] [G loss: 1.822131]\n",
      "epoch:3 step:2643 [D loss: 0.754233, acc: 49.22%] [G loss: 1.622312]\n",
      "epoch:3 step:2644 [D loss: 0.807948, acc: 44.53%] [G loss: 1.532973]\n",
      "epoch:3 step:2645 [D loss: 0.700032, acc: 56.25%] [G loss: 1.761704]\n",
      "epoch:3 step:2646 [D loss: 0.677537, acc: 56.25%] [G loss: 1.675616]\n",
      "epoch:3 step:2647 [D loss: 0.824038, acc: 40.62%] [G loss: 1.619634]\n",
      "epoch:3 step:2648 [D loss: 0.777096, acc: 43.75%] [G loss: 1.651216]\n",
      "epoch:3 step:2649 [D loss: 0.692050, acc: 57.81%] [G loss: 1.756181]\n",
      "epoch:3 step:2650 [D loss: 0.687304, acc: 59.38%] [G loss: 1.875833]\n",
      "epoch:3 step:2651 [D loss: 0.671135, acc: 56.25%] [G loss: 1.774300]\n",
      "epoch:3 step:2652 [D loss: 0.685029, acc: 55.47%] [G loss: 1.848238]\n",
      "epoch:3 step:2653 [D loss: 0.660063, acc: 64.84%] [G loss: 1.764691]\n",
      "epoch:3 step:2654 [D loss: 0.668984, acc: 60.94%] [G loss: 1.907805]\n",
      "epoch:3 step:2655 [D loss: 0.606781, acc: 69.53%] [G loss: 1.946817]\n",
      "epoch:3 step:2656 [D loss: 0.694621, acc: 57.81%] [G loss: 1.955997]\n",
      "epoch:3 step:2657 [D loss: 0.671130, acc: 60.94%] [G loss: 1.930931]\n",
      "epoch:3 step:2658 [D loss: 0.758112, acc: 48.44%] [G loss: 1.961241]\n",
      "epoch:3 step:2659 [D loss: 0.615655, acc: 71.09%] [G loss: 1.964688]\n",
      "epoch:3 step:2660 [D loss: 0.620190, acc: 63.28%] [G loss: 1.973983]\n",
      "epoch:3 step:2661 [D loss: 0.699863, acc: 62.50%] [G loss: 1.747844]\n",
      "epoch:3 step:2662 [D loss: 0.724770, acc: 57.03%] [G loss: 1.954564]\n",
      "epoch:3 step:2663 [D loss: 0.566320, acc: 70.31%] [G loss: 2.196833]\n",
      "epoch:3 step:2664 [D loss: 0.805417, acc: 45.31%] [G loss: 1.825746]\n",
      "epoch:3 step:2665 [D loss: 0.675496, acc: 61.72%] [G loss: 1.852261]\n",
      "epoch:3 step:2666 [D loss: 0.651986, acc: 68.75%] [G loss: 1.945753]\n",
      "epoch:3 step:2667 [D loss: 0.846323, acc: 45.31%] [G loss: 1.794894]\n",
      "epoch:3 step:2668 [D loss: 0.784182, acc: 42.97%] [G loss: 1.763229]\n",
      "epoch:3 step:2669 [D loss: 0.719573, acc: 52.34%] [G loss: 1.701214]\n",
      "epoch:3 step:2670 [D loss: 0.726387, acc: 56.25%] [G loss: 1.808937]\n",
      "epoch:3 step:2671 [D loss: 0.718939, acc: 50.00%] [G loss: 1.697101]\n",
      "epoch:3 step:2672 [D loss: 0.746718, acc: 48.44%] [G loss: 1.668982]\n",
      "epoch:3 step:2673 [D loss: 0.647222, acc: 61.72%] [G loss: 1.873822]\n",
      "epoch:3 step:2674 [D loss: 0.887038, acc: 43.75%] [G loss: 1.763360]\n",
      "epoch:3 step:2675 [D loss: 0.710417, acc: 52.34%] [G loss: 1.691459]\n",
      "epoch:3 step:2676 [D loss: 0.719419, acc: 57.81%] [G loss: 1.852681]\n",
      "epoch:3 step:2677 [D loss: 0.682780, acc: 61.72%] [G loss: 1.902461]\n",
      "epoch:3 step:2678 [D loss: 0.687770, acc: 53.91%] [G loss: 1.876917]\n",
      "epoch:3 step:2679 [D loss: 0.700622, acc: 56.25%] [G loss: 1.966854]\n",
      "epoch:3 step:2680 [D loss: 0.745798, acc: 50.00%] [G loss: 1.749536]\n",
      "epoch:3 step:2681 [D loss: 0.670964, acc: 59.38%] [G loss: 2.004540]\n",
      "epoch:3 step:2682 [D loss: 0.742062, acc: 53.12%] [G loss: 1.800079]\n",
      "epoch:3 step:2683 [D loss: 0.757675, acc: 56.25%] [G loss: 1.713598]\n",
      "epoch:3 step:2684 [D loss: 0.681028, acc: 54.69%] [G loss: 1.819467]\n",
      "epoch:3 step:2685 [D loss: 0.720410, acc: 53.12%] [G loss: 1.774014]\n",
      "epoch:3 step:2686 [D loss: 0.862441, acc: 39.06%] [G loss: 1.592976]\n",
      "epoch:3 step:2687 [D loss: 0.759449, acc: 44.53%] [G loss: 1.552804]\n",
      "epoch:3 step:2688 [D loss: 0.754841, acc: 51.56%] [G loss: 1.650748]\n",
      "epoch:3 step:2689 [D loss: 0.680136, acc: 63.28%] [G loss: 1.779705]\n",
      "epoch:3 step:2690 [D loss: 0.702321, acc: 54.69%] [G loss: 1.691311]\n",
      "epoch:3 step:2691 [D loss: 0.768441, acc: 48.44%] [G loss: 1.728859]\n",
      "epoch:3 step:2692 [D loss: 0.721254, acc: 53.91%] [G loss: 1.835497]\n",
      "epoch:3 step:2693 [D loss: 0.764938, acc: 46.88%] [G loss: 1.668827]\n",
      "epoch:3 step:2694 [D loss: 0.750005, acc: 50.78%] [G loss: 1.577349]\n",
      "epoch:3 step:2695 [D loss: 0.657372, acc: 61.72%] [G loss: 1.759914]\n",
      "epoch:3 step:2696 [D loss: 0.678830, acc: 55.47%] [G loss: 1.773479]\n",
      "epoch:3 step:2697 [D loss: 0.699040, acc: 52.34%] [G loss: 1.707708]\n",
      "epoch:3 step:2698 [D loss: 0.674181, acc: 69.53%] [G loss: 1.798808]\n",
      "epoch:3 step:2699 [D loss: 0.714792, acc: 55.47%] [G loss: 1.794254]\n",
      "epoch:3 step:2700 [D loss: 0.628660, acc: 71.88%] [G loss: 1.836654]\n",
      "epoch:3 step:2701 [D loss: 0.743695, acc: 48.44%] [G loss: 1.782038]\n",
      "epoch:3 step:2702 [D loss: 0.692803, acc: 62.50%] [G loss: 1.655755]\n",
      "epoch:3 step:2703 [D loss: 0.711045, acc: 57.81%] [G loss: 1.762517]\n",
      "epoch:3 step:2704 [D loss: 0.817456, acc: 41.41%] [G loss: 1.592606]\n",
      "epoch:3 step:2705 [D loss: 0.779673, acc: 42.97%] [G loss: 1.548484]\n",
      "epoch:3 step:2706 [D loss: 0.683789, acc: 60.94%] [G loss: 1.808196]\n",
      "epoch:3 step:2707 [D loss: 0.710055, acc: 53.12%] [G loss: 1.820237]\n",
      "epoch:3 step:2708 [D loss: 0.726646, acc: 50.00%] [G loss: 1.747906]\n",
      "epoch:3 step:2709 [D loss: 0.727520, acc: 53.91%] [G loss: 1.604847]\n",
      "epoch:3 step:2710 [D loss: 0.672396, acc: 63.28%] [G loss: 1.937469]\n",
      "epoch:3 step:2711 [D loss: 0.710037, acc: 54.69%] [G loss: 1.705183]\n",
      "epoch:3 step:2712 [D loss: 0.747129, acc: 50.00%] [G loss: 1.597772]\n",
      "epoch:3 step:2713 [D loss: 0.670100, acc: 56.25%] [G loss: 1.721205]\n",
      "epoch:3 step:2714 [D loss: 0.716305, acc: 53.12%] [G loss: 1.744715]\n",
      "epoch:3 step:2715 [D loss: 0.695408, acc: 53.91%] [G loss: 1.635725]\n",
      "epoch:3 step:2716 [D loss: 0.773905, acc: 42.19%] [G loss: 1.576026]\n",
      "epoch:3 step:2717 [D loss: 0.745019, acc: 47.66%] [G loss: 1.758602]\n",
      "epoch:3 step:2718 [D loss: 0.770292, acc: 43.75%] [G loss: 1.663760]\n",
      "epoch:3 step:2719 [D loss: 0.635035, acc: 61.72%] [G loss: 1.944758]\n",
      "epoch:3 step:2720 [D loss: 0.751112, acc: 52.34%] [G loss: 1.776413]\n",
      "epoch:3 step:2721 [D loss: 0.731353, acc: 50.00%] [G loss: 1.674255]\n",
      "epoch:3 step:2722 [D loss: 0.801727, acc: 41.41%] [G loss: 1.666034]\n",
      "epoch:3 step:2723 [D loss: 0.702322, acc: 57.81%] [G loss: 1.833456]\n",
      "epoch:3 step:2724 [D loss: 0.641486, acc: 67.19%] [G loss: 1.946273]\n",
      "epoch:3 step:2725 [D loss: 0.643591, acc: 62.50%] [G loss: 1.919021]\n",
      "epoch:3 step:2726 [D loss: 0.621833, acc: 66.41%] [G loss: 1.705034]\n",
      "epoch:3 step:2727 [D loss: 0.711805, acc: 55.47%] [G loss: 1.740735]\n",
      "epoch:3 step:2728 [D loss: 0.757882, acc: 52.34%] [G loss: 1.697495]\n",
      "epoch:3 step:2729 [D loss: 0.716676, acc: 58.59%] [G loss: 1.851461]\n",
      "epoch:3 step:2730 [D loss: 0.807943, acc: 44.53%] [G loss: 1.572514]\n",
      "epoch:3 step:2731 [D loss: 0.736948, acc: 49.22%] [G loss: 1.567675]\n",
      "epoch:3 step:2732 [D loss: 0.632935, acc: 67.19%] [G loss: 1.675900]\n",
      "epoch:3 step:2733 [D loss: 0.633093, acc: 71.88%] [G loss: 2.003615]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2734 [D loss: 0.760273, acc: 48.44%] [G loss: 1.572223]\n",
      "epoch:3 step:2735 [D loss: 0.704758, acc: 51.56%] [G loss: 1.777847]\n",
      "epoch:3 step:2736 [D loss: 0.826590, acc: 41.41%] [G loss: 1.604392]\n",
      "epoch:3 step:2737 [D loss: 0.679523, acc: 58.59%] [G loss: 1.820788]\n",
      "epoch:3 step:2738 [D loss: 0.661542, acc: 59.38%] [G loss: 1.795080]\n",
      "epoch:3 step:2739 [D loss: 0.669936, acc: 63.28%] [G loss: 1.711447]\n",
      "epoch:3 step:2740 [D loss: 0.744597, acc: 49.22%] [G loss: 1.836291]\n",
      "epoch:3 step:2741 [D loss: 0.746841, acc: 50.00%] [G loss: 1.721239]\n",
      "epoch:3 step:2742 [D loss: 0.733020, acc: 56.25%] [G loss: 1.884593]\n",
      "epoch:3 step:2743 [D loss: 0.728230, acc: 55.47%] [G loss: 1.648074]\n",
      "epoch:3 step:2744 [D loss: 0.640223, acc: 67.19%] [G loss: 1.861910]\n",
      "epoch:3 step:2745 [D loss: 0.810393, acc: 44.53%] [G loss: 1.604063]\n",
      "epoch:3 step:2746 [D loss: 0.705086, acc: 50.78%] [G loss: 1.925364]\n",
      "epoch:3 step:2747 [D loss: 0.668389, acc: 60.94%] [G loss: 1.658962]\n",
      "epoch:3 step:2748 [D loss: 0.764227, acc: 52.34%] [G loss: 1.767481]\n",
      "epoch:3 step:2749 [D loss: 0.701011, acc: 57.81%] [G loss: 1.819697]\n",
      "epoch:3 step:2750 [D loss: 0.703362, acc: 55.47%] [G loss: 1.647938]\n",
      "epoch:3 step:2751 [D loss: 0.720791, acc: 43.75%] [G loss: 1.660237]\n",
      "epoch:3 step:2752 [D loss: 0.696596, acc: 53.91%] [G loss: 1.800580]\n",
      "epoch:3 step:2753 [D loss: 0.682018, acc: 60.16%] [G loss: 1.666861]\n",
      "epoch:3 step:2754 [D loss: 0.783966, acc: 45.31%] [G loss: 1.631876]\n",
      "epoch:3 step:2755 [D loss: 0.657019, acc: 64.06%] [G loss: 1.866695]\n",
      "epoch:3 step:2756 [D loss: 0.684361, acc: 54.69%] [G loss: 1.756365]\n",
      "epoch:3 step:2757 [D loss: 0.713722, acc: 56.25%] [G loss: 1.746027]\n",
      "epoch:3 step:2758 [D loss: 0.636485, acc: 66.41%] [G loss: 1.797284]\n",
      "epoch:3 step:2759 [D loss: 0.757508, acc: 47.66%] [G loss: 1.728462]\n",
      "epoch:3 step:2760 [D loss: 0.702448, acc: 50.00%] [G loss: 1.828767]\n",
      "epoch:3 step:2761 [D loss: 0.741281, acc: 52.34%] [G loss: 1.690968]\n",
      "epoch:3 step:2762 [D loss: 0.740024, acc: 44.53%] [G loss: 1.517954]\n",
      "epoch:3 step:2763 [D loss: 0.809044, acc: 46.09%] [G loss: 1.678220]\n",
      "epoch:3 step:2764 [D loss: 0.654393, acc: 64.84%] [G loss: 1.728412]\n",
      "epoch:3 step:2765 [D loss: 0.713916, acc: 54.69%] [G loss: 1.746833]\n",
      "epoch:3 step:2766 [D loss: 0.668902, acc: 57.81%] [G loss: 1.674618]\n",
      "epoch:3 step:2767 [D loss: 0.711274, acc: 55.47%] [G loss: 1.759045]\n",
      "epoch:3 step:2768 [D loss: 0.697135, acc: 56.25%] [G loss: 1.856782]\n",
      "epoch:3 step:2769 [D loss: 0.688487, acc: 60.94%] [G loss: 1.753307]\n",
      "epoch:3 step:2770 [D loss: 0.657148, acc: 63.28%] [G loss: 1.724250]\n",
      "epoch:3 step:2771 [D loss: 0.766008, acc: 46.09%] [G loss: 1.793880]\n",
      "epoch:3 step:2772 [D loss: 0.779693, acc: 51.56%] [G loss: 1.772154]\n",
      "epoch:3 step:2773 [D loss: 0.718535, acc: 58.59%] [G loss: 1.829979]\n",
      "epoch:3 step:2774 [D loss: 0.601260, acc: 68.75%] [G loss: 2.050843]\n",
      "epoch:3 step:2775 [D loss: 0.630940, acc: 63.28%] [G loss: 1.997530]\n",
      "epoch:3 step:2776 [D loss: 0.695570, acc: 57.81%] [G loss: 1.722942]\n",
      "epoch:3 step:2777 [D loss: 0.630837, acc: 61.72%] [G loss: 1.809205]\n",
      "epoch:3 step:2778 [D loss: 0.762142, acc: 42.97%] [G loss: 1.689383]\n",
      "epoch:3 step:2779 [D loss: 0.711167, acc: 58.59%] [G loss: 1.830874]\n",
      "epoch:3 step:2780 [D loss: 0.757025, acc: 54.69%] [G loss: 1.541629]\n",
      "epoch:3 step:2781 [D loss: 0.692901, acc: 59.38%] [G loss: 1.833816]\n",
      "epoch:3 step:2782 [D loss: 0.631164, acc: 66.41%] [G loss: 1.760852]\n",
      "epoch:3 step:2783 [D loss: 0.799420, acc: 46.09%] [G loss: 1.440463]\n",
      "epoch:3 step:2784 [D loss: 0.780225, acc: 44.53%] [G loss: 1.452014]\n",
      "epoch:3 step:2785 [D loss: 0.721981, acc: 58.59%] [G loss: 1.666878]\n",
      "epoch:3 step:2786 [D loss: 0.874825, acc: 42.97%] [G loss: 1.483190]\n",
      "epoch:3 step:2787 [D loss: 0.687425, acc: 56.25%] [G loss: 1.677493]\n",
      "epoch:3 step:2788 [D loss: 0.717829, acc: 58.59%] [G loss: 1.460623]\n",
      "epoch:3 step:2789 [D loss: 0.789716, acc: 45.31%] [G loss: 1.576277]\n",
      "epoch:3 step:2790 [D loss: 0.743696, acc: 46.09%] [G loss: 1.625880]\n",
      "epoch:3 step:2791 [D loss: 0.914385, acc: 33.59%] [G loss: 1.338565]\n",
      "epoch:3 step:2792 [D loss: 0.832704, acc: 41.41%] [G loss: 1.417288]\n",
      "epoch:3 step:2793 [D loss: 0.736939, acc: 50.78%] [G loss: 1.460465]\n",
      "epoch:3 step:2794 [D loss: 0.731815, acc: 50.78%] [G loss: 1.759945]\n",
      "epoch:3 step:2795 [D loss: 0.705949, acc: 53.12%] [G loss: 1.633117]\n",
      "epoch:3 step:2796 [D loss: 0.805841, acc: 42.19%] [G loss: 1.763449]\n",
      "epoch:3 step:2797 [D loss: 0.751088, acc: 46.88%] [G loss: 1.609772]\n",
      "epoch:3 step:2798 [D loss: 0.748180, acc: 49.22%] [G loss: 1.680232]\n",
      "epoch:3 step:2799 [D loss: 0.759805, acc: 50.78%] [G loss: 1.688920]\n",
      "epoch:3 step:2800 [D loss: 0.748784, acc: 50.00%] [G loss: 1.889971]\n",
      "epoch:3 step:2801 [D loss: 0.691392, acc: 57.81%] [G loss: 1.982637]\n",
      "epoch:3 step:2802 [D loss: 0.669402, acc: 61.72%] [G loss: 1.858469]\n",
      "epoch:3 step:2803 [D loss: 0.736998, acc: 53.91%] [G loss: 1.646693]\n",
      "epoch:3 step:2804 [D loss: 0.705994, acc: 56.25%] [G loss: 1.722598]\n",
      "epoch:3 step:2805 [D loss: 0.666330, acc: 60.94%] [G loss: 1.874860]\n",
      "epoch:3 step:2806 [D loss: 0.666454, acc: 59.38%] [G loss: 1.698810]\n",
      "epoch:3 step:2807 [D loss: 0.831782, acc: 38.28%] [G loss: 1.628811]\n",
      "epoch:3 step:2808 [D loss: 0.703603, acc: 54.69%] [G loss: 1.590900]\n",
      "epoch:3 step:2809 [D loss: 0.756755, acc: 46.09%] [G loss: 1.651736]\n",
      "epoch:3 step:2810 [D loss: 0.667642, acc: 57.03%] [G loss: 1.627208]\n",
      "epoch:3 step:2811 [D loss: 0.744273, acc: 46.88%] [G loss: 1.650471]\n",
      "epoch:3 step:2812 [D loss: 0.691386, acc: 57.03%] [G loss: 1.630132]\n",
      "epoch:3 step:2813 [D loss: 0.787554, acc: 44.53%] [G loss: 1.493201]\n",
      "epoch:3 step:2814 [D loss: 0.706914, acc: 56.25%] [G loss: 1.725260]\n",
      "epoch:3 step:2815 [D loss: 0.711944, acc: 54.69%] [G loss: 1.586776]\n",
      "epoch:3 step:2816 [D loss: 0.713151, acc: 53.91%] [G loss: 1.562102]\n",
      "epoch:3 step:2817 [D loss: 0.742450, acc: 46.88%] [G loss: 1.569615]\n",
      "epoch:3 step:2818 [D loss: 0.804338, acc: 43.75%] [G loss: 1.466879]\n",
      "epoch:3 step:2819 [D loss: 0.693752, acc: 57.81%] [G loss: 1.635402]\n",
      "epoch:3 step:2820 [D loss: 0.682414, acc: 58.59%] [G loss: 1.569553]\n",
      "epoch:3 step:2821 [D loss: 0.709027, acc: 52.34%] [G loss: 1.712560]\n",
      "epoch:3 step:2822 [D loss: 0.653635, acc: 57.03%] [G loss: 1.716132]\n",
      "epoch:3 step:2823 [D loss: 0.675663, acc: 59.38%] [G loss: 1.776989]\n",
      "epoch:3 step:2824 [D loss: 0.761212, acc: 50.78%] [G loss: 1.579738]\n",
      "epoch:3 step:2825 [D loss: 0.670288, acc: 60.16%] [G loss: 1.803061]\n",
      "epoch:3 step:2826 [D loss: 0.695988, acc: 53.91%] [G loss: 1.630697]\n",
      "epoch:3 step:2827 [D loss: 0.642674, acc: 65.62%] [G loss: 1.805310]\n",
      "epoch:3 step:2828 [D loss: 0.727816, acc: 52.34%] [G loss: 1.809559]\n",
      "epoch:3 step:2829 [D loss: 0.734656, acc: 52.34%] [G loss: 1.752292]\n",
      "epoch:3 step:2830 [D loss: 0.633481, acc: 62.50%] [G loss: 1.909558]\n",
      "epoch:3 step:2831 [D loss: 0.654602, acc: 61.72%] [G loss: 1.906589]\n",
      "epoch:3 step:2832 [D loss: 0.770518, acc: 46.88%] [G loss: 1.798220]\n",
      "epoch:3 step:2833 [D loss: 0.688140, acc: 56.25%] [G loss: 1.901536]\n",
      "epoch:3 step:2834 [D loss: 0.689605, acc: 59.38%] [G loss: 1.735183]\n",
      "epoch:3 step:2835 [D loss: 0.688046, acc: 54.69%] [G loss: 1.693353]\n",
      "epoch:3 step:2836 [D loss: 0.712015, acc: 53.12%] [G loss: 1.620149]\n",
      "epoch:3 step:2837 [D loss: 0.694467, acc: 54.69%] [G loss: 1.501633]\n",
      "epoch:3 step:2838 [D loss: 0.722097, acc: 53.12%] [G loss: 1.549026]\n",
      "epoch:3 step:2839 [D loss: 0.663123, acc: 61.72%] [G loss: 1.580160]\n",
      "epoch:3 step:2840 [D loss: 0.701915, acc: 53.12%] [G loss: 1.685921]\n",
      "epoch:3 step:2841 [D loss: 0.699396, acc: 62.50%] [G loss: 1.735551]\n",
      "epoch:3 step:2842 [D loss: 0.752594, acc: 44.53%] [G loss: 1.777163]\n",
      "epoch:3 step:2843 [D loss: 0.688694, acc: 55.47%] [G loss: 1.374067]\n",
      "epoch:3 step:2844 [D loss: 0.814834, acc: 44.53%] [G loss: 1.551594]\n",
      "epoch:3 step:2845 [D loss: 0.644895, acc: 63.28%] [G loss: 1.674254]\n",
      "epoch:3 step:2846 [D loss: 0.792714, acc: 46.09%] [G loss: 1.739126]\n",
      "epoch:3 step:2847 [D loss: 0.622034, acc: 65.62%] [G loss: 1.737048]\n",
      "epoch:3 step:2848 [D loss: 0.668789, acc: 60.16%] [G loss: 1.786846]\n",
      "epoch:3 step:2849 [D loss: 0.732167, acc: 50.00%] [G loss: 1.691148]\n",
      "epoch:3 step:2850 [D loss: 0.685242, acc: 56.25%] [G loss: 1.706811]\n",
      "epoch:3 step:2851 [D loss: 0.779799, acc: 48.44%] [G loss: 1.651752]\n",
      "epoch:3 step:2852 [D loss: 0.752281, acc: 51.56%] [G loss: 1.679529]\n",
      "epoch:3 step:2853 [D loss: 0.718500, acc: 52.34%] [G loss: 1.540538]\n",
      "epoch:3 step:2854 [D loss: 0.828381, acc: 42.97%] [G loss: 1.552621]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2855 [D loss: 0.665910, acc: 58.59%] [G loss: 1.692593]\n",
      "epoch:3 step:2856 [D loss: 0.840822, acc: 35.94%] [G loss: 1.542964]\n",
      "epoch:3 step:2857 [D loss: 0.769541, acc: 44.53%] [G loss: 1.669021]\n",
      "epoch:3 step:2858 [D loss: 0.715673, acc: 51.56%] [G loss: 1.832274]\n",
      "epoch:3 step:2859 [D loss: 0.682556, acc: 57.03%] [G loss: 1.568601]\n",
      "epoch:3 step:2860 [D loss: 0.818671, acc: 35.94%] [G loss: 1.501634]\n",
      "epoch:3 step:2861 [D loss: 0.655985, acc: 63.28%] [G loss: 1.581363]\n",
      "epoch:3 step:2862 [D loss: 0.771154, acc: 46.09%] [G loss: 1.511099]\n",
      "epoch:3 step:2863 [D loss: 0.775256, acc: 42.97%] [G loss: 1.596621]\n",
      "epoch:3 step:2864 [D loss: 0.695714, acc: 54.69%] [G loss: 1.869728]\n",
      "epoch:3 step:2865 [D loss: 0.798637, acc: 43.75%] [G loss: 1.535281]\n",
      "epoch:3 step:2866 [D loss: 0.786114, acc: 39.84%] [G loss: 1.535800]\n",
      "epoch:3 step:2867 [D loss: 0.767962, acc: 39.84%] [G loss: 1.559103]\n",
      "epoch:3 step:2868 [D loss: 0.695962, acc: 53.12%] [G loss: 1.643572]\n",
      "epoch:3 step:2869 [D loss: 0.752912, acc: 50.78%] [G loss: 1.457096]\n",
      "epoch:3 step:2870 [D loss: 0.684465, acc: 61.72%] [G loss: 1.600246]\n",
      "epoch:3 step:2871 [D loss: 0.760687, acc: 47.66%] [G loss: 1.579086]\n",
      "epoch:3 step:2872 [D loss: 0.736956, acc: 46.88%] [G loss: 1.644365]\n",
      "epoch:3 step:2873 [D loss: 0.720059, acc: 56.25%] [G loss: 1.635061]\n",
      "epoch:3 step:2874 [D loss: 0.731007, acc: 51.56%] [G loss: 1.654030]\n",
      "epoch:3 step:2875 [D loss: 0.816087, acc: 38.28%] [G loss: 1.587903]\n",
      "epoch:3 step:2876 [D loss: 0.701906, acc: 47.66%] [G loss: 1.629159]\n",
      "epoch:3 step:2877 [D loss: 0.704620, acc: 52.34%] [G loss: 1.683867]\n",
      "epoch:3 step:2878 [D loss: 0.833087, acc: 36.72%] [G loss: 1.537445]\n",
      "epoch:3 step:2879 [D loss: 0.633616, acc: 63.28%] [G loss: 1.880695]\n",
      "epoch:3 step:2880 [D loss: 0.728098, acc: 54.69%] [G loss: 1.666723]\n",
      "epoch:3 step:2881 [D loss: 0.693668, acc: 52.34%] [G loss: 1.639733]\n",
      "epoch:3 step:2882 [D loss: 0.699986, acc: 54.69%] [G loss: 1.672663]\n",
      "epoch:3 step:2883 [D loss: 0.696620, acc: 58.59%] [G loss: 1.686680]\n",
      "epoch:3 step:2884 [D loss: 0.681448, acc: 56.25%] [G loss: 1.693577]\n",
      "epoch:3 step:2885 [D loss: 0.670767, acc: 60.94%] [G loss: 1.752725]\n",
      "epoch:3 step:2886 [D loss: 0.733359, acc: 53.12%] [G loss: 1.605772]\n",
      "epoch:3 step:2887 [D loss: 0.720999, acc: 53.91%] [G loss: 1.730628]\n",
      "epoch:3 step:2888 [D loss: 0.676304, acc: 61.72%] [G loss: 1.572220]\n",
      "epoch:3 step:2889 [D loss: 0.738442, acc: 46.88%] [G loss: 1.736944]\n",
      "epoch:3 step:2890 [D loss: 0.723688, acc: 53.91%] [G loss: 1.632238]\n",
      "epoch:3 step:2891 [D loss: 0.764921, acc: 42.97%] [G loss: 1.542841]\n",
      "epoch:3 step:2892 [D loss: 0.652451, acc: 62.50%] [G loss: 1.707685]\n",
      "epoch:3 step:2893 [D loss: 0.719517, acc: 54.69%] [G loss: 1.592384]\n",
      "epoch:3 step:2894 [D loss: 0.691642, acc: 54.69%] [G loss: 1.639328]\n",
      "epoch:3 step:2895 [D loss: 0.828444, acc: 35.16%] [G loss: 1.404744]\n",
      "epoch:3 step:2896 [D loss: 0.788462, acc: 44.53%] [G loss: 1.464452]\n",
      "epoch:3 step:2897 [D loss: 0.726528, acc: 51.56%] [G loss: 1.573824]\n",
      "epoch:3 step:2898 [D loss: 0.754676, acc: 42.97%] [G loss: 1.710989]\n",
      "epoch:3 step:2899 [D loss: 0.738973, acc: 48.44%] [G loss: 1.615224]\n",
      "epoch:3 step:2900 [D loss: 0.719280, acc: 52.34%] [G loss: 1.585188]\n",
      "epoch:3 step:2901 [D loss: 0.799340, acc: 44.53%] [G loss: 1.567051]\n",
      "epoch:3 step:2902 [D loss: 0.819754, acc: 36.72%] [G loss: 1.482620]\n",
      "epoch:3 step:2903 [D loss: 0.762459, acc: 46.88%] [G loss: 1.598312]\n",
      "epoch:3 step:2904 [D loss: 0.742945, acc: 48.44%] [G loss: 1.560176]\n",
      "epoch:3 step:2905 [D loss: 0.805541, acc: 37.50%] [G loss: 1.494409]\n",
      "epoch:3 step:2906 [D loss: 0.772252, acc: 42.97%] [G loss: 1.496358]\n",
      "epoch:3 step:2907 [D loss: 0.694858, acc: 54.69%] [G loss: 1.670919]\n",
      "epoch:3 step:2908 [D loss: 0.755872, acc: 45.31%] [G loss: 1.559079]\n",
      "epoch:3 step:2909 [D loss: 0.702446, acc: 57.81%] [G loss: 1.624673]\n",
      "epoch:3 step:2910 [D loss: 0.721078, acc: 59.38%] [G loss: 1.570426]\n",
      "epoch:3 step:2911 [D loss: 0.811987, acc: 35.16%] [G loss: 1.618248]\n",
      "epoch:3 step:2912 [D loss: 0.729680, acc: 51.56%] [G loss: 1.637556]\n",
      "epoch:3 step:2913 [D loss: 0.706138, acc: 57.81%] [G loss: 1.609497]\n",
      "epoch:3 step:2914 [D loss: 0.693434, acc: 57.03%] [G loss: 1.622503]\n",
      "epoch:3 step:2915 [D loss: 0.692137, acc: 54.69%] [G loss: 1.638902]\n",
      "epoch:3 step:2916 [D loss: 0.690786, acc: 54.69%] [G loss: 1.735919]\n",
      "epoch:3 step:2917 [D loss: 0.771407, acc: 42.97%] [G loss: 1.585234]\n",
      "epoch:3 step:2918 [D loss: 0.707778, acc: 61.72%] [G loss: 1.680637]\n",
      "epoch:3 step:2919 [D loss: 0.661502, acc: 65.62%] [G loss: 1.713010]\n",
      "epoch:3 step:2920 [D loss: 0.702611, acc: 57.03%] [G loss: 1.709264]\n",
      "epoch:3 step:2921 [D loss: 0.708497, acc: 52.34%] [G loss: 1.632342]\n",
      "epoch:3 step:2922 [D loss: 0.674929, acc: 53.91%] [G loss: 1.706941]\n",
      "epoch:3 step:2923 [D loss: 0.731808, acc: 50.00%] [G loss: 1.626585]\n",
      "epoch:3 step:2924 [D loss: 0.752195, acc: 45.31%] [G loss: 1.613805]\n",
      "epoch:3 step:2925 [D loss: 0.725848, acc: 53.91%] [G loss: 1.624250]\n",
      "epoch:3 step:2926 [D loss: 0.736131, acc: 51.56%] [G loss: 1.620679]\n",
      "epoch:3 step:2927 [D loss: 0.703409, acc: 49.22%] [G loss: 1.620732]\n",
      "epoch:3 step:2928 [D loss: 0.730296, acc: 46.88%] [G loss: 1.656246]\n",
      "epoch:3 step:2929 [D loss: 0.712687, acc: 56.25%] [G loss: 1.600374]\n",
      "epoch:3 step:2930 [D loss: 0.716157, acc: 57.81%] [G loss: 1.698170]\n",
      "epoch:3 step:2931 [D loss: 0.691039, acc: 60.16%] [G loss: 1.680004]\n",
      "epoch:3 step:2932 [D loss: 0.755654, acc: 39.84%] [G loss: 1.496277]\n",
      "epoch:3 step:2933 [D loss: 0.680774, acc: 57.03%] [G loss: 1.623094]\n",
      "epoch:3 step:2934 [D loss: 0.724782, acc: 52.34%] [G loss: 1.590307]\n",
      "epoch:3 step:2935 [D loss: 0.670494, acc: 57.03%] [G loss: 1.599156]\n",
      "epoch:3 step:2936 [D loss: 0.723103, acc: 52.34%] [G loss: 1.752700]\n",
      "epoch:3 step:2937 [D loss: 0.715577, acc: 49.22%] [G loss: 1.595215]\n",
      "epoch:3 step:2938 [D loss: 0.701644, acc: 55.47%] [G loss: 1.593716]\n",
      "epoch:3 step:2939 [D loss: 0.698588, acc: 55.47%] [G loss: 1.684181]\n",
      "epoch:3 step:2940 [D loss: 0.709219, acc: 55.47%] [G loss: 1.694378]\n",
      "epoch:3 step:2941 [D loss: 0.668133, acc: 56.25%] [G loss: 1.859973]\n",
      "epoch:3 step:2942 [D loss: 0.692607, acc: 57.81%] [G loss: 1.749534]\n",
      "epoch:3 step:2943 [D loss: 0.706694, acc: 50.78%] [G loss: 1.705391]\n",
      "epoch:3 step:2944 [D loss: 0.726129, acc: 57.03%] [G loss: 1.746850]\n",
      "epoch:3 step:2945 [D loss: 0.753523, acc: 52.34%] [G loss: 1.584053]\n",
      "epoch:3 step:2946 [D loss: 0.721476, acc: 50.78%] [G loss: 1.650865]\n",
      "epoch:3 step:2947 [D loss: 0.797202, acc: 35.16%] [G loss: 1.564974]\n",
      "epoch:3 step:2948 [D loss: 0.744057, acc: 49.22%] [G loss: 1.630980]\n",
      "epoch:3 step:2949 [D loss: 0.730988, acc: 51.56%] [G loss: 1.543392]\n",
      "epoch:3 step:2950 [D loss: 0.707698, acc: 52.34%] [G loss: 1.649504]\n",
      "epoch:3 step:2951 [D loss: 0.708490, acc: 53.91%] [G loss: 1.615705]\n",
      "epoch:3 step:2952 [D loss: 0.778199, acc: 39.06%] [G loss: 1.587020]\n",
      "epoch:3 step:2953 [D loss: 0.805884, acc: 38.28%] [G loss: 1.535365]\n",
      "epoch:3 step:2954 [D loss: 0.701137, acc: 57.03%] [G loss: 1.704940]\n",
      "epoch:3 step:2955 [D loss: 0.698551, acc: 57.81%] [G loss: 1.531169]\n",
      "epoch:3 step:2956 [D loss: 0.797508, acc: 48.44%] [G loss: 1.677263]\n",
      "epoch:3 step:2957 [D loss: 0.720835, acc: 55.47%] [G loss: 1.581618]\n",
      "epoch:3 step:2958 [D loss: 0.731686, acc: 51.56%] [G loss: 1.589743]\n",
      "epoch:3 step:2959 [D loss: 0.645582, acc: 64.06%] [G loss: 1.766242]\n",
      "epoch:3 step:2960 [D loss: 0.787100, acc: 41.41%] [G loss: 1.578512]\n",
      "epoch:3 step:2961 [D loss: 0.610276, acc: 64.06%] [G loss: 1.688581]\n",
      "epoch:3 step:2962 [D loss: 0.621405, acc: 67.19%] [G loss: 1.685471]\n",
      "epoch:3 step:2963 [D loss: 0.715755, acc: 52.34%] [G loss: 1.550915]\n",
      "epoch:3 step:2964 [D loss: 0.584135, acc: 68.75%] [G loss: 1.589516]\n",
      "epoch:3 step:2965 [D loss: 0.745471, acc: 52.34%] [G loss: 1.523467]\n",
      "epoch:3 step:2966 [D loss: 0.765324, acc: 56.25%] [G loss: 1.590422]\n",
      "epoch:3 step:2967 [D loss: 0.725527, acc: 48.44%] [G loss: 1.605500]\n",
      "epoch:3 step:2968 [D loss: 0.753494, acc: 44.53%] [G loss: 1.502464]\n",
      "epoch:3 step:2969 [D loss: 0.823368, acc: 32.81%] [G loss: 1.486519]\n",
      "epoch:3 step:2970 [D loss: 0.750266, acc: 49.22%] [G loss: 1.497832]\n",
      "epoch:3 step:2971 [D loss: 0.700313, acc: 50.00%] [G loss: 1.516609]\n",
      "epoch:3 step:2972 [D loss: 0.713893, acc: 50.78%] [G loss: 1.714448]\n",
      "epoch:3 step:2973 [D loss: 0.715482, acc: 53.12%] [G loss: 1.672315]\n",
      "epoch:3 step:2974 [D loss: 0.692999, acc: 54.69%] [G loss: 1.702571]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2975 [D loss: 0.762219, acc: 42.19%] [G loss: 1.574579]\n",
      "epoch:3 step:2976 [D loss: 0.662485, acc: 61.72%] [G loss: 1.706942]\n",
      "epoch:3 step:2977 [D loss: 0.660281, acc: 60.94%] [G loss: 1.710981]\n",
      "epoch:3 step:2978 [D loss: 0.731242, acc: 49.22%] [G loss: 1.682683]\n",
      "epoch:3 step:2979 [D loss: 0.665530, acc: 56.25%] [G loss: 1.773424]\n",
      "epoch:3 step:2980 [D loss: 0.650281, acc: 63.28%] [G loss: 1.786900]\n",
      "epoch:3 step:2981 [D loss: 0.659440, acc: 64.06%] [G loss: 1.769550]\n",
      "epoch:3 step:2982 [D loss: 0.685875, acc: 56.25%] [G loss: 1.825427]\n",
      "epoch:3 step:2983 [D loss: 0.679996, acc: 56.25%] [G loss: 1.775966]\n",
      "epoch:3 step:2984 [D loss: 0.671962, acc: 57.81%] [G loss: 1.753982]\n",
      "epoch:3 step:2985 [D loss: 0.592202, acc: 71.09%] [G loss: 2.027890]\n",
      "epoch:3 step:2986 [D loss: 0.595813, acc: 72.66%] [G loss: 2.072001]\n",
      "epoch:3 step:2987 [D loss: 0.680397, acc: 60.94%] [G loss: 1.780185]\n",
      "epoch:3 step:2988 [D loss: 0.711149, acc: 55.47%] [G loss: 1.641966]\n",
      "epoch:3 step:2989 [D loss: 0.678389, acc: 57.03%] [G loss: 1.783249]\n",
      "epoch:3 step:2990 [D loss: 0.679140, acc: 66.41%] [G loss: 1.692705]\n",
      "epoch:3 step:2991 [D loss: 0.697251, acc: 58.59%] [G loss: 1.621532]\n",
      "epoch:3 step:2992 [D loss: 0.574532, acc: 75.00%] [G loss: 1.650593]\n",
      "epoch:3 step:2993 [D loss: 0.631102, acc: 66.41%] [G loss: 1.565451]\n",
      "epoch:3 step:2994 [D loss: 0.595474, acc: 74.22%] [G loss: 1.720657]\n",
      "epoch:3 step:2995 [D loss: 0.739341, acc: 53.12%] [G loss: 1.537090]\n",
      "epoch:3 step:2996 [D loss: 0.738058, acc: 51.56%] [G loss: 1.362558]\n",
      "epoch:3 step:2997 [D loss: 0.696671, acc: 57.81%] [G loss: 1.814013]\n",
      "epoch:3 step:2998 [D loss: 0.746318, acc: 48.44%] [G loss: 1.592584]\n",
      "epoch:3 step:2999 [D loss: 0.900522, acc: 35.94%] [G loss: 1.520001]\n",
      "epoch:3 step:3000 [D loss: 0.809127, acc: 43.75%] [G loss: 1.557502]\n",
      "epoch:3 step:3001 [D loss: 0.829443, acc: 43.75%] [G loss: 1.526053]\n",
      "epoch:3 step:3002 [D loss: 0.686262, acc: 53.12%] [G loss: 1.718296]\n",
      "epoch:3 step:3003 [D loss: 0.758245, acc: 48.44%] [G loss: 1.600447]\n",
      "epoch:3 step:3004 [D loss: 0.755992, acc: 48.44%] [G loss: 1.578606]\n",
      "epoch:3 step:3005 [D loss: 0.680973, acc: 57.03%] [G loss: 1.696821]\n",
      "epoch:3 step:3006 [D loss: 0.736062, acc: 50.78%] [G loss: 1.632013]\n",
      "epoch:3 step:3007 [D loss: 0.766549, acc: 48.44%] [G loss: 1.625304]\n",
      "epoch:3 step:3008 [D loss: 0.692343, acc: 60.16%] [G loss: 1.658939]\n",
      "epoch:3 step:3009 [D loss: 0.728497, acc: 51.56%] [G loss: 1.683245]\n",
      "epoch:3 step:3010 [D loss: 0.771675, acc: 42.19%] [G loss: 1.546850]\n",
      "epoch:3 step:3011 [D loss: 0.757089, acc: 42.97%] [G loss: 1.559582]\n",
      "epoch:3 step:3012 [D loss: 0.793080, acc: 41.41%] [G loss: 1.507600]\n",
      "epoch:3 step:3013 [D loss: 0.766842, acc: 45.31%] [G loss: 1.604907]\n",
      "epoch:3 step:3014 [D loss: 0.687236, acc: 56.25%] [G loss: 1.697525]\n",
      "epoch:3 step:3015 [D loss: 0.781263, acc: 47.66%] [G loss: 1.493209]\n",
      "epoch:3 step:3016 [D loss: 0.856199, acc: 35.16%] [G loss: 1.518222]\n",
      "epoch:3 step:3017 [D loss: 0.743078, acc: 46.88%] [G loss: 1.583149]\n",
      "epoch:3 step:3018 [D loss: 0.721223, acc: 48.44%] [G loss: 1.503879]\n",
      "epoch:3 step:3019 [D loss: 0.816654, acc: 38.28%] [G loss: 1.533135]\n",
      "epoch:3 step:3020 [D loss: 0.692466, acc: 52.34%] [G loss: 1.603230]\n",
      "epoch:3 step:3021 [D loss: 0.755982, acc: 48.44%] [G loss: 1.581342]\n",
      "epoch:3 step:3022 [D loss: 0.788942, acc: 44.53%] [G loss: 1.566933]\n",
      "epoch:3 step:3023 [D loss: 0.804430, acc: 39.06%] [G loss: 1.571393]\n",
      "epoch:3 step:3024 [D loss: 0.730412, acc: 52.34%] [G loss: 1.603219]\n",
      "epoch:3 step:3025 [D loss: 0.801170, acc: 42.97%] [G loss: 1.555783]\n",
      "epoch:3 step:3026 [D loss: 0.688574, acc: 54.69%] [G loss: 1.663506]\n",
      "epoch:3 step:3027 [D loss: 0.676076, acc: 61.72%] [G loss: 1.661292]\n",
      "epoch:3 step:3028 [D loss: 0.730072, acc: 51.56%] [G loss: 1.690016]\n",
      "epoch:3 step:3029 [D loss: 0.738724, acc: 48.44%] [G loss: 1.627788]\n",
      "epoch:3 step:3030 [D loss: 0.670766, acc: 57.81%] [G loss: 1.735568]\n",
      "epoch:3 step:3031 [D loss: 0.683703, acc: 57.03%] [G loss: 1.604230]\n",
      "epoch:3 step:3032 [D loss: 0.702455, acc: 53.91%] [G loss: 1.616922]\n",
      "epoch:3 step:3033 [D loss: 0.702652, acc: 50.78%] [G loss: 1.504273]\n",
      "epoch:3 step:3034 [D loss: 0.686042, acc: 59.38%] [G loss: 1.804868]\n",
      "epoch:3 step:3035 [D loss: 0.761414, acc: 42.19%] [G loss: 1.548470]\n",
      "epoch:3 step:3036 [D loss: 0.720874, acc: 55.47%] [G loss: 1.686593]\n",
      "epoch:3 step:3037 [D loss: 0.715141, acc: 56.25%] [G loss: 1.541173]\n",
      "epoch:3 step:3038 [D loss: 0.674635, acc: 56.25%] [G loss: 1.627748]\n",
      "epoch:3 step:3039 [D loss: 0.702854, acc: 54.69%] [G loss: 1.704357]\n",
      "epoch:3 step:3040 [D loss: 0.722884, acc: 54.69%] [G loss: 1.641045]\n",
      "epoch:3 step:3041 [D loss: 0.689379, acc: 57.81%] [G loss: 1.546224]\n",
      "epoch:3 step:3042 [D loss: 0.758921, acc: 48.44%] [G loss: 1.540314]\n",
      "epoch:3 step:3043 [D loss: 0.706327, acc: 49.22%] [G loss: 1.727366]\n",
      "epoch:3 step:3044 [D loss: 0.699695, acc: 57.81%] [G loss: 1.697146]\n",
      "epoch:3 step:3045 [D loss: 0.705302, acc: 50.78%] [G loss: 1.495146]\n",
      "epoch:3 step:3046 [D loss: 0.788011, acc: 46.09%] [G loss: 1.509131]\n",
      "epoch:3 step:3047 [D loss: 0.875141, acc: 29.69%] [G loss: 1.611332]\n",
      "epoch:3 step:3048 [D loss: 0.732628, acc: 52.34%] [G loss: 1.446817]\n",
      "epoch:3 step:3049 [D loss: 0.740716, acc: 47.66%] [G loss: 1.460683]\n",
      "epoch:3 step:3050 [D loss: 0.729346, acc: 48.44%] [G loss: 1.550581]\n",
      "epoch:3 step:3051 [D loss: 0.701283, acc: 50.78%] [G loss: 1.658510]\n",
      "epoch:3 step:3052 [D loss: 0.727830, acc: 48.44%] [G loss: 1.621546]\n",
      "epoch:3 step:3053 [D loss: 0.742959, acc: 46.88%] [G loss: 1.673047]\n",
      "epoch:3 step:3054 [D loss: 0.686070, acc: 59.38%] [G loss: 1.576082]\n",
      "epoch:3 step:3055 [D loss: 0.724369, acc: 52.34%] [G loss: 1.424783]\n",
      "epoch:3 step:3056 [D loss: 0.731999, acc: 51.56%] [G loss: 1.663253]\n",
      "epoch:3 step:3057 [D loss: 0.747543, acc: 51.56%] [G loss: 1.599280]\n",
      "epoch:3 step:3058 [D loss: 0.776585, acc: 39.84%] [G loss: 1.641875]\n",
      "epoch:3 step:3059 [D loss: 0.721145, acc: 43.75%] [G loss: 1.636403]\n",
      "epoch:3 step:3060 [D loss: 0.706464, acc: 52.34%] [G loss: 1.719083]\n",
      "epoch:3 step:3061 [D loss: 0.739455, acc: 52.34%] [G loss: 1.655209]\n",
      "epoch:3 step:3062 [D loss: 0.586143, acc: 71.88%] [G loss: 1.690107]\n",
      "epoch:3 step:3063 [D loss: 0.663387, acc: 59.38%] [G loss: 1.611290]\n",
      "epoch:3 step:3064 [D loss: 0.708546, acc: 53.12%] [G loss: 1.665200]\n",
      "epoch:3 step:3065 [D loss: 0.702186, acc: 57.81%] [G loss: 1.712235]\n",
      "epoch:3 step:3066 [D loss: 0.712552, acc: 49.22%] [G loss: 1.503969]\n",
      "epoch:3 step:3067 [D loss: 0.687536, acc: 59.38%] [G loss: 1.616576]\n",
      "epoch:3 step:3068 [D loss: 0.703653, acc: 55.47%] [G loss: 1.780726]\n",
      "epoch:3 step:3069 [D loss: 0.736748, acc: 53.12%] [G loss: 1.652452]\n",
      "epoch:3 step:3070 [D loss: 0.715975, acc: 53.12%] [G loss: 1.614120]\n",
      "epoch:3 step:3071 [D loss: 0.664475, acc: 55.47%] [G loss: 1.604735]\n",
      "epoch:3 step:3072 [D loss: 0.728648, acc: 50.00%] [G loss: 1.666096]\n",
      "epoch:3 step:3073 [D loss: 0.703434, acc: 57.81%] [G loss: 1.681368]\n",
      "epoch:3 step:3074 [D loss: 0.731233, acc: 56.25%] [G loss: 1.730134]\n",
      "epoch:3 step:3075 [D loss: 0.720283, acc: 46.88%] [G loss: 1.598565]\n",
      "epoch:3 step:3076 [D loss: 0.689919, acc: 61.72%] [G loss: 1.652565]\n",
      "epoch:3 step:3077 [D loss: 0.650967, acc: 59.38%] [G loss: 1.557836]\n",
      "epoch:3 step:3078 [D loss: 0.680215, acc: 57.03%] [G loss: 1.672244]\n",
      "epoch:3 step:3079 [D loss: 0.694322, acc: 58.59%] [G loss: 1.732304]\n",
      "epoch:3 step:3080 [D loss: 0.736248, acc: 45.31%] [G loss: 1.538684]\n",
      "epoch:3 step:3081 [D loss: 0.701945, acc: 53.12%] [G loss: 1.592669]\n",
      "epoch:3 step:3082 [D loss: 0.756909, acc: 52.34%] [G loss: 1.640861]\n",
      "epoch:3 step:3083 [D loss: 0.790553, acc: 42.97%] [G loss: 1.663925]\n",
      "epoch:3 step:3084 [D loss: 0.714991, acc: 57.03%] [G loss: 1.586003]\n",
      "epoch:3 step:3085 [D loss: 0.783023, acc: 38.28%] [G loss: 1.590325]\n",
      "epoch:3 step:3086 [D loss: 0.768355, acc: 46.09%] [G loss: 1.645353]\n",
      "epoch:3 step:3087 [D loss: 0.772871, acc: 42.97%] [G loss: 1.561063]\n",
      "epoch:3 step:3088 [D loss: 0.716334, acc: 56.25%] [G loss: 1.583967]\n",
      "epoch:3 step:3089 [D loss: 0.746344, acc: 44.53%] [G loss: 1.494038]\n",
      "epoch:3 step:3090 [D loss: 0.734769, acc: 48.44%] [G loss: 1.545257]\n",
      "epoch:3 step:3091 [D loss: 0.659099, acc: 61.72%] [G loss: 1.759483]\n",
      "epoch:3 step:3092 [D loss: 0.694086, acc: 57.03%] [G loss: 1.677237]\n",
      "epoch:3 step:3093 [D loss: 0.717213, acc: 53.91%] [G loss: 1.625224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3094 [D loss: 0.761109, acc: 42.19%] [G loss: 1.537071]\n",
      "epoch:3 step:3095 [D loss: 0.694854, acc: 52.34%] [G loss: 1.630102]\n",
      "epoch:3 step:3096 [D loss: 0.656317, acc: 59.38%] [G loss: 1.766947]\n",
      "epoch:3 step:3097 [D loss: 0.711487, acc: 46.88%] [G loss: 1.728069]\n",
      "epoch:3 step:3098 [D loss: 0.657780, acc: 63.28%] [G loss: 1.519176]\n",
      "epoch:3 step:3099 [D loss: 0.685580, acc: 53.91%] [G loss: 1.805148]\n",
      "epoch:3 step:3100 [D loss: 0.676234, acc: 53.12%] [G loss: 1.627869]\n",
      "epoch:3 step:3101 [D loss: 0.735134, acc: 48.44%] [G loss: 1.626166]\n",
      "epoch:3 step:3102 [D loss: 0.762406, acc: 48.44%] [G loss: 1.661663]\n",
      "epoch:3 step:3103 [D loss: 0.664983, acc: 60.94%] [G loss: 1.695548]\n",
      "epoch:3 step:3104 [D loss: 0.699927, acc: 53.91%] [G loss: 1.693029]\n",
      "epoch:3 step:3105 [D loss: 0.709911, acc: 48.44%] [G loss: 1.710300]\n",
      "epoch:3 step:3106 [D loss: 0.718395, acc: 55.47%] [G loss: 1.617897]\n",
      "epoch:3 step:3107 [D loss: 0.708002, acc: 51.56%] [G loss: 1.609999]\n",
      "epoch:3 step:3108 [D loss: 0.710108, acc: 53.12%] [G loss: 1.678499]\n",
      "epoch:3 step:3109 [D loss: 0.682731, acc: 58.59%] [G loss: 1.651146]\n",
      "epoch:3 step:3110 [D loss: 0.696289, acc: 60.94%] [G loss: 1.726088]\n",
      "epoch:3 step:3111 [D loss: 0.697809, acc: 57.81%] [G loss: 1.701962]\n",
      "epoch:3 step:3112 [D loss: 0.667705, acc: 61.72%] [G loss: 1.739204]\n",
      "epoch:3 step:3113 [D loss: 0.724002, acc: 51.56%] [G loss: 1.635654]\n",
      "epoch:3 step:3114 [D loss: 0.754598, acc: 45.31%] [G loss: 1.547921]\n",
      "epoch:3 step:3115 [D loss: 0.736610, acc: 52.34%] [G loss: 1.637320]\n",
      "epoch:3 step:3116 [D loss: 0.746464, acc: 50.78%] [G loss: 1.667489]\n",
      "epoch:3 step:3117 [D loss: 0.664928, acc: 57.03%] [G loss: 1.755426]\n",
      "epoch:3 step:3118 [D loss: 0.734306, acc: 48.44%] [G loss: 1.639241]\n",
      "epoch:3 step:3119 [D loss: 0.697401, acc: 50.78%] [G loss: 1.629059]\n",
      "epoch:3 step:3120 [D loss: 0.797464, acc: 35.16%] [G loss: 1.482080]\n",
      "epoch:3 step:3121 [D loss: 0.674606, acc: 52.34%] [G loss: 1.599998]\n",
      "epoch:3 step:3122 [D loss: 0.686309, acc: 59.38%] [G loss: 1.653667]\n",
      "epoch:3 step:3123 [D loss: 0.773699, acc: 45.31%] [G loss: 1.643990]\n",
      "epoch:3 step:3124 [D loss: 0.731635, acc: 48.44%] [G loss: 1.712838]\n",
      "epoch:4 step:3125 [D loss: 0.731689, acc: 46.88%] [G loss: 1.726238]\n",
      "epoch:4 step:3126 [D loss: 0.669959, acc: 59.38%] [G loss: 1.840639]\n",
      "epoch:4 step:3127 [D loss: 0.683818, acc: 57.81%] [G loss: 1.769593]\n",
      "epoch:4 step:3128 [D loss: 0.711780, acc: 53.91%] [G loss: 1.667539]\n",
      "epoch:4 step:3129 [D loss: 0.645601, acc: 64.06%] [G loss: 1.716450]\n",
      "epoch:4 step:3130 [D loss: 0.796839, acc: 38.28%] [G loss: 1.568502]\n",
      "epoch:4 step:3131 [D loss: 0.699011, acc: 58.59%] [G loss: 1.808005]\n",
      "epoch:4 step:3132 [D loss: 0.661586, acc: 61.72%] [G loss: 1.640982]\n",
      "epoch:4 step:3133 [D loss: 0.737209, acc: 50.78%] [G loss: 1.607386]\n",
      "epoch:4 step:3134 [D loss: 0.726674, acc: 52.34%] [G loss: 1.656604]\n",
      "epoch:4 step:3135 [D loss: 0.750599, acc: 52.34%] [G loss: 1.732777]\n",
      "epoch:4 step:3136 [D loss: 0.636250, acc: 64.06%] [G loss: 1.717510]\n",
      "epoch:4 step:3137 [D loss: 0.691264, acc: 55.47%] [G loss: 1.624402]\n",
      "epoch:4 step:3138 [D loss: 0.772473, acc: 43.75%] [G loss: 1.615523]\n",
      "epoch:4 step:3139 [D loss: 0.753498, acc: 47.66%] [G loss: 1.604595]\n",
      "epoch:4 step:3140 [D loss: 0.743438, acc: 45.31%] [G loss: 1.602769]\n",
      "epoch:4 step:3141 [D loss: 0.606019, acc: 69.53%] [G loss: 1.630318]\n",
      "epoch:4 step:3142 [D loss: 0.730510, acc: 49.22%] [G loss: 1.625172]\n",
      "epoch:4 step:3143 [D loss: 0.737889, acc: 42.97%] [G loss: 1.663299]\n",
      "epoch:4 step:3144 [D loss: 0.729503, acc: 53.12%] [G loss: 1.651732]\n",
      "epoch:4 step:3145 [D loss: 0.690609, acc: 57.03%] [G loss: 1.718345]\n",
      "epoch:4 step:3146 [D loss: 0.729927, acc: 55.47%] [G loss: 1.572530]\n",
      "epoch:4 step:3147 [D loss: 0.679785, acc: 60.16%] [G loss: 1.617865]\n",
      "epoch:4 step:3148 [D loss: 0.730482, acc: 57.03%] [G loss: 1.510392]\n",
      "epoch:4 step:3149 [D loss: 0.759185, acc: 47.66%] [G loss: 1.683591]\n",
      "epoch:4 step:3150 [D loss: 0.689700, acc: 64.84%] [G loss: 1.673678]\n",
      "epoch:4 step:3151 [D loss: 0.730932, acc: 50.78%] [G loss: 1.647644]\n",
      "epoch:4 step:3152 [D loss: 0.799796, acc: 40.62%] [G loss: 1.549115]\n",
      "epoch:4 step:3153 [D loss: 0.772530, acc: 47.66%] [G loss: 1.591079]\n",
      "epoch:4 step:3154 [D loss: 0.716545, acc: 53.12%] [G loss: 1.659499]\n",
      "epoch:4 step:3155 [D loss: 0.798512, acc: 39.06%] [G loss: 1.605973]\n",
      "epoch:4 step:3156 [D loss: 0.761908, acc: 43.75%] [G loss: 1.651359]\n",
      "epoch:4 step:3157 [D loss: 0.820191, acc: 34.38%] [G loss: 1.508274]\n",
      "epoch:4 step:3158 [D loss: 0.731786, acc: 46.88%] [G loss: 1.635575]\n",
      "epoch:4 step:3159 [D loss: 0.782037, acc: 39.84%] [G loss: 1.543621]\n",
      "epoch:4 step:3160 [D loss: 0.791182, acc: 47.66%] [G loss: 1.660820]\n",
      "epoch:4 step:3161 [D loss: 0.693971, acc: 53.91%] [G loss: 1.555352]\n",
      "epoch:4 step:3162 [D loss: 0.720953, acc: 51.56%] [G loss: 1.561395]\n",
      "epoch:4 step:3163 [D loss: 0.696826, acc: 55.47%] [G loss: 1.635293]\n",
      "epoch:4 step:3164 [D loss: 0.649334, acc: 61.72%] [G loss: 1.619188]\n",
      "epoch:4 step:3165 [D loss: 0.742940, acc: 45.31%] [G loss: 1.526196]\n",
      "epoch:4 step:3166 [D loss: 0.616583, acc: 67.97%] [G loss: 1.675105]\n",
      "epoch:4 step:3167 [D loss: 0.721811, acc: 53.91%] [G loss: 1.694251]\n",
      "epoch:4 step:3168 [D loss: 0.723623, acc: 48.44%] [G loss: 1.917901]\n",
      "epoch:4 step:3169 [D loss: 0.745837, acc: 45.31%] [G loss: 1.863674]\n",
      "epoch:4 step:3170 [D loss: 0.694065, acc: 59.38%] [G loss: 1.818735]\n",
      "epoch:4 step:3171 [D loss: 0.723805, acc: 51.56%] [G loss: 1.734429]\n",
      "epoch:4 step:3172 [D loss: 0.623839, acc: 63.28%] [G loss: 2.013740]\n",
      "epoch:4 step:3173 [D loss: 0.755404, acc: 46.09%] [G loss: 1.669179]\n",
      "epoch:4 step:3174 [D loss: 0.640115, acc: 65.62%] [G loss: 1.778123]\n",
      "epoch:4 step:3175 [D loss: 0.669894, acc: 58.59%] [G loss: 1.780514]\n",
      "epoch:4 step:3176 [D loss: 0.692991, acc: 58.59%] [G loss: 1.644973]\n",
      "epoch:4 step:3177 [D loss: 0.716577, acc: 42.97%] [G loss: 1.659813]\n",
      "epoch:4 step:3178 [D loss: 0.626011, acc: 62.50%] [G loss: 1.953144]\n",
      "epoch:4 step:3179 [D loss: 0.739256, acc: 53.91%] [G loss: 1.719095]\n",
      "epoch:4 step:3180 [D loss: 0.701806, acc: 55.47%] [G loss: 1.719291]\n",
      "epoch:4 step:3181 [D loss: 0.652307, acc: 63.28%] [G loss: 1.750776]\n",
      "epoch:4 step:3182 [D loss: 0.672840, acc: 60.16%] [G loss: 1.637669]\n",
      "epoch:4 step:3183 [D loss: 0.645252, acc: 61.72%] [G loss: 1.619494]\n",
      "epoch:4 step:3184 [D loss: 0.703871, acc: 50.78%] [G loss: 1.615485]\n",
      "epoch:4 step:3185 [D loss: 0.687852, acc: 55.47%] [G loss: 1.644205]\n",
      "epoch:4 step:3186 [D loss: 0.728139, acc: 47.66%] [G loss: 1.454897]\n",
      "epoch:4 step:3187 [D loss: 0.757356, acc: 45.31%] [G loss: 1.621215]\n",
      "epoch:4 step:3188 [D loss: 0.716140, acc: 54.69%] [G loss: 1.783484]\n",
      "epoch:4 step:3189 [D loss: 0.579753, acc: 71.09%] [G loss: 1.772187]\n",
      "epoch:4 step:3190 [D loss: 0.773266, acc: 47.66%] [G loss: 1.691652]\n",
      "epoch:4 step:3191 [D loss: 0.862706, acc: 35.16%] [G loss: 1.559153]\n",
      "epoch:4 step:3192 [D loss: 0.660899, acc: 58.59%] [G loss: 1.743702]\n",
      "epoch:4 step:3193 [D loss: 0.784531, acc: 50.78%] [G loss: 1.705867]\n",
      "epoch:4 step:3194 [D loss: 0.782780, acc: 45.31%] [G loss: 1.709496]\n",
      "epoch:4 step:3195 [D loss: 0.746820, acc: 53.12%] [G loss: 1.562762]\n",
      "epoch:4 step:3196 [D loss: 0.748584, acc: 53.12%] [G loss: 1.658900]\n",
      "epoch:4 step:3197 [D loss: 0.672871, acc: 54.69%] [G loss: 1.708678]\n",
      "epoch:4 step:3198 [D loss: 0.713859, acc: 51.56%] [G loss: 1.784956]\n",
      "epoch:4 step:3199 [D loss: 0.680123, acc: 61.72%] [G loss: 1.830779]\n",
      "epoch:4 step:3200 [D loss: 0.623447, acc: 59.38%] [G loss: 1.915917]\n",
      "epoch:4 step:3201 [D loss: 0.628207, acc: 67.97%] [G loss: 1.726566]\n",
      "epoch:4 step:3202 [D loss: 0.634133, acc: 62.50%] [G loss: 1.837046]\n",
      "epoch:4 step:3203 [D loss: 0.572336, acc: 71.09%] [G loss: 1.883147]\n",
      "epoch:4 step:3204 [D loss: 0.734196, acc: 51.56%] [G loss: 1.688846]\n",
      "epoch:4 step:3205 [D loss: 0.747843, acc: 46.88%] [G loss: 1.660083]\n",
      "epoch:4 step:3206 [D loss: 0.702744, acc: 55.47%] [G loss: 1.721632]\n",
      "epoch:4 step:3207 [D loss: 0.706867, acc: 50.00%] [G loss: 1.618744]\n",
      "epoch:4 step:3208 [D loss: 0.679407, acc: 55.47%] [G loss: 1.548436]\n",
      "epoch:4 step:3209 [D loss: 0.631543, acc: 68.75%] [G loss: 1.924904]\n",
      "epoch:4 step:3210 [D loss: 0.711429, acc: 47.66%] [G loss: 1.671200]\n",
      "epoch:4 step:3211 [D loss: 0.701146, acc: 52.34%] [G loss: 1.623286]\n",
      "epoch:4 step:3212 [D loss: 0.716109, acc: 50.00%] [G loss: 1.711230]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3213 [D loss: 0.707501, acc: 57.03%] [G loss: 1.879744]\n",
      "epoch:4 step:3214 [D loss: 0.807775, acc: 42.19%] [G loss: 1.629774]\n",
      "epoch:4 step:3215 [D loss: 0.715567, acc: 53.12%] [G loss: 1.649174]\n",
      "epoch:4 step:3216 [D loss: 0.689168, acc: 63.28%] [G loss: 1.599504]\n",
      "epoch:4 step:3217 [D loss: 0.654281, acc: 65.62%] [G loss: 1.738482]\n",
      "epoch:4 step:3218 [D loss: 0.686454, acc: 60.94%] [G loss: 1.569138]\n",
      "epoch:4 step:3219 [D loss: 0.692756, acc: 64.06%] [G loss: 1.692847]\n",
      "epoch:4 step:3220 [D loss: 0.711334, acc: 52.34%] [G loss: 1.517280]\n",
      "epoch:4 step:3221 [D loss: 0.682691, acc: 61.72%] [G loss: 1.567811]\n",
      "epoch:4 step:3222 [D loss: 0.680425, acc: 56.25%] [G loss: 1.693342]\n",
      "epoch:4 step:3223 [D loss: 0.683694, acc: 62.50%] [G loss: 1.627607]\n",
      "epoch:4 step:3224 [D loss: 0.672659, acc: 65.62%] [G loss: 1.790107]\n",
      "epoch:4 step:3225 [D loss: 0.644677, acc: 64.84%] [G loss: 1.437670]\n",
      "epoch:4 step:3226 [D loss: 0.663408, acc: 60.16%] [G loss: 1.521959]\n",
      "epoch:4 step:3227 [D loss: 0.737296, acc: 47.66%] [G loss: 1.589208]\n",
      "epoch:4 step:3228 [D loss: 0.893071, acc: 29.69%] [G loss: 1.419363]\n",
      "epoch:4 step:3229 [D loss: 0.815905, acc: 32.81%] [G loss: 1.584044]\n",
      "epoch:4 step:3230 [D loss: 0.657221, acc: 63.28%] [G loss: 1.699155]\n",
      "epoch:4 step:3231 [D loss: 0.726904, acc: 50.78%] [G loss: 1.696668]\n",
      "epoch:4 step:3232 [D loss: 0.667577, acc: 60.94%] [G loss: 1.773985]\n",
      "epoch:4 step:3233 [D loss: 0.683267, acc: 57.03%] [G loss: 1.635820]\n",
      "epoch:4 step:3234 [D loss: 0.719160, acc: 48.44%] [G loss: 1.568434]\n",
      "epoch:4 step:3235 [D loss: 0.691184, acc: 56.25%] [G loss: 1.625852]\n",
      "epoch:4 step:3236 [D loss: 0.723928, acc: 51.56%] [G loss: 1.607750]\n",
      "epoch:4 step:3237 [D loss: 0.726024, acc: 50.00%] [G loss: 1.655709]\n",
      "epoch:4 step:3238 [D loss: 0.688667, acc: 60.94%] [G loss: 1.590074]\n",
      "epoch:4 step:3239 [D loss: 0.690228, acc: 53.91%] [G loss: 1.643502]\n",
      "epoch:4 step:3240 [D loss: 0.708777, acc: 54.69%] [G loss: 1.641713]\n",
      "epoch:4 step:3241 [D loss: 0.759102, acc: 48.44%] [G loss: 1.494076]\n",
      "epoch:4 step:3242 [D loss: 0.739271, acc: 50.78%] [G loss: 1.613848]\n",
      "epoch:4 step:3243 [D loss: 0.735844, acc: 47.66%] [G loss: 1.708533]\n",
      "epoch:4 step:3244 [D loss: 0.700673, acc: 53.12%] [G loss: 1.529678]\n",
      "epoch:4 step:3245 [D loss: 0.724312, acc: 54.69%] [G loss: 1.572890]\n",
      "epoch:4 step:3246 [D loss: 0.710849, acc: 57.81%] [G loss: 1.593211]\n",
      "epoch:4 step:3247 [D loss: 0.771386, acc: 44.53%] [G loss: 1.545838]\n",
      "epoch:4 step:3248 [D loss: 0.751550, acc: 44.53%] [G loss: 1.544990]\n",
      "epoch:4 step:3249 [D loss: 0.716460, acc: 53.12%] [G loss: 1.531260]\n",
      "epoch:4 step:3250 [D loss: 0.734092, acc: 45.31%] [G loss: 1.601642]\n",
      "epoch:4 step:3251 [D loss: 0.690699, acc: 53.12%] [G loss: 1.541598]\n",
      "epoch:4 step:3252 [D loss: 0.618332, acc: 71.09%] [G loss: 1.617444]\n",
      "epoch:4 step:3253 [D loss: 0.697886, acc: 53.91%] [G loss: 1.579094]\n",
      "epoch:4 step:3254 [D loss: 0.689110, acc: 60.16%] [G loss: 1.777138]\n",
      "epoch:4 step:3255 [D loss: 0.627726, acc: 64.06%] [G loss: 1.719388]\n",
      "epoch:4 step:3256 [D loss: 0.843857, acc: 32.81%] [G loss: 1.609565]\n",
      "epoch:4 step:3257 [D loss: 0.673661, acc: 58.59%] [G loss: 1.847081]\n",
      "epoch:4 step:3258 [D loss: 0.700058, acc: 53.91%] [G loss: 1.694349]\n",
      "epoch:4 step:3259 [D loss: 0.697707, acc: 57.81%] [G loss: 1.647374]\n",
      "epoch:4 step:3260 [D loss: 0.598242, acc: 69.53%] [G loss: 1.906623]\n",
      "epoch:4 step:3261 [D loss: 0.763255, acc: 43.75%] [G loss: 1.627179]\n",
      "epoch:4 step:3262 [D loss: 0.673011, acc: 58.59%] [G loss: 1.661730]\n",
      "epoch:4 step:3263 [D loss: 0.618709, acc: 71.09%] [G loss: 1.750025]\n",
      "epoch:4 step:3264 [D loss: 0.675234, acc: 61.72%] [G loss: 1.760118]\n",
      "epoch:4 step:3265 [D loss: 0.690451, acc: 56.25%] [G loss: 1.690488]\n",
      "epoch:4 step:3266 [D loss: 0.673187, acc: 59.38%] [G loss: 1.753390]\n",
      "epoch:4 step:3267 [D loss: 0.669692, acc: 62.50%] [G loss: 1.801765]\n",
      "epoch:4 step:3268 [D loss: 0.687521, acc: 54.69%] [G loss: 1.607255]\n",
      "epoch:4 step:3269 [D loss: 0.788547, acc: 45.31%] [G loss: 1.516267]\n",
      "epoch:4 step:3270 [D loss: 0.692025, acc: 57.03%] [G loss: 1.595614]\n",
      "epoch:4 step:3271 [D loss: 0.718851, acc: 57.81%] [G loss: 1.782403]\n",
      "epoch:4 step:3272 [D loss: 0.677611, acc: 59.38%] [G loss: 1.666188]\n",
      "epoch:4 step:3273 [D loss: 0.809353, acc: 42.19%] [G loss: 1.649560]\n",
      "epoch:4 step:3274 [D loss: 0.753931, acc: 52.34%] [G loss: 1.609664]\n",
      "epoch:4 step:3275 [D loss: 0.714406, acc: 50.78%] [G loss: 1.566271]\n",
      "epoch:4 step:3276 [D loss: 0.665480, acc: 67.97%] [G loss: 1.662620]\n",
      "epoch:4 step:3277 [D loss: 0.718374, acc: 52.34%] [G loss: 1.666206]\n",
      "epoch:4 step:3278 [D loss: 0.651781, acc: 54.69%] [G loss: 1.643481]\n",
      "epoch:4 step:3279 [D loss: 0.709115, acc: 59.38%] [G loss: 1.702037]\n",
      "epoch:4 step:3280 [D loss: 0.636811, acc: 69.53%] [G loss: 1.621903]\n",
      "epoch:4 step:3281 [D loss: 0.748743, acc: 40.62%] [G loss: 1.606513]\n",
      "epoch:4 step:3282 [D loss: 0.753636, acc: 46.09%] [G loss: 1.481321]\n",
      "epoch:4 step:3283 [D loss: 0.757367, acc: 46.09%] [G loss: 1.463357]\n",
      "epoch:4 step:3284 [D loss: 0.699380, acc: 50.78%] [G loss: 1.489228]\n",
      "epoch:4 step:3285 [D loss: 0.746908, acc: 45.31%] [G loss: 1.505718]\n",
      "epoch:4 step:3286 [D loss: 0.663140, acc: 59.38%] [G loss: 1.643239]\n",
      "epoch:4 step:3287 [D loss: 0.680135, acc: 53.12%] [G loss: 1.559592]\n",
      "epoch:4 step:3288 [D loss: 0.754666, acc: 42.97%] [G loss: 1.524300]\n",
      "epoch:4 step:3289 [D loss: 0.661860, acc: 62.50%] [G loss: 1.596833]\n",
      "epoch:4 step:3290 [D loss: 0.715998, acc: 51.56%] [G loss: 1.538314]\n",
      "epoch:4 step:3291 [D loss: 0.686128, acc: 58.59%] [G loss: 1.648359]\n",
      "epoch:4 step:3292 [D loss: 0.650112, acc: 65.62%] [G loss: 1.666077]\n",
      "epoch:4 step:3293 [D loss: 0.736746, acc: 55.47%] [G loss: 1.667044]\n",
      "epoch:4 step:3294 [D loss: 0.704739, acc: 53.12%] [G loss: 1.659311]\n",
      "epoch:4 step:3295 [D loss: 0.749794, acc: 42.97%] [G loss: 1.464978]\n",
      "epoch:4 step:3296 [D loss: 0.694300, acc: 59.38%] [G loss: 1.559433]\n",
      "epoch:4 step:3297 [D loss: 0.700915, acc: 57.81%] [G loss: 1.544953]\n",
      "epoch:4 step:3298 [D loss: 0.712076, acc: 53.12%] [G loss: 1.599019]\n",
      "epoch:4 step:3299 [D loss: 0.741589, acc: 45.31%] [G loss: 1.554389]\n",
      "epoch:4 step:3300 [D loss: 0.714692, acc: 50.00%] [G loss: 1.617902]\n",
      "epoch:4 step:3301 [D loss: 0.721154, acc: 48.44%] [G loss: 1.586292]\n",
      "epoch:4 step:3302 [D loss: 0.748423, acc: 46.09%] [G loss: 1.641727]\n",
      "epoch:4 step:3303 [D loss: 0.771847, acc: 42.97%] [G loss: 1.534913]\n",
      "epoch:4 step:3304 [D loss: 0.721663, acc: 55.47%] [G loss: 1.581526]\n",
      "epoch:4 step:3305 [D loss: 0.739255, acc: 50.78%] [G loss: 1.565842]\n",
      "epoch:4 step:3306 [D loss: 0.676895, acc: 57.03%] [G loss: 1.673341]\n",
      "epoch:4 step:3307 [D loss: 0.746221, acc: 46.09%] [G loss: 1.605096]\n",
      "epoch:4 step:3308 [D loss: 0.729071, acc: 50.78%] [G loss: 1.535234]\n",
      "epoch:4 step:3309 [D loss: 0.744582, acc: 42.97%] [G loss: 1.533490]\n",
      "epoch:4 step:3310 [D loss: 0.735338, acc: 55.47%] [G loss: 1.582680]\n",
      "epoch:4 step:3311 [D loss: 0.719418, acc: 53.12%] [G loss: 1.676583]\n",
      "epoch:4 step:3312 [D loss: 0.756458, acc: 42.19%] [G loss: 1.551329]\n",
      "epoch:4 step:3313 [D loss: 0.737458, acc: 46.88%] [G loss: 1.635561]\n",
      "epoch:4 step:3314 [D loss: 0.709903, acc: 55.47%] [G loss: 1.579179]\n",
      "epoch:4 step:3315 [D loss: 0.704835, acc: 54.69%] [G loss: 1.608681]\n",
      "epoch:4 step:3316 [D loss: 0.633904, acc: 67.97%] [G loss: 1.657401]\n",
      "epoch:4 step:3317 [D loss: 0.705060, acc: 54.69%] [G loss: 1.601224]\n",
      "epoch:4 step:3318 [D loss: 0.655177, acc: 60.94%] [G loss: 1.652171]\n",
      "epoch:4 step:3319 [D loss: 0.706810, acc: 50.00%] [G loss: 1.573828]\n",
      "epoch:4 step:3320 [D loss: 0.826391, acc: 34.38%] [G loss: 1.529777]\n",
      "epoch:4 step:3321 [D loss: 0.670971, acc: 59.38%] [G loss: 1.685231]\n",
      "epoch:4 step:3322 [D loss: 0.583817, acc: 67.97%] [G loss: 1.737220]\n",
      "epoch:4 step:3323 [D loss: 0.686872, acc: 53.12%] [G loss: 1.822042]\n",
      "epoch:4 step:3324 [D loss: 0.623417, acc: 67.97%] [G loss: 1.771109]\n",
      "epoch:4 step:3325 [D loss: 0.646334, acc: 63.28%] [G loss: 1.755595]\n",
      "epoch:4 step:3326 [D loss: 0.730681, acc: 47.66%] [G loss: 1.658075]\n",
      "epoch:4 step:3327 [D loss: 0.706425, acc: 50.78%] [G loss: 1.673054]\n",
      "epoch:4 step:3328 [D loss: 0.743975, acc: 50.00%] [G loss: 1.695496]\n",
      "epoch:4 step:3329 [D loss: 0.791706, acc: 43.75%] [G loss: 1.667084]\n",
      "epoch:4 step:3330 [D loss: 0.687373, acc: 57.03%] [G loss: 1.775976]\n",
      "epoch:4 step:3331 [D loss: 0.693510, acc: 54.69%] [G loss: 1.706976]\n",
      "epoch:4 step:3332 [D loss: 0.706098, acc: 52.34%] [G loss: 1.643757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3333 [D loss: 0.634358, acc: 64.06%] [G loss: 1.666714]\n",
      "epoch:4 step:3334 [D loss: 0.731765, acc: 55.47%] [G loss: 1.720837]\n",
      "epoch:4 step:3335 [D loss: 0.651614, acc: 59.38%] [G loss: 1.748687]\n",
      "epoch:4 step:3336 [D loss: 0.681449, acc: 53.12%] [G loss: 1.750220]\n",
      "epoch:4 step:3337 [D loss: 0.696102, acc: 60.94%] [G loss: 1.531859]\n",
      "epoch:4 step:3338 [D loss: 0.776668, acc: 46.88%] [G loss: 1.469312]\n",
      "epoch:4 step:3339 [D loss: 0.659825, acc: 59.38%] [G loss: 1.634512]\n",
      "epoch:4 step:3340 [D loss: 0.701942, acc: 53.91%] [G loss: 1.510635]\n",
      "epoch:4 step:3341 [D loss: 0.647366, acc: 60.16%] [G loss: 1.477495]\n",
      "epoch:4 step:3342 [D loss: 0.685243, acc: 56.25%] [G loss: 1.518195]\n",
      "epoch:4 step:3343 [D loss: 0.735419, acc: 50.78%] [G loss: 1.479735]\n",
      "epoch:4 step:3344 [D loss: 0.755976, acc: 47.66%] [G loss: 1.464733]\n",
      "epoch:4 step:3345 [D loss: 0.772436, acc: 46.09%] [G loss: 1.514403]\n",
      "epoch:4 step:3346 [D loss: 0.759334, acc: 48.44%] [G loss: 1.496258]\n",
      "epoch:4 step:3347 [D loss: 0.693795, acc: 60.94%] [G loss: 1.781865]\n",
      "epoch:4 step:3348 [D loss: 0.654189, acc: 59.38%] [G loss: 1.747916]\n",
      "epoch:4 step:3349 [D loss: 0.702963, acc: 56.25%] [G loss: 1.725506]\n",
      "epoch:4 step:3350 [D loss: 0.713553, acc: 53.91%] [G loss: 1.720247]\n",
      "epoch:4 step:3351 [D loss: 0.650342, acc: 65.62%] [G loss: 1.813457]\n",
      "epoch:4 step:3352 [D loss: 0.614351, acc: 64.84%] [G loss: 2.026783]\n",
      "epoch:4 step:3353 [D loss: 0.650338, acc: 64.84%] [G loss: 1.946589]\n",
      "epoch:4 step:3354 [D loss: 0.588565, acc: 70.31%] [G loss: 1.982972]\n",
      "epoch:4 step:3355 [D loss: 0.580967, acc: 74.22%] [G loss: 1.928215]\n",
      "epoch:4 step:3356 [D loss: 0.657799, acc: 57.81%] [G loss: 1.717584]\n",
      "epoch:4 step:3357 [D loss: 0.671793, acc: 58.59%] [G loss: 1.929672]\n",
      "epoch:4 step:3358 [D loss: 0.653896, acc: 56.25%] [G loss: 1.739918]\n",
      "epoch:4 step:3359 [D loss: 0.731143, acc: 54.69%] [G loss: 1.679400]\n",
      "epoch:4 step:3360 [D loss: 0.644855, acc: 67.19%] [G loss: 1.749284]\n",
      "epoch:4 step:3361 [D loss: 0.601549, acc: 70.31%] [G loss: 1.837759]\n",
      "epoch:4 step:3362 [D loss: 0.715017, acc: 56.25%] [G loss: 1.684597]\n",
      "epoch:4 step:3363 [D loss: 0.740464, acc: 43.75%] [G loss: 1.415784]\n",
      "epoch:4 step:3364 [D loss: 0.642974, acc: 63.28%] [G loss: 1.580349]\n",
      "epoch:4 step:3365 [D loss: 0.791810, acc: 45.31%] [G loss: 1.371234]\n",
      "epoch:4 step:3366 [D loss: 0.921241, acc: 25.78%] [G loss: 1.384617]\n",
      "epoch:4 step:3367 [D loss: 0.730564, acc: 54.69%] [G loss: 1.541370]\n",
      "epoch:4 step:3368 [D loss: 0.767227, acc: 42.97%] [G loss: 1.582530]\n",
      "epoch:4 step:3369 [D loss: 0.760406, acc: 41.41%] [G loss: 1.573550]\n",
      "epoch:4 step:3370 [D loss: 0.715710, acc: 56.25%] [G loss: 1.850098]\n",
      "epoch:4 step:3371 [D loss: 0.747776, acc: 49.22%] [G loss: 1.677667]\n",
      "epoch:4 step:3372 [D loss: 0.636873, acc: 65.62%] [G loss: 1.770970]\n",
      "epoch:4 step:3373 [D loss: 0.814844, acc: 37.50%] [G loss: 1.619462]\n",
      "epoch:4 step:3374 [D loss: 0.753104, acc: 50.78%] [G loss: 1.708659]\n",
      "epoch:4 step:3375 [D loss: 0.725432, acc: 49.22%] [G loss: 1.956145]\n",
      "epoch:4 step:3376 [D loss: 0.668714, acc: 61.72%] [G loss: 1.819272]\n",
      "epoch:4 step:3377 [D loss: 0.702299, acc: 54.69%] [G loss: 1.808445]\n",
      "epoch:4 step:3378 [D loss: 0.673373, acc: 61.72%] [G loss: 1.782045]\n",
      "epoch:4 step:3379 [D loss: 0.650074, acc: 61.72%] [G loss: 1.831377]\n",
      "epoch:4 step:3380 [D loss: 0.655712, acc: 66.41%] [G loss: 1.843368]\n",
      "epoch:4 step:3381 [D loss: 0.764386, acc: 47.66%] [G loss: 1.669216]\n",
      "epoch:4 step:3382 [D loss: 0.675932, acc: 58.59%] [G loss: 1.756211]\n",
      "epoch:4 step:3383 [D loss: 0.633803, acc: 66.41%] [G loss: 1.673665]\n",
      "epoch:4 step:3384 [D loss: 0.746803, acc: 53.12%] [G loss: 1.737491]\n",
      "epoch:4 step:3385 [D loss: 0.751915, acc: 43.75%] [G loss: 1.643894]\n",
      "epoch:4 step:3386 [D loss: 0.734148, acc: 52.34%] [G loss: 1.634530]\n",
      "epoch:4 step:3387 [D loss: 0.775244, acc: 44.53%] [G loss: 1.481990]\n",
      "epoch:4 step:3388 [D loss: 0.677938, acc: 56.25%] [G loss: 1.751474]\n",
      "epoch:4 step:3389 [D loss: 0.667114, acc: 60.94%] [G loss: 1.839535]\n",
      "epoch:4 step:3390 [D loss: 0.815925, acc: 42.97%] [G loss: 1.533661]\n",
      "epoch:4 step:3391 [D loss: 0.856471, acc: 35.16%] [G loss: 1.547415]\n",
      "epoch:4 step:3392 [D loss: 0.760851, acc: 43.75%] [G loss: 1.686794]\n",
      "epoch:4 step:3393 [D loss: 0.779470, acc: 36.72%] [G loss: 1.661579]\n",
      "epoch:4 step:3394 [D loss: 0.665481, acc: 59.38%] [G loss: 1.718326]\n",
      "epoch:4 step:3395 [D loss: 0.690333, acc: 54.69%] [G loss: 1.596884]\n",
      "epoch:4 step:3396 [D loss: 0.729815, acc: 51.56%] [G loss: 1.628725]\n",
      "epoch:4 step:3397 [D loss: 0.750101, acc: 48.44%] [G loss: 1.753647]\n",
      "epoch:4 step:3398 [D loss: 0.761964, acc: 46.09%] [G loss: 1.512146]\n",
      "epoch:4 step:3399 [D loss: 0.705670, acc: 55.47%] [G loss: 1.569963]\n",
      "epoch:4 step:3400 [D loss: 0.710838, acc: 53.91%] [G loss: 1.617862]\n",
      "epoch:4 step:3401 [D loss: 0.729083, acc: 47.66%] [G loss: 1.696039]\n",
      "epoch:4 step:3402 [D loss: 0.755778, acc: 42.19%] [G loss: 1.570539]\n",
      "epoch:4 step:3403 [D loss: 0.686981, acc: 60.94%] [G loss: 1.565375]\n",
      "epoch:4 step:3404 [D loss: 0.710796, acc: 55.47%] [G loss: 1.772117]\n",
      "epoch:4 step:3405 [D loss: 0.764553, acc: 44.53%] [G loss: 1.562527]\n",
      "epoch:4 step:3406 [D loss: 0.702412, acc: 53.12%] [G loss: 1.717196]\n",
      "epoch:4 step:3407 [D loss: 0.722954, acc: 51.56%] [G loss: 1.668698]\n",
      "epoch:4 step:3408 [D loss: 0.684876, acc: 60.94%] [G loss: 1.775054]\n",
      "epoch:4 step:3409 [D loss: 0.703205, acc: 50.78%] [G loss: 1.662032]\n",
      "epoch:4 step:3410 [D loss: 0.634861, acc: 66.41%] [G loss: 1.902416]\n",
      "epoch:4 step:3411 [D loss: 0.738935, acc: 53.91%] [G loss: 1.740052]\n",
      "epoch:4 step:3412 [D loss: 0.731416, acc: 50.78%] [G loss: 1.809515]\n",
      "epoch:4 step:3413 [D loss: 0.653784, acc: 67.97%] [G loss: 1.820336]\n",
      "epoch:4 step:3414 [D loss: 0.645938, acc: 60.16%] [G loss: 1.699801]\n",
      "epoch:4 step:3415 [D loss: 0.777987, acc: 46.09%] [G loss: 1.622871]\n",
      "epoch:4 step:3416 [D loss: 0.738570, acc: 50.00%] [G loss: 1.714996]\n",
      "epoch:4 step:3417 [D loss: 0.794807, acc: 42.19%] [G loss: 1.525728]\n",
      "epoch:4 step:3418 [D loss: 0.641092, acc: 64.06%] [G loss: 1.724966]\n",
      "epoch:4 step:3419 [D loss: 0.761107, acc: 51.56%] [G loss: 1.607248]\n",
      "epoch:4 step:3420 [D loss: 0.766573, acc: 39.84%] [G loss: 1.507852]\n",
      "epoch:4 step:3421 [D loss: 0.664746, acc: 60.16%] [G loss: 1.668865]\n",
      "epoch:4 step:3422 [D loss: 0.711454, acc: 46.88%] [G loss: 1.531485]\n",
      "epoch:4 step:3423 [D loss: 0.786044, acc: 43.75%] [G loss: 1.640527]\n",
      "epoch:4 step:3424 [D loss: 0.803061, acc: 35.94%] [G loss: 1.520721]\n",
      "epoch:4 step:3425 [D loss: 0.757817, acc: 45.31%] [G loss: 1.533018]\n",
      "epoch:4 step:3426 [D loss: 0.658579, acc: 61.72%] [G loss: 1.591583]\n",
      "epoch:4 step:3427 [D loss: 0.650627, acc: 58.59%] [G loss: 1.791572]\n",
      "epoch:4 step:3428 [D loss: 0.692312, acc: 57.03%] [G loss: 1.675462]\n",
      "epoch:4 step:3429 [D loss: 0.787181, acc: 39.84%] [G loss: 1.487505]\n",
      "epoch:4 step:3430 [D loss: 0.669533, acc: 57.81%] [G loss: 1.667813]\n",
      "epoch:4 step:3431 [D loss: 0.759051, acc: 43.75%] [G loss: 1.637901]\n",
      "epoch:4 step:3432 [D loss: 0.701368, acc: 53.91%] [G loss: 1.641132]\n",
      "epoch:4 step:3433 [D loss: 0.654450, acc: 62.50%] [G loss: 1.673933]\n",
      "epoch:4 step:3434 [D loss: 0.641211, acc: 67.19%] [G loss: 1.715161]\n",
      "epoch:4 step:3435 [D loss: 0.743691, acc: 46.88%] [G loss: 1.766159]\n",
      "epoch:4 step:3436 [D loss: 0.682849, acc: 60.16%] [G loss: 1.870603]\n",
      "epoch:4 step:3437 [D loss: 0.820727, acc: 35.94%] [G loss: 1.619949]\n",
      "epoch:4 step:3438 [D loss: 0.758631, acc: 39.06%] [G loss: 1.543439]\n",
      "epoch:4 step:3439 [D loss: 0.790295, acc: 45.31%] [G loss: 1.741122]\n",
      "epoch:4 step:3440 [D loss: 0.653833, acc: 63.28%] [G loss: 1.720762]\n",
      "epoch:4 step:3441 [D loss: 0.727495, acc: 50.00%] [G loss: 1.634744]\n",
      "epoch:4 step:3442 [D loss: 0.644421, acc: 63.28%] [G loss: 1.772240]\n",
      "epoch:4 step:3443 [D loss: 0.747331, acc: 46.88%] [G loss: 1.657746]\n",
      "epoch:4 step:3444 [D loss: 0.730654, acc: 46.09%] [G loss: 1.644017]\n",
      "epoch:4 step:3445 [D loss: 0.723789, acc: 47.66%] [G loss: 1.616514]\n",
      "epoch:4 step:3446 [D loss: 0.816436, acc: 42.97%] [G loss: 1.671104]\n",
      "epoch:4 step:3447 [D loss: 0.651604, acc: 61.72%] [G loss: 1.650083]\n",
      "epoch:4 step:3448 [D loss: 0.760676, acc: 46.09%] [G loss: 1.562653]\n",
      "epoch:4 step:3449 [D loss: 0.640013, acc: 65.62%] [G loss: 1.616445]\n",
      "epoch:4 step:3450 [D loss: 0.677638, acc: 56.25%] [G loss: 1.651189]\n",
      "epoch:4 step:3451 [D loss: 0.723583, acc: 47.66%] [G loss: 1.644125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3452 [D loss: 0.785686, acc: 40.62%] [G loss: 1.592797]\n",
      "epoch:4 step:3453 [D loss: 0.789865, acc: 38.28%] [G loss: 1.391583]\n",
      "epoch:4 step:3454 [D loss: 0.760348, acc: 43.75%] [G loss: 1.594287]\n",
      "epoch:4 step:3455 [D loss: 0.727236, acc: 53.12%] [G loss: 1.689590]\n",
      "epoch:4 step:3456 [D loss: 0.664623, acc: 59.38%] [G loss: 1.687098]\n",
      "epoch:4 step:3457 [D loss: 0.707793, acc: 52.34%] [G loss: 1.680854]\n",
      "epoch:4 step:3458 [D loss: 0.731421, acc: 46.88%] [G loss: 1.642620]\n",
      "epoch:4 step:3459 [D loss: 0.662709, acc: 63.28%] [G loss: 1.684024]\n",
      "epoch:4 step:3460 [D loss: 0.795409, acc: 45.31%] [G loss: 1.763179]\n",
      "epoch:4 step:3461 [D loss: 0.655388, acc: 58.59%] [G loss: 1.654237]\n",
      "epoch:4 step:3462 [D loss: 0.718304, acc: 53.12%] [G loss: 1.599293]\n",
      "epoch:4 step:3463 [D loss: 0.693584, acc: 49.22%] [G loss: 1.539062]\n",
      "epoch:4 step:3464 [D loss: 0.725191, acc: 49.22%] [G loss: 1.566672]\n",
      "epoch:4 step:3465 [D loss: 0.606849, acc: 66.41%] [G loss: 1.708812]\n",
      "epoch:4 step:3466 [D loss: 0.688598, acc: 57.81%] [G loss: 1.561701]\n",
      "epoch:4 step:3467 [D loss: 0.703900, acc: 53.12%] [G loss: 1.657732]\n",
      "epoch:4 step:3468 [D loss: 0.799907, acc: 36.72%] [G loss: 1.512989]\n",
      "epoch:4 step:3469 [D loss: 0.693916, acc: 57.03%] [G loss: 1.513540]\n",
      "epoch:4 step:3470 [D loss: 0.655674, acc: 62.50%] [G loss: 1.599526]\n",
      "epoch:4 step:3471 [D loss: 0.688835, acc: 53.91%] [G loss: 1.587472]\n",
      "epoch:4 step:3472 [D loss: 0.735821, acc: 45.31%] [G loss: 1.616460]\n",
      "epoch:4 step:3473 [D loss: 0.713093, acc: 50.00%] [G loss: 1.650959]\n",
      "epoch:4 step:3474 [D loss: 0.729761, acc: 46.88%] [G loss: 1.680733]\n",
      "epoch:4 step:3475 [D loss: 0.777532, acc: 46.09%] [G loss: 1.661007]\n",
      "epoch:4 step:3476 [D loss: 0.663889, acc: 64.06%] [G loss: 1.729623]\n",
      "epoch:4 step:3477 [D loss: 0.728441, acc: 57.81%] [G loss: 1.718847]\n",
      "epoch:4 step:3478 [D loss: 0.748862, acc: 47.66%] [G loss: 1.596791]\n",
      "epoch:4 step:3479 [D loss: 0.655130, acc: 58.59%] [G loss: 1.786833]\n",
      "epoch:4 step:3480 [D loss: 0.651852, acc: 66.41%] [G loss: 1.849503]\n",
      "epoch:4 step:3481 [D loss: 0.659570, acc: 61.72%] [G loss: 1.830040]\n",
      "epoch:4 step:3482 [D loss: 0.659730, acc: 60.94%] [G loss: 1.797170]\n",
      "epoch:4 step:3483 [D loss: 0.691304, acc: 55.47%] [G loss: 1.588048]\n",
      "epoch:4 step:3484 [D loss: 0.608238, acc: 69.53%] [G loss: 1.829910]\n",
      "epoch:4 step:3485 [D loss: 0.610357, acc: 67.97%] [G loss: 1.683039]\n",
      "epoch:4 step:3486 [D loss: 0.683034, acc: 54.69%] [G loss: 1.633730]\n",
      "epoch:4 step:3487 [D loss: 0.743013, acc: 51.56%] [G loss: 1.497580]\n",
      "epoch:4 step:3488 [D loss: 0.616349, acc: 70.31%] [G loss: 1.791550]\n",
      "epoch:4 step:3489 [D loss: 0.776878, acc: 45.31%] [G loss: 1.489679]\n",
      "epoch:4 step:3490 [D loss: 0.693176, acc: 54.69%] [G loss: 1.384404]\n",
      "epoch:4 step:3491 [D loss: 0.723893, acc: 50.78%] [G loss: 1.517589]\n",
      "epoch:4 step:3492 [D loss: 0.600897, acc: 73.44%] [G loss: 1.509075]\n",
      "epoch:4 step:3493 [D loss: 0.647711, acc: 62.50%] [G loss: 1.660999]\n",
      "epoch:4 step:3494 [D loss: 0.686692, acc: 52.34%] [G loss: 1.713934]\n",
      "epoch:4 step:3495 [D loss: 0.727619, acc: 47.66%] [G loss: 1.564597]\n",
      "epoch:4 step:3496 [D loss: 0.717771, acc: 54.69%] [G loss: 1.674537]\n",
      "epoch:4 step:3497 [D loss: 0.983213, acc: 22.66%] [G loss: 1.454080]\n",
      "epoch:4 step:3498 [D loss: 0.696536, acc: 57.03%] [G loss: 1.704079]\n",
      "epoch:4 step:3499 [D loss: 0.670337, acc: 53.91%] [G loss: 1.758831]\n",
      "epoch:4 step:3500 [D loss: 0.703068, acc: 58.59%] [G loss: 1.941972]\n",
      "epoch:4 step:3501 [D loss: 0.662227, acc: 64.84%] [G loss: 1.881005]\n",
      "epoch:4 step:3502 [D loss: 0.655608, acc: 57.81%] [G loss: 1.885165]\n",
      "epoch:4 step:3503 [D loss: 0.724185, acc: 51.56%] [G loss: 1.736522]\n",
      "epoch:4 step:3504 [D loss: 0.669399, acc: 60.16%] [G loss: 1.789457]\n",
      "epoch:4 step:3505 [D loss: 0.684491, acc: 60.16%] [G loss: 1.881033]\n",
      "epoch:4 step:3506 [D loss: 0.688061, acc: 58.59%] [G loss: 1.745871]\n",
      "epoch:4 step:3507 [D loss: 0.735213, acc: 51.56%] [G loss: 1.661828]\n",
      "epoch:4 step:3508 [D loss: 0.766918, acc: 47.66%] [G loss: 1.568859]\n",
      "epoch:4 step:3509 [D loss: 0.682407, acc: 59.38%] [G loss: 1.546191]\n",
      "epoch:4 step:3510 [D loss: 0.841782, acc: 36.72%] [G loss: 1.518223]\n",
      "epoch:4 step:3511 [D loss: 0.723232, acc: 50.00%] [G loss: 1.640842]\n",
      "epoch:4 step:3512 [D loss: 0.799520, acc: 43.75%] [G loss: 1.507587]\n",
      "epoch:4 step:3513 [D loss: 0.716155, acc: 46.88%] [G loss: 1.678962]\n",
      "epoch:4 step:3514 [D loss: 0.651238, acc: 59.38%] [G loss: 1.786771]\n",
      "epoch:4 step:3515 [D loss: 0.726069, acc: 48.44%] [G loss: 1.569325]\n",
      "epoch:4 step:3516 [D loss: 0.712521, acc: 57.03%] [G loss: 1.573668]\n",
      "epoch:4 step:3517 [D loss: 0.716097, acc: 49.22%] [G loss: 1.639710]\n",
      "epoch:4 step:3518 [D loss: 0.660689, acc: 64.06%] [G loss: 1.729971]\n",
      "epoch:4 step:3519 [D loss: 0.680378, acc: 57.03%] [G loss: 1.662477]\n",
      "epoch:4 step:3520 [D loss: 0.768643, acc: 49.22%] [G loss: 1.630197]\n",
      "epoch:4 step:3521 [D loss: 0.704081, acc: 58.59%] [G loss: 1.631468]\n",
      "epoch:4 step:3522 [D loss: 0.639192, acc: 66.41%] [G loss: 1.728426]\n",
      "epoch:4 step:3523 [D loss: 0.678981, acc: 56.25%] [G loss: 1.671260]\n",
      "epoch:4 step:3524 [D loss: 0.761835, acc: 42.97%] [G loss: 1.567355]\n",
      "epoch:4 step:3525 [D loss: 0.634166, acc: 62.50%] [G loss: 1.730723]\n",
      "epoch:4 step:3526 [D loss: 0.743700, acc: 42.97%] [G loss: 1.560352]\n",
      "epoch:4 step:3527 [D loss: 0.678573, acc: 59.38%] [G loss: 1.729234]\n",
      "epoch:4 step:3528 [D loss: 0.703327, acc: 53.12%] [G loss: 1.815886]\n",
      "epoch:4 step:3529 [D loss: 0.688677, acc: 57.03%] [G loss: 1.633949]\n",
      "epoch:4 step:3530 [D loss: 0.705976, acc: 53.12%] [G loss: 1.793935]\n",
      "epoch:4 step:3531 [D loss: 0.701343, acc: 51.56%] [G loss: 1.566474]\n",
      "epoch:4 step:3532 [D loss: 0.756437, acc: 43.75%] [G loss: 1.486067]\n",
      "epoch:4 step:3533 [D loss: 0.794261, acc: 37.50%] [G loss: 1.601286]\n",
      "epoch:4 step:3534 [D loss: 0.725921, acc: 48.44%] [G loss: 1.567130]\n",
      "epoch:4 step:3535 [D loss: 0.772607, acc: 39.84%] [G loss: 1.596877]\n",
      "epoch:4 step:3536 [D loss: 0.709500, acc: 57.81%] [G loss: 1.633728]\n",
      "epoch:4 step:3537 [D loss: 0.698164, acc: 52.34%] [G loss: 1.618655]\n",
      "epoch:4 step:3538 [D loss: 0.758454, acc: 46.88%] [G loss: 1.516323]\n",
      "epoch:4 step:3539 [D loss: 0.754760, acc: 39.84%] [G loss: 1.579570]\n",
      "epoch:4 step:3540 [D loss: 0.687518, acc: 56.25%] [G loss: 1.647915]\n",
      "epoch:4 step:3541 [D loss: 0.763815, acc: 48.44%] [G loss: 1.636027]\n",
      "epoch:4 step:3542 [D loss: 0.668581, acc: 59.38%] [G loss: 1.676329]\n",
      "epoch:4 step:3543 [D loss: 0.716755, acc: 57.81%] [G loss: 1.586877]\n",
      "epoch:4 step:3544 [D loss: 0.757706, acc: 45.31%] [G loss: 1.572859]\n",
      "epoch:4 step:3545 [D loss: 0.634312, acc: 64.84%] [G loss: 1.680486]\n",
      "epoch:4 step:3546 [D loss: 0.701830, acc: 54.69%] [G loss: 1.651490]\n",
      "epoch:4 step:3547 [D loss: 0.660966, acc: 58.59%] [G loss: 1.471501]\n",
      "epoch:4 step:3548 [D loss: 0.712625, acc: 52.34%] [G loss: 1.563892]\n",
      "epoch:4 step:3549 [D loss: 0.658830, acc: 60.94%] [G loss: 1.540389]\n",
      "epoch:4 step:3550 [D loss: 0.680776, acc: 53.12%] [G loss: 1.479603]\n",
      "epoch:4 step:3551 [D loss: 0.684101, acc: 55.47%] [G loss: 1.592932]\n",
      "epoch:4 step:3552 [D loss: 0.708119, acc: 50.00%] [G loss: 1.587774]\n",
      "epoch:4 step:3553 [D loss: 0.703200, acc: 54.69%] [G loss: 1.683798]\n",
      "epoch:4 step:3554 [D loss: 0.759800, acc: 47.66%] [G loss: 1.553604]\n",
      "epoch:4 step:3555 [D loss: 0.770691, acc: 41.41%] [G loss: 1.751002]\n",
      "epoch:4 step:3556 [D loss: 0.744795, acc: 49.22%] [G loss: 1.737355]\n",
      "epoch:4 step:3557 [D loss: 0.734805, acc: 50.00%] [G loss: 1.688766]\n",
      "epoch:4 step:3558 [D loss: 0.758472, acc: 44.53%] [G loss: 1.644789]\n",
      "epoch:4 step:3559 [D loss: 0.711322, acc: 51.56%] [G loss: 1.679056]\n",
      "epoch:4 step:3560 [D loss: 0.727130, acc: 46.88%] [G loss: 1.742800]\n",
      "epoch:4 step:3561 [D loss: 0.702933, acc: 48.44%] [G loss: 1.693841]\n",
      "epoch:4 step:3562 [D loss: 0.707951, acc: 53.91%] [G loss: 1.634413]\n",
      "epoch:4 step:3563 [D loss: 0.687628, acc: 61.72%] [G loss: 1.757140]\n",
      "epoch:4 step:3564 [D loss: 0.667409, acc: 59.38%] [G loss: 1.645366]\n",
      "epoch:4 step:3565 [D loss: 0.726372, acc: 50.78%] [G loss: 1.603005]\n",
      "epoch:4 step:3566 [D loss: 0.692078, acc: 56.25%] [G loss: 1.615773]\n",
      "epoch:4 step:3567 [D loss: 0.716755, acc: 52.34%] [G loss: 1.697250]\n",
      "epoch:4 step:3568 [D loss: 0.655172, acc: 67.19%] [G loss: 1.584095]\n",
      "epoch:4 step:3569 [D loss: 0.666135, acc: 58.59%] [G loss: 1.655263]\n",
      "epoch:4 step:3570 [D loss: 0.720436, acc: 50.00%] [G loss: 1.663661]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3571 [D loss: 0.677392, acc: 53.12%] [G loss: 1.710701]\n",
      "epoch:4 step:3572 [D loss: 0.737914, acc: 49.22%] [G loss: 1.811199]\n",
      "epoch:4 step:3573 [D loss: 0.746498, acc: 48.44%] [G loss: 1.562085]\n",
      "epoch:4 step:3574 [D loss: 0.760117, acc: 44.53%] [G loss: 1.656905]\n",
      "epoch:4 step:3575 [D loss: 0.727973, acc: 46.88%] [G loss: 1.615934]\n",
      "epoch:4 step:3576 [D loss: 0.628836, acc: 65.62%] [G loss: 1.849586]\n",
      "epoch:4 step:3577 [D loss: 0.692622, acc: 56.25%] [G loss: 1.751916]\n",
      "epoch:4 step:3578 [D loss: 0.714113, acc: 52.34%] [G loss: 1.504248]\n",
      "epoch:4 step:3579 [D loss: 0.725425, acc: 50.78%] [G loss: 1.590605]\n",
      "epoch:4 step:3580 [D loss: 0.722740, acc: 50.78%] [G loss: 1.622095]\n",
      "epoch:4 step:3581 [D loss: 0.703541, acc: 51.56%] [G loss: 1.577535]\n",
      "epoch:4 step:3582 [D loss: 0.775585, acc: 46.88%] [G loss: 1.638515]\n",
      "epoch:4 step:3583 [D loss: 0.693394, acc: 53.12%] [G loss: 1.704028]\n",
      "epoch:4 step:3584 [D loss: 0.691263, acc: 50.78%] [G loss: 1.603477]\n",
      "epoch:4 step:3585 [D loss: 0.711682, acc: 54.69%] [G loss: 1.590184]\n",
      "epoch:4 step:3586 [D loss: 0.678420, acc: 55.47%] [G loss: 1.757418]\n",
      "epoch:4 step:3587 [D loss: 0.697434, acc: 57.81%] [G loss: 1.645906]\n",
      "epoch:4 step:3588 [D loss: 0.679282, acc: 63.28%] [G loss: 1.867884]\n",
      "epoch:4 step:3589 [D loss: 0.734921, acc: 46.09%] [G loss: 1.643668]\n",
      "epoch:4 step:3590 [D loss: 0.630753, acc: 60.94%] [G loss: 1.677969]\n",
      "epoch:4 step:3591 [D loss: 0.653447, acc: 62.50%] [G loss: 1.741516]\n",
      "epoch:4 step:3592 [D loss: 0.686694, acc: 57.03%] [G loss: 1.668186]\n",
      "epoch:4 step:3593 [D loss: 0.621927, acc: 64.06%] [G loss: 1.764101]\n",
      "epoch:4 step:3594 [D loss: 0.762322, acc: 48.44%] [G loss: 1.567786]\n",
      "epoch:4 step:3595 [D loss: 0.665811, acc: 57.81%] [G loss: 1.779307]\n",
      "epoch:4 step:3596 [D loss: 0.705402, acc: 53.91%] [G loss: 1.602396]\n",
      "epoch:4 step:3597 [D loss: 0.694560, acc: 57.81%] [G loss: 1.621454]\n",
      "epoch:4 step:3598 [D loss: 0.693172, acc: 49.22%] [G loss: 1.511388]\n",
      "epoch:4 step:3599 [D loss: 0.678094, acc: 54.69%] [G loss: 1.778231]\n",
      "epoch:4 step:3600 [D loss: 0.731888, acc: 50.00%] [G loss: 1.583039]\n",
      "epoch:4 step:3601 [D loss: 0.718805, acc: 52.34%] [G loss: 1.587533]\n",
      "epoch:4 step:3602 [D loss: 0.698935, acc: 59.38%] [G loss: 1.685730]\n",
      "epoch:4 step:3603 [D loss: 0.799371, acc: 35.16%] [G loss: 1.467744]\n",
      "epoch:4 step:3604 [D loss: 0.773903, acc: 43.75%] [G loss: 1.580111]\n",
      "epoch:4 step:3605 [D loss: 0.794562, acc: 45.31%] [G loss: 1.615534]\n",
      "epoch:4 step:3606 [D loss: 0.724368, acc: 53.12%] [G loss: 1.551472]\n",
      "epoch:4 step:3607 [D loss: 0.758944, acc: 44.53%] [G loss: 1.630877]\n",
      "epoch:4 step:3608 [D loss: 0.717584, acc: 46.09%] [G loss: 1.669133]\n",
      "epoch:4 step:3609 [D loss: 0.752219, acc: 45.31%] [G loss: 1.607408]\n",
      "epoch:4 step:3610 [D loss: 0.692771, acc: 52.34%] [G loss: 1.689682]\n",
      "epoch:4 step:3611 [D loss: 0.699553, acc: 51.56%] [G loss: 1.631787]\n",
      "epoch:4 step:3612 [D loss: 0.760125, acc: 46.09%] [G loss: 1.590480]\n",
      "epoch:4 step:3613 [D loss: 0.743958, acc: 47.66%] [G loss: 1.601020]\n",
      "epoch:4 step:3614 [D loss: 0.653671, acc: 62.50%] [G loss: 1.817954]\n",
      "epoch:4 step:3615 [D loss: 0.695158, acc: 52.34%] [G loss: 1.632239]\n",
      "epoch:4 step:3616 [D loss: 0.695061, acc: 54.69%] [G loss: 1.620396]\n",
      "epoch:4 step:3617 [D loss: 0.634566, acc: 69.53%] [G loss: 1.782694]\n",
      "epoch:4 step:3618 [D loss: 0.662275, acc: 57.81%] [G loss: 1.709178]\n",
      "epoch:4 step:3619 [D loss: 0.609303, acc: 71.88%] [G loss: 1.864976]\n",
      "epoch:4 step:3620 [D loss: 0.727466, acc: 46.88%] [G loss: 1.757203]\n",
      "epoch:4 step:3621 [D loss: 0.630237, acc: 62.50%] [G loss: 1.558534]\n",
      "epoch:4 step:3622 [D loss: 0.741571, acc: 50.00%] [G loss: 1.682410]\n",
      "epoch:4 step:3623 [D loss: 0.849822, acc: 25.78%] [G loss: 1.542465]\n",
      "epoch:4 step:3624 [D loss: 0.625966, acc: 64.84%] [G loss: 1.555084]\n",
      "epoch:4 step:3625 [D loss: 0.640891, acc: 60.16%] [G loss: 1.754601]\n",
      "epoch:4 step:3626 [D loss: 0.683939, acc: 57.81%] [G loss: 1.549886]\n",
      "epoch:4 step:3627 [D loss: 0.716230, acc: 50.78%] [G loss: 1.619137]\n",
      "epoch:4 step:3628 [D loss: 0.683941, acc: 57.81%] [G loss: 1.601842]\n",
      "epoch:4 step:3629 [D loss: 0.726744, acc: 50.78%] [G loss: 1.540190]\n",
      "epoch:4 step:3630 [D loss: 0.636349, acc: 66.41%] [G loss: 1.569621]\n",
      "epoch:4 step:3631 [D loss: 0.806716, acc: 42.19%] [G loss: 1.403310]\n",
      "epoch:4 step:3632 [D loss: 0.723907, acc: 50.00%] [G loss: 1.676826]\n",
      "epoch:4 step:3633 [D loss: 0.719595, acc: 49.22%] [G loss: 1.518343]\n",
      "epoch:4 step:3634 [D loss: 0.722527, acc: 48.44%] [G loss: 1.515360]\n",
      "epoch:4 step:3635 [D loss: 0.654999, acc: 65.62%] [G loss: 1.671056]\n",
      "epoch:4 step:3636 [D loss: 0.767735, acc: 42.97%] [G loss: 1.638974]\n",
      "epoch:4 step:3637 [D loss: 0.858656, acc: 30.47%] [G loss: 1.527373]\n",
      "epoch:4 step:3638 [D loss: 0.787880, acc: 42.97%] [G loss: 1.736794]\n",
      "epoch:4 step:3639 [D loss: 0.642378, acc: 61.72%] [G loss: 1.803715]\n",
      "epoch:4 step:3640 [D loss: 0.639635, acc: 62.50%] [G loss: 1.842448]\n",
      "epoch:4 step:3641 [D loss: 0.652660, acc: 60.16%] [G loss: 1.771973]\n",
      "epoch:4 step:3642 [D loss: 0.694790, acc: 53.91%] [G loss: 1.712437]\n",
      "epoch:4 step:3643 [D loss: 0.752426, acc: 50.00%] [G loss: 1.694609]\n",
      "epoch:4 step:3644 [D loss: 0.692624, acc: 57.03%] [G loss: 1.685455]\n",
      "epoch:4 step:3645 [D loss: 0.773312, acc: 45.31%] [G loss: 1.611839]\n",
      "epoch:4 step:3646 [D loss: 0.627229, acc: 64.84%] [G loss: 1.763131]\n",
      "epoch:4 step:3647 [D loss: 0.674696, acc: 57.81%] [G loss: 1.622427]\n",
      "epoch:4 step:3648 [D loss: 0.605948, acc: 71.88%] [G loss: 1.826958]\n",
      "epoch:4 step:3649 [D loss: 0.666915, acc: 59.38%] [G loss: 1.571561]\n",
      "epoch:4 step:3650 [D loss: 0.719772, acc: 49.22%] [G loss: 1.593027]\n",
      "epoch:4 step:3651 [D loss: 0.790446, acc: 36.72%] [G loss: 1.362974]\n",
      "epoch:4 step:3652 [D loss: 0.612925, acc: 65.62%] [G loss: 1.509795]\n",
      "epoch:4 step:3653 [D loss: 0.733192, acc: 46.88%] [G loss: 1.459112]\n",
      "epoch:4 step:3654 [D loss: 0.680992, acc: 60.16%] [G loss: 1.455328]\n",
      "epoch:4 step:3655 [D loss: 0.815420, acc: 33.59%] [G loss: 1.439593]\n",
      "epoch:4 step:3656 [D loss: 0.737537, acc: 48.44%] [G loss: 1.666345]\n",
      "epoch:4 step:3657 [D loss: 0.814963, acc: 39.06%] [G loss: 1.524309]\n",
      "epoch:4 step:3658 [D loss: 0.687908, acc: 57.03%] [G loss: 1.687819]\n",
      "epoch:4 step:3659 [D loss: 0.795136, acc: 39.84%] [G loss: 1.507832]\n",
      "epoch:4 step:3660 [D loss: 0.699924, acc: 50.00%] [G loss: 1.774862]\n",
      "epoch:4 step:3661 [D loss: 0.743959, acc: 47.66%] [G loss: 1.739847]\n",
      "epoch:4 step:3662 [D loss: 0.780730, acc: 43.75%] [G loss: 1.745092]\n",
      "epoch:4 step:3663 [D loss: 0.765953, acc: 43.75%] [G loss: 1.675539]\n",
      "epoch:4 step:3664 [D loss: 0.749613, acc: 51.56%] [G loss: 1.818522]\n",
      "epoch:4 step:3665 [D loss: 0.724081, acc: 47.66%] [G loss: 1.802539]\n",
      "epoch:4 step:3666 [D loss: 0.782144, acc: 40.62%] [G loss: 1.575966]\n",
      "epoch:4 step:3667 [D loss: 0.712492, acc: 53.91%] [G loss: 1.715858]\n",
      "epoch:4 step:3668 [D loss: 0.700705, acc: 50.78%] [G loss: 1.698521]\n",
      "epoch:4 step:3669 [D loss: 0.642239, acc: 60.16%] [G loss: 1.721710]\n",
      "epoch:4 step:3670 [D loss: 0.684635, acc: 56.25%] [G loss: 1.734387]\n",
      "epoch:4 step:3671 [D loss: 0.720500, acc: 50.78%] [G loss: 1.602372]\n",
      "epoch:4 step:3672 [D loss: 0.722786, acc: 50.78%] [G loss: 1.594208]\n",
      "epoch:4 step:3673 [D loss: 0.747621, acc: 49.22%] [G loss: 1.639130]\n",
      "epoch:4 step:3674 [D loss: 0.782847, acc: 43.75%] [G loss: 1.585308]\n",
      "epoch:4 step:3675 [D loss: 0.687724, acc: 59.38%] [G loss: 1.743604]\n",
      "epoch:4 step:3676 [D loss: 0.691124, acc: 57.03%] [G loss: 1.601699]\n",
      "epoch:4 step:3677 [D loss: 0.674341, acc: 64.06%] [G loss: 1.531776]\n",
      "epoch:4 step:3678 [D loss: 0.644429, acc: 60.94%] [G loss: 1.604398]\n",
      "epoch:4 step:3679 [D loss: 0.715792, acc: 49.22%] [G loss: 1.423942]\n",
      "epoch:4 step:3680 [D loss: 0.618430, acc: 71.09%] [G loss: 1.629571]\n",
      "epoch:4 step:3681 [D loss: 0.738313, acc: 50.78%] [G loss: 1.543516]\n",
      "epoch:4 step:3682 [D loss: 0.762035, acc: 46.88%] [G loss: 1.511907]\n",
      "epoch:4 step:3683 [D loss: 0.687025, acc: 57.03%] [G loss: 1.588310]\n",
      "epoch:4 step:3684 [D loss: 0.801975, acc: 34.38%] [G loss: 1.482109]\n",
      "epoch:4 step:3685 [D loss: 0.767564, acc: 42.19%] [G loss: 1.629917]\n",
      "epoch:4 step:3686 [D loss: 0.697315, acc: 52.34%] [G loss: 1.665063]\n",
      "epoch:4 step:3687 [D loss: 0.713458, acc: 53.12%] [G loss: 1.594289]\n",
      "epoch:4 step:3688 [D loss: 0.734645, acc: 53.12%] [G loss: 1.674461]\n",
      "epoch:4 step:3689 [D loss: 0.654456, acc: 65.62%] [G loss: 1.679961]\n",
      "epoch:4 step:3690 [D loss: 0.689177, acc: 63.28%] [G loss: 1.611833]\n",
      "epoch:4 step:3691 [D loss: 0.793140, acc: 42.97%] [G loss: 1.588574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3692 [D loss: 0.644802, acc: 64.84%] [G loss: 1.614645]\n",
      "epoch:4 step:3693 [D loss: 0.654407, acc: 60.94%] [G loss: 1.594081]\n",
      "epoch:4 step:3694 [D loss: 0.613905, acc: 64.84%] [G loss: 1.596703]\n",
      "epoch:4 step:3695 [D loss: 0.621829, acc: 64.84%] [G loss: 1.618860]\n",
      "epoch:4 step:3696 [D loss: 0.665092, acc: 53.91%] [G loss: 1.588577]\n",
      "epoch:4 step:3697 [D loss: 0.588418, acc: 74.22%] [G loss: 1.570732]\n",
      "epoch:4 step:3698 [D loss: 0.747792, acc: 46.88%] [G loss: 1.292872]\n",
      "epoch:4 step:3699 [D loss: 0.647288, acc: 64.84%] [G loss: 1.571189]\n",
      "epoch:4 step:3700 [D loss: 0.600017, acc: 69.53%] [G loss: 1.624808]\n",
      "epoch:4 step:3701 [D loss: 0.692410, acc: 48.44%] [G loss: 1.502944]\n",
      "epoch:4 step:3702 [D loss: 0.728734, acc: 49.22%] [G loss: 1.568158]\n",
      "epoch:4 step:3703 [D loss: 0.727374, acc: 49.22%] [G loss: 1.545213]\n",
      "epoch:4 step:3704 [D loss: 0.792682, acc: 36.72%] [G loss: 1.470384]\n",
      "epoch:4 step:3705 [D loss: 0.678688, acc: 58.59%] [G loss: 1.560205]\n",
      "epoch:4 step:3706 [D loss: 0.721028, acc: 53.91%] [G loss: 1.488762]\n",
      "epoch:4 step:3707 [D loss: 0.765153, acc: 49.22%] [G loss: 1.701035]\n",
      "epoch:4 step:3708 [D loss: 0.659054, acc: 64.84%] [G loss: 1.677477]\n",
      "epoch:4 step:3709 [D loss: 0.836299, acc: 36.72%] [G loss: 1.498755]\n",
      "epoch:4 step:3710 [D loss: 0.729197, acc: 42.19%] [G loss: 1.630973]\n",
      "epoch:4 step:3711 [D loss: 0.741751, acc: 50.78%] [G loss: 1.678580]\n",
      "epoch:4 step:3712 [D loss: 0.781144, acc: 42.19%] [G loss: 1.633667]\n",
      "epoch:4 step:3713 [D loss: 0.695444, acc: 52.34%] [G loss: 1.590875]\n",
      "epoch:4 step:3714 [D loss: 0.672410, acc: 57.03%] [G loss: 1.669678]\n",
      "epoch:4 step:3715 [D loss: 0.688445, acc: 59.38%] [G loss: 1.560640]\n",
      "epoch:4 step:3716 [D loss: 0.646633, acc: 60.94%] [G loss: 1.685982]\n",
      "epoch:4 step:3717 [D loss: 0.770171, acc: 39.84%] [G loss: 1.522708]\n",
      "epoch:4 step:3718 [D loss: 0.676987, acc: 58.59%] [G loss: 1.658127]\n",
      "epoch:4 step:3719 [D loss: 0.737268, acc: 46.88%] [G loss: 1.434576]\n",
      "epoch:4 step:3720 [D loss: 0.694783, acc: 56.25%] [G loss: 1.613180]\n",
      "epoch:4 step:3721 [D loss: 0.677954, acc: 56.25%] [G loss: 1.528718]\n",
      "epoch:4 step:3722 [D loss: 0.733023, acc: 49.22%] [G loss: 1.509618]\n",
      "epoch:4 step:3723 [D loss: 0.738183, acc: 46.09%] [G loss: 1.532988]\n",
      "epoch:4 step:3724 [D loss: 0.692901, acc: 51.56%] [G loss: 1.503742]\n",
      "epoch:4 step:3725 [D loss: 0.775578, acc: 44.53%] [G loss: 1.636581]\n",
      "epoch:4 step:3726 [D loss: 0.702158, acc: 49.22%] [G loss: 1.555804]\n",
      "epoch:4 step:3727 [D loss: 0.682525, acc: 52.34%] [G loss: 1.688333]\n",
      "epoch:4 step:3728 [D loss: 0.781911, acc: 46.88%] [G loss: 1.797541]\n",
      "epoch:4 step:3729 [D loss: 0.670137, acc: 62.50%] [G loss: 1.679986]\n",
      "epoch:4 step:3730 [D loss: 0.703049, acc: 59.38%] [G loss: 1.829547]\n",
      "epoch:4 step:3731 [D loss: 0.666174, acc: 58.59%] [G loss: 1.719108]\n",
      "epoch:4 step:3732 [D loss: 0.781791, acc: 35.94%] [G loss: 1.603098]\n",
      "epoch:4 step:3733 [D loss: 0.764815, acc: 45.31%] [G loss: 1.474095]\n",
      "epoch:4 step:3734 [D loss: 0.678745, acc: 57.03%] [G loss: 1.493064]\n",
      "epoch:4 step:3735 [D loss: 0.664069, acc: 57.81%] [G loss: 1.561431]\n",
      "epoch:4 step:3736 [D loss: 0.658417, acc: 57.81%] [G loss: 1.591373]\n",
      "epoch:4 step:3737 [D loss: 0.745627, acc: 46.88%] [G loss: 1.521868]\n",
      "epoch:4 step:3738 [D loss: 0.742892, acc: 50.78%] [G loss: 1.484386]\n",
      "epoch:4 step:3739 [D loss: 0.717417, acc: 53.12%] [G loss: 1.544249]\n",
      "epoch:4 step:3740 [D loss: 0.713629, acc: 49.22%] [G loss: 1.513108]\n",
      "epoch:4 step:3741 [D loss: 0.714619, acc: 57.81%] [G loss: 1.575045]\n",
      "epoch:4 step:3742 [D loss: 0.695782, acc: 55.47%] [G loss: 1.559630]\n",
      "epoch:4 step:3743 [D loss: 0.744172, acc: 47.66%] [G loss: 1.600900]\n",
      "epoch:4 step:3744 [D loss: 0.674040, acc: 62.50%] [G loss: 1.652921]\n",
      "epoch:4 step:3745 [D loss: 0.716978, acc: 48.44%] [G loss: 1.761009]\n",
      "epoch:4 step:3746 [D loss: 0.660214, acc: 62.50%] [G loss: 1.737552]\n",
      "epoch:4 step:3747 [D loss: 0.692856, acc: 55.47%] [G loss: 1.826505]\n",
      "epoch:4 step:3748 [D loss: 0.709422, acc: 60.16%] [G loss: 1.613893]\n",
      "epoch:4 step:3749 [D loss: 0.696647, acc: 50.78%] [G loss: 1.617108]\n",
      "epoch:4 step:3750 [D loss: 0.761531, acc: 43.75%] [G loss: 1.520896]\n",
      "epoch:4 step:3751 [D loss: 0.739926, acc: 49.22%] [G loss: 1.722163]\n",
      "epoch:4 step:3752 [D loss: 0.739447, acc: 46.09%] [G loss: 1.534515]\n",
      "epoch:4 step:3753 [D loss: 0.713874, acc: 56.25%] [G loss: 1.584850]\n",
      "epoch:4 step:3754 [D loss: 0.685018, acc: 57.81%] [G loss: 1.591907]\n",
      "epoch:4 step:3755 [D loss: 0.736849, acc: 45.31%] [G loss: 1.548883]\n",
      "epoch:4 step:3756 [D loss: 0.739064, acc: 46.09%] [G loss: 1.596204]\n",
      "epoch:4 step:3757 [D loss: 0.726911, acc: 54.69%] [G loss: 1.524412]\n",
      "epoch:4 step:3758 [D loss: 0.636954, acc: 64.84%] [G loss: 1.662165]\n",
      "epoch:4 step:3759 [D loss: 0.678449, acc: 57.81%] [G loss: 1.537611]\n",
      "epoch:4 step:3760 [D loss: 0.581376, acc: 73.44%] [G loss: 1.741732]\n",
      "epoch:4 step:3761 [D loss: 0.770186, acc: 43.75%] [G loss: 1.519613]\n",
      "epoch:4 step:3762 [D loss: 0.698657, acc: 54.69%] [G loss: 1.716858]\n",
      "epoch:4 step:3763 [D loss: 0.736428, acc: 50.78%] [G loss: 1.483277]\n",
      "epoch:4 step:3764 [D loss: 0.773654, acc: 46.09%] [G loss: 1.548636]\n",
      "epoch:4 step:3765 [D loss: 0.729276, acc: 51.56%] [G loss: 1.482794]\n",
      "epoch:4 step:3766 [D loss: 0.660283, acc: 62.50%] [G loss: 1.805375]\n",
      "epoch:4 step:3767 [D loss: 0.665064, acc: 57.03%] [G loss: 1.740202]\n",
      "epoch:4 step:3768 [D loss: 0.714483, acc: 50.00%] [G loss: 1.568427]\n",
      "epoch:4 step:3769 [D loss: 0.745607, acc: 45.31%] [G loss: 1.606410]\n",
      "epoch:4 step:3770 [D loss: 0.726298, acc: 49.22%] [G loss: 1.750400]\n",
      "epoch:4 step:3771 [D loss: 0.671937, acc: 61.72%] [G loss: 1.710255]\n",
      "epoch:4 step:3772 [D loss: 0.800011, acc: 42.97%] [G loss: 1.706990]\n",
      "epoch:4 step:3773 [D loss: 0.745481, acc: 45.31%] [G loss: 1.643200]\n",
      "epoch:4 step:3774 [D loss: 0.713687, acc: 57.81%] [G loss: 1.599476]\n",
      "epoch:4 step:3775 [D loss: 0.580981, acc: 78.12%] [G loss: 1.804316]\n",
      "epoch:4 step:3776 [D loss: 0.699147, acc: 54.69%] [G loss: 1.618482]\n",
      "epoch:4 step:3777 [D loss: 0.739930, acc: 51.56%] [G loss: 1.607809]\n",
      "epoch:4 step:3778 [D loss: 0.658641, acc: 59.38%] [G loss: 1.520872]\n",
      "epoch:4 step:3779 [D loss: 0.623616, acc: 64.84%] [G loss: 1.748865]\n",
      "epoch:4 step:3780 [D loss: 0.836485, acc: 35.94%] [G loss: 1.393946]\n",
      "epoch:4 step:3781 [D loss: 0.718295, acc: 49.22%] [G loss: 1.656548]\n",
      "epoch:4 step:3782 [D loss: 0.689632, acc: 56.25%] [G loss: 1.843997]\n",
      "epoch:4 step:3783 [D loss: 0.648394, acc: 60.94%] [G loss: 1.742821]\n",
      "epoch:4 step:3784 [D loss: 0.641461, acc: 63.28%] [G loss: 1.626042]\n",
      "epoch:4 step:3785 [D loss: 0.696478, acc: 57.03%] [G loss: 1.719553]\n",
      "epoch:4 step:3786 [D loss: 0.625440, acc: 65.62%] [G loss: 1.709750]\n",
      "epoch:4 step:3787 [D loss: 0.670741, acc: 58.59%] [G loss: 1.756124]\n",
      "epoch:4 step:3788 [D loss: 0.708591, acc: 55.47%] [G loss: 1.634672]\n",
      "epoch:4 step:3789 [D loss: 0.726911, acc: 46.09%] [G loss: 1.720308]\n",
      "epoch:4 step:3790 [D loss: 0.673028, acc: 59.38%] [G loss: 1.794570]\n",
      "epoch:4 step:3791 [D loss: 0.698363, acc: 55.47%] [G loss: 1.756219]\n",
      "epoch:4 step:3792 [D loss: 0.666566, acc: 60.16%] [G loss: 1.823591]\n",
      "epoch:4 step:3793 [D loss: 0.748568, acc: 50.00%] [G loss: 1.675827]\n",
      "epoch:4 step:3794 [D loss: 0.615574, acc: 67.19%] [G loss: 1.688412]\n",
      "epoch:4 step:3795 [D loss: 0.739797, acc: 51.56%] [G loss: 1.584518]\n",
      "epoch:4 step:3796 [D loss: 0.743103, acc: 49.22%] [G loss: 1.811470]\n",
      "epoch:4 step:3797 [D loss: 0.707487, acc: 53.91%] [G loss: 1.817483]\n",
      "epoch:4 step:3798 [D loss: 0.636285, acc: 60.94%] [G loss: 1.997807]\n",
      "epoch:4 step:3799 [D loss: 0.745741, acc: 45.31%] [G loss: 1.691061]\n",
      "epoch:4 step:3800 [D loss: 0.665831, acc: 60.16%] [G loss: 1.675371]\n",
      "epoch:4 step:3801 [D loss: 0.619690, acc: 67.97%] [G loss: 1.794128]\n",
      "epoch:4 step:3802 [D loss: 0.642731, acc: 68.75%] [G loss: 1.914015]\n",
      "epoch:4 step:3803 [D loss: 0.588915, acc: 71.88%] [G loss: 1.858746]\n",
      "epoch:4 step:3804 [D loss: 0.651755, acc: 59.38%] [G loss: 1.595926]\n",
      "epoch:4 step:3805 [D loss: 0.564889, acc: 74.22%] [G loss: 1.771833]\n",
      "epoch:4 step:3806 [D loss: 0.697181, acc: 57.03%] [G loss: 1.581402]\n",
      "epoch:4 step:3807 [D loss: 0.656912, acc: 64.06%] [G loss: 1.700927]\n",
      "epoch:4 step:3808 [D loss: 0.596560, acc: 67.97%] [G loss: 1.862836]\n",
      "epoch:4 step:3809 [D loss: 0.651198, acc: 62.50%] [G loss: 1.858324]\n",
      "epoch:4 step:3810 [D loss: 0.665827, acc: 66.41%] [G loss: 1.674033]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3811 [D loss: 0.604072, acc: 72.66%] [G loss: 1.749263]\n",
      "epoch:4 step:3812 [D loss: 0.577203, acc: 71.09%] [G loss: 1.874089]\n",
      "epoch:4 step:3813 [D loss: 0.566164, acc: 73.44%] [G loss: 1.676538]\n",
      "epoch:4 step:3814 [D loss: 0.671792, acc: 60.16%] [G loss: 1.583551]\n",
      "epoch:4 step:3815 [D loss: 0.622606, acc: 68.75%] [G loss: 1.584274]\n",
      "epoch:4 step:3816 [D loss: 0.633838, acc: 66.41%] [G loss: 1.827221]\n",
      "epoch:4 step:3817 [D loss: 0.657090, acc: 64.06%] [G loss: 1.609169]\n",
      "epoch:4 step:3818 [D loss: 0.630667, acc: 61.72%] [G loss: 1.839129]\n",
      "epoch:4 step:3819 [D loss: 0.779770, acc: 46.09%] [G loss: 1.720944]\n",
      "epoch:4 step:3820 [D loss: 0.770180, acc: 49.22%] [G loss: 1.929641]\n",
      "epoch:4 step:3821 [D loss: 0.638520, acc: 64.84%] [G loss: 1.597752]\n",
      "epoch:4 step:3822 [D loss: 0.832995, acc: 42.19%] [G loss: 1.720165]\n",
      "epoch:4 step:3823 [D loss: 0.665093, acc: 61.72%] [G loss: 1.836799]\n",
      "epoch:4 step:3824 [D loss: 0.643697, acc: 62.50%] [G loss: 1.798476]\n",
      "epoch:4 step:3825 [D loss: 0.660929, acc: 60.16%] [G loss: 1.832520]\n",
      "epoch:4 step:3826 [D loss: 0.671876, acc: 61.72%] [G loss: 1.871580]\n",
      "epoch:4 step:3827 [D loss: 0.709947, acc: 59.38%] [G loss: 1.874436]\n",
      "epoch:4 step:3828 [D loss: 0.578533, acc: 74.22%] [G loss: 2.128441]\n",
      "epoch:4 step:3829 [D loss: 0.729868, acc: 52.34%] [G loss: 1.867877]\n",
      "epoch:4 step:3830 [D loss: 0.692349, acc: 59.38%] [G loss: 1.781747]\n",
      "epoch:4 step:3831 [D loss: 0.691056, acc: 54.69%] [G loss: 1.797939]\n",
      "epoch:4 step:3832 [D loss: 0.673374, acc: 60.16%] [G loss: 1.495322]\n",
      "epoch:4 step:3833 [D loss: 0.559739, acc: 74.22%] [G loss: 1.672968]\n",
      "epoch:4 step:3834 [D loss: 0.553947, acc: 75.00%] [G loss: 1.480075]\n",
      "epoch:4 step:3835 [D loss: 0.734090, acc: 50.00%] [G loss: 1.592464]\n",
      "epoch:4 step:3836 [D loss: 0.638210, acc: 66.41%] [G loss: 1.569699]\n",
      "epoch:4 step:3837 [D loss: 0.938119, acc: 30.47%] [G loss: 1.293060]\n",
      "epoch:4 step:3838 [D loss: 0.635815, acc: 68.75%] [G loss: 1.692434]\n",
      "epoch:4 step:3839 [D loss: 1.154456, acc: 13.28%] [G loss: 1.413738]\n",
      "epoch:4 step:3840 [D loss: 0.873671, acc: 32.03%] [G loss: 1.580222]\n",
      "epoch:4 step:3841 [D loss: 0.707601, acc: 54.69%] [G loss: 1.750604]\n",
      "epoch:4 step:3842 [D loss: 0.808910, acc: 37.50%] [G loss: 1.686511]\n",
      "epoch:4 step:3843 [D loss: 0.618417, acc: 64.06%] [G loss: 2.041538]\n",
      "epoch:4 step:3844 [D loss: 0.668486, acc: 58.59%] [G loss: 1.962527]\n",
      "epoch:4 step:3845 [D loss: 0.701583, acc: 49.22%] [G loss: 1.899938]\n",
      "epoch:4 step:3846 [D loss: 0.694144, acc: 54.69%] [G loss: 1.656405]\n",
      "epoch:4 step:3847 [D loss: 0.676739, acc: 61.72%] [G loss: 1.776129]\n",
      "epoch:4 step:3848 [D loss: 0.753660, acc: 46.88%] [G loss: 1.651996]\n",
      "epoch:4 step:3849 [D loss: 0.766717, acc: 47.66%] [G loss: 1.639603]\n",
      "epoch:4 step:3850 [D loss: 0.709920, acc: 59.38%] [G loss: 1.682942]\n",
      "epoch:4 step:3851 [D loss: 0.731945, acc: 53.91%] [G loss: 1.616865]\n",
      "epoch:4 step:3852 [D loss: 0.689492, acc: 51.56%] [G loss: 1.728010]\n",
      "epoch:4 step:3853 [D loss: 0.802833, acc: 40.62%] [G loss: 1.778974]\n",
      "epoch:4 step:3854 [D loss: 0.692278, acc: 53.12%] [G loss: 1.719630]\n",
      "epoch:4 step:3855 [D loss: 0.730310, acc: 55.47%] [G loss: 1.679972]\n",
      "epoch:4 step:3856 [D loss: 0.741378, acc: 50.78%] [G loss: 1.689640]\n",
      "epoch:4 step:3857 [D loss: 0.680269, acc: 59.38%] [G loss: 1.583328]\n",
      "epoch:4 step:3858 [D loss: 0.711670, acc: 51.56%] [G loss: 1.675331]\n",
      "epoch:4 step:3859 [D loss: 0.713168, acc: 53.91%] [G loss: 1.773612]\n",
      "epoch:4 step:3860 [D loss: 0.805836, acc: 47.66%] [G loss: 1.589734]\n",
      "epoch:4 step:3861 [D loss: 0.709902, acc: 50.00%] [G loss: 1.739674]\n",
      "epoch:4 step:3862 [D loss: 0.700894, acc: 55.47%] [G loss: 1.620816]\n",
      "epoch:4 step:3863 [D loss: 0.624514, acc: 64.06%] [G loss: 1.757888]\n",
      "epoch:4 step:3864 [D loss: 0.655784, acc: 57.81%] [G loss: 1.651626]\n",
      "epoch:4 step:3865 [D loss: 0.632371, acc: 64.84%] [G loss: 1.749993]\n",
      "epoch:4 step:3866 [D loss: 0.562327, acc: 77.34%] [G loss: 1.525172]\n",
      "epoch:4 step:3867 [D loss: 0.480029, acc: 86.72%] [G loss: 1.717880]\n",
      "epoch:4 step:3868 [D loss: 0.663705, acc: 64.06%] [G loss: 1.448774]\n",
      "epoch:4 step:3869 [D loss: 0.677160, acc: 60.16%] [G loss: 1.398275]\n",
      "epoch:4 step:3870 [D loss: 0.756749, acc: 47.66%] [G loss: 1.342770]\n",
      "epoch:4 step:3871 [D loss: 0.550149, acc: 75.78%] [G loss: 1.507970]\n",
      "epoch:4 step:3872 [D loss: 0.787656, acc: 39.06%] [G loss: 1.383918]\n",
      "epoch:4 step:3873 [D loss: 0.626805, acc: 65.62%] [G loss: 1.444586]\n",
      "epoch:4 step:3874 [D loss: 0.508684, acc: 80.47%] [G loss: 1.656583]\n",
      "epoch:4 step:3875 [D loss: 0.812320, acc: 38.28%] [G loss: 1.418546]\n",
      "epoch:4 step:3876 [D loss: 0.796457, acc: 36.72%] [G loss: 1.469295]\n",
      "epoch:4 step:3877 [D loss: 0.824992, acc: 39.06%] [G loss: 1.655462]\n",
      "epoch:4 step:3878 [D loss: 0.835918, acc: 33.59%] [G loss: 1.633704]\n",
      "epoch:4 step:3879 [D loss: 0.746535, acc: 46.88%] [G loss: 1.564702]\n",
      "epoch:4 step:3880 [D loss: 0.597971, acc: 68.75%] [G loss: 1.724491]\n",
      "epoch:4 step:3881 [D loss: 0.764144, acc: 47.66%] [G loss: 1.914228]\n",
      "epoch:4 step:3882 [D loss: 0.699441, acc: 53.91%] [G loss: 1.782125]\n",
      "epoch:4 step:3883 [D loss: 0.738421, acc: 43.75%] [G loss: 1.720342]\n",
      "epoch:4 step:3884 [D loss: 0.713336, acc: 53.91%] [G loss: 1.608724]\n",
      "epoch:4 step:3885 [D loss: 0.729789, acc: 50.78%] [G loss: 1.685933]\n",
      "epoch:4 step:3886 [D loss: 0.703225, acc: 46.88%] [G loss: 1.674570]\n",
      "epoch:4 step:3887 [D loss: 0.629084, acc: 62.50%] [G loss: 1.701482]\n",
      "epoch:4 step:3888 [D loss: 0.805166, acc: 33.59%] [G loss: 1.552547]\n",
      "epoch:4 step:3889 [D loss: 0.721181, acc: 48.44%] [G loss: 1.713989]\n",
      "epoch:4 step:3890 [D loss: 0.674868, acc: 60.16%] [G loss: 1.652915]\n",
      "epoch:4 step:3891 [D loss: 0.605063, acc: 71.09%] [G loss: 1.636138]\n",
      "epoch:4 step:3892 [D loss: 0.653589, acc: 61.72%] [G loss: 1.699993]\n",
      "epoch:4 step:3893 [D loss: 0.735525, acc: 46.09%] [G loss: 1.540876]\n",
      "epoch:4 step:3894 [D loss: 0.586152, acc: 71.88%] [G loss: 1.556967]\n",
      "epoch:4 step:3895 [D loss: 0.569445, acc: 75.78%] [G loss: 1.907638]\n",
      "epoch:4 step:3896 [D loss: 0.606408, acc: 71.09%] [G loss: 1.685655]\n",
      "epoch:4 step:3897 [D loss: 0.728513, acc: 52.34%] [G loss: 1.634552]\n",
      "epoch:4 step:3898 [D loss: 0.757291, acc: 44.53%] [G loss: 1.393881]\n",
      "epoch:4 step:3899 [D loss: 0.691688, acc: 55.47%] [G loss: 1.464655]\n",
      "epoch:4 step:3900 [D loss: 0.635701, acc: 61.72%] [G loss: 1.619815]\n",
      "epoch:4 step:3901 [D loss: 0.665654, acc: 64.06%] [G loss: 1.540660]\n",
      "epoch:4 step:3902 [D loss: 0.559844, acc: 77.34%] [G loss: 1.596878]\n",
      "epoch:4 step:3903 [D loss: 0.851230, acc: 42.19%] [G loss: 1.216925]\n",
      "epoch:4 step:3904 [D loss: 0.729256, acc: 50.00%] [G loss: 1.591629]\n",
      "epoch:4 step:3905 [D loss: 0.835979, acc: 34.38%] [G loss: 1.437627]\n",
      "epoch:5 step:3906 [D loss: 0.756022, acc: 42.97%] [G loss: 1.514980]\n",
      "epoch:5 step:3907 [D loss: 0.835057, acc: 34.38%] [G loss: 1.572208]\n",
      "epoch:5 step:3908 [D loss: 0.687227, acc: 57.03%] [G loss: 1.562805]\n",
      "epoch:5 step:3909 [D loss: 0.672885, acc: 62.50%] [G loss: 1.729092]\n",
      "epoch:5 step:3910 [D loss: 0.790711, acc: 37.50%] [G loss: 1.601866]\n",
      "epoch:5 step:3911 [D loss: 0.703721, acc: 53.12%] [G loss: 1.813336]\n",
      "epoch:5 step:3912 [D loss: 0.734520, acc: 51.56%] [G loss: 1.649463]\n",
      "epoch:5 step:3913 [D loss: 0.650388, acc: 65.62%] [G loss: 1.745583]\n",
      "epoch:5 step:3914 [D loss: 0.698713, acc: 55.47%] [G loss: 1.631974]\n",
      "epoch:5 step:3915 [D loss: 0.711867, acc: 54.69%] [G loss: 1.738808]\n",
      "epoch:5 step:3916 [D loss: 0.655028, acc: 64.06%] [G loss: 1.616940]\n",
      "epoch:5 step:3917 [D loss: 0.586907, acc: 71.88%] [G loss: 1.748127]\n",
      "epoch:5 step:3918 [D loss: 0.527197, acc: 83.59%] [G loss: 1.655946]\n",
      "epoch:5 step:3919 [D loss: 0.586920, acc: 71.09%] [G loss: 1.675686]\n",
      "epoch:5 step:3920 [D loss: 0.862569, acc: 28.91%] [G loss: 1.471833]\n",
      "epoch:5 step:3921 [D loss: 0.695177, acc: 60.16%] [G loss: 1.515028]\n",
      "epoch:5 step:3922 [D loss: 0.749877, acc: 46.09%] [G loss: 1.659298]\n",
      "epoch:5 step:3923 [D loss: 0.761058, acc: 49.22%] [G loss: 1.489269]\n",
      "epoch:5 step:3924 [D loss: 0.624090, acc: 66.41%] [G loss: 1.783349]\n",
      "epoch:5 step:3925 [D loss: 0.617871, acc: 67.19%] [G loss: 1.726831]\n",
      "epoch:5 step:3926 [D loss: 0.767851, acc: 39.06%] [G loss: 1.412105]\n",
      "epoch:5 step:3927 [D loss: 0.648416, acc: 60.16%] [G loss: 1.604357]\n",
      "epoch:5 step:3928 [D loss: 0.791113, acc: 40.62%] [G loss: 1.516451]\n",
      "epoch:5 step:3929 [D loss: 0.732333, acc: 44.53%] [G loss: 1.670749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:3930 [D loss: 0.654556, acc: 62.50%] [G loss: 1.803629]\n",
      "epoch:5 step:3931 [D loss: 0.645695, acc: 68.75%] [G loss: 1.738769]\n",
      "epoch:5 step:3932 [D loss: 0.643181, acc: 65.62%] [G loss: 1.575249]\n",
      "epoch:5 step:3933 [D loss: 0.694342, acc: 53.91%] [G loss: 1.767822]\n",
      "epoch:5 step:3934 [D loss: 0.674042, acc: 57.03%] [G loss: 1.734106]\n",
      "epoch:5 step:3935 [D loss: 0.746729, acc: 46.88%] [G loss: 1.550014]\n",
      "epoch:5 step:3936 [D loss: 0.684615, acc: 58.59%] [G loss: 1.818329]\n",
      "epoch:5 step:3937 [D loss: 0.680706, acc: 60.94%] [G loss: 1.638048]\n",
      "epoch:5 step:3938 [D loss: 0.745307, acc: 50.00%] [G loss: 1.647570]\n",
      "epoch:5 step:3939 [D loss: 0.720425, acc: 55.47%] [G loss: 1.673774]\n",
      "epoch:5 step:3940 [D loss: 0.657061, acc: 60.94%] [G loss: 1.846487]\n",
      "epoch:5 step:3941 [D loss: 0.741923, acc: 50.00%] [G loss: 1.719163]\n",
      "epoch:5 step:3942 [D loss: 0.716792, acc: 50.00%] [G loss: 1.786942]\n",
      "epoch:5 step:3943 [D loss: 0.731501, acc: 45.31%] [G loss: 1.557174]\n",
      "epoch:5 step:3944 [D loss: 0.688993, acc: 57.81%] [G loss: 1.725883]\n",
      "epoch:5 step:3945 [D loss: 0.647200, acc: 60.94%] [G loss: 1.862329]\n",
      "epoch:5 step:3946 [D loss: 0.735359, acc: 50.00%] [G loss: 1.555414]\n",
      "epoch:5 step:3947 [D loss: 0.635361, acc: 69.53%] [G loss: 1.643170]\n",
      "epoch:5 step:3948 [D loss: 0.725513, acc: 50.00%] [G loss: 1.794343]\n",
      "epoch:5 step:3949 [D loss: 0.770384, acc: 43.75%] [G loss: 1.508864]\n",
      "epoch:5 step:3950 [D loss: 0.689794, acc: 59.38%] [G loss: 1.478110]\n",
      "epoch:5 step:3951 [D loss: 0.725039, acc: 50.78%] [G loss: 1.590949]\n",
      "epoch:5 step:3952 [D loss: 0.751921, acc: 46.88%] [G loss: 1.521094]\n",
      "epoch:5 step:3953 [D loss: 0.612971, acc: 65.62%] [G loss: 1.631776]\n",
      "epoch:5 step:3954 [D loss: 0.528454, acc: 80.47%] [G loss: 1.707555]\n",
      "epoch:5 step:3955 [D loss: 0.566230, acc: 70.31%] [G loss: 1.470368]\n",
      "epoch:5 step:3956 [D loss: 0.469607, acc: 82.03%] [G loss: 1.644303]\n",
      "epoch:5 step:3957 [D loss: 0.410347, acc: 80.47%] [G loss: 1.439108]\n",
      "epoch:5 step:3958 [D loss: 0.745317, acc: 53.91%] [G loss: 1.587214]\n",
      "epoch:5 step:3959 [D loss: 0.353512, acc: 88.28%] [G loss: 1.482913]\n",
      "epoch:5 step:3960 [D loss: 0.557353, acc: 78.91%] [G loss: 1.517489]\n",
      "epoch:5 step:3961 [D loss: 0.997360, acc: 19.53%] [G loss: 1.082780]\n",
      "epoch:5 step:3962 [D loss: 0.750138, acc: 50.00%] [G loss: 1.376287]\n",
      "epoch:5 step:3963 [D loss: 0.603911, acc: 68.75%] [G loss: 1.475107]\n",
      "epoch:5 step:3964 [D loss: 0.825421, acc: 39.84%] [G loss: 1.668931]\n",
      "epoch:5 step:3965 [D loss: 0.699818, acc: 59.38%] [G loss: 1.663415]\n",
      "epoch:5 step:3966 [D loss: 0.735876, acc: 60.16%] [G loss: 1.911918]\n",
      "epoch:5 step:3967 [D loss: 0.684549, acc: 54.69%] [G loss: 1.881618]\n",
      "epoch:5 step:3968 [D loss: 0.571158, acc: 71.88%] [G loss: 2.072406]\n",
      "epoch:5 step:3969 [D loss: 0.790775, acc: 47.66%] [G loss: 2.081828]\n",
      "epoch:5 step:3970 [D loss: 0.567306, acc: 67.97%] [G loss: 2.002897]\n",
      "epoch:5 step:3971 [D loss: 0.529707, acc: 75.78%] [G loss: 1.968880]\n",
      "epoch:5 step:3972 [D loss: 0.663846, acc: 64.84%] [G loss: 1.573996]\n",
      "epoch:5 step:3973 [D loss: 0.466464, acc: 86.72%] [G loss: 1.724444]\n",
      "epoch:5 step:3974 [D loss: 0.739376, acc: 57.03%] [G loss: 1.544759]\n",
      "epoch:5 step:3975 [D loss: 0.722638, acc: 51.56%] [G loss: 1.357177]\n",
      "epoch:5 step:3976 [D loss: 0.640270, acc: 64.84%] [G loss: 1.602136]\n",
      "epoch:5 step:3977 [D loss: 0.697958, acc: 58.59%] [G loss: 1.289257]\n",
      "epoch:5 step:3978 [D loss: 0.639255, acc: 59.38%] [G loss: 1.318135]\n",
      "epoch:5 step:3979 [D loss: 0.539293, acc: 78.91%] [G loss: 1.359335]\n",
      "epoch:5 step:3980 [D loss: 0.829880, acc: 45.31%] [G loss: 1.601824]\n",
      "epoch:5 step:3981 [D loss: 0.818861, acc: 42.19%] [G loss: 1.512967]\n",
      "epoch:5 step:3982 [D loss: 0.584001, acc: 73.44%] [G loss: 1.725290]\n",
      "epoch:5 step:3983 [D loss: 0.760505, acc: 51.56%] [G loss: 1.764459]\n",
      "epoch:5 step:3984 [D loss: 0.750619, acc: 44.53%] [G loss: 2.282265]\n",
      "epoch:5 step:3985 [D loss: 0.644167, acc: 67.97%] [G loss: 1.858509]\n",
      "epoch:5 step:3986 [D loss: 0.592828, acc: 61.72%] [G loss: 1.824435]\n",
      "epoch:5 step:3987 [D loss: 0.729518, acc: 50.78%] [G loss: 1.756025]\n",
      "epoch:5 step:3988 [D loss: 0.696169, acc: 53.91%] [G loss: 1.585998]\n",
      "epoch:5 step:3989 [D loss: 0.826686, acc: 41.41%] [G loss: 1.708836]\n",
      "epoch:5 step:3990 [D loss: 0.800487, acc: 43.75%] [G loss: 1.905395]\n",
      "epoch:5 step:3991 [D loss: 0.744573, acc: 50.78%] [G loss: 2.017306]\n",
      "epoch:5 step:3992 [D loss: 0.743002, acc: 51.56%] [G loss: 1.820311]\n",
      "epoch:5 step:3993 [D loss: 0.771716, acc: 53.12%] [G loss: 1.611268]\n",
      "epoch:5 step:3994 [D loss: 0.758288, acc: 48.44%] [G loss: 1.631975]\n",
      "epoch:5 step:3995 [D loss: 1.015653, acc: 25.00%] [G loss: 1.568769]\n",
      "epoch:5 step:3996 [D loss: 0.768082, acc: 44.53%] [G loss: 1.664682]\n",
      "epoch:5 step:3997 [D loss: 0.738634, acc: 47.66%] [G loss: 1.599422]\n",
      "epoch:5 step:3998 [D loss: 0.779161, acc: 39.84%] [G loss: 1.613066]\n",
      "epoch:5 step:3999 [D loss: 0.677994, acc: 59.38%] [G loss: 1.722046]\n",
      "epoch:5 step:4000 [D loss: 0.726715, acc: 53.91%] [G loss: 1.634720]\n",
      "epoch:5 step:4001 [D loss: 0.760981, acc: 42.19%] [G loss: 1.625619]\n",
      "epoch:5 step:4002 [D loss: 0.767052, acc: 44.53%] [G loss: 1.668901]\n",
      "epoch:5 step:4003 [D loss: 0.775086, acc: 39.84%] [G loss: 1.659859]\n",
      "epoch:5 step:4004 [D loss: 0.779032, acc: 45.31%] [G loss: 1.557233]\n",
      "epoch:5 step:4005 [D loss: 0.741114, acc: 46.09%] [G loss: 1.675047]\n",
      "epoch:5 step:4006 [D loss: 0.775769, acc: 41.41%] [G loss: 1.612411]\n",
      "epoch:5 step:4007 [D loss: 0.757785, acc: 46.09%] [G loss: 1.613244]\n",
      "epoch:5 step:4008 [D loss: 0.814222, acc: 32.03%] [G loss: 1.505650]\n",
      "epoch:5 step:4009 [D loss: 0.803247, acc: 42.19%] [G loss: 1.542735]\n",
      "epoch:5 step:4010 [D loss: 0.711465, acc: 51.56%] [G loss: 1.559055]\n",
      "epoch:5 step:4011 [D loss: 0.755913, acc: 45.31%] [G loss: 1.466019]\n",
      "epoch:5 step:4012 [D loss: 0.674928, acc: 56.25%] [G loss: 1.677428]\n",
      "epoch:5 step:4013 [D loss: 0.744651, acc: 44.53%] [G loss: 1.575172]\n",
      "epoch:5 step:4014 [D loss: 0.734419, acc: 51.56%] [G loss: 1.646180]\n",
      "epoch:5 step:4015 [D loss: 0.679082, acc: 51.56%] [G loss: 1.682870]\n",
      "epoch:5 step:4016 [D loss: 0.839728, acc: 34.38%] [G loss: 1.905968]\n",
      "epoch:5 step:4017 [D loss: 0.653349, acc: 64.06%] [G loss: 1.707689]\n",
      "epoch:5 step:4018 [D loss: 0.713997, acc: 52.34%] [G loss: 1.671593]\n",
      "epoch:5 step:4019 [D loss: 0.756389, acc: 42.19%] [G loss: 1.629034]\n",
      "epoch:5 step:4020 [D loss: 0.813083, acc: 35.16%] [G loss: 1.489429]\n",
      "epoch:5 step:4021 [D loss: 0.696187, acc: 49.22%] [G loss: 1.635157]\n",
      "epoch:5 step:4022 [D loss: 0.655448, acc: 63.28%] [G loss: 1.614627]\n",
      "epoch:5 step:4023 [D loss: 0.705072, acc: 53.91%] [G loss: 1.583186]\n",
      "epoch:5 step:4024 [D loss: 0.661496, acc: 61.72%] [G loss: 1.687681]\n",
      "epoch:5 step:4025 [D loss: 0.713570, acc: 52.34%] [G loss: 1.561170]\n",
      "epoch:5 step:4026 [D loss: 0.695518, acc: 60.16%] [G loss: 1.620275]\n",
      "epoch:5 step:4027 [D loss: 0.671349, acc: 59.38%] [G loss: 1.629799]\n",
      "epoch:5 step:4028 [D loss: 0.653028, acc: 60.94%] [G loss: 1.675915]\n",
      "epoch:5 step:4029 [D loss: 0.615227, acc: 67.19%] [G loss: 1.626811]\n",
      "epoch:5 step:4030 [D loss: 0.646419, acc: 61.72%] [G loss: 1.800346]\n",
      "epoch:5 step:4031 [D loss: 0.680942, acc: 55.47%] [G loss: 1.482751]\n",
      "epoch:5 step:4032 [D loss: 0.748479, acc: 47.66%] [G loss: 1.575595]\n",
      "epoch:5 step:4033 [D loss: 0.791769, acc: 39.84%] [G loss: 1.509692]\n",
      "epoch:5 step:4034 [D loss: 0.687630, acc: 55.47%] [G loss: 1.644488]\n",
      "epoch:5 step:4035 [D loss: 0.883082, acc: 30.47%] [G loss: 1.481305]\n",
      "epoch:5 step:4036 [D loss: 0.786728, acc: 46.88%] [G loss: 1.867497]\n",
      "epoch:5 step:4037 [D loss: 0.795522, acc: 39.06%] [G loss: 1.627759]\n",
      "epoch:5 step:4038 [D loss: 0.657844, acc: 64.06%] [G loss: 1.782798]\n",
      "epoch:5 step:4039 [D loss: 0.637306, acc: 65.62%] [G loss: 1.704274]\n",
      "epoch:5 step:4040 [D loss: 0.695216, acc: 57.81%] [G loss: 1.695708]\n",
      "epoch:5 step:4041 [D loss: 0.679882, acc: 56.25%] [G loss: 1.729655]\n",
      "epoch:5 step:4042 [D loss: 0.812855, acc: 35.16%] [G loss: 1.370588]\n",
      "epoch:5 step:4043 [D loss: 0.768559, acc: 40.62%] [G loss: 1.594723]\n",
      "epoch:5 step:4044 [D loss: 0.718961, acc: 48.44%] [G loss: 1.513796]\n",
      "epoch:5 step:4045 [D loss: 0.789865, acc: 42.19%] [G loss: 1.464804]\n",
      "epoch:5 step:4046 [D loss: 0.771645, acc: 50.00%] [G loss: 1.557311]\n",
      "epoch:5 step:4047 [D loss: 0.793786, acc: 45.31%] [G loss: 1.571572]\n",
      "epoch:5 step:4048 [D loss: 0.836555, acc: 34.38%] [G loss: 1.693188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4049 [D loss: 0.748092, acc: 45.31%] [G loss: 1.709751]\n",
      "epoch:5 step:4050 [D loss: 0.770885, acc: 42.19%] [G loss: 1.600166]\n",
      "epoch:5 step:4051 [D loss: 0.648276, acc: 60.16%] [G loss: 1.694756]\n",
      "epoch:5 step:4052 [D loss: 0.701514, acc: 51.56%] [G loss: 1.700028]\n",
      "epoch:5 step:4053 [D loss: 0.659677, acc: 57.03%] [G loss: 1.589768]\n",
      "epoch:5 step:4054 [D loss: 0.702659, acc: 53.91%] [G loss: 1.547079]\n",
      "epoch:5 step:4055 [D loss: 0.720693, acc: 50.00%] [G loss: 1.470981]\n",
      "epoch:5 step:4056 [D loss: 0.704183, acc: 56.25%] [G loss: 1.531087]\n",
      "epoch:5 step:4057 [D loss: 0.605861, acc: 70.31%] [G loss: 1.621492]\n",
      "epoch:5 step:4058 [D loss: 0.687957, acc: 54.69%] [G loss: 1.659741]\n",
      "epoch:5 step:4059 [D loss: 0.670760, acc: 61.72%] [G loss: 1.564324]\n",
      "epoch:5 step:4060 [D loss: 0.630875, acc: 64.84%] [G loss: 1.556252]\n",
      "epoch:5 step:4061 [D loss: 0.606366, acc: 67.97%] [G loss: 1.438680]\n",
      "epoch:5 step:4062 [D loss: 0.648094, acc: 60.16%] [G loss: 1.460632]\n",
      "epoch:5 step:4063 [D loss: 0.792061, acc: 39.84%] [G loss: 1.417361]\n",
      "epoch:5 step:4064 [D loss: 0.740420, acc: 42.19%] [G loss: 1.628133]\n",
      "epoch:5 step:4065 [D loss: 0.853074, acc: 29.69%] [G loss: 1.413678]\n",
      "epoch:5 step:4066 [D loss: 0.744547, acc: 44.53%] [G loss: 1.699630]\n",
      "epoch:5 step:4067 [D loss: 0.717684, acc: 49.22%] [G loss: 1.619318]\n",
      "epoch:5 step:4068 [D loss: 0.644864, acc: 64.06%] [G loss: 1.621317]\n",
      "epoch:5 step:4069 [D loss: 0.735685, acc: 50.78%] [G loss: 1.594804]\n",
      "epoch:5 step:4070 [D loss: 0.717171, acc: 59.38%] [G loss: 1.581914]\n",
      "epoch:5 step:4071 [D loss: 0.868823, acc: 31.25%] [G loss: 1.555782]\n",
      "epoch:5 step:4072 [D loss: 0.674685, acc: 61.72%] [G loss: 1.621608]\n",
      "epoch:5 step:4073 [D loss: 0.596442, acc: 71.88%] [G loss: 1.643503]\n",
      "epoch:5 step:4074 [D loss: 0.744699, acc: 46.88%] [G loss: 1.629995]\n",
      "epoch:5 step:4075 [D loss: 0.601581, acc: 68.75%] [G loss: 1.706183]\n",
      "epoch:5 step:4076 [D loss: 0.744906, acc: 45.31%] [G loss: 1.563631]\n",
      "epoch:5 step:4077 [D loss: 0.702638, acc: 50.00%] [G loss: 1.626804]\n",
      "epoch:5 step:4078 [D loss: 0.698468, acc: 55.47%] [G loss: 1.399709]\n",
      "epoch:5 step:4079 [D loss: 0.587584, acc: 76.56%] [G loss: 1.588451]\n",
      "epoch:5 step:4080 [D loss: 0.745200, acc: 46.09%] [G loss: 1.600867]\n",
      "epoch:5 step:4081 [D loss: 0.684510, acc: 54.69%] [G loss: 1.589645]\n",
      "epoch:5 step:4082 [D loss: 0.761557, acc: 42.19%] [G loss: 1.569099]\n",
      "epoch:5 step:4083 [D loss: 0.779122, acc: 39.06%] [G loss: 1.597217]\n",
      "epoch:5 step:4084 [D loss: 0.695855, acc: 58.59%] [G loss: 1.696788]\n",
      "epoch:5 step:4085 [D loss: 0.573882, acc: 73.44%] [G loss: 1.677799]\n",
      "epoch:5 step:4086 [D loss: 0.701693, acc: 50.78%] [G loss: 1.559598]\n",
      "epoch:5 step:4087 [D loss: 0.710249, acc: 53.91%] [G loss: 1.520496]\n",
      "epoch:5 step:4088 [D loss: 0.763782, acc: 41.41%] [G loss: 1.497407]\n",
      "epoch:5 step:4089 [D loss: 0.752353, acc: 36.72%] [G loss: 1.684441]\n",
      "epoch:5 step:4090 [D loss: 0.810926, acc: 37.50%] [G loss: 1.504732]\n",
      "epoch:5 step:4091 [D loss: 0.704202, acc: 55.47%] [G loss: 1.631346]\n",
      "epoch:5 step:4092 [D loss: 0.737784, acc: 50.00%] [G loss: 1.743915]\n",
      "epoch:5 step:4093 [D loss: 0.760659, acc: 43.75%] [G loss: 1.554275]\n",
      "epoch:5 step:4094 [D loss: 0.693652, acc: 58.59%] [G loss: 1.665642]\n",
      "epoch:5 step:4095 [D loss: 0.710019, acc: 53.12%] [G loss: 1.559862]\n",
      "epoch:5 step:4096 [D loss: 0.668258, acc: 60.16%] [G loss: 1.612190]\n",
      "epoch:5 step:4097 [D loss: 0.719563, acc: 53.91%] [G loss: 1.527764]\n",
      "epoch:5 step:4098 [D loss: 0.712245, acc: 54.69%] [G loss: 1.650738]\n",
      "epoch:5 step:4099 [D loss: 0.702850, acc: 53.12%] [G loss: 1.594995]\n",
      "epoch:5 step:4100 [D loss: 0.784094, acc: 38.28%] [G loss: 1.538335]\n",
      "epoch:5 step:4101 [D loss: 0.821338, acc: 33.59%] [G loss: 1.407332]\n",
      "epoch:5 step:4102 [D loss: 0.722870, acc: 43.75%] [G loss: 1.554469]\n",
      "epoch:5 step:4103 [D loss: 0.631294, acc: 67.97%] [G loss: 1.552230]\n",
      "epoch:5 step:4104 [D loss: 0.656680, acc: 62.50%] [G loss: 1.497807]\n",
      "epoch:5 step:4105 [D loss: 0.757290, acc: 48.44%] [G loss: 1.598376]\n",
      "epoch:5 step:4106 [D loss: 0.747783, acc: 51.56%] [G loss: 1.688759]\n",
      "epoch:5 step:4107 [D loss: 0.750262, acc: 41.41%] [G loss: 1.491736]\n",
      "epoch:5 step:4108 [D loss: 0.689178, acc: 57.81%] [G loss: 1.646756]\n",
      "epoch:5 step:4109 [D loss: 0.698005, acc: 57.81%] [G loss: 1.618260]\n",
      "epoch:5 step:4110 [D loss: 0.816758, acc: 35.94%] [G loss: 1.575148]\n",
      "epoch:5 step:4111 [D loss: 0.784066, acc: 36.72%] [G loss: 1.490195]\n",
      "epoch:5 step:4112 [D loss: 0.623247, acc: 65.62%] [G loss: 1.637574]\n",
      "epoch:5 step:4113 [D loss: 0.744833, acc: 39.06%] [G loss: 1.506115]\n",
      "epoch:5 step:4114 [D loss: 0.775165, acc: 39.06%] [G loss: 1.558098]\n",
      "epoch:5 step:4115 [D loss: 0.744130, acc: 51.56%] [G loss: 1.603793]\n",
      "epoch:5 step:4116 [D loss: 0.664857, acc: 59.38%] [G loss: 1.576126]\n",
      "epoch:5 step:4117 [D loss: 0.732865, acc: 55.47%] [G loss: 1.628327]\n",
      "epoch:5 step:4118 [D loss: 0.768497, acc: 42.97%] [G loss: 1.558630]\n",
      "epoch:5 step:4119 [D loss: 0.721416, acc: 47.66%] [G loss: 1.511005]\n",
      "epoch:5 step:4120 [D loss: 0.712964, acc: 50.00%] [G loss: 1.569961]\n",
      "epoch:5 step:4121 [D loss: 0.746365, acc: 50.00%] [G loss: 1.569796]\n",
      "epoch:5 step:4122 [D loss: 0.712860, acc: 51.56%] [G loss: 1.581423]\n",
      "epoch:5 step:4123 [D loss: 0.779545, acc: 37.50%] [G loss: 1.516232]\n",
      "epoch:5 step:4124 [D loss: 0.756189, acc: 43.75%] [G loss: 1.519946]\n",
      "epoch:5 step:4125 [D loss: 0.710411, acc: 59.38%] [G loss: 1.520303]\n",
      "epoch:5 step:4126 [D loss: 0.727416, acc: 43.75%] [G loss: 1.607567]\n",
      "epoch:5 step:4127 [D loss: 0.737347, acc: 41.41%] [G loss: 1.499198]\n",
      "epoch:5 step:4128 [D loss: 0.731033, acc: 57.81%] [G loss: 1.688040]\n",
      "epoch:5 step:4129 [D loss: 0.751701, acc: 47.66%] [G loss: 1.451977]\n",
      "epoch:5 step:4130 [D loss: 0.768663, acc: 44.53%] [G loss: 1.556978]\n",
      "epoch:5 step:4131 [D loss: 0.773213, acc: 42.19%] [G loss: 1.499114]\n",
      "epoch:5 step:4132 [D loss: 0.842539, acc: 30.47%] [G loss: 1.455521]\n",
      "epoch:5 step:4133 [D loss: 0.692021, acc: 55.47%] [G loss: 1.615893]\n",
      "epoch:5 step:4134 [D loss: 0.641633, acc: 57.03%] [G loss: 1.573461]\n",
      "epoch:5 step:4135 [D loss: 0.726720, acc: 50.78%] [G loss: 1.624350]\n",
      "epoch:5 step:4136 [D loss: 0.709529, acc: 56.25%] [G loss: 1.547560]\n",
      "epoch:5 step:4137 [D loss: 0.806676, acc: 39.84%] [G loss: 1.449826]\n",
      "epoch:5 step:4138 [D loss: 0.699411, acc: 53.91%] [G loss: 1.519730]\n",
      "epoch:5 step:4139 [D loss: 0.689076, acc: 54.69%] [G loss: 1.717892]\n",
      "epoch:5 step:4140 [D loss: 0.711888, acc: 44.53%] [G loss: 1.558714]\n",
      "epoch:5 step:4141 [D loss: 0.762594, acc: 42.97%] [G loss: 1.641192]\n",
      "epoch:5 step:4142 [D loss: 0.729465, acc: 51.56%] [G loss: 1.493018]\n",
      "epoch:5 step:4143 [D loss: 0.606180, acc: 73.44%] [G loss: 1.591064]\n",
      "epoch:5 step:4144 [D loss: 0.716730, acc: 51.56%] [G loss: 1.614507]\n",
      "epoch:5 step:4145 [D loss: 0.710638, acc: 55.47%] [G loss: 1.625618]\n",
      "epoch:5 step:4146 [D loss: 0.715011, acc: 59.38%] [G loss: 1.608509]\n",
      "epoch:5 step:4147 [D loss: 0.752003, acc: 41.41%] [G loss: 1.440345]\n",
      "epoch:5 step:4148 [D loss: 0.733589, acc: 42.19%] [G loss: 1.474797]\n",
      "epoch:5 step:4149 [D loss: 0.696792, acc: 53.12%] [G loss: 1.655424]\n",
      "epoch:5 step:4150 [D loss: 0.716993, acc: 49.22%] [G loss: 1.488603]\n",
      "epoch:5 step:4151 [D loss: 0.718995, acc: 53.91%] [G loss: 1.667525]\n",
      "epoch:5 step:4152 [D loss: 0.728342, acc: 49.22%] [G loss: 1.430327]\n",
      "epoch:5 step:4153 [D loss: 0.696539, acc: 56.25%] [G loss: 1.535053]\n",
      "epoch:5 step:4154 [D loss: 0.630106, acc: 64.84%] [G loss: 1.577849]\n",
      "epoch:5 step:4155 [D loss: 0.639126, acc: 65.62%] [G loss: 1.674628]\n",
      "epoch:5 step:4156 [D loss: 0.642685, acc: 69.53%] [G loss: 1.627462]\n",
      "epoch:5 step:4157 [D loss: 0.709415, acc: 51.56%] [G loss: 1.673912]\n",
      "epoch:5 step:4158 [D loss: 0.760768, acc: 43.75%] [G loss: 1.662285]\n",
      "epoch:5 step:4159 [D loss: 0.763332, acc: 44.53%] [G loss: 1.482645]\n",
      "epoch:5 step:4160 [D loss: 0.759696, acc: 47.66%] [G loss: 1.573764]\n",
      "epoch:5 step:4161 [D loss: 0.618878, acc: 68.75%] [G loss: 1.616773]\n",
      "epoch:5 step:4162 [D loss: 0.746526, acc: 44.53%] [G loss: 1.434268]\n",
      "epoch:5 step:4163 [D loss: 0.665743, acc: 57.03%] [G loss: 1.656111]\n",
      "epoch:5 step:4164 [D loss: 0.677531, acc: 56.25%] [G loss: 1.586642]\n",
      "epoch:5 step:4165 [D loss: 0.668205, acc: 57.81%] [G loss: 1.567655]\n",
      "epoch:5 step:4166 [D loss: 0.637832, acc: 68.75%] [G loss: 1.640764]\n",
      "epoch:5 step:4167 [D loss: 0.636051, acc: 61.72%] [G loss: 1.685007]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4168 [D loss: 0.793935, acc: 37.50%] [G loss: 1.518526]\n",
      "epoch:5 step:4169 [D loss: 0.723190, acc: 50.78%] [G loss: 1.685121]\n",
      "epoch:5 step:4170 [D loss: 0.698834, acc: 55.47%] [G loss: 1.660636]\n",
      "epoch:5 step:4171 [D loss: 0.727883, acc: 48.44%] [G loss: 1.604439]\n",
      "epoch:5 step:4172 [D loss: 0.964619, acc: 29.69%] [G loss: 1.266419]\n",
      "epoch:5 step:4173 [D loss: 0.724161, acc: 51.56%] [G loss: 1.533460]\n",
      "epoch:5 step:4174 [D loss: 0.774319, acc: 44.53%] [G loss: 1.472543]\n",
      "epoch:5 step:4175 [D loss: 0.748470, acc: 42.19%] [G loss: 1.491877]\n",
      "epoch:5 step:4176 [D loss: 0.740352, acc: 46.09%] [G loss: 1.404986]\n",
      "epoch:5 step:4177 [D loss: 0.681615, acc: 52.34%] [G loss: 1.610616]\n",
      "epoch:5 step:4178 [D loss: 0.788415, acc: 39.06%] [G loss: 1.495442]\n",
      "epoch:5 step:4179 [D loss: 0.757714, acc: 37.50%] [G loss: 1.471164]\n",
      "epoch:5 step:4180 [D loss: 0.756967, acc: 39.84%] [G loss: 1.513895]\n",
      "epoch:5 step:4181 [D loss: 0.700412, acc: 55.47%] [G loss: 1.594969]\n",
      "epoch:5 step:4182 [D loss: 0.837000, acc: 30.47%] [G loss: 1.415382]\n",
      "epoch:5 step:4183 [D loss: 0.722944, acc: 49.22%] [G loss: 1.536127]\n",
      "epoch:5 step:4184 [D loss: 0.640981, acc: 61.72%] [G loss: 1.571693]\n",
      "epoch:5 step:4185 [D loss: 0.621997, acc: 71.09%] [G loss: 1.516676]\n",
      "epoch:5 step:4186 [D loss: 0.699816, acc: 55.47%] [G loss: 1.503574]\n",
      "epoch:5 step:4187 [D loss: 0.736816, acc: 49.22%] [G loss: 1.445279]\n",
      "epoch:5 step:4188 [D loss: 0.752082, acc: 42.97%] [G loss: 1.435659]\n",
      "epoch:5 step:4189 [D loss: 0.705392, acc: 50.00%] [G loss: 1.525878]\n",
      "epoch:5 step:4190 [D loss: 0.688121, acc: 53.91%] [G loss: 1.567342]\n",
      "epoch:5 step:4191 [D loss: 0.683141, acc: 52.34%] [G loss: 1.613297]\n",
      "epoch:5 step:4192 [D loss: 0.641538, acc: 56.25%] [G loss: 1.598216]\n",
      "epoch:5 step:4193 [D loss: 0.696850, acc: 60.16%] [G loss: 1.627641]\n",
      "epoch:5 step:4194 [D loss: 0.768498, acc: 50.00%] [G loss: 1.503498]\n",
      "epoch:5 step:4195 [D loss: 0.742038, acc: 43.75%] [G loss: 1.395812]\n",
      "epoch:5 step:4196 [D loss: 0.949348, acc: 19.53%] [G loss: 1.302791]\n",
      "epoch:5 step:4197 [D loss: 0.714975, acc: 48.44%] [G loss: 1.604846]\n",
      "epoch:5 step:4198 [D loss: 0.782170, acc: 33.59%] [G loss: 1.415944]\n",
      "epoch:5 step:4199 [D loss: 0.760434, acc: 38.28%] [G loss: 1.478962]\n",
      "epoch:5 step:4200 [D loss: 0.715435, acc: 52.34%] [G loss: 1.609074]\n",
      "epoch:5 step:4201 [D loss: 0.822598, acc: 30.47%] [G loss: 1.330316]\n",
      "epoch:5 step:4202 [D loss: 0.748323, acc: 44.53%] [G loss: 1.443700]\n",
      "epoch:5 step:4203 [D loss: 0.726709, acc: 44.53%] [G loss: 1.461506]\n",
      "epoch:5 step:4204 [D loss: 0.732523, acc: 47.66%] [G loss: 1.613368]\n",
      "epoch:5 step:4205 [D loss: 0.664476, acc: 60.16%] [G loss: 1.551721]\n",
      "epoch:5 step:4206 [D loss: 0.704780, acc: 53.91%] [G loss: 1.596228]\n",
      "epoch:5 step:4207 [D loss: 0.705881, acc: 51.56%] [G loss: 1.561669]\n",
      "epoch:5 step:4208 [D loss: 0.720294, acc: 47.66%] [G loss: 1.535437]\n",
      "epoch:5 step:4209 [D loss: 0.720755, acc: 46.09%] [G loss: 1.480019]\n",
      "epoch:5 step:4210 [D loss: 0.690163, acc: 55.47%] [G loss: 1.515288]\n",
      "epoch:5 step:4211 [D loss: 0.608901, acc: 67.97%] [G loss: 1.597539]\n",
      "epoch:5 step:4212 [D loss: 0.677189, acc: 58.59%] [G loss: 1.611953]\n",
      "epoch:5 step:4213 [D loss: 0.470085, acc: 81.25%] [G loss: 1.564006]\n",
      "epoch:5 step:4214 [D loss: 0.642378, acc: 65.62%] [G loss: 1.569532]\n",
      "epoch:5 step:4215 [D loss: 0.681448, acc: 55.47%] [G loss: 1.542736]\n",
      "epoch:5 step:4216 [D loss: 0.734176, acc: 42.97%] [G loss: 1.448771]\n",
      "epoch:5 step:4217 [D loss: 0.780918, acc: 35.94%] [G loss: 1.518136]\n",
      "epoch:5 step:4218 [D loss: 0.788564, acc: 34.38%] [G loss: 1.318903]\n",
      "epoch:5 step:4219 [D loss: 0.660036, acc: 62.50%] [G loss: 1.555426]\n",
      "epoch:5 step:4220 [D loss: 0.919430, acc: 21.88%] [G loss: 1.238861]\n",
      "epoch:5 step:4221 [D loss: 0.649577, acc: 63.28%] [G loss: 1.624053]\n",
      "epoch:5 step:4222 [D loss: 0.668105, acc: 57.81%] [G loss: 1.571849]\n",
      "epoch:5 step:4223 [D loss: 0.702297, acc: 54.69%] [G loss: 1.557121]\n",
      "epoch:5 step:4224 [D loss: 0.692568, acc: 60.16%] [G loss: 1.612687]\n",
      "epoch:5 step:4225 [D loss: 0.797612, acc: 38.28%] [G loss: 1.543921]\n",
      "epoch:5 step:4226 [D loss: 0.768304, acc: 39.06%] [G loss: 1.552843]\n",
      "epoch:5 step:4227 [D loss: 0.727860, acc: 51.56%] [G loss: 1.607732]\n",
      "epoch:5 step:4228 [D loss: 0.667804, acc: 57.81%] [G loss: 1.608266]\n",
      "epoch:5 step:4229 [D loss: 0.694732, acc: 53.12%] [G loss: 1.593678]\n",
      "epoch:5 step:4230 [D loss: 0.729150, acc: 50.00%] [G loss: 1.547551]\n",
      "epoch:5 step:4231 [D loss: 0.673147, acc: 58.59%] [G loss: 1.503975]\n",
      "epoch:5 step:4232 [D loss: 0.689513, acc: 53.12%] [G loss: 1.543524]\n",
      "epoch:5 step:4233 [D loss: 0.723526, acc: 48.44%] [G loss: 1.439353]\n",
      "epoch:5 step:4234 [D loss: 0.728004, acc: 54.69%] [G loss: 1.518107]\n",
      "epoch:5 step:4235 [D loss: 0.671559, acc: 57.03%] [G loss: 1.485023]\n",
      "epoch:5 step:4236 [D loss: 0.749554, acc: 46.88%] [G loss: 1.586777]\n",
      "epoch:5 step:4237 [D loss: 0.689940, acc: 51.56%] [G loss: 1.555503]\n",
      "epoch:5 step:4238 [D loss: 0.695910, acc: 56.25%] [G loss: 1.505942]\n",
      "epoch:5 step:4239 [D loss: 0.669206, acc: 59.38%] [G loss: 1.632211]\n",
      "epoch:5 step:4240 [D loss: 0.653892, acc: 63.28%] [G loss: 1.496637]\n",
      "epoch:5 step:4241 [D loss: 0.712049, acc: 52.34%] [G loss: 1.434251]\n",
      "epoch:5 step:4242 [D loss: 0.782399, acc: 41.41%] [G loss: 1.440815]\n",
      "epoch:5 step:4243 [D loss: 0.733772, acc: 43.75%] [G loss: 1.494079]\n",
      "epoch:5 step:4244 [D loss: 0.781105, acc: 42.97%] [G loss: 1.433437]\n",
      "epoch:5 step:4245 [D loss: 0.702576, acc: 51.56%] [G loss: 1.548169]\n",
      "epoch:5 step:4246 [D loss: 0.666692, acc: 62.50%] [G loss: 1.544419]\n",
      "epoch:5 step:4247 [D loss: 0.716796, acc: 46.88%] [G loss: 1.572592]\n",
      "epoch:5 step:4248 [D loss: 0.751222, acc: 42.19%] [G loss: 1.560296]\n",
      "epoch:5 step:4249 [D loss: 0.747480, acc: 48.44%] [G loss: 1.466260]\n",
      "epoch:5 step:4250 [D loss: 0.679087, acc: 55.47%] [G loss: 1.510247]\n",
      "epoch:5 step:4251 [D loss: 0.621114, acc: 67.97%] [G loss: 1.641123]\n",
      "epoch:5 step:4252 [D loss: 0.712057, acc: 46.09%] [G loss: 1.580364]\n",
      "epoch:5 step:4253 [D loss: 0.686855, acc: 53.91%] [G loss: 1.522241]\n",
      "epoch:5 step:4254 [D loss: 0.742761, acc: 44.53%] [G loss: 1.518543]\n",
      "epoch:5 step:4255 [D loss: 0.735955, acc: 46.09%] [G loss: 1.612102]\n",
      "epoch:5 step:4256 [D loss: 0.642638, acc: 62.50%] [G loss: 1.548881]\n",
      "epoch:5 step:4257 [D loss: 0.797209, acc: 34.38%] [G loss: 1.551195]\n",
      "epoch:5 step:4258 [D loss: 0.713530, acc: 50.78%] [G loss: 1.550908]\n",
      "epoch:5 step:4259 [D loss: 0.725254, acc: 49.22%] [G loss: 1.590422]\n",
      "epoch:5 step:4260 [D loss: 0.679704, acc: 54.69%] [G loss: 1.585789]\n",
      "epoch:5 step:4261 [D loss: 0.769019, acc: 39.06%] [G loss: 1.396214]\n",
      "epoch:5 step:4262 [D loss: 0.644986, acc: 66.41%] [G loss: 1.623296]\n",
      "epoch:5 step:4263 [D loss: 0.692148, acc: 57.03%] [G loss: 1.547670]\n",
      "epoch:5 step:4264 [D loss: 0.725065, acc: 45.31%] [G loss: 1.586669]\n",
      "epoch:5 step:4265 [D loss: 0.691629, acc: 57.03%] [G loss: 1.559532]\n",
      "epoch:5 step:4266 [D loss: 0.793644, acc: 35.16%] [G loss: 1.427099]\n",
      "epoch:5 step:4267 [D loss: 0.723483, acc: 52.34%] [G loss: 1.562146]\n",
      "epoch:5 step:4268 [D loss: 0.741127, acc: 52.34%] [G loss: 1.451662]\n",
      "epoch:5 step:4269 [D loss: 0.688978, acc: 52.34%] [G loss: 1.561250]\n",
      "epoch:5 step:4270 [D loss: 0.685003, acc: 52.34%] [G loss: 1.544548]\n",
      "epoch:5 step:4271 [D loss: 0.643738, acc: 62.50%] [G loss: 1.497842]\n",
      "epoch:5 step:4272 [D loss: 0.710956, acc: 53.91%] [G loss: 1.564662]\n",
      "epoch:5 step:4273 [D loss: 0.677376, acc: 57.81%] [G loss: 1.467821]\n",
      "epoch:5 step:4274 [D loss: 0.796740, acc: 35.94%] [G loss: 1.452288]\n",
      "epoch:5 step:4275 [D loss: 0.693247, acc: 60.94%] [G loss: 1.606993]\n",
      "epoch:5 step:4276 [D loss: 0.706089, acc: 57.81%] [G loss: 1.492011]\n",
      "epoch:5 step:4277 [D loss: 0.671443, acc: 59.38%] [G loss: 1.596284]\n",
      "epoch:5 step:4278 [D loss: 0.799801, acc: 36.72%] [G loss: 1.398890]\n",
      "epoch:5 step:4279 [D loss: 0.774588, acc: 47.66%] [G loss: 1.451823]\n",
      "epoch:5 step:4280 [D loss: 0.703596, acc: 53.91%] [G loss: 1.377363]\n",
      "epoch:5 step:4281 [D loss: 0.843699, acc: 25.00%] [G loss: 1.470192]\n",
      "epoch:5 step:4282 [D loss: 0.679990, acc: 55.47%] [G loss: 1.597087]\n",
      "epoch:5 step:4283 [D loss: 0.716528, acc: 51.56%] [G loss: 1.576221]\n",
      "epoch:5 step:4284 [D loss: 0.766727, acc: 42.19%] [G loss: 1.608053]\n",
      "epoch:5 step:4285 [D loss: 0.681025, acc: 53.91%] [G loss: 1.715698]\n",
      "epoch:5 step:4286 [D loss: 0.684800, acc: 57.81%] [G loss: 1.593940]\n",
      "epoch:5 step:4287 [D loss: 0.683775, acc: 57.03%] [G loss: 1.642505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4288 [D loss: 0.693871, acc: 56.25%] [G loss: 1.558996]\n",
      "epoch:5 step:4289 [D loss: 0.697502, acc: 52.34%] [G loss: 1.642895]\n",
      "epoch:5 step:4290 [D loss: 0.682851, acc: 52.34%] [G loss: 1.598156]\n",
      "epoch:5 step:4291 [D loss: 0.705528, acc: 53.91%] [G loss: 1.601382]\n",
      "epoch:5 step:4292 [D loss: 0.675787, acc: 61.72%] [G loss: 1.573005]\n",
      "epoch:5 step:4293 [D loss: 0.717004, acc: 53.91%] [G loss: 1.494970]\n",
      "epoch:5 step:4294 [D loss: 0.704135, acc: 47.66%] [G loss: 1.499090]\n",
      "epoch:5 step:4295 [D loss: 0.749067, acc: 40.62%] [G loss: 1.511489]\n",
      "epoch:5 step:4296 [D loss: 0.667766, acc: 59.38%] [G loss: 1.566481]\n",
      "epoch:5 step:4297 [D loss: 0.697449, acc: 50.78%] [G loss: 1.504500]\n",
      "epoch:5 step:4298 [D loss: 0.715566, acc: 47.66%] [G loss: 1.348583]\n",
      "epoch:5 step:4299 [D loss: 0.690603, acc: 61.72%] [G loss: 1.513303]\n",
      "epoch:5 step:4300 [D loss: 0.735438, acc: 47.66%] [G loss: 1.590425]\n",
      "epoch:5 step:4301 [D loss: 0.692404, acc: 56.25%] [G loss: 1.652335]\n",
      "epoch:5 step:4302 [D loss: 0.730088, acc: 50.00%] [G loss: 1.576482]\n",
      "epoch:5 step:4303 [D loss: 0.706878, acc: 52.34%] [G loss: 1.508742]\n",
      "epoch:5 step:4304 [D loss: 0.751703, acc: 47.66%] [G loss: 1.473276]\n",
      "epoch:5 step:4305 [D loss: 0.740311, acc: 39.84%] [G loss: 1.493915]\n",
      "epoch:5 step:4306 [D loss: 0.669473, acc: 60.16%] [G loss: 1.570079]\n",
      "epoch:5 step:4307 [D loss: 0.779603, acc: 34.38%] [G loss: 1.537670]\n",
      "epoch:5 step:4308 [D loss: 0.629439, acc: 64.84%] [G loss: 1.578930]\n",
      "epoch:5 step:4309 [D loss: 0.693588, acc: 51.56%] [G loss: 1.567412]\n",
      "epoch:5 step:4310 [D loss: 0.744596, acc: 50.78%] [G loss: 1.705766]\n",
      "epoch:5 step:4311 [D loss: 0.699344, acc: 49.22%] [G loss: 1.602239]\n",
      "epoch:5 step:4312 [D loss: 0.743443, acc: 46.09%] [G loss: 1.570871]\n",
      "epoch:5 step:4313 [D loss: 0.775998, acc: 44.53%] [G loss: 1.546334]\n",
      "epoch:5 step:4314 [D loss: 0.714810, acc: 48.44%] [G loss: 1.464771]\n",
      "epoch:5 step:4315 [D loss: 0.732202, acc: 44.53%] [G loss: 1.509897]\n",
      "epoch:5 step:4316 [D loss: 0.681609, acc: 53.12%] [G loss: 1.564794]\n",
      "epoch:5 step:4317 [D loss: 0.690246, acc: 50.00%] [G loss: 1.643001]\n",
      "epoch:5 step:4318 [D loss: 0.666391, acc: 60.94%] [G loss: 1.622719]\n",
      "epoch:5 step:4319 [D loss: 0.719822, acc: 46.09%] [G loss: 1.473172]\n",
      "epoch:5 step:4320 [D loss: 0.699544, acc: 57.81%] [G loss: 1.608216]\n",
      "epoch:5 step:4321 [D loss: 0.779659, acc: 39.06%] [G loss: 1.570133]\n",
      "epoch:5 step:4322 [D loss: 0.586527, acc: 71.88%] [G loss: 1.797643]\n",
      "epoch:5 step:4323 [D loss: 0.652854, acc: 61.72%] [G loss: 1.557628]\n",
      "epoch:5 step:4324 [D loss: 0.630889, acc: 62.50%] [G loss: 1.539872]\n",
      "epoch:5 step:4325 [D loss: 0.751702, acc: 42.19%] [G loss: 1.530940]\n",
      "epoch:5 step:4326 [D loss: 0.734671, acc: 46.88%] [G loss: 1.497374]\n",
      "epoch:5 step:4327 [D loss: 0.747711, acc: 48.44%] [G loss: 1.624769]\n",
      "epoch:5 step:4328 [D loss: 0.715676, acc: 52.34%] [G loss: 1.582626]\n",
      "epoch:5 step:4329 [D loss: 0.725454, acc: 49.22%] [G loss: 1.601655]\n",
      "epoch:5 step:4330 [D loss: 0.762790, acc: 46.09%] [G loss: 1.630013]\n",
      "epoch:5 step:4331 [D loss: 0.711960, acc: 46.09%] [G loss: 1.430951]\n",
      "epoch:5 step:4332 [D loss: 0.750403, acc: 46.88%] [G loss: 1.568953]\n",
      "epoch:5 step:4333 [D loss: 0.775709, acc: 48.44%] [G loss: 1.487972]\n",
      "epoch:5 step:4334 [D loss: 0.723696, acc: 47.66%] [G loss: 1.500520]\n",
      "epoch:5 step:4335 [D loss: 0.799148, acc: 35.16%] [G loss: 1.495342]\n",
      "epoch:5 step:4336 [D loss: 0.746891, acc: 43.75%] [G loss: 1.538925]\n",
      "epoch:5 step:4337 [D loss: 0.646575, acc: 66.41%] [G loss: 1.758891]\n",
      "epoch:5 step:4338 [D loss: 0.740515, acc: 43.75%] [G loss: 1.438392]\n",
      "epoch:5 step:4339 [D loss: 0.787108, acc: 35.16%] [G loss: 1.460551]\n",
      "epoch:5 step:4340 [D loss: 0.779227, acc: 38.28%] [G loss: 1.436115]\n",
      "epoch:5 step:4341 [D loss: 0.697784, acc: 54.69%] [G loss: 1.559342]\n",
      "epoch:5 step:4342 [D loss: 0.795235, acc: 35.16%] [G loss: 1.488616]\n",
      "epoch:5 step:4343 [D loss: 0.717272, acc: 44.53%] [G loss: 1.550260]\n",
      "epoch:5 step:4344 [D loss: 0.672194, acc: 64.84%] [G loss: 1.592484]\n",
      "epoch:5 step:4345 [D loss: 0.744097, acc: 42.19%] [G loss: 1.529956]\n",
      "epoch:5 step:4346 [D loss: 0.701450, acc: 53.91%] [G loss: 1.552044]\n",
      "epoch:5 step:4347 [D loss: 0.705199, acc: 53.91%] [G loss: 1.607960]\n",
      "epoch:5 step:4348 [D loss: 0.715070, acc: 46.88%] [G loss: 1.522901]\n",
      "epoch:5 step:4349 [D loss: 0.686103, acc: 58.59%] [G loss: 1.470240]\n",
      "epoch:5 step:4350 [D loss: 0.725517, acc: 50.00%] [G loss: 1.565372]\n",
      "epoch:5 step:4351 [D loss: 0.735109, acc: 44.53%] [G loss: 1.576846]\n",
      "epoch:5 step:4352 [D loss: 0.666392, acc: 61.72%] [G loss: 1.508089]\n",
      "epoch:5 step:4353 [D loss: 0.737217, acc: 42.19%] [G loss: 1.649599]\n",
      "epoch:5 step:4354 [D loss: 0.654344, acc: 63.28%] [G loss: 1.444157]\n",
      "epoch:5 step:4355 [D loss: 0.705593, acc: 58.59%] [G loss: 1.475165]\n",
      "epoch:5 step:4356 [D loss: 0.690310, acc: 57.81%] [G loss: 1.533962]\n",
      "epoch:5 step:4357 [D loss: 0.761058, acc: 49.22%] [G loss: 1.623959]\n",
      "epoch:5 step:4358 [D loss: 0.599414, acc: 74.22%] [G loss: 1.708751]\n",
      "epoch:5 step:4359 [D loss: 0.714781, acc: 50.78%] [G loss: 1.488530]\n",
      "epoch:5 step:4360 [D loss: 0.721257, acc: 48.44%] [G loss: 1.523470]\n",
      "epoch:5 step:4361 [D loss: 0.740846, acc: 49.22%] [G loss: 1.499558]\n",
      "epoch:5 step:4362 [D loss: 0.702603, acc: 53.12%] [G loss: 1.559990]\n",
      "epoch:5 step:4363 [D loss: 0.657158, acc: 62.50%] [G loss: 1.545546]\n",
      "epoch:5 step:4364 [D loss: 0.706375, acc: 57.81%] [G loss: 1.505296]\n",
      "epoch:5 step:4365 [D loss: 0.757338, acc: 42.97%] [G loss: 1.514452]\n",
      "epoch:5 step:4366 [D loss: 0.715386, acc: 50.00%] [G loss: 1.552741]\n",
      "epoch:5 step:4367 [D loss: 0.658846, acc: 60.94%] [G loss: 1.682842]\n",
      "epoch:5 step:4368 [D loss: 0.761919, acc: 46.09%] [G loss: 1.496962]\n",
      "epoch:5 step:4369 [D loss: 0.695056, acc: 51.56%] [G loss: 1.735322]\n",
      "epoch:5 step:4370 [D loss: 0.662402, acc: 67.19%] [G loss: 1.495878]\n",
      "epoch:5 step:4371 [D loss: 0.839432, acc: 25.00%] [G loss: 1.453379]\n",
      "epoch:5 step:4372 [D loss: 0.704353, acc: 46.88%] [G loss: 1.613555]\n",
      "epoch:5 step:4373 [D loss: 0.721010, acc: 42.97%] [G loss: 1.566015]\n",
      "epoch:5 step:4374 [D loss: 0.669500, acc: 60.94%] [G loss: 1.601197]\n",
      "epoch:5 step:4375 [D loss: 0.730281, acc: 46.88%] [G loss: 1.529571]\n",
      "epoch:5 step:4376 [D loss: 0.798180, acc: 32.03%] [G loss: 1.435419]\n",
      "epoch:5 step:4377 [D loss: 0.723784, acc: 46.88%] [G loss: 1.495949]\n",
      "epoch:5 step:4378 [D loss: 0.702565, acc: 55.47%] [G loss: 1.539610]\n",
      "epoch:5 step:4379 [D loss: 0.757731, acc: 36.72%] [G loss: 1.522669]\n",
      "epoch:5 step:4380 [D loss: 0.712466, acc: 50.78%] [G loss: 1.605242]\n",
      "epoch:5 step:4381 [D loss: 0.709224, acc: 50.00%] [G loss: 1.602566]\n",
      "epoch:5 step:4382 [D loss: 0.688880, acc: 53.91%] [G loss: 1.576458]\n",
      "epoch:5 step:4383 [D loss: 0.679506, acc: 60.94%] [G loss: 1.556862]\n",
      "epoch:5 step:4384 [D loss: 0.755020, acc: 43.75%] [G loss: 1.493663]\n",
      "epoch:5 step:4385 [D loss: 0.734379, acc: 44.53%] [G loss: 1.504127]\n",
      "epoch:5 step:4386 [D loss: 0.733639, acc: 45.31%] [G loss: 1.510357]\n",
      "epoch:5 step:4387 [D loss: 0.708712, acc: 50.00%] [G loss: 1.568858]\n",
      "epoch:5 step:4388 [D loss: 0.736005, acc: 42.19%] [G loss: 1.530142]\n",
      "epoch:5 step:4389 [D loss: 0.714103, acc: 53.12%] [G loss: 1.592128]\n",
      "epoch:5 step:4390 [D loss: 0.693710, acc: 52.34%] [G loss: 1.488831]\n",
      "epoch:5 step:4391 [D loss: 0.711931, acc: 50.78%] [G loss: 1.467318]\n",
      "epoch:5 step:4392 [D loss: 0.716663, acc: 45.31%] [G loss: 1.559338]\n",
      "epoch:5 step:4393 [D loss: 0.716879, acc: 54.69%] [G loss: 1.576488]\n",
      "epoch:5 step:4394 [D loss: 0.709707, acc: 49.22%] [G loss: 1.519141]\n",
      "epoch:5 step:4395 [D loss: 0.675579, acc: 58.59%] [G loss: 1.563783]\n",
      "epoch:5 step:4396 [D loss: 0.706558, acc: 52.34%] [G loss: 1.477268]\n",
      "epoch:5 step:4397 [D loss: 0.683088, acc: 52.34%] [G loss: 1.549394]\n",
      "epoch:5 step:4398 [D loss: 0.828938, acc: 33.59%] [G loss: 1.413023]\n",
      "epoch:5 step:4399 [D loss: 0.714157, acc: 53.12%] [G loss: 1.535026]\n",
      "epoch:5 step:4400 [D loss: 0.675862, acc: 58.59%] [G loss: 1.640333]\n",
      "epoch:5 step:4401 [D loss: 0.635464, acc: 66.41%] [G loss: 1.687509]\n",
      "epoch:5 step:4402 [D loss: 0.682603, acc: 56.25%] [G loss: 1.594605]\n",
      "epoch:5 step:4403 [D loss: 0.718335, acc: 52.34%] [G loss: 1.532348]\n",
      "epoch:5 step:4404 [D loss: 0.732500, acc: 45.31%] [G loss: 1.470160]\n",
      "epoch:5 step:4405 [D loss: 0.706107, acc: 52.34%] [G loss: 1.490730]\n",
      "epoch:5 step:4406 [D loss: 0.660435, acc: 64.06%] [G loss: 1.747360]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4407 [D loss: 0.661351, acc: 64.06%] [G loss: 1.564485]\n",
      "epoch:5 step:4408 [D loss: 0.676220, acc: 58.59%] [G loss: 1.566050]\n",
      "epoch:5 step:4409 [D loss: 0.703020, acc: 51.56%] [G loss: 1.436596]\n",
      "epoch:5 step:4410 [D loss: 0.687879, acc: 53.12%] [G loss: 1.702813]\n",
      "epoch:5 step:4411 [D loss: 0.687475, acc: 51.56%] [G loss: 1.525493]\n",
      "epoch:5 step:4412 [D loss: 0.723861, acc: 47.66%] [G loss: 1.604403]\n",
      "epoch:5 step:4413 [D loss: 0.790073, acc: 36.72%] [G loss: 1.473808]\n",
      "epoch:5 step:4414 [D loss: 0.649031, acc: 60.94%] [G loss: 1.573430]\n",
      "epoch:5 step:4415 [D loss: 0.691878, acc: 53.12%] [G loss: 1.582727]\n",
      "epoch:5 step:4416 [D loss: 0.742848, acc: 50.78%] [G loss: 1.569382]\n",
      "epoch:5 step:4417 [D loss: 0.733755, acc: 46.09%] [G loss: 1.514215]\n",
      "epoch:5 step:4418 [D loss: 0.703281, acc: 53.12%] [G loss: 1.438823]\n",
      "epoch:5 step:4419 [D loss: 0.801616, acc: 38.28%] [G loss: 1.544143]\n",
      "epoch:5 step:4420 [D loss: 0.787817, acc: 39.06%] [G loss: 1.553386]\n",
      "epoch:5 step:4421 [D loss: 0.688719, acc: 52.34%] [G loss: 1.591613]\n",
      "epoch:5 step:4422 [D loss: 0.719581, acc: 46.09%] [G loss: 1.450903]\n",
      "epoch:5 step:4423 [D loss: 0.789723, acc: 37.50%] [G loss: 1.479345]\n",
      "epoch:5 step:4424 [D loss: 0.740401, acc: 49.22%] [G loss: 1.521851]\n",
      "epoch:5 step:4425 [D loss: 0.721696, acc: 53.91%] [G loss: 1.612505]\n",
      "epoch:5 step:4426 [D loss: 0.693165, acc: 51.56%] [G loss: 1.630875]\n",
      "epoch:5 step:4427 [D loss: 0.724985, acc: 50.78%] [G loss: 1.606658]\n",
      "epoch:5 step:4428 [D loss: 0.721439, acc: 50.00%] [G loss: 1.594612]\n",
      "epoch:5 step:4429 [D loss: 0.672653, acc: 61.72%] [G loss: 1.559998]\n",
      "epoch:5 step:4430 [D loss: 0.703679, acc: 50.00%] [G loss: 1.629275]\n",
      "epoch:5 step:4431 [D loss: 0.727922, acc: 53.12%] [G loss: 1.479756]\n",
      "epoch:5 step:4432 [D loss: 0.719085, acc: 46.88%] [G loss: 1.588917]\n",
      "epoch:5 step:4433 [D loss: 0.706785, acc: 57.81%] [G loss: 1.484012]\n",
      "epoch:5 step:4434 [D loss: 0.712027, acc: 53.12%] [G loss: 1.560146]\n",
      "epoch:5 step:4435 [D loss: 0.708768, acc: 53.12%] [G loss: 1.561051]\n",
      "epoch:5 step:4436 [D loss: 0.692823, acc: 57.81%] [G loss: 1.519792]\n",
      "epoch:5 step:4437 [D loss: 0.731282, acc: 49.22%] [G loss: 1.552114]\n",
      "epoch:5 step:4438 [D loss: 0.759784, acc: 48.44%] [G loss: 1.428647]\n",
      "epoch:5 step:4439 [D loss: 0.674165, acc: 61.72%] [G loss: 1.561896]\n",
      "epoch:5 step:4440 [D loss: 0.765934, acc: 42.97%] [G loss: 1.500027]\n",
      "epoch:5 step:4441 [D loss: 0.681445, acc: 62.50%] [G loss: 1.589314]\n",
      "epoch:5 step:4442 [D loss: 0.777282, acc: 41.41%] [G loss: 1.507686]\n",
      "epoch:5 step:4443 [D loss: 0.666982, acc: 60.94%] [G loss: 1.591959]\n",
      "epoch:5 step:4444 [D loss: 0.708572, acc: 50.78%] [G loss: 1.529566]\n",
      "epoch:5 step:4445 [D loss: 0.703442, acc: 52.34%] [G loss: 1.593165]\n",
      "epoch:5 step:4446 [D loss: 0.659806, acc: 58.59%] [G loss: 1.595846]\n",
      "epoch:5 step:4447 [D loss: 0.696936, acc: 52.34%] [G loss: 1.515427]\n",
      "epoch:5 step:4448 [D loss: 0.674633, acc: 57.03%] [G loss: 1.488600]\n",
      "epoch:5 step:4449 [D loss: 0.713163, acc: 53.91%] [G loss: 1.555958]\n",
      "epoch:5 step:4450 [D loss: 0.705451, acc: 50.00%] [G loss: 1.587901]\n",
      "epoch:5 step:4451 [D loss: 0.741383, acc: 51.56%] [G loss: 1.523703]\n",
      "epoch:5 step:4452 [D loss: 0.644208, acc: 66.41%] [G loss: 1.650501]\n",
      "epoch:5 step:4453 [D loss: 0.695557, acc: 57.81%] [G loss: 1.547908]\n",
      "epoch:5 step:4454 [D loss: 0.761458, acc: 44.53%] [G loss: 1.455354]\n",
      "epoch:5 step:4455 [D loss: 0.694035, acc: 49.22%] [G loss: 1.658193]\n",
      "epoch:5 step:4456 [D loss: 0.630235, acc: 64.84%] [G loss: 1.570139]\n",
      "epoch:5 step:4457 [D loss: 0.701730, acc: 54.69%] [G loss: 1.430374]\n",
      "epoch:5 step:4458 [D loss: 0.755193, acc: 39.06%] [G loss: 1.402681]\n",
      "epoch:5 step:4459 [D loss: 0.681722, acc: 60.16%] [G loss: 1.577827]\n",
      "epoch:5 step:4460 [D loss: 0.682668, acc: 56.25%] [G loss: 1.487204]\n",
      "epoch:5 step:4461 [D loss: 0.737381, acc: 46.88%] [G loss: 1.473387]\n",
      "epoch:5 step:4462 [D loss: 0.716514, acc: 48.44%] [G loss: 1.610188]\n",
      "epoch:5 step:4463 [D loss: 0.725598, acc: 43.75%] [G loss: 1.469361]\n",
      "epoch:5 step:4464 [D loss: 0.755404, acc: 46.88%] [G loss: 1.495862]\n",
      "epoch:5 step:4465 [D loss: 0.641765, acc: 60.16%] [G loss: 1.587177]\n",
      "epoch:5 step:4466 [D loss: 0.721535, acc: 54.69%] [G loss: 1.509750]\n",
      "epoch:5 step:4467 [D loss: 0.732261, acc: 52.34%] [G loss: 1.509442]\n",
      "epoch:5 step:4468 [D loss: 0.788992, acc: 32.81%] [G loss: 1.464724]\n",
      "epoch:5 step:4469 [D loss: 0.712969, acc: 51.56%] [G loss: 1.564828]\n",
      "epoch:5 step:4470 [D loss: 0.655208, acc: 64.84%] [G loss: 1.632502]\n",
      "epoch:5 step:4471 [D loss: 0.740242, acc: 43.75%] [G loss: 1.564216]\n",
      "epoch:5 step:4472 [D loss: 0.677883, acc: 60.16%] [G loss: 1.504858]\n",
      "epoch:5 step:4473 [D loss: 0.725201, acc: 50.78%] [G loss: 1.532720]\n",
      "epoch:5 step:4474 [D loss: 0.786623, acc: 39.84%] [G loss: 1.499663]\n",
      "epoch:5 step:4475 [D loss: 0.731857, acc: 46.88%] [G loss: 1.579489]\n",
      "epoch:5 step:4476 [D loss: 0.683202, acc: 57.81%] [G loss: 1.637733]\n",
      "epoch:5 step:4477 [D loss: 0.679620, acc: 57.81%] [G loss: 1.689480]\n",
      "epoch:5 step:4478 [D loss: 0.693825, acc: 55.47%] [G loss: 1.574238]\n",
      "epoch:5 step:4479 [D loss: 0.792469, acc: 34.38%] [G loss: 1.623504]\n",
      "epoch:5 step:4480 [D loss: 0.744174, acc: 48.44%] [G loss: 1.548969]\n",
      "epoch:5 step:4481 [D loss: 0.738177, acc: 39.06%] [G loss: 1.596835]\n",
      "epoch:5 step:4482 [D loss: 0.660285, acc: 59.38%] [G loss: 1.740281]\n",
      "epoch:5 step:4483 [D loss: 0.735633, acc: 42.19%] [G loss: 1.572430]\n",
      "epoch:5 step:4484 [D loss: 0.663714, acc: 60.16%] [G loss: 1.523142]\n",
      "epoch:5 step:4485 [D loss: 0.784311, acc: 33.59%] [G loss: 1.459740]\n",
      "epoch:5 step:4486 [D loss: 0.670169, acc: 53.12%] [G loss: 1.614023]\n",
      "epoch:5 step:4487 [D loss: 0.701246, acc: 55.47%] [G loss: 1.598102]\n",
      "epoch:5 step:4488 [D loss: 0.668063, acc: 60.16%] [G loss: 1.476596]\n",
      "epoch:5 step:4489 [D loss: 0.701281, acc: 55.47%] [G loss: 1.585207]\n",
      "epoch:5 step:4490 [D loss: 0.702273, acc: 50.00%] [G loss: 1.578785]\n",
      "epoch:5 step:4491 [D loss: 0.736851, acc: 53.12%] [G loss: 1.569805]\n",
      "epoch:5 step:4492 [D loss: 0.728940, acc: 42.97%] [G loss: 1.518792]\n",
      "epoch:5 step:4493 [D loss: 0.740623, acc: 46.88%] [G loss: 1.493737]\n",
      "epoch:5 step:4494 [D loss: 0.690309, acc: 48.44%] [G loss: 1.546838]\n",
      "epoch:5 step:4495 [D loss: 0.702763, acc: 57.81%] [G loss: 1.554267]\n",
      "epoch:5 step:4496 [D loss: 0.753871, acc: 37.50%] [G loss: 1.563807]\n",
      "epoch:5 step:4497 [D loss: 0.671074, acc: 60.94%] [G loss: 1.505579]\n",
      "epoch:5 step:4498 [D loss: 0.713774, acc: 50.00%] [G loss: 1.694294]\n",
      "epoch:5 step:4499 [D loss: 0.692244, acc: 53.12%] [G loss: 1.578354]\n",
      "epoch:5 step:4500 [D loss: 0.713272, acc: 48.44%] [G loss: 1.519266]\n",
      "epoch:5 step:4501 [D loss: 0.666310, acc: 58.59%] [G loss: 1.641593]\n",
      "epoch:5 step:4502 [D loss: 0.687913, acc: 50.00%] [G loss: 1.549228]\n",
      "epoch:5 step:4503 [D loss: 0.751731, acc: 47.66%] [G loss: 1.538900]\n",
      "epoch:5 step:4504 [D loss: 0.707898, acc: 49.22%] [G loss: 1.605518]\n",
      "epoch:5 step:4505 [D loss: 0.687270, acc: 53.12%] [G loss: 1.649647]\n",
      "epoch:5 step:4506 [D loss: 0.691018, acc: 57.03%] [G loss: 1.658679]\n",
      "epoch:5 step:4507 [D loss: 0.645038, acc: 71.09%] [G loss: 1.679826]\n",
      "epoch:5 step:4508 [D loss: 0.752815, acc: 41.41%] [G loss: 1.515800]\n",
      "epoch:5 step:4509 [D loss: 0.661957, acc: 60.94%] [G loss: 1.720508]\n",
      "epoch:5 step:4510 [D loss: 0.700034, acc: 57.03%] [G loss: 1.568606]\n",
      "epoch:5 step:4511 [D loss: 0.631605, acc: 64.06%] [G loss: 1.634258]\n",
      "epoch:5 step:4512 [D loss: 0.764205, acc: 40.62%] [G loss: 1.510288]\n",
      "epoch:5 step:4513 [D loss: 0.662061, acc: 61.72%] [G loss: 1.659163]\n",
      "epoch:5 step:4514 [D loss: 0.720082, acc: 46.88%] [G loss: 1.515456]\n",
      "epoch:5 step:4515 [D loss: 0.625319, acc: 68.75%] [G loss: 1.664375]\n",
      "epoch:5 step:4516 [D loss: 0.669996, acc: 61.72%] [G loss: 1.557931]\n",
      "epoch:5 step:4517 [D loss: 0.693684, acc: 54.69%] [G loss: 1.616447]\n",
      "epoch:5 step:4518 [D loss: 0.781335, acc: 44.53%] [G loss: 1.398048]\n",
      "epoch:5 step:4519 [D loss: 0.653024, acc: 60.94%] [G loss: 1.584655]\n",
      "epoch:5 step:4520 [D loss: 0.623404, acc: 67.97%] [G loss: 1.512314]\n",
      "epoch:5 step:4521 [D loss: 0.665280, acc: 65.62%] [G loss: 1.590611]\n",
      "epoch:5 step:4522 [D loss: 0.784017, acc: 41.41%] [G loss: 1.400073]\n",
      "epoch:5 step:4523 [D loss: 0.744911, acc: 46.09%] [G loss: 1.485638]\n",
      "epoch:5 step:4524 [D loss: 0.713793, acc: 53.12%] [G loss: 1.546708]\n",
      "epoch:5 step:4525 [D loss: 0.821819, acc: 34.38%] [G loss: 1.464786]\n",
      "epoch:5 step:4526 [D loss: 0.704263, acc: 51.56%] [G loss: 1.446159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4527 [D loss: 0.703880, acc: 58.59%] [G loss: 1.532722]\n",
      "epoch:5 step:4528 [D loss: 0.752193, acc: 48.44%] [G loss: 1.534880]\n",
      "epoch:5 step:4529 [D loss: 0.692127, acc: 57.03%] [G loss: 1.597987]\n",
      "epoch:5 step:4530 [D loss: 0.680704, acc: 53.12%] [G loss: 1.628816]\n",
      "epoch:5 step:4531 [D loss: 0.696913, acc: 58.59%] [G loss: 1.604841]\n",
      "epoch:5 step:4532 [D loss: 0.614920, acc: 67.97%] [G loss: 1.636300]\n",
      "epoch:5 step:4533 [D loss: 0.644451, acc: 62.50%] [G loss: 1.604277]\n",
      "epoch:5 step:4534 [D loss: 0.616716, acc: 67.97%] [G loss: 1.542913]\n",
      "epoch:5 step:4535 [D loss: 0.720852, acc: 53.12%] [G loss: 1.535515]\n",
      "epoch:5 step:4536 [D loss: 0.611991, acc: 72.66%] [G loss: 1.649697]\n",
      "epoch:5 step:4537 [D loss: 0.696035, acc: 57.03%] [G loss: 1.339662]\n",
      "epoch:5 step:4538 [D loss: 0.810979, acc: 34.38%] [G loss: 1.490469]\n",
      "epoch:5 step:4539 [D loss: 0.646977, acc: 64.84%] [G loss: 1.526357]\n",
      "epoch:5 step:4540 [D loss: 0.742899, acc: 42.97%] [G loss: 1.552966]\n",
      "epoch:5 step:4541 [D loss: 0.726914, acc: 42.97%] [G loss: 1.488489]\n",
      "epoch:5 step:4542 [D loss: 0.638543, acc: 65.62%] [G loss: 1.596594]\n",
      "epoch:5 step:4543 [D loss: 0.775718, acc: 39.84%] [G loss: 1.314901]\n",
      "epoch:5 step:4544 [D loss: 0.693913, acc: 57.81%] [G loss: 1.515370]\n",
      "epoch:5 step:4545 [D loss: 0.736161, acc: 44.53%] [G loss: 1.531038]\n",
      "epoch:5 step:4546 [D loss: 0.723000, acc: 48.44%] [G loss: 1.499060]\n",
      "epoch:5 step:4547 [D loss: 0.759097, acc: 46.09%] [G loss: 1.597089]\n",
      "epoch:5 step:4548 [D loss: 0.616127, acc: 67.19%] [G loss: 1.693938]\n",
      "epoch:5 step:4549 [D loss: 0.712798, acc: 57.81%] [G loss: 1.645641]\n",
      "epoch:5 step:4550 [D loss: 0.756180, acc: 45.31%] [G loss: 1.283533]\n",
      "epoch:5 step:4551 [D loss: 0.742729, acc: 45.31%] [G loss: 1.564896]\n",
      "epoch:5 step:4552 [D loss: 0.699737, acc: 53.12%] [G loss: 1.635554]\n",
      "epoch:5 step:4553 [D loss: 0.700644, acc: 51.56%] [G loss: 1.573004]\n",
      "epoch:5 step:4554 [D loss: 0.681306, acc: 56.25%] [G loss: 1.602577]\n",
      "epoch:5 step:4555 [D loss: 0.665046, acc: 67.19%] [G loss: 1.698523]\n",
      "epoch:5 step:4556 [D loss: 0.657843, acc: 60.94%] [G loss: 1.580131]\n",
      "epoch:5 step:4557 [D loss: 0.673039, acc: 60.94%] [G loss: 1.568572]\n",
      "epoch:5 step:4558 [D loss: 0.589995, acc: 71.88%] [G loss: 1.514919]\n",
      "epoch:5 step:4559 [D loss: 0.639436, acc: 63.28%] [G loss: 1.552066]\n",
      "epoch:5 step:4560 [D loss: 0.549874, acc: 79.69%] [G loss: 1.691045]\n",
      "epoch:5 step:4561 [D loss: 0.653376, acc: 60.16%] [G loss: 1.588568]\n",
      "epoch:5 step:4562 [D loss: 0.731154, acc: 45.31%] [G loss: 1.681951]\n",
      "epoch:5 step:4563 [D loss: 0.591357, acc: 71.88%] [G loss: 1.680050]\n",
      "epoch:5 step:4564 [D loss: 0.750955, acc: 42.19%] [G loss: 1.745122]\n",
      "epoch:5 step:4565 [D loss: 0.670022, acc: 62.50%] [G loss: 1.576623]\n",
      "epoch:5 step:4566 [D loss: 0.717944, acc: 45.31%] [G loss: 1.684079]\n",
      "epoch:5 step:4567 [D loss: 0.803110, acc: 42.97%] [G loss: 1.476891]\n",
      "epoch:5 step:4568 [D loss: 0.679076, acc: 59.38%] [G loss: 1.734678]\n",
      "epoch:5 step:4569 [D loss: 0.744821, acc: 42.97%] [G loss: 1.607984]\n",
      "epoch:5 step:4570 [D loss: 0.787315, acc: 45.31%] [G loss: 1.588964]\n",
      "epoch:5 step:4571 [D loss: 0.553485, acc: 79.69%] [G loss: 1.633360]\n",
      "epoch:5 step:4572 [D loss: 0.630270, acc: 68.75%] [G loss: 1.606341]\n",
      "epoch:5 step:4573 [D loss: 0.689774, acc: 57.03%] [G loss: 1.557408]\n",
      "epoch:5 step:4574 [D loss: 0.623271, acc: 67.19%] [G loss: 1.583252]\n",
      "epoch:5 step:4575 [D loss: 0.715363, acc: 54.69%] [G loss: 1.517110]\n",
      "epoch:5 step:4576 [D loss: 0.681920, acc: 58.59%] [G loss: 1.459447]\n",
      "epoch:5 step:4577 [D loss: 0.722838, acc: 50.78%] [G loss: 1.314777]\n",
      "epoch:5 step:4578 [D loss: 0.852315, acc: 28.12%] [G loss: 1.349778]\n",
      "epoch:5 step:4579 [D loss: 0.679010, acc: 57.81%] [G loss: 1.571013]\n",
      "epoch:5 step:4580 [D loss: 0.714243, acc: 60.16%] [G loss: 1.452381]\n",
      "epoch:5 step:4581 [D loss: 0.662148, acc: 57.03%] [G loss: 1.543061]\n",
      "epoch:5 step:4582 [D loss: 0.571782, acc: 76.56%] [G loss: 1.444421]\n",
      "epoch:5 step:4583 [D loss: 0.805260, acc: 36.72%] [G loss: 1.397567]\n",
      "epoch:5 step:4584 [D loss: 0.886466, acc: 22.66%] [G loss: 1.319399]\n",
      "epoch:5 step:4585 [D loss: 0.626106, acc: 66.41%] [G loss: 1.581468]\n",
      "epoch:5 step:4586 [D loss: 0.736070, acc: 46.88%] [G loss: 1.466027]\n",
      "epoch:5 step:4587 [D loss: 0.701239, acc: 50.78%] [G loss: 1.685647]\n",
      "epoch:5 step:4588 [D loss: 0.638888, acc: 57.81%] [G loss: 1.656515]\n",
      "epoch:5 step:4589 [D loss: 0.727269, acc: 50.00%] [G loss: 1.666243]\n",
      "epoch:5 step:4590 [D loss: 0.746714, acc: 44.53%] [G loss: 1.632982]\n",
      "epoch:5 step:4591 [D loss: 0.689991, acc: 57.81%] [G loss: 1.756233]\n",
      "epoch:5 step:4592 [D loss: 0.666927, acc: 61.72%] [G loss: 1.651578]\n",
      "epoch:5 step:4593 [D loss: 0.701484, acc: 54.69%] [G loss: 1.546524]\n",
      "epoch:5 step:4594 [D loss: 0.690886, acc: 58.59%] [G loss: 1.757868]\n",
      "epoch:5 step:4595 [D loss: 0.635376, acc: 67.97%] [G loss: 1.681808]\n",
      "epoch:5 step:4596 [D loss: 0.739684, acc: 54.69%] [G loss: 1.551336]\n",
      "epoch:5 step:4597 [D loss: 0.772316, acc: 42.97%] [G loss: 1.589647]\n",
      "epoch:5 step:4598 [D loss: 0.700201, acc: 50.00%] [G loss: 1.489885]\n",
      "epoch:5 step:4599 [D loss: 0.712199, acc: 53.12%] [G loss: 1.497003]\n",
      "epoch:5 step:4600 [D loss: 0.580714, acc: 71.09%] [G loss: 1.638568]\n",
      "epoch:5 step:4601 [D loss: 0.663453, acc: 58.59%] [G loss: 1.592301]\n",
      "epoch:5 step:4602 [D loss: 0.666834, acc: 57.81%] [G loss: 1.458209]\n",
      "epoch:5 step:4603 [D loss: 0.564296, acc: 76.56%] [G loss: 1.613016]\n",
      "epoch:5 step:4604 [D loss: 0.681238, acc: 53.12%] [G loss: 1.515193]\n",
      "epoch:5 step:4605 [D loss: 0.756387, acc: 43.75%] [G loss: 1.512329]\n",
      "epoch:5 step:4606 [D loss: 0.766993, acc: 48.44%] [G loss: 1.519318]\n",
      "epoch:5 step:4607 [D loss: 0.789103, acc: 39.06%] [G loss: 1.389829]\n",
      "epoch:5 step:4608 [D loss: 0.733688, acc: 50.78%] [G loss: 1.622453]\n",
      "epoch:5 step:4609 [D loss: 0.748572, acc: 43.75%] [G loss: 1.441568]\n",
      "epoch:5 step:4610 [D loss: 0.630605, acc: 64.84%] [G loss: 1.616373]\n",
      "epoch:5 step:4611 [D loss: 0.572235, acc: 75.00%] [G loss: 1.778626]\n",
      "epoch:5 step:4612 [D loss: 0.749457, acc: 42.97%] [G loss: 1.443811]\n",
      "epoch:5 step:4613 [D loss: 0.840411, acc: 25.00%] [G loss: 1.469607]\n",
      "epoch:5 step:4614 [D loss: 0.673094, acc: 61.72%] [G loss: 1.771958]\n",
      "epoch:5 step:4615 [D loss: 0.777226, acc: 42.97%] [G loss: 1.664999]\n",
      "epoch:5 step:4616 [D loss: 0.758466, acc: 39.84%] [G loss: 1.736796]\n",
      "epoch:5 step:4617 [D loss: 0.696279, acc: 51.56%] [G loss: 1.671589]\n",
      "epoch:5 step:4618 [D loss: 0.726858, acc: 48.44%] [G loss: 1.651526]\n",
      "epoch:5 step:4619 [D loss: 0.651780, acc: 63.28%] [G loss: 1.589158]\n",
      "epoch:5 step:4620 [D loss: 0.761163, acc: 44.53%] [G loss: 1.765457]\n",
      "epoch:5 step:4621 [D loss: 0.581580, acc: 74.22%] [G loss: 1.742388]\n",
      "epoch:5 step:4622 [D loss: 0.603327, acc: 74.22%] [G loss: 1.839156]\n",
      "epoch:5 step:4623 [D loss: 0.663334, acc: 59.38%] [G loss: 1.680345]\n",
      "epoch:5 step:4624 [D loss: 0.683180, acc: 53.12%] [G loss: 1.731928]\n",
      "epoch:5 step:4625 [D loss: 0.680944, acc: 55.47%] [G loss: 1.594409]\n",
      "epoch:5 step:4626 [D loss: 0.840896, acc: 32.03%] [G loss: 1.448971]\n",
      "epoch:5 step:4627 [D loss: 0.662699, acc: 63.28%] [G loss: 1.668092]\n",
      "epoch:5 step:4628 [D loss: 0.735199, acc: 43.75%] [G loss: 1.540911]\n",
      "epoch:5 step:4629 [D loss: 0.740478, acc: 43.75%] [G loss: 1.623952]\n",
      "epoch:5 step:4630 [D loss: 0.743222, acc: 46.88%] [G loss: 1.712998]\n",
      "epoch:5 step:4631 [D loss: 0.704955, acc: 49.22%] [G loss: 1.607389]\n",
      "epoch:5 step:4632 [D loss: 0.784549, acc: 43.75%] [G loss: 1.498687]\n",
      "epoch:5 step:4633 [D loss: 0.723125, acc: 53.12%] [G loss: 1.539220]\n",
      "epoch:5 step:4634 [D loss: 0.780257, acc: 35.16%] [G loss: 1.575835]\n",
      "epoch:5 step:4635 [D loss: 0.688039, acc: 58.59%] [G loss: 1.628638]\n",
      "epoch:5 step:4636 [D loss: 0.627795, acc: 61.72%] [G loss: 1.604841]\n",
      "epoch:5 step:4637 [D loss: 0.729538, acc: 50.78%] [G loss: 1.563996]\n",
      "epoch:5 step:4638 [D loss: 0.774627, acc: 40.62%] [G loss: 1.639307]\n",
      "epoch:5 step:4639 [D loss: 0.781774, acc: 47.66%] [G loss: 1.431435]\n",
      "epoch:5 step:4640 [D loss: 0.707907, acc: 49.22%] [G loss: 1.623755]\n",
      "epoch:5 step:4641 [D loss: 0.709680, acc: 52.34%] [G loss: 1.562384]\n",
      "epoch:5 step:4642 [D loss: 0.722287, acc: 48.44%] [G loss: 1.523708]\n",
      "epoch:5 step:4643 [D loss: 0.809724, acc: 28.91%] [G loss: 1.419274]\n",
      "epoch:5 step:4644 [D loss: 0.784026, acc: 34.38%] [G loss: 1.555201]\n",
      "epoch:5 step:4645 [D loss: 0.794638, acc: 35.94%] [G loss: 1.501101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4646 [D loss: 0.694737, acc: 55.47%] [G loss: 1.560387]\n",
      "epoch:5 step:4647 [D loss: 0.790904, acc: 40.62%] [G loss: 1.444554]\n",
      "epoch:5 step:4648 [D loss: 0.664403, acc: 57.81%] [G loss: 1.483820]\n",
      "epoch:5 step:4649 [D loss: 0.749416, acc: 44.53%] [G loss: 1.580849]\n",
      "epoch:5 step:4650 [D loss: 0.679969, acc: 57.81%] [G loss: 1.566446]\n",
      "epoch:5 step:4651 [D loss: 0.708210, acc: 53.91%] [G loss: 1.667717]\n",
      "epoch:5 step:4652 [D loss: 0.714162, acc: 51.56%] [G loss: 1.644384]\n",
      "epoch:5 step:4653 [D loss: 0.646167, acc: 57.81%] [G loss: 1.478848]\n",
      "epoch:5 step:4654 [D loss: 0.675641, acc: 60.16%] [G loss: 1.606639]\n",
      "epoch:5 step:4655 [D loss: 0.632306, acc: 65.62%] [G loss: 1.559664]\n",
      "epoch:5 step:4656 [D loss: 0.658318, acc: 56.25%] [G loss: 1.521805]\n",
      "epoch:5 step:4657 [D loss: 0.638529, acc: 60.94%] [G loss: 1.710052]\n",
      "epoch:5 step:4658 [D loss: 0.810787, acc: 42.19%] [G loss: 1.546179]\n",
      "epoch:5 step:4659 [D loss: 0.769682, acc: 36.72%] [G loss: 1.542267]\n",
      "epoch:5 step:4660 [D loss: 0.728865, acc: 47.66%] [G loss: 1.666175]\n",
      "epoch:5 step:4661 [D loss: 0.692320, acc: 63.28%] [G loss: 1.504967]\n",
      "epoch:5 step:4662 [D loss: 0.636066, acc: 66.41%] [G loss: 1.587374]\n",
      "epoch:5 step:4663 [D loss: 0.730134, acc: 46.09%] [G loss: 1.528044]\n",
      "epoch:5 step:4664 [D loss: 0.825035, acc: 35.16%] [G loss: 1.508703]\n",
      "epoch:5 step:4665 [D loss: 0.696701, acc: 56.25%] [G loss: 1.550006]\n",
      "epoch:5 step:4666 [D loss: 0.711070, acc: 55.47%] [G loss: 1.634270]\n",
      "epoch:5 step:4667 [D loss: 0.772797, acc: 35.16%] [G loss: 1.652387]\n",
      "epoch:5 step:4668 [D loss: 0.702902, acc: 52.34%] [G loss: 1.622238]\n",
      "epoch:5 step:4669 [D loss: 0.708474, acc: 52.34%] [G loss: 1.523149]\n",
      "epoch:5 step:4670 [D loss: 0.665697, acc: 63.28%] [G loss: 1.662924]\n",
      "epoch:5 step:4671 [D loss: 0.604367, acc: 72.66%] [G loss: 1.586108]\n",
      "epoch:5 step:4672 [D loss: 0.736532, acc: 42.97%] [G loss: 1.604891]\n",
      "epoch:5 step:4673 [D loss: 0.709846, acc: 57.03%] [G loss: 1.659529]\n",
      "epoch:5 step:4674 [D loss: 0.668783, acc: 53.91%] [G loss: 1.593446]\n",
      "epoch:5 step:4675 [D loss: 0.578109, acc: 72.66%] [G loss: 1.638303]\n",
      "epoch:5 step:4676 [D loss: 0.771073, acc: 34.38%] [G loss: 1.512579]\n",
      "epoch:5 step:4677 [D loss: 0.758772, acc: 47.66%] [G loss: 1.609446]\n",
      "epoch:5 step:4678 [D loss: 0.684527, acc: 50.00%] [G loss: 1.509047]\n",
      "epoch:5 step:4679 [D loss: 0.758716, acc: 39.06%] [G loss: 1.352154]\n",
      "epoch:5 step:4680 [D loss: 0.758049, acc: 38.28%] [G loss: 1.498895]\n",
      "epoch:5 step:4681 [D loss: 0.722572, acc: 46.88%] [G loss: 1.550421]\n",
      "epoch:5 step:4682 [D loss: 0.723472, acc: 53.12%] [G loss: 1.678931]\n",
      "epoch:5 step:4683 [D loss: 0.549472, acc: 79.69%] [G loss: 1.628926]\n",
      "epoch:5 step:4684 [D loss: 0.789741, acc: 40.62%] [G loss: 1.404299]\n",
      "epoch:5 step:4685 [D loss: 0.749274, acc: 44.53%] [G loss: 1.442213]\n",
      "epoch:5 step:4686 [D loss: 0.587998, acc: 76.56%] [G loss: 1.536258]\n",
      "epoch:6 step:4687 [D loss: 0.603342, acc: 73.44%] [G loss: 1.585781]\n",
      "epoch:6 step:4688 [D loss: 0.749929, acc: 47.66%] [G loss: 1.508035]\n",
      "epoch:6 step:4689 [D loss: 0.658641, acc: 62.50%] [G loss: 1.602494]\n",
      "epoch:6 step:4690 [D loss: 0.760297, acc: 46.88%] [G loss: 1.447412]\n",
      "epoch:6 step:4691 [D loss: 0.813997, acc: 32.81%] [G loss: 1.502438]\n",
      "epoch:6 step:4692 [D loss: 0.737427, acc: 42.97%] [G loss: 1.503325]\n",
      "epoch:6 step:4693 [D loss: 0.781207, acc: 41.41%] [G loss: 1.517181]\n",
      "epoch:6 step:4694 [D loss: 0.686727, acc: 54.69%] [G loss: 1.483217]\n",
      "epoch:6 step:4695 [D loss: 0.847835, acc: 20.31%] [G loss: 1.280015]\n",
      "epoch:6 step:4696 [D loss: 0.616071, acc: 72.66%] [G loss: 1.519232]\n",
      "epoch:6 step:4697 [D loss: 0.720680, acc: 46.88%] [G loss: 1.580733]\n",
      "epoch:6 step:4698 [D loss: 0.697314, acc: 54.69%] [G loss: 1.379768]\n",
      "epoch:6 step:4699 [D loss: 0.782965, acc: 41.41%] [G loss: 1.543698]\n",
      "epoch:6 step:4700 [D loss: 0.736521, acc: 42.97%] [G loss: 1.572757]\n",
      "epoch:6 step:4701 [D loss: 0.696798, acc: 50.78%] [G loss: 1.511117]\n",
      "epoch:6 step:4702 [D loss: 0.710127, acc: 53.12%] [G loss: 1.479740]\n",
      "epoch:6 step:4703 [D loss: 0.737264, acc: 44.53%] [G loss: 1.516396]\n",
      "epoch:6 step:4704 [D loss: 0.667821, acc: 63.28%] [G loss: 1.602071]\n",
      "epoch:6 step:4705 [D loss: 0.694611, acc: 52.34%] [G loss: 1.514669]\n",
      "epoch:6 step:4706 [D loss: 0.707100, acc: 51.56%] [G loss: 1.523309]\n",
      "epoch:6 step:4707 [D loss: 0.671105, acc: 62.50%] [G loss: 1.406445]\n",
      "epoch:6 step:4708 [D loss: 0.637977, acc: 63.28%] [G loss: 1.605135]\n",
      "epoch:6 step:4709 [D loss: 0.803937, acc: 37.50%] [G loss: 1.389588]\n",
      "epoch:6 step:4710 [D loss: 0.706512, acc: 52.34%] [G loss: 1.521731]\n",
      "epoch:6 step:4711 [D loss: 0.645012, acc: 64.06%] [G loss: 1.578277]\n",
      "epoch:6 step:4712 [D loss: 0.723200, acc: 46.09%] [G loss: 1.483248]\n",
      "epoch:6 step:4713 [D loss: 0.701562, acc: 52.34%] [G loss: 1.466779]\n",
      "epoch:6 step:4714 [D loss: 0.763128, acc: 33.59%] [G loss: 1.445087]\n",
      "epoch:6 step:4715 [D loss: 0.749405, acc: 42.19%] [G loss: 1.505448]\n",
      "epoch:6 step:4716 [D loss: 0.678860, acc: 57.03%] [G loss: 1.809674]\n",
      "epoch:6 step:4717 [D loss: 0.788002, acc: 35.94%] [G loss: 1.443404]\n",
      "epoch:6 step:4718 [D loss: 0.603557, acc: 71.88%] [G loss: 1.637589]\n",
      "epoch:6 step:4719 [D loss: 0.700201, acc: 53.91%] [G loss: 1.582309]\n",
      "epoch:6 step:4720 [D loss: 0.687732, acc: 54.69%] [G loss: 1.502193]\n",
      "epoch:6 step:4721 [D loss: 0.849009, acc: 24.22%] [G loss: 1.420609]\n",
      "epoch:6 step:4722 [D loss: 0.761352, acc: 37.50%] [G loss: 1.538977]\n",
      "epoch:6 step:4723 [D loss: 0.764755, acc: 42.97%] [G loss: 1.493642]\n",
      "epoch:6 step:4724 [D loss: 0.764261, acc: 43.75%] [G loss: 1.535659]\n",
      "epoch:6 step:4725 [D loss: 0.680210, acc: 57.03%] [G loss: 1.732183]\n",
      "epoch:6 step:4726 [D loss: 0.774128, acc: 44.53%] [G loss: 1.754837]\n",
      "epoch:6 step:4727 [D loss: 0.689695, acc: 53.91%] [G loss: 1.572896]\n",
      "epoch:6 step:4728 [D loss: 0.644995, acc: 66.41%] [G loss: 1.657872]\n",
      "epoch:6 step:4729 [D loss: 0.764359, acc: 41.41%] [G loss: 1.498508]\n",
      "epoch:6 step:4730 [D loss: 0.749374, acc: 45.31%] [G loss: 1.623199]\n",
      "epoch:6 step:4731 [D loss: 0.693051, acc: 49.22%] [G loss: 1.558834]\n",
      "epoch:6 step:4732 [D loss: 0.699587, acc: 46.09%] [G loss: 1.466341]\n",
      "epoch:6 step:4733 [D loss: 0.658031, acc: 62.50%] [G loss: 1.662561]\n",
      "epoch:6 step:4734 [D loss: 0.693573, acc: 56.25%] [G loss: 1.569803]\n",
      "epoch:6 step:4735 [D loss: 0.765596, acc: 45.31%] [G loss: 1.462418]\n",
      "epoch:6 step:4736 [D loss: 0.787670, acc: 32.81%] [G loss: 1.430401]\n",
      "epoch:6 step:4737 [D loss: 0.743023, acc: 46.88%] [G loss: 1.551633]\n",
      "epoch:6 step:4738 [D loss: 0.634174, acc: 60.16%] [G loss: 1.751096]\n",
      "epoch:6 step:4739 [D loss: 0.731649, acc: 46.88%] [G loss: 1.477564]\n",
      "epoch:6 step:4740 [D loss: 0.686845, acc: 61.72%] [G loss: 1.564339]\n",
      "epoch:6 step:4741 [D loss: 0.701173, acc: 55.47%] [G loss: 1.618539]\n",
      "epoch:6 step:4742 [D loss: 0.653690, acc: 55.47%] [G loss: 1.661411]\n",
      "epoch:6 step:4743 [D loss: 0.651315, acc: 64.06%] [G loss: 1.645137]\n",
      "epoch:6 step:4744 [D loss: 0.700071, acc: 51.56%] [G loss: 1.675701]\n",
      "epoch:6 step:4745 [D loss: 0.641648, acc: 64.84%] [G loss: 1.547351]\n",
      "epoch:6 step:4746 [D loss: 0.641862, acc: 67.97%] [G loss: 1.559369]\n",
      "epoch:6 step:4747 [D loss: 0.748283, acc: 40.62%] [G loss: 1.488525]\n",
      "epoch:6 step:4748 [D loss: 0.678062, acc: 56.25%] [G loss: 1.513721]\n",
      "epoch:6 step:4749 [D loss: 0.658915, acc: 61.72%] [G loss: 1.765883]\n",
      "epoch:6 step:4750 [D loss: 0.601947, acc: 67.97%] [G loss: 1.506615]\n",
      "epoch:6 step:4751 [D loss: 0.727873, acc: 47.66%] [G loss: 1.426593]\n",
      "epoch:6 step:4752 [D loss: 0.611185, acc: 67.19%] [G loss: 1.560349]\n",
      "epoch:6 step:4753 [D loss: 0.636768, acc: 59.38%] [G loss: 1.533545]\n",
      "epoch:6 step:4754 [D loss: 0.575589, acc: 78.12%] [G loss: 1.475420]\n",
      "epoch:6 step:4755 [D loss: 0.728002, acc: 46.88%] [G loss: 1.607129]\n",
      "epoch:6 step:4756 [D loss: 0.642117, acc: 61.72%] [G loss: 1.484080]\n",
      "epoch:6 step:4757 [D loss: 0.941908, acc: 22.66%] [G loss: 1.264077]\n",
      "epoch:6 step:4758 [D loss: 0.706825, acc: 63.28%] [G loss: 1.641925]\n",
      "epoch:6 step:4759 [D loss: 0.796884, acc: 32.81%] [G loss: 1.427457]\n",
      "epoch:6 step:4760 [D loss: 0.784142, acc: 32.03%] [G loss: 1.578377]\n",
      "epoch:6 step:4761 [D loss: 0.790057, acc: 35.16%] [G loss: 1.480554]\n",
      "epoch:6 step:4762 [D loss: 0.814209, acc: 34.38%] [G loss: 1.449440]\n",
      "epoch:6 step:4763 [D loss: 0.812038, acc: 32.81%] [G loss: 1.432584]\n",
      "epoch:6 step:4764 [D loss: 0.768157, acc: 41.41%] [G loss: 1.511432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:4765 [D loss: 0.679922, acc: 59.38%] [G loss: 1.649082]\n",
      "epoch:6 step:4766 [D loss: 0.772532, acc: 38.28%] [G loss: 1.551779]\n",
      "epoch:6 step:4767 [D loss: 0.708171, acc: 55.47%] [G loss: 1.552852]\n",
      "epoch:6 step:4768 [D loss: 0.706458, acc: 50.78%] [G loss: 1.541722]\n",
      "epoch:6 step:4769 [D loss: 0.589981, acc: 64.84%] [G loss: 1.649399]\n",
      "epoch:6 step:4770 [D loss: 0.679963, acc: 50.00%] [G loss: 1.629580]\n",
      "epoch:6 step:4771 [D loss: 0.642626, acc: 66.41%] [G loss: 1.651100]\n",
      "epoch:6 step:4772 [D loss: 0.714981, acc: 53.12%] [G loss: 1.478194]\n",
      "epoch:6 step:4773 [D loss: 0.646726, acc: 68.75%] [G loss: 1.596208]\n",
      "epoch:6 step:4774 [D loss: 0.778907, acc: 34.38%] [G loss: 1.454246]\n",
      "epoch:6 step:4775 [D loss: 0.670045, acc: 60.94%] [G loss: 1.653171]\n",
      "epoch:6 step:4776 [D loss: 0.709832, acc: 52.34%] [G loss: 1.571341]\n",
      "epoch:6 step:4777 [D loss: 0.721358, acc: 45.31%] [G loss: 1.569036]\n",
      "epoch:6 step:4778 [D loss: 0.668486, acc: 58.59%] [G loss: 1.441581]\n",
      "epoch:6 step:4779 [D loss: 0.755563, acc: 42.97%] [G loss: 1.485650]\n",
      "epoch:6 step:4780 [D loss: 0.783126, acc: 35.16%] [G loss: 1.457955]\n",
      "epoch:6 step:4781 [D loss: 0.661180, acc: 63.28%] [G loss: 1.599405]\n",
      "epoch:6 step:4782 [D loss: 0.640108, acc: 64.84%] [G loss: 1.633142]\n",
      "epoch:6 step:4783 [D loss: 0.671200, acc: 64.06%] [G loss: 1.683089]\n",
      "epoch:6 step:4784 [D loss: 0.681071, acc: 57.03%] [G loss: 1.514230]\n",
      "epoch:6 step:4785 [D loss: 0.647757, acc: 64.06%] [G loss: 1.567402]\n",
      "epoch:6 step:4786 [D loss: 0.731806, acc: 45.31%] [G loss: 1.538761]\n",
      "epoch:6 step:4787 [D loss: 0.644670, acc: 63.28%] [G loss: 1.497606]\n",
      "epoch:6 step:4788 [D loss: 0.775977, acc: 38.28%] [G loss: 1.522742]\n",
      "epoch:6 step:4789 [D loss: 0.660806, acc: 61.72%] [G loss: 1.530448]\n",
      "epoch:6 step:4790 [D loss: 0.815151, acc: 36.72%] [G loss: 1.330068]\n",
      "epoch:6 step:4791 [D loss: 0.723255, acc: 48.44%] [G loss: 1.432488]\n",
      "epoch:6 step:4792 [D loss: 0.692829, acc: 53.91%] [G loss: 1.566794]\n",
      "epoch:6 step:4793 [D loss: 0.711301, acc: 50.00%] [G loss: 1.613641]\n",
      "epoch:6 step:4794 [D loss: 0.656181, acc: 56.25%] [G loss: 1.723945]\n",
      "epoch:6 step:4795 [D loss: 0.697490, acc: 57.03%] [G loss: 1.594364]\n",
      "epoch:6 step:4796 [D loss: 0.671537, acc: 60.94%] [G loss: 1.581525]\n",
      "epoch:6 step:4797 [D loss: 0.705239, acc: 53.12%] [G loss: 1.615330]\n",
      "epoch:6 step:4798 [D loss: 0.781762, acc: 32.03%] [G loss: 1.390397]\n",
      "epoch:6 step:4799 [D loss: 0.748531, acc: 45.31%] [G loss: 1.517439]\n",
      "epoch:6 step:4800 [D loss: 0.702105, acc: 49.22%] [G loss: 1.556852]\n",
      "epoch:6 step:4801 [D loss: 0.663099, acc: 60.16%] [G loss: 1.571914]\n",
      "epoch:6 step:4802 [D loss: 0.704367, acc: 49.22%] [G loss: 1.654795]\n",
      "epoch:6 step:4803 [D loss: 0.731487, acc: 49.22%] [G loss: 1.410785]\n",
      "epoch:6 step:4804 [D loss: 0.743973, acc: 43.75%] [G loss: 1.413819]\n",
      "epoch:6 step:4805 [D loss: 0.563324, acc: 82.03%] [G loss: 1.746635]\n",
      "epoch:6 step:4806 [D loss: 0.675740, acc: 57.81%] [G loss: 1.536948]\n",
      "epoch:6 step:4807 [D loss: 0.660199, acc: 64.84%] [G loss: 1.689946]\n",
      "epoch:6 step:4808 [D loss: 0.690267, acc: 53.12%] [G loss: 1.688506]\n",
      "epoch:6 step:4809 [D loss: 0.716511, acc: 50.78%] [G loss: 1.492277]\n",
      "epoch:6 step:4810 [D loss: 0.708131, acc: 51.56%] [G loss: 1.594559]\n",
      "epoch:6 step:4811 [D loss: 0.717013, acc: 54.69%] [G loss: 1.614616]\n",
      "epoch:6 step:4812 [D loss: 0.796707, acc: 32.81%] [G loss: 1.474204]\n",
      "epoch:6 step:4813 [D loss: 0.745661, acc: 39.84%] [G loss: 1.455548]\n",
      "epoch:6 step:4814 [D loss: 0.708915, acc: 50.00%] [G loss: 1.617254]\n",
      "epoch:6 step:4815 [D loss: 0.668750, acc: 57.81%] [G loss: 1.644310]\n",
      "epoch:6 step:4816 [D loss: 0.711805, acc: 53.91%] [G loss: 1.245048]\n",
      "epoch:6 step:4817 [D loss: 0.804302, acc: 37.50%] [G loss: 1.403579]\n",
      "epoch:6 step:4818 [D loss: 0.631926, acc: 64.06%] [G loss: 1.693734]\n",
      "epoch:6 step:4819 [D loss: 0.630218, acc: 70.31%] [G loss: 1.638244]\n",
      "epoch:6 step:4820 [D loss: 0.716260, acc: 45.31%] [G loss: 1.533699]\n",
      "epoch:6 step:4821 [D loss: 0.657471, acc: 62.50%] [G loss: 1.539429]\n",
      "epoch:6 step:4822 [D loss: 0.692764, acc: 56.25%] [G loss: 1.633710]\n",
      "epoch:6 step:4823 [D loss: 0.746309, acc: 40.62%] [G loss: 1.481127]\n",
      "epoch:6 step:4824 [D loss: 0.724450, acc: 50.78%] [G loss: 1.538789]\n",
      "epoch:6 step:4825 [D loss: 0.664271, acc: 57.03%] [G loss: 1.596189]\n",
      "epoch:6 step:4826 [D loss: 0.656462, acc: 62.50%] [G loss: 1.554773]\n",
      "epoch:6 step:4827 [D loss: 0.768260, acc: 41.41%] [G loss: 1.358186]\n",
      "epoch:6 step:4828 [D loss: 0.704552, acc: 50.78%] [G loss: 1.567478]\n",
      "epoch:6 step:4829 [D loss: 0.757546, acc: 39.84%] [G loss: 1.539144]\n",
      "epoch:6 step:4830 [D loss: 0.719241, acc: 46.88%] [G loss: 1.441774]\n",
      "epoch:6 step:4831 [D loss: 0.668865, acc: 64.84%] [G loss: 1.456733]\n",
      "epoch:6 step:4832 [D loss: 0.729095, acc: 49.22%] [G loss: 1.505168]\n",
      "epoch:6 step:4833 [D loss: 0.654107, acc: 67.19%] [G loss: 1.570054]\n",
      "epoch:6 step:4834 [D loss: 0.629042, acc: 68.75%] [G loss: 1.585867]\n",
      "epoch:6 step:4835 [D loss: 0.575687, acc: 73.44%] [G loss: 1.550197]\n",
      "epoch:6 step:4836 [D loss: 0.505262, acc: 87.50%] [G loss: 1.650726]\n",
      "epoch:6 step:4837 [D loss: 0.771435, acc: 46.09%] [G loss: 1.472172]\n",
      "epoch:6 step:4838 [D loss: 0.684021, acc: 53.12%] [G loss: 1.555241]\n",
      "epoch:6 step:4839 [D loss: 0.711040, acc: 48.44%] [G loss: 1.559530]\n",
      "epoch:6 step:4840 [D loss: 0.727617, acc: 40.62%] [G loss: 1.499389]\n",
      "epoch:6 step:4841 [D loss: 0.651228, acc: 68.75%] [G loss: 1.526138]\n",
      "epoch:6 step:4842 [D loss: 0.648519, acc: 63.28%] [G loss: 1.664157]\n",
      "epoch:6 step:4843 [D loss: 0.680175, acc: 57.03%] [G loss: 1.498252]\n",
      "epoch:6 step:4844 [D loss: 0.856634, acc: 30.47%] [G loss: 1.572418]\n",
      "epoch:6 step:4845 [D loss: 0.705633, acc: 53.12%] [G loss: 1.640225]\n",
      "epoch:6 step:4846 [D loss: 0.872883, acc: 18.75%] [G loss: 1.314885]\n",
      "epoch:6 step:4847 [D loss: 0.699797, acc: 61.72%] [G loss: 1.581608]\n",
      "epoch:6 step:4848 [D loss: 0.654733, acc: 61.72%] [G loss: 1.546195]\n",
      "epoch:6 step:4849 [D loss: 0.734858, acc: 40.62%] [G loss: 1.515752]\n",
      "epoch:6 step:4850 [D loss: 0.560277, acc: 82.03%] [G loss: 1.683725]\n",
      "epoch:6 step:4851 [D loss: 0.669810, acc: 56.25%] [G loss: 1.651029]\n",
      "epoch:6 step:4852 [D loss: 0.914778, acc: 34.38%] [G loss: 1.351894]\n",
      "epoch:6 step:4853 [D loss: 0.678495, acc: 61.72%] [G loss: 1.560428]\n",
      "epoch:6 step:4854 [D loss: 0.602374, acc: 75.00%] [G loss: 1.583648]\n",
      "epoch:6 step:4855 [D loss: 0.703893, acc: 46.09%] [G loss: 1.534107]\n",
      "epoch:6 step:4856 [D loss: 0.721577, acc: 51.56%] [G loss: 1.506058]\n",
      "epoch:6 step:4857 [D loss: 0.704544, acc: 51.56%] [G loss: 1.571980]\n",
      "epoch:6 step:4858 [D loss: 0.646098, acc: 63.28%] [G loss: 1.650931]\n",
      "epoch:6 step:4859 [D loss: 0.775501, acc: 38.28%] [G loss: 1.336974]\n",
      "epoch:6 step:4860 [D loss: 0.635898, acc: 65.62%] [G loss: 1.714621]\n",
      "epoch:6 step:4861 [D loss: 0.671753, acc: 58.59%] [G loss: 1.492428]\n",
      "epoch:6 step:4862 [D loss: 0.706006, acc: 50.78%] [G loss: 1.507915]\n",
      "epoch:6 step:4863 [D loss: 0.594005, acc: 77.34%] [G loss: 1.510402]\n",
      "epoch:6 step:4864 [D loss: 0.670242, acc: 65.62%] [G loss: 1.526679]\n",
      "epoch:6 step:4865 [D loss: 0.592523, acc: 74.22%] [G loss: 1.687826]\n",
      "epoch:6 step:4866 [D loss: 0.598206, acc: 68.75%] [G loss: 1.628300]\n",
      "epoch:6 step:4867 [D loss: 0.700312, acc: 53.12%] [G loss: 1.529074]\n",
      "epoch:6 step:4868 [D loss: 0.817624, acc: 35.94%] [G loss: 1.443397]\n",
      "epoch:6 step:4869 [D loss: 0.696719, acc: 50.00%] [G loss: 1.546709]\n",
      "epoch:6 step:4870 [D loss: 0.757292, acc: 42.97%] [G loss: 1.472519]\n",
      "epoch:6 step:4871 [D loss: 0.752825, acc: 50.00%] [G loss: 1.353269]\n",
      "epoch:6 step:4872 [D loss: 0.751424, acc: 48.44%] [G loss: 1.417902]\n",
      "epoch:6 step:4873 [D loss: 0.679373, acc: 56.25%] [G loss: 1.697096]\n",
      "epoch:6 step:4874 [D loss: 0.660065, acc: 66.41%] [G loss: 1.552208]\n",
      "epoch:6 step:4875 [D loss: 0.630978, acc: 64.06%] [G loss: 1.605719]\n",
      "epoch:6 step:4876 [D loss: 0.671243, acc: 54.69%] [G loss: 1.617614]\n",
      "epoch:6 step:4877 [D loss: 0.771934, acc: 44.53%] [G loss: 1.432442]\n",
      "epoch:6 step:4878 [D loss: 0.724267, acc: 49.22%] [G loss: 1.742896]\n",
      "epoch:6 step:4879 [D loss: 0.724162, acc: 47.66%] [G loss: 1.580907]\n",
      "epoch:6 step:4880 [D loss: 0.679045, acc: 53.91%] [G loss: 1.514757]\n",
      "epoch:6 step:4881 [D loss: 0.766241, acc: 39.84%] [G loss: 1.420319]\n",
      "epoch:6 step:4882 [D loss: 0.909075, acc: 32.03%] [G loss: 1.263912]\n",
      "epoch:6 step:4883 [D loss: 0.762305, acc: 42.97%] [G loss: 1.563895]\n",
      "epoch:6 step:4884 [D loss: 0.683810, acc: 61.72%] [G loss: 1.639152]\n",
      "epoch:6 step:4885 [D loss: 0.772500, acc: 46.88%] [G loss: 1.547820]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:4886 [D loss: 0.584345, acc: 72.66%] [G loss: 1.630760]\n",
      "epoch:6 step:4887 [D loss: 0.626610, acc: 63.28%] [G loss: 1.636284]\n",
      "epoch:6 step:4888 [D loss: 0.697888, acc: 47.66%] [G loss: 1.494057]\n",
      "epoch:6 step:4889 [D loss: 0.580357, acc: 78.12%] [G loss: 1.434159]\n",
      "epoch:6 step:4890 [D loss: 0.537828, acc: 76.56%] [G loss: 1.494267]\n",
      "epoch:6 step:4891 [D loss: 0.914252, acc: 21.88%] [G loss: 1.358609]\n",
      "epoch:6 step:4892 [D loss: 0.678347, acc: 60.16%] [G loss: 1.496487]\n",
      "epoch:6 step:4893 [D loss: 0.611766, acc: 70.31%] [G loss: 1.484614]\n",
      "epoch:6 step:4894 [D loss: 0.742064, acc: 45.31%] [G loss: 1.387591]\n",
      "epoch:6 step:4895 [D loss: 0.694240, acc: 53.12%] [G loss: 1.226394]\n",
      "epoch:6 step:4896 [D loss: 0.926382, acc: 21.88%] [G loss: 1.290573]\n",
      "epoch:6 step:4897 [D loss: 0.640194, acc: 64.06%] [G loss: 1.577787]\n",
      "epoch:6 step:4898 [D loss: 0.664656, acc: 59.38%] [G loss: 1.692449]\n",
      "epoch:6 step:4899 [D loss: 0.603007, acc: 70.31%] [G loss: 1.620667]\n",
      "epoch:6 step:4900 [D loss: 0.755171, acc: 40.62%] [G loss: 1.521417]\n",
      "epoch:6 step:4901 [D loss: 0.827726, acc: 27.34%] [G loss: 1.425393]\n",
      "epoch:6 step:4902 [D loss: 0.717094, acc: 50.00%] [G loss: 1.513393]\n",
      "epoch:6 step:4903 [D loss: 0.692151, acc: 51.56%] [G loss: 1.460709]\n",
      "epoch:6 step:4904 [D loss: 0.820294, acc: 29.69%] [G loss: 1.453328]\n",
      "epoch:6 step:4905 [D loss: 0.633892, acc: 67.19%] [G loss: 1.596937]\n",
      "epoch:6 step:4906 [D loss: 0.714197, acc: 50.78%] [G loss: 1.527164]\n",
      "epoch:6 step:4907 [D loss: 0.701901, acc: 50.00%] [G loss: 1.590098]\n",
      "epoch:6 step:4908 [D loss: 0.723290, acc: 46.88%] [G loss: 1.643059]\n",
      "epoch:6 step:4909 [D loss: 0.694661, acc: 53.12%] [G loss: 1.577854]\n",
      "epoch:6 step:4910 [D loss: 0.723997, acc: 48.44%] [G loss: 1.507995]\n",
      "epoch:6 step:4911 [D loss: 0.697943, acc: 53.91%] [G loss: 1.642436]\n",
      "epoch:6 step:4912 [D loss: 0.748561, acc: 39.06%] [G loss: 1.463690]\n",
      "epoch:6 step:4913 [D loss: 0.872162, acc: 26.56%] [G loss: 1.409354]\n",
      "epoch:6 step:4914 [D loss: 0.735342, acc: 50.00%] [G loss: 1.587334]\n",
      "epoch:6 step:4915 [D loss: 0.694788, acc: 56.25%] [G loss: 1.510368]\n",
      "epoch:6 step:4916 [D loss: 0.646984, acc: 65.62%] [G loss: 1.543017]\n",
      "epoch:6 step:4917 [D loss: 0.633247, acc: 65.62%] [G loss: 1.550350]\n",
      "epoch:6 step:4918 [D loss: 0.787738, acc: 35.16%] [G loss: 1.376319]\n",
      "epoch:6 step:4919 [D loss: 0.746118, acc: 42.97%] [G loss: 1.498406]\n",
      "epoch:6 step:4920 [D loss: 0.703195, acc: 49.22%] [G loss: 1.424262]\n",
      "epoch:6 step:4921 [D loss: 0.757069, acc: 46.09%] [G loss: 1.480232]\n",
      "epoch:6 step:4922 [D loss: 0.714153, acc: 54.69%] [G loss: 1.504186]\n",
      "epoch:6 step:4923 [D loss: 0.755378, acc: 43.75%] [G loss: 1.598282]\n",
      "epoch:6 step:4924 [D loss: 0.748728, acc: 39.84%] [G loss: 1.548851]\n",
      "epoch:6 step:4925 [D loss: 0.741182, acc: 39.84%] [G loss: 1.467083]\n",
      "epoch:6 step:4926 [D loss: 0.677646, acc: 53.91%] [G loss: 1.632252]\n",
      "epoch:6 step:4927 [D loss: 0.725390, acc: 52.34%] [G loss: 1.583526]\n",
      "epoch:6 step:4928 [D loss: 0.724412, acc: 47.66%] [G loss: 1.400341]\n",
      "epoch:6 step:4929 [D loss: 0.766482, acc: 31.25%] [G loss: 1.489926]\n",
      "epoch:6 step:4930 [D loss: 0.747178, acc: 47.66%] [G loss: 1.559939]\n",
      "epoch:6 step:4931 [D loss: 0.750326, acc: 46.09%] [G loss: 1.447936]\n",
      "epoch:6 step:4932 [D loss: 0.746987, acc: 46.88%] [G loss: 1.615691]\n",
      "epoch:6 step:4933 [D loss: 0.724298, acc: 50.78%] [G loss: 1.418354]\n",
      "epoch:6 step:4934 [D loss: 0.777129, acc: 42.97%] [G loss: 1.654884]\n",
      "epoch:6 step:4935 [D loss: 0.769442, acc: 35.94%] [G loss: 1.498611]\n",
      "epoch:6 step:4936 [D loss: 0.783018, acc: 36.72%] [G loss: 1.431901]\n",
      "epoch:6 step:4937 [D loss: 0.719835, acc: 47.66%] [G loss: 1.558697]\n",
      "epoch:6 step:4938 [D loss: 0.667034, acc: 57.03%] [G loss: 1.624503]\n",
      "epoch:6 step:4939 [D loss: 0.735677, acc: 40.62%] [G loss: 1.505492]\n",
      "epoch:6 step:4940 [D loss: 0.717277, acc: 49.22%] [G loss: 1.538393]\n",
      "epoch:6 step:4941 [D loss: 0.744656, acc: 39.06%] [G loss: 1.454370]\n",
      "epoch:6 step:4942 [D loss: 0.768627, acc: 35.94%] [G loss: 1.457086]\n",
      "epoch:6 step:4943 [D loss: 0.670561, acc: 53.12%] [G loss: 1.577895]\n",
      "epoch:6 step:4944 [D loss: 0.727170, acc: 50.00%] [G loss: 1.551602]\n",
      "epoch:6 step:4945 [D loss: 0.660461, acc: 60.94%] [G loss: 1.526790]\n",
      "epoch:6 step:4946 [D loss: 0.736888, acc: 39.06%] [G loss: 1.568984]\n",
      "epoch:6 step:4947 [D loss: 0.683441, acc: 55.47%] [G loss: 1.592685]\n",
      "epoch:6 step:4948 [D loss: 0.679948, acc: 57.81%] [G loss: 1.623118]\n",
      "epoch:6 step:4949 [D loss: 0.657077, acc: 62.50%] [G loss: 1.519001]\n",
      "epoch:6 step:4950 [D loss: 0.708298, acc: 53.12%] [G loss: 1.593848]\n",
      "epoch:6 step:4951 [D loss: 0.623311, acc: 75.78%] [G loss: 1.609822]\n",
      "epoch:6 step:4952 [D loss: 0.625581, acc: 69.53%] [G loss: 1.530544]\n",
      "epoch:6 step:4953 [D loss: 0.879439, acc: 19.53%] [G loss: 1.293468]\n",
      "epoch:6 step:4954 [D loss: 0.705924, acc: 51.56%] [G loss: 1.628731]\n",
      "epoch:6 step:4955 [D loss: 0.654945, acc: 62.50%] [G loss: 1.528545]\n",
      "epoch:6 step:4956 [D loss: 0.714730, acc: 46.09%] [G loss: 1.470950]\n",
      "epoch:6 step:4957 [D loss: 0.719486, acc: 50.00%] [G loss: 1.536714]\n",
      "epoch:6 step:4958 [D loss: 0.660746, acc: 58.59%] [G loss: 1.607202]\n",
      "epoch:6 step:4959 [D loss: 0.774633, acc: 42.19%] [G loss: 1.500615]\n",
      "epoch:6 step:4960 [D loss: 0.823604, acc: 29.69%] [G loss: 1.443599]\n",
      "epoch:6 step:4961 [D loss: 0.682557, acc: 57.81%] [G loss: 1.536817]\n",
      "epoch:6 step:4962 [D loss: 0.736225, acc: 42.19%] [G loss: 1.424461]\n",
      "epoch:6 step:4963 [D loss: 0.737412, acc: 39.84%] [G loss: 1.540097]\n",
      "epoch:6 step:4964 [D loss: 0.718649, acc: 50.00%] [G loss: 1.532990]\n",
      "epoch:6 step:4965 [D loss: 0.673012, acc: 57.03%] [G loss: 1.552833]\n",
      "epoch:6 step:4966 [D loss: 0.713184, acc: 50.78%] [G loss: 1.610523]\n",
      "epoch:6 step:4967 [D loss: 0.720358, acc: 40.62%] [G loss: 1.575173]\n",
      "epoch:6 step:4968 [D loss: 0.818183, acc: 31.25%] [G loss: 1.377553]\n",
      "epoch:6 step:4969 [D loss: 0.708861, acc: 56.25%] [G loss: 1.481902]\n",
      "epoch:6 step:4970 [D loss: 0.674218, acc: 57.81%] [G loss: 1.478024]\n",
      "epoch:6 step:4971 [D loss: 0.687748, acc: 55.47%] [G loss: 1.529236]\n",
      "epoch:6 step:4972 [D loss: 0.699510, acc: 55.47%] [G loss: 1.689491]\n",
      "epoch:6 step:4973 [D loss: 0.708293, acc: 52.34%] [G loss: 1.471995]\n",
      "epoch:6 step:4974 [D loss: 0.737272, acc: 35.94%] [G loss: 1.593341]\n",
      "epoch:6 step:4975 [D loss: 0.741442, acc: 45.31%] [G loss: 1.479445]\n",
      "epoch:6 step:4976 [D loss: 0.721103, acc: 50.00%] [G loss: 1.493209]\n",
      "epoch:6 step:4977 [D loss: 0.836769, acc: 28.12%] [G loss: 1.509602]\n",
      "epoch:6 step:4978 [D loss: 0.715986, acc: 50.78%] [G loss: 1.519344]\n",
      "epoch:6 step:4979 [D loss: 0.747306, acc: 36.72%] [G loss: 1.519005]\n",
      "epoch:6 step:4980 [D loss: 0.696920, acc: 53.12%] [G loss: 1.528607]\n",
      "epoch:6 step:4981 [D loss: 0.747186, acc: 43.75%] [G loss: 1.558681]\n",
      "epoch:6 step:4982 [D loss: 0.739666, acc: 40.62%] [G loss: 1.513069]\n",
      "epoch:6 step:4983 [D loss: 0.753025, acc: 39.06%] [G loss: 1.448483]\n",
      "epoch:6 step:4984 [D loss: 0.775082, acc: 38.28%] [G loss: 1.434710]\n",
      "epoch:6 step:4985 [D loss: 0.662301, acc: 61.72%] [G loss: 1.519636]\n",
      "epoch:6 step:4986 [D loss: 0.658675, acc: 58.59%] [G loss: 1.500369]\n",
      "epoch:6 step:4987 [D loss: 0.764343, acc: 36.72%] [G loss: 1.478127]\n",
      "epoch:6 step:4988 [D loss: 0.675408, acc: 59.38%] [G loss: 1.581454]\n",
      "epoch:6 step:4989 [D loss: 0.643427, acc: 60.16%] [G loss: 1.517074]\n",
      "epoch:6 step:4990 [D loss: 0.735478, acc: 53.91%] [G loss: 1.493936]\n",
      "epoch:6 step:4991 [D loss: 0.671351, acc: 57.81%] [G loss: 1.441942]\n",
      "epoch:6 step:4992 [D loss: 0.738863, acc: 46.88%] [G loss: 1.547963]\n",
      "epoch:6 step:4993 [D loss: 0.703641, acc: 53.91%] [G loss: 1.425745]\n",
      "epoch:6 step:4994 [D loss: 0.674360, acc: 58.59%] [G loss: 1.531541]\n",
      "epoch:6 step:4995 [D loss: 0.692859, acc: 59.38%] [G loss: 1.529344]\n",
      "epoch:6 step:4996 [D loss: 0.627388, acc: 72.66%] [G loss: 1.604999]\n",
      "epoch:6 step:4997 [D loss: 0.777717, acc: 40.62%] [G loss: 1.438831]\n",
      "epoch:6 step:4998 [D loss: 0.753767, acc: 48.44%] [G loss: 1.501381]\n",
      "epoch:6 step:4999 [D loss: 0.787711, acc: 32.03%] [G loss: 1.444460]\n",
      "epoch:6 step:5000 [D loss: 0.696809, acc: 55.47%] [G loss: 1.565004]\n",
      "epoch:6 step:5001 [D loss: 0.840935, acc: 26.56%] [G loss: 1.420579]\n",
      "epoch:6 step:5002 [D loss: 0.660132, acc: 63.28%] [G loss: 1.536611]\n",
      "epoch:6 step:5003 [D loss: 0.626162, acc: 71.88%] [G loss: 1.746246]\n",
      "epoch:6 step:5004 [D loss: 0.682477, acc: 62.50%] [G loss: 1.615961]\n",
      "epoch:6 step:5005 [D loss: 0.699860, acc: 51.56%] [G loss: 1.507897]\n",
      "epoch:6 step:5006 [D loss: 0.790875, acc: 35.16%] [G loss: 1.468532]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5007 [D loss: 0.760791, acc: 43.75%] [G loss: 1.561779]\n",
      "epoch:6 step:5008 [D loss: 0.738863, acc: 40.62%] [G loss: 1.505160]\n",
      "epoch:6 step:5009 [D loss: 0.658009, acc: 62.50%] [G loss: 1.509784]\n",
      "epoch:6 step:5010 [D loss: 0.756625, acc: 42.19%] [G loss: 1.421733]\n",
      "epoch:6 step:5011 [D loss: 0.720230, acc: 50.00%] [G loss: 1.481811]\n",
      "epoch:6 step:5012 [D loss: 0.707253, acc: 46.88%] [G loss: 1.472844]\n",
      "epoch:6 step:5013 [D loss: 0.676670, acc: 57.03%] [G loss: 1.449942]\n",
      "epoch:6 step:5014 [D loss: 0.693752, acc: 52.34%] [G loss: 1.457178]\n",
      "epoch:6 step:5015 [D loss: 0.768370, acc: 39.06%] [G loss: 1.456852]\n",
      "epoch:6 step:5016 [D loss: 0.701326, acc: 50.00%] [G loss: 1.614131]\n",
      "epoch:6 step:5017 [D loss: 0.802933, acc: 39.06%] [G loss: 1.587513]\n",
      "epoch:6 step:5018 [D loss: 0.710807, acc: 50.78%] [G loss: 1.504861]\n",
      "epoch:6 step:5019 [D loss: 0.713807, acc: 48.44%] [G loss: 1.521157]\n",
      "epoch:6 step:5020 [D loss: 0.716546, acc: 47.66%] [G loss: 1.533125]\n",
      "epoch:6 step:5021 [D loss: 0.686015, acc: 55.47%] [G loss: 1.606156]\n",
      "epoch:6 step:5022 [D loss: 0.711403, acc: 52.34%] [G loss: 1.555597]\n",
      "epoch:6 step:5023 [D loss: 0.681370, acc: 55.47%] [G loss: 1.583691]\n",
      "epoch:6 step:5024 [D loss: 0.650664, acc: 67.19%] [G loss: 1.657887]\n",
      "epoch:6 step:5025 [D loss: 0.700217, acc: 55.47%] [G loss: 1.516412]\n",
      "epoch:6 step:5026 [D loss: 0.693071, acc: 56.25%] [G loss: 1.601854]\n",
      "epoch:6 step:5027 [D loss: 0.732695, acc: 49.22%] [G loss: 1.492126]\n",
      "epoch:6 step:5028 [D loss: 0.633054, acc: 67.19%] [G loss: 1.652744]\n",
      "epoch:6 step:5029 [D loss: 0.659689, acc: 68.75%] [G loss: 1.538097]\n",
      "epoch:6 step:5030 [D loss: 0.632177, acc: 70.31%] [G loss: 1.483295]\n",
      "epoch:6 step:5031 [D loss: 0.665413, acc: 64.06%] [G loss: 1.543225]\n",
      "epoch:6 step:5032 [D loss: 0.691128, acc: 52.34%] [G loss: 1.711829]\n",
      "epoch:6 step:5033 [D loss: 0.678386, acc: 53.91%] [G loss: 1.468561]\n",
      "epoch:6 step:5034 [D loss: 0.721198, acc: 46.88%] [G loss: 1.412709]\n",
      "epoch:6 step:5035 [D loss: 0.730213, acc: 52.34%] [G loss: 1.509278]\n",
      "epoch:6 step:5036 [D loss: 0.712098, acc: 53.91%] [G loss: 1.576657]\n",
      "epoch:6 step:5037 [D loss: 0.829113, acc: 32.81%] [G loss: 1.463814]\n",
      "epoch:6 step:5038 [D loss: 0.742998, acc: 44.53%] [G loss: 1.572509]\n",
      "epoch:6 step:5039 [D loss: 0.634782, acc: 68.75%] [G loss: 1.594492]\n",
      "epoch:6 step:5040 [D loss: 0.712535, acc: 56.25%] [G loss: 1.476660]\n",
      "epoch:6 step:5041 [D loss: 0.719138, acc: 48.44%] [G loss: 1.375605]\n",
      "epoch:6 step:5042 [D loss: 0.768317, acc: 38.28%] [G loss: 1.535195]\n",
      "epoch:6 step:5043 [D loss: 0.745466, acc: 42.19%] [G loss: 1.487683]\n",
      "epoch:6 step:5044 [D loss: 0.805390, acc: 29.69%] [G loss: 1.443071]\n",
      "epoch:6 step:5045 [D loss: 0.803363, acc: 30.47%] [G loss: 1.445010]\n",
      "epoch:6 step:5046 [D loss: 0.785279, acc: 32.03%] [G loss: 1.504089]\n",
      "epoch:6 step:5047 [D loss: 0.711625, acc: 55.47%] [G loss: 1.430771]\n",
      "epoch:6 step:5048 [D loss: 0.631840, acc: 64.06%] [G loss: 1.515190]\n",
      "epoch:6 step:5049 [D loss: 0.747179, acc: 42.97%] [G loss: 1.488206]\n",
      "epoch:6 step:5050 [D loss: 0.661438, acc: 58.59%] [G loss: 1.542256]\n",
      "epoch:6 step:5051 [D loss: 0.662599, acc: 56.25%] [G loss: 1.701782]\n",
      "epoch:6 step:5052 [D loss: 0.765597, acc: 40.62%] [G loss: 1.402423]\n",
      "epoch:6 step:5053 [D loss: 0.716404, acc: 48.44%] [G loss: 1.495000]\n",
      "epoch:6 step:5054 [D loss: 0.708502, acc: 53.12%] [G loss: 1.518075]\n",
      "epoch:6 step:5055 [D loss: 0.737004, acc: 48.44%] [G loss: 1.535558]\n",
      "epoch:6 step:5056 [D loss: 0.643478, acc: 64.06%] [G loss: 1.582750]\n",
      "epoch:6 step:5057 [D loss: 0.745241, acc: 45.31%] [G loss: 1.562512]\n",
      "epoch:6 step:5058 [D loss: 0.715423, acc: 46.09%] [G loss: 1.459680]\n",
      "epoch:6 step:5059 [D loss: 0.839226, acc: 35.94%] [G loss: 1.308499]\n",
      "epoch:6 step:5060 [D loss: 0.694748, acc: 53.12%] [G loss: 1.558909]\n",
      "epoch:6 step:5061 [D loss: 0.734788, acc: 46.88%] [G loss: 1.552888]\n",
      "epoch:6 step:5062 [D loss: 0.714211, acc: 50.00%] [G loss: 1.679321]\n",
      "epoch:6 step:5063 [D loss: 0.683135, acc: 57.81%] [G loss: 1.536030]\n",
      "epoch:6 step:5064 [D loss: 0.706693, acc: 48.44%] [G loss: 1.459454]\n",
      "epoch:6 step:5065 [D loss: 0.719077, acc: 50.78%] [G loss: 1.544658]\n",
      "epoch:6 step:5066 [D loss: 0.746428, acc: 43.75%] [G loss: 1.493864]\n",
      "epoch:6 step:5067 [D loss: 0.676717, acc: 53.91%] [G loss: 1.633774]\n",
      "epoch:6 step:5068 [D loss: 0.656229, acc: 58.59%] [G loss: 1.569059]\n",
      "epoch:6 step:5069 [D loss: 0.693202, acc: 53.91%] [G loss: 1.590226]\n",
      "epoch:6 step:5070 [D loss: 0.679137, acc: 57.03%] [G loss: 1.545997]\n",
      "epoch:6 step:5071 [D loss: 0.727013, acc: 40.62%] [G loss: 1.593648]\n",
      "epoch:6 step:5072 [D loss: 0.718605, acc: 49.22%] [G loss: 1.493081]\n",
      "epoch:6 step:5073 [D loss: 0.649192, acc: 63.28%] [G loss: 1.600902]\n",
      "epoch:6 step:5074 [D loss: 0.822296, acc: 25.00%] [G loss: 1.428742]\n",
      "epoch:6 step:5075 [D loss: 0.721222, acc: 51.56%] [G loss: 1.517027]\n",
      "epoch:6 step:5076 [D loss: 0.714536, acc: 50.00%] [G loss: 1.563896]\n",
      "epoch:6 step:5077 [D loss: 0.725607, acc: 52.34%] [G loss: 1.385694]\n",
      "epoch:6 step:5078 [D loss: 0.703091, acc: 53.91%] [G loss: 1.481549]\n",
      "epoch:6 step:5079 [D loss: 0.716853, acc: 50.78%] [G loss: 1.599341]\n",
      "epoch:6 step:5080 [D loss: 0.698004, acc: 54.69%] [G loss: 1.466114]\n",
      "epoch:6 step:5081 [D loss: 0.646412, acc: 67.19%] [G loss: 1.481352]\n",
      "epoch:6 step:5082 [D loss: 0.755921, acc: 34.38%] [G loss: 1.485050]\n",
      "epoch:6 step:5083 [D loss: 0.818906, acc: 39.84%] [G loss: 1.315874]\n",
      "epoch:6 step:5084 [D loss: 0.724626, acc: 52.34%] [G loss: 1.458478]\n",
      "epoch:6 step:5085 [D loss: 0.665383, acc: 64.06%] [G loss: 1.464324]\n",
      "epoch:6 step:5086 [D loss: 0.702884, acc: 53.91%] [G loss: 1.416127]\n",
      "epoch:6 step:5087 [D loss: 0.624092, acc: 69.53%] [G loss: 1.625452]\n",
      "epoch:6 step:5088 [D loss: 0.792201, acc: 33.59%] [G loss: 1.482126]\n",
      "epoch:6 step:5089 [D loss: 0.706074, acc: 56.25%] [G loss: 1.611643]\n",
      "epoch:6 step:5090 [D loss: 0.693608, acc: 52.34%] [G loss: 1.490690]\n",
      "epoch:6 step:5091 [D loss: 0.723295, acc: 50.78%] [G loss: 1.647398]\n",
      "epoch:6 step:5092 [D loss: 0.656092, acc: 64.84%] [G loss: 1.556805]\n",
      "epoch:6 step:5093 [D loss: 0.649007, acc: 65.62%] [G loss: 1.581323]\n",
      "epoch:6 step:5094 [D loss: 0.752869, acc: 45.31%] [G loss: 1.374033]\n",
      "epoch:6 step:5095 [D loss: 0.657153, acc: 65.62%] [G loss: 1.568751]\n",
      "epoch:6 step:5096 [D loss: 0.713149, acc: 52.34%] [G loss: 1.578624]\n",
      "epoch:6 step:5097 [D loss: 0.719317, acc: 47.66%] [G loss: 1.577418]\n",
      "epoch:6 step:5098 [D loss: 0.675157, acc: 61.72%] [G loss: 1.605709]\n",
      "epoch:6 step:5099 [D loss: 0.698438, acc: 50.00%] [G loss: 1.575659]\n",
      "epoch:6 step:5100 [D loss: 0.724181, acc: 44.53%] [G loss: 1.553343]\n",
      "epoch:6 step:5101 [D loss: 0.623866, acc: 70.31%] [G loss: 1.528631]\n",
      "epoch:6 step:5102 [D loss: 0.758111, acc: 42.19%] [G loss: 1.393642]\n",
      "epoch:6 step:5103 [D loss: 0.666688, acc: 56.25%] [G loss: 1.506598]\n",
      "epoch:6 step:5104 [D loss: 0.713613, acc: 50.00%] [G loss: 1.475622]\n",
      "epoch:6 step:5105 [D loss: 0.707311, acc: 57.81%] [G loss: 1.483295]\n",
      "epoch:6 step:5106 [D loss: 0.677251, acc: 53.91%] [G loss: 1.548167]\n",
      "epoch:6 step:5107 [D loss: 0.792228, acc: 35.94%] [G loss: 1.411747]\n",
      "epoch:6 step:5108 [D loss: 0.710448, acc: 53.12%] [G loss: 1.564273]\n",
      "epoch:6 step:5109 [D loss: 0.658892, acc: 61.72%] [G loss: 1.549546]\n",
      "epoch:6 step:5110 [D loss: 0.797203, acc: 31.25%] [G loss: 1.436568]\n",
      "epoch:6 step:5111 [D loss: 0.704488, acc: 55.47%] [G loss: 1.566521]\n",
      "epoch:6 step:5112 [D loss: 0.774513, acc: 32.03%] [G loss: 1.491920]\n",
      "epoch:6 step:5113 [D loss: 0.708001, acc: 51.56%] [G loss: 1.648470]\n",
      "epoch:6 step:5114 [D loss: 0.663706, acc: 59.38%] [G loss: 1.626318]\n",
      "epoch:6 step:5115 [D loss: 0.706701, acc: 52.34%] [G loss: 1.602457]\n",
      "epoch:6 step:5116 [D loss: 0.770688, acc: 43.75%] [G loss: 1.470053]\n",
      "epoch:6 step:5117 [D loss: 0.642628, acc: 57.81%] [G loss: 1.531674]\n",
      "epoch:6 step:5118 [D loss: 0.725540, acc: 54.69%] [G loss: 1.504098]\n",
      "epoch:6 step:5119 [D loss: 0.681857, acc: 57.81%] [G loss: 1.543369]\n",
      "epoch:6 step:5120 [D loss: 0.663693, acc: 59.38%] [G loss: 1.453971]\n",
      "epoch:6 step:5121 [D loss: 0.690765, acc: 52.34%] [G loss: 1.456038]\n",
      "epoch:6 step:5122 [D loss: 0.664814, acc: 55.47%] [G loss: 1.523799]\n",
      "epoch:6 step:5123 [D loss: 0.592910, acc: 65.62%] [G loss: 1.461569]\n",
      "epoch:6 step:5124 [D loss: 0.748951, acc: 41.41%] [G loss: 1.377530]\n",
      "epoch:6 step:5125 [D loss: 0.629787, acc: 64.84%] [G loss: 1.426189]\n",
      "epoch:6 step:5126 [D loss: 0.731933, acc: 46.88%] [G loss: 1.421739]\n",
      "epoch:6 step:5127 [D loss: 0.648619, acc: 62.50%] [G loss: 1.424661]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5128 [D loss: 0.667755, acc: 56.25%] [G loss: 1.641649]\n",
      "epoch:6 step:5129 [D loss: 0.722329, acc: 51.56%] [G loss: 1.390524]\n",
      "epoch:6 step:5130 [D loss: 0.753100, acc: 45.31%] [G loss: 1.353614]\n",
      "epoch:6 step:5131 [D loss: 0.826735, acc: 32.03%] [G loss: 1.273524]\n",
      "epoch:6 step:5132 [D loss: 0.840302, acc: 32.81%] [G loss: 1.406550]\n",
      "epoch:6 step:5133 [D loss: 0.741012, acc: 47.66%] [G loss: 1.606060]\n",
      "epoch:6 step:5134 [D loss: 0.723916, acc: 47.66%] [G loss: 1.574024]\n",
      "epoch:6 step:5135 [D loss: 0.719382, acc: 51.56%] [G loss: 1.444131]\n",
      "epoch:6 step:5136 [D loss: 0.724643, acc: 55.47%] [G loss: 1.449336]\n",
      "epoch:6 step:5137 [D loss: 0.728668, acc: 51.56%] [G loss: 1.584145]\n",
      "epoch:6 step:5138 [D loss: 0.748368, acc: 37.50%] [G loss: 1.529262]\n",
      "epoch:6 step:5139 [D loss: 0.706433, acc: 55.47%] [G loss: 1.570737]\n",
      "epoch:6 step:5140 [D loss: 0.613211, acc: 70.31%] [G loss: 1.637995]\n",
      "epoch:6 step:5141 [D loss: 0.683861, acc: 55.47%] [G loss: 1.508752]\n",
      "epoch:6 step:5142 [D loss: 0.657863, acc: 64.84%] [G loss: 1.481694]\n",
      "epoch:6 step:5143 [D loss: 0.665285, acc: 60.94%] [G loss: 1.406941]\n",
      "epoch:6 step:5144 [D loss: 0.631787, acc: 64.06%] [G loss: 1.402624]\n",
      "epoch:6 step:5145 [D loss: 0.670876, acc: 52.34%] [G loss: 1.451911]\n",
      "epoch:6 step:5146 [D loss: 0.660479, acc: 61.72%] [G loss: 1.542657]\n",
      "epoch:6 step:5147 [D loss: 0.786428, acc: 30.47%] [G loss: 1.298753]\n",
      "epoch:6 step:5148 [D loss: 0.742755, acc: 42.97%] [G loss: 1.507939]\n",
      "epoch:6 step:5149 [D loss: 0.723636, acc: 47.66%] [G loss: 1.571219]\n",
      "epoch:6 step:5150 [D loss: 0.739304, acc: 46.88%] [G loss: 1.372329]\n",
      "epoch:6 step:5151 [D loss: 0.747825, acc: 42.19%] [G loss: 1.414891]\n",
      "epoch:6 step:5152 [D loss: 0.705854, acc: 49.22%] [G loss: 1.425527]\n",
      "epoch:6 step:5153 [D loss: 0.693440, acc: 57.03%] [G loss: 1.502742]\n",
      "epoch:6 step:5154 [D loss: 0.775212, acc: 38.28%] [G loss: 1.342067]\n",
      "epoch:6 step:5155 [D loss: 0.664513, acc: 60.16%] [G loss: 1.436051]\n",
      "epoch:6 step:5156 [D loss: 0.855645, acc: 19.53%] [G loss: 1.326037]\n",
      "epoch:6 step:5157 [D loss: 0.760015, acc: 34.38%] [G loss: 1.417464]\n",
      "epoch:6 step:5158 [D loss: 0.695196, acc: 48.44%] [G loss: 1.429335]\n",
      "epoch:6 step:5159 [D loss: 0.662387, acc: 62.50%] [G loss: 1.540720]\n",
      "epoch:6 step:5160 [D loss: 0.723645, acc: 49.22%] [G loss: 1.409902]\n",
      "epoch:6 step:5161 [D loss: 0.688897, acc: 56.25%] [G loss: 1.455859]\n",
      "epoch:6 step:5162 [D loss: 0.672239, acc: 63.28%] [G loss: 1.460366]\n",
      "epoch:6 step:5163 [D loss: 0.722106, acc: 45.31%] [G loss: 1.354699]\n",
      "epoch:6 step:5164 [D loss: 0.723810, acc: 46.09%] [G loss: 1.468180]\n",
      "epoch:6 step:5165 [D loss: 0.794053, acc: 27.34%] [G loss: 1.421233]\n",
      "epoch:6 step:5166 [D loss: 0.702575, acc: 52.34%] [G loss: 1.459968]\n",
      "epoch:6 step:5167 [D loss: 0.709516, acc: 55.47%] [G loss: 1.439662]\n",
      "epoch:6 step:5168 [D loss: 0.686382, acc: 53.91%] [G loss: 1.485642]\n",
      "epoch:6 step:5169 [D loss: 0.716528, acc: 48.44%] [G loss: 1.444951]\n",
      "epoch:6 step:5170 [D loss: 0.590300, acc: 78.12%] [G loss: 1.460823]\n",
      "epoch:6 step:5171 [D loss: 0.725161, acc: 46.88%] [G loss: 1.416055]\n",
      "epoch:6 step:5172 [D loss: 0.734486, acc: 48.44%] [G loss: 1.524566]\n",
      "epoch:6 step:5173 [D loss: 0.708632, acc: 51.56%] [G loss: 1.501739]\n",
      "epoch:6 step:5174 [D loss: 0.700686, acc: 50.78%] [G loss: 1.436696]\n",
      "epoch:6 step:5175 [D loss: 0.663567, acc: 60.94%] [G loss: 1.492959]\n",
      "epoch:6 step:5176 [D loss: 0.613852, acc: 72.66%] [G loss: 1.539999]\n",
      "epoch:6 step:5177 [D loss: 0.759749, acc: 38.28%] [G loss: 1.415544]\n",
      "epoch:6 step:5178 [D loss: 0.714174, acc: 53.12%] [G loss: 1.458065]\n",
      "epoch:6 step:5179 [D loss: 0.727541, acc: 46.88%] [G loss: 1.516662]\n",
      "epoch:6 step:5180 [D loss: 0.768814, acc: 32.03%] [G loss: 1.416323]\n",
      "epoch:6 step:5181 [D loss: 0.747706, acc: 36.72%] [G loss: 1.462928]\n",
      "epoch:6 step:5182 [D loss: 0.717442, acc: 50.00%] [G loss: 1.496974]\n",
      "epoch:6 step:5183 [D loss: 0.699456, acc: 53.12%] [G loss: 1.554013]\n",
      "epoch:6 step:5184 [D loss: 0.710292, acc: 52.34%] [G loss: 1.547711]\n",
      "epoch:6 step:5185 [D loss: 0.855219, acc: 32.03%] [G loss: 1.318860]\n",
      "epoch:6 step:5186 [D loss: 0.701114, acc: 53.91%] [G loss: 1.453101]\n",
      "epoch:6 step:5187 [D loss: 0.700280, acc: 53.91%] [G loss: 1.544486]\n",
      "epoch:6 step:5188 [D loss: 0.712537, acc: 49.22%] [G loss: 1.475446]\n",
      "epoch:6 step:5189 [D loss: 0.696844, acc: 57.81%] [G loss: 1.499451]\n",
      "epoch:6 step:5190 [D loss: 0.721415, acc: 49.22%] [G loss: 1.435850]\n",
      "epoch:6 step:5191 [D loss: 0.694694, acc: 56.25%] [G loss: 1.521210]\n",
      "epoch:6 step:5192 [D loss: 0.690026, acc: 53.91%] [G loss: 1.515403]\n",
      "epoch:6 step:5193 [D loss: 0.718280, acc: 48.44%] [G loss: 1.547034]\n",
      "epoch:6 step:5194 [D loss: 0.734816, acc: 46.88%] [G loss: 1.451253]\n",
      "epoch:6 step:5195 [D loss: 0.632688, acc: 64.84%] [G loss: 1.624610]\n",
      "epoch:6 step:5196 [D loss: 0.719695, acc: 53.91%] [G loss: 1.480483]\n",
      "epoch:6 step:5197 [D loss: 0.662187, acc: 64.84%] [G loss: 1.499029]\n",
      "epoch:6 step:5198 [D loss: 0.687837, acc: 50.00%] [G loss: 1.516138]\n",
      "epoch:6 step:5199 [D loss: 0.729848, acc: 49.22%] [G loss: 1.513405]\n",
      "epoch:6 step:5200 [D loss: 0.643481, acc: 64.84%] [G loss: 1.562678]\n",
      "epoch:6 step:5201 [D loss: 0.758543, acc: 39.84%] [G loss: 1.534790]\n",
      "epoch:6 step:5202 [D loss: 0.687712, acc: 50.78%] [G loss: 1.633132]\n",
      "epoch:6 step:5203 [D loss: 0.702366, acc: 53.91%] [G loss: 1.505154]\n",
      "epoch:6 step:5204 [D loss: 0.702712, acc: 50.78%] [G loss: 1.557631]\n",
      "epoch:6 step:5205 [D loss: 0.802067, acc: 30.47%] [G loss: 1.409512]\n",
      "epoch:6 step:5206 [D loss: 0.677992, acc: 58.59%] [G loss: 1.553838]\n",
      "epoch:6 step:5207 [D loss: 0.640108, acc: 65.62%] [G loss: 1.539117]\n",
      "epoch:6 step:5208 [D loss: 0.651225, acc: 61.72%] [G loss: 1.490549]\n",
      "epoch:6 step:5209 [D loss: 0.707089, acc: 48.44%] [G loss: 1.433100]\n",
      "epoch:6 step:5210 [D loss: 0.800431, acc: 33.59%] [G loss: 1.461424]\n",
      "epoch:6 step:5211 [D loss: 0.621214, acc: 69.53%] [G loss: 1.559336]\n",
      "epoch:6 step:5212 [D loss: 0.822731, acc: 31.25%] [G loss: 1.380408]\n",
      "epoch:6 step:5213 [D loss: 0.567068, acc: 82.03%] [G loss: 1.529664]\n",
      "epoch:6 step:5214 [D loss: 0.627808, acc: 67.97%] [G loss: 1.526798]\n",
      "epoch:6 step:5215 [D loss: 0.719877, acc: 46.09%] [G loss: 1.437790]\n",
      "epoch:6 step:5216 [D loss: 0.639742, acc: 68.75%] [G loss: 1.465638]\n",
      "epoch:6 step:5217 [D loss: 0.745950, acc: 49.22%] [G loss: 1.511255]\n",
      "epoch:6 step:5218 [D loss: 0.893550, acc: 13.28%] [G loss: 1.229596]\n",
      "epoch:6 step:5219 [D loss: 0.714726, acc: 52.34%] [G loss: 1.616659]\n",
      "epoch:6 step:5220 [D loss: 0.701403, acc: 53.12%] [G loss: 1.384165]\n",
      "epoch:6 step:5221 [D loss: 0.800642, acc: 32.03%] [G loss: 1.362455]\n",
      "epoch:6 step:5222 [D loss: 0.545505, acc: 79.69%] [G loss: 1.510260]\n",
      "epoch:6 step:5223 [D loss: 0.969533, acc: 17.19%] [G loss: 1.319597]\n",
      "epoch:6 step:5224 [D loss: 0.705628, acc: 50.78%] [G loss: 1.570012]\n",
      "epoch:6 step:5225 [D loss: 0.675518, acc: 59.38%] [G loss: 1.435983]\n",
      "epoch:6 step:5226 [D loss: 0.751940, acc: 42.97%] [G loss: 1.446423]\n",
      "epoch:6 step:5227 [D loss: 0.717484, acc: 46.09%] [G loss: 1.491201]\n",
      "epoch:6 step:5228 [D loss: 0.741219, acc: 42.19%] [G loss: 1.436245]\n",
      "epoch:6 step:5229 [D loss: 0.720522, acc: 44.53%] [G loss: 1.485461]\n",
      "epoch:6 step:5230 [D loss: 0.694797, acc: 52.34%] [G loss: 1.576153]\n",
      "epoch:6 step:5231 [D loss: 0.714317, acc: 53.91%] [G loss: 1.714352]\n",
      "epoch:6 step:5232 [D loss: 0.721902, acc: 46.88%] [G loss: 1.545720]\n",
      "epoch:6 step:5233 [D loss: 0.686621, acc: 57.81%] [G loss: 1.605078]\n",
      "epoch:6 step:5234 [D loss: 0.735524, acc: 49.22%] [G loss: 1.519976]\n",
      "epoch:6 step:5235 [D loss: 0.707905, acc: 51.56%] [G loss: 1.630890]\n",
      "epoch:6 step:5236 [D loss: 0.730050, acc: 46.09%] [G loss: 1.536156]\n",
      "epoch:6 step:5237 [D loss: 0.669746, acc: 61.72%] [G loss: 1.507526]\n",
      "epoch:6 step:5238 [D loss: 0.698329, acc: 54.69%] [G loss: 1.388247]\n",
      "epoch:6 step:5239 [D loss: 0.724002, acc: 53.91%] [G loss: 1.462930]\n",
      "epoch:6 step:5240 [D loss: 0.716464, acc: 52.34%] [G loss: 1.623582]\n",
      "epoch:6 step:5241 [D loss: 0.640152, acc: 66.41%] [G loss: 1.483344]\n",
      "epoch:6 step:5242 [D loss: 0.739587, acc: 39.06%] [G loss: 1.465166]\n",
      "epoch:6 step:5243 [D loss: 0.704777, acc: 57.03%] [G loss: 1.515116]\n",
      "epoch:6 step:5244 [D loss: 0.651384, acc: 67.97%] [G loss: 1.545437]\n",
      "epoch:6 step:5245 [D loss: 0.717641, acc: 47.66%] [G loss: 1.466267]\n",
      "epoch:6 step:5246 [D loss: 0.732861, acc: 49.22%] [G loss: 1.540728]\n",
      "epoch:6 step:5247 [D loss: 0.720740, acc: 47.66%] [G loss: 1.476303]\n",
      "epoch:6 step:5248 [D loss: 0.718742, acc: 44.53%] [G loss: 1.533368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5249 [D loss: 0.787718, acc: 34.38%] [G loss: 1.347899]\n",
      "epoch:6 step:5250 [D loss: 0.728766, acc: 45.31%] [G loss: 1.444696]\n",
      "epoch:6 step:5251 [D loss: 0.701356, acc: 50.00%] [G loss: 1.461604]\n",
      "epoch:6 step:5252 [D loss: 0.727301, acc: 43.75%] [G loss: 1.607320]\n",
      "epoch:6 step:5253 [D loss: 0.704586, acc: 53.91%] [G loss: 1.530121]\n",
      "epoch:6 step:5254 [D loss: 0.670456, acc: 64.84%] [G loss: 1.500355]\n",
      "epoch:6 step:5255 [D loss: 0.725148, acc: 48.44%] [G loss: 1.502974]\n",
      "epoch:6 step:5256 [D loss: 0.707598, acc: 46.09%] [G loss: 1.503770]\n",
      "epoch:6 step:5257 [D loss: 0.703035, acc: 50.78%] [G loss: 1.548433]\n",
      "epoch:6 step:5258 [D loss: 0.679635, acc: 55.47%] [G loss: 1.554218]\n",
      "epoch:6 step:5259 [D loss: 0.688887, acc: 55.47%] [G loss: 1.562035]\n",
      "epoch:6 step:5260 [D loss: 0.736441, acc: 46.09%] [G loss: 1.497028]\n",
      "epoch:6 step:5261 [D loss: 0.709543, acc: 48.44%] [G loss: 1.557158]\n",
      "epoch:6 step:5262 [D loss: 0.685514, acc: 57.81%] [G loss: 1.572820]\n",
      "epoch:6 step:5263 [D loss: 0.699115, acc: 46.09%] [G loss: 1.581011]\n",
      "epoch:6 step:5264 [D loss: 0.599177, acc: 71.88%] [G loss: 1.585745]\n",
      "epoch:6 step:5265 [D loss: 0.681846, acc: 57.03%] [G loss: 1.504467]\n",
      "epoch:6 step:5266 [D loss: 0.699816, acc: 53.12%] [G loss: 1.583872]\n",
      "epoch:6 step:5267 [D loss: 0.662397, acc: 54.69%] [G loss: 1.585511]\n",
      "epoch:6 step:5268 [D loss: 0.605616, acc: 74.22%] [G loss: 1.602679]\n",
      "epoch:6 step:5269 [D loss: 0.748675, acc: 48.44%] [G loss: 1.528921]\n",
      "epoch:6 step:5270 [D loss: 0.703533, acc: 55.47%] [G loss: 1.549937]\n",
      "epoch:6 step:5271 [D loss: 0.756500, acc: 46.09%] [G loss: 1.415586]\n",
      "epoch:6 step:5272 [D loss: 0.708692, acc: 50.78%] [G loss: 1.477461]\n",
      "epoch:6 step:5273 [D loss: 0.779783, acc: 32.81%] [G loss: 1.454716]\n",
      "epoch:6 step:5274 [D loss: 0.778201, acc: 32.81%] [G loss: 1.455753]\n",
      "epoch:6 step:5275 [D loss: 0.806088, acc: 28.91%] [G loss: 1.370764]\n",
      "epoch:6 step:5276 [D loss: 0.679015, acc: 58.59%] [G loss: 1.458456]\n",
      "epoch:6 step:5277 [D loss: 0.725329, acc: 48.44%] [G loss: 1.521386]\n",
      "epoch:6 step:5278 [D loss: 0.680785, acc: 57.81%] [G loss: 1.519383]\n",
      "epoch:6 step:5279 [D loss: 0.660368, acc: 60.94%] [G loss: 1.407791]\n",
      "epoch:6 step:5280 [D loss: 0.717423, acc: 46.09%] [G loss: 1.491674]\n",
      "epoch:6 step:5281 [D loss: 0.780329, acc: 39.06%] [G loss: 1.450235]\n",
      "epoch:6 step:5282 [D loss: 0.763272, acc: 41.41%] [G loss: 1.418499]\n",
      "epoch:6 step:5283 [D loss: 0.693770, acc: 51.56%] [G loss: 1.540450]\n",
      "epoch:6 step:5284 [D loss: 0.713924, acc: 50.78%] [G loss: 1.448411]\n",
      "epoch:6 step:5285 [D loss: 0.767042, acc: 38.28%] [G loss: 1.494961]\n",
      "epoch:6 step:5286 [D loss: 0.685751, acc: 59.38%] [G loss: 1.582137]\n",
      "epoch:6 step:5287 [D loss: 0.677474, acc: 58.59%] [G loss: 1.558724]\n",
      "epoch:6 step:5288 [D loss: 0.725853, acc: 53.12%] [G loss: 1.532824]\n",
      "epoch:6 step:5289 [D loss: 0.740915, acc: 36.72%] [G loss: 1.441451]\n",
      "epoch:6 step:5290 [D loss: 0.695807, acc: 56.25%] [G loss: 1.602238]\n",
      "epoch:6 step:5291 [D loss: 0.715730, acc: 53.12%] [G loss: 1.539699]\n",
      "epoch:6 step:5292 [D loss: 0.694490, acc: 51.56%] [G loss: 1.663081]\n",
      "epoch:6 step:5293 [D loss: 0.665209, acc: 61.72%] [G loss: 1.522461]\n",
      "epoch:6 step:5294 [D loss: 0.731139, acc: 45.31%] [G loss: 1.390911]\n",
      "epoch:6 step:5295 [D loss: 0.746984, acc: 41.41%] [G loss: 1.411914]\n",
      "epoch:6 step:5296 [D loss: 0.718856, acc: 51.56%] [G loss: 1.431037]\n",
      "epoch:6 step:5297 [D loss: 0.750159, acc: 42.19%] [G loss: 1.541806]\n",
      "epoch:6 step:5298 [D loss: 0.706053, acc: 55.47%] [G loss: 1.515695]\n",
      "epoch:6 step:5299 [D loss: 0.702110, acc: 49.22%] [G loss: 1.519531]\n",
      "epoch:6 step:5300 [D loss: 0.674243, acc: 55.47%] [G loss: 1.472704]\n",
      "epoch:6 step:5301 [D loss: 0.582289, acc: 82.81%] [G loss: 1.610687]\n",
      "epoch:6 step:5302 [D loss: 0.707560, acc: 53.91%] [G loss: 1.416523]\n",
      "epoch:6 step:5303 [D loss: 0.733842, acc: 46.88%] [G loss: 1.516760]\n",
      "epoch:6 step:5304 [D loss: 0.728181, acc: 50.00%] [G loss: 1.490859]\n",
      "epoch:6 step:5305 [D loss: 0.703048, acc: 57.03%] [G loss: 1.446929]\n",
      "epoch:6 step:5306 [D loss: 0.818282, acc: 28.91%] [G loss: 1.412506]\n",
      "epoch:6 step:5307 [D loss: 0.632582, acc: 71.88%] [G loss: 1.660694]\n",
      "epoch:6 step:5308 [D loss: 0.763977, acc: 39.06%] [G loss: 1.427338]\n",
      "epoch:6 step:5309 [D loss: 0.695594, acc: 58.59%] [G loss: 1.440943]\n",
      "epoch:6 step:5310 [D loss: 0.746286, acc: 40.62%] [G loss: 1.494746]\n",
      "epoch:6 step:5311 [D loss: 0.594891, acc: 67.19%] [G loss: 1.419202]\n",
      "epoch:6 step:5312 [D loss: 0.708161, acc: 53.12%] [G loss: 1.300042]\n",
      "epoch:6 step:5313 [D loss: 0.678439, acc: 63.28%] [G loss: 1.556009]\n",
      "epoch:6 step:5314 [D loss: 0.724101, acc: 42.19%] [G loss: 1.435677]\n",
      "epoch:6 step:5315 [D loss: 0.744375, acc: 36.72%] [G loss: 1.425816]\n",
      "epoch:6 step:5316 [D loss: 0.702292, acc: 50.78%] [G loss: 1.538642]\n",
      "epoch:6 step:5317 [D loss: 0.852607, acc: 22.66%] [G loss: 1.440308]\n",
      "epoch:6 step:5318 [D loss: 0.695808, acc: 54.69%] [G loss: 1.468111]\n",
      "epoch:6 step:5319 [D loss: 0.723687, acc: 51.56%] [G loss: 1.489104]\n",
      "epoch:6 step:5320 [D loss: 0.673529, acc: 56.25%] [G loss: 1.573198]\n",
      "epoch:6 step:5321 [D loss: 0.726824, acc: 46.88%] [G loss: 1.530057]\n",
      "epoch:6 step:5322 [D loss: 0.644414, acc: 65.62%] [G loss: 1.571829]\n",
      "epoch:6 step:5323 [D loss: 0.730830, acc: 46.09%] [G loss: 1.375833]\n",
      "epoch:6 step:5324 [D loss: 0.684240, acc: 55.47%] [G loss: 1.508835]\n",
      "epoch:6 step:5325 [D loss: 0.712065, acc: 46.88%] [G loss: 1.455055]\n",
      "epoch:6 step:5326 [D loss: 0.705015, acc: 52.34%] [G loss: 1.650074]\n",
      "epoch:6 step:5327 [D loss: 0.757608, acc: 42.19%] [G loss: 1.483237]\n",
      "epoch:6 step:5328 [D loss: 0.723064, acc: 42.19%] [G loss: 1.594071]\n",
      "epoch:6 step:5329 [D loss: 0.691420, acc: 53.12%] [G loss: 1.570488]\n",
      "epoch:6 step:5330 [D loss: 0.543044, acc: 79.69%] [G loss: 1.612113]\n",
      "epoch:6 step:5331 [D loss: 0.714352, acc: 53.12%] [G loss: 1.358989]\n",
      "epoch:6 step:5332 [D loss: 0.770370, acc: 36.72%] [G loss: 1.519486]\n",
      "epoch:6 step:5333 [D loss: 0.614564, acc: 80.47%] [G loss: 1.485660]\n",
      "epoch:6 step:5334 [D loss: 0.692912, acc: 53.91%] [G loss: 1.488946]\n",
      "epoch:6 step:5335 [D loss: 0.752076, acc: 42.97%] [G loss: 1.629700]\n",
      "epoch:6 step:5336 [D loss: 0.679581, acc: 59.38%] [G loss: 1.456746]\n",
      "epoch:6 step:5337 [D loss: 0.692148, acc: 54.69%] [G loss: 1.427602]\n",
      "epoch:6 step:5338 [D loss: 0.829448, acc: 21.88%] [G loss: 1.315938]\n",
      "epoch:6 step:5339 [D loss: 0.753013, acc: 44.53%] [G loss: 1.565604]\n",
      "epoch:6 step:5340 [D loss: 0.640414, acc: 63.28%] [G loss: 1.580246]\n",
      "epoch:6 step:5341 [D loss: 0.674581, acc: 57.03%] [G loss: 1.555507]\n",
      "epoch:6 step:5342 [D loss: 0.836091, acc: 34.38%] [G loss: 1.366765]\n",
      "epoch:6 step:5343 [D loss: 0.740683, acc: 44.53%] [G loss: 1.566210]\n",
      "epoch:6 step:5344 [D loss: 0.796820, acc: 27.34%] [G loss: 1.417679]\n",
      "epoch:6 step:5345 [D loss: 0.665541, acc: 64.06%] [G loss: 1.592381]\n",
      "epoch:6 step:5346 [D loss: 0.625450, acc: 72.66%] [G loss: 1.590367]\n",
      "epoch:6 step:5347 [D loss: 0.638263, acc: 66.41%] [G loss: 1.582145]\n",
      "epoch:6 step:5348 [D loss: 0.787725, acc: 39.84%] [G loss: 1.507056]\n",
      "epoch:6 step:5349 [D loss: 0.757816, acc: 38.28%] [G loss: 1.476022]\n",
      "epoch:6 step:5350 [D loss: 0.630064, acc: 67.19%] [G loss: 1.568764]\n",
      "epoch:6 step:5351 [D loss: 0.715311, acc: 47.66%] [G loss: 1.510922]\n",
      "epoch:6 step:5352 [D loss: 0.729059, acc: 48.44%] [G loss: 1.565688]\n",
      "epoch:6 step:5353 [D loss: 0.713401, acc: 50.00%] [G loss: 1.546664]\n",
      "epoch:6 step:5354 [D loss: 0.682276, acc: 60.16%] [G loss: 1.584935]\n",
      "epoch:6 step:5355 [D loss: 0.695462, acc: 53.91%] [G loss: 1.531417]\n",
      "epoch:6 step:5356 [D loss: 0.789719, acc: 36.72%] [G loss: 1.484985]\n",
      "epoch:6 step:5357 [D loss: 0.697313, acc: 54.69%] [G loss: 1.530406]\n",
      "epoch:6 step:5358 [D loss: 0.742436, acc: 42.97%] [G loss: 1.498515]\n",
      "epoch:6 step:5359 [D loss: 0.740769, acc: 42.97%] [G loss: 1.468839]\n",
      "epoch:6 step:5360 [D loss: 0.725974, acc: 44.53%] [G loss: 1.455801]\n",
      "epoch:6 step:5361 [D loss: 0.751267, acc: 42.19%] [G loss: 1.423178]\n",
      "epoch:6 step:5362 [D loss: 0.753187, acc: 37.50%] [G loss: 1.463344]\n",
      "epoch:6 step:5363 [D loss: 0.689543, acc: 56.25%] [G loss: 1.576889]\n",
      "epoch:6 step:5364 [D loss: 0.652242, acc: 64.06%] [G loss: 1.554818]\n",
      "epoch:6 step:5365 [D loss: 0.699557, acc: 48.44%] [G loss: 1.462645]\n",
      "epoch:6 step:5366 [D loss: 0.711541, acc: 51.56%] [G loss: 1.526122]\n",
      "epoch:6 step:5367 [D loss: 0.679155, acc: 56.25%] [G loss: 1.534182]\n",
      "epoch:6 step:5368 [D loss: 0.754632, acc: 46.88%] [G loss: 1.501793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5369 [D loss: 0.679065, acc: 57.03%] [G loss: 1.561352]\n",
      "epoch:6 step:5370 [D loss: 0.706708, acc: 53.91%] [G loss: 1.523000]\n",
      "epoch:6 step:5371 [D loss: 0.709079, acc: 46.88%] [G loss: 1.507400]\n",
      "epoch:6 step:5372 [D loss: 0.647132, acc: 64.06%] [G loss: 1.566117]\n",
      "epoch:6 step:5373 [D loss: 0.680233, acc: 55.47%] [G loss: 1.569019]\n",
      "epoch:6 step:5374 [D loss: 0.772063, acc: 35.94%] [G loss: 1.414558]\n",
      "epoch:6 step:5375 [D loss: 0.759947, acc: 39.84%] [G loss: 1.545354]\n",
      "epoch:6 step:5376 [D loss: 0.694308, acc: 55.47%] [G loss: 1.545212]\n",
      "epoch:6 step:5377 [D loss: 0.708874, acc: 53.91%] [G loss: 1.523790]\n",
      "epoch:6 step:5378 [D loss: 0.690841, acc: 54.69%] [G loss: 1.443686]\n",
      "epoch:6 step:5379 [D loss: 0.714588, acc: 51.56%] [G loss: 1.511033]\n",
      "epoch:6 step:5380 [D loss: 0.723420, acc: 42.19%] [G loss: 1.595116]\n",
      "epoch:6 step:5381 [D loss: 0.726562, acc: 42.19%] [G loss: 1.566352]\n",
      "epoch:6 step:5382 [D loss: 0.660135, acc: 66.41%] [G loss: 1.519822]\n",
      "epoch:6 step:5383 [D loss: 0.714574, acc: 47.66%] [G loss: 1.575425]\n",
      "epoch:6 step:5384 [D loss: 0.634205, acc: 60.16%] [G loss: 1.532084]\n",
      "epoch:6 step:5385 [D loss: 0.747522, acc: 44.53%] [G loss: 1.509077]\n",
      "epoch:6 step:5386 [D loss: 0.697117, acc: 53.12%] [G loss: 1.571059]\n",
      "epoch:6 step:5387 [D loss: 0.647068, acc: 64.06%] [G loss: 1.488052]\n",
      "epoch:6 step:5388 [D loss: 0.700442, acc: 55.47%] [G loss: 1.524396]\n",
      "epoch:6 step:5389 [D loss: 0.766034, acc: 36.72%] [G loss: 1.544528]\n",
      "epoch:6 step:5390 [D loss: 0.731406, acc: 47.66%] [G loss: 1.464458]\n",
      "epoch:6 step:5391 [D loss: 0.733534, acc: 42.97%] [G loss: 1.535202]\n",
      "epoch:6 step:5392 [D loss: 0.696099, acc: 50.78%] [G loss: 1.474241]\n",
      "epoch:6 step:5393 [D loss: 0.670562, acc: 55.47%] [G loss: 1.619839]\n",
      "epoch:6 step:5394 [D loss: 0.711796, acc: 53.12%] [G loss: 1.478821]\n",
      "epoch:6 step:5395 [D loss: 0.709568, acc: 54.69%] [G loss: 1.497611]\n",
      "epoch:6 step:5396 [D loss: 0.553477, acc: 86.72%] [G loss: 1.611140]\n",
      "epoch:6 step:5397 [D loss: 0.744234, acc: 51.56%] [G loss: 1.460392]\n",
      "epoch:6 step:5398 [D loss: 0.623530, acc: 73.44%] [G loss: 1.600506]\n",
      "epoch:6 step:5399 [D loss: 0.732262, acc: 44.53%] [G loss: 1.584487]\n",
      "epoch:6 step:5400 [D loss: 0.653948, acc: 64.06%] [G loss: 1.479648]\n",
      "epoch:6 step:5401 [D loss: 0.804111, acc: 35.16%] [G loss: 1.490336]\n",
      "epoch:6 step:5402 [D loss: 0.602286, acc: 73.44%] [G loss: 1.744491]\n",
      "epoch:6 step:5403 [D loss: 0.721426, acc: 57.03%] [G loss: 1.603814]\n",
      "epoch:6 step:5404 [D loss: 0.650804, acc: 64.84%] [G loss: 1.464043]\n",
      "epoch:6 step:5405 [D loss: 0.545107, acc: 82.81%] [G loss: 1.620273]\n",
      "epoch:6 step:5406 [D loss: 0.778962, acc: 39.06%] [G loss: 1.492236]\n",
      "epoch:6 step:5407 [D loss: 0.685997, acc: 53.12%] [G loss: 1.483322]\n",
      "epoch:6 step:5408 [D loss: 0.716597, acc: 52.34%] [G loss: 1.454467]\n",
      "epoch:6 step:5409 [D loss: 0.700180, acc: 59.38%] [G loss: 1.525831]\n",
      "epoch:6 step:5410 [D loss: 0.754332, acc: 44.53%] [G loss: 1.530804]\n",
      "epoch:6 step:5411 [D loss: 0.706519, acc: 55.47%] [G loss: 1.597833]\n",
      "epoch:6 step:5412 [D loss: 0.781101, acc: 40.62%] [G loss: 1.459006]\n",
      "epoch:6 step:5413 [D loss: 0.798558, acc: 30.47%] [G loss: 1.529781]\n",
      "epoch:6 step:5414 [D loss: 0.639121, acc: 63.28%] [G loss: 1.601285]\n",
      "epoch:6 step:5415 [D loss: 0.587576, acc: 77.34%] [G loss: 1.636875]\n",
      "epoch:6 step:5416 [D loss: 0.753410, acc: 37.50%] [G loss: 1.411209]\n",
      "epoch:6 step:5417 [D loss: 0.676231, acc: 63.28%] [G loss: 1.584699]\n",
      "epoch:6 step:5418 [D loss: 0.748571, acc: 44.53%] [G loss: 1.486657]\n",
      "epoch:6 step:5419 [D loss: 0.677462, acc: 55.47%] [G loss: 1.573902]\n",
      "epoch:6 step:5420 [D loss: 0.706142, acc: 54.69%] [G loss: 1.486693]\n",
      "epoch:6 step:5421 [D loss: 0.765320, acc: 39.84%] [G loss: 1.537266]\n",
      "epoch:6 step:5422 [D loss: 0.707522, acc: 54.69%] [G loss: 1.586506]\n",
      "epoch:6 step:5423 [D loss: 0.717967, acc: 46.09%] [G loss: 1.475472]\n",
      "epoch:6 step:5424 [D loss: 0.774148, acc: 39.84%] [G loss: 1.430631]\n",
      "epoch:6 step:5425 [D loss: 0.649976, acc: 63.28%] [G loss: 1.607100]\n",
      "epoch:6 step:5426 [D loss: 0.746776, acc: 43.75%] [G loss: 1.511842]\n",
      "epoch:6 step:5427 [D loss: 0.742974, acc: 45.31%] [G loss: 1.543695]\n",
      "epoch:6 step:5428 [D loss: 0.783665, acc: 32.81%] [G loss: 1.443416]\n",
      "epoch:6 step:5429 [D loss: 0.674487, acc: 61.72%] [G loss: 1.524502]\n",
      "epoch:6 step:5430 [D loss: 0.737436, acc: 38.28%] [G loss: 1.462717]\n",
      "epoch:6 step:5431 [D loss: 0.715674, acc: 49.22%] [G loss: 1.555389]\n",
      "epoch:6 step:5432 [D loss: 0.669178, acc: 61.72%] [G loss: 1.538990]\n",
      "epoch:6 step:5433 [D loss: 0.782142, acc: 35.94%] [G loss: 1.576201]\n",
      "epoch:6 step:5434 [D loss: 0.735500, acc: 43.75%] [G loss: 1.572067]\n",
      "epoch:6 step:5435 [D loss: 0.736589, acc: 43.75%] [G loss: 1.488189]\n",
      "epoch:6 step:5436 [D loss: 0.679413, acc: 55.47%] [G loss: 1.485772]\n",
      "epoch:6 step:5437 [D loss: 0.784767, acc: 40.62%] [G loss: 1.397513]\n",
      "epoch:6 step:5438 [D loss: 0.700111, acc: 44.53%] [G loss: 1.479271]\n",
      "epoch:6 step:5439 [D loss: 0.683993, acc: 54.69%] [G loss: 1.620513]\n",
      "epoch:6 step:5440 [D loss: 0.724785, acc: 42.19%] [G loss: 1.496125]\n",
      "epoch:6 step:5441 [D loss: 0.693568, acc: 51.56%] [G loss: 1.569135]\n",
      "epoch:6 step:5442 [D loss: 0.748545, acc: 32.03%] [G loss: 1.475991]\n",
      "epoch:6 step:5443 [D loss: 0.655380, acc: 60.94%] [G loss: 1.614664]\n",
      "epoch:6 step:5444 [D loss: 0.706945, acc: 46.88%] [G loss: 1.500977]\n",
      "epoch:6 step:5445 [D loss: 0.705450, acc: 51.56%] [G loss: 1.526673]\n",
      "epoch:6 step:5446 [D loss: 0.733911, acc: 42.19%] [G loss: 1.576985]\n",
      "epoch:6 step:5447 [D loss: 0.718095, acc: 46.88%] [G loss: 1.575699]\n",
      "epoch:6 step:5448 [D loss: 0.714647, acc: 45.31%] [G loss: 1.679750]\n",
      "epoch:6 step:5449 [D loss: 0.693570, acc: 60.16%] [G loss: 1.569935]\n",
      "epoch:6 step:5450 [D loss: 0.687085, acc: 50.00%] [G loss: 1.423673]\n",
      "epoch:6 step:5451 [D loss: 0.657426, acc: 64.84%] [G loss: 1.515787]\n",
      "epoch:6 step:5452 [D loss: 0.669180, acc: 62.50%] [G loss: 1.561175]\n",
      "epoch:6 step:5453 [D loss: 0.776669, acc: 36.72%] [G loss: 1.473048]\n",
      "epoch:6 step:5454 [D loss: 0.691562, acc: 54.69%] [G loss: 1.587122]\n",
      "epoch:6 step:5455 [D loss: 0.747259, acc: 41.41%] [G loss: 1.494459]\n",
      "epoch:6 step:5456 [D loss: 0.706350, acc: 47.66%] [G loss: 1.537529]\n",
      "epoch:6 step:5457 [D loss: 0.788955, acc: 38.28%] [G loss: 1.529585]\n",
      "epoch:6 step:5458 [D loss: 0.724421, acc: 48.44%] [G loss: 1.519920]\n",
      "epoch:6 step:5459 [D loss: 0.750864, acc: 45.31%] [G loss: 1.487059]\n",
      "epoch:6 step:5460 [D loss: 0.704272, acc: 51.56%] [G loss: 1.485621]\n",
      "epoch:6 step:5461 [D loss: 0.697234, acc: 49.22%] [G loss: 1.519222]\n",
      "epoch:6 step:5462 [D loss: 0.624263, acc: 68.75%] [G loss: 1.467405]\n",
      "epoch:6 step:5463 [D loss: 0.727506, acc: 46.09%] [G loss: 1.465294]\n",
      "epoch:6 step:5464 [D loss: 0.699730, acc: 53.91%] [G loss: 1.491761]\n",
      "epoch:6 step:5465 [D loss: 0.827657, acc: 27.34%] [G loss: 1.291564]\n",
      "epoch:6 step:5466 [D loss: 0.775332, acc: 33.59%] [G loss: 1.372933]\n",
      "epoch:6 step:5467 [D loss: 0.707873, acc: 53.91%] [G loss: 1.485718]\n",
      "epoch:7 step:5468 [D loss: 0.674810, acc: 57.81%] [G loss: 1.550397]\n",
      "epoch:7 step:5469 [D loss: 0.712385, acc: 48.44%] [G loss: 1.456166]\n",
      "epoch:7 step:5470 [D loss: 0.714165, acc: 49.22%] [G loss: 1.417287]\n",
      "epoch:7 step:5471 [D loss: 0.682486, acc: 54.69%] [G loss: 1.557522]\n",
      "epoch:7 step:5472 [D loss: 0.701580, acc: 53.12%] [G loss: 1.613727]\n",
      "epoch:7 step:5473 [D loss: 0.742640, acc: 43.75%] [G loss: 1.430866]\n",
      "epoch:7 step:5474 [D loss: 0.685986, acc: 57.03%] [G loss: 1.571876]\n",
      "epoch:7 step:5475 [D loss: 0.770574, acc: 34.38%] [G loss: 1.442660]\n",
      "epoch:7 step:5476 [D loss: 0.757600, acc: 38.28%] [G loss: 1.500451]\n",
      "epoch:7 step:5477 [D loss: 0.557607, acc: 75.00%] [G loss: 1.533467]\n",
      "epoch:7 step:5478 [D loss: 0.658328, acc: 65.62%] [G loss: 1.543499]\n",
      "epoch:7 step:5479 [D loss: 0.787257, acc: 32.03%] [G loss: 1.405171]\n",
      "epoch:7 step:5480 [D loss: 0.723584, acc: 47.66%] [G loss: 1.451971]\n",
      "epoch:7 step:5481 [D loss: 0.720575, acc: 50.78%] [G loss: 1.486967]\n",
      "epoch:7 step:5482 [D loss: 0.790269, acc: 27.34%] [G loss: 1.434378]\n",
      "epoch:7 step:5483 [D loss: 0.750233, acc: 46.09%] [G loss: 1.498372]\n",
      "epoch:7 step:5484 [D loss: 0.630822, acc: 63.28%] [G loss: 1.637075]\n",
      "epoch:7 step:5485 [D loss: 0.622946, acc: 71.09%] [G loss: 1.500359]\n",
      "epoch:7 step:5486 [D loss: 0.727885, acc: 46.09%] [G loss: 1.594744]\n",
      "epoch:7 step:5487 [D loss: 0.683700, acc: 59.38%] [G loss: 1.526644]\n",
      "epoch:7 step:5488 [D loss: 0.723825, acc: 46.88%] [G loss: 1.503224]\n",
      "epoch:7 step:5489 [D loss: 0.643167, acc: 63.28%] [G loss: 1.697484]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:5490 [D loss: 0.752194, acc: 39.84%] [G loss: 1.573857]\n",
      "epoch:7 step:5491 [D loss: 0.641924, acc: 62.50%] [G loss: 1.543413]\n",
      "epoch:7 step:5492 [D loss: 0.712769, acc: 53.12%] [G loss: 1.701089]\n",
      "epoch:7 step:5493 [D loss: 0.727625, acc: 46.09%] [G loss: 1.461839]\n",
      "epoch:7 step:5494 [D loss: 0.700624, acc: 49.22%] [G loss: 1.575549]\n",
      "epoch:7 step:5495 [D loss: 0.660088, acc: 62.50%] [G loss: 1.530389]\n",
      "epoch:7 step:5496 [D loss: 0.658854, acc: 62.50%] [G loss: 1.541903]\n",
      "epoch:7 step:5497 [D loss: 0.632415, acc: 66.41%] [G loss: 1.585127]\n",
      "epoch:7 step:5498 [D loss: 0.802986, acc: 35.94%] [G loss: 1.528273]\n",
      "epoch:7 step:5499 [D loss: 0.671214, acc: 58.59%] [G loss: 1.613112]\n",
      "epoch:7 step:5500 [D loss: 0.651599, acc: 58.59%] [G loss: 1.504981]\n",
      "epoch:7 step:5501 [D loss: 0.724658, acc: 50.00%] [G loss: 1.532145]\n",
      "epoch:7 step:5502 [D loss: 0.709978, acc: 51.56%] [G loss: 1.529134]\n",
      "epoch:7 step:5503 [D loss: 0.565827, acc: 80.47%] [G loss: 1.758463]\n",
      "epoch:7 step:5504 [D loss: 0.678243, acc: 58.59%] [G loss: 1.455933]\n",
      "epoch:7 step:5505 [D loss: 0.775904, acc: 31.25%] [G loss: 1.392859]\n",
      "epoch:7 step:5506 [D loss: 0.785365, acc: 35.94%] [G loss: 1.481523]\n",
      "epoch:7 step:5507 [D loss: 0.633180, acc: 65.62%] [G loss: 1.652846]\n",
      "epoch:7 step:5508 [D loss: 0.692481, acc: 55.47%] [G loss: 1.532222]\n",
      "epoch:7 step:5509 [D loss: 0.724817, acc: 46.09%] [G loss: 1.389951]\n",
      "epoch:7 step:5510 [D loss: 0.674589, acc: 57.81%] [G loss: 1.549725]\n",
      "epoch:7 step:5511 [D loss: 0.563022, acc: 82.03%] [G loss: 1.672977]\n",
      "epoch:7 step:5512 [D loss: 0.699678, acc: 50.78%] [G loss: 1.604501]\n",
      "epoch:7 step:5513 [D loss: 0.717484, acc: 48.44%] [G loss: 1.525199]\n",
      "epoch:7 step:5514 [D loss: 0.756140, acc: 43.75%] [G loss: 1.626009]\n",
      "epoch:7 step:5515 [D loss: 0.531245, acc: 81.25%] [G loss: 1.600776]\n",
      "epoch:7 step:5516 [D loss: 0.625057, acc: 61.72%] [G loss: 1.526295]\n",
      "epoch:7 step:5517 [D loss: 0.728723, acc: 43.75%] [G loss: 1.805618]\n",
      "epoch:7 step:5518 [D loss: 0.668949, acc: 60.94%] [G loss: 1.516662]\n",
      "epoch:7 step:5519 [D loss: 0.696666, acc: 52.34%] [G loss: 1.566836]\n",
      "epoch:7 step:5520 [D loss: 0.588140, acc: 75.78%] [G loss: 1.666327]\n",
      "epoch:7 step:5521 [D loss: 0.670386, acc: 63.28%] [G loss: 1.426413]\n",
      "epoch:7 step:5522 [D loss: 0.446927, acc: 86.72%] [G loss: 1.665117]\n",
      "epoch:7 step:5523 [D loss: 0.916632, acc: 17.19%] [G loss: 1.274378]\n",
      "epoch:7 step:5524 [D loss: 0.685954, acc: 55.47%] [G loss: 1.636854]\n",
      "epoch:7 step:5525 [D loss: 0.775343, acc: 48.44%] [G loss: 1.374510]\n",
      "epoch:7 step:5526 [D loss: 0.540549, acc: 82.81%] [G loss: 1.577843]\n",
      "epoch:7 step:5527 [D loss: 0.657145, acc: 54.69%] [G loss: 1.265932]\n",
      "epoch:7 step:5528 [D loss: 0.602756, acc: 73.44%] [G loss: 1.474112]\n",
      "epoch:7 step:5529 [D loss: 0.547008, acc: 78.91%] [G loss: 1.587005]\n",
      "epoch:7 step:5530 [D loss: 0.669457, acc: 58.59%] [G loss: 1.575249]\n",
      "epoch:7 step:5531 [D loss: 0.859417, acc: 41.41%] [G loss: 1.204792]\n",
      "epoch:7 step:5532 [D loss: 1.042992, acc: 14.06%] [G loss: 1.139613]\n",
      "epoch:7 step:5533 [D loss: 0.852887, acc: 37.50%] [G loss: 1.306231]\n",
      "epoch:7 step:5534 [D loss: 0.591962, acc: 77.34%] [G loss: 1.564392]\n",
      "epoch:7 step:5535 [D loss: 0.675740, acc: 56.25%] [G loss: 1.396555]\n",
      "epoch:7 step:5536 [D loss: 0.794569, acc: 35.16%] [G loss: 1.470404]\n",
      "epoch:7 step:5537 [D loss: 0.520695, acc: 78.91%] [G loss: 1.807505]\n",
      "epoch:7 step:5538 [D loss: 1.049786, acc: 31.25%] [G loss: 1.466930]\n",
      "epoch:7 step:5539 [D loss: 0.560225, acc: 85.94%] [G loss: 1.994500]\n",
      "epoch:7 step:5540 [D loss: 0.652974, acc: 64.06%] [G loss: 1.693379]\n",
      "epoch:7 step:5541 [D loss: 0.704787, acc: 60.94%] [G loss: 1.665885]\n",
      "epoch:7 step:5542 [D loss: 0.606833, acc: 73.44%] [G loss: 1.762809]\n",
      "epoch:7 step:5543 [D loss: 0.716627, acc: 53.91%] [G loss: 1.615504]\n",
      "epoch:7 step:5544 [D loss: 0.653479, acc: 67.19%] [G loss: 1.670285]\n",
      "epoch:7 step:5545 [D loss: 0.723920, acc: 47.66%] [G loss: 1.603444]\n",
      "epoch:7 step:5546 [D loss: 0.622923, acc: 65.62%] [G loss: 1.583147]\n",
      "epoch:7 step:5547 [D loss: 0.724491, acc: 46.88%] [G loss: 1.599100]\n",
      "epoch:7 step:5548 [D loss: 0.701071, acc: 49.22%] [G loss: 1.503830]\n",
      "epoch:7 step:5549 [D loss: 0.682523, acc: 54.69%] [G loss: 1.622995]\n",
      "epoch:7 step:5550 [D loss: 0.716067, acc: 46.88%] [G loss: 1.579374]\n",
      "epoch:7 step:5551 [D loss: 0.717974, acc: 55.47%] [G loss: 1.420420]\n",
      "epoch:7 step:5552 [D loss: 0.588451, acc: 72.66%] [G loss: 1.651686]\n",
      "epoch:7 step:5553 [D loss: 0.584714, acc: 79.69%] [G loss: 1.638984]\n",
      "epoch:7 step:5554 [D loss: 0.745603, acc: 44.53%] [G loss: 1.521993]\n",
      "epoch:7 step:5555 [D loss: 0.810050, acc: 31.25%] [G loss: 1.461491]\n",
      "epoch:7 step:5556 [D loss: 0.648986, acc: 60.94%] [G loss: 1.692177]\n",
      "epoch:7 step:5557 [D loss: 0.689808, acc: 57.81%] [G loss: 1.561400]\n",
      "epoch:7 step:5558 [D loss: 0.703495, acc: 52.34%] [G loss: 1.493072]\n",
      "epoch:7 step:5559 [D loss: 0.669034, acc: 57.81%] [G loss: 1.436134]\n",
      "epoch:7 step:5560 [D loss: 0.681141, acc: 57.81%] [G loss: 1.615616]\n",
      "epoch:7 step:5561 [D loss: 0.808559, acc: 29.69%] [G loss: 1.410967]\n",
      "epoch:7 step:5562 [D loss: 0.671667, acc: 60.16%] [G loss: 1.515600]\n",
      "epoch:7 step:5563 [D loss: 0.700176, acc: 54.69%] [G loss: 1.514807]\n",
      "epoch:7 step:5564 [D loss: 0.702580, acc: 52.34%] [G loss: 1.525771]\n",
      "epoch:7 step:5565 [D loss: 0.789532, acc: 32.81%] [G loss: 1.503273]\n",
      "epoch:7 step:5566 [D loss: 0.718690, acc: 49.22%] [G loss: 1.583521]\n",
      "epoch:7 step:5567 [D loss: 0.717552, acc: 46.88%] [G loss: 1.488935]\n",
      "epoch:7 step:5568 [D loss: 0.725881, acc: 50.00%] [G loss: 1.500685]\n",
      "epoch:7 step:5569 [D loss: 0.737622, acc: 40.62%] [G loss: 1.668474]\n",
      "epoch:7 step:5570 [D loss: 0.706849, acc: 47.66%] [G loss: 1.499512]\n",
      "epoch:7 step:5571 [D loss: 0.805077, acc: 35.94%] [G loss: 1.382133]\n",
      "epoch:7 step:5572 [D loss: 0.629463, acc: 66.41%] [G loss: 1.490769]\n",
      "epoch:7 step:5573 [D loss: 0.629441, acc: 69.53%] [G loss: 1.559496]\n",
      "epoch:7 step:5574 [D loss: 0.702552, acc: 46.88%] [G loss: 1.714477]\n",
      "epoch:7 step:5575 [D loss: 0.795912, acc: 32.81%] [G loss: 1.394070]\n",
      "epoch:7 step:5576 [D loss: 0.691583, acc: 57.81%] [G loss: 1.581636]\n",
      "epoch:7 step:5577 [D loss: 0.742465, acc: 45.31%] [G loss: 1.534324]\n",
      "epoch:7 step:5578 [D loss: 0.726125, acc: 42.97%] [G loss: 1.589268]\n",
      "epoch:7 step:5579 [D loss: 0.649106, acc: 57.03%] [G loss: 1.523394]\n",
      "epoch:7 step:5580 [D loss: 0.749657, acc: 35.94%] [G loss: 1.414563]\n",
      "epoch:7 step:5581 [D loss: 0.697936, acc: 55.47%] [G loss: 1.478136]\n",
      "epoch:7 step:5582 [D loss: 0.767998, acc: 35.94%] [G loss: 1.427284]\n",
      "epoch:7 step:5583 [D loss: 0.697099, acc: 48.44%] [G loss: 1.570727]\n",
      "epoch:7 step:5584 [D loss: 0.703240, acc: 50.00%] [G loss: 1.565082]\n",
      "epoch:7 step:5585 [D loss: 0.779501, acc: 30.47%] [G loss: 1.434235]\n",
      "epoch:7 step:5586 [D loss: 0.657957, acc: 64.06%] [G loss: 1.475947]\n",
      "epoch:7 step:5587 [D loss: 0.688478, acc: 56.25%] [G loss: 1.572011]\n",
      "epoch:7 step:5588 [D loss: 0.680932, acc: 57.03%] [G loss: 1.646923]\n",
      "epoch:7 step:5589 [D loss: 0.629964, acc: 67.97%] [G loss: 1.728584]\n",
      "epoch:7 step:5590 [D loss: 0.745457, acc: 43.75%] [G loss: 1.568110]\n",
      "epoch:7 step:5591 [D loss: 0.643639, acc: 65.62%] [G loss: 1.716032]\n",
      "epoch:7 step:5592 [D loss: 0.674592, acc: 59.38%] [G loss: 1.444387]\n",
      "epoch:7 step:5593 [D loss: 0.712721, acc: 46.88%] [G loss: 1.462873]\n",
      "epoch:7 step:5594 [D loss: 0.654670, acc: 65.62%] [G loss: 1.568242]\n",
      "epoch:7 step:5595 [D loss: 0.647925, acc: 66.41%] [G loss: 1.722600]\n",
      "epoch:7 step:5596 [D loss: 0.630318, acc: 67.97%] [G loss: 1.532950]\n",
      "epoch:7 step:5597 [D loss: 0.871530, acc: 17.19%] [G loss: 1.377288]\n",
      "epoch:7 step:5598 [D loss: 0.674573, acc: 62.50%] [G loss: 1.508470]\n",
      "epoch:7 step:5599 [D loss: 0.783462, acc: 39.06%] [G loss: 1.489517]\n",
      "epoch:7 step:5600 [D loss: 0.624302, acc: 71.88%] [G loss: 1.596249]\n",
      "epoch:7 step:5601 [D loss: 0.729244, acc: 50.00%] [G loss: 1.675703]\n",
      "epoch:7 step:5602 [D loss: 0.648594, acc: 64.84%] [G loss: 1.579289]\n",
      "epoch:7 step:5603 [D loss: 0.597663, acc: 75.00%] [G loss: 1.559444]\n",
      "epoch:7 step:5604 [D loss: 0.791906, acc: 31.25%] [G loss: 1.416902]\n",
      "epoch:7 step:5605 [D loss: 0.703780, acc: 51.56%] [G loss: 1.784232]\n",
      "epoch:7 step:5606 [D loss: 0.664372, acc: 59.38%] [G loss: 1.438788]\n",
      "epoch:7 step:5607 [D loss: 0.700346, acc: 54.69%] [G loss: 1.578398]\n",
      "epoch:7 step:5608 [D loss: 0.712511, acc: 48.44%] [G loss: 1.484926]\n",
      "epoch:7 step:5609 [D loss: 0.781461, acc: 34.38%] [G loss: 1.493608]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:5610 [D loss: 0.794833, acc: 31.25%] [G loss: 1.531774]\n",
      "epoch:7 step:5611 [D loss: 0.604974, acc: 71.09%] [G loss: 1.499900]\n",
      "epoch:7 step:5612 [D loss: 0.614895, acc: 69.53%] [G loss: 1.553457]\n",
      "epoch:7 step:5613 [D loss: 0.686950, acc: 54.69%] [G loss: 1.618001]\n",
      "epoch:7 step:5614 [D loss: 0.672644, acc: 54.69%] [G loss: 1.627736]\n",
      "epoch:7 step:5615 [D loss: 0.596082, acc: 79.69%] [G loss: 1.412649]\n",
      "epoch:7 step:5616 [D loss: 0.675864, acc: 58.59%] [G loss: 1.647495]\n",
      "epoch:7 step:5617 [D loss: 0.714541, acc: 53.12%] [G loss: 1.553886]\n",
      "epoch:7 step:5618 [D loss: 0.632376, acc: 70.31%] [G loss: 1.468590]\n",
      "epoch:7 step:5619 [D loss: 0.682144, acc: 51.56%] [G loss: 1.408851]\n",
      "epoch:7 step:5620 [D loss: 0.619456, acc: 69.53%] [G loss: 1.450632]\n",
      "epoch:7 step:5621 [D loss: 0.614293, acc: 65.62%] [G loss: 1.543120]\n",
      "epoch:7 step:5622 [D loss: 0.782360, acc: 42.97%] [G loss: 1.591850]\n",
      "epoch:7 step:5623 [D loss: 0.734295, acc: 40.62%] [G loss: 1.619510]\n",
      "epoch:7 step:5624 [D loss: 0.696811, acc: 54.69%] [G loss: 1.532829]\n",
      "epoch:7 step:5625 [D loss: 0.586545, acc: 69.53%] [G loss: 1.696883]\n",
      "epoch:7 step:5626 [D loss: 0.643533, acc: 69.53%] [G loss: 1.635265]\n",
      "epoch:7 step:5627 [D loss: 0.809355, acc: 32.81%] [G loss: 1.474859]\n",
      "epoch:7 step:5628 [D loss: 0.644190, acc: 63.28%] [G loss: 1.779399]\n",
      "epoch:7 step:5629 [D loss: 0.597435, acc: 75.00%] [G loss: 1.798788]\n",
      "epoch:7 step:5630 [D loss: 0.751534, acc: 45.31%] [G loss: 1.590960]\n",
      "epoch:7 step:5631 [D loss: 0.626140, acc: 67.19%] [G loss: 1.720458]\n",
      "epoch:7 step:5632 [D loss: 0.641772, acc: 64.84%] [G loss: 1.559047]\n",
      "epoch:7 step:5633 [D loss: 0.700617, acc: 56.25%] [G loss: 1.428665]\n",
      "epoch:7 step:5634 [D loss: 0.737082, acc: 46.88%] [G loss: 1.528534]\n",
      "epoch:7 step:5635 [D loss: 0.547844, acc: 81.25%] [G loss: 1.548177]\n",
      "epoch:7 step:5636 [D loss: 0.498157, acc: 81.25%] [G loss: 1.596661]\n",
      "epoch:7 step:5637 [D loss: 0.624394, acc: 65.62%] [G loss: 1.743326]\n",
      "epoch:7 step:5638 [D loss: 0.437448, acc: 95.31%] [G loss: 1.617313]\n",
      "epoch:7 step:5639 [D loss: 0.814559, acc: 35.94%] [G loss: 1.456964]\n",
      "epoch:7 step:5640 [D loss: 1.021526, acc: 10.94%] [G loss: 1.200689]\n",
      "epoch:7 step:5641 [D loss: 0.805973, acc: 44.53%] [G loss: 1.478610]\n",
      "epoch:7 step:5642 [D loss: 0.716588, acc: 43.75%] [G loss: 1.435666]\n",
      "epoch:7 step:5643 [D loss: 0.716114, acc: 57.81%] [G loss: 1.376081]\n",
      "epoch:7 step:5644 [D loss: 0.765706, acc: 38.28%] [G loss: 1.430928]\n",
      "epoch:7 step:5645 [D loss: 0.591767, acc: 78.12%] [G loss: 1.579057]\n",
      "epoch:7 step:5646 [D loss: 0.693835, acc: 55.47%] [G loss: 1.699408]\n",
      "epoch:7 step:5647 [D loss: 0.644089, acc: 57.81%] [G loss: 1.625124]\n",
      "epoch:7 step:5648 [D loss: 0.620788, acc: 68.75%] [G loss: 1.628789]\n",
      "epoch:7 step:5649 [D loss: 0.718637, acc: 52.34%] [G loss: 1.385939]\n",
      "epoch:7 step:5650 [D loss: 0.983313, acc: 13.28%] [G loss: 1.333328]\n",
      "epoch:7 step:5651 [D loss: 0.658498, acc: 61.72%] [G loss: 1.567025]\n",
      "epoch:7 step:5652 [D loss: 0.786398, acc: 35.94%] [G loss: 1.620770]\n",
      "epoch:7 step:5653 [D loss: 0.703983, acc: 49.22%] [G loss: 1.458900]\n",
      "epoch:7 step:5654 [D loss: 0.584709, acc: 75.00%] [G loss: 1.638145]\n",
      "epoch:7 step:5655 [D loss: 0.628371, acc: 67.19%] [G loss: 1.582522]\n",
      "epoch:7 step:5656 [D loss: 0.597540, acc: 70.31%] [G loss: 1.807002]\n",
      "epoch:7 step:5657 [D loss: 0.766724, acc: 42.97%] [G loss: 1.546475]\n",
      "epoch:7 step:5658 [D loss: 0.533600, acc: 85.94%] [G loss: 1.673640]\n",
      "epoch:7 step:5659 [D loss: 0.602824, acc: 72.66%] [G loss: 1.590923]\n",
      "epoch:7 step:5660 [D loss: 0.825294, acc: 32.03%] [G loss: 1.413892]\n",
      "epoch:7 step:5661 [D loss: 0.653745, acc: 64.84%] [G loss: 1.660179]\n",
      "epoch:7 step:5662 [D loss: 0.731267, acc: 42.97%] [G loss: 1.487105]\n",
      "epoch:7 step:5663 [D loss: 0.753750, acc: 47.66%] [G loss: 1.546499]\n",
      "epoch:7 step:5664 [D loss: 0.592466, acc: 65.62%] [G loss: 1.386313]\n",
      "epoch:7 step:5665 [D loss: 0.903115, acc: 10.94%] [G loss: 1.471900]\n",
      "epoch:7 step:5666 [D loss: 0.880122, acc: 24.22%] [G loss: 1.310650]\n",
      "epoch:7 step:5667 [D loss: 0.700490, acc: 51.56%] [G loss: 1.482413]\n",
      "epoch:7 step:5668 [D loss: 0.663922, acc: 58.59%] [G loss: 1.576389]\n",
      "epoch:7 step:5669 [D loss: 0.645303, acc: 64.84%] [G loss: 1.452637]\n",
      "epoch:7 step:5670 [D loss: 0.738711, acc: 46.09%] [G loss: 1.500875]\n",
      "epoch:7 step:5671 [D loss: 0.694794, acc: 55.47%] [G loss: 1.471214]\n",
      "epoch:7 step:5672 [D loss: 0.822698, acc: 29.69%] [G loss: 1.478726]\n",
      "epoch:7 step:5673 [D loss: 0.754376, acc: 39.84%] [G loss: 1.517014]\n",
      "epoch:7 step:5674 [D loss: 0.567721, acc: 75.78%] [G loss: 1.551975]\n",
      "epoch:7 step:5675 [D loss: 0.840309, acc: 25.00%] [G loss: 1.331267]\n",
      "epoch:7 step:5676 [D loss: 0.771897, acc: 36.72%] [G loss: 1.478414]\n",
      "epoch:7 step:5677 [D loss: 0.710039, acc: 55.47%] [G loss: 1.518953]\n",
      "epoch:7 step:5678 [D loss: 0.630894, acc: 64.84%] [G loss: 1.671804]\n",
      "epoch:7 step:5679 [D loss: 0.721424, acc: 52.34%] [G loss: 1.617016]\n",
      "epoch:7 step:5680 [D loss: 0.728970, acc: 47.66%] [G loss: 1.617413]\n",
      "epoch:7 step:5681 [D loss: 0.700203, acc: 48.44%] [G loss: 1.536535]\n",
      "epoch:7 step:5682 [D loss: 0.746724, acc: 40.62%] [G loss: 1.513953]\n",
      "epoch:7 step:5683 [D loss: 0.772195, acc: 32.81%] [G loss: 1.482673]\n",
      "epoch:7 step:5684 [D loss: 0.736198, acc: 47.66%] [G loss: 1.488732]\n",
      "epoch:7 step:5685 [D loss: 0.691248, acc: 57.81%] [G loss: 1.372183]\n",
      "epoch:7 step:5686 [D loss: 0.671758, acc: 57.81%] [G loss: 1.722704]\n",
      "epoch:7 step:5687 [D loss: 0.683558, acc: 57.81%] [G loss: 1.537474]\n",
      "epoch:7 step:5688 [D loss: 0.631914, acc: 72.66%] [G loss: 1.631231]\n",
      "epoch:7 step:5689 [D loss: 0.768623, acc: 37.50%] [G loss: 1.590108]\n",
      "epoch:7 step:5690 [D loss: 0.691776, acc: 60.94%] [G loss: 1.552867]\n",
      "epoch:7 step:5691 [D loss: 0.724241, acc: 46.09%] [G loss: 1.447430]\n",
      "epoch:7 step:5692 [D loss: 0.820147, acc: 35.94%] [G loss: 1.486197]\n",
      "epoch:7 step:5693 [D loss: 0.747417, acc: 51.56%] [G loss: 1.435160]\n",
      "epoch:7 step:5694 [D loss: 0.741037, acc: 49.22%] [G loss: 1.534213]\n",
      "epoch:7 step:5695 [D loss: 0.629654, acc: 71.09%] [G loss: 1.581121]\n",
      "epoch:7 step:5696 [D loss: 0.675021, acc: 55.47%] [G loss: 1.525082]\n",
      "epoch:7 step:5697 [D loss: 0.695395, acc: 53.12%] [G loss: 1.546546]\n",
      "epoch:7 step:5698 [D loss: 0.582215, acc: 72.66%] [G loss: 1.768664]\n",
      "epoch:7 step:5699 [D loss: 0.727656, acc: 44.53%] [G loss: 1.517954]\n",
      "epoch:7 step:5700 [D loss: 0.636176, acc: 70.31%] [G loss: 1.504126]\n",
      "epoch:7 step:5701 [D loss: 0.693740, acc: 58.59%] [G loss: 1.561314]\n",
      "epoch:7 step:5702 [D loss: 0.706142, acc: 52.34%] [G loss: 1.564641]\n",
      "epoch:7 step:5703 [D loss: 0.811937, acc: 29.69%] [G loss: 1.568071]\n",
      "epoch:7 step:5704 [D loss: 0.616171, acc: 73.44%] [G loss: 1.605030]\n",
      "epoch:7 step:5705 [D loss: 0.644780, acc: 71.09%] [G loss: 1.612788]\n",
      "epoch:7 step:5706 [D loss: 0.679799, acc: 56.25%] [G loss: 1.587199]\n",
      "epoch:7 step:5707 [D loss: 0.789286, acc: 35.16%] [G loss: 1.494813]\n",
      "epoch:7 step:5708 [D loss: 0.634984, acc: 64.06%] [G loss: 1.652352]\n",
      "epoch:7 step:5709 [D loss: 0.714977, acc: 49.22%] [G loss: 1.487035]\n",
      "epoch:7 step:5710 [D loss: 0.640432, acc: 68.75%] [G loss: 1.550287]\n",
      "epoch:7 step:5711 [D loss: 0.686997, acc: 57.03%] [G loss: 1.609757]\n",
      "epoch:7 step:5712 [D loss: 0.690892, acc: 58.59%] [G loss: 1.546124]\n",
      "epoch:7 step:5713 [D loss: 0.676495, acc: 61.72%] [G loss: 1.726376]\n",
      "epoch:7 step:5714 [D loss: 0.712617, acc: 48.44%] [G loss: 1.595287]\n",
      "epoch:7 step:5715 [D loss: 0.752393, acc: 40.62%] [G loss: 1.489249]\n",
      "epoch:7 step:5716 [D loss: 0.727328, acc: 46.09%] [G loss: 1.452777]\n",
      "epoch:7 step:5717 [D loss: 0.768235, acc: 33.59%] [G loss: 1.468658]\n",
      "epoch:7 step:5718 [D loss: 0.633311, acc: 71.09%] [G loss: 1.568436]\n",
      "epoch:7 step:5719 [D loss: 0.630811, acc: 66.41%] [G loss: 1.577583]\n",
      "epoch:7 step:5720 [D loss: 0.777605, acc: 39.84%] [G loss: 1.497386]\n",
      "epoch:7 step:5721 [D loss: 0.777882, acc: 33.59%] [G loss: 1.540149]\n",
      "epoch:7 step:5722 [D loss: 0.734851, acc: 48.44%] [G loss: 1.585294]\n",
      "epoch:7 step:5723 [D loss: 0.745835, acc: 47.66%] [G loss: 1.505962]\n",
      "epoch:7 step:5724 [D loss: 0.795770, acc: 39.06%] [G loss: 1.510828]\n",
      "epoch:7 step:5725 [D loss: 0.682261, acc: 55.47%] [G loss: 1.535390]\n",
      "epoch:7 step:5726 [D loss: 0.684956, acc: 63.28%] [G loss: 1.617610]\n",
      "epoch:7 step:5727 [D loss: 0.758939, acc: 42.97%] [G loss: 1.500824]\n",
      "epoch:7 step:5728 [D loss: 0.693568, acc: 55.47%] [G loss: 1.496356]\n",
      "epoch:7 step:5729 [D loss: 0.623303, acc: 68.75%] [G loss: 1.667090]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:5730 [D loss: 0.791132, acc: 33.59%] [G loss: 1.497249]\n",
      "epoch:7 step:5731 [D loss: 0.660720, acc: 64.84%] [G loss: 1.531627]\n",
      "epoch:7 step:5732 [D loss: 0.648596, acc: 67.19%] [G loss: 1.614068]\n",
      "epoch:7 step:5733 [D loss: 0.716656, acc: 49.22%] [G loss: 1.461478]\n",
      "epoch:7 step:5734 [D loss: 0.987864, acc: 25.00%] [G loss: 1.360680]\n",
      "epoch:7 step:5735 [D loss: 0.635972, acc: 65.62%] [G loss: 1.647963]\n",
      "epoch:7 step:5736 [D loss: 0.699824, acc: 46.88%] [G loss: 1.624115]\n",
      "epoch:7 step:5737 [D loss: 0.652333, acc: 60.94%] [G loss: 1.605438]\n",
      "epoch:7 step:5738 [D loss: 0.671863, acc: 57.81%] [G loss: 1.629613]\n",
      "epoch:7 step:5739 [D loss: 0.660092, acc: 60.16%] [G loss: 1.429483]\n",
      "epoch:7 step:5740 [D loss: 0.782022, acc: 30.47%] [G loss: 1.547061]\n",
      "epoch:7 step:5741 [D loss: 0.794238, acc: 35.16%] [G loss: 1.388675]\n",
      "epoch:7 step:5742 [D loss: 0.717549, acc: 43.75%] [G loss: 1.480955]\n",
      "epoch:7 step:5743 [D loss: 0.767313, acc: 39.06%] [G loss: 1.419838]\n",
      "epoch:7 step:5744 [D loss: 0.713411, acc: 50.00%] [G loss: 1.416762]\n",
      "epoch:7 step:5745 [D loss: 0.705892, acc: 52.34%] [G loss: 1.580105]\n",
      "epoch:7 step:5746 [D loss: 0.723639, acc: 45.31%] [G loss: 1.437373]\n",
      "epoch:7 step:5747 [D loss: 0.605454, acc: 71.09%] [G loss: 1.682881]\n",
      "epoch:7 step:5748 [D loss: 0.652493, acc: 66.41%] [G loss: 1.512661]\n",
      "epoch:7 step:5749 [D loss: 0.828127, acc: 24.22%] [G loss: 1.340358]\n",
      "epoch:7 step:5750 [D loss: 0.744166, acc: 38.28%] [G loss: 1.516125]\n",
      "epoch:7 step:5751 [D loss: 0.727812, acc: 47.66%] [G loss: 1.521525]\n",
      "epoch:7 step:5752 [D loss: 0.714859, acc: 50.00%] [G loss: 1.499820]\n",
      "epoch:7 step:5753 [D loss: 0.701849, acc: 47.66%] [G loss: 1.547880]\n",
      "epoch:7 step:5754 [D loss: 0.653885, acc: 65.62%] [G loss: 1.600198]\n",
      "epoch:7 step:5755 [D loss: 0.715243, acc: 49.22%] [G loss: 1.594014]\n",
      "epoch:7 step:5756 [D loss: 0.681787, acc: 56.25%] [G loss: 1.520355]\n",
      "epoch:7 step:5757 [D loss: 0.720939, acc: 45.31%] [G loss: 1.473250]\n",
      "epoch:7 step:5758 [D loss: 0.847105, acc: 27.34%] [G loss: 1.397122]\n",
      "epoch:7 step:5759 [D loss: 0.662618, acc: 62.50%] [G loss: 1.516678]\n",
      "epoch:7 step:5760 [D loss: 0.730147, acc: 46.09%] [G loss: 1.424788]\n",
      "epoch:7 step:5761 [D loss: 0.689595, acc: 53.91%] [G loss: 1.614584]\n",
      "epoch:7 step:5762 [D loss: 0.683097, acc: 56.25%] [G loss: 1.542635]\n",
      "epoch:7 step:5763 [D loss: 0.722941, acc: 47.66%] [G loss: 1.508453]\n",
      "epoch:7 step:5764 [D loss: 0.700920, acc: 51.56%] [G loss: 1.502238]\n",
      "epoch:7 step:5765 [D loss: 0.665532, acc: 59.38%] [G loss: 1.637115]\n",
      "epoch:7 step:5766 [D loss: 0.727864, acc: 50.78%] [G loss: 1.527138]\n",
      "epoch:7 step:5767 [D loss: 0.759890, acc: 38.28%] [G loss: 1.469712]\n",
      "epoch:7 step:5768 [D loss: 0.737157, acc: 48.44%] [G loss: 1.474970]\n",
      "epoch:7 step:5769 [D loss: 0.687927, acc: 56.25%] [G loss: 1.583356]\n",
      "epoch:7 step:5770 [D loss: 0.712930, acc: 50.00%] [G loss: 1.501663]\n",
      "epoch:7 step:5771 [D loss: 0.748027, acc: 44.53%] [G loss: 1.494252]\n",
      "epoch:7 step:5772 [D loss: 0.701995, acc: 53.12%] [G loss: 1.540093]\n",
      "epoch:7 step:5773 [D loss: 0.711674, acc: 46.09%] [G loss: 1.538599]\n",
      "epoch:7 step:5774 [D loss: 0.730244, acc: 42.97%] [G loss: 1.524479]\n",
      "epoch:7 step:5775 [D loss: 0.671821, acc: 57.81%] [G loss: 1.502289]\n",
      "epoch:7 step:5776 [D loss: 0.758995, acc: 41.41%] [G loss: 1.485627]\n",
      "epoch:7 step:5777 [D loss: 0.701251, acc: 48.44%] [G loss: 1.496448]\n",
      "epoch:7 step:5778 [D loss: 0.752999, acc: 37.50%] [G loss: 1.495940]\n",
      "epoch:7 step:5779 [D loss: 0.676753, acc: 60.94%] [G loss: 1.517698]\n",
      "epoch:7 step:5780 [D loss: 0.756444, acc: 41.41%] [G loss: 1.434940]\n",
      "epoch:7 step:5781 [D loss: 0.535277, acc: 82.03%] [G loss: 1.549423]\n",
      "epoch:7 step:5782 [D loss: 0.895396, acc: 11.72%] [G loss: 1.281397]\n",
      "epoch:7 step:5783 [D loss: 0.740474, acc: 46.09%] [G loss: 1.457406]\n",
      "epoch:7 step:5784 [D loss: 0.720261, acc: 48.44%] [G loss: 1.549047]\n",
      "epoch:7 step:5785 [D loss: 0.705740, acc: 51.56%] [G loss: 1.488377]\n",
      "epoch:7 step:5786 [D loss: 0.752275, acc: 40.62%] [G loss: 1.488013]\n",
      "epoch:7 step:5787 [D loss: 0.764527, acc: 32.81%] [G loss: 1.498712]\n",
      "epoch:7 step:5788 [D loss: 0.742352, acc: 44.53%] [G loss: 1.540035]\n",
      "epoch:7 step:5789 [D loss: 0.694112, acc: 50.78%] [G loss: 1.503988]\n",
      "epoch:7 step:5790 [D loss: 0.731977, acc: 49.22%] [G loss: 1.495891]\n",
      "epoch:7 step:5791 [D loss: 0.712691, acc: 46.09%] [G loss: 1.503619]\n",
      "epoch:7 step:5792 [D loss: 0.703283, acc: 49.22%] [G loss: 1.533775]\n",
      "epoch:7 step:5793 [D loss: 0.678632, acc: 58.59%] [G loss: 1.531578]\n",
      "epoch:7 step:5794 [D loss: 0.699104, acc: 52.34%] [G loss: 1.515749]\n",
      "epoch:7 step:5795 [D loss: 0.722989, acc: 45.31%] [G loss: 1.519838]\n",
      "epoch:7 step:5796 [D loss: 0.693353, acc: 57.81%] [G loss: 1.537398]\n",
      "epoch:7 step:5797 [D loss: 0.708946, acc: 46.88%] [G loss: 1.477107]\n",
      "epoch:7 step:5798 [D loss: 0.703130, acc: 49.22%] [G loss: 1.572741]\n",
      "epoch:7 step:5799 [D loss: 0.691159, acc: 57.03%] [G loss: 1.463190]\n",
      "epoch:7 step:5800 [D loss: 0.706909, acc: 46.09%] [G loss: 1.507993]\n",
      "epoch:7 step:5801 [D loss: 0.651175, acc: 65.62%] [G loss: 1.619248]\n",
      "epoch:7 step:5802 [D loss: 0.619453, acc: 69.53%] [G loss: 1.586426]\n",
      "epoch:7 step:5803 [D loss: 0.717418, acc: 46.88%] [G loss: 1.589237]\n",
      "epoch:7 step:5804 [D loss: 0.690247, acc: 52.34%] [G loss: 1.479632]\n",
      "epoch:7 step:5805 [D loss: 0.794975, acc: 36.72%] [G loss: 1.480647]\n",
      "epoch:7 step:5806 [D loss: 0.734177, acc: 50.00%] [G loss: 1.492102]\n",
      "epoch:7 step:5807 [D loss: 0.666872, acc: 61.72%] [G loss: 1.480199]\n",
      "epoch:7 step:5808 [D loss: 0.671514, acc: 60.16%] [G loss: 1.506445]\n",
      "epoch:7 step:5809 [D loss: 0.745256, acc: 45.31%] [G loss: 1.550622]\n",
      "epoch:7 step:5810 [D loss: 0.679057, acc: 57.03%] [G loss: 1.583908]\n",
      "epoch:7 step:5811 [D loss: 0.645367, acc: 58.59%] [G loss: 1.529941]\n",
      "epoch:7 step:5812 [D loss: 0.686949, acc: 52.34%] [G loss: 1.415780]\n",
      "epoch:7 step:5813 [D loss: 0.589089, acc: 75.00%] [G loss: 1.672523]\n",
      "epoch:7 step:5814 [D loss: 0.706066, acc: 55.47%] [G loss: 1.571167]\n",
      "epoch:7 step:5815 [D loss: 0.684852, acc: 53.12%] [G loss: 1.551465]\n",
      "epoch:7 step:5816 [D loss: 0.639573, acc: 68.75%] [G loss: 1.705558]\n",
      "epoch:7 step:5817 [D loss: 0.767046, acc: 41.41%] [G loss: 1.553096]\n",
      "epoch:7 step:5818 [D loss: 0.790392, acc: 28.12%] [G loss: 1.428573]\n",
      "epoch:7 step:5819 [D loss: 0.708161, acc: 51.56%] [G loss: 1.551792]\n",
      "epoch:7 step:5820 [D loss: 0.696213, acc: 55.47%] [G loss: 1.542861]\n",
      "epoch:7 step:5821 [D loss: 0.746779, acc: 41.41%] [G loss: 1.373403]\n",
      "epoch:7 step:5822 [D loss: 0.701849, acc: 56.25%] [G loss: 1.410744]\n",
      "epoch:7 step:5823 [D loss: 0.720208, acc: 46.09%] [G loss: 1.449904]\n",
      "epoch:7 step:5824 [D loss: 0.713047, acc: 47.66%] [G loss: 1.564924]\n",
      "epoch:7 step:5825 [D loss: 0.765217, acc: 37.50%] [G loss: 1.358945]\n",
      "epoch:7 step:5826 [D loss: 0.692099, acc: 53.12%] [G loss: 1.413141]\n",
      "epoch:7 step:5827 [D loss: 0.770872, acc: 36.72%] [G loss: 1.340506]\n",
      "epoch:7 step:5828 [D loss: 0.617282, acc: 71.09%] [G loss: 1.592129]\n",
      "epoch:7 step:5829 [D loss: 0.723412, acc: 47.66%] [G loss: 1.461123]\n",
      "epoch:7 step:5830 [D loss: 0.753085, acc: 46.88%] [G loss: 1.563997]\n",
      "epoch:7 step:5831 [D loss: 0.658723, acc: 61.72%] [G loss: 1.693740]\n",
      "epoch:7 step:5832 [D loss: 0.534658, acc: 86.72%] [G loss: 1.522534]\n",
      "epoch:7 step:5833 [D loss: 0.725690, acc: 46.09%] [G loss: 1.500558]\n",
      "epoch:7 step:5834 [D loss: 0.555160, acc: 82.03%] [G loss: 1.570219]\n",
      "epoch:7 step:5835 [D loss: 0.720540, acc: 49.22%] [G loss: 1.553206]\n",
      "epoch:7 step:5836 [D loss: 0.555501, acc: 74.22%] [G loss: 1.513780]\n",
      "epoch:7 step:5837 [D loss: 0.632030, acc: 71.09%] [G loss: 1.770245]\n",
      "epoch:7 step:5838 [D loss: 0.788419, acc: 26.56%] [G loss: 1.480290]\n",
      "epoch:7 step:5839 [D loss: 0.709375, acc: 52.34%] [G loss: 1.613696]\n",
      "epoch:7 step:5840 [D loss: 0.961939, acc: 14.84%] [G loss: 1.131086]\n",
      "epoch:7 step:5841 [D loss: 0.718893, acc: 44.53%] [G loss: 1.560251]\n",
      "epoch:7 step:5842 [D loss: 0.842515, acc: 26.56%] [G loss: 1.391683]\n",
      "epoch:7 step:5843 [D loss: 0.700274, acc: 50.78%] [G loss: 1.583508]\n",
      "epoch:7 step:5844 [D loss: 0.667487, acc: 57.81%] [G loss: 1.567935]\n",
      "epoch:7 step:5845 [D loss: 0.775970, acc: 38.28%] [G loss: 1.420823]\n",
      "epoch:7 step:5846 [D loss: 0.680298, acc: 54.69%] [G loss: 1.493351]\n",
      "epoch:7 step:5847 [D loss: 0.712917, acc: 44.53%] [G loss: 1.580567]\n",
      "epoch:7 step:5848 [D loss: 0.665379, acc: 64.06%] [G loss: 1.531057]\n",
      "epoch:7 step:5849 [D loss: 0.706334, acc: 42.19%] [G loss: 1.497120]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:5850 [D loss: 0.669943, acc: 54.69%] [G loss: 1.478469]\n",
      "epoch:7 step:5851 [D loss: 0.673324, acc: 61.72%] [G loss: 1.684141]\n",
      "epoch:7 step:5852 [D loss: 0.702912, acc: 52.34%] [G loss: 1.581219]\n",
      "epoch:7 step:5853 [D loss: 0.715510, acc: 49.22%] [G loss: 1.570671]\n",
      "epoch:7 step:5854 [D loss: 0.658355, acc: 57.81%] [G loss: 1.426744]\n",
      "epoch:7 step:5855 [D loss: 0.666185, acc: 55.47%] [G loss: 1.495714]\n",
      "epoch:7 step:5856 [D loss: 0.662029, acc: 64.06%] [G loss: 1.744126]\n",
      "epoch:7 step:5857 [D loss: 0.778495, acc: 44.53%] [G loss: 1.470662]\n",
      "epoch:7 step:5858 [D loss: 0.759326, acc: 42.19%] [G loss: 1.503223]\n",
      "epoch:7 step:5859 [D loss: 0.596830, acc: 78.12%] [G loss: 1.668330]\n",
      "epoch:7 step:5860 [D loss: 0.780597, acc: 29.69%] [G loss: 1.447495]\n",
      "epoch:7 step:5861 [D loss: 0.632726, acc: 68.75%] [G loss: 1.557017]\n",
      "epoch:7 step:5862 [D loss: 0.763292, acc: 33.59%] [G loss: 1.529516]\n",
      "epoch:7 step:5863 [D loss: 0.711871, acc: 50.00%] [G loss: 1.573974]\n",
      "epoch:7 step:5864 [D loss: 0.727118, acc: 46.88%] [G loss: 1.512436]\n",
      "epoch:7 step:5865 [D loss: 0.703755, acc: 52.34%] [G loss: 1.431754]\n",
      "epoch:7 step:5866 [D loss: 0.709203, acc: 46.88%] [G loss: 1.617661]\n",
      "epoch:7 step:5867 [D loss: 0.695328, acc: 50.78%] [G loss: 1.556660]\n",
      "epoch:7 step:5868 [D loss: 0.666872, acc: 57.81%] [G loss: 1.522329]\n",
      "epoch:7 step:5869 [D loss: 0.692960, acc: 53.91%] [G loss: 1.559068]\n",
      "epoch:7 step:5870 [D loss: 0.640792, acc: 66.41%] [G loss: 1.497384]\n",
      "epoch:7 step:5871 [D loss: 0.662123, acc: 57.03%] [G loss: 1.646906]\n",
      "epoch:7 step:5872 [D loss: 0.595998, acc: 75.00%] [G loss: 1.604322]\n",
      "epoch:7 step:5873 [D loss: 0.723024, acc: 51.56%] [G loss: 1.536552]\n",
      "epoch:7 step:5874 [D loss: 0.719779, acc: 44.53%] [G loss: 1.482068]\n",
      "epoch:7 step:5875 [D loss: 0.712724, acc: 52.34%] [G loss: 1.408476]\n",
      "epoch:7 step:5876 [D loss: 0.698120, acc: 51.56%] [G loss: 1.489344]\n",
      "epoch:7 step:5877 [D loss: 0.603175, acc: 73.44%] [G loss: 1.596514]\n",
      "epoch:7 step:5878 [D loss: 0.753464, acc: 33.59%] [G loss: 1.429192]\n",
      "epoch:7 step:5879 [D loss: 0.697218, acc: 55.47%] [G loss: 1.552247]\n",
      "epoch:7 step:5880 [D loss: 0.652229, acc: 68.75%] [G loss: 1.495180]\n",
      "epoch:7 step:5881 [D loss: 0.711114, acc: 53.91%] [G loss: 1.627727]\n",
      "epoch:7 step:5882 [D loss: 0.678290, acc: 57.03%] [G loss: 1.528396]\n",
      "epoch:7 step:5883 [D loss: 0.606324, acc: 67.19%] [G loss: 1.663498]\n",
      "epoch:7 step:5884 [D loss: 0.640739, acc: 65.62%] [G loss: 1.688049]\n",
      "epoch:7 step:5885 [D loss: 0.574578, acc: 76.56%] [G loss: 1.924096]\n",
      "epoch:7 step:5886 [D loss: 0.676048, acc: 62.50%] [G loss: 1.538740]\n",
      "epoch:7 step:5887 [D loss: 0.773133, acc: 35.16%] [G loss: 1.536304]\n",
      "epoch:7 step:5888 [D loss: 0.560626, acc: 82.81%] [G loss: 1.598349]\n",
      "epoch:7 step:5889 [D loss: 0.595045, acc: 70.31%] [G loss: 1.686315]\n",
      "epoch:7 step:5890 [D loss: 0.760603, acc: 39.84%] [G loss: 1.527416]\n",
      "epoch:7 step:5891 [D loss: 0.492962, acc: 86.72%] [G loss: 1.613265]\n",
      "epoch:7 step:5892 [D loss: 0.829034, acc: 23.44%] [G loss: 1.553025]\n",
      "epoch:7 step:5893 [D loss: 0.504562, acc: 89.06%] [G loss: 1.600055]\n",
      "epoch:7 step:5894 [D loss: 0.678456, acc: 56.25%] [G loss: 1.566018]\n",
      "epoch:7 step:5895 [D loss: 0.910078, acc: 18.75%] [G loss: 1.340413]\n",
      "epoch:7 step:5896 [D loss: 0.647690, acc: 69.53%] [G loss: 1.468363]\n",
      "epoch:7 step:5897 [D loss: 0.954563, acc: 28.91%] [G loss: 1.183316]\n",
      "epoch:7 step:5898 [D loss: 0.805576, acc: 26.56%] [G loss: 1.478625]\n",
      "epoch:7 step:5899 [D loss: 0.654722, acc: 62.50%] [G loss: 1.389221]\n",
      "epoch:7 step:5900 [D loss: 0.547653, acc: 80.47%] [G loss: 1.551027]\n",
      "epoch:7 step:5901 [D loss: 0.682324, acc: 57.81%] [G loss: 1.485429]\n",
      "epoch:7 step:5902 [D loss: 0.630502, acc: 72.66%] [G loss: 1.478226]\n",
      "epoch:7 step:5903 [D loss: 0.735238, acc: 46.09%] [G loss: 1.504961]\n",
      "epoch:7 step:5904 [D loss: 0.789366, acc: 38.28%] [G loss: 1.539492]\n",
      "epoch:7 step:5905 [D loss: 0.800341, acc: 33.59%] [G loss: 1.272389]\n",
      "epoch:7 step:5906 [D loss: 0.629724, acc: 71.09%] [G loss: 1.594078]\n",
      "epoch:7 step:5907 [D loss: 0.712505, acc: 48.44%] [G loss: 1.549451]\n",
      "epoch:7 step:5908 [D loss: 0.802915, acc: 28.91%] [G loss: 1.457986]\n",
      "epoch:7 step:5909 [D loss: 0.679852, acc: 60.16%] [G loss: 1.700477]\n",
      "epoch:7 step:5910 [D loss: 0.687435, acc: 61.72%] [G loss: 1.762412]\n",
      "epoch:7 step:5911 [D loss: 0.588839, acc: 71.88%] [G loss: 1.927554]\n",
      "epoch:7 step:5912 [D loss: 0.786960, acc: 44.53%] [G loss: 1.707600]\n",
      "epoch:7 step:5913 [D loss: 0.679762, acc: 55.47%] [G loss: 1.658725]\n",
      "epoch:7 step:5914 [D loss: 0.687928, acc: 55.47%] [G loss: 1.717277]\n",
      "epoch:7 step:5915 [D loss: 0.604976, acc: 68.75%] [G loss: 1.970116]\n",
      "epoch:7 step:5916 [D loss: 0.831699, acc: 31.25%] [G loss: 1.362327]\n",
      "epoch:7 step:5917 [D loss: 0.681751, acc: 57.81%] [G loss: 1.449072]\n",
      "epoch:7 step:5918 [D loss: 0.713710, acc: 50.78%] [G loss: 1.551934]\n",
      "epoch:7 step:5919 [D loss: 0.720875, acc: 51.56%] [G loss: 1.573248]\n",
      "epoch:7 step:5920 [D loss: 0.656357, acc: 57.03%] [G loss: 1.627360]\n",
      "epoch:7 step:5921 [D loss: 0.692290, acc: 53.91%] [G loss: 1.544721]\n",
      "epoch:7 step:5922 [D loss: 0.787979, acc: 38.28%] [G loss: 1.436648]\n",
      "epoch:7 step:5923 [D loss: 0.792403, acc: 28.12%] [G loss: 1.607496]\n",
      "epoch:7 step:5924 [D loss: 0.707166, acc: 53.12%] [G loss: 1.532225]\n",
      "epoch:7 step:5925 [D loss: 0.772864, acc: 45.31%] [G loss: 1.474112]\n",
      "epoch:7 step:5926 [D loss: 0.604758, acc: 74.22%] [G loss: 1.649703]\n",
      "epoch:7 step:5927 [D loss: 0.707879, acc: 53.91%] [G loss: 1.556893]\n",
      "epoch:7 step:5928 [D loss: 0.752037, acc: 48.44%] [G loss: 1.387760]\n",
      "epoch:7 step:5929 [D loss: 0.709746, acc: 51.56%] [G loss: 1.632447]\n",
      "epoch:7 step:5930 [D loss: 0.638011, acc: 65.62%] [G loss: 1.727201]\n",
      "epoch:7 step:5931 [D loss: 0.710969, acc: 53.91%] [G loss: 1.569321]\n",
      "epoch:7 step:5932 [D loss: 0.650962, acc: 58.59%] [G loss: 1.537280]\n",
      "epoch:7 step:5933 [D loss: 0.703573, acc: 53.91%] [G loss: 1.652795]\n",
      "epoch:7 step:5934 [D loss: 0.699173, acc: 53.91%] [G loss: 1.665097]\n",
      "epoch:7 step:5935 [D loss: 0.691904, acc: 53.12%] [G loss: 1.679956]\n",
      "epoch:7 step:5936 [D loss: 0.703093, acc: 53.12%] [G loss: 1.658076]\n",
      "epoch:7 step:5937 [D loss: 0.632293, acc: 60.94%] [G loss: 1.545555]\n",
      "epoch:7 step:5938 [D loss: 0.788998, acc: 32.03%] [G loss: 1.453561]\n",
      "epoch:7 step:5939 [D loss: 0.703154, acc: 48.44%] [G loss: 1.540895]\n",
      "epoch:7 step:5940 [D loss: 0.717264, acc: 50.78%] [G loss: 1.615079]\n",
      "epoch:7 step:5941 [D loss: 0.711094, acc: 57.03%] [G loss: 1.425440]\n",
      "epoch:7 step:5942 [D loss: 0.679654, acc: 53.91%] [G loss: 1.664213]\n",
      "epoch:7 step:5943 [D loss: 0.625913, acc: 71.88%] [G loss: 1.706906]\n",
      "epoch:7 step:5944 [D loss: 0.756025, acc: 39.84%] [G loss: 1.486503]\n",
      "epoch:7 step:5945 [D loss: 0.762036, acc: 41.41%] [G loss: 1.598762]\n",
      "epoch:7 step:5946 [D loss: 0.749759, acc: 42.19%] [G loss: 1.589016]\n",
      "epoch:7 step:5947 [D loss: 0.533812, acc: 81.25%] [G loss: 1.680450]\n",
      "epoch:7 step:5948 [D loss: 0.608405, acc: 67.19%] [G loss: 1.746542]\n",
      "epoch:7 step:5949 [D loss: 0.761422, acc: 43.75%] [G loss: 1.579260]\n",
      "epoch:7 step:5950 [D loss: 0.675707, acc: 57.03%] [G loss: 1.594497]\n",
      "epoch:7 step:5951 [D loss: 0.711808, acc: 50.00%] [G loss: 1.518227]\n",
      "epoch:7 step:5952 [D loss: 0.671681, acc: 57.03%] [G loss: 1.586058]\n",
      "epoch:7 step:5953 [D loss: 0.731571, acc: 42.19%] [G loss: 1.607247]\n",
      "epoch:7 step:5954 [D loss: 0.545018, acc: 84.38%] [G loss: 1.876667]\n",
      "epoch:7 step:5955 [D loss: 0.658500, acc: 64.84%] [G loss: 1.404769]\n",
      "epoch:7 step:5956 [D loss: 0.642066, acc: 68.75%] [G loss: 1.667262]\n",
      "epoch:7 step:5957 [D loss: 0.746743, acc: 40.62%] [G loss: 1.478004]\n",
      "epoch:7 step:5958 [D loss: 0.691500, acc: 50.00%] [G loss: 1.460908]\n",
      "epoch:7 step:5959 [D loss: 0.734863, acc: 43.75%] [G loss: 1.581555]\n",
      "epoch:7 step:5960 [D loss: 0.775431, acc: 36.72%] [G loss: 1.538934]\n",
      "epoch:7 step:5961 [D loss: 0.594539, acc: 68.75%] [G loss: 1.513307]\n",
      "epoch:7 step:5962 [D loss: 0.571371, acc: 80.47%] [G loss: 1.583234]\n",
      "epoch:7 step:5963 [D loss: 0.751678, acc: 44.53%] [G loss: 1.587519]\n",
      "epoch:7 step:5964 [D loss: 0.743431, acc: 39.84%] [G loss: 1.579680]\n",
      "epoch:7 step:5965 [D loss: 0.746564, acc: 39.06%] [G loss: 1.463577]\n",
      "epoch:7 step:5966 [D loss: 0.895130, acc: 25.78%] [G loss: 1.370863]\n",
      "epoch:7 step:5967 [D loss: 0.707862, acc: 55.47%] [G loss: 1.477763]\n",
      "epoch:7 step:5968 [D loss: 0.617376, acc: 69.53%] [G loss: 1.688280]\n",
      "epoch:7 step:5969 [D loss: 0.670422, acc: 62.50%] [G loss: 1.508553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:5970 [D loss: 0.701571, acc: 50.00%] [G loss: 1.596106]\n",
      "epoch:7 step:5971 [D loss: 0.694075, acc: 53.12%] [G loss: 1.578386]\n",
      "epoch:7 step:5972 [D loss: 0.652235, acc: 60.16%] [G loss: 1.604186]\n",
      "epoch:7 step:5973 [D loss: 0.706322, acc: 56.25%] [G loss: 1.830591]\n",
      "epoch:7 step:5974 [D loss: 0.687537, acc: 53.91%] [G loss: 1.581463]\n",
      "epoch:7 step:5975 [D loss: 0.606313, acc: 71.09%] [G loss: 1.642443]\n",
      "epoch:7 step:5976 [D loss: 0.758265, acc: 43.75%] [G loss: 1.576726]\n",
      "epoch:7 step:5977 [D loss: 0.751213, acc: 38.28%] [G loss: 1.722163]\n",
      "epoch:7 step:5978 [D loss: 0.636111, acc: 67.19%] [G loss: 1.640057]\n",
      "epoch:7 step:5979 [D loss: 0.665213, acc: 60.16%] [G loss: 1.672630]\n",
      "epoch:7 step:5980 [D loss: 0.769320, acc: 42.97%] [G loss: 1.557866]\n",
      "epoch:7 step:5981 [D loss: 0.679660, acc: 57.03%] [G loss: 1.635426]\n",
      "epoch:7 step:5982 [D loss: 0.663869, acc: 57.03%] [G loss: 1.634750]\n",
      "epoch:7 step:5983 [D loss: 0.649813, acc: 64.06%] [G loss: 1.591600]\n",
      "epoch:7 step:5984 [D loss: 0.743091, acc: 45.31%] [G loss: 1.597513]\n",
      "epoch:7 step:5985 [D loss: 0.704022, acc: 49.22%] [G loss: 1.496627]\n",
      "epoch:7 step:5986 [D loss: 0.752558, acc: 40.62%] [G loss: 1.402189]\n",
      "epoch:7 step:5987 [D loss: 0.592601, acc: 72.66%] [G loss: 1.633144]\n",
      "epoch:7 step:5988 [D loss: 0.672804, acc: 58.59%] [G loss: 1.537557]\n",
      "epoch:7 step:5989 [D loss: 0.665742, acc: 58.59%] [G loss: 1.613829]\n",
      "epoch:7 step:5990 [D loss: 0.691828, acc: 54.69%] [G loss: 1.586852]\n",
      "epoch:7 step:5991 [D loss: 0.777862, acc: 41.41%] [G loss: 1.484066]\n",
      "epoch:7 step:5992 [D loss: 0.613240, acc: 71.09%] [G loss: 1.537549]\n",
      "epoch:7 step:5993 [D loss: 0.692953, acc: 52.34%] [G loss: 1.522497]\n",
      "epoch:7 step:5994 [D loss: 0.719748, acc: 46.09%] [G loss: 1.548038]\n",
      "epoch:7 step:5995 [D loss: 0.665476, acc: 57.81%] [G loss: 1.518831]\n",
      "epoch:7 step:5996 [D loss: 0.638999, acc: 65.62%] [G loss: 1.747046]\n",
      "epoch:7 step:5997 [D loss: 0.707398, acc: 58.59%] [G loss: 1.477140]\n",
      "epoch:7 step:5998 [D loss: 0.806730, acc: 32.03%] [G loss: 1.371297]\n",
      "epoch:7 step:5999 [D loss: 0.678013, acc: 60.94%] [G loss: 1.443028]\n",
      "epoch:7 step:6000 [D loss: 0.684251, acc: 54.69%] [G loss: 1.775723]\n",
      "epoch:7 step:6001 [D loss: 0.737041, acc: 47.66%] [G loss: 1.706530]\n",
      "epoch:7 step:6002 [D loss: 0.748167, acc: 43.75%] [G loss: 1.584841]\n",
      "epoch:7 step:6003 [D loss: 0.710311, acc: 47.66%] [G loss: 1.719005]\n",
      "epoch:7 step:6004 [D loss: 0.789448, acc: 36.72%] [G loss: 1.581222]\n",
      "epoch:7 step:6005 [D loss: 0.661642, acc: 64.84%] [G loss: 1.746604]\n",
      "epoch:7 step:6006 [D loss: 0.646498, acc: 62.50%] [G loss: 1.618948]\n",
      "epoch:7 step:6007 [D loss: 0.757729, acc: 39.84%] [G loss: 1.517101]\n",
      "epoch:7 step:6008 [D loss: 0.660851, acc: 61.72%] [G loss: 1.894416]\n",
      "epoch:7 step:6009 [D loss: 0.756572, acc: 43.75%] [G loss: 1.639048]\n",
      "epoch:7 step:6010 [D loss: 0.759354, acc: 39.84%] [G loss: 1.431796]\n",
      "epoch:7 step:6011 [D loss: 0.531345, acc: 80.47%] [G loss: 1.623144]\n",
      "epoch:7 step:6012 [D loss: 0.716212, acc: 46.09%] [G loss: 1.494038]\n",
      "epoch:7 step:6013 [D loss: 0.679933, acc: 60.16%] [G loss: 1.523601]\n",
      "epoch:7 step:6014 [D loss: 0.676346, acc: 56.25%] [G loss: 1.492362]\n",
      "epoch:7 step:6015 [D loss: 0.662325, acc: 63.28%] [G loss: 1.680393]\n",
      "epoch:7 step:6016 [D loss: 0.629984, acc: 67.19%] [G loss: 1.647233]\n",
      "epoch:7 step:6017 [D loss: 0.803564, acc: 39.06%] [G loss: 1.547462]\n",
      "epoch:7 step:6018 [D loss: 0.746931, acc: 41.41%] [G loss: 1.574513]\n",
      "epoch:7 step:6019 [D loss: 0.741156, acc: 44.53%] [G loss: 1.532781]\n",
      "epoch:7 step:6020 [D loss: 0.736043, acc: 40.62%] [G loss: 1.617062]\n",
      "epoch:7 step:6021 [D loss: 0.594865, acc: 72.66%] [G loss: 1.766110]\n",
      "epoch:7 step:6022 [D loss: 0.672248, acc: 60.16%] [G loss: 1.733155]\n",
      "epoch:7 step:6023 [D loss: 0.616203, acc: 68.75%] [G loss: 1.479723]\n",
      "epoch:7 step:6024 [D loss: 0.732560, acc: 46.09%] [G loss: 1.613035]\n",
      "epoch:7 step:6025 [D loss: 0.685207, acc: 57.03%] [G loss: 1.687330]\n",
      "epoch:7 step:6026 [D loss: 0.704131, acc: 56.25%] [G loss: 1.682039]\n",
      "epoch:7 step:6027 [D loss: 0.737689, acc: 43.75%] [G loss: 1.581673]\n",
      "epoch:7 step:6028 [D loss: 0.715942, acc: 50.78%] [G loss: 1.523445]\n",
      "epoch:7 step:6029 [D loss: 0.661245, acc: 55.47%] [G loss: 1.666936]\n",
      "epoch:7 step:6030 [D loss: 0.769931, acc: 43.75%] [G loss: 1.428141]\n",
      "epoch:7 step:6031 [D loss: 0.805085, acc: 33.59%] [G loss: 1.449993]\n",
      "epoch:7 step:6032 [D loss: 0.713592, acc: 53.91%] [G loss: 1.529092]\n",
      "epoch:7 step:6033 [D loss: 0.572272, acc: 76.56%] [G loss: 1.751673]\n",
      "epoch:7 step:6034 [D loss: 0.624281, acc: 66.41%] [G loss: 1.742841]\n",
      "epoch:7 step:6035 [D loss: 0.674951, acc: 59.38%] [G loss: 1.608646]\n",
      "epoch:7 step:6036 [D loss: 0.837557, acc: 28.12%] [G loss: 1.447801]\n",
      "epoch:7 step:6037 [D loss: 0.657928, acc: 64.06%] [G loss: 1.585509]\n",
      "epoch:7 step:6038 [D loss: 0.743330, acc: 48.44%] [G loss: 1.552245]\n",
      "epoch:7 step:6039 [D loss: 0.712840, acc: 52.34%] [G loss: 1.494214]\n",
      "epoch:7 step:6040 [D loss: 0.636802, acc: 66.41%] [G loss: 1.544979]\n",
      "epoch:7 step:6041 [D loss: 0.654272, acc: 53.12%] [G loss: 1.414768]\n",
      "epoch:7 step:6042 [D loss: 0.726223, acc: 43.75%] [G loss: 1.527500]\n",
      "epoch:7 step:6043 [D loss: 0.610709, acc: 71.09%] [G loss: 1.524775]\n",
      "epoch:7 step:6044 [D loss: 0.504055, acc: 79.69%] [G loss: 1.764650]\n",
      "epoch:7 step:6045 [D loss: 0.708440, acc: 54.69%] [G loss: 1.591514]\n",
      "epoch:7 step:6046 [D loss: 0.789018, acc: 36.72%] [G loss: 1.608234]\n",
      "epoch:7 step:6047 [D loss: 0.725190, acc: 47.66%] [G loss: 1.679834]\n",
      "epoch:7 step:6048 [D loss: 0.554514, acc: 82.03%] [G loss: 1.582283]\n",
      "epoch:7 step:6049 [D loss: 0.577537, acc: 78.12%] [G loss: 1.420425]\n",
      "epoch:7 step:6050 [D loss: 0.606034, acc: 68.75%] [G loss: 1.674796]\n",
      "epoch:7 step:6051 [D loss: 0.821234, acc: 43.75%] [G loss: 1.427471]\n",
      "epoch:7 step:6052 [D loss: 0.746454, acc: 44.53%] [G loss: 1.534218]\n",
      "epoch:7 step:6053 [D loss: 0.724005, acc: 50.78%] [G loss: 1.623589]\n",
      "epoch:7 step:6054 [D loss: 0.807081, acc: 38.28%] [G loss: 1.531665]\n",
      "epoch:7 step:6055 [D loss: 0.726268, acc: 48.44%] [G loss: 1.475577]\n",
      "epoch:7 step:6056 [D loss: 0.847316, acc: 29.69%] [G loss: 1.578875]\n",
      "epoch:7 step:6057 [D loss: 0.682408, acc: 57.03%] [G loss: 1.764335]\n",
      "epoch:7 step:6058 [D loss: 0.700011, acc: 57.81%] [G loss: 1.614327]\n",
      "epoch:7 step:6059 [D loss: 0.651717, acc: 62.50%] [G loss: 1.644240]\n",
      "epoch:7 step:6060 [D loss: 0.717557, acc: 45.31%] [G loss: 1.565293]\n",
      "epoch:7 step:6061 [D loss: 0.697188, acc: 54.69%] [G loss: 1.489591]\n",
      "epoch:7 step:6062 [D loss: 0.658440, acc: 64.06%] [G loss: 1.661188]\n",
      "epoch:7 step:6063 [D loss: 0.485317, acc: 67.97%] [G loss: 1.533154]\n",
      "epoch:7 step:6064 [D loss: 0.723139, acc: 50.00%] [G loss: 1.659751]\n",
      "epoch:7 step:6065 [D loss: 0.568150, acc: 79.69%] [G loss: 1.734295]\n",
      "epoch:7 step:6066 [D loss: 0.770105, acc: 41.41%] [G loss: 1.442846]\n",
      "epoch:7 step:6067 [D loss: 0.452971, acc: 89.06%] [G loss: 1.796804]\n",
      "epoch:7 step:6068 [D loss: 0.609491, acc: 71.88%] [G loss: 1.648364]\n",
      "epoch:7 step:6069 [D loss: 0.663009, acc: 60.16%] [G loss: 1.513952]\n",
      "epoch:7 step:6070 [D loss: 0.725339, acc: 44.53%] [G loss: 1.465238]\n",
      "epoch:7 step:6071 [D loss: 0.785873, acc: 47.66%] [G loss: 1.456164]\n",
      "epoch:7 step:6072 [D loss: 0.781391, acc: 32.81%] [G loss: 1.507685]\n",
      "epoch:7 step:6073 [D loss: 0.772201, acc: 39.84%] [G loss: 1.634614]\n",
      "epoch:7 step:6074 [D loss: 0.758742, acc: 39.84%] [G loss: 1.489144]\n",
      "epoch:7 step:6075 [D loss: 0.664550, acc: 65.62%] [G loss: 1.517147]\n",
      "epoch:7 step:6076 [D loss: 0.676041, acc: 58.59%] [G loss: 1.666824]\n",
      "epoch:7 step:6077 [D loss: 0.763964, acc: 39.06%] [G loss: 1.666338]\n",
      "epoch:7 step:6078 [D loss: 0.667188, acc: 64.06%] [G loss: 1.557348]\n",
      "epoch:7 step:6079 [D loss: 0.744577, acc: 39.06%] [G loss: 1.590309]\n",
      "epoch:7 step:6080 [D loss: 0.802951, acc: 33.59%] [G loss: 1.429315]\n",
      "epoch:7 step:6081 [D loss: 0.712185, acc: 49.22%] [G loss: 1.487698]\n",
      "epoch:7 step:6082 [D loss: 0.632135, acc: 71.88%] [G loss: 1.552675]\n",
      "epoch:7 step:6083 [D loss: 0.764505, acc: 39.06%] [G loss: 1.378924]\n",
      "epoch:7 step:6084 [D loss: 0.634898, acc: 63.28%] [G loss: 1.551034]\n",
      "epoch:7 step:6085 [D loss: 0.659087, acc: 60.16%] [G loss: 1.544501]\n",
      "epoch:7 step:6086 [D loss: 0.793175, acc: 32.81%] [G loss: 1.484973]\n",
      "epoch:7 step:6087 [D loss: 0.659011, acc: 60.16%] [G loss: 1.759950]\n",
      "epoch:7 step:6088 [D loss: 0.662920, acc: 60.94%] [G loss: 1.557796]\n",
      "epoch:7 step:6089 [D loss: 0.638237, acc: 64.06%] [G loss: 1.748519]\n",
      "epoch:7 step:6090 [D loss: 0.736159, acc: 45.31%] [G loss: 1.914852]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6091 [D loss: 0.617051, acc: 71.88%] [G loss: 1.549064]\n",
      "epoch:7 step:6092 [D loss: 0.659469, acc: 57.81%] [G loss: 1.739578]\n",
      "epoch:7 step:6093 [D loss: 0.780626, acc: 34.38%] [G loss: 1.483014]\n",
      "epoch:7 step:6094 [D loss: 0.821536, acc: 24.22%] [G loss: 1.499201]\n",
      "epoch:7 step:6095 [D loss: 0.676647, acc: 60.94%] [G loss: 1.535824]\n",
      "epoch:7 step:6096 [D loss: 0.689201, acc: 51.56%] [G loss: 1.508529]\n",
      "epoch:7 step:6097 [D loss: 0.594603, acc: 71.88%] [G loss: 1.605253]\n",
      "epoch:7 step:6098 [D loss: 0.687407, acc: 57.03%] [G loss: 1.615456]\n",
      "epoch:7 step:6099 [D loss: 0.851486, acc: 33.59%] [G loss: 1.318706]\n",
      "epoch:7 step:6100 [D loss: 0.631249, acc: 71.88%] [G loss: 1.680547]\n",
      "epoch:7 step:6101 [D loss: 0.746984, acc: 48.44%] [G loss: 1.598140]\n",
      "epoch:7 step:6102 [D loss: 0.542063, acc: 77.34%] [G loss: 1.580001]\n",
      "epoch:7 step:6103 [D loss: 0.733649, acc: 46.88%] [G loss: 1.467883]\n",
      "epoch:7 step:6104 [D loss: 0.691263, acc: 55.47%] [G loss: 1.584691]\n",
      "epoch:7 step:6105 [D loss: 0.886922, acc: 14.06%] [G loss: 1.235013]\n",
      "epoch:7 step:6106 [D loss: 0.797078, acc: 34.38%] [G loss: 1.434672]\n",
      "epoch:7 step:6107 [D loss: 0.745269, acc: 42.19%] [G loss: 1.436217]\n",
      "epoch:7 step:6108 [D loss: 0.723103, acc: 45.31%] [G loss: 1.538874]\n",
      "epoch:7 step:6109 [D loss: 0.718779, acc: 49.22%] [G loss: 1.624174]\n",
      "epoch:7 step:6110 [D loss: 0.595379, acc: 71.88%] [G loss: 1.508334]\n",
      "epoch:7 step:6111 [D loss: 0.662483, acc: 64.84%] [G loss: 1.521624]\n",
      "epoch:7 step:6112 [D loss: 0.799920, acc: 31.25%] [G loss: 1.521370]\n",
      "epoch:7 step:6113 [D loss: 0.806190, acc: 35.16%] [G loss: 1.322384]\n",
      "epoch:7 step:6114 [D loss: 0.644557, acc: 66.41%] [G loss: 1.571550]\n",
      "epoch:7 step:6115 [D loss: 0.715102, acc: 51.56%] [G loss: 1.473450]\n",
      "epoch:7 step:6116 [D loss: 0.931519, acc: 29.69%] [G loss: 1.577949]\n",
      "epoch:7 step:6117 [D loss: 0.678379, acc: 53.12%] [G loss: 1.634088]\n",
      "epoch:7 step:6118 [D loss: 0.688870, acc: 57.81%] [G loss: 1.571254]\n",
      "epoch:7 step:6119 [D loss: 0.717066, acc: 51.56%] [G loss: 1.518911]\n",
      "epoch:7 step:6120 [D loss: 0.607080, acc: 71.88%] [G loss: 1.618380]\n",
      "epoch:7 step:6121 [D loss: 0.633740, acc: 62.50%] [G loss: 1.644058]\n",
      "epoch:7 step:6122 [D loss: 0.558063, acc: 77.34%] [G loss: 1.669366]\n",
      "epoch:7 step:6123 [D loss: 0.730584, acc: 47.66%] [G loss: 1.464816]\n",
      "epoch:7 step:6124 [D loss: 0.680002, acc: 56.25%] [G loss: 1.667627]\n",
      "epoch:7 step:6125 [D loss: 0.664769, acc: 63.28%] [G loss: 1.750189]\n",
      "epoch:7 step:6126 [D loss: 0.478084, acc: 82.81%] [G loss: 1.726341]\n",
      "epoch:7 step:6127 [D loss: 0.742447, acc: 43.75%] [G loss: 1.585503]\n",
      "epoch:7 step:6128 [D loss: 0.648219, acc: 67.97%] [G loss: 1.436273]\n",
      "epoch:7 step:6129 [D loss: 0.825893, acc: 25.00%] [G loss: 1.559673]\n",
      "epoch:7 step:6130 [D loss: 0.646965, acc: 61.72%] [G loss: 1.576980]\n",
      "epoch:7 step:6131 [D loss: 0.596573, acc: 70.31%] [G loss: 1.669289]\n",
      "epoch:7 step:6132 [D loss: 0.824765, acc: 32.03%] [G loss: 1.838043]\n",
      "epoch:7 step:6133 [D loss: 0.648863, acc: 64.84%] [G loss: 1.678905]\n",
      "epoch:7 step:6134 [D loss: 0.559316, acc: 76.56%] [G loss: 1.491339]\n",
      "epoch:7 step:6135 [D loss: 0.664271, acc: 65.62%] [G loss: 1.491811]\n",
      "epoch:7 step:6136 [D loss: 0.698568, acc: 58.59%] [G loss: 1.422660]\n",
      "epoch:7 step:6137 [D loss: 0.819888, acc: 38.28%] [G loss: 1.661185]\n",
      "epoch:7 step:6138 [D loss: 0.646361, acc: 64.06%] [G loss: 1.652834]\n",
      "epoch:7 step:6139 [D loss: 0.751944, acc: 42.97%] [G loss: 1.470181]\n",
      "epoch:7 step:6140 [D loss: 0.743223, acc: 42.97%] [G loss: 1.431819]\n",
      "epoch:7 step:6141 [D loss: 0.492871, acc: 86.72%] [G loss: 1.717170]\n",
      "epoch:7 step:6142 [D loss: 0.663078, acc: 62.50%] [G loss: 1.719519]\n",
      "epoch:7 step:6143 [D loss: 0.751568, acc: 45.31%] [G loss: 1.547995]\n",
      "epoch:7 step:6144 [D loss: 0.657288, acc: 56.25%] [G loss: 1.699583]\n",
      "epoch:7 step:6145 [D loss: 0.555110, acc: 79.69%] [G loss: 1.799806]\n",
      "epoch:7 step:6146 [D loss: 0.683175, acc: 57.81%] [G loss: 1.693850]\n",
      "epoch:7 step:6147 [D loss: 0.487385, acc: 85.16%] [G loss: 1.884224]\n",
      "epoch:7 step:6148 [D loss: 0.671525, acc: 62.50%] [G loss: 1.537691]\n",
      "epoch:7 step:6149 [D loss: 0.639602, acc: 67.19%] [G loss: 1.607009]\n",
      "epoch:7 step:6150 [D loss: 0.720514, acc: 51.56%] [G loss: 1.466324]\n",
      "epoch:7 step:6151 [D loss: 0.803769, acc: 31.25%] [G loss: 1.549972]\n",
      "epoch:7 step:6152 [D loss: 0.697314, acc: 53.12%] [G loss: 1.714309]\n",
      "epoch:7 step:6153 [D loss: 0.696358, acc: 58.59%] [G loss: 1.567264]\n",
      "epoch:7 step:6154 [D loss: 0.629315, acc: 63.28%] [G loss: 1.582435]\n",
      "epoch:7 step:6155 [D loss: 0.712661, acc: 53.12%] [G loss: 1.495164]\n",
      "epoch:7 step:6156 [D loss: 0.682618, acc: 57.81%] [G loss: 1.729631]\n",
      "epoch:7 step:6157 [D loss: 0.712393, acc: 46.09%] [G loss: 1.598724]\n",
      "epoch:7 step:6158 [D loss: 0.750328, acc: 46.88%] [G loss: 1.658801]\n",
      "epoch:7 step:6159 [D loss: 0.666559, acc: 57.03%] [G loss: 1.619564]\n",
      "epoch:7 step:6160 [D loss: 0.673519, acc: 53.91%] [G loss: 1.573411]\n",
      "epoch:7 step:6161 [D loss: 0.731854, acc: 50.00%] [G loss: 1.671522]\n",
      "epoch:7 step:6162 [D loss: 0.689976, acc: 54.69%] [G loss: 1.777606]\n",
      "epoch:7 step:6163 [D loss: 0.634664, acc: 62.50%] [G loss: 1.735931]\n",
      "epoch:7 step:6164 [D loss: 0.759151, acc: 42.19%] [G loss: 1.490228]\n",
      "epoch:7 step:6165 [D loss: 0.683094, acc: 60.16%] [G loss: 1.622246]\n",
      "epoch:7 step:6166 [D loss: 0.758131, acc: 37.50%] [G loss: 1.684874]\n",
      "epoch:7 step:6167 [D loss: 0.667731, acc: 60.94%] [G loss: 1.693184]\n",
      "epoch:7 step:6168 [D loss: 0.666051, acc: 57.81%] [G loss: 1.862376]\n",
      "epoch:7 step:6169 [D loss: 0.695220, acc: 60.16%] [G loss: 1.605733]\n",
      "epoch:7 step:6170 [D loss: 0.665387, acc: 60.16%] [G loss: 1.756780]\n",
      "epoch:7 step:6171 [D loss: 0.703970, acc: 51.56%] [G loss: 1.660600]\n",
      "epoch:7 step:6172 [D loss: 0.620389, acc: 71.88%] [G loss: 1.807530]\n",
      "epoch:7 step:6173 [D loss: 0.613622, acc: 68.75%] [G loss: 1.743275]\n",
      "epoch:7 step:6174 [D loss: 0.671983, acc: 57.03%] [G loss: 1.613731]\n",
      "epoch:7 step:6175 [D loss: 0.728255, acc: 50.78%] [G loss: 1.639506]\n",
      "epoch:7 step:6176 [D loss: 0.662416, acc: 57.81%] [G loss: 1.605483]\n",
      "epoch:7 step:6177 [D loss: 0.690307, acc: 54.69%] [G loss: 1.657092]\n",
      "epoch:7 step:6178 [D loss: 0.781335, acc: 39.84%] [G loss: 1.438454]\n",
      "epoch:7 step:6179 [D loss: 0.524121, acc: 85.16%] [G loss: 1.847357]\n",
      "epoch:7 step:6180 [D loss: 0.724463, acc: 52.34%] [G loss: 1.670988]\n",
      "epoch:7 step:6181 [D loss: 0.581749, acc: 77.34%] [G loss: 1.605543]\n",
      "epoch:7 step:6182 [D loss: 1.067926, acc: 12.50%] [G loss: 1.550495]\n",
      "epoch:7 step:6183 [D loss: 0.621250, acc: 71.88%] [G loss: 1.826789]\n",
      "epoch:7 step:6184 [D loss: 0.676082, acc: 58.59%] [G loss: 1.716130]\n",
      "epoch:7 step:6185 [D loss: 0.716587, acc: 50.78%] [G loss: 1.649554]\n",
      "epoch:7 step:6186 [D loss: 0.627557, acc: 66.41%] [G loss: 1.812778]\n",
      "epoch:7 step:6187 [D loss: 0.775157, acc: 40.62%] [G loss: 1.629997]\n",
      "epoch:7 step:6188 [D loss: 0.709243, acc: 50.78%] [G loss: 1.488375]\n",
      "epoch:7 step:6189 [D loss: 0.724043, acc: 48.44%] [G loss: 1.736977]\n",
      "epoch:7 step:6190 [D loss: 0.767367, acc: 42.97%] [G loss: 1.558088]\n",
      "epoch:7 step:6191 [D loss: 0.677622, acc: 60.94%] [G loss: 1.620664]\n",
      "epoch:7 step:6192 [D loss: 0.666110, acc: 58.59%] [G loss: 1.557967]\n",
      "epoch:7 step:6193 [D loss: 0.850159, acc: 25.00%] [G loss: 1.462516]\n",
      "epoch:7 step:6194 [D loss: 0.683056, acc: 54.69%] [G loss: 1.655248]\n",
      "epoch:7 step:6195 [D loss: 0.747275, acc: 46.09%] [G loss: 1.589591]\n",
      "epoch:7 step:6196 [D loss: 0.806832, acc: 39.06%] [G loss: 1.569447]\n",
      "epoch:7 step:6197 [D loss: 0.662554, acc: 60.94%] [G loss: 1.683518]\n",
      "epoch:7 step:6198 [D loss: 0.727426, acc: 46.09%] [G loss: 1.593269]\n",
      "epoch:7 step:6199 [D loss: 0.725299, acc: 51.56%] [G loss: 1.649031]\n",
      "epoch:7 step:6200 [D loss: 0.620960, acc: 67.97%] [G loss: 1.753008]\n",
      "epoch:7 step:6201 [D loss: 0.656260, acc: 58.59%] [G loss: 1.689104]\n",
      "epoch:7 step:6202 [D loss: 0.711673, acc: 53.91%] [G loss: 1.550440]\n",
      "epoch:7 step:6203 [D loss: 0.703170, acc: 53.12%] [G loss: 1.798180]\n",
      "epoch:7 step:6204 [D loss: 0.700078, acc: 51.56%] [G loss: 1.537351]\n",
      "epoch:7 step:6205 [D loss: 0.813243, acc: 33.59%] [G loss: 1.508253]\n",
      "epoch:7 step:6206 [D loss: 0.639360, acc: 66.41%] [G loss: 1.642633]\n",
      "epoch:7 step:6207 [D loss: 0.501312, acc: 87.50%] [G loss: 1.667181]\n",
      "epoch:7 step:6208 [D loss: 0.575232, acc: 78.91%] [G loss: 1.750050]\n",
      "epoch:7 step:6209 [D loss: 0.765509, acc: 38.28%] [G loss: 1.779851]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6210 [D loss: 0.740911, acc: 47.66%] [G loss: 1.867117]\n",
      "epoch:7 step:6211 [D loss: 0.637283, acc: 63.28%] [G loss: 1.583854]\n",
      "epoch:7 step:6212 [D loss: 0.620053, acc: 67.19%] [G loss: 1.499312]\n",
      "epoch:7 step:6213 [D loss: 0.693187, acc: 55.47%] [G loss: 1.527953]\n",
      "epoch:7 step:6214 [D loss: 0.672309, acc: 54.69%] [G loss: 1.657850]\n",
      "epoch:7 step:6215 [D loss: 0.738107, acc: 43.75%] [G loss: 1.524617]\n",
      "epoch:7 step:6216 [D loss: 0.693204, acc: 60.16%] [G loss: 1.417507]\n",
      "epoch:7 step:6217 [D loss: 0.662465, acc: 60.16%] [G loss: 1.508494]\n",
      "epoch:7 step:6218 [D loss: 0.740604, acc: 52.34%] [G loss: 1.433947]\n",
      "epoch:7 step:6219 [D loss: 0.799538, acc: 31.25%] [G loss: 1.461153]\n",
      "epoch:7 step:6220 [D loss: 0.702079, acc: 46.09%] [G loss: 1.796834]\n",
      "epoch:7 step:6221 [D loss: 0.689743, acc: 57.81%] [G loss: 1.838197]\n",
      "epoch:7 step:6222 [D loss: 0.872042, acc: 30.47%] [G loss: 1.524319]\n",
      "epoch:7 step:6223 [D loss: 0.722781, acc: 46.88%] [G loss: 1.537127]\n",
      "epoch:7 step:6224 [D loss: 0.615821, acc: 70.31%] [G loss: 1.674580]\n",
      "epoch:7 step:6225 [D loss: 0.491432, acc: 73.44%] [G loss: 1.812098]\n",
      "epoch:7 step:6226 [D loss: 0.757368, acc: 45.31%] [G loss: 1.613263]\n",
      "epoch:7 step:6227 [D loss: 0.541742, acc: 74.22%] [G loss: 1.548834]\n",
      "epoch:7 step:6228 [D loss: 0.578866, acc: 78.12%] [G loss: 1.765020]\n",
      "epoch:7 step:6229 [D loss: 0.699325, acc: 57.81%] [G loss: 1.586192]\n",
      "epoch:7 step:6230 [D loss: 0.585528, acc: 71.09%] [G loss: 1.798557]\n",
      "epoch:7 step:6231 [D loss: 0.585460, acc: 67.19%] [G loss: 1.426716]\n",
      "epoch:7 step:6232 [D loss: 0.706667, acc: 53.91%] [G loss: 1.672313]\n",
      "epoch:7 step:6233 [D loss: 0.615891, acc: 67.19%] [G loss: 1.518478]\n",
      "epoch:7 step:6234 [D loss: 0.682774, acc: 60.94%] [G loss: 1.590454]\n",
      "epoch:7 step:6235 [D loss: 0.574054, acc: 78.12%] [G loss: 1.714951]\n",
      "epoch:7 step:6236 [D loss: 0.896974, acc: 27.34%] [G loss: 1.482185]\n",
      "epoch:7 step:6237 [D loss: 0.712636, acc: 50.78%] [G loss: 1.658627]\n",
      "epoch:7 step:6238 [D loss: 0.574773, acc: 73.44%] [G loss: 1.955102]\n",
      "epoch:7 step:6239 [D loss: 0.536225, acc: 84.38%] [G loss: 1.536450]\n",
      "epoch:7 step:6240 [D loss: 0.725989, acc: 50.00%] [G loss: 1.461654]\n",
      "epoch:7 step:6241 [D loss: 0.856506, acc: 27.34%] [G loss: 1.442954]\n",
      "epoch:7 step:6242 [D loss: 0.827819, acc: 28.91%] [G loss: 1.438937]\n",
      "epoch:7 step:6243 [D loss: 0.692232, acc: 58.59%] [G loss: 1.727992]\n",
      "epoch:7 step:6244 [D loss: 0.682115, acc: 57.03%] [G loss: 1.526268]\n",
      "epoch:7 step:6245 [D loss: 0.664990, acc: 63.28%] [G loss: 1.686728]\n",
      "epoch:7 step:6246 [D loss: 0.872293, acc: 34.38%] [G loss: 1.519098]\n",
      "epoch:7 step:6247 [D loss: 0.920449, acc: 24.22%] [G loss: 1.306662]\n",
      "epoch:7 step:6248 [D loss: 0.622149, acc: 65.62%] [G loss: 1.778857]\n",
      "epoch:8 step:6249 [D loss: 0.725237, acc: 49.22%] [G loss: 1.536945]\n",
      "epoch:8 step:6250 [D loss: 0.685734, acc: 56.25%] [G loss: 1.846589]\n",
      "epoch:8 step:6251 [D loss: 0.725173, acc: 49.22%] [G loss: 1.753809]\n",
      "epoch:8 step:6252 [D loss: 0.582276, acc: 64.84%] [G loss: 1.811365]\n",
      "epoch:8 step:6253 [D loss: 0.628792, acc: 66.41%] [G loss: 1.547713]\n",
      "epoch:8 step:6254 [D loss: 0.699063, acc: 50.00%] [G loss: 1.686054]\n",
      "epoch:8 step:6255 [D loss: 0.697553, acc: 50.78%] [G loss: 1.635493]\n",
      "epoch:8 step:6256 [D loss: 0.650008, acc: 63.28%] [G loss: 1.537710]\n",
      "epoch:8 step:6257 [D loss: 0.798220, acc: 30.47%] [G loss: 1.522144]\n",
      "epoch:8 step:6258 [D loss: 0.656806, acc: 64.06%] [G loss: 1.612095]\n",
      "epoch:8 step:6259 [D loss: 0.552780, acc: 78.91%] [G loss: 1.997723]\n",
      "epoch:8 step:6260 [D loss: 0.792957, acc: 37.50%] [G loss: 1.580332]\n",
      "epoch:8 step:6261 [D loss: 0.713574, acc: 53.12%] [G loss: 1.558804]\n",
      "epoch:8 step:6262 [D loss: 0.675189, acc: 60.16%] [G loss: 1.839042]\n",
      "epoch:8 step:6263 [D loss: 0.872488, acc: 19.53%] [G loss: 1.422457]\n",
      "epoch:8 step:6264 [D loss: 0.742943, acc: 46.88%] [G loss: 1.681567]\n",
      "epoch:8 step:6265 [D loss: 0.615486, acc: 64.06%] [G loss: 1.712891]\n",
      "epoch:8 step:6266 [D loss: 0.655966, acc: 60.94%] [G loss: 1.714163]\n",
      "epoch:8 step:6267 [D loss: 0.495799, acc: 85.16%] [G loss: 1.701271]\n",
      "epoch:8 step:6268 [D loss: 0.394614, acc: 85.16%] [G loss: 2.159572]\n",
      "epoch:8 step:6269 [D loss: 0.779975, acc: 44.53%] [G loss: 1.545981]\n",
      "epoch:8 step:6270 [D loss: 0.671372, acc: 58.59%] [G loss: 1.515348]\n",
      "epoch:8 step:6271 [D loss: 0.764642, acc: 39.06%] [G loss: 1.503492]\n",
      "epoch:8 step:6272 [D loss: 0.758462, acc: 42.19%] [G loss: 1.675099]\n",
      "epoch:8 step:6273 [D loss: 0.760991, acc: 35.94%] [G loss: 1.614921]\n",
      "epoch:8 step:6274 [D loss: 0.643370, acc: 64.06%] [G loss: 1.497514]\n",
      "epoch:8 step:6275 [D loss: 0.497482, acc: 81.25%] [G loss: 1.882706]\n",
      "epoch:8 step:6276 [D loss: 0.738788, acc: 43.75%] [G loss: 1.426851]\n",
      "epoch:8 step:6277 [D loss: 0.753288, acc: 41.41%] [G loss: 1.471139]\n",
      "epoch:8 step:6278 [D loss: 0.680336, acc: 58.59%] [G loss: 1.446020]\n",
      "epoch:8 step:6279 [D loss: 0.769906, acc: 39.84%] [G loss: 1.525010]\n",
      "epoch:8 step:6280 [D loss: 0.616656, acc: 66.41%] [G loss: 1.552393]\n",
      "epoch:8 step:6281 [D loss: 0.643129, acc: 64.06%] [G loss: 1.530824]\n",
      "epoch:8 step:6282 [D loss: 0.660318, acc: 58.59%] [G loss: 1.603864]\n",
      "epoch:8 step:6283 [D loss: 0.820164, acc: 42.19%] [G loss: 1.597324]\n",
      "epoch:8 step:6284 [D loss: 0.660140, acc: 60.94%] [G loss: 1.670826]\n",
      "epoch:8 step:6285 [D loss: 0.576177, acc: 79.69%] [G loss: 1.531560]\n",
      "epoch:8 step:6286 [D loss: 0.588486, acc: 76.56%] [G loss: 1.725594]\n",
      "epoch:8 step:6287 [D loss: 0.711069, acc: 50.00%] [G loss: 1.631165]\n",
      "epoch:8 step:6288 [D loss: 0.656847, acc: 60.16%] [G loss: 1.949034]\n",
      "epoch:8 step:6289 [D loss: 0.692192, acc: 52.34%] [G loss: 1.510300]\n",
      "epoch:8 step:6290 [D loss: 0.614488, acc: 71.88%] [G loss: 1.543033]\n",
      "epoch:8 step:6291 [D loss: 0.685449, acc: 57.81%] [G loss: 1.685714]\n",
      "epoch:8 step:6292 [D loss: 0.834703, acc: 32.81%] [G loss: 1.695020]\n",
      "epoch:8 step:6293 [D loss: 0.717211, acc: 52.34%] [G loss: 1.660395]\n",
      "epoch:8 step:6294 [D loss: 0.664989, acc: 59.38%] [G loss: 1.682287]\n",
      "epoch:8 step:6295 [D loss: 0.708918, acc: 51.56%] [G loss: 1.731846]\n",
      "epoch:8 step:6296 [D loss: 0.672618, acc: 55.47%] [G loss: 1.795250]\n",
      "epoch:8 step:6297 [D loss: 0.516053, acc: 70.31%] [G loss: 1.648851]\n",
      "epoch:8 step:6298 [D loss: 0.697831, acc: 46.88%] [G loss: 1.599473]\n",
      "epoch:8 step:6299 [D loss: 0.586146, acc: 71.09%] [G loss: 1.840649]\n",
      "epoch:8 step:6300 [D loss: 0.675762, acc: 54.69%] [G loss: 1.670240]\n",
      "epoch:8 step:6301 [D loss: 0.633021, acc: 64.84%] [G loss: 1.579631]\n",
      "epoch:8 step:6302 [D loss: 0.734145, acc: 47.66%] [G loss: 1.579386]\n",
      "epoch:8 step:6303 [D loss: 0.697790, acc: 53.91%] [G loss: 1.937811]\n",
      "epoch:8 step:6304 [D loss: 0.707219, acc: 53.12%] [G loss: 1.621899]\n",
      "epoch:8 step:6305 [D loss: 0.714511, acc: 53.12%] [G loss: 1.602521]\n",
      "epoch:8 step:6306 [D loss: 0.506571, acc: 85.94%] [G loss: 1.746768]\n",
      "epoch:8 step:6307 [D loss: 0.752866, acc: 42.19%] [G loss: 1.918827]\n",
      "epoch:8 step:6308 [D loss: 0.598875, acc: 67.97%] [G loss: 1.648250]\n",
      "epoch:8 step:6309 [D loss: 0.727996, acc: 51.56%] [G loss: 1.465131]\n",
      "epoch:8 step:6310 [D loss: 0.677456, acc: 54.69%] [G loss: 1.431611]\n",
      "epoch:8 step:6311 [D loss: 0.625772, acc: 67.19%] [G loss: 1.412979]\n",
      "epoch:8 step:6312 [D loss: 0.704700, acc: 57.81%] [G loss: 1.569562]\n",
      "epoch:8 step:6313 [D loss: 0.604359, acc: 72.66%] [G loss: 1.503042]\n",
      "epoch:8 step:6314 [D loss: 0.551683, acc: 81.25%] [G loss: 1.624507]\n",
      "epoch:8 step:6315 [D loss: 0.870985, acc: 28.91%] [G loss: 1.389857]\n",
      "epoch:8 step:6316 [D loss: 0.813879, acc: 37.50%] [G loss: 1.530110]\n",
      "epoch:8 step:6317 [D loss: 0.852338, acc: 33.59%] [G loss: 1.455554]\n",
      "epoch:8 step:6318 [D loss: 0.936855, acc: 17.97%] [G loss: 1.499080]\n",
      "epoch:8 step:6319 [D loss: 0.677237, acc: 55.47%] [G loss: 1.444038]\n",
      "epoch:8 step:6320 [D loss: 0.750292, acc: 40.62%] [G loss: 1.459176]\n",
      "epoch:8 step:6321 [D loss: 0.512851, acc: 85.16%] [G loss: 1.727724]\n",
      "epoch:8 step:6322 [D loss: 0.725926, acc: 49.22%] [G loss: 1.544650]\n",
      "epoch:8 step:6323 [D loss: 0.677792, acc: 60.94%] [G loss: 1.829469]\n",
      "epoch:8 step:6324 [D loss: 0.708364, acc: 50.00%] [G loss: 1.578740]\n",
      "epoch:8 step:6325 [D loss: 0.612128, acc: 69.53%] [G loss: 1.788948]\n",
      "epoch:8 step:6326 [D loss: 0.602347, acc: 67.19%] [G loss: 1.698365]\n",
      "epoch:8 step:6327 [D loss: 0.717938, acc: 55.47%] [G loss: 1.672045]\n",
      "epoch:8 step:6328 [D loss: 0.701386, acc: 54.69%] [G loss: 1.557148]\n",
      "epoch:8 step:6329 [D loss: 0.771124, acc: 39.06%] [G loss: 1.530500]\n",
      "epoch:8 step:6330 [D loss: 0.669054, acc: 58.59%] [G loss: 1.704116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6331 [D loss: 0.591797, acc: 73.44%] [G loss: 1.805974]\n",
      "epoch:8 step:6332 [D loss: 0.624011, acc: 57.81%] [G loss: 1.511666]\n",
      "epoch:8 step:6333 [D loss: 0.801384, acc: 32.03%] [G loss: 1.619128]\n",
      "epoch:8 step:6334 [D loss: 0.748753, acc: 48.44%] [G loss: 1.697412]\n",
      "epoch:8 step:6335 [D loss: 0.535319, acc: 78.12%] [G loss: 1.754650]\n",
      "epoch:8 step:6336 [D loss: 0.855201, acc: 25.00%] [G loss: 1.520574]\n",
      "epoch:8 step:6337 [D loss: 0.698970, acc: 53.91%] [G loss: 1.613690]\n",
      "epoch:8 step:6338 [D loss: 0.766932, acc: 39.06%] [G loss: 1.579948]\n",
      "epoch:8 step:6339 [D loss: 0.692802, acc: 58.59%] [G loss: 1.577300]\n",
      "epoch:8 step:6340 [D loss: 0.741350, acc: 47.66%] [G loss: 1.439566]\n",
      "epoch:8 step:6341 [D loss: 0.724984, acc: 44.53%] [G loss: 1.480267]\n",
      "epoch:8 step:6342 [D loss: 0.732429, acc: 45.31%] [G loss: 1.411274]\n",
      "epoch:8 step:6343 [D loss: 0.567296, acc: 78.12%] [G loss: 1.742681]\n",
      "epoch:8 step:6344 [D loss: 0.644717, acc: 66.41%] [G loss: 1.676902]\n",
      "epoch:8 step:6345 [D loss: 0.656238, acc: 64.06%] [G loss: 1.595205]\n",
      "epoch:8 step:6346 [D loss: 0.709506, acc: 47.66%] [G loss: 1.677689]\n",
      "epoch:8 step:6347 [D loss: 0.737570, acc: 42.97%] [G loss: 1.537813]\n",
      "epoch:8 step:6348 [D loss: 0.774258, acc: 39.84%] [G loss: 1.564433]\n",
      "epoch:8 step:6349 [D loss: 0.628301, acc: 64.06%] [G loss: 1.564755]\n",
      "epoch:8 step:6350 [D loss: 0.728181, acc: 46.88%] [G loss: 1.652038]\n",
      "epoch:8 step:6351 [D loss: 0.836391, acc: 27.34%] [G loss: 1.424511]\n",
      "epoch:8 step:6352 [D loss: 0.691082, acc: 55.47%] [G loss: 1.467378]\n",
      "epoch:8 step:6353 [D loss: 0.704355, acc: 49.22%] [G loss: 1.540095]\n",
      "epoch:8 step:6354 [D loss: 0.664720, acc: 60.16%] [G loss: 1.629332]\n",
      "epoch:8 step:6355 [D loss: 0.647028, acc: 57.03%] [G loss: 1.678260]\n",
      "epoch:8 step:6356 [D loss: 0.659159, acc: 58.59%] [G loss: 1.642954]\n",
      "epoch:8 step:6357 [D loss: 0.698660, acc: 46.88%] [G loss: 1.602059]\n",
      "epoch:8 step:6358 [D loss: 0.582769, acc: 77.34%] [G loss: 1.697119]\n",
      "epoch:8 step:6359 [D loss: 0.768533, acc: 37.50%] [G loss: 1.578398]\n",
      "epoch:8 step:6360 [D loss: 0.610521, acc: 73.44%] [G loss: 1.618117]\n",
      "epoch:8 step:6361 [D loss: 0.723885, acc: 39.84%] [G loss: 1.476167]\n",
      "epoch:8 step:6362 [D loss: 0.717855, acc: 46.09%] [G loss: 1.775399]\n",
      "epoch:8 step:6363 [D loss: 0.685389, acc: 51.56%] [G loss: 1.568658]\n",
      "epoch:8 step:6364 [D loss: 0.654119, acc: 60.94%] [G loss: 1.722820]\n",
      "epoch:8 step:6365 [D loss: 0.759312, acc: 43.75%] [G loss: 1.551506]\n",
      "epoch:8 step:6366 [D loss: 0.793459, acc: 35.94%] [G loss: 1.433753]\n",
      "epoch:8 step:6367 [D loss: 0.727107, acc: 49.22%] [G loss: 1.607600]\n",
      "epoch:8 step:6368 [D loss: 0.687587, acc: 55.47%] [G loss: 1.681869]\n",
      "epoch:8 step:6369 [D loss: 0.708427, acc: 47.66%] [G loss: 1.551614]\n",
      "epoch:8 step:6370 [D loss: 0.671427, acc: 64.84%] [G loss: 1.588784]\n",
      "epoch:8 step:6371 [D loss: 0.643581, acc: 60.94%] [G loss: 1.633963]\n",
      "epoch:8 step:6372 [D loss: 0.557280, acc: 72.66%] [G loss: 1.600631]\n",
      "epoch:8 step:6373 [D loss: 0.750995, acc: 37.50%] [G loss: 1.451627]\n",
      "epoch:8 step:6374 [D loss: 0.693800, acc: 60.16%] [G loss: 1.540539]\n",
      "epoch:8 step:6375 [D loss: 0.676049, acc: 56.25%] [G loss: 1.584229]\n",
      "epoch:8 step:6376 [D loss: 0.595039, acc: 71.09%] [G loss: 1.720903]\n",
      "epoch:8 step:6377 [D loss: 0.663014, acc: 60.16%] [G loss: 1.801069]\n",
      "epoch:8 step:6378 [D loss: 0.712220, acc: 52.34%] [G loss: 1.651422]\n",
      "epoch:8 step:6379 [D loss: 0.657087, acc: 61.72%] [G loss: 1.677392]\n",
      "epoch:8 step:6380 [D loss: 0.721490, acc: 50.00%] [G loss: 1.566364]\n",
      "epoch:8 step:6381 [D loss: 0.628306, acc: 63.28%] [G loss: 1.553149]\n",
      "epoch:8 step:6382 [D loss: 0.627646, acc: 65.62%] [G loss: 1.815325]\n",
      "epoch:8 step:6383 [D loss: 0.756482, acc: 46.88%] [G loss: 1.526984]\n",
      "epoch:8 step:6384 [D loss: 0.709853, acc: 49.22%] [G loss: 1.697468]\n",
      "epoch:8 step:6385 [D loss: 0.728881, acc: 47.66%] [G loss: 1.593285]\n",
      "epoch:8 step:6386 [D loss: 0.688864, acc: 62.50%] [G loss: 1.612737]\n",
      "epoch:8 step:6387 [D loss: 0.577183, acc: 72.66%] [G loss: 1.588106]\n",
      "epoch:8 step:6388 [D loss: 0.763676, acc: 43.75%] [G loss: 1.752084]\n",
      "epoch:8 step:6389 [D loss: 0.599764, acc: 73.44%] [G loss: 1.740649]\n",
      "epoch:8 step:6390 [D loss: 0.837170, acc: 28.91%] [G loss: 1.420475]\n",
      "epoch:8 step:6391 [D loss: 0.882092, acc: 29.69%] [G loss: 1.614189]\n",
      "epoch:8 step:6392 [D loss: 0.705994, acc: 50.78%] [G loss: 1.432071]\n",
      "epoch:8 step:6393 [D loss: 0.676661, acc: 55.47%] [G loss: 1.543900]\n",
      "epoch:8 step:6394 [D loss: 0.696740, acc: 53.12%] [G loss: 1.540823]\n",
      "epoch:8 step:6395 [D loss: 0.729678, acc: 47.66%] [G loss: 1.503892]\n",
      "epoch:8 step:6396 [D loss: 0.706436, acc: 53.12%] [G loss: 1.643887]\n",
      "epoch:8 step:6397 [D loss: 0.736925, acc: 49.22%] [G loss: 1.620548]\n",
      "epoch:8 step:6398 [D loss: 0.725062, acc: 46.09%] [G loss: 1.557137]\n",
      "epoch:8 step:6399 [D loss: 0.668150, acc: 59.38%] [G loss: 1.729104]\n",
      "epoch:8 step:6400 [D loss: 0.713217, acc: 49.22%] [G loss: 1.521805]\n",
      "epoch:8 step:6401 [D loss: 0.679947, acc: 58.59%] [G loss: 1.568961]\n",
      "epoch:8 step:6402 [D loss: 0.614736, acc: 71.09%] [G loss: 1.623288]\n",
      "epoch:8 step:6403 [D loss: 0.541616, acc: 77.34%] [G loss: 1.732275]\n",
      "epoch:8 step:6404 [D loss: 0.639241, acc: 65.62%] [G loss: 1.721603]\n",
      "epoch:8 step:6405 [D loss: 0.741624, acc: 42.97%] [G loss: 1.590183]\n",
      "epoch:8 step:6406 [D loss: 0.739292, acc: 53.91%] [G loss: 1.806146]\n",
      "epoch:8 step:6407 [D loss: 0.688391, acc: 57.03%] [G loss: 1.613180]\n",
      "epoch:8 step:6408 [D loss: 0.839175, acc: 29.69%] [G loss: 1.418803]\n",
      "epoch:8 step:6409 [D loss: 0.727337, acc: 46.09%] [G loss: 1.685305]\n",
      "epoch:8 step:6410 [D loss: 0.744365, acc: 38.28%] [G loss: 1.563338]\n",
      "epoch:8 step:6411 [D loss: 0.779711, acc: 34.38%] [G loss: 1.540287]\n",
      "epoch:8 step:6412 [D loss: 0.636303, acc: 67.19%] [G loss: 1.695786]\n",
      "epoch:8 step:6413 [D loss: 0.689434, acc: 54.69%] [G loss: 1.603346]\n",
      "epoch:8 step:6414 [D loss: 0.844718, acc: 35.94%] [G loss: 1.498795]\n",
      "epoch:8 step:6415 [D loss: 0.714429, acc: 50.78%] [G loss: 1.465936]\n",
      "epoch:8 step:6416 [D loss: 0.700892, acc: 53.91%] [G loss: 1.707750]\n",
      "epoch:8 step:6417 [D loss: 0.672768, acc: 53.91%] [G loss: 1.590926]\n",
      "epoch:8 step:6418 [D loss: 0.690030, acc: 53.12%] [G loss: 1.689740]\n",
      "epoch:8 step:6419 [D loss: 0.718509, acc: 50.00%] [G loss: 1.601420]\n",
      "epoch:8 step:6420 [D loss: 0.690692, acc: 56.25%] [G loss: 1.668325]\n",
      "epoch:8 step:6421 [D loss: 0.675741, acc: 57.81%] [G loss: 1.310749]\n",
      "epoch:8 step:6422 [D loss: 0.785738, acc: 35.94%] [G loss: 1.500148]\n",
      "epoch:8 step:6423 [D loss: 0.734286, acc: 44.53%] [G loss: 1.552167]\n",
      "epoch:8 step:6424 [D loss: 0.744452, acc: 47.66%] [G loss: 1.510087]\n",
      "epoch:8 step:6425 [D loss: 0.581566, acc: 78.91%] [G loss: 1.755810]\n",
      "epoch:8 step:6426 [D loss: 0.722223, acc: 45.31%] [G loss: 1.468778]\n",
      "epoch:8 step:6427 [D loss: 0.691586, acc: 51.56%] [G loss: 1.778279]\n",
      "epoch:8 step:6428 [D loss: 0.732052, acc: 45.31%] [G loss: 1.459886]\n",
      "epoch:8 step:6429 [D loss: 0.665618, acc: 59.38%] [G loss: 1.657795]\n",
      "epoch:8 step:6430 [D loss: 0.773765, acc: 42.19%] [G loss: 1.495860]\n",
      "epoch:8 step:6431 [D loss: 0.665030, acc: 61.72%] [G loss: 1.682218]\n",
      "epoch:8 step:6432 [D loss: 0.746928, acc: 42.97%] [G loss: 1.571552]\n",
      "epoch:8 step:6433 [D loss: 0.776393, acc: 35.16%] [G loss: 1.567451]\n",
      "epoch:8 step:6434 [D loss: 0.699743, acc: 57.81%] [G loss: 1.625347]\n",
      "epoch:8 step:6435 [D loss: 0.591103, acc: 72.66%] [G loss: 1.741753]\n",
      "epoch:8 step:6436 [D loss: 0.781407, acc: 38.28%] [G loss: 1.526935]\n",
      "epoch:8 step:6437 [D loss: 0.675380, acc: 63.28%] [G loss: 1.732821]\n",
      "epoch:8 step:6438 [D loss: 0.739474, acc: 42.19%] [G loss: 1.626341]\n",
      "epoch:8 step:6439 [D loss: 0.693668, acc: 53.12%] [G loss: 1.698171]\n",
      "epoch:8 step:6440 [D loss: 0.754324, acc: 46.88%] [G loss: 1.455449]\n",
      "epoch:8 step:6441 [D loss: 0.704034, acc: 51.56%] [G loss: 1.490840]\n",
      "epoch:8 step:6442 [D loss: 0.658147, acc: 63.28%] [G loss: 1.604242]\n",
      "epoch:8 step:6443 [D loss: 0.702641, acc: 51.56%] [G loss: 1.501621]\n",
      "epoch:8 step:6444 [D loss: 0.890520, acc: 24.22%] [G loss: 1.268295]\n",
      "epoch:8 step:6445 [D loss: 0.687066, acc: 53.91%] [G loss: 1.616336]\n",
      "epoch:8 step:6446 [D loss: 0.738608, acc: 44.53%] [G loss: 1.587330]\n",
      "epoch:8 step:6447 [D loss: 0.649221, acc: 64.84%] [G loss: 1.592327]\n",
      "epoch:8 step:6448 [D loss: 0.651705, acc: 60.16%] [G loss: 1.896175]\n",
      "epoch:8 step:6449 [D loss: 0.585974, acc: 75.78%] [G loss: 1.685139]\n",
      "epoch:8 step:6450 [D loss: 0.746495, acc: 43.75%] [G loss: 1.445268]\n",
      "epoch:8 step:6451 [D loss: 0.670414, acc: 59.38%] [G loss: 1.636371]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6452 [D loss: 0.679411, acc: 59.38%] [G loss: 1.719528]\n",
      "epoch:8 step:6453 [D loss: 0.803404, acc: 36.72%] [G loss: 1.450222]\n",
      "epoch:8 step:6454 [D loss: 0.511378, acc: 71.09%] [G loss: 1.777709]\n",
      "epoch:8 step:6455 [D loss: 0.688308, acc: 60.16%] [G loss: 1.615612]\n",
      "epoch:8 step:6456 [D loss: 0.756043, acc: 46.09%] [G loss: 1.508758]\n",
      "epoch:8 step:6457 [D loss: 0.665645, acc: 54.69%] [G loss: 1.622032]\n",
      "epoch:8 step:6458 [D loss: 0.654011, acc: 62.50%] [G loss: 1.750639]\n",
      "epoch:8 step:6459 [D loss: 0.524548, acc: 85.16%] [G loss: 1.621161]\n",
      "epoch:8 step:6460 [D loss: 0.508486, acc: 84.38%] [G loss: 1.751429]\n",
      "epoch:8 step:6461 [D loss: 0.798765, acc: 35.94%] [G loss: 1.473528]\n",
      "epoch:8 step:6462 [D loss: 0.649808, acc: 60.16%] [G loss: 1.943976]\n",
      "epoch:8 step:6463 [D loss: 0.711494, acc: 48.44%] [G loss: 1.422930]\n",
      "epoch:8 step:6464 [D loss: 0.703235, acc: 57.81%] [G loss: 1.625742]\n",
      "epoch:8 step:6465 [D loss: 0.785850, acc: 39.06%] [G loss: 1.465376]\n",
      "epoch:8 step:6466 [D loss: 0.672590, acc: 54.69%] [G loss: 1.590634]\n",
      "epoch:8 step:6467 [D loss: 0.614114, acc: 69.53%] [G loss: 1.527480]\n",
      "epoch:8 step:6468 [D loss: 0.740097, acc: 42.97%] [G loss: 1.492801]\n",
      "epoch:8 step:6469 [D loss: 0.734379, acc: 51.56%] [G loss: 1.618662]\n",
      "epoch:8 step:6470 [D loss: 0.713711, acc: 53.91%] [G loss: 1.584768]\n",
      "epoch:8 step:6471 [D loss: 0.613409, acc: 70.31%] [G loss: 1.651375]\n",
      "epoch:8 step:6472 [D loss: 0.645092, acc: 63.28%] [G loss: 1.732568]\n",
      "epoch:8 step:6473 [D loss: 0.627932, acc: 64.06%] [G loss: 1.663964]\n",
      "epoch:8 step:6474 [D loss: 0.851541, acc: 32.03%] [G loss: 1.446414]\n",
      "epoch:8 step:6475 [D loss: 0.564217, acc: 77.34%] [G loss: 1.436114]\n",
      "epoch:8 step:6476 [D loss: 0.785112, acc: 50.00%] [G loss: 1.626746]\n",
      "epoch:8 step:6477 [D loss: 0.679484, acc: 56.25%] [G loss: 1.512043]\n",
      "epoch:8 step:6478 [D loss: 0.642594, acc: 63.28%] [G loss: 1.825083]\n",
      "epoch:8 step:6479 [D loss: 0.523981, acc: 76.56%] [G loss: 1.679527]\n",
      "epoch:8 step:6480 [D loss: 0.659218, acc: 60.94%] [G loss: 1.547510]\n",
      "epoch:8 step:6481 [D loss: 0.548435, acc: 80.47%] [G loss: 1.598732]\n",
      "epoch:8 step:6482 [D loss: 0.651987, acc: 59.38%] [G loss: 1.850522]\n",
      "epoch:8 step:6483 [D loss: 0.601471, acc: 71.09%] [G loss: 1.698512]\n",
      "epoch:8 step:6484 [D loss: 0.699896, acc: 56.25%] [G loss: 1.561665]\n",
      "epoch:8 step:6485 [D loss: 0.508042, acc: 78.91%] [G loss: 1.578725]\n",
      "epoch:8 step:6486 [D loss: 0.913247, acc: 34.38%] [G loss: 1.487129]\n",
      "epoch:8 step:6487 [D loss: 0.526547, acc: 78.91%] [G loss: 1.469069]\n",
      "epoch:8 step:6488 [D loss: 0.718524, acc: 54.69%] [G loss: 1.675246]\n",
      "epoch:8 step:6489 [D loss: 0.737936, acc: 44.53%] [G loss: 1.404679]\n",
      "epoch:8 step:6490 [D loss: 0.751625, acc: 42.97%] [G loss: 1.332757]\n",
      "epoch:8 step:6491 [D loss: 0.565060, acc: 69.53%] [G loss: 1.435689]\n",
      "epoch:8 step:6492 [D loss: 0.668422, acc: 58.59%] [G loss: 1.470268]\n",
      "epoch:8 step:6493 [D loss: 0.779272, acc: 34.38%] [G loss: 1.547359]\n",
      "epoch:8 step:6494 [D loss: 0.692218, acc: 62.50%] [G loss: 1.757180]\n",
      "epoch:8 step:6495 [D loss: 0.626513, acc: 69.53%] [G loss: 1.640200]\n",
      "epoch:8 step:6496 [D loss: 0.884975, acc: 31.25%] [G loss: 1.365245]\n",
      "epoch:8 step:6497 [D loss: 0.521885, acc: 75.78%] [G loss: 1.696013]\n",
      "epoch:8 step:6498 [D loss: 0.903724, acc: 18.75%] [G loss: 1.279149]\n",
      "epoch:8 step:6499 [D loss: 0.731622, acc: 47.66%] [G loss: 1.586652]\n",
      "epoch:8 step:6500 [D loss: 0.667970, acc: 64.84%] [G loss: 1.583191]\n",
      "epoch:8 step:6501 [D loss: 0.744408, acc: 42.19%] [G loss: 1.527461]\n",
      "epoch:8 step:6502 [D loss: 0.637208, acc: 57.81%] [G loss: 1.500795]\n",
      "epoch:8 step:6503 [D loss: 0.884377, acc: 25.00%] [G loss: 1.372196]\n",
      "epoch:8 step:6504 [D loss: 0.751590, acc: 39.84%] [G loss: 1.574468]\n",
      "epoch:8 step:6505 [D loss: 0.893415, acc: 20.31%] [G loss: 1.322806]\n",
      "epoch:8 step:6506 [D loss: 0.692816, acc: 54.69%] [G loss: 1.522265]\n",
      "epoch:8 step:6507 [D loss: 0.763400, acc: 36.72%] [G loss: 1.368928]\n",
      "epoch:8 step:6508 [D loss: 0.662594, acc: 59.38%] [G loss: 1.643250]\n",
      "epoch:8 step:6509 [D loss: 0.687175, acc: 56.25%] [G loss: 1.599051]\n",
      "epoch:8 step:6510 [D loss: 0.631345, acc: 67.19%] [G loss: 1.597460]\n",
      "epoch:8 step:6511 [D loss: 0.685214, acc: 57.03%] [G loss: 1.437398]\n",
      "epoch:8 step:6512 [D loss: 0.669112, acc: 60.16%] [G loss: 1.636722]\n",
      "epoch:8 step:6513 [D loss: 0.605274, acc: 76.56%] [G loss: 1.794652]\n",
      "epoch:8 step:6514 [D loss: 0.648394, acc: 63.28%] [G loss: 1.602139]\n",
      "epoch:8 step:6515 [D loss: 1.105115, acc: 16.41%] [G loss: 1.256956]\n",
      "epoch:8 step:6516 [D loss: 0.710957, acc: 50.00%] [G loss: 1.530729]\n",
      "epoch:8 step:6517 [D loss: 0.717374, acc: 47.66%] [G loss: 1.549698]\n",
      "epoch:8 step:6518 [D loss: 0.622139, acc: 71.09%] [G loss: 1.442459]\n",
      "epoch:8 step:6519 [D loss: 0.628850, acc: 69.53%] [G loss: 1.728465]\n",
      "epoch:8 step:6520 [D loss: 0.582083, acc: 75.78%] [G loss: 1.554395]\n",
      "epoch:8 step:6521 [D loss: 0.788233, acc: 42.19%] [G loss: 1.490073]\n",
      "epoch:8 step:6522 [D loss: 0.764800, acc: 38.28%] [G loss: 1.529526]\n",
      "epoch:8 step:6523 [D loss: 0.646600, acc: 66.41%] [G loss: 1.516241]\n",
      "epoch:8 step:6524 [D loss: 0.733617, acc: 48.44%] [G loss: 1.610114]\n",
      "epoch:8 step:6525 [D loss: 0.872219, acc: 21.09%] [G loss: 1.279386]\n",
      "epoch:8 step:6526 [D loss: 0.712240, acc: 52.34%] [G loss: 1.750412]\n",
      "epoch:8 step:6527 [D loss: 0.672565, acc: 60.16%] [G loss: 1.630083]\n",
      "epoch:8 step:6528 [D loss: 0.516180, acc: 82.81%] [G loss: 1.763823]\n",
      "epoch:8 step:6529 [D loss: 0.641722, acc: 65.62%] [G loss: 1.501465]\n",
      "epoch:8 step:6530 [D loss: 0.805107, acc: 38.28%] [G loss: 1.399760]\n",
      "epoch:8 step:6531 [D loss: 0.730912, acc: 46.09%] [G loss: 1.561412]\n",
      "epoch:8 step:6532 [D loss: 0.731271, acc: 41.41%] [G loss: 1.446641]\n",
      "epoch:8 step:6533 [D loss: 0.722015, acc: 49.22%] [G loss: 1.505924]\n",
      "epoch:8 step:6534 [D loss: 0.745165, acc: 42.97%] [G loss: 1.555213]\n",
      "epoch:8 step:6535 [D loss: 0.631472, acc: 67.19%] [G loss: 1.537179]\n",
      "epoch:8 step:6536 [D loss: 0.682583, acc: 52.34%] [G loss: 1.576394]\n",
      "epoch:8 step:6537 [D loss: 0.767110, acc: 41.41%] [G loss: 1.516073]\n",
      "epoch:8 step:6538 [D loss: 0.660410, acc: 64.84%] [G loss: 1.509182]\n",
      "epoch:8 step:6539 [D loss: 0.702592, acc: 51.56%] [G loss: 1.478271]\n",
      "epoch:8 step:6540 [D loss: 0.742515, acc: 45.31%] [G loss: 1.571321]\n",
      "epoch:8 step:6541 [D loss: 0.697416, acc: 50.00%] [G loss: 1.463479]\n",
      "epoch:8 step:6542 [D loss: 0.628057, acc: 65.62%] [G loss: 1.697044]\n",
      "epoch:8 step:6543 [D loss: 0.592795, acc: 75.00%] [G loss: 1.839171]\n",
      "epoch:8 step:6544 [D loss: 0.608284, acc: 71.88%] [G loss: 1.867244]\n",
      "epoch:8 step:6545 [D loss: 0.793613, acc: 36.72%] [G loss: 1.586085]\n",
      "epoch:8 step:6546 [D loss: 0.666541, acc: 60.16%] [G loss: 1.582425]\n",
      "epoch:8 step:6547 [D loss: 0.712847, acc: 55.47%] [G loss: 1.663778]\n",
      "epoch:8 step:6548 [D loss: 0.733595, acc: 43.75%] [G loss: 1.533090]\n",
      "epoch:8 step:6549 [D loss: 0.749814, acc: 46.09%] [G loss: 1.415285]\n",
      "epoch:8 step:6550 [D loss: 0.723043, acc: 46.09%] [G loss: 1.545378]\n",
      "epoch:8 step:6551 [D loss: 0.684833, acc: 53.12%] [G loss: 1.554625]\n",
      "epoch:8 step:6552 [D loss: 0.727226, acc: 46.88%] [G loss: 1.578836]\n",
      "epoch:8 step:6553 [D loss: 0.709494, acc: 56.25%] [G loss: 1.621056]\n",
      "epoch:8 step:6554 [D loss: 0.602648, acc: 64.84%] [G loss: 1.681066]\n",
      "epoch:8 step:6555 [D loss: 0.765235, acc: 39.84%] [G loss: 1.868423]\n",
      "epoch:8 step:6556 [D loss: 0.675439, acc: 60.16%] [G loss: 1.539903]\n",
      "epoch:8 step:6557 [D loss: 0.708057, acc: 53.12%] [G loss: 1.584703]\n",
      "epoch:8 step:6558 [D loss: 0.663429, acc: 60.16%] [G loss: 1.687108]\n",
      "epoch:8 step:6559 [D loss: 0.738771, acc: 48.44%] [G loss: 1.617756]\n",
      "epoch:8 step:6560 [D loss: 0.570520, acc: 75.78%] [G loss: 1.753065]\n",
      "epoch:8 step:6561 [D loss: 0.707221, acc: 51.56%] [G loss: 1.638396]\n",
      "epoch:8 step:6562 [D loss: 0.671235, acc: 60.16%] [G loss: 1.632682]\n",
      "epoch:8 step:6563 [D loss: 0.889022, acc: 21.88%] [G loss: 1.268568]\n",
      "epoch:8 step:6564 [D loss: 0.679400, acc: 58.59%] [G loss: 1.630727]\n",
      "epoch:8 step:6565 [D loss: 0.624104, acc: 67.19%] [G loss: 1.711709]\n",
      "epoch:8 step:6566 [D loss: 0.635144, acc: 67.19%] [G loss: 1.595212]\n",
      "epoch:8 step:6567 [D loss: 0.676201, acc: 60.16%] [G loss: 1.586653]\n",
      "epoch:8 step:6568 [D loss: 0.740105, acc: 44.53%] [G loss: 1.483701]\n",
      "epoch:8 step:6569 [D loss: 0.680451, acc: 54.69%] [G loss: 1.647599]\n",
      "epoch:8 step:6570 [D loss: 0.710991, acc: 53.91%] [G loss: 1.560156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6571 [D loss: 0.649429, acc: 62.50%] [G loss: 1.549664]\n",
      "epoch:8 step:6572 [D loss: 0.696766, acc: 52.34%] [G loss: 1.572946]\n",
      "epoch:8 step:6573 [D loss: 0.701806, acc: 52.34%] [G loss: 1.872332]\n",
      "epoch:8 step:6574 [D loss: 0.687510, acc: 56.25%] [G loss: 1.602628]\n",
      "epoch:8 step:6575 [D loss: 0.701442, acc: 50.00%] [G loss: 1.656251]\n",
      "epoch:8 step:6576 [D loss: 0.625226, acc: 68.75%] [G loss: 1.640096]\n",
      "epoch:8 step:6577 [D loss: 0.624010, acc: 68.75%] [G loss: 1.872564]\n",
      "epoch:8 step:6578 [D loss: 0.518149, acc: 78.91%] [G loss: 1.648695]\n",
      "epoch:8 step:6579 [D loss: 0.687259, acc: 51.56%] [G loss: 1.808178]\n",
      "epoch:8 step:6580 [D loss: 0.707619, acc: 56.25%] [G loss: 1.676633]\n",
      "epoch:8 step:6581 [D loss: 0.703371, acc: 57.81%] [G loss: 1.596217]\n",
      "epoch:8 step:6582 [D loss: 0.711882, acc: 50.78%] [G loss: 1.689018]\n",
      "epoch:8 step:6583 [D loss: 0.674946, acc: 57.81%] [G loss: 1.599635]\n",
      "epoch:8 step:6584 [D loss: 0.651989, acc: 59.38%] [G loss: 1.748159]\n",
      "epoch:8 step:6585 [D loss: 0.642401, acc: 68.75%] [G loss: 1.595249]\n",
      "epoch:8 step:6586 [D loss: 0.630878, acc: 60.16%] [G loss: 1.868573]\n",
      "epoch:8 step:6587 [D loss: 0.685470, acc: 57.81%] [G loss: 1.651619]\n",
      "epoch:8 step:6588 [D loss: 0.741477, acc: 48.44%] [G loss: 1.759110]\n",
      "epoch:8 step:6589 [D loss: 0.562945, acc: 81.25%] [G loss: 1.804937]\n",
      "epoch:8 step:6590 [D loss: 0.606329, acc: 71.09%] [G loss: 1.752195]\n",
      "epoch:8 step:6591 [D loss: 0.742415, acc: 47.66%] [G loss: 1.715359]\n",
      "epoch:8 step:6592 [D loss: 0.606561, acc: 67.19%] [G loss: 1.788396]\n",
      "epoch:8 step:6593 [D loss: 0.638572, acc: 67.97%] [G loss: 1.645641]\n",
      "epoch:8 step:6594 [D loss: 0.566078, acc: 74.22%] [G loss: 2.038427]\n",
      "epoch:8 step:6595 [D loss: 0.704087, acc: 53.91%] [G loss: 1.666154]\n",
      "epoch:8 step:6596 [D loss: 0.556504, acc: 78.12%] [G loss: 1.726632]\n",
      "epoch:8 step:6597 [D loss: 0.663358, acc: 58.59%] [G loss: 1.657742]\n",
      "epoch:8 step:6598 [D loss: 0.756879, acc: 48.44%] [G loss: 1.787832]\n",
      "epoch:8 step:6599 [D loss: 0.859722, acc: 32.03%] [G loss: 1.401855]\n",
      "epoch:8 step:6600 [D loss: 0.661974, acc: 60.16%] [G loss: 1.731243]\n",
      "epoch:8 step:6601 [D loss: 0.717578, acc: 50.78%] [G loss: 1.668248]\n",
      "epoch:8 step:6602 [D loss: 0.736768, acc: 47.66%] [G loss: 1.483864]\n",
      "epoch:8 step:6603 [D loss: 0.752127, acc: 44.53%] [G loss: 1.557386]\n",
      "epoch:8 step:6604 [D loss: 0.792773, acc: 33.59%] [G loss: 1.327539]\n",
      "epoch:8 step:6605 [D loss: 0.679094, acc: 60.94%] [G loss: 1.689101]\n",
      "epoch:8 step:6606 [D loss: 0.807327, acc: 34.38%] [G loss: 1.452322]\n",
      "epoch:8 step:6607 [D loss: 0.814712, acc: 39.84%] [G loss: 1.370380]\n",
      "epoch:8 step:6608 [D loss: 0.656025, acc: 60.16%] [G loss: 1.646430]\n",
      "epoch:8 step:6609 [D loss: 0.891591, acc: 25.78%] [G loss: 1.530977]\n",
      "epoch:8 step:6610 [D loss: 0.734898, acc: 46.09%] [G loss: 1.712279]\n",
      "epoch:8 step:6611 [D loss: 0.665947, acc: 58.59%] [G loss: 1.689141]\n",
      "epoch:8 step:6612 [D loss: 0.709769, acc: 52.34%] [G loss: 1.542432]\n",
      "epoch:8 step:6613 [D loss: 0.659184, acc: 60.94%] [G loss: 1.653535]\n",
      "epoch:8 step:6614 [D loss: 0.651232, acc: 60.94%] [G loss: 1.572310]\n",
      "epoch:8 step:6615 [D loss: 0.619162, acc: 71.09%] [G loss: 1.750335]\n",
      "epoch:8 step:6616 [D loss: 0.703099, acc: 57.03%] [G loss: 1.783389]\n",
      "epoch:8 step:6617 [D loss: 0.732745, acc: 44.53%] [G loss: 1.604351]\n",
      "epoch:8 step:6618 [D loss: 0.623017, acc: 67.19%] [G loss: 1.737572]\n",
      "epoch:8 step:6619 [D loss: 0.665047, acc: 63.28%] [G loss: 1.857248]\n",
      "epoch:8 step:6620 [D loss: 0.635483, acc: 65.62%] [G loss: 1.602502]\n",
      "epoch:8 step:6621 [D loss: 0.829183, acc: 32.81%] [G loss: 1.432576]\n",
      "epoch:8 step:6622 [D loss: 0.738024, acc: 46.88%] [G loss: 1.606928]\n",
      "epoch:8 step:6623 [D loss: 0.681297, acc: 59.38%] [G loss: 1.623623]\n",
      "epoch:8 step:6624 [D loss: 0.881844, acc: 23.44%] [G loss: 1.435483]\n",
      "epoch:8 step:6625 [D loss: 0.713930, acc: 57.81%] [G loss: 1.630016]\n",
      "epoch:8 step:6626 [D loss: 0.753806, acc: 40.62%] [G loss: 1.492478]\n",
      "epoch:8 step:6627 [D loss: 0.662909, acc: 62.50%] [G loss: 1.718960]\n",
      "epoch:8 step:6628 [D loss: 0.714416, acc: 51.56%] [G loss: 1.543319]\n",
      "epoch:8 step:6629 [D loss: 0.726784, acc: 49.22%] [G loss: 1.593931]\n",
      "epoch:8 step:6630 [D loss: 0.596581, acc: 71.88%] [G loss: 1.594730]\n",
      "epoch:8 step:6631 [D loss: 0.673081, acc: 57.81%] [G loss: 1.648269]\n",
      "epoch:8 step:6632 [D loss: 0.729796, acc: 49.22%] [G loss: 1.573172]\n",
      "epoch:8 step:6633 [D loss: 0.721870, acc: 47.66%] [G loss: 1.611531]\n",
      "epoch:8 step:6634 [D loss: 0.635293, acc: 62.50%] [G loss: 1.547900]\n",
      "epoch:8 step:6635 [D loss: 0.750562, acc: 43.75%] [G loss: 1.513510]\n",
      "epoch:8 step:6636 [D loss: 0.847603, acc: 43.75%] [G loss: 1.307833]\n",
      "epoch:8 step:6637 [D loss: 0.718929, acc: 50.00%] [G loss: 1.547329]\n",
      "epoch:8 step:6638 [D loss: 0.689662, acc: 53.12%] [G loss: 1.581116]\n",
      "epoch:8 step:6639 [D loss: 0.871123, acc: 15.62%] [G loss: 1.496932]\n",
      "epoch:8 step:6640 [D loss: 0.596791, acc: 71.09%] [G loss: 1.566706]\n",
      "epoch:8 step:6641 [D loss: 0.806771, acc: 35.16%] [G loss: 1.380032]\n",
      "epoch:8 step:6642 [D loss: 0.645590, acc: 61.72%] [G loss: 1.587440]\n",
      "epoch:8 step:6643 [D loss: 0.704776, acc: 50.78%] [G loss: 1.418015]\n",
      "epoch:8 step:6644 [D loss: 0.699125, acc: 48.44%] [G loss: 1.566786]\n",
      "epoch:8 step:6645 [D loss: 0.815493, acc: 32.03%] [G loss: 1.454197]\n",
      "epoch:8 step:6646 [D loss: 0.735339, acc: 45.31%] [G loss: 1.493005]\n",
      "epoch:8 step:6647 [D loss: 0.648795, acc: 65.62%] [G loss: 1.516824]\n",
      "epoch:8 step:6648 [D loss: 0.679462, acc: 53.91%] [G loss: 1.571312]\n",
      "epoch:8 step:6649 [D loss: 0.675790, acc: 58.59%] [G loss: 1.539689]\n",
      "epoch:8 step:6650 [D loss: 0.670883, acc: 60.94%] [G loss: 1.514659]\n",
      "epoch:8 step:6651 [D loss: 0.667841, acc: 62.50%] [G loss: 1.790409]\n",
      "epoch:8 step:6652 [D loss: 0.643254, acc: 66.41%] [G loss: 1.606714]\n",
      "epoch:8 step:6653 [D loss: 0.701694, acc: 53.12%] [G loss: 1.607589]\n",
      "epoch:8 step:6654 [D loss: 0.672089, acc: 57.81%] [G loss: 1.562297]\n",
      "epoch:8 step:6655 [D loss: 0.675396, acc: 60.16%] [G loss: 1.612302]\n",
      "epoch:8 step:6656 [D loss: 0.789325, acc: 36.72%] [G loss: 1.448604]\n",
      "epoch:8 step:6657 [D loss: 0.530042, acc: 78.91%] [G loss: 1.659975]\n",
      "epoch:8 step:6658 [D loss: 0.723049, acc: 50.78%] [G loss: 1.598279]\n",
      "epoch:8 step:6659 [D loss: 0.707943, acc: 47.66%] [G loss: 1.544616]\n",
      "epoch:8 step:6660 [D loss: 0.595670, acc: 75.00%] [G loss: 1.607827]\n",
      "epoch:8 step:6661 [D loss: 0.707591, acc: 47.66%] [G loss: 1.478774]\n",
      "epoch:8 step:6662 [D loss: 0.592749, acc: 77.34%] [G loss: 1.520927]\n",
      "epoch:8 step:6663 [D loss: 0.703796, acc: 50.00%] [G loss: 1.518213]\n",
      "epoch:8 step:6664 [D loss: 0.806187, acc: 35.16%] [G loss: 1.371621]\n",
      "epoch:8 step:6665 [D loss: 0.724679, acc: 45.31%] [G loss: 1.578861]\n",
      "epoch:8 step:6666 [D loss: 0.612991, acc: 75.00%] [G loss: 1.503976]\n",
      "epoch:8 step:6667 [D loss: 0.670461, acc: 60.16%] [G loss: 1.582150]\n",
      "epoch:8 step:6668 [D loss: 0.715884, acc: 51.56%] [G loss: 1.666503]\n",
      "epoch:8 step:6669 [D loss: 0.711139, acc: 54.69%] [G loss: 1.538494]\n",
      "epoch:8 step:6670 [D loss: 0.679406, acc: 53.12%] [G loss: 1.784358]\n",
      "epoch:8 step:6671 [D loss: 0.630662, acc: 71.88%] [G loss: 1.725792]\n",
      "epoch:8 step:6672 [D loss: 0.745797, acc: 53.12%] [G loss: 1.782437]\n",
      "epoch:8 step:6673 [D loss: 0.713593, acc: 51.56%] [G loss: 1.582311]\n",
      "epoch:8 step:6674 [D loss: 0.612753, acc: 68.75%] [G loss: 1.643055]\n",
      "epoch:8 step:6675 [D loss: 0.555757, acc: 80.47%] [G loss: 1.908102]\n",
      "epoch:8 step:6676 [D loss: 0.730425, acc: 41.41%] [G loss: 1.464941]\n",
      "epoch:8 step:6677 [D loss: 0.653354, acc: 68.75%] [G loss: 1.624076]\n",
      "epoch:8 step:6678 [D loss: 0.707098, acc: 51.56%] [G loss: 1.452741]\n",
      "epoch:8 step:6679 [D loss: 0.722439, acc: 49.22%] [G loss: 1.817193]\n",
      "epoch:8 step:6680 [D loss: 0.676965, acc: 58.59%] [G loss: 1.552062]\n",
      "epoch:8 step:6681 [D loss: 0.702962, acc: 53.12%] [G loss: 1.577071]\n",
      "epoch:8 step:6682 [D loss: 0.727485, acc: 49.22%] [G loss: 1.440587]\n",
      "epoch:8 step:6683 [D loss: 0.729960, acc: 45.31%] [G loss: 1.526639]\n",
      "epoch:8 step:6684 [D loss: 0.622033, acc: 74.22%] [G loss: 1.640961]\n",
      "epoch:8 step:6685 [D loss: 0.746889, acc: 39.06%] [G loss: 1.529140]\n",
      "epoch:8 step:6686 [D loss: 0.745900, acc: 46.09%] [G loss: 1.473617]\n",
      "epoch:8 step:6687 [D loss: 0.570222, acc: 77.34%] [G loss: 1.534144]\n",
      "epoch:8 step:6688 [D loss: 0.753600, acc: 46.09%] [G loss: 1.433494]\n",
      "epoch:8 step:6689 [D loss: 0.747244, acc: 42.19%] [G loss: 1.558795]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6690 [D loss: 0.684952, acc: 60.16%] [G loss: 1.585391]\n",
      "epoch:8 step:6691 [D loss: 0.674404, acc: 60.16%] [G loss: 1.617992]\n",
      "epoch:8 step:6692 [D loss: 0.753511, acc: 38.28%] [G loss: 1.478366]\n",
      "epoch:8 step:6693 [D loss: 0.735803, acc: 50.78%] [G loss: 1.470019]\n",
      "epoch:8 step:6694 [D loss: 0.669909, acc: 60.16%] [G loss: 1.578343]\n",
      "epoch:8 step:6695 [D loss: 0.711606, acc: 46.88%] [G loss: 1.620150]\n",
      "epoch:8 step:6696 [D loss: 0.624925, acc: 68.75%] [G loss: 1.645338]\n",
      "epoch:8 step:6697 [D loss: 0.695265, acc: 57.03%] [G loss: 1.542702]\n",
      "epoch:8 step:6698 [D loss: 0.621895, acc: 64.84%] [G loss: 1.835973]\n",
      "epoch:8 step:6699 [D loss: 0.716178, acc: 52.34%] [G loss: 1.566726]\n",
      "epoch:8 step:6700 [D loss: 0.779694, acc: 43.75%] [G loss: 1.725959]\n",
      "epoch:8 step:6701 [D loss: 0.755965, acc: 39.06%] [G loss: 1.550445]\n",
      "epoch:8 step:6702 [D loss: 0.620273, acc: 67.19%] [G loss: 1.567419]\n",
      "epoch:8 step:6703 [D loss: 0.517228, acc: 79.69%] [G loss: 1.828351]\n",
      "epoch:8 step:6704 [D loss: 0.551748, acc: 82.03%] [G loss: 1.607250]\n",
      "epoch:8 step:6705 [D loss: 0.540224, acc: 87.50%] [G loss: 1.671791]\n",
      "epoch:8 step:6706 [D loss: 0.654570, acc: 57.03%] [G loss: 1.602683]\n",
      "epoch:8 step:6707 [D loss: 0.666447, acc: 62.50%] [G loss: 1.639596]\n",
      "epoch:8 step:6708 [D loss: 0.731315, acc: 53.12%] [G loss: 1.683974]\n",
      "epoch:8 step:6709 [D loss: 0.753604, acc: 39.84%] [G loss: 1.637688]\n",
      "epoch:8 step:6710 [D loss: 0.533910, acc: 81.25%] [G loss: 1.638458]\n",
      "epoch:8 step:6711 [D loss: 0.730230, acc: 49.22%] [G loss: 1.741259]\n",
      "epoch:8 step:6712 [D loss: 0.630606, acc: 65.62%] [G loss: 1.754423]\n",
      "epoch:8 step:6713 [D loss: 0.829740, acc: 28.12%] [G loss: 1.515397]\n",
      "epoch:8 step:6714 [D loss: 0.475013, acc: 73.44%] [G loss: 1.594873]\n",
      "epoch:8 step:6715 [D loss: 0.526815, acc: 90.62%] [G loss: 1.678069]\n",
      "epoch:8 step:6716 [D loss: 0.778396, acc: 36.72%] [G loss: 1.397115]\n",
      "epoch:8 step:6717 [D loss: 0.734872, acc: 50.00%] [G loss: 1.423302]\n",
      "epoch:8 step:6718 [D loss: 0.807126, acc: 32.81%] [G loss: 1.362043]\n",
      "epoch:8 step:6719 [D loss: 0.682422, acc: 56.25%] [G loss: 1.453725]\n",
      "epoch:8 step:6720 [D loss: 0.592254, acc: 72.66%] [G loss: 1.756667]\n",
      "epoch:8 step:6721 [D loss: 0.704916, acc: 53.91%] [G loss: 1.695091]\n",
      "epoch:8 step:6722 [D loss: 0.681422, acc: 57.81%] [G loss: 1.535620]\n",
      "epoch:8 step:6723 [D loss: 0.658649, acc: 62.50%] [G loss: 1.801167]\n",
      "epoch:8 step:6724 [D loss: 0.637734, acc: 66.41%] [G loss: 1.640882]\n",
      "epoch:8 step:6725 [D loss: 0.867153, acc: 23.44%] [G loss: 1.378849]\n",
      "epoch:8 step:6726 [D loss: 0.901519, acc: 17.97%] [G loss: 1.385494]\n",
      "epoch:8 step:6727 [D loss: 0.785317, acc: 36.72%] [G loss: 1.409796]\n",
      "epoch:8 step:6728 [D loss: 0.661817, acc: 59.38%] [G loss: 1.505509]\n",
      "epoch:8 step:6729 [D loss: 0.621902, acc: 64.84%] [G loss: 1.683577]\n",
      "epoch:8 step:6730 [D loss: 0.705629, acc: 50.78%] [G loss: 1.594145]\n",
      "epoch:8 step:6731 [D loss: 0.729938, acc: 48.44%] [G loss: 1.535135]\n",
      "epoch:8 step:6732 [D loss: 0.758330, acc: 47.66%] [G loss: 1.515689]\n",
      "epoch:8 step:6733 [D loss: 0.705148, acc: 53.12%] [G loss: 1.471300]\n",
      "epoch:8 step:6734 [D loss: 0.688582, acc: 53.12%] [G loss: 1.672983]\n",
      "epoch:8 step:6735 [D loss: 0.700528, acc: 48.44%] [G loss: 1.570017]\n",
      "epoch:8 step:6736 [D loss: 0.683565, acc: 55.47%] [G loss: 1.462947]\n",
      "epoch:8 step:6737 [D loss: 0.632022, acc: 70.31%] [G loss: 1.712100]\n",
      "epoch:8 step:6738 [D loss: 0.668724, acc: 63.28%] [G loss: 1.684473]\n",
      "epoch:8 step:6739 [D loss: 0.694446, acc: 53.91%] [G loss: 1.589488]\n",
      "epoch:8 step:6740 [D loss: 0.680439, acc: 54.69%] [G loss: 1.502266]\n",
      "epoch:8 step:6741 [D loss: 0.694051, acc: 57.03%] [G loss: 1.676684]\n",
      "epoch:8 step:6742 [D loss: 0.730578, acc: 46.09%] [G loss: 1.470041]\n",
      "epoch:8 step:6743 [D loss: 0.578098, acc: 79.69%] [G loss: 1.846228]\n",
      "epoch:8 step:6744 [D loss: 0.677474, acc: 59.38%] [G loss: 1.601547]\n",
      "epoch:8 step:6745 [D loss: 0.605519, acc: 71.09%] [G loss: 1.716190]\n",
      "epoch:8 step:6746 [D loss: 0.749276, acc: 42.19%] [G loss: 1.748433]\n",
      "epoch:8 step:6747 [D loss: 0.836692, acc: 32.03%] [G loss: 1.440395]\n",
      "epoch:8 step:6748 [D loss: 0.734677, acc: 50.00%] [G loss: 1.500530]\n",
      "epoch:8 step:6749 [D loss: 0.511413, acc: 85.94%] [G loss: 1.608771]\n",
      "epoch:8 step:6750 [D loss: 0.624538, acc: 69.53%] [G loss: 1.538824]\n",
      "epoch:8 step:6751 [D loss: 0.627856, acc: 71.88%] [G loss: 1.535347]\n",
      "epoch:8 step:6752 [D loss: 0.682666, acc: 56.25%] [G loss: 1.564384]\n",
      "epoch:8 step:6753 [D loss: 0.428320, acc: 79.69%] [G loss: 1.576628]\n",
      "epoch:8 step:6754 [D loss: 0.524339, acc: 71.09%] [G loss: 1.382967]\n",
      "epoch:8 step:6755 [D loss: 0.620969, acc: 64.06%] [G loss: 1.410388]\n",
      "epoch:8 step:6756 [D loss: 0.458550, acc: 90.62%] [G loss: 1.555733]\n",
      "epoch:8 step:6757 [D loss: 0.735062, acc: 43.75%] [G loss: 1.168467]\n",
      "epoch:8 step:6758 [D loss: 0.899395, acc: 27.34%] [G loss: 1.334134]\n",
      "epoch:8 step:6759 [D loss: 0.627202, acc: 70.31%] [G loss: 1.421826]\n",
      "epoch:8 step:6760 [D loss: 0.503013, acc: 76.56%] [G loss: 1.307034]\n",
      "epoch:8 step:6761 [D loss: 0.724093, acc: 47.66%] [G loss: 1.403105]\n",
      "epoch:8 step:6762 [D loss: 0.634024, acc: 63.28%] [G loss: 1.613642]\n",
      "epoch:8 step:6763 [D loss: 0.854999, acc: 36.72%] [G loss: 1.394301]\n",
      "epoch:8 step:6764 [D loss: 0.770863, acc: 46.88%] [G loss: 1.607728]\n",
      "epoch:8 step:6765 [D loss: 0.558017, acc: 77.34%] [G loss: 1.598466]\n",
      "epoch:8 step:6766 [D loss: 0.520850, acc: 74.22%] [G loss: 1.714119]\n",
      "epoch:8 step:6767 [D loss: 0.694099, acc: 56.25%] [G loss: 1.749804]\n",
      "epoch:8 step:6768 [D loss: 0.710084, acc: 53.91%] [G loss: 1.858319]\n",
      "epoch:8 step:6769 [D loss: 0.660599, acc: 55.47%] [G loss: 1.854219]\n",
      "epoch:8 step:6770 [D loss: 0.746163, acc: 57.03%] [G loss: 2.062720]\n",
      "epoch:8 step:6771 [D loss: 0.675352, acc: 54.69%] [G loss: 1.643134]\n",
      "epoch:8 step:6772 [D loss: 0.733590, acc: 50.00%] [G loss: 1.951504]\n",
      "epoch:8 step:6773 [D loss: 0.475170, acc: 82.81%] [G loss: 1.969894]\n",
      "epoch:8 step:6774 [D loss: 0.669745, acc: 59.38%] [G loss: 1.857662]\n",
      "epoch:8 step:6775 [D loss: 0.721212, acc: 53.12%] [G loss: 1.750572]\n",
      "epoch:8 step:6776 [D loss: 0.526286, acc: 82.03%] [G loss: 1.631516]\n",
      "epoch:8 step:6777 [D loss: 0.442590, acc: 82.81%] [G loss: 1.694707]\n",
      "epoch:8 step:6778 [D loss: 0.862486, acc: 32.81%] [G loss: 1.530837]\n",
      "epoch:8 step:6779 [D loss: 0.584587, acc: 71.88%] [G loss: 1.362414]\n",
      "epoch:8 step:6780 [D loss: 0.625097, acc: 66.41%] [G loss: 1.726808]\n",
      "epoch:8 step:6781 [D loss: 0.600807, acc: 67.19%] [G loss: 1.534545]\n",
      "epoch:8 step:6782 [D loss: 0.626858, acc: 63.28%] [G loss: 1.514814]\n",
      "epoch:8 step:6783 [D loss: 0.597526, acc: 71.09%] [G loss: 1.692060]\n",
      "epoch:8 step:6784 [D loss: 0.828226, acc: 28.91%] [G loss: 1.736694]\n",
      "epoch:8 step:6785 [D loss: 0.682295, acc: 53.91%] [G loss: 2.182119]\n",
      "epoch:8 step:6786 [D loss: 0.736937, acc: 52.34%] [G loss: 1.671281]\n",
      "epoch:8 step:6787 [D loss: 0.578012, acc: 63.28%] [G loss: 1.507431]\n",
      "epoch:8 step:6788 [D loss: 0.808472, acc: 51.56%] [G loss: 1.588398]\n",
      "epoch:8 step:6789 [D loss: 0.659755, acc: 54.69%] [G loss: 1.659989]\n",
      "epoch:8 step:6790 [D loss: 0.527761, acc: 81.25%] [G loss: 1.688576]\n",
      "epoch:8 step:6791 [D loss: 0.721161, acc: 48.44%] [G loss: 1.603137]\n",
      "epoch:8 step:6792 [D loss: 0.600306, acc: 67.97%] [G loss: 1.560234]\n",
      "epoch:8 step:6793 [D loss: 0.583665, acc: 68.75%] [G loss: 1.677059]\n",
      "epoch:8 step:6794 [D loss: 0.602403, acc: 78.91%] [G loss: 1.580653]\n",
      "epoch:8 step:6795 [D loss: 0.616984, acc: 71.09%] [G loss: 1.635459]\n",
      "epoch:8 step:6796 [D loss: 0.626408, acc: 64.84%] [G loss: 1.487304]\n",
      "epoch:8 step:6797 [D loss: 0.763708, acc: 46.09%] [G loss: 1.390013]\n",
      "epoch:8 step:6798 [D loss: 0.483626, acc: 84.38%] [G loss: 2.010414]\n",
      "epoch:8 step:6799 [D loss: 0.690305, acc: 58.59%] [G loss: 1.689459]\n",
      "epoch:8 step:6800 [D loss: 0.883477, acc: 18.75%] [G loss: 1.343555]\n",
      "epoch:8 step:6801 [D loss: 0.739899, acc: 53.12%] [G loss: 1.633093]\n",
      "epoch:8 step:6802 [D loss: 0.575636, acc: 75.00%] [G loss: 1.789346]\n",
      "epoch:8 step:6803 [D loss: 0.773473, acc: 49.22%] [G loss: 1.794583]\n",
      "epoch:8 step:6804 [D loss: 0.407129, acc: 84.38%] [G loss: 1.786486]\n",
      "epoch:8 step:6805 [D loss: 0.423396, acc: 91.41%] [G loss: 1.885396]\n",
      "epoch:8 step:6806 [D loss: 0.528162, acc: 62.50%] [G loss: 1.418649]\n",
      "epoch:8 step:6807 [D loss: 0.712385, acc: 53.12%] [G loss: 1.689300]\n",
      "epoch:8 step:6808 [D loss: 0.494605, acc: 89.06%] [G loss: 1.688066]\n",
      "epoch:8 step:6809 [D loss: 0.785107, acc: 40.62%] [G loss: 1.216284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6810 [D loss: 0.305065, acc: 95.31%] [G loss: 1.554161]\n",
      "epoch:8 step:6811 [D loss: 0.610960, acc: 69.53%] [G loss: 1.555788]\n",
      "epoch:8 step:6812 [D loss: 0.530368, acc: 69.53%] [G loss: 1.263584]\n",
      "epoch:8 step:6813 [D loss: 0.772910, acc: 47.66%] [G loss: 1.385899]\n",
      "epoch:8 step:6814 [D loss: 1.142100, acc: 20.31%] [G loss: 1.338198]\n",
      "epoch:8 step:6815 [D loss: 0.798068, acc: 34.38%] [G loss: 1.267097]\n",
      "epoch:8 step:6816 [D loss: 0.738497, acc: 48.44%] [G loss: 1.438665]\n",
      "epoch:8 step:6817 [D loss: 0.675255, acc: 53.91%] [G loss: 1.652058]\n",
      "epoch:8 step:6818 [D loss: 0.556837, acc: 81.25%] [G loss: 1.413126]\n",
      "epoch:8 step:6819 [D loss: 0.933581, acc: 18.75%] [G loss: 1.357726]\n",
      "epoch:8 step:6820 [D loss: 0.732276, acc: 49.22%] [G loss: 1.514479]\n",
      "epoch:8 step:6821 [D loss: 0.765865, acc: 34.38%] [G loss: 1.575387]\n",
      "epoch:8 step:6822 [D loss: 0.735729, acc: 45.31%] [G loss: 1.592518]\n",
      "epoch:8 step:6823 [D loss: 0.545801, acc: 75.78%] [G loss: 1.950838]\n",
      "epoch:8 step:6824 [D loss: 0.754439, acc: 43.75%] [G loss: 1.572557]\n",
      "epoch:8 step:6825 [D loss: 0.544490, acc: 76.56%] [G loss: 1.809402]\n",
      "epoch:8 step:6826 [D loss: 0.600345, acc: 73.44%] [G loss: 1.667820]\n",
      "epoch:8 step:6827 [D loss: 0.611239, acc: 64.06%] [G loss: 1.727762]\n",
      "epoch:8 step:6828 [D loss: 0.683595, acc: 57.81%] [G loss: 1.635476]\n",
      "epoch:8 step:6829 [D loss: 0.583000, acc: 75.00%] [G loss: 2.187087]\n",
      "epoch:8 step:6830 [D loss: 0.482729, acc: 83.59%] [G loss: 1.675453]\n",
      "epoch:8 step:6831 [D loss: 0.637014, acc: 60.94%] [G loss: 1.662052]\n",
      "epoch:8 step:6832 [D loss: 0.581131, acc: 72.66%] [G loss: 1.574911]\n",
      "epoch:8 step:6833 [D loss: 0.593517, acc: 72.66%] [G loss: 1.500766]\n",
      "epoch:8 step:6834 [D loss: 0.612102, acc: 67.19%] [G loss: 1.653932]\n",
      "epoch:8 step:6835 [D loss: 0.723275, acc: 50.00%] [G loss: 1.492054]\n",
      "epoch:8 step:6836 [D loss: 0.819823, acc: 40.62%] [G loss: 1.274631]\n",
      "epoch:8 step:6837 [D loss: 1.019642, acc: 16.41%] [G loss: 1.141230]\n",
      "epoch:8 step:6838 [D loss: 0.792452, acc: 32.81%] [G loss: 1.325600]\n",
      "epoch:8 step:6839 [D loss: 0.384224, acc: 98.44%] [G loss: 1.629047]\n",
      "epoch:8 step:6840 [D loss: 0.450849, acc: 92.19%] [G loss: 1.629492]\n",
      "epoch:8 step:6841 [D loss: 0.722033, acc: 50.78%] [G loss: 1.641157]\n",
      "epoch:8 step:6842 [D loss: 0.859698, acc: 32.03%] [G loss: 1.376124]\n",
      "epoch:8 step:6843 [D loss: 0.766484, acc: 42.97%] [G loss: 1.733427]\n",
      "epoch:8 step:6844 [D loss: 0.765744, acc: 46.09%] [G loss: 1.373580]\n",
      "epoch:8 step:6845 [D loss: 0.704567, acc: 46.09%] [G loss: 1.500197]\n",
      "epoch:8 step:6846 [D loss: 0.689680, acc: 55.47%] [G loss: 1.599126]\n",
      "epoch:8 step:6847 [D loss: 0.850789, acc: 23.44%] [G loss: 1.339510]\n",
      "epoch:8 step:6848 [D loss: 0.535659, acc: 78.12%] [G loss: 1.556318]\n",
      "epoch:8 step:6849 [D loss: 0.705551, acc: 54.69%] [G loss: 1.644284]\n",
      "epoch:8 step:6850 [D loss: 0.470052, acc: 87.50%] [G loss: 1.914270]\n",
      "epoch:8 step:6851 [D loss: 0.745080, acc: 46.88%] [G loss: 1.421099]\n",
      "epoch:8 step:6852 [D loss: 0.690663, acc: 50.78%] [G loss: 1.682715]\n",
      "epoch:8 step:6853 [D loss: 0.765109, acc: 42.19%] [G loss: 1.507500]\n",
      "epoch:8 step:6854 [D loss: 0.760615, acc: 39.06%] [G loss: 1.616068]\n",
      "epoch:8 step:6855 [D loss: 0.720537, acc: 52.34%] [G loss: 1.728024]\n",
      "epoch:8 step:6856 [D loss: 0.719233, acc: 52.34%] [G loss: 1.380801]\n",
      "epoch:8 step:6857 [D loss: 0.683547, acc: 57.81%] [G loss: 1.653912]\n",
      "epoch:8 step:6858 [D loss: 0.626383, acc: 57.81%] [G loss: 1.338187]\n",
      "epoch:8 step:6859 [D loss: 0.723775, acc: 42.97%] [G loss: 1.585745]\n",
      "epoch:8 step:6860 [D loss: 0.735252, acc: 42.97%] [G loss: 1.510057]\n",
      "epoch:8 step:6861 [D loss: 0.719745, acc: 50.00%] [G loss: 1.542206]\n",
      "epoch:8 step:6862 [D loss: 0.865886, acc: 21.09%] [G loss: 1.347672]\n",
      "epoch:8 step:6863 [D loss: 0.708328, acc: 54.69%] [G loss: 1.571842]\n",
      "epoch:8 step:6864 [D loss: 0.817108, acc: 35.94%] [G loss: 1.457284]\n",
      "epoch:8 step:6865 [D loss: 0.541105, acc: 72.66%] [G loss: 1.741485]\n",
      "epoch:8 step:6866 [D loss: 0.716588, acc: 46.09%] [G loss: 1.683794]\n",
      "epoch:8 step:6867 [D loss: 0.791191, acc: 42.97%] [G loss: 1.395133]\n",
      "epoch:8 step:6868 [D loss: 0.722558, acc: 42.19%] [G loss: 1.665669]\n",
      "epoch:8 step:6869 [D loss: 0.656656, acc: 64.84%] [G loss: 1.621386]\n",
      "epoch:8 step:6870 [D loss: 0.646188, acc: 64.06%] [G loss: 1.573686]\n",
      "epoch:8 step:6871 [D loss: 0.641540, acc: 67.19%] [G loss: 1.717377]\n",
      "epoch:8 step:6872 [D loss: 0.576333, acc: 78.91%] [G loss: 1.617026]\n",
      "epoch:8 step:6873 [D loss: 0.631646, acc: 68.75%] [G loss: 1.568596]\n",
      "epoch:8 step:6874 [D loss: 0.838723, acc: 30.47%] [G loss: 1.489666]\n",
      "epoch:8 step:6875 [D loss: 0.789767, acc: 32.03%] [G loss: 1.520651]\n",
      "epoch:8 step:6876 [D loss: 0.695032, acc: 53.91%] [G loss: 1.541161]\n",
      "epoch:8 step:6877 [D loss: 0.543699, acc: 77.34%] [G loss: 1.640437]\n",
      "epoch:8 step:6878 [D loss: 0.646347, acc: 68.75%] [G loss: 1.624800]\n",
      "epoch:8 step:6879 [D loss: 0.715944, acc: 46.88%] [G loss: 1.575790]\n",
      "epoch:8 step:6880 [D loss: 0.906293, acc: 25.78%] [G loss: 1.263419]\n",
      "epoch:8 step:6881 [D loss: 0.662254, acc: 62.50%] [G loss: 1.561607]\n",
      "epoch:8 step:6882 [D loss: 0.696283, acc: 60.16%] [G loss: 1.569000]\n",
      "epoch:8 step:6883 [D loss: 0.673285, acc: 57.81%] [G loss: 1.581573]\n",
      "epoch:8 step:6884 [D loss: 0.685170, acc: 61.72%] [G loss: 1.645084]\n",
      "epoch:8 step:6885 [D loss: 0.943102, acc: 32.81%] [G loss: 1.324663]\n",
      "epoch:8 step:6886 [D loss: 0.806207, acc: 32.81%] [G loss: 1.477058]\n",
      "epoch:8 step:6887 [D loss: 0.709856, acc: 55.47%] [G loss: 1.612451]\n",
      "epoch:8 step:6888 [D loss: 0.726274, acc: 47.66%] [G loss: 1.575985]\n",
      "epoch:8 step:6889 [D loss: 0.750723, acc: 37.50%] [G loss: 1.446930]\n",
      "epoch:8 step:6890 [D loss: 0.736619, acc: 47.66%] [G loss: 1.517103]\n",
      "epoch:8 step:6891 [D loss: 0.569485, acc: 78.12%] [G loss: 1.641800]\n",
      "epoch:8 step:6892 [D loss: 0.732564, acc: 42.19%] [G loss: 1.382172]\n",
      "epoch:8 step:6893 [D loss: 0.859508, acc: 28.91%] [G loss: 1.349438]\n",
      "epoch:8 step:6894 [D loss: 0.882244, acc: 42.19%] [G loss: 1.545937]\n",
      "epoch:8 step:6895 [D loss: 0.729285, acc: 46.88%] [G loss: 1.538817]\n",
      "epoch:8 step:6896 [D loss: 0.644819, acc: 64.06%] [G loss: 1.551113]\n",
      "epoch:8 step:6897 [D loss: 0.925238, acc: 24.22%] [G loss: 1.484527]\n",
      "epoch:8 step:6898 [D loss: 0.692452, acc: 56.25%] [G loss: 1.558061]\n",
      "epoch:8 step:6899 [D loss: 0.692268, acc: 52.34%] [G loss: 1.569433]\n",
      "epoch:8 step:6900 [D loss: 0.790230, acc: 35.16%] [G loss: 1.488417]\n",
      "epoch:8 step:6901 [D loss: 0.671905, acc: 60.94%] [G loss: 1.622136]\n",
      "epoch:8 step:6902 [D loss: 0.770128, acc: 42.19%] [G loss: 1.500098]\n",
      "epoch:8 step:6903 [D loss: 0.576373, acc: 78.12%] [G loss: 1.738725]\n",
      "epoch:8 step:6904 [D loss: 0.814128, acc: 42.97%] [G loss: 1.434806]\n",
      "epoch:8 step:6905 [D loss: 0.745775, acc: 44.53%] [G loss: 1.501282]\n",
      "epoch:8 step:6906 [D loss: 0.713512, acc: 53.91%] [G loss: 1.514421]\n",
      "epoch:8 step:6907 [D loss: 0.659516, acc: 60.16%] [G loss: 1.700265]\n",
      "epoch:8 step:6908 [D loss: 0.760358, acc: 44.53%] [G loss: 1.499841]\n",
      "epoch:8 step:6909 [D loss: 0.732924, acc: 40.62%] [G loss: 1.499969]\n",
      "epoch:8 step:6910 [D loss: 0.724978, acc: 50.00%] [G loss: 1.491024]\n",
      "epoch:8 step:6911 [D loss: 0.723448, acc: 49.22%] [G loss: 1.575857]\n",
      "epoch:8 step:6912 [D loss: 0.678057, acc: 56.25%] [G loss: 1.626330]\n",
      "epoch:8 step:6913 [D loss: 0.818460, acc: 35.16%] [G loss: 1.643883]\n",
      "epoch:8 step:6914 [D loss: 0.730424, acc: 43.75%] [G loss: 1.509957]\n",
      "epoch:8 step:6915 [D loss: 0.696654, acc: 54.69%] [G loss: 1.479544]\n",
      "epoch:8 step:6916 [D loss: 0.642698, acc: 67.19%] [G loss: 1.551021]\n",
      "epoch:8 step:6917 [D loss: 0.650351, acc: 71.09%] [G loss: 1.560143]\n",
      "epoch:8 step:6918 [D loss: 0.872610, acc: 28.12%] [G loss: 1.453602]\n",
      "epoch:8 step:6919 [D loss: 0.693771, acc: 55.47%] [G loss: 1.628986]\n",
      "epoch:8 step:6920 [D loss: 0.782316, acc: 35.94%] [G loss: 1.390760]\n",
      "epoch:8 step:6921 [D loss: 0.737648, acc: 48.44%] [G loss: 1.467746]\n",
      "epoch:8 step:6922 [D loss: 0.736503, acc: 45.31%] [G loss: 1.531204]\n",
      "epoch:8 step:6923 [D loss: 0.695597, acc: 53.12%] [G loss: 1.533923]\n",
      "epoch:8 step:6924 [D loss: 0.726372, acc: 44.53%] [G loss: 1.489958]\n",
      "epoch:8 step:6925 [D loss: 0.699955, acc: 47.66%] [G loss: 1.601258]\n",
      "epoch:8 step:6926 [D loss: 0.687038, acc: 54.69%] [G loss: 1.587084]\n",
      "epoch:8 step:6927 [D loss: 0.676454, acc: 60.94%] [G loss: 1.796598]\n",
      "epoch:8 step:6928 [D loss: 0.696510, acc: 48.44%] [G loss: 1.614029]\n",
      "epoch:8 step:6929 [D loss: 0.637627, acc: 65.62%] [G loss: 1.681878]\n",
      "epoch:8 step:6930 [D loss: 0.707751, acc: 52.34%] [G loss: 1.456031]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6931 [D loss: 0.689009, acc: 56.25%] [G loss: 1.588364]\n",
      "epoch:8 step:6932 [D loss: 0.703749, acc: 51.56%] [G loss: 1.554414]\n",
      "epoch:8 step:6933 [D loss: 0.696186, acc: 52.34%] [G loss: 1.689573]\n",
      "epoch:8 step:6934 [D loss: 0.675081, acc: 61.72%] [G loss: 1.522695]\n",
      "epoch:8 step:6935 [D loss: 0.633490, acc: 70.31%] [G loss: 1.537816]\n",
      "epoch:8 step:6936 [D loss: 0.611312, acc: 71.09%] [G loss: 1.484787]\n",
      "epoch:8 step:6937 [D loss: 0.744528, acc: 42.19%] [G loss: 1.501999]\n",
      "epoch:8 step:6938 [D loss: 0.764924, acc: 40.62%] [G loss: 1.420789]\n",
      "epoch:8 step:6939 [D loss: 0.662697, acc: 64.06%] [G loss: 1.601285]\n",
      "epoch:8 step:6940 [D loss: 0.738298, acc: 44.53%] [G loss: 1.463628]\n",
      "epoch:8 step:6941 [D loss: 0.665936, acc: 60.94%] [G loss: 1.520733]\n",
      "epoch:8 step:6942 [D loss: 0.685822, acc: 57.03%] [G loss: 1.614495]\n",
      "epoch:8 step:6943 [D loss: 0.707337, acc: 53.12%] [G loss: 1.522314]\n",
      "epoch:8 step:6944 [D loss: 0.703328, acc: 51.56%] [G loss: 1.555554]\n",
      "epoch:8 step:6945 [D loss: 0.701123, acc: 49.22%] [G loss: 1.512635]\n",
      "epoch:8 step:6946 [D loss: 0.704588, acc: 48.44%] [G loss: 1.458784]\n",
      "epoch:8 step:6947 [D loss: 0.672646, acc: 59.38%] [G loss: 1.570664]\n",
      "epoch:8 step:6948 [D loss: 0.704005, acc: 53.12%] [G loss: 1.510976]\n",
      "epoch:8 step:6949 [D loss: 0.639585, acc: 63.28%] [G loss: 1.599693]\n",
      "epoch:8 step:6950 [D loss: 0.601775, acc: 64.06%] [G loss: 1.542683]\n",
      "epoch:8 step:6951 [D loss: 0.729991, acc: 43.75%] [G loss: 1.592740]\n",
      "epoch:8 step:6952 [D loss: 0.889640, acc: 28.12%] [G loss: 1.410993]\n",
      "epoch:8 step:6953 [D loss: 0.684741, acc: 56.25%] [G loss: 1.582422]\n",
      "epoch:8 step:6954 [D loss: 0.597894, acc: 78.12%] [G loss: 1.619379]\n",
      "epoch:8 step:6955 [D loss: 0.751176, acc: 47.66%] [G loss: 1.468797]\n",
      "epoch:8 step:6956 [D loss: 0.784635, acc: 36.72%] [G loss: 1.403702]\n",
      "epoch:8 step:6957 [D loss: 0.706896, acc: 57.03%] [G loss: 1.494013]\n",
      "epoch:8 step:6958 [D loss: 0.706959, acc: 54.69%] [G loss: 1.558774]\n",
      "epoch:8 step:6959 [D loss: 0.734232, acc: 46.09%] [G loss: 1.523954]\n",
      "epoch:8 step:6960 [D loss: 0.648931, acc: 62.50%] [G loss: 1.529163]\n",
      "epoch:8 step:6961 [D loss: 0.604729, acc: 67.97%] [G loss: 1.779363]\n",
      "epoch:8 step:6962 [D loss: 0.724400, acc: 50.00%] [G loss: 1.580520]\n",
      "epoch:8 step:6963 [D loss: 0.839968, acc: 30.47%] [G loss: 1.452762]\n",
      "epoch:8 step:6964 [D loss: 0.695802, acc: 54.69%] [G loss: 1.613414]\n",
      "epoch:8 step:6965 [D loss: 0.626505, acc: 69.53%] [G loss: 1.646935]\n",
      "epoch:8 step:6966 [D loss: 0.690528, acc: 53.91%] [G loss: 1.576262]\n",
      "epoch:8 step:6967 [D loss: 0.640267, acc: 61.72%] [G loss: 1.698154]\n",
      "epoch:8 step:6968 [D loss: 0.787198, acc: 39.84%] [G loss: 1.455808]\n",
      "epoch:8 step:6969 [D loss: 0.713131, acc: 49.22%] [G loss: 1.476004]\n",
      "epoch:8 step:6970 [D loss: 0.585676, acc: 77.34%] [G loss: 1.683642]\n",
      "epoch:8 step:6971 [D loss: 0.719626, acc: 54.69%] [G loss: 1.485370]\n",
      "epoch:8 step:6972 [D loss: 0.705711, acc: 53.12%] [G loss: 1.605814]\n",
      "epoch:8 step:6973 [D loss: 0.709292, acc: 58.59%] [G loss: 1.656132]\n",
      "epoch:8 step:6974 [D loss: 0.657422, acc: 57.03%] [G loss: 1.474689]\n",
      "epoch:8 step:6975 [D loss: 0.688402, acc: 53.12%] [G loss: 1.634526]\n",
      "epoch:8 step:6976 [D loss: 0.681837, acc: 54.69%] [G loss: 1.689666]\n",
      "epoch:8 step:6977 [D loss: 0.745630, acc: 43.75%] [G loss: 1.497728]\n",
      "epoch:8 step:6978 [D loss: 0.688852, acc: 57.03%] [G loss: 1.520849]\n",
      "epoch:8 step:6979 [D loss: 0.687716, acc: 53.91%] [G loss: 1.548806]\n",
      "epoch:8 step:6980 [D loss: 0.628803, acc: 66.41%] [G loss: 1.507998]\n",
      "epoch:8 step:6981 [D loss: 0.703832, acc: 49.22%] [G loss: 1.661258]\n",
      "epoch:8 step:6982 [D loss: 0.777891, acc: 35.94%] [G loss: 1.475670]\n",
      "epoch:8 step:6983 [D loss: 0.747273, acc: 40.62%] [G loss: 1.503931]\n",
      "epoch:8 step:6984 [D loss: 0.804498, acc: 35.94%] [G loss: 1.468069]\n",
      "epoch:8 step:6985 [D loss: 0.648252, acc: 61.72%] [G loss: 1.599400]\n",
      "epoch:8 step:6986 [D loss: 0.553497, acc: 75.00%] [G loss: 1.755761]\n",
      "epoch:8 step:6987 [D loss: 0.737337, acc: 42.19%] [G loss: 1.649319]\n",
      "epoch:8 step:6988 [D loss: 0.768231, acc: 38.28%] [G loss: 1.448223]\n",
      "epoch:8 step:6989 [D loss: 0.661260, acc: 60.16%] [G loss: 1.559055]\n",
      "epoch:8 step:6990 [D loss: 0.695972, acc: 53.91%] [G loss: 1.588027]\n",
      "epoch:8 step:6991 [D loss: 0.707459, acc: 56.25%] [G loss: 1.628976]\n",
      "epoch:8 step:6992 [D loss: 0.658062, acc: 65.62%] [G loss: 1.615205]\n",
      "epoch:8 step:6993 [D loss: 0.649122, acc: 64.84%] [G loss: 1.573825]\n",
      "epoch:8 step:6994 [D loss: 0.689049, acc: 53.91%] [G loss: 1.580175]\n",
      "epoch:8 step:6995 [D loss: 0.724855, acc: 45.31%] [G loss: 1.585623]\n",
      "epoch:8 step:6996 [D loss: 0.581463, acc: 76.56%] [G loss: 1.706576]\n",
      "epoch:8 step:6997 [D loss: 0.621624, acc: 68.75%] [G loss: 1.597713]\n",
      "epoch:8 step:6998 [D loss: 0.769881, acc: 38.28%] [G loss: 1.492376]\n",
      "epoch:8 step:6999 [D loss: 0.783705, acc: 34.38%] [G loss: 1.536700]\n",
      "epoch:8 step:7000 [D loss: 0.641866, acc: 64.06%] [G loss: 1.604320]\n",
      "epoch:8 step:7001 [D loss: 0.666885, acc: 59.38%] [G loss: 1.608952]\n",
      "epoch:8 step:7002 [D loss: 0.692257, acc: 55.47%] [G loss: 1.643004]\n",
      "epoch:8 step:7003 [D loss: 0.700908, acc: 52.34%] [G loss: 1.511424]\n",
      "epoch:8 step:7004 [D loss: 0.751162, acc: 50.78%] [G loss: 1.489847]\n",
      "epoch:8 step:7005 [D loss: 0.541126, acc: 78.91%] [G loss: 1.625062]\n",
      "epoch:8 step:7006 [D loss: 0.703868, acc: 53.12%] [G loss: 1.484122]\n",
      "epoch:8 step:7007 [D loss: 0.740687, acc: 46.88%] [G loss: 1.429809]\n",
      "epoch:8 step:7008 [D loss: 0.711053, acc: 52.34%] [G loss: 1.558315]\n",
      "epoch:8 step:7009 [D loss: 0.746003, acc: 46.09%] [G loss: 1.506517]\n",
      "epoch:8 step:7010 [D loss: 0.749233, acc: 43.75%] [G loss: 1.525765]\n",
      "epoch:8 step:7011 [D loss: 0.644411, acc: 65.62%] [G loss: 1.829703]\n",
      "epoch:8 step:7012 [D loss: 0.641670, acc: 67.19%] [G loss: 1.575172]\n",
      "epoch:8 step:7013 [D loss: 0.696589, acc: 54.69%] [G loss: 1.473706]\n",
      "epoch:8 step:7014 [D loss: 0.627727, acc: 66.41%] [G loss: 1.663445]\n",
      "epoch:8 step:7015 [D loss: 0.774090, acc: 36.72%] [G loss: 1.533463]\n",
      "epoch:8 step:7016 [D loss: 0.778209, acc: 37.50%] [G loss: 1.591094]\n",
      "epoch:8 step:7017 [D loss: 0.624489, acc: 64.06%] [G loss: 1.660171]\n",
      "epoch:8 step:7018 [D loss: 0.639697, acc: 62.50%] [G loss: 1.657660]\n",
      "epoch:8 step:7019 [D loss: 0.859582, acc: 24.22%] [G loss: 1.435466]\n",
      "epoch:8 step:7020 [D loss: 0.720834, acc: 46.88%] [G loss: 1.526810]\n",
      "epoch:8 step:7021 [D loss: 0.642735, acc: 67.19%] [G loss: 1.613081]\n",
      "epoch:8 step:7022 [D loss: 0.718768, acc: 49.22%] [G loss: 1.515093]\n",
      "epoch:8 step:7023 [D loss: 0.690561, acc: 58.59%] [G loss: 1.687120]\n",
      "epoch:8 step:7024 [D loss: 0.711829, acc: 50.00%] [G loss: 1.524756]\n",
      "epoch:8 step:7025 [D loss: 0.632640, acc: 67.19%] [G loss: 1.812229]\n",
      "epoch:8 step:7026 [D loss: 0.710512, acc: 50.00%] [G loss: 1.537502]\n",
      "epoch:8 step:7027 [D loss: 0.845870, acc: 21.88%] [G loss: 1.451552]\n",
      "epoch:8 step:7028 [D loss: 0.843540, acc: 32.03%] [G loss: 1.444543]\n",
      "epoch:8 step:7029 [D loss: 0.700295, acc: 57.03%] [G loss: 1.544685]\n",
      "epoch:9 step:7030 [D loss: 0.700577, acc: 49.22%] [G loss: 1.608657]\n",
      "epoch:9 step:7031 [D loss: 0.558335, acc: 83.59%] [G loss: 1.752917]\n",
      "epoch:9 step:7032 [D loss: 0.600278, acc: 73.44%] [G loss: 1.647178]\n",
      "epoch:9 step:7033 [D loss: 0.700592, acc: 53.12%] [G loss: 1.520497]\n",
      "epoch:9 step:7034 [D loss: 0.699806, acc: 54.69%] [G loss: 1.505305]\n",
      "epoch:9 step:7035 [D loss: 0.587456, acc: 75.78%] [G loss: 1.699047]\n",
      "epoch:9 step:7036 [D loss: 0.638219, acc: 62.50%] [G loss: 1.627675]\n",
      "epoch:9 step:7037 [D loss: 0.616086, acc: 67.19%] [G loss: 1.644958]\n",
      "epoch:9 step:7038 [D loss: 0.589733, acc: 67.19%] [G loss: 1.546673]\n",
      "epoch:9 step:7039 [D loss: 0.606817, acc: 74.22%] [G loss: 1.501075]\n",
      "epoch:9 step:7040 [D loss: 0.604559, acc: 70.31%] [G loss: 1.663924]\n",
      "epoch:9 step:7041 [D loss: 0.717582, acc: 54.69%] [G loss: 1.712602]\n",
      "epoch:9 step:7042 [D loss: 0.574986, acc: 82.03%] [G loss: 1.657740]\n",
      "epoch:9 step:7043 [D loss: 0.695651, acc: 50.78%] [G loss: 1.675769]\n",
      "epoch:9 step:7044 [D loss: 0.814285, acc: 32.03%] [G loss: 1.380182]\n",
      "epoch:9 step:7045 [D loss: 0.692996, acc: 57.03%] [G loss: 1.528740]\n",
      "epoch:9 step:7046 [D loss: 0.530501, acc: 87.50%] [G loss: 1.715714]\n",
      "epoch:9 step:7047 [D loss: 0.694480, acc: 57.03%] [G loss: 1.626797]\n",
      "epoch:9 step:7048 [D loss: 0.503717, acc: 84.38%] [G loss: 1.808643]\n",
      "epoch:9 step:7049 [D loss: 0.639774, acc: 70.31%] [G loss: 1.684292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7050 [D loss: 0.654635, acc: 60.16%] [G loss: 1.564860]\n",
      "epoch:9 step:7051 [D loss: 0.684753, acc: 56.25%] [G loss: 1.600745]\n",
      "epoch:9 step:7052 [D loss: 0.726487, acc: 46.09%] [G loss: 1.603309]\n",
      "epoch:9 step:7053 [D loss: 0.764981, acc: 32.81%] [G loss: 1.563920]\n",
      "epoch:9 step:7054 [D loss: 0.528615, acc: 73.44%] [G loss: 1.581750]\n",
      "epoch:9 step:7055 [D loss: 0.664738, acc: 53.91%] [G loss: 1.544578]\n",
      "epoch:9 step:7056 [D loss: 0.667063, acc: 57.03%] [G loss: 1.584502]\n",
      "epoch:9 step:7057 [D loss: 0.802707, acc: 38.28%] [G loss: 1.558470]\n",
      "epoch:9 step:7058 [D loss: 0.575421, acc: 69.53%] [G loss: 1.503565]\n",
      "epoch:9 step:7059 [D loss: 0.643830, acc: 60.94%] [G loss: 1.637268]\n",
      "epoch:9 step:7060 [D loss: 0.805003, acc: 31.25%] [G loss: 1.396095]\n",
      "epoch:9 step:7061 [D loss: 0.775886, acc: 44.53%] [G loss: 1.621536]\n",
      "epoch:9 step:7062 [D loss: 0.684817, acc: 53.12%] [G loss: 1.693762]\n",
      "epoch:9 step:7063 [D loss: 0.705792, acc: 53.91%] [G loss: 1.574757]\n",
      "epoch:9 step:7064 [D loss: 0.647739, acc: 59.38%] [G loss: 1.528812]\n",
      "epoch:9 step:7065 [D loss: 0.755642, acc: 42.19%] [G loss: 1.634028]\n",
      "epoch:9 step:7066 [D loss: 0.585759, acc: 75.78%] [G loss: 1.720320]\n",
      "epoch:9 step:7067 [D loss: 0.675518, acc: 53.12%] [G loss: 1.633957]\n",
      "epoch:9 step:7068 [D loss: 0.585834, acc: 75.00%] [G loss: 1.921461]\n",
      "epoch:9 step:7069 [D loss: 0.739096, acc: 47.66%] [G loss: 1.480750]\n",
      "epoch:9 step:7070 [D loss: 0.719173, acc: 50.00%] [G loss: 1.814568]\n",
      "epoch:9 step:7071 [D loss: 0.604777, acc: 71.09%] [G loss: 1.755741]\n",
      "epoch:9 step:7072 [D loss: 0.738028, acc: 43.75%] [G loss: 1.543696]\n",
      "epoch:9 step:7073 [D loss: 0.798344, acc: 29.69%] [G loss: 1.509793]\n",
      "epoch:9 step:7074 [D loss: 0.786143, acc: 36.72%] [G loss: 1.648039]\n",
      "epoch:9 step:7075 [D loss: 0.729565, acc: 51.56%] [G loss: 1.563648]\n",
      "epoch:9 step:7076 [D loss: 0.679944, acc: 57.81%] [G loss: 1.493599]\n",
      "epoch:9 step:7077 [D loss: 0.662038, acc: 62.50%] [G loss: 1.672429]\n",
      "epoch:9 step:7078 [D loss: 0.605802, acc: 75.00%] [G loss: 1.599688]\n",
      "epoch:9 step:7079 [D loss: 0.751262, acc: 45.31%] [G loss: 1.577563]\n",
      "epoch:9 step:7080 [D loss: 0.691008, acc: 57.81%] [G loss: 1.711906]\n",
      "epoch:9 step:7081 [D loss: 0.650251, acc: 63.28%] [G loss: 1.751096]\n",
      "epoch:9 step:7082 [D loss: 0.595774, acc: 75.00%] [G loss: 1.698432]\n",
      "epoch:9 step:7083 [D loss: 0.623586, acc: 69.53%] [G loss: 1.810878]\n",
      "epoch:9 step:7084 [D loss: 0.447670, acc: 88.28%] [G loss: 1.733898]\n",
      "epoch:9 step:7085 [D loss: 0.837732, acc: 26.56%] [G loss: 1.477415]\n",
      "epoch:9 step:7086 [D loss: 0.702162, acc: 49.22%] [G loss: 1.921648]\n",
      "epoch:9 step:7087 [D loss: 0.483711, acc: 89.84%] [G loss: 1.596779]\n",
      "epoch:9 step:7088 [D loss: 0.722634, acc: 50.00%] [G loss: 1.663329]\n",
      "epoch:9 step:7089 [D loss: 0.700421, acc: 55.47%] [G loss: 1.551171]\n",
      "epoch:9 step:7090 [D loss: 0.621491, acc: 62.50%] [G loss: 1.353513]\n",
      "epoch:9 step:7091 [D loss: 0.812311, acc: 28.91%] [G loss: 1.523764]\n",
      "epoch:9 step:7092 [D loss: 0.728511, acc: 50.78%] [G loss: 1.602269]\n",
      "epoch:9 step:7093 [D loss: 0.689377, acc: 54.69%] [G loss: 1.749791]\n",
      "epoch:9 step:7094 [D loss: 0.782861, acc: 32.03%] [G loss: 1.464856]\n",
      "epoch:9 step:7095 [D loss: 0.693242, acc: 53.91%] [G loss: 1.648743]\n",
      "epoch:9 step:7096 [D loss: 0.726016, acc: 49.22%] [G loss: 1.439623]\n",
      "epoch:9 step:7097 [D loss: 0.731705, acc: 47.66%] [G loss: 1.603558]\n",
      "epoch:9 step:7098 [D loss: 0.625330, acc: 71.88%] [G loss: 1.590259]\n",
      "epoch:9 step:7099 [D loss: 0.820380, acc: 34.38%] [G loss: 1.430182]\n",
      "epoch:9 step:7100 [D loss: 0.870495, acc: 26.56%] [G loss: 1.390062]\n",
      "epoch:9 step:7101 [D loss: 0.879984, acc: 19.53%] [G loss: 1.277256]\n",
      "epoch:9 step:7102 [D loss: 0.683074, acc: 54.69%] [G loss: 1.523930]\n",
      "epoch:9 step:7103 [D loss: 0.695807, acc: 53.91%] [G loss: 1.580696]\n",
      "epoch:9 step:7104 [D loss: 0.670634, acc: 57.81%] [G loss: 1.543834]\n",
      "epoch:9 step:7105 [D loss: 0.527312, acc: 78.12%] [G loss: 1.733518]\n",
      "epoch:9 step:7106 [D loss: 0.677648, acc: 62.50%] [G loss: 1.581928]\n",
      "epoch:9 step:7107 [D loss: 0.732984, acc: 46.88%] [G loss: 1.447568]\n",
      "epoch:9 step:7108 [D loss: 0.579157, acc: 77.34%] [G loss: 1.706271]\n",
      "epoch:9 step:7109 [D loss: 0.720199, acc: 46.09%] [G loss: 1.719751]\n",
      "epoch:9 step:7110 [D loss: 0.725483, acc: 45.31%] [G loss: 1.536087]\n",
      "epoch:9 step:7111 [D loss: 0.693915, acc: 55.47%] [G loss: 1.569962]\n",
      "epoch:9 step:7112 [D loss: 0.633627, acc: 66.41%] [G loss: 1.617921]\n",
      "epoch:9 step:7113 [D loss: 0.864195, acc: 38.28%] [G loss: 1.621542]\n",
      "epoch:9 step:7114 [D loss: 0.706311, acc: 53.91%] [G loss: 1.672530]\n",
      "epoch:9 step:7115 [D loss: 0.642902, acc: 70.31%] [G loss: 1.521313]\n",
      "epoch:9 step:7116 [D loss: 0.555425, acc: 79.69%] [G loss: 1.676204]\n",
      "epoch:9 step:7117 [D loss: 0.834744, acc: 30.47%] [G loss: 1.411027]\n",
      "epoch:9 step:7118 [D loss: 0.581392, acc: 75.00%] [G loss: 1.750436]\n",
      "epoch:9 step:7119 [D loss: 0.556383, acc: 77.34%] [G loss: 1.553971]\n",
      "epoch:9 step:7120 [D loss: 0.758652, acc: 43.75%] [G loss: 1.544247]\n",
      "epoch:9 step:7121 [D loss: 0.683520, acc: 59.38%] [G loss: 1.318256]\n",
      "epoch:9 step:7122 [D loss: 0.760420, acc: 39.06%] [G loss: 1.449204]\n",
      "epoch:9 step:7123 [D loss: 0.773799, acc: 42.97%] [G loss: 1.407053]\n",
      "epoch:9 step:7124 [D loss: 0.632925, acc: 64.84%] [G loss: 1.573697]\n",
      "epoch:9 step:7125 [D loss: 0.694605, acc: 53.12%] [G loss: 1.668832]\n",
      "epoch:9 step:7126 [D loss: 0.722545, acc: 50.00%] [G loss: 1.563258]\n",
      "epoch:9 step:7127 [D loss: 0.692134, acc: 46.09%] [G loss: 1.474976]\n",
      "epoch:9 step:7128 [D loss: 0.625642, acc: 64.06%] [G loss: 1.561556]\n",
      "epoch:9 step:7129 [D loss: 0.699873, acc: 50.78%] [G loss: 1.636841]\n",
      "epoch:9 step:7130 [D loss: 0.687731, acc: 54.69%] [G loss: 1.732860]\n",
      "epoch:9 step:7131 [D loss: 0.635127, acc: 67.97%] [G loss: 1.620861]\n",
      "epoch:9 step:7132 [D loss: 0.777063, acc: 36.72%] [G loss: 1.506852]\n",
      "epoch:9 step:7133 [D loss: 0.781960, acc: 42.97%] [G loss: 1.502161]\n",
      "epoch:9 step:7134 [D loss: 0.677971, acc: 60.16%] [G loss: 1.695301]\n",
      "epoch:9 step:7135 [D loss: 0.788576, acc: 35.94%] [G loss: 1.495515]\n",
      "epoch:9 step:7136 [D loss: 0.676546, acc: 57.81%] [G loss: 1.740028]\n",
      "epoch:9 step:7137 [D loss: 0.660585, acc: 60.16%] [G loss: 1.615235]\n",
      "epoch:9 step:7138 [D loss: 0.566479, acc: 72.66%] [G loss: 1.613974]\n",
      "epoch:9 step:7139 [D loss: 0.653992, acc: 61.72%] [G loss: 1.695348]\n",
      "epoch:9 step:7140 [D loss: 0.780486, acc: 36.72%] [G loss: 1.545579]\n",
      "epoch:9 step:7141 [D loss: 0.791115, acc: 36.72%] [G loss: 1.417086]\n",
      "epoch:9 step:7142 [D loss: 0.807860, acc: 30.47%] [G loss: 1.426431]\n",
      "epoch:9 step:7143 [D loss: 0.659107, acc: 57.03%] [G loss: 1.631194]\n",
      "epoch:9 step:7144 [D loss: 0.671073, acc: 56.25%] [G loss: 1.490783]\n",
      "epoch:9 step:7145 [D loss: 0.682966, acc: 55.47%] [G loss: 1.511708]\n",
      "epoch:9 step:7146 [D loss: 0.758250, acc: 38.28%] [G loss: 1.625025]\n",
      "epoch:9 step:7147 [D loss: 0.688076, acc: 55.47%] [G loss: 1.561169]\n",
      "epoch:9 step:7148 [D loss: 0.708851, acc: 56.25%] [G loss: 1.524035]\n",
      "epoch:9 step:7149 [D loss: 0.711340, acc: 52.34%] [G loss: 1.574674]\n",
      "epoch:9 step:7150 [D loss: 0.692344, acc: 60.94%] [G loss: 1.635458]\n",
      "epoch:9 step:7151 [D loss: 0.682767, acc: 51.56%] [G loss: 1.462362]\n",
      "epoch:9 step:7152 [D loss: 0.648093, acc: 65.62%] [G loss: 1.518134]\n",
      "epoch:9 step:7153 [D loss: 0.717199, acc: 50.78%] [G loss: 1.565971]\n",
      "epoch:9 step:7154 [D loss: 0.714371, acc: 50.78%] [G loss: 1.552164]\n",
      "epoch:9 step:7155 [D loss: 0.806180, acc: 35.94%] [G loss: 1.396662]\n",
      "epoch:9 step:7156 [D loss: 0.705707, acc: 58.59%] [G loss: 1.522153]\n",
      "epoch:9 step:7157 [D loss: 0.635692, acc: 66.41%] [G loss: 1.694068]\n",
      "epoch:9 step:7158 [D loss: 0.625877, acc: 65.62%] [G loss: 1.805448]\n",
      "epoch:9 step:7159 [D loss: 0.831012, acc: 35.16%] [G loss: 1.391023]\n",
      "epoch:9 step:7160 [D loss: 0.721695, acc: 50.78%] [G loss: 1.679678]\n",
      "epoch:9 step:7161 [D loss: 0.799170, acc: 40.62%] [G loss: 1.561405]\n",
      "epoch:9 step:7162 [D loss: 0.654350, acc: 69.53%] [G loss: 1.738310]\n",
      "epoch:9 step:7163 [D loss: 0.478117, acc: 85.16%] [G loss: 1.889289]\n",
      "epoch:9 step:7164 [D loss: 0.728336, acc: 50.78%] [G loss: 1.530751]\n",
      "epoch:9 step:7165 [D loss: 0.654266, acc: 60.16%] [G loss: 1.629904]\n",
      "epoch:9 step:7166 [D loss: 0.670840, acc: 57.81%] [G loss: 1.624528]\n",
      "epoch:9 step:7167 [D loss: 0.673766, acc: 58.59%] [G loss: 1.615917]\n",
      "epoch:9 step:7168 [D loss: 0.684146, acc: 54.69%] [G loss: 1.674891]\n",
      "epoch:9 step:7169 [D loss: 0.746185, acc: 42.19%] [G loss: 1.552691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7170 [D loss: 0.669337, acc: 57.81%] [G loss: 1.733094]\n",
      "epoch:9 step:7171 [D loss: 0.689985, acc: 59.38%] [G loss: 1.611444]\n",
      "epoch:9 step:7172 [D loss: 0.797863, acc: 38.28%] [G loss: 1.703864]\n",
      "epoch:9 step:7173 [D loss: 0.628383, acc: 71.88%] [G loss: 1.674918]\n",
      "epoch:9 step:7174 [D loss: 0.735012, acc: 47.66%] [G loss: 1.545647]\n",
      "epoch:9 step:7175 [D loss: 0.662138, acc: 64.06%] [G loss: 1.660442]\n",
      "epoch:9 step:7176 [D loss: 0.595003, acc: 78.12%] [G loss: 1.934935]\n",
      "epoch:9 step:7177 [D loss: 0.678261, acc: 53.91%] [G loss: 1.438979]\n",
      "epoch:9 step:7178 [D loss: 0.786056, acc: 33.59%] [G loss: 1.433227]\n",
      "epoch:9 step:7179 [D loss: 0.690303, acc: 57.81%] [G loss: 1.565572]\n",
      "epoch:9 step:7180 [D loss: 0.782532, acc: 36.72%] [G loss: 1.486106]\n",
      "epoch:9 step:7181 [D loss: 0.680606, acc: 57.03%] [G loss: 1.510256]\n",
      "epoch:9 step:7182 [D loss: 0.718216, acc: 52.34%] [G loss: 1.808444]\n",
      "epoch:9 step:7183 [D loss: 0.518964, acc: 79.69%] [G loss: 1.631625]\n",
      "epoch:9 step:7184 [D loss: 0.610670, acc: 65.62%] [G loss: 2.043350]\n",
      "epoch:9 step:7185 [D loss: 0.695187, acc: 53.12%] [G loss: 1.660641]\n",
      "epoch:9 step:7186 [D loss: 0.581061, acc: 74.22%] [G loss: 1.516994]\n",
      "epoch:9 step:7187 [D loss: 0.606232, acc: 67.19%] [G loss: 1.574742]\n",
      "epoch:9 step:7188 [D loss: 0.656640, acc: 64.84%] [G loss: 1.832393]\n",
      "epoch:9 step:7189 [D loss: 1.050899, acc: 11.72%] [G loss: 1.191815]\n",
      "epoch:9 step:7190 [D loss: 0.711748, acc: 49.22%] [G loss: 1.514282]\n",
      "epoch:9 step:7191 [D loss: 0.618904, acc: 68.75%] [G loss: 1.679210]\n",
      "epoch:9 step:7192 [D loss: 0.744755, acc: 40.62%] [G loss: 1.586627]\n",
      "epoch:9 step:7193 [D loss: 0.660415, acc: 55.47%] [G loss: 1.618603]\n",
      "epoch:9 step:7194 [D loss: 0.691767, acc: 55.47%] [G loss: 1.681306]\n",
      "epoch:9 step:7195 [D loss: 0.733933, acc: 57.03%] [G loss: 1.457280]\n",
      "epoch:9 step:7196 [D loss: 0.580102, acc: 75.00%] [G loss: 1.706903]\n",
      "epoch:9 step:7197 [D loss: 0.601507, acc: 72.66%] [G loss: 1.708853]\n",
      "epoch:9 step:7198 [D loss: 0.769285, acc: 42.19%] [G loss: 1.608228]\n",
      "epoch:9 step:7199 [D loss: 0.646741, acc: 64.06%] [G loss: 1.679199]\n",
      "epoch:9 step:7200 [D loss: 0.733371, acc: 42.19%] [G loss: 1.544110]\n",
      "epoch:9 step:7201 [D loss: 0.620023, acc: 67.19%] [G loss: 1.690032]\n",
      "epoch:9 step:7202 [D loss: 0.668267, acc: 57.03%] [G loss: 1.615499]\n",
      "epoch:9 step:7203 [D loss: 0.823129, acc: 34.38%] [G loss: 1.463501]\n",
      "epoch:9 step:7204 [D loss: 0.699928, acc: 50.00%] [G loss: 1.585944]\n",
      "epoch:9 step:7205 [D loss: 0.752571, acc: 38.28%] [G loss: 1.593288]\n",
      "epoch:9 step:7206 [D loss: 0.543155, acc: 81.25%] [G loss: 1.677019]\n",
      "epoch:9 step:7207 [D loss: 0.632786, acc: 64.06%] [G loss: 1.658550]\n",
      "epoch:9 step:7208 [D loss: 0.671466, acc: 58.59%] [G loss: 1.754910]\n",
      "epoch:9 step:7209 [D loss: 0.743905, acc: 48.44%] [G loss: 1.602558]\n",
      "epoch:9 step:7210 [D loss: 0.762980, acc: 46.88%] [G loss: 1.977306]\n",
      "epoch:9 step:7211 [D loss: 0.664524, acc: 62.50%] [G loss: 1.716438]\n",
      "epoch:9 step:7212 [D loss: 0.663239, acc: 58.59%] [G loss: 1.607433]\n",
      "epoch:9 step:7213 [D loss: 0.651377, acc: 65.62%] [G loss: 1.644888]\n",
      "epoch:9 step:7214 [D loss: 0.646096, acc: 67.97%] [G loss: 1.622985]\n",
      "epoch:9 step:7215 [D loss: 0.682873, acc: 57.81%] [G loss: 1.682520]\n",
      "epoch:9 step:7216 [D loss: 0.529745, acc: 71.88%] [G loss: 1.937141]\n",
      "epoch:9 step:7217 [D loss: 0.607666, acc: 74.22%] [G loss: 1.858682]\n",
      "epoch:9 step:7218 [D loss: 0.677048, acc: 59.38%] [G loss: 1.722891]\n",
      "epoch:9 step:7219 [D loss: 0.753131, acc: 47.66%] [G loss: 1.558461]\n",
      "epoch:9 step:7220 [D loss: 0.512487, acc: 87.50%] [G loss: 1.872611]\n",
      "epoch:9 step:7221 [D loss: 0.553519, acc: 74.22%] [G loss: 1.699883]\n",
      "epoch:9 step:7222 [D loss: 0.592363, acc: 70.31%] [G loss: 1.630556]\n",
      "epoch:9 step:7223 [D loss: 0.702573, acc: 51.56%] [G loss: 1.650419]\n",
      "epoch:9 step:7224 [D loss: 0.729325, acc: 51.56%] [G loss: 1.594669]\n",
      "epoch:9 step:7225 [D loss: 0.940092, acc: 24.22%] [G loss: 1.361223]\n",
      "epoch:9 step:7226 [D loss: 0.692443, acc: 53.91%] [G loss: 1.580602]\n",
      "epoch:9 step:7227 [D loss: 0.693130, acc: 55.47%] [G loss: 1.606524]\n",
      "epoch:9 step:7228 [D loss: 0.592332, acc: 63.28%] [G loss: 1.661597]\n",
      "epoch:9 step:7229 [D loss: 0.548411, acc: 83.59%] [G loss: 1.693541]\n",
      "epoch:9 step:7230 [D loss: 0.530961, acc: 79.69%] [G loss: 2.053396]\n",
      "epoch:9 step:7231 [D loss: 0.884661, acc: 19.53%] [G loss: 1.648390]\n",
      "epoch:9 step:7232 [D loss: 0.647806, acc: 60.94%] [G loss: 1.687013]\n",
      "epoch:9 step:7233 [D loss: 0.704640, acc: 49.22%] [G loss: 1.671582]\n",
      "epoch:9 step:7234 [D loss: 0.924989, acc: 25.78%] [G loss: 1.422020]\n",
      "epoch:9 step:7235 [D loss: 0.737771, acc: 46.88%] [G loss: 1.352532]\n",
      "epoch:9 step:7236 [D loss: 0.717620, acc: 47.66%] [G loss: 1.511090]\n",
      "epoch:9 step:7237 [D loss: 0.698599, acc: 53.12%] [G loss: 1.520947]\n",
      "epoch:9 step:7238 [D loss: 0.671249, acc: 60.94%] [G loss: 1.517310]\n",
      "epoch:9 step:7239 [D loss: 0.693685, acc: 50.00%] [G loss: 1.623182]\n",
      "epoch:9 step:7240 [D loss: 0.640321, acc: 61.72%] [G loss: 1.714472]\n",
      "epoch:9 step:7241 [D loss: 0.738478, acc: 46.88%] [G loss: 1.560060]\n",
      "epoch:9 step:7242 [D loss: 0.797141, acc: 34.38%] [G loss: 1.541205]\n",
      "epoch:9 step:7243 [D loss: 0.643258, acc: 64.84%] [G loss: 1.482062]\n",
      "epoch:9 step:7244 [D loss: 0.626438, acc: 64.84%] [G loss: 1.759380]\n",
      "epoch:9 step:7245 [D loss: 0.678419, acc: 63.28%] [G loss: 1.681567]\n",
      "epoch:9 step:7246 [D loss: 0.845441, acc: 28.12%] [G loss: 1.407714]\n",
      "epoch:9 step:7247 [D loss: 0.561590, acc: 76.56%] [G loss: 1.984327]\n",
      "epoch:9 step:7248 [D loss: 0.680364, acc: 56.25%] [G loss: 1.725245]\n",
      "epoch:9 step:7249 [D loss: 0.689023, acc: 53.91%] [G loss: 1.624192]\n",
      "epoch:9 step:7250 [D loss: 0.694104, acc: 57.03%] [G loss: 1.630859]\n",
      "epoch:9 step:7251 [D loss: 0.723696, acc: 53.12%] [G loss: 1.571159]\n",
      "epoch:9 step:7252 [D loss: 0.648365, acc: 64.06%] [G loss: 1.834748]\n",
      "epoch:9 step:7253 [D loss: 0.733084, acc: 50.00%] [G loss: 1.748990]\n",
      "epoch:9 step:7254 [D loss: 0.675839, acc: 53.91%] [G loss: 1.859123]\n",
      "epoch:9 step:7255 [D loss: 0.813950, acc: 35.16%] [G loss: 1.559009]\n",
      "epoch:9 step:7256 [D loss: 0.705466, acc: 52.34%] [G loss: 1.635185]\n",
      "epoch:9 step:7257 [D loss: 0.616816, acc: 66.41%] [G loss: 1.664680]\n",
      "epoch:9 step:7258 [D loss: 0.684762, acc: 60.16%] [G loss: 1.622002]\n",
      "epoch:9 step:7259 [D loss: 0.698720, acc: 53.12%] [G loss: 1.582526]\n",
      "epoch:9 step:7260 [D loss: 0.642512, acc: 64.06%] [G loss: 1.563100]\n",
      "epoch:9 step:7261 [D loss: 0.778351, acc: 40.62%] [G loss: 1.523699]\n",
      "epoch:9 step:7262 [D loss: 0.554245, acc: 76.56%] [G loss: 1.849702]\n",
      "epoch:9 step:7263 [D loss: 0.766912, acc: 39.84%] [G loss: 1.531175]\n",
      "epoch:9 step:7264 [D loss: 0.733582, acc: 47.66%] [G loss: 1.495650]\n",
      "epoch:9 step:7265 [D loss: 0.925161, acc: 30.47%] [G loss: 1.490186]\n",
      "epoch:9 step:7266 [D loss: 0.568311, acc: 78.91%] [G loss: 1.870363]\n",
      "epoch:9 step:7267 [D loss: 0.707861, acc: 53.12%] [G loss: 1.711097]\n",
      "epoch:9 step:7268 [D loss: 0.611153, acc: 64.84%] [G loss: 1.736519]\n",
      "epoch:9 step:7269 [D loss: 0.707669, acc: 51.56%] [G loss: 1.849167]\n",
      "epoch:9 step:7270 [D loss: 0.584029, acc: 75.00%] [G loss: 1.646480]\n",
      "epoch:9 step:7271 [D loss: 0.640463, acc: 63.28%] [G loss: 1.558330]\n",
      "epoch:9 step:7272 [D loss: 0.599098, acc: 70.31%] [G loss: 1.724916]\n",
      "epoch:9 step:7273 [D loss: 0.641316, acc: 60.94%] [G loss: 1.602556]\n",
      "epoch:9 step:7274 [D loss: 0.675763, acc: 60.16%] [G loss: 1.595882]\n",
      "epoch:9 step:7275 [D loss: 0.564672, acc: 77.34%] [G loss: 1.825497]\n",
      "epoch:9 step:7276 [D loss: 0.707737, acc: 51.56%] [G loss: 1.757418]\n",
      "epoch:9 step:7277 [D loss: 0.700719, acc: 50.78%] [G loss: 1.671762]\n",
      "epoch:9 step:7278 [D loss: 0.711555, acc: 53.12%] [G loss: 1.658562]\n",
      "epoch:9 step:7279 [D loss: 0.745229, acc: 49.22%] [G loss: 1.617808]\n",
      "epoch:9 step:7280 [D loss: 0.640703, acc: 59.38%] [G loss: 1.575683]\n",
      "epoch:9 step:7281 [D loss: 0.565159, acc: 82.03%] [G loss: 1.701380]\n",
      "epoch:9 step:7282 [D loss: 0.645641, acc: 58.59%] [G loss: 1.624787]\n",
      "epoch:9 step:7283 [D loss: 0.786821, acc: 36.72%] [G loss: 1.535323]\n",
      "epoch:9 step:7284 [D loss: 0.753811, acc: 37.50%] [G loss: 1.588472]\n",
      "epoch:9 step:7285 [D loss: 0.692490, acc: 60.16%] [G loss: 1.981778]\n",
      "epoch:9 step:7286 [D loss: 0.702050, acc: 58.59%] [G loss: 1.487385]\n",
      "epoch:9 step:7287 [D loss: 0.702907, acc: 55.47%] [G loss: 1.587515]\n",
      "epoch:9 step:7288 [D loss: 0.730686, acc: 45.31%] [G loss: 1.556180]\n",
      "epoch:9 step:7289 [D loss: 0.672093, acc: 55.47%] [G loss: 1.745870]\n",
      "epoch:9 step:7290 [D loss: 0.626997, acc: 63.28%] [G loss: 1.714185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7291 [D loss: 0.529008, acc: 74.22%] [G loss: 1.774103]\n",
      "epoch:9 step:7292 [D loss: 0.802440, acc: 35.16%] [G loss: 1.570576]\n",
      "epoch:9 step:7293 [D loss: 0.694119, acc: 52.34%] [G loss: 1.639505]\n",
      "epoch:9 step:7294 [D loss: 0.605987, acc: 72.66%] [G loss: 1.719656]\n",
      "epoch:9 step:7295 [D loss: 0.810851, acc: 41.41%] [G loss: 1.566460]\n",
      "epoch:9 step:7296 [D loss: 1.091302, acc: 25.00%] [G loss: 1.263956]\n",
      "epoch:9 step:7297 [D loss: 0.728383, acc: 43.75%] [G loss: 1.531993]\n",
      "epoch:9 step:7298 [D loss: 0.810090, acc: 34.38%] [G loss: 1.512914]\n",
      "epoch:9 step:7299 [D loss: 0.686065, acc: 57.81%] [G loss: 1.721576]\n",
      "epoch:9 step:7300 [D loss: 0.640110, acc: 64.06%] [G loss: 1.667784]\n",
      "epoch:9 step:7301 [D loss: 0.724309, acc: 49.22%] [G loss: 1.563748]\n",
      "epoch:9 step:7302 [D loss: 0.713108, acc: 50.00%] [G loss: 1.760477]\n",
      "epoch:9 step:7303 [D loss: 0.729331, acc: 46.09%] [G loss: 1.505140]\n",
      "epoch:9 step:7304 [D loss: 0.564394, acc: 78.12%] [G loss: 1.684498]\n",
      "epoch:9 step:7305 [D loss: 0.694866, acc: 48.44%] [G loss: 1.581967]\n",
      "epoch:9 step:7306 [D loss: 0.714154, acc: 52.34%] [G loss: 1.694150]\n",
      "epoch:9 step:7307 [D loss: 0.593432, acc: 77.34%] [G loss: 1.752291]\n",
      "epoch:9 step:7308 [D loss: 0.675860, acc: 59.38%] [G loss: 1.632674]\n",
      "epoch:9 step:7309 [D loss: 0.684461, acc: 55.47%] [G loss: 1.628749]\n",
      "epoch:9 step:7310 [D loss: 0.723494, acc: 46.09%] [G loss: 1.587398]\n",
      "epoch:9 step:7311 [D loss: 0.635734, acc: 67.19%] [G loss: 1.614963]\n",
      "epoch:9 step:7312 [D loss: 0.682047, acc: 53.91%] [G loss: 1.528253]\n",
      "epoch:9 step:7313 [D loss: 0.667521, acc: 58.59%] [G loss: 1.562134]\n",
      "epoch:9 step:7314 [D loss: 0.742229, acc: 43.75%] [G loss: 1.678519]\n",
      "epoch:9 step:7315 [D loss: 0.644522, acc: 62.50%] [G loss: 1.634784]\n",
      "epoch:9 step:7316 [D loss: 0.767369, acc: 42.97%] [G loss: 1.435940]\n",
      "epoch:9 step:7317 [D loss: 0.717867, acc: 47.66%] [G loss: 1.616902]\n",
      "epoch:9 step:7318 [D loss: 0.691514, acc: 57.03%] [G loss: 1.633465]\n",
      "epoch:9 step:7319 [D loss: 0.689777, acc: 57.03%] [G loss: 1.677148]\n",
      "epoch:9 step:7320 [D loss: 0.687712, acc: 53.12%] [G loss: 1.625249]\n",
      "epoch:9 step:7321 [D loss: 0.723093, acc: 47.66%] [G loss: 1.609819]\n",
      "epoch:9 step:7322 [D loss: 0.777695, acc: 41.41%] [G loss: 1.540464]\n",
      "epoch:9 step:7323 [D loss: 0.691484, acc: 53.12%] [G loss: 1.638862]\n",
      "epoch:9 step:7324 [D loss: 0.666217, acc: 60.16%] [G loss: 1.568405]\n",
      "epoch:9 step:7325 [D loss: 0.699805, acc: 53.12%] [G loss: 1.585779]\n",
      "epoch:9 step:7326 [D loss: 0.718332, acc: 49.22%] [G loss: 1.477726]\n",
      "epoch:9 step:7327 [D loss: 0.624298, acc: 68.75%] [G loss: 1.790740]\n",
      "epoch:9 step:7328 [D loss: 0.639046, acc: 64.84%] [G loss: 1.696356]\n",
      "epoch:9 step:7329 [D loss: 0.778824, acc: 35.94%] [G loss: 1.588977]\n",
      "epoch:9 step:7330 [D loss: 0.803967, acc: 35.16%] [G loss: 1.525272]\n",
      "epoch:9 step:7331 [D loss: 0.567135, acc: 78.12%] [G loss: 1.695304]\n",
      "epoch:9 step:7332 [D loss: 0.625017, acc: 65.62%] [G loss: 1.884782]\n",
      "epoch:9 step:7333 [D loss: 0.605586, acc: 70.31%] [G loss: 1.779796]\n",
      "epoch:9 step:7334 [D loss: 0.714398, acc: 49.22%] [G loss: 1.690427]\n",
      "epoch:9 step:7335 [D loss: 0.638070, acc: 63.28%] [G loss: 1.665298]\n",
      "epoch:9 step:7336 [D loss: 0.750128, acc: 46.09%] [G loss: 1.648336]\n",
      "epoch:9 step:7337 [D loss: 0.505996, acc: 86.72%] [G loss: 1.902618]\n",
      "epoch:9 step:7338 [D loss: 0.663925, acc: 62.50%] [G loss: 1.635322]\n",
      "epoch:9 step:7339 [D loss: 0.725128, acc: 46.88%] [G loss: 1.539331]\n",
      "epoch:9 step:7340 [D loss: 0.845290, acc: 28.91%] [G loss: 1.547921]\n",
      "epoch:9 step:7341 [D loss: 0.754162, acc: 50.78%] [G loss: 1.546525]\n",
      "epoch:9 step:7342 [D loss: 0.676323, acc: 56.25%] [G loss: 1.654963]\n",
      "epoch:9 step:7343 [D loss: 0.740967, acc: 44.53%] [G loss: 1.618844]\n",
      "epoch:9 step:7344 [D loss: 0.762277, acc: 46.09%] [G loss: 1.602407]\n",
      "epoch:9 step:7345 [D loss: 0.687622, acc: 52.34%] [G loss: 1.621613]\n",
      "epoch:9 step:7346 [D loss: 0.664617, acc: 60.94%] [G loss: 1.867917]\n",
      "epoch:9 step:7347 [D loss: 0.688993, acc: 56.25%] [G loss: 1.729157]\n",
      "epoch:9 step:7348 [D loss: 0.605840, acc: 67.19%] [G loss: 1.776797]\n",
      "epoch:9 step:7349 [D loss: 0.704782, acc: 50.78%] [G loss: 1.680639]\n",
      "epoch:9 step:7350 [D loss: 0.735997, acc: 46.09%] [G loss: 1.658905]\n",
      "epoch:9 step:7351 [D loss: 0.714182, acc: 50.78%] [G loss: 1.566849]\n",
      "epoch:9 step:7352 [D loss: 0.628267, acc: 70.31%] [G loss: 1.782296]\n",
      "epoch:9 step:7353 [D loss: 0.687951, acc: 55.47%] [G loss: 1.857365]\n",
      "epoch:9 step:7354 [D loss: 0.685902, acc: 53.12%] [G loss: 1.662646]\n",
      "epoch:9 step:7355 [D loss: 0.620605, acc: 71.09%] [G loss: 1.722972]\n",
      "epoch:9 step:7356 [D loss: 0.639009, acc: 63.28%] [G loss: 2.076649]\n",
      "epoch:9 step:7357 [D loss: 0.666479, acc: 53.91%] [G loss: 1.757855]\n",
      "epoch:9 step:7358 [D loss: 0.643631, acc: 67.97%] [G loss: 1.760366]\n",
      "epoch:9 step:7359 [D loss: 0.717545, acc: 50.78%] [G loss: 1.614426]\n",
      "epoch:9 step:7360 [D loss: 0.684719, acc: 57.03%] [G loss: 1.769254]\n",
      "epoch:9 step:7361 [D loss: 0.612818, acc: 72.66%] [G loss: 1.746546]\n",
      "epoch:9 step:7362 [D loss: 0.573443, acc: 70.31%] [G loss: 1.851137]\n",
      "epoch:9 step:7363 [D loss: 0.644251, acc: 64.06%] [G loss: 1.764870]\n",
      "epoch:9 step:7364 [D loss: 0.734770, acc: 50.78%] [G loss: 1.723395]\n",
      "epoch:9 step:7365 [D loss: 0.788715, acc: 39.06%] [G loss: 1.499768]\n",
      "epoch:9 step:7366 [D loss: 0.681162, acc: 64.84%] [G loss: 1.605853]\n",
      "epoch:9 step:7367 [D loss: 0.686450, acc: 50.78%] [G loss: 1.792732]\n",
      "epoch:9 step:7368 [D loss: 0.732368, acc: 47.66%] [G loss: 1.654862]\n",
      "epoch:9 step:7369 [D loss: 0.654745, acc: 56.25%] [G loss: 1.794877]\n",
      "epoch:9 step:7370 [D loss: 0.701380, acc: 54.69%] [G loss: 1.582599]\n",
      "epoch:9 step:7371 [D loss: 0.638534, acc: 65.62%] [G loss: 1.697622]\n",
      "epoch:9 step:7372 [D loss: 0.752169, acc: 46.88%] [G loss: 1.623181]\n",
      "epoch:9 step:7373 [D loss: 0.653739, acc: 59.38%] [G loss: 1.716039]\n",
      "epoch:9 step:7374 [D loss: 0.693926, acc: 53.91%] [G loss: 1.705411]\n",
      "epoch:9 step:7375 [D loss: 0.609639, acc: 71.88%] [G loss: 1.659799]\n",
      "epoch:9 step:7376 [D loss: 0.638694, acc: 66.41%] [G loss: 1.926666]\n",
      "epoch:9 step:7377 [D loss: 0.751749, acc: 53.12%] [G loss: 1.545100]\n",
      "epoch:9 step:7378 [D loss: 0.697901, acc: 52.34%] [G loss: 1.926553]\n",
      "epoch:9 step:7379 [D loss: 0.627417, acc: 67.97%] [G loss: 1.746470]\n",
      "epoch:9 step:7380 [D loss: 0.800952, acc: 38.28%] [G loss: 1.417549]\n",
      "epoch:9 step:7381 [D loss: 0.635482, acc: 61.72%] [G loss: 1.871780]\n",
      "epoch:9 step:7382 [D loss: 0.752895, acc: 42.97%] [G loss: 1.612613]\n",
      "epoch:9 step:7383 [D loss: 0.672833, acc: 60.94%] [G loss: 1.524747]\n",
      "epoch:9 step:7384 [D loss: 0.631008, acc: 68.75%] [G loss: 1.472931]\n",
      "epoch:9 step:7385 [D loss: 0.615115, acc: 61.72%] [G loss: 1.834516]\n",
      "epoch:9 step:7386 [D loss: 0.663412, acc: 63.28%] [G loss: 1.985970]\n",
      "epoch:9 step:7387 [D loss: 0.582206, acc: 76.56%] [G loss: 1.699860]\n",
      "epoch:9 step:7388 [D loss: 0.476298, acc: 77.34%] [G loss: 1.927885]\n",
      "epoch:9 step:7389 [D loss: 0.733556, acc: 52.34%] [G loss: 1.733512]\n",
      "epoch:9 step:7390 [D loss: 0.964796, acc: 24.22%] [G loss: 1.362900]\n",
      "epoch:9 step:7391 [D loss: 0.738445, acc: 53.12%] [G loss: 1.554318]\n",
      "epoch:9 step:7392 [D loss: 0.636376, acc: 64.06%] [G loss: 1.880578]\n",
      "epoch:9 step:7393 [D loss: 0.572042, acc: 72.66%] [G loss: 1.705536]\n",
      "epoch:9 step:7394 [D loss: 0.662492, acc: 60.16%] [G loss: 1.582540]\n",
      "epoch:9 step:7395 [D loss: 0.693919, acc: 52.34%] [G loss: 1.751209]\n",
      "epoch:9 step:7396 [D loss: 0.564351, acc: 76.56%] [G loss: 1.654876]\n",
      "epoch:9 step:7397 [D loss: 0.634127, acc: 67.19%] [G loss: 1.581667]\n",
      "epoch:9 step:7398 [D loss: 0.771798, acc: 40.62%] [G loss: 1.585162]\n",
      "epoch:9 step:7399 [D loss: 0.689191, acc: 57.81%] [G loss: 1.576316]\n",
      "epoch:9 step:7400 [D loss: 0.469046, acc: 85.94%] [G loss: 1.699314]\n",
      "epoch:9 step:7401 [D loss: 0.735626, acc: 47.66%] [G loss: 1.665403]\n",
      "epoch:9 step:7402 [D loss: 0.725342, acc: 46.09%] [G loss: 1.610114]\n",
      "epoch:9 step:7403 [D loss: 0.713340, acc: 49.22%] [G loss: 1.923405]\n",
      "epoch:9 step:7404 [D loss: 0.761395, acc: 46.88%] [G loss: 1.562070]\n",
      "epoch:9 step:7405 [D loss: 0.894985, acc: 28.91%] [G loss: 1.698818]\n",
      "epoch:9 step:7406 [D loss: 0.678205, acc: 58.59%] [G loss: 1.716791]\n",
      "epoch:9 step:7407 [D loss: 0.618305, acc: 73.44%] [G loss: 1.747774]\n",
      "epoch:9 step:7408 [D loss: 0.618285, acc: 62.50%] [G loss: 1.616140]\n",
      "epoch:9 step:7409 [D loss: 0.643623, acc: 60.16%] [G loss: 2.074497]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7410 [D loss: 0.638713, acc: 65.62%] [G loss: 1.816281]\n",
      "epoch:9 step:7411 [D loss: 0.488509, acc: 86.72%] [G loss: 1.776046]\n",
      "epoch:9 step:7412 [D loss: 0.762884, acc: 46.09%] [G loss: 1.576804]\n",
      "epoch:9 step:7413 [D loss: 0.702311, acc: 57.81%] [G loss: 1.589046]\n",
      "epoch:9 step:7414 [D loss: 0.547788, acc: 75.00%] [G loss: 1.672359]\n",
      "epoch:9 step:7415 [D loss: 0.582320, acc: 71.88%] [G loss: 1.647576]\n",
      "epoch:9 step:7416 [D loss: 0.761798, acc: 40.62%] [G loss: 1.311705]\n",
      "epoch:9 step:7417 [D loss: 0.584252, acc: 72.66%] [G loss: 1.620249]\n",
      "epoch:9 step:7418 [D loss: 0.492065, acc: 84.38%] [G loss: 1.606670]\n",
      "epoch:9 step:7419 [D loss: 0.669562, acc: 58.59%] [G loss: 1.547272]\n",
      "epoch:9 step:7420 [D loss: 0.611490, acc: 71.09%] [G loss: 1.710892]\n",
      "epoch:9 step:7421 [D loss: 0.726655, acc: 45.31%] [G loss: 1.370799]\n",
      "epoch:9 step:7422 [D loss: 0.752177, acc: 53.12%] [G loss: 1.230974]\n",
      "epoch:9 step:7423 [D loss: 0.621859, acc: 71.88%] [G loss: 1.586032]\n",
      "epoch:9 step:7424 [D loss: 0.830641, acc: 42.19%] [G loss: 1.610914]\n",
      "epoch:9 step:7425 [D loss: 0.749909, acc: 49.22%] [G loss: 1.615968]\n",
      "epoch:9 step:7426 [D loss: 0.624391, acc: 66.41%] [G loss: 1.630009]\n",
      "epoch:9 step:7427 [D loss: 0.965892, acc: 21.09%] [G loss: 1.358875]\n",
      "epoch:9 step:7428 [D loss: 0.783556, acc: 42.19%] [G loss: 1.624200]\n",
      "epoch:9 step:7429 [D loss: 0.696580, acc: 56.25%] [G loss: 1.710778]\n",
      "epoch:9 step:7430 [D loss: 0.717300, acc: 44.53%] [G loss: 1.805337]\n",
      "epoch:9 step:7431 [D loss: 0.592974, acc: 71.88%] [G loss: 1.677234]\n",
      "epoch:9 step:7432 [D loss: 0.660172, acc: 54.69%] [G loss: 1.630934]\n",
      "epoch:9 step:7433 [D loss: 0.648310, acc: 64.84%] [G loss: 1.612576]\n",
      "epoch:9 step:7434 [D loss: 0.525052, acc: 83.59%] [G loss: 1.842565]\n",
      "epoch:9 step:7435 [D loss: 0.731953, acc: 50.78%] [G loss: 1.817343]\n",
      "epoch:9 step:7436 [D loss: 0.778894, acc: 37.50%] [G loss: 1.420360]\n",
      "epoch:9 step:7437 [D loss: 0.760145, acc: 44.53%] [G loss: 1.529265]\n",
      "epoch:9 step:7438 [D loss: 0.621730, acc: 68.75%] [G loss: 1.701360]\n",
      "epoch:9 step:7439 [D loss: 0.589049, acc: 71.88%] [G loss: 1.661793]\n",
      "epoch:9 step:7440 [D loss: 0.718911, acc: 42.97%] [G loss: 1.751809]\n",
      "epoch:9 step:7441 [D loss: 0.571264, acc: 71.88%] [G loss: 2.004668]\n",
      "epoch:9 step:7442 [D loss: 0.508331, acc: 80.47%] [G loss: 1.709092]\n",
      "epoch:9 step:7443 [D loss: 0.623941, acc: 64.06%] [G loss: 1.784760]\n",
      "epoch:9 step:7444 [D loss: 0.627482, acc: 66.41%] [G loss: 1.638676]\n",
      "epoch:9 step:7445 [D loss: 0.674826, acc: 55.47%] [G loss: 1.591479]\n",
      "epoch:9 step:7446 [D loss: 0.419409, acc: 81.25%] [G loss: 1.717050]\n",
      "epoch:9 step:7447 [D loss: 0.551822, acc: 78.12%] [G loss: 1.790825]\n",
      "epoch:9 step:7448 [D loss: 0.667350, acc: 60.94%] [G loss: 1.472578]\n",
      "epoch:9 step:7449 [D loss: 0.982872, acc: 18.75%] [G loss: 1.772933]\n",
      "epoch:9 step:7450 [D loss: 0.510017, acc: 86.72%] [G loss: 1.731782]\n",
      "epoch:9 step:7451 [D loss: 0.641014, acc: 62.50%] [G loss: 1.757623]\n",
      "epoch:9 step:7452 [D loss: 0.662954, acc: 65.62%] [G loss: 1.653606]\n",
      "epoch:9 step:7453 [D loss: 0.775827, acc: 38.28%] [G loss: 1.705632]\n",
      "epoch:9 step:7454 [D loss: 0.774992, acc: 39.06%] [G loss: 1.582775]\n",
      "epoch:9 step:7455 [D loss: 0.599678, acc: 67.97%] [G loss: 1.859195]\n",
      "epoch:9 step:7456 [D loss: 0.685007, acc: 55.47%] [G loss: 1.636398]\n",
      "epoch:9 step:7457 [D loss: 0.591993, acc: 69.53%] [G loss: 1.862901]\n",
      "epoch:9 step:7458 [D loss: 0.717248, acc: 46.09%] [G loss: 1.576994]\n",
      "epoch:9 step:7459 [D loss: 0.936772, acc: 16.41%] [G loss: 1.544848]\n",
      "epoch:9 step:7460 [D loss: 0.822921, acc: 26.56%] [G loss: 1.529273]\n",
      "epoch:9 step:7461 [D loss: 0.655627, acc: 60.16%] [G loss: 1.778361]\n",
      "epoch:9 step:7462 [D loss: 0.667034, acc: 59.38%] [G loss: 1.634204]\n",
      "epoch:9 step:7463 [D loss: 0.743478, acc: 47.66%] [G loss: 1.648732]\n",
      "epoch:9 step:7464 [D loss: 0.701349, acc: 52.34%] [G loss: 1.650960]\n",
      "epoch:9 step:7465 [D loss: 0.587589, acc: 79.69%] [G loss: 1.689831]\n",
      "epoch:9 step:7466 [D loss: 0.849974, acc: 24.22%] [G loss: 1.301211]\n",
      "epoch:9 step:7467 [D loss: 0.641414, acc: 64.84%] [G loss: 1.707338]\n",
      "epoch:9 step:7468 [D loss: 0.644475, acc: 60.16%] [G loss: 1.617021]\n",
      "epoch:9 step:7469 [D loss: 0.802516, acc: 31.25%] [G loss: 1.438416]\n",
      "epoch:9 step:7470 [D loss: 0.672800, acc: 58.59%] [G loss: 2.112232]\n",
      "epoch:9 step:7471 [D loss: 0.700652, acc: 53.91%] [G loss: 1.639546]\n",
      "epoch:9 step:7472 [D loss: 0.664097, acc: 60.16%] [G loss: 1.635913]\n",
      "epoch:9 step:7473 [D loss: 0.723017, acc: 47.66%] [G loss: 1.612540]\n",
      "epoch:9 step:7474 [D loss: 0.706747, acc: 52.34%] [G loss: 1.741091]\n",
      "epoch:9 step:7475 [D loss: 0.629247, acc: 68.75%] [G loss: 1.839556]\n",
      "epoch:9 step:7476 [D loss: 0.629869, acc: 65.62%] [G loss: 1.698593]\n",
      "epoch:9 step:7477 [D loss: 0.519580, acc: 78.91%] [G loss: 2.380229]\n",
      "epoch:9 step:7478 [D loss: 0.728191, acc: 48.44%] [G loss: 1.663833]\n",
      "epoch:9 step:7479 [D loss: 0.711718, acc: 52.34%] [G loss: 1.636570]\n",
      "epoch:9 step:7480 [D loss: 0.671893, acc: 62.50%] [G loss: 1.832607]\n",
      "epoch:9 step:7481 [D loss: 0.555798, acc: 70.31%] [G loss: 2.112759]\n",
      "epoch:9 step:7482 [D loss: 0.617578, acc: 70.31%] [G loss: 1.911000]\n",
      "epoch:9 step:7483 [D loss: 0.621849, acc: 64.84%] [G loss: 1.776753]\n",
      "epoch:9 step:7484 [D loss: 0.751851, acc: 40.62%] [G loss: 1.596229]\n",
      "epoch:9 step:7485 [D loss: 0.535824, acc: 75.78%] [G loss: 1.783797]\n",
      "epoch:9 step:7486 [D loss: 0.641628, acc: 61.72%] [G loss: 1.782018]\n",
      "epoch:9 step:7487 [D loss: 0.744801, acc: 41.41%] [G loss: 1.607115]\n",
      "epoch:9 step:7488 [D loss: 0.620158, acc: 65.62%] [G loss: 1.724969]\n",
      "epoch:9 step:7489 [D loss: 0.678107, acc: 59.38%] [G loss: 1.514030]\n",
      "epoch:9 step:7490 [D loss: 0.837512, acc: 28.91%] [G loss: 1.691986]\n",
      "epoch:9 step:7491 [D loss: 0.679360, acc: 57.03%] [G loss: 1.781385]\n",
      "epoch:9 step:7492 [D loss: 0.570971, acc: 71.09%] [G loss: 1.743864]\n",
      "epoch:9 step:7493 [D loss: 0.586530, acc: 75.78%] [G loss: 1.689254]\n",
      "epoch:9 step:7494 [D loss: 0.774167, acc: 42.19%] [G loss: 1.500571]\n",
      "epoch:9 step:7495 [D loss: 0.887966, acc: 28.12%] [G loss: 1.437119]\n",
      "epoch:9 step:7496 [D loss: 0.591620, acc: 73.44%] [G loss: 1.730563]\n",
      "epoch:9 step:7497 [D loss: 0.589955, acc: 75.78%] [G loss: 1.588129]\n",
      "epoch:9 step:7498 [D loss: 0.828253, acc: 32.03%] [G loss: 1.460337]\n",
      "epoch:9 step:7499 [D loss: 0.715153, acc: 51.56%] [G loss: 1.528990]\n",
      "epoch:9 step:7500 [D loss: 0.801940, acc: 28.91%] [G loss: 1.566842]\n",
      "epoch:9 step:7501 [D loss: 0.547130, acc: 78.12%] [G loss: 1.669237]\n",
      "epoch:9 step:7502 [D loss: 0.649173, acc: 63.28%] [G loss: 1.683983]\n",
      "epoch:9 step:7503 [D loss: 0.736785, acc: 46.88%] [G loss: 1.639957]\n",
      "epoch:9 step:7504 [D loss: 0.657851, acc: 53.12%] [G loss: 1.661144]\n",
      "epoch:9 step:7505 [D loss: 0.571795, acc: 69.53%] [G loss: 1.649632]\n",
      "epoch:9 step:7506 [D loss: 0.690269, acc: 56.25%] [G loss: 1.654712]\n",
      "epoch:9 step:7507 [D loss: 0.667867, acc: 62.50%] [G loss: 1.885189]\n",
      "epoch:9 step:7508 [D loss: 0.671200, acc: 63.28%] [G loss: 1.660912]\n",
      "epoch:9 step:7509 [D loss: 0.562988, acc: 78.91%] [G loss: 1.728824]\n",
      "epoch:9 step:7510 [D loss: 0.732178, acc: 51.56%] [G loss: 1.889452]\n",
      "epoch:9 step:7511 [D loss: 0.608795, acc: 65.62%] [G loss: 1.791789]\n",
      "epoch:9 step:7512 [D loss: 0.673625, acc: 58.59%] [G loss: 1.728869]\n",
      "epoch:9 step:7513 [D loss: 0.634310, acc: 62.50%] [G loss: 1.590695]\n",
      "epoch:9 step:7514 [D loss: 0.728661, acc: 50.78%] [G loss: 1.686811]\n",
      "epoch:9 step:7515 [D loss: 0.623254, acc: 63.28%] [G loss: 1.734628]\n",
      "epoch:9 step:7516 [D loss: 0.534821, acc: 77.34%] [G loss: 1.974725]\n",
      "epoch:9 step:7517 [D loss: 0.611857, acc: 62.50%] [G loss: 1.534085]\n",
      "epoch:9 step:7518 [D loss: 0.679278, acc: 57.81%] [G loss: 1.838264]\n",
      "epoch:9 step:7519 [D loss: 0.585814, acc: 75.78%] [G loss: 1.958643]\n",
      "epoch:9 step:7520 [D loss: 0.757902, acc: 39.84%] [G loss: 1.668731]\n",
      "epoch:9 step:7521 [D loss: 0.510138, acc: 82.03%] [G loss: 1.928597]\n",
      "epoch:9 step:7522 [D loss: 0.914843, acc: 22.66%] [G loss: 1.379153]\n",
      "epoch:9 step:7523 [D loss: 0.814165, acc: 33.59%] [G loss: 1.384017]\n",
      "epoch:9 step:7524 [D loss: 0.583209, acc: 72.66%] [G loss: 1.732338]\n",
      "epoch:9 step:7525 [D loss: 0.563890, acc: 76.56%] [G loss: 1.898307]\n",
      "epoch:9 step:7526 [D loss: 0.604022, acc: 70.31%] [G loss: 1.646792]\n",
      "epoch:9 step:7527 [D loss: 0.557334, acc: 71.09%] [G loss: 2.379782]\n",
      "epoch:9 step:7528 [D loss: 0.777992, acc: 45.31%] [G loss: 2.246106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7529 [D loss: 0.853426, acc: 37.50%] [G loss: 1.485542]\n",
      "epoch:9 step:7530 [D loss: 0.704598, acc: 53.91%] [G loss: 1.669298]\n",
      "epoch:9 step:7531 [D loss: 0.604944, acc: 75.78%] [G loss: 1.822990]\n",
      "epoch:9 step:7532 [D loss: 0.467283, acc: 80.47%] [G loss: 2.342461]\n",
      "epoch:9 step:7533 [D loss: 0.790011, acc: 43.75%] [G loss: 1.758220]\n",
      "epoch:9 step:7534 [D loss: 0.570406, acc: 74.22%] [G loss: 1.771909]\n",
      "epoch:9 step:7535 [D loss: 0.716964, acc: 49.22%] [G loss: 1.533622]\n",
      "epoch:9 step:7536 [D loss: 0.741282, acc: 50.00%] [G loss: 1.694527]\n",
      "epoch:9 step:7537 [D loss: 0.743642, acc: 49.22%] [G loss: 1.674172]\n",
      "epoch:9 step:7538 [D loss: 0.694640, acc: 55.47%] [G loss: 1.659217]\n",
      "epoch:9 step:7539 [D loss: 0.688283, acc: 56.25%] [G loss: 2.096076]\n",
      "epoch:9 step:7540 [D loss: 0.579388, acc: 73.44%] [G loss: 1.874862]\n",
      "epoch:9 step:7541 [D loss: 0.656404, acc: 61.72%] [G loss: 1.759514]\n",
      "epoch:9 step:7542 [D loss: 0.766046, acc: 43.75%] [G loss: 1.706960]\n",
      "epoch:9 step:7543 [D loss: 0.776007, acc: 38.28%] [G loss: 1.875374]\n",
      "epoch:9 step:7544 [D loss: 0.622067, acc: 67.97%] [G loss: 2.038378]\n",
      "epoch:9 step:7545 [D loss: 0.558154, acc: 79.69%] [G loss: 2.161882]\n",
      "epoch:9 step:7546 [D loss: 0.660669, acc: 60.94%] [G loss: 1.707242]\n",
      "epoch:9 step:7547 [D loss: 0.622181, acc: 66.41%] [G loss: 1.754086]\n",
      "epoch:9 step:7548 [D loss: 0.808953, acc: 34.38%] [G loss: 1.715320]\n",
      "epoch:9 step:7549 [D loss: 0.546011, acc: 82.03%] [G loss: 1.867085]\n",
      "epoch:9 step:7550 [D loss: 0.624111, acc: 66.41%] [G loss: 1.750179]\n",
      "epoch:9 step:7551 [D loss: 0.662209, acc: 61.72%] [G loss: 1.884516]\n",
      "epoch:9 step:7552 [D loss: 0.784053, acc: 39.06%] [G loss: 1.572583]\n",
      "epoch:9 step:7553 [D loss: 0.626533, acc: 66.41%] [G loss: 2.181620]\n",
      "epoch:9 step:7554 [D loss: 0.689175, acc: 57.03%] [G loss: 1.828386]\n",
      "epoch:9 step:7555 [D loss: 0.582245, acc: 72.66%] [G loss: 2.065423]\n",
      "epoch:9 step:7556 [D loss: 0.664308, acc: 61.72%] [G loss: 1.597018]\n",
      "epoch:9 step:7557 [D loss: 0.773933, acc: 39.06%] [G loss: 1.640598]\n",
      "epoch:9 step:7558 [D loss: 0.616045, acc: 68.75%] [G loss: 1.702003]\n",
      "epoch:9 step:7559 [D loss: 0.768361, acc: 39.06%] [G loss: 1.631845]\n",
      "epoch:9 step:7560 [D loss: 0.646947, acc: 61.72%] [G loss: 1.662365]\n",
      "epoch:9 step:7561 [D loss: 0.949008, acc: 24.22%] [G loss: 1.414420]\n",
      "epoch:9 step:7562 [D loss: 0.709534, acc: 50.78%] [G loss: 1.741453]\n",
      "epoch:9 step:7563 [D loss: 0.712141, acc: 52.34%] [G loss: 1.524006]\n",
      "epoch:9 step:7564 [D loss: 0.705007, acc: 47.66%] [G loss: 1.645068]\n",
      "epoch:9 step:7565 [D loss: 0.597569, acc: 64.84%] [G loss: 1.613724]\n",
      "epoch:9 step:7566 [D loss: 0.513724, acc: 86.72%] [G loss: 1.937437]\n",
      "epoch:9 step:7567 [D loss: 0.698403, acc: 51.56%] [G loss: 1.691901]\n",
      "epoch:9 step:7568 [D loss: 0.640268, acc: 63.28%] [G loss: 1.751625]\n",
      "epoch:9 step:7569 [D loss: 0.684930, acc: 56.25%] [G loss: 1.714927]\n",
      "epoch:9 step:7570 [D loss: 0.723718, acc: 51.56%] [G loss: 1.599584]\n",
      "epoch:9 step:7571 [D loss: 0.614839, acc: 68.75%] [G loss: 1.773106]\n",
      "epoch:9 step:7572 [D loss: 0.759841, acc: 42.97%] [G loss: 1.474927]\n",
      "epoch:9 step:7573 [D loss: 0.687462, acc: 50.78%] [G loss: 1.779771]\n",
      "epoch:9 step:7574 [D loss: 0.627870, acc: 69.53%] [G loss: 1.701768]\n",
      "epoch:9 step:7575 [D loss: 0.723249, acc: 44.53%] [G loss: 1.543672]\n",
      "epoch:9 step:7576 [D loss: 0.792991, acc: 42.19%] [G loss: 1.729709]\n",
      "epoch:9 step:7577 [D loss: 0.590022, acc: 67.19%] [G loss: 2.145437]\n",
      "epoch:9 step:7578 [D loss: 0.751263, acc: 43.75%] [G loss: 1.899431]\n",
      "epoch:9 step:7579 [D loss: 0.619601, acc: 63.28%] [G loss: 1.914339]\n",
      "epoch:9 step:7580 [D loss: 0.713936, acc: 50.78%] [G loss: 1.869519]\n",
      "epoch:9 step:7581 [D loss: 0.669091, acc: 55.47%] [G loss: 1.595498]\n",
      "epoch:9 step:7582 [D loss: 0.633363, acc: 67.19%] [G loss: 1.770869]\n",
      "epoch:9 step:7583 [D loss: 0.772004, acc: 37.50%] [G loss: 1.569791]\n",
      "epoch:9 step:7584 [D loss: 0.782177, acc: 35.94%] [G loss: 1.551685]\n",
      "epoch:9 step:7585 [D loss: 0.730717, acc: 54.69%] [G loss: 1.571186]\n",
      "epoch:9 step:7586 [D loss: 0.644864, acc: 60.16%] [G loss: 1.578696]\n",
      "epoch:9 step:7587 [D loss: 0.702741, acc: 53.12%] [G loss: 1.741646]\n",
      "epoch:9 step:7588 [D loss: 0.628833, acc: 65.62%] [G loss: 1.780640]\n",
      "epoch:9 step:7589 [D loss: 0.590169, acc: 74.22%] [G loss: 1.967543]\n",
      "epoch:9 step:7590 [D loss: 0.712176, acc: 48.44%] [G loss: 1.715049]\n",
      "epoch:9 step:7591 [D loss: 0.679552, acc: 50.78%] [G loss: 1.468995]\n",
      "epoch:9 step:7592 [D loss: 0.718782, acc: 53.91%] [G loss: 2.135035]\n",
      "epoch:9 step:7593 [D loss: 0.677859, acc: 54.69%] [G loss: 1.607383]\n",
      "epoch:9 step:7594 [D loss: 0.673331, acc: 62.50%] [G loss: 1.743952]\n",
      "epoch:9 step:7595 [D loss: 0.709414, acc: 48.44%] [G loss: 1.753355]\n",
      "epoch:9 step:7596 [D loss: 0.487281, acc: 78.12%] [G loss: 2.000925]\n",
      "epoch:9 step:7597 [D loss: 0.728954, acc: 48.44%] [G loss: 1.641005]\n",
      "epoch:9 step:7598 [D loss: 0.712251, acc: 51.56%] [G loss: 1.606466]\n",
      "epoch:9 step:7599 [D loss: 0.485385, acc: 86.72%] [G loss: 1.862693]\n",
      "epoch:9 step:7600 [D loss: 0.700840, acc: 52.34%] [G loss: 1.682846]\n",
      "epoch:9 step:7601 [D loss: 0.753407, acc: 45.31%] [G loss: 1.573315]\n",
      "epoch:9 step:7602 [D loss: 0.609654, acc: 66.41%] [G loss: 1.914897]\n",
      "epoch:9 step:7603 [D loss: 0.650324, acc: 62.50%] [G loss: 1.511792]\n",
      "epoch:9 step:7604 [D loss: 0.519926, acc: 81.25%] [G loss: 1.805727]\n",
      "epoch:9 step:7605 [D loss: 0.507593, acc: 87.50%] [G loss: 1.904756]\n",
      "epoch:9 step:7606 [D loss: 0.653573, acc: 51.56%] [G loss: 2.033174]\n",
      "epoch:9 step:7607 [D loss: 0.592462, acc: 70.31%] [G loss: 1.807884]\n",
      "epoch:9 step:7608 [D loss: 0.738391, acc: 50.78%] [G loss: 1.695502]\n",
      "epoch:9 step:7609 [D loss: 0.600100, acc: 70.31%] [G loss: 1.812752]\n",
      "epoch:9 step:7610 [D loss: 0.637349, acc: 67.97%] [G loss: 1.875125]\n",
      "epoch:9 step:7611 [D loss: 0.763919, acc: 43.75%] [G loss: 1.801727]\n",
      "epoch:9 step:7612 [D loss: 0.735147, acc: 52.34%] [G loss: 1.570029]\n",
      "epoch:9 step:7613 [D loss: 0.689104, acc: 58.59%] [G loss: 1.783623]\n",
      "epoch:9 step:7614 [D loss: 0.715867, acc: 53.12%] [G loss: 1.845938]\n",
      "epoch:9 step:7615 [D loss: 0.648057, acc: 64.84%] [G loss: 1.748799]\n",
      "epoch:9 step:7616 [D loss: 0.547684, acc: 75.78%] [G loss: 1.822058]\n",
      "epoch:9 step:7617 [D loss: 0.559617, acc: 75.78%] [G loss: 1.944578]\n",
      "epoch:9 step:7618 [D loss: 0.772380, acc: 45.31%] [G loss: 1.700848]\n",
      "epoch:9 step:7619 [D loss: 0.655209, acc: 63.28%] [G loss: 1.840914]\n",
      "epoch:9 step:7620 [D loss: 0.596526, acc: 66.41%] [G loss: 1.673405]\n",
      "epoch:9 step:7621 [D loss: 0.699437, acc: 52.34%] [G loss: 1.859476]\n",
      "epoch:9 step:7622 [D loss: 0.971882, acc: 17.19%] [G loss: 1.402536]\n",
      "epoch:9 step:7623 [D loss: 0.663913, acc: 61.72%] [G loss: 1.802543]\n",
      "epoch:9 step:7624 [D loss: 0.591511, acc: 75.00%] [G loss: 1.760145]\n",
      "epoch:9 step:7625 [D loss: 0.667606, acc: 60.94%] [G loss: 1.702374]\n",
      "epoch:9 step:7626 [D loss: 0.690825, acc: 56.25%] [G loss: 1.590086]\n",
      "epoch:9 step:7627 [D loss: 0.729683, acc: 46.09%] [G loss: 1.875036]\n",
      "epoch:9 step:7628 [D loss: 0.717850, acc: 49.22%] [G loss: 1.669795]\n",
      "epoch:9 step:7629 [D loss: 0.715726, acc: 51.56%] [G loss: 1.548028]\n",
      "epoch:9 step:7630 [D loss: 0.578704, acc: 74.22%] [G loss: 1.860836]\n",
      "epoch:9 step:7631 [D loss: 0.731742, acc: 44.53%] [G loss: 1.549271]\n",
      "epoch:9 step:7632 [D loss: 0.649319, acc: 62.50%] [G loss: 1.860928]\n",
      "epoch:9 step:7633 [D loss: 0.843130, acc: 35.94%] [G loss: 1.862184]\n",
      "epoch:9 step:7634 [D loss: 0.598513, acc: 72.66%] [G loss: 2.027251]\n",
      "epoch:9 step:7635 [D loss: 0.626841, acc: 66.41%] [G loss: 1.831266]\n",
      "epoch:9 step:7636 [D loss: 0.916093, acc: 25.00%] [G loss: 1.492546]\n",
      "epoch:9 step:7637 [D loss: 0.699659, acc: 59.38%] [G loss: 1.478249]\n",
      "epoch:9 step:7638 [D loss: 0.714268, acc: 57.03%] [G loss: 1.642422]\n",
      "epoch:9 step:7639 [D loss: 0.595724, acc: 69.53%] [G loss: 1.851954]\n",
      "epoch:9 step:7640 [D loss: 0.523760, acc: 78.91%] [G loss: 1.833184]\n",
      "epoch:9 step:7641 [D loss: 0.631537, acc: 67.19%] [G loss: 1.817150]\n",
      "epoch:9 step:7642 [D loss: 0.508583, acc: 79.69%] [G loss: 2.060973]\n",
      "epoch:9 step:7643 [D loss: 0.684354, acc: 54.69%] [G loss: 1.659716]\n",
      "epoch:9 step:7644 [D loss: 0.746737, acc: 44.53%] [G loss: 1.741964]\n",
      "epoch:9 step:7645 [D loss: 0.702719, acc: 57.03%] [G loss: 1.674168]\n",
      "epoch:9 step:7646 [D loss: 0.684521, acc: 60.94%] [G loss: 2.038741]\n",
      "epoch:9 step:7647 [D loss: 0.627245, acc: 66.41%] [G loss: 1.863791]\n",
      "epoch:9 step:7648 [D loss: 0.683092, acc: 60.16%] [G loss: 1.760766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7649 [D loss: 0.737765, acc: 53.91%] [G loss: 1.772089]\n",
      "epoch:9 step:7650 [D loss: 0.517593, acc: 75.78%] [G loss: 1.722241]\n",
      "epoch:9 step:7651 [D loss: 0.593935, acc: 65.62%] [G loss: 1.633799]\n",
      "epoch:9 step:7652 [D loss: 0.631249, acc: 65.62%] [G loss: 2.016267]\n",
      "epoch:9 step:7653 [D loss: 0.647368, acc: 64.84%] [G loss: 2.078762]\n",
      "epoch:9 step:7654 [D loss: 0.461394, acc: 87.50%] [G loss: 2.262790]\n",
      "epoch:9 step:7655 [D loss: 0.654212, acc: 61.72%] [G loss: 1.627977]\n",
      "epoch:9 step:7656 [D loss: 0.854293, acc: 34.38%] [G loss: 1.500653]\n",
      "epoch:9 step:7657 [D loss: 0.687289, acc: 60.94%] [G loss: 1.770186]\n",
      "epoch:9 step:7658 [D loss: 0.481062, acc: 86.72%] [G loss: 2.059295]\n",
      "epoch:9 step:7659 [D loss: 0.555551, acc: 75.78%] [G loss: 1.862636]\n",
      "epoch:9 step:7660 [D loss: 0.663598, acc: 63.28%] [G loss: 1.657616]\n",
      "epoch:9 step:7661 [D loss: 0.932840, acc: 31.25%] [G loss: 1.384664]\n",
      "epoch:9 step:7662 [D loss: 0.664789, acc: 63.28%] [G loss: 1.725470]\n",
      "epoch:9 step:7663 [D loss: 0.819299, acc: 32.03%] [G loss: 1.593149]\n",
      "epoch:9 step:7664 [D loss: 0.673112, acc: 58.59%] [G loss: 1.663179]\n",
      "epoch:9 step:7665 [D loss: 0.762382, acc: 42.97%] [G loss: 1.926517]\n",
      "epoch:9 step:7666 [D loss: 0.782884, acc: 44.53%] [G loss: 1.655922]\n",
      "epoch:9 step:7667 [D loss: 0.700029, acc: 49.22%] [G loss: 1.647833]\n",
      "epoch:9 step:7668 [D loss: 0.721024, acc: 50.00%] [G loss: 1.776591]\n",
      "epoch:9 step:7669 [D loss: 0.621682, acc: 66.41%] [G loss: 1.997897]\n",
      "epoch:9 step:7670 [D loss: 0.805965, acc: 44.53%] [G loss: 1.652449]\n",
      "epoch:9 step:7671 [D loss: 0.623430, acc: 63.28%] [G loss: 1.911646]\n",
      "epoch:9 step:7672 [D loss: 0.660019, acc: 54.69%] [G loss: 1.840822]\n",
      "epoch:9 step:7673 [D loss: 0.552120, acc: 74.22%] [G loss: 1.756276]\n",
      "epoch:9 step:7674 [D loss: 0.831207, acc: 48.44%] [G loss: 1.509109]\n",
      "epoch:9 step:7675 [D loss: 0.744528, acc: 42.97%] [G loss: 1.860239]\n",
      "epoch:9 step:7676 [D loss: 0.720914, acc: 55.47%] [G loss: 1.468353]\n",
      "epoch:9 step:7677 [D loss: 0.649363, acc: 63.28%] [G loss: 1.858745]\n",
      "epoch:9 step:7678 [D loss: 0.696373, acc: 50.78%] [G loss: 1.865657]\n",
      "epoch:9 step:7679 [D loss: 0.644395, acc: 64.84%] [G loss: 1.931907]\n",
      "epoch:9 step:7680 [D loss: 0.611848, acc: 64.84%] [G loss: 1.721988]\n",
      "epoch:9 step:7681 [D loss: 0.675042, acc: 56.25%] [G loss: 1.796318]\n",
      "epoch:9 step:7682 [D loss: 0.709633, acc: 56.25%] [G loss: 1.852155]\n",
      "epoch:9 step:7683 [D loss: 0.541318, acc: 78.91%] [G loss: 1.742387]\n",
      "epoch:9 step:7684 [D loss: 0.652771, acc: 64.06%] [G loss: 1.833136]\n",
      "epoch:9 step:7685 [D loss: 0.960604, acc: 21.09%] [G loss: 1.399239]\n",
      "epoch:9 step:7686 [D loss: 0.732633, acc: 51.56%] [G loss: 1.708785]\n",
      "epoch:9 step:7687 [D loss: 0.427356, acc: 83.59%] [G loss: 1.887636]\n",
      "epoch:9 step:7688 [D loss: 0.656994, acc: 60.94%] [G loss: 1.785942]\n",
      "epoch:9 step:7689 [D loss: 0.780548, acc: 39.06%] [G loss: 1.469628]\n",
      "epoch:9 step:7690 [D loss: 0.552479, acc: 77.34%] [G loss: 1.808330]\n",
      "epoch:9 step:7691 [D loss: 0.669814, acc: 56.25%] [G loss: 1.889812]\n",
      "epoch:9 step:7692 [D loss: 0.654272, acc: 65.62%] [G loss: 1.990595]\n",
      "epoch:9 step:7693 [D loss: 0.620471, acc: 66.41%] [G loss: 1.925199]\n",
      "epoch:9 step:7694 [D loss: 0.657221, acc: 58.59%] [G loss: 1.898020]\n",
      "epoch:9 step:7695 [D loss: 0.666868, acc: 57.81%] [G loss: 1.719556]\n",
      "epoch:9 step:7696 [D loss: 0.534549, acc: 75.78%] [G loss: 1.677853]\n",
      "epoch:9 step:7697 [D loss: 0.534204, acc: 78.12%] [G loss: 2.316710]\n",
      "epoch:9 step:7698 [D loss: 0.719573, acc: 51.56%] [G loss: 1.811038]\n",
      "epoch:9 step:7699 [D loss: 0.855695, acc: 40.62%] [G loss: 1.361156]\n",
      "epoch:9 step:7700 [D loss: 0.601336, acc: 68.75%] [G loss: 1.813868]\n",
      "epoch:9 step:7701 [D loss: 0.812608, acc: 40.62%] [G loss: 1.698080]\n",
      "epoch:9 step:7702 [D loss: 0.634976, acc: 62.50%] [G loss: 1.763325]\n",
      "epoch:9 step:7703 [D loss: 0.682959, acc: 57.03%] [G loss: 1.680442]\n",
      "epoch:9 step:7704 [D loss: 0.700788, acc: 53.12%] [G loss: 1.526431]\n",
      "epoch:9 step:7705 [D loss: 0.869391, acc: 39.06%] [G loss: 1.783354]\n",
      "epoch:9 step:7706 [D loss: 0.671651, acc: 51.56%] [G loss: 1.840461]\n",
      "epoch:9 step:7707 [D loss: 0.443374, acc: 85.94%] [G loss: 2.066013]\n",
      "epoch:9 step:7708 [D loss: 0.732000, acc: 46.09%] [G loss: 1.734925]\n",
      "epoch:9 step:7709 [D loss: 0.610658, acc: 65.62%] [G loss: 2.038546]\n",
      "epoch:9 step:7710 [D loss: 0.622326, acc: 67.97%] [G loss: 1.999753]\n",
      "epoch:9 step:7711 [D loss: 0.713403, acc: 50.78%] [G loss: 1.656062]\n",
      "epoch:9 step:7712 [D loss: 0.609534, acc: 69.53%] [G loss: 2.106735]\n",
      "epoch:9 step:7713 [D loss: 0.730311, acc: 50.00%] [G loss: 1.939867]\n",
      "epoch:9 step:7714 [D loss: 0.509485, acc: 82.03%] [G loss: 2.356884]\n",
      "epoch:9 step:7715 [D loss: 0.578344, acc: 72.66%] [G loss: 2.133477]\n",
      "epoch:9 step:7716 [D loss: 0.629413, acc: 64.84%] [G loss: 1.990762]\n",
      "epoch:9 step:7717 [D loss: 0.608294, acc: 72.66%] [G loss: 1.611825]\n",
      "epoch:9 step:7718 [D loss: 0.662658, acc: 60.94%] [G loss: 1.858386]\n",
      "epoch:9 step:7719 [D loss: 0.623315, acc: 62.50%] [G loss: 1.518783]\n",
      "epoch:9 step:7720 [D loss: 0.764871, acc: 44.53%] [G loss: 1.656801]\n",
      "epoch:9 step:7721 [D loss: 0.543770, acc: 75.00%] [G loss: 1.745475]\n",
      "epoch:9 step:7722 [D loss: 0.677244, acc: 54.69%] [G loss: 1.854350]\n",
      "epoch:9 step:7723 [D loss: 0.630801, acc: 60.94%] [G loss: 1.863930]\n",
      "epoch:9 step:7724 [D loss: 0.735017, acc: 53.91%] [G loss: 1.975822]\n",
      "epoch:9 step:7725 [D loss: 0.615007, acc: 69.53%] [G loss: 1.741774]\n",
      "epoch:9 step:7726 [D loss: 0.458811, acc: 88.28%] [G loss: 1.757697]\n",
      "epoch:9 step:7727 [D loss: 0.617013, acc: 64.84%] [G loss: 1.813410]\n",
      "epoch:9 step:7728 [D loss: 0.866475, acc: 29.69%] [G loss: 2.063922]\n",
      "epoch:9 step:7729 [D loss: 0.676817, acc: 59.38%] [G loss: 1.761455]\n",
      "epoch:9 step:7730 [D loss: 0.663527, acc: 57.03%] [G loss: 1.779901]\n",
      "epoch:9 step:7731 [D loss: 0.523607, acc: 71.09%] [G loss: 1.664382]\n",
      "epoch:9 step:7732 [D loss: 0.630135, acc: 68.75%] [G loss: 2.011016]\n",
      "epoch:9 step:7733 [D loss: 0.683614, acc: 53.91%] [G loss: 1.851761]\n",
      "epoch:9 step:7734 [D loss: 0.702160, acc: 51.56%] [G loss: 1.882720]\n",
      "epoch:9 step:7735 [D loss: 0.787221, acc: 40.62%] [G loss: 1.940618]\n",
      "epoch:9 step:7736 [D loss: 0.741389, acc: 49.22%] [G loss: 1.754122]\n",
      "epoch:9 step:7737 [D loss: 0.607772, acc: 73.44%] [G loss: 1.891166]\n",
      "epoch:9 step:7738 [D loss: 0.700134, acc: 50.78%] [G loss: 1.506978]\n",
      "epoch:9 step:7739 [D loss: 0.598810, acc: 72.66%] [G loss: 1.592860]\n",
      "epoch:9 step:7740 [D loss: 0.873295, acc: 37.50%] [G loss: 1.668981]\n",
      "epoch:9 step:7741 [D loss: 0.713262, acc: 51.56%] [G loss: 1.643178]\n",
      "epoch:9 step:7742 [D loss: 0.680422, acc: 53.91%] [G loss: 1.868057]\n",
      "epoch:9 step:7743 [D loss: 0.719083, acc: 52.34%] [G loss: 1.662637]\n",
      "epoch:9 step:7744 [D loss: 0.966026, acc: 25.78%] [G loss: 1.561584]\n",
      "epoch:9 step:7745 [D loss: 0.589745, acc: 69.53%] [G loss: 1.730804]\n",
      "epoch:9 step:7746 [D loss: 0.608744, acc: 74.22%] [G loss: 1.876504]\n",
      "epoch:9 step:7747 [D loss: 0.746934, acc: 47.66%] [G loss: 1.702321]\n",
      "epoch:9 step:7748 [D loss: 0.629169, acc: 63.28%] [G loss: 1.739831]\n",
      "epoch:9 step:7749 [D loss: 0.948588, acc: 26.56%] [G loss: 1.334606]\n",
      "epoch:9 step:7750 [D loss: 0.702383, acc: 53.91%] [G loss: 1.592744]\n",
      "epoch:9 step:7751 [D loss: 0.689056, acc: 55.47%] [G loss: 1.637050]\n",
      "epoch:9 step:7752 [D loss: 0.583997, acc: 71.09%] [G loss: 1.530531]\n",
      "epoch:9 step:7753 [D loss: 0.728491, acc: 48.44%] [G loss: 1.588814]\n",
      "epoch:9 step:7754 [D loss: 0.654068, acc: 57.03%] [G loss: 1.806807]\n",
      "epoch:9 step:7755 [D loss: 0.625053, acc: 65.62%] [G loss: 1.692549]\n",
      "epoch:9 step:7756 [D loss: 0.725392, acc: 46.88%] [G loss: 1.596635]\n",
      "epoch:9 step:7757 [D loss: 0.710046, acc: 50.78%] [G loss: 1.722515]\n",
      "epoch:9 step:7758 [D loss: 0.670670, acc: 55.47%] [G loss: 1.664590]\n",
      "epoch:9 step:7759 [D loss: 0.576357, acc: 67.97%] [G loss: 1.941436]\n",
      "epoch:9 step:7760 [D loss: 0.562151, acc: 80.47%] [G loss: 1.498991]\n",
      "epoch:9 step:7761 [D loss: 0.531250, acc: 84.38%] [G loss: 1.921457]\n",
      "epoch:9 step:7762 [D loss: 0.625771, acc: 64.84%] [G loss: 2.217605]\n",
      "epoch:9 step:7763 [D loss: 0.731950, acc: 53.12%] [G loss: 1.744120]\n",
      "epoch:9 step:7764 [D loss: 0.691548, acc: 52.34%] [G loss: 1.590135]\n",
      "epoch:9 step:7765 [D loss: 0.531180, acc: 71.88%] [G loss: 1.684855]\n",
      "epoch:9 step:7766 [D loss: 0.598577, acc: 71.09%] [G loss: 1.991838]\n",
      "epoch:9 step:7767 [D loss: 0.870631, acc: 29.69%] [G loss: 1.516092]\n",
      "epoch:9 step:7768 [D loss: 0.786510, acc: 43.75%] [G loss: 1.749084]\n",
      "epoch:9 step:7769 [D loss: 0.779169, acc: 38.28%] [G loss: 1.688782]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7770 [D loss: 0.600940, acc: 67.97%] [G loss: 1.950680]\n",
      "epoch:9 step:7771 [D loss: 0.756508, acc: 51.56%] [G loss: 1.456041]\n",
      "epoch:9 step:7772 [D loss: 0.726640, acc: 50.78%] [G loss: 1.912849]\n",
      "epoch:9 step:7773 [D loss: 0.736641, acc: 46.88%] [G loss: 1.656692]\n",
      "epoch:9 step:7774 [D loss: 0.542665, acc: 82.03%] [G loss: 2.106434]\n",
      "epoch:9 step:7775 [D loss: 0.641839, acc: 63.28%] [G loss: 1.649221]\n",
      "epoch:9 step:7776 [D loss: 0.547221, acc: 74.22%] [G loss: 1.808723]\n",
      "epoch:9 step:7777 [D loss: 0.678035, acc: 53.12%] [G loss: 1.593026]\n",
      "epoch:9 step:7778 [D loss: 0.805570, acc: 33.59%] [G loss: 1.523146]\n",
      "epoch:9 step:7779 [D loss: 0.669140, acc: 59.38%] [G loss: 1.622550]\n",
      "epoch:9 step:7780 [D loss: 0.835393, acc: 34.38%] [G loss: 1.469239]\n",
      "epoch:9 step:7781 [D loss: 0.584868, acc: 73.44%] [G loss: 1.601874]\n",
      "epoch:9 step:7782 [D loss: 0.525317, acc: 81.25%] [G loss: 1.861226]\n",
      "epoch:9 step:7783 [D loss: 0.619962, acc: 67.97%] [G loss: 1.745882]\n",
      "epoch:9 step:7784 [D loss: 0.686919, acc: 57.03%] [G loss: 1.661024]\n",
      "epoch:9 step:7785 [D loss: 0.724132, acc: 52.34%] [G loss: 1.659752]\n",
      "epoch:9 step:7786 [D loss: 0.589714, acc: 71.88%] [G loss: 1.965013]\n",
      "epoch:9 step:7787 [D loss: 0.645695, acc: 62.50%] [G loss: 1.694573]\n",
      "epoch:9 step:7788 [D loss: 0.617996, acc: 67.97%] [G loss: 1.697120]\n",
      "epoch:9 step:7789 [D loss: 0.629601, acc: 65.62%] [G loss: 1.548919]\n",
      "epoch:9 step:7790 [D loss: 0.825165, acc: 33.59%] [G loss: 1.808278]\n",
      "epoch:9 step:7791 [D loss: 0.515854, acc: 83.59%] [G loss: 1.745408]\n",
      "epoch:9 step:7792 [D loss: 0.700593, acc: 53.91%] [G loss: 1.665510]\n",
      "epoch:9 step:7793 [D loss: 0.838272, acc: 34.38%] [G loss: 1.354207]\n",
      "epoch:9 step:7794 [D loss: 0.739414, acc: 48.44%] [G loss: 1.802796]\n",
      "epoch:9 step:7795 [D loss: 0.508905, acc: 78.91%] [G loss: 1.743945]\n",
      "epoch:9 step:7796 [D loss: 0.678345, acc: 62.50%] [G loss: 1.647097]\n",
      "epoch:9 step:7797 [D loss: 0.660682, acc: 54.69%] [G loss: 1.889023]\n",
      "epoch:9 step:7798 [D loss: 0.610748, acc: 64.06%] [G loss: 1.473200]\n",
      "epoch:9 step:7799 [D loss: 0.598766, acc: 67.19%] [G loss: 1.723382]\n",
      "epoch:9 step:7800 [D loss: 0.585536, acc: 70.31%] [G loss: 1.723562]\n",
      "epoch:9 step:7801 [D loss: 0.751420, acc: 41.41%] [G loss: 1.680754]\n",
      "epoch:9 step:7802 [D loss: 0.701978, acc: 53.12%] [G loss: 1.803993]\n",
      "epoch:9 step:7803 [D loss: 0.599628, acc: 71.88%] [G loss: 1.743249]\n",
      "epoch:9 step:7804 [D loss: 0.516215, acc: 84.38%] [G loss: 1.932298]\n",
      "epoch:9 step:7805 [D loss: 0.606951, acc: 68.75%] [G loss: 1.855256]\n",
      "epoch:9 step:7806 [D loss: 0.622108, acc: 68.75%] [G loss: 1.653623]\n",
      "epoch:9 step:7807 [D loss: 0.795146, acc: 36.72%] [G loss: 1.336833]\n",
      "epoch:9 step:7808 [D loss: 0.706749, acc: 57.03%] [G loss: 1.696360]\n",
      "epoch:9 step:7809 [D loss: 0.731451, acc: 53.91%] [G loss: 1.505563]\n",
      "epoch:9 step:7810 [D loss: 0.543374, acc: 74.22%] [G loss: 1.620249]\n",
      "epoch:10 step:7811 [D loss: 0.877610, acc: 28.91%] [G loss: 1.782990]\n",
      "epoch:10 step:7812 [D loss: 0.720638, acc: 52.34%] [G loss: 1.952821]\n",
      "epoch:10 step:7813 [D loss: 0.673103, acc: 59.38%] [G loss: 1.649687]\n",
      "epoch:10 step:7814 [D loss: 0.692043, acc: 53.91%] [G loss: 1.404501]\n",
      "epoch:10 step:7815 [D loss: 0.606823, acc: 70.31%] [G loss: 1.952971]\n",
      "epoch:10 step:7816 [D loss: 0.493080, acc: 83.59%] [G loss: 1.969033]\n",
      "epoch:10 step:7817 [D loss: 0.659123, acc: 63.28%] [G loss: 1.760365]\n",
      "epoch:10 step:7818 [D loss: 0.854176, acc: 31.25%] [G loss: 1.281986]\n",
      "epoch:10 step:7819 [D loss: 0.686053, acc: 57.03%] [G loss: 1.966525]\n",
      "epoch:10 step:7820 [D loss: 0.736394, acc: 50.78%] [G loss: 1.703889]\n",
      "epoch:10 step:7821 [D loss: 0.573880, acc: 71.09%] [G loss: 2.017337]\n",
      "epoch:10 step:7822 [D loss: 0.661129, acc: 62.50%] [G loss: 2.064704]\n",
      "epoch:10 step:7823 [D loss: 0.709372, acc: 51.56%] [G loss: 2.012168]\n",
      "epoch:10 step:7824 [D loss: 0.523814, acc: 72.66%] [G loss: 1.712574]\n",
      "epoch:10 step:7825 [D loss: 1.023658, acc: 45.31%] [G loss: 1.230883]\n",
      "epoch:10 step:7826 [D loss: 0.755561, acc: 43.75%] [G loss: 1.664968]\n",
      "epoch:10 step:7827 [D loss: 0.575782, acc: 68.75%] [G loss: 2.057746]\n",
      "epoch:10 step:7828 [D loss: 0.622215, acc: 66.41%] [G loss: 1.818042]\n",
      "epoch:10 step:7829 [D loss: 0.649787, acc: 65.62%] [G loss: 1.663581]\n",
      "epoch:10 step:7830 [D loss: 0.638142, acc: 65.62%] [G loss: 1.946033]\n",
      "epoch:10 step:7831 [D loss: 0.526706, acc: 80.47%] [G loss: 1.936578]\n",
      "epoch:10 step:7832 [D loss: 0.597456, acc: 70.31%] [G loss: 1.785195]\n",
      "epoch:10 step:7833 [D loss: 0.796725, acc: 43.75%] [G loss: 2.348043]\n",
      "epoch:10 step:7834 [D loss: 0.566131, acc: 69.53%] [G loss: 1.674333]\n",
      "epoch:10 step:7835 [D loss: 0.652436, acc: 58.59%] [G loss: 1.775330]\n",
      "epoch:10 step:7836 [D loss: 0.700399, acc: 52.34%] [G loss: 1.591192]\n",
      "epoch:10 step:7837 [D loss: 0.717489, acc: 48.44%] [G loss: 2.034019]\n",
      "epoch:10 step:7838 [D loss: 0.732567, acc: 45.31%] [G loss: 1.654182]\n",
      "epoch:10 step:7839 [D loss: 0.658207, acc: 60.16%] [G loss: 1.773287]\n",
      "epoch:10 step:7840 [D loss: 0.695676, acc: 56.25%] [G loss: 1.793418]\n",
      "epoch:10 step:7841 [D loss: 0.795838, acc: 34.38%] [G loss: 1.654309]\n",
      "epoch:10 step:7842 [D loss: 0.450346, acc: 82.03%] [G loss: 1.986735]\n",
      "epoch:10 step:7843 [D loss: 0.714821, acc: 47.66%] [G loss: 1.789734]\n",
      "epoch:10 step:7844 [D loss: 0.574531, acc: 67.97%] [G loss: 1.902561]\n",
      "epoch:10 step:7845 [D loss: 0.763518, acc: 45.31%] [G loss: 1.490340]\n",
      "epoch:10 step:7846 [D loss: 0.616280, acc: 64.84%] [G loss: 1.923232]\n",
      "epoch:10 step:7847 [D loss: 0.678306, acc: 54.69%] [G loss: 1.744762]\n",
      "epoch:10 step:7848 [D loss: 0.760385, acc: 47.66%] [G loss: 1.773832]\n",
      "epoch:10 step:7849 [D loss: 0.810930, acc: 41.41%] [G loss: 1.652026]\n",
      "epoch:10 step:7850 [D loss: 0.642271, acc: 57.81%] [G loss: 1.890740]\n",
      "epoch:10 step:7851 [D loss: 0.546122, acc: 75.78%] [G loss: 1.904553]\n",
      "epoch:10 step:7852 [D loss: 0.636218, acc: 62.50%] [G loss: 1.627167]\n",
      "epoch:10 step:7853 [D loss: 0.826663, acc: 36.72%] [G loss: 1.527562]\n",
      "epoch:10 step:7854 [D loss: 0.706403, acc: 48.44%] [G loss: 1.581578]\n",
      "epoch:10 step:7855 [D loss: 0.548160, acc: 85.16%] [G loss: 2.015938]\n",
      "epoch:10 step:7856 [D loss: 0.685443, acc: 57.81%] [G loss: 2.010596]\n",
      "epoch:10 step:7857 [D loss: 0.681035, acc: 60.16%] [G loss: 1.707680]\n",
      "epoch:10 step:7858 [D loss: 0.601742, acc: 72.66%] [G loss: 1.684973]\n",
      "epoch:10 step:7859 [D loss: 0.888507, acc: 20.31%] [G loss: 1.450957]\n",
      "epoch:10 step:7860 [D loss: 0.595779, acc: 64.06%] [G loss: 1.542632]\n",
      "epoch:10 step:7861 [D loss: 0.641135, acc: 66.41%] [G loss: 1.683064]\n",
      "epoch:10 step:7862 [D loss: 0.521343, acc: 82.81%] [G loss: 1.939095]\n",
      "epoch:10 step:7863 [D loss: 0.695315, acc: 57.03%] [G loss: 1.771707]\n",
      "epoch:10 step:7864 [D loss: 0.786361, acc: 39.06%] [G loss: 1.781211]\n",
      "epoch:10 step:7865 [D loss: 0.600857, acc: 68.75%] [G loss: 1.817962]\n",
      "epoch:10 step:7866 [D loss: 0.626381, acc: 61.72%] [G loss: 1.561296]\n",
      "epoch:10 step:7867 [D loss: 0.744331, acc: 43.75%] [G loss: 1.625795]\n",
      "epoch:10 step:7868 [D loss: 0.488784, acc: 84.38%] [G loss: 1.668469]\n",
      "epoch:10 step:7869 [D loss: 0.570573, acc: 73.44%] [G loss: 1.686301]\n",
      "epoch:10 step:7870 [D loss: 0.739651, acc: 44.53%] [G loss: 1.584110]\n",
      "epoch:10 step:7871 [D loss: 0.917124, acc: 24.22%] [G loss: 1.610593]\n",
      "epoch:10 step:7872 [D loss: 0.820535, acc: 36.72%] [G loss: 1.640452]\n",
      "epoch:10 step:7873 [D loss: 0.686432, acc: 56.25%] [G loss: 1.869749]\n",
      "epoch:10 step:7874 [D loss: 0.575201, acc: 74.22%] [G loss: 1.892011]\n",
      "epoch:10 step:7875 [D loss: 0.701052, acc: 53.91%] [G loss: 1.673238]\n",
      "epoch:10 step:7876 [D loss: 0.699647, acc: 54.69%] [G loss: 1.726757]\n",
      "epoch:10 step:7877 [D loss: 0.908199, acc: 25.00%] [G loss: 1.571139]\n",
      "epoch:10 step:7878 [D loss: 0.627826, acc: 61.72%] [G loss: 1.562234]\n",
      "epoch:10 step:7879 [D loss: 0.483426, acc: 82.81%] [G loss: 2.133823]\n",
      "epoch:10 step:7880 [D loss: 0.716750, acc: 52.34%] [G loss: 1.588911]\n",
      "epoch:10 step:7881 [D loss: 0.823291, acc: 39.84%] [G loss: 1.311062]\n",
      "epoch:10 step:7882 [D loss: 0.652850, acc: 59.38%] [G loss: 1.442232]\n",
      "epoch:10 step:7883 [D loss: 0.730174, acc: 49.22%] [G loss: 1.887934]\n",
      "epoch:10 step:7884 [D loss: 0.638398, acc: 64.84%] [G loss: 1.799117]\n",
      "epoch:10 step:7885 [D loss: 0.582699, acc: 74.22%] [G loss: 1.795201]\n",
      "epoch:10 step:7886 [D loss: 0.675220, acc: 53.91%] [G loss: 1.650469]\n",
      "epoch:10 step:7887 [D loss: 0.672127, acc: 58.59%] [G loss: 1.609370]\n",
      "epoch:10 step:7888 [D loss: 0.781032, acc: 46.88%] [G loss: 1.699632]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:7889 [D loss: 0.564405, acc: 80.47%] [G loss: 1.708238]\n",
      "epoch:10 step:7890 [D loss: 0.712844, acc: 52.34%] [G loss: 1.533721]\n",
      "epoch:10 step:7891 [D loss: 0.694174, acc: 54.69%] [G loss: 1.714915]\n",
      "epoch:10 step:7892 [D loss: 0.714177, acc: 53.12%] [G loss: 1.856458]\n",
      "epoch:10 step:7893 [D loss: 0.660744, acc: 55.47%] [G loss: 1.784270]\n",
      "epoch:10 step:7894 [D loss: 0.815332, acc: 43.75%] [G loss: 1.570625]\n",
      "epoch:10 step:7895 [D loss: 0.718992, acc: 50.78%] [G loss: 1.609635]\n",
      "epoch:10 step:7896 [D loss: 0.689039, acc: 60.16%] [G loss: 1.792078]\n",
      "epoch:10 step:7897 [D loss: 0.703336, acc: 57.81%] [G loss: 1.639997]\n",
      "epoch:10 step:7898 [D loss: 0.619187, acc: 63.28%] [G loss: 1.721843]\n",
      "epoch:10 step:7899 [D loss: 0.782594, acc: 46.88%] [G loss: 1.647897]\n",
      "epoch:10 step:7900 [D loss: 0.647490, acc: 64.06%] [G loss: 1.677937]\n",
      "epoch:10 step:7901 [D loss: 0.698915, acc: 53.91%] [G loss: 1.730734]\n",
      "epoch:10 step:7902 [D loss: 0.843825, acc: 34.38%] [G loss: 1.435988]\n",
      "epoch:10 step:7903 [D loss: 0.647525, acc: 63.28%] [G loss: 1.620747]\n",
      "epoch:10 step:7904 [D loss: 0.739496, acc: 45.31%] [G loss: 1.525704]\n",
      "epoch:10 step:7905 [D loss: 0.745245, acc: 49.22%] [G loss: 1.547986]\n",
      "epoch:10 step:7906 [D loss: 0.569696, acc: 67.19%] [G loss: 1.924274]\n",
      "epoch:10 step:7907 [D loss: 0.855296, acc: 35.16%] [G loss: 1.467481]\n",
      "epoch:10 step:7908 [D loss: 0.732335, acc: 47.66%] [G loss: 1.638989]\n",
      "epoch:10 step:7909 [D loss: 0.585674, acc: 70.31%] [G loss: 1.676880]\n",
      "epoch:10 step:7910 [D loss: 0.688662, acc: 57.03%] [G loss: 1.709712]\n",
      "epoch:10 step:7911 [D loss: 0.735950, acc: 49.22%] [G loss: 1.539283]\n",
      "epoch:10 step:7912 [D loss: 0.649320, acc: 59.38%] [G loss: 1.756638]\n",
      "epoch:10 step:7913 [D loss: 0.785740, acc: 44.53%] [G loss: 1.557899]\n",
      "epoch:10 step:7914 [D loss: 0.757493, acc: 42.19%] [G loss: 1.594636]\n",
      "epoch:10 step:7915 [D loss: 0.586559, acc: 70.31%] [G loss: 1.625379]\n",
      "epoch:10 step:7916 [D loss: 0.689973, acc: 53.91%] [G loss: 1.630205]\n",
      "epoch:10 step:7917 [D loss: 0.809597, acc: 42.19%] [G loss: 1.574578]\n",
      "epoch:10 step:7918 [D loss: 0.615888, acc: 66.41%] [G loss: 1.668091]\n",
      "epoch:10 step:7919 [D loss: 0.673965, acc: 57.81%] [G loss: 1.639417]\n",
      "epoch:10 step:7920 [D loss: 0.555643, acc: 72.66%] [G loss: 1.848368]\n",
      "epoch:10 step:7921 [D loss: 0.700259, acc: 50.00%] [G loss: 1.554166]\n",
      "epoch:10 step:7922 [D loss: 0.726840, acc: 50.00%] [G loss: 1.700734]\n",
      "epoch:10 step:7923 [D loss: 0.756284, acc: 48.44%] [G loss: 1.632189]\n",
      "epoch:10 step:7924 [D loss: 0.630840, acc: 67.97%] [G loss: 1.613972]\n",
      "epoch:10 step:7925 [D loss: 0.954343, acc: 24.22%] [G loss: 1.434893]\n",
      "epoch:10 step:7926 [D loss: 0.704895, acc: 51.56%] [G loss: 1.656028]\n",
      "epoch:10 step:7927 [D loss: 0.719856, acc: 50.78%] [G loss: 1.672854]\n",
      "epoch:10 step:7928 [D loss: 0.667017, acc: 64.06%] [G loss: 1.607113]\n",
      "epoch:10 step:7929 [D loss: 0.529530, acc: 79.69%] [G loss: 2.109429]\n",
      "epoch:10 step:7930 [D loss: 0.724685, acc: 48.44%] [G loss: 1.682882]\n",
      "epoch:10 step:7931 [D loss: 0.642384, acc: 64.06%] [G loss: 1.693061]\n",
      "epoch:10 step:7932 [D loss: 0.675313, acc: 56.25%] [G loss: 1.738925]\n",
      "epoch:10 step:7933 [D loss: 0.642168, acc: 69.53%] [G loss: 1.798514]\n",
      "epoch:10 step:7934 [D loss: 0.639946, acc: 66.41%] [G loss: 1.563330]\n",
      "epoch:10 step:7935 [D loss: 0.636184, acc: 63.28%] [G loss: 1.547803]\n",
      "epoch:10 step:7936 [D loss: 0.663580, acc: 60.16%] [G loss: 1.624729]\n",
      "epoch:10 step:7937 [D loss: 0.692994, acc: 60.94%] [G loss: 1.759589]\n",
      "epoch:10 step:7938 [D loss: 0.663750, acc: 57.81%] [G loss: 1.764429]\n",
      "epoch:10 step:7939 [D loss: 0.611574, acc: 71.88%] [G loss: 1.746317]\n",
      "epoch:10 step:7940 [D loss: 0.859853, acc: 30.47%] [G loss: 1.377752]\n",
      "epoch:10 step:7941 [D loss: 0.598174, acc: 73.44%] [G loss: 1.897082]\n",
      "epoch:10 step:7942 [D loss: 0.763527, acc: 41.41%] [G loss: 1.538702]\n",
      "epoch:10 step:7943 [D loss: 0.679874, acc: 55.47%] [G loss: 1.569770]\n",
      "epoch:10 step:7944 [D loss: 0.699359, acc: 53.91%] [G loss: 1.647105]\n",
      "epoch:10 step:7945 [D loss: 0.677053, acc: 58.59%] [G loss: 1.613294]\n",
      "epoch:10 step:7946 [D loss: 0.684585, acc: 57.81%] [G loss: 1.690232]\n",
      "epoch:10 step:7947 [D loss: 0.675198, acc: 63.28%] [G loss: 1.613493]\n",
      "epoch:10 step:7948 [D loss: 0.683151, acc: 59.38%] [G loss: 1.686419]\n",
      "epoch:10 step:7949 [D loss: 0.632434, acc: 66.41%] [G loss: 1.645001]\n",
      "epoch:10 step:7950 [D loss: 0.603240, acc: 62.50%] [G loss: 1.436126]\n",
      "epoch:10 step:7951 [D loss: 0.874444, acc: 25.00%] [G loss: 1.502848]\n",
      "epoch:10 step:7952 [D loss: 0.813648, acc: 32.03%] [G loss: 1.458475]\n",
      "epoch:10 step:7953 [D loss: 0.724883, acc: 47.66%] [G loss: 1.561930]\n",
      "epoch:10 step:7954 [D loss: 0.711199, acc: 46.88%] [G loss: 1.598301]\n",
      "epoch:10 step:7955 [D loss: 0.614548, acc: 67.19%] [G loss: 1.642833]\n",
      "epoch:10 step:7956 [D loss: 0.590099, acc: 76.56%] [G loss: 1.663704]\n",
      "epoch:10 step:7957 [D loss: 0.636550, acc: 62.50%] [G loss: 1.713503]\n",
      "epoch:10 step:7958 [D loss: 0.710616, acc: 56.25%] [G loss: 1.696199]\n",
      "epoch:10 step:7959 [D loss: 0.756963, acc: 44.53%] [G loss: 1.519610]\n",
      "epoch:10 step:7960 [D loss: 0.694447, acc: 57.03%] [G loss: 1.490514]\n",
      "epoch:10 step:7961 [D loss: 0.747597, acc: 39.06%] [G loss: 1.503397]\n",
      "epoch:10 step:7962 [D loss: 0.706548, acc: 52.34%] [G loss: 1.592863]\n",
      "epoch:10 step:7963 [D loss: 0.721077, acc: 47.66%] [G loss: 1.877106]\n",
      "epoch:10 step:7964 [D loss: 0.586243, acc: 71.09%] [G loss: 1.536052]\n",
      "epoch:10 step:7965 [D loss: 0.753366, acc: 40.62%] [G loss: 1.681803]\n",
      "epoch:10 step:7966 [D loss: 0.664901, acc: 56.25%] [G loss: 1.756078]\n",
      "epoch:10 step:7967 [D loss: 0.704525, acc: 46.88%] [G loss: 1.534574]\n",
      "epoch:10 step:7968 [D loss: 0.557910, acc: 77.34%] [G loss: 1.737938]\n",
      "epoch:10 step:7969 [D loss: 0.696128, acc: 57.03%] [G loss: 1.725026]\n",
      "epoch:10 step:7970 [D loss: 0.759971, acc: 40.62%] [G loss: 1.797786]\n",
      "epoch:10 step:7971 [D loss: 0.692010, acc: 50.78%] [G loss: 1.585521]\n",
      "epoch:10 step:7972 [D loss: 0.589343, acc: 73.44%] [G loss: 1.720917]\n",
      "epoch:10 step:7973 [D loss: 0.707846, acc: 53.12%] [G loss: 1.747356]\n",
      "epoch:10 step:7974 [D loss: 0.669922, acc: 55.47%] [G loss: 1.596985]\n",
      "epoch:10 step:7975 [D loss: 0.715786, acc: 49.22%] [G loss: 1.613845]\n",
      "epoch:10 step:7976 [D loss: 0.744921, acc: 48.44%] [G loss: 1.527546]\n",
      "epoch:10 step:7977 [D loss: 0.651734, acc: 64.06%] [G loss: 1.567961]\n",
      "epoch:10 step:7978 [D loss: 0.723666, acc: 53.91%] [G loss: 1.685756]\n",
      "epoch:10 step:7979 [D loss: 0.601588, acc: 64.84%] [G loss: 1.547416]\n",
      "epoch:10 step:7980 [D loss: 0.702049, acc: 51.56%] [G loss: 1.616216]\n",
      "epoch:10 step:7981 [D loss: 0.717457, acc: 51.56%] [G loss: 1.512775]\n",
      "epoch:10 step:7982 [D loss: 0.614968, acc: 68.75%] [G loss: 1.786389]\n",
      "epoch:10 step:7983 [D loss: 0.772588, acc: 39.84%] [G loss: 1.428182]\n",
      "epoch:10 step:7984 [D loss: 0.743720, acc: 48.44%] [G loss: 1.580103]\n",
      "epoch:10 step:7985 [D loss: 0.608370, acc: 69.53%] [G loss: 1.746858]\n",
      "epoch:10 step:7986 [D loss: 0.780419, acc: 42.97%] [G loss: 1.586843]\n",
      "epoch:10 step:7987 [D loss: 0.675479, acc: 58.59%] [G loss: 1.584940]\n",
      "epoch:10 step:7988 [D loss: 0.732646, acc: 52.34%] [G loss: 1.557620]\n",
      "epoch:10 step:7989 [D loss: 0.654242, acc: 61.72%] [G loss: 1.694283]\n",
      "epoch:10 step:7990 [D loss: 0.801857, acc: 33.59%] [G loss: 1.501436]\n",
      "epoch:10 step:7991 [D loss: 0.565158, acc: 77.34%] [G loss: 2.025962]\n",
      "epoch:10 step:7992 [D loss: 0.785300, acc: 40.62%] [G loss: 1.570025]\n",
      "epoch:10 step:7993 [D loss: 0.546667, acc: 75.78%] [G loss: 1.669903]\n",
      "epoch:10 step:7994 [D loss: 0.613022, acc: 69.53%] [G loss: 1.688494]\n",
      "epoch:10 step:7995 [D loss: 0.676700, acc: 60.94%] [G loss: 1.561340]\n",
      "epoch:10 step:7996 [D loss: 0.627342, acc: 68.75%] [G loss: 1.704350]\n",
      "epoch:10 step:7997 [D loss: 0.751583, acc: 51.56%] [G loss: 1.414974]\n",
      "epoch:10 step:7998 [D loss: 0.721427, acc: 49.22%] [G loss: 1.501746]\n",
      "epoch:10 step:7999 [D loss: 0.712260, acc: 46.88%] [G loss: 1.643060]\n",
      "epoch:10 step:8000 [D loss: 0.738198, acc: 47.66%] [G loss: 1.600572]\n",
      "epoch:10 step:8001 [D loss: 0.684065, acc: 55.47%] [G loss: 1.750854]\n",
      "epoch:10 step:8002 [D loss: 0.763258, acc: 46.88%] [G loss: 1.599516]\n",
      "epoch:10 step:8003 [D loss: 0.622256, acc: 65.62%] [G loss: 1.676909]\n",
      "epoch:10 step:8004 [D loss: 0.671946, acc: 56.25%] [G loss: 1.714543]\n",
      "epoch:10 step:8005 [D loss: 0.628987, acc: 64.84%] [G loss: 1.723634]\n",
      "epoch:10 step:8006 [D loss: 0.976726, acc: 15.62%] [G loss: 1.417613]\n",
      "epoch:10 step:8007 [D loss: 0.748360, acc: 47.66%] [G loss: 1.522146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8008 [D loss: 0.585835, acc: 74.22%] [G loss: 1.623536]\n",
      "epoch:10 step:8009 [D loss: 0.783869, acc: 42.97%] [G loss: 1.459613]\n",
      "epoch:10 step:8010 [D loss: 0.728062, acc: 48.44%] [G loss: 1.630442]\n",
      "epoch:10 step:8011 [D loss: 0.702914, acc: 53.12%] [G loss: 1.594020]\n",
      "epoch:10 step:8012 [D loss: 0.755910, acc: 42.19%] [G loss: 1.472467]\n",
      "epoch:10 step:8013 [D loss: 0.615748, acc: 71.09%] [G loss: 1.696227]\n",
      "epoch:10 step:8014 [D loss: 0.687202, acc: 58.59%] [G loss: 1.596666]\n",
      "epoch:10 step:8015 [D loss: 0.842166, acc: 30.47%] [G loss: 1.426957]\n",
      "epoch:10 step:8016 [D loss: 0.764468, acc: 43.75%] [G loss: 1.641662]\n",
      "epoch:10 step:8017 [D loss: 0.703080, acc: 52.34%] [G loss: 1.612363]\n",
      "epoch:10 step:8018 [D loss: 0.626667, acc: 68.75%] [G loss: 1.753661]\n",
      "epoch:10 step:8019 [D loss: 0.692086, acc: 59.38%] [G loss: 1.553169]\n",
      "epoch:10 step:8020 [D loss: 0.682959, acc: 52.34%] [G loss: 1.691721]\n",
      "epoch:10 step:8021 [D loss: 0.739808, acc: 42.97%] [G loss: 1.579916]\n",
      "epoch:10 step:8022 [D loss: 0.694563, acc: 55.47%] [G loss: 1.593884]\n",
      "epoch:10 step:8023 [D loss: 0.657740, acc: 63.28%] [G loss: 1.451580]\n",
      "epoch:10 step:8024 [D loss: 0.551983, acc: 79.69%] [G loss: 1.938459]\n",
      "epoch:10 step:8025 [D loss: 0.614987, acc: 67.19%] [G loss: 1.769348]\n",
      "epoch:10 step:8026 [D loss: 0.672325, acc: 61.72%] [G loss: 1.699254]\n",
      "epoch:10 step:8027 [D loss: 0.784680, acc: 35.94%] [G loss: 1.432403]\n",
      "epoch:10 step:8028 [D loss: 0.537108, acc: 77.34%] [G loss: 1.785005]\n",
      "epoch:10 step:8029 [D loss: 0.641639, acc: 67.19%] [G loss: 1.720082]\n",
      "epoch:10 step:8030 [D loss: 0.636578, acc: 68.75%] [G loss: 1.651902]\n",
      "epoch:10 step:8031 [D loss: 0.679157, acc: 59.38%] [G loss: 1.634888]\n",
      "epoch:10 step:8032 [D loss: 0.598355, acc: 70.31%] [G loss: 1.849494]\n",
      "epoch:10 step:8033 [D loss: 0.649727, acc: 59.38%] [G loss: 1.568160]\n",
      "epoch:10 step:8034 [D loss: 0.645589, acc: 63.28%] [G loss: 1.712125]\n",
      "epoch:10 step:8035 [D loss: 0.576672, acc: 76.56%] [G loss: 1.785120]\n",
      "epoch:10 step:8036 [D loss: 0.746477, acc: 47.66%] [G loss: 1.596021]\n",
      "epoch:10 step:8037 [D loss: 0.746213, acc: 42.97%] [G loss: 1.522531]\n",
      "epoch:10 step:8038 [D loss: 0.652985, acc: 62.50%] [G loss: 1.545712]\n",
      "epoch:10 step:8039 [D loss: 0.631924, acc: 58.59%] [G loss: 1.664876]\n",
      "epoch:10 step:8040 [D loss: 0.695857, acc: 51.56%] [G loss: 1.580151]\n",
      "epoch:10 step:8041 [D loss: 0.554314, acc: 79.69%] [G loss: 1.794556]\n",
      "epoch:10 step:8042 [D loss: 0.776703, acc: 35.94%] [G loss: 1.585464]\n",
      "epoch:10 step:8043 [D loss: 0.711655, acc: 50.00%] [G loss: 1.610194]\n",
      "epoch:10 step:8044 [D loss: 0.741005, acc: 44.53%] [G loss: 1.691677]\n",
      "epoch:10 step:8045 [D loss: 0.729971, acc: 42.97%] [G loss: 1.673611]\n",
      "epoch:10 step:8046 [D loss: 0.769920, acc: 39.06%] [G loss: 1.740248]\n",
      "epoch:10 step:8047 [D loss: 0.669592, acc: 55.47%] [G loss: 1.797451]\n",
      "epoch:10 step:8048 [D loss: 0.759937, acc: 48.44%] [G loss: 1.600037]\n",
      "epoch:10 step:8049 [D loss: 0.688642, acc: 56.25%] [G loss: 1.633965]\n",
      "epoch:10 step:8050 [D loss: 0.648754, acc: 62.50%] [G loss: 1.738793]\n",
      "epoch:10 step:8051 [D loss: 0.700904, acc: 58.59%] [G loss: 1.763854]\n",
      "epoch:10 step:8052 [D loss: 0.639317, acc: 65.62%] [G loss: 1.673336]\n",
      "epoch:10 step:8053 [D loss: 0.626170, acc: 70.31%] [G loss: 1.600840]\n",
      "epoch:10 step:8054 [D loss: 0.661618, acc: 57.81%] [G loss: 1.637536]\n",
      "epoch:10 step:8055 [D loss: 0.625183, acc: 68.75%] [G loss: 1.578584]\n",
      "epoch:10 step:8056 [D loss: 0.551579, acc: 78.12%] [G loss: 1.917730]\n",
      "epoch:10 step:8057 [D loss: 0.684780, acc: 53.91%] [G loss: 1.758030]\n",
      "epoch:10 step:8058 [D loss: 0.655738, acc: 60.94%] [G loss: 1.580444]\n",
      "epoch:10 step:8059 [D loss: 0.787767, acc: 40.62%] [G loss: 1.588778]\n",
      "epoch:10 step:8060 [D loss: 0.743328, acc: 50.00%] [G loss: 1.701529]\n",
      "epoch:10 step:8061 [D loss: 0.687173, acc: 52.34%] [G loss: 1.696970]\n",
      "epoch:10 step:8062 [D loss: 0.633863, acc: 64.84%] [G loss: 1.653627]\n",
      "epoch:10 step:8063 [D loss: 0.693551, acc: 58.59%] [G loss: 1.716336]\n",
      "epoch:10 step:8064 [D loss: 0.668925, acc: 55.47%] [G loss: 1.823584]\n",
      "epoch:10 step:8065 [D loss: 0.810606, acc: 30.47%] [G loss: 1.549914]\n",
      "epoch:10 step:8066 [D loss: 0.752172, acc: 53.91%] [G loss: 1.595456]\n",
      "epoch:10 step:8067 [D loss: 0.780361, acc: 43.75%] [G loss: 1.579848]\n",
      "epoch:10 step:8068 [D loss: 0.618486, acc: 67.19%] [G loss: 1.747650]\n",
      "epoch:10 step:8069 [D loss: 0.704014, acc: 45.31%] [G loss: 1.605198]\n",
      "epoch:10 step:8070 [D loss: 0.610648, acc: 67.19%] [G loss: 2.019580]\n",
      "epoch:10 step:8071 [D loss: 0.620104, acc: 65.62%] [G loss: 1.782798]\n",
      "epoch:10 step:8072 [D loss: 0.654741, acc: 66.41%] [G loss: 1.652631]\n",
      "epoch:10 step:8073 [D loss: 0.627313, acc: 69.53%] [G loss: 1.813534]\n",
      "epoch:10 step:8074 [D loss: 0.737169, acc: 46.09%] [G loss: 1.565934]\n",
      "epoch:10 step:8075 [D loss: 0.679394, acc: 63.28%] [G loss: 1.709909]\n",
      "epoch:10 step:8076 [D loss: 0.680324, acc: 64.84%] [G loss: 1.711526]\n",
      "epoch:10 step:8077 [D loss: 1.065504, acc: 28.12%] [G loss: 1.377406]\n",
      "epoch:10 step:8078 [D loss: 0.742617, acc: 39.06%] [G loss: 1.672057]\n",
      "epoch:10 step:8079 [D loss: 0.692015, acc: 57.03%] [G loss: 1.704684]\n",
      "epoch:10 step:8080 [D loss: 0.725180, acc: 46.88%] [G loss: 1.692819]\n",
      "epoch:10 step:8081 [D loss: 0.700651, acc: 56.25%] [G loss: 1.752258]\n",
      "epoch:10 step:8082 [D loss: 0.660154, acc: 64.84%] [G loss: 1.564327]\n",
      "epoch:10 step:8083 [D loss: 0.743468, acc: 50.00%] [G loss: 1.793260]\n",
      "epoch:10 step:8084 [D loss: 0.733440, acc: 46.09%] [G loss: 1.481375]\n",
      "epoch:10 step:8085 [D loss: 0.577582, acc: 73.44%] [G loss: 1.613292]\n",
      "epoch:10 step:8086 [D loss: 0.598230, acc: 75.00%] [G loss: 1.761497]\n",
      "epoch:10 step:8087 [D loss: 0.692648, acc: 50.00%] [G loss: 1.562826]\n",
      "epoch:10 step:8088 [D loss: 0.671422, acc: 59.38%] [G loss: 1.773668]\n",
      "epoch:10 step:8089 [D loss: 0.660961, acc: 60.94%] [G loss: 1.668050]\n",
      "epoch:10 step:8090 [D loss: 0.687140, acc: 53.12%] [G loss: 1.662187]\n",
      "epoch:10 step:8091 [D loss: 0.687100, acc: 56.25%] [G loss: 1.618332]\n",
      "epoch:10 step:8092 [D loss: 0.616770, acc: 68.75%] [G loss: 1.445828]\n",
      "epoch:10 step:8093 [D loss: 0.730984, acc: 50.78%] [G loss: 1.722770]\n",
      "epoch:10 step:8094 [D loss: 0.751325, acc: 43.75%] [G loss: 1.493206]\n",
      "epoch:10 step:8095 [D loss: 0.626341, acc: 64.84%] [G loss: 1.767102]\n",
      "epoch:10 step:8096 [D loss: 0.646289, acc: 63.28%] [G loss: 1.659521]\n",
      "epoch:10 step:8097 [D loss: 0.581218, acc: 71.09%] [G loss: 1.761547]\n",
      "epoch:10 step:8098 [D loss: 0.721132, acc: 52.34%] [G loss: 1.718115]\n",
      "epoch:10 step:8099 [D loss: 0.766127, acc: 35.16%] [G loss: 1.573321]\n",
      "epoch:10 step:8100 [D loss: 0.588680, acc: 71.88%] [G loss: 1.755368]\n",
      "epoch:10 step:8101 [D loss: 0.767449, acc: 40.62%] [G loss: 1.586592]\n",
      "epoch:10 step:8102 [D loss: 0.720590, acc: 44.53%] [G loss: 1.718565]\n",
      "epoch:10 step:8103 [D loss: 0.709150, acc: 51.56%] [G loss: 1.448271]\n",
      "epoch:10 step:8104 [D loss: 0.584863, acc: 70.31%] [G loss: 1.664869]\n",
      "epoch:10 step:8105 [D loss: 0.649826, acc: 62.50%] [G loss: 1.728198]\n",
      "epoch:10 step:8106 [D loss: 0.532423, acc: 79.69%] [G loss: 1.757352]\n",
      "epoch:10 step:8107 [D loss: 0.709578, acc: 52.34%] [G loss: 1.568448]\n",
      "epoch:10 step:8108 [D loss: 0.542896, acc: 82.03%] [G loss: 1.739969]\n",
      "epoch:10 step:8109 [D loss: 0.678665, acc: 57.81%] [G loss: 1.742359]\n",
      "epoch:10 step:8110 [D loss: 0.797815, acc: 37.50%] [G loss: 1.396360]\n",
      "epoch:10 step:8111 [D loss: 0.810485, acc: 32.81%] [G loss: 1.427213]\n",
      "epoch:10 step:8112 [D loss: 0.702974, acc: 54.69%] [G loss: 1.785058]\n",
      "epoch:10 step:8113 [D loss: 0.616309, acc: 65.62%] [G loss: 1.713748]\n",
      "epoch:10 step:8114 [D loss: 0.673294, acc: 54.69%] [G loss: 1.657551]\n",
      "epoch:10 step:8115 [D loss: 0.839170, acc: 32.03%] [G loss: 1.493906]\n",
      "epoch:10 step:8116 [D loss: 0.667203, acc: 60.16%] [G loss: 1.704497]\n",
      "epoch:10 step:8117 [D loss: 0.663456, acc: 58.59%] [G loss: 1.536504]\n",
      "epoch:10 step:8118 [D loss: 0.645325, acc: 62.50%] [G loss: 1.546092]\n",
      "epoch:10 step:8119 [D loss: 0.645548, acc: 63.28%] [G loss: 1.702826]\n",
      "epoch:10 step:8120 [D loss: 0.638658, acc: 64.06%] [G loss: 1.664601]\n",
      "epoch:10 step:8121 [D loss: 0.662851, acc: 56.25%] [G loss: 1.505341]\n",
      "epoch:10 step:8122 [D loss: 0.739877, acc: 50.78%] [G loss: 1.611226]\n",
      "epoch:10 step:8123 [D loss: 0.683491, acc: 54.69%] [G loss: 1.485131]\n",
      "epoch:10 step:8124 [D loss: 0.674503, acc: 57.03%] [G loss: 1.606949]\n",
      "epoch:10 step:8125 [D loss: 0.829220, acc: 36.72%] [G loss: 1.461778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8126 [D loss: 0.702969, acc: 53.12%] [G loss: 1.710501]\n",
      "epoch:10 step:8127 [D loss: 0.678988, acc: 59.38%] [G loss: 1.682802]\n",
      "epoch:10 step:8128 [D loss: 0.561559, acc: 82.81%] [G loss: 1.793255]\n",
      "epoch:10 step:8129 [D loss: 0.752726, acc: 45.31%] [G loss: 1.505364]\n",
      "epoch:10 step:8130 [D loss: 0.718510, acc: 51.56%] [G loss: 1.585835]\n",
      "epoch:10 step:8131 [D loss: 0.654281, acc: 61.72%] [G loss: 1.751022]\n",
      "epoch:10 step:8132 [D loss: 0.739367, acc: 45.31%] [G loss: 1.686029]\n",
      "epoch:10 step:8133 [D loss: 0.450677, acc: 83.59%] [G loss: 1.940527]\n",
      "epoch:10 step:8134 [D loss: 0.475575, acc: 85.16%] [G loss: 1.796790]\n",
      "epoch:10 step:8135 [D loss: 0.744453, acc: 46.09%] [G loss: 1.569455]\n",
      "epoch:10 step:8136 [D loss: 0.702769, acc: 57.03%] [G loss: 1.576265]\n",
      "epoch:10 step:8137 [D loss: 0.568205, acc: 78.12%] [G loss: 1.942658]\n",
      "epoch:10 step:8138 [D loss: 0.695213, acc: 49.22%] [G loss: 1.608480]\n",
      "epoch:10 step:8139 [D loss: 0.671443, acc: 60.16%] [G loss: 1.536726]\n",
      "epoch:10 step:8140 [D loss: 0.624343, acc: 65.62%] [G loss: 1.552380]\n",
      "epoch:10 step:8141 [D loss: 0.666715, acc: 59.38%] [G loss: 1.852109]\n",
      "epoch:10 step:8142 [D loss: 0.673258, acc: 62.50%] [G loss: 1.850714]\n",
      "epoch:10 step:8143 [D loss: 0.715431, acc: 53.12%] [G loss: 1.671843]\n",
      "epoch:10 step:8144 [D loss: 0.684630, acc: 56.25%] [G loss: 1.782117]\n",
      "epoch:10 step:8145 [D loss: 0.661769, acc: 59.38%] [G loss: 1.676503]\n",
      "epoch:10 step:8146 [D loss: 0.725101, acc: 53.91%] [G loss: 1.732883]\n",
      "epoch:10 step:8147 [D loss: 0.660740, acc: 57.81%] [G loss: 1.754783]\n",
      "epoch:10 step:8148 [D loss: 0.801327, acc: 36.72%] [G loss: 1.611993]\n",
      "epoch:10 step:8149 [D loss: 0.811823, acc: 34.38%] [G loss: 1.461994]\n",
      "epoch:10 step:8150 [D loss: 0.676896, acc: 54.69%] [G loss: 1.651312]\n",
      "epoch:10 step:8151 [D loss: 0.678279, acc: 61.72%] [G loss: 1.624556]\n",
      "epoch:10 step:8152 [D loss: 0.592799, acc: 71.09%] [G loss: 1.521839]\n",
      "epoch:10 step:8153 [D loss: 0.688683, acc: 50.78%] [G loss: 1.566906]\n",
      "epoch:10 step:8154 [D loss: 0.716337, acc: 53.12%] [G loss: 1.547769]\n",
      "epoch:10 step:8155 [D loss: 0.631340, acc: 65.62%] [G loss: 1.741084]\n",
      "epoch:10 step:8156 [D loss: 0.673730, acc: 58.59%] [G loss: 1.638242]\n",
      "epoch:10 step:8157 [D loss: 0.750827, acc: 51.56%] [G loss: 1.649505]\n",
      "epoch:10 step:8158 [D loss: 0.581408, acc: 71.09%] [G loss: 1.777296]\n",
      "epoch:10 step:8159 [D loss: 0.649174, acc: 64.06%] [G loss: 1.771840]\n",
      "epoch:10 step:8160 [D loss: 0.784135, acc: 42.19%] [G loss: 1.542628]\n",
      "epoch:10 step:8161 [D loss: 0.684267, acc: 55.47%] [G loss: 1.720344]\n",
      "epoch:10 step:8162 [D loss: 0.700501, acc: 52.34%] [G loss: 1.720248]\n",
      "epoch:10 step:8163 [D loss: 0.674495, acc: 55.47%] [G loss: 1.710288]\n",
      "epoch:10 step:8164 [D loss: 0.730811, acc: 49.22%] [G loss: 1.547199]\n",
      "epoch:10 step:8165 [D loss: 0.657811, acc: 60.16%] [G loss: 1.745181]\n",
      "epoch:10 step:8166 [D loss: 0.708449, acc: 57.03%] [G loss: 1.690261]\n",
      "epoch:10 step:8167 [D loss: 0.693894, acc: 58.59%] [G loss: 1.669587]\n",
      "epoch:10 step:8168 [D loss: 0.715445, acc: 50.78%] [G loss: 1.489596]\n",
      "epoch:10 step:8169 [D loss: 0.689113, acc: 63.28%] [G loss: 1.620622]\n",
      "epoch:10 step:8170 [D loss: 0.720149, acc: 42.97%] [G loss: 1.509157]\n",
      "epoch:10 step:8171 [D loss: 0.647507, acc: 64.84%] [G loss: 1.519485]\n",
      "epoch:10 step:8172 [D loss: 0.479882, acc: 91.41%] [G loss: 1.699900]\n",
      "epoch:10 step:8173 [D loss: 0.726523, acc: 47.66%] [G loss: 1.587131]\n",
      "epoch:10 step:8174 [D loss: 0.622273, acc: 67.97%] [G loss: 1.801385]\n",
      "epoch:10 step:8175 [D loss: 0.715847, acc: 50.00%] [G loss: 1.809033]\n",
      "epoch:10 step:8176 [D loss: 0.708575, acc: 53.91%] [G loss: 1.705878]\n",
      "epoch:10 step:8177 [D loss: 0.535968, acc: 78.91%] [G loss: 1.890117]\n",
      "epoch:10 step:8178 [D loss: 0.755120, acc: 45.31%] [G loss: 1.480293]\n",
      "epoch:10 step:8179 [D loss: 0.612401, acc: 71.09%] [G loss: 1.795391]\n",
      "epoch:10 step:8180 [D loss: 0.566894, acc: 69.53%] [G loss: 1.886213]\n",
      "epoch:10 step:8181 [D loss: 0.627069, acc: 64.06%] [G loss: 1.713497]\n",
      "epoch:10 step:8182 [D loss: 0.605011, acc: 67.97%] [G loss: 1.671349]\n",
      "epoch:10 step:8183 [D loss: 0.804888, acc: 37.50%] [G loss: 1.482630]\n",
      "epoch:10 step:8184 [D loss: 0.632949, acc: 69.53%] [G loss: 1.931022]\n",
      "epoch:10 step:8185 [D loss: 0.774991, acc: 49.22%] [G loss: 1.654780]\n",
      "epoch:10 step:8186 [D loss: 0.690708, acc: 50.78%] [G loss: 1.698447]\n",
      "epoch:10 step:8187 [D loss: 0.614521, acc: 69.53%] [G loss: 1.795732]\n",
      "epoch:10 step:8188 [D loss: 0.841700, acc: 31.25%] [G loss: 1.676890]\n",
      "epoch:10 step:8189 [D loss: 0.594439, acc: 72.66%] [G loss: 1.815634]\n",
      "epoch:10 step:8190 [D loss: 0.676571, acc: 55.47%] [G loss: 1.881040]\n",
      "epoch:10 step:8191 [D loss: 0.696241, acc: 52.34%] [G loss: 1.543004]\n",
      "epoch:10 step:8192 [D loss: 0.575665, acc: 71.88%] [G loss: 2.109630]\n",
      "epoch:10 step:8193 [D loss: 0.750587, acc: 46.88%] [G loss: 1.540313]\n",
      "epoch:10 step:8194 [D loss: 0.763896, acc: 42.19%] [G loss: 1.556293]\n",
      "epoch:10 step:8195 [D loss: 0.733099, acc: 51.56%] [G loss: 1.765511]\n",
      "epoch:10 step:8196 [D loss: 0.715257, acc: 52.34%] [G loss: 1.669309]\n",
      "epoch:10 step:8197 [D loss: 0.735625, acc: 53.91%] [G loss: 1.742943]\n",
      "epoch:10 step:8198 [D loss: 0.786160, acc: 39.84%] [G loss: 1.609122]\n",
      "epoch:10 step:8199 [D loss: 0.731585, acc: 47.66%] [G loss: 1.658822]\n",
      "epoch:10 step:8200 [D loss: 0.644476, acc: 64.06%] [G loss: 1.890336]\n",
      "epoch:10 step:8201 [D loss: 0.607223, acc: 70.31%] [G loss: 1.606271]\n",
      "epoch:10 step:8202 [D loss: 0.650200, acc: 66.41%] [G loss: 1.655593]\n",
      "epoch:10 step:8203 [D loss: 0.672339, acc: 60.94%] [G loss: 1.561587]\n",
      "epoch:10 step:8204 [D loss: 0.639360, acc: 64.06%] [G loss: 1.779024]\n",
      "epoch:10 step:8205 [D loss: 0.651966, acc: 57.03%] [G loss: 1.663754]\n",
      "epoch:10 step:8206 [D loss: 0.567629, acc: 78.12%] [G loss: 1.924585]\n",
      "epoch:10 step:8207 [D loss: 0.594426, acc: 68.75%] [G loss: 1.604572]\n",
      "epoch:10 step:8208 [D loss: 0.795719, acc: 39.06%] [G loss: 1.569484]\n",
      "epoch:10 step:8209 [D loss: 0.709159, acc: 51.56%] [G loss: 1.706864]\n",
      "epoch:10 step:8210 [D loss: 0.664396, acc: 58.59%] [G loss: 1.734772]\n",
      "epoch:10 step:8211 [D loss: 0.665937, acc: 58.59%] [G loss: 1.796979]\n",
      "epoch:10 step:8212 [D loss: 0.563873, acc: 65.62%] [G loss: 1.852376]\n",
      "epoch:10 step:8213 [D loss: 0.748885, acc: 49.22%] [G loss: 1.775844]\n",
      "epoch:10 step:8214 [D loss: 0.737145, acc: 51.56%] [G loss: 1.713808]\n",
      "epoch:10 step:8215 [D loss: 0.540659, acc: 75.00%] [G loss: 1.947399]\n",
      "epoch:10 step:8216 [D loss: 0.717530, acc: 54.69%] [G loss: 1.753998]\n",
      "epoch:10 step:8217 [D loss: 0.639662, acc: 65.62%] [G loss: 1.869312]\n",
      "epoch:10 step:8218 [D loss: 0.632466, acc: 67.97%] [G loss: 2.060648]\n",
      "epoch:10 step:8219 [D loss: 0.458732, acc: 87.50%] [G loss: 2.195361]\n",
      "epoch:10 step:8220 [D loss: 0.612972, acc: 67.19%] [G loss: 1.872210]\n",
      "epoch:10 step:8221 [D loss: 0.753587, acc: 45.31%] [G loss: 1.592605]\n",
      "epoch:10 step:8222 [D loss: 0.572330, acc: 71.88%] [G loss: 2.059128]\n",
      "epoch:10 step:8223 [D loss: 0.623210, acc: 63.28%] [G loss: 1.843508]\n",
      "epoch:10 step:8224 [D loss: 0.629219, acc: 67.19%] [G loss: 1.651314]\n",
      "epoch:10 step:8225 [D loss: 0.637234, acc: 61.72%] [G loss: 1.733828]\n",
      "epoch:10 step:8226 [D loss: 0.578353, acc: 72.66%] [G loss: 1.728146]\n",
      "epoch:10 step:8227 [D loss: 0.658653, acc: 63.28%] [G loss: 1.699532]\n",
      "epoch:10 step:8228 [D loss: 0.643725, acc: 60.16%] [G loss: 1.734700]\n",
      "epoch:10 step:8229 [D loss: 0.658446, acc: 61.72%] [G loss: 1.853051]\n",
      "epoch:10 step:8230 [D loss: 0.767060, acc: 46.09%] [G loss: 1.554032]\n",
      "epoch:10 step:8231 [D loss: 0.802248, acc: 42.19%] [G loss: 1.565637]\n",
      "epoch:10 step:8232 [D loss: 0.482007, acc: 88.28%] [G loss: 1.922703]\n",
      "epoch:10 step:8233 [D loss: 0.629816, acc: 64.84%] [G loss: 1.773712]\n",
      "epoch:10 step:8234 [D loss: 0.933514, acc: 28.12%] [G loss: 1.515504]\n",
      "epoch:10 step:8235 [D loss: 0.627666, acc: 59.38%] [G loss: 1.628404]\n",
      "epoch:10 step:8236 [D loss: 0.840374, acc: 35.16%] [G loss: 1.531286]\n",
      "epoch:10 step:8237 [D loss: 0.660956, acc: 63.28%] [G loss: 1.620511]\n",
      "epoch:10 step:8238 [D loss: 0.630252, acc: 67.19%] [G loss: 1.712473]\n",
      "epoch:10 step:8239 [D loss: 0.724602, acc: 50.78%] [G loss: 1.585577]\n",
      "epoch:10 step:8240 [D loss: 0.644168, acc: 65.62%] [G loss: 1.640922]\n",
      "epoch:10 step:8241 [D loss: 0.674733, acc: 60.16%] [G loss: 1.751652]\n",
      "epoch:10 step:8242 [D loss: 0.647847, acc: 59.38%] [G loss: 1.725070]\n",
      "epoch:10 step:8243 [D loss: 0.663766, acc: 57.81%] [G loss: 1.639088]\n",
      "epoch:10 step:8244 [D loss: 0.772488, acc: 45.31%] [G loss: 1.535733]\n",
      "epoch:10 step:8245 [D loss: 0.689400, acc: 53.91%] [G loss: 1.786221]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8246 [D loss: 0.464869, acc: 82.03%] [G loss: 1.908431]\n",
      "epoch:10 step:8247 [D loss: 0.870717, acc: 26.56%] [G loss: 1.525187]\n",
      "epoch:10 step:8248 [D loss: 0.617333, acc: 67.19%] [G loss: 1.839492]\n",
      "epoch:10 step:8249 [D loss: 0.778709, acc: 42.19%] [G loss: 1.535436]\n",
      "epoch:10 step:8250 [D loss: 0.452049, acc: 78.91%] [G loss: 1.730194]\n",
      "epoch:10 step:8251 [D loss: 0.707962, acc: 53.91%] [G loss: 1.739707]\n",
      "epoch:10 step:8252 [D loss: 0.740172, acc: 51.56%] [G loss: 1.701716]\n",
      "epoch:10 step:8253 [D loss: 0.645627, acc: 62.50%] [G loss: 1.593507]\n",
      "epoch:10 step:8254 [D loss: 0.625809, acc: 71.09%] [G loss: 2.002192]\n",
      "epoch:10 step:8255 [D loss: 0.932593, acc: 27.34%] [G loss: 1.323159]\n",
      "epoch:10 step:8256 [D loss: 0.649236, acc: 62.50%] [G loss: 1.749722]\n",
      "epoch:10 step:8257 [D loss: 0.638120, acc: 58.59%] [G loss: 1.667046]\n",
      "epoch:10 step:8258 [D loss: 0.511042, acc: 84.38%] [G loss: 1.900254]\n",
      "epoch:10 step:8259 [D loss: 0.723969, acc: 54.69%] [G loss: 1.618448]\n",
      "epoch:10 step:8260 [D loss: 0.663502, acc: 60.94%] [G loss: 1.637438]\n",
      "epoch:10 step:8261 [D loss: 0.631655, acc: 58.59%] [G loss: 1.761636]\n",
      "epoch:10 step:8262 [D loss: 0.798823, acc: 37.50%] [G loss: 1.447382]\n",
      "epoch:10 step:8263 [D loss: 0.655287, acc: 64.84%] [G loss: 1.623309]\n",
      "epoch:10 step:8264 [D loss: 0.791759, acc: 37.50%] [G loss: 1.533812]\n",
      "epoch:10 step:8265 [D loss: 0.591938, acc: 74.22%] [G loss: 1.810950]\n",
      "epoch:10 step:8266 [D loss: 0.710371, acc: 53.12%] [G loss: 1.514790]\n",
      "epoch:10 step:8267 [D loss: 0.700782, acc: 57.03%] [G loss: 1.680994]\n",
      "epoch:10 step:8268 [D loss: 0.573158, acc: 79.69%] [G loss: 1.627748]\n",
      "epoch:10 step:8269 [D loss: 0.683507, acc: 58.59%] [G loss: 1.720522]\n",
      "epoch:10 step:8270 [D loss: 0.672410, acc: 60.16%] [G loss: 1.760257]\n",
      "epoch:10 step:8271 [D loss: 0.482801, acc: 82.03%] [G loss: 2.147721]\n",
      "epoch:10 step:8272 [D loss: 0.699789, acc: 53.12%] [G loss: 1.600777]\n",
      "epoch:10 step:8273 [D loss: 0.642738, acc: 62.50%] [G loss: 1.718624]\n",
      "epoch:10 step:8274 [D loss: 0.637796, acc: 64.06%] [G loss: 1.830385]\n",
      "epoch:10 step:8275 [D loss: 0.718484, acc: 56.25%] [G loss: 1.450497]\n",
      "epoch:10 step:8276 [D loss: 0.679088, acc: 57.81%] [G loss: 1.809386]\n",
      "epoch:10 step:8277 [D loss: 0.532894, acc: 85.94%] [G loss: 1.742054]\n",
      "epoch:10 step:8278 [D loss: 0.714551, acc: 50.78%] [G loss: 1.625890]\n",
      "epoch:10 step:8279 [D loss: 0.649463, acc: 64.84%] [G loss: 1.871186]\n",
      "epoch:10 step:8280 [D loss: 0.607915, acc: 73.44%] [G loss: 1.592570]\n",
      "epoch:10 step:8281 [D loss: 0.775810, acc: 46.09%] [G loss: 1.651255]\n",
      "epoch:10 step:8282 [D loss: 0.764341, acc: 42.19%] [G loss: 1.725481]\n",
      "epoch:10 step:8283 [D loss: 0.714169, acc: 53.91%] [G loss: 1.528522]\n",
      "epoch:10 step:8284 [D loss: 0.777277, acc: 48.44%] [G loss: 1.570213]\n",
      "epoch:10 step:8285 [D loss: 0.611255, acc: 69.53%] [G loss: 1.640696]\n",
      "epoch:10 step:8286 [D loss: 0.642429, acc: 61.72%] [G loss: 1.599786]\n",
      "epoch:10 step:8287 [D loss: 0.691411, acc: 57.03%] [G loss: 1.584707]\n",
      "epoch:10 step:8288 [D loss: 0.538977, acc: 75.78%] [G loss: 1.845286]\n",
      "epoch:10 step:8289 [D loss: 0.686780, acc: 57.81%] [G loss: 1.510095]\n",
      "epoch:10 step:8290 [D loss: 0.688952, acc: 50.78%] [G loss: 1.676111]\n",
      "epoch:10 step:8291 [D loss: 0.703458, acc: 52.34%] [G loss: 1.733897]\n",
      "epoch:10 step:8292 [D loss: 0.663683, acc: 58.59%] [G loss: 1.513766]\n",
      "epoch:10 step:8293 [D loss: 0.584968, acc: 75.00%] [G loss: 1.830838]\n",
      "epoch:10 step:8294 [D loss: 0.699229, acc: 59.38%] [G loss: 1.635942]\n",
      "epoch:10 step:8295 [D loss: 0.733551, acc: 46.88%] [G loss: 1.430988]\n",
      "epoch:10 step:8296 [D loss: 0.659879, acc: 58.59%] [G loss: 1.614277]\n",
      "epoch:10 step:8297 [D loss: 0.714487, acc: 52.34%] [G loss: 1.571726]\n",
      "epoch:10 step:8298 [D loss: 0.810811, acc: 36.72%] [G loss: 1.711089]\n",
      "epoch:10 step:8299 [D loss: 0.712803, acc: 55.47%] [G loss: 1.685674]\n",
      "epoch:10 step:8300 [D loss: 0.671053, acc: 59.38%] [G loss: 1.810447]\n",
      "epoch:10 step:8301 [D loss: 0.526795, acc: 80.47%] [G loss: 2.169110]\n",
      "epoch:10 step:8302 [D loss: 0.606212, acc: 64.06%] [G loss: 2.114620]\n",
      "epoch:10 step:8303 [D loss: 0.740744, acc: 46.88%] [G loss: 1.670425]\n",
      "epoch:10 step:8304 [D loss: 0.611514, acc: 67.97%] [G loss: 1.633500]\n",
      "epoch:10 step:8305 [D loss: 0.633732, acc: 64.84%] [G loss: 1.884638]\n",
      "epoch:10 step:8306 [D loss: 0.618472, acc: 66.41%] [G loss: 1.776982]\n",
      "epoch:10 step:8307 [D loss: 0.600365, acc: 74.22%] [G loss: 1.885759]\n",
      "epoch:10 step:8308 [D loss: 0.606945, acc: 67.97%] [G loss: 2.254619]\n",
      "epoch:10 step:8309 [D loss: 0.791711, acc: 37.50%] [G loss: 1.624911]\n",
      "epoch:10 step:8310 [D loss: 0.686960, acc: 59.38%] [G loss: 1.853273]\n",
      "epoch:10 step:8311 [D loss: 0.637073, acc: 63.28%] [G loss: 1.851673]\n",
      "epoch:10 step:8312 [D loss: 0.647925, acc: 60.94%] [G loss: 1.955588]\n",
      "epoch:10 step:8313 [D loss: 0.716343, acc: 54.69%] [G loss: 1.566730]\n",
      "epoch:10 step:8314 [D loss: 0.660003, acc: 58.59%] [G loss: 1.568012]\n",
      "epoch:10 step:8315 [D loss: 0.568658, acc: 74.22%] [G loss: 1.805339]\n",
      "epoch:10 step:8316 [D loss: 0.748836, acc: 50.00%] [G loss: 1.578009]\n",
      "epoch:10 step:8317 [D loss: 0.711359, acc: 47.66%] [G loss: 1.540046]\n",
      "epoch:10 step:8318 [D loss: 0.616425, acc: 64.06%] [G loss: 1.673341]\n",
      "epoch:10 step:8319 [D loss: 0.777394, acc: 41.41%] [G loss: 1.561270]\n",
      "epoch:10 step:8320 [D loss: 0.788996, acc: 42.19%] [G loss: 1.547921]\n",
      "epoch:10 step:8321 [D loss: 0.544512, acc: 78.12%] [G loss: 2.142839]\n",
      "epoch:10 step:8322 [D loss: 0.668379, acc: 60.16%] [G loss: 1.713385]\n",
      "epoch:10 step:8323 [D loss: 0.800668, acc: 40.62%] [G loss: 1.492155]\n",
      "epoch:10 step:8324 [D loss: 0.693765, acc: 57.81%] [G loss: 1.502718]\n",
      "epoch:10 step:8325 [D loss: 0.690375, acc: 57.81%] [G loss: 1.892075]\n",
      "epoch:10 step:8326 [D loss: 0.695563, acc: 57.03%] [G loss: 1.786684]\n",
      "epoch:10 step:8327 [D loss: 0.631549, acc: 62.50%] [G loss: 1.686307]\n",
      "epoch:10 step:8328 [D loss: 0.524659, acc: 79.69%] [G loss: 1.808581]\n",
      "epoch:10 step:8329 [D loss: 0.851043, acc: 37.50%] [G loss: 1.898569]\n",
      "epoch:10 step:8330 [D loss: 0.574248, acc: 73.44%] [G loss: 1.923634]\n",
      "epoch:10 step:8331 [D loss: 0.453629, acc: 91.41%] [G loss: 1.932902]\n",
      "epoch:10 step:8332 [D loss: 0.778904, acc: 42.19%] [G loss: 1.557156]\n",
      "epoch:10 step:8333 [D loss: 0.659327, acc: 53.91%] [G loss: 1.527048]\n",
      "epoch:10 step:8334 [D loss: 0.743896, acc: 50.00%] [G loss: 1.697959]\n",
      "epoch:10 step:8335 [D loss: 0.644921, acc: 63.28%] [G loss: 1.783919]\n",
      "epoch:10 step:8336 [D loss: 0.604596, acc: 66.41%] [G loss: 1.933598]\n",
      "epoch:10 step:8337 [D loss: 0.568821, acc: 71.09%] [G loss: 1.571252]\n",
      "epoch:10 step:8338 [D loss: 0.532204, acc: 81.25%] [G loss: 2.296484]\n",
      "epoch:10 step:8339 [D loss: 0.657827, acc: 62.50%] [G loss: 1.857982]\n",
      "epoch:10 step:8340 [D loss: 0.581810, acc: 62.50%] [G loss: 1.931459]\n",
      "epoch:10 step:8341 [D loss: 0.730284, acc: 46.09%] [G loss: 1.599002]\n",
      "epoch:10 step:8342 [D loss: 0.738133, acc: 48.44%] [G loss: 1.553279]\n",
      "epoch:10 step:8343 [D loss: 0.708134, acc: 53.91%] [G loss: 1.783742]\n",
      "epoch:10 step:8344 [D loss: 0.636608, acc: 64.06%] [G loss: 1.796267]\n",
      "epoch:10 step:8345 [D loss: 0.613442, acc: 71.88%] [G loss: 1.708168]\n",
      "epoch:10 step:8346 [D loss: 0.676997, acc: 54.69%] [G loss: 1.808546]\n",
      "epoch:10 step:8347 [D loss: 0.664017, acc: 60.16%] [G loss: 2.199212]\n",
      "epoch:10 step:8348 [D loss: 0.741687, acc: 48.44%] [G loss: 1.663242]\n",
      "epoch:10 step:8349 [D loss: 0.647311, acc: 65.62%] [G loss: 1.919138]\n",
      "epoch:10 step:8350 [D loss: 0.724394, acc: 51.56%] [G loss: 1.689630]\n",
      "epoch:10 step:8351 [D loss: 0.688687, acc: 64.84%] [G loss: 1.858418]\n",
      "epoch:10 step:8352 [D loss: 0.749734, acc: 48.44%] [G loss: 1.788046]\n",
      "epoch:10 step:8353 [D loss: 0.792305, acc: 37.50%] [G loss: 1.729720]\n",
      "epoch:10 step:8354 [D loss: 0.572681, acc: 71.88%] [G loss: 1.800224]\n",
      "epoch:10 step:8355 [D loss: 0.593202, acc: 75.78%] [G loss: 1.851644]\n",
      "epoch:10 step:8356 [D loss: 0.816507, acc: 46.09%] [G loss: 1.731351]\n",
      "epoch:10 step:8357 [D loss: 0.575957, acc: 71.09%] [G loss: 1.869896]\n",
      "epoch:10 step:8358 [D loss: 0.622580, acc: 70.31%] [G loss: 1.695230]\n",
      "epoch:10 step:8359 [D loss: 0.641352, acc: 64.84%] [G loss: 1.793510]\n",
      "epoch:10 step:8360 [D loss: 0.661454, acc: 60.94%] [G loss: 1.728285]\n",
      "epoch:10 step:8361 [D loss: 0.791235, acc: 42.97%] [G loss: 1.730441]\n",
      "epoch:10 step:8362 [D loss: 0.654808, acc: 65.62%] [G loss: 1.632414]\n",
      "epoch:10 step:8363 [D loss: 0.709891, acc: 52.34%] [G loss: 1.887197]\n",
      "epoch:10 step:8364 [D loss: 0.641893, acc: 64.06%] [G loss: 1.782215]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8365 [D loss: 0.629371, acc: 67.19%] [G loss: 1.817065]\n",
      "epoch:10 step:8366 [D loss: 0.661439, acc: 60.16%] [G loss: 1.632261]\n",
      "epoch:10 step:8367 [D loss: 0.624193, acc: 64.84%] [G loss: 1.679931]\n",
      "epoch:10 step:8368 [D loss: 0.796451, acc: 38.28%] [G loss: 1.586062]\n",
      "epoch:10 step:8369 [D loss: 0.646556, acc: 59.38%] [G loss: 1.877820]\n",
      "epoch:10 step:8370 [D loss: 0.668882, acc: 60.16%] [G loss: 1.757879]\n",
      "epoch:10 step:8371 [D loss: 0.435896, acc: 82.81%] [G loss: 1.885104]\n",
      "epoch:10 step:8372 [D loss: 0.428327, acc: 89.84%] [G loss: 1.587411]\n",
      "epoch:10 step:8373 [D loss: 0.623699, acc: 70.31%] [G loss: 1.472720]\n",
      "epoch:10 step:8374 [D loss: 0.703107, acc: 59.38%] [G loss: 1.452083]\n",
      "epoch:10 step:8375 [D loss: 0.870405, acc: 34.38%] [G loss: 1.732592]\n",
      "epoch:10 step:8376 [D loss: 0.708781, acc: 46.09%] [G loss: 1.461039]\n",
      "epoch:10 step:8377 [D loss: 0.652827, acc: 60.94%] [G loss: 1.634011]\n",
      "epoch:10 step:8378 [D loss: 0.953200, acc: 38.28%] [G loss: 1.532336]\n",
      "epoch:10 step:8379 [D loss: 0.707582, acc: 57.03%] [G loss: 1.765838]\n",
      "epoch:10 step:8380 [D loss: 0.685859, acc: 57.03%] [G loss: 1.604252]\n",
      "epoch:10 step:8381 [D loss: 0.901645, acc: 21.09%] [G loss: 1.547333]\n",
      "epoch:10 step:8382 [D loss: 0.556315, acc: 81.25%] [G loss: 1.784053]\n",
      "epoch:10 step:8383 [D loss: 0.778867, acc: 37.50%] [G loss: 1.683009]\n",
      "epoch:10 step:8384 [D loss: 0.561785, acc: 71.88%] [G loss: 1.845549]\n",
      "epoch:10 step:8385 [D loss: 0.463017, acc: 82.81%] [G loss: 2.144882]\n",
      "epoch:10 step:8386 [D loss: 0.477140, acc: 84.38%] [G loss: 1.810054]\n",
      "epoch:10 step:8387 [D loss: 0.783862, acc: 48.44%] [G loss: 1.728338]\n",
      "epoch:10 step:8388 [D loss: 0.510818, acc: 84.38%] [G loss: 1.874447]\n",
      "epoch:10 step:8389 [D loss: 0.656462, acc: 64.06%] [G loss: 1.782061]\n",
      "epoch:10 step:8390 [D loss: 0.724489, acc: 53.12%] [G loss: 1.805163]\n",
      "epoch:10 step:8391 [D loss: 0.610882, acc: 71.09%] [G loss: 1.953953]\n",
      "epoch:10 step:8392 [D loss: 0.618087, acc: 67.97%] [G loss: 1.664011]\n",
      "epoch:10 step:8393 [D loss: 0.577054, acc: 67.19%] [G loss: 1.505518]\n",
      "epoch:10 step:8394 [D loss: 0.614254, acc: 70.31%] [G loss: 1.771170]\n",
      "epoch:10 step:8395 [D loss: 0.686004, acc: 54.69%] [G loss: 1.690660]\n",
      "epoch:10 step:8396 [D loss: 0.557562, acc: 77.34%] [G loss: 1.612033]\n",
      "epoch:10 step:8397 [D loss: 0.747247, acc: 46.88%] [G loss: 1.572587]\n",
      "epoch:10 step:8398 [D loss: 0.974929, acc: 21.88%] [G loss: 1.376583]\n",
      "epoch:10 step:8399 [D loss: 1.137284, acc: 29.69%] [G loss: 1.186777]\n",
      "epoch:10 step:8400 [D loss: 0.810510, acc: 32.81%] [G loss: 1.355607]\n",
      "epoch:10 step:8401 [D loss: 0.531440, acc: 84.38%] [G loss: 1.629514]\n",
      "epoch:10 step:8402 [D loss: 0.539544, acc: 78.91%] [G loss: 1.698738]\n",
      "epoch:10 step:8403 [D loss: 0.610801, acc: 69.53%] [G loss: 1.646315]\n",
      "epoch:10 step:8404 [D loss: 0.782441, acc: 40.62%] [G loss: 1.684594]\n",
      "epoch:10 step:8405 [D loss: 0.594830, acc: 73.44%] [G loss: 1.615426]\n",
      "epoch:10 step:8406 [D loss: 0.846298, acc: 30.47%] [G loss: 1.568853]\n",
      "epoch:10 step:8407 [D loss: 0.865216, acc: 28.91%] [G loss: 1.723011]\n",
      "epoch:10 step:8408 [D loss: 0.717999, acc: 45.31%] [G loss: 1.685510]\n",
      "epoch:10 step:8409 [D loss: 0.724283, acc: 49.22%] [G loss: 1.638861]\n",
      "epoch:10 step:8410 [D loss: 0.585396, acc: 71.09%] [G loss: 1.660480]\n",
      "epoch:10 step:8411 [D loss: 0.616544, acc: 65.62%] [G loss: 1.737255]\n",
      "epoch:10 step:8412 [D loss: 0.614171, acc: 70.31%] [G loss: 1.759415]\n",
      "epoch:10 step:8413 [D loss: 0.711009, acc: 50.78%] [G loss: 1.684965]\n",
      "epoch:10 step:8414 [D loss: 0.739101, acc: 45.31%] [G loss: 1.968205]\n",
      "epoch:10 step:8415 [D loss: 0.682582, acc: 57.03%] [G loss: 1.675632]\n",
      "epoch:10 step:8416 [D loss: 0.672868, acc: 60.16%] [G loss: 1.879693]\n",
      "epoch:10 step:8417 [D loss: 0.698237, acc: 53.12%] [G loss: 1.470608]\n",
      "epoch:10 step:8418 [D loss: 0.617650, acc: 73.44%] [G loss: 1.538708]\n",
      "epoch:10 step:8419 [D loss: 0.670681, acc: 59.38%] [G loss: 1.742762]\n",
      "epoch:10 step:8420 [D loss: 0.544716, acc: 72.66%] [G loss: 1.905219]\n",
      "epoch:10 step:8421 [D loss: 0.749259, acc: 45.31%] [G loss: 1.653651]\n",
      "epoch:10 step:8422 [D loss: 0.537224, acc: 77.34%] [G loss: 1.848703]\n",
      "epoch:10 step:8423 [D loss: 0.754108, acc: 45.31%] [G loss: 1.815798]\n",
      "epoch:10 step:8424 [D loss: 0.631769, acc: 64.84%] [G loss: 1.619481]\n",
      "epoch:10 step:8425 [D loss: 0.657127, acc: 60.94%] [G loss: 1.770241]\n",
      "epoch:10 step:8426 [D loss: 0.917395, acc: 28.12%] [G loss: 1.360587]\n",
      "epoch:10 step:8427 [D loss: 0.690107, acc: 55.47%] [G loss: 1.731068]\n",
      "epoch:10 step:8428 [D loss: 0.684433, acc: 52.34%] [G loss: 1.738298]\n",
      "epoch:10 step:8429 [D loss: 0.653193, acc: 59.38%] [G loss: 1.848784]\n",
      "epoch:10 step:8430 [D loss: 0.578508, acc: 73.44%] [G loss: 1.576709]\n",
      "epoch:10 step:8431 [D loss: 0.711712, acc: 53.91%] [G loss: 1.630708]\n",
      "epoch:10 step:8432 [D loss: 0.670283, acc: 55.47%] [G loss: 1.681501]\n",
      "epoch:10 step:8433 [D loss: 0.640691, acc: 60.16%] [G loss: 1.677695]\n",
      "epoch:10 step:8434 [D loss: 0.687626, acc: 54.69%] [G loss: 1.509115]\n",
      "epoch:10 step:8435 [D loss: 0.638500, acc: 64.84%] [G loss: 1.727525]\n",
      "epoch:10 step:8436 [D loss: 0.701457, acc: 55.47%] [G loss: 1.825269]\n",
      "epoch:10 step:8437 [D loss: 0.700571, acc: 56.25%] [G loss: 1.594584]\n",
      "epoch:10 step:8438 [D loss: 0.706394, acc: 55.47%] [G loss: 1.610716]\n",
      "epoch:10 step:8439 [D loss: 0.625849, acc: 73.44%] [G loss: 1.650139]\n",
      "epoch:10 step:8440 [D loss: 0.688961, acc: 54.69%] [G loss: 1.872728]\n",
      "epoch:10 step:8441 [D loss: 0.475472, acc: 75.78%] [G loss: 1.743484]\n",
      "epoch:10 step:8442 [D loss: 0.814568, acc: 41.41%] [G loss: 1.415792]\n",
      "epoch:10 step:8443 [D loss: 0.757305, acc: 44.53%] [G loss: 1.603557]\n",
      "epoch:10 step:8444 [D loss: 0.678479, acc: 59.38%] [G loss: 1.362292]\n",
      "epoch:10 step:8445 [D loss: 0.637095, acc: 55.47%] [G loss: 1.620533]\n",
      "epoch:10 step:8446 [D loss: 0.702772, acc: 57.03%] [G loss: 1.749823]\n",
      "epoch:10 step:8447 [D loss: 0.743693, acc: 48.44%] [G loss: 1.568588]\n",
      "epoch:10 step:8448 [D loss: 0.926869, acc: 21.09%] [G loss: 1.187575]\n",
      "epoch:10 step:8449 [D loss: 0.853852, acc: 28.91%] [G loss: 1.478860]\n",
      "epoch:10 step:8450 [D loss: 0.741433, acc: 50.78%] [G loss: 1.632988]\n",
      "epoch:10 step:8451 [D loss: 0.620116, acc: 69.53%] [G loss: 1.671729]\n",
      "epoch:10 step:8452 [D loss: 0.598430, acc: 74.22%] [G loss: 1.857399]\n",
      "epoch:10 step:8453 [D loss: 0.708561, acc: 55.47%] [G loss: 1.749256]\n",
      "epoch:10 step:8454 [D loss: 0.597785, acc: 71.09%] [G loss: 1.797738]\n",
      "epoch:10 step:8455 [D loss: 0.917832, acc: 21.88%] [G loss: 1.364174]\n",
      "epoch:10 step:8456 [D loss: 0.732420, acc: 42.19%] [G loss: 1.931993]\n",
      "epoch:10 step:8457 [D loss: 0.649466, acc: 64.06%] [G loss: 1.560836]\n",
      "epoch:10 step:8458 [D loss: 0.684780, acc: 53.91%] [G loss: 1.974403]\n",
      "epoch:10 step:8459 [D loss: 0.705048, acc: 50.00%] [G loss: 1.875052]\n",
      "epoch:10 step:8460 [D loss: 0.566513, acc: 82.81%] [G loss: 1.812157]\n",
      "epoch:10 step:8461 [D loss: 0.536559, acc: 81.25%] [G loss: 1.814363]\n",
      "epoch:10 step:8462 [D loss: 0.656581, acc: 62.50%] [G loss: 1.609103]\n",
      "epoch:10 step:8463 [D loss: 0.702831, acc: 56.25%] [G loss: 1.735664]\n",
      "epoch:10 step:8464 [D loss: 0.655304, acc: 58.59%] [G loss: 1.841880]\n",
      "epoch:10 step:8465 [D loss: 0.574634, acc: 76.56%] [G loss: 1.801196]\n",
      "epoch:10 step:8466 [D loss: 1.028443, acc: 16.41%] [G loss: 1.404984]\n",
      "epoch:10 step:8467 [D loss: 0.643453, acc: 63.28%] [G loss: 1.934173]\n",
      "epoch:10 step:8468 [D loss: 0.553249, acc: 75.00%] [G loss: 1.653777]\n",
      "epoch:10 step:8469 [D loss: 0.371188, acc: 89.06%] [G loss: 2.354952]\n",
      "epoch:10 step:8470 [D loss: 0.665608, acc: 57.81%] [G loss: 1.789760]\n",
      "epoch:10 step:8471 [D loss: 0.706843, acc: 55.47%] [G loss: 1.591573]\n",
      "epoch:10 step:8472 [D loss: 0.695446, acc: 55.47%] [G loss: 1.953242]\n",
      "epoch:10 step:8473 [D loss: 0.706625, acc: 56.25%] [G loss: 1.708015]\n",
      "epoch:10 step:8474 [D loss: 0.612784, acc: 67.97%] [G loss: 1.796520]\n",
      "epoch:10 step:8475 [D loss: 0.645825, acc: 65.62%] [G loss: 1.907430]\n",
      "epoch:10 step:8476 [D loss: 0.557752, acc: 82.03%] [G loss: 1.978158]\n",
      "epoch:10 step:8477 [D loss: 0.719638, acc: 50.78%] [G loss: 1.682744]\n",
      "epoch:10 step:8478 [D loss: 0.516579, acc: 80.47%] [G loss: 1.782752]\n",
      "epoch:10 step:8479 [D loss: 0.739858, acc: 42.97%] [G loss: 1.642580]\n",
      "epoch:10 step:8480 [D loss: 0.924840, acc: 23.44%] [G loss: 1.345465]\n",
      "epoch:10 step:8481 [D loss: 0.633843, acc: 62.50%] [G loss: 1.796948]\n",
      "epoch:10 step:8482 [D loss: 0.752377, acc: 42.97%] [G loss: 1.499652]\n",
      "epoch:10 step:8483 [D loss: 0.524788, acc: 75.00%] [G loss: 1.688561]\n",
      "epoch:10 step:8484 [D loss: 0.774882, acc: 47.66%] [G loss: 1.631606]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8485 [D loss: 0.618367, acc: 68.75%] [G loss: 2.058997]\n",
      "epoch:10 step:8486 [D loss: 0.595503, acc: 64.84%] [G loss: 1.597077]\n",
      "epoch:10 step:8487 [D loss: 0.672116, acc: 57.81%] [G loss: 1.660019]\n",
      "epoch:10 step:8488 [D loss: 0.636681, acc: 61.72%] [G loss: 1.840467]\n",
      "epoch:10 step:8489 [D loss: 0.581612, acc: 76.56%] [G loss: 1.758822]\n",
      "epoch:10 step:8490 [D loss: 0.643025, acc: 64.06%] [G loss: 1.577287]\n",
      "epoch:10 step:8491 [D loss: 0.648815, acc: 64.06%] [G loss: 1.578334]\n",
      "epoch:10 step:8492 [D loss: 1.082201, acc: 21.88%] [G loss: 1.299583]\n",
      "epoch:10 step:8493 [D loss: 0.741696, acc: 46.09%] [G loss: 1.892480]\n",
      "epoch:10 step:8494 [D loss: 0.706649, acc: 57.03%] [G loss: 1.725126]\n",
      "epoch:10 step:8495 [D loss: 0.390469, acc: 91.41%] [G loss: 2.010007]\n",
      "epoch:10 step:8496 [D loss: 0.737952, acc: 44.53%] [G loss: 1.720312]\n",
      "epoch:10 step:8497 [D loss: 0.621866, acc: 65.62%] [G loss: 1.929383]\n",
      "epoch:10 step:8498 [D loss: 0.676581, acc: 57.81%] [G loss: 1.804795]\n",
      "epoch:10 step:8499 [D loss: 0.704150, acc: 53.12%] [G loss: 1.879387]\n",
      "epoch:10 step:8500 [D loss: 0.720026, acc: 53.91%] [G loss: 1.811761]\n",
      "epoch:10 step:8501 [D loss: 0.543913, acc: 78.91%] [G loss: 1.971549]\n",
      "epoch:10 step:8502 [D loss: 0.717838, acc: 55.47%] [G loss: 1.790837]\n",
      "epoch:10 step:8503 [D loss: 0.653732, acc: 60.16%] [G loss: 1.819031]\n",
      "epoch:10 step:8504 [D loss: 0.625202, acc: 64.06%] [G loss: 1.666398]\n",
      "epoch:10 step:8505 [D loss: 0.673666, acc: 55.47%] [G loss: 1.807839]\n",
      "epoch:10 step:8506 [D loss: 0.665865, acc: 58.59%] [G loss: 1.651617]\n",
      "epoch:10 step:8507 [D loss: 0.768456, acc: 44.53%] [G loss: 1.674832]\n",
      "epoch:10 step:8508 [D loss: 0.725784, acc: 48.44%] [G loss: 1.764366]\n",
      "epoch:10 step:8509 [D loss: 0.740066, acc: 53.91%] [G loss: 1.518384]\n",
      "epoch:10 step:8510 [D loss: 0.696017, acc: 55.47%] [G loss: 1.659761]\n",
      "epoch:10 step:8511 [D loss: 0.691606, acc: 58.59%] [G loss: 1.632095]\n",
      "epoch:10 step:8512 [D loss: 0.691514, acc: 58.59%] [G loss: 1.647328]\n",
      "epoch:10 step:8513 [D loss: 0.708633, acc: 46.88%] [G loss: 1.662732]\n",
      "epoch:10 step:8514 [D loss: 0.743573, acc: 45.31%] [G loss: 1.794039]\n",
      "epoch:10 step:8515 [D loss: 0.661394, acc: 59.38%] [G loss: 1.704195]\n",
      "epoch:10 step:8516 [D loss: 0.743898, acc: 46.09%] [G loss: 1.534939]\n",
      "epoch:10 step:8517 [D loss: 0.735348, acc: 50.00%] [G loss: 1.549611]\n",
      "epoch:10 step:8518 [D loss: 0.556442, acc: 81.25%] [G loss: 1.698389]\n",
      "epoch:10 step:8519 [D loss: 0.709308, acc: 49.22%] [G loss: 1.913508]\n",
      "epoch:10 step:8520 [D loss: 0.612255, acc: 66.41%] [G loss: 1.744164]\n",
      "epoch:10 step:8521 [D loss: 0.792172, acc: 42.19%] [G loss: 1.510048]\n",
      "epoch:10 step:8522 [D loss: 0.606566, acc: 65.62%] [G loss: 1.851621]\n",
      "epoch:10 step:8523 [D loss: 0.525055, acc: 78.91%] [G loss: 2.026585]\n",
      "epoch:10 step:8524 [D loss: 0.634588, acc: 63.28%] [G loss: 1.712376]\n",
      "epoch:10 step:8525 [D loss: 0.762976, acc: 45.31%] [G loss: 1.758665]\n",
      "epoch:10 step:8526 [D loss: 0.597586, acc: 77.34%] [G loss: 1.660969]\n",
      "epoch:10 step:8527 [D loss: 0.661696, acc: 57.03%] [G loss: 1.771347]\n",
      "epoch:10 step:8528 [D loss: 0.726597, acc: 51.56%] [G loss: 1.758755]\n",
      "epoch:10 step:8529 [D loss: 0.630075, acc: 63.28%] [G loss: 1.921938]\n",
      "epoch:10 step:8530 [D loss: 0.811961, acc: 44.53%] [G loss: 1.526708]\n",
      "epoch:10 step:8531 [D loss: 0.664871, acc: 61.72%] [G loss: 1.580152]\n",
      "epoch:10 step:8532 [D loss: 0.563732, acc: 75.00%] [G loss: 1.818550]\n",
      "epoch:10 step:8533 [D loss: 0.593424, acc: 76.56%] [G loss: 1.806338]\n",
      "epoch:10 step:8534 [D loss: 0.691910, acc: 54.69%] [G loss: 1.657298]\n",
      "epoch:10 step:8535 [D loss: 0.527733, acc: 77.34%] [G loss: 1.715986]\n",
      "epoch:10 step:8536 [D loss: 0.752834, acc: 43.75%] [G loss: 1.544665]\n",
      "epoch:10 step:8537 [D loss: 0.683571, acc: 57.03%] [G loss: 1.762210]\n",
      "epoch:10 step:8538 [D loss: 0.674592, acc: 57.03%] [G loss: 1.803496]\n",
      "epoch:10 step:8539 [D loss: 0.747134, acc: 42.97%] [G loss: 1.504584]\n",
      "epoch:10 step:8540 [D loss: 0.632267, acc: 69.53%] [G loss: 1.664598]\n",
      "epoch:10 step:8541 [D loss: 0.561324, acc: 71.88%] [G loss: 1.633417]\n",
      "epoch:10 step:8542 [D loss: 0.783865, acc: 40.62%] [G loss: 1.522548]\n",
      "epoch:10 step:8543 [D loss: 0.722256, acc: 47.66%] [G loss: 1.517122]\n",
      "epoch:10 step:8544 [D loss: 0.667065, acc: 60.94%] [G loss: 1.626112]\n",
      "epoch:10 step:8545 [D loss: 0.539127, acc: 76.56%] [G loss: 1.674266]\n",
      "epoch:10 step:8546 [D loss: 0.698746, acc: 55.47%] [G loss: 1.819750]\n",
      "epoch:10 step:8547 [D loss: 0.665666, acc: 60.16%] [G loss: 1.607067]\n",
      "epoch:10 step:8548 [D loss: 0.717122, acc: 54.69%] [G loss: 1.794802]\n",
      "epoch:10 step:8549 [D loss: 0.646577, acc: 58.59%] [G loss: 1.743560]\n",
      "epoch:10 step:8550 [D loss: 0.730390, acc: 47.66%] [G loss: 1.791355]\n",
      "epoch:10 step:8551 [D loss: 0.628544, acc: 70.31%] [G loss: 1.995173]\n",
      "epoch:10 step:8552 [D loss: 0.708976, acc: 50.00%] [G loss: 1.436278]\n",
      "epoch:10 step:8553 [D loss: 0.719448, acc: 49.22%] [G loss: 1.658536]\n",
      "epoch:10 step:8554 [D loss: 0.506904, acc: 77.34%] [G loss: 1.735845]\n",
      "epoch:10 step:8555 [D loss: 0.608341, acc: 75.78%] [G loss: 1.714330]\n",
      "epoch:10 step:8556 [D loss: 0.605411, acc: 75.00%] [G loss: 1.645391]\n",
      "epoch:10 step:8557 [D loss: 0.624201, acc: 68.75%] [G loss: 1.832307]\n",
      "epoch:10 step:8558 [D loss: 0.583822, acc: 69.53%] [G loss: 1.685410]\n",
      "epoch:10 step:8559 [D loss: 0.536735, acc: 82.03%] [G loss: 1.701085]\n",
      "epoch:10 step:8560 [D loss: 0.704236, acc: 58.59%] [G loss: 1.791483]\n",
      "epoch:10 step:8561 [D loss: 0.726786, acc: 50.00%] [G loss: 1.538690]\n",
      "epoch:10 step:8562 [D loss: 0.390817, acc: 73.44%] [G loss: 2.018719]\n",
      "epoch:10 step:8563 [D loss: 0.675445, acc: 59.38%] [G loss: 1.848661]\n",
      "epoch:10 step:8564 [D loss: 0.698676, acc: 57.81%] [G loss: 1.554754]\n",
      "epoch:10 step:8565 [D loss: 0.970094, acc: 20.31%] [G loss: 1.308887]\n",
      "epoch:10 step:8566 [D loss: 0.622099, acc: 70.31%] [G loss: 1.759847]\n",
      "epoch:10 step:8567 [D loss: 0.571448, acc: 70.31%] [G loss: 1.963346]\n",
      "epoch:10 step:8568 [D loss: 0.867315, acc: 35.16%] [G loss: 1.500869]\n",
      "epoch:10 step:8569 [D loss: 0.726680, acc: 43.75%] [G loss: 1.589034]\n",
      "epoch:10 step:8570 [D loss: 0.694214, acc: 52.34%] [G loss: 1.818635]\n",
      "epoch:10 step:8571 [D loss: 0.687855, acc: 59.38%] [G loss: 1.672550]\n",
      "epoch:10 step:8572 [D loss: 0.706171, acc: 57.03%] [G loss: 1.571892]\n",
      "epoch:10 step:8573 [D loss: 0.583108, acc: 70.31%] [G loss: 2.003991]\n",
      "epoch:10 step:8574 [D loss: 0.616353, acc: 73.44%] [G loss: 1.639886]\n",
      "epoch:10 step:8575 [D loss: 0.849987, acc: 28.12%] [G loss: 1.624642]\n",
      "epoch:10 step:8576 [D loss: 0.601698, acc: 67.19%] [G loss: 1.753808]\n",
      "epoch:10 step:8577 [D loss: 0.724066, acc: 47.66%] [G loss: 1.555138]\n",
      "epoch:10 step:8578 [D loss: 0.588365, acc: 67.97%] [G loss: 1.890083]\n",
      "epoch:10 step:8579 [D loss: 0.695128, acc: 54.69%] [G loss: 1.620275]\n",
      "epoch:10 step:8580 [D loss: 0.647983, acc: 58.59%] [G loss: 1.825008]\n",
      "epoch:10 step:8581 [D loss: 0.692815, acc: 50.78%] [G loss: 1.779475]\n",
      "epoch:10 step:8582 [D loss: 0.627053, acc: 66.41%] [G loss: 1.744861]\n",
      "epoch:10 step:8583 [D loss: 0.506000, acc: 87.50%] [G loss: 1.903534]\n",
      "epoch:10 step:8584 [D loss: 0.737074, acc: 49.22%] [G loss: 1.802408]\n",
      "epoch:10 step:8585 [D loss: 0.743300, acc: 43.75%] [G loss: 1.512117]\n",
      "epoch:10 step:8586 [D loss: 0.765163, acc: 39.06%] [G loss: 1.601291]\n",
      "epoch:10 step:8587 [D loss: 0.705392, acc: 54.69%] [G loss: 1.517904]\n",
      "epoch:10 step:8588 [D loss: 0.770980, acc: 42.19%] [G loss: 1.598310]\n",
      "epoch:10 step:8589 [D loss: 0.607481, acc: 57.03%] [G loss: 1.408590]\n",
      "epoch:10 step:8590 [D loss: 0.731773, acc: 50.00%] [G loss: 1.564674]\n",
      "epoch:10 step:8591 [D loss: 0.610091, acc: 74.22%] [G loss: 1.799521]\n",
      "epoch:11 step:8592 [D loss: 0.606749, acc: 67.19%] [G loss: 1.797333]\n",
      "epoch:11 step:8593 [D loss: 0.696782, acc: 54.69%] [G loss: 1.763581]\n",
      "epoch:11 step:8594 [D loss: 0.569743, acc: 75.00%] [G loss: 1.756656]\n",
      "epoch:11 step:8595 [D loss: 0.660871, acc: 58.59%] [G loss: 1.611489]\n",
      "epoch:11 step:8596 [D loss: 0.734898, acc: 47.66%] [G loss: 1.617343]\n",
      "epoch:11 step:8597 [D loss: 0.452671, acc: 78.91%] [G loss: 1.713279]\n",
      "epoch:11 step:8598 [D loss: 0.655758, acc: 66.41%] [G loss: 1.625118]\n",
      "epoch:11 step:8599 [D loss: 0.406766, acc: 88.28%] [G loss: 1.707192]\n",
      "epoch:11 step:8600 [D loss: 0.786149, acc: 34.38%] [G loss: 1.662029]\n",
      "epoch:11 step:8601 [D loss: 0.720961, acc: 43.75%] [G loss: 1.735721]\n",
      "epoch:11 step:8602 [D loss: 0.722312, acc: 55.47%] [G loss: 1.561431]\n",
      "epoch:11 step:8603 [D loss: 0.738641, acc: 46.88%] [G loss: 1.501889]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:8604 [D loss: 0.684460, acc: 57.81%] [G loss: 1.671794]\n",
      "epoch:11 step:8605 [D loss: 0.584639, acc: 71.88%] [G loss: 1.690243]\n",
      "epoch:11 step:8606 [D loss: 0.870600, acc: 25.78%] [G loss: 1.420736]\n",
      "epoch:11 step:8607 [D loss: 0.637791, acc: 66.41%] [G loss: 1.877920]\n",
      "epoch:11 step:8608 [D loss: 0.735085, acc: 48.44%] [G loss: 1.771291]\n",
      "epoch:11 step:8609 [D loss: 0.686423, acc: 55.47%] [G loss: 1.716802]\n",
      "epoch:11 step:8610 [D loss: 0.649721, acc: 62.50%] [G loss: 1.732559]\n",
      "epoch:11 step:8611 [D loss: 0.665152, acc: 62.50%] [G loss: 1.775175]\n",
      "epoch:11 step:8612 [D loss: 0.608468, acc: 68.75%] [G loss: 1.749188]\n",
      "epoch:11 step:8613 [D loss: 0.676043, acc: 55.47%] [G loss: 1.850507]\n",
      "epoch:11 step:8614 [D loss: 0.585528, acc: 67.97%] [G loss: 1.852809]\n",
      "epoch:11 step:8615 [D loss: 0.666831, acc: 57.81%] [G loss: 1.629750]\n",
      "epoch:11 step:8616 [D loss: 0.654929, acc: 60.94%] [G loss: 1.861320]\n",
      "epoch:11 step:8617 [D loss: 0.529791, acc: 68.75%] [G loss: 1.871898]\n",
      "epoch:11 step:8618 [D loss: 0.563106, acc: 78.12%] [G loss: 1.856045]\n",
      "epoch:11 step:8619 [D loss: 0.567601, acc: 75.00%] [G loss: 1.779994]\n",
      "epoch:11 step:8620 [D loss: 0.587243, acc: 64.06%] [G loss: 1.771123]\n",
      "epoch:11 step:8621 [D loss: 0.559237, acc: 80.47%] [G loss: 1.957853]\n",
      "epoch:11 step:8622 [D loss: 0.760117, acc: 46.88%] [G loss: 1.484186]\n",
      "epoch:11 step:8623 [D loss: 0.594500, acc: 71.88%] [G loss: 1.963092]\n",
      "epoch:11 step:8624 [D loss: 0.665679, acc: 60.16%] [G loss: 1.668043]\n",
      "epoch:11 step:8625 [D loss: 0.669135, acc: 54.69%] [G loss: 1.839426]\n",
      "epoch:11 step:8626 [D loss: 0.835869, acc: 32.03%] [G loss: 1.499731]\n",
      "epoch:11 step:8627 [D loss: 0.618515, acc: 69.53%] [G loss: 2.101869]\n",
      "epoch:11 step:8628 [D loss: 0.660679, acc: 64.84%] [G loss: 2.008700]\n",
      "epoch:11 step:8629 [D loss: 0.770118, acc: 41.41%] [G loss: 1.900439]\n",
      "epoch:11 step:8630 [D loss: 0.626672, acc: 67.19%] [G loss: 1.887745]\n",
      "epoch:11 step:8631 [D loss: 0.757623, acc: 43.75%] [G loss: 1.715839]\n",
      "epoch:11 step:8632 [D loss: 0.566052, acc: 70.31%] [G loss: 2.065875]\n",
      "epoch:11 step:8633 [D loss: 0.631401, acc: 67.19%] [G loss: 1.619545]\n",
      "epoch:11 step:8634 [D loss: 0.704652, acc: 56.25%] [G loss: 1.548009]\n",
      "epoch:11 step:8635 [D loss: 0.768393, acc: 45.31%] [G loss: 1.701306]\n",
      "epoch:11 step:8636 [D loss: 0.634757, acc: 63.28%] [G loss: 1.878786]\n",
      "epoch:11 step:8637 [D loss: 0.656355, acc: 59.38%] [G loss: 2.254470]\n",
      "epoch:11 step:8638 [D loss: 0.626361, acc: 59.38%] [G loss: 2.015950]\n",
      "epoch:11 step:8639 [D loss: 0.661871, acc: 57.03%] [G loss: 1.773860]\n",
      "epoch:11 step:8640 [D loss: 0.807565, acc: 36.72%] [G loss: 1.512824]\n",
      "epoch:11 step:8641 [D loss: 0.719373, acc: 49.22%] [G loss: 1.656187]\n",
      "epoch:11 step:8642 [D loss: 0.716663, acc: 53.91%] [G loss: 1.770258]\n",
      "epoch:11 step:8643 [D loss: 0.638055, acc: 62.50%] [G loss: 1.935370]\n",
      "epoch:11 step:8644 [D loss: 0.549460, acc: 71.88%] [G loss: 1.727937]\n",
      "epoch:11 step:8645 [D loss: 0.718474, acc: 50.78%] [G loss: 1.780322]\n",
      "epoch:11 step:8646 [D loss: 0.688442, acc: 56.25%] [G loss: 1.801095]\n",
      "epoch:11 step:8647 [D loss: 0.938093, acc: 23.44%] [G loss: 1.435408]\n",
      "epoch:11 step:8648 [D loss: 0.624774, acc: 65.62%] [G loss: 1.628655]\n",
      "epoch:11 step:8649 [D loss: 0.787192, acc: 48.44%] [G loss: 1.649220]\n",
      "epoch:11 step:8650 [D loss: 0.589888, acc: 69.53%] [G loss: 1.714685]\n",
      "epoch:11 step:8651 [D loss: 0.650994, acc: 60.16%] [G loss: 1.595462]\n",
      "epoch:11 step:8652 [D loss: 0.686603, acc: 56.25%] [G loss: 1.735947]\n",
      "epoch:11 step:8653 [D loss: 0.738644, acc: 50.00%] [G loss: 1.909448]\n",
      "epoch:11 step:8654 [D loss: 0.601767, acc: 68.75%] [G loss: 1.990199]\n",
      "epoch:11 step:8655 [D loss: 0.436557, acc: 93.75%] [G loss: 2.133124]\n",
      "epoch:11 step:8656 [D loss: 0.487854, acc: 78.12%] [G loss: 2.012661]\n",
      "epoch:11 step:8657 [D loss: 0.603879, acc: 66.41%] [G loss: 1.811961]\n",
      "epoch:11 step:8658 [D loss: 0.922956, acc: 29.69%] [G loss: 1.492513]\n",
      "epoch:11 step:8659 [D loss: 0.760780, acc: 51.56%] [G loss: 1.599867]\n",
      "epoch:11 step:8660 [D loss: 0.624178, acc: 63.28%] [G loss: 1.715660]\n",
      "epoch:11 step:8661 [D loss: 0.682047, acc: 50.00%] [G loss: 1.475502]\n",
      "epoch:11 step:8662 [D loss: 0.585712, acc: 65.62%] [G loss: 1.713584]\n",
      "epoch:11 step:8663 [D loss: 0.853424, acc: 37.50%] [G loss: 1.287598]\n",
      "epoch:11 step:8664 [D loss: 0.731789, acc: 50.00%] [G loss: 1.666620]\n",
      "epoch:11 step:8665 [D loss: 0.758720, acc: 44.53%] [G loss: 1.483250]\n",
      "epoch:11 step:8666 [D loss: 0.601520, acc: 63.28%] [G loss: 1.506711]\n",
      "epoch:11 step:8667 [D loss: 0.623255, acc: 69.53%] [G loss: 1.634046]\n",
      "epoch:11 step:8668 [D loss: 0.576903, acc: 76.56%] [G loss: 1.578050]\n",
      "epoch:11 step:8669 [D loss: 0.552838, acc: 75.78%] [G loss: 1.881033]\n",
      "epoch:11 step:8670 [D loss: 0.610806, acc: 68.75%] [G loss: 1.707277]\n",
      "epoch:11 step:8671 [D loss: 0.573531, acc: 75.00%] [G loss: 1.636072]\n",
      "epoch:11 step:8672 [D loss: 0.534049, acc: 65.62%] [G loss: 1.427455]\n",
      "epoch:11 step:8673 [D loss: 0.531478, acc: 78.91%] [G loss: 1.484687]\n",
      "epoch:11 step:8674 [D loss: 0.875101, acc: 41.41%] [G loss: 1.578610]\n",
      "epoch:11 step:8675 [D loss: 1.165682, acc: 5.47%] [G loss: 1.238304]\n",
      "epoch:11 step:8676 [D loss: 0.709953, acc: 51.56%] [G loss: 1.738085]\n",
      "epoch:11 step:8677 [D loss: 0.787433, acc: 39.06%] [G loss: 1.725307]\n",
      "epoch:11 step:8678 [D loss: 0.647104, acc: 66.41%] [G loss: 1.648538]\n",
      "epoch:11 step:8679 [D loss: 0.784327, acc: 44.53%] [G loss: 1.453430]\n",
      "epoch:11 step:8680 [D loss: 0.593308, acc: 67.97%] [G loss: 1.701153]\n",
      "epoch:11 step:8681 [D loss: 0.651944, acc: 59.38%] [G loss: 1.864848]\n",
      "epoch:11 step:8682 [D loss: 0.727139, acc: 50.78%] [G loss: 1.651278]\n",
      "epoch:11 step:8683 [D loss: 0.716343, acc: 46.88%] [G loss: 1.462708]\n",
      "epoch:11 step:8684 [D loss: 0.724971, acc: 47.66%] [G loss: 1.574080]\n",
      "epoch:11 step:8685 [D loss: 0.806052, acc: 36.72%] [G loss: 1.630584]\n",
      "epoch:11 step:8686 [D loss: 0.417167, acc: 87.50%] [G loss: 1.898582]\n",
      "epoch:11 step:8687 [D loss: 0.718907, acc: 50.78%] [G loss: 1.659525]\n",
      "epoch:11 step:8688 [D loss: 0.564727, acc: 71.88%] [G loss: 2.009403]\n",
      "epoch:11 step:8689 [D loss: 0.716778, acc: 47.66%] [G loss: 1.779735]\n",
      "epoch:11 step:8690 [D loss: 0.535183, acc: 83.59%] [G loss: 1.793447]\n",
      "epoch:11 step:8691 [D loss: 0.544146, acc: 82.03%] [G loss: 1.804062]\n",
      "epoch:11 step:8692 [D loss: 0.671883, acc: 57.81%] [G loss: 1.651874]\n",
      "epoch:11 step:8693 [D loss: 0.561116, acc: 77.34%] [G loss: 1.857236]\n",
      "epoch:11 step:8694 [D loss: 0.844150, acc: 32.81%] [G loss: 1.545786]\n",
      "epoch:11 step:8695 [D loss: 0.686311, acc: 50.00%] [G loss: 1.608002]\n",
      "epoch:11 step:8696 [D loss: 0.683343, acc: 59.38%] [G loss: 1.628297]\n",
      "epoch:11 step:8697 [D loss: 0.648809, acc: 59.38%] [G loss: 1.850992]\n",
      "epoch:11 step:8698 [D loss: 0.739584, acc: 52.34%] [G loss: 2.092479]\n",
      "epoch:11 step:8699 [D loss: 0.516395, acc: 78.91%] [G loss: 1.702234]\n",
      "epoch:11 step:8700 [D loss: 0.697424, acc: 53.12%] [G loss: 1.605254]\n",
      "epoch:11 step:8701 [D loss: 0.623792, acc: 64.84%] [G loss: 1.812483]\n",
      "epoch:11 step:8702 [D loss: 0.831486, acc: 35.94%] [G loss: 1.789237]\n",
      "epoch:11 step:8703 [D loss: 0.728938, acc: 48.44%] [G loss: 1.705183]\n",
      "epoch:11 step:8704 [D loss: 0.647149, acc: 63.28%] [G loss: 1.711265]\n",
      "epoch:11 step:8705 [D loss: 0.573079, acc: 74.22%] [G loss: 1.783741]\n",
      "epoch:11 step:8706 [D loss: 0.726968, acc: 49.22%] [G loss: 1.442860]\n",
      "epoch:11 step:8707 [D loss: 0.663981, acc: 62.50%] [G loss: 1.823697]\n",
      "epoch:11 step:8708 [D loss: 0.646608, acc: 63.28%] [G loss: 1.762058]\n",
      "epoch:11 step:8709 [D loss: 0.563599, acc: 71.09%] [G loss: 1.529798]\n",
      "epoch:11 step:8710 [D loss: 0.615164, acc: 71.09%] [G loss: 1.579331]\n",
      "epoch:11 step:8711 [D loss: 0.530345, acc: 83.59%] [G loss: 1.577975]\n",
      "epoch:11 step:8712 [D loss: 0.558666, acc: 80.47%] [G loss: 1.659126]\n",
      "epoch:11 step:8713 [D loss: 0.784502, acc: 42.97%] [G loss: 1.860927]\n",
      "epoch:11 step:8714 [D loss: 0.652887, acc: 61.72%] [G loss: 1.893171]\n",
      "epoch:11 step:8715 [D loss: 0.657417, acc: 56.25%] [G loss: 1.876966]\n",
      "epoch:11 step:8716 [D loss: 1.085010, acc: 8.59%] [G loss: 1.514036]\n",
      "epoch:11 step:8717 [D loss: 0.657345, acc: 64.06%] [G loss: 1.612004]\n",
      "epoch:11 step:8718 [D loss: 0.601161, acc: 72.66%] [G loss: 1.759650]\n",
      "epoch:11 step:8719 [D loss: 0.640691, acc: 63.28%] [G loss: 1.734939]\n",
      "epoch:11 step:8720 [D loss: 0.713440, acc: 54.69%] [G loss: 1.672325]\n",
      "epoch:11 step:8721 [D loss: 0.778150, acc: 43.75%] [G loss: 1.752992]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:8722 [D loss: 0.619807, acc: 63.28%] [G loss: 1.724768]\n",
      "epoch:11 step:8723 [D loss: 0.832561, acc: 34.38%] [G loss: 1.783157]\n",
      "epoch:11 step:8724 [D loss: 0.682641, acc: 55.47%] [G loss: 1.742570]\n",
      "epoch:11 step:8725 [D loss: 0.652693, acc: 64.84%] [G loss: 1.702097]\n",
      "epoch:11 step:8726 [D loss: 0.720336, acc: 56.25%] [G loss: 1.629498]\n",
      "epoch:11 step:8727 [D loss: 0.675203, acc: 57.03%] [G loss: 1.852606]\n",
      "epoch:11 step:8728 [D loss: 0.688321, acc: 53.12%] [G loss: 1.800643]\n",
      "epoch:11 step:8729 [D loss: 0.639739, acc: 67.19%] [G loss: 1.761324]\n",
      "epoch:11 step:8730 [D loss: 0.671733, acc: 53.12%] [G loss: 1.724043]\n",
      "epoch:11 step:8731 [D loss: 0.631272, acc: 64.06%] [G loss: 1.700167]\n",
      "epoch:11 step:8732 [D loss: 0.654247, acc: 62.50%] [G loss: 1.785031]\n",
      "epoch:11 step:8733 [D loss: 0.597692, acc: 68.75%] [G loss: 1.754691]\n",
      "epoch:11 step:8734 [D loss: 0.703936, acc: 48.44%] [G loss: 1.687586]\n",
      "epoch:11 step:8735 [D loss: 0.647363, acc: 64.06%] [G loss: 1.692800]\n",
      "epoch:11 step:8736 [D loss: 0.742547, acc: 51.56%] [G loss: 1.686676]\n",
      "epoch:11 step:8737 [D loss: 0.636900, acc: 67.97%] [G loss: 1.686551]\n",
      "epoch:11 step:8738 [D loss: 0.761223, acc: 43.75%] [G loss: 1.754646]\n",
      "epoch:11 step:8739 [D loss: 0.630853, acc: 61.72%] [G loss: 1.793705]\n",
      "epoch:11 step:8740 [D loss: 0.801079, acc: 41.41%] [G loss: 1.579467]\n",
      "epoch:11 step:8741 [D loss: 0.698334, acc: 50.78%] [G loss: 1.730436]\n",
      "epoch:11 step:8742 [D loss: 0.552783, acc: 67.97%] [G loss: 1.523248]\n",
      "epoch:11 step:8743 [D loss: 0.709800, acc: 54.69%] [G loss: 1.598582]\n",
      "epoch:11 step:8744 [D loss: 0.704673, acc: 57.81%] [G loss: 1.663319]\n",
      "epoch:11 step:8745 [D loss: 0.693515, acc: 57.81%] [G loss: 1.598974]\n",
      "epoch:11 step:8746 [D loss: 0.672849, acc: 61.72%] [G loss: 1.536451]\n",
      "epoch:11 step:8747 [D loss: 0.593895, acc: 64.84%] [G loss: 1.643187]\n",
      "epoch:11 step:8748 [D loss: 0.722760, acc: 46.88%] [G loss: 1.644476]\n",
      "epoch:11 step:8749 [D loss: 0.602810, acc: 68.75%] [G loss: 2.052640]\n",
      "epoch:11 step:8750 [D loss: 0.697560, acc: 55.47%] [G loss: 1.717328]\n",
      "epoch:11 step:8751 [D loss: 0.811154, acc: 29.69%] [G loss: 1.467148]\n",
      "epoch:11 step:8752 [D loss: 0.681874, acc: 56.25%] [G loss: 1.662602]\n",
      "epoch:11 step:8753 [D loss: 0.532648, acc: 80.47%] [G loss: 1.734749]\n",
      "epoch:11 step:8754 [D loss: 0.637456, acc: 64.06%] [G loss: 1.591483]\n",
      "epoch:11 step:8755 [D loss: 0.706042, acc: 47.66%] [G loss: 1.566106]\n",
      "epoch:11 step:8756 [D loss: 0.702291, acc: 56.25%] [G loss: 1.597656]\n",
      "epoch:11 step:8757 [D loss: 0.672159, acc: 57.03%] [G loss: 1.723033]\n",
      "epoch:11 step:8758 [D loss: 0.689555, acc: 56.25%] [G loss: 1.623438]\n",
      "epoch:11 step:8759 [D loss: 0.659166, acc: 64.84%] [G loss: 1.674679]\n",
      "epoch:11 step:8760 [D loss: 0.695853, acc: 51.56%] [G loss: 1.724570]\n",
      "epoch:11 step:8761 [D loss: 0.689735, acc: 54.69%] [G loss: 1.855754]\n",
      "epoch:11 step:8762 [D loss: 0.615937, acc: 66.41%] [G loss: 1.839980]\n",
      "epoch:11 step:8763 [D loss: 0.625804, acc: 68.75%] [G loss: 1.805715]\n",
      "epoch:11 step:8764 [D loss: 0.793305, acc: 46.09%] [G loss: 1.540410]\n",
      "epoch:11 step:8765 [D loss: 0.663784, acc: 53.91%] [G loss: 1.887642]\n",
      "epoch:11 step:8766 [D loss: 0.467898, acc: 89.84%] [G loss: 1.842772]\n",
      "epoch:11 step:8767 [D loss: 0.678423, acc: 53.91%] [G loss: 1.751890]\n",
      "epoch:11 step:8768 [D loss: 0.693261, acc: 55.47%] [G loss: 1.929899]\n",
      "epoch:11 step:8769 [D loss: 0.596786, acc: 64.84%] [G loss: 1.687584]\n",
      "epoch:11 step:8770 [D loss: 0.718717, acc: 49.22%] [G loss: 1.693925]\n",
      "epoch:11 step:8771 [D loss: 0.699166, acc: 53.91%] [G loss: 1.677529]\n",
      "epoch:11 step:8772 [D loss: 0.714826, acc: 53.91%] [G loss: 1.800147]\n",
      "epoch:11 step:8773 [D loss: 0.699883, acc: 52.34%] [G loss: 1.684511]\n",
      "epoch:11 step:8774 [D loss: 0.591846, acc: 74.22%] [G loss: 2.231621]\n",
      "epoch:11 step:8775 [D loss: 0.499970, acc: 78.91%] [G loss: 1.918728]\n",
      "epoch:11 step:8776 [D loss: 0.764314, acc: 47.66%] [G loss: 1.748816]\n",
      "epoch:11 step:8777 [D loss: 0.451615, acc: 90.62%] [G loss: 2.385042]\n",
      "epoch:11 step:8778 [D loss: 0.690954, acc: 48.44%] [G loss: 1.896155]\n",
      "epoch:11 step:8779 [D loss: 0.610908, acc: 70.31%] [G loss: 1.687404]\n",
      "epoch:11 step:8780 [D loss: 0.537608, acc: 82.03%] [G loss: 1.901606]\n",
      "epoch:11 step:8781 [D loss: 0.847433, acc: 28.91%] [G loss: 1.530731]\n",
      "epoch:11 step:8782 [D loss: 0.474265, acc: 89.06%] [G loss: 1.822775]\n",
      "epoch:11 step:8783 [D loss: 0.722121, acc: 53.91%] [G loss: 1.578649]\n",
      "epoch:11 step:8784 [D loss: 0.755583, acc: 41.41%] [G loss: 1.592950]\n",
      "epoch:11 step:8785 [D loss: 0.709712, acc: 49.22%] [G loss: 1.645882]\n",
      "epoch:11 step:8786 [D loss: 0.690845, acc: 53.91%] [G loss: 1.626142]\n",
      "epoch:11 step:8787 [D loss: 0.955416, acc: 20.31%] [G loss: 1.426529]\n",
      "epoch:11 step:8788 [D loss: 0.787647, acc: 38.28%] [G loss: 1.522838]\n",
      "epoch:11 step:8789 [D loss: 0.751722, acc: 43.75%] [G loss: 1.584613]\n",
      "epoch:11 step:8790 [D loss: 0.907665, acc: 35.16%] [G loss: 1.792143]\n",
      "epoch:11 step:8791 [D loss: 0.717117, acc: 52.34%] [G loss: 1.734886]\n",
      "epoch:11 step:8792 [D loss: 0.627756, acc: 65.62%] [G loss: 1.739077]\n",
      "epoch:11 step:8793 [D loss: 0.757282, acc: 44.53%] [G loss: 1.629468]\n",
      "epoch:11 step:8794 [D loss: 0.643859, acc: 60.94%] [G loss: 1.825242]\n",
      "epoch:11 step:8795 [D loss: 0.732351, acc: 49.22%] [G loss: 1.681961]\n",
      "epoch:11 step:8796 [D loss: 0.831105, acc: 39.84%] [G loss: 1.433840]\n",
      "epoch:11 step:8797 [D loss: 0.730512, acc: 49.22%] [G loss: 1.471252]\n",
      "epoch:11 step:8798 [D loss: 0.666795, acc: 62.50%] [G loss: 1.717921]\n",
      "epoch:11 step:8799 [D loss: 0.598743, acc: 70.31%] [G loss: 1.704800]\n",
      "epoch:11 step:8800 [D loss: 0.744821, acc: 41.41%] [G loss: 1.724942]\n",
      "epoch:11 step:8801 [D loss: 0.660612, acc: 59.38%] [G loss: 1.731474]\n",
      "epoch:11 step:8802 [D loss: 0.700051, acc: 51.56%] [G loss: 1.650281]\n",
      "epoch:11 step:8803 [D loss: 0.710586, acc: 48.44%] [G loss: 1.744989]\n",
      "epoch:11 step:8804 [D loss: 0.698080, acc: 53.91%] [G loss: 1.648832]\n",
      "epoch:11 step:8805 [D loss: 0.539420, acc: 79.69%] [G loss: 1.942576]\n",
      "epoch:11 step:8806 [D loss: 0.682294, acc: 53.12%] [G loss: 1.587383]\n",
      "epoch:11 step:8807 [D loss: 0.678097, acc: 59.38%] [G loss: 1.851748]\n",
      "epoch:11 step:8808 [D loss: 0.768209, acc: 42.19%] [G loss: 1.581814]\n",
      "epoch:11 step:8809 [D loss: 0.711715, acc: 48.44%] [G loss: 1.763561]\n",
      "epoch:11 step:8810 [D loss: 0.615205, acc: 69.53%] [G loss: 1.766418]\n",
      "epoch:11 step:8811 [D loss: 0.655879, acc: 64.84%] [G loss: 1.839967]\n",
      "epoch:11 step:8812 [D loss: 0.646533, acc: 62.50%] [G loss: 1.793712]\n",
      "epoch:11 step:8813 [D loss: 0.781209, acc: 45.31%] [G loss: 1.774292]\n",
      "epoch:11 step:8814 [D loss: 0.717044, acc: 52.34%] [G loss: 1.579357]\n",
      "epoch:11 step:8815 [D loss: 0.715714, acc: 47.66%] [G loss: 1.471718]\n",
      "epoch:11 step:8816 [D loss: 0.657317, acc: 59.38%] [G loss: 1.708768]\n",
      "epoch:11 step:8817 [D loss: 0.824874, acc: 33.59%] [G loss: 1.414992]\n",
      "epoch:11 step:8818 [D loss: 0.635742, acc: 65.62%] [G loss: 1.567261]\n",
      "epoch:11 step:8819 [D loss: 0.622338, acc: 64.84%] [G loss: 1.575081]\n",
      "epoch:11 step:8820 [D loss: 0.691115, acc: 54.69%] [G loss: 1.797117]\n",
      "epoch:11 step:8821 [D loss: 0.613196, acc: 68.75%] [G loss: 1.643925]\n",
      "epoch:11 step:8822 [D loss: 0.676710, acc: 53.91%] [G loss: 1.728200]\n",
      "epoch:11 step:8823 [D loss: 0.731346, acc: 49.22%] [G loss: 1.681713]\n",
      "epoch:11 step:8824 [D loss: 0.679233, acc: 53.12%] [G loss: 1.701444]\n",
      "epoch:11 step:8825 [D loss: 0.740268, acc: 42.19%] [G loss: 1.539841]\n",
      "epoch:11 step:8826 [D loss: 0.746792, acc: 46.88%] [G loss: 1.546877]\n",
      "epoch:11 step:8827 [D loss: 0.719483, acc: 50.00%] [G loss: 1.603040]\n",
      "epoch:11 step:8828 [D loss: 0.746987, acc: 43.75%] [G loss: 1.578373]\n",
      "epoch:11 step:8829 [D loss: 0.600653, acc: 72.66%] [G loss: 1.806258]\n",
      "epoch:11 step:8830 [D loss: 0.564410, acc: 78.12%] [G loss: 1.844493]\n",
      "epoch:11 step:8831 [D loss: 0.751658, acc: 49.22%] [G loss: 1.960863]\n",
      "epoch:11 step:8832 [D loss: 0.750106, acc: 52.34%] [G loss: 1.692155]\n",
      "epoch:11 step:8833 [D loss: 0.734551, acc: 47.66%] [G loss: 1.675403]\n",
      "epoch:11 step:8834 [D loss: 0.675532, acc: 56.25%] [G loss: 1.724620]\n",
      "epoch:11 step:8835 [D loss: 0.557577, acc: 73.44%] [G loss: 1.966818]\n",
      "epoch:11 step:8836 [D loss: 0.504089, acc: 78.91%] [G loss: 1.762015]\n",
      "epoch:11 step:8837 [D loss: 0.607076, acc: 68.75%] [G loss: 1.975453]\n",
      "epoch:11 step:8838 [D loss: 0.610443, acc: 70.31%] [G loss: 1.653092]\n",
      "epoch:11 step:8839 [D loss: 0.702940, acc: 51.56%] [G loss: 1.492374]\n",
      "epoch:11 step:8840 [D loss: 0.730690, acc: 48.44%] [G loss: 1.566839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:8841 [D loss: 0.676877, acc: 64.06%] [G loss: 1.702706]\n",
      "epoch:11 step:8842 [D loss: 0.695598, acc: 56.25%] [G loss: 1.611307]\n",
      "epoch:11 step:8843 [D loss: 0.661933, acc: 63.28%] [G loss: 1.866381]\n",
      "epoch:11 step:8844 [D loss: 0.610392, acc: 67.19%] [G loss: 1.709169]\n",
      "epoch:11 step:8845 [D loss: 0.656261, acc: 60.94%] [G loss: 1.670090]\n",
      "epoch:11 step:8846 [D loss: 0.874387, acc: 28.12%] [G loss: 1.488747]\n",
      "epoch:11 step:8847 [D loss: 0.713129, acc: 50.00%] [G loss: 1.623413]\n",
      "epoch:11 step:8848 [D loss: 0.795419, acc: 36.72%] [G loss: 1.397362]\n",
      "epoch:11 step:8849 [D loss: 0.678646, acc: 60.16%] [G loss: 1.626225]\n",
      "epoch:11 step:8850 [D loss: 0.854772, acc: 24.22%] [G loss: 1.448253]\n",
      "epoch:11 step:8851 [D loss: 0.708976, acc: 51.56%] [G loss: 1.627126]\n",
      "epoch:11 step:8852 [D loss: 0.599290, acc: 72.66%] [G loss: 1.804575]\n",
      "epoch:11 step:8853 [D loss: 0.703855, acc: 54.69%] [G loss: 1.588661]\n",
      "epoch:11 step:8854 [D loss: 0.673654, acc: 54.69%] [G loss: 1.639612]\n",
      "epoch:11 step:8855 [D loss: 0.627768, acc: 60.94%] [G loss: 1.604049]\n",
      "epoch:11 step:8856 [D loss: 0.696056, acc: 47.66%] [G loss: 1.647244]\n",
      "epoch:11 step:8857 [D loss: 0.738470, acc: 50.00%] [G loss: 1.608880]\n",
      "epoch:11 step:8858 [D loss: 1.087126, acc: 16.41%] [G loss: 1.291971]\n",
      "epoch:11 step:8859 [D loss: 0.528503, acc: 82.03%] [G loss: 2.303845]\n",
      "epoch:11 step:8860 [D loss: 0.733194, acc: 42.97%] [G loss: 1.665638]\n",
      "epoch:11 step:8861 [D loss: 0.703572, acc: 51.56%] [G loss: 1.768160]\n",
      "epoch:11 step:8862 [D loss: 0.625957, acc: 63.28%] [G loss: 1.662823]\n",
      "epoch:11 step:8863 [D loss: 0.689647, acc: 57.81%] [G loss: 1.589142]\n",
      "epoch:11 step:8864 [D loss: 0.447355, acc: 80.47%] [G loss: 1.702026]\n",
      "epoch:11 step:8865 [D loss: 0.702105, acc: 53.91%] [G loss: 1.762948]\n",
      "epoch:11 step:8866 [D loss: 0.630860, acc: 67.19%] [G loss: 1.640763]\n",
      "epoch:11 step:8867 [D loss: 0.727481, acc: 53.12%] [G loss: 1.742828]\n",
      "epoch:11 step:8868 [D loss: 0.796593, acc: 38.28%] [G loss: 1.504129]\n",
      "epoch:11 step:8869 [D loss: 0.668048, acc: 64.84%] [G loss: 1.732141]\n",
      "epoch:11 step:8870 [D loss: 0.670801, acc: 56.25%] [G loss: 1.640967]\n",
      "epoch:11 step:8871 [D loss: 0.623617, acc: 73.44%] [G loss: 1.675070]\n",
      "epoch:11 step:8872 [D loss: 0.641969, acc: 62.50%] [G loss: 1.806424]\n",
      "epoch:11 step:8873 [D loss: 0.780035, acc: 42.19%] [G loss: 1.447711]\n",
      "epoch:11 step:8874 [D loss: 0.654723, acc: 67.19%] [G loss: 1.702613]\n",
      "epoch:11 step:8875 [D loss: 0.674974, acc: 59.38%] [G loss: 1.697390]\n",
      "epoch:11 step:8876 [D loss: 0.721981, acc: 44.53%] [G loss: 1.565905]\n",
      "epoch:11 step:8877 [D loss: 0.685447, acc: 50.78%] [G loss: 1.748779]\n",
      "epoch:11 step:8878 [D loss: 0.635576, acc: 67.19%] [G loss: 1.687963]\n",
      "epoch:11 step:8879 [D loss: 0.641660, acc: 67.97%] [G loss: 1.753121]\n",
      "epoch:11 step:8880 [D loss: 0.698295, acc: 53.12%] [G loss: 1.711754]\n",
      "epoch:11 step:8881 [D loss: 0.702259, acc: 50.78%] [G loss: 1.609958]\n",
      "epoch:11 step:8882 [D loss: 0.682651, acc: 60.16%] [G loss: 1.704140]\n",
      "epoch:11 step:8883 [D loss: 0.694453, acc: 55.47%] [G loss: 1.685779]\n",
      "epoch:11 step:8884 [D loss: 0.759082, acc: 39.84%] [G loss: 1.652286]\n",
      "epoch:11 step:8885 [D loss: 0.717080, acc: 46.09%] [G loss: 1.565423]\n",
      "epoch:11 step:8886 [D loss: 0.645720, acc: 65.62%] [G loss: 1.870308]\n",
      "epoch:11 step:8887 [D loss: 0.715753, acc: 48.44%] [G loss: 1.637197]\n",
      "epoch:11 step:8888 [D loss: 0.829982, acc: 28.12%] [G loss: 1.524552]\n",
      "epoch:11 step:8889 [D loss: 0.721602, acc: 47.66%] [G loss: 1.638931]\n",
      "epoch:11 step:8890 [D loss: 0.631977, acc: 72.66%] [G loss: 1.744099]\n",
      "epoch:11 step:8891 [D loss: 0.761373, acc: 40.62%] [G loss: 1.465810]\n",
      "epoch:11 step:8892 [D loss: 0.796429, acc: 42.97%] [G loss: 1.605416]\n",
      "epoch:11 step:8893 [D loss: 0.643372, acc: 65.62%] [G loss: 1.725336]\n",
      "epoch:11 step:8894 [D loss: 0.602012, acc: 71.09%] [G loss: 1.725562]\n",
      "epoch:11 step:8895 [D loss: 0.706582, acc: 56.25%] [G loss: 1.627511]\n",
      "epoch:11 step:8896 [D loss: 0.802639, acc: 38.28%] [G loss: 1.577507]\n",
      "epoch:11 step:8897 [D loss: 0.669229, acc: 57.81%] [G loss: 1.724303]\n",
      "epoch:11 step:8898 [D loss: 0.755542, acc: 46.88%] [G loss: 1.632803]\n",
      "epoch:11 step:8899 [D loss: 0.649318, acc: 63.28%] [G loss: 1.651665]\n",
      "epoch:11 step:8900 [D loss: 0.687859, acc: 50.00%] [G loss: 1.701327]\n",
      "epoch:11 step:8901 [D loss: 0.681771, acc: 60.16%] [G loss: 1.769156]\n",
      "epoch:11 step:8902 [D loss: 0.664984, acc: 63.28%] [G loss: 1.570848]\n",
      "epoch:11 step:8903 [D loss: 0.672095, acc: 60.94%] [G loss: 1.561766]\n",
      "epoch:11 step:8904 [D loss: 0.701077, acc: 54.69%] [G loss: 1.487299]\n",
      "epoch:11 step:8905 [D loss: 0.732980, acc: 50.00%] [G loss: 1.579858]\n",
      "epoch:11 step:8906 [D loss: 0.839533, acc: 35.16%] [G loss: 1.610619]\n",
      "epoch:11 step:8907 [D loss: 0.678845, acc: 58.59%] [G loss: 1.628319]\n",
      "epoch:11 step:8908 [D loss: 0.716329, acc: 50.00%] [G loss: 1.468402]\n",
      "epoch:11 step:8909 [D loss: 0.655891, acc: 60.94%] [G loss: 1.526332]\n",
      "epoch:11 step:8910 [D loss: 0.694423, acc: 51.56%] [G loss: 1.567838]\n",
      "epoch:11 step:8911 [D loss: 0.681812, acc: 53.12%] [G loss: 1.747931]\n",
      "epoch:11 step:8912 [D loss: 0.718658, acc: 53.91%] [G loss: 1.689521]\n",
      "epoch:11 step:8913 [D loss: 0.684868, acc: 55.47%] [G loss: 1.514944]\n",
      "epoch:11 step:8914 [D loss: 0.692360, acc: 55.47%] [G loss: 1.619459]\n",
      "epoch:11 step:8915 [D loss: 0.709859, acc: 52.34%] [G loss: 1.623833]\n",
      "epoch:11 step:8916 [D loss: 0.722306, acc: 50.00%] [G loss: 1.543702]\n",
      "epoch:11 step:8917 [D loss: 0.637468, acc: 65.62%] [G loss: 1.571316]\n",
      "epoch:11 step:8918 [D loss: 0.630684, acc: 69.53%] [G loss: 1.661057]\n",
      "epoch:11 step:8919 [D loss: 0.752492, acc: 46.09%] [G loss: 1.600777]\n",
      "epoch:11 step:8920 [D loss: 0.689384, acc: 60.16%] [G loss: 1.626317]\n",
      "epoch:11 step:8921 [D loss: 0.677421, acc: 58.59%] [G loss: 1.722293]\n",
      "epoch:11 step:8922 [D loss: 0.665592, acc: 61.72%] [G loss: 1.803831]\n",
      "epoch:11 step:8923 [D loss: 0.565230, acc: 74.22%] [G loss: 1.765368]\n",
      "epoch:11 step:8924 [D loss: 0.654353, acc: 60.94%] [G loss: 1.560885]\n",
      "epoch:11 step:8925 [D loss: 0.615357, acc: 65.62%] [G loss: 1.661492]\n",
      "epoch:11 step:8926 [D loss: 0.644237, acc: 62.50%] [G loss: 1.818829]\n",
      "epoch:11 step:8927 [D loss: 0.740289, acc: 43.75%] [G loss: 1.628430]\n",
      "epoch:11 step:8928 [D loss: 0.633888, acc: 64.84%] [G loss: 1.762008]\n",
      "epoch:11 step:8929 [D loss: 0.725131, acc: 50.78%] [G loss: 1.758986]\n",
      "epoch:11 step:8930 [D loss: 0.705787, acc: 46.09%] [G loss: 1.578371]\n",
      "epoch:11 step:8931 [D loss: 0.628047, acc: 67.19%] [G loss: 1.767958]\n",
      "epoch:11 step:8932 [D loss: 0.685684, acc: 59.38%] [G loss: 1.835849]\n",
      "epoch:11 step:8933 [D loss: 0.645643, acc: 67.19%] [G loss: 1.525019]\n",
      "epoch:11 step:8934 [D loss: 0.590572, acc: 71.09%] [G loss: 1.816778]\n",
      "epoch:11 step:8935 [D loss: 0.650707, acc: 63.28%] [G loss: 1.599994]\n",
      "epoch:11 step:8936 [D loss: 0.751770, acc: 47.66%] [G loss: 1.651832]\n",
      "epoch:11 step:8937 [D loss: 0.643019, acc: 65.62%] [G loss: 1.638732]\n",
      "epoch:11 step:8938 [D loss: 0.685938, acc: 53.12%] [G loss: 1.845887]\n",
      "epoch:11 step:8939 [D loss: 0.678925, acc: 58.59%] [G loss: 1.633905]\n",
      "epoch:11 step:8940 [D loss: 0.504443, acc: 81.25%] [G loss: 1.986382]\n",
      "epoch:11 step:8941 [D loss: 0.694577, acc: 52.34%] [G loss: 1.636771]\n",
      "epoch:11 step:8942 [D loss: 0.796974, acc: 30.47%] [G loss: 1.571397]\n",
      "epoch:11 step:8943 [D loss: 0.710513, acc: 50.78%] [G loss: 1.685941]\n",
      "epoch:11 step:8944 [D loss: 0.540574, acc: 78.12%] [G loss: 1.858173]\n",
      "epoch:11 step:8945 [D loss: 0.657192, acc: 60.94%] [G loss: 1.609875]\n",
      "epoch:11 step:8946 [D loss: 0.641898, acc: 63.28%] [G loss: 1.962979]\n",
      "epoch:11 step:8947 [D loss: 0.758884, acc: 42.97%] [G loss: 1.775222]\n",
      "epoch:11 step:8948 [D loss: 0.630782, acc: 63.28%] [G loss: 1.728185]\n",
      "epoch:11 step:8949 [D loss: 0.644806, acc: 60.94%] [G loss: 1.725105]\n",
      "epoch:11 step:8950 [D loss: 0.726225, acc: 51.56%] [G loss: 1.756499]\n",
      "epoch:11 step:8951 [D loss: 0.678270, acc: 50.78%] [G loss: 1.501146]\n",
      "epoch:11 step:8952 [D loss: 0.692442, acc: 54.69%] [G loss: 1.660166]\n",
      "epoch:11 step:8953 [D loss: 0.592950, acc: 74.22%] [G loss: 1.672218]\n",
      "epoch:11 step:8954 [D loss: 0.674270, acc: 53.91%] [G loss: 1.769331]\n",
      "epoch:11 step:8955 [D loss: 0.584859, acc: 72.66%] [G loss: 1.995409]\n",
      "epoch:11 step:8956 [D loss: 0.539419, acc: 78.12%] [G loss: 1.883593]\n",
      "epoch:11 step:8957 [D loss: 0.674946, acc: 60.16%] [G loss: 1.788934]\n",
      "epoch:11 step:8958 [D loss: 0.652294, acc: 60.94%] [G loss: 1.760555]\n",
      "epoch:11 step:8959 [D loss: 0.498522, acc: 75.00%] [G loss: 1.815843]\n",
      "epoch:11 step:8960 [D loss: 0.744790, acc: 46.88%] [G loss: 1.625366]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:8961 [D loss: 0.710513, acc: 55.47%] [G loss: 1.750955]\n",
      "epoch:11 step:8962 [D loss: 0.625689, acc: 61.72%] [G loss: 1.671316]\n",
      "epoch:11 step:8963 [D loss: 0.629090, acc: 67.97%] [G loss: 1.777302]\n",
      "epoch:11 step:8964 [D loss: 0.818255, acc: 41.41%] [G loss: 1.415327]\n",
      "epoch:11 step:8965 [D loss: 0.519065, acc: 83.59%] [G loss: 1.811118]\n",
      "epoch:11 step:8966 [D loss: 0.853078, acc: 26.56%] [G loss: 1.615246]\n",
      "epoch:11 step:8967 [D loss: 0.977762, acc: 15.62%] [G loss: 1.403759]\n",
      "epoch:11 step:8968 [D loss: 0.524430, acc: 86.72%] [G loss: 1.596365]\n",
      "epoch:11 step:8969 [D loss: 0.797696, acc: 40.62%] [G loss: 1.662930]\n",
      "epoch:11 step:8970 [D loss: 0.672754, acc: 61.72%] [G loss: 1.603326]\n",
      "epoch:11 step:8971 [D loss: 0.657857, acc: 57.81%] [G loss: 1.698373]\n",
      "epoch:11 step:8972 [D loss: 0.687550, acc: 57.81%] [G loss: 1.737268]\n",
      "epoch:11 step:8973 [D loss: 0.514959, acc: 78.12%] [G loss: 2.076460]\n",
      "epoch:11 step:8974 [D loss: 0.744298, acc: 42.97%] [G loss: 1.695562]\n",
      "epoch:11 step:8975 [D loss: 0.676937, acc: 58.59%] [G loss: 1.679544]\n",
      "epoch:11 step:8976 [D loss: 0.677838, acc: 60.94%] [G loss: 1.834888]\n",
      "epoch:11 step:8977 [D loss: 0.715409, acc: 55.47%] [G loss: 1.603032]\n",
      "epoch:11 step:8978 [D loss: 0.711231, acc: 53.12%] [G loss: 1.896469]\n",
      "epoch:11 step:8979 [D loss: 0.784256, acc: 47.66%] [G loss: 1.708665]\n",
      "epoch:11 step:8980 [D loss: 0.649642, acc: 63.28%] [G loss: 1.785495]\n",
      "epoch:11 step:8981 [D loss: 0.726288, acc: 52.34%] [G loss: 1.750213]\n",
      "epoch:11 step:8982 [D loss: 0.718889, acc: 55.47%] [G loss: 1.716163]\n",
      "epoch:11 step:8983 [D loss: 0.668424, acc: 53.12%] [G loss: 1.697786]\n",
      "epoch:11 step:8984 [D loss: 0.746416, acc: 45.31%] [G loss: 1.636685]\n",
      "epoch:11 step:8985 [D loss: 0.571608, acc: 76.56%] [G loss: 1.775135]\n",
      "epoch:11 step:8986 [D loss: 0.550974, acc: 81.25%] [G loss: 1.755780]\n",
      "epoch:11 step:8987 [D loss: 0.727513, acc: 45.31%] [G loss: 1.874442]\n",
      "epoch:11 step:8988 [D loss: 0.833822, acc: 37.50%] [G loss: 1.473462]\n",
      "epoch:11 step:8989 [D loss: 0.689533, acc: 58.59%] [G loss: 1.576482]\n",
      "epoch:11 step:8990 [D loss: 0.707039, acc: 53.12%] [G loss: 1.756608]\n",
      "epoch:11 step:8991 [D loss: 0.607914, acc: 68.75%] [G loss: 1.848145]\n",
      "epoch:11 step:8992 [D loss: 0.703882, acc: 56.25%] [G loss: 1.876488]\n",
      "epoch:11 step:8993 [D loss: 0.665034, acc: 58.59%] [G loss: 1.635238]\n",
      "epoch:11 step:8994 [D loss: 0.718993, acc: 48.44%] [G loss: 1.579095]\n",
      "epoch:11 step:8995 [D loss: 0.646947, acc: 64.06%] [G loss: 1.615666]\n",
      "epoch:11 step:8996 [D loss: 0.645166, acc: 62.50%] [G loss: 1.827534]\n",
      "epoch:11 step:8997 [D loss: 0.760874, acc: 41.41%] [G loss: 1.714782]\n",
      "epoch:11 step:8998 [D loss: 0.634250, acc: 67.97%] [G loss: 1.655937]\n",
      "epoch:11 step:8999 [D loss: 0.696488, acc: 54.69%] [G loss: 1.493078]\n",
      "epoch:11 step:9000 [D loss: 0.681636, acc: 54.69%] [G loss: 1.727168]\n",
      "epoch:11 step:9001 [D loss: 0.706068, acc: 57.03%] [G loss: 1.692875]\n",
      "epoch:11 step:9002 [D loss: 0.693898, acc: 57.81%] [G loss: 1.826050]\n",
      "epoch:11 step:9003 [D loss: 0.708502, acc: 53.91%] [G loss: 1.705845]\n",
      "epoch:11 step:9004 [D loss: 0.558518, acc: 81.25%] [G loss: 1.657281]\n",
      "epoch:11 step:9005 [D loss: 0.667232, acc: 55.47%] [G loss: 1.687733]\n",
      "epoch:11 step:9006 [D loss: 0.655156, acc: 62.50%] [G loss: 1.899409]\n",
      "epoch:11 step:9007 [D loss: 0.623632, acc: 67.19%] [G loss: 1.552032]\n",
      "epoch:11 step:9008 [D loss: 0.738022, acc: 50.00%] [G loss: 1.761134]\n",
      "epoch:11 step:9009 [D loss: 0.660615, acc: 57.81%] [G loss: 1.591084]\n",
      "epoch:11 step:9010 [D loss: 0.641118, acc: 63.28%] [G loss: 1.917806]\n",
      "epoch:11 step:9011 [D loss: 0.758666, acc: 47.66%] [G loss: 1.557943]\n",
      "epoch:11 step:9012 [D loss: 0.644476, acc: 60.16%] [G loss: 1.891238]\n",
      "epoch:11 step:9013 [D loss: 0.555044, acc: 78.91%] [G loss: 1.857277]\n",
      "epoch:11 step:9014 [D loss: 0.653291, acc: 65.62%] [G loss: 1.690608]\n",
      "epoch:11 step:9015 [D loss: 0.728606, acc: 50.78%] [G loss: 1.668783]\n",
      "epoch:11 step:9016 [D loss: 0.708286, acc: 58.59%] [G loss: 1.620184]\n",
      "epoch:11 step:9017 [D loss: 0.655491, acc: 64.84%] [G loss: 1.600792]\n",
      "epoch:11 step:9018 [D loss: 0.700605, acc: 53.91%] [G loss: 1.698332]\n",
      "epoch:11 step:9019 [D loss: 0.707315, acc: 50.78%] [G loss: 1.855682]\n",
      "epoch:11 step:9020 [D loss: 0.690370, acc: 58.59%] [G loss: 1.594791]\n",
      "epoch:11 step:9021 [D loss: 0.725290, acc: 55.47%] [G loss: 1.733013]\n",
      "epoch:11 step:9022 [D loss: 0.709226, acc: 49.22%] [G loss: 1.653688]\n",
      "epoch:11 step:9023 [D loss: 0.648592, acc: 64.06%] [G loss: 1.735421]\n",
      "epoch:11 step:9024 [D loss: 0.635810, acc: 63.28%] [G loss: 2.092835]\n",
      "epoch:11 step:9025 [D loss: 0.839218, acc: 28.91%] [G loss: 1.621069]\n",
      "epoch:11 step:9026 [D loss: 0.800291, acc: 33.59%] [G loss: 1.620746]\n",
      "epoch:11 step:9027 [D loss: 0.738208, acc: 50.78%] [G loss: 1.812461]\n",
      "epoch:11 step:9028 [D loss: 0.769380, acc: 39.84%] [G loss: 1.625811]\n",
      "epoch:11 step:9029 [D loss: 0.547839, acc: 75.78%] [G loss: 1.839433]\n",
      "epoch:11 step:9030 [D loss: 0.642548, acc: 66.41%] [G loss: 1.663868]\n",
      "epoch:11 step:9031 [D loss: 0.764419, acc: 48.44%] [G loss: 1.657657]\n",
      "epoch:11 step:9032 [D loss: 0.623073, acc: 67.19%] [G loss: 1.709439]\n",
      "epoch:11 step:9033 [D loss: 0.599142, acc: 72.66%] [G loss: 2.042498]\n",
      "epoch:11 step:9034 [D loss: 0.732884, acc: 46.09%] [G loss: 1.550266]\n",
      "epoch:11 step:9035 [D loss: 0.605412, acc: 76.56%] [G loss: 1.673245]\n",
      "epoch:11 step:9036 [D loss: 0.931855, acc: 18.75%] [G loss: 1.434741]\n",
      "epoch:11 step:9037 [D loss: 0.643582, acc: 61.72%] [G loss: 1.637905]\n",
      "epoch:11 step:9038 [D loss: 0.623789, acc: 71.88%] [G loss: 1.729260]\n",
      "epoch:11 step:9039 [D loss: 0.621594, acc: 63.28%] [G loss: 1.791010]\n",
      "epoch:11 step:9040 [D loss: 0.765278, acc: 46.09%] [G loss: 1.605215]\n",
      "epoch:11 step:9041 [D loss: 0.744105, acc: 44.53%] [G loss: 1.669107]\n",
      "epoch:11 step:9042 [D loss: 0.790463, acc: 36.72%] [G loss: 1.618284]\n",
      "epoch:11 step:9043 [D loss: 0.730579, acc: 46.88%] [G loss: 1.670050]\n",
      "epoch:11 step:9044 [D loss: 0.634740, acc: 64.06%] [G loss: 1.864905]\n",
      "epoch:11 step:9045 [D loss: 0.566475, acc: 70.31%] [G loss: 1.792129]\n",
      "epoch:11 step:9046 [D loss: 0.769322, acc: 39.84%] [G loss: 1.575729]\n",
      "epoch:11 step:9047 [D loss: 0.664779, acc: 60.16%] [G loss: 1.699925]\n",
      "epoch:11 step:9048 [D loss: 0.760811, acc: 45.31%] [G loss: 1.529415]\n",
      "epoch:11 step:9049 [D loss: 0.570251, acc: 73.44%] [G loss: 2.026669]\n",
      "epoch:11 step:9050 [D loss: 0.643148, acc: 57.81%] [G loss: 1.548459]\n",
      "epoch:11 step:9051 [D loss: 0.518908, acc: 82.03%] [G loss: 2.063741]\n",
      "epoch:11 step:9052 [D loss: 0.752311, acc: 42.19%] [G loss: 1.672070]\n",
      "epoch:11 step:9053 [D loss: 0.704016, acc: 49.22%] [G loss: 1.669132]\n",
      "epoch:11 step:9054 [D loss: 0.642831, acc: 62.50%] [G loss: 1.759991]\n",
      "epoch:11 step:9055 [D loss: 0.706281, acc: 45.31%] [G loss: 1.772279]\n",
      "epoch:11 step:9056 [D loss: 0.569329, acc: 63.28%] [G loss: 1.758691]\n",
      "epoch:11 step:9057 [D loss: 0.591735, acc: 74.22%] [G loss: 1.646771]\n",
      "epoch:11 step:9058 [D loss: 0.676769, acc: 57.03%] [G loss: 1.946435]\n",
      "epoch:11 step:9059 [D loss: 0.821562, acc: 34.38%] [G loss: 1.574056]\n",
      "epoch:11 step:9060 [D loss: 0.635448, acc: 64.84%] [G loss: 1.742241]\n",
      "epoch:11 step:9061 [D loss: 0.720244, acc: 56.25%] [G loss: 1.481298]\n",
      "epoch:11 step:9062 [D loss: 0.743240, acc: 47.66%] [G loss: 1.518281]\n",
      "epoch:11 step:9063 [D loss: 0.678877, acc: 57.03%] [G loss: 1.784230]\n",
      "epoch:11 step:9064 [D loss: 0.680339, acc: 54.69%] [G loss: 1.728899]\n",
      "epoch:11 step:9065 [D loss: 0.761058, acc: 42.19%] [G loss: 1.547987]\n",
      "epoch:11 step:9066 [D loss: 0.567669, acc: 70.31%] [G loss: 1.806281]\n",
      "epoch:11 step:9067 [D loss: 0.657347, acc: 63.28%] [G loss: 1.677672]\n",
      "epoch:11 step:9068 [D loss: 0.614743, acc: 73.44%] [G loss: 2.221393]\n",
      "epoch:11 step:9069 [D loss: 0.634095, acc: 67.97%] [G loss: 1.586385]\n",
      "epoch:11 step:9070 [D loss: 0.724106, acc: 45.31%] [G loss: 1.632955]\n",
      "epoch:11 step:9071 [D loss: 0.631605, acc: 67.97%] [G loss: 1.722647]\n",
      "epoch:11 step:9072 [D loss: 0.704650, acc: 55.47%] [G loss: 1.610726]\n",
      "epoch:11 step:9073 [D loss: 0.653586, acc: 64.06%] [G loss: 1.732851]\n",
      "epoch:11 step:9074 [D loss: 0.620915, acc: 71.09%] [G loss: 1.695453]\n",
      "epoch:11 step:9075 [D loss: 0.649841, acc: 60.94%] [G loss: 1.848157]\n",
      "epoch:11 step:9076 [D loss: 0.600116, acc: 67.97%] [G loss: 1.842372]\n",
      "epoch:11 step:9077 [D loss: 0.580596, acc: 75.00%] [G loss: 1.751071]\n",
      "epoch:11 step:9078 [D loss: 0.755687, acc: 42.97%] [G loss: 1.585372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:9079 [D loss: 0.561381, acc: 75.78%] [G loss: 1.729685]\n",
      "epoch:11 step:9080 [D loss: 0.586352, acc: 76.56%] [G loss: 1.884820]\n",
      "epoch:11 step:9081 [D loss: 0.567001, acc: 77.34%] [G loss: 2.067058]\n",
      "epoch:11 step:9082 [D loss: 0.595849, acc: 67.97%] [G loss: 2.046858]\n",
      "epoch:11 step:9083 [D loss: 0.698760, acc: 57.81%] [G loss: 1.741739]\n",
      "epoch:11 step:9084 [D loss: 0.634809, acc: 64.84%] [G loss: 1.889566]\n",
      "epoch:11 step:9085 [D loss: 0.838842, acc: 25.00%] [G loss: 1.433340]\n",
      "epoch:11 step:9086 [D loss: 0.694543, acc: 53.12%] [G loss: 1.620653]\n",
      "epoch:11 step:9087 [D loss: 0.520984, acc: 85.94%] [G loss: 2.092237]\n",
      "epoch:11 step:9088 [D loss: 0.522197, acc: 82.81%] [G loss: 2.123099]\n",
      "epoch:11 step:9089 [D loss: 0.575140, acc: 71.09%] [G loss: 2.044379]\n",
      "epoch:11 step:9090 [D loss: 0.710899, acc: 47.66%] [G loss: 1.838763]\n",
      "epoch:11 step:9091 [D loss: 0.668145, acc: 62.50%] [G loss: 1.807210]\n",
      "epoch:11 step:9092 [D loss: 0.639939, acc: 60.94%] [G loss: 1.722589]\n",
      "epoch:11 step:9093 [D loss: 0.690158, acc: 61.72%] [G loss: 1.585346]\n",
      "epoch:11 step:9094 [D loss: 0.677583, acc: 64.06%] [G loss: 2.013815]\n",
      "epoch:11 step:9095 [D loss: 0.797699, acc: 39.06%] [G loss: 1.608919]\n",
      "epoch:11 step:9096 [D loss: 0.571189, acc: 75.00%] [G loss: 2.079670]\n",
      "epoch:11 step:9097 [D loss: 0.765987, acc: 43.75%] [G loss: 1.600734]\n",
      "epoch:11 step:9098 [D loss: 0.709169, acc: 53.12%] [G loss: 1.864520]\n",
      "epoch:11 step:9099 [D loss: 0.721494, acc: 51.56%] [G loss: 1.690121]\n",
      "epoch:11 step:9100 [D loss: 0.683850, acc: 56.25%] [G loss: 1.766666]\n",
      "epoch:11 step:9101 [D loss: 0.660565, acc: 63.28%] [G loss: 1.763272]\n",
      "epoch:11 step:9102 [D loss: 0.431639, acc: 90.62%] [G loss: 2.121503]\n",
      "epoch:11 step:9103 [D loss: 0.688059, acc: 61.72%] [G loss: 2.099798]\n",
      "epoch:11 step:9104 [D loss: 0.814948, acc: 32.81%] [G loss: 1.623284]\n",
      "epoch:11 step:9105 [D loss: 0.667345, acc: 57.81%] [G loss: 1.728349]\n",
      "epoch:11 step:9106 [D loss: 0.565971, acc: 80.47%] [G loss: 1.841889]\n",
      "epoch:11 step:9107 [D loss: 0.481114, acc: 83.59%] [G loss: 2.224347]\n",
      "epoch:11 step:9108 [D loss: 0.522217, acc: 84.38%] [G loss: 1.829157]\n",
      "epoch:11 step:9109 [D loss: 0.664563, acc: 57.81%] [G loss: 1.753669]\n",
      "epoch:11 step:9110 [D loss: 0.601202, acc: 67.97%] [G loss: 1.843267]\n",
      "epoch:11 step:9111 [D loss: 0.577395, acc: 74.22%] [G loss: 2.093710]\n",
      "epoch:11 step:9112 [D loss: 0.569255, acc: 75.78%] [G loss: 2.104126]\n",
      "epoch:11 step:9113 [D loss: 0.724995, acc: 52.34%] [G loss: 1.948765]\n",
      "epoch:11 step:9114 [D loss: 0.795625, acc: 40.62%] [G loss: 1.479509]\n",
      "epoch:11 step:9115 [D loss: 0.885789, acc: 32.03%] [G loss: 1.782887]\n",
      "epoch:11 step:9116 [D loss: 0.506707, acc: 85.16%] [G loss: 2.246346]\n",
      "epoch:11 step:9117 [D loss: 0.613427, acc: 64.06%] [G loss: 1.975163]\n",
      "epoch:11 step:9118 [D loss: 0.746332, acc: 48.44%] [G loss: 1.722452]\n",
      "epoch:11 step:9119 [D loss: 0.542858, acc: 73.44%] [G loss: 2.294709]\n",
      "epoch:11 step:9120 [D loss: 0.682937, acc: 58.59%] [G loss: 1.730503]\n",
      "epoch:11 step:9121 [D loss: 0.765505, acc: 46.88%] [G loss: 1.601872]\n",
      "epoch:11 step:9122 [D loss: 0.674651, acc: 55.47%] [G loss: 2.020881]\n",
      "epoch:11 step:9123 [D loss: 0.711012, acc: 48.44%] [G loss: 1.891129]\n",
      "epoch:11 step:9124 [D loss: 0.446336, acc: 80.47%] [G loss: 2.054386]\n",
      "epoch:11 step:9125 [D loss: 0.727654, acc: 53.12%] [G loss: 1.716470]\n",
      "epoch:11 step:9126 [D loss: 0.728728, acc: 55.47%] [G loss: 1.647999]\n",
      "epoch:11 step:9127 [D loss: 0.546025, acc: 76.56%] [G loss: 2.079286]\n",
      "epoch:11 step:9128 [D loss: 0.487654, acc: 84.38%] [G loss: 2.425145]\n",
      "epoch:11 step:9129 [D loss: 0.701799, acc: 59.38%] [G loss: 1.841822]\n",
      "epoch:11 step:9130 [D loss: 0.669689, acc: 53.12%] [G loss: 1.844902]\n",
      "epoch:11 step:9131 [D loss: 0.746871, acc: 46.09%] [G loss: 1.711159]\n",
      "epoch:11 step:9132 [D loss: 0.751470, acc: 48.44%] [G loss: 1.628397]\n",
      "epoch:11 step:9133 [D loss: 0.578198, acc: 76.56%] [G loss: 1.760739]\n",
      "epoch:11 step:9134 [D loss: 0.733937, acc: 48.44%] [G loss: 1.692338]\n",
      "epoch:11 step:9135 [D loss: 0.545138, acc: 83.59%] [G loss: 1.743094]\n",
      "epoch:11 step:9136 [D loss: 0.703728, acc: 55.47%] [G loss: 1.735263]\n",
      "epoch:11 step:9137 [D loss: 0.626525, acc: 68.75%] [G loss: 1.982512]\n",
      "epoch:11 step:9138 [D loss: 0.615913, acc: 69.53%] [G loss: 1.886097]\n",
      "epoch:11 step:9139 [D loss: 0.705864, acc: 52.34%] [G loss: 1.745661]\n",
      "epoch:11 step:9140 [D loss: 0.626659, acc: 63.28%] [G loss: 1.831163]\n",
      "epoch:11 step:9141 [D loss: 0.640941, acc: 60.94%] [G loss: 1.872695]\n",
      "epoch:11 step:9142 [D loss: 0.597811, acc: 75.00%] [G loss: 2.074747]\n",
      "epoch:11 step:9143 [D loss: 0.817517, acc: 35.94%] [G loss: 1.640434]\n",
      "epoch:11 step:9144 [D loss: 0.810964, acc: 36.72%] [G loss: 2.023304]\n",
      "epoch:11 step:9145 [D loss: 0.815513, acc: 39.84%] [G loss: 1.485572]\n",
      "epoch:11 step:9146 [D loss: 0.547853, acc: 78.91%] [G loss: 2.069037]\n",
      "epoch:11 step:9147 [D loss: 0.621558, acc: 64.06%] [G loss: 1.669212]\n",
      "epoch:11 step:9148 [D loss: 0.846725, acc: 40.62%] [G loss: 1.696629]\n",
      "epoch:11 step:9149 [D loss: 0.666693, acc: 60.16%] [G loss: 1.628004]\n",
      "epoch:11 step:9150 [D loss: 0.497625, acc: 85.16%] [G loss: 2.143206]\n",
      "epoch:11 step:9151 [D loss: 0.696445, acc: 50.78%] [G loss: 1.806332]\n",
      "epoch:11 step:9152 [D loss: 0.554739, acc: 77.34%] [G loss: 1.786888]\n",
      "epoch:11 step:9153 [D loss: 0.873725, acc: 29.69%] [G loss: 1.617185]\n",
      "epoch:11 step:9154 [D loss: 0.629840, acc: 57.03%] [G loss: 1.678538]\n",
      "epoch:11 step:9155 [D loss: 0.732150, acc: 51.56%] [G loss: 1.658810]\n",
      "epoch:11 step:9156 [D loss: 0.544259, acc: 76.56%] [G loss: 1.941247]\n",
      "epoch:11 step:9157 [D loss: 0.650156, acc: 61.72%] [G loss: 1.994434]\n",
      "epoch:11 step:9158 [D loss: 0.661092, acc: 59.38%] [G loss: 1.782669]\n",
      "epoch:11 step:9159 [D loss: 0.656991, acc: 60.94%] [G loss: 1.793215]\n",
      "epoch:11 step:9160 [D loss: 0.558935, acc: 71.09%] [G loss: 1.903326]\n",
      "epoch:11 step:9161 [D loss: 0.605899, acc: 72.66%] [G loss: 1.841531]\n",
      "epoch:11 step:9162 [D loss: 0.766692, acc: 49.22%] [G loss: 1.648674]\n",
      "epoch:11 step:9163 [D loss: 0.664081, acc: 63.28%] [G loss: 1.757502]\n",
      "epoch:11 step:9164 [D loss: 0.673360, acc: 60.94%] [G loss: 1.910709]\n",
      "epoch:11 step:9165 [D loss: 0.692292, acc: 50.00%] [G loss: 1.641358]\n",
      "epoch:11 step:9166 [D loss: 0.746153, acc: 52.34%] [G loss: 1.908537]\n",
      "epoch:11 step:9167 [D loss: 0.574116, acc: 75.00%] [G loss: 1.959454]\n",
      "epoch:11 step:9168 [D loss: 0.624323, acc: 67.97%] [G loss: 2.088833]\n",
      "epoch:11 step:9169 [D loss: 0.640082, acc: 64.84%] [G loss: 1.912460]\n",
      "epoch:11 step:9170 [D loss: 0.768647, acc: 41.41%] [G loss: 1.805702]\n",
      "epoch:11 step:9171 [D loss: 0.717098, acc: 50.00%] [G loss: 1.761116]\n",
      "epoch:11 step:9172 [D loss: 0.559742, acc: 79.69%] [G loss: 2.062465]\n",
      "epoch:11 step:9173 [D loss: 0.641812, acc: 68.75%] [G loss: 1.701243]\n",
      "epoch:11 step:9174 [D loss: 0.793238, acc: 32.03%] [G loss: 1.539880]\n",
      "epoch:11 step:9175 [D loss: 0.702966, acc: 54.69%] [G loss: 1.723862]\n",
      "epoch:11 step:9176 [D loss: 0.669579, acc: 55.47%] [G loss: 1.772213]\n",
      "epoch:11 step:9177 [D loss: 0.602068, acc: 69.53%] [G loss: 1.770324]\n",
      "epoch:11 step:9178 [D loss: 0.608478, acc: 73.44%] [G loss: 2.182164]\n",
      "epoch:11 step:9179 [D loss: 0.677042, acc: 57.81%] [G loss: 1.650749]\n",
      "epoch:11 step:9180 [D loss: 0.887946, acc: 31.25%] [G loss: 1.542652]\n",
      "epoch:11 step:9181 [D loss: 0.586603, acc: 69.53%] [G loss: 2.098526]\n",
      "epoch:11 step:9182 [D loss: 0.613262, acc: 73.44%] [G loss: 2.042299]\n",
      "epoch:11 step:9183 [D loss: 0.548780, acc: 77.34%] [G loss: 1.896375]\n",
      "epoch:11 step:9184 [D loss: 0.900389, acc: 22.66%] [G loss: 1.857231]\n",
      "epoch:11 step:9185 [D loss: 0.481862, acc: 87.50%] [G loss: 2.110743]\n",
      "epoch:11 step:9186 [D loss: 0.632778, acc: 65.62%] [G loss: 1.598246]\n",
      "epoch:11 step:9187 [D loss: 0.755746, acc: 42.19%] [G loss: 1.537731]\n",
      "epoch:11 step:9188 [D loss: 0.572133, acc: 73.44%] [G loss: 1.930504]\n",
      "epoch:11 step:9189 [D loss: 0.685722, acc: 58.59%] [G loss: 1.806772]\n",
      "epoch:11 step:9190 [D loss: 0.694035, acc: 56.25%] [G loss: 1.662433]\n",
      "epoch:11 step:9191 [D loss: 0.831745, acc: 35.16%] [G loss: 1.449964]\n",
      "epoch:11 step:9192 [D loss: 0.798080, acc: 45.31%] [G loss: 1.841641]\n",
      "epoch:11 step:9193 [D loss: 0.619670, acc: 71.09%] [G loss: 1.694525]\n",
      "epoch:11 step:9194 [D loss: 0.594043, acc: 68.75%] [G loss: 1.945853]\n",
      "epoch:11 step:9195 [D loss: 0.776568, acc: 49.22%] [G loss: 2.157054]\n",
      "epoch:11 step:9196 [D loss: 0.588001, acc: 75.00%] [G loss: 1.642023]\n",
      "epoch:11 step:9197 [D loss: 0.613447, acc: 71.09%] [G loss: 1.783694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:9198 [D loss: 0.906092, acc: 25.00%] [G loss: 1.477852]\n",
      "epoch:11 step:9199 [D loss: 0.704967, acc: 55.47%] [G loss: 1.868732]\n",
      "epoch:11 step:9200 [D loss: 0.674463, acc: 63.28%] [G loss: 1.634593]\n",
      "epoch:11 step:9201 [D loss: 0.678255, acc: 58.59%] [G loss: 1.703087]\n",
      "epoch:11 step:9202 [D loss: 0.586250, acc: 73.44%] [G loss: 2.014192]\n",
      "epoch:11 step:9203 [D loss: 0.697066, acc: 50.00%] [G loss: 1.668673]\n",
      "epoch:11 step:9204 [D loss: 0.774525, acc: 46.09%] [G loss: 1.543039]\n",
      "epoch:11 step:9205 [D loss: 0.710212, acc: 53.91%] [G loss: 1.883136]\n",
      "epoch:11 step:9206 [D loss: 0.629969, acc: 70.31%] [G loss: 1.942091]\n",
      "epoch:11 step:9207 [D loss: 0.762044, acc: 47.66%] [G loss: 1.813471]\n",
      "epoch:11 step:9208 [D loss: 0.640907, acc: 68.75%] [G loss: 1.708529]\n",
      "epoch:11 step:9209 [D loss: 0.569779, acc: 71.09%] [G loss: 1.908857]\n",
      "epoch:11 step:9210 [D loss: 0.590122, acc: 73.44%] [G loss: 2.007177]\n",
      "epoch:11 step:9211 [D loss: 0.709402, acc: 50.00%] [G loss: 1.802259]\n",
      "epoch:11 step:9212 [D loss: 0.570509, acc: 73.44%] [G loss: 1.812201]\n",
      "epoch:11 step:9213 [D loss: 0.733710, acc: 53.12%] [G loss: 1.908767]\n",
      "epoch:11 step:9214 [D loss: 0.603265, acc: 69.53%] [G loss: 1.981331]\n",
      "epoch:11 step:9215 [D loss: 0.744772, acc: 52.34%] [G loss: 1.810869]\n",
      "epoch:11 step:9216 [D loss: 0.330639, acc: 94.53%] [G loss: 2.686689]\n",
      "epoch:11 step:9217 [D loss: 0.502670, acc: 67.19%] [G loss: 2.436308]\n",
      "epoch:11 step:9218 [D loss: 0.575424, acc: 71.09%] [G loss: 1.617313]\n",
      "epoch:11 step:9219 [D loss: 0.696303, acc: 60.16%] [G loss: 2.325622]\n",
      "epoch:11 step:9220 [D loss: 0.396700, acc: 94.53%] [G loss: 1.702460]\n",
      "epoch:11 step:9221 [D loss: 0.429603, acc: 82.03%] [G loss: 1.667516]\n",
      "epoch:11 step:9222 [D loss: 0.493836, acc: 86.72%] [G loss: 1.794510]\n",
      "epoch:11 step:9223 [D loss: 0.861430, acc: 44.53%] [G loss: 1.212329]\n",
      "epoch:11 step:9224 [D loss: 0.650054, acc: 65.62%] [G loss: 1.746264]\n",
      "epoch:11 step:9225 [D loss: 0.662568, acc: 61.72%] [G loss: 1.548341]\n",
      "epoch:11 step:9226 [D loss: 0.655914, acc: 59.38%] [G loss: 1.768540]\n",
      "epoch:11 step:9227 [D loss: 0.572162, acc: 73.44%] [G loss: 1.606098]\n",
      "epoch:11 step:9228 [D loss: 0.656965, acc: 60.16%] [G loss: 2.106125]\n",
      "epoch:11 step:9229 [D loss: 1.119449, acc: 10.94%] [G loss: 1.265865]\n",
      "epoch:11 step:9230 [D loss: 0.797453, acc: 37.50%] [G loss: 1.661708]\n",
      "epoch:11 step:9231 [D loss: 0.853252, acc: 35.94%] [G loss: 1.706677]\n",
      "epoch:11 step:9232 [D loss: 0.533856, acc: 84.38%] [G loss: 1.632243]\n",
      "epoch:11 step:9233 [D loss: 0.512548, acc: 82.81%] [G loss: 1.947683]\n",
      "epoch:11 step:9234 [D loss: 0.579789, acc: 73.44%] [G loss: 1.998954]\n",
      "epoch:11 step:9235 [D loss: 0.588733, acc: 70.31%] [G loss: 1.788512]\n",
      "epoch:11 step:9236 [D loss: 1.003004, acc: 17.97%] [G loss: 1.299252]\n",
      "epoch:11 step:9237 [D loss: 0.676589, acc: 55.47%] [G loss: 1.991453]\n",
      "epoch:11 step:9238 [D loss: 0.715777, acc: 53.12%] [G loss: 1.499811]\n",
      "epoch:11 step:9239 [D loss: 0.761396, acc: 46.09%] [G loss: 1.868776]\n",
      "epoch:11 step:9240 [D loss: 0.624629, acc: 63.28%] [G loss: 2.031107]\n",
      "epoch:11 step:9241 [D loss: 0.536520, acc: 78.91%] [G loss: 2.113694]\n",
      "epoch:11 step:9242 [D loss: 0.704449, acc: 52.34%] [G loss: 1.849816]\n",
      "epoch:11 step:9243 [D loss: 0.590598, acc: 70.31%] [G loss: 1.788481]\n",
      "epoch:11 step:9244 [D loss: 0.632877, acc: 66.41%] [G loss: 2.179734]\n",
      "epoch:11 step:9245 [D loss: 0.380955, acc: 82.81%] [G loss: 2.288428]\n",
      "epoch:11 step:9246 [D loss: 0.657660, acc: 62.50%] [G loss: 2.079090]\n",
      "epoch:11 step:9247 [D loss: 0.754714, acc: 42.19%] [G loss: 1.921530]\n",
      "epoch:11 step:9248 [D loss: 0.572550, acc: 66.41%] [G loss: 2.047974]\n",
      "epoch:11 step:9249 [D loss: 0.650770, acc: 60.94%] [G loss: 1.949357]\n",
      "epoch:11 step:9250 [D loss: 0.513398, acc: 78.12%] [G loss: 1.895062]\n",
      "epoch:11 step:9251 [D loss: 0.504255, acc: 70.31%] [G loss: 1.859645]\n",
      "epoch:11 step:9252 [D loss: 0.563775, acc: 71.09%] [G loss: 1.854758]\n",
      "epoch:11 step:9253 [D loss: 0.886527, acc: 23.44%] [G loss: 1.723539]\n",
      "epoch:11 step:9254 [D loss: 0.611544, acc: 66.41%] [G loss: 2.164837]\n",
      "epoch:11 step:9255 [D loss: 0.294772, acc: 93.75%] [G loss: 1.760167]\n",
      "epoch:11 step:9256 [D loss: 0.654664, acc: 54.69%] [G loss: 1.818455]\n",
      "epoch:11 step:9257 [D loss: 0.724238, acc: 51.56%] [G loss: 1.772355]\n",
      "epoch:11 step:9258 [D loss: 0.569396, acc: 78.12%] [G loss: 1.988845]\n",
      "epoch:11 step:9259 [D loss: 0.513579, acc: 82.03%] [G loss: 2.020759]\n",
      "epoch:11 step:9260 [D loss: 0.751491, acc: 47.66%] [G loss: 1.586794]\n",
      "epoch:11 step:9261 [D loss: 1.031556, acc: 14.84%] [G loss: 1.479683]\n",
      "epoch:11 step:9262 [D loss: 0.489390, acc: 82.81%] [G loss: 1.740188]\n",
      "epoch:11 step:9263 [D loss: 0.539280, acc: 75.78%] [G loss: 1.764737]\n",
      "epoch:11 step:9264 [D loss: 0.787340, acc: 39.06%] [G loss: 1.631355]\n",
      "epoch:11 step:9265 [D loss: 0.868967, acc: 26.56%] [G loss: 1.642834]\n",
      "epoch:11 step:9266 [D loss: 0.831620, acc: 32.81%] [G loss: 1.659265]\n",
      "epoch:11 step:9267 [D loss: 0.701649, acc: 52.34%] [G loss: 1.421850]\n",
      "epoch:11 step:9268 [D loss: 0.664414, acc: 57.81%] [G loss: 1.852541]\n",
      "epoch:11 step:9269 [D loss: 0.602007, acc: 70.31%] [G loss: 1.719776]\n",
      "epoch:11 step:9270 [D loss: 0.582636, acc: 75.78%] [G loss: 2.060364]\n",
      "epoch:11 step:9271 [D loss: 0.730943, acc: 45.31%] [G loss: 1.577109]\n",
      "epoch:11 step:9272 [D loss: 0.674374, acc: 60.16%] [G loss: 1.661796]\n",
      "epoch:11 step:9273 [D loss: 1.068800, acc: 16.41%] [G loss: 1.537008]\n",
      "epoch:11 step:9274 [D loss: 0.612879, acc: 71.09%] [G loss: 1.720110]\n",
      "epoch:11 step:9275 [D loss: 0.668707, acc: 62.50%] [G loss: 1.838272]\n",
      "epoch:11 step:9276 [D loss: 0.653108, acc: 58.59%] [G loss: 1.951861]\n",
      "epoch:11 step:9277 [D loss: 0.786094, acc: 39.06%] [G loss: 1.647178]\n",
      "epoch:11 step:9278 [D loss: 0.621449, acc: 64.84%] [G loss: 2.195161]\n",
      "epoch:11 step:9279 [D loss: 0.566841, acc: 75.78%] [G loss: 1.934591]\n",
      "epoch:11 step:9280 [D loss: 0.467015, acc: 82.03%] [G loss: 2.167574]\n",
      "epoch:11 step:9281 [D loss: 0.849525, acc: 46.88%] [G loss: 1.759362]\n",
      "epoch:11 step:9282 [D loss: 0.461066, acc: 85.16%] [G loss: 2.572260]\n",
      "epoch:11 step:9283 [D loss: 0.741996, acc: 44.53%] [G loss: 1.977822]\n",
      "epoch:11 step:9284 [D loss: 0.532864, acc: 79.69%] [G loss: 2.351337]\n",
      "epoch:11 step:9285 [D loss: 0.725975, acc: 53.12%] [G loss: 2.057154]\n",
      "epoch:11 step:9286 [D loss: 0.700318, acc: 55.47%] [G loss: 1.917278]\n",
      "epoch:11 step:9287 [D loss: 0.721758, acc: 50.00%] [G loss: 1.849790]\n",
      "epoch:11 step:9288 [D loss: 0.603033, acc: 69.53%] [G loss: 2.107682]\n",
      "epoch:11 step:9289 [D loss: 0.576035, acc: 72.66%] [G loss: 2.070684]\n",
      "epoch:11 step:9290 [D loss: 0.783119, acc: 42.19%] [G loss: 1.816025]\n",
      "epoch:11 step:9291 [D loss: 0.552255, acc: 76.56%] [G loss: 1.945144]\n",
      "epoch:11 step:9292 [D loss: 0.695892, acc: 57.03%] [G loss: 2.189402]\n",
      "epoch:11 step:9293 [D loss: 0.604194, acc: 67.19%] [G loss: 1.719242]\n",
      "epoch:11 step:9294 [D loss: 0.726522, acc: 53.12%] [G loss: 1.646185]\n",
      "epoch:11 step:9295 [D loss: 0.610668, acc: 68.75%] [G loss: 1.860789]\n",
      "epoch:11 step:9296 [D loss: 0.636794, acc: 60.94%] [G loss: 2.179512]\n",
      "epoch:11 step:9297 [D loss: 0.664878, acc: 59.38%] [G loss: 1.855593]\n",
      "epoch:11 step:9298 [D loss: 0.614942, acc: 69.53%] [G loss: 1.756277]\n",
      "epoch:11 step:9299 [D loss: 0.605901, acc: 66.41%] [G loss: 1.942530]\n",
      "epoch:11 step:9300 [D loss: 0.659936, acc: 63.28%] [G loss: 1.822373]\n",
      "epoch:11 step:9301 [D loss: 0.642103, acc: 60.94%] [G loss: 1.950434]\n",
      "epoch:11 step:9302 [D loss: 0.457093, acc: 79.69%] [G loss: 1.811912]\n",
      "epoch:11 step:9303 [D loss: 0.708572, acc: 55.47%] [G loss: 1.997679]\n",
      "epoch:11 step:9304 [D loss: 0.666673, acc: 62.50%] [G loss: 1.995162]\n",
      "epoch:11 step:9305 [D loss: 0.658035, acc: 61.72%] [G loss: 1.933276]\n",
      "epoch:11 step:9306 [D loss: 0.710278, acc: 58.59%] [G loss: 2.074782]\n",
      "epoch:11 step:9307 [D loss: 0.593458, acc: 67.97%] [G loss: 2.232885]\n",
      "epoch:11 step:9308 [D loss: 0.321259, acc: 96.88%] [G loss: 2.222508]\n",
      "epoch:11 step:9309 [D loss: 0.716195, acc: 51.56%] [G loss: 1.666952]\n",
      "epoch:11 step:9310 [D loss: 0.451383, acc: 89.06%] [G loss: 1.816520]\n",
      "epoch:11 step:9311 [D loss: 0.842148, acc: 35.16%] [G loss: 2.059137]\n",
      "epoch:11 step:9312 [D loss: 0.720473, acc: 52.34%] [G loss: 1.570151]\n",
      "epoch:11 step:9313 [D loss: 0.507439, acc: 82.81%] [G loss: 2.083180]\n",
      "epoch:11 step:9314 [D loss: 0.661842, acc: 59.38%] [G loss: 2.031137]\n",
      "epoch:11 step:9315 [D loss: 0.884997, acc: 35.16%] [G loss: 1.586731]\n",
      "epoch:11 step:9316 [D loss: 0.614847, acc: 67.19%] [G loss: 1.778811]\n",
      "epoch:11 step:9317 [D loss: 0.778756, acc: 39.06%] [G loss: 1.620574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:9318 [D loss: 0.618886, acc: 66.41%] [G loss: 1.741271]\n",
      "epoch:11 step:9319 [D loss: 0.579532, acc: 74.22%] [G loss: 1.640011]\n",
      "epoch:11 step:9320 [D loss: 0.890290, acc: 31.25%] [G loss: 1.822453]\n",
      "epoch:11 step:9321 [D loss: 0.638770, acc: 64.84%] [G loss: 1.839016]\n",
      "epoch:11 step:9322 [D loss: 0.658998, acc: 59.38%] [G loss: 1.693859]\n",
      "epoch:11 step:9323 [D loss: 0.779777, acc: 48.44%] [G loss: 1.570060]\n",
      "epoch:11 step:9324 [D loss: 0.723523, acc: 52.34%] [G loss: 1.831554]\n",
      "epoch:11 step:9325 [D loss: 0.731853, acc: 51.56%] [G loss: 1.816830]\n",
      "epoch:11 step:9326 [D loss: 0.758748, acc: 46.88%] [G loss: 2.046506]\n",
      "epoch:11 step:9327 [D loss: 0.717964, acc: 53.91%] [G loss: 1.780732]\n",
      "epoch:11 step:9328 [D loss: 0.523413, acc: 80.47%] [G loss: 2.392811]\n",
      "epoch:11 step:9329 [D loss: 0.608266, acc: 72.66%] [G loss: 1.699383]\n",
      "epoch:11 step:9330 [D loss: 0.681050, acc: 56.25%] [G loss: 1.863526]\n",
      "epoch:11 step:9331 [D loss: 0.814551, acc: 38.28%] [G loss: 1.518100]\n",
      "epoch:11 step:9332 [D loss: 0.460422, acc: 90.62%] [G loss: 2.044489]\n",
      "epoch:11 step:9333 [D loss: 0.643845, acc: 67.19%] [G loss: 1.819104]\n",
      "epoch:11 step:9334 [D loss: 0.711574, acc: 56.25%] [G loss: 1.959131]\n",
      "epoch:11 step:9335 [D loss: 0.584865, acc: 68.75%] [G loss: 2.070118]\n",
      "epoch:11 step:9336 [D loss: 0.526974, acc: 78.12%] [G loss: 1.807060]\n",
      "epoch:11 step:9337 [D loss: 0.530734, acc: 78.12%] [G loss: 2.074823]\n",
      "epoch:11 step:9338 [D loss: 0.752960, acc: 50.78%] [G loss: 1.810637]\n",
      "epoch:11 step:9339 [D loss: 0.630922, acc: 60.94%] [G loss: 2.051027]\n",
      "epoch:11 step:9340 [D loss: 0.638806, acc: 67.19%] [G loss: 2.148923]\n",
      "epoch:11 step:9341 [D loss: 0.705525, acc: 53.91%] [G loss: 1.823776]\n",
      "epoch:11 step:9342 [D loss: 0.750564, acc: 44.53%] [G loss: 1.560098]\n",
      "epoch:11 step:9343 [D loss: 0.667814, acc: 63.28%] [G loss: 1.881984]\n",
      "epoch:11 step:9344 [D loss: 0.637048, acc: 60.16%] [G loss: 2.088282]\n",
      "epoch:11 step:9345 [D loss: 0.600668, acc: 67.19%] [G loss: 2.020215]\n",
      "epoch:11 step:9346 [D loss: 0.620574, acc: 68.75%] [G loss: 2.002676]\n",
      "epoch:11 step:9347 [D loss: 0.565544, acc: 76.56%] [G loss: 2.164248]\n",
      "epoch:11 step:9348 [D loss: 0.555861, acc: 75.00%] [G loss: 2.545611]\n",
      "epoch:11 step:9349 [D loss: 0.724342, acc: 51.56%] [G loss: 2.380834]\n",
      "epoch:11 step:9350 [D loss: 0.678506, acc: 57.81%] [G loss: 1.795780]\n",
      "epoch:11 step:9351 [D loss: 0.525704, acc: 75.00%] [G loss: 2.160855]\n",
      "epoch:11 step:9352 [D loss: 0.652745, acc: 61.72%] [G loss: 1.771753]\n",
      "epoch:11 step:9353 [D loss: 0.615352, acc: 67.19%] [G loss: 2.129385]\n",
      "epoch:11 step:9354 [D loss: 0.712684, acc: 56.25%] [G loss: 2.039865]\n",
      "epoch:11 step:9355 [D loss: 0.792951, acc: 39.06%] [G loss: 1.719656]\n",
      "epoch:11 step:9356 [D loss: 0.500170, acc: 65.62%] [G loss: 2.591419]\n",
      "epoch:11 step:9357 [D loss: 0.757888, acc: 48.44%] [G loss: 1.955459]\n",
      "epoch:11 step:9358 [D loss: 0.703899, acc: 53.12%] [G loss: 1.838159]\n",
      "epoch:11 step:9359 [D loss: 0.549709, acc: 78.91%] [G loss: 2.060201]\n",
      "epoch:11 step:9360 [D loss: 0.873261, acc: 25.00%] [G loss: 1.640215]\n",
      "epoch:11 step:9361 [D loss: 0.613446, acc: 69.53%] [G loss: 2.033633]\n",
      "epoch:11 step:9362 [D loss: 0.679355, acc: 59.38%] [G loss: 2.111412]\n",
      "epoch:11 step:9363 [D loss: 0.712119, acc: 50.78%] [G loss: 1.755665]\n",
      "epoch:11 step:9364 [D loss: 0.600098, acc: 70.31%] [G loss: 1.994076]\n",
      "epoch:11 step:9365 [D loss: 0.528413, acc: 78.12%] [G loss: 1.861299]\n",
      "epoch:11 step:9366 [D loss: 0.833526, acc: 42.19%] [G loss: 1.780554]\n",
      "epoch:11 step:9367 [D loss: 0.692210, acc: 55.47%] [G loss: 1.817932]\n",
      "epoch:11 step:9368 [D loss: 0.763105, acc: 39.06%] [G loss: 1.687262]\n",
      "epoch:11 step:9369 [D loss: 0.886554, acc: 24.22%] [G loss: 1.614771]\n",
      "epoch:11 step:9370 [D loss: 0.831576, acc: 28.12%] [G loss: 1.665042]\n",
      "epoch:11 step:9371 [D loss: 0.701343, acc: 47.66%] [G loss: 1.625606]\n",
      "epoch:11 step:9372 [D loss: 0.694419, acc: 53.12%] [G loss: 1.950320]\n",
      "epoch:12 step:9373 [D loss: 0.592290, acc: 67.97%] [G loss: 1.885224]\n",
      "epoch:12 step:9374 [D loss: 0.533888, acc: 71.88%] [G loss: 1.758804]\n",
      "epoch:12 step:9375 [D loss: 0.546079, acc: 77.34%] [G loss: 2.253878]\n",
      "epoch:12 step:9376 [D loss: 0.694160, acc: 54.69%] [G loss: 1.654043]\n",
      "epoch:12 step:9377 [D loss: 0.526656, acc: 79.69%] [G loss: 2.038728]\n",
      "epoch:12 step:9378 [D loss: 0.638545, acc: 63.28%] [G loss: 1.914550]\n",
      "epoch:12 step:9379 [D loss: 0.400105, acc: 92.97%] [G loss: 2.564124]\n",
      "epoch:12 step:9380 [D loss: 0.677601, acc: 59.38%] [G loss: 1.753695]\n",
      "epoch:12 step:9381 [D loss: 0.614440, acc: 63.28%] [G loss: 1.855175]\n",
      "epoch:12 step:9382 [D loss: 0.692296, acc: 55.47%] [G loss: 1.803110]\n",
      "epoch:12 step:9383 [D loss: 0.728360, acc: 53.91%] [G loss: 2.000809]\n",
      "epoch:12 step:9384 [D loss: 0.675270, acc: 55.47%] [G loss: 1.875908]\n",
      "epoch:12 step:9385 [D loss: 0.678425, acc: 59.38%] [G loss: 1.868266]\n",
      "epoch:12 step:9386 [D loss: 0.422763, acc: 77.34%] [G loss: 2.272964]\n",
      "epoch:12 step:9387 [D loss: 1.077875, acc: 15.62%] [G loss: 1.317843]\n",
      "epoch:12 step:9388 [D loss: 0.769303, acc: 39.84%] [G loss: 1.701017]\n",
      "epoch:12 step:9389 [D loss: 0.612029, acc: 64.84%] [G loss: 2.038552]\n",
      "epoch:12 step:9390 [D loss: 0.655489, acc: 60.16%] [G loss: 1.540606]\n",
      "epoch:12 step:9391 [D loss: 0.656413, acc: 54.69%] [G loss: 1.724008]\n",
      "epoch:12 step:9392 [D loss: 0.756499, acc: 47.66%] [G loss: 1.655193]\n",
      "epoch:12 step:9393 [D loss: 0.518115, acc: 71.09%] [G loss: 1.884383]\n",
      "epoch:12 step:9394 [D loss: 0.691372, acc: 60.94%] [G loss: 1.706707]\n",
      "epoch:12 step:9395 [D loss: 0.531852, acc: 78.12%] [G loss: 1.853239]\n",
      "epoch:12 step:9396 [D loss: 0.820603, acc: 32.03%] [G loss: 1.614169]\n",
      "epoch:12 step:9397 [D loss: 0.594682, acc: 65.62%] [G loss: 1.797712]\n",
      "epoch:12 step:9398 [D loss: 0.742326, acc: 51.56%] [G loss: 1.547021]\n",
      "epoch:12 step:9399 [D loss: 0.631543, acc: 62.50%] [G loss: 2.102300]\n",
      "epoch:12 step:9400 [D loss: 0.595320, acc: 69.53%] [G loss: 1.922391]\n",
      "epoch:12 step:9401 [D loss: 0.558551, acc: 79.69%] [G loss: 1.807442]\n",
      "epoch:12 step:9402 [D loss: 0.673307, acc: 56.25%] [G loss: 1.712049]\n",
      "epoch:12 step:9403 [D loss: 0.622597, acc: 68.75%] [G loss: 1.836950]\n",
      "epoch:12 step:9404 [D loss: 0.642161, acc: 62.50%] [G loss: 1.732208]\n",
      "epoch:12 step:9405 [D loss: 0.712929, acc: 49.22%] [G loss: 1.644051]\n",
      "epoch:12 step:9406 [D loss: 0.598149, acc: 69.53%] [G loss: 1.663068]\n",
      "epoch:12 step:9407 [D loss: 0.667660, acc: 60.16%] [G loss: 1.689488]\n",
      "epoch:12 step:9408 [D loss: 0.609308, acc: 63.28%] [G loss: 2.295625]\n",
      "epoch:12 step:9409 [D loss: 0.621555, acc: 67.97%] [G loss: 1.898701]\n",
      "epoch:12 step:9410 [D loss: 0.700195, acc: 53.91%] [G loss: 1.756765]\n",
      "epoch:12 step:9411 [D loss: 0.554886, acc: 84.38%] [G loss: 1.708882]\n",
      "epoch:12 step:9412 [D loss: 0.708838, acc: 52.34%] [G loss: 1.768267]\n",
      "epoch:12 step:9413 [D loss: 0.518369, acc: 82.81%] [G loss: 2.192470]\n",
      "epoch:12 step:9414 [D loss: 0.667837, acc: 62.50%] [G loss: 2.348422]\n",
      "epoch:12 step:9415 [D loss: 0.465441, acc: 85.94%] [G loss: 2.457671]\n",
      "epoch:12 step:9416 [D loss: 0.554228, acc: 66.41%] [G loss: 2.356024]\n",
      "epoch:12 step:9417 [D loss: 0.747922, acc: 54.69%] [G loss: 1.974494]\n",
      "epoch:12 step:9418 [D loss: 0.618417, acc: 61.72%] [G loss: 2.107637]\n",
      "epoch:12 step:9419 [D loss: 0.756204, acc: 48.44%] [G loss: 1.963262]\n",
      "epoch:12 step:9420 [D loss: 0.514479, acc: 80.47%] [G loss: 1.537329]\n",
      "epoch:12 step:9421 [D loss: 0.911874, acc: 29.69%] [G loss: 1.428037]\n",
      "epoch:12 step:9422 [D loss: 0.728135, acc: 50.00%] [G loss: 1.532885]\n",
      "epoch:12 step:9423 [D loss: 0.461900, acc: 79.69%] [G loss: 1.931670]\n",
      "epoch:12 step:9424 [D loss: 0.653831, acc: 64.84%] [G loss: 2.090248]\n",
      "epoch:12 step:9425 [D loss: 0.813513, acc: 35.94%] [G loss: 1.582811]\n",
      "epoch:12 step:9426 [D loss: 0.743216, acc: 51.56%] [G loss: 1.848745]\n",
      "epoch:12 step:9427 [D loss: 0.503983, acc: 86.72%] [G loss: 2.031039]\n",
      "epoch:12 step:9428 [D loss: 0.843988, acc: 35.16%] [G loss: 1.577322]\n",
      "epoch:12 step:9429 [D loss: 0.663765, acc: 60.16%] [G loss: 1.579164]\n",
      "epoch:12 step:9430 [D loss: 0.623563, acc: 67.97%] [G loss: 1.916968]\n",
      "epoch:12 step:9431 [D loss: 0.617741, acc: 65.62%] [G loss: 1.974312]\n",
      "epoch:12 step:9432 [D loss: 0.693010, acc: 53.91%] [G loss: 1.781744]\n",
      "epoch:12 step:9433 [D loss: 0.793783, acc: 39.84%] [G loss: 1.929158]\n",
      "epoch:12 step:9434 [D loss: 0.718467, acc: 48.44%] [G loss: 1.719189]\n",
      "epoch:12 step:9435 [D loss: 0.649479, acc: 63.28%] [G loss: 2.113004]\n",
      "epoch:12 step:9436 [D loss: 0.556347, acc: 74.22%] [G loss: 1.906738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9437 [D loss: 0.715171, acc: 50.78%] [G loss: 1.623414]\n",
      "epoch:12 step:9438 [D loss: 0.754382, acc: 46.09%] [G loss: 1.832736]\n",
      "epoch:12 step:9439 [D loss: 0.898419, acc: 32.81%] [G loss: 1.331677]\n",
      "epoch:12 step:9440 [D loss: 0.664117, acc: 57.03%] [G loss: 1.905162]\n",
      "epoch:12 step:9441 [D loss: 0.443936, acc: 88.28%] [G loss: 2.039977]\n",
      "epoch:12 step:9442 [D loss: 0.658271, acc: 61.72%] [G loss: 1.676178]\n",
      "epoch:12 step:9443 [D loss: 1.145447, acc: 10.94%] [G loss: 1.410924]\n",
      "epoch:12 step:9444 [D loss: 0.897718, acc: 28.91%] [G loss: 1.705612]\n",
      "epoch:12 step:9445 [D loss: 0.568859, acc: 71.88%] [G loss: 1.831152]\n",
      "epoch:12 step:9446 [D loss: 0.779510, acc: 45.31%] [G loss: 1.747738]\n",
      "epoch:12 step:9447 [D loss: 0.695697, acc: 48.44%] [G loss: 1.718999]\n",
      "epoch:12 step:9448 [D loss: 0.706562, acc: 47.66%] [G loss: 1.783364]\n",
      "epoch:12 step:9449 [D loss: 0.620208, acc: 71.09%] [G loss: 1.621681]\n",
      "epoch:12 step:9450 [D loss: 0.837058, acc: 30.47%] [G loss: 1.418934]\n",
      "epoch:12 step:9451 [D loss: 0.674620, acc: 53.12%] [G loss: 1.694523]\n",
      "epoch:12 step:9452 [D loss: 0.740623, acc: 42.19%] [G loss: 1.551511]\n",
      "epoch:12 step:9453 [D loss: 0.673889, acc: 57.03%] [G loss: 1.615261]\n",
      "epoch:12 step:9454 [D loss: 0.593272, acc: 68.75%] [G loss: 1.546810]\n",
      "epoch:12 step:9455 [D loss: 0.772988, acc: 42.97%] [G loss: 1.583754]\n",
      "epoch:12 step:9456 [D loss: 0.796096, acc: 35.16%] [G loss: 1.500472]\n",
      "epoch:12 step:9457 [D loss: 0.692584, acc: 53.12%] [G loss: 1.756007]\n",
      "epoch:12 step:9458 [D loss: 0.697755, acc: 57.03%] [G loss: 1.632544]\n",
      "epoch:12 step:9459 [D loss: 0.570316, acc: 80.47%] [G loss: 1.925590]\n",
      "epoch:12 step:9460 [D loss: 0.784749, acc: 39.84%] [G loss: 1.512959]\n",
      "epoch:12 step:9461 [D loss: 0.712479, acc: 50.00%] [G loss: 1.641742]\n",
      "epoch:12 step:9462 [D loss: 0.705489, acc: 45.31%] [G loss: 1.608706]\n",
      "epoch:12 step:9463 [D loss: 0.611389, acc: 73.44%] [G loss: 1.873369]\n",
      "epoch:12 step:9464 [D loss: 0.702903, acc: 56.25%] [G loss: 1.471105]\n",
      "epoch:12 step:9465 [D loss: 0.709212, acc: 46.09%] [G loss: 1.711640]\n",
      "epoch:12 step:9466 [D loss: 0.785135, acc: 40.62%] [G loss: 1.608154]\n",
      "epoch:12 step:9467 [D loss: 0.630449, acc: 63.28%] [G loss: 1.814983]\n",
      "epoch:12 step:9468 [D loss: 0.527606, acc: 81.25%] [G loss: 1.931941]\n",
      "epoch:12 step:9469 [D loss: 0.777873, acc: 44.53%] [G loss: 1.575407]\n",
      "epoch:12 step:9470 [D loss: 0.701611, acc: 57.81%] [G loss: 1.673579]\n",
      "epoch:12 step:9471 [D loss: 0.661615, acc: 56.25%] [G loss: 1.841345]\n",
      "epoch:12 step:9472 [D loss: 0.662299, acc: 63.28%] [G loss: 1.659374]\n",
      "epoch:12 step:9473 [D loss: 0.731270, acc: 46.09%] [G loss: 1.611299]\n",
      "epoch:12 step:9474 [D loss: 0.530331, acc: 75.78%] [G loss: 1.874696]\n",
      "epoch:12 step:9475 [D loss: 0.695376, acc: 55.47%] [G loss: 2.006849]\n",
      "epoch:12 step:9476 [D loss: 0.731094, acc: 48.44%] [G loss: 1.831186]\n",
      "epoch:12 step:9477 [D loss: 0.698155, acc: 51.56%] [G loss: 1.678985]\n",
      "epoch:12 step:9478 [D loss: 0.614735, acc: 74.22%] [G loss: 1.821403]\n",
      "epoch:12 step:9479 [D loss: 0.763649, acc: 46.09%] [G loss: 1.785430]\n",
      "epoch:12 step:9480 [D loss: 0.569637, acc: 76.56%] [G loss: 1.836856]\n",
      "epoch:12 step:9481 [D loss: 0.665087, acc: 64.84%] [G loss: 1.818756]\n",
      "epoch:12 step:9482 [D loss: 0.642126, acc: 62.50%] [G loss: 1.923599]\n",
      "epoch:12 step:9483 [D loss: 0.617547, acc: 67.97%] [G loss: 1.782048]\n",
      "epoch:12 step:9484 [D loss: 0.507620, acc: 77.34%] [G loss: 1.860385]\n",
      "epoch:12 step:9485 [D loss: 0.800433, acc: 46.09%] [G loss: 1.721621]\n",
      "epoch:12 step:9486 [D loss: 0.729095, acc: 56.25%] [G loss: 1.792305]\n",
      "epoch:12 step:9487 [D loss: 0.707183, acc: 54.69%] [G loss: 1.520633]\n",
      "epoch:12 step:9488 [D loss: 0.535533, acc: 76.56%] [G loss: 2.072347]\n",
      "epoch:12 step:9489 [D loss: 0.738176, acc: 51.56%] [G loss: 1.624361]\n",
      "epoch:12 step:9490 [D loss: 0.611290, acc: 68.75%] [G loss: 1.838809]\n",
      "epoch:12 step:9491 [D loss: 0.620692, acc: 64.06%] [G loss: 1.847361]\n",
      "epoch:12 step:9492 [D loss: 0.625234, acc: 65.62%] [G loss: 1.913457]\n",
      "epoch:12 step:9493 [D loss: 0.615255, acc: 69.53%] [G loss: 1.842343]\n",
      "epoch:12 step:9494 [D loss: 0.600019, acc: 64.06%] [G loss: 1.923553]\n",
      "epoch:12 step:9495 [D loss: 0.545605, acc: 75.78%] [G loss: 2.111062]\n",
      "epoch:12 step:9496 [D loss: 0.816414, acc: 35.94%] [G loss: 1.668449]\n",
      "epoch:12 step:9497 [D loss: 0.695620, acc: 54.69%] [G loss: 1.717472]\n",
      "epoch:12 step:9498 [D loss: 0.693933, acc: 52.34%] [G loss: 1.727397]\n",
      "epoch:12 step:9499 [D loss: 0.693209, acc: 53.12%] [G loss: 1.753889]\n",
      "epoch:12 step:9500 [D loss: 0.636845, acc: 67.19%] [G loss: 1.762896]\n",
      "epoch:12 step:9501 [D loss: 0.615299, acc: 67.19%] [G loss: 1.900021]\n",
      "epoch:12 step:9502 [D loss: 0.886827, acc: 35.16%] [G loss: 1.512048]\n",
      "epoch:12 step:9503 [D loss: 0.565389, acc: 78.12%] [G loss: 1.750559]\n",
      "epoch:12 step:9504 [D loss: 0.597012, acc: 69.53%] [G loss: 1.877904]\n",
      "epoch:12 step:9505 [D loss: 0.610901, acc: 67.97%] [G loss: 2.036728]\n",
      "epoch:12 step:9506 [D loss: 0.489975, acc: 88.28%] [G loss: 2.073082]\n",
      "epoch:12 step:9507 [D loss: 0.691632, acc: 50.78%] [G loss: 1.794383]\n",
      "epoch:12 step:9508 [D loss: 0.581850, acc: 71.09%] [G loss: 1.905844]\n",
      "epoch:12 step:9509 [D loss: 0.620867, acc: 60.94%] [G loss: 1.801398]\n",
      "epoch:12 step:9510 [D loss: 0.626367, acc: 61.72%] [G loss: 2.082623]\n",
      "epoch:12 step:9511 [D loss: 0.546687, acc: 74.22%] [G loss: 1.939592]\n",
      "epoch:12 step:9512 [D loss: 0.477865, acc: 86.72%] [G loss: 2.147386]\n",
      "epoch:12 step:9513 [D loss: 0.576712, acc: 74.22%] [G loss: 1.898898]\n",
      "epoch:12 step:9514 [D loss: 0.684339, acc: 57.81%] [G loss: 1.876603]\n",
      "epoch:12 step:9515 [D loss: 0.777595, acc: 46.09%] [G loss: 1.985035]\n",
      "epoch:12 step:9516 [D loss: 0.765286, acc: 45.31%] [G loss: 1.949305]\n",
      "epoch:12 step:9517 [D loss: 0.492891, acc: 84.38%] [G loss: 2.257405]\n",
      "epoch:12 step:9518 [D loss: 0.585195, acc: 71.88%] [G loss: 1.956593]\n",
      "epoch:12 step:9519 [D loss: 0.402740, acc: 92.19%] [G loss: 2.024664]\n",
      "epoch:12 step:9520 [D loss: 0.720481, acc: 50.00%] [G loss: 1.642765]\n",
      "epoch:12 step:9521 [D loss: 0.470300, acc: 89.06%] [G loss: 2.123981]\n",
      "epoch:12 step:9522 [D loss: 0.549266, acc: 72.66%] [G loss: 1.916892]\n",
      "epoch:12 step:9523 [D loss: 0.592320, acc: 72.66%] [G loss: 1.726107]\n",
      "epoch:12 step:9524 [D loss: 0.954721, acc: 36.72%] [G loss: 1.813420]\n",
      "epoch:12 step:9525 [D loss: 0.518517, acc: 78.91%] [G loss: 1.610991]\n",
      "epoch:12 step:9526 [D loss: 0.479773, acc: 89.84%] [G loss: 1.903544]\n",
      "epoch:12 step:9527 [D loss: 0.571285, acc: 72.66%] [G loss: 2.007370]\n",
      "epoch:12 step:9528 [D loss: 0.728977, acc: 54.69%] [G loss: 1.768893]\n",
      "epoch:12 step:9529 [D loss: 0.555099, acc: 76.56%] [G loss: 1.791673]\n",
      "epoch:12 step:9530 [D loss: 0.922636, acc: 23.44%] [G loss: 1.727513]\n",
      "epoch:12 step:9531 [D loss: 0.643706, acc: 68.75%] [G loss: 1.731998]\n",
      "epoch:12 step:9532 [D loss: 1.059938, acc: 12.50%] [G loss: 1.366436]\n",
      "epoch:12 step:9533 [D loss: 0.743174, acc: 50.00%] [G loss: 1.948548]\n",
      "epoch:12 step:9534 [D loss: 0.654896, acc: 68.75%] [G loss: 1.875367]\n",
      "epoch:12 step:9535 [D loss: 0.542257, acc: 79.69%] [G loss: 1.774714]\n",
      "epoch:12 step:9536 [D loss: 0.576631, acc: 73.44%] [G loss: 2.148658]\n",
      "epoch:12 step:9537 [D loss: 0.622931, acc: 67.97%] [G loss: 2.039342]\n",
      "epoch:12 step:9538 [D loss: 0.945959, acc: 24.22%] [G loss: 1.487961]\n",
      "epoch:12 step:9539 [D loss: 0.725969, acc: 57.81%] [G loss: 1.925102]\n",
      "epoch:12 step:9540 [D loss: 0.522304, acc: 81.25%] [G loss: 1.937829]\n",
      "epoch:12 step:9541 [D loss: 0.598268, acc: 69.53%] [G loss: 1.866836]\n",
      "epoch:12 step:9542 [D loss: 0.429497, acc: 83.59%] [G loss: 2.208968]\n",
      "epoch:12 step:9543 [D loss: 0.644988, acc: 63.28%] [G loss: 1.958581]\n",
      "epoch:12 step:9544 [D loss: 0.653649, acc: 64.06%] [G loss: 1.727274]\n",
      "epoch:12 step:9545 [D loss: 0.961070, acc: 25.00%] [G loss: 1.415728]\n",
      "epoch:12 step:9546 [D loss: 0.570723, acc: 76.56%] [G loss: 2.321142]\n",
      "epoch:12 step:9547 [D loss: 0.446809, acc: 89.06%] [G loss: 1.891690]\n",
      "epoch:12 step:9548 [D loss: 0.701319, acc: 51.56%] [G loss: 1.620570]\n",
      "epoch:12 step:9549 [D loss: 0.626945, acc: 67.97%] [G loss: 1.793476]\n",
      "epoch:12 step:9550 [D loss: 0.659125, acc: 57.81%] [G loss: 2.212207]\n",
      "epoch:12 step:9551 [D loss: 0.550269, acc: 72.66%] [G loss: 2.032321]\n",
      "epoch:12 step:9552 [D loss: 0.539804, acc: 76.56%] [G loss: 1.743304]\n",
      "epoch:12 step:9553 [D loss: 0.538898, acc: 78.91%] [G loss: 1.938661]\n",
      "epoch:12 step:9554 [D loss: 0.600578, acc: 66.41%] [G loss: 1.875112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9555 [D loss: 0.656203, acc: 63.28%] [G loss: 1.681907]\n",
      "epoch:12 step:9556 [D loss: 0.392805, acc: 93.75%] [G loss: 1.869835]\n",
      "epoch:12 step:9557 [D loss: 0.412556, acc: 86.72%] [G loss: 1.703317]\n",
      "epoch:12 step:9558 [D loss: 0.782839, acc: 43.75%] [G loss: 1.809706]\n",
      "epoch:12 step:9559 [D loss: 0.616833, acc: 62.50%] [G loss: 2.073544]\n",
      "epoch:12 step:9560 [D loss: 0.513706, acc: 82.81%] [G loss: 1.582066]\n",
      "epoch:12 step:9561 [D loss: 0.537357, acc: 75.00%] [G loss: 1.832806]\n",
      "epoch:12 step:9562 [D loss: 0.833760, acc: 38.28%] [G loss: 1.736523]\n",
      "epoch:12 step:9563 [D loss: 0.357939, acc: 92.97%] [G loss: 2.071995]\n",
      "epoch:12 step:9564 [D loss: 0.713283, acc: 50.00%] [G loss: 1.553780]\n",
      "epoch:12 step:9565 [D loss: 0.650441, acc: 61.72%] [G loss: 1.709726]\n",
      "epoch:12 step:9566 [D loss: 0.841114, acc: 37.50%] [G loss: 1.656507]\n",
      "epoch:12 step:9567 [D loss: 0.725377, acc: 52.34%] [G loss: 1.610681]\n",
      "epoch:12 step:9568 [D loss: 1.064526, acc: 27.34%] [G loss: 1.283252]\n",
      "epoch:12 step:9569 [D loss: 0.789829, acc: 43.75%] [G loss: 1.721464]\n",
      "epoch:12 step:9570 [D loss: 0.658697, acc: 60.16%] [G loss: 1.731009]\n",
      "epoch:12 step:9571 [D loss: 0.729726, acc: 51.56%] [G loss: 1.482868]\n",
      "epoch:12 step:9572 [D loss: 0.694038, acc: 59.38%] [G loss: 1.768999]\n",
      "epoch:12 step:9573 [D loss: 0.592700, acc: 71.09%] [G loss: 1.927529]\n",
      "epoch:12 step:9574 [D loss: 0.771924, acc: 48.44%] [G loss: 1.437964]\n",
      "epoch:12 step:9575 [D loss: 0.620107, acc: 66.41%] [G loss: 1.894989]\n",
      "epoch:12 step:9576 [D loss: 0.469643, acc: 86.72%] [G loss: 1.644879]\n",
      "epoch:12 step:9577 [D loss: 0.676936, acc: 55.47%] [G loss: 1.640146]\n",
      "epoch:12 step:9578 [D loss: 0.701375, acc: 53.91%] [G loss: 1.526373]\n",
      "epoch:12 step:9579 [D loss: 0.719495, acc: 50.78%] [G loss: 1.755439]\n",
      "epoch:12 step:9580 [D loss: 0.695533, acc: 50.78%] [G loss: 1.605707]\n",
      "epoch:12 step:9581 [D loss: 0.745312, acc: 42.19%] [G loss: 1.405815]\n",
      "epoch:12 step:9582 [D loss: 0.641008, acc: 64.06%] [G loss: 1.865489]\n",
      "epoch:12 step:9583 [D loss: 0.580549, acc: 72.66%] [G loss: 1.720309]\n",
      "epoch:12 step:9584 [D loss: 0.471450, acc: 87.50%] [G loss: 1.999008]\n",
      "epoch:12 step:9585 [D loss: 0.564578, acc: 77.34%] [G loss: 2.008803]\n",
      "epoch:12 step:9586 [D loss: 0.661936, acc: 60.16%] [G loss: 1.860242]\n",
      "epoch:12 step:9587 [D loss: 0.758538, acc: 46.88%] [G loss: 1.720334]\n",
      "epoch:12 step:9588 [D loss: 0.652886, acc: 57.03%] [G loss: 1.864123]\n",
      "epoch:12 step:9589 [D loss: 0.734166, acc: 52.34%] [G loss: 1.762798]\n",
      "epoch:12 step:9590 [D loss: 0.710917, acc: 57.03%] [G loss: 1.614986]\n",
      "epoch:12 step:9591 [D loss: 0.707294, acc: 57.03%] [G loss: 1.787147]\n",
      "epoch:12 step:9592 [D loss: 0.487089, acc: 75.00%] [G loss: 1.659155]\n",
      "epoch:12 step:9593 [D loss: 0.655941, acc: 65.62%] [G loss: 1.922600]\n",
      "epoch:12 step:9594 [D loss: 0.837112, acc: 39.84%] [G loss: 1.712399]\n",
      "epoch:12 step:9595 [D loss: 0.715929, acc: 53.12%] [G loss: 1.696154]\n",
      "epoch:12 step:9596 [D loss: 0.548421, acc: 78.12%] [G loss: 1.823573]\n",
      "epoch:12 step:9597 [D loss: 0.603531, acc: 63.28%] [G loss: 1.756205]\n",
      "epoch:12 step:9598 [D loss: 0.993478, acc: 24.22%] [G loss: 1.575574]\n",
      "epoch:12 step:9599 [D loss: 0.450997, acc: 89.06%] [G loss: 1.973721]\n",
      "epoch:12 step:9600 [D loss: 0.757792, acc: 55.47%] [G loss: 1.807579]\n",
      "epoch:12 step:9601 [D loss: 0.810978, acc: 38.28%] [G loss: 1.470617]\n",
      "epoch:12 step:9602 [D loss: 0.772868, acc: 48.44%] [G loss: 1.673738]\n",
      "epoch:12 step:9603 [D loss: 0.624892, acc: 68.75%] [G loss: 1.948776]\n",
      "epoch:12 step:9604 [D loss: 0.479950, acc: 79.69%] [G loss: 1.730839]\n",
      "epoch:12 step:9605 [D loss: 0.575239, acc: 72.66%] [G loss: 1.816516]\n",
      "epoch:12 step:9606 [D loss: 0.602599, acc: 72.66%] [G loss: 1.855507]\n",
      "epoch:12 step:9607 [D loss: 0.707827, acc: 59.38%] [G loss: 1.654956]\n",
      "epoch:12 step:9608 [D loss: 1.098714, acc: 16.41%] [G loss: 1.572918]\n",
      "epoch:12 step:9609 [D loss: 0.741852, acc: 49.22%] [G loss: 1.732031]\n",
      "epoch:12 step:9610 [D loss: 0.762697, acc: 47.66%] [G loss: 1.623500]\n",
      "epoch:12 step:9611 [D loss: 0.651268, acc: 64.84%] [G loss: 1.932097]\n",
      "epoch:12 step:9612 [D loss: 0.671343, acc: 60.94%] [G loss: 1.825874]\n",
      "epoch:12 step:9613 [D loss: 0.668312, acc: 60.16%] [G loss: 1.750194]\n",
      "epoch:12 step:9614 [D loss: 0.607784, acc: 69.53%] [G loss: 1.483185]\n",
      "epoch:12 step:9615 [D loss: 0.653183, acc: 63.28%] [G loss: 1.660562]\n",
      "epoch:12 step:9616 [D loss: 0.753886, acc: 44.53%] [G loss: 1.693928]\n",
      "epoch:12 step:9617 [D loss: 0.567828, acc: 72.66%] [G loss: 1.646969]\n",
      "epoch:12 step:9618 [D loss: 0.510740, acc: 82.03%] [G loss: 1.981984]\n",
      "epoch:12 step:9619 [D loss: 0.540873, acc: 79.69%] [G loss: 1.855037]\n",
      "epoch:12 step:9620 [D loss: 0.877497, acc: 32.81%] [G loss: 1.772583]\n",
      "epoch:12 step:9621 [D loss: 0.713821, acc: 51.56%] [G loss: 1.829815]\n",
      "epoch:12 step:9622 [D loss: 0.763649, acc: 45.31%] [G loss: 1.825819]\n",
      "epoch:12 step:9623 [D loss: 0.606892, acc: 68.75%] [G loss: 1.803022]\n",
      "epoch:12 step:9624 [D loss: 0.483840, acc: 86.72%] [G loss: 1.827137]\n",
      "epoch:12 step:9625 [D loss: 0.655403, acc: 60.16%] [G loss: 1.749958]\n",
      "epoch:12 step:9626 [D loss: 0.717637, acc: 48.44%] [G loss: 1.599707]\n",
      "epoch:12 step:9627 [D loss: 0.771686, acc: 44.53%] [G loss: 1.761689]\n",
      "epoch:12 step:9628 [D loss: 0.740558, acc: 46.09%] [G loss: 1.522569]\n",
      "epoch:12 step:9629 [D loss: 0.896206, acc: 23.44%] [G loss: 1.441575]\n",
      "epoch:12 step:9630 [D loss: 0.576109, acc: 76.56%] [G loss: 1.717690]\n",
      "epoch:12 step:9631 [D loss: 0.693459, acc: 57.81%] [G loss: 1.741434]\n",
      "epoch:12 step:9632 [D loss: 0.629629, acc: 64.84%] [G loss: 1.866488]\n",
      "epoch:12 step:9633 [D loss: 0.631932, acc: 69.53%] [G loss: 1.775917]\n",
      "epoch:12 step:9634 [D loss: 0.655249, acc: 60.94%] [G loss: 1.726286]\n",
      "epoch:12 step:9635 [D loss: 0.609143, acc: 65.62%] [G loss: 1.817169]\n",
      "epoch:12 step:9636 [D loss: 0.585878, acc: 77.34%] [G loss: 1.702922]\n",
      "epoch:12 step:9637 [D loss: 0.600930, acc: 69.53%] [G loss: 1.689545]\n",
      "epoch:12 step:9638 [D loss: 0.694132, acc: 54.69%] [G loss: 1.877471]\n",
      "epoch:12 step:9639 [D loss: 1.315977, acc: 21.88%] [G loss: 1.361188]\n",
      "epoch:12 step:9640 [D loss: 0.600422, acc: 71.88%] [G loss: 1.813660]\n",
      "epoch:12 step:9641 [D loss: 0.595732, acc: 71.88%] [G loss: 1.899883]\n",
      "epoch:12 step:9642 [D loss: 0.724939, acc: 49.22%] [G loss: 1.730932]\n",
      "epoch:12 step:9643 [D loss: 0.727830, acc: 54.69%] [G loss: 1.744011]\n",
      "epoch:12 step:9644 [D loss: 0.821881, acc: 30.47%] [G loss: 1.619935]\n",
      "epoch:12 step:9645 [D loss: 0.546240, acc: 78.91%] [G loss: 1.922243]\n",
      "epoch:12 step:9646 [D loss: 0.781304, acc: 34.38%] [G loss: 1.474306]\n",
      "epoch:12 step:9647 [D loss: 0.584942, acc: 71.09%] [G loss: 1.744887]\n",
      "epoch:12 step:9648 [D loss: 0.652516, acc: 64.06%] [G loss: 1.655763]\n",
      "epoch:12 step:9649 [D loss: 0.566823, acc: 75.00%] [G loss: 1.585937]\n",
      "epoch:12 step:9650 [D loss: 0.486480, acc: 84.38%] [G loss: 1.868596]\n",
      "epoch:12 step:9651 [D loss: 0.546999, acc: 75.00%] [G loss: 1.706255]\n",
      "epoch:12 step:9652 [D loss: 0.633321, acc: 62.50%] [G loss: 1.953230]\n",
      "epoch:12 step:9653 [D loss: 0.602835, acc: 72.66%] [G loss: 1.802156]\n",
      "epoch:12 step:9654 [D loss: 0.419615, acc: 90.62%] [G loss: 1.898296]\n",
      "epoch:12 step:9655 [D loss: 0.571237, acc: 74.22%] [G loss: 1.950709]\n",
      "epoch:12 step:9656 [D loss: 0.494885, acc: 86.72%] [G loss: 1.893381]\n",
      "epoch:12 step:9657 [D loss: 0.745062, acc: 46.09%] [G loss: 1.727512]\n",
      "epoch:12 step:9658 [D loss: 0.582891, acc: 71.09%] [G loss: 1.934863]\n",
      "epoch:12 step:9659 [D loss: 0.478941, acc: 93.75%] [G loss: 2.139638]\n",
      "epoch:12 step:9660 [D loss: 0.576283, acc: 74.22%] [G loss: 1.871172]\n",
      "epoch:12 step:9661 [D loss: 0.714574, acc: 55.47%] [G loss: 1.669443]\n",
      "epoch:12 step:9662 [D loss: 0.711659, acc: 49.22%] [G loss: 1.613410]\n",
      "epoch:12 step:9663 [D loss: 0.689399, acc: 61.72%] [G loss: 1.757205]\n",
      "epoch:12 step:9664 [D loss: 0.633275, acc: 61.72%] [G loss: 1.965642]\n",
      "epoch:12 step:9665 [D loss: 0.666589, acc: 62.50%] [G loss: 1.712112]\n",
      "epoch:12 step:9666 [D loss: 0.640461, acc: 64.84%] [G loss: 1.764865]\n",
      "epoch:12 step:9667 [D loss: 0.563190, acc: 73.44%] [G loss: 2.128587]\n",
      "epoch:12 step:9668 [D loss: 0.680094, acc: 54.69%] [G loss: 1.885956]\n",
      "epoch:12 step:9669 [D loss: 0.470105, acc: 75.78%] [G loss: 2.108930]\n",
      "epoch:12 step:9670 [D loss: 0.635157, acc: 67.19%] [G loss: 1.833697]\n",
      "epoch:12 step:9671 [D loss: 0.737498, acc: 49.22%] [G loss: 2.057934]\n",
      "epoch:12 step:9672 [D loss: 0.657019, acc: 64.84%] [G loss: 1.561236]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9673 [D loss: 0.863956, acc: 28.91%] [G loss: 1.368264]\n",
      "epoch:12 step:9674 [D loss: 0.490798, acc: 85.94%] [G loss: 1.911051]\n",
      "epoch:12 step:9675 [D loss: 0.489429, acc: 78.12%] [G loss: 1.926849]\n",
      "epoch:12 step:9676 [D loss: 0.619694, acc: 62.50%] [G loss: 1.392154]\n",
      "epoch:12 step:9677 [D loss: 0.924428, acc: 30.47%] [G loss: 1.274358]\n",
      "epoch:12 step:9678 [D loss: 0.691531, acc: 57.03%] [G loss: 1.738345]\n",
      "epoch:12 step:9679 [D loss: 0.602815, acc: 67.97%] [G loss: 1.916575]\n",
      "epoch:12 step:9680 [D loss: 0.643831, acc: 64.84%] [G loss: 1.741077]\n",
      "epoch:12 step:9681 [D loss: 0.386643, acc: 81.25%] [G loss: 1.888107]\n",
      "epoch:12 step:9682 [D loss: 0.715562, acc: 51.56%] [G loss: 2.080979]\n",
      "epoch:12 step:9683 [D loss: 0.864732, acc: 32.81%] [G loss: 1.408796]\n",
      "epoch:12 step:9684 [D loss: 0.608325, acc: 69.53%] [G loss: 1.931046]\n",
      "epoch:12 step:9685 [D loss: 0.941910, acc: 25.00%] [G loss: 1.455736]\n",
      "epoch:12 step:9686 [D loss: 0.586068, acc: 71.88%] [G loss: 1.698008]\n",
      "epoch:12 step:9687 [D loss: 1.095394, acc: 12.50%] [G loss: 1.401135]\n",
      "epoch:12 step:9688 [D loss: 0.647555, acc: 63.28%] [G loss: 1.627472]\n",
      "epoch:12 step:9689 [D loss: 0.637716, acc: 63.28%] [G loss: 1.652439]\n",
      "epoch:12 step:9690 [D loss: 0.512976, acc: 80.47%] [G loss: 2.022272]\n",
      "epoch:12 step:9691 [D loss: 0.723231, acc: 49.22%] [G loss: 1.829311]\n",
      "epoch:12 step:9692 [D loss: 0.663009, acc: 61.72%] [G loss: 1.727401]\n",
      "epoch:12 step:9693 [D loss: 0.697884, acc: 56.25%] [G loss: 1.852561]\n",
      "epoch:12 step:9694 [D loss: 0.569128, acc: 82.81%] [G loss: 1.865643]\n",
      "epoch:12 step:9695 [D loss: 0.576588, acc: 72.66%] [G loss: 1.985860]\n",
      "epoch:12 step:9696 [D loss: 0.555511, acc: 76.56%] [G loss: 2.140230]\n",
      "epoch:12 step:9697 [D loss: 0.715260, acc: 49.22%] [G loss: 1.801903]\n",
      "epoch:12 step:9698 [D loss: 0.552031, acc: 78.91%] [G loss: 1.918705]\n",
      "epoch:12 step:9699 [D loss: 0.572508, acc: 71.09%] [G loss: 1.840944]\n",
      "epoch:12 step:9700 [D loss: 0.657543, acc: 61.72%] [G loss: 1.705616]\n",
      "epoch:12 step:9701 [D loss: 0.724304, acc: 42.19%] [G loss: 1.705494]\n",
      "epoch:12 step:9702 [D loss: 0.624274, acc: 61.72%] [G loss: 1.559641]\n",
      "epoch:12 step:9703 [D loss: 0.630820, acc: 59.38%] [G loss: 2.072301]\n",
      "epoch:12 step:9704 [D loss: 0.645101, acc: 59.38%] [G loss: 1.756010]\n",
      "epoch:12 step:9705 [D loss: 0.738031, acc: 46.09%] [G loss: 1.566575]\n",
      "epoch:12 step:9706 [D loss: 0.541770, acc: 77.34%] [G loss: 2.029114]\n",
      "epoch:12 step:9707 [D loss: 0.588253, acc: 72.66%] [G loss: 2.057972]\n",
      "epoch:12 step:9708 [D loss: 0.632910, acc: 62.50%] [G loss: 1.832872]\n",
      "epoch:12 step:9709 [D loss: 0.451696, acc: 91.41%] [G loss: 2.042331]\n",
      "epoch:12 step:9710 [D loss: 0.594264, acc: 70.31%] [G loss: 2.048671]\n",
      "epoch:12 step:9711 [D loss: 0.933052, acc: 35.94%] [G loss: 1.610919]\n",
      "epoch:12 step:9712 [D loss: 0.668795, acc: 57.03%] [G loss: 1.952732]\n",
      "epoch:12 step:9713 [D loss: 0.457877, acc: 87.50%] [G loss: 1.661665]\n",
      "epoch:12 step:9714 [D loss: 0.625022, acc: 66.41%] [G loss: 1.824633]\n",
      "epoch:12 step:9715 [D loss: 0.653497, acc: 60.94%] [G loss: 1.689417]\n",
      "epoch:12 step:9716 [D loss: 0.720713, acc: 50.00%] [G loss: 1.770217]\n",
      "epoch:12 step:9717 [D loss: 0.799206, acc: 38.28%] [G loss: 1.564698]\n",
      "epoch:12 step:9718 [D loss: 0.490459, acc: 89.84%] [G loss: 2.113522]\n",
      "epoch:12 step:9719 [D loss: 0.647959, acc: 60.94%] [G loss: 2.236611]\n",
      "epoch:12 step:9720 [D loss: 0.695372, acc: 56.25%] [G loss: 1.752209]\n",
      "epoch:12 step:9721 [D loss: 0.469297, acc: 82.03%] [G loss: 2.330158]\n",
      "epoch:12 step:9722 [D loss: 0.691530, acc: 60.16%] [G loss: 1.811547]\n",
      "epoch:12 step:9723 [D loss: 0.590983, acc: 71.09%] [G loss: 1.663145]\n",
      "epoch:12 step:9724 [D loss: 0.622567, acc: 67.19%] [G loss: 2.061422]\n",
      "epoch:12 step:9725 [D loss: 0.683269, acc: 56.25%] [G loss: 2.263483]\n",
      "epoch:12 step:9726 [D loss: 0.786033, acc: 43.75%] [G loss: 1.780624]\n",
      "epoch:12 step:9727 [D loss: 0.649665, acc: 62.50%] [G loss: 1.774944]\n",
      "epoch:12 step:9728 [D loss: 0.644340, acc: 60.16%] [G loss: 1.744152]\n",
      "epoch:12 step:9729 [D loss: 0.587484, acc: 76.56%] [G loss: 1.891801]\n",
      "epoch:12 step:9730 [D loss: 0.844512, acc: 34.38%] [G loss: 1.764181]\n",
      "epoch:12 step:9731 [D loss: 0.748242, acc: 48.44%] [G loss: 1.790287]\n",
      "epoch:12 step:9732 [D loss: 0.778462, acc: 37.50%] [G loss: 1.617060]\n",
      "epoch:12 step:9733 [D loss: 0.654704, acc: 65.62%] [G loss: 1.823986]\n",
      "epoch:12 step:9734 [D loss: 0.606376, acc: 71.09%] [G loss: 2.030979]\n",
      "epoch:12 step:9735 [D loss: 0.609534, acc: 73.44%] [G loss: 1.917567]\n",
      "epoch:12 step:9736 [D loss: 0.571712, acc: 72.66%] [G loss: 2.155060]\n",
      "epoch:12 step:9737 [D loss: 0.518315, acc: 77.34%] [G loss: 2.002972]\n",
      "epoch:12 step:9738 [D loss: 0.497700, acc: 81.25%] [G loss: 1.974862]\n",
      "epoch:12 step:9739 [D loss: 0.501814, acc: 80.47%] [G loss: 1.938605]\n",
      "epoch:12 step:9740 [D loss: 0.605408, acc: 72.66%] [G loss: 1.837178]\n",
      "epoch:12 step:9741 [D loss: 0.708650, acc: 57.81%] [G loss: 1.723452]\n",
      "epoch:12 step:9742 [D loss: 0.689445, acc: 57.03%] [G loss: 1.908308]\n",
      "epoch:12 step:9743 [D loss: 0.584992, acc: 72.66%] [G loss: 1.781279]\n",
      "epoch:12 step:9744 [D loss: 0.490977, acc: 65.62%] [G loss: 1.984568]\n",
      "epoch:12 step:9745 [D loss: 0.900931, acc: 23.44%] [G loss: 1.859686]\n",
      "epoch:12 step:9746 [D loss: 0.679636, acc: 56.25%] [G loss: 2.141422]\n",
      "epoch:12 step:9747 [D loss: 0.852911, acc: 30.47%] [G loss: 2.000860]\n",
      "epoch:12 step:9748 [D loss: 0.576398, acc: 71.09%] [G loss: 1.585539]\n",
      "epoch:12 step:9749 [D loss: 0.681243, acc: 55.47%] [G loss: 1.547269]\n",
      "epoch:12 step:9750 [D loss: 0.681191, acc: 53.12%] [G loss: 1.659582]\n",
      "epoch:12 step:9751 [D loss: 0.423801, acc: 91.41%] [G loss: 1.917999]\n",
      "epoch:12 step:9752 [D loss: 0.505692, acc: 82.81%] [G loss: 2.309872]\n",
      "epoch:12 step:9753 [D loss: 0.432431, acc: 93.75%] [G loss: 1.806523]\n",
      "epoch:12 step:9754 [D loss: 0.465989, acc: 90.62%] [G loss: 2.014552]\n",
      "epoch:12 step:9755 [D loss: 0.774483, acc: 52.34%] [G loss: 1.769268]\n",
      "epoch:12 step:9756 [D loss: 0.508856, acc: 75.78%] [G loss: 1.905463]\n",
      "epoch:12 step:9757 [D loss: 0.579186, acc: 72.66%] [G loss: 2.513997]\n",
      "epoch:12 step:9758 [D loss: 0.640784, acc: 65.62%] [G loss: 1.839572]\n",
      "epoch:12 step:9759 [D loss: 0.617147, acc: 68.75%] [G loss: 1.742396]\n",
      "epoch:12 step:9760 [D loss: 0.763187, acc: 50.00%] [G loss: 1.681910]\n",
      "epoch:12 step:9761 [D loss: 0.701014, acc: 53.91%] [G loss: 2.106184]\n",
      "epoch:12 step:9762 [D loss: 0.878077, acc: 28.12%] [G loss: 1.553159]\n",
      "epoch:12 step:9763 [D loss: 0.858755, acc: 32.03%] [G loss: 1.506941]\n",
      "epoch:12 step:9764 [D loss: 0.584588, acc: 75.00%] [G loss: 1.751747]\n",
      "epoch:12 step:9765 [D loss: 0.640008, acc: 60.16%] [G loss: 1.653815]\n",
      "epoch:12 step:9766 [D loss: 0.813855, acc: 40.62%] [G loss: 1.565481]\n",
      "epoch:12 step:9767 [D loss: 0.661507, acc: 54.69%] [G loss: 1.980379]\n",
      "epoch:12 step:9768 [D loss: 0.535485, acc: 75.78%] [G loss: 2.310472]\n",
      "epoch:12 step:9769 [D loss: 0.850182, acc: 43.75%] [G loss: 1.654976]\n",
      "epoch:12 step:9770 [D loss: 0.751619, acc: 44.53%] [G loss: 1.696556]\n",
      "epoch:12 step:9771 [D loss: 0.625861, acc: 70.31%] [G loss: 2.160537]\n",
      "epoch:12 step:9772 [D loss: 0.700601, acc: 52.34%] [G loss: 1.853270]\n",
      "epoch:12 step:9773 [D loss: 0.436795, acc: 92.19%] [G loss: 1.999518]\n",
      "epoch:12 step:9774 [D loss: 0.719946, acc: 49.22%] [G loss: 1.785709]\n",
      "epoch:12 step:9775 [D loss: 0.666826, acc: 58.59%] [G loss: 1.830256]\n",
      "epoch:12 step:9776 [D loss: 0.627999, acc: 67.97%] [G loss: 2.014339]\n",
      "epoch:12 step:9777 [D loss: 0.630137, acc: 60.16%] [G loss: 2.007996]\n",
      "epoch:12 step:9778 [D loss: 0.648258, acc: 61.72%] [G loss: 1.750319]\n",
      "epoch:12 step:9779 [D loss: 0.793067, acc: 39.84%] [G loss: 1.746549]\n",
      "epoch:12 step:9780 [D loss: 0.538705, acc: 71.09%] [G loss: 1.896476]\n",
      "epoch:12 step:9781 [D loss: 0.722321, acc: 53.91%] [G loss: 1.783925]\n",
      "epoch:12 step:9782 [D loss: 0.649029, acc: 64.84%] [G loss: 1.752751]\n",
      "epoch:12 step:9783 [D loss: 0.636835, acc: 63.28%] [G loss: 2.069153]\n",
      "epoch:12 step:9784 [D loss: 0.636102, acc: 63.28%] [G loss: 1.568737]\n",
      "epoch:12 step:9785 [D loss: 0.659838, acc: 59.38%] [G loss: 1.861711]\n",
      "epoch:12 step:9786 [D loss: 0.372722, acc: 87.50%] [G loss: 2.124737]\n",
      "epoch:12 step:9787 [D loss: 0.502670, acc: 77.34%] [G loss: 1.754153]\n",
      "epoch:12 step:9788 [D loss: 0.516889, acc: 77.34%] [G loss: 1.796404]\n",
      "epoch:12 step:9789 [D loss: 0.994761, acc: 32.81%] [G loss: 1.913644]\n",
      "epoch:12 step:9790 [D loss: 0.580353, acc: 72.66%] [G loss: 2.451850]\n",
      "epoch:12 step:9791 [D loss: 0.515757, acc: 78.12%] [G loss: 1.792107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9792 [D loss: 0.635715, acc: 63.28%] [G loss: 1.705857]\n",
      "epoch:12 step:9793 [D loss: 0.582644, acc: 71.88%] [G loss: 1.996135]\n",
      "epoch:12 step:9794 [D loss: 0.383996, acc: 92.97%] [G loss: 2.036959]\n",
      "epoch:12 step:9795 [D loss: 0.637516, acc: 64.84%] [G loss: 1.957813]\n",
      "epoch:12 step:9796 [D loss: 0.863575, acc: 32.81%] [G loss: 1.634812]\n",
      "epoch:12 step:9797 [D loss: 0.709252, acc: 50.78%] [G loss: 1.847102]\n",
      "epoch:12 step:9798 [D loss: 0.624543, acc: 64.06%] [G loss: 1.737525]\n",
      "epoch:12 step:9799 [D loss: 0.557747, acc: 75.78%] [G loss: 2.153442]\n",
      "epoch:12 step:9800 [D loss: 0.639315, acc: 59.38%] [G loss: 1.802528]\n",
      "epoch:12 step:9801 [D loss: 0.719703, acc: 48.44%] [G loss: 2.544914]\n",
      "epoch:12 step:9802 [D loss: 0.447030, acc: 78.12%] [G loss: 2.177951]\n",
      "epoch:12 step:9803 [D loss: 0.480094, acc: 85.16%] [G loss: 2.071810]\n",
      "epoch:12 step:9804 [D loss: 0.649283, acc: 56.25%] [G loss: 1.986126]\n",
      "epoch:12 step:9805 [D loss: 0.423253, acc: 91.41%] [G loss: 2.362877]\n",
      "epoch:12 step:9806 [D loss: 0.726533, acc: 51.56%] [G loss: 2.669823]\n",
      "epoch:12 step:9807 [D loss: 0.584236, acc: 73.44%] [G loss: 1.970860]\n",
      "epoch:12 step:9808 [D loss: 0.519188, acc: 79.69%] [G loss: 2.516081]\n",
      "epoch:12 step:9809 [D loss: 0.855363, acc: 27.34%] [G loss: 1.634157]\n",
      "epoch:12 step:9810 [D loss: 0.690785, acc: 53.91%] [G loss: 2.069149]\n",
      "epoch:12 step:9811 [D loss: 0.515914, acc: 78.12%] [G loss: 1.995294]\n",
      "epoch:12 step:9812 [D loss: 0.690727, acc: 54.69%] [G loss: 1.755066]\n",
      "epoch:12 step:9813 [D loss: 0.748034, acc: 48.44%] [G loss: 2.007052]\n",
      "epoch:12 step:9814 [D loss: 0.611221, acc: 63.28%] [G loss: 1.888800]\n",
      "epoch:12 step:9815 [D loss: 0.586684, acc: 71.88%] [G loss: 1.888674]\n",
      "epoch:12 step:9816 [D loss: 0.662074, acc: 62.50%] [G loss: 2.049126]\n",
      "epoch:12 step:9817 [D loss: 0.713456, acc: 56.25%] [G loss: 1.823852]\n",
      "epoch:12 step:9818 [D loss: 0.579260, acc: 72.66%] [G loss: 1.978206]\n",
      "epoch:12 step:9819 [D loss: 0.605812, acc: 62.50%] [G loss: 1.885155]\n",
      "epoch:12 step:9820 [D loss: 0.537154, acc: 70.31%] [G loss: 2.252475]\n",
      "epoch:12 step:9821 [D loss: 0.615873, acc: 71.09%] [G loss: 1.976639]\n",
      "epoch:12 step:9822 [D loss: 0.626299, acc: 65.62%] [G loss: 2.160840]\n",
      "epoch:12 step:9823 [D loss: 0.683141, acc: 53.91%] [G loss: 2.216657]\n",
      "epoch:12 step:9824 [D loss: 0.695152, acc: 56.25%] [G loss: 1.959358]\n",
      "epoch:12 step:9825 [D loss: 0.564547, acc: 72.66%] [G loss: 2.542019]\n",
      "epoch:12 step:9826 [D loss: 0.535554, acc: 80.47%] [G loss: 1.915942]\n",
      "epoch:12 step:9827 [D loss: 0.630292, acc: 64.84%] [G loss: 2.077050]\n",
      "epoch:12 step:9828 [D loss: 0.736289, acc: 50.78%] [G loss: 1.868427]\n",
      "epoch:12 step:9829 [D loss: 0.662543, acc: 63.28%] [G loss: 1.863266]\n",
      "epoch:12 step:9830 [D loss: 0.554520, acc: 75.00%] [G loss: 1.934437]\n",
      "epoch:12 step:9831 [D loss: 0.640683, acc: 59.38%] [G loss: 1.921489]\n",
      "epoch:12 step:9832 [D loss: 0.505678, acc: 79.69%] [G loss: 2.118001]\n",
      "epoch:12 step:9833 [D loss: 0.674576, acc: 53.12%] [G loss: 1.946736]\n",
      "epoch:12 step:9834 [D loss: 0.629366, acc: 63.28%] [G loss: 1.881178]\n",
      "epoch:12 step:9835 [D loss: 0.566718, acc: 72.66%] [G loss: 1.998441]\n",
      "epoch:12 step:9836 [D loss: 0.536555, acc: 77.34%] [G loss: 2.290286]\n",
      "epoch:12 step:9837 [D loss: 0.403321, acc: 82.03%] [G loss: 2.594450]\n",
      "epoch:12 step:9838 [D loss: 0.575081, acc: 68.75%] [G loss: 2.044788]\n",
      "epoch:12 step:9839 [D loss: 0.591067, acc: 67.97%] [G loss: 2.230449]\n",
      "epoch:12 step:9840 [D loss: 0.604122, acc: 71.88%] [G loss: 1.782938]\n",
      "epoch:12 step:9841 [D loss: 0.611013, acc: 62.50%] [G loss: 1.864790]\n",
      "epoch:12 step:9842 [D loss: 0.618847, acc: 67.19%] [G loss: 1.751290]\n",
      "epoch:12 step:9843 [D loss: 0.751420, acc: 39.06%] [G loss: 2.183871]\n",
      "epoch:12 step:9844 [D loss: 0.635851, acc: 63.28%] [G loss: 2.058421]\n",
      "epoch:12 step:9845 [D loss: 0.560328, acc: 75.00%] [G loss: 1.808740]\n",
      "epoch:12 step:9846 [D loss: 0.524727, acc: 64.06%] [G loss: 2.349620]\n",
      "epoch:12 step:9847 [D loss: 0.636385, acc: 64.06%] [G loss: 2.033030]\n",
      "epoch:12 step:9848 [D loss: 0.490483, acc: 78.12%] [G loss: 2.492772]\n",
      "epoch:12 step:9849 [D loss: 0.841424, acc: 32.81%] [G loss: 1.642186]\n",
      "epoch:12 step:9850 [D loss: 0.645763, acc: 60.94%] [G loss: 1.970315]\n",
      "epoch:12 step:9851 [D loss: 0.737767, acc: 53.12%] [G loss: 1.866685]\n",
      "epoch:12 step:9852 [D loss: 0.679627, acc: 54.69%] [G loss: 2.082178]\n",
      "epoch:12 step:9853 [D loss: 0.780179, acc: 46.88%] [G loss: 1.828818]\n",
      "epoch:12 step:9854 [D loss: 0.819498, acc: 42.19%] [G loss: 1.912623]\n",
      "epoch:12 step:9855 [D loss: 0.512292, acc: 84.38%] [G loss: 2.129637]\n",
      "epoch:12 step:9856 [D loss: 0.686579, acc: 59.38%] [G loss: 2.137251]\n",
      "epoch:12 step:9857 [D loss: 0.844936, acc: 41.41%] [G loss: 1.711936]\n",
      "epoch:12 step:9858 [D loss: 0.494093, acc: 71.09%] [G loss: 2.596633]\n",
      "epoch:12 step:9859 [D loss: 0.732950, acc: 45.31%] [G loss: 2.018716]\n",
      "epoch:12 step:9860 [D loss: 0.692699, acc: 57.81%] [G loss: 2.187760]\n",
      "epoch:12 step:9861 [D loss: 0.644282, acc: 63.28%] [G loss: 1.877936]\n",
      "epoch:12 step:9862 [D loss: 0.599264, acc: 71.88%] [G loss: 2.303883]\n",
      "epoch:12 step:9863 [D loss: 0.536241, acc: 80.47%] [G loss: 2.317368]\n",
      "epoch:12 step:9864 [D loss: 0.595108, acc: 64.84%] [G loss: 2.060336]\n",
      "epoch:12 step:9865 [D loss: 0.608500, acc: 69.53%] [G loss: 2.707506]\n",
      "epoch:12 step:9866 [D loss: 0.680627, acc: 51.56%] [G loss: 1.711934]\n",
      "epoch:12 step:9867 [D loss: 0.488726, acc: 84.38%] [G loss: 2.139440]\n",
      "epoch:12 step:9868 [D loss: 0.492426, acc: 89.06%] [G loss: 2.064539]\n",
      "epoch:12 step:9869 [D loss: 0.483899, acc: 83.59%] [G loss: 2.149580]\n",
      "epoch:12 step:9870 [D loss: 0.587685, acc: 69.53%] [G loss: 2.015749]\n",
      "epoch:12 step:9871 [D loss: 0.742253, acc: 53.12%] [G loss: 1.906950]\n",
      "epoch:12 step:9872 [D loss: 0.600838, acc: 72.66%] [G loss: 1.922423]\n",
      "epoch:12 step:9873 [D loss: 0.372635, acc: 92.97%] [G loss: 2.404555]\n",
      "epoch:12 step:9874 [D loss: 0.530106, acc: 66.41%] [G loss: 3.269498]\n",
      "epoch:12 step:9875 [D loss: 0.637066, acc: 57.03%] [G loss: 2.459077]\n",
      "epoch:12 step:9876 [D loss: 0.768725, acc: 48.44%] [G loss: 1.765164]\n",
      "epoch:12 step:9877 [D loss: 0.353468, acc: 91.41%] [G loss: 2.401271]\n",
      "epoch:12 step:9878 [D loss: 0.779315, acc: 47.66%] [G loss: 2.006866]\n",
      "epoch:12 step:9879 [D loss: 0.571666, acc: 73.44%] [G loss: 2.529209]\n",
      "epoch:12 step:9880 [D loss: 0.501983, acc: 71.88%] [G loss: 2.900486]\n",
      "epoch:12 step:9881 [D loss: 0.443751, acc: 86.72%] [G loss: 3.081316]\n",
      "epoch:12 step:9882 [D loss: 0.338677, acc: 89.06%] [G loss: 4.609831]\n",
      "epoch:12 step:9883 [D loss: 0.607502, acc: 67.19%] [G loss: 3.326867]\n",
      "epoch:12 step:9884 [D loss: 0.448593, acc: 89.06%] [G loss: 2.794728]\n",
      "epoch:12 step:9885 [D loss: 0.677002, acc: 57.81%] [G loss: 2.328506]\n",
      "epoch:12 step:9886 [D loss: 0.566929, acc: 61.72%] [G loss: 2.754397]\n",
      "epoch:12 step:9887 [D loss: 0.751159, acc: 50.78%] [G loss: 2.019015]\n",
      "epoch:12 step:9888 [D loss: 0.368783, acc: 93.75%] [G loss: 2.137980]\n",
      "epoch:12 step:9889 [D loss: 0.392420, acc: 86.72%] [G loss: 3.362188]\n",
      "epoch:12 step:9890 [D loss: 0.499874, acc: 82.03%] [G loss: 2.611350]\n",
      "epoch:12 step:9891 [D loss: 0.914150, acc: 25.78%] [G loss: 2.541612]\n",
      "epoch:12 step:9892 [D loss: 0.528691, acc: 75.00%] [G loss: 2.287245]\n",
      "epoch:12 step:9893 [D loss: 0.536320, acc: 79.69%] [G loss: 2.089860]\n",
      "epoch:12 step:9894 [D loss: 0.758554, acc: 53.91%] [G loss: 3.311390]\n",
      "epoch:12 step:9895 [D loss: 0.467095, acc: 83.59%] [G loss: 1.961752]\n",
      "epoch:12 step:9896 [D loss: 0.801364, acc: 41.41%] [G loss: 2.184962]\n",
      "epoch:12 step:9897 [D loss: 0.564674, acc: 70.31%] [G loss: 2.183185]\n",
      "epoch:12 step:9898 [D loss: 0.810616, acc: 41.41%] [G loss: 1.972229]\n",
      "epoch:12 step:9899 [D loss: 0.395168, acc: 91.41%] [G loss: 1.982389]\n",
      "epoch:12 step:9900 [D loss: 0.568031, acc: 77.34%] [G loss: 2.077824]\n",
      "epoch:12 step:9901 [D loss: 0.594716, acc: 72.66%] [G loss: 1.932928]\n",
      "epoch:12 step:9902 [D loss: 0.706553, acc: 56.25%] [G loss: 2.261810]\n",
      "epoch:12 step:9903 [D loss: 0.676668, acc: 52.34%] [G loss: 2.034495]\n",
      "epoch:12 step:9904 [D loss: 1.107895, acc: 38.28%] [G loss: 2.140010]\n",
      "epoch:12 step:9905 [D loss: 0.806337, acc: 46.09%] [G loss: 2.259571]\n",
      "epoch:12 step:9906 [D loss: 0.520033, acc: 77.34%] [G loss: 2.169923]\n",
      "epoch:12 step:9907 [D loss: 0.610344, acc: 66.41%] [G loss: 2.022713]\n",
      "epoch:12 step:9908 [D loss: 0.730475, acc: 50.78%] [G loss: 2.191075]\n",
      "epoch:12 step:9909 [D loss: 0.307284, acc: 95.31%] [G loss: 2.836429]\n",
      "epoch:12 step:9910 [D loss: 0.700201, acc: 57.03%] [G loss: 2.085794]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9911 [D loss: 0.587674, acc: 73.44%] [G loss: 2.107412]\n",
      "epoch:12 step:9912 [D loss: 0.744970, acc: 57.03%] [G loss: 1.767590]\n",
      "epoch:12 step:9913 [D loss: 0.324423, acc: 96.09%] [G loss: 2.457872]\n",
      "epoch:12 step:9914 [D loss: 0.743443, acc: 50.78%] [G loss: 1.972972]\n",
      "epoch:12 step:9915 [D loss: 0.472485, acc: 83.59%] [G loss: 2.504086]\n",
      "epoch:12 step:9916 [D loss: 0.478955, acc: 72.66%] [G loss: 1.748402]\n",
      "epoch:12 step:9917 [D loss: 0.378084, acc: 90.62%] [G loss: 2.152954]\n",
      "epoch:12 step:9918 [D loss: 0.557327, acc: 74.22%] [G loss: 2.113470]\n",
      "epoch:12 step:9919 [D loss: 0.391543, acc: 90.62%] [G loss: 2.252147]\n",
      "epoch:12 step:9920 [D loss: 0.779472, acc: 52.34%] [G loss: 1.885884]\n",
      "epoch:12 step:9921 [D loss: 0.729397, acc: 53.12%] [G loss: 2.424645]\n",
      "epoch:12 step:9922 [D loss: 0.597129, acc: 62.50%] [G loss: 2.340762]\n",
      "epoch:12 step:9923 [D loss: 0.357334, acc: 87.50%] [G loss: 2.105814]\n",
      "epoch:12 step:9924 [D loss: 0.578264, acc: 64.06%] [G loss: 2.259949]\n",
      "epoch:12 step:9925 [D loss: 0.849347, acc: 41.41%] [G loss: 1.748240]\n",
      "epoch:12 step:9926 [D loss: 0.798616, acc: 48.44%] [G loss: 1.784987]\n",
      "epoch:12 step:9927 [D loss: 0.384195, acc: 92.97%] [G loss: 2.220514]\n",
      "epoch:12 step:9928 [D loss: 0.558649, acc: 76.56%] [G loss: 1.913012]\n",
      "epoch:12 step:9929 [D loss: 0.566835, acc: 67.19%] [G loss: 2.602856]\n",
      "epoch:12 step:9930 [D loss: 0.602320, acc: 67.19%] [G loss: 2.312393]\n",
      "epoch:12 step:9931 [D loss: 0.278474, acc: 99.22%] [G loss: 3.017588]\n",
      "epoch:12 step:9932 [D loss: 0.495297, acc: 82.81%] [G loss: 2.976445]\n",
      "epoch:12 step:9933 [D loss: 0.514701, acc: 80.47%] [G loss: 2.680208]\n",
      "epoch:12 step:9934 [D loss: 0.953526, acc: 36.72%] [G loss: 2.540203]\n",
      "epoch:12 step:9935 [D loss: 0.977784, acc: 27.34%] [G loss: 2.581528]\n",
      "epoch:12 step:9936 [D loss: 0.562372, acc: 72.66%] [G loss: 1.807332]\n",
      "epoch:12 step:9937 [D loss: 0.635415, acc: 62.50%] [G loss: 2.416276]\n",
      "epoch:12 step:9938 [D loss: 0.433822, acc: 84.38%] [G loss: 2.822793]\n",
      "epoch:12 step:9939 [D loss: 0.423023, acc: 85.16%] [G loss: 2.421695]\n",
      "epoch:12 step:9940 [D loss: 0.689213, acc: 54.69%] [G loss: 2.045545]\n",
      "epoch:12 step:9941 [D loss: 0.631063, acc: 62.50%] [G loss: 1.959061]\n",
      "epoch:12 step:9942 [D loss: 0.414033, acc: 85.16%] [G loss: 2.493596]\n",
      "epoch:12 step:9943 [D loss: 0.552576, acc: 75.00%] [G loss: 2.526990]\n",
      "epoch:12 step:9944 [D loss: 0.810316, acc: 43.75%] [G loss: 2.233140]\n",
      "epoch:12 step:9945 [D loss: 0.560560, acc: 68.75%] [G loss: 1.849288]\n",
      "epoch:12 step:9946 [D loss: 0.438184, acc: 80.47%] [G loss: 2.733119]\n",
      "epoch:12 step:9947 [D loss: 0.709894, acc: 54.69%] [G loss: 2.422240]\n",
      "epoch:12 step:9948 [D loss: 0.625039, acc: 65.62%] [G loss: 1.854064]\n",
      "epoch:12 step:9949 [D loss: 0.635282, acc: 65.62%] [G loss: 2.890314]\n",
      "epoch:12 step:9950 [D loss: 0.524410, acc: 73.44%] [G loss: 2.391555]\n",
      "epoch:12 step:9951 [D loss: 0.489514, acc: 76.56%] [G loss: 2.485826]\n",
      "epoch:12 step:9952 [D loss: 0.378842, acc: 83.59%] [G loss: 3.208089]\n",
      "epoch:12 step:9953 [D loss: 0.507336, acc: 82.03%] [G loss: 2.286295]\n",
      "epoch:12 step:9954 [D loss: 0.201526, acc: 99.22%] [G loss: 2.840864]\n",
      "epoch:12 step:9955 [D loss: 0.851867, acc: 39.06%] [G loss: 2.207994]\n",
      "epoch:12 step:9956 [D loss: 0.496948, acc: 76.56%] [G loss: 2.069165]\n",
      "epoch:12 step:9957 [D loss: 0.344248, acc: 82.81%] [G loss: 2.064762]\n",
      "epoch:12 step:9958 [D loss: 0.632834, acc: 61.72%] [G loss: 1.958565]\n",
      "epoch:12 step:9959 [D loss: 0.611931, acc: 59.38%] [G loss: 2.640166]\n",
      "epoch:12 step:9960 [D loss: 0.713364, acc: 50.00%] [G loss: 1.934160]\n",
      "epoch:12 step:9961 [D loss: 0.976171, acc: 49.22%] [G loss: 2.056358]\n",
      "epoch:12 step:9962 [D loss: 0.498000, acc: 82.81%] [G loss: 3.206086]\n",
      "epoch:12 step:9963 [D loss: 0.749692, acc: 50.00%] [G loss: 1.604368]\n",
      "epoch:12 step:9964 [D loss: 0.591923, acc: 64.06%] [G loss: 2.343431]\n",
      "epoch:12 step:9965 [D loss: 1.647810, acc: 3.91%] [G loss: 1.482355]\n",
      "epoch:12 step:9966 [D loss: 0.661708, acc: 54.69%] [G loss: 1.798985]\n",
      "epoch:12 step:9967 [D loss: 0.350943, acc: 85.94%] [G loss: 2.240661]\n",
      "epoch:12 step:9968 [D loss: 0.766841, acc: 53.91%] [G loss: 2.381423]\n",
      "epoch:12 step:9969 [D loss: 0.459766, acc: 84.38%] [G loss: 2.163170]\n",
      "epoch:12 step:9970 [D loss: 0.643049, acc: 60.94%] [G loss: 2.276668]\n",
      "epoch:12 step:9971 [D loss: 0.361612, acc: 90.62%] [G loss: 2.552271]\n",
      "epoch:12 step:9972 [D loss: 0.333242, acc: 81.25%] [G loss: 2.370994]\n",
      "epoch:12 step:9973 [D loss: 0.784767, acc: 54.69%] [G loss: 2.510916]\n",
      "epoch:12 step:9974 [D loss: 0.473510, acc: 82.03%] [G loss: 1.975390]\n",
      "epoch:12 step:9975 [D loss: 0.240831, acc: 99.22%] [G loss: 2.567335]\n",
      "epoch:12 step:9976 [D loss: 0.718529, acc: 59.38%] [G loss: 1.895132]\n",
      "epoch:12 step:9977 [D loss: 0.875451, acc: 53.12%] [G loss: 1.914251]\n",
      "epoch:12 step:9978 [D loss: 0.365574, acc: 95.31%] [G loss: 2.023687]\n",
      "epoch:12 step:9979 [D loss: 1.141816, acc: 17.97%] [G loss: 1.644210]\n",
      "epoch:12 step:9980 [D loss: 0.594437, acc: 66.41%] [G loss: 1.887196]\n",
      "epoch:12 step:9981 [D loss: 0.922269, acc: 32.81%] [G loss: 1.910451]\n",
      "epoch:12 step:9982 [D loss: 0.581095, acc: 71.09%] [G loss: 2.181113]\n",
      "epoch:12 step:9983 [D loss: 0.770695, acc: 50.78%] [G loss: 1.997251]\n",
      "epoch:12 step:9984 [D loss: 0.637529, acc: 63.28%] [G loss: 1.873512]\n",
      "epoch:12 step:9985 [D loss: 0.699825, acc: 60.16%] [G loss: 2.325683]\n",
      "epoch:12 step:9986 [D loss: 0.418353, acc: 89.84%] [G loss: 2.312067]\n",
      "epoch:12 step:9987 [D loss: 0.611892, acc: 60.16%] [G loss: 2.347291]\n",
      "epoch:12 step:9988 [D loss: 0.899200, acc: 29.69%] [G loss: 1.621329]\n",
      "epoch:12 step:9989 [D loss: 0.736826, acc: 50.78%] [G loss: 1.994272]\n",
      "epoch:12 step:9990 [D loss: 0.466863, acc: 84.38%] [G loss: 2.537405]\n",
      "epoch:12 step:9991 [D loss: 0.822836, acc: 40.62%] [G loss: 1.816471]\n",
      "epoch:12 step:9992 [D loss: 0.432964, acc: 80.47%] [G loss: 2.459298]\n",
      "epoch:12 step:9993 [D loss: 0.836235, acc: 39.84%] [G loss: 1.957235]\n",
      "epoch:12 step:9994 [D loss: 0.348980, acc: 89.06%] [G loss: 2.105850]\n",
      "epoch:12 step:9995 [D loss: 0.722803, acc: 55.47%] [G loss: 1.988556]\n",
      "epoch:12 step:9996 [D loss: 0.653347, acc: 60.94%] [G loss: 2.905474]\n",
      "epoch:12 step:9997 [D loss: 0.550593, acc: 74.22%] [G loss: 2.424840]\n",
      "epoch:12 step:9998 [D loss: 0.714964, acc: 53.12%] [G loss: 2.184285]\n",
      "epoch:12 step:9999 [D loss: 0.584307, acc: 74.22%] [G loss: 1.898412]\n",
      "epoch:12 step:10000 [D loss: 0.539015, acc: 77.34%] [G loss: 2.140044]\n",
      "epoch:12 step:10001 [D loss: 0.498325, acc: 81.25%] [G loss: 2.694788]\n",
      "epoch:12 step:10002 [D loss: 0.597097, acc: 72.66%] [G loss: 2.215086]\n",
      "epoch:12 step:10003 [D loss: 0.317690, acc: 93.75%] [G loss: 2.241534]\n",
      "epoch:12 step:10004 [D loss: 0.831641, acc: 39.84%] [G loss: 1.718673]\n",
      "epoch:12 step:10005 [D loss: 0.797488, acc: 48.44%] [G loss: 2.250176]\n",
      "epoch:12 step:10006 [D loss: 0.601209, acc: 67.97%] [G loss: 2.165161]\n",
      "epoch:12 step:10007 [D loss: 0.583849, acc: 68.75%] [G loss: 2.209472]\n",
      "epoch:12 step:10008 [D loss: 0.503397, acc: 78.12%] [G loss: 2.330187]\n",
      "epoch:12 step:10009 [D loss: 0.829904, acc: 34.38%] [G loss: 1.766416]\n",
      "epoch:12 step:10010 [D loss: 0.724160, acc: 53.91%] [G loss: 1.347129]\n",
      "epoch:12 step:10011 [D loss: 0.869947, acc: 31.25%] [G loss: 2.339718]\n",
      "epoch:12 step:10012 [D loss: 0.719615, acc: 50.78%] [G loss: 2.094314]\n",
      "epoch:12 step:10013 [D loss: 0.623090, acc: 64.84%] [G loss: 2.002326]\n",
      "epoch:12 step:10014 [D loss: 0.509148, acc: 79.69%] [G loss: 2.158241]\n",
      "epoch:12 step:10015 [D loss: 0.510861, acc: 70.31%] [G loss: 2.066748]\n",
      "epoch:12 step:10016 [D loss: 0.588150, acc: 71.88%] [G loss: 2.531446]\n",
      "epoch:12 step:10017 [D loss: 1.333222, acc: 15.62%] [G loss: 1.270768]\n",
      "epoch:12 step:10018 [D loss: 0.615618, acc: 62.50%] [G loss: 2.430992]\n",
      "epoch:12 step:10019 [D loss: 0.635741, acc: 57.81%] [G loss: 1.780126]\n",
      "epoch:12 step:10020 [D loss: 0.683449, acc: 56.25%] [G loss: 1.987134]\n",
      "epoch:12 step:10021 [D loss: 0.707349, acc: 52.34%] [G loss: 2.194507]\n",
      "epoch:12 step:10022 [D loss: 0.522402, acc: 82.81%] [G loss: 1.845727]\n",
      "epoch:12 step:10023 [D loss: 0.423573, acc: 85.16%] [G loss: 2.429943]\n",
      "epoch:12 step:10024 [D loss: 0.467886, acc: 84.38%] [G loss: 1.933277]\n",
      "epoch:12 step:10025 [D loss: 0.706110, acc: 55.47%] [G loss: 2.285079]\n",
      "epoch:12 step:10026 [D loss: 0.472610, acc: 85.16%] [G loss: 2.520016]\n",
      "epoch:12 step:10027 [D loss: 0.692788, acc: 55.47%] [G loss: 1.901874]\n",
      "epoch:12 step:10028 [D loss: 1.028548, acc: 47.66%] [G loss: 1.460172]\n",
      "epoch:12 step:10029 [D loss: 0.826220, acc: 50.78%] [G loss: 2.052068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:10030 [D loss: 0.739249, acc: 56.25%] [G loss: 1.822630]\n",
      "epoch:12 step:10031 [D loss: 0.492868, acc: 84.38%] [G loss: 2.011477]\n",
      "epoch:12 step:10032 [D loss: 0.828978, acc: 39.06%] [G loss: 1.731546]\n",
      "epoch:12 step:10033 [D loss: 0.648878, acc: 67.19%] [G loss: 1.999428]\n",
      "epoch:12 step:10034 [D loss: 0.583122, acc: 71.88%] [G loss: 1.998524]\n",
      "epoch:12 step:10035 [D loss: 0.652408, acc: 61.72%] [G loss: 1.848873]\n",
      "epoch:12 step:10036 [D loss: 0.523679, acc: 76.56%] [G loss: 2.155502]\n",
      "epoch:12 step:10037 [D loss: 0.710497, acc: 54.69%] [G loss: 1.990525]\n",
      "epoch:12 step:10038 [D loss: 0.597950, acc: 64.06%] [G loss: 1.763441]\n",
      "epoch:12 step:10039 [D loss: 0.482333, acc: 78.12%] [G loss: 1.906943]\n",
      "epoch:12 step:10040 [D loss: 0.586619, acc: 71.88%] [G loss: 1.811628]\n",
      "epoch:12 step:10041 [D loss: 0.687658, acc: 56.25%] [G loss: 1.979136]\n",
      "epoch:12 step:10042 [D loss: 0.669536, acc: 53.12%] [G loss: 1.249675]\n",
      "epoch:12 step:10043 [D loss: 0.499358, acc: 76.56%] [G loss: 2.007120]\n",
      "epoch:12 step:10044 [D loss: 0.730527, acc: 52.34%] [G loss: 1.935095]\n",
      "epoch:12 step:10045 [D loss: 0.703096, acc: 51.56%] [G loss: 1.764448]\n",
      "epoch:12 step:10046 [D loss: 0.542751, acc: 74.22%] [G loss: 1.637927]\n",
      "epoch:12 step:10047 [D loss: 0.473348, acc: 86.72%] [G loss: 2.011377]\n",
      "epoch:12 step:10048 [D loss: 0.888734, acc: 28.91%] [G loss: 1.683938]\n",
      "epoch:12 step:10049 [D loss: 0.832659, acc: 35.94%] [G loss: 1.814378]\n",
      "epoch:12 step:10050 [D loss: 0.730909, acc: 52.34%] [G loss: 1.750216]\n",
      "epoch:12 step:10051 [D loss: 0.659120, acc: 57.81%] [G loss: 1.887853]\n",
      "epoch:12 step:10052 [D loss: 0.471699, acc: 67.19%] [G loss: 2.018183]\n",
      "epoch:12 step:10053 [D loss: 0.614593, acc: 71.09%] [G loss: 1.840399]\n",
      "epoch:12 step:10054 [D loss: 0.966353, acc: 25.00%] [G loss: 1.613829]\n",
      "epoch:12 step:10055 [D loss: 0.685607, acc: 58.59%] [G loss: 1.822760]\n",
      "epoch:12 step:10056 [D loss: 0.637172, acc: 61.72%] [G loss: 1.903929]\n",
      "epoch:12 step:10057 [D loss: 0.524019, acc: 76.56%] [G loss: 2.170592]\n",
      "epoch:12 step:10058 [D loss: 0.755591, acc: 48.44%] [G loss: 1.796070]\n",
      "epoch:12 step:10059 [D loss: 0.409218, acc: 90.62%] [G loss: 2.455335]\n",
      "epoch:12 step:10060 [D loss: 0.622257, acc: 63.28%] [G loss: 1.973815]\n",
      "epoch:12 step:10061 [D loss: 0.538702, acc: 75.78%] [G loss: 2.695750]\n",
      "epoch:12 step:10062 [D loss: 0.569623, acc: 70.31%] [G loss: 1.794096]\n",
      "epoch:12 step:10063 [D loss: 0.546694, acc: 74.22%] [G loss: 2.195539]\n",
      "epoch:12 step:10064 [D loss: 0.714703, acc: 53.91%] [G loss: 1.727978]\n",
      "epoch:12 step:10065 [D loss: 0.676766, acc: 57.03%] [G loss: 1.743055]\n",
      "epoch:12 step:10066 [D loss: 0.724512, acc: 50.78%] [G loss: 1.762306]\n",
      "epoch:12 step:10067 [D loss: 0.478493, acc: 82.81%] [G loss: 2.128226]\n",
      "epoch:12 step:10068 [D loss: 0.588443, acc: 71.09%] [G loss: 1.975318]\n",
      "epoch:12 step:10069 [D loss: 0.817000, acc: 39.06%] [G loss: 1.651293]\n",
      "epoch:12 step:10070 [D loss: 0.673557, acc: 56.25%] [G loss: 1.855393]\n",
      "epoch:12 step:10071 [D loss: 0.656567, acc: 60.16%] [G loss: 2.185013]\n",
      "epoch:12 step:10072 [D loss: 0.553482, acc: 71.09%] [G loss: 2.291446]\n",
      "epoch:12 step:10073 [D loss: 0.519506, acc: 78.12%] [G loss: 2.272665]\n",
      "epoch:12 step:10074 [D loss: 0.715245, acc: 55.47%] [G loss: 1.999137]\n",
      "epoch:12 step:10075 [D loss: 0.504183, acc: 80.47%] [G loss: 2.113723]\n",
      "epoch:12 step:10076 [D loss: 0.784848, acc: 44.53%] [G loss: 2.035624]\n",
      "epoch:12 step:10077 [D loss: 0.708587, acc: 54.69%] [G loss: 2.202230]\n",
      "epoch:12 step:10078 [D loss: 0.662040, acc: 66.41%] [G loss: 1.914715]\n",
      "epoch:12 step:10079 [D loss: 0.493860, acc: 84.38%] [G loss: 1.912520]\n",
      "epoch:12 step:10080 [D loss: 0.571341, acc: 68.75%] [G loss: 2.226650]\n",
      "epoch:12 step:10081 [D loss: 0.650081, acc: 59.38%] [G loss: 1.948225]\n",
      "epoch:12 step:10082 [D loss: 0.469152, acc: 83.59%] [G loss: 1.862966]\n",
      "epoch:12 step:10083 [D loss: 0.732492, acc: 55.47%] [G loss: 2.118379]\n",
      "epoch:12 step:10084 [D loss: 0.560271, acc: 74.22%] [G loss: 2.077633]\n",
      "epoch:12 step:10085 [D loss: 0.391496, acc: 91.41%] [G loss: 2.316480]\n",
      "epoch:12 step:10086 [D loss: 0.749455, acc: 48.44%] [G loss: 2.286755]\n",
      "epoch:12 step:10087 [D loss: 0.574841, acc: 71.88%] [G loss: 2.010989]\n",
      "epoch:12 step:10088 [D loss: 0.584855, acc: 72.66%] [G loss: 1.996794]\n",
      "epoch:12 step:10089 [D loss: 0.763803, acc: 40.62%] [G loss: 2.108658]\n",
      "epoch:12 step:10090 [D loss: 0.722013, acc: 53.91%] [G loss: 2.153557]\n",
      "epoch:12 step:10091 [D loss: 0.436096, acc: 87.50%] [G loss: 2.049387]\n",
      "epoch:12 step:10092 [D loss: 0.451581, acc: 71.09%] [G loss: 2.200841]\n",
      "epoch:12 step:10093 [D loss: 1.103194, acc: 17.19%] [G loss: 1.492927]\n",
      "epoch:12 step:10094 [D loss: 0.694077, acc: 58.59%] [G loss: 2.362394]\n",
      "epoch:12 step:10095 [D loss: 0.731480, acc: 53.91%] [G loss: 1.713361]\n",
      "epoch:12 step:10096 [D loss: 0.749379, acc: 49.22%] [G loss: 1.701647]\n",
      "epoch:12 step:10097 [D loss: 0.765364, acc: 43.75%] [G loss: 1.978790]\n",
      "epoch:12 step:10098 [D loss: 0.737819, acc: 46.09%] [G loss: 1.681401]\n",
      "epoch:12 step:10099 [D loss: 0.706649, acc: 51.56%] [G loss: 1.844105]\n",
      "epoch:12 step:10100 [D loss: 0.799252, acc: 46.88%] [G loss: 1.925633]\n",
      "epoch:12 step:10101 [D loss: 0.676757, acc: 57.81%] [G loss: 1.863810]\n",
      "epoch:12 step:10102 [D loss: 0.684740, acc: 55.47%] [G loss: 1.699166]\n",
      "epoch:12 step:10103 [D loss: 0.417631, acc: 89.06%] [G loss: 2.070298]\n",
      "epoch:12 step:10104 [D loss: 0.544886, acc: 78.12%] [G loss: 2.151051]\n",
      "epoch:12 step:10105 [D loss: 0.647895, acc: 63.28%] [G loss: 1.885447]\n",
      "epoch:12 step:10106 [D loss: 0.635799, acc: 62.50%] [G loss: 2.011049]\n",
      "epoch:12 step:10107 [D loss: 0.633824, acc: 67.97%] [G loss: 2.487109]\n",
      "epoch:12 step:10108 [D loss: 0.596928, acc: 65.62%] [G loss: 1.975527]\n",
      "epoch:12 step:10109 [D loss: 0.440966, acc: 88.28%] [G loss: 2.165992]\n",
      "epoch:12 step:10110 [D loss: 0.677990, acc: 60.94%] [G loss: 1.892090]\n",
      "epoch:12 step:10111 [D loss: 0.444955, acc: 84.38%] [G loss: 2.291032]\n",
      "epoch:12 step:10112 [D loss: 0.934357, acc: 24.22%] [G loss: 1.735500]\n",
      "epoch:12 step:10113 [D loss: 0.496768, acc: 82.03%] [G loss: 1.879827]\n",
      "epoch:12 step:10114 [D loss: 0.689881, acc: 57.81%] [G loss: 1.941862]\n",
      "epoch:12 step:10115 [D loss: 0.511102, acc: 78.91%] [G loss: 2.323618]\n",
      "epoch:12 step:10116 [D loss: 0.628395, acc: 64.06%] [G loss: 2.003758]\n",
      "epoch:12 step:10117 [D loss: 0.692767, acc: 53.91%] [G loss: 1.851331]\n",
      "epoch:12 step:10118 [D loss: 0.498658, acc: 85.16%] [G loss: 2.125780]\n",
      "epoch:12 step:10119 [D loss: 0.780204, acc: 38.28%] [G loss: 2.035102]\n",
      "epoch:12 step:10120 [D loss: 0.559196, acc: 71.88%] [G loss: 2.094981]\n",
      "epoch:12 step:10121 [D loss: 0.677680, acc: 60.16%] [G loss: 2.088652]\n",
      "epoch:12 step:10122 [D loss: 0.630308, acc: 67.97%] [G loss: 1.699173]\n",
      "epoch:12 step:10123 [D loss: 0.809298, acc: 39.84%] [G loss: 2.045325]\n",
      "epoch:12 step:10124 [D loss: 0.741503, acc: 50.00%] [G loss: 1.872051]\n",
      "epoch:12 step:10125 [D loss: 0.568364, acc: 75.78%] [G loss: 2.340599]\n",
      "epoch:12 step:10126 [D loss: 0.638481, acc: 67.97%] [G loss: 1.987115]\n",
      "epoch:12 step:10127 [D loss: 0.809155, acc: 39.06%] [G loss: 1.767521]\n",
      "epoch:12 step:10128 [D loss: 0.391274, acc: 77.34%] [G loss: 2.133332]\n",
      "epoch:12 step:10129 [D loss: 0.498072, acc: 85.16%] [G loss: 1.972470]\n",
      "epoch:12 step:10130 [D loss: 0.622697, acc: 63.28%] [G loss: 1.728036]\n",
      "epoch:12 step:10131 [D loss: 0.611740, acc: 67.97%] [G loss: 2.020654]\n",
      "epoch:12 step:10132 [D loss: 0.306529, acc: 96.88%] [G loss: 2.179874]\n",
      "epoch:12 step:10133 [D loss: 0.334515, acc: 91.41%] [G loss: 2.001056]\n",
      "epoch:12 step:10134 [D loss: 0.373784, acc: 84.38%] [G loss: 2.737334]\n",
      "epoch:12 step:10135 [D loss: 0.853094, acc: 49.22%] [G loss: 1.987659]\n",
      "epoch:12 step:10136 [D loss: 0.466237, acc: 84.38%] [G loss: 2.338337]\n",
      "epoch:12 step:10137 [D loss: 0.918862, acc: 25.00%] [G loss: 1.929512]\n",
      "epoch:12 step:10138 [D loss: 0.503018, acc: 80.47%] [G loss: 1.941645]\n",
      "epoch:12 step:10139 [D loss: 0.659921, acc: 63.28%] [G loss: 1.874373]\n",
      "epoch:12 step:10140 [D loss: 0.588888, acc: 71.09%] [G loss: 2.081692]\n",
      "epoch:12 step:10141 [D loss: 0.774361, acc: 39.06%] [G loss: 1.866110]\n",
      "epoch:12 step:10142 [D loss: 0.528822, acc: 79.69%] [G loss: 2.451060]\n",
      "epoch:12 step:10143 [D loss: 1.062014, acc: 32.03%] [G loss: 2.182199]\n",
      "epoch:12 step:10144 [D loss: 0.689524, acc: 51.56%] [G loss: 1.924275]\n",
      "epoch:12 step:10145 [D loss: 0.589204, acc: 73.44%] [G loss: 1.949895]\n",
      "epoch:12 step:10146 [D loss: 0.603952, acc: 69.53%] [G loss: 2.632592]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:10147 [D loss: 0.575195, acc: 71.88%] [G loss: 1.701404]\n",
      "epoch:12 step:10148 [D loss: 0.606983, acc: 67.97%] [G loss: 2.364890]\n",
      "epoch:12 step:10149 [D loss: 0.872789, acc: 28.12%] [G loss: 1.789463]\n",
      "epoch:12 step:10150 [D loss: 0.630908, acc: 61.72%] [G loss: 1.745665]\n",
      "epoch:12 step:10151 [D loss: 0.764038, acc: 47.66%] [G loss: 1.915133]\n",
      "epoch:12 step:10152 [D loss: 0.822122, acc: 30.47%] [G loss: 1.388637]\n",
      "epoch:12 step:10153 [D loss: 0.557097, acc: 69.53%] [G loss: 1.690999]\n",
      "epoch:13 step:10154 [D loss: 0.676202, acc: 57.03%] [G loss: 1.651968]\n",
      "epoch:13 step:10155 [D loss: 0.563432, acc: 71.09%] [G loss: 2.029301]\n",
      "epoch:13 step:10156 [D loss: 0.496861, acc: 82.03%] [G loss: 1.943979]\n",
      "epoch:13 step:10157 [D loss: 0.884643, acc: 30.47%] [G loss: 1.585751]\n",
      "epoch:13 step:10158 [D loss: 0.416404, acc: 89.84%] [G loss: 2.535637]\n",
      "epoch:13 step:10159 [D loss: 0.564628, acc: 72.66%] [G loss: 1.994160]\n",
      "epoch:13 step:10160 [D loss: 0.642645, acc: 68.75%] [G loss: 1.823716]\n",
      "epoch:13 step:10161 [D loss: 0.728281, acc: 44.53%] [G loss: 1.539817]\n",
      "epoch:13 step:10162 [D loss: 0.591362, acc: 70.31%] [G loss: 2.146457]\n",
      "epoch:13 step:10163 [D loss: 0.564059, acc: 75.78%] [G loss: 2.388389]\n",
      "epoch:13 step:10164 [D loss: 0.849106, acc: 36.72%] [G loss: 1.801518]\n",
      "epoch:13 step:10165 [D loss: 0.537804, acc: 76.56%] [G loss: 2.140012]\n",
      "epoch:13 step:10166 [D loss: 0.603951, acc: 70.31%] [G loss: 1.920118]\n",
      "epoch:13 step:10167 [D loss: 0.682877, acc: 54.69%] [G loss: 1.789881]\n",
      "epoch:13 step:10168 [D loss: 1.286854, acc: 14.84%] [G loss: 1.495169]\n",
      "epoch:13 step:10169 [D loss: 0.792716, acc: 38.28%] [G loss: 1.480764]\n",
      "epoch:13 step:10170 [D loss: 0.456798, acc: 87.50%] [G loss: 2.173159]\n",
      "epoch:13 step:10171 [D loss: 0.585160, acc: 70.31%] [G loss: 1.910558]\n",
      "epoch:13 step:10172 [D loss: 0.682807, acc: 55.47%] [G loss: 1.548500]\n",
      "epoch:13 step:10173 [D loss: 0.565754, acc: 64.84%] [G loss: 1.688320]\n",
      "epoch:13 step:10174 [D loss: 0.656337, acc: 62.50%] [G loss: 1.811120]\n",
      "epoch:13 step:10175 [D loss: 0.563474, acc: 74.22%] [G loss: 2.414322]\n",
      "epoch:13 step:10176 [D loss: 0.499247, acc: 82.03%] [G loss: 2.216622]\n",
      "epoch:13 step:10177 [D loss: 0.730749, acc: 50.00%] [G loss: 1.911126]\n",
      "epoch:13 step:10178 [D loss: 0.575424, acc: 71.09%] [G loss: 2.190055]\n",
      "epoch:13 step:10179 [D loss: 0.775301, acc: 42.97%] [G loss: 2.010858]\n",
      "epoch:13 step:10180 [D loss: 0.581158, acc: 71.09%] [G loss: 2.148555]\n",
      "epoch:13 step:10181 [D loss: 0.450182, acc: 86.72%] [G loss: 1.785048]\n",
      "epoch:13 step:10182 [D loss: 0.609162, acc: 65.62%] [G loss: 1.699948]\n",
      "epoch:13 step:10183 [D loss: 0.606769, acc: 68.75%] [G loss: 2.211348]\n",
      "epoch:13 step:10184 [D loss: 0.775411, acc: 46.88%] [G loss: 1.539747]\n",
      "epoch:13 step:10185 [D loss: 0.758016, acc: 52.34%] [G loss: 2.059800]\n",
      "epoch:13 step:10186 [D loss: 0.688759, acc: 54.69%] [G loss: 1.721846]\n",
      "epoch:13 step:10187 [D loss: 0.753824, acc: 52.34%] [G loss: 2.411711]\n",
      "epoch:13 step:10188 [D loss: 0.658552, acc: 64.84%] [G loss: 2.026583]\n",
      "epoch:13 step:10189 [D loss: 0.658956, acc: 60.16%] [G loss: 1.938094]\n",
      "epoch:13 step:10190 [D loss: 0.471387, acc: 86.72%] [G loss: 1.942713]\n",
      "epoch:13 step:10191 [D loss: 0.664836, acc: 58.59%] [G loss: 2.008482]\n",
      "epoch:13 step:10192 [D loss: 0.723580, acc: 51.56%] [G loss: 1.989682]\n",
      "epoch:13 step:10193 [D loss: 0.540137, acc: 75.78%] [G loss: 1.637747]\n",
      "epoch:13 step:10194 [D loss: 0.433605, acc: 87.50%] [G loss: 2.480939]\n",
      "epoch:13 step:10195 [D loss: 0.561873, acc: 69.53%] [G loss: 1.646620]\n",
      "epoch:13 step:10196 [D loss: 0.604208, acc: 70.31%] [G loss: 2.201918]\n",
      "epoch:13 step:10197 [D loss: 0.672797, acc: 60.16%] [G loss: 1.793210]\n",
      "epoch:13 step:10198 [D loss: 0.942202, acc: 25.00%] [G loss: 1.562422]\n",
      "epoch:13 step:10199 [D loss: 0.501356, acc: 83.59%] [G loss: 2.346294]\n",
      "epoch:13 step:10200 [D loss: 0.494639, acc: 83.59%] [G loss: 2.079685]\n",
      "epoch:13 step:10201 [D loss: 0.834951, acc: 35.16%] [G loss: 1.927503]\n",
      "epoch:13 step:10202 [D loss: 0.741446, acc: 49.22%] [G loss: 1.744981]\n",
      "epoch:13 step:10203 [D loss: 0.639709, acc: 58.59%] [G loss: 1.841085]\n",
      "epoch:13 step:10204 [D loss: 0.710875, acc: 53.91%] [G loss: 2.032007]\n",
      "epoch:13 step:10205 [D loss: 0.513889, acc: 79.69%] [G loss: 2.281524]\n",
      "epoch:13 step:10206 [D loss: 0.779532, acc: 40.62%] [G loss: 1.844040]\n",
      "epoch:13 step:10207 [D loss: 0.773161, acc: 49.22%] [G loss: 1.558126]\n",
      "epoch:13 step:10208 [D loss: 0.736399, acc: 46.09%] [G loss: 2.123034]\n",
      "epoch:13 step:10209 [D loss: 0.703999, acc: 52.34%] [G loss: 1.921280]\n",
      "epoch:13 step:10210 [D loss: 0.716097, acc: 46.88%] [G loss: 1.869465]\n",
      "epoch:13 step:10211 [D loss: 0.765517, acc: 47.66%] [G loss: 1.727669]\n",
      "epoch:13 step:10212 [D loss: 0.530281, acc: 80.47%] [G loss: 2.381634]\n",
      "epoch:13 step:10213 [D loss: 0.528717, acc: 80.47%] [G loss: 2.125719]\n",
      "epoch:13 step:10214 [D loss: 0.696203, acc: 53.91%] [G loss: 1.887570]\n",
      "epoch:13 step:10215 [D loss: 0.736340, acc: 51.56%] [G loss: 1.896241]\n",
      "epoch:13 step:10216 [D loss: 0.683475, acc: 63.28%] [G loss: 2.272408]\n",
      "epoch:13 step:10217 [D loss: 0.638464, acc: 64.06%] [G loss: 2.528180]\n",
      "epoch:13 step:10218 [D loss: 0.862782, acc: 27.34%] [G loss: 1.740773]\n",
      "epoch:13 step:10219 [D loss: 0.533843, acc: 67.19%] [G loss: 2.629404]\n",
      "epoch:13 step:10220 [D loss: 0.872652, acc: 30.47%] [G loss: 1.473259]\n",
      "epoch:13 step:10221 [D loss: 0.785707, acc: 49.22%] [G loss: 1.553673]\n",
      "epoch:13 step:10222 [D loss: 0.674504, acc: 60.16%] [G loss: 1.709627]\n",
      "epoch:13 step:10223 [D loss: 0.676159, acc: 58.59%] [G loss: 1.639845]\n",
      "epoch:13 step:10224 [D loss: 0.820431, acc: 43.75%] [G loss: 1.437907]\n",
      "epoch:13 step:10225 [D loss: 1.172616, acc: 14.84%] [G loss: 1.534767]\n",
      "epoch:13 step:10226 [D loss: 0.498750, acc: 82.81%] [G loss: 1.727587]\n",
      "epoch:13 step:10227 [D loss: 0.720332, acc: 46.09%] [G loss: 1.735991]\n",
      "epoch:13 step:10228 [D loss: 0.550256, acc: 72.66%] [G loss: 1.969379]\n",
      "epoch:13 step:10229 [D loss: 0.608955, acc: 64.84%] [G loss: 2.225244]\n",
      "epoch:13 step:10230 [D loss: 0.710520, acc: 51.56%] [G loss: 1.613438]\n",
      "epoch:13 step:10231 [D loss: 0.771655, acc: 46.88%] [G loss: 1.660258]\n",
      "epoch:13 step:10232 [D loss: 0.565409, acc: 68.75%] [G loss: 2.000324]\n",
      "epoch:13 step:10233 [D loss: 0.403280, acc: 91.41%] [G loss: 1.971537]\n",
      "epoch:13 step:10234 [D loss: 0.643701, acc: 60.94%] [G loss: 2.654703]\n",
      "epoch:13 step:10235 [D loss: 0.557708, acc: 73.44%] [G loss: 1.805194]\n",
      "epoch:13 step:10236 [D loss: 0.489724, acc: 78.91%] [G loss: 1.938931]\n",
      "epoch:13 step:10237 [D loss: 0.831730, acc: 49.22%] [G loss: 1.352194]\n",
      "epoch:13 step:10238 [D loss: 0.639263, acc: 61.72%] [G loss: 2.117246]\n",
      "epoch:13 step:10239 [D loss: 0.783400, acc: 49.22%] [G loss: 1.939735]\n",
      "epoch:13 step:10240 [D loss: 0.541233, acc: 75.78%] [G loss: 2.068977]\n",
      "epoch:13 step:10241 [D loss: 0.890645, acc: 32.03%] [G loss: 1.827976]\n",
      "epoch:13 step:10242 [D loss: 0.513741, acc: 82.81%] [G loss: 1.882996]\n",
      "epoch:13 step:10243 [D loss: 0.563100, acc: 66.41%] [G loss: 2.279330]\n",
      "epoch:13 step:10244 [D loss: 0.637444, acc: 63.28%] [G loss: 2.038987]\n",
      "epoch:13 step:10245 [D loss: 0.776725, acc: 43.75%] [G loss: 1.781338]\n",
      "epoch:13 step:10246 [D loss: 0.420474, acc: 92.19%] [G loss: 2.196328]\n",
      "epoch:13 step:10247 [D loss: 0.867050, acc: 28.91%] [G loss: 1.947548]\n",
      "epoch:13 step:10248 [D loss: 0.650731, acc: 60.16%] [G loss: 2.270369]\n",
      "epoch:13 step:10249 [D loss: 0.496778, acc: 82.03%] [G loss: 2.264754]\n",
      "epoch:13 step:10250 [D loss: 0.776561, acc: 42.19%] [G loss: 1.639006]\n",
      "epoch:13 step:10251 [D loss: 0.682366, acc: 54.69%] [G loss: 1.810797]\n",
      "epoch:13 step:10252 [D loss: 0.555706, acc: 73.44%] [G loss: 2.292302]\n",
      "epoch:13 step:10253 [D loss: 0.678175, acc: 57.03%] [G loss: 1.879563]\n",
      "epoch:13 step:10254 [D loss: 0.778325, acc: 49.22%] [G loss: 1.672219]\n",
      "epoch:13 step:10255 [D loss: 0.601683, acc: 75.00%] [G loss: 2.129846]\n",
      "epoch:13 step:10256 [D loss: 0.610794, acc: 57.03%] [G loss: 2.515931]\n",
      "epoch:13 step:10257 [D loss: 0.911665, acc: 28.12%] [G loss: 1.550339]\n",
      "epoch:13 step:10258 [D loss: 0.680945, acc: 58.59%] [G loss: 1.846441]\n",
      "epoch:13 step:10259 [D loss: 0.608585, acc: 67.97%] [G loss: 1.635521]\n",
      "epoch:13 step:10260 [D loss: 0.764326, acc: 41.41%] [G loss: 1.826943]\n",
      "epoch:13 step:10261 [D loss: 0.668881, acc: 62.50%] [G loss: 1.757952]\n",
      "epoch:13 step:10262 [D loss: 0.552571, acc: 73.44%] [G loss: 2.292579]\n",
      "epoch:13 step:10263 [D loss: 0.696655, acc: 57.03%] [G loss: 1.904858]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10264 [D loss: 0.737348, acc: 54.69%] [G loss: 1.915641]\n",
      "epoch:13 step:10265 [D loss: 0.702659, acc: 53.91%] [G loss: 1.853100]\n",
      "epoch:13 step:10266 [D loss: 0.822970, acc: 36.72%] [G loss: 1.575398]\n",
      "epoch:13 step:10267 [D loss: 0.515126, acc: 85.94%] [G loss: 2.234837]\n",
      "epoch:13 step:10268 [D loss: 0.699769, acc: 52.34%] [G loss: 1.733797]\n",
      "epoch:13 step:10269 [D loss: 0.437187, acc: 89.84%] [G loss: 2.117707]\n",
      "epoch:13 step:10270 [D loss: 0.710075, acc: 50.00%] [G loss: 1.869288]\n",
      "epoch:13 step:10271 [D loss: 0.566112, acc: 68.75%] [G loss: 2.159662]\n",
      "epoch:13 step:10272 [D loss: 0.716585, acc: 56.25%] [G loss: 1.704696]\n",
      "epoch:13 step:10273 [D loss: 0.692289, acc: 58.59%] [G loss: 1.770396]\n",
      "epoch:13 step:10274 [D loss: 0.483362, acc: 85.16%] [G loss: 2.249227]\n",
      "epoch:13 step:10275 [D loss: 0.784599, acc: 42.19%] [G loss: 1.864951]\n",
      "epoch:13 step:10276 [D loss: 0.526973, acc: 84.38%] [G loss: 1.684806]\n",
      "epoch:13 step:10277 [D loss: 0.745758, acc: 55.47%] [G loss: 1.904842]\n",
      "epoch:13 step:10278 [D loss: 0.856777, acc: 28.91%] [G loss: 1.774405]\n",
      "epoch:13 step:10279 [D loss: 0.725586, acc: 50.00%] [G loss: 1.650289]\n",
      "epoch:13 step:10280 [D loss: 0.554226, acc: 79.69%] [G loss: 2.106964]\n",
      "epoch:13 step:10281 [D loss: 0.634062, acc: 65.62%] [G loss: 2.262940]\n",
      "epoch:13 step:10282 [D loss: 0.584491, acc: 71.09%] [G loss: 1.829381]\n",
      "epoch:13 step:10283 [D loss: 0.951401, acc: 39.06%] [G loss: 1.577838]\n",
      "epoch:13 step:10284 [D loss: 0.755797, acc: 49.22%] [G loss: 1.597216]\n",
      "epoch:13 step:10285 [D loss: 0.566455, acc: 69.53%] [G loss: 2.290871]\n",
      "epoch:13 step:10286 [D loss: 0.653942, acc: 60.16%] [G loss: 2.040570]\n",
      "epoch:13 step:10287 [D loss: 0.445180, acc: 92.19%] [G loss: 2.690324]\n",
      "epoch:13 step:10288 [D loss: 0.594837, acc: 69.53%] [G loss: 1.839046]\n",
      "epoch:13 step:10289 [D loss: 0.652503, acc: 66.41%] [G loss: 1.907645]\n",
      "epoch:13 step:10290 [D loss: 0.613033, acc: 70.31%] [G loss: 2.092887]\n",
      "epoch:13 step:10291 [D loss: 0.427226, acc: 90.62%] [G loss: 2.466426]\n",
      "epoch:13 step:10292 [D loss: 0.550604, acc: 76.56%] [G loss: 1.817910]\n",
      "epoch:13 step:10293 [D loss: 0.710400, acc: 52.34%] [G loss: 1.760010]\n",
      "epoch:13 step:10294 [D loss: 0.740750, acc: 49.22%] [G loss: 1.981901]\n",
      "epoch:13 step:10295 [D loss: 0.427601, acc: 89.06%] [G loss: 2.388047]\n",
      "epoch:13 step:10296 [D loss: 0.732267, acc: 51.56%] [G loss: 1.999090]\n",
      "epoch:13 step:10297 [D loss: 0.663378, acc: 60.94%] [G loss: 2.164752]\n",
      "epoch:13 step:10298 [D loss: 0.619205, acc: 63.28%] [G loss: 2.243269]\n",
      "epoch:13 step:10299 [D loss: 0.875948, acc: 30.47%] [G loss: 1.671687]\n",
      "epoch:13 step:10300 [D loss: 0.547009, acc: 75.00%] [G loss: 2.626254]\n",
      "epoch:13 step:10301 [D loss: 0.528873, acc: 83.59%] [G loss: 1.986317]\n",
      "epoch:13 step:10302 [D loss: 0.684859, acc: 60.94%] [G loss: 1.869108]\n",
      "epoch:13 step:10303 [D loss: 0.654544, acc: 61.72%] [G loss: 1.966465]\n",
      "epoch:13 step:10304 [D loss: 0.618844, acc: 62.50%] [G loss: 2.010347]\n",
      "epoch:13 step:10305 [D loss: 0.801490, acc: 44.53%] [G loss: 1.544208]\n",
      "epoch:13 step:10306 [D loss: 0.703944, acc: 52.34%] [G loss: 1.767496]\n",
      "epoch:13 step:10307 [D loss: 0.656755, acc: 62.50%] [G loss: 1.892896]\n",
      "epoch:13 step:10308 [D loss: 0.715227, acc: 50.78%] [G loss: 1.717307]\n",
      "epoch:13 step:10309 [D loss: 0.626665, acc: 60.94%] [G loss: 1.999555]\n",
      "epoch:13 step:10310 [D loss: 0.478676, acc: 81.25%] [G loss: 1.851908]\n",
      "epoch:13 step:10311 [D loss: 0.543752, acc: 73.44%] [G loss: 2.646776]\n",
      "epoch:13 step:10312 [D loss: 0.414410, acc: 85.16%] [G loss: 2.234013]\n",
      "epoch:13 step:10313 [D loss: 0.920941, acc: 25.78%] [G loss: 1.547315]\n",
      "epoch:13 step:10314 [D loss: 0.623133, acc: 65.62%] [G loss: 1.905413]\n",
      "epoch:13 step:10315 [D loss: 0.697451, acc: 57.81%] [G loss: 1.847126]\n",
      "epoch:13 step:10316 [D loss: 0.630556, acc: 60.94%] [G loss: 1.994126]\n",
      "epoch:13 step:10317 [D loss: 0.713164, acc: 51.56%] [G loss: 1.946815]\n",
      "epoch:13 step:10318 [D loss: 0.444957, acc: 82.03%] [G loss: 1.821705]\n",
      "epoch:13 step:10319 [D loss: 0.775112, acc: 45.31%] [G loss: 1.661378]\n",
      "epoch:13 step:10320 [D loss: 0.379538, acc: 95.31%] [G loss: 1.961924]\n",
      "epoch:13 step:10321 [D loss: 0.648046, acc: 54.69%] [G loss: 2.032511]\n",
      "epoch:13 step:10322 [D loss: 0.796920, acc: 39.84%] [G loss: 1.707226]\n",
      "epoch:13 step:10323 [D loss: 0.431102, acc: 89.06%] [G loss: 1.753645]\n",
      "epoch:13 step:10324 [D loss: 0.779170, acc: 42.97%] [G loss: 1.497849]\n",
      "epoch:13 step:10325 [D loss: 0.490265, acc: 82.81%] [G loss: 2.311105]\n",
      "epoch:13 step:10326 [D loss: 0.849255, acc: 34.38%] [G loss: 1.837848]\n",
      "epoch:13 step:10327 [D loss: 0.825648, acc: 40.62%] [G loss: 1.678506]\n",
      "epoch:13 step:10328 [D loss: 0.317074, acc: 90.62%] [G loss: 1.906371]\n",
      "epoch:13 step:10329 [D loss: 0.598445, acc: 64.84%] [G loss: 1.990367]\n",
      "epoch:13 step:10330 [D loss: 0.653182, acc: 60.94%] [G loss: 2.141153]\n",
      "epoch:13 step:10331 [D loss: 0.816403, acc: 35.94%] [G loss: 1.711940]\n",
      "epoch:13 step:10332 [D loss: 0.722462, acc: 49.22%] [G loss: 1.840539]\n",
      "epoch:13 step:10333 [D loss: 0.862374, acc: 32.81%] [G loss: 1.539512]\n",
      "epoch:13 step:10334 [D loss: 0.493042, acc: 83.59%] [G loss: 2.417154]\n",
      "epoch:13 step:10335 [D loss: 0.691450, acc: 54.69%] [G loss: 1.823995]\n",
      "epoch:13 step:10336 [D loss: 0.655261, acc: 59.38%] [G loss: 1.915831]\n",
      "epoch:13 step:10337 [D loss: 0.631276, acc: 68.75%] [G loss: 1.791369]\n",
      "epoch:13 step:10338 [D loss: 0.626488, acc: 61.72%] [G loss: 2.575327]\n",
      "epoch:13 step:10339 [D loss: 0.674480, acc: 57.03%] [G loss: 1.694158]\n",
      "epoch:13 step:10340 [D loss: 0.544121, acc: 75.78%] [G loss: 2.363490]\n",
      "epoch:13 step:10341 [D loss: 0.569459, acc: 73.44%] [G loss: 2.174883]\n",
      "epoch:13 step:10342 [D loss: 0.458012, acc: 83.59%] [G loss: 2.293568]\n",
      "epoch:13 step:10343 [D loss: 0.710724, acc: 49.22%] [G loss: 1.659324]\n",
      "epoch:13 step:10344 [D loss: 0.553100, acc: 78.91%] [G loss: 2.396639]\n",
      "epoch:13 step:10345 [D loss: 0.588038, acc: 70.31%] [G loss: 1.759482]\n",
      "epoch:13 step:10346 [D loss: 0.499629, acc: 81.25%] [G loss: 1.849197]\n",
      "epoch:13 step:10347 [D loss: 0.639605, acc: 60.94%] [G loss: 1.649298]\n",
      "epoch:13 step:10348 [D loss: 0.705330, acc: 57.81%] [G loss: 2.139633]\n",
      "epoch:13 step:10349 [D loss: 0.987601, acc: 27.34%] [G loss: 1.491755]\n",
      "epoch:13 step:10350 [D loss: 0.617892, acc: 66.41%] [G loss: 2.715242]\n",
      "epoch:13 step:10351 [D loss: 0.487080, acc: 81.25%] [G loss: 1.942884]\n",
      "epoch:13 step:10352 [D loss: 0.746647, acc: 53.91%] [G loss: 1.934141]\n",
      "epoch:13 step:10353 [D loss: 0.530369, acc: 74.22%] [G loss: 1.871915]\n",
      "epoch:13 step:10354 [D loss: 0.649019, acc: 56.25%] [G loss: 1.956636]\n",
      "epoch:13 step:10355 [D loss: 1.057338, acc: 23.44%] [G loss: 1.448654]\n",
      "epoch:13 step:10356 [D loss: 0.562058, acc: 81.25%] [G loss: 2.432963]\n",
      "epoch:13 step:10357 [D loss: 0.578336, acc: 69.53%] [G loss: 2.372070]\n",
      "epoch:13 step:10358 [D loss: 0.678807, acc: 61.72%] [G loss: 1.845811]\n",
      "epoch:13 step:10359 [D loss: 0.908112, acc: 30.47%] [G loss: 1.822850]\n",
      "epoch:13 step:10360 [D loss: 0.730193, acc: 53.91%] [G loss: 1.758665]\n",
      "epoch:13 step:10361 [D loss: 0.633263, acc: 60.94%] [G loss: 1.980217]\n",
      "epoch:13 step:10362 [D loss: 0.648742, acc: 67.97%] [G loss: 1.675412]\n",
      "epoch:13 step:10363 [D loss: 0.529582, acc: 78.91%] [G loss: 2.028817]\n",
      "epoch:13 step:10364 [D loss: 0.785819, acc: 38.28%] [G loss: 1.719411]\n",
      "epoch:13 step:10365 [D loss: 0.633319, acc: 63.28%] [G loss: 2.166791]\n",
      "epoch:13 step:10366 [D loss: 0.612706, acc: 69.53%] [G loss: 1.770189]\n",
      "epoch:13 step:10367 [D loss: 0.573279, acc: 71.09%] [G loss: 2.274242]\n",
      "epoch:13 step:10368 [D loss: 0.622778, acc: 61.72%] [G loss: 1.661664]\n",
      "epoch:13 step:10369 [D loss: 0.540613, acc: 79.69%] [G loss: 1.861607]\n",
      "epoch:13 step:10370 [D loss: 0.813365, acc: 40.62%] [G loss: 1.773115]\n",
      "epoch:13 step:10371 [D loss: 0.624248, acc: 65.62%] [G loss: 2.024919]\n",
      "epoch:13 step:10372 [D loss: 0.670670, acc: 62.50%] [G loss: 1.942450]\n",
      "epoch:13 step:10373 [D loss: 0.946693, acc: 18.75%] [G loss: 1.678026]\n",
      "epoch:13 step:10374 [D loss: 0.555990, acc: 76.56%] [G loss: 1.903910]\n",
      "epoch:13 step:10375 [D loss: 0.613032, acc: 61.72%] [G loss: 1.968155]\n",
      "epoch:13 step:10376 [D loss: 0.690279, acc: 60.16%] [G loss: 1.630241]\n",
      "epoch:13 step:10377 [D loss: 0.495601, acc: 74.22%] [G loss: 2.315418]\n",
      "epoch:13 step:10378 [D loss: 0.639473, acc: 64.06%] [G loss: 2.096695]\n",
      "epoch:13 step:10379 [D loss: 0.704098, acc: 50.78%] [G loss: 1.587323]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10380 [D loss: 0.579177, acc: 75.00%] [G loss: 2.016615]\n",
      "epoch:13 step:10381 [D loss: 0.675740, acc: 53.91%] [G loss: 1.721255]\n",
      "epoch:13 step:10382 [D loss: 0.730980, acc: 46.88%] [G loss: 1.939024]\n",
      "epoch:13 step:10383 [D loss: 0.621439, acc: 64.84%] [G loss: 1.865512]\n",
      "epoch:13 step:10384 [D loss: 0.529169, acc: 82.03%] [G loss: 1.983073]\n",
      "epoch:13 step:10385 [D loss: 0.808688, acc: 43.75%] [G loss: 1.807436]\n",
      "epoch:13 step:10386 [D loss: 0.519247, acc: 79.69%] [G loss: 2.188998]\n",
      "epoch:13 step:10387 [D loss: 0.610900, acc: 71.88%] [G loss: 2.332484]\n",
      "epoch:13 step:10388 [D loss: 0.736361, acc: 46.09%] [G loss: 2.381605]\n",
      "epoch:13 step:10389 [D loss: 0.726688, acc: 51.56%] [G loss: 1.812033]\n",
      "epoch:13 step:10390 [D loss: 0.623534, acc: 61.72%] [G loss: 2.137896]\n",
      "epoch:13 step:10391 [D loss: 0.471009, acc: 85.16%] [G loss: 1.992563]\n",
      "epoch:13 step:10392 [D loss: 0.621053, acc: 57.81%] [G loss: 2.047791]\n",
      "epoch:13 step:10393 [D loss: 0.572245, acc: 71.88%] [G loss: 2.146165]\n",
      "epoch:13 step:10394 [D loss: 0.665749, acc: 64.06%] [G loss: 2.023092]\n",
      "epoch:13 step:10395 [D loss: 0.528384, acc: 82.03%] [G loss: 1.771753]\n",
      "epoch:13 step:10396 [D loss: 0.498292, acc: 77.34%] [G loss: 2.208153]\n",
      "epoch:13 step:10397 [D loss: 0.589258, acc: 73.44%] [G loss: 2.076081]\n",
      "epoch:13 step:10398 [D loss: 0.808075, acc: 42.97%] [G loss: 1.634797]\n",
      "epoch:13 step:10399 [D loss: 0.705249, acc: 47.66%] [G loss: 2.195632]\n",
      "epoch:13 step:10400 [D loss: 0.680896, acc: 56.25%] [G loss: 2.268882]\n",
      "epoch:13 step:10401 [D loss: 0.635415, acc: 69.53%] [G loss: 1.805641]\n",
      "epoch:13 step:10402 [D loss: 0.530982, acc: 72.66%] [G loss: 1.979345]\n",
      "epoch:13 step:10403 [D loss: 0.674433, acc: 57.81%] [G loss: 2.150080]\n",
      "epoch:13 step:10404 [D loss: 0.571182, acc: 75.00%] [G loss: 1.804051]\n",
      "epoch:13 step:10405 [D loss: 0.618437, acc: 61.72%] [G loss: 2.041185]\n",
      "epoch:13 step:10406 [D loss: 0.656395, acc: 62.50%] [G loss: 1.898125]\n",
      "epoch:13 step:10407 [D loss: 0.854612, acc: 37.50%] [G loss: 1.600221]\n",
      "epoch:13 step:10408 [D loss: 0.782997, acc: 48.44%] [G loss: 1.814707]\n",
      "epoch:13 step:10409 [D loss: 0.780914, acc: 42.97%] [G loss: 1.637883]\n",
      "epoch:13 step:10410 [D loss: 0.832666, acc: 35.94%] [G loss: 1.567014]\n",
      "epoch:13 step:10411 [D loss: 0.606272, acc: 64.84%] [G loss: 1.816101]\n",
      "epoch:13 step:10412 [D loss: 0.817959, acc: 37.50%] [G loss: 1.762524]\n",
      "epoch:13 step:10413 [D loss: 0.443587, acc: 89.06%] [G loss: 2.204502]\n",
      "epoch:13 step:10414 [D loss: 0.520784, acc: 76.56%] [G loss: 2.050511]\n",
      "epoch:13 step:10415 [D loss: 0.734042, acc: 53.91%] [G loss: 1.747294]\n",
      "epoch:13 step:10416 [D loss: 0.590156, acc: 71.09%] [G loss: 1.939147]\n",
      "epoch:13 step:10417 [D loss: 0.599818, acc: 68.75%] [G loss: 2.117037]\n",
      "epoch:13 step:10418 [D loss: 0.613676, acc: 64.84%] [G loss: 1.842804]\n",
      "epoch:13 step:10419 [D loss: 0.696225, acc: 56.25%] [G loss: 1.917179]\n",
      "epoch:13 step:10420 [D loss: 1.108060, acc: 25.78%] [G loss: 1.321169]\n",
      "epoch:13 step:10421 [D loss: 0.645574, acc: 68.75%] [G loss: 1.910346]\n",
      "epoch:13 step:10422 [D loss: 0.661490, acc: 56.25%] [G loss: 1.894325]\n",
      "epoch:13 step:10423 [D loss: 0.870138, acc: 32.81%] [G loss: 1.822208]\n",
      "epoch:13 step:10424 [D loss: 0.632811, acc: 61.72%] [G loss: 1.963373]\n",
      "epoch:13 step:10425 [D loss: 0.713128, acc: 52.34%] [G loss: 1.712255]\n",
      "epoch:13 step:10426 [D loss: 0.578568, acc: 71.09%] [G loss: 2.175089]\n",
      "epoch:13 step:10427 [D loss: 0.675490, acc: 60.16%] [G loss: 1.519757]\n",
      "epoch:13 step:10428 [D loss: 0.524189, acc: 82.03%] [G loss: 1.980320]\n",
      "epoch:13 step:10429 [D loss: 0.595342, acc: 71.88%] [G loss: 1.934604]\n",
      "epoch:13 step:10430 [D loss: 0.735122, acc: 49.22%] [G loss: 1.715802]\n",
      "epoch:13 step:10431 [D loss: 0.460829, acc: 81.25%] [G loss: 2.097625]\n",
      "epoch:13 step:10432 [D loss: 0.639403, acc: 60.16%] [G loss: 1.840287]\n",
      "epoch:13 step:10433 [D loss: 0.630155, acc: 67.19%] [G loss: 1.837625]\n",
      "epoch:13 step:10434 [D loss: 0.479951, acc: 77.34%] [G loss: 2.407191]\n",
      "epoch:13 step:10435 [D loss: 0.875287, acc: 32.81%] [G loss: 1.664904]\n",
      "epoch:13 step:10436 [D loss: 0.494468, acc: 87.50%] [G loss: 2.274004]\n",
      "epoch:13 step:10437 [D loss: 0.422382, acc: 90.62%] [G loss: 1.921519]\n",
      "epoch:13 step:10438 [D loss: 0.545671, acc: 77.34%] [G loss: 1.658317]\n",
      "epoch:13 step:10439 [D loss: 0.528158, acc: 77.34%] [G loss: 1.764196]\n",
      "epoch:13 step:10440 [D loss: 0.475724, acc: 88.28%] [G loss: 1.805590]\n",
      "epoch:13 step:10441 [D loss: 0.805231, acc: 39.84%] [G loss: 1.813632]\n",
      "epoch:13 step:10442 [D loss: 0.527178, acc: 78.12%] [G loss: 2.218430]\n",
      "epoch:13 step:10443 [D loss: 0.613922, acc: 63.28%] [G loss: 1.758111]\n",
      "epoch:13 step:10444 [D loss: 0.837618, acc: 34.38%] [G loss: 1.805349]\n",
      "epoch:13 step:10445 [D loss: 0.591180, acc: 68.75%] [G loss: 1.725116]\n",
      "epoch:13 step:10446 [D loss: 0.766807, acc: 50.00%] [G loss: 1.638558]\n",
      "epoch:13 step:10447 [D loss: 0.660276, acc: 63.28%] [G loss: 1.783104]\n",
      "epoch:13 step:10448 [D loss: 0.558793, acc: 71.88%] [G loss: 1.992444]\n",
      "epoch:13 step:10449 [D loss: 0.676586, acc: 60.16%] [G loss: 1.989814]\n",
      "epoch:13 step:10450 [D loss: 0.652020, acc: 58.59%] [G loss: 2.036239]\n",
      "epoch:13 step:10451 [D loss: 0.750021, acc: 50.78%] [G loss: 1.753335]\n",
      "epoch:13 step:10452 [D loss: 0.672666, acc: 58.59%] [G loss: 1.984128]\n",
      "epoch:13 step:10453 [D loss: 0.750562, acc: 51.56%] [G loss: 1.650525]\n",
      "epoch:13 step:10454 [D loss: 0.953230, acc: 17.97%] [G loss: 1.497379]\n",
      "epoch:13 step:10455 [D loss: 0.578055, acc: 70.31%] [G loss: 2.049544]\n",
      "epoch:13 step:10456 [D loss: 0.542716, acc: 76.56%] [G loss: 2.083331]\n",
      "epoch:13 step:10457 [D loss: 0.871125, acc: 25.78%] [G loss: 1.582799]\n",
      "epoch:13 step:10458 [D loss: 0.961033, acc: 21.88%] [G loss: 1.324966]\n",
      "epoch:13 step:10459 [D loss: 0.545625, acc: 82.03%] [G loss: 2.061494]\n",
      "epoch:13 step:10460 [D loss: 0.498604, acc: 80.47%] [G loss: 1.928667]\n",
      "epoch:13 step:10461 [D loss: 0.434048, acc: 89.84%] [G loss: 2.151605]\n",
      "epoch:13 step:10462 [D loss: 0.685895, acc: 57.81%] [G loss: 2.311622]\n",
      "epoch:13 step:10463 [D loss: 0.655987, acc: 62.50%] [G loss: 2.343180]\n",
      "epoch:13 step:10464 [D loss: 0.620131, acc: 61.72%] [G loss: 1.478135]\n",
      "epoch:13 step:10465 [D loss: 0.750279, acc: 53.12%] [G loss: 2.046775]\n",
      "epoch:13 step:10466 [D loss: 0.817417, acc: 34.38%] [G loss: 1.700558]\n",
      "epoch:13 step:10467 [D loss: 0.690115, acc: 56.25%] [G loss: 1.717871]\n",
      "epoch:13 step:10468 [D loss: 0.905281, acc: 28.91%] [G loss: 1.669301]\n",
      "epoch:13 step:10469 [D loss: 0.688980, acc: 58.59%] [G loss: 1.949732]\n",
      "epoch:13 step:10470 [D loss: 0.471517, acc: 87.50%] [G loss: 2.160749]\n",
      "epoch:13 step:10471 [D loss: 0.634166, acc: 64.84%] [G loss: 2.077362]\n",
      "epoch:13 step:10472 [D loss: 0.639036, acc: 62.50%] [G loss: 1.753003]\n",
      "epoch:13 step:10473 [D loss: 0.432087, acc: 92.97%] [G loss: 2.376572]\n",
      "epoch:13 step:10474 [D loss: 0.648524, acc: 60.94%] [G loss: 1.905309]\n",
      "epoch:13 step:10475 [D loss: 0.673617, acc: 59.38%] [G loss: 2.236728]\n",
      "epoch:13 step:10476 [D loss: 0.515512, acc: 75.78%] [G loss: 2.322633]\n",
      "epoch:13 step:10477 [D loss: 0.528817, acc: 72.66%] [G loss: 1.868056]\n",
      "epoch:13 step:10478 [D loss: 0.662119, acc: 58.59%] [G loss: 1.908214]\n",
      "epoch:13 step:10479 [D loss: 0.495636, acc: 85.16%] [G loss: 1.965343]\n",
      "epoch:13 step:10480 [D loss: 0.593980, acc: 76.56%] [G loss: 2.067401]\n",
      "epoch:13 step:10481 [D loss: 0.636739, acc: 64.84%] [G loss: 2.238894]\n",
      "epoch:13 step:10482 [D loss: 0.738918, acc: 47.66%] [G loss: 1.566849]\n",
      "epoch:13 step:10483 [D loss: 0.527811, acc: 77.34%] [G loss: 1.738985]\n",
      "epoch:13 step:10484 [D loss: 0.486351, acc: 84.38%] [G loss: 2.059591]\n",
      "epoch:13 step:10485 [D loss: 0.769125, acc: 47.66%] [G loss: 1.817979]\n",
      "epoch:13 step:10486 [D loss: 0.862784, acc: 30.47%] [G loss: 1.786792]\n",
      "epoch:13 step:10487 [D loss: 0.714259, acc: 46.09%] [G loss: 2.337250]\n",
      "epoch:13 step:10488 [D loss: 0.554600, acc: 72.66%] [G loss: 2.096770]\n",
      "epoch:13 step:10489 [D loss: 0.759126, acc: 53.12%] [G loss: 1.839741]\n",
      "epoch:13 step:10490 [D loss: 0.675899, acc: 63.28%] [G loss: 1.720349]\n",
      "epoch:13 step:10491 [D loss: 0.644671, acc: 61.72%] [G loss: 1.860535]\n",
      "epoch:13 step:10492 [D loss: 0.743572, acc: 50.00%] [G loss: 1.900179]\n",
      "epoch:13 step:10493 [D loss: 0.522590, acc: 83.59%] [G loss: 1.932160]\n",
      "epoch:13 step:10494 [D loss: 0.541023, acc: 78.91%] [G loss: 1.985282]\n",
      "epoch:13 step:10495 [D loss: 0.488842, acc: 88.28%] [G loss: 2.104481]\n",
      "epoch:13 step:10496 [D loss: 0.587758, acc: 67.19%] [G loss: 2.111562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10497 [D loss: 0.715719, acc: 52.34%] [G loss: 1.784017]\n",
      "epoch:13 step:10498 [D loss: 0.533521, acc: 66.41%] [G loss: 1.780360]\n",
      "epoch:13 step:10499 [D loss: 0.452237, acc: 85.94%] [G loss: 2.208394]\n",
      "epoch:13 step:10500 [D loss: 0.587907, acc: 68.75%] [G loss: 2.159062]\n",
      "epoch:13 step:10501 [D loss: 0.672496, acc: 60.94%] [G loss: 1.822351]\n",
      "epoch:13 step:10502 [D loss: 0.427982, acc: 85.16%] [G loss: 3.088429]\n",
      "epoch:13 step:10503 [D loss: 0.599638, acc: 69.53%] [G loss: 2.213421]\n",
      "epoch:13 step:10504 [D loss: 0.945847, acc: 26.56%] [G loss: 1.635391]\n",
      "epoch:13 step:10505 [D loss: 0.494048, acc: 86.72%] [G loss: 2.320251]\n",
      "epoch:13 step:10506 [D loss: 0.530670, acc: 76.56%] [G loss: 2.285688]\n",
      "epoch:13 step:10507 [D loss: 0.970365, acc: 28.12%] [G loss: 1.724290]\n",
      "epoch:13 step:10508 [D loss: 0.751249, acc: 46.09%] [G loss: 1.920751]\n",
      "epoch:13 step:10509 [D loss: 0.556527, acc: 69.53%] [G loss: 1.590106]\n",
      "epoch:13 step:10510 [D loss: 0.600230, acc: 71.88%] [G loss: 1.909917]\n",
      "epoch:13 step:10511 [D loss: 0.704617, acc: 46.09%] [G loss: 1.684295]\n",
      "epoch:13 step:10512 [D loss: 0.733474, acc: 44.53%] [G loss: 1.961259]\n",
      "epoch:13 step:10513 [D loss: 0.874739, acc: 28.12%] [G loss: 1.481554]\n",
      "epoch:13 step:10514 [D loss: 0.500781, acc: 80.47%] [G loss: 2.193512]\n",
      "epoch:13 step:10515 [D loss: 0.658875, acc: 60.16%] [G loss: 2.144402]\n",
      "epoch:13 step:10516 [D loss: 0.593075, acc: 74.22%] [G loss: 2.151903]\n",
      "epoch:13 step:10517 [D loss: 0.561713, acc: 77.34%] [G loss: 2.285571]\n",
      "epoch:13 step:10518 [D loss: 0.573071, acc: 71.09%] [G loss: 2.188451]\n",
      "epoch:13 step:10519 [D loss: 0.501158, acc: 82.81%] [G loss: 2.182578]\n",
      "epoch:13 step:10520 [D loss: 0.526331, acc: 83.59%] [G loss: 2.271331]\n",
      "epoch:13 step:10521 [D loss: 0.458429, acc: 85.16%] [G loss: 1.639261]\n",
      "epoch:13 step:10522 [D loss: 0.467570, acc: 86.72%] [G loss: 2.352619]\n",
      "epoch:13 step:10523 [D loss: 0.524477, acc: 82.03%] [G loss: 2.528292]\n",
      "epoch:13 step:10524 [D loss: 0.494981, acc: 86.72%] [G loss: 2.378881]\n",
      "epoch:13 step:10525 [D loss: 0.611698, acc: 66.41%] [G loss: 2.407847]\n",
      "epoch:13 step:10526 [D loss: 0.743440, acc: 55.47%] [G loss: 1.597659]\n",
      "epoch:13 step:10527 [D loss: 0.556918, acc: 69.53%] [G loss: 2.512830]\n",
      "epoch:13 step:10528 [D loss: 0.816301, acc: 40.62%] [G loss: 1.415698]\n",
      "epoch:13 step:10529 [D loss: 0.766778, acc: 48.44%] [G loss: 2.145450]\n",
      "epoch:13 step:10530 [D loss: 0.692925, acc: 57.81%] [G loss: 1.732532]\n",
      "epoch:13 step:10531 [D loss: 0.749806, acc: 53.12%] [G loss: 2.146190]\n",
      "epoch:13 step:10532 [D loss: 0.588161, acc: 68.75%] [G loss: 1.906606]\n",
      "epoch:13 step:10533 [D loss: 0.694953, acc: 54.69%] [G loss: 1.817419]\n",
      "epoch:13 step:10534 [D loss: 0.423133, acc: 93.75%] [G loss: 2.439520]\n",
      "epoch:13 step:10535 [D loss: 0.646421, acc: 65.62%] [G loss: 1.890203]\n",
      "epoch:13 step:10536 [D loss: 0.746577, acc: 47.66%] [G loss: 1.633197]\n",
      "epoch:13 step:10537 [D loss: 0.784344, acc: 38.28%] [G loss: 1.841081]\n",
      "epoch:13 step:10538 [D loss: 0.652582, acc: 67.97%] [G loss: 1.979007]\n",
      "epoch:13 step:10539 [D loss: 0.689477, acc: 53.91%] [G loss: 1.863208]\n",
      "epoch:13 step:10540 [D loss: 0.707273, acc: 53.12%] [G loss: 1.943641]\n",
      "epoch:13 step:10541 [D loss: 0.667982, acc: 56.25%] [G loss: 2.056004]\n",
      "epoch:13 step:10542 [D loss: 0.705833, acc: 53.91%] [G loss: 2.201270]\n",
      "epoch:13 step:10543 [D loss: 0.756534, acc: 44.53%] [G loss: 1.961724]\n",
      "epoch:13 step:10544 [D loss: 0.803342, acc: 37.50%] [G loss: 1.734865]\n",
      "epoch:13 step:10545 [D loss: 0.716040, acc: 52.34%] [G loss: 1.807106]\n",
      "epoch:13 step:10546 [D loss: 0.794083, acc: 41.41%] [G loss: 1.538436]\n",
      "epoch:13 step:10547 [D loss: 0.572360, acc: 75.78%] [G loss: 2.006849]\n",
      "epoch:13 step:10548 [D loss: 0.605247, acc: 71.09%] [G loss: 2.038060]\n",
      "epoch:13 step:10549 [D loss: 0.488557, acc: 75.78%] [G loss: 2.227090]\n",
      "epoch:13 step:10550 [D loss: 0.629903, acc: 60.16%] [G loss: 1.834552]\n",
      "epoch:13 step:10551 [D loss: 0.683712, acc: 62.50%] [G loss: 1.872870]\n",
      "epoch:13 step:10552 [D loss: 0.643753, acc: 61.72%] [G loss: 2.238668]\n",
      "epoch:13 step:10553 [D loss: 0.476533, acc: 82.81%] [G loss: 2.660676]\n",
      "epoch:13 step:10554 [D loss: 0.608333, acc: 69.53%] [G loss: 2.089569]\n",
      "epoch:13 step:10555 [D loss: 0.715286, acc: 54.69%] [G loss: 1.983727]\n",
      "epoch:13 step:10556 [D loss: 0.695368, acc: 50.78%] [G loss: 2.030673]\n",
      "epoch:13 step:10557 [D loss: 0.593540, acc: 72.66%] [G loss: 2.491567]\n",
      "epoch:13 step:10558 [D loss: 0.757937, acc: 50.78%] [G loss: 2.516196]\n",
      "epoch:13 step:10559 [D loss: 0.518276, acc: 81.25%] [G loss: 2.454248]\n",
      "epoch:13 step:10560 [D loss: 0.684387, acc: 60.16%] [G loss: 1.881542]\n",
      "epoch:13 step:10561 [D loss: 0.470605, acc: 76.56%] [G loss: 2.383463]\n",
      "epoch:13 step:10562 [D loss: 0.580390, acc: 71.09%] [G loss: 1.943462]\n",
      "epoch:13 step:10563 [D loss: 0.701493, acc: 50.78%] [G loss: 1.818959]\n",
      "epoch:13 step:10564 [D loss: 0.671137, acc: 59.38%] [G loss: 1.603128]\n",
      "epoch:13 step:10565 [D loss: 0.497260, acc: 78.91%] [G loss: 1.975971]\n",
      "epoch:13 step:10566 [D loss: 0.653615, acc: 62.50%] [G loss: 1.926835]\n",
      "epoch:13 step:10567 [D loss: 0.522873, acc: 73.44%] [G loss: 2.907137]\n",
      "epoch:13 step:10568 [D loss: 0.646928, acc: 71.88%] [G loss: 2.028396]\n",
      "epoch:13 step:10569 [D loss: 0.507557, acc: 81.25%] [G loss: 2.409376]\n",
      "epoch:13 step:10570 [D loss: 0.477184, acc: 80.47%] [G loss: 2.215632]\n",
      "epoch:13 step:10571 [D loss: 0.619416, acc: 65.62%] [G loss: 1.989631]\n",
      "epoch:13 step:10572 [D loss: 0.618142, acc: 67.19%] [G loss: 2.086758]\n",
      "epoch:13 step:10573 [D loss: 0.741898, acc: 56.25%] [G loss: 2.180996]\n",
      "epoch:13 step:10574 [D loss: 0.903840, acc: 32.03%] [G loss: 2.053070]\n",
      "epoch:13 step:10575 [D loss: 0.542825, acc: 78.91%] [G loss: 2.375777]\n",
      "epoch:13 step:10576 [D loss: 0.746654, acc: 51.56%] [G loss: 2.064218]\n",
      "epoch:13 step:10577 [D loss: 0.960741, acc: 21.09%] [G loss: 1.781188]\n",
      "epoch:13 step:10578 [D loss: 0.728212, acc: 54.69%] [G loss: 1.916488]\n",
      "epoch:13 step:10579 [D loss: 0.540171, acc: 75.00%] [G loss: 2.458520]\n",
      "epoch:13 step:10580 [D loss: 0.557174, acc: 77.34%] [G loss: 2.082804]\n",
      "epoch:13 step:10581 [D loss: 0.694126, acc: 57.03%] [G loss: 1.999711]\n",
      "epoch:13 step:10582 [D loss: 0.786073, acc: 42.97%] [G loss: 1.697886]\n",
      "epoch:13 step:10583 [D loss: 0.629096, acc: 67.19%] [G loss: 2.402297]\n",
      "epoch:13 step:10584 [D loss: 0.525475, acc: 78.12%] [G loss: 2.403722]\n",
      "epoch:13 step:10585 [D loss: 0.478671, acc: 85.94%] [G loss: 2.777850]\n",
      "epoch:13 step:10586 [D loss: 0.505680, acc: 82.81%] [G loss: 2.290289]\n",
      "epoch:13 step:10587 [D loss: 0.722656, acc: 55.47%] [G loss: 1.870607]\n",
      "epoch:13 step:10588 [D loss: 0.651172, acc: 67.97%] [G loss: 1.777491]\n",
      "epoch:13 step:10589 [D loss: 0.730782, acc: 50.78%] [G loss: 2.086143]\n",
      "epoch:13 step:10590 [D loss: 0.649504, acc: 59.38%] [G loss: 2.406642]\n",
      "epoch:13 step:10591 [D loss: 0.685307, acc: 53.12%] [G loss: 2.134902]\n",
      "epoch:13 step:10592 [D loss: 0.769182, acc: 46.09%] [G loss: 1.869450]\n",
      "epoch:13 step:10593 [D loss: 0.878556, acc: 34.38%] [G loss: 1.769598]\n",
      "epoch:13 step:10594 [D loss: 0.767753, acc: 42.97%] [G loss: 1.692122]\n",
      "epoch:13 step:10595 [D loss: 0.496695, acc: 69.53%] [G loss: 2.856244]\n",
      "epoch:13 step:10596 [D loss: 0.791893, acc: 43.75%] [G loss: 1.772280]\n",
      "epoch:13 step:10597 [D loss: 0.613413, acc: 64.06%] [G loss: 2.021959]\n",
      "epoch:13 step:10598 [D loss: 0.534073, acc: 74.22%] [G loss: 2.442564]\n",
      "epoch:13 step:10599 [D loss: 0.428077, acc: 87.50%] [G loss: 2.678794]\n",
      "epoch:13 step:10600 [D loss: 0.703851, acc: 56.25%] [G loss: 1.927919]\n",
      "epoch:13 step:10601 [D loss: 0.482063, acc: 77.34%] [G loss: 2.358880]\n",
      "epoch:13 step:10602 [D loss: 0.607972, acc: 75.78%] [G loss: 1.873033]\n",
      "epoch:13 step:10603 [D loss: 0.568529, acc: 67.97%] [G loss: 1.720929]\n",
      "epoch:13 step:10604 [D loss: 0.370933, acc: 88.28%] [G loss: 2.574233]\n",
      "epoch:13 step:10605 [D loss: 0.429547, acc: 88.28%] [G loss: 2.717603]\n",
      "epoch:13 step:10606 [D loss: 0.399454, acc: 91.41%] [G loss: 3.575415]\n",
      "epoch:13 step:10607 [D loss: 0.711047, acc: 56.25%] [G loss: 2.158829]\n",
      "epoch:13 step:10608 [D loss: 0.619978, acc: 68.75%] [G loss: 2.409755]\n",
      "epoch:13 step:10609 [D loss: 0.791440, acc: 47.66%] [G loss: 1.929797]\n",
      "epoch:13 step:10610 [D loss: 0.528091, acc: 71.09%] [G loss: 2.383434]\n",
      "epoch:13 step:10611 [D loss: 0.690471, acc: 57.81%] [G loss: 1.720012]\n",
      "epoch:13 step:10612 [D loss: 0.694763, acc: 54.69%] [G loss: 2.343918]\n",
      "epoch:13 step:10613 [D loss: 0.563197, acc: 75.00%] [G loss: 2.564664]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10614 [D loss: 0.603064, acc: 64.06%] [G loss: 2.709295]\n",
      "epoch:13 step:10615 [D loss: 0.596760, acc: 64.84%] [G loss: 3.048726]\n",
      "epoch:13 step:10616 [D loss: 0.634261, acc: 64.84%] [G loss: 2.605505]\n",
      "epoch:13 step:10617 [D loss: 0.436557, acc: 89.84%] [G loss: 2.233994]\n",
      "epoch:13 step:10618 [D loss: 0.611639, acc: 68.75%] [G loss: 1.978791]\n",
      "epoch:13 step:10619 [D loss: 0.513654, acc: 82.81%] [G loss: 2.148416]\n",
      "epoch:13 step:10620 [D loss: 0.753121, acc: 47.66%] [G loss: 1.779984]\n",
      "epoch:13 step:10621 [D loss: 0.475305, acc: 84.38%] [G loss: 1.996280]\n",
      "epoch:13 step:10622 [D loss: 0.582993, acc: 70.31%] [G loss: 2.034880]\n",
      "epoch:13 step:10623 [D loss: 0.611471, acc: 66.41%] [G loss: 1.978086]\n",
      "epoch:13 step:10624 [D loss: 0.645365, acc: 63.28%] [G loss: 2.145125]\n",
      "epoch:13 step:10625 [D loss: 0.458273, acc: 86.72%] [G loss: 2.392682]\n",
      "epoch:13 step:10626 [D loss: 0.590814, acc: 72.66%] [G loss: 1.878816]\n",
      "epoch:13 step:10627 [D loss: 0.625052, acc: 64.06%] [G loss: 2.640994]\n",
      "epoch:13 step:10628 [D loss: 0.494150, acc: 77.34%] [G loss: 2.845788]\n",
      "epoch:13 step:10629 [D loss: 0.547655, acc: 67.97%] [G loss: 2.448138]\n",
      "epoch:13 step:10630 [D loss: 0.413518, acc: 83.59%] [G loss: 2.681134]\n",
      "epoch:13 step:10631 [D loss: 0.577808, acc: 65.62%] [G loss: 2.372720]\n",
      "epoch:13 step:10632 [D loss: 0.686230, acc: 61.72%] [G loss: 2.629691]\n",
      "epoch:13 step:10633 [D loss: 0.647469, acc: 60.94%] [G loss: 1.812415]\n",
      "epoch:13 step:10634 [D loss: 0.757335, acc: 51.56%] [G loss: 1.811867]\n",
      "epoch:13 step:10635 [D loss: 0.687345, acc: 50.78%] [G loss: 2.170534]\n",
      "epoch:13 step:10636 [D loss: 0.503266, acc: 77.34%] [G loss: 2.158456]\n",
      "epoch:13 step:10637 [D loss: 0.553859, acc: 66.41%] [G loss: 2.771242]\n",
      "epoch:13 step:10638 [D loss: 0.735779, acc: 48.44%] [G loss: 1.720690]\n",
      "epoch:13 step:10639 [D loss: 0.743431, acc: 47.66%] [G loss: 2.324666]\n",
      "epoch:13 step:10640 [D loss: 0.429048, acc: 85.16%] [G loss: 2.253989]\n",
      "epoch:13 step:10641 [D loss: 0.582811, acc: 66.41%] [G loss: 1.720951]\n",
      "epoch:13 step:10642 [D loss: 0.641102, acc: 64.06%] [G loss: 1.743930]\n",
      "epoch:13 step:10643 [D loss: 0.649695, acc: 61.72%] [G loss: 3.203668]\n",
      "epoch:13 step:10644 [D loss: 0.545050, acc: 76.56%] [G loss: 2.296032]\n",
      "epoch:13 step:10645 [D loss: 0.513345, acc: 73.44%] [G loss: 2.825073]\n",
      "epoch:13 step:10646 [D loss: 0.839236, acc: 37.50%] [G loss: 2.084561]\n",
      "epoch:13 step:10647 [D loss: 0.477273, acc: 81.25%] [G loss: 1.883132]\n",
      "epoch:13 step:10648 [D loss: 0.609226, acc: 63.28%] [G loss: 2.607647]\n",
      "epoch:13 step:10649 [D loss: 0.588090, acc: 65.62%] [G loss: 1.864977]\n",
      "epoch:13 step:10650 [D loss: 0.495837, acc: 73.44%] [G loss: 2.959576]\n",
      "epoch:13 step:10651 [D loss: 0.504394, acc: 78.12%] [G loss: 2.411232]\n",
      "epoch:13 step:10652 [D loss: 0.688786, acc: 56.25%] [G loss: 2.563425]\n",
      "epoch:13 step:10653 [D loss: 0.651427, acc: 65.62%] [G loss: 2.339151]\n",
      "epoch:13 step:10654 [D loss: 0.598029, acc: 67.19%] [G loss: 2.164900]\n",
      "epoch:13 step:10655 [D loss: 0.670364, acc: 57.03%] [G loss: 1.864777]\n",
      "epoch:13 step:10656 [D loss: 0.833341, acc: 52.34%] [G loss: 2.295946]\n",
      "epoch:13 step:10657 [D loss: 0.665091, acc: 57.03%] [G loss: 2.683955]\n",
      "epoch:13 step:10658 [D loss: 0.789656, acc: 50.00%] [G loss: 2.395177]\n",
      "epoch:13 step:10659 [D loss: 0.511419, acc: 81.25%] [G loss: 3.143053]\n",
      "epoch:13 step:10660 [D loss: 0.733304, acc: 53.12%] [G loss: 2.246214]\n",
      "epoch:13 step:10661 [D loss: 0.452111, acc: 83.59%] [G loss: 2.250265]\n",
      "epoch:13 step:10662 [D loss: 0.462143, acc: 88.28%] [G loss: 2.493800]\n",
      "epoch:13 step:10663 [D loss: 0.556602, acc: 74.22%] [G loss: 2.164941]\n",
      "epoch:13 step:10664 [D loss: 0.472144, acc: 83.59%] [G loss: 2.424538]\n",
      "epoch:13 step:10665 [D loss: 0.452062, acc: 84.38%] [G loss: 3.004293]\n",
      "epoch:13 step:10666 [D loss: 0.555859, acc: 64.84%] [G loss: 2.487227]\n",
      "epoch:13 step:10667 [D loss: 0.685077, acc: 58.59%] [G loss: 2.432642]\n",
      "epoch:13 step:10668 [D loss: 0.646310, acc: 60.16%] [G loss: 1.761675]\n",
      "epoch:13 step:10669 [D loss: 0.564785, acc: 64.84%] [G loss: 2.127597]\n",
      "epoch:13 step:10670 [D loss: 0.486393, acc: 84.38%] [G loss: 2.227397]\n",
      "epoch:13 step:10671 [D loss: 0.808045, acc: 43.75%] [G loss: 1.991038]\n",
      "epoch:13 step:10672 [D loss: 0.926393, acc: 35.94%] [G loss: 1.479117]\n",
      "epoch:13 step:10673 [D loss: 0.554748, acc: 75.78%] [G loss: 2.027069]\n",
      "epoch:13 step:10674 [D loss: 0.424362, acc: 90.62%] [G loss: 2.446433]\n",
      "epoch:13 step:10675 [D loss: 0.918935, acc: 48.44%] [G loss: 1.975594]\n",
      "epoch:13 step:10676 [D loss: 0.676541, acc: 57.03%] [G loss: 2.452937]\n",
      "epoch:13 step:10677 [D loss: 0.744346, acc: 53.12%] [G loss: 2.153263]\n",
      "epoch:13 step:10678 [D loss: 0.540405, acc: 78.91%] [G loss: 1.808540]\n",
      "epoch:13 step:10679 [D loss: 0.974543, acc: 29.69%] [G loss: 2.244434]\n",
      "epoch:13 step:10680 [D loss: 0.671406, acc: 61.72%] [G loss: 1.922661]\n",
      "epoch:13 step:10681 [D loss: 0.465357, acc: 83.59%] [G loss: 2.344279]\n",
      "epoch:13 step:10682 [D loss: 0.577859, acc: 75.00%] [G loss: 2.570871]\n",
      "epoch:13 step:10683 [D loss: 0.602441, acc: 69.53%] [G loss: 2.513343]\n",
      "epoch:13 step:10684 [D loss: 0.658699, acc: 60.16%] [G loss: 1.873801]\n",
      "epoch:13 step:10685 [D loss: 0.934174, acc: 28.91%] [G loss: 2.429797]\n",
      "epoch:13 step:10686 [D loss: 0.513123, acc: 79.69%] [G loss: 2.546382]\n",
      "epoch:13 step:10687 [D loss: 0.675484, acc: 58.59%] [G loss: 1.908066]\n",
      "epoch:13 step:10688 [D loss: 0.645069, acc: 60.94%] [G loss: 2.164908]\n",
      "epoch:13 step:10689 [D loss: 0.593416, acc: 64.06%] [G loss: 2.314991]\n",
      "epoch:13 step:10690 [D loss: 0.617679, acc: 64.06%] [G loss: 2.330381]\n",
      "epoch:13 step:10691 [D loss: 0.643907, acc: 63.28%] [G loss: 1.785177]\n",
      "epoch:13 step:10692 [D loss: 0.784768, acc: 42.19%] [G loss: 1.872831]\n",
      "epoch:13 step:10693 [D loss: 0.862057, acc: 36.72%] [G loss: 1.952549]\n",
      "epoch:13 step:10694 [D loss: 0.581998, acc: 74.22%] [G loss: 2.531942]\n",
      "epoch:13 step:10695 [D loss: 0.564876, acc: 68.75%] [G loss: 2.251391]\n",
      "epoch:13 step:10696 [D loss: 0.783251, acc: 42.19%] [G loss: 1.951158]\n",
      "epoch:13 step:10697 [D loss: 0.574236, acc: 75.00%] [G loss: 2.141924]\n",
      "epoch:13 step:10698 [D loss: 0.669272, acc: 57.03%] [G loss: 1.944185]\n",
      "epoch:13 step:10699 [D loss: 0.726245, acc: 51.56%] [G loss: 1.888150]\n",
      "epoch:13 step:10700 [D loss: 0.644133, acc: 62.50%] [G loss: 2.168856]\n",
      "epoch:13 step:10701 [D loss: 0.756384, acc: 47.66%] [G loss: 2.143276]\n",
      "epoch:13 step:10702 [D loss: 0.764763, acc: 51.56%] [G loss: 2.030536]\n",
      "epoch:13 step:10703 [D loss: 0.570178, acc: 68.75%] [G loss: 2.158086]\n",
      "epoch:13 step:10704 [D loss: 0.546469, acc: 77.34%] [G loss: 2.040669]\n",
      "epoch:13 step:10705 [D loss: 0.684516, acc: 62.50%] [G loss: 1.775501]\n",
      "epoch:13 step:10706 [D loss: 0.826979, acc: 37.50%] [G loss: 2.000405]\n",
      "epoch:13 step:10707 [D loss: 0.702777, acc: 51.56%] [G loss: 1.855219]\n",
      "epoch:13 step:10708 [D loss: 0.559851, acc: 75.78%] [G loss: 2.597953]\n",
      "epoch:13 step:10709 [D loss: 0.541697, acc: 74.22%] [G loss: 2.441468]\n",
      "epoch:13 step:10710 [D loss: 0.650072, acc: 62.50%] [G loss: 1.929769]\n",
      "epoch:13 step:10711 [D loss: 0.759148, acc: 49.22%] [G loss: 2.028901]\n",
      "epoch:13 step:10712 [D loss: 0.481713, acc: 82.81%] [G loss: 2.369270]\n",
      "epoch:13 step:10713 [D loss: 0.462777, acc: 88.28%] [G loss: 2.696647]\n",
      "epoch:13 step:10714 [D loss: 0.579676, acc: 73.44%] [G loss: 2.225241]\n",
      "epoch:13 step:10715 [D loss: 0.643748, acc: 64.06%] [G loss: 1.957476]\n",
      "epoch:13 step:10716 [D loss: 0.771071, acc: 46.09%] [G loss: 2.021892]\n",
      "epoch:13 step:10717 [D loss: 0.638712, acc: 60.16%] [G loss: 2.557855]\n",
      "epoch:13 step:10718 [D loss: 0.492666, acc: 84.38%] [G loss: 2.279819]\n",
      "epoch:13 step:10719 [D loss: 0.671384, acc: 61.72%] [G loss: 2.392039]\n",
      "epoch:13 step:10720 [D loss: 0.601941, acc: 67.19%] [G loss: 2.031207]\n",
      "epoch:13 step:10721 [D loss: 0.759913, acc: 48.44%] [G loss: 1.846112]\n",
      "epoch:13 step:10722 [D loss: 0.750285, acc: 53.12%] [G loss: 2.093654]\n",
      "epoch:13 step:10723 [D loss: 0.450902, acc: 82.81%] [G loss: 2.312433]\n",
      "epoch:13 step:10724 [D loss: 0.659874, acc: 60.16%] [G loss: 2.284339]\n",
      "epoch:13 step:10725 [D loss: 0.432717, acc: 85.16%] [G loss: 2.617697]\n",
      "epoch:13 step:10726 [D loss: 0.779147, acc: 42.19%] [G loss: 2.197788]\n",
      "epoch:13 step:10727 [D loss: 0.613804, acc: 68.75%] [G loss: 2.444993]\n",
      "epoch:13 step:10728 [D loss: 0.499603, acc: 79.69%] [G loss: 2.502141]\n",
      "epoch:13 step:10729 [D loss: 0.715627, acc: 53.12%] [G loss: 2.268145]\n",
      "epoch:13 step:10730 [D loss: 0.691983, acc: 60.94%] [G loss: 1.787559]\n",
      "epoch:13 step:10731 [D loss: 0.380415, acc: 89.84%] [G loss: 2.545550]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10732 [D loss: 0.530661, acc: 70.31%] [G loss: 2.582653]\n",
      "epoch:13 step:10733 [D loss: 0.741124, acc: 54.69%] [G loss: 2.077060]\n",
      "epoch:13 step:10734 [D loss: 0.570961, acc: 71.09%] [G loss: 2.796278]\n",
      "epoch:13 step:10735 [D loss: 0.656282, acc: 59.38%] [G loss: 2.557889]\n",
      "epoch:13 step:10736 [D loss: 0.588416, acc: 72.66%] [G loss: 2.427274]\n",
      "epoch:13 step:10737 [D loss: 0.773701, acc: 46.09%] [G loss: 2.020007]\n",
      "epoch:13 step:10738 [D loss: 0.746112, acc: 47.66%] [G loss: 2.080348]\n",
      "epoch:13 step:10739 [D loss: 0.559568, acc: 63.28%] [G loss: 2.240756]\n",
      "epoch:13 step:10740 [D loss: 0.599584, acc: 64.06%] [G loss: 2.241740]\n",
      "epoch:13 step:10741 [D loss: 0.624472, acc: 63.28%] [G loss: 1.938479]\n",
      "epoch:13 step:10742 [D loss: 1.145962, acc: 24.22%] [G loss: 1.650274]\n",
      "epoch:13 step:10743 [D loss: 0.773582, acc: 44.53%] [G loss: 2.248645]\n",
      "epoch:13 step:10744 [D loss: 0.564255, acc: 75.00%] [G loss: 2.065970]\n",
      "epoch:13 step:10745 [D loss: 0.623800, acc: 63.28%] [G loss: 2.394576]\n",
      "epoch:13 step:10746 [D loss: 1.098177, acc: 17.19%] [G loss: 1.473829]\n",
      "epoch:13 step:10747 [D loss: 0.753552, acc: 49.22%] [G loss: 2.155941]\n",
      "epoch:13 step:10748 [D loss: 0.608441, acc: 64.84%] [G loss: 1.962437]\n",
      "epoch:13 step:10749 [D loss: 0.789649, acc: 43.75%] [G loss: 1.698193]\n",
      "epoch:13 step:10750 [D loss: 0.546453, acc: 75.00%] [G loss: 1.821145]\n",
      "epoch:13 step:10751 [D loss: 0.677246, acc: 60.94%] [G loss: 1.959006]\n",
      "epoch:13 step:10752 [D loss: 0.581473, acc: 68.75%] [G loss: 2.296814]\n",
      "epoch:13 step:10753 [D loss: 0.657581, acc: 60.94%] [G loss: 2.128729]\n",
      "epoch:13 step:10754 [D loss: 0.636445, acc: 66.41%] [G loss: 2.262088]\n",
      "epoch:13 step:10755 [D loss: 0.804078, acc: 40.62%] [G loss: 1.718078]\n",
      "epoch:13 step:10756 [D loss: 0.711523, acc: 58.59%] [G loss: 1.895065]\n",
      "epoch:13 step:10757 [D loss: 0.661113, acc: 62.50%] [G loss: 2.487247]\n",
      "epoch:13 step:10758 [D loss: 0.567710, acc: 73.44%] [G loss: 2.536071]\n",
      "epoch:13 step:10759 [D loss: 0.659940, acc: 60.16%] [G loss: 1.969260]\n",
      "epoch:13 step:10760 [D loss: 0.767854, acc: 48.44%] [G loss: 2.089620]\n",
      "epoch:13 step:10761 [D loss: 0.490739, acc: 83.59%] [G loss: 2.209146]\n",
      "epoch:13 step:10762 [D loss: 0.776375, acc: 39.84%] [G loss: 2.151595]\n",
      "epoch:13 step:10763 [D loss: 0.524652, acc: 79.69%] [G loss: 2.285427]\n",
      "epoch:13 step:10764 [D loss: 0.708036, acc: 50.78%] [G loss: 1.653968]\n",
      "epoch:13 step:10765 [D loss: 0.722310, acc: 55.47%] [G loss: 2.228714]\n",
      "epoch:13 step:10766 [D loss: 0.613442, acc: 66.41%] [G loss: 2.225437]\n",
      "epoch:13 step:10767 [D loss: 0.664690, acc: 58.59%] [G loss: 2.167477]\n",
      "epoch:13 step:10768 [D loss: 0.591372, acc: 74.22%] [G loss: 1.796360]\n",
      "epoch:13 step:10769 [D loss: 0.792809, acc: 50.78%] [G loss: 1.764444]\n",
      "epoch:13 step:10770 [D loss: 0.402998, acc: 87.50%] [G loss: 1.989538]\n",
      "epoch:13 step:10771 [D loss: 0.651738, acc: 58.59%] [G loss: 2.115131]\n",
      "epoch:13 step:10772 [D loss: 0.623789, acc: 64.84%] [G loss: 1.636795]\n",
      "epoch:13 step:10773 [D loss: 0.578344, acc: 70.31%] [G loss: 2.177402]\n",
      "epoch:13 step:10774 [D loss: 0.680047, acc: 54.69%] [G loss: 1.697877]\n",
      "epoch:13 step:10775 [D loss: 0.572592, acc: 71.09%] [G loss: 2.277579]\n",
      "epoch:13 step:10776 [D loss: 0.484448, acc: 82.03%] [G loss: 2.428011]\n",
      "epoch:13 step:10777 [D loss: 0.723739, acc: 49.22%] [G loss: 2.310524]\n",
      "epoch:13 step:10778 [D loss: 0.598071, acc: 66.41%] [G loss: 1.943316]\n",
      "epoch:13 step:10779 [D loss: 0.579367, acc: 74.22%] [G loss: 2.032042]\n",
      "epoch:13 step:10780 [D loss: 0.434474, acc: 85.16%] [G loss: 2.400464]\n",
      "epoch:13 step:10781 [D loss: 0.726366, acc: 57.81%] [G loss: 1.791181]\n",
      "epoch:13 step:10782 [D loss: 0.561589, acc: 75.00%] [G loss: 2.021737]\n",
      "epoch:13 step:10783 [D loss: 0.605618, acc: 68.75%] [G loss: 2.171478]\n",
      "epoch:13 step:10784 [D loss: 0.529993, acc: 73.44%] [G loss: 2.243312]\n",
      "epoch:13 step:10785 [D loss: 0.828748, acc: 46.09%] [G loss: 1.821550]\n",
      "epoch:13 step:10786 [D loss: 0.581011, acc: 75.00%] [G loss: 2.497773]\n",
      "epoch:13 step:10787 [D loss: 0.825189, acc: 39.06%] [G loss: 1.292956]\n",
      "epoch:13 step:10788 [D loss: 0.834201, acc: 43.75%] [G loss: 1.807461]\n",
      "epoch:13 step:10789 [D loss: 0.362147, acc: 86.72%] [G loss: 3.273000]\n",
      "epoch:13 step:10790 [D loss: 0.582201, acc: 71.88%] [G loss: 2.327444]\n",
      "epoch:13 step:10791 [D loss: 0.778923, acc: 50.78%] [G loss: 1.987249]\n",
      "epoch:13 step:10792 [D loss: 0.779337, acc: 47.66%] [G loss: 1.976543]\n",
      "epoch:13 step:10793 [D loss: 0.638976, acc: 60.16%] [G loss: 2.094630]\n",
      "epoch:13 step:10794 [D loss: 0.629847, acc: 64.06%] [G loss: 2.420963]\n",
      "epoch:13 step:10795 [D loss: 0.565211, acc: 72.66%] [G loss: 2.073473]\n",
      "epoch:13 step:10796 [D loss: 0.602040, acc: 65.62%] [G loss: 2.201784]\n",
      "epoch:13 step:10797 [D loss: 0.458790, acc: 91.41%] [G loss: 2.305151]\n",
      "epoch:13 step:10798 [D loss: 0.924923, acc: 25.78%] [G loss: 1.474460]\n",
      "epoch:13 step:10799 [D loss: 0.672386, acc: 58.59%] [G loss: 2.057212]\n",
      "epoch:13 step:10800 [D loss: 0.668688, acc: 58.59%] [G loss: 2.408094]\n",
      "epoch:13 step:10801 [D loss: 0.786309, acc: 46.09%] [G loss: 2.090004]\n",
      "epoch:13 step:10802 [D loss: 0.692828, acc: 57.81%] [G loss: 2.244227]\n",
      "epoch:13 step:10803 [D loss: 0.744557, acc: 52.34%] [G loss: 2.068021]\n",
      "epoch:13 step:10804 [D loss: 0.527201, acc: 80.47%] [G loss: 2.899150]\n",
      "epoch:13 step:10805 [D loss: 0.715967, acc: 52.34%] [G loss: 1.765854]\n",
      "epoch:13 step:10806 [D loss: 0.352517, acc: 92.97%] [G loss: 2.795249]\n",
      "epoch:13 step:10807 [D loss: 0.359649, acc: 96.09%] [G loss: 2.375179]\n",
      "epoch:13 step:10808 [D loss: 0.506561, acc: 81.25%] [G loss: 2.128955]\n",
      "epoch:13 step:10809 [D loss: 1.153119, acc: 14.84%] [G loss: 1.347178]\n",
      "epoch:13 step:10810 [D loss: 0.588201, acc: 69.53%] [G loss: 2.903214]\n",
      "epoch:13 step:10811 [D loss: 0.653088, acc: 64.84%] [G loss: 1.827389]\n",
      "epoch:13 step:10812 [D loss: 0.433097, acc: 82.03%] [G loss: 2.406904]\n",
      "epoch:13 step:10813 [D loss: 0.802480, acc: 39.06%] [G loss: 1.943434]\n",
      "epoch:13 step:10814 [D loss: 0.548195, acc: 78.12%] [G loss: 2.154739]\n",
      "epoch:13 step:10815 [D loss: 0.514872, acc: 77.34%] [G loss: 2.328490]\n",
      "epoch:13 step:10816 [D loss: 0.645139, acc: 63.28%] [G loss: 2.052857]\n",
      "epoch:13 step:10817 [D loss: 0.447664, acc: 88.28%] [G loss: 2.733159]\n",
      "epoch:13 step:10818 [D loss: 0.539287, acc: 73.44%] [G loss: 2.197354]\n",
      "epoch:13 step:10819 [D loss: 0.508441, acc: 78.91%] [G loss: 2.012846]\n",
      "epoch:13 step:10820 [D loss: 0.505756, acc: 70.31%] [G loss: 1.911507]\n",
      "epoch:13 step:10821 [D loss: 0.680690, acc: 58.59%] [G loss: 1.946939]\n",
      "epoch:13 step:10822 [D loss: 0.576605, acc: 65.62%] [G loss: 2.777272]\n",
      "epoch:13 step:10823 [D loss: 0.866253, acc: 43.75%] [G loss: 1.706006]\n",
      "epoch:13 step:10824 [D loss: 0.532602, acc: 71.09%] [G loss: 1.883244]\n",
      "epoch:13 step:10825 [D loss: 0.829443, acc: 35.94%] [G loss: 1.825232]\n",
      "epoch:13 step:10826 [D loss: 0.763460, acc: 44.53%] [G loss: 1.920221]\n",
      "epoch:13 step:10827 [D loss: 0.561738, acc: 75.78%] [G loss: 1.899659]\n",
      "epoch:13 step:10828 [D loss: 0.630740, acc: 64.06%] [G loss: 1.875806]\n",
      "epoch:13 step:10829 [D loss: 0.998137, acc: 25.00%] [G loss: 1.962054]\n",
      "epoch:13 step:10830 [D loss: 0.500303, acc: 82.81%] [G loss: 2.047209]\n",
      "epoch:13 step:10831 [D loss: 0.523647, acc: 80.47%] [G loss: 2.294710]\n",
      "epoch:13 step:10832 [D loss: 0.404362, acc: 90.62%] [G loss: 2.074361]\n",
      "epoch:13 step:10833 [D loss: 0.409692, acc: 91.41%] [G loss: 1.832420]\n",
      "epoch:13 step:10834 [D loss: 0.322099, acc: 98.44%] [G loss: 2.351916]\n",
      "epoch:13 step:10835 [D loss: 0.877925, acc: 43.75%] [G loss: 1.200921]\n",
      "epoch:13 step:10836 [D loss: 0.665854, acc: 61.72%] [G loss: 2.079211]\n",
      "epoch:13 step:10837 [D loss: 0.705761, acc: 58.59%] [G loss: 1.944319]\n",
      "epoch:13 step:10838 [D loss: 0.587988, acc: 68.75%] [G loss: 2.052526]\n",
      "epoch:13 step:10839 [D loss: 0.934128, acc: 27.34%] [G loss: 2.332238]\n",
      "epoch:13 step:10840 [D loss: 0.639364, acc: 60.94%] [G loss: 1.752604]\n",
      "epoch:13 step:10841 [D loss: 0.480041, acc: 83.59%] [G loss: 2.018367]\n",
      "epoch:13 step:10842 [D loss: 0.506032, acc: 78.12%] [G loss: 2.098771]\n",
      "epoch:13 step:10843 [D loss: 0.578618, acc: 67.19%] [G loss: 1.825872]\n",
      "epoch:13 step:10844 [D loss: 0.593471, acc: 69.53%] [G loss: 1.741883]\n",
      "epoch:13 step:10845 [D loss: 1.124393, acc: 15.62%] [G loss: 1.635707]\n",
      "epoch:13 step:10846 [D loss: 0.574383, acc: 66.41%] [G loss: 2.188890]\n",
      "epoch:13 step:10847 [D loss: 0.584540, acc: 73.44%] [G loss: 2.621930]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10848 [D loss: 0.394416, acc: 83.59%] [G loss: 2.622819]\n",
      "epoch:13 step:10849 [D loss: 0.713630, acc: 52.34%] [G loss: 1.917606]\n",
      "epoch:13 step:10850 [D loss: 0.692969, acc: 56.25%] [G loss: 1.993038]\n",
      "epoch:13 step:10851 [D loss: 0.524521, acc: 77.34%] [G loss: 1.956852]\n",
      "epoch:13 step:10852 [D loss: 0.607831, acc: 65.62%] [G loss: 2.235440]\n",
      "epoch:13 step:10853 [D loss: 0.616692, acc: 65.62%] [G loss: 1.860015]\n",
      "epoch:13 step:10854 [D loss: 0.594686, acc: 64.06%] [G loss: 2.448381]\n",
      "epoch:13 step:10855 [D loss: 0.643437, acc: 64.84%] [G loss: 1.809517]\n",
      "epoch:13 step:10856 [D loss: 0.536822, acc: 78.12%] [G loss: 2.369421]\n",
      "epoch:13 step:10857 [D loss: 1.021037, acc: 23.44%] [G loss: 2.007530]\n",
      "epoch:13 step:10858 [D loss: 0.540395, acc: 69.53%] [G loss: 2.136888]\n",
      "epoch:13 step:10859 [D loss: 0.638914, acc: 60.94%] [G loss: 2.016308]\n",
      "epoch:13 step:10860 [D loss: 0.743705, acc: 50.78%] [G loss: 2.243640]\n",
      "epoch:13 step:10861 [D loss: 0.661539, acc: 60.16%] [G loss: 2.187856]\n",
      "epoch:13 step:10862 [D loss: 0.612482, acc: 64.84%] [G loss: 2.043259]\n",
      "epoch:13 step:10863 [D loss: 0.577601, acc: 69.53%] [G loss: 2.255914]\n",
      "epoch:13 step:10864 [D loss: 0.488610, acc: 84.38%] [G loss: 2.155591]\n",
      "epoch:13 step:10865 [D loss: 0.650432, acc: 63.28%] [G loss: 2.134997]\n",
      "epoch:13 step:10866 [D loss: 0.579916, acc: 70.31%] [G loss: 2.364912]\n",
      "epoch:13 step:10867 [D loss: 0.351206, acc: 89.06%] [G loss: 2.260568]\n",
      "epoch:13 step:10868 [D loss: 0.543687, acc: 77.34%] [G loss: 2.267441]\n",
      "epoch:13 step:10869 [D loss: 0.290995, acc: 96.09%] [G loss: 2.182425]\n",
      "epoch:13 step:10870 [D loss: 0.406460, acc: 89.06%] [G loss: 2.154372]\n",
      "epoch:13 step:10871 [D loss: 0.492159, acc: 83.59%] [G loss: 2.018599]\n",
      "epoch:13 step:10872 [D loss: 0.327117, acc: 96.09%] [G loss: 2.217160]\n",
      "epoch:13 step:10873 [D loss: 0.679059, acc: 58.59%] [G loss: 1.749617]\n",
      "epoch:13 step:10874 [D loss: 0.831603, acc: 39.06%] [G loss: 1.579999]\n",
      "epoch:13 step:10875 [D loss: 0.569418, acc: 67.19%] [G loss: 2.349538]\n",
      "epoch:13 step:10876 [D loss: 0.560487, acc: 74.22%] [G loss: 2.346422]\n",
      "epoch:13 step:10877 [D loss: 0.714072, acc: 58.59%] [G loss: 1.731300]\n",
      "epoch:13 step:10878 [D loss: 0.479991, acc: 83.59%] [G loss: 2.255949]\n",
      "epoch:13 step:10879 [D loss: 0.714265, acc: 49.22%] [G loss: 2.060628]\n",
      "epoch:13 step:10880 [D loss: 0.494208, acc: 75.78%] [G loss: 2.040348]\n",
      "epoch:13 step:10881 [D loss: 0.400713, acc: 92.19%] [G loss: 2.188462]\n",
      "epoch:13 step:10882 [D loss: 0.606234, acc: 67.97%] [G loss: 2.065758]\n",
      "epoch:13 step:10883 [D loss: 0.345292, acc: 92.97%] [G loss: 2.086665]\n",
      "epoch:13 step:10884 [D loss: 0.776361, acc: 48.44%] [G loss: 1.807019]\n",
      "epoch:13 step:10885 [D loss: 0.636523, acc: 64.84%] [G loss: 1.935096]\n",
      "epoch:13 step:10886 [D loss: 0.891883, acc: 34.38%] [G loss: 1.745888]\n",
      "epoch:13 step:10887 [D loss: 0.391959, acc: 91.41%] [G loss: 2.206695]\n",
      "epoch:13 step:10888 [D loss: 0.850948, acc: 51.56%] [G loss: 1.943584]\n",
      "epoch:13 step:10889 [D loss: 0.751781, acc: 51.56%] [G loss: 2.466604]\n",
      "epoch:13 step:10890 [D loss: 0.386705, acc: 87.50%] [G loss: 2.955692]\n",
      "epoch:13 step:10891 [D loss: 0.817905, acc: 43.75%] [G loss: 2.325835]\n",
      "epoch:13 step:10892 [D loss: 0.658197, acc: 60.94%] [G loss: 2.855042]\n",
      "epoch:13 step:10893 [D loss: 0.768562, acc: 53.91%] [G loss: 2.316243]\n",
      "epoch:13 step:10894 [D loss: 0.541588, acc: 72.66%] [G loss: 2.759574]\n",
      "epoch:13 step:10895 [D loss: 0.808068, acc: 36.72%] [G loss: 1.878368]\n",
      "epoch:13 step:10896 [D loss: 0.474429, acc: 82.81%] [G loss: 2.368189]\n",
      "epoch:13 step:10897 [D loss: 0.389476, acc: 91.41%] [G loss: 2.236230]\n",
      "epoch:13 step:10898 [D loss: 0.653981, acc: 60.16%] [G loss: 2.138853]\n",
      "epoch:13 step:10899 [D loss: 0.408753, acc: 92.97%] [G loss: 2.241102]\n",
      "epoch:13 step:10900 [D loss: 0.885765, acc: 34.38%] [G loss: 2.271849]\n",
      "epoch:13 step:10901 [D loss: 0.500531, acc: 78.91%] [G loss: 2.464588]\n",
      "epoch:13 step:10902 [D loss: 0.572975, acc: 57.81%] [G loss: 2.380289]\n",
      "epoch:13 step:10903 [D loss: 0.507515, acc: 75.78%] [G loss: 1.949017]\n",
      "epoch:13 step:10904 [D loss: 0.882607, acc: 44.53%] [G loss: 2.167054]\n",
      "epoch:13 step:10905 [D loss: 0.464151, acc: 84.38%] [G loss: 1.842155]\n",
      "epoch:13 step:10906 [D loss: 0.683949, acc: 57.03%] [G loss: 2.587334]\n",
      "epoch:13 step:10907 [D loss: 0.628933, acc: 66.41%] [G loss: 2.741945]\n",
      "epoch:13 step:10908 [D loss: 0.575620, acc: 70.31%] [G loss: 2.182036]\n",
      "epoch:13 step:10909 [D loss: 0.412205, acc: 85.94%] [G loss: 1.898415]\n",
      "epoch:13 step:10910 [D loss: 0.390284, acc: 77.34%] [G loss: 2.016670]\n",
      "epoch:13 step:10911 [D loss: 0.762201, acc: 51.56%] [G loss: 2.266691]\n",
      "epoch:13 step:10912 [D loss: 0.688937, acc: 56.25%] [G loss: 1.973205]\n",
      "epoch:13 step:10913 [D loss: 0.436977, acc: 87.50%] [G loss: 1.805006]\n",
      "epoch:13 step:10914 [D loss: 0.570196, acc: 67.97%] [G loss: 2.691463]\n",
      "epoch:13 step:10915 [D loss: 0.863172, acc: 30.47%] [G loss: 1.775659]\n",
      "epoch:13 step:10916 [D loss: 0.686305, acc: 54.69%] [G loss: 2.754418]\n",
      "epoch:13 step:10917 [D loss: 0.527119, acc: 78.12%] [G loss: 2.497035]\n",
      "epoch:13 step:10918 [D loss: 1.028006, acc: 18.75%] [G loss: 2.123251]\n",
      "epoch:13 step:10919 [D loss: 0.552145, acc: 68.75%] [G loss: 2.233303]\n",
      "epoch:13 step:10920 [D loss: 0.753669, acc: 54.69%] [G loss: 1.708469]\n",
      "epoch:13 step:10921 [D loss: 0.577746, acc: 71.88%] [G loss: 2.560864]\n",
      "epoch:13 step:10922 [D loss: 0.723213, acc: 49.22%] [G loss: 2.226362]\n",
      "epoch:13 step:10923 [D loss: 0.382467, acc: 79.69%] [G loss: 2.841024]\n",
      "epoch:13 step:10924 [D loss: 0.715401, acc: 57.81%] [G loss: 2.104245]\n",
      "epoch:13 step:10925 [D loss: 0.545372, acc: 74.22%] [G loss: 2.841731]\n",
      "epoch:13 step:10926 [D loss: 0.428974, acc: 89.06%] [G loss: 2.605806]\n",
      "epoch:13 step:10927 [D loss: 0.689175, acc: 57.81%] [G loss: 2.142550]\n",
      "epoch:13 step:10928 [D loss: 0.748683, acc: 43.75%] [G loss: 2.201972]\n",
      "epoch:13 step:10929 [D loss: 0.603090, acc: 70.31%] [G loss: 2.512441]\n",
      "epoch:13 step:10930 [D loss: 0.624868, acc: 63.28%] [G loss: 1.857924]\n",
      "epoch:13 step:10931 [D loss: 0.774764, acc: 43.75%] [G loss: 2.181482]\n",
      "epoch:13 step:10932 [D loss: 0.872193, acc: 31.25%] [G loss: 2.157027]\n",
      "epoch:13 step:10933 [D loss: 0.754081, acc: 50.78%] [G loss: 2.320940]\n",
      "epoch:13 step:10934 [D loss: 0.688676, acc: 59.38%] [G loss: 2.562600]\n",
      "epoch:14 step:10935 [D loss: 0.627238, acc: 63.28%] [G loss: 2.032399]\n",
      "epoch:14 step:10936 [D loss: 0.351674, acc: 82.03%] [G loss: 3.460649]\n",
      "epoch:14 step:10937 [D loss: 0.555676, acc: 73.44%] [G loss: 2.062224]\n",
      "epoch:14 step:10938 [D loss: 0.630698, acc: 57.03%] [G loss: 1.691666]\n",
      "epoch:14 step:10939 [D loss: 0.650597, acc: 63.28%] [G loss: 2.000518]\n",
      "epoch:14 step:10940 [D loss: 0.494267, acc: 85.94%] [G loss: 2.285691]\n",
      "epoch:14 step:10941 [D loss: 0.650109, acc: 60.16%] [G loss: 2.137520]\n",
      "epoch:14 step:10942 [D loss: 0.652691, acc: 64.84%] [G loss: 2.302550]\n",
      "epoch:14 step:10943 [D loss: 0.497016, acc: 71.88%] [G loss: 2.353486]\n",
      "epoch:14 step:10944 [D loss: 0.649451, acc: 65.62%] [G loss: 2.158718]\n",
      "epoch:14 step:10945 [D loss: 0.543018, acc: 71.88%] [G loss: 2.093382]\n",
      "epoch:14 step:10946 [D loss: 0.745356, acc: 55.47%] [G loss: 1.803788]\n",
      "epoch:14 step:10947 [D loss: 0.774228, acc: 46.88%] [G loss: 1.849612]\n",
      "epoch:14 step:10948 [D loss: 0.601772, acc: 65.62%] [G loss: 2.126550]\n",
      "epoch:14 step:10949 [D loss: 0.924995, acc: 49.22%] [G loss: 1.782589]\n",
      "epoch:14 step:10950 [D loss: 0.809412, acc: 44.53%] [G loss: 1.678138]\n",
      "epoch:14 step:10951 [D loss: 0.423500, acc: 87.50%] [G loss: 2.609921]\n",
      "epoch:14 step:10952 [D loss: 0.611265, acc: 68.75%] [G loss: 1.992288]\n",
      "epoch:14 step:10953 [D loss: 0.585703, acc: 74.22%] [G loss: 2.308696]\n",
      "epoch:14 step:10954 [D loss: 0.675738, acc: 57.81%] [G loss: 2.075044]\n",
      "epoch:14 step:10955 [D loss: 0.755149, acc: 48.44%] [G loss: 1.969576]\n",
      "epoch:14 step:10956 [D loss: 0.760584, acc: 50.78%] [G loss: 2.146526]\n",
      "epoch:14 step:10957 [D loss: 0.520505, acc: 80.47%] [G loss: 2.514752]\n",
      "epoch:14 step:10958 [D loss: 0.530867, acc: 78.12%] [G loss: 2.299322]\n",
      "epoch:14 step:10959 [D loss: 0.439932, acc: 82.81%] [G loss: 2.661841]\n",
      "epoch:14 step:10960 [D loss: 0.724448, acc: 50.78%] [G loss: 1.955390]\n",
      "epoch:14 step:10961 [D loss: 0.685197, acc: 58.59%] [G loss: 2.256161]\n",
      "epoch:14 step:10962 [D loss: 0.531870, acc: 75.78%] [G loss: 2.130000]\n",
      "epoch:14 step:10963 [D loss: 0.691594, acc: 56.25%] [G loss: 2.161851]\n",
      "epoch:14 step:10964 [D loss: 0.585693, acc: 72.66%] [G loss: 2.062277]\n",
      "epoch:14 step:10965 [D loss: 0.739903, acc: 54.69%] [G loss: 1.960215]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:10966 [D loss: 0.710263, acc: 52.34%] [G loss: 2.141068]\n",
      "epoch:14 step:10967 [D loss: 0.545462, acc: 75.78%] [G loss: 2.460370]\n",
      "epoch:14 step:10968 [D loss: 0.677381, acc: 57.03%] [G loss: 2.115200]\n",
      "epoch:14 step:10969 [D loss: 0.436880, acc: 76.56%] [G loss: 3.465271]\n",
      "epoch:14 step:10970 [D loss: 0.775179, acc: 53.91%] [G loss: 2.527810]\n",
      "epoch:14 step:10971 [D loss: 0.692935, acc: 60.16%] [G loss: 1.982615]\n",
      "epoch:14 step:10972 [D loss: 0.856503, acc: 28.91%] [G loss: 1.788922]\n",
      "epoch:14 step:10973 [D loss: 0.671490, acc: 55.47%] [G loss: 2.012037]\n",
      "epoch:14 step:10974 [D loss: 0.674904, acc: 58.59%] [G loss: 1.872495]\n",
      "epoch:14 step:10975 [D loss: 0.780686, acc: 48.44%] [G loss: 1.849444]\n",
      "epoch:14 step:10976 [D loss: 0.698721, acc: 53.12%] [G loss: 1.903170]\n",
      "epoch:14 step:10977 [D loss: 0.470282, acc: 76.56%] [G loss: 2.515820]\n",
      "epoch:14 step:10978 [D loss: 0.757711, acc: 46.09%] [G loss: 1.847301]\n",
      "epoch:14 step:10979 [D loss: 0.751504, acc: 46.09%] [G loss: 1.824890]\n",
      "epoch:14 step:10980 [D loss: 0.632508, acc: 66.41%] [G loss: 1.949811]\n",
      "epoch:14 step:10981 [D loss: 0.672208, acc: 57.03%] [G loss: 2.297364]\n",
      "epoch:14 step:10982 [D loss: 0.755697, acc: 52.34%] [G loss: 1.964417]\n",
      "epoch:14 step:10983 [D loss: 0.696727, acc: 53.91%] [G loss: 2.010900]\n",
      "epoch:14 step:10984 [D loss: 0.464657, acc: 89.06%] [G loss: 1.800663]\n",
      "epoch:14 step:10985 [D loss: 0.730847, acc: 52.34%] [G loss: 2.067530]\n",
      "epoch:14 step:10986 [D loss: 0.536203, acc: 75.78%] [G loss: 2.157063]\n",
      "epoch:14 step:10987 [D loss: 0.718763, acc: 50.78%] [G loss: 1.549065]\n",
      "epoch:14 step:10988 [D loss: 0.813311, acc: 45.31%] [G loss: 2.517486]\n",
      "epoch:14 step:10989 [D loss: 0.602640, acc: 63.28%] [G loss: 2.168903]\n",
      "epoch:14 step:10990 [D loss: 0.819134, acc: 47.66%] [G loss: 1.718037]\n",
      "epoch:14 step:10991 [D loss: 0.834024, acc: 43.75%] [G loss: 1.773745]\n",
      "epoch:14 step:10992 [D loss: 0.600411, acc: 68.75%] [G loss: 2.107476]\n",
      "epoch:14 step:10993 [D loss: 0.514796, acc: 79.69%] [G loss: 2.160897]\n",
      "epoch:14 step:10994 [D loss: 0.755368, acc: 39.84%] [G loss: 1.710300]\n",
      "epoch:14 step:10995 [D loss: 0.713376, acc: 53.91%] [G loss: 2.467899]\n",
      "epoch:14 step:10996 [D loss: 0.613676, acc: 71.09%] [G loss: 2.165574]\n",
      "epoch:14 step:10997 [D loss: 0.503895, acc: 78.91%] [G loss: 2.603131]\n",
      "epoch:14 step:10998 [D loss: 0.597939, acc: 70.31%] [G loss: 2.259713]\n",
      "epoch:14 step:10999 [D loss: 0.717408, acc: 53.91%] [G loss: 2.499224]\n",
      "epoch:14 step:11000 [D loss: 0.645881, acc: 65.62%] [G loss: 2.038691]\n",
      "epoch:14 step:11001 [D loss: 0.500761, acc: 85.94%] [G loss: 2.431680]\n",
      "epoch:14 step:11002 [D loss: 0.679732, acc: 66.41%] [G loss: 2.344753]\n",
      "epoch:14 step:11003 [D loss: 0.437941, acc: 90.62%] [G loss: 2.711345]\n",
      "epoch:14 step:11004 [D loss: 0.452234, acc: 83.59%] [G loss: 2.248040]\n",
      "epoch:14 step:11005 [D loss: 1.143164, acc: 12.50%] [G loss: 1.698205]\n",
      "epoch:14 step:11006 [D loss: 0.621491, acc: 64.84%] [G loss: 2.020395]\n",
      "epoch:14 step:11007 [D loss: 0.729727, acc: 53.12%] [G loss: 1.750604]\n",
      "epoch:14 step:11008 [D loss: 0.503969, acc: 79.69%] [G loss: 1.950462]\n",
      "epoch:14 step:11009 [D loss: 0.636255, acc: 58.59%] [G loss: 2.175932]\n",
      "epoch:14 step:11010 [D loss: 0.631074, acc: 62.50%] [G loss: 2.073412]\n",
      "epoch:14 step:11011 [D loss: 0.777309, acc: 42.97%] [G loss: 2.010018]\n",
      "epoch:14 step:11012 [D loss: 0.707759, acc: 51.56%] [G loss: 2.111816]\n",
      "epoch:14 step:11013 [D loss: 0.507915, acc: 85.16%] [G loss: 1.760122]\n",
      "epoch:14 step:11014 [D loss: 0.536259, acc: 77.34%] [G loss: 2.275199]\n",
      "epoch:14 step:11015 [D loss: 0.543957, acc: 76.56%] [G loss: 1.945956]\n",
      "epoch:14 step:11016 [D loss: 0.671896, acc: 56.25%] [G loss: 2.385885]\n",
      "epoch:14 step:11017 [D loss: 0.458430, acc: 85.94%] [G loss: 2.328114]\n",
      "epoch:14 step:11018 [D loss: 0.754545, acc: 44.53%] [G loss: 1.876470]\n",
      "epoch:14 step:11019 [D loss: 0.708263, acc: 54.69%] [G loss: 1.808064]\n",
      "epoch:14 step:11020 [D loss: 0.637751, acc: 64.84%] [G loss: 1.881644]\n",
      "epoch:14 step:11021 [D loss: 0.727400, acc: 47.66%] [G loss: 1.916302]\n",
      "epoch:14 step:11022 [D loss: 0.861041, acc: 39.06%] [G loss: 1.915798]\n",
      "epoch:14 step:11023 [D loss: 0.502506, acc: 77.34%] [G loss: 2.362136]\n",
      "epoch:14 step:11024 [D loss: 0.538766, acc: 75.00%] [G loss: 2.769851]\n",
      "epoch:14 step:11025 [D loss: 0.571817, acc: 71.09%] [G loss: 2.157990]\n",
      "epoch:14 step:11026 [D loss: 0.737867, acc: 52.34%] [G loss: 2.132254]\n",
      "epoch:14 step:11027 [D loss: 0.694429, acc: 57.03%] [G loss: 1.697229]\n",
      "epoch:14 step:11028 [D loss: 0.617352, acc: 67.19%] [G loss: 1.969608]\n",
      "epoch:14 step:11029 [D loss: 0.588272, acc: 72.66%] [G loss: 2.234196]\n",
      "epoch:14 step:11030 [D loss: 0.583439, acc: 71.88%] [G loss: 2.224881]\n",
      "epoch:14 step:11031 [D loss: 0.721337, acc: 56.25%] [G loss: 1.862689]\n",
      "epoch:14 step:11032 [D loss: 0.743009, acc: 50.78%] [G loss: 2.160975]\n",
      "epoch:14 step:11033 [D loss: 0.513877, acc: 80.47%] [G loss: 2.616169]\n",
      "epoch:14 step:11034 [D loss: 0.651990, acc: 65.62%] [G loss: 2.097252]\n",
      "epoch:14 step:11035 [D loss: 0.526537, acc: 79.69%] [G loss: 1.931421]\n",
      "epoch:14 step:11036 [D loss: 0.626406, acc: 64.06%] [G loss: 2.068597]\n",
      "epoch:14 step:11037 [D loss: 0.611317, acc: 65.62%] [G loss: 2.080169]\n",
      "epoch:14 step:11038 [D loss: 0.761222, acc: 52.34%] [G loss: 2.291522]\n",
      "epoch:14 step:11039 [D loss: 0.611900, acc: 60.16%] [G loss: 1.818087]\n",
      "epoch:14 step:11040 [D loss: 0.593707, acc: 68.75%] [G loss: 1.966499]\n",
      "epoch:14 step:11041 [D loss: 0.659596, acc: 60.16%] [G loss: 1.921275]\n",
      "epoch:14 step:11042 [D loss: 0.683300, acc: 57.03%] [G loss: 2.250519]\n",
      "epoch:14 step:11043 [D loss: 0.634720, acc: 66.41%] [G loss: 1.933063]\n",
      "epoch:14 step:11044 [D loss: 0.378698, acc: 92.97%] [G loss: 2.662807]\n",
      "epoch:14 step:11045 [D loss: 0.597349, acc: 66.41%] [G loss: 2.224454]\n",
      "epoch:14 step:11046 [D loss: 0.737819, acc: 51.56%] [G loss: 2.104228]\n",
      "epoch:14 step:11047 [D loss: 0.702272, acc: 54.69%] [G loss: 1.729277]\n",
      "epoch:14 step:11048 [D loss: 0.475198, acc: 83.59%] [G loss: 2.373771]\n",
      "epoch:14 step:11049 [D loss: 0.778202, acc: 46.88%] [G loss: 1.742607]\n",
      "epoch:14 step:11050 [D loss: 0.656601, acc: 69.53%] [G loss: 2.157163]\n",
      "epoch:14 step:11051 [D loss: 0.689378, acc: 58.59%] [G loss: 1.876804]\n",
      "epoch:14 step:11052 [D loss: 0.608445, acc: 71.88%] [G loss: 2.263832]\n",
      "epoch:14 step:11053 [D loss: 0.626193, acc: 66.41%] [G loss: 2.033657]\n",
      "epoch:14 step:11054 [D loss: 0.485970, acc: 86.72%] [G loss: 2.069547]\n",
      "epoch:14 step:11055 [D loss: 0.571861, acc: 71.09%] [G loss: 1.899186]\n",
      "epoch:14 step:11056 [D loss: 0.385937, acc: 93.75%] [G loss: 2.910611]\n",
      "epoch:14 step:11057 [D loss: 0.633557, acc: 60.94%] [G loss: 2.291070]\n",
      "epoch:14 step:11058 [D loss: 0.610972, acc: 66.41%] [G loss: 1.868698]\n",
      "epoch:14 step:11059 [D loss: 0.850234, acc: 35.94%] [G loss: 1.586691]\n",
      "epoch:14 step:11060 [D loss: 0.555826, acc: 70.31%] [G loss: 1.856002]\n",
      "epoch:14 step:11061 [D loss: 0.533686, acc: 75.00%] [G loss: 2.464187]\n",
      "epoch:14 step:11062 [D loss: 0.653023, acc: 58.59%] [G loss: 2.191178]\n",
      "epoch:14 step:11063 [D loss: 0.605241, acc: 67.97%] [G loss: 2.145105]\n",
      "epoch:14 step:11064 [D loss: 0.701374, acc: 53.12%] [G loss: 2.296835]\n",
      "epoch:14 step:11065 [D loss: 0.694506, acc: 56.25%] [G loss: 2.262167]\n",
      "epoch:14 step:11066 [D loss: 0.362282, acc: 93.75%] [G loss: 2.454690]\n",
      "epoch:14 step:11067 [D loss: 0.458869, acc: 79.69%] [G loss: 2.826736]\n",
      "epoch:14 step:11068 [D loss: 0.498651, acc: 72.66%] [G loss: 2.497568]\n",
      "epoch:14 step:11069 [D loss: 0.719079, acc: 50.78%] [G loss: 2.212589]\n",
      "epoch:14 step:11070 [D loss: 0.447428, acc: 87.50%] [G loss: 2.524962]\n",
      "epoch:14 step:11071 [D loss: 0.682607, acc: 58.59%] [G loss: 1.991448]\n",
      "epoch:14 step:11072 [D loss: 0.276234, acc: 94.53%] [G loss: 3.287081]\n",
      "epoch:14 step:11073 [D loss: 0.353421, acc: 95.31%] [G loss: 3.193599]\n",
      "epoch:14 step:11074 [D loss: 0.619993, acc: 57.03%] [G loss: 2.505089]\n",
      "epoch:14 step:11075 [D loss: 0.774184, acc: 46.88%] [G loss: 2.189183]\n",
      "epoch:14 step:11076 [D loss: 0.529848, acc: 75.00%] [G loss: 2.458019]\n",
      "epoch:14 step:11077 [D loss: 0.603991, acc: 64.84%] [G loss: 2.326234]\n",
      "epoch:14 step:11078 [D loss: 0.579187, acc: 69.53%] [G loss: 2.458417]\n",
      "epoch:14 step:11079 [D loss: 0.506720, acc: 79.69%] [G loss: 2.337136]\n",
      "epoch:14 step:11080 [D loss: 0.683427, acc: 59.38%] [G loss: 2.191622]\n",
      "epoch:14 step:11081 [D loss: 0.483083, acc: 82.03%] [G loss: 2.528067]\n",
      "epoch:14 step:11082 [D loss: 0.605862, acc: 70.31%] [G loss: 2.067270]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11083 [D loss: 0.753361, acc: 50.78%] [G loss: 1.878628]\n",
      "epoch:14 step:11084 [D loss: 0.727768, acc: 48.44%] [G loss: 1.915169]\n",
      "epoch:14 step:11085 [D loss: 0.491000, acc: 71.09%] [G loss: 3.014726]\n",
      "epoch:14 step:11086 [D loss: 0.596725, acc: 71.09%] [G loss: 2.213554]\n",
      "epoch:14 step:11087 [D loss: 0.743911, acc: 53.91%] [G loss: 2.021361]\n",
      "epoch:14 step:11088 [D loss: 0.523045, acc: 77.34%] [G loss: 2.409447]\n",
      "epoch:14 step:11089 [D loss: 0.449728, acc: 85.94%] [G loss: 2.203931]\n",
      "epoch:14 step:11090 [D loss: 0.504197, acc: 74.22%] [G loss: 2.000401]\n",
      "epoch:14 step:11091 [D loss: 0.602996, acc: 61.72%] [G loss: 2.180034]\n",
      "epoch:14 step:11092 [D loss: 0.471113, acc: 81.25%] [G loss: 2.751611]\n",
      "epoch:14 step:11093 [D loss: 0.353187, acc: 85.94%] [G loss: 3.419664]\n",
      "epoch:14 step:11094 [D loss: 0.838067, acc: 45.31%] [G loss: 1.905818]\n",
      "epoch:14 step:11095 [D loss: 0.656097, acc: 60.94%] [G loss: 2.111627]\n",
      "epoch:14 step:11096 [D loss: 0.467679, acc: 84.38%] [G loss: 2.293105]\n",
      "epoch:14 step:11097 [D loss: 0.762275, acc: 46.88%] [G loss: 2.192467]\n",
      "epoch:14 step:11098 [D loss: 0.544707, acc: 72.66%] [G loss: 2.057621]\n",
      "epoch:14 step:11099 [D loss: 0.803186, acc: 44.53%] [G loss: 2.022262]\n",
      "epoch:14 step:11100 [D loss: 0.623269, acc: 65.62%] [G loss: 1.724997]\n",
      "epoch:14 step:11101 [D loss: 0.641086, acc: 63.28%] [G loss: 1.976920]\n",
      "epoch:14 step:11102 [D loss: 0.702024, acc: 54.69%] [G loss: 2.423721]\n",
      "epoch:14 step:11103 [D loss: 0.472458, acc: 83.59%] [G loss: 2.027294]\n",
      "epoch:14 step:11104 [D loss: 0.604549, acc: 67.97%] [G loss: 2.493436]\n",
      "epoch:14 step:11105 [D loss: 0.682242, acc: 57.03%] [G loss: 1.739121]\n",
      "epoch:14 step:11106 [D loss: 0.415957, acc: 89.06%] [G loss: 3.037667]\n",
      "epoch:14 step:11107 [D loss: 1.186893, acc: 16.41%] [G loss: 1.830772]\n",
      "epoch:14 step:11108 [D loss: 0.403882, acc: 89.84%] [G loss: 2.733434]\n",
      "epoch:14 step:11109 [D loss: 0.577724, acc: 67.97%] [G loss: 2.414520]\n",
      "epoch:14 step:11110 [D loss: 0.876527, acc: 45.31%] [G loss: 2.278522]\n",
      "epoch:14 step:11111 [D loss: 0.531013, acc: 76.56%] [G loss: 2.114549]\n",
      "epoch:14 step:11112 [D loss: 0.730157, acc: 53.12%] [G loss: 2.117864]\n",
      "epoch:14 step:11113 [D loss: 0.535670, acc: 73.44%] [G loss: 2.064070]\n",
      "epoch:14 step:11114 [D loss: 0.585083, acc: 75.00%] [G loss: 2.279254]\n",
      "epoch:14 step:11115 [D loss: 0.706370, acc: 53.12%] [G loss: 2.100299]\n",
      "epoch:14 step:11116 [D loss: 0.550173, acc: 75.00%] [G loss: 2.018741]\n",
      "epoch:14 step:11117 [D loss: 0.761384, acc: 51.56%] [G loss: 1.998665]\n",
      "epoch:14 step:11118 [D loss: 0.681943, acc: 58.59%] [G loss: 2.255466]\n",
      "epoch:14 step:11119 [D loss: 0.738598, acc: 53.91%] [G loss: 2.000618]\n",
      "epoch:14 step:11120 [D loss: 0.827638, acc: 37.50%] [G loss: 1.672402]\n",
      "epoch:14 step:11121 [D loss: 0.435666, acc: 85.16%] [G loss: 2.553644]\n",
      "epoch:14 step:11122 [D loss: 0.415521, acc: 84.38%] [G loss: 2.646541]\n",
      "epoch:14 step:11123 [D loss: 0.327717, acc: 96.88%] [G loss: 2.595644]\n",
      "epoch:14 step:11124 [D loss: 0.393719, acc: 89.84%] [G loss: 1.925716]\n",
      "epoch:14 step:11125 [D loss: 0.466784, acc: 82.03%] [G loss: 2.865648]\n",
      "epoch:14 step:11126 [D loss: 0.618323, acc: 68.75%] [G loss: 1.771431]\n",
      "epoch:14 step:11127 [D loss: 0.630174, acc: 64.06%] [G loss: 1.794522]\n",
      "epoch:14 step:11128 [D loss: 0.469445, acc: 75.78%] [G loss: 1.514000]\n",
      "epoch:14 step:11129 [D loss: 0.914391, acc: 42.19%] [G loss: 1.607207]\n",
      "epoch:14 step:11130 [D loss: 1.116450, acc: 13.28%] [G loss: 1.214613]\n",
      "epoch:14 step:11131 [D loss: 0.778764, acc: 45.31%] [G loss: 1.939490]\n",
      "epoch:14 step:11132 [D loss: 0.568933, acc: 75.00%] [G loss: 2.204627]\n",
      "epoch:14 step:11133 [D loss: 0.688879, acc: 57.03%] [G loss: 1.833170]\n",
      "epoch:14 step:11134 [D loss: 0.430692, acc: 89.06%] [G loss: 2.238574]\n",
      "epoch:14 step:11135 [D loss: 0.546370, acc: 74.22%] [G loss: 2.189522]\n",
      "epoch:14 step:11136 [D loss: 0.978381, acc: 44.53%] [G loss: 1.276954]\n",
      "epoch:14 step:11137 [D loss: 0.626633, acc: 65.62%] [G loss: 2.022563]\n",
      "epoch:14 step:11138 [D loss: 0.681253, acc: 52.34%] [G loss: 1.409489]\n",
      "epoch:14 step:11139 [D loss: 0.788226, acc: 50.00%] [G loss: 1.643214]\n",
      "epoch:14 step:11140 [D loss: 0.851592, acc: 32.81%] [G loss: 2.070155]\n",
      "epoch:14 step:11141 [D loss: 0.658080, acc: 57.81%] [G loss: 2.003885]\n",
      "epoch:14 step:11142 [D loss: 0.618054, acc: 60.94%] [G loss: 2.289392]\n",
      "epoch:14 step:11143 [D loss: 0.516934, acc: 76.56%] [G loss: 2.308160]\n",
      "epoch:14 step:11144 [D loss: 0.460220, acc: 85.94%] [G loss: 2.653743]\n",
      "epoch:14 step:11145 [D loss: 0.640001, acc: 60.16%] [G loss: 2.008186]\n",
      "epoch:14 step:11146 [D loss: 0.695741, acc: 59.38%] [G loss: 1.876815]\n",
      "epoch:14 step:11147 [D loss: 0.514488, acc: 76.56%] [G loss: 1.929368]\n",
      "epoch:14 step:11148 [D loss: 0.308604, acc: 95.31%] [G loss: 3.115286]\n",
      "epoch:14 step:11149 [D loss: 0.640556, acc: 60.94%] [G loss: 2.081976]\n",
      "epoch:14 step:11150 [D loss: 0.431964, acc: 89.06%] [G loss: 2.361693]\n",
      "epoch:14 step:11151 [D loss: 0.656253, acc: 57.81%] [G loss: 2.371533]\n",
      "epoch:14 step:11152 [D loss: 0.576463, acc: 70.31%] [G loss: 2.468257]\n",
      "epoch:14 step:11153 [D loss: 0.334139, acc: 92.19%] [G loss: 2.742425]\n",
      "epoch:14 step:11154 [D loss: 0.643137, acc: 64.06%] [G loss: 2.418424]\n",
      "epoch:14 step:11155 [D loss: 0.680040, acc: 60.94%] [G loss: 1.938281]\n",
      "epoch:14 step:11156 [D loss: 0.534120, acc: 78.91%] [G loss: 2.513003]\n",
      "epoch:14 step:11157 [D loss: 0.452429, acc: 89.84%] [G loss: 2.291398]\n",
      "epoch:14 step:11158 [D loss: 0.461269, acc: 79.69%] [G loss: 2.394047]\n",
      "epoch:14 step:11159 [D loss: 0.666502, acc: 57.81%] [G loss: 1.961427]\n",
      "epoch:14 step:11160 [D loss: 0.822162, acc: 44.53%] [G loss: 1.976836]\n",
      "epoch:14 step:11161 [D loss: 0.640033, acc: 57.03%] [G loss: 2.062328]\n",
      "epoch:14 step:11162 [D loss: 0.561538, acc: 69.53%] [G loss: 2.314710]\n",
      "epoch:14 step:11163 [D loss: 0.558944, acc: 75.00%] [G loss: 1.713407]\n",
      "epoch:14 step:11164 [D loss: 0.770662, acc: 50.00%] [G loss: 1.898788]\n",
      "epoch:14 step:11165 [D loss: 0.529920, acc: 80.47%] [G loss: 2.154323]\n",
      "epoch:14 step:11166 [D loss: 0.434980, acc: 82.81%] [G loss: 2.007173]\n",
      "epoch:14 step:11167 [D loss: 0.187694, acc: 98.44%] [G loss: 2.792961]\n",
      "epoch:14 step:11168 [D loss: 0.785562, acc: 43.75%] [G loss: 2.136214]\n",
      "epoch:14 step:11169 [D loss: 0.658427, acc: 62.50%] [G loss: 1.805114]\n",
      "epoch:14 step:11170 [D loss: 0.869588, acc: 33.59%] [G loss: 1.836927]\n",
      "epoch:14 step:11171 [D loss: 0.619778, acc: 65.62%] [G loss: 1.933423]\n",
      "epoch:14 step:11172 [D loss: 0.566407, acc: 73.44%] [G loss: 2.218613]\n",
      "epoch:14 step:11173 [D loss: 0.611964, acc: 70.31%] [G loss: 2.073290]\n",
      "epoch:14 step:11174 [D loss: 1.174697, acc: 19.53%] [G loss: 1.762084]\n",
      "epoch:14 step:11175 [D loss: 0.483348, acc: 79.69%] [G loss: 2.167499]\n",
      "epoch:14 step:11176 [D loss: 0.621254, acc: 67.19%] [G loss: 2.254168]\n",
      "epoch:14 step:11177 [D loss: 0.674709, acc: 54.69%] [G loss: 2.145932]\n",
      "epoch:14 step:11178 [D loss: 0.527731, acc: 70.31%] [G loss: 2.712169]\n",
      "epoch:14 step:11179 [D loss: 0.863321, acc: 40.62%] [G loss: 1.596527]\n",
      "epoch:14 step:11180 [D loss: 0.618909, acc: 64.06%] [G loss: 2.068576]\n",
      "epoch:14 step:11181 [D loss: 0.820247, acc: 46.88%] [G loss: 2.026630]\n",
      "epoch:14 step:11182 [D loss: 0.676500, acc: 56.25%] [G loss: 2.233931]\n",
      "epoch:14 step:11183 [D loss: 0.603334, acc: 70.31%] [G loss: 2.217419]\n",
      "epoch:14 step:11184 [D loss: 0.574331, acc: 66.41%] [G loss: 2.419696]\n",
      "epoch:14 step:11185 [D loss: 0.665568, acc: 58.59%] [G loss: 2.264688]\n",
      "epoch:14 step:11186 [D loss: 0.509452, acc: 85.94%] [G loss: 2.635535]\n",
      "epoch:14 step:11187 [D loss: 0.539323, acc: 72.66%] [G loss: 2.369200]\n",
      "epoch:14 step:11188 [D loss: 0.513154, acc: 82.81%] [G loss: 2.462254]\n",
      "epoch:14 step:11189 [D loss: 0.550020, acc: 71.88%] [G loss: 2.169875]\n",
      "epoch:14 step:11190 [D loss: 0.624882, acc: 58.59%] [G loss: 1.983468]\n",
      "epoch:14 step:11191 [D loss: 0.594433, acc: 69.53%] [G loss: 2.105992]\n",
      "epoch:14 step:11192 [D loss: 0.701988, acc: 53.91%] [G loss: 1.917933]\n",
      "epoch:14 step:11193 [D loss: 0.750902, acc: 52.34%] [G loss: 1.611916]\n",
      "epoch:14 step:11194 [D loss: 0.316881, acc: 89.84%] [G loss: 2.557371]\n",
      "epoch:14 step:11195 [D loss: 0.437109, acc: 85.94%] [G loss: 2.920698]\n",
      "epoch:14 step:11196 [D loss: 0.365956, acc: 94.53%] [G loss: 2.335573]\n",
      "epoch:14 step:11197 [D loss: 0.422793, acc: 88.28%] [G loss: 2.104637]\n",
      "epoch:14 step:11198 [D loss: 0.657024, acc: 60.16%] [G loss: 2.218429]\n",
      "epoch:14 step:11199 [D loss: 0.389975, acc: 89.84%] [G loss: 2.375404]\n",
      "epoch:14 step:11200 [D loss: 0.515199, acc: 71.09%] [G loss: 2.513176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11201 [D loss: 1.366950, acc: 17.97%] [G loss: 1.115974]\n",
      "epoch:14 step:11202 [D loss: 0.886580, acc: 39.84%] [G loss: 2.003066]\n",
      "epoch:14 step:11203 [D loss: 0.514118, acc: 73.44%] [G loss: 1.835761]\n",
      "epoch:14 step:11204 [D loss: 0.626127, acc: 61.72%] [G loss: 2.276180]\n",
      "epoch:14 step:11205 [D loss: 0.544426, acc: 77.34%] [G loss: 1.967625]\n",
      "epoch:14 step:11206 [D loss: 0.761067, acc: 49.22%] [G loss: 1.922145]\n",
      "epoch:14 step:11207 [D loss: 0.600555, acc: 65.62%] [G loss: 2.447543]\n",
      "epoch:14 step:11208 [D loss: 0.842911, acc: 41.41%] [G loss: 1.675378]\n",
      "epoch:14 step:11209 [D loss: 0.798918, acc: 44.53%] [G loss: 1.881816]\n",
      "epoch:14 step:11210 [D loss: 0.472364, acc: 77.34%] [G loss: 2.090720]\n",
      "epoch:14 step:11211 [D loss: 0.590284, acc: 69.53%] [G loss: 2.170406]\n",
      "epoch:14 step:11212 [D loss: 0.709399, acc: 57.81%] [G loss: 2.852083]\n",
      "epoch:14 step:11213 [D loss: 0.679437, acc: 57.03%] [G loss: 2.581049]\n",
      "epoch:14 step:11214 [D loss: 0.730802, acc: 53.12%] [G loss: 2.025575]\n",
      "epoch:14 step:11215 [D loss: 0.610813, acc: 64.06%] [G loss: 1.885254]\n",
      "epoch:14 step:11216 [D loss: 0.532208, acc: 79.69%] [G loss: 2.205699]\n",
      "epoch:14 step:11217 [D loss: 0.480536, acc: 82.03%] [G loss: 2.062761]\n",
      "epoch:14 step:11218 [D loss: 0.457871, acc: 80.47%] [G loss: 2.725788]\n",
      "epoch:14 step:11219 [D loss: 0.485207, acc: 81.25%] [G loss: 2.039672]\n",
      "epoch:14 step:11220 [D loss: 0.632265, acc: 60.94%] [G loss: 1.963551]\n",
      "epoch:14 step:11221 [D loss: 0.599068, acc: 72.66%] [G loss: 1.956161]\n",
      "epoch:14 step:11222 [D loss: 0.581905, acc: 68.75%] [G loss: 2.178144]\n",
      "epoch:14 step:11223 [D loss: 0.503837, acc: 79.69%] [G loss: 2.453950]\n",
      "epoch:14 step:11224 [D loss: 0.731236, acc: 53.91%] [G loss: 2.035332]\n",
      "epoch:14 step:11225 [D loss: 0.646321, acc: 63.28%] [G loss: 2.134694]\n",
      "epoch:14 step:11226 [D loss: 0.609383, acc: 64.84%] [G loss: 2.117415]\n",
      "epoch:14 step:11227 [D loss: 0.628365, acc: 65.62%] [G loss: 1.902251]\n",
      "epoch:14 step:11228 [D loss: 0.556823, acc: 71.09%] [G loss: 2.465134]\n",
      "epoch:14 step:11229 [D loss: 0.523195, acc: 73.44%] [G loss: 2.211292]\n",
      "epoch:14 step:11230 [D loss: 0.531241, acc: 78.12%] [G loss: 2.283893]\n",
      "epoch:14 step:11231 [D loss: 0.817673, acc: 50.78%] [G loss: 2.325047]\n",
      "epoch:14 step:11232 [D loss: 0.650573, acc: 63.28%] [G loss: 2.261702]\n",
      "epoch:14 step:11233 [D loss: 0.591344, acc: 67.19%] [G loss: 2.721320]\n",
      "epoch:14 step:11234 [D loss: 0.705059, acc: 54.69%] [G loss: 2.636104]\n",
      "epoch:14 step:11235 [D loss: 0.583116, acc: 77.34%] [G loss: 2.008472]\n",
      "epoch:14 step:11236 [D loss: 0.244146, acc: 94.53%] [G loss: 2.587898]\n",
      "epoch:14 step:11237 [D loss: 0.814692, acc: 43.75%] [G loss: 2.138590]\n",
      "epoch:14 step:11238 [D loss: 0.524121, acc: 80.47%] [G loss: 2.181426]\n",
      "epoch:14 step:11239 [D loss: 0.742935, acc: 46.09%] [G loss: 1.936340]\n",
      "epoch:14 step:11240 [D loss: 0.644655, acc: 65.62%] [G loss: 1.880513]\n",
      "epoch:14 step:11241 [D loss: 0.643887, acc: 64.06%] [G loss: 1.916187]\n",
      "epoch:14 step:11242 [D loss: 0.674922, acc: 56.25%] [G loss: 1.894056]\n",
      "epoch:14 step:11243 [D loss: 0.435757, acc: 82.81%] [G loss: 1.837860]\n",
      "epoch:14 step:11244 [D loss: 0.521185, acc: 78.91%] [G loss: 2.470295]\n",
      "epoch:14 step:11245 [D loss: 0.513643, acc: 69.53%] [G loss: 1.809615]\n",
      "epoch:14 step:11246 [D loss: 0.727863, acc: 55.47%] [G loss: 2.439222]\n",
      "epoch:14 step:11247 [D loss: 0.850457, acc: 35.94%] [G loss: 1.577491]\n",
      "epoch:14 step:11248 [D loss: 0.371973, acc: 92.19%] [G loss: 2.474023]\n",
      "epoch:14 step:11249 [D loss: 1.289010, acc: 7.03%] [G loss: 1.534923]\n",
      "epoch:14 step:11250 [D loss: 0.609774, acc: 63.28%] [G loss: 1.789215]\n",
      "epoch:14 step:11251 [D loss: 0.648956, acc: 64.06%] [G loss: 1.843694]\n",
      "epoch:14 step:11252 [D loss: 0.702567, acc: 55.47%] [G loss: 1.870515]\n",
      "epoch:14 step:11253 [D loss: 0.826646, acc: 46.09%] [G loss: 2.095567]\n",
      "epoch:14 step:11254 [D loss: 0.536445, acc: 73.44%] [G loss: 2.102943]\n",
      "epoch:14 step:11255 [D loss: 0.814345, acc: 46.09%] [G loss: 1.976243]\n",
      "epoch:14 step:11256 [D loss: 0.692153, acc: 53.91%] [G loss: 2.003423]\n",
      "epoch:14 step:11257 [D loss: 0.362057, acc: 88.28%] [G loss: 2.136576]\n",
      "epoch:14 step:11258 [D loss: 0.678623, acc: 55.47%] [G loss: 2.219822]\n",
      "epoch:14 step:11259 [D loss: 0.634770, acc: 63.28%] [G loss: 1.976109]\n",
      "epoch:14 step:11260 [D loss: 0.666973, acc: 59.38%] [G loss: 1.966817]\n",
      "epoch:14 step:11261 [D loss: 0.631055, acc: 67.19%] [G loss: 2.352298]\n",
      "epoch:14 step:11262 [D loss: 0.561634, acc: 73.44%] [G loss: 2.337396]\n",
      "epoch:14 step:11263 [D loss: 0.566382, acc: 78.12%] [G loss: 2.011603]\n",
      "epoch:14 step:11264 [D loss: 0.552418, acc: 77.34%] [G loss: 2.069729]\n",
      "epoch:14 step:11265 [D loss: 0.505371, acc: 74.22%] [G loss: 2.032472]\n",
      "epoch:14 step:11266 [D loss: 0.608330, acc: 70.31%] [G loss: 2.223866]\n",
      "epoch:14 step:11267 [D loss: 0.594883, acc: 64.84%] [G loss: 2.184038]\n",
      "epoch:14 step:11268 [D loss: 0.405183, acc: 85.94%] [G loss: 2.508621]\n",
      "epoch:14 step:11269 [D loss: 0.658145, acc: 60.16%] [G loss: 2.156999]\n",
      "epoch:14 step:11270 [D loss: 0.888917, acc: 35.16%] [G loss: 1.689311]\n",
      "epoch:14 step:11271 [D loss: 0.663959, acc: 60.16%] [G loss: 1.737368]\n",
      "epoch:14 step:11272 [D loss: 0.914236, acc: 30.47%] [G loss: 1.655034]\n",
      "epoch:14 step:11273 [D loss: 0.616153, acc: 69.53%] [G loss: 1.677094]\n",
      "epoch:14 step:11274 [D loss: 0.588817, acc: 72.66%] [G loss: 2.227872]\n",
      "epoch:14 step:11275 [D loss: 0.663976, acc: 59.38%] [G loss: 2.254981]\n",
      "epoch:14 step:11276 [D loss: 0.528246, acc: 79.69%] [G loss: 2.001464]\n",
      "epoch:14 step:11277 [D loss: 0.402740, acc: 90.62%] [G loss: 2.741098]\n",
      "epoch:14 step:11278 [D loss: 0.597921, acc: 70.31%] [G loss: 1.600892]\n",
      "epoch:14 step:11279 [D loss: 0.608981, acc: 67.19%] [G loss: 1.660235]\n",
      "epoch:14 step:11280 [D loss: 0.303383, acc: 97.66%] [G loss: 2.301165]\n",
      "epoch:14 step:11281 [D loss: 0.428364, acc: 89.84%] [G loss: 2.626046]\n",
      "epoch:14 step:11282 [D loss: 0.566865, acc: 75.78%] [G loss: 1.930624]\n",
      "epoch:14 step:11283 [D loss: 0.385776, acc: 94.53%] [G loss: 2.342459]\n",
      "epoch:14 step:11284 [D loss: 0.489125, acc: 82.81%] [G loss: 2.639997]\n",
      "epoch:14 step:11285 [D loss: 0.604106, acc: 69.53%] [G loss: 1.850781]\n",
      "epoch:14 step:11286 [D loss: 0.530586, acc: 73.44%] [G loss: 2.174795]\n",
      "epoch:14 step:11287 [D loss: 0.419449, acc: 88.28%] [G loss: 2.559919]\n",
      "epoch:14 step:11288 [D loss: 0.888946, acc: 39.06%] [G loss: 1.725376]\n",
      "epoch:14 step:11289 [D loss: 0.508972, acc: 71.09%] [G loss: 1.851935]\n",
      "epoch:14 step:11290 [D loss: 0.894479, acc: 38.28%] [G loss: 2.017805]\n",
      "epoch:14 step:11291 [D loss: 0.422514, acc: 89.06%] [G loss: 1.933778]\n",
      "epoch:14 step:11292 [D loss: 0.613925, acc: 65.62%] [G loss: 2.360415]\n",
      "epoch:14 step:11293 [D loss: 0.703662, acc: 53.91%] [G loss: 1.617903]\n",
      "epoch:14 step:11294 [D loss: 0.983482, acc: 22.66%] [G loss: 1.667228]\n",
      "epoch:14 step:11295 [D loss: 0.921794, acc: 33.59%] [G loss: 1.730583]\n",
      "epoch:14 step:11296 [D loss: 0.619729, acc: 66.41%] [G loss: 1.616183]\n",
      "epoch:14 step:11297 [D loss: 0.578161, acc: 73.44%] [G loss: 2.560704]\n",
      "epoch:14 step:11298 [D loss: 0.674685, acc: 60.94%] [G loss: 2.059917]\n",
      "epoch:14 step:11299 [D loss: 0.790465, acc: 46.09%] [G loss: 2.020401]\n",
      "epoch:14 step:11300 [D loss: 0.599140, acc: 71.09%] [G loss: 2.404960]\n",
      "epoch:14 step:11301 [D loss: 0.670500, acc: 61.72%] [G loss: 2.018322]\n",
      "epoch:14 step:11302 [D loss: 0.525836, acc: 80.47%] [G loss: 2.089047]\n",
      "epoch:14 step:11303 [D loss: 0.582288, acc: 73.44%] [G loss: 2.092945]\n",
      "epoch:14 step:11304 [D loss: 0.457012, acc: 81.25%] [G loss: 2.148231]\n",
      "epoch:14 step:11305 [D loss: 0.651869, acc: 62.50%] [G loss: 2.391841]\n",
      "epoch:14 step:11306 [D loss: 0.749008, acc: 50.78%] [G loss: 2.915647]\n",
      "epoch:14 step:11307 [D loss: 1.164297, acc: 22.66%] [G loss: 2.101480]\n",
      "epoch:14 step:11308 [D loss: 0.616544, acc: 60.94%] [G loss: 2.438236]\n",
      "epoch:14 step:11309 [D loss: 0.578033, acc: 66.41%] [G loss: 2.187565]\n",
      "epoch:14 step:11310 [D loss: 0.774588, acc: 48.44%] [G loss: 2.020642]\n",
      "epoch:14 step:11311 [D loss: 0.653465, acc: 65.62%] [G loss: 2.228951]\n",
      "epoch:14 step:11312 [D loss: 0.760042, acc: 50.78%] [G loss: 1.556896]\n",
      "epoch:14 step:11313 [D loss: 0.632571, acc: 67.97%] [G loss: 2.745976]\n",
      "epoch:14 step:11314 [D loss: 0.727097, acc: 55.47%] [G loss: 2.012444]\n",
      "epoch:14 step:11315 [D loss: 0.585959, acc: 73.44%] [G loss: 2.044823]\n",
      "epoch:14 step:11316 [D loss: 0.521904, acc: 79.69%] [G loss: 2.293669]\n",
      "epoch:14 step:11317 [D loss: 0.730375, acc: 48.44%] [G loss: 2.027755]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11318 [D loss: 0.383370, acc: 78.91%] [G loss: 2.062294]\n",
      "epoch:14 step:11319 [D loss: 0.580116, acc: 73.44%] [G loss: 2.805892]\n",
      "epoch:14 step:11320 [D loss: 0.725351, acc: 53.12%] [G loss: 1.826943]\n",
      "epoch:14 step:11321 [D loss: 0.566347, acc: 75.78%] [G loss: 2.334843]\n",
      "epoch:14 step:11322 [D loss: 0.845717, acc: 38.28%] [G loss: 1.838247]\n",
      "epoch:14 step:11323 [D loss: 0.416628, acc: 89.84%] [G loss: 2.413409]\n",
      "epoch:14 step:11324 [D loss: 0.427631, acc: 90.62%] [G loss: 1.898475]\n",
      "epoch:14 step:11325 [D loss: 1.049622, acc: 10.16%] [G loss: 1.745848]\n",
      "epoch:14 step:11326 [D loss: 0.508631, acc: 81.25%] [G loss: 2.239349]\n",
      "epoch:14 step:11327 [D loss: 0.612933, acc: 64.84%] [G loss: 1.738385]\n",
      "epoch:14 step:11328 [D loss: 0.451097, acc: 88.28%] [G loss: 2.752483]\n",
      "epoch:14 step:11329 [D loss: 0.797110, acc: 40.62%] [G loss: 1.977561]\n",
      "epoch:14 step:11330 [D loss: 0.477662, acc: 81.25%] [G loss: 2.113461]\n",
      "epoch:14 step:11331 [D loss: 0.669810, acc: 62.50%] [G loss: 1.793555]\n",
      "epoch:14 step:11332 [D loss: 0.661237, acc: 60.94%] [G loss: 2.122386]\n",
      "epoch:14 step:11333 [D loss: 0.753584, acc: 42.19%] [G loss: 1.897378]\n",
      "epoch:14 step:11334 [D loss: 0.474040, acc: 86.72%] [G loss: 2.440243]\n",
      "epoch:14 step:11335 [D loss: 0.307521, acc: 97.66%] [G loss: 2.709121]\n",
      "epoch:14 step:11336 [D loss: 0.595866, acc: 74.22%] [G loss: 2.047940]\n",
      "epoch:14 step:11337 [D loss: 0.463336, acc: 82.03%] [G loss: 2.693429]\n",
      "epoch:14 step:11338 [D loss: 0.345321, acc: 89.06%] [G loss: 2.031650]\n",
      "epoch:14 step:11339 [D loss: 0.689728, acc: 57.03%] [G loss: 2.305993]\n",
      "epoch:14 step:11340 [D loss: 0.425741, acc: 84.38%] [G loss: 2.422685]\n",
      "epoch:14 step:11341 [D loss: 0.473165, acc: 80.47%] [G loss: 2.645967]\n",
      "epoch:14 step:11342 [D loss: 0.651829, acc: 65.62%] [G loss: 2.149511]\n",
      "epoch:14 step:11343 [D loss: 0.687691, acc: 60.16%] [G loss: 1.770207]\n",
      "epoch:14 step:11344 [D loss: 0.681854, acc: 52.34%] [G loss: 2.002486]\n",
      "epoch:14 step:11345 [D loss: 0.674942, acc: 60.94%] [G loss: 2.459318]\n",
      "epoch:14 step:11346 [D loss: 0.439600, acc: 86.72%] [G loss: 2.638319]\n",
      "epoch:14 step:11347 [D loss: 0.457668, acc: 84.38%] [G loss: 2.322217]\n",
      "epoch:14 step:11348 [D loss: 0.584704, acc: 67.19%] [G loss: 2.397244]\n",
      "epoch:14 step:11349 [D loss: 0.672023, acc: 63.28%] [G loss: 2.390227]\n",
      "epoch:14 step:11350 [D loss: 0.466599, acc: 85.16%] [G loss: 2.167406]\n",
      "epoch:14 step:11351 [D loss: 0.333572, acc: 94.53%] [G loss: 2.308883]\n",
      "epoch:14 step:11352 [D loss: 0.294137, acc: 98.44%] [G loss: 3.120416]\n",
      "epoch:14 step:11353 [D loss: 0.972898, acc: 35.16%] [G loss: 1.959987]\n",
      "epoch:14 step:11354 [D loss: 0.402005, acc: 83.59%] [G loss: 2.703611]\n",
      "epoch:14 step:11355 [D loss: 0.446467, acc: 82.03%] [G loss: 1.965745]\n",
      "epoch:14 step:11356 [D loss: 0.411800, acc: 86.72%] [G loss: 2.990277]\n",
      "epoch:14 step:11357 [D loss: 0.530640, acc: 78.91%] [G loss: 2.242895]\n",
      "epoch:14 step:11358 [D loss: 0.658635, acc: 60.94%] [G loss: 2.167635]\n",
      "epoch:14 step:11359 [D loss: 0.518142, acc: 78.91%] [G loss: 2.019571]\n",
      "epoch:14 step:11360 [D loss: 0.607275, acc: 74.22%] [G loss: 2.551853]\n",
      "epoch:14 step:11361 [D loss: 0.619674, acc: 68.75%] [G loss: 2.157829]\n",
      "epoch:14 step:11362 [D loss: 0.735504, acc: 56.25%] [G loss: 2.531831]\n",
      "epoch:14 step:11363 [D loss: 0.334429, acc: 96.88%] [G loss: 3.412818]\n",
      "epoch:14 step:11364 [D loss: 1.179260, acc: 20.31%] [G loss: 1.959498]\n",
      "epoch:14 step:11365 [D loss: 0.547825, acc: 70.31%] [G loss: 2.180612]\n",
      "epoch:14 step:11366 [D loss: 0.486259, acc: 76.56%] [G loss: 2.248971]\n",
      "epoch:14 step:11367 [D loss: 0.600849, acc: 67.97%] [G loss: 1.824849]\n",
      "epoch:14 step:11368 [D loss: 1.009439, acc: 21.09%] [G loss: 1.670753]\n",
      "epoch:14 step:11369 [D loss: 0.778040, acc: 52.34%] [G loss: 2.229233]\n",
      "epoch:14 step:11370 [D loss: 0.717430, acc: 55.47%] [G loss: 2.768047]\n",
      "epoch:14 step:11371 [D loss: 0.811186, acc: 32.81%] [G loss: 1.548120]\n",
      "epoch:14 step:11372 [D loss: 0.644726, acc: 61.72%] [G loss: 2.147223]\n",
      "epoch:14 step:11373 [D loss: 0.349500, acc: 89.06%] [G loss: 4.500864]\n",
      "epoch:14 step:11374 [D loss: 0.835523, acc: 36.72%] [G loss: 2.971792]\n",
      "epoch:14 step:11375 [D loss: 0.736552, acc: 53.12%] [G loss: 2.356887]\n",
      "epoch:14 step:11376 [D loss: 0.558771, acc: 76.56%] [G loss: 3.205042]\n",
      "epoch:14 step:11377 [D loss: 0.768520, acc: 50.00%] [G loss: 2.446082]\n",
      "epoch:14 step:11378 [D loss: 0.469402, acc: 79.69%] [G loss: 2.686069]\n",
      "epoch:14 step:11379 [D loss: 0.867281, acc: 36.72%] [G loss: 1.837666]\n",
      "epoch:14 step:11380 [D loss: 0.558935, acc: 77.34%] [G loss: 2.470149]\n",
      "epoch:14 step:11381 [D loss: 0.448002, acc: 83.59%] [G loss: 3.030715]\n",
      "epoch:14 step:11382 [D loss: 0.470493, acc: 80.47%] [G loss: 2.830813]\n",
      "epoch:14 step:11383 [D loss: 0.523054, acc: 78.91%] [G loss: 2.353007]\n",
      "epoch:14 step:11384 [D loss: 0.335681, acc: 92.19%] [G loss: 2.558597]\n",
      "epoch:14 step:11385 [D loss: 0.701671, acc: 53.91%] [G loss: 2.533879]\n",
      "epoch:14 step:11386 [D loss: 0.446841, acc: 77.34%] [G loss: 2.487654]\n",
      "epoch:14 step:11387 [D loss: 0.448313, acc: 84.38%] [G loss: 2.993181]\n",
      "epoch:14 step:11388 [D loss: 0.576377, acc: 67.97%] [G loss: 2.969566]\n",
      "epoch:14 step:11389 [D loss: 0.404217, acc: 88.28%] [G loss: 2.018964]\n",
      "epoch:14 step:11390 [D loss: 0.998244, acc: 32.03%] [G loss: 1.924392]\n",
      "epoch:14 step:11391 [D loss: 0.465932, acc: 85.16%] [G loss: 2.114737]\n",
      "epoch:14 step:11392 [D loss: 0.668749, acc: 64.06%] [G loss: 2.919203]\n",
      "epoch:14 step:11393 [D loss: 0.525768, acc: 79.69%] [G loss: 2.009981]\n",
      "epoch:14 step:11394 [D loss: 0.531761, acc: 75.78%] [G loss: 3.656559]\n",
      "epoch:14 step:11395 [D loss: 0.762832, acc: 45.31%] [G loss: 2.121455]\n",
      "epoch:14 step:11396 [D loss: 0.566133, acc: 70.31%] [G loss: 2.814735]\n",
      "epoch:14 step:11397 [D loss: 0.509399, acc: 71.88%] [G loss: 2.438813]\n",
      "epoch:14 step:11398 [D loss: 0.524748, acc: 77.34%] [G loss: 2.831130]\n",
      "epoch:14 step:11399 [D loss: 0.621754, acc: 64.06%] [G loss: 2.162524]\n",
      "epoch:14 step:11400 [D loss: 0.702611, acc: 53.91%] [G loss: 2.636021]\n",
      "epoch:14 step:11401 [D loss: 0.480245, acc: 78.91%] [G loss: 2.475847]\n",
      "epoch:14 step:11402 [D loss: 0.559868, acc: 75.00%] [G loss: 2.471125]\n",
      "epoch:14 step:11403 [D loss: 0.595452, acc: 67.97%] [G loss: 2.624597]\n",
      "epoch:14 step:11404 [D loss: 0.539637, acc: 71.09%] [G loss: 2.079723]\n",
      "epoch:14 step:11405 [D loss: 0.538317, acc: 74.22%] [G loss: 2.074548]\n",
      "epoch:14 step:11406 [D loss: 0.645651, acc: 57.03%] [G loss: 1.809919]\n",
      "epoch:14 step:11407 [D loss: 0.565750, acc: 69.53%] [G loss: 3.213393]\n",
      "epoch:14 step:11408 [D loss: 0.535361, acc: 75.00%] [G loss: 2.103004]\n",
      "epoch:14 step:11409 [D loss: 0.525429, acc: 79.69%] [G loss: 3.318422]\n",
      "epoch:14 step:11410 [D loss: 0.343385, acc: 91.41%] [G loss: 2.798053]\n",
      "epoch:14 step:11411 [D loss: 0.497735, acc: 78.12%] [G loss: 2.575524]\n",
      "epoch:14 step:11412 [D loss: 0.561354, acc: 69.53%] [G loss: 2.251792]\n",
      "epoch:14 step:11413 [D loss: 0.749033, acc: 48.44%] [G loss: 1.889916]\n",
      "epoch:14 step:11414 [D loss: 0.424990, acc: 89.06%] [G loss: 1.899218]\n",
      "epoch:14 step:11415 [D loss: 0.600613, acc: 67.19%] [G loss: 2.224333]\n",
      "epoch:14 step:11416 [D loss: 0.557914, acc: 73.44%] [G loss: 2.198751]\n",
      "epoch:14 step:11417 [D loss: 0.678833, acc: 57.03%] [G loss: 2.533197]\n",
      "epoch:14 step:11418 [D loss: 0.497153, acc: 68.75%] [G loss: 2.247842]\n",
      "epoch:14 step:11419 [D loss: 0.620146, acc: 60.94%] [G loss: 2.156216]\n",
      "epoch:14 step:11420 [D loss: 0.544239, acc: 75.78%] [G loss: 2.327428]\n",
      "epoch:14 step:11421 [D loss: 0.484946, acc: 77.34%] [G loss: 3.030161]\n",
      "epoch:14 step:11422 [D loss: 0.601854, acc: 67.97%] [G loss: 2.132350]\n",
      "epoch:14 step:11423 [D loss: 0.541243, acc: 71.88%] [G loss: 2.245947]\n",
      "epoch:14 step:11424 [D loss: 0.304534, acc: 92.97%] [G loss: 2.731996]\n",
      "epoch:14 step:11425 [D loss: 0.730512, acc: 51.56%] [G loss: 3.266369]\n",
      "epoch:14 step:11426 [D loss: 0.741034, acc: 52.34%] [G loss: 1.893555]\n",
      "epoch:14 step:11427 [D loss: 0.348386, acc: 87.50%] [G loss: 3.287729]\n",
      "epoch:14 step:11428 [D loss: 0.849941, acc: 38.28%] [G loss: 1.936170]\n",
      "epoch:14 step:11429 [D loss: 0.486713, acc: 82.03%] [G loss: 4.099647]\n",
      "epoch:14 step:11430 [D loss: 0.592920, acc: 75.78%] [G loss: 2.728732]\n",
      "epoch:14 step:11431 [D loss: 0.352770, acc: 92.97%] [G loss: 2.290987]\n",
      "epoch:14 step:11432 [D loss: 0.560484, acc: 67.19%] [G loss: 2.876850]\n",
      "epoch:14 step:11433 [D loss: 0.763119, acc: 46.88%] [G loss: 2.343157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11434 [D loss: 0.509064, acc: 72.66%] [G loss: 3.564129]\n",
      "epoch:14 step:11435 [D loss: 0.301981, acc: 95.31%] [G loss: 3.452307]\n",
      "epoch:14 step:11436 [D loss: 0.382024, acc: 91.41%] [G loss: 2.545702]\n",
      "epoch:14 step:11437 [D loss: 0.668430, acc: 61.72%] [G loss: 3.733044]\n",
      "epoch:14 step:11438 [D loss: 0.776859, acc: 54.69%] [G loss: 1.981409]\n",
      "epoch:14 step:11439 [D loss: 0.726864, acc: 56.25%] [G loss: 2.254753]\n",
      "epoch:14 step:11440 [D loss: 0.668226, acc: 60.16%] [G loss: 1.850436]\n",
      "epoch:14 step:11441 [D loss: 0.735821, acc: 55.47%] [G loss: 2.721793]\n",
      "epoch:14 step:11442 [D loss: 0.448641, acc: 78.91%] [G loss: 3.593120]\n",
      "epoch:14 step:11443 [D loss: 0.380878, acc: 92.19%] [G loss: 3.082327]\n",
      "epoch:14 step:11444 [D loss: 0.196393, acc: 98.44%] [G loss: 3.753571]\n",
      "epoch:14 step:11445 [D loss: 0.425236, acc: 78.91%] [G loss: 3.609910]\n",
      "epoch:14 step:11446 [D loss: 0.342703, acc: 84.38%] [G loss: 4.457624]\n",
      "epoch:14 step:11447 [D loss: 0.701071, acc: 59.38%] [G loss: 2.876127]\n",
      "epoch:14 step:11448 [D loss: 0.449408, acc: 86.72%] [G loss: 2.952890]\n",
      "epoch:14 step:11449 [D loss: 0.451285, acc: 85.16%] [G loss: 2.836643]\n",
      "epoch:14 step:11450 [D loss: 0.818393, acc: 53.12%] [G loss: 2.099290]\n",
      "epoch:14 step:11451 [D loss: 0.287222, acc: 95.31%] [G loss: 4.483948]\n",
      "epoch:14 step:11452 [D loss: 0.727393, acc: 47.66%] [G loss: 2.560798]\n",
      "epoch:14 step:11453 [D loss: 0.977305, acc: 25.78%] [G loss: 1.598638]\n",
      "epoch:14 step:11454 [D loss: 0.302083, acc: 97.66%] [G loss: 2.413268]\n",
      "epoch:14 step:11455 [D loss: 0.432121, acc: 86.72%] [G loss: 3.013759]\n",
      "epoch:14 step:11456 [D loss: 0.893690, acc: 46.88%] [G loss: 1.758755]\n",
      "epoch:14 step:11457 [D loss: 1.150930, acc: 14.06%] [G loss: 1.636157]\n",
      "epoch:14 step:11458 [D loss: 0.656251, acc: 62.50%] [G loss: 2.186046]\n",
      "epoch:14 step:11459 [D loss: 0.649931, acc: 64.06%] [G loss: 2.379792]\n",
      "epoch:14 step:11460 [D loss: 0.789500, acc: 38.28%] [G loss: 1.969727]\n",
      "epoch:14 step:11461 [D loss: 0.643651, acc: 66.41%] [G loss: 2.351912]\n",
      "epoch:14 step:11462 [D loss: 0.441588, acc: 89.84%] [G loss: 2.672843]\n",
      "epoch:14 step:11463 [D loss: 0.676391, acc: 64.06%] [G loss: 2.229182]\n",
      "epoch:14 step:11464 [D loss: 0.498383, acc: 78.91%] [G loss: 2.469119]\n",
      "epoch:14 step:11465 [D loss: 0.556600, acc: 76.56%] [G loss: 2.463590]\n",
      "epoch:14 step:11466 [D loss: 0.996781, acc: 44.53%] [G loss: 2.644263]\n",
      "epoch:14 step:11467 [D loss: 0.428972, acc: 87.50%] [G loss: 2.444595]\n",
      "epoch:14 step:11468 [D loss: 0.575763, acc: 68.75%] [G loss: 2.027703]\n",
      "epoch:14 step:11469 [D loss: 0.627098, acc: 67.19%] [G loss: 2.361087]\n",
      "epoch:14 step:11470 [D loss: 0.501894, acc: 71.88%] [G loss: 2.974055]\n",
      "epoch:14 step:11471 [D loss: 0.449634, acc: 88.28%] [G loss: 2.786642]\n",
      "epoch:14 step:11472 [D loss: 0.638645, acc: 64.84%] [G loss: 2.411597]\n",
      "epoch:14 step:11473 [D loss: 0.536551, acc: 76.56%] [G loss: 2.598991]\n",
      "epoch:14 step:11474 [D loss: 0.659783, acc: 54.69%] [G loss: 2.765353]\n",
      "epoch:14 step:11475 [D loss: 0.719411, acc: 53.91%] [G loss: 2.162066]\n",
      "epoch:14 step:11476 [D loss: 0.575293, acc: 73.44%] [G loss: 2.789136]\n",
      "epoch:14 step:11477 [D loss: 0.600562, acc: 67.97%] [G loss: 2.341795]\n",
      "epoch:14 step:11478 [D loss: 0.341796, acc: 85.16%] [G loss: 2.989708]\n",
      "epoch:14 step:11479 [D loss: 0.632484, acc: 63.28%] [G loss: 2.815641]\n",
      "epoch:14 step:11480 [D loss: 0.465455, acc: 85.94%] [G loss: 2.451136]\n",
      "epoch:14 step:11481 [D loss: 0.382547, acc: 90.62%] [G loss: 2.349643]\n",
      "epoch:14 step:11482 [D loss: 0.698034, acc: 53.91%] [G loss: 2.400307]\n",
      "epoch:14 step:11483 [D loss: 0.572519, acc: 72.66%] [G loss: 2.148694]\n",
      "epoch:14 step:11484 [D loss: 0.714937, acc: 55.47%] [G loss: 2.303889]\n",
      "epoch:14 step:11485 [D loss: 0.598474, acc: 67.19%] [G loss: 2.652203]\n",
      "epoch:14 step:11486 [D loss: 0.707903, acc: 55.47%] [G loss: 2.483665]\n",
      "epoch:14 step:11487 [D loss: 0.582267, acc: 70.31%] [G loss: 2.127568]\n",
      "epoch:14 step:11488 [D loss: 0.393680, acc: 91.41%] [G loss: 2.499013]\n",
      "epoch:14 step:11489 [D loss: 0.678068, acc: 60.94%] [G loss: 2.702497]\n",
      "epoch:14 step:11490 [D loss: 0.886213, acc: 34.38%] [G loss: 1.710834]\n",
      "epoch:14 step:11491 [D loss: 0.637197, acc: 63.28%] [G loss: 1.952570]\n",
      "epoch:14 step:11492 [D loss: 0.545223, acc: 74.22%] [G loss: 2.632324]\n",
      "epoch:14 step:11493 [D loss: 0.510935, acc: 71.09%] [G loss: 2.203591]\n",
      "epoch:14 step:11494 [D loss: 0.727377, acc: 53.91%] [G loss: 2.354056]\n",
      "epoch:14 step:11495 [D loss: 0.437154, acc: 84.38%] [G loss: 2.624364]\n",
      "epoch:14 step:11496 [D loss: 0.945063, acc: 28.12%] [G loss: 1.977004]\n",
      "epoch:14 step:11497 [D loss: 0.973123, acc: 24.22%] [G loss: 2.046583]\n",
      "epoch:14 step:11498 [D loss: 0.484534, acc: 86.72%] [G loss: 2.205008]\n",
      "epoch:14 step:11499 [D loss: 0.397520, acc: 90.62%] [G loss: 2.163371]\n",
      "epoch:14 step:11500 [D loss: 0.504953, acc: 77.34%] [G loss: 2.527298]\n",
      "epoch:14 step:11501 [D loss: 0.362460, acc: 91.41%] [G loss: 2.503432]\n",
      "epoch:14 step:11502 [D loss: 0.444182, acc: 82.81%] [G loss: 2.399109]\n",
      "epoch:14 step:11503 [D loss: 0.490623, acc: 82.03%] [G loss: 2.377359]\n",
      "epoch:14 step:11504 [D loss: 0.879799, acc: 50.00%] [G loss: 2.043429]\n",
      "epoch:14 step:11505 [D loss: 0.605815, acc: 69.53%] [G loss: 2.705953]\n",
      "epoch:14 step:11506 [D loss: 0.338267, acc: 84.38%] [G loss: 2.360542]\n",
      "epoch:14 step:11507 [D loss: 0.805427, acc: 45.31%] [G loss: 2.107703]\n",
      "epoch:14 step:11508 [D loss: 0.661032, acc: 64.84%] [G loss: 2.756787]\n",
      "epoch:14 step:11509 [D loss: 0.854288, acc: 41.41%] [G loss: 2.662898]\n",
      "epoch:14 step:11510 [D loss: 0.511215, acc: 81.25%] [G loss: 2.670862]\n",
      "epoch:14 step:11511 [D loss: 0.405495, acc: 74.22%] [G loss: 3.183116]\n",
      "epoch:14 step:11512 [D loss: 0.802648, acc: 41.41%] [G loss: 2.644638]\n",
      "epoch:14 step:11513 [D loss: 0.684146, acc: 53.12%] [G loss: 2.005756]\n",
      "epoch:14 step:11514 [D loss: 0.808221, acc: 37.50%] [G loss: 2.295266]\n",
      "epoch:14 step:11515 [D loss: 0.400379, acc: 90.62%] [G loss: 2.277042]\n",
      "epoch:14 step:11516 [D loss: 0.494768, acc: 81.25%] [G loss: 1.891740]\n",
      "epoch:14 step:11517 [D loss: 0.676793, acc: 59.38%] [G loss: 3.093928]\n",
      "epoch:14 step:11518 [D loss: 0.598792, acc: 68.75%] [G loss: 2.226391]\n",
      "epoch:14 step:11519 [D loss: 0.570665, acc: 72.66%] [G loss: 2.625209]\n",
      "epoch:14 step:11520 [D loss: 0.315897, acc: 89.06%] [G loss: 2.812282]\n",
      "epoch:14 step:11521 [D loss: 0.318026, acc: 96.09%] [G loss: 2.367276]\n",
      "epoch:14 step:11522 [D loss: 0.443908, acc: 90.62%] [G loss: 2.545916]\n",
      "epoch:14 step:11523 [D loss: 0.754932, acc: 45.31%] [G loss: 2.782924]\n",
      "epoch:14 step:11524 [D loss: 0.333182, acc: 93.75%] [G loss: 2.660320]\n",
      "epoch:14 step:11525 [D loss: 0.191205, acc: 98.44%] [G loss: 2.604151]\n",
      "epoch:14 step:11526 [D loss: 0.282535, acc: 95.31%] [G loss: 2.504973]\n",
      "epoch:14 step:11527 [D loss: 0.861874, acc: 40.62%] [G loss: 2.258940]\n",
      "epoch:14 step:11528 [D loss: 0.402068, acc: 79.69%] [G loss: 2.376225]\n",
      "epoch:14 step:11529 [D loss: 0.744898, acc: 49.22%] [G loss: 1.909729]\n",
      "epoch:14 step:11530 [D loss: 0.252797, acc: 93.75%] [G loss: 2.998164]\n",
      "epoch:14 step:11531 [D loss: 0.491355, acc: 75.00%] [G loss: 2.228411]\n",
      "epoch:14 step:11532 [D loss: 0.583557, acc: 67.19%] [G loss: 1.745659]\n",
      "epoch:14 step:11533 [D loss: 0.675102, acc: 60.94%] [G loss: 2.548688]\n",
      "epoch:14 step:11534 [D loss: 0.585167, acc: 70.31%] [G loss: 2.501232]\n",
      "epoch:14 step:11535 [D loss: 0.744338, acc: 50.00%] [G loss: 1.913645]\n",
      "epoch:14 step:11536 [D loss: 0.344721, acc: 84.38%] [G loss: 2.880073]\n",
      "epoch:14 step:11537 [D loss: 0.829900, acc: 51.56%] [G loss: 1.721808]\n",
      "epoch:14 step:11538 [D loss: 0.588324, acc: 71.88%] [G loss: 1.913422]\n",
      "epoch:14 step:11539 [D loss: 0.641697, acc: 67.97%] [G loss: 3.185271]\n",
      "epoch:14 step:11540 [D loss: 0.491523, acc: 81.25%] [G loss: 2.179187]\n",
      "epoch:14 step:11541 [D loss: 0.835793, acc: 50.00%] [G loss: 2.167138]\n",
      "epoch:14 step:11542 [D loss: 0.887043, acc: 50.00%] [G loss: 2.154411]\n",
      "epoch:14 step:11543 [D loss: 1.111551, acc: 19.53%] [G loss: 2.081661]\n",
      "epoch:14 step:11544 [D loss: 0.411697, acc: 73.44%] [G loss: 2.035516]\n",
      "epoch:14 step:11545 [D loss: 0.223635, acc: 97.66%] [G loss: 2.620105]\n",
      "epoch:14 step:11546 [D loss: 0.829641, acc: 51.56%] [G loss: 2.515180]\n",
      "epoch:14 step:11547 [D loss: 0.387427, acc: 90.62%] [G loss: 2.069841]\n",
      "epoch:14 step:11548 [D loss: 0.464624, acc: 83.59%] [G loss: 2.736173]\n",
      "epoch:14 step:11549 [D loss: 0.553324, acc: 74.22%] [G loss: 2.204925]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11550 [D loss: 0.445244, acc: 81.25%] [G loss: 2.877770]\n",
      "epoch:14 step:11551 [D loss: 0.697071, acc: 53.12%] [G loss: 2.646341]\n",
      "epoch:14 step:11552 [D loss: 0.539177, acc: 77.34%] [G loss: 2.400210]\n",
      "epoch:14 step:11553 [D loss: 0.695832, acc: 60.16%] [G loss: 2.712220]\n",
      "epoch:14 step:11554 [D loss: 0.585667, acc: 72.66%] [G loss: 2.629822]\n",
      "epoch:14 step:11555 [D loss: 0.540786, acc: 77.34%] [G loss: 2.724202]\n",
      "epoch:14 step:11556 [D loss: 0.745132, acc: 49.22%] [G loss: 2.361239]\n",
      "epoch:14 step:11557 [D loss: 0.353797, acc: 92.19%] [G loss: 3.146807]\n",
      "epoch:14 step:11558 [D loss: 0.493783, acc: 77.34%] [G loss: 2.596726]\n",
      "epoch:14 step:11559 [D loss: 0.290763, acc: 92.97%] [G loss: 3.309768]\n",
      "epoch:14 step:11560 [D loss: 0.655439, acc: 65.62%] [G loss: 2.381253]\n",
      "epoch:14 step:11561 [D loss: 0.675852, acc: 60.94%] [G loss: 3.252977]\n",
      "epoch:14 step:11562 [D loss: 0.534455, acc: 78.91%] [G loss: 2.674521]\n",
      "epoch:14 step:11563 [D loss: 0.371691, acc: 90.62%] [G loss: 3.131806]\n",
      "epoch:14 step:11564 [D loss: 0.362676, acc: 91.41%] [G loss: 2.399462]\n",
      "epoch:14 step:11565 [D loss: 0.469252, acc: 76.56%] [G loss: 2.542799]\n",
      "epoch:14 step:11566 [D loss: 0.590096, acc: 67.97%] [G loss: 1.819258]\n",
      "epoch:14 step:11567 [D loss: 0.791265, acc: 46.88%] [G loss: 2.421148]\n",
      "epoch:14 step:11568 [D loss: 0.462012, acc: 75.00%] [G loss: 2.706430]\n",
      "epoch:14 step:11569 [D loss: 0.504975, acc: 79.69%] [G loss: 2.166423]\n",
      "epoch:14 step:11570 [D loss: 0.570509, acc: 65.62%] [G loss: 1.971392]\n",
      "epoch:14 step:11571 [D loss: 0.739265, acc: 52.34%] [G loss: 1.754529]\n",
      "epoch:14 step:11572 [D loss: 0.475141, acc: 77.34%] [G loss: 2.432428]\n",
      "epoch:14 step:11573 [D loss: 0.902338, acc: 39.84%] [G loss: 2.493264]\n",
      "epoch:14 step:11574 [D loss: 0.341917, acc: 91.41%] [G loss: 2.456684]\n",
      "epoch:14 step:11575 [D loss: 1.052878, acc: 30.47%] [G loss: 2.569633]\n",
      "epoch:14 step:11576 [D loss: 0.802032, acc: 52.34%] [G loss: 2.861958]\n",
      "epoch:14 step:11577 [D loss: 0.513773, acc: 81.25%] [G loss: 1.936755]\n",
      "epoch:14 step:11578 [D loss: 0.386642, acc: 84.38%] [G loss: 2.742983]\n",
      "epoch:14 step:11579 [D loss: 1.239904, acc: 13.28%] [G loss: 2.369464]\n",
      "epoch:14 step:11580 [D loss: 0.264929, acc: 94.53%] [G loss: 2.819050]\n",
      "epoch:14 step:11581 [D loss: 0.767994, acc: 52.34%] [G loss: 1.977321]\n",
      "epoch:14 step:11582 [D loss: 0.668085, acc: 57.81%] [G loss: 3.010890]\n",
      "epoch:14 step:11583 [D loss: 0.412975, acc: 88.28%] [G loss: 2.430171]\n",
      "epoch:14 step:11584 [D loss: 0.685859, acc: 57.81%] [G loss: 2.189461]\n",
      "epoch:14 step:11585 [D loss: 0.601283, acc: 67.19%] [G loss: 2.762064]\n",
      "epoch:14 step:11586 [D loss: 0.309803, acc: 98.44%] [G loss: 2.058928]\n",
      "epoch:14 step:11587 [D loss: 0.313882, acc: 93.75%] [G loss: 2.968783]\n",
      "epoch:14 step:11588 [D loss: 0.679674, acc: 58.59%] [G loss: 2.052610]\n",
      "epoch:14 step:11589 [D loss: 0.611251, acc: 70.31%] [G loss: 2.555186]\n",
      "epoch:14 step:11590 [D loss: 1.248583, acc: 25.78%] [G loss: 1.951689]\n",
      "epoch:14 step:11591 [D loss: 0.202777, acc: 99.22%] [G loss: 3.744451]\n",
      "epoch:14 step:11592 [D loss: 0.496624, acc: 82.03%] [G loss: 2.258274]\n",
      "epoch:14 step:11593 [D loss: 0.445796, acc: 84.38%] [G loss: 2.505056]\n",
      "epoch:14 step:11594 [D loss: 0.331057, acc: 93.75%] [G loss: 2.412866]\n",
      "epoch:14 step:11595 [D loss: 0.309128, acc: 94.53%] [G loss: 2.450279]\n",
      "epoch:14 step:11596 [D loss: 0.485116, acc: 78.91%] [G loss: 2.559414]\n",
      "epoch:14 step:11597 [D loss: 0.669256, acc: 60.16%] [G loss: 2.344409]\n",
      "epoch:14 step:11598 [D loss: 0.671926, acc: 55.47%] [G loss: 2.613064]\n",
      "epoch:14 step:11599 [D loss: 0.649554, acc: 65.62%] [G loss: 3.778019]\n",
      "epoch:14 step:11600 [D loss: 0.700820, acc: 60.94%] [G loss: 2.486077]\n",
      "epoch:14 step:11601 [D loss: 0.273157, acc: 91.41%] [G loss: 3.696497]\n",
      "epoch:14 step:11602 [D loss: 0.435318, acc: 78.12%] [G loss: 3.149168]\n",
      "epoch:14 step:11603 [D loss: 0.937533, acc: 33.59%] [G loss: 2.347214]\n",
      "epoch:14 step:11604 [D loss: 0.616063, acc: 67.97%] [G loss: 1.967300]\n",
      "epoch:14 step:11605 [D loss: 0.507712, acc: 82.81%] [G loss: 2.137321]\n",
      "epoch:14 step:11606 [D loss: 0.628837, acc: 63.28%] [G loss: 1.821551]\n",
      "epoch:14 step:11607 [D loss: 0.675977, acc: 59.38%] [G loss: 2.284542]\n",
      "epoch:14 step:11608 [D loss: 0.846464, acc: 46.88%] [G loss: 2.068591]\n",
      "epoch:14 step:11609 [D loss: 0.385783, acc: 92.97%] [G loss: 2.499734]\n",
      "epoch:14 step:11610 [D loss: 0.604270, acc: 69.53%] [G loss: 2.468584]\n",
      "epoch:14 step:11611 [D loss: 0.540501, acc: 75.78%] [G loss: 2.568082]\n",
      "epoch:14 step:11612 [D loss: 0.625365, acc: 65.62%] [G loss: 2.541611]\n",
      "epoch:14 step:11613 [D loss: 0.408866, acc: 85.94%] [G loss: 3.130197]\n",
      "epoch:14 step:11614 [D loss: 0.419983, acc: 91.41%] [G loss: 2.547488]\n",
      "epoch:14 step:11615 [D loss: 0.420737, acc: 92.97%] [G loss: 3.055598]\n",
      "epoch:14 step:11616 [D loss: 1.100013, acc: 26.56%] [G loss: 2.065150]\n",
      "epoch:14 step:11617 [D loss: 0.427575, acc: 85.94%] [G loss: 2.709016]\n",
      "epoch:14 step:11618 [D loss: 0.754587, acc: 53.91%] [G loss: 2.006138]\n",
      "epoch:14 step:11619 [D loss: 0.709810, acc: 53.91%] [G loss: 2.189231]\n",
      "epoch:14 step:11620 [D loss: 0.524121, acc: 79.69%] [G loss: 2.024365]\n",
      "epoch:14 step:11621 [D loss: 0.487997, acc: 76.56%] [G loss: 2.192910]\n",
      "epoch:14 step:11622 [D loss: 0.527447, acc: 74.22%] [G loss: 2.627148]\n",
      "epoch:14 step:11623 [D loss: 0.647607, acc: 58.59%] [G loss: 2.536233]\n",
      "epoch:14 step:11624 [D loss: 0.497828, acc: 79.69%] [G loss: 2.515253]\n",
      "epoch:14 step:11625 [D loss: 0.664673, acc: 60.16%] [G loss: 2.249297]\n",
      "epoch:14 step:11626 [D loss: 0.923970, acc: 45.31%] [G loss: 2.592044]\n",
      "epoch:14 step:11627 [D loss: 0.608085, acc: 64.84%] [G loss: 2.293446]\n",
      "epoch:14 step:11628 [D loss: 0.460672, acc: 71.88%] [G loss: 2.239713]\n",
      "epoch:14 step:11629 [D loss: 0.782795, acc: 43.75%] [G loss: 1.663218]\n",
      "epoch:14 step:11630 [D loss: 0.456482, acc: 85.94%] [G loss: 1.931210]\n",
      "epoch:14 step:11631 [D loss: 0.819622, acc: 45.31%] [G loss: 2.303000]\n",
      "epoch:14 step:11632 [D loss: 0.371934, acc: 82.03%] [G loss: 3.122251]\n",
      "epoch:14 step:11633 [D loss: 0.511011, acc: 78.12%] [G loss: 2.312916]\n",
      "epoch:14 step:11634 [D loss: 0.539531, acc: 74.22%] [G loss: 2.276458]\n",
      "epoch:14 step:11635 [D loss: 0.549403, acc: 71.88%] [G loss: 2.535400]\n",
      "epoch:14 step:11636 [D loss: 0.437293, acc: 82.81%] [G loss: 2.896847]\n",
      "epoch:14 step:11637 [D loss: 0.723650, acc: 52.34%] [G loss: 2.753086]\n",
      "epoch:14 step:11638 [D loss: 0.766633, acc: 50.78%] [G loss: 2.683162]\n",
      "epoch:14 step:11639 [D loss: 0.801371, acc: 43.75%] [G loss: 2.201377]\n",
      "epoch:14 step:11640 [D loss: 0.354994, acc: 91.41%] [G loss: 3.404301]\n",
      "epoch:14 step:11641 [D loss: 0.429086, acc: 86.72%] [G loss: 2.436434]\n",
      "epoch:14 step:11642 [D loss: 0.287592, acc: 95.31%] [G loss: 2.423287]\n",
      "epoch:14 step:11643 [D loss: 0.537217, acc: 65.62%] [G loss: 2.582659]\n",
      "epoch:14 step:11644 [D loss: 0.505700, acc: 79.69%] [G loss: 3.169002]\n",
      "epoch:14 step:11645 [D loss: 0.682046, acc: 57.81%] [G loss: 2.632355]\n",
      "epoch:14 step:11646 [D loss: 0.311554, acc: 92.97%] [G loss: 3.954218]\n",
      "epoch:14 step:11647 [D loss: 0.457508, acc: 82.03%] [G loss: 2.664388]\n",
      "epoch:14 step:11648 [D loss: 0.338421, acc: 93.75%] [G loss: 3.193459]\n",
      "epoch:14 step:11649 [D loss: 0.439309, acc: 76.56%] [G loss: 2.485137]\n",
      "epoch:14 step:11650 [D loss: 0.404168, acc: 85.16%] [G loss: 2.735886]\n",
      "epoch:14 step:11651 [D loss: 0.943279, acc: 49.22%] [G loss: 1.938632]\n",
      "epoch:14 step:11652 [D loss: 0.459513, acc: 82.81%] [G loss: 1.746776]\n",
      "epoch:14 step:11653 [D loss: 0.628575, acc: 57.03%] [G loss: 2.961359]\n",
      "epoch:14 step:11654 [D loss: 0.650135, acc: 56.25%] [G loss: 2.432178]\n",
      "epoch:14 step:11655 [D loss: 0.928628, acc: 26.56%] [G loss: 1.882753]\n",
      "epoch:14 step:11656 [D loss: 0.700234, acc: 54.69%] [G loss: 2.173730]\n",
      "epoch:14 step:11657 [D loss: 0.648213, acc: 65.62%] [G loss: 2.504877]\n",
      "epoch:14 step:11658 [D loss: 0.792193, acc: 47.66%] [G loss: 2.970004]\n",
      "epoch:14 step:11659 [D loss: 0.421569, acc: 82.03%] [G loss: 1.990141]\n",
      "epoch:14 step:11660 [D loss: 0.436132, acc: 81.25%] [G loss: 1.752637]\n",
      "epoch:14 step:11661 [D loss: 0.276367, acc: 97.66%] [G loss: 2.585504]\n",
      "epoch:14 step:11662 [D loss: 0.454894, acc: 76.56%] [G loss: 2.642222]\n",
      "epoch:14 step:11663 [D loss: 0.527494, acc: 76.56%] [G loss: 2.040617]\n",
      "epoch:14 step:11664 [D loss: 0.272019, acc: 94.53%] [G loss: 2.893764]\n",
      "epoch:14 step:11665 [D loss: 0.826600, acc: 44.53%] [G loss: 3.269679]\n",
      "epoch:14 step:11666 [D loss: 0.472554, acc: 81.25%] [G loss: 2.558782]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11667 [D loss: 0.492223, acc: 81.25%] [G loss: 2.679051]\n",
      "epoch:14 step:11668 [D loss: 0.297081, acc: 93.75%] [G loss: 3.590624]\n",
      "epoch:14 step:11669 [D loss: 1.031064, acc: 28.12%] [G loss: 2.022338]\n",
      "epoch:14 step:11670 [D loss: 1.119531, acc: 14.06%] [G loss: 1.632748]\n",
      "epoch:14 step:11671 [D loss: 0.550216, acc: 71.88%] [G loss: 2.853068]\n",
      "epoch:14 step:11672 [D loss: 0.580380, acc: 67.97%] [G loss: 2.335239]\n",
      "epoch:14 step:11673 [D loss: 0.535722, acc: 75.78%] [G loss: 2.266633]\n",
      "epoch:14 step:11674 [D loss: 1.081016, acc: 21.88%] [G loss: 2.200420]\n",
      "epoch:14 step:11675 [D loss: 0.416026, acc: 82.81%] [G loss: 2.631860]\n",
      "epoch:14 step:11676 [D loss: 0.462048, acc: 84.38%] [G loss: 2.978175]\n",
      "epoch:14 step:11677 [D loss: 0.469800, acc: 80.47%] [G loss: 2.785934]\n",
      "epoch:14 step:11678 [D loss: 0.702242, acc: 54.69%] [G loss: 2.595893]\n",
      "epoch:14 step:11679 [D loss: 0.391629, acc: 85.16%] [G loss: 2.772104]\n",
      "epoch:14 step:11680 [D loss: 0.584285, acc: 67.19%] [G loss: 2.842972]\n",
      "epoch:14 step:11681 [D loss: 0.806962, acc: 43.75%] [G loss: 2.963369]\n",
      "epoch:14 step:11682 [D loss: 0.648025, acc: 58.59%] [G loss: 2.701454]\n",
      "epoch:14 step:11683 [D loss: 0.631120, acc: 64.84%] [G loss: 2.348896]\n",
      "epoch:14 step:11684 [D loss: 0.402599, acc: 82.81%] [G loss: 2.448884]\n",
      "epoch:14 step:11685 [D loss: 0.519021, acc: 75.78%] [G loss: 1.551804]\n",
      "epoch:14 step:11686 [D loss: 0.604621, acc: 65.62%] [G loss: 1.739780]\n",
      "epoch:14 step:11687 [D loss: 0.435754, acc: 76.56%] [G loss: 2.812299]\n",
      "epoch:14 step:11688 [D loss: 0.765450, acc: 47.66%] [G loss: 2.165525]\n",
      "epoch:14 step:11689 [D loss: 1.078577, acc: 26.56%] [G loss: 1.745010]\n",
      "epoch:14 step:11690 [D loss: 0.642799, acc: 65.62%] [G loss: 2.121205]\n",
      "epoch:14 step:11691 [D loss: 0.922698, acc: 28.12%] [G loss: 2.188392]\n",
      "epoch:14 step:11692 [D loss: 0.530261, acc: 72.66%] [G loss: 2.513115]\n",
      "epoch:14 step:11693 [D loss: 0.804690, acc: 51.56%] [G loss: 2.000871]\n",
      "epoch:14 step:11694 [D loss: 0.516370, acc: 76.56%] [G loss: 1.916739]\n",
      "epoch:14 step:11695 [D loss: 0.777941, acc: 46.88%] [G loss: 2.043576]\n",
      "epoch:14 step:11696 [D loss: 0.354212, acc: 85.94%] [G loss: 2.420273]\n",
      "epoch:14 step:11697 [D loss: 0.474287, acc: 82.03%] [G loss: 2.460283]\n",
      "epoch:14 step:11698 [D loss: 0.598892, acc: 71.09%] [G loss: 2.924171]\n",
      "epoch:14 step:11699 [D loss: 0.594918, acc: 67.19%] [G loss: 2.878805]\n",
      "epoch:14 step:11700 [D loss: 0.429721, acc: 83.59%] [G loss: 2.689281]\n",
      "epoch:14 step:11701 [D loss: 0.363097, acc: 92.19%] [G loss: 2.433021]\n",
      "epoch:14 step:11702 [D loss: 0.459902, acc: 82.81%] [G loss: 3.149881]\n",
      "epoch:14 step:11703 [D loss: 0.469070, acc: 78.91%] [G loss: 2.456700]\n",
      "epoch:14 step:11704 [D loss: 0.803293, acc: 50.00%] [G loss: 2.569486]\n",
      "epoch:14 step:11705 [D loss: 0.785825, acc: 49.22%] [G loss: 2.431085]\n",
      "epoch:14 step:11706 [D loss: 0.674215, acc: 60.94%] [G loss: 2.445498]\n",
      "epoch:14 step:11707 [D loss: 0.411531, acc: 82.03%] [G loss: 3.112014]\n",
      "epoch:14 step:11708 [D loss: 0.569466, acc: 71.88%] [G loss: 2.355937]\n",
      "epoch:14 step:11709 [D loss: 0.887957, acc: 35.94%] [G loss: 1.695953]\n",
      "epoch:14 step:11710 [D loss: 0.417895, acc: 85.94%] [G loss: 2.315738]\n",
      "epoch:14 step:11711 [D loss: 0.774859, acc: 46.09%] [G loss: 2.114300]\n",
      "epoch:14 step:11712 [D loss: 0.746614, acc: 49.22%] [G loss: 2.011126]\n",
      "epoch:14 step:11713 [D loss: 0.838190, acc: 45.31%] [G loss: 1.938170]\n",
      "epoch:14 step:11714 [D loss: 0.807540, acc: 39.84%] [G loss: 2.124740]\n",
      "epoch:14 step:11715 [D loss: 0.576108, acc: 67.97%] [G loss: 2.539838]\n",
      "epoch:15 step:11716 [D loss: 0.391566, acc: 89.84%] [G loss: 2.371325]\n",
      "epoch:15 step:11717 [D loss: 0.572311, acc: 70.31%] [G loss: 2.543979]\n",
      "epoch:15 step:11718 [D loss: 0.908076, acc: 34.38%] [G loss: 2.424123]\n",
      "epoch:15 step:11719 [D loss: 0.908108, acc: 48.44%] [G loss: 2.053667]\n",
      "epoch:15 step:11720 [D loss: 0.529592, acc: 71.88%] [G loss: 2.247145]\n",
      "epoch:15 step:11721 [D loss: 0.516856, acc: 75.00%] [G loss: 2.308764]\n",
      "epoch:15 step:11722 [D loss: 0.534929, acc: 75.00%] [G loss: 2.966834]\n",
      "epoch:15 step:11723 [D loss: 0.473203, acc: 85.16%] [G loss: 3.067956]\n",
      "epoch:15 step:11724 [D loss: 0.366354, acc: 91.41%] [G loss: 2.190231]\n",
      "epoch:15 step:11725 [D loss: 0.565205, acc: 73.44%] [G loss: 2.363681]\n",
      "epoch:15 step:11726 [D loss: 0.413783, acc: 82.03%] [G loss: 2.713805]\n",
      "epoch:15 step:11727 [D loss: 0.678617, acc: 57.81%] [G loss: 2.471264]\n",
      "epoch:15 step:11728 [D loss: 0.424126, acc: 86.72%] [G loss: 2.459269]\n",
      "epoch:15 step:11729 [D loss: 0.632793, acc: 64.06%] [G loss: 2.683056]\n",
      "epoch:15 step:11730 [D loss: 1.252313, acc: 32.03%] [G loss: 2.410656]\n",
      "epoch:15 step:11731 [D loss: 0.698151, acc: 64.84%] [G loss: 2.198298]\n",
      "epoch:15 step:11732 [D loss: 0.319353, acc: 93.75%] [G loss: 2.745232]\n",
      "epoch:15 step:11733 [D loss: 0.380525, acc: 91.41%] [G loss: 2.322790]\n",
      "epoch:15 step:11734 [D loss: 0.500512, acc: 80.47%] [G loss: 2.008117]\n",
      "epoch:15 step:11735 [D loss: 0.710992, acc: 54.69%] [G loss: 2.300024]\n",
      "epoch:15 step:11736 [D loss: 0.311805, acc: 96.09%] [G loss: 2.097395]\n",
      "epoch:15 step:11737 [D loss: 0.589532, acc: 66.41%] [G loss: 1.849080]\n",
      "epoch:15 step:11738 [D loss: 0.442518, acc: 81.25%] [G loss: 2.456211]\n",
      "epoch:15 step:11739 [D loss: 0.942176, acc: 32.81%] [G loss: 1.852913]\n",
      "epoch:15 step:11740 [D loss: 0.560058, acc: 65.62%] [G loss: 2.285166]\n",
      "epoch:15 step:11741 [D loss: 0.764873, acc: 50.78%] [G loss: 2.709942]\n",
      "epoch:15 step:11742 [D loss: 0.722341, acc: 50.00%] [G loss: 1.873800]\n",
      "epoch:15 step:11743 [D loss: 0.816524, acc: 42.97%] [G loss: 1.847193]\n",
      "epoch:15 step:11744 [D loss: 0.663521, acc: 63.28%] [G loss: 2.283240]\n",
      "epoch:15 step:11745 [D loss: 0.495126, acc: 81.25%] [G loss: 2.328074]\n",
      "epoch:15 step:11746 [D loss: 1.155863, acc: 19.53%] [G loss: 1.790830]\n",
      "epoch:15 step:11747 [D loss: 0.530039, acc: 78.12%] [G loss: 2.466221]\n",
      "epoch:15 step:11748 [D loss: 0.505464, acc: 78.12%] [G loss: 2.389629]\n",
      "epoch:15 step:11749 [D loss: 0.499522, acc: 78.12%] [G loss: 1.946898]\n",
      "epoch:15 step:11750 [D loss: 0.527666, acc: 71.09%] [G loss: 2.638198]\n",
      "epoch:15 step:11751 [D loss: 0.555772, acc: 69.53%] [G loss: 2.593262]\n",
      "epoch:15 step:11752 [D loss: 0.462441, acc: 83.59%] [G loss: 2.228389]\n",
      "epoch:15 step:11753 [D loss: 0.512709, acc: 77.34%] [G loss: 2.340702]\n",
      "epoch:15 step:11754 [D loss: 0.431284, acc: 89.84%] [G loss: 2.378527]\n",
      "epoch:15 step:11755 [D loss: 0.501703, acc: 71.09%] [G loss: 2.213369]\n",
      "epoch:15 step:11756 [D loss: 0.529380, acc: 72.66%] [G loss: 2.424592]\n",
      "epoch:15 step:11757 [D loss: 0.534928, acc: 78.12%] [G loss: 2.236604]\n",
      "epoch:15 step:11758 [D loss: 0.477922, acc: 80.47%] [G loss: 2.074771]\n",
      "epoch:15 step:11759 [D loss: 0.702461, acc: 53.91%] [G loss: 2.543002]\n",
      "epoch:15 step:11760 [D loss: 0.346168, acc: 93.75%] [G loss: 3.149066]\n",
      "epoch:15 step:11761 [D loss: 0.654131, acc: 57.03%] [G loss: 2.299433]\n",
      "epoch:15 step:11762 [D loss: 0.406866, acc: 83.59%] [G loss: 3.284335]\n",
      "epoch:15 step:11763 [D loss: 0.625884, acc: 64.84%] [G loss: 2.538850]\n",
      "epoch:15 step:11764 [D loss: 0.720665, acc: 57.03%] [G loss: 2.257525]\n",
      "epoch:15 step:11765 [D loss: 1.045391, acc: 44.53%] [G loss: 2.056084]\n",
      "epoch:15 step:11766 [D loss: 0.486647, acc: 85.94%] [G loss: 2.292631]\n",
      "epoch:15 step:11767 [D loss: 0.229478, acc: 97.66%] [G loss: 2.710758]\n",
      "epoch:15 step:11768 [D loss: 0.719109, acc: 57.81%] [G loss: 2.536557]\n",
      "epoch:15 step:11769 [D loss: 0.973630, acc: 35.16%] [G loss: 2.378007]\n",
      "epoch:15 step:11770 [D loss: 0.463502, acc: 85.94%] [G loss: 2.132091]\n",
      "epoch:15 step:11771 [D loss: 0.516556, acc: 82.03%] [G loss: 2.244971]\n",
      "epoch:15 step:11772 [D loss: 0.466322, acc: 81.25%] [G loss: 2.402584]\n",
      "epoch:15 step:11773 [D loss: 0.534800, acc: 77.34%] [G loss: 3.015017]\n",
      "epoch:15 step:11774 [D loss: 0.784226, acc: 46.09%] [G loss: 1.804708]\n",
      "epoch:15 step:11775 [D loss: 0.473404, acc: 80.47%] [G loss: 2.908272]\n",
      "epoch:15 step:11776 [D loss: 0.546414, acc: 71.88%] [G loss: 2.468218]\n",
      "epoch:15 step:11777 [D loss: 0.453794, acc: 86.72%] [G loss: 2.966676]\n",
      "epoch:15 step:11778 [D loss: 0.429089, acc: 84.38%] [G loss: 3.150874]\n",
      "epoch:15 step:11779 [D loss: 0.341671, acc: 93.75%] [G loss: 2.658620]\n",
      "epoch:15 step:11780 [D loss: 0.674413, acc: 58.59%] [G loss: 2.110858]\n",
      "epoch:15 step:11781 [D loss: 0.641604, acc: 63.28%] [G loss: 2.110480]\n",
      "epoch:15 step:11782 [D loss: 0.473630, acc: 71.88%] [G loss: 2.103247]\n",
      "epoch:15 step:11783 [D loss: 0.671669, acc: 62.50%] [G loss: 2.125226]\n",
      "epoch:15 step:11784 [D loss: 0.611200, acc: 64.84%] [G loss: 2.057430]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:11785 [D loss: 0.972638, acc: 30.47%] [G loss: 1.580315]\n",
      "epoch:15 step:11786 [D loss: 0.864509, acc: 35.16%] [G loss: 2.033851]\n",
      "epoch:15 step:11787 [D loss: 1.086860, acc: 27.34%] [G loss: 1.668040]\n",
      "epoch:15 step:11788 [D loss: 0.687267, acc: 55.47%] [G loss: 1.651707]\n",
      "epoch:15 step:11789 [D loss: 0.374800, acc: 88.28%] [G loss: 2.266642]\n",
      "epoch:15 step:11790 [D loss: 0.602731, acc: 69.53%] [G loss: 2.249871]\n",
      "epoch:15 step:11791 [D loss: 0.363813, acc: 92.19%] [G loss: 2.746677]\n",
      "epoch:15 step:11792 [D loss: 0.560084, acc: 69.53%] [G loss: 2.255419]\n",
      "epoch:15 step:11793 [D loss: 0.881950, acc: 46.88%] [G loss: 2.540054]\n",
      "epoch:15 step:11794 [D loss: 0.323330, acc: 97.66%] [G loss: 2.650654]\n",
      "epoch:15 step:11795 [D loss: 0.553653, acc: 73.44%] [G loss: 2.106693]\n",
      "epoch:15 step:11796 [D loss: 0.795158, acc: 46.09%] [G loss: 2.541173]\n",
      "epoch:15 step:11797 [D loss: 0.655072, acc: 60.94%] [G loss: 2.268512]\n",
      "epoch:15 step:11798 [D loss: 0.561553, acc: 66.41%] [G loss: 2.295085]\n",
      "epoch:15 step:11799 [D loss: 1.123729, acc: 20.31%] [G loss: 1.596605]\n",
      "epoch:15 step:11800 [D loss: 0.827668, acc: 46.09%] [G loss: 1.751869]\n",
      "epoch:15 step:11801 [D loss: 0.406582, acc: 82.03%] [G loss: 2.152529]\n",
      "epoch:15 step:11802 [D loss: 0.633480, acc: 64.06%] [G loss: 2.697436]\n",
      "epoch:15 step:11803 [D loss: 0.637937, acc: 64.06%] [G loss: 2.176656]\n",
      "epoch:15 step:11804 [D loss: 0.728620, acc: 51.56%] [G loss: 2.277174]\n",
      "epoch:15 step:11805 [D loss: 0.534766, acc: 79.69%] [G loss: 2.475332]\n",
      "epoch:15 step:11806 [D loss: 0.464639, acc: 83.59%] [G loss: 2.119449]\n",
      "epoch:15 step:11807 [D loss: 1.040493, acc: 23.44%] [G loss: 1.684940]\n",
      "epoch:15 step:11808 [D loss: 0.572440, acc: 71.88%] [G loss: 2.104353]\n",
      "epoch:15 step:11809 [D loss: 0.699648, acc: 53.91%] [G loss: 2.044470]\n",
      "epoch:15 step:11810 [D loss: 0.421626, acc: 82.81%] [G loss: 2.307349]\n",
      "epoch:15 step:11811 [D loss: 0.507552, acc: 80.47%] [G loss: 2.170115]\n",
      "epoch:15 step:11812 [D loss: 0.612451, acc: 72.66%] [G loss: 1.809222]\n",
      "epoch:15 step:11813 [D loss: 0.800650, acc: 39.84%] [G loss: 1.862075]\n",
      "epoch:15 step:11814 [D loss: 0.504988, acc: 78.91%] [G loss: 2.397627]\n",
      "epoch:15 step:11815 [D loss: 0.376250, acc: 92.19%] [G loss: 2.625499]\n",
      "epoch:15 step:11816 [D loss: 0.524173, acc: 75.78%] [G loss: 2.314194]\n",
      "epoch:15 step:11817 [D loss: 0.321523, acc: 96.09%] [G loss: 2.232785]\n",
      "epoch:15 step:11818 [D loss: 0.939237, acc: 42.19%] [G loss: 2.148536]\n",
      "epoch:15 step:11819 [D loss: 0.493877, acc: 78.91%] [G loss: 2.304670]\n",
      "epoch:15 step:11820 [D loss: 0.568155, acc: 75.78%] [G loss: 2.334353]\n",
      "epoch:15 step:11821 [D loss: 0.252846, acc: 96.88%] [G loss: 2.320737]\n",
      "epoch:15 step:11822 [D loss: 0.585646, acc: 67.19%] [G loss: 2.228002]\n",
      "epoch:15 step:11823 [D loss: 0.482048, acc: 83.59%] [G loss: 2.136491]\n",
      "epoch:15 step:11824 [D loss: 0.441363, acc: 82.03%] [G loss: 2.219028]\n",
      "epoch:15 step:11825 [D loss: 0.649746, acc: 55.47%] [G loss: 2.304681]\n",
      "epoch:15 step:11826 [D loss: 0.922821, acc: 32.03%] [G loss: 2.227923]\n",
      "epoch:15 step:11827 [D loss: 0.388383, acc: 92.19%] [G loss: 2.511076]\n",
      "epoch:15 step:11828 [D loss: 0.750306, acc: 46.88%] [G loss: 1.679813]\n",
      "epoch:15 step:11829 [D loss: 0.344643, acc: 97.66%] [G loss: 2.462838]\n",
      "epoch:15 step:11830 [D loss: 0.973442, acc: 30.47%] [G loss: 1.638256]\n",
      "epoch:15 step:11831 [D loss: 0.596504, acc: 67.97%] [G loss: 2.105683]\n",
      "epoch:15 step:11832 [D loss: 0.594669, acc: 71.09%] [G loss: 2.037570]\n",
      "epoch:15 step:11833 [D loss: 0.470838, acc: 83.59%] [G loss: 2.680431]\n",
      "epoch:15 step:11834 [D loss: 0.903412, acc: 43.75%] [G loss: 1.990258]\n",
      "epoch:15 step:11835 [D loss: 0.843536, acc: 34.38%] [G loss: 2.304053]\n",
      "epoch:15 step:11836 [D loss: 0.303029, acc: 98.44%] [G loss: 1.892665]\n",
      "epoch:15 step:11837 [D loss: 0.266582, acc: 94.53%] [G loss: 2.471424]\n",
      "epoch:15 step:11838 [D loss: 0.659362, acc: 59.38%] [G loss: 2.620366]\n",
      "epoch:15 step:11839 [D loss: 0.826307, acc: 42.19%] [G loss: 1.737026]\n",
      "epoch:15 step:11840 [D loss: 0.835489, acc: 35.16%] [G loss: 2.047454]\n",
      "epoch:15 step:11841 [D loss: 0.513815, acc: 77.34%] [G loss: 2.124081]\n",
      "epoch:15 step:11842 [D loss: 0.657148, acc: 61.72%] [G loss: 2.053011]\n",
      "epoch:15 step:11843 [D loss: 0.611647, acc: 67.97%] [G loss: 2.427579]\n",
      "epoch:15 step:11844 [D loss: 0.444301, acc: 87.50%] [G loss: 2.765132]\n",
      "epoch:15 step:11845 [D loss: 0.529634, acc: 73.44%] [G loss: 2.676007]\n",
      "epoch:15 step:11846 [D loss: 0.641732, acc: 63.28%] [G loss: 2.537584]\n",
      "epoch:15 step:11847 [D loss: 0.510785, acc: 82.81%] [G loss: 2.556543]\n",
      "epoch:15 step:11848 [D loss: 0.628655, acc: 68.75%] [G loss: 2.571004]\n",
      "epoch:15 step:11849 [D loss: 0.468737, acc: 78.12%] [G loss: 2.581797]\n",
      "epoch:15 step:11850 [D loss: 0.546008, acc: 76.56%] [G loss: 1.990916]\n",
      "epoch:15 step:11851 [D loss: 0.717815, acc: 57.03%] [G loss: 2.182258]\n",
      "epoch:15 step:11852 [D loss: 0.524257, acc: 78.91%] [G loss: 2.437232]\n",
      "epoch:15 step:11853 [D loss: 0.361182, acc: 85.16%] [G loss: 3.225657]\n",
      "epoch:15 step:11854 [D loss: 0.359842, acc: 92.19%] [G loss: 2.830947]\n",
      "epoch:15 step:11855 [D loss: 0.419056, acc: 85.16%] [G loss: 2.353613]\n",
      "epoch:15 step:11856 [D loss: 0.559980, acc: 75.00%] [G loss: 3.079885]\n",
      "epoch:15 step:11857 [D loss: 0.443508, acc: 81.25%] [G loss: 2.549625]\n",
      "epoch:15 step:11858 [D loss: 0.258103, acc: 94.53%] [G loss: 2.382141]\n",
      "epoch:15 step:11859 [D loss: 0.532549, acc: 71.88%] [G loss: 2.238551]\n",
      "epoch:15 step:11860 [D loss: 0.436980, acc: 83.59%] [G loss: 2.619184]\n",
      "epoch:15 step:11861 [D loss: 0.553021, acc: 62.50%] [G loss: 2.971262]\n",
      "epoch:15 step:11862 [D loss: 0.275655, acc: 93.75%] [G loss: 2.896958]\n",
      "epoch:15 step:11863 [D loss: 0.541531, acc: 72.66%] [G loss: 2.729572]\n",
      "epoch:15 step:11864 [D loss: 0.715306, acc: 59.38%] [G loss: 2.114985]\n",
      "epoch:15 step:11865 [D loss: 0.660361, acc: 57.81%] [G loss: 1.737735]\n",
      "epoch:15 step:11866 [D loss: 0.521319, acc: 66.41%] [G loss: 2.597312]\n",
      "epoch:15 step:11867 [D loss: 0.882660, acc: 41.41%] [G loss: 1.987211]\n",
      "epoch:15 step:11868 [D loss: 0.579193, acc: 73.44%] [G loss: 2.187394]\n",
      "epoch:15 step:11869 [D loss: 0.617128, acc: 63.28%] [G loss: 3.059390]\n",
      "epoch:15 step:11870 [D loss: 0.562197, acc: 70.31%] [G loss: 2.723578]\n",
      "epoch:15 step:11871 [D loss: 0.509762, acc: 71.88%] [G loss: 2.827674]\n",
      "epoch:15 step:11872 [D loss: 0.614524, acc: 68.75%] [G loss: 2.437200]\n",
      "epoch:15 step:11873 [D loss: 0.185514, acc: 97.66%] [G loss: 2.725922]\n",
      "epoch:15 step:11874 [D loss: 0.742577, acc: 50.78%] [G loss: 1.905858]\n",
      "epoch:15 step:11875 [D loss: 0.914730, acc: 28.12%] [G loss: 1.926834]\n",
      "epoch:15 step:11876 [D loss: 0.818473, acc: 46.09%] [G loss: 2.226200]\n",
      "epoch:15 step:11877 [D loss: 0.322085, acc: 93.75%] [G loss: 2.233757]\n",
      "epoch:15 step:11878 [D loss: 0.564422, acc: 72.66%] [G loss: 2.435446]\n",
      "epoch:15 step:11879 [D loss: 0.602912, acc: 69.53%] [G loss: 2.464298]\n",
      "epoch:15 step:11880 [D loss: 0.526562, acc: 79.69%] [G loss: 1.986795]\n",
      "epoch:15 step:11881 [D loss: 0.549309, acc: 76.56%] [G loss: 2.302629]\n",
      "epoch:15 step:11882 [D loss: 0.689922, acc: 60.16%] [G loss: 2.776405]\n",
      "epoch:15 step:11883 [D loss: 0.488631, acc: 79.69%] [G loss: 2.464994]\n",
      "epoch:15 step:11884 [D loss: 0.486837, acc: 82.81%] [G loss: 2.606097]\n",
      "epoch:15 step:11885 [D loss: 0.547082, acc: 71.88%] [G loss: 2.060557]\n",
      "epoch:15 step:11886 [D loss: 0.856109, acc: 42.97%] [G loss: 1.989529]\n",
      "epoch:15 step:11887 [D loss: 0.436872, acc: 84.38%] [G loss: 2.555714]\n",
      "epoch:15 step:11888 [D loss: 0.845648, acc: 42.19%] [G loss: 2.643727]\n",
      "epoch:15 step:11889 [D loss: 0.446134, acc: 65.62%] [G loss: 2.841014]\n",
      "epoch:15 step:11890 [D loss: 0.530326, acc: 73.44%] [G loss: 2.021323]\n",
      "epoch:15 step:11891 [D loss: 1.019754, acc: 28.91%] [G loss: 2.330502]\n",
      "epoch:15 step:11892 [D loss: 0.663679, acc: 60.94%] [G loss: 3.160276]\n",
      "epoch:15 step:11893 [D loss: 1.129439, acc: 46.09%] [G loss: 1.985042]\n",
      "epoch:15 step:11894 [D loss: 0.717436, acc: 57.03%] [G loss: 2.062575]\n",
      "epoch:15 step:11895 [D loss: 0.814561, acc: 48.44%] [G loss: 1.707966]\n",
      "epoch:15 step:11896 [D loss: 0.441717, acc: 88.28%] [G loss: 2.181332]\n",
      "epoch:15 step:11897 [D loss: 0.633593, acc: 61.72%] [G loss: 1.975296]\n",
      "epoch:15 step:11898 [D loss: 0.619015, acc: 63.28%] [G loss: 2.088937]\n",
      "epoch:15 step:11899 [D loss: 0.370218, acc: 84.38%] [G loss: 2.397866]\n",
      "epoch:15 step:11900 [D loss: 0.613497, acc: 66.41%] [G loss: 2.412379]\n",
      "epoch:15 step:11901 [D loss: 0.420134, acc: 90.62%] [G loss: 2.559001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:11902 [D loss: 0.526770, acc: 74.22%] [G loss: 2.373240]\n",
      "epoch:15 step:11903 [D loss: 0.414155, acc: 89.84%] [G loss: 2.051367]\n",
      "epoch:15 step:11904 [D loss: 0.433715, acc: 77.34%] [G loss: 2.914835]\n",
      "epoch:15 step:11905 [D loss: 0.761730, acc: 55.47%] [G loss: 2.219588]\n",
      "epoch:15 step:11906 [D loss: 0.364986, acc: 92.19%] [G loss: 3.065554]\n",
      "epoch:15 step:11907 [D loss: 0.515080, acc: 78.91%] [G loss: 1.937919]\n",
      "epoch:15 step:11908 [D loss: 0.574442, acc: 66.41%] [G loss: 2.622064]\n",
      "epoch:15 step:11909 [D loss: 0.646878, acc: 65.62%] [G loss: 2.301351]\n",
      "epoch:15 step:11910 [D loss: 0.574486, acc: 75.00%] [G loss: 2.128717]\n",
      "epoch:15 step:11911 [D loss: 1.174819, acc: 16.41%] [G loss: 1.796950]\n",
      "epoch:15 step:11912 [D loss: 0.610316, acc: 67.97%] [G loss: 2.139514]\n",
      "epoch:15 step:11913 [D loss: 0.374718, acc: 91.41%] [G loss: 3.277067]\n",
      "epoch:15 step:11914 [D loss: 0.811919, acc: 45.31%] [G loss: 2.300322]\n",
      "epoch:15 step:11915 [D loss: 0.341156, acc: 92.97%] [G loss: 2.729325]\n",
      "epoch:15 step:11916 [D loss: 0.380650, acc: 85.16%] [G loss: 3.164091]\n",
      "epoch:15 step:11917 [D loss: 1.742498, acc: 0.00%] [G loss: 1.368903]\n",
      "epoch:15 step:11918 [D loss: 0.702326, acc: 57.81%] [G loss: 2.278946]\n",
      "epoch:15 step:11919 [D loss: 0.590747, acc: 69.53%] [G loss: 2.818527]\n",
      "epoch:15 step:11920 [D loss: 0.806212, acc: 50.00%] [G loss: 2.439178]\n",
      "epoch:15 step:11921 [D loss: 0.746190, acc: 48.44%] [G loss: 1.535397]\n",
      "epoch:15 step:11922 [D loss: 0.593362, acc: 67.19%] [G loss: 1.879768]\n",
      "epoch:15 step:11923 [D loss: 0.369412, acc: 96.09%] [G loss: 2.017635]\n",
      "epoch:15 step:11924 [D loss: 0.913833, acc: 29.69%] [G loss: 2.038238]\n",
      "epoch:15 step:11925 [D loss: 0.512436, acc: 77.34%] [G loss: 2.292404]\n",
      "epoch:15 step:11926 [D loss: 0.476903, acc: 80.47%] [G loss: 2.159981]\n",
      "epoch:15 step:11927 [D loss: 0.599707, acc: 72.66%] [G loss: 2.381484]\n",
      "epoch:15 step:11928 [D loss: 0.711672, acc: 54.69%] [G loss: 1.979277]\n",
      "epoch:15 step:11929 [D loss: 0.536792, acc: 76.56%] [G loss: 2.747587]\n",
      "epoch:15 step:11930 [D loss: 0.459665, acc: 88.28%] [G loss: 2.626104]\n",
      "epoch:15 step:11931 [D loss: 0.337338, acc: 94.53%] [G loss: 2.429145]\n",
      "epoch:15 step:11932 [D loss: 0.696034, acc: 59.38%] [G loss: 1.823631]\n",
      "epoch:15 step:11933 [D loss: 0.583383, acc: 75.00%] [G loss: 2.338832]\n",
      "epoch:15 step:11934 [D loss: 0.353761, acc: 88.28%] [G loss: 3.183781]\n",
      "epoch:15 step:11935 [D loss: 0.613781, acc: 69.53%] [G loss: 2.150742]\n",
      "epoch:15 step:11936 [D loss: 0.468550, acc: 82.81%] [G loss: 2.454076]\n",
      "epoch:15 step:11937 [D loss: 0.404154, acc: 77.34%] [G loss: 2.335139]\n",
      "epoch:15 step:11938 [D loss: 0.886073, acc: 49.22%] [G loss: 2.721851]\n",
      "epoch:15 step:11939 [D loss: 0.473763, acc: 82.03%] [G loss: 2.484169]\n",
      "epoch:15 step:11940 [D loss: 0.547647, acc: 75.00%] [G loss: 2.602987]\n",
      "epoch:15 step:11941 [D loss: 0.816224, acc: 38.28%] [G loss: 2.127098]\n",
      "epoch:15 step:11942 [D loss: 0.396951, acc: 88.28%] [G loss: 2.228892]\n",
      "epoch:15 step:11943 [D loss: 0.582212, acc: 71.09%] [G loss: 2.070497]\n",
      "epoch:15 step:11944 [D loss: 0.824484, acc: 42.19%] [G loss: 1.592006]\n",
      "epoch:15 step:11945 [D loss: 0.853848, acc: 47.66%] [G loss: 1.908745]\n",
      "epoch:15 step:11946 [D loss: 0.529736, acc: 74.22%] [G loss: 1.971394]\n",
      "epoch:15 step:11947 [D loss: 0.904038, acc: 36.72%] [G loss: 2.327591]\n",
      "epoch:15 step:11948 [D loss: 0.520169, acc: 82.03%] [G loss: 2.342546]\n",
      "epoch:15 step:11949 [D loss: 0.967513, acc: 39.84%] [G loss: 1.723754]\n",
      "epoch:15 step:11950 [D loss: 0.576997, acc: 70.31%] [G loss: 1.998311]\n",
      "epoch:15 step:11951 [D loss: 0.947530, acc: 29.69%] [G loss: 2.107717]\n",
      "epoch:15 step:11952 [D loss: 0.763260, acc: 45.31%] [G loss: 1.883157]\n",
      "epoch:15 step:11953 [D loss: 0.576394, acc: 68.75%] [G loss: 2.041902]\n",
      "epoch:15 step:11954 [D loss: 0.582447, acc: 64.84%] [G loss: 2.715662]\n",
      "epoch:15 step:11955 [D loss: 0.902084, acc: 42.97%] [G loss: 1.958466]\n",
      "epoch:15 step:11956 [D loss: 0.424595, acc: 89.84%] [G loss: 2.872046]\n",
      "epoch:15 step:11957 [D loss: 0.676242, acc: 58.59%] [G loss: 2.755721]\n",
      "epoch:15 step:11958 [D loss: 0.618226, acc: 62.50%] [G loss: 2.387621]\n",
      "epoch:15 step:11959 [D loss: 0.589701, acc: 67.19%] [G loss: 2.229162]\n",
      "epoch:15 step:11960 [D loss: 0.835853, acc: 48.44%] [G loss: 2.193838]\n",
      "epoch:15 step:11961 [D loss: 0.414646, acc: 88.28%] [G loss: 2.765631]\n",
      "epoch:15 step:11962 [D loss: 0.536529, acc: 78.12%] [G loss: 2.342227]\n",
      "epoch:15 step:11963 [D loss: 0.617278, acc: 60.16%] [G loss: 2.027958]\n",
      "epoch:15 step:11964 [D loss: 0.407635, acc: 83.59%] [G loss: 2.647621]\n",
      "epoch:15 step:11965 [D loss: 0.450247, acc: 79.69%] [G loss: 2.532528]\n",
      "epoch:15 step:11966 [D loss: 0.588208, acc: 69.53%] [G loss: 2.367736]\n",
      "epoch:15 step:11967 [D loss: 0.388870, acc: 89.06%] [G loss: 2.695490]\n",
      "epoch:15 step:11968 [D loss: 0.483743, acc: 76.56%] [G loss: 2.323232]\n",
      "epoch:15 step:11969 [D loss: 0.547300, acc: 75.78%] [G loss: 2.040879]\n",
      "epoch:15 step:11970 [D loss: 0.592571, acc: 65.62%] [G loss: 1.790541]\n",
      "epoch:15 step:11971 [D loss: 0.696742, acc: 61.72%] [G loss: 2.300062]\n",
      "epoch:15 step:11972 [D loss: 1.124830, acc: 25.00%] [G loss: 1.713243]\n",
      "epoch:15 step:11973 [D loss: 0.724539, acc: 50.78%] [G loss: 1.861345]\n",
      "epoch:15 step:11974 [D loss: 0.505968, acc: 79.69%] [G loss: 2.039552]\n",
      "epoch:15 step:11975 [D loss: 0.599667, acc: 64.84%] [G loss: 2.311721]\n",
      "epoch:15 step:11976 [D loss: 0.535054, acc: 74.22%] [G loss: 2.546981]\n",
      "epoch:15 step:11977 [D loss: 0.417654, acc: 91.41%] [G loss: 2.222354]\n",
      "epoch:15 step:11978 [D loss: 0.900638, acc: 35.94%] [G loss: 1.806453]\n",
      "epoch:15 step:11979 [D loss: 0.558988, acc: 69.53%] [G loss: 2.334090]\n",
      "epoch:15 step:11980 [D loss: 0.352971, acc: 92.19%] [G loss: 2.723460]\n",
      "epoch:15 step:11981 [D loss: 0.483713, acc: 81.25%] [G loss: 2.163047]\n",
      "epoch:15 step:11982 [D loss: 1.293038, acc: 22.66%] [G loss: 1.366411]\n",
      "epoch:15 step:11983 [D loss: 0.642022, acc: 60.94%] [G loss: 2.090796]\n",
      "epoch:15 step:11984 [D loss: 0.942802, acc: 30.47%] [G loss: 1.857483]\n",
      "epoch:15 step:11985 [D loss: 0.333119, acc: 92.97%] [G loss: 2.987065]\n",
      "epoch:15 step:11986 [D loss: 0.477534, acc: 78.91%] [G loss: 2.232948]\n",
      "epoch:15 step:11987 [D loss: 0.689821, acc: 56.25%] [G loss: 2.075301]\n",
      "epoch:15 step:11988 [D loss: 0.706359, acc: 56.25%] [G loss: 2.397923]\n",
      "epoch:15 step:11989 [D loss: 0.789796, acc: 50.00%] [G loss: 1.985638]\n",
      "epoch:15 step:11990 [D loss: 0.534779, acc: 76.56%] [G loss: 2.103777]\n",
      "epoch:15 step:11991 [D loss: 0.835658, acc: 49.22%] [G loss: 2.124618]\n",
      "epoch:15 step:11992 [D loss: 0.853915, acc: 42.97%] [G loss: 1.724530]\n",
      "epoch:15 step:11993 [D loss: 0.644268, acc: 64.84%] [G loss: 2.178078]\n",
      "epoch:15 step:11994 [D loss: 0.471650, acc: 78.91%] [G loss: 2.155011]\n",
      "epoch:15 step:11995 [D loss: 0.530818, acc: 79.69%] [G loss: 2.408202]\n",
      "epoch:15 step:11996 [D loss: 0.447132, acc: 85.16%] [G loss: 2.515300]\n",
      "epoch:15 step:11997 [D loss: 0.650894, acc: 66.41%] [G loss: 2.118505]\n",
      "epoch:15 step:11998 [D loss: 0.460753, acc: 89.06%] [G loss: 2.151282]\n",
      "epoch:15 step:11999 [D loss: 0.458400, acc: 83.59%] [G loss: 2.668433]\n",
      "epoch:15 step:12000 [D loss: 0.547946, acc: 78.91%] [G loss: 2.188577]\n",
      "epoch:15 step:12001 [D loss: 0.638673, acc: 67.19%] [G loss: 2.199933]\n",
      "epoch:15 step:12002 [D loss: 0.551271, acc: 76.56%] [G loss: 2.480903]\n",
      "epoch:15 step:12003 [D loss: 0.713539, acc: 54.69%] [G loss: 2.138582]\n",
      "epoch:15 step:12004 [D loss: 0.371424, acc: 85.16%] [G loss: 3.403209]\n",
      "epoch:15 step:12005 [D loss: 0.610268, acc: 66.41%] [G loss: 2.072541]\n",
      "epoch:15 step:12006 [D loss: 0.377003, acc: 91.41%] [G loss: 2.249812]\n",
      "epoch:15 step:12007 [D loss: 0.536291, acc: 74.22%] [G loss: 2.114949]\n",
      "epoch:15 step:12008 [D loss: 0.582913, acc: 67.97%] [G loss: 2.208372]\n",
      "epoch:15 step:12009 [D loss: 0.633174, acc: 60.94%] [G loss: 2.755507]\n",
      "epoch:15 step:12010 [D loss: 0.409315, acc: 85.16%] [G loss: 2.491342]\n",
      "epoch:15 step:12011 [D loss: 0.372144, acc: 88.28%] [G loss: 2.503007]\n",
      "epoch:15 step:12012 [D loss: 0.956946, acc: 28.12%] [G loss: 2.321431]\n",
      "epoch:15 step:12013 [D loss: 0.489734, acc: 81.25%] [G loss: 2.244533]\n",
      "epoch:15 step:12014 [D loss: 0.907255, acc: 49.22%] [G loss: 2.285477]\n",
      "epoch:15 step:12015 [D loss: 0.834077, acc: 51.56%] [G loss: 2.292128]\n",
      "epoch:15 step:12016 [D loss: 0.856151, acc: 40.62%] [G loss: 1.771799]\n",
      "epoch:15 step:12017 [D loss: 0.801550, acc: 51.56%] [G loss: 2.371962]\n",
      "epoch:15 step:12018 [D loss: 0.536396, acc: 71.09%] [G loss: 2.328625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12019 [D loss: 0.666936, acc: 54.69%] [G loss: 1.795443]\n",
      "epoch:15 step:12020 [D loss: 0.791708, acc: 45.31%] [G loss: 1.891874]\n",
      "epoch:15 step:12021 [D loss: 0.533913, acc: 75.78%] [G loss: 2.405288]\n",
      "epoch:15 step:12022 [D loss: 0.617944, acc: 66.41%] [G loss: 2.205353]\n",
      "epoch:15 step:12023 [D loss: 0.528555, acc: 77.34%] [G loss: 2.430511]\n",
      "epoch:15 step:12024 [D loss: 0.437432, acc: 87.50%] [G loss: 2.526999]\n",
      "epoch:15 step:12025 [D loss: 0.636854, acc: 66.41%] [G loss: 2.470260]\n",
      "epoch:15 step:12026 [D loss: 0.686373, acc: 53.12%] [G loss: 2.028144]\n",
      "epoch:15 step:12027 [D loss: 0.627690, acc: 64.06%] [G loss: 2.274701]\n",
      "epoch:15 step:12028 [D loss: 0.532406, acc: 80.47%] [G loss: 2.166234]\n",
      "epoch:15 step:12029 [D loss: 0.417629, acc: 90.62%] [G loss: 2.294018]\n",
      "epoch:15 step:12030 [D loss: 0.989525, acc: 25.78%] [G loss: 2.182151]\n",
      "epoch:15 step:12031 [D loss: 0.570698, acc: 68.75%] [G loss: 2.582684]\n",
      "epoch:15 step:12032 [D loss: 0.456649, acc: 85.94%] [G loss: 2.464084]\n",
      "epoch:15 step:12033 [D loss: 0.507251, acc: 74.22%] [G loss: 2.290835]\n",
      "epoch:15 step:12034 [D loss: 0.801499, acc: 43.75%] [G loss: 1.935892]\n",
      "epoch:15 step:12035 [D loss: 0.818219, acc: 45.31%] [G loss: 2.025674]\n",
      "epoch:15 step:12036 [D loss: 0.575219, acc: 71.88%] [G loss: 2.322718]\n",
      "epoch:15 step:12037 [D loss: 0.646129, acc: 64.84%] [G loss: 1.739642]\n",
      "epoch:15 step:12038 [D loss: 0.656056, acc: 60.94%] [G loss: 2.555942]\n",
      "epoch:15 step:12039 [D loss: 0.570942, acc: 68.75%] [G loss: 2.696873]\n",
      "epoch:15 step:12040 [D loss: 0.755632, acc: 47.66%] [G loss: 2.460828]\n",
      "epoch:15 step:12041 [D loss: 0.388363, acc: 86.72%] [G loss: 2.330860]\n",
      "epoch:15 step:12042 [D loss: 0.373657, acc: 93.75%] [G loss: 2.932708]\n",
      "epoch:15 step:12043 [D loss: 0.666061, acc: 57.81%] [G loss: 2.124098]\n",
      "epoch:15 step:12044 [D loss: 0.448825, acc: 84.38%] [G loss: 2.351456]\n",
      "epoch:15 step:12045 [D loss: 0.717754, acc: 50.78%] [G loss: 2.071422]\n",
      "epoch:15 step:12046 [D loss: 0.505947, acc: 82.81%] [G loss: 1.823084]\n",
      "epoch:15 step:12047 [D loss: 0.514192, acc: 78.91%] [G loss: 2.082692]\n",
      "epoch:15 step:12048 [D loss: 0.402834, acc: 87.50%] [G loss: 2.336781]\n",
      "epoch:15 step:12049 [D loss: 0.702288, acc: 54.69%] [G loss: 2.557863]\n",
      "epoch:15 step:12050 [D loss: 0.538669, acc: 80.47%] [G loss: 2.100244]\n",
      "epoch:15 step:12051 [D loss: 0.882724, acc: 42.19%] [G loss: 1.833183]\n",
      "epoch:15 step:12052 [D loss: 0.760140, acc: 52.34%] [G loss: 2.312034]\n",
      "epoch:15 step:12053 [D loss: 0.671454, acc: 58.59%] [G loss: 2.538710]\n",
      "epoch:15 step:12054 [D loss: 0.531803, acc: 68.75%] [G loss: 2.336682]\n",
      "epoch:15 step:12055 [D loss: 0.720035, acc: 52.34%] [G loss: 2.511130]\n",
      "epoch:15 step:12056 [D loss: 0.565174, acc: 69.53%] [G loss: 2.468462]\n",
      "epoch:15 step:12057 [D loss: 0.755848, acc: 48.44%] [G loss: 1.924732]\n",
      "epoch:15 step:12058 [D loss: 0.609754, acc: 60.94%] [G loss: 2.747019]\n",
      "epoch:15 step:12059 [D loss: 0.547704, acc: 74.22%] [G loss: 3.071952]\n",
      "epoch:15 step:12060 [D loss: 0.648520, acc: 60.16%] [G loss: 1.857338]\n",
      "epoch:15 step:12061 [D loss: 0.445926, acc: 88.28%] [G loss: 2.589406]\n",
      "epoch:15 step:12062 [D loss: 0.507818, acc: 68.75%] [G loss: 2.701407]\n",
      "epoch:15 step:12063 [D loss: 0.635839, acc: 61.72%] [G loss: 1.905980]\n",
      "epoch:15 step:12064 [D loss: 0.565399, acc: 71.09%] [G loss: 2.559189]\n",
      "epoch:15 step:12065 [D loss: 0.602265, acc: 67.97%] [G loss: 2.674379]\n",
      "epoch:15 step:12066 [D loss: 0.676163, acc: 55.47%] [G loss: 2.174236]\n",
      "epoch:15 step:12067 [D loss: 0.374215, acc: 92.19%] [G loss: 2.622526]\n",
      "epoch:15 step:12068 [D loss: 0.387541, acc: 91.41%] [G loss: 3.292911]\n",
      "epoch:15 step:12069 [D loss: 0.660300, acc: 63.28%] [G loss: 1.830724]\n",
      "epoch:15 step:12070 [D loss: 0.618266, acc: 65.62%] [G loss: 2.140620]\n",
      "epoch:15 step:12071 [D loss: 0.512673, acc: 82.81%] [G loss: 2.467752]\n",
      "epoch:15 step:12072 [D loss: 0.424297, acc: 87.50%] [G loss: 2.565990]\n",
      "epoch:15 step:12073 [D loss: 0.499697, acc: 73.44%] [G loss: 1.951916]\n",
      "epoch:15 step:12074 [D loss: 0.914641, acc: 32.81%] [G loss: 1.974042]\n",
      "epoch:15 step:12075 [D loss: 0.766964, acc: 45.31%] [G loss: 1.946420]\n",
      "epoch:15 step:12076 [D loss: 0.549020, acc: 76.56%] [G loss: 2.673312]\n",
      "epoch:15 step:12077 [D loss: 0.544000, acc: 77.34%] [G loss: 2.105711]\n",
      "epoch:15 step:12078 [D loss: 0.416105, acc: 88.28%] [G loss: 3.638855]\n",
      "epoch:15 step:12079 [D loss: 0.362056, acc: 91.41%] [G loss: 2.821844]\n",
      "epoch:15 step:12080 [D loss: 0.633584, acc: 64.06%] [G loss: 2.368845]\n",
      "epoch:15 step:12081 [D loss: 0.649173, acc: 62.50%] [G loss: 2.615658]\n",
      "epoch:15 step:12082 [D loss: 0.490321, acc: 75.00%] [G loss: 2.591924]\n",
      "epoch:15 step:12083 [D loss: 0.732462, acc: 50.78%] [G loss: 2.398062]\n",
      "epoch:15 step:12084 [D loss: 0.444466, acc: 85.16%] [G loss: 2.792845]\n",
      "epoch:15 step:12085 [D loss: 0.357862, acc: 92.97%] [G loss: 2.346563]\n",
      "epoch:15 step:12086 [D loss: 0.302253, acc: 97.66%] [G loss: 2.464705]\n",
      "epoch:15 step:12087 [D loss: 0.919478, acc: 28.91%] [G loss: 2.017645]\n",
      "epoch:15 step:12088 [D loss: 0.608102, acc: 64.84%] [G loss: 1.798473]\n",
      "epoch:15 step:12089 [D loss: 0.362834, acc: 96.88%] [G loss: 3.203917]\n",
      "epoch:15 step:12090 [D loss: 0.779251, acc: 50.78%] [G loss: 1.727212]\n",
      "epoch:15 step:12091 [D loss: 0.500617, acc: 77.34%] [G loss: 2.521926]\n",
      "epoch:15 step:12092 [D loss: 0.554426, acc: 65.62%] [G loss: 3.114046]\n",
      "epoch:15 step:12093 [D loss: 0.654706, acc: 60.94%] [G loss: 2.207248]\n",
      "epoch:15 step:12094 [D loss: 0.531331, acc: 75.00%] [G loss: 2.508063]\n",
      "epoch:15 step:12095 [D loss: 0.485945, acc: 80.47%] [G loss: 2.482123]\n",
      "epoch:15 step:12096 [D loss: 0.361822, acc: 91.41%] [G loss: 3.004838]\n",
      "epoch:15 step:12097 [D loss: 0.561251, acc: 68.75%] [G loss: 2.645149]\n",
      "epoch:15 step:12098 [D loss: 0.862114, acc: 42.97%] [G loss: 2.051841]\n",
      "epoch:15 step:12099 [D loss: 0.547318, acc: 74.22%] [G loss: 2.807822]\n",
      "epoch:15 step:12100 [D loss: 0.635378, acc: 64.06%] [G loss: 2.445122]\n",
      "epoch:15 step:12101 [D loss: 0.616900, acc: 60.16%] [G loss: 3.223137]\n",
      "epoch:15 step:12102 [D loss: 0.782465, acc: 50.00%] [G loss: 1.629133]\n",
      "epoch:15 step:12103 [D loss: 0.701092, acc: 53.91%] [G loss: 1.949066]\n",
      "epoch:15 step:12104 [D loss: 0.510895, acc: 80.47%] [G loss: 2.317649]\n",
      "epoch:15 step:12105 [D loss: 0.566563, acc: 64.06%] [G loss: 2.044107]\n",
      "epoch:15 step:12106 [D loss: 0.984925, acc: 25.00%] [G loss: 1.812914]\n",
      "epoch:15 step:12107 [D loss: 0.607023, acc: 64.06%] [G loss: 2.482880]\n",
      "epoch:15 step:12108 [D loss: 0.649870, acc: 58.59%] [G loss: 2.437171]\n",
      "epoch:15 step:12109 [D loss: 0.795381, acc: 42.97%] [G loss: 1.861680]\n",
      "epoch:15 step:12110 [D loss: 0.605419, acc: 63.28%] [G loss: 2.610706]\n",
      "epoch:15 step:12111 [D loss: 0.754327, acc: 48.44%] [G loss: 2.198569]\n",
      "epoch:15 step:12112 [D loss: 0.707680, acc: 52.34%] [G loss: 1.781709]\n",
      "epoch:15 step:12113 [D loss: 0.541981, acc: 76.56%] [G loss: 2.484527]\n",
      "epoch:15 step:12114 [D loss: 0.479047, acc: 78.91%] [G loss: 2.586999]\n",
      "epoch:15 step:12115 [D loss: 0.554477, acc: 74.22%] [G loss: 2.458460]\n",
      "epoch:15 step:12116 [D loss: 0.262392, acc: 92.97%] [G loss: 3.214019]\n",
      "epoch:15 step:12117 [D loss: 0.783791, acc: 42.97%] [G loss: 1.972247]\n",
      "epoch:15 step:12118 [D loss: 0.670588, acc: 56.25%] [G loss: 2.722808]\n",
      "epoch:15 step:12119 [D loss: 0.605965, acc: 68.75%] [G loss: 2.261807]\n",
      "epoch:15 step:12120 [D loss: 0.810402, acc: 39.06%] [G loss: 2.509131]\n",
      "epoch:15 step:12121 [D loss: 0.537645, acc: 75.00%] [G loss: 2.532788]\n",
      "epoch:15 step:12122 [D loss: 0.561008, acc: 70.31%] [G loss: 2.348437]\n",
      "epoch:15 step:12123 [D loss: 0.524185, acc: 85.94%] [G loss: 2.376133]\n",
      "epoch:15 step:12124 [D loss: 0.437169, acc: 88.28%] [G loss: 2.492881]\n",
      "epoch:15 step:12125 [D loss: 0.749894, acc: 50.00%] [G loss: 2.365443]\n",
      "epoch:15 step:12126 [D loss: 0.620177, acc: 64.84%] [G loss: 2.667714]\n",
      "epoch:15 step:12127 [D loss: 0.356740, acc: 89.06%] [G loss: 3.118814]\n",
      "epoch:15 step:12128 [D loss: 0.748055, acc: 43.75%] [G loss: 2.601986]\n",
      "epoch:15 step:12129 [D loss: 0.514616, acc: 78.12%] [G loss: 2.169362]\n",
      "epoch:15 step:12130 [D loss: 0.404115, acc: 88.28%] [G loss: 2.950383]\n",
      "epoch:15 step:12131 [D loss: 0.469476, acc: 88.28%] [G loss: 2.415699]\n",
      "epoch:15 step:12132 [D loss: 0.507072, acc: 81.25%] [G loss: 2.761373]\n",
      "epoch:15 step:12133 [D loss: 0.666145, acc: 60.16%] [G loss: 1.987848]\n",
      "epoch:15 step:12134 [D loss: 0.509454, acc: 67.97%] [G loss: 2.685585]\n",
      "epoch:15 step:12135 [D loss: 0.618743, acc: 67.97%] [G loss: 2.402428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12136 [D loss: 0.600614, acc: 66.41%] [G loss: 2.163656]\n",
      "epoch:15 step:12137 [D loss: 0.400998, acc: 91.41%] [G loss: 2.290778]\n",
      "epoch:15 step:12138 [D loss: 0.637113, acc: 60.94%] [G loss: 2.199847]\n",
      "epoch:15 step:12139 [D loss: 0.529167, acc: 80.47%] [G loss: 2.594485]\n",
      "epoch:15 step:12140 [D loss: 0.464637, acc: 84.38%] [G loss: 2.778181]\n",
      "epoch:15 step:12141 [D loss: 0.865963, acc: 39.84%] [G loss: 1.943592]\n",
      "epoch:15 step:12142 [D loss: 0.360760, acc: 85.94%] [G loss: 2.664081]\n",
      "epoch:15 step:12143 [D loss: 0.690934, acc: 56.25%] [G loss: 2.552067]\n",
      "epoch:15 step:12144 [D loss: 1.033239, acc: 27.34%] [G loss: 1.643034]\n",
      "epoch:15 step:12145 [D loss: 0.583865, acc: 66.41%] [G loss: 2.066851]\n",
      "epoch:15 step:12146 [D loss: 0.531555, acc: 75.00%] [G loss: 2.188290]\n",
      "epoch:15 step:12147 [D loss: 0.658710, acc: 61.72%] [G loss: 2.303724]\n",
      "epoch:15 step:12148 [D loss: 0.335126, acc: 93.75%] [G loss: 2.801057]\n",
      "epoch:15 step:12149 [D loss: 0.722188, acc: 48.44%] [G loss: 1.917675]\n",
      "epoch:15 step:12150 [D loss: 0.576755, acc: 72.66%] [G loss: 2.486366]\n",
      "epoch:15 step:12151 [D loss: 0.769914, acc: 49.22%] [G loss: 1.964026]\n",
      "epoch:15 step:12152 [D loss: 0.600666, acc: 69.53%] [G loss: 2.650522]\n",
      "epoch:15 step:12153 [D loss: 0.700907, acc: 57.81%] [G loss: 2.400032]\n",
      "epoch:15 step:12154 [D loss: 0.455745, acc: 85.16%] [G loss: 2.832565]\n",
      "epoch:15 step:12155 [D loss: 0.842531, acc: 35.94%] [G loss: 2.099433]\n",
      "epoch:15 step:12156 [D loss: 0.652717, acc: 59.38%] [G loss: 2.201242]\n",
      "epoch:15 step:12157 [D loss: 0.747766, acc: 50.00%] [G loss: 2.369958]\n",
      "epoch:15 step:12158 [D loss: 0.446296, acc: 78.91%] [G loss: 2.709683]\n",
      "epoch:15 step:12159 [D loss: 0.635631, acc: 63.28%] [G loss: 2.454783]\n",
      "epoch:15 step:12160 [D loss: 0.859395, acc: 42.97%] [G loss: 1.776747]\n",
      "epoch:15 step:12161 [D loss: 0.294210, acc: 96.88%] [G loss: 2.352271]\n",
      "epoch:15 step:12162 [D loss: 0.748304, acc: 53.91%] [G loss: 2.015952]\n",
      "epoch:15 step:12163 [D loss: 0.501227, acc: 80.47%] [G loss: 2.670379]\n",
      "epoch:15 step:12164 [D loss: 0.441117, acc: 73.44%] [G loss: 3.339950]\n",
      "epoch:15 step:12165 [D loss: 0.746150, acc: 50.78%] [G loss: 1.983363]\n",
      "epoch:15 step:12166 [D loss: 0.554865, acc: 68.75%] [G loss: 2.560978]\n",
      "epoch:15 step:12167 [D loss: 0.777245, acc: 44.53%] [G loss: 2.138803]\n",
      "epoch:15 step:12168 [D loss: 0.714138, acc: 58.59%] [G loss: 2.899405]\n",
      "epoch:15 step:12169 [D loss: 0.595580, acc: 69.53%] [G loss: 2.208718]\n",
      "epoch:15 step:12170 [D loss: 0.652501, acc: 60.94%] [G loss: 1.845158]\n",
      "epoch:15 step:12171 [D loss: 0.698228, acc: 59.38%] [G loss: 2.219903]\n",
      "epoch:15 step:12172 [D loss: 0.495622, acc: 78.12%] [G loss: 2.384521]\n",
      "epoch:15 step:12173 [D loss: 1.124805, acc: 20.31%] [G loss: 1.849134]\n",
      "epoch:15 step:12174 [D loss: 0.537481, acc: 78.12%] [G loss: 2.253578]\n",
      "epoch:15 step:12175 [D loss: 0.427032, acc: 86.72%] [G loss: 2.352066]\n",
      "epoch:15 step:12176 [D loss: 0.585913, acc: 68.75%] [G loss: 3.195196]\n",
      "epoch:15 step:12177 [D loss: 0.554294, acc: 75.00%] [G loss: 2.015021]\n",
      "epoch:15 step:12178 [D loss: 0.579221, acc: 62.50%] [G loss: 2.309042]\n",
      "epoch:15 step:12179 [D loss: 0.538639, acc: 71.09%] [G loss: 2.589169]\n",
      "epoch:15 step:12180 [D loss: 0.702578, acc: 55.47%] [G loss: 2.230567]\n",
      "epoch:15 step:12181 [D loss: 0.319092, acc: 89.84%] [G loss: 3.421366]\n",
      "epoch:15 step:12182 [D loss: 0.448631, acc: 89.06%] [G loss: 2.449729]\n",
      "epoch:15 step:12183 [D loss: 0.603128, acc: 71.88%] [G loss: 2.289367]\n",
      "epoch:15 step:12184 [D loss: 0.439864, acc: 85.94%] [G loss: 3.122293]\n",
      "epoch:15 step:12185 [D loss: 0.461572, acc: 81.25%] [G loss: 2.230806]\n",
      "epoch:15 step:12186 [D loss: 0.417022, acc: 81.25%] [G loss: 3.295775]\n",
      "epoch:15 step:12187 [D loss: 0.721473, acc: 52.34%] [G loss: 2.091575]\n",
      "epoch:15 step:12188 [D loss: 0.312161, acc: 96.09%] [G loss: 2.474478]\n",
      "epoch:15 step:12189 [D loss: 0.611575, acc: 64.06%] [G loss: 2.438116]\n",
      "epoch:15 step:12190 [D loss: 0.943880, acc: 37.50%] [G loss: 1.847148]\n",
      "epoch:15 step:12191 [D loss: 0.434023, acc: 85.16%] [G loss: 2.588489]\n",
      "epoch:15 step:12192 [D loss: 0.320273, acc: 95.31%] [G loss: 3.005826]\n",
      "epoch:15 step:12193 [D loss: 0.355179, acc: 91.41%] [G loss: 3.387079]\n",
      "epoch:15 step:12194 [D loss: 0.619117, acc: 65.62%] [G loss: 2.291720]\n",
      "epoch:15 step:12195 [D loss: 0.595542, acc: 69.53%] [G loss: 2.824942]\n",
      "epoch:15 step:12196 [D loss: 0.560639, acc: 72.66%] [G loss: 2.282403]\n",
      "epoch:15 step:12197 [D loss: 0.661126, acc: 57.81%] [G loss: 2.113254]\n",
      "epoch:15 step:12198 [D loss: 0.459895, acc: 82.81%] [G loss: 2.475636]\n",
      "epoch:15 step:12199 [D loss: 0.546867, acc: 76.56%] [G loss: 3.211927]\n",
      "epoch:15 step:12200 [D loss: 0.396107, acc: 89.06%] [G loss: 2.741718]\n",
      "epoch:15 step:12201 [D loss: 0.496586, acc: 77.34%] [G loss: 2.463666]\n",
      "epoch:15 step:12202 [D loss: 0.672219, acc: 57.03%] [G loss: 2.852021]\n",
      "epoch:15 step:12203 [D loss: 0.593709, acc: 67.97%] [G loss: 2.496415]\n",
      "epoch:15 step:12204 [D loss: 0.798537, acc: 43.75%] [G loss: 2.343867]\n",
      "epoch:15 step:12205 [D loss: 0.417533, acc: 92.19%] [G loss: 2.680962]\n",
      "epoch:15 step:12206 [D loss: 0.642726, acc: 64.84%] [G loss: 2.541195]\n",
      "epoch:15 step:12207 [D loss: 0.593648, acc: 69.53%] [G loss: 2.372214]\n",
      "epoch:15 step:12208 [D loss: 0.610551, acc: 69.53%] [G loss: 2.487828]\n",
      "epoch:15 step:12209 [D loss: 0.492651, acc: 85.16%] [G loss: 2.617081]\n",
      "epoch:15 step:12210 [D loss: 0.566978, acc: 64.06%] [G loss: 2.314306]\n",
      "epoch:15 step:12211 [D loss: 0.456308, acc: 82.81%] [G loss: 3.256779]\n",
      "epoch:15 step:12212 [D loss: 0.372116, acc: 95.31%] [G loss: 2.520289]\n",
      "epoch:15 step:12213 [D loss: 0.352572, acc: 91.41%] [G loss: 2.927323]\n",
      "epoch:15 step:12214 [D loss: 0.702435, acc: 57.03%] [G loss: 2.504512]\n",
      "epoch:15 step:12215 [D loss: 0.842406, acc: 42.97%] [G loss: 1.863473]\n",
      "epoch:15 step:12216 [D loss: 0.623184, acc: 60.94%] [G loss: 2.148395]\n",
      "epoch:15 step:12217 [D loss: 0.750339, acc: 50.00%] [G loss: 2.507037]\n",
      "epoch:15 step:12218 [D loss: 0.634323, acc: 65.62%] [G loss: 3.082636]\n",
      "epoch:15 step:12219 [D loss: 0.714760, acc: 55.47%] [G loss: 2.132100]\n",
      "epoch:15 step:12220 [D loss: 0.731649, acc: 49.22%] [G loss: 3.201762]\n",
      "epoch:15 step:12221 [D loss: 0.456838, acc: 84.38%] [G loss: 3.111244]\n",
      "epoch:15 step:12222 [D loss: 0.629491, acc: 61.72%] [G loss: 2.314387]\n",
      "epoch:15 step:12223 [D loss: 0.730869, acc: 51.56%] [G loss: 1.864562]\n",
      "epoch:15 step:12224 [D loss: 0.515917, acc: 77.34%] [G loss: 2.965954]\n",
      "epoch:15 step:12225 [D loss: 0.304092, acc: 90.62%] [G loss: 3.360749]\n",
      "epoch:15 step:12226 [D loss: 0.419848, acc: 82.81%] [G loss: 2.559380]\n",
      "epoch:15 step:12227 [D loss: 0.481924, acc: 81.25%] [G loss: 2.304354]\n",
      "epoch:15 step:12228 [D loss: 0.514316, acc: 77.34%] [G loss: 2.012574]\n",
      "epoch:15 step:12229 [D loss: 0.672910, acc: 57.03%] [G loss: 2.702644]\n",
      "epoch:15 step:12230 [D loss: 0.749456, acc: 55.47%] [G loss: 1.950800]\n",
      "epoch:15 step:12231 [D loss: 0.567268, acc: 71.09%] [G loss: 2.088851]\n",
      "epoch:15 step:12232 [D loss: 0.602786, acc: 59.38%] [G loss: 2.589782]\n",
      "epoch:15 step:12233 [D loss: 0.533763, acc: 71.09%] [G loss: 1.982886]\n",
      "epoch:15 step:12234 [D loss: 0.690659, acc: 53.12%] [G loss: 3.169882]\n",
      "epoch:15 step:12235 [D loss: 0.776265, acc: 54.69%] [G loss: 2.510939]\n",
      "epoch:15 step:12236 [D loss: 0.496705, acc: 74.22%] [G loss: 2.506733]\n",
      "epoch:15 step:12237 [D loss: 0.521284, acc: 70.31%] [G loss: 2.384071]\n",
      "epoch:15 step:12238 [D loss: 0.759604, acc: 52.34%] [G loss: 3.732138]\n",
      "epoch:15 step:12239 [D loss: 0.655028, acc: 55.47%] [G loss: 2.166720]\n",
      "epoch:15 step:12240 [D loss: 0.656065, acc: 56.25%] [G loss: 2.285876]\n",
      "epoch:15 step:12241 [D loss: 1.013456, acc: 32.81%] [G loss: 1.717142]\n",
      "epoch:15 step:12242 [D loss: 0.902358, acc: 37.50%] [G loss: 2.129382]\n",
      "epoch:15 step:12243 [D loss: 0.583547, acc: 65.62%] [G loss: 2.310875]\n",
      "epoch:15 step:12244 [D loss: 0.598361, acc: 68.75%] [G loss: 2.085757]\n",
      "epoch:15 step:12245 [D loss: 0.699666, acc: 53.12%] [G loss: 2.468523]\n",
      "epoch:15 step:12246 [D loss: 0.654116, acc: 63.28%] [G loss: 2.189945]\n",
      "epoch:15 step:12247 [D loss: 0.676565, acc: 57.03%] [G loss: 2.948215]\n",
      "epoch:15 step:12248 [D loss: 0.431019, acc: 83.59%] [G loss: 3.520008]\n",
      "epoch:15 step:12249 [D loss: 0.728760, acc: 53.91%] [G loss: 2.367805]\n",
      "epoch:15 step:12250 [D loss: 0.362712, acc: 85.94%] [G loss: 2.751086]\n",
      "epoch:15 step:12251 [D loss: 0.486512, acc: 80.47%] [G loss: 3.119124]\n",
      "epoch:15 step:12252 [D loss: 0.551598, acc: 67.97%] [G loss: 2.326086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12253 [D loss: 0.414718, acc: 88.28%] [G loss: 3.020374]\n",
      "epoch:15 step:12254 [D loss: 0.653993, acc: 63.28%] [G loss: 2.178371]\n",
      "epoch:15 step:12255 [D loss: 0.461032, acc: 75.78%] [G loss: 2.726649]\n",
      "epoch:15 step:12256 [D loss: 0.518274, acc: 80.47%] [G loss: 2.816774]\n",
      "epoch:15 step:12257 [D loss: 0.375031, acc: 90.62%] [G loss: 3.195834]\n",
      "epoch:15 step:12258 [D loss: 0.389375, acc: 90.62%] [G loss: 2.213839]\n",
      "epoch:15 step:12259 [D loss: 0.758263, acc: 50.00%] [G loss: 2.806575]\n",
      "epoch:15 step:12260 [D loss: 0.297721, acc: 89.06%] [G loss: 3.420852]\n",
      "epoch:15 step:12261 [D loss: 0.607125, acc: 64.84%] [G loss: 2.440640]\n",
      "epoch:15 step:12262 [D loss: 0.506618, acc: 82.03%] [G loss: 3.093536]\n",
      "epoch:15 step:12263 [D loss: 0.629199, acc: 67.19%] [G loss: 2.371479]\n",
      "epoch:15 step:12264 [D loss: 0.510871, acc: 62.50%] [G loss: 2.898353]\n",
      "epoch:15 step:12265 [D loss: 0.576454, acc: 67.19%] [G loss: 2.838191]\n",
      "epoch:15 step:12266 [D loss: 0.703825, acc: 53.91%] [G loss: 2.273013]\n",
      "epoch:15 step:12267 [D loss: 0.778782, acc: 42.19%] [G loss: 2.775269]\n",
      "epoch:15 step:12268 [D loss: 0.724328, acc: 50.00%] [G loss: 2.357768]\n",
      "epoch:15 step:12269 [D loss: 0.332433, acc: 96.09%] [G loss: 2.540056]\n",
      "epoch:15 step:12270 [D loss: 0.412199, acc: 91.41%] [G loss: 2.811298]\n",
      "epoch:15 step:12271 [D loss: 0.341795, acc: 88.28%] [G loss: 2.683722]\n",
      "epoch:15 step:12272 [D loss: 0.578807, acc: 69.53%] [G loss: 2.750295]\n",
      "epoch:15 step:12273 [D loss: 0.635573, acc: 60.94%] [G loss: 1.999376]\n",
      "epoch:15 step:12274 [D loss: 0.499892, acc: 80.47%] [G loss: 2.098257]\n",
      "epoch:15 step:12275 [D loss: 0.515974, acc: 76.56%] [G loss: 1.863092]\n",
      "epoch:15 step:12276 [D loss: 0.686396, acc: 60.94%] [G loss: 1.810425]\n",
      "epoch:15 step:12277 [D loss: 0.349549, acc: 85.16%] [G loss: 2.299176]\n",
      "epoch:15 step:12278 [D loss: 0.584933, acc: 68.75%] [G loss: 2.620199]\n",
      "epoch:15 step:12279 [D loss: 1.020674, acc: 28.12%] [G loss: 2.981853]\n",
      "epoch:15 step:12280 [D loss: 0.938854, acc: 28.91%] [G loss: 2.102116]\n",
      "epoch:15 step:12281 [D loss: 0.784032, acc: 53.12%] [G loss: 2.199629]\n",
      "epoch:15 step:12282 [D loss: 0.624823, acc: 64.06%] [G loss: 2.190734]\n",
      "epoch:15 step:12283 [D loss: 0.614365, acc: 64.06%] [G loss: 2.402325]\n",
      "epoch:15 step:12284 [D loss: 0.266777, acc: 97.66%] [G loss: 3.463681]\n",
      "epoch:15 step:12285 [D loss: 0.491790, acc: 82.03%] [G loss: 2.672990]\n",
      "epoch:15 step:12286 [D loss: 0.465873, acc: 78.12%] [G loss: 2.362317]\n",
      "epoch:15 step:12287 [D loss: 0.404343, acc: 89.06%] [G loss: 3.158575]\n",
      "epoch:15 step:12288 [D loss: 0.677754, acc: 58.59%] [G loss: 3.701960]\n",
      "epoch:15 step:12289 [D loss: 0.485979, acc: 84.38%] [G loss: 2.874684]\n",
      "epoch:15 step:12290 [D loss: 0.856771, acc: 38.28%] [G loss: 3.017955]\n",
      "epoch:15 step:12291 [D loss: 0.336801, acc: 94.53%] [G loss: 2.569642]\n",
      "epoch:15 step:12292 [D loss: 0.487577, acc: 83.59%] [G loss: 2.661589]\n",
      "epoch:15 step:12293 [D loss: 0.406422, acc: 91.41%] [G loss: 2.701895]\n",
      "epoch:15 step:12294 [D loss: 0.716371, acc: 56.25%] [G loss: 2.373655]\n",
      "epoch:15 step:12295 [D loss: 0.826401, acc: 39.84%] [G loss: 2.228251]\n",
      "epoch:15 step:12296 [D loss: 0.381223, acc: 90.62%] [G loss: 2.618326]\n",
      "epoch:15 step:12297 [D loss: 0.336142, acc: 94.53%] [G loss: 2.551534]\n",
      "epoch:15 step:12298 [D loss: 0.566091, acc: 74.22%] [G loss: 2.880680]\n",
      "epoch:15 step:12299 [D loss: 0.591925, acc: 63.28%] [G loss: 2.361543]\n",
      "epoch:15 step:12300 [D loss: 0.333524, acc: 97.66%] [G loss: 2.815130]\n",
      "epoch:15 step:12301 [D loss: 0.357333, acc: 92.97%] [G loss: 2.820516]\n",
      "epoch:15 step:12302 [D loss: 0.702625, acc: 55.47%] [G loss: 2.834865]\n",
      "epoch:15 step:12303 [D loss: 0.868453, acc: 35.94%] [G loss: 1.967386]\n",
      "epoch:15 step:12304 [D loss: 1.171777, acc: 9.38%] [G loss: 1.660741]\n",
      "epoch:15 step:12305 [D loss: 0.476856, acc: 80.47%] [G loss: 2.154645]\n",
      "epoch:15 step:12306 [D loss: 0.749470, acc: 53.91%] [G loss: 2.417897]\n",
      "epoch:15 step:12307 [D loss: 0.449802, acc: 82.81%] [G loss: 2.209441]\n",
      "epoch:15 step:12308 [D loss: 0.546029, acc: 75.00%] [G loss: 2.587624]\n",
      "epoch:15 step:12309 [D loss: 0.654785, acc: 60.16%] [G loss: 2.381433]\n",
      "epoch:15 step:12310 [D loss: 0.405569, acc: 91.41%] [G loss: 3.037208]\n",
      "epoch:15 step:12311 [D loss: 0.662888, acc: 64.06%] [G loss: 2.382491]\n",
      "epoch:15 step:12312 [D loss: 0.840361, acc: 41.41%] [G loss: 2.123904]\n",
      "epoch:15 step:12313 [D loss: 0.909374, acc: 26.56%] [G loss: 3.029026]\n",
      "epoch:15 step:12314 [D loss: 0.624288, acc: 64.84%] [G loss: 2.689617]\n",
      "epoch:15 step:12315 [D loss: 0.275051, acc: 94.53%] [G loss: 4.588094]\n",
      "epoch:15 step:12316 [D loss: 0.298485, acc: 94.53%] [G loss: 3.116650]\n",
      "epoch:15 step:12317 [D loss: 0.384499, acc: 87.50%] [G loss: 2.626182]\n",
      "epoch:15 step:12318 [D loss: 0.460738, acc: 79.69%] [G loss: 2.985291]\n",
      "epoch:15 step:12319 [D loss: 0.124398, acc: 100.00%] [G loss: 2.556679]\n",
      "epoch:15 step:12320 [D loss: 0.730309, acc: 56.25%] [G loss: 2.432091]\n",
      "epoch:15 step:12321 [D loss: 0.521590, acc: 76.56%] [G loss: 2.188012]\n",
      "epoch:15 step:12322 [D loss: 0.261364, acc: 96.88%] [G loss: 2.889225]\n",
      "epoch:15 step:12323 [D loss: 0.827663, acc: 35.94%] [G loss: 2.994268]\n",
      "epoch:15 step:12324 [D loss: 0.830765, acc: 49.22%] [G loss: 2.491172]\n",
      "epoch:15 step:12325 [D loss: 0.596395, acc: 69.53%] [G loss: 2.303014]\n",
      "epoch:15 step:12326 [D loss: 0.761520, acc: 49.22%] [G loss: 2.035227]\n",
      "epoch:15 step:12327 [D loss: 0.554577, acc: 71.09%] [G loss: 3.209671]\n",
      "epoch:15 step:12328 [D loss: 0.303286, acc: 96.09%] [G loss: 2.464875]\n",
      "epoch:15 step:12329 [D loss: 0.427533, acc: 86.72%] [G loss: 2.227154]\n",
      "epoch:15 step:12330 [D loss: 0.761536, acc: 53.12%] [G loss: 2.375756]\n",
      "epoch:15 step:12331 [D loss: 1.054168, acc: 46.88%] [G loss: 1.995075]\n",
      "epoch:15 step:12332 [D loss: 0.609895, acc: 64.06%] [G loss: 3.186971]\n",
      "epoch:15 step:12333 [D loss: 0.612929, acc: 65.62%] [G loss: 3.294448]\n",
      "epoch:15 step:12334 [D loss: 0.345880, acc: 83.59%] [G loss: 2.911461]\n",
      "epoch:15 step:12335 [D loss: 0.570564, acc: 75.00%] [G loss: 2.774497]\n",
      "epoch:15 step:12336 [D loss: 0.509036, acc: 76.56%] [G loss: 2.529802]\n",
      "epoch:15 step:12337 [D loss: 0.457094, acc: 85.94%] [G loss: 2.625362]\n",
      "epoch:15 step:12338 [D loss: 0.399984, acc: 86.72%] [G loss: 2.412999]\n",
      "epoch:15 step:12339 [D loss: 0.718030, acc: 53.12%] [G loss: 2.083804]\n",
      "epoch:15 step:12340 [D loss: 0.416904, acc: 85.94%] [G loss: 2.518350]\n",
      "epoch:15 step:12341 [D loss: 0.821227, acc: 43.75%] [G loss: 2.120644]\n",
      "epoch:15 step:12342 [D loss: 0.751654, acc: 47.66%] [G loss: 2.300249]\n",
      "epoch:15 step:12343 [D loss: 0.431076, acc: 92.19%] [G loss: 2.545431]\n",
      "epoch:15 step:12344 [D loss: 0.663882, acc: 60.94%] [G loss: 1.888849]\n",
      "epoch:15 step:12345 [D loss: 0.300802, acc: 95.31%] [G loss: 3.387828]\n",
      "epoch:15 step:12346 [D loss: 0.415258, acc: 85.16%] [G loss: 3.191327]\n",
      "epoch:15 step:12347 [D loss: 1.002987, acc: 31.25%] [G loss: 1.957418]\n",
      "epoch:15 step:12348 [D loss: 0.290234, acc: 93.75%] [G loss: 3.006536]\n",
      "epoch:15 step:12349 [D loss: 0.839475, acc: 40.62%] [G loss: 3.064704]\n",
      "epoch:15 step:12350 [D loss: 0.374430, acc: 87.50%] [G loss: 3.526741]\n",
      "epoch:15 step:12351 [D loss: 0.544282, acc: 64.84%] [G loss: 2.710578]\n",
      "epoch:15 step:12352 [D loss: 0.769059, acc: 54.69%] [G loss: 1.797536]\n",
      "epoch:15 step:12353 [D loss: 0.755217, acc: 50.00%] [G loss: 1.674474]\n",
      "epoch:15 step:12354 [D loss: 0.363137, acc: 85.16%] [G loss: 1.930483]\n",
      "epoch:15 step:12355 [D loss: 0.540603, acc: 64.84%] [G loss: 2.742625]\n",
      "epoch:15 step:12356 [D loss: 0.837076, acc: 44.53%] [G loss: 2.081646]\n",
      "epoch:15 step:12357 [D loss: 0.945725, acc: 29.69%] [G loss: 2.236479]\n",
      "epoch:15 step:12358 [D loss: 0.483216, acc: 82.81%] [G loss: 2.616642]\n",
      "epoch:15 step:12359 [D loss: 0.586659, acc: 61.72%] [G loss: 2.429756]\n",
      "epoch:15 step:12360 [D loss: 0.840475, acc: 40.62%] [G loss: 1.925120]\n",
      "epoch:15 step:12361 [D loss: 0.562077, acc: 74.22%] [G loss: 2.395100]\n",
      "epoch:15 step:12362 [D loss: 0.626087, acc: 63.28%] [G loss: 3.356438]\n",
      "epoch:15 step:12363 [D loss: 0.403471, acc: 79.69%] [G loss: 2.240448]\n",
      "epoch:15 step:12364 [D loss: 0.344625, acc: 91.41%] [G loss: 3.715971]\n",
      "epoch:15 step:12365 [D loss: 0.313526, acc: 96.09%] [G loss: 2.486546]\n",
      "epoch:15 step:12366 [D loss: 0.304790, acc: 91.41%] [G loss: 3.931991]\n",
      "epoch:15 step:12367 [D loss: 0.539357, acc: 74.22%] [G loss: 2.265756]\n",
      "epoch:15 step:12368 [D loss: 0.393322, acc: 85.16%] [G loss: 2.559987]\n",
      "epoch:15 step:12369 [D loss: 0.274279, acc: 97.66%] [G loss: 3.721594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12370 [D loss: 0.363894, acc: 89.84%] [G loss: 3.032080]\n",
      "epoch:15 step:12371 [D loss: 0.845135, acc: 48.44%] [G loss: 2.491326]\n",
      "epoch:15 step:12372 [D loss: 0.599199, acc: 61.72%] [G loss: 2.796016]\n",
      "epoch:15 step:12373 [D loss: 0.574404, acc: 67.97%] [G loss: 1.938528]\n",
      "epoch:15 step:12374 [D loss: 0.612339, acc: 70.31%] [G loss: 3.283669]\n",
      "epoch:15 step:12375 [D loss: 0.535800, acc: 73.44%] [G loss: 2.659682]\n",
      "epoch:15 step:12376 [D loss: 0.599049, acc: 65.62%] [G loss: 3.114757]\n",
      "epoch:15 step:12377 [D loss: 0.334289, acc: 96.09%] [G loss: 4.403539]\n",
      "epoch:15 step:12378 [D loss: 0.380229, acc: 89.06%] [G loss: 3.012345]\n",
      "epoch:15 step:12379 [D loss: 0.416799, acc: 84.38%] [G loss: 2.877288]\n",
      "epoch:15 step:12380 [D loss: 0.747583, acc: 53.12%] [G loss: 2.680306]\n",
      "epoch:15 step:12381 [D loss: 0.575985, acc: 68.75%] [G loss: 3.423332]\n",
      "epoch:15 step:12382 [D loss: 0.546899, acc: 78.12%] [G loss: 2.551723]\n",
      "epoch:15 step:12383 [D loss: 0.329914, acc: 93.75%] [G loss: 3.248107]\n",
      "epoch:15 step:12384 [D loss: 0.913204, acc: 45.31%] [G loss: 3.050443]\n",
      "epoch:15 step:12385 [D loss: 0.612398, acc: 65.62%] [G loss: 2.431051]\n",
      "epoch:15 step:12386 [D loss: 0.782331, acc: 49.22%] [G loss: 2.441401]\n",
      "epoch:15 step:12387 [D loss: 0.629763, acc: 64.84%] [G loss: 2.168046]\n",
      "epoch:15 step:12388 [D loss: 0.749107, acc: 48.44%] [G loss: 1.921964]\n",
      "epoch:15 step:12389 [D loss: 0.433219, acc: 87.50%] [G loss: 2.541233]\n",
      "epoch:15 step:12390 [D loss: 0.689363, acc: 56.25%] [G loss: 4.221991]\n",
      "epoch:15 step:12391 [D loss: 0.880356, acc: 37.50%] [G loss: 3.304491]\n",
      "epoch:15 step:12392 [D loss: 0.592600, acc: 70.31%] [G loss: 3.099346]\n",
      "epoch:15 step:12393 [D loss: 0.683547, acc: 60.16%] [G loss: 2.892868]\n",
      "epoch:15 step:12394 [D loss: 0.375282, acc: 90.62%] [G loss: 4.291556]\n",
      "epoch:15 step:12395 [D loss: 0.426327, acc: 88.28%] [G loss: 2.841519]\n",
      "epoch:15 step:12396 [D loss: 0.709912, acc: 50.78%] [G loss: 2.554929]\n",
      "epoch:15 step:12397 [D loss: 0.734918, acc: 51.56%] [G loss: 2.208265]\n",
      "epoch:15 step:12398 [D loss: 0.435130, acc: 82.03%] [G loss: 3.268600]\n",
      "epoch:15 step:12399 [D loss: 0.611170, acc: 64.06%] [G loss: 2.285670]\n",
      "epoch:15 step:12400 [D loss: 0.442114, acc: 85.16%] [G loss: 3.747441]\n",
      "epoch:15 step:12401 [D loss: 0.524202, acc: 74.22%] [G loss: 2.659349]\n",
      "epoch:15 step:12402 [D loss: 0.540079, acc: 77.34%] [G loss: 4.396239]\n",
      "epoch:15 step:12403 [D loss: 0.437643, acc: 78.91%] [G loss: 2.582488]\n",
      "epoch:15 step:12404 [D loss: 0.877178, acc: 35.94%] [G loss: 2.391924]\n",
      "epoch:15 step:12405 [D loss: 0.519436, acc: 79.69%] [G loss: 2.159561]\n",
      "epoch:15 step:12406 [D loss: 1.066791, acc: 19.53%] [G loss: 2.248821]\n",
      "epoch:15 step:12407 [D loss: 0.416586, acc: 78.91%] [G loss: 2.707952]\n",
      "epoch:15 step:12408 [D loss: 0.701195, acc: 56.25%] [G loss: 2.385322]\n",
      "epoch:15 step:12409 [D loss: 0.555910, acc: 72.66%] [G loss: 2.725094]\n",
      "epoch:15 step:12410 [D loss: 0.528597, acc: 71.09%] [G loss: 2.451110]\n",
      "epoch:15 step:12411 [D loss: 0.860737, acc: 40.62%] [G loss: 2.651726]\n",
      "epoch:15 step:12412 [D loss: 0.321104, acc: 89.06%] [G loss: 2.957294]\n",
      "epoch:15 step:12413 [D loss: 0.693543, acc: 56.25%] [G loss: 2.132351]\n",
      "epoch:15 step:12414 [D loss: 0.688065, acc: 55.47%] [G loss: 3.294873]\n",
      "epoch:15 step:12415 [D loss: 0.479073, acc: 76.56%] [G loss: 2.996038]\n",
      "epoch:15 step:12416 [D loss: 0.720725, acc: 53.91%] [G loss: 3.170153]\n",
      "epoch:15 step:12417 [D loss: 0.502556, acc: 80.47%] [G loss: 3.685614]\n",
      "epoch:15 step:12418 [D loss: 0.330336, acc: 89.84%] [G loss: 3.336120]\n",
      "epoch:15 step:12419 [D loss: 0.445716, acc: 83.59%] [G loss: 2.571098]\n",
      "epoch:15 step:12420 [D loss: 0.821289, acc: 44.53%] [G loss: 2.325119]\n",
      "epoch:15 step:12421 [D loss: 0.311428, acc: 94.53%] [G loss: 2.058397]\n",
      "epoch:15 step:12422 [D loss: 0.746352, acc: 52.34%] [G loss: 1.914284]\n",
      "epoch:15 step:12423 [D loss: 0.490284, acc: 85.16%] [G loss: 2.386908]\n",
      "epoch:15 step:12424 [D loss: 0.333010, acc: 90.62%] [G loss: 2.645157]\n",
      "epoch:15 step:12425 [D loss: 0.481974, acc: 86.72%] [G loss: 2.685808]\n",
      "epoch:15 step:12426 [D loss: 0.312104, acc: 96.88%] [G loss: 2.980568]\n",
      "epoch:15 step:12427 [D loss: 0.465050, acc: 87.50%] [G loss: 3.178691]\n",
      "epoch:15 step:12428 [D loss: 0.489118, acc: 85.94%] [G loss: 2.852850]\n",
      "epoch:15 step:12429 [D loss: 0.425621, acc: 89.84%] [G loss: 3.442876]\n",
      "epoch:15 step:12430 [D loss: 0.768830, acc: 50.78%] [G loss: 2.449845]\n",
      "epoch:15 step:12431 [D loss: 0.247276, acc: 93.75%] [G loss: 3.423829]\n",
      "epoch:15 step:12432 [D loss: 0.565286, acc: 65.62%] [G loss: 2.694009]\n",
      "epoch:15 step:12433 [D loss: 0.519604, acc: 76.56%] [G loss: 2.671603]\n",
      "epoch:15 step:12434 [D loss: 0.602488, acc: 71.09%] [G loss: 2.490799]\n",
      "epoch:15 step:12435 [D loss: 0.535286, acc: 66.41%] [G loss: 3.268624]\n",
      "epoch:15 step:12436 [D loss: 0.777030, acc: 50.00%] [G loss: 2.373082]\n",
      "epoch:15 step:12437 [D loss: 0.176866, acc: 97.66%] [G loss: 4.178958]\n",
      "epoch:15 step:12438 [D loss: 0.680465, acc: 58.59%] [G loss: 2.360269]\n",
      "epoch:15 step:12439 [D loss: 0.459659, acc: 80.47%] [G loss: 2.392001]\n",
      "epoch:15 step:12440 [D loss: 0.703126, acc: 60.16%] [G loss: 2.204634]\n",
      "epoch:15 step:12441 [D loss: 0.602041, acc: 67.97%] [G loss: 2.809814]\n",
      "epoch:15 step:12442 [D loss: 0.751605, acc: 53.12%] [G loss: 2.442091]\n",
      "epoch:15 step:12443 [D loss: 0.501266, acc: 81.25%] [G loss: 2.834348]\n",
      "epoch:15 step:12444 [D loss: 0.637962, acc: 64.84%] [G loss: 2.313414]\n",
      "epoch:15 step:12445 [D loss: 0.655736, acc: 61.72%] [G loss: 2.089087]\n",
      "epoch:15 step:12446 [D loss: 0.531315, acc: 82.03%] [G loss: 2.556930]\n",
      "epoch:15 step:12447 [D loss: 0.705903, acc: 51.56%] [G loss: 2.470707]\n",
      "epoch:15 step:12448 [D loss: 0.377206, acc: 89.06%] [G loss: 2.933666]\n",
      "epoch:15 step:12449 [D loss: 0.448470, acc: 80.47%] [G loss: 2.584842]\n",
      "epoch:15 step:12450 [D loss: 0.483499, acc: 82.81%] [G loss: 2.521499]\n",
      "epoch:15 step:12451 [D loss: 0.502031, acc: 80.47%] [G loss: 3.133931]\n",
      "epoch:15 step:12452 [D loss: 0.287297, acc: 96.09%] [G loss: 2.905885]\n",
      "epoch:15 step:12453 [D loss: 0.962717, acc: 27.34%] [G loss: 2.194639]\n",
      "epoch:15 step:12454 [D loss: 0.413781, acc: 93.75%] [G loss: 3.677383]\n",
      "epoch:15 step:12455 [D loss: 0.996975, acc: 20.31%] [G loss: 2.254303]\n",
      "epoch:15 step:12456 [D loss: 0.265471, acc: 96.09%] [G loss: 2.732615]\n",
      "epoch:15 step:12457 [D loss: 0.572488, acc: 67.97%] [G loss: 2.491046]\n",
      "epoch:15 step:12458 [D loss: 0.435098, acc: 82.81%] [G loss: 2.921724]\n",
      "epoch:15 step:12459 [D loss: 0.702747, acc: 55.47%] [G loss: 2.141420]\n",
      "epoch:15 step:12460 [D loss: 0.715575, acc: 56.25%] [G loss: 2.835599]\n",
      "epoch:15 step:12461 [D loss: 0.526132, acc: 68.75%] [G loss: 2.358794]\n",
      "epoch:15 step:12462 [D loss: 0.871163, acc: 37.50%] [G loss: 3.027627]\n",
      "epoch:15 step:12463 [D loss: 0.392527, acc: 83.59%] [G loss: 3.339960]\n",
      "epoch:15 step:12464 [D loss: 0.611338, acc: 62.50%] [G loss: 2.531869]\n",
      "epoch:15 step:12465 [D loss: 0.727539, acc: 62.50%] [G loss: 2.266426]\n",
      "epoch:15 step:12466 [D loss: 0.945957, acc: 35.16%] [G loss: 2.023330]\n",
      "epoch:15 step:12467 [D loss: 0.452000, acc: 81.25%] [G loss: 2.529023]\n",
      "epoch:15 step:12468 [D loss: 0.750142, acc: 50.78%] [G loss: 3.505870]\n",
      "epoch:15 step:12469 [D loss: 0.519087, acc: 74.22%] [G loss: 2.580846]\n",
      "epoch:15 step:12470 [D loss: 0.408751, acc: 83.59%] [G loss: 2.609759]\n",
      "epoch:15 step:12471 [D loss: 0.597105, acc: 69.53%] [G loss: 3.192479]\n",
      "epoch:15 step:12472 [D loss: 0.617691, acc: 61.72%] [G loss: 2.821144]\n",
      "epoch:15 step:12473 [D loss: 0.542109, acc: 73.44%] [G loss: 2.443940]\n",
      "epoch:15 step:12474 [D loss: 0.563997, acc: 73.44%] [G loss: 2.931951]\n",
      "epoch:15 step:12475 [D loss: 0.627406, acc: 65.62%] [G loss: 2.910319]\n",
      "epoch:15 step:12476 [D loss: 0.528572, acc: 67.19%] [G loss: 2.765518]\n",
      "epoch:15 step:12477 [D loss: 0.441427, acc: 82.03%] [G loss: 2.833874]\n",
      "epoch:15 step:12478 [D loss: 0.637352, acc: 64.84%] [G loss: 2.675083]\n",
      "epoch:15 step:12479 [D loss: 0.562487, acc: 73.44%] [G loss: 3.261496]\n",
      "epoch:15 step:12480 [D loss: 0.709906, acc: 55.47%] [G loss: 3.216863]\n",
      "epoch:15 step:12481 [D loss: 0.525873, acc: 71.09%] [G loss: 3.287978]\n",
      "epoch:15 step:12482 [D loss: 0.818416, acc: 46.09%] [G loss: 2.554047]\n",
      "epoch:15 step:12483 [D loss: 0.330923, acc: 91.41%] [G loss: 2.992234]\n",
      "epoch:15 step:12484 [D loss: 0.873390, acc: 51.56%] [G loss: 2.693975]\n",
      "epoch:15 step:12485 [D loss: 0.291128, acc: 91.41%] [G loss: 4.048201]\n",
      "epoch:15 step:12486 [D loss: 0.668209, acc: 63.28%] [G loss: 2.013931]\n",
      "epoch:15 step:12487 [D loss: 0.521650, acc: 81.25%] [G loss: 3.130253]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12488 [D loss: 0.353640, acc: 89.06%] [G loss: 2.510824]\n",
      "epoch:15 step:12489 [D loss: 0.582767, acc: 75.00%] [G loss: 2.691090]\n",
      "epoch:15 step:12490 [D loss: 0.568295, acc: 67.19%] [G loss: 3.610964]\n",
      "epoch:15 step:12491 [D loss: 0.472500, acc: 79.69%] [G loss: 3.283490]\n",
      "epoch:15 step:12492 [D loss: 0.790042, acc: 43.75%] [G loss: 2.309890]\n",
      "epoch:15 step:12493 [D loss: 0.956641, acc: 35.94%] [G loss: 2.187293]\n",
      "epoch:15 step:12494 [D loss: 0.482875, acc: 80.47%] [G loss: 1.979761]\n",
      "epoch:15 step:12495 [D loss: 0.357022, acc: 92.97%] [G loss: 2.821877]\n",
      "epoch:15 step:12496 [D loss: 0.663695, acc: 60.16%] [G loss: 2.348012]\n",
      "epoch:16 step:12497 [D loss: 0.721402, acc: 52.34%] [G loss: 2.289458]\n",
      "epoch:16 step:12498 [D loss: 0.663230, acc: 61.72%] [G loss: 3.284410]\n",
      "epoch:16 step:12499 [D loss: 0.718534, acc: 52.34%] [G loss: 2.858879]\n",
      "epoch:16 step:12500 [D loss: 0.612615, acc: 66.41%] [G loss: 1.995430]\n",
      "epoch:16 step:12501 [D loss: 0.452119, acc: 86.72%] [G loss: 3.446344]\n",
      "epoch:16 step:12502 [D loss: 0.345538, acc: 88.28%] [G loss: 3.320795]\n",
      "epoch:16 step:12503 [D loss: 0.707188, acc: 53.12%] [G loss: 2.639604]\n",
      "epoch:16 step:12504 [D loss: 0.587246, acc: 66.41%] [G loss: 2.588337]\n",
      "epoch:16 step:12505 [D loss: 0.687714, acc: 58.59%] [G loss: 3.167480]\n",
      "epoch:16 step:12506 [D loss: 0.577821, acc: 75.78%] [G loss: 2.724856]\n",
      "epoch:16 step:12507 [D loss: 0.541208, acc: 77.34%] [G loss: 3.265908]\n",
      "epoch:16 step:12508 [D loss: 0.373694, acc: 95.31%] [G loss: 2.709241]\n",
      "epoch:16 step:12509 [D loss: 0.704790, acc: 58.59%] [G loss: 2.539176]\n",
      "epoch:16 step:12510 [D loss: 0.823629, acc: 43.75%] [G loss: 2.482854]\n",
      "epoch:16 step:12511 [D loss: 0.973975, acc: 49.22%] [G loss: 1.751330]\n",
      "epoch:16 step:12512 [D loss: 0.584405, acc: 68.75%] [G loss: 2.745002]\n",
      "epoch:16 step:12513 [D loss: 0.686447, acc: 54.69%] [G loss: 3.017170]\n",
      "epoch:16 step:12514 [D loss: 0.707609, acc: 59.38%] [G loss: 2.522521]\n",
      "epoch:16 step:12515 [D loss: 0.716305, acc: 62.50%] [G loss: 1.906049]\n",
      "epoch:16 step:12516 [D loss: 0.547718, acc: 68.75%] [G loss: 2.753596]\n",
      "epoch:16 step:12517 [D loss: 0.491303, acc: 82.03%] [G loss: 3.369787]\n",
      "epoch:16 step:12518 [D loss: 0.478937, acc: 83.59%] [G loss: 2.704096]\n",
      "epoch:16 step:12519 [D loss: 0.463350, acc: 75.78%] [G loss: 2.393245]\n",
      "epoch:16 step:12520 [D loss: 0.682196, acc: 56.25%] [G loss: 2.685049]\n",
      "epoch:16 step:12521 [D loss: 0.748020, acc: 53.91%] [G loss: 2.707460]\n",
      "epoch:16 step:12522 [D loss: 0.297832, acc: 88.28%] [G loss: 3.076858]\n",
      "epoch:16 step:12523 [D loss: 0.791718, acc: 53.12%] [G loss: 2.095595]\n",
      "epoch:16 step:12524 [D loss: 0.740436, acc: 50.00%] [G loss: 2.367309]\n",
      "epoch:16 step:12525 [D loss: 0.604069, acc: 68.75%] [G loss: 2.457581]\n",
      "epoch:16 step:12526 [D loss: 0.500987, acc: 78.91%] [G loss: 2.663719]\n",
      "epoch:16 step:12527 [D loss: 0.777069, acc: 45.31%] [G loss: 2.371123]\n",
      "epoch:16 step:12528 [D loss: 0.644321, acc: 60.16%] [G loss: 2.501877]\n",
      "epoch:16 step:12529 [D loss: 0.578994, acc: 73.44%] [G loss: 2.439231]\n",
      "epoch:16 step:12530 [D loss: 0.538555, acc: 75.78%] [G loss: 1.879765]\n",
      "epoch:16 step:12531 [D loss: 0.636939, acc: 64.06%] [G loss: 2.464313]\n",
      "epoch:16 step:12532 [D loss: 0.489231, acc: 77.34%] [G loss: 2.199870]\n",
      "epoch:16 step:12533 [D loss: 0.838715, acc: 50.00%] [G loss: 2.108881]\n",
      "epoch:16 step:12534 [D loss: 0.817355, acc: 42.97%] [G loss: 2.144401]\n",
      "epoch:16 step:12535 [D loss: 0.433179, acc: 87.50%] [G loss: 2.809338]\n",
      "epoch:16 step:12536 [D loss: 0.400296, acc: 85.94%] [G loss: 2.380005]\n",
      "epoch:16 step:12537 [D loss: 0.575941, acc: 64.84%] [G loss: 2.735322]\n",
      "epoch:16 step:12538 [D loss: 0.650825, acc: 67.19%] [G loss: 2.260855]\n",
      "epoch:16 step:12539 [D loss: 0.543654, acc: 72.66%] [G loss: 2.324533]\n",
      "epoch:16 step:12540 [D loss: 0.572373, acc: 69.53%] [G loss: 2.454584]\n",
      "epoch:16 step:12541 [D loss: 0.393386, acc: 82.81%] [G loss: 2.601912]\n",
      "epoch:16 step:12542 [D loss: 0.727289, acc: 52.34%] [G loss: 2.497535]\n",
      "epoch:16 step:12543 [D loss: 0.272089, acc: 99.22%] [G loss: 2.373151]\n",
      "epoch:16 step:12544 [D loss: 0.706433, acc: 49.22%] [G loss: 2.433481]\n",
      "epoch:16 step:12545 [D loss: 1.007450, acc: 31.25%] [G loss: 1.827241]\n",
      "epoch:16 step:12546 [D loss: 0.882924, acc: 39.06%] [G loss: 1.563381]\n",
      "epoch:16 step:12547 [D loss: 0.714323, acc: 53.12%] [G loss: 2.261159]\n",
      "epoch:16 step:12548 [D loss: 0.541044, acc: 75.78%] [G loss: 2.897416]\n",
      "epoch:16 step:12549 [D loss: 0.778895, acc: 50.78%] [G loss: 2.722930]\n",
      "epoch:16 step:12550 [D loss: 0.620350, acc: 64.84%] [G loss: 2.219654]\n",
      "epoch:16 step:12551 [D loss: 0.764353, acc: 55.47%] [G loss: 2.330115]\n",
      "epoch:16 step:12552 [D loss: 0.905365, acc: 28.91%] [G loss: 1.786224]\n",
      "epoch:16 step:12553 [D loss: 0.587137, acc: 68.75%] [G loss: 2.582512]\n",
      "epoch:16 step:12554 [D loss: 0.481239, acc: 80.47%] [G loss: 2.330261]\n",
      "epoch:16 step:12555 [D loss: 0.528374, acc: 75.00%] [G loss: 2.094503]\n",
      "epoch:16 step:12556 [D loss: 0.537488, acc: 73.44%] [G loss: 2.159942]\n",
      "epoch:16 step:12557 [D loss: 0.609007, acc: 66.41%] [G loss: 2.577298]\n",
      "epoch:16 step:12558 [D loss: 0.853042, acc: 42.19%] [G loss: 2.551996]\n",
      "epoch:16 step:12559 [D loss: 0.412208, acc: 91.41%] [G loss: 2.481560]\n",
      "epoch:16 step:12560 [D loss: 0.511175, acc: 73.44%] [G loss: 3.095193]\n",
      "epoch:16 step:12561 [D loss: 0.580622, acc: 66.41%] [G loss: 2.853254]\n",
      "epoch:16 step:12562 [D loss: 0.745528, acc: 53.91%] [G loss: 2.680408]\n",
      "epoch:16 step:12563 [D loss: 0.478546, acc: 82.81%] [G loss: 2.339249]\n",
      "epoch:16 step:12564 [D loss: 0.651549, acc: 56.25%] [G loss: 2.731058]\n",
      "epoch:16 step:12565 [D loss: 0.444831, acc: 84.38%] [G loss: 2.947140]\n",
      "epoch:16 step:12566 [D loss: 0.648824, acc: 60.94%] [G loss: 2.150566]\n",
      "epoch:16 step:12567 [D loss: 0.853147, acc: 48.44%] [G loss: 2.185458]\n",
      "epoch:16 step:12568 [D loss: 0.900101, acc: 36.72%] [G loss: 2.092331]\n",
      "epoch:16 step:12569 [D loss: 0.660917, acc: 60.94%] [G loss: 2.375844]\n",
      "epoch:16 step:12570 [D loss: 0.537510, acc: 78.12%] [G loss: 2.995561]\n",
      "epoch:16 step:12571 [D loss: 0.557588, acc: 74.22%] [G loss: 2.401535]\n",
      "epoch:16 step:12572 [D loss: 0.442706, acc: 84.38%] [G loss: 2.637804]\n",
      "epoch:16 step:12573 [D loss: 0.564916, acc: 75.78%] [G loss: 2.214547]\n",
      "epoch:16 step:12574 [D loss: 0.583165, acc: 68.75%] [G loss: 1.954709]\n",
      "epoch:16 step:12575 [D loss: 0.376456, acc: 90.62%] [G loss: 2.764091]\n",
      "epoch:16 step:12576 [D loss: 0.618195, acc: 69.53%] [G loss: 2.592569]\n",
      "epoch:16 step:12577 [D loss: 0.902655, acc: 46.88%] [G loss: 1.954785]\n",
      "epoch:16 step:12578 [D loss: 0.454877, acc: 84.38%] [G loss: 3.001316]\n",
      "epoch:16 step:12579 [D loss: 0.402609, acc: 83.59%] [G loss: 2.391667]\n",
      "epoch:16 step:12580 [D loss: 0.904432, acc: 36.72%] [G loss: 2.167553]\n",
      "epoch:16 step:12581 [D loss: 0.851701, acc: 41.41%] [G loss: 1.893174]\n",
      "epoch:16 step:12582 [D loss: 0.461934, acc: 82.03%] [G loss: 2.781059]\n",
      "epoch:16 step:12583 [D loss: 0.469936, acc: 84.38%] [G loss: 2.414439]\n",
      "epoch:16 step:12584 [D loss: 0.480316, acc: 82.81%] [G loss: 2.326966]\n",
      "epoch:16 step:12585 [D loss: 0.690442, acc: 63.28%] [G loss: 2.510375]\n",
      "epoch:16 step:12586 [D loss: 0.497294, acc: 73.44%] [G loss: 3.998168]\n",
      "epoch:16 step:12587 [D loss: 0.657983, acc: 60.94%] [G loss: 2.719946]\n",
      "epoch:16 step:12588 [D loss: 0.537200, acc: 73.44%] [G loss: 2.115283]\n",
      "epoch:16 step:12589 [D loss: 0.347071, acc: 91.41%] [G loss: 3.373196]\n",
      "epoch:16 step:12590 [D loss: 0.365992, acc: 92.19%] [G loss: 2.237553]\n",
      "epoch:16 step:12591 [D loss: 1.006082, acc: 42.97%] [G loss: 2.162449]\n",
      "epoch:16 step:12592 [D loss: 0.544134, acc: 80.47%] [G loss: 2.064550]\n",
      "epoch:16 step:12593 [D loss: 0.723336, acc: 49.22%] [G loss: 2.062384]\n",
      "epoch:16 step:12594 [D loss: 0.701319, acc: 59.38%] [G loss: 1.990219]\n",
      "epoch:16 step:12595 [D loss: 0.387162, acc: 86.72%] [G loss: 2.246757]\n",
      "epoch:16 step:12596 [D loss: 0.633987, acc: 64.06%] [G loss: 1.711985]\n",
      "epoch:16 step:12597 [D loss: 0.665877, acc: 57.03%] [G loss: 2.432954]\n",
      "epoch:16 step:12598 [D loss: 0.443709, acc: 83.59%] [G loss: 2.969794]\n",
      "epoch:16 step:12599 [D loss: 0.788609, acc: 51.56%] [G loss: 2.182794]\n",
      "epoch:16 step:12600 [D loss: 0.477728, acc: 79.69%] [G loss: 3.066634]\n",
      "epoch:16 step:12601 [D loss: 0.565043, acc: 63.28%] [G loss: 2.246017]\n",
      "epoch:16 step:12602 [D loss: 0.253005, acc: 98.44%] [G loss: 3.132360]\n",
      "epoch:16 step:12603 [D loss: 0.816888, acc: 46.09%] [G loss: 2.382506]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:12604 [D loss: 0.715006, acc: 61.72%] [G loss: 2.402003]\n",
      "epoch:16 step:12605 [D loss: 0.441350, acc: 75.00%] [G loss: 1.986446]\n",
      "epoch:16 step:12606 [D loss: 0.613030, acc: 64.06%] [G loss: 2.767836]\n",
      "epoch:16 step:12607 [D loss: 0.536674, acc: 73.44%] [G loss: 2.231804]\n",
      "epoch:16 step:12608 [D loss: 0.498925, acc: 78.91%] [G loss: 2.075628]\n",
      "epoch:16 step:12609 [D loss: 0.471671, acc: 72.66%] [G loss: 1.837168]\n",
      "epoch:16 step:12610 [D loss: 0.689105, acc: 57.81%] [G loss: 3.345984]\n",
      "epoch:16 step:12611 [D loss: 0.744519, acc: 51.56%] [G loss: 2.352760]\n",
      "epoch:16 step:12612 [D loss: 0.422681, acc: 86.72%] [G loss: 3.052207]\n",
      "epoch:16 step:12613 [D loss: 0.741308, acc: 52.34%] [G loss: 1.613955]\n",
      "epoch:16 step:12614 [D loss: 0.618357, acc: 64.06%] [G loss: 2.096715]\n",
      "epoch:16 step:12615 [D loss: 0.421459, acc: 89.06%] [G loss: 3.273438]\n",
      "epoch:16 step:12616 [D loss: 0.633395, acc: 64.06%] [G loss: 2.528580]\n",
      "epoch:16 step:12617 [D loss: 0.377886, acc: 92.97%] [G loss: 2.386007]\n",
      "epoch:16 step:12618 [D loss: 0.329990, acc: 92.19%] [G loss: 3.004837]\n",
      "epoch:16 step:12619 [D loss: 0.210560, acc: 98.44%] [G loss: 4.128317]\n",
      "epoch:16 step:12620 [D loss: 0.351989, acc: 92.19%] [G loss: 1.987350]\n",
      "epoch:16 step:12621 [D loss: 0.789712, acc: 50.78%] [G loss: 1.929307]\n",
      "epoch:16 step:12622 [D loss: 0.501490, acc: 76.56%] [G loss: 2.294643]\n",
      "epoch:16 step:12623 [D loss: 0.221703, acc: 96.88%] [G loss: 2.269951]\n",
      "epoch:16 step:12624 [D loss: 0.566370, acc: 69.53%] [G loss: 1.929049]\n",
      "epoch:16 step:12625 [D loss: 0.514120, acc: 78.12%] [G loss: 2.940837]\n",
      "epoch:16 step:12626 [D loss: 0.719618, acc: 54.69%] [G loss: 2.157215]\n",
      "epoch:16 step:12627 [D loss: 0.583036, acc: 60.16%] [G loss: 2.562116]\n",
      "epoch:16 step:12628 [D loss: 0.688020, acc: 55.47%] [G loss: 2.577447]\n",
      "epoch:16 step:12629 [D loss: 0.681786, acc: 56.25%] [G loss: 2.726132]\n",
      "epoch:16 step:12630 [D loss: 0.612550, acc: 64.06%] [G loss: 3.642659]\n",
      "epoch:16 step:12631 [D loss: 0.609962, acc: 62.50%] [G loss: 2.712700]\n",
      "epoch:16 step:12632 [D loss: 0.512469, acc: 75.78%] [G loss: 2.157875]\n",
      "epoch:16 step:12633 [D loss: 0.371116, acc: 92.19%] [G loss: 2.146727]\n",
      "epoch:16 step:12634 [D loss: 0.624580, acc: 61.72%] [G loss: 2.890957]\n",
      "epoch:16 step:12635 [D loss: 0.599675, acc: 67.19%] [G loss: 3.371165]\n",
      "epoch:16 step:12636 [D loss: 0.899599, acc: 40.62%] [G loss: 2.527895]\n",
      "epoch:16 step:12637 [D loss: 1.160167, acc: 19.53%] [G loss: 1.671641]\n",
      "epoch:16 step:12638 [D loss: 0.431465, acc: 87.50%] [G loss: 2.696072]\n",
      "epoch:16 step:12639 [D loss: 0.284716, acc: 95.31%] [G loss: 2.561340]\n",
      "epoch:16 step:12640 [D loss: 0.823116, acc: 41.41%] [G loss: 2.118342]\n",
      "epoch:16 step:12641 [D loss: 0.431421, acc: 86.72%] [G loss: 2.400601]\n",
      "epoch:16 step:12642 [D loss: 0.605453, acc: 66.41%] [G loss: 2.492173]\n",
      "epoch:16 step:12643 [D loss: 0.837626, acc: 47.66%] [G loss: 2.514285]\n",
      "epoch:16 step:12644 [D loss: 0.624236, acc: 71.09%] [G loss: 2.399801]\n",
      "epoch:16 step:12645 [D loss: 0.391524, acc: 87.50%] [G loss: 2.146554]\n",
      "epoch:16 step:12646 [D loss: 0.616420, acc: 61.72%] [G loss: 2.310049]\n",
      "epoch:16 step:12647 [D loss: 0.524523, acc: 78.91%] [G loss: 2.026295]\n",
      "epoch:16 step:12648 [D loss: 0.560662, acc: 67.97%] [G loss: 2.501082]\n",
      "epoch:16 step:12649 [D loss: 0.834540, acc: 42.97%] [G loss: 2.111057]\n",
      "epoch:16 step:12650 [D loss: 0.524516, acc: 79.69%] [G loss: 2.213923]\n",
      "epoch:16 step:12651 [D loss: 0.664954, acc: 57.81%] [G loss: 2.349583]\n",
      "epoch:16 step:12652 [D loss: 0.788796, acc: 46.09%] [G loss: 2.088717]\n",
      "epoch:16 step:12653 [D loss: 0.400970, acc: 88.28%] [G loss: 2.358050]\n",
      "epoch:16 step:12654 [D loss: 0.684950, acc: 58.59%] [G loss: 2.306426]\n",
      "epoch:16 step:12655 [D loss: 0.290899, acc: 92.19%] [G loss: 3.382198]\n",
      "epoch:16 step:12656 [D loss: 0.705430, acc: 57.03%] [G loss: 2.386757]\n",
      "epoch:16 step:12657 [D loss: 0.633504, acc: 61.72%] [G loss: 2.634916]\n",
      "epoch:16 step:12658 [D loss: 0.492666, acc: 81.25%] [G loss: 2.590585]\n",
      "epoch:16 step:12659 [D loss: 0.610454, acc: 66.41%] [G loss: 2.276191]\n",
      "epoch:16 step:12660 [D loss: 0.321029, acc: 84.38%] [G loss: 3.502343]\n",
      "epoch:16 step:12661 [D loss: 0.542047, acc: 78.12%] [G loss: 3.106403]\n",
      "epoch:16 step:12662 [D loss: 0.565617, acc: 78.91%] [G loss: 2.171019]\n",
      "epoch:16 step:12663 [D loss: 0.743298, acc: 56.25%] [G loss: 1.970500]\n",
      "epoch:16 step:12664 [D loss: 0.597294, acc: 62.50%] [G loss: 2.550005]\n",
      "epoch:16 step:12665 [D loss: 0.719455, acc: 57.03%] [G loss: 1.979928]\n",
      "epoch:16 step:12666 [D loss: 0.475530, acc: 82.81%] [G loss: 2.633034]\n",
      "epoch:16 step:12667 [D loss: 0.481153, acc: 71.09%] [G loss: 2.609338]\n",
      "epoch:16 step:12668 [D loss: 0.465058, acc: 78.91%] [G loss: 2.100704]\n",
      "epoch:16 step:12669 [D loss: 0.665210, acc: 62.50%] [G loss: 2.296993]\n",
      "epoch:16 step:12670 [D loss: 0.510613, acc: 79.69%] [G loss: 1.769535]\n",
      "epoch:16 step:12671 [D loss: 0.401511, acc: 89.06%] [G loss: 2.565098]\n",
      "epoch:16 step:12672 [D loss: 0.628137, acc: 63.28%] [G loss: 2.491289]\n",
      "epoch:16 step:12673 [D loss: 0.475593, acc: 80.47%] [G loss: 3.213235]\n",
      "epoch:16 step:12674 [D loss: 0.809009, acc: 48.44%] [G loss: 2.244601]\n",
      "epoch:16 step:12675 [D loss: 0.282398, acc: 95.31%] [G loss: 2.059886]\n",
      "epoch:16 step:12676 [D loss: 0.596476, acc: 67.19%] [G loss: 2.479934]\n",
      "epoch:16 step:12677 [D loss: 0.589994, acc: 66.41%] [G loss: 2.220725]\n",
      "epoch:16 step:12678 [D loss: 0.543721, acc: 70.31%] [G loss: 2.216625]\n",
      "epoch:16 step:12679 [D loss: 0.545789, acc: 69.53%] [G loss: 2.060012]\n",
      "epoch:16 step:12680 [D loss: 0.693150, acc: 57.03%] [G loss: 2.576771]\n",
      "epoch:16 step:12681 [D loss: 0.545508, acc: 71.09%] [G loss: 2.165873]\n",
      "epoch:16 step:12682 [D loss: 0.588551, acc: 64.06%] [G loss: 1.910507]\n",
      "epoch:16 step:12683 [D loss: 0.363641, acc: 91.41%] [G loss: 2.743694]\n",
      "epoch:16 step:12684 [D loss: 0.369166, acc: 89.06%] [G loss: 2.964874]\n",
      "epoch:16 step:12685 [D loss: 0.584956, acc: 57.81%] [G loss: 2.873383]\n",
      "epoch:16 step:12686 [D loss: 0.676816, acc: 57.03%] [G loss: 1.852201]\n",
      "epoch:16 step:12687 [D loss: 0.493380, acc: 80.47%] [G loss: 2.661641]\n",
      "epoch:16 step:12688 [D loss: 0.374267, acc: 79.69%] [G loss: 1.848942]\n",
      "epoch:16 step:12689 [D loss: 0.696364, acc: 53.91%] [G loss: 2.406122]\n",
      "epoch:16 step:12690 [D loss: 1.180393, acc: 17.97%] [G loss: 2.356622]\n",
      "epoch:16 step:12691 [D loss: 0.419136, acc: 86.72%] [G loss: 2.122204]\n",
      "epoch:16 step:12692 [D loss: 1.068455, acc: 22.66%] [G loss: 2.028108]\n",
      "epoch:16 step:12693 [D loss: 0.485543, acc: 82.03%] [G loss: 2.121320]\n",
      "epoch:16 step:12694 [D loss: 0.487569, acc: 71.88%] [G loss: 2.564228]\n",
      "epoch:16 step:12695 [D loss: 0.764086, acc: 44.53%] [G loss: 2.279924]\n",
      "epoch:16 step:12696 [D loss: 0.435408, acc: 78.91%] [G loss: 2.229476]\n",
      "epoch:16 step:12697 [D loss: 0.307129, acc: 91.41%] [G loss: 3.073630]\n",
      "epoch:16 step:12698 [D loss: 1.277476, acc: 10.94%] [G loss: 1.397553]\n",
      "epoch:16 step:12699 [D loss: 0.771983, acc: 54.69%] [G loss: 1.889331]\n",
      "epoch:16 step:12700 [D loss: 0.527844, acc: 77.34%] [G loss: 2.726960]\n",
      "epoch:16 step:12701 [D loss: 0.620494, acc: 60.94%] [G loss: 2.332386]\n",
      "epoch:16 step:12702 [D loss: 1.025951, acc: 29.69%] [G loss: 2.017900]\n",
      "epoch:16 step:12703 [D loss: 0.735734, acc: 48.44%] [G loss: 2.279318]\n",
      "epoch:16 step:12704 [D loss: 0.494716, acc: 78.12%] [G loss: 2.434608]\n",
      "epoch:16 step:12705 [D loss: 0.569059, acc: 72.66%] [G loss: 2.195468]\n",
      "epoch:16 step:12706 [D loss: 0.560219, acc: 69.53%] [G loss: 2.176072]\n",
      "epoch:16 step:12707 [D loss: 0.534843, acc: 71.09%] [G loss: 2.155250]\n",
      "epoch:16 step:12708 [D loss: 0.543737, acc: 77.34%] [G loss: 2.531949]\n",
      "epoch:16 step:12709 [D loss: 0.526842, acc: 68.75%] [G loss: 2.958414]\n",
      "epoch:16 step:12710 [D loss: 0.424934, acc: 83.59%] [G loss: 2.961101]\n",
      "epoch:16 step:12711 [D loss: 0.485654, acc: 86.72%] [G loss: 2.555094]\n",
      "epoch:16 step:12712 [D loss: 0.175396, acc: 99.22%] [G loss: 2.510515]\n",
      "epoch:16 step:12713 [D loss: 0.630717, acc: 64.06%] [G loss: 1.462702]\n",
      "epoch:16 step:12714 [D loss: 0.489184, acc: 84.38%] [G loss: 2.349268]\n",
      "epoch:16 step:12715 [D loss: 0.389558, acc: 90.62%] [G loss: 2.461629]\n",
      "epoch:16 step:12716 [D loss: 0.442066, acc: 78.91%] [G loss: 2.085263]\n",
      "epoch:16 step:12717 [D loss: 0.667640, acc: 54.69%] [G loss: 2.104170]\n",
      "epoch:16 step:12718 [D loss: 0.622795, acc: 61.72%] [G loss: 2.434632]\n",
      "epoch:16 step:12719 [D loss: 0.824070, acc: 46.88%] [G loss: 1.922081]\n",
      "epoch:16 step:12720 [D loss: 0.595821, acc: 66.41%] [G loss: 2.497879]\n",
      "epoch:16 step:12721 [D loss: 0.669571, acc: 58.59%] [G loss: 1.815547]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:12722 [D loss: 0.495747, acc: 63.28%] [G loss: 2.058333]\n",
      "epoch:16 step:12723 [D loss: 0.181746, acc: 99.22%] [G loss: 2.540786]\n",
      "epoch:16 step:12724 [D loss: 0.295849, acc: 96.09%] [G loss: 2.276694]\n",
      "epoch:16 step:12725 [D loss: 1.096457, acc: 30.47%] [G loss: 1.558521]\n",
      "epoch:16 step:12726 [D loss: 0.714543, acc: 59.38%] [G loss: 2.415384]\n",
      "epoch:16 step:12727 [D loss: 0.294682, acc: 91.41%] [G loss: 2.622217]\n",
      "epoch:16 step:12728 [D loss: 0.497597, acc: 78.91%] [G loss: 1.889776]\n",
      "epoch:16 step:12729 [D loss: 0.493786, acc: 78.91%] [G loss: 2.136832]\n",
      "epoch:16 step:12730 [D loss: 0.450338, acc: 75.00%] [G loss: 1.857810]\n",
      "epoch:16 step:12731 [D loss: 0.795840, acc: 51.56%] [G loss: 2.042215]\n",
      "epoch:16 step:12732 [D loss: 1.261645, acc: 10.94%] [G loss: 2.658556]\n",
      "epoch:16 step:12733 [D loss: 0.471572, acc: 83.59%] [G loss: 2.357591]\n",
      "epoch:16 step:12734 [D loss: 0.363977, acc: 87.50%] [G loss: 3.007329]\n",
      "epoch:16 step:12735 [D loss: 0.200751, acc: 99.22%] [G loss: 2.891932]\n",
      "epoch:16 step:12736 [D loss: 0.781301, acc: 44.53%] [G loss: 2.707156]\n",
      "epoch:16 step:12737 [D loss: 0.679337, acc: 57.03%] [G loss: 2.430184]\n",
      "epoch:16 step:12738 [D loss: 0.657491, acc: 53.91%] [G loss: 2.350056]\n",
      "epoch:16 step:12739 [D loss: 0.626815, acc: 60.94%] [G loss: 3.016665]\n",
      "epoch:16 step:12740 [D loss: 0.397421, acc: 88.28%] [G loss: 2.300932]\n",
      "epoch:16 step:12741 [D loss: 0.906040, acc: 48.44%] [G loss: 2.054326]\n",
      "epoch:16 step:12742 [D loss: 0.497767, acc: 82.03%] [G loss: 2.852042]\n",
      "epoch:16 step:12743 [D loss: 0.600494, acc: 73.44%] [G loss: 2.528343]\n",
      "epoch:16 step:12744 [D loss: 0.629154, acc: 64.06%] [G loss: 2.167671]\n",
      "epoch:16 step:12745 [D loss: 0.651430, acc: 61.72%] [G loss: 1.891876]\n",
      "epoch:16 step:12746 [D loss: 0.566356, acc: 72.66%] [G loss: 2.655688]\n",
      "epoch:16 step:12747 [D loss: 0.417515, acc: 89.84%] [G loss: 2.297034]\n",
      "epoch:16 step:12748 [D loss: 0.268974, acc: 97.66%] [G loss: 2.481824]\n",
      "epoch:16 step:12749 [D loss: 0.685040, acc: 55.47%] [G loss: 2.067877]\n",
      "epoch:16 step:12750 [D loss: 0.545472, acc: 68.75%] [G loss: 1.896812]\n",
      "epoch:16 step:12751 [D loss: 0.410311, acc: 85.94%] [G loss: 2.645409]\n",
      "epoch:16 step:12752 [D loss: 0.330868, acc: 90.62%] [G loss: 3.194111]\n",
      "epoch:16 step:12753 [D loss: 0.656291, acc: 57.03%] [G loss: 2.195520]\n",
      "epoch:16 step:12754 [D loss: 0.776707, acc: 43.75%] [G loss: 1.697786]\n",
      "epoch:16 step:12755 [D loss: 0.652705, acc: 59.38%] [G loss: 1.971496]\n",
      "epoch:16 step:12756 [D loss: 0.388058, acc: 91.41%] [G loss: 2.442579]\n",
      "epoch:16 step:12757 [D loss: 0.433612, acc: 83.59%] [G loss: 2.513021]\n",
      "epoch:16 step:12758 [D loss: 0.483873, acc: 75.78%] [G loss: 2.568737]\n",
      "epoch:16 step:12759 [D loss: 0.858207, acc: 46.88%] [G loss: 2.641149]\n",
      "epoch:16 step:12760 [D loss: 0.831713, acc: 46.09%] [G loss: 2.360237]\n",
      "epoch:16 step:12761 [D loss: 0.550070, acc: 70.31%] [G loss: 2.836157]\n",
      "epoch:16 step:12762 [D loss: 0.818492, acc: 43.75%] [G loss: 2.073776]\n",
      "epoch:16 step:12763 [D loss: 1.407614, acc: 48.44%] [G loss: 2.329815]\n",
      "epoch:16 step:12764 [D loss: 0.529238, acc: 70.31%] [G loss: 2.924198]\n",
      "epoch:16 step:12765 [D loss: 0.539357, acc: 74.22%] [G loss: 1.957475]\n",
      "epoch:16 step:12766 [D loss: 0.586417, acc: 64.84%] [G loss: 2.292352]\n",
      "epoch:16 step:12767 [D loss: 0.454877, acc: 88.28%] [G loss: 2.681935]\n",
      "epoch:16 step:12768 [D loss: 0.936704, acc: 42.97%] [G loss: 2.480877]\n",
      "epoch:16 step:12769 [D loss: 0.498793, acc: 71.09%] [G loss: 2.357800]\n",
      "epoch:16 step:12770 [D loss: 0.440392, acc: 86.72%] [G loss: 3.178865]\n",
      "epoch:16 step:12771 [D loss: 0.758224, acc: 54.69%] [G loss: 2.538950]\n",
      "epoch:16 step:12772 [D loss: 0.638569, acc: 62.50%] [G loss: 3.442063]\n",
      "epoch:16 step:12773 [D loss: 0.647149, acc: 63.28%] [G loss: 3.091999]\n",
      "epoch:16 step:12774 [D loss: 0.441904, acc: 87.50%] [G loss: 2.899181]\n",
      "epoch:16 step:12775 [D loss: 0.453754, acc: 82.81%] [G loss: 3.378455]\n",
      "epoch:16 step:12776 [D loss: 0.519692, acc: 72.66%] [G loss: 2.653091]\n",
      "epoch:16 step:12777 [D loss: 0.351762, acc: 89.84%] [G loss: 2.499413]\n",
      "epoch:16 step:12778 [D loss: 0.679355, acc: 60.16%] [G loss: 2.204283]\n",
      "epoch:16 step:12779 [D loss: 0.800786, acc: 53.91%] [G loss: 2.122153]\n",
      "epoch:16 step:12780 [D loss: 0.479522, acc: 79.69%] [G loss: 2.561248]\n",
      "epoch:16 step:12781 [D loss: 0.722688, acc: 53.91%] [G loss: 2.577850]\n",
      "epoch:16 step:12782 [D loss: 0.779818, acc: 45.31%] [G loss: 2.053470]\n",
      "epoch:16 step:12783 [D loss: 0.263218, acc: 93.75%] [G loss: 2.922243]\n",
      "epoch:16 step:12784 [D loss: 0.409161, acc: 86.72%] [G loss: 2.656730]\n",
      "epoch:16 step:12785 [D loss: 0.780385, acc: 46.88%] [G loss: 2.265663]\n",
      "epoch:16 step:12786 [D loss: 0.426122, acc: 85.94%] [G loss: 2.447756]\n",
      "epoch:16 step:12787 [D loss: 0.469832, acc: 84.38%] [G loss: 2.122636]\n",
      "epoch:16 step:12788 [D loss: 0.577639, acc: 67.19%] [G loss: 2.547485]\n",
      "epoch:16 step:12789 [D loss: 0.557907, acc: 75.00%] [G loss: 2.293566]\n",
      "epoch:16 step:12790 [D loss: 0.505171, acc: 79.69%] [G loss: 2.877967]\n",
      "epoch:16 step:12791 [D loss: 0.576537, acc: 71.88%] [G loss: 2.956903]\n",
      "epoch:16 step:12792 [D loss: 0.381850, acc: 90.62%] [G loss: 2.820163]\n",
      "epoch:16 step:12793 [D loss: 0.492046, acc: 62.50%] [G loss: 2.350694]\n",
      "epoch:16 step:12794 [D loss: 0.726565, acc: 53.91%] [G loss: 2.624591]\n",
      "epoch:16 step:12795 [D loss: 0.551275, acc: 70.31%] [G loss: 2.765813]\n",
      "epoch:16 step:12796 [D loss: 0.946992, acc: 32.03%] [G loss: 2.281866]\n",
      "epoch:16 step:12797 [D loss: 0.523969, acc: 63.28%] [G loss: 2.256863]\n",
      "epoch:16 step:12798 [D loss: 0.427577, acc: 84.38%] [G loss: 2.688680]\n",
      "epoch:16 step:12799 [D loss: 0.773492, acc: 42.19%] [G loss: 1.948820]\n",
      "epoch:16 step:12800 [D loss: 0.306933, acc: 96.88%] [G loss: 2.186065]\n",
      "epoch:16 step:12801 [D loss: 0.397090, acc: 80.47%] [G loss: 2.061219]\n",
      "epoch:16 step:12802 [D loss: 0.643347, acc: 62.50%] [G loss: 2.497723]\n",
      "epoch:16 step:12803 [D loss: 0.691694, acc: 57.81%] [G loss: 2.354033]\n",
      "epoch:16 step:12804 [D loss: 0.423645, acc: 75.78%] [G loss: 2.302294]\n",
      "epoch:16 step:12805 [D loss: 0.464959, acc: 85.94%] [G loss: 2.476517]\n",
      "epoch:16 step:12806 [D loss: 0.298467, acc: 94.53%] [G loss: 2.221441]\n",
      "epoch:16 step:12807 [D loss: 0.890123, acc: 28.91%] [G loss: 2.107611]\n",
      "epoch:16 step:12808 [D loss: 0.384336, acc: 92.19%] [G loss: 2.414143]\n",
      "epoch:16 step:12809 [D loss: 0.624693, acc: 64.06%] [G loss: 1.989598]\n",
      "epoch:16 step:12810 [D loss: 0.554342, acc: 64.84%] [G loss: 2.406769]\n",
      "epoch:16 step:12811 [D loss: 1.413754, acc: 11.72%] [G loss: 1.974021]\n",
      "epoch:16 step:12812 [D loss: 0.511120, acc: 81.25%] [G loss: 2.393191]\n",
      "epoch:16 step:12813 [D loss: 0.591351, acc: 65.62%] [G loss: 2.474461]\n",
      "epoch:16 step:12814 [D loss: 0.754829, acc: 52.34%] [G loss: 2.234380]\n",
      "epoch:16 step:12815 [D loss: 0.761338, acc: 50.00%] [G loss: 1.614605]\n",
      "epoch:16 step:12816 [D loss: 0.545338, acc: 61.72%] [G loss: 2.641989]\n",
      "epoch:16 step:12817 [D loss: 0.706697, acc: 53.12%] [G loss: 2.310995]\n",
      "epoch:16 step:12818 [D loss: 0.455282, acc: 89.84%] [G loss: 2.262642]\n",
      "epoch:16 step:12819 [D loss: 0.906572, acc: 34.38%] [G loss: 1.731746]\n",
      "epoch:16 step:12820 [D loss: 0.768658, acc: 45.31%] [G loss: 1.827447]\n",
      "epoch:16 step:12821 [D loss: 0.590450, acc: 69.53%] [G loss: 2.097965]\n",
      "epoch:16 step:12822 [D loss: 0.402720, acc: 82.03%] [G loss: 2.716256]\n",
      "epoch:16 step:12823 [D loss: 0.696679, acc: 56.25%] [G loss: 2.193607]\n",
      "epoch:16 step:12824 [D loss: 0.422540, acc: 88.28%] [G loss: 2.928296]\n",
      "epoch:16 step:12825 [D loss: 0.428011, acc: 88.28%] [G loss: 2.301371]\n",
      "epoch:16 step:12826 [D loss: 0.741966, acc: 50.00%] [G loss: 2.361319]\n",
      "epoch:16 step:12827 [D loss: 0.688739, acc: 63.28%] [G loss: 2.369861]\n",
      "epoch:16 step:12828 [D loss: 0.553836, acc: 75.78%] [G loss: 2.292050]\n",
      "epoch:16 step:12829 [D loss: 0.235578, acc: 99.22%] [G loss: 3.817069]\n",
      "epoch:16 step:12830 [D loss: 0.396802, acc: 90.62%] [G loss: 2.427770]\n",
      "epoch:16 step:12831 [D loss: 0.681129, acc: 54.69%] [G loss: 3.032820]\n",
      "epoch:16 step:12832 [D loss: 0.622676, acc: 61.72%] [G loss: 2.442426]\n",
      "epoch:16 step:12833 [D loss: 0.561821, acc: 74.22%] [G loss: 2.498012]\n",
      "epoch:16 step:12834 [D loss: 0.783616, acc: 47.66%] [G loss: 2.309240]\n",
      "epoch:16 step:12835 [D loss: 0.727656, acc: 56.25%] [G loss: 2.314141]\n",
      "epoch:16 step:12836 [D loss: 0.972990, acc: 32.81%] [G loss: 1.997017]\n",
      "epoch:16 step:12837 [D loss: 0.636260, acc: 64.84%] [G loss: 2.148047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:12838 [D loss: 0.548788, acc: 77.34%] [G loss: 1.844614]\n",
      "epoch:16 step:12839 [D loss: 0.414775, acc: 91.41%] [G loss: 2.371799]\n",
      "epoch:16 step:12840 [D loss: 0.530361, acc: 79.69%] [G loss: 2.332500]\n",
      "epoch:16 step:12841 [D loss: 0.621579, acc: 64.06%] [G loss: 2.167147]\n",
      "epoch:16 step:12842 [D loss: 0.331163, acc: 95.31%] [G loss: 2.762630]\n",
      "epoch:16 step:12843 [D loss: 0.392218, acc: 88.28%] [G loss: 3.061977]\n",
      "epoch:16 step:12844 [D loss: 0.401940, acc: 82.81%] [G loss: 2.817816]\n",
      "epoch:16 step:12845 [D loss: 0.577550, acc: 70.31%] [G loss: 2.395028]\n",
      "epoch:16 step:12846 [D loss: 0.474413, acc: 75.00%] [G loss: 2.532448]\n",
      "epoch:16 step:12847 [D loss: 0.695175, acc: 53.91%] [G loss: 2.272347]\n",
      "epoch:16 step:12848 [D loss: 0.346103, acc: 92.19%] [G loss: 2.671997]\n",
      "epoch:16 step:12849 [D loss: 0.450270, acc: 83.59%] [G loss: 3.082260]\n",
      "epoch:16 step:12850 [D loss: 0.507666, acc: 77.34%] [G loss: 2.660921]\n",
      "epoch:16 step:12851 [D loss: 0.380788, acc: 88.28%] [G loss: 2.077124]\n",
      "epoch:16 step:12852 [D loss: 0.489706, acc: 78.12%] [G loss: 2.206435]\n",
      "epoch:16 step:12853 [D loss: 0.521013, acc: 70.31%] [G loss: 2.003964]\n",
      "epoch:16 step:12854 [D loss: 0.896933, acc: 35.16%] [G loss: 1.926136]\n",
      "epoch:16 step:12855 [D loss: 0.802772, acc: 38.28%] [G loss: 2.248807]\n",
      "epoch:16 step:12856 [D loss: 0.995691, acc: 40.62%] [G loss: 1.584162]\n",
      "epoch:16 step:12857 [D loss: 0.473878, acc: 82.81%] [G loss: 1.836253]\n",
      "epoch:16 step:12858 [D loss: 0.941747, acc: 32.81%] [G loss: 1.808112]\n",
      "epoch:16 step:12859 [D loss: 0.247777, acc: 98.44%] [G loss: 2.157048]\n",
      "epoch:16 step:12860 [D loss: 0.412479, acc: 91.41%] [G loss: 1.992770]\n",
      "epoch:16 step:12861 [D loss: 0.501014, acc: 80.47%] [G loss: 2.059627]\n",
      "epoch:16 step:12862 [D loss: 0.807988, acc: 39.84%] [G loss: 2.404429]\n",
      "epoch:16 step:12863 [D loss: 0.558932, acc: 75.78%] [G loss: 2.231915]\n",
      "epoch:16 step:12864 [D loss: 0.560339, acc: 73.44%] [G loss: 2.233961]\n",
      "epoch:16 step:12865 [D loss: 0.453304, acc: 79.69%] [G loss: 3.443618]\n",
      "epoch:16 step:12866 [D loss: 0.287575, acc: 92.97%] [G loss: 2.173851]\n",
      "epoch:16 step:12867 [D loss: 0.688292, acc: 59.38%] [G loss: 2.445985]\n",
      "epoch:16 step:12868 [D loss: 0.668541, acc: 58.59%] [G loss: 2.394399]\n",
      "epoch:16 step:12869 [D loss: 1.255633, acc: 21.09%] [G loss: 2.321165]\n",
      "epoch:16 step:12870 [D loss: 0.475226, acc: 82.03%] [G loss: 2.308262]\n",
      "epoch:16 step:12871 [D loss: 0.450879, acc: 87.50%] [G loss: 3.203100]\n",
      "epoch:16 step:12872 [D loss: 0.508142, acc: 83.59%] [G loss: 2.335178]\n",
      "epoch:16 step:12873 [D loss: 0.632378, acc: 64.84%] [G loss: 2.702654]\n",
      "epoch:16 step:12874 [D loss: 0.411436, acc: 83.59%] [G loss: 2.647760]\n",
      "epoch:16 step:12875 [D loss: 0.589094, acc: 70.31%] [G loss: 2.467537]\n",
      "epoch:16 step:12876 [D loss: 0.323380, acc: 87.50%] [G loss: 2.603887]\n",
      "epoch:16 step:12877 [D loss: 0.479296, acc: 77.34%] [G loss: 2.409149]\n",
      "epoch:16 step:12878 [D loss: 0.339512, acc: 95.31%] [G loss: 2.961880]\n",
      "epoch:16 step:12879 [D loss: 0.534137, acc: 77.34%] [G loss: 2.511478]\n",
      "epoch:16 step:12880 [D loss: 0.488391, acc: 80.47%] [G loss: 3.245547]\n",
      "epoch:16 step:12881 [D loss: 0.433304, acc: 82.81%] [G loss: 2.338472]\n",
      "epoch:16 step:12882 [D loss: 0.583841, acc: 66.41%] [G loss: 2.095088]\n",
      "epoch:16 step:12883 [D loss: 0.544054, acc: 75.00%] [G loss: 2.037504]\n",
      "epoch:16 step:12884 [D loss: 0.618376, acc: 60.16%] [G loss: 2.437251]\n",
      "epoch:16 step:12885 [D loss: 0.616976, acc: 64.06%] [G loss: 2.593176]\n",
      "epoch:16 step:12886 [D loss: 0.415678, acc: 83.59%] [G loss: 2.573594]\n",
      "epoch:16 step:12887 [D loss: 0.914299, acc: 32.81%] [G loss: 3.029329]\n",
      "epoch:16 step:12888 [D loss: 0.364791, acc: 87.50%] [G loss: 2.820683]\n",
      "epoch:16 step:12889 [D loss: 0.593838, acc: 67.19%] [G loss: 1.848219]\n",
      "epoch:16 step:12890 [D loss: 0.606223, acc: 69.53%] [G loss: 2.294106]\n",
      "epoch:16 step:12891 [D loss: 0.350522, acc: 94.53%] [G loss: 2.924095]\n",
      "epoch:16 step:12892 [D loss: 0.437562, acc: 81.25%] [G loss: 2.621521]\n",
      "epoch:16 step:12893 [D loss: 0.619174, acc: 66.41%] [G loss: 1.652736]\n",
      "epoch:16 step:12894 [D loss: 0.429756, acc: 88.28%] [G loss: 2.383341]\n",
      "epoch:16 step:12895 [D loss: 0.645351, acc: 57.81%] [G loss: 2.463511]\n",
      "epoch:16 step:12896 [D loss: 0.349735, acc: 94.53%] [G loss: 2.598181]\n",
      "epoch:16 step:12897 [D loss: 0.503579, acc: 74.22%] [G loss: 3.255044]\n",
      "epoch:16 step:12898 [D loss: 0.671432, acc: 57.81%] [G loss: 2.598543]\n",
      "epoch:16 step:12899 [D loss: 0.611300, acc: 65.62%] [G loss: 2.578582]\n",
      "epoch:16 step:12900 [D loss: 0.660631, acc: 58.59%] [G loss: 2.417301]\n",
      "epoch:16 step:12901 [D loss: 0.814583, acc: 44.53%] [G loss: 2.040187]\n",
      "epoch:16 step:12902 [D loss: 0.662795, acc: 59.38%] [G loss: 3.270989]\n",
      "epoch:16 step:12903 [D loss: 0.739896, acc: 53.12%] [G loss: 1.858647]\n",
      "epoch:16 step:12904 [D loss: 0.278296, acc: 87.50%] [G loss: 3.871541]\n",
      "epoch:16 step:12905 [D loss: 0.751292, acc: 49.22%] [G loss: 2.402912]\n",
      "epoch:16 step:12906 [D loss: 0.565021, acc: 75.78%] [G loss: 3.086890]\n",
      "epoch:16 step:12907 [D loss: 0.786356, acc: 46.09%] [G loss: 2.254436]\n",
      "epoch:16 step:12908 [D loss: 0.583193, acc: 69.53%] [G loss: 2.408544]\n",
      "epoch:16 step:12909 [D loss: 0.339772, acc: 90.62%] [G loss: 2.433014]\n",
      "epoch:16 step:12910 [D loss: 0.627173, acc: 66.41%] [G loss: 2.836661]\n",
      "epoch:16 step:12911 [D loss: 0.504667, acc: 81.25%] [G loss: 2.983381]\n",
      "epoch:16 step:12912 [D loss: 0.536550, acc: 78.91%] [G loss: 2.551584]\n",
      "epoch:16 step:12913 [D loss: 0.489521, acc: 71.88%] [G loss: 2.604030]\n",
      "epoch:16 step:12914 [D loss: 0.416174, acc: 91.41%] [G loss: 3.134595]\n",
      "epoch:16 step:12915 [D loss: 0.475238, acc: 75.00%] [G loss: 2.844947]\n",
      "epoch:16 step:12916 [D loss: 0.966730, acc: 34.38%] [G loss: 2.056482]\n",
      "epoch:16 step:12917 [D loss: 0.474244, acc: 76.56%] [G loss: 3.920680]\n",
      "epoch:16 step:12918 [D loss: 0.465154, acc: 78.91%] [G loss: 2.542459]\n",
      "epoch:16 step:12919 [D loss: 0.415433, acc: 89.84%] [G loss: 2.741359]\n",
      "epoch:16 step:12920 [D loss: 0.668671, acc: 61.72%] [G loss: 1.856317]\n",
      "epoch:16 step:12921 [D loss: 0.586087, acc: 68.75%] [G loss: 2.520395]\n",
      "epoch:16 step:12922 [D loss: 0.429884, acc: 85.16%] [G loss: 2.281889]\n",
      "epoch:16 step:12923 [D loss: 0.492260, acc: 77.34%] [G loss: 2.554820]\n",
      "epoch:16 step:12924 [D loss: 0.345935, acc: 92.19%] [G loss: 3.328928]\n",
      "epoch:16 step:12925 [D loss: 0.407063, acc: 85.16%] [G loss: 2.731690]\n",
      "epoch:16 step:12926 [D loss: 0.715588, acc: 58.59%] [G loss: 3.889242]\n",
      "epoch:16 step:12927 [D loss: 0.328142, acc: 92.19%] [G loss: 3.933713]\n",
      "epoch:16 step:12928 [D loss: 0.243799, acc: 96.88%] [G loss: 4.825731]\n",
      "epoch:16 step:12929 [D loss: 0.529361, acc: 75.78%] [G loss: 2.536184]\n",
      "epoch:16 step:12930 [D loss: 0.643083, acc: 63.28%] [G loss: 2.154137]\n",
      "epoch:16 step:12931 [D loss: 0.468802, acc: 82.81%] [G loss: 3.098169]\n",
      "epoch:16 step:12932 [D loss: 0.397076, acc: 89.06%] [G loss: 2.543893]\n",
      "epoch:16 step:12933 [D loss: 0.835938, acc: 43.75%] [G loss: 2.252397]\n",
      "epoch:16 step:12934 [D loss: 0.428538, acc: 82.81%] [G loss: 2.507645]\n",
      "epoch:16 step:12935 [D loss: 0.551614, acc: 72.66%] [G loss: 2.167436]\n",
      "epoch:16 step:12936 [D loss: 0.439362, acc: 88.28%] [G loss: 2.474310]\n",
      "epoch:16 step:12937 [D loss: 0.744072, acc: 53.91%] [G loss: 2.116947]\n",
      "epoch:16 step:12938 [D loss: 0.743656, acc: 51.56%] [G loss: 2.331596]\n",
      "epoch:16 step:12939 [D loss: 0.627018, acc: 62.50%] [G loss: 2.598439]\n",
      "epoch:16 step:12940 [D loss: 0.549999, acc: 67.97%] [G loss: 1.988032]\n",
      "epoch:16 step:12941 [D loss: 0.587667, acc: 71.88%] [G loss: 2.516915]\n",
      "epoch:16 step:12942 [D loss: 0.919194, acc: 46.09%] [G loss: 2.213180]\n",
      "epoch:16 step:12943 [D loss: 0.420327, acc: 83.59%] [G loss: 3.010666]\n",
      "epoch:16 step:12944 [D loss: 0.392682, acc: 89.06%] [G loss: 2.748983]\n",
      "epoch:16 step:12945 [D loss: 0.306968, acc: 94.53%] [G loss: 3.465188]\n",
      "epoch:16 step:12946 [D loss: 0.676013, acc: 58.59%] [G loss: 3.290454]\n",
      "epoch:16 step:12947 [D loss: 0.535280, acc: 74.22%] [G loss: 2.707690]\n",
      "epoch:16 step:12948 [D loss: 0.609373, acc: 71.09%] [G loss: 2.644336]\n",
      "epoch:16 step:12949 [D loss: 0.784909, acc: 42.97%] [G loss: 3.355794]\n",
      "epoch:16 step:12950 [D loss: 0.784590, acc: 49.22%] [G loss: 2.447488]\n",
      "epoch:16 step:12951 [D loss: 0.704885, acc: 57.81%] [G loss: 1.730213]\n",
      "epoch:16 step:12952 [D loss: 0.715541, acc: 56.25%] [G loss: 2.750344]\n",
      "epoch:16 step:12953 [D loss: 0.617068, acc: 65.62%] [G loss: 2.460477]\n",
      "epoch:16 step:12954 [D loss: 0.426588, acc: 84.38%] [G loss: 3.379703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:12955 [D loss: 0.312103, acc: 93.75%] [G loss: 1.963604]\n",
      "epoch:16 step:12956 [D loss: 0.653619, acc: 64.06%] [G loss: 2.466424]\n",
      "epoch:16 step:12957 [D loss: 0.924684, acc: 39.84%] [G loss: 2.353343]\n",
      "epoch:16 step:12958 [D loss: 0.351692, acc: 87.50%] [G loss: 2.787451]\n",
      "epoch:16 step:12959 [D loss: 0.901931, acc: 34.38%] [G loss: 1.840245]\n",
      "epoch:16 step:12960 [D loss: 0.780292, acc: 53.12%] [G loss: 2.966108]\n",
      "epoch:16 step:12961 [D loss: 0.559205, acc: 67.19%] [G loss: 2.310028]\n",
      "epoch:16 step:12962 [D loss: 0.238337, acc: 99.22%] [G loss: 2.470131]\n",
      "epoch:16 step:12963 [D loss: 0.563405, acc: 72.66%] [G loss: 3.077856]\n",
      "epoch:16 step:12964 [D loss: 0.825785, acc: 51.56%] [G loss: 2.238803]\n",
      "epoch:16 step:12965 [D loss: 0.486600, acc: 85.16%] [G loss: 2.345545]\n",
      "epoch:16 step:12966 [D loss: 0.487661, acc: 79.69%] [G loss: 2.942551]\n",
      "epoch:16 step:12967 [D loss: 0.685035, acc: 60.16%] [G loss: 2.799055]\n",
      "epoch:16 step:12968 [D loss: 0.436292, acc: 74.22%] [G loss: 3.698118]\n",
      "epoch:16 step:12969 [D loss: 0.600790, acc: 66.41%] [G loss: 2.394256]\n",
      "epoch:16 step:12970 [D loss: 0.175399, acc: 97.66%] [G loss: 4.192056]\n",
      "epoch:16 step:12971 [D loss: 0.752989, acc: 58.59%] [G loss: 2.070541]\n",
      "epoch:16 step:12972 [D loss: 0.248350, acc: 97.66%] [G loss: 2.692332]\n",
      "epoch:16 step:12973 [D loss: 0.684766, acc: 56.25%] [G loss: 2.136240]\n",
      "epoch:16 step:12974 [D loss: 0.349981, acc: 89.84%] [G loss: 2.480257]\n",
      "epoch:16 step:12975 [D loss: 0.456448, acc: 85.94%] [G loss: 2.277425]\n",
      "epoch:16 step:12976 [D loss: 0.719523, acc: 50.78%] [G loss: 2.420477]\n",
      "epoch:16 step:12977 [D loss: 0.366836, acc: 87.50%] [G loss: 3.904849]\n",
      "epoch:16 step:12978 [D loss: 0.892146, acc: 42.19%] [G loss: 2.563979]\n",
      "epoch:16 step:12979 [D loss: 0.419073, acc: 85.94%] [G loss: 2.722521]\n",
      "epoch:16 step:12980 [D loss: 0.693593, acc: 57.81%] [G loss: 2.478169]\n",
      "epoch:16 step:12981 [D loss: 0.857121, acc: 43.75%] [G loss: 1.976141]\n",
      "epoch:16 step:12982 [D loss: 0.383020, acc: 85.16%] [G loss: 3.214637]\n",
      "epoch:16 step:12983 [D loss: 0.749627, acc: 54.69%] [G loss: 2.546985]\n",
      "epoch:16 step:12984 [D loss: 0.654924, acc: 60.16%] [G loss: 2.382383]\n",
      "epoch:16 step:12985 [D loss: 0.643190, acc: 67.19%] [G loss: 2.468086]\n",
      "epoch:16 step:12986 [D loss: 0.306132, acc: 96.88%] [G loss: 3.312474]\n",
      "epoch:16 step:12987 [D loss: 0.679098, acc: 58.59%] [G loss: 2.817133]\n",
      "epoch:16 step:12988 [D loss: 0.672255, acc: 59.38%] [G loss: 2.167822]\n",
      "epoch:16 step:12989 [D loss: 0.714244, acc: 53.12%] [G loss: 3.014246]\n",
      "epoch:16 step:12990 [D loss: 0.353904, acc: 92.19%] [G loss: 2.133067]\n",
      "epoch:16 step:12991 [D loss: 0.608266, acc: 66.41%] [G loss: 2.571998]\n",
      "epoch:16 step:12992 [D loss: 0.570722, acc: 64.84%] [G loss: 2.783636]\n",
      "epoch:16 step:12993 [D loss: 0.231523, acc: 95.31%] [G loss: 3.312213]\n",
      "epoch:16 step:12994 [D loss: 0.324235, acc: 87.50%] [G loss: 3.158377]\n",
      "epoch:16 step:12995 [D loss: 1.020574, acc: 21.09%] [G loss: 2.313031]\n",
      "epoch:16 step:12996 [D loss: 0.653096, acc: 64.06%] [G loss: 3.446773]\n",
      "epoch:16 step:12997 [D loss: 0.369291, acc: 89.06%] [G loss: 2.674847]\n",
      "epoch:16 step:12998 [D loss: 0.457930, acc: 78.12%] [G loss: 2.181345]\n",
      "epoch:16 step:12999 [D loss: 0.696290, acc: 56.25%] [G loss: 2.252290]\n",
      "epoch:16 step:13000 [D loss: 0.605780, acc: 67.19%] [G loss: 2.295754]\n",
      "epoch:16 step:13001 [D loss: 0.478633, acc: 78.91%] [G loss: 3.374818]\n",
      "epoch:16 step:13002 [D loss: 0.791027, acc: 45.31%] [G loss: 2.390773]\n",
      "epoch:16 step:13003 [D loss: 0.369286, acc: 92.19%] [G loss: 2.754003]\n",
      "epoch:16 step:13004 [D loss: 0.471896, acc: 79.69%] [G loss: 3.664188]\n",
      "epoch:16 step:13005 [D loss: 0.386657, acc: 87.50%] [G loss: 2.905247]\n",
      "epoch:16 step:13006 [D loss: 0.497425, acc: 70.31%] [G loss: 3.021526]\n",
      "epoch:16 step:13007 [D loss: 0.208023, acc: 98.44%] [G loss: 4.913706]\n",
      "epoch:16 step:13008 [D loss: 0.705087, acc: 53.12%] [G loss: 3.310250]\n",
      "epoch:16 step:13009 [D loss: 0.884508, acc: 32.03%] [G loss: 2.519238]\n",
      "epoch:16 step:13010 [D loss: 0.519271, acc: 76.56%] [G loss: 3.343068]\n",
      "epoch:16 step:13011 [D loss: 0.516989, acc: 80.47%] [G loss: 2.642465]\n",
      "epoch:16 step:13012 [D loss: 0.723230, acc: 57.03%] [G loss: 1.930511]\n",
      "epoch:16 step:13013 [D loss: 0.379260, acc: 83.59%] [G loss: 2.625894]\n",
      "epoch:16 step:13014 [D loss: 0.737287, acc: 55.47%] [G loss: 2.824321]\n",
      "epoch:16 step:13015 [D loss: 1.053853, acc: 18.75%] [G loss: 2.533877]\n",
      "epoch:16 step:13016 [D loss: 0.342672, acc: 89.06%] [G loss: 3.451337]\n",
      "epoch:16 step:13017 [D loss: 0.461601, acc: 84.38%] [G loss: 2.396051]\n",
      "epoch:16 step:13018 [D loss: 0.803979, acc: 52.34%] [G loss: 2.802174]\n",
      "epoch:16 step:13019 [D loss: 0.688156, acc: 55.47%] [G loss: 1.763353]\n",
      "epoch:16 step:13020 [D loss: 0.586960, acc: 66.41%] [G loss: 2.513679]\n",
      "epoch:16 step:13021 [D loss: 0.362375, acc: 90.62%] [G loss: 3.097472]\n",
      "epoch:16 step:13022 [D loss: 1.207882, acc: 17.97%] [G loss: 2.144355]\n",
      "epoch:16 step:13023 [D loss: 0.497626, acc: 78.91%] [G loss: 2.361182]\n",
      "epoch:16 step:13024 [D loss: 0.495200, acc: 76.56%] [G loss: 2.824629]\n",
      "epoch:16 step:13025 [D loss: 0.502175, acc: 73.44%] [G loss: 2.850374]\n",
      "epoch:16 step:13026 [D loss: 0.580676, acc: 68.75%] [G loss: 3.096078]\n",
      "epoch:16 step:13027 [D loss: 0.712412, acc: 59.38%] [G loss: 2.267714]\n",
      "epoch:16 step:13028 [D loss: 0.711654, acc: 52.34%] [G loss: 2.543684]\n",
      "epoch:16 step:13029 [D loss: 0.773300, acc: 50.00%] [G loss: 2.372993]\n",
      "epoch:16 step:13030 [D loss: 0.513327, acc: 75.78%] [G loss: 2.352024]\n",
      "epoch:16 step:13031 [D loss: 0.545784, acc: 74.22%] [G loss: 2.982167]\n",
      "epoch:16 step:13032 [D loss: 0.236220, acc: 97.66%] [G loss: 3.301229]\n",
      "epoch:16 step:13033 [D loss: 0.540630, acc: 75.00%] [G loss: 2.912642]\n",
      "epoch:16 step:13034 [D loss: 0.446128, acc: 85.16%] [G loss: 2.554644]\n",
      "epoch:16 step:13035 [D loss: 0.820999, acc: 39.06%] [G loss: 1.992721]\n",
      "epoch:16 step:13036 [D loss: 0.409071, acc: 83.59%] [G loss: 2.555811]\n",
      "epoch:16 step:13037 [D loss: 0.766065, acc: 53.12%] [G loss: 3.036873]\n",
      "epoch:16 step:13038 [D loss: 0.444555, acc: 88.28%] [G loss: 3.066726]\n",
      "epoch:16 step:13039 [D loss: 0.468306, acc: 81.25%] [G loss: 2.944148]\n",
      "epoch:16 step:13040 [D loss: 0.681970, acc: 55.47%] [G loss: 2.418074]\n",
      "epoch:16 step:13041 [D loss: 0.571653, acc: 71.09%] [G loss: 2.867221]\n",
      "epoch:16 step:13042 [D loss: 0.284146, acc: 92.97%] [G loss: 3.183076]\n",
      "epoch:16 step:13043 [D loss: 0.760858, acc: 54.69%] [G loss: 2.269970]\n",
      "epoch:16 step:13044 [D loss: 0.550456, acc: 67.19%] [G loss: 3.045340]\n",
      "epoch:16 step:13045 [D loss: 0.497833, acc: 77.34%] [G loss: 2.618118]\n",
      "epoch:16 step:13046 [D loss: 0.366070, acc: 90.62%] [G loss: 2.971830]\n",
      "epoch:16 step:13047 [D loss: 0.526142, acc: 75.78%] [G loss: 3.067069]\n",
      "epoch:16 step:13048 [D loss: 0.520635, acc: 75.78%] [G loss: 2.182127]\n",
      "epoch:16 step:13049 [D loss: 0.564889, acc: 67.97%] [G loss: 2.995852]\n",
      "epoch:16 step:13050 [D loss: 0.256842, acc: 96.09%] [G loss: 2.772436]\n",
      "epoch:16 step:13051 [D loss: 0.384803, acc: 89.06%] [G loss: 3.123596]\n",
      "epoch:16 step:13052 [D loss: 0.587731, acc: 65.62%] [G loss: 3.370867]\n",
      "epoch:16 step:13053 [D loss: 0.972234, acc: 34.38%] [G loss: 2.380649]\n",
      "epoch:16 step:13054 [D loss: 0.588696, acc: 67.19%] [G loss: 2.359982]\n",
      "epoch:16 step:13055 [D loss: 0.653443, acc: 61.72%] [G loss: 2.683640]\n",
      "epoch:16 step:13056 [D loss: 0.467334, acc: 76.56%] [G loss: 2.409734]\n",
      "epoch:16 step:13057 [D loss: 0.421979, acc: 88.28%] [G loss: 2.489156]\n",
      "epoch:16 step:13058 [D loss: 0.587094, acc: 64.06%] [G loss: 2.226646]\n",
      "epoch:16 step:13059 [D loss: 0.643301, acc: 64.06%] [G loss: 2.018729]\n",
      "epoch:16 step:13060 [D loss: 0.246464, acc: 95.31%] [G loss: 2.690630]\n",
      "epoch:16 step:13061 [D loss: 0.402250, acc: 86.72%] [G loss: 2.557557]\n",
      "epoch:16 step:13062 [D loss: 0.509407, acc: 77.34%] [G loss: 1.826453]\n",
      "epoch:16 step:13063 [D loss: 1.014955, acc: 28.12%] [G loss: 2.272898]\n",
      "epoch:16 step:13064 [D loss: 0.851580, acc: 45.31%] [G loss: 1.917874]\n",
      "epoch:16 step:13065 [D loss: 0.415523, acc: 81.25%] [G loss: 2.232189]\n",
      "epoch:16 step:13066 [D loss: 0.570422, acc: 57.81%] [G loss: 2.538640]\n",
      "epoch:16 step:13067 [D loss: 0.657227, acc: 67.19%] [G loss: 2.228803]\n",
      "epoch:16 step:13068 [D loss: 0.530456, acc: 71.09%] [G loss: 2.748965]\n",
      "epoch:16 step:13069 [D loss: 0.642472, acc: 64.84%] [G loss: 3.155492]\n",
      "epoch:16 step:13070 [D loss: 0.691437, acc: 57.03%] [G loss: 2.601162]\n",
      "epoch:16 step:13071 [D loss: 0.601251, acc: 64.06%] [G loss: 2.780915]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:13072 [D loss: 0.490098, acc: 85.16%] [G loss: 3.767171]\n",
      "epoch:16 step:13073 [D loss: 0.510920, acc: 67.19%] [G loss: 3.431175]\n",
      "epoch:16 step:13074 [D loss: 0.555009, acc: 72.66%] [G loss: 3.263858]\n",
      "epoch:16 step:13075 [D loss: 0.654033, acc: 60.16%] [G loss: 2.407194]\n",
      "epoch:16 step:13076 [D loss: 0.593575, acc: 67.97%] [G loss: 2.895781]\n",
      "epoch:16 step:13077 [D loss: 0.406294, acc: 89.84%] [G loss: 2.677145]\n",
      "epoch:16 step:13078 [D loss: 0.675473, acc: 62.50%] [G loss: 2.613155]\n",
      "epoch:16 step:13079 [D loss: 0.512853, acc: 73.44%] [G loss: 2.896641]\n",
      "epoch:16 step:13080 [D loss: 0.414147, acc: 88.28%] [G loss: 2.149366]\n",
      "epoch:16 step:13081 [D loss: 0.249350, acc: 98.44%] [G loss: 2.443254]\n",
      "epoch:16 step:13082 [D loss: 0.441816, acc: 79.69%] [G loss: 2.281521]\n",
      "epoch:16 step:13083 [D loss: 0.456089, acc: 83.59%] [G loss: 2.578865]\n",
      "epoch:16 step:13084 [D loss: 0.763482, acc: 50.00%] [G loss: 4.262803]\n",
      "epoch:16 step:13085 [D loss: 1.602442, acc: 8.59%] [G loss: 2.383563]\n",
      "epoch:16 step:13086 [D loss: 0.261564, acc: 95.31%] [G loss: 3.391950]\n",
      "epoch:16 step:13087 [D loss: 0.448919, acc: 86.72%] [G loss: 3.638670]\n",
      "epoch:16 step:13088 [D loss: 0.665519, acc: 57.03%] [G loss: 2.211835]\n",
      "epoch:16 step:13089 [D loss: 0.646712, acc: 61.72%] [G loss: 2.429845]\n",
      "epoch:16 step:13090 [D loss: 0.756077, acc: 51.56%] [G loss: 2.546268]\n",
      "epoch:16 step:13091 [D loss: 0.325632, acc: 96.09%] [G loss: 3.060998]\n",
      "epoch:16 step:13092 [D loss: 1.074684, acc: 27.34%] [G loss: 2.042567]\n",
      "epoch:16 step:13093 [D loss: 0.582337, acc: 72.66%] [G loss: 3.295615]\n",
      "epoch:16 step:13094 [D loss: 1.002847, acc: 26.56%] [G loss: 2.411194]\n",
      "epoch:16 step:13095 [D loss: 0.728029, acc: 55.47%] [G loss: 3.335836]\n",
      "epoch:16 step:13096 [D loss: 0.773628, acc: 50.00%] [G loss: 2.287477]\n",
      "epoch:16 step:13097 [D loss: 0.335599, acc: 92.97%] [G loss: 2.851833]\n",
      "epoch:16 step:13098 [D loss: 0.566125, acc: 73.44%] [G loss: 2.715663]\n",
      "epoch:16 step:13099 [D loss: 0.507998, acc: 82.81%] [G loss: 3.060237]\n",
      "epoch:16 step:13100 [D loss: 0.416151, acc: 86.72%] [G loss: 3.021849]\n",
      "epoch:16 step:13101 [D loss: 0.378488, acc: 88.28%] [G loss: 2.892746]\n",
      "epoch:16 step:13102 [D loss: 0.753955, acc: 49.22%] [G loss: 2.389844]\n",
      "epoch:16 step:13103 [D loss: 0.561558, acc: 73.44%] [G loss: 2.357933]\n",
      "epoch:16 step:13104 [D loss: 0.551205, acc: 72.66%] [G loss: 2.242663]\n",
      "epoch:16 step:13105 [D loss: 1.003674, acc: 28.91%] [G loss: 2.051816]\n",
      "epoch:16 step:13106 [D loss: 0.385747, acc: 90.62%] [G loss: 2.545081]\n",
      "epoch:16 step:13107 [D loss: 0.577094, acc: 67.19%] [G loss: 2.266982]\n",
      "epoch:16 step:13108 [D loss: 0.712184, acc: 57.03%] [G loss: 2.317448]\n",
      "epoch:16 step:13109 [D loss: 0.582797, acc: 72.66%] [G loss: 2.608579]\n",
      "epoch:16 step:13110 [D loss: 0.512622, acc: 80.47%] [G loss: 2.331698]\n",
      "epoch:16 step:13111 [D loss: 0.450453, acc: 73.44%] [G loss: 2.670296]\n",
      "epoch:16 step:13112 [D loss: 0.991398, acc: 28.12%] [G loss: 2.410754]\n",
      "epoch:16 step:13113 [D loss: 0.569480, acc: 67.97%] [G loss: 3.612154]\n",
      "epoch:16 step:13114 [D loss: 0.337574, acc: 97.66%] [G loss: 2.891822]\n",
      "epoch:16 step:13115 [D loss: 0.471422, acc: 78.12%] [G loss: 2.574650]\n",
      "epoch:16 step:13116 [D loss: 0.462388, acc: 83.59%] [G loss: 2.673621]\n",
      "epoch:16 step:13117 [D loss: 0.435020, acc: 82.03%] [G loss: 2.737227]\n",
      "epoch:16 step:13118 [D loss: 0.524720, acc: 71.09%] [G loss: 2.258619]\n",
      "epoch:16 step:13119 [D loss: 0.784446, acc: 50.00%] [G loss: 2.483331]\n",
      "epoch:16 step:13120 [D loss: 0.448945, acc: 80.47%] [G loss: 1.972504]\n",
      "epoch:16 step:13121 [D loss: 0.437361, acc: 89.84%] [G loss: 2.986968]\n",
      "epoch:16 step:13122 [D loss: 0.264131, acc: 96.88%] [G loss: 2.684047]\n",
      "epoch:16 step:13123 [D loss: 0.819311, acc: 36.72%] [G loss: 2.507914]\n",
      "epoch:16 step:13124 [D loss: 0.714163, acc: 57.81%] [G loss: 2.208848]\n",
      "epoch:16 step:13125 [D loss: 0.369974, acc: 92.19%] [G loss: 2.647594]\n",
      "epoch:16 step:13126 [D loss: 0.500674, acc: 81.25%] [G loss: 3.993219]\n",
      "epoch:16 step:13127 [D loss: 0.746866, acc: 51.56%] [G loss: 2.406048]\n",
      "epoch:16 step:13128 [D loss: 0.715500, acc: 50.00%] [G loss: 3.332427]\n",
      "epoch:16 step:13129 [D loss: 0.473077, acc: 75.00%] [G loss: 2.593612]\n",
      "epoch:16 step:13130 [D loss: 0.747980, acc: 52.34%] [G loss: 2.382974]\n",
      "epoch:16 step:13131 [D loss: 0.390008, acc: 92.19%] [G loss: 1.983459]\n",
      "epoch:16 step:13132 [D loss: 0.738747, acc: 52.34%] [G loss: 2.525333]\n",
      "epoch:16 step:13133 [D loss: 0.859383, acc: 35.94%] [G loss: 2.873784]\n",
      "epoch:16 step:13134 [D loss: 0.322635, acc: 96.09%] [G loss: 2.533477]\n",
      "epoch:16 step:13135 [D loss: 0.615735, acc: 66.41%] [G loss: 2.870451]\n",
      "epoch:16 step:13136 [D loss: 0.410919, acc: 88.28%] [G loss: 2.058698]\n",
      "epoch:16 step:13137 [D loss: 0.555607, acc: 74.22%] [G loss: 2.704349]\n",
      "epoch:16 step:13138 [D loss: 0.845558, acc: 36.72%] [G loss: 1.546542]\n",
      "epoch:16 step:13139 [D loss: 0.455521, acc: 86.72%] [G loss: 2.810854]\n",
      "epoch:16 step:13140 [D loss: 0.528959, acc: 74.22%] [G loss: 1.871473]\n",
      "epoch:16 step:13141 [D loss: 0.628876, acc: 64.84%] [G loss: 2.193304]\n",
      "epoch:16 step:13142 [D loss: 1.033699, acc: 23.44%] [G loss: 2.434849]\n",
      "epoch:16 step:13143 [D loss: 0.453541, acc: 87.50%] [G loss: 2.476506]\n",
      "epoch:16 step:13144 [D loss: 0.500862, acc: 76.56%] [G loss: 2.617531]\n",
      "epoch:16 step:13145 [D loss: 0.496258, acc: 80.47%] [G loss: 2.144410]\n",
      "epoch:16 step:13146 [D loss: 0.388881, acc: 88.28%] [G loss: 2.526082]\n",
      "epoch:16 step:13147 [D loss: 0.657032, acc: 53.91%] [G loss: 2.719294]\n",
      "epoch:16 step:13148 [D loss: 0.376684, acc: 90.62%] [G loss: 3.068913]\n",
      "epoch:16 step:13149 [D loss: 0.493142, acc: 76.56%] [G loss: 2.456115]\n",
      "epoch:16 step:13150 [D loss: 0.253221, acc: 95.31%] [G loss: 2.859121]\n",
      "epoch:16 step:13151 [D loss: 0.682172, acc: 58.59%] [G loss: 2.170910]\n",
      "epoch:16 step:13152 [D loss: 0.707323, acc: 57.03%] [G loss: 2.775955]\n",
      "epoch:16 step:13153 [D loss: 0.135629, acc: 99.22%] [G loss: 4.312795]\n",
      "epoch:16 step:13154 [D loss: 0.398739, acc: 88.28%] [G loss: 3.001656]\n",
      "epoch:16 step:13155 [D loss: 0.854775, acc: 51.56%] [G loss: 2.605625]\n",
      "epoch:16 step:13156 [D loss: 0.621367, acc: 64.06%] [G loss: 2.001078]\n",
      "epoch:16 step:13157 [D loss: 0.653816, acc: 60.94%] [G loss: 2.891064]\n",
      "epoch:16 step:13158 [D loss: 0.365387, acc: 89.84%] [G loss: 2.204254]\n",
      "epoch:16 step:13159 [D loss: 0.258533, acc: 97.66%] [G loss: 2.636522]\n",
      "epoch:16 step:13160 [D loss: 0.437672, acc: 82.81%] [G loss: 2.866072]\n",
      "epoch:16 step:13161 [D loss: 1.030771, acc: 25.00%] [G loss: 1.726353]\n",
      "epoch:16 step:13162 [D loss: 0.627580, acc: 69.53%] [G loss: 2.194754]\n",
      "epoch:16 step:13163 [D loss: 0.247180, acc: 93.75%] [G loss: 2.832386]\n",
      "epoch:16 step:13164 [D loss: 0.302397, acc: 94.53%] [G loss: 2.736078]\n",
      "epoch:16 step:13165 [D loss: 0.692922, acc: 57.03%] [G loss: 2.176040]\n",
      "epoch:16 step:13166 [D loss: 0.652648, acc: 57.81%] [G loss: 2.406216]\n",
      "epoch:16 step:13167 [D loss: 0.509688, acc: 73.44%] [G loss: 2.681056]\n",
      "epoch:16 step:13168 [D loss: 0.414430, acc: 89.06%] [G loss: 2.099253]\n",
      "epoch:16 step:13169 [D loss: 0.879129, acc: 43.75%] [G loss: 2.233471]\n",
      "epoch:16 step:13170 [D loss: 0.967527, acc: 32.81%] [G loss: 1.684714]\n",
      "epoch:16 step:13171 [D loss: 0.380909, acc: 86.72%] [G loss: 2.752913]\n",
      "epoch:16 step:13172 [D loss: 0.903984, acc: 44.53%] [G loss: 3.309493]\n",
      "epoch:16 step:13173 [D loss: 0.814947, acc: 53.91%] [G loss: 2.583601]\n",
      "epoch:16 step:13174 [D loss: 0.798323, acc: 46.09%] [G loss: 2.528196]\n",
      "epoch:16 step:13175 [D loss: 0.698191, acc: 55.47%] [G loss: 2.484990]\n",
      "epoch:16 step:13176 [D loss: 0.467945, acc: 71.88%] [G loss: 2.621179]\n",
      "epoch:16 step:13177 [D loss: 0.533838, acc: 75.78%] [G loss: 2.616606]\n",
      "epoch:16 step:13178 [D loss: 0.829985, acc: 40.62%] [G loss: 1.997658]\n",
      "epoch:16 step:13179 [D loss: 0.502133, acc: 77.34%] [G loss: 2.753074]\n",
      "epoch:16 step:13180 [D loss: 0.584287, acc: 67.97%] [G loss: 3.028006]\n",
      "epoch:16 step:13181 [D loss: 0.324977, acc: 88.28%] [G loss: 2.896751]\n",
      "epoch:16 step:13182 [D loss: 0.434426, acc: 82.81%] [G loss: 3.940670]\n",
      "epoch:16 step:13183 [D loss: 0.498210, acc: 79.69%] [G loss: 2.193176]\n",
      "epoch:16 step:13184 [D loss: 0.556584, acc: 61.72%] [G loss: 3.544178]\n",
      "epoch:16 step:13185 [D loss: 0.513951, acc: 78.91%] [G loss: 2.274993]\n",
      "epoch:16 step:13186 [D loss: 0.590146, acc: 64.84%] [G loss: 2.043338]\n",
      "epoch:16 step:13187 [D loss: 0.412568, acc: 79.69%] [G loss: 3.413616]\n",
      "epoch:16 step:13188 [D loss: 0.984606, acc: 46.88%] [G loss: 2.090144]\n",
      "epoch:16 step:13189 [D loss: 0.205257, acc: 98.44%] [G loss: 3.197579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:13190 [D loss: 0.591339, acc: 71.88%] [G loss: 3.323405]\n",
      "epoch:16 step:13191 [D loss: 0.410294, acc: 89.84%] [G loss: 2.340447]\n",
      "epoch:16 step:13192 [D loss: 0.560429, acc: 75.00%] [G loss: 2.495403]\n",
      "epoch:16 step:13193 [D loss: 1.186471, acc: 19.53%] [G loss: 2.592683]\n",
      "epoch:16 step:13194 [D loss: 0.628374, acc: 67.97%] [G loss: 1.925456]\n",
      "epoch:16 step:13195 [D loss: 1.037410, acc: 39.84%] [G loss: 2.065869]\n",
      "epoch:16 step:13196 [D loss: 0.417630, acc: 90.62%] [G loss: 2.492411]\n",
      "epoch:16 step:13197 [D loss: 0.594466, acc: 67.19%] [G loss: 2.568291]\n",
      "epoch:16 step:13198 [D loss: 0.787271, acc: 44.53%] [G loss: 1.949462]\n",
      "epoch:16 step:13199 [D loss: 0.803603, acc: 50.78%] [G loss: 2.467483]\n",
      "epoch:16 step:13200 [D loss: 0.480792, acc: 76.56%] [G loss: 2.200787]\n",
      "epoch:16 step:13201 [D loss: 0.894455, acc: 29.69%] [G loss: 2.637231]\n",
      "epoch:16 step:13202 [D loss: 0.800829, acc: 44.53%] [G loss: 1.901818]\n",
      "epoch:16 step:13203 [D loss: 0.600150, acc: 67.97%] [G loss: 3.112438]\n",
      "epoch:16 step:13204 [D loss: 0.669777, acc: 63.28%] [G loss: 1.996708]\n",
      "epoch:16 step:13205 [D loss: 0.370528, acc: 89.84%] [G loss: 2.653052]\n",
      "epoch:16 step:13206 [D loss: 0.438741, acc: 76.56%] [G loss: 2.771516]\n",
      "epoch:16 step:13207 [D loss: 0.432272, acc: 86.72%] [G loss: 3.496166]\n",
      "epoch:16 step:13208 [D loss: 0.295938, acc: 93.75%] [G loss: 3.031577]\n",
      "epoch:16 step:13209 [D loss: 0.327779, acc: 95.31%] [G loss: 2.681999]\n",
      "epoch:16 step:13210 [D loss: 0.471484, acc: 77.34%] [G loss: 2.449415]\n",
      "epoch:16 step:13211 [D loss: 0.616550, acc: 63.28%] [G loss: 2.775451]\n",
      "epoch:16 step:13212 [D loss: 0.474534, acc: 84.38%] [G loss: 3.355330]\n",
      "epoch:16 step:13213 [D loss: 0.765923, acc: 46.09%] [G loss: 2.303406]\n",
      "epoch:16 step:13214 [D loss: 0.616294, acc: 65.62%] [G loss: 3.453120]\n",
      "epoch:16 step:13215 [D loss: 0.431430, acc: 86.72%] [G loss: 3.247723]\n",
      "epoch:16 step:13216 [D loss: 1.131565, acc: 20.31%] [G loss: 2.776832]\n",
      "epoch:16 step:13217 [D loss: 0.606852, acc: 64.06%] [G loss: 3.262555]\n",
      "epoch:16 step:13218 [D loss: 0.412192, acc: 86.72%] [G loss: 2.302696]\n",
      "epoch:16 step:13219 [D loss: 0.474043, acc: 82.03%] [G loss: 2.632626]\n",
      "epoch:16 step:13220 [D loss: 0.402087, acc: 85.16%] [G loss: 2.564865]\n",
      "epoch:16 step:13221 [D loss: 0.919380, acc: 31.25%] [G loss: 2.505480]\n",
      "epoch:16 step:13222 [D loss: 0.403349, acc: 92.97%] [G loss: 2.529283]\n",
      "epoch:16 step:13223 [D loss: 0.444843, acc: 90.62%] [G loss: 2.512693]\n",
      "epoch:16 step:13224 [D loss: 0.339542, acc: 89.06%] [G loss: 2.814535]\n",
      "epoch:16 step:13225 [D loss: 0.523301, acc: 75.78%] [G loss: 2.445550]\n",
      "epoch:16 step:13226 [D loss: 0.430396, acc: 88.28%] [G loss: 2.200590]\n",
      "epoch:16 step:13227 [D loss: 0.395668, acc: 91.41%] [G loss: 3.710085]\n",
      "epoch:16 step:13228 [D loss: 0.557284, acc: 73.44%] [G loss: 2.574834]\n",
      "epoch:16 step:13229 [D loss: 0.245045, acc: 92.97%] [G loss: 3.192265]\n",
      "epoch:16 step:13230 [D loss: 0.365513, acc: 94.53%] [G loss: 3.067730]\n",
      "epoch:16 step:13231 [D loss: 0.256377, acc: 96.09%] [G loss: 2.556576]\n",
      "epoch:16 step:13232 [D loss: 0.657945, acc: 59.38%] [G loss: 2.175548]\n",
      "epoch:16 step:13233 [D loss: 0.418252, acc: 89.84%] [G loss: 2.433806]\n",
      "epoch:16 step:13234 [D loss: 0.439404, acc: 83.59%] [G loss: 2.837329]\n",
      "epoch:16 step:13235 [D loss: 0.262512, acc: 96.09%] [G loss: 2.910538]\n",
      "epoch:16 step:13236 [D loss: 0.930539, acc: 32.03%] [G loss: 2.597474]\n",
      "epoch:16 step:13237 [D loss: 0.313352, acc: 86.72%] [G loss: 3.063837]\n",
      "epoch:16 step:13238 [D loss: 0.380216, acc: 73.44%] [G loss: 3.371063]\n",
      "epoch:16 step:13239 [D loss: 0.457770, acc: 81.25%] [G loss: 2.945238]\n",
      "epoch:16 step:13240 [D loss: 0.505322, acc: 78.91%] [G loss: 3.896395]\n",
      "epoch:16 step:13241 [D loss: 0.363880, acc: 87.50%] [G loss: 2.167524]\n",
      "epoch:16 step:13242 [D loss: 0.454250, acc: 85.94%] [G loss: 2.384172]\n",
      "epoch:16 step:13243 [D loss: 1.200919, acc: 17.97%] [G loss: 3.297089]\n",
      "epoch:16 step:13244 [D loss: 0.305527, acc: 92.97%] [G loss: 3.349450]\n",
      "epoch:16 step:13245 [D loss: 0.828614, acc: 39.06%] [G loss: 2.483698]\n",
      "epoch:16 step:13246 [D loss: 0.626763, acc: 64.84%] [G loss: 2.921311]\n",
      "epoch:16 step:13247 [D loss: 0.592931, acc: 60.94%] [G loss: 2.720800]\n",
      "epoch:16 step:13248 [D loss: 0.476347, acc: 78.12%] [G loss: 2.210826]\n",
      "epoch:16 step:13249 [D loss: 0.724292, acc: 58.59%] [G loss: 2.654676]\n",
      "epoch:16 step:13250 [D loss: 0.353807, acc: 89.06%] [G loss: 3.411730]\n",
      "epoch:16 step:13251 [D loss: 0.328263, acc: 93.75%] [G loss: 2.792503]\n",
      "epoch:16 step:13252 [D loss: 0.649243, acc: 60.16%] [G loss: 2.759185]\n",
      "epoch:16 step:13253 [D loss: 1.127237, acc: 15.62%] [G loss: 2.436527]\n",
      "epoch:16 step:13254 [D loss: 0.574001, acc: 66.41%] [G loss: 3.308937]\n",
      "epoch:16 step:13255 [D loss: 0.607910, acc: 70.31%] [G loss: 2.468113]\n",
      "epoch:16 step:13256 [D loss: 0.689045, acc: 56.25%] [G loss: 2.347507]\n",
      "epoch:16 step:13257 [D loss: 0.684792, acc: 55.47%] [G loss: 1.886053]\n",
      "epoch:16 step:13258 [D loss: 0.537719, acc: 73.44%] [G loss: 2.599671]\n",
      "epoch:16 step:13259 [D loss: 0.436274, acc: 87.50%] [G loss: 2.542148]\n",
      "epoch:16 step:13260 [D loss: 0.811509, acc: 49.22%] [G loss: 2.884683]\n",
      "epoch:16 step:13261 [D loss: 0.872345, acc: 39.84%] [G loss: 2.124924]\n",
      "epoch:16 step:13262 [D loss: 0.376528, acc: 89.06%] [G loss: 2.650775]\n",
      "epoch:16 step:13263 [D loss: 0.341712, acc: 92.19%] [G loss: 3.049466]\n",
      "epoch:16 step:13264 [D loss: 0.346851, acc: 93.75%] [G loss: 2.801197]\n",
      "epoch:16 step:13265 [D loss: 0.537130, acc: 65.62%] [G loss: 2.766850]\n",
      "epoch:16 step:13266 [D loss: 0.550317, acc: 70.31%] [G loss: 2.884576]\n",
      "epoch:16 step:13267 [D loss: 0.613313, acc: 67.97%] [G loss: 2.180168]\n",
      "epoch:16 step:13268 [D loss: 0.535255, acc: 78.91%] [G loss: 2.405613]\n",
      "epoch:16 step:13269 [D loss: 0.443527, acc: 79.69%] [G loss: 3.635016]\n",
      "epoch:16 step:13270 [D loss: 0.465559, acc: 81.25%] [G loss: 3.230182]\n",
      "epoch:16 step:13271 [D loss: 1.033665, acc: 28.12%] [G loss: 2.549408]\n",
      "epoch:16 step:13272 [D loss: 0.801885, acc: 46.88%] [G loss: 2.435766]\n",
      "epoch:16 step:13273 [D loss: 0.913551, acc: 54.69%] [G loss: 3.098873]\n",
      "epoch:16 step:13274 [D loss: 0.497990, acc: 77.34%] [G loss: 2.841766]\n",
      "epoch:16 step:13275 [D loss: 0.768137, acc: 57.03%] [G loss: 1.993615]\n",
      "epoch:16 step:13276 [D loss: 0.921588, acc: 49.22%] [G loss: 1.805249]\n",
      "epoch:16 step:13277 [D loss: 0.437959, acc: 82.03%] [G loss: 3.890083]\n",
      "epoch:17 step:13278 [D loss: 0.468164, acc: 75.00%] [G loss: 2.952562]\n",
      "epoch:17 step:13279 [D loss: 0.495784, acc: 78.91%] [G loss: 2.588684]\n",
      "epoch:17 step:13280 [D loss: 0.652330, acc: 64.06%] [G loss: 2.878533]\n",
      "epoch:17 step:13281 [D loss: 0.378089, acc: 91.41%] [G loss: 3.971579]\n",
      "epoch:17 step:13282 [D loss: 0.611762, acc: 66.41%] [G loss: 2.862819]\n",
      "epoch:17 step:13283 [D loss: 0.336797, acc: 89.84%] [G loss: 3.110364]\n",
      "epoch:17 step:13284 [D loss: 0.302917, acc: 90.62%] [G loss: 2.691079]\n",
      "epoch:17 step:13285 [D loss: 0.709570, acc: 58.59%] [G loss: 3.004874]\n",
      "epoch:17 step:13286 [D loss: 0.343755, acc: 93.75%] [G loss: 2.301920]\n",
      "epoch:17 step:13287 [D loss: 0.965603, acc: 32.03%] [G loss: 2.522960]\n",
      "epoch:17 step:13288 [D loss: 0.422245, acc: 81.25%] [G loss: 3.347485]\n",
      "epoch:17 step:13289 [D loss: 0.633100, acc: 64.06%] [G loss: 2.558917]\n",
      "epoch:17 step:13290 [D loss: 0.532721, acc: 75.00%] [G loss: 2.932721]\n",
      "epoch:17 step:13291 [D loss: 0.514448, acc: 78.91%] [G loss: 2.731719]\n",
      "epoch:17 step:13292 [D loss: 1.137777, acc: 28.12%] [G loss: 2.792651]\n",
      "epoch:17 step:13293 [D loss: 1.036874, acc: 21.88%] [G loss: 1.730906]\n",
      "epoch:17 step:13294 [D loss: 0.258672, acc: 99.22%] [G loss: 2.654943]\n",
      "epoch:17 step:13295 [D loss: 0.563897, acc: 71.09%] [G loss: 2.513600]\n",
      "epoch:17 step:13296 [D loss: 0.380883, acc: 92.19%] [G loss: 2.440469]\n",
      "epoch:17 step:13297 [D loss: 0.515397, acc: 69.53%] [G loss: 2.041107]\n",
      "epoch:17 step:13298 [D loss: 0.511678, acc: 69.53%] [G loss: 2.639310]\n",
      "epoch:17 step:13299 [D loss: 0.392617, acc: 86.72%] [G loss: 3.017118]\n",
      "epoch:17 step:13300 [D loss: 0.333018, acc: 94.53%] [G loss: 4.126287]\n",
      "epoch:17 step:13301 [D loss: 0.582765, acc: 71.09%] [G loss: 2.159421]\n",
      "epoch:17 step:13302 [D loss: 0.468244, acc: 83.59%] [G loss: 2.466067]\n",
      "epoch:17 step:13303 [D loss: 0.964449, acc: 26.56%] [G loss: 2.030104]\n",
      "epoch:17 step:13304 [D loss: 0.373859, acc: 88.28%] [G loss: 2.348893]\n",
      "epoch:17 step:13305 [D loss: 0.585597, acc: 69.53%] [G loss: 2.561758]\n",
      "epoch:17 step:13306 [D loss: 0.544373, acc: 73.44%] [G loss: 2.601493]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13307 [D loss: 0.547997, acc: 71.88%] [G loss: 2.861729]\n",
      "epoch:17 step:13308 [D loss: 0.670595, acc: 59.38%] [G loss: 2.189042]\n",
      "epoch:17 step:13309 [D loss: 0.595258, acc: 67.19%] [G loss: 2.124341]\n",
      "epoch:17 step:13310 [D loss: 0.662457, acc: 53.91%] [G loss: 2.647758]\n",
      "epoch:17 step:13311 [D loss: 0.452915, acc: 84.38%] [G loss: 2.901518]\n",
      "epoch:17 step:13312 [D loss: 0.291991, acc: 85.94%] [G loss: 4.582161]\n",
      "epoch:17 step:13313 [D loss: 0.313101, acc: 94.53%] [G loss: 2.825261]\n",
      "epoch:17 step:13314 [D loss: 0.448485, acc: 82.81%] [G loss: 2.621862]\n",
      "epoch:17 step:13315 [D loss: 0.469314, acc: 80.47%] [G loss: 2.479726]\n",
      "epoch:17 step:13316 [D loss: 0.632587, acc: 66.41%] [G loss: 2.248573]\n",
      "epoch:17 step:13317 [D loss: 0.455753, acc: 75.78%] [G loss: 2.291583]\n",
      "epoch:17 step:13318 [D loss: 0.307546, acc: 96.09%] [G loss: 2.690321]\n",
      "epoch:17 step:13319 [D loss: 0.441931, acc: 85.16%] [G loss: 2.718649]\n",
      "epoch:17 step:13320 [D loss: 0.282837, acc: 96.09%] [G loss: 2.739439]\n",
      "epoch:17 step:13321 [D loss: 0.546599, acc: 72.66%] [G loss: 2.501610]\n",
      "epoch:17 step:13322 [D loss: 0.522178, acc: 71.88%] [G loss: 3.517071]\n",
      "epoch:17 step:13323 [D loss: 0.707002, acc: 54.69%] [G loss: 2.906299]\n",
      "epoch:17 step:13324 [D loss: 0.478528, acc: 82.03%] [G loss: 2.215938]\n",
      "epoch:17 step:13325 [D loss: 0.683405, acc: 62.50%] [G loss: 2.780802]\n",
      "epoch:17 step:13326 [D loss: 0.957655, acc: 34.38%] [G loss: 2.544335]\n",
      "epoch:17 step:13327 [D loss: 0.643658, acc: 59.38%] [G loss: 2.648603]\n",
      "epoch:17 step:13328 [D loss: 0.264899, acc: 97.66%] [G loss: 2.818750]\n",
      "epoch:17 step:13329 [D loss: 0.464717, acc: 70.31%] [G loss: 3.398844]\n",
      "epoch:17 step:13330 [D loss: 0.552203, acc: 74.22%] [G loss: 3.447315]\n",
      "epoch:17 step:13331 [D loss: 0.731786, acc: 50.00%] [G loss: 2.265357]\n",
      "epoch:17 step:13332 [D loss: 0.418384, acc: 87.50%] [G loss: 2.688660]\n",
      "epoch:17 step:13333 [D loss: 0.937387, acc: 36.72%] [G loss: 2.378937]\n",
      "epoch:17 step:13334 [D loss: 0.333763, acc: 95.31%] [G loss: 2.824117]\n",
      "epoch:17 step:13335 [D loss: 0.562092, acc: 70.31%] [G loss: 2.521812]\n",
      "epoch:17 step:13336 [D loss: 0.655263, acc: 61.72%] [G loss: 2.591878]\n",
      "epoch:17 step:13337 [D loss: 0.404854, acc: 87.50%] [G loss: 2.669791]\n",
      "epoch:17 step:13338 [D loss: 0.419240, acc: 83.59%] [G loss: 2.564312]\n",
      "epoch:17 step:13339 [D loss: 0.489233, acc: 78.91%] [G loss: 2.921116]\n",
      "epoch:17 step:13340 [D loss: 0.356786, acc: 86.72%] [G loss: 2.819675]\n",
      "epoch:17 step:13341 [D loss: 0.397557, acc: 89.84%] [G loss: 3.484726]\n",
      "epoch:17 step:13342 [D loss: 1.060683, acc: 22.66%] [G loss: 2.072433]\n",
      "epoch:17 step:13343 [D loss: 0.905383, acc: 28.91%] [G loss: 1.802453]\n",
      "epoch:17 step:13344 [D loss: 0.540192, acc: 69.53%] [G loss: 2.259708]\n",
      "epoch:17 step:13345 [D loss: 0.701219, acc: 57.03%] [G loss: 2.432545]\n",
      "epoch:17 step:13346 [D loss: 0.633192, acc: 61.72%] [G loss: 3.540908]\n",
      "epoch:17 step:13347 [D loss: 0.572866, acc: 67.97%] [G loss: 3.229372]\n",
      "epoch:17 step:13348 [D loss: 1.261973, acc: 10.94%] [G loss: 2.426884]\n",
      "epoch:17 step:13349 [D loss: 1.445761, acc: 10.94%] [G loss: 1.901807]\n",
      "epoch:17 step:13350 [D loss: 0.377455, acc: 91.41%] [G loss: 3.104751]\n",
      "epoch:17 step:13351 [D loss: 0.639492, acc: 59.38%] [G loss: 2.836348]\n",
      "epoch:17 step:13352 [D loss: 0.396593, acc: 85.94%] [G loss: 2.995440]\n",
      "epoch:17 step:13353 [D loss: 0.588683, acc: 71.09%] [G loss: 2.728791]\n",
      "epoch:17 step:13354 [D loss: 0.831389, acc: 48.44%] [G loss: 2.281199]\n",
      "epoch:17 step:13355 [D loss: 0.707236, acc: 54.69%] [G loss: 2.609548]\n",
      "epoch:17 step:13356 [D loss: 0.462801, acc: 82.03%] [G loss: 3.191892]\n",
      "epoch:17 step:13357 [D loss: 0.526609, acc: 75.78%] [G loss: 4.212011]\n",
      "epoch:17 step:13358 [D loss: 0.422974, acc: 85.94%] [G loss: 3.026370]\n",
      "epoch:17 step:13359 [D loss: 0.720900, acc: 59.38%] [G loss: 2.858134]\n",
      "epoch:17 step:13360 [D loss: 0.474950, acc: 83.59%] [G loss: 3.459715]\n",
      "epoch:17 step:13361 [D loss: 0.945576, acc: 30.47%] [G loss: 2.416130]\n",
      "epoch:17 step:13362 [D loss: 0.817072, acc: 41.41%] [G loss: 2.259231]\n",
      "epoch:17 step:13363 [D loss: 0.371671, acc: 89.06%] [G loss: 2.672091]\n",
      "epoch:17 step:13364 [D loss: 0.512765, acc: 80.47%] [G loss: 2.621083]\n",
      "epoch:17 step:13365 [D loss: 0.785974, acc: 43.75%] [G loss: 3.038347]\n",
      "epoch:17 step:13366 [D loss: 0.298078, acc: 96.09%] [G loss: 3.095008]\n",
      "epoch:17 step:13367 [D loss: 0.509271, acc: 78.91%] [G loss: 1.951561]\n",
      "epoch:17 step:13368 [D loss: 0.508725, acc: 80.47%] [G loss: 2.576892]\n",
      "epoch:17 step:13369 [D loss: 0.865684, acc: 35.16%] [G loss: 2.780126]\n",
      "epoch:17 step:13370 [D loss: 0.474513, acc: 71.88%] [G loss: 2.686404]\n",
      "epoch:17 step:13371 [D loss: 0.521757, acc: 75.00%] [G loss: 2.614675]\n",
      "epoch:17 step:13372 [D loss: 0.805783, acc: 48.44%] [G loss: 2.588441]\n",
      "epoch:17 step:13373 [D loss: 0.730204, acc: 45.31%] [G loss: 2.611347]\n",
      "epoch:17 step:13374 [D loss: 0.831258, acc: 41.41%] [G loss: 2.207035]\n",
      "epoch:17 step:13375 [D loss: 0.329426, acc: 88.28%] [G loss: 4.066493]\n",
      "epoch:17 step:13376 [D loss: 0.750861, acc: 51.56%] [G loss: 2.223490]\n",
      "epoch:17 step:13377 [D loss: 0.542265, acc: 75.00%] [G loss: 2.205540]\n",
      "epoch:17 step:13378 [D loss: 0.646249, acc: 60.94%] [G loss: 1.944562]\n",
      "epoch:17 step:13379 [D loss: 0.537881, acc: 76.56%] [G loss: 2.722004]\n",
      "epoch:17 step:13380 [D loss: 0.590120, acc: 64.84%] [G loss: 2.625279]\n",
      "epoch:17 step:13381 [D loss: 0.520802, acc: 77.34%] [G loss: 3.044658]\n",
      "epoch:17 step:13382 [D loss: 0.878701, acc: 33.59%] [G loss: 2.201671]\n",
      "epoch:17 step:13383 [D loss: 0.598524, acc: 71.09%] [G loss: 2.609733]\n",
      "epoch:17 step:13384 [D loss: 0.766190, acc: 50.00%] [G loss: 2.428660]\n",
      "epoch:17 step:13385 [D loss: 0.739014, acc: 52.34%] [G loss: 2.390519]\n",
      "epoch:17 step:13386 [D loss: 0.418489, acc: 88.28%] [G loss: 2.217050]\n",
      "epoch:17 step:13387 [D loss: 0.405138, acc: 85.94%] [G loss: 2.528332]\n",
      "epoch:17 step:13388 [D loss: 0.607919, acc: 66.41%] [G loss: 2.946738]\n",
      "epoch:17 step:13389 [D loss: 0.862581, acc: 40.62%] [G loss: 3.035563]\n",
      "epoch:17 step:13390 [D loss: 0.810717, acc: 46.88%] [G loss: 2.554029]\n",
      "epoch:17 step:13391 [D loss: 0.462282, acc: 82.81%] [G loss: 2.789880]\n",
      "epoch:17 step:13392 [D loss: 0.655859, acc: 59.38%] [G loss: 2.518585]\n",
      "epoch:17 step:13393 [D loss: 0.437776, acc: 85.16%] [G loss: 2.492915]\n",
      "epoch:17 step:13394 [D loss: 0.526146, acc: 77.34%] [G loss: 2.527539]\n",
      "epoch:17 step:13395 [D loss: 0.688086, acc: 61.72%] [G loss: 2.531287]\n",
      "epoch:17 step:13396 [D loss: 0.431729, acc: 85.94%] [G loss: 2.864791]\n",
      "epoch:17 step:13397 [D loss: 0.444542, acc: 80.47%] [G loss: 2.682791]\n",
      "epoch:17 step:13398 [D loss: 0.413374, acc: 78.91%] [G loss: 2.376498]\n",
      "epoch:17 step:13399 [D loss: 0.424438, acc: 86.72%] [G loss: 2.974407]\n",
      "epoch:17 step:13400 [D loss: 0.215074, acc: 98.44%] [G loss: 2.548722]\n",
      "epoch:17 step:13401 [D loss: 0.468727, acc: 78.91%] [G loss: 2.484367]\n",
      "epoch:17 step:13402 [D loss: 0.322303, acc: 96.09%] [G loss: 3.204660]\n",
      "epoch:17 step:13403 [D loss: 0.879828, acc: 41.41%] [G loss: 2.301677]\n",
      "epoch:17 step:13404 [D loss: 0.486121, acc: 78.12%] [G loss: 2.647771]\n",
      "epoch:17 step:13405 [D loss: 0.409654, acc: 82.03%] [G loss: 3.633404]\n",
      "epoch:17 step:13406 [D loss: 0.555780, acc: 68.75%] [G loss: 3.420775]\n",
      "epoch:17 step:13407 [D loss: 0.827192, acc: 43.75%] [G loss: 2.156193]\n",
      "epoch:17 step:13408 [D loss: 0.336478, acc: 96.09%] [G loss: 2.512686]\n",
      "epoch:17 step:13409 [D loss: 0.822324, acc: 42.19%] [G loss: 2.625570]\n",
      "epoch:17 step:13410 [D loss: 0.413578, acc: 88.28%] [G loss: 3.024076]\n",
      "epoch:17 step:13411 [D loss: 0.338998, acc: 90.62%] [G loss: 3.230275]\n",
      "epoch:17 step:13412 [D loss: 0.818588, acc: 46.09%] [G loss: 2.668559]\n",
      "epoch:17 step:13413 [D loss: 0.640895, acc: 63.28%] [G loss: 2.752417]\n",
      "epoch:17 step:13414 [D loss: 0.288415, acc: 91.41%] [G loss: 3.816486]\n",
      "epoch:17 step:13415 [D loss: 0.557651, acc: 67.19%] [G loss: 2.298229]\n",
      "epoch:17 step:13416 [D loss: 0.509819, acc: 73.44%] [G loss: 2.614243]\n",
      "epoch:17 step:13417 [D loss: 0.504449, acc: 77.34%] [G loss: 2.450820]\n",
      "epoch:17 step:13418 [D loss: 0.841661, acc: 45.31%] [G loss: 2.864605]\n",
      "epoch:17 step:13419 [D loss: 0.811252, acc: 46.88%] [G loss: 2.088466]\n",
      "epoch:17 step:13420 [D loss: 0.623859, acc: 63.28%] [G loss: 2.736331]\n",
      "epoch:17 step:13421 [D loss: 0.677375, acc: 56.25%] [G loss: 2.748600]\n",
      "epoch:17 step:13422 [D loss: 0.565105, acc: 60.16%] [G loss: 2.920901]\n",
      "epoch:17 step:13423 [D loss: 0.409968, acc: 89.06%] [G loss: 2.349889]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13424 [D loss: 0.593612, acc: 66.41%] [G loss: 2.577632]\n",
      "epoch:17 step:13425 [D loss: 0.607544, acc: 67.97%] [G loss: 2.919245]\n",
      "epoch:17 step:13426 [D loss: 0.526812, acc: 78.12%] [G loss: 2.237279]\n",
      "epoch:17 step:13427 [D loss: 0.701205, acc: 55.47%] [G loss: 2.544114]\n",
      "epoch:17 step:13428 [D loss: 0.452495, acc: 81.25%] [G loss: 3.533520]\n",
      "epoch:17 step:13429 [D loss: 0.738502, acc: 57.81%] [G loss: 2.355987]\n",
      "epoch:17 step:13430 [D loss: 0.694019, acc: 58.59%] [G loss: 2.665260]\n",
      "epoch:17 step:13431 [D loss: 0.457246, acc: 82.81%] [G loss: 2.355704]\n",
      "epoch:17 step:13432 [D loss: 0.639633, acc: 60.16%] [G loss: 1.874928]\n",
      "epoch:17 step:13433 [D loss: 0.507510, acc: 76.56%] [G loss: 3.363808]\n",
      "epoch:17 step:13434 [D loss: 0.529505, acc: 76.56%] [G loss: 2.522382]\n",
      "epoch:17 step:13435 [D loss: 0.401079, acc: 78.91%] [G loss: 2.539436]\n",
      "epoch:17 step:13436 [D loss: 0.435694, acc: 90.62%] [G loss: 2.944281]\n",
      "epoch:17 step:13437 [D loss: 1.300022, acc: 27.34%] [G loss: 1.950340]\n",
      "epoch:17 step:13438 [D loss: 0.803870, acc: 39.84%] [G loss: 2.268080]\n",
      "epoch:17 step:13439 [D loss: 0.441705, acc: 87.50%] [G loss: 2.711238]\n",
      "epoch:17 step:13440 [D loss: 0.399932, acc: 83.59%] [G loss: 2.931348]\n",
      "epoch:17 step:13441 [D loss: 0.517391, acc: 75.00%] [G loss: 2.916195]\n",
      "epoch:17 step:13442 [D loss: 0.705008, acc: 51.56%] [G loss: 2.688137]\n",
      "epoch:17 step:13443 [D loss: 0.384388, acc: 94.53%] [G loss: 2.978102]\n",
      "epoch:17 step:13444 [D loss: 0.213011, acc: 96.09%] [G loss: 3.094182]\n",
      "epoch:17 step:13445 [D loss: 0.508901, acc: 75.78%] [G loss: 2.601683]\n",
      "epoch:17 step:13446 [D loss: 0.929154, acc: 41.41%] [G loss: 1.907341]\n",
      "epoch:17 step:13447 [D loss: 0.256184, acc: 93.75%] [G loss: 3.735078]\n",
      "epoch:17 step:13448 [D loss: 0.911849, acc: 34.38%] [G loss: 2.100079]\n",
      "epoch:17 step:13449 [D loss: 0.734984, acc: 53.12%] [G loss: 2.531703]\n",
      "epoch:17 step:13450 [D loss: 0.635653, acc: 57.03%] [G loss: 3.153159]\n",
      "epoch:17 step:13451 [D loss: 0.442483, acc: 79.69%] [G loss: 2.245104]\n",
      "epoch:17 step:13452 [D loss: 0.381051, acc: 90.62%] [G loss: 2.369662]\n",
      "epoch:17 step:13453 [D loss: 0.914339, acc: 49.22%] [G loss: 2.089349]\n",
      "epoch:17 step:13454 [D loss: 0.303798, acc: 86.72%] [G loss: 2.748288]\n",
      "epoch:17 step:13455 [D loss: 1.024105, acc: 21.09%] [G loss: 2.271386]\n",
      "epoch:17 step:13456 [D loss: 0.565517, acc: 71.09%] [G loss: 3.374959]\n",
      "epoch:17 step:13457 [D loss: 0.665604, acc: 60.16%] [G loss: 2.067442]\n",
      "epoch:17 step:13458 [D loss: 0.205800, acc: 96.88%] [G loss: 4.205059]\n",
      "epoch:17 step:13459 [D loss: 0.741440, acc: 53.91%] [G loss: 1.849423]\n",
      "epoch:17 step:13460 [D loss: 0.454771, acc: 82.81%] [G loss: 3.280592]\n",
      "epoch:17 step:13461 [D loss: 0.499834, acc: 79.69%] [G loss: 1.970392]\n",
      "epoch:17 step:13462 [D loss: 0.542578, acc: 72.66%] [G loss: 2.559106]\n",
      "epoch:17 step:13463 [D loss: 0.293570, acc: 96.88%] [G loss: 2.567311]\n",
      "epoch:17 step:13464 [D loss: 0.560776, acc: 70.31%] [G loss: 2.437523]\n",
      "epoch:17 step:13465 [D loss: 0.484277, acc: 81.25%] [G loss: 3.337607]\n",
      "epoch:17 step:13466 [D loss: 0.243974, acc: 97.66%] [G loss: 3.329848]\n",
      "epoch:17 step:13467 [D loss: 0.521684, acc: 67.19%] [G loss: 4.031468]\n",
      "epoch:17 step:13468 [D loss: 0.847989, acc: 42.97%] [G loss: 2.773491]\n",
      "epoch:17 step:13469 [D loss: 0.517913, acc: 77.34%] [G loss: 2.720137]\n",
      "epoch:17 step:13470 [D loss: 0.900952, acc: 39.84%] [G loss: 2.620856]\n",
      "epoch:17 step:13471 [D loss: 0.510921, acc: 75.00%] [G loss: 2.895832]\n",
      "epoch:17 step:13472 [D loss: 0.484475, acc: 81.25%] [G loss: 3.485951]\n",
      "epoch:17 step:13473 [D loss: 0.653103, acc: 64.06%] [G loss: 2.297012]\n",
      "epoch:17 step:13474 [D loss: 0.407576, acc: 89.06%] [G loss: 3.297885]\n",
      "epoch:17 step:13475 [D loss: 0.381994, acc: 92.97%] [G loss: 2.812493]\n",
      "epoch:17 step:13476 [D loss: 0.639927, acc: 60.16%] [G loss: 3.263791]\n",
      "epoch:17 step:13477 [D loss: 0.403186, acc: 89.84%] [G loss: 2.700164]\n",
      "epoch:17 step:13478 [D loss: 0.412523, acc: 89.06%] [G loss: 3.260684]\n",
      "epoch:17 step:13479 [D loss: 1.187197, acc: 35.94%] [G loss: 1.929291]\n",
      "epoch:17 step:13480 [D loss: 0.423700, acc: 87.50%] [G loss: 2.373936]\n",
      "epoch:17 step:13481 [D loss: 0.595141, acc: 67.97%] [G loss: 2.291551]\n",
      "epoch:17 step:13482 [D loss: 0.713351, acc: 57.03%] [G loss: 2.130650]\n",
      "epoch:17 step:13483 [D loss: 0.771034, acc: 53.12%] [G loss: 2.192934]\n",
      "epoch:17 step:13484 [D loss: 0.785888, acc: 46.09%] [G loss: 2.388596]\n",
      "epoch:17 step:13485 [D loss: 0.636897, acc: 61.72%] [G loss: 2.572081]\n",
      "epoch:17 step:13486 [D loss: 0.686581, acc: 53.12%] [G loss: 2.460239]\n",
      "epoch:17 step:13487 [D loss: 0.227458, acc: 96.09%] [G loss: 3.138020]\n",
      "epoch:17 step:13488 [D loss: 0.442986, acc: 81.25%] [G loss: 3.806041]\n",
      "epoch:17 step:13489 [D loss: 0.231866, acc: 94.53%] [G loss: 3.144159]\n",
      "epoch:17 step:13490 [D loss: 0.715554, acc: 52.34%] [G loss: 2.693559]\n",
      "epoch:17 step:13491 [D loss: 0.408136, acc: 89.84%] [G loss: 3.405746]\n",
      "epoch:17 step:13492 [D loss: 0.332625, acc: 93.75%] [G loss: 2.764245]\n",
      "epoch:17 step:13493 [D loss: 0.322946, acc: 96.09%] [G loss: 3.636102]\n",
      "epoch:17 step:13494 [D loss: 0.471892, acc: 80.47%] [G loss: 3.135951]\n",
      "epoch:17 step:13495 [D loss: 0.641224, acc: 58.59%] [G loss: 2.638618]\n",
      "epoch:17 step:13496 [D loss: 0.398687, acc: 84.38%] [G loss: 2.910685]\n",
      "epoch:17 step:13497 [D loss: 0.704033, acc: 55.47%] [G loss: 3.945580]\n",
      "epoch:17 step:13498 [D loss: 0.635961, acc: 61.72%] [G loss: 2.632110]\n",
      "epoch:17 step:13499 [D loss: 0.509211, acc: 78.12%] [G loss: 3.020428]\n",
      "epoch:17 step:13500 [D loss: 0.434846, acc: 87.50%] [G loss: 2.645030]\n",
      "epoch:17 step:13501 [D loss: 0.588592, acc: 75.00%] [G loss: 2.414877]\n",
      "epoch:17 step:13502 [D loss: 0.407763, acc: 83.59%] [G loss: 2.937626]\n",
      "epoch:17 step:13503 [D loss: 0.571858, acc: 69.53%] [G loss: 2.470689]\n",
      "epoch:17 step:13504 [D loss: 0.547179, acc: 78.91%] [G loss: 2.669111]\n",
      "epoch:17 step:13505 [D loss: 0.479124, acc: 82.81%] [G loss: 2.800865]\n",
      "epoch:17 step:13506 [D loss: 0.800813, acc: 42.19%] [G loss: 2.445748]\n",
      "epoch:17 step:13507 [D loss: 0.592608, acc: 71.88%] [G loss: 2.304343]\n",
      "epoch:17 step:13508 [D loss: 0.552372, acc: 75.00%] [G loss: 2.587214]\n",
      "epoch:17 step:13509 [D loss: 0.666582, acc: 64.06%] [G loss: 2.984966]\n",
      "epoch:17 step:13510 [D loss: 0.541382, acc: 77.34%] [G loss: 2.475628]\n",
      "epoch:17 step:13511 [D loss: 0.602696, acc: 60.94%] [G loss: 2.478918]\n",
      "epoch:17 step:13512 [D loss: 0.416151, acc: 86.72%] [G loss: 2.940515]\n",
      "epoch:17 step:13513 [D loss: 0.528267, acc: 72.66%] [G loss: 2.552409]\n",
      "epoch:17 step:13514 [D loss: 0.758591, acc: 50.00%] [G loss: 1.892984]\n",
      "epoch:17 step:13515 [D loss: 0.538473, acc: 69.53%] [G loss: 3.214131]\n",
      "epoch:17 step:13516 [D loss: 0.411123, acc: 86.72%] [G loss: 2.545411]\n",
      "epoch:17 step:13517 [D loss: 0.591851, acc: 65.62%] [G loss: 3.385541]\n",
      "epoch:17 step:13518 [D loss: 0.550786, acc: 74.22%] [G loss: 3.145014]\n",
      "epoch:17 step:13519 [D loss: 0.352808, acc: 91.41%] [G loss: 2.841105]\n",
      "epoch:17 step:13520 [D loss: 0.209289, acc: 98.44%] [G loss: 3.821127]\n",
      "epoch:17 step:13521 [D loss: 0.414374, acc: 85.16%] [G loss: 2.858213]\n",
      "epoch:17 step:13522 [D loss: 1.068713, acc: 17.19%] [G loss: 1.814333]\n",
      "epoch:17 step:13523 [D loss: 0.826865, acc: 46.88%] [G loss: 2.373279]\n",
      "epoch:17 step:13524 [D loss: 0.391467, acc: 90.62%] [G loss: 3.095753]\n",
      "epoch:17 step:13525 [D loss: 0.668668, acc: 53.91%] [G loss: 3.027484]\n",
      "epoch:17 step:13526 [D loss: 0.610680, acc: 64.06%] [G loss: 2.499207]\n",
      "epoch:17 step:13527 [D loss: 0.505387, acc: 82.81%] [G loss: 2.882379]\n",
      "epoch:17 step:13528 [D loss: 0.600426, acc: 70.31%] [G loss: 2.584810]\n",
      "epoch:17 step:13529 [D loss: 0.338485, acc: 93.75%] [G loss: 2.613041]\n",
      "epoch:17 step:13530 [D loss: 0.470291, acc: 69.53%] [G loss: 2.903433]\n",
      "epoch:17 step:13531 [D loss: 0.370897, acc: 91.41%] [G loss: 3.222225]\n",
      "epoch:17 step:13532 [D loss: 0.590638, acc: 64.84%] [G loss: 2.646745]\n",
      "epoch:17 step:13533 [D loss: 0.223341, acc: 98.44%] [G loss: 2.928323]\n",
      "epoch:17 step:13534 [D loss: 0.767368, acc: 49.22%] [G loss: 2.582732]\n",
      "epoch:17 step:13535 [D loss: 0.700705, acc: 54.69%] [G loss: 2.322110]\n",
      "epoch:17 step:13536 [D loss: 0.723719, acc: 53.91%] [G loss: 2.361225]\n",
      "epoch:17 step:13537 [D loss: 0.388830, acc: 86.72%] [G loss: 2.466231]\n",
      "epoch:17 step:13538 [D loss: 0.398508, acc: 89.06%] [G loss: 2.852918]\n",
      "epoch:17 step:13539 [D loss: 0.227282, acc: 95.31%] [G loss: 4.005309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13540 [D loss: 0.617545, acc: 64.06%] [G loss: 2.110882]\n",
      "epoch:17 step:13541 [D loss: 0.857734, acc: 41.41%] [G loss: 2.887268]\n",
      "epoch:17 step:13542 [D loss: 0.562306, acc: 71.88%] [G loss: 2.434410]\n",
      "epoch:17 step:13543 [D loss: 0.626666, acc: 67.19%] [G loss: 2.707637]\n",
      "epoch:17 step:13544 [D loss: 1.624342, acc: 16.41%] [G loss: 2.050341]\n",
      "epoch:17 step:13545 [D loss: 0.366548, acc: 92.97%] [G loss: 2.697089]\n",
      "epoch:17 step:13546 [D loss: 0.930318, acc: 31.25%] [G loss: 2.241616]\n",
      "epoch:17 step:13547 [D loss: 0.396704, acc: 78.12%] [G loss: 3.552722]\n",
      "epoch:17 step:13548 [D loss: 0.619073, acc: 64.06%] [G loss: 2.603831]\n",
      "epoch:17 step:13549 [D loss: 0.535408, acc: 71.09%] [G loss: 3.200179]\n",
      "epoch:17 step:13550 [D loss: 0.448022, acc: 85.16%] [G loss: 3.437435]\n",
      "epoch:17 step:13551 [D loss: 0.715019, acc: 53.91%] [G loss: 2.126020]\n",
      "epoch:17 step:13552 [D loss: 0.786451, acc: 46.09%] [G loss: 3.130944]\n",
      "epoch:17 step:13553 [D loss: 0.533238, acc: 74.22%] [G loss: 3.058274]\n",
      "epoch:17 step:13554 [D loss: 0.704815, acc: 57.81%] [G loss: 1.976688]\n",
      "epoch:17 step:13555 [D loss: 0.312426, acc: 92.97%] [G loss: 3.123879]\n",
      "epoch:17 step:13556 [D loss: 0.468753, acc: 82.81%] [G loss: 1.864662]\n",
      "epoch:17 step:13557 [D loss: 0.387321, acc: 87.50%] [G loss: 2.655676]\n",
      "epoch:17 step:13558 [D loss: 0.470604, acc: 85.16%] [G loss: 2.823547]\n",
      "epoch:17 step:13559 [D loss: 0.565855, acc: 64.06%] [G loss: 2.955786]\n",
      "epoch:17 step:13560 [D loss: 0.465541, acc: 78.12%] [G loss: 2.172466]\n",
      "epoch:17 step:13561 [D loss: 0.457222, acc: 80.47%] [G loss: 2.728654]\n",
      "epoch:17 step:13562 [D loss: 0.437608, acc: 81.25%] [G loss: 2.512782]\n",
      "epoch:17 step:13563 [D loss: 0.593179, acc: 69.53%] [G loss: 2.763985]\n",
      "epoch:17 step:13564 [D loss: 0.429264, acc: 85.94%] [G loss: 3.556797]\n",
      "epoch:17 step:13565 [D loss: 0.645305, acc: 64.84%] [G loss: 2.347267]\n",
      "epoch:17 step:13566 [D loss: 0.528793, acc: 78.12%] [G loss: 2.609938]\n",
      "epoch:17 step:13567 [D loss: 0.454692, acc: 78.91%] [G loss: 2.574094]\n",
      "epoch:17 step:13568 [D loss: 0.558968, acc: 64.84%] [G loss: 2.956291]\n",
      "epoch:17 step:13569 [D loss: 0.689511, acc: 57.03%] [G loss: 2.027819]\n",
      "epoch:17 step:13570 [D loss: 0.584446, acc: 67.97%] [G loss: 2.365558]\n",
      "epoch:17 step:13571 [D loss: 0.797382, acc: 48.44%] [G loss: 2.160625]\n",
      "epoch:17 step:13572 [D loss: 0.567334, acc: 69.53%] [G loss: 2.735139]\n",
      "epoch:17 step:13573 [D loss: 0.552695, acc: 65.62%] [G loss: 2.089185]\n",
      "epoch:17 step:13574 [D loss: 0.874762, acc: 44.53%] [G loss: 2.582775]\n",
      "epoch:17 step:13575 [D loss: 0.526427, acc: 81.25%] [G loss: 2.683944]\n",
      "epoch:17 step:13576 [D loss: 0.600755, acc: 64.06%] [G loss: 2.720401]\n",
      "epoch:17 step:13577 [D loss: 0.882360, acc: 37.50%] [G loss: 1.920429]\n",
      "epoch:17 step:13578 [D loss: 0.840773, acc: 42.19%] [G loss: 1.849218]\n",
      "epoch:17 step:13579 [D loss: 0.496487, acc: 75.00%] [G loss: 2.667370]\n",
      "epoch:17 step:13580 [D loss: 0.622753, acc: 64.84%] [G loss: 2.854168]\n",
      "epoch:17 step:13581 [D loss: 0.562133, acc: 67.97%] [G loss: 2.298391]\n",
      "epoch:17 step:13582 [D loss: 0.776786, acc: 50.78%] [G loss: 1.944501]\n",
      "epoch:17 step:13583 [D loss: 0.521213, acc: 72.66%] [G loss: 3.376379]\n",
      "epoch:17 step:13584 [D loss: 0.634713, acc: 63.28%] [G loss: 2.455222]\n",
      "epoch:17 step:13585 [D loss: 0.463820, acc: 85.16%] [G loss: 2.397280]\n",
      "epoch:17 step:13586 [D loss: 0.334972, acc: 96.09%] [G loss: 3.886830]\n",
      "epoch:17 step:13587 [D loss: 0.674600, acc: 59.38%] [G loss: 2.712940]\n",
      "epoch:17 step:13588 [D loss: 0.624629, acc: 65.62%] [G loss: 2.317209]\n",
      "epoch:17 step:13589 [D loss: 1.340865, acc: 3.91%] [G loss: 2.088181]\n",
      "epoch:17 step:13590 [D loss: 0.801909, acc: 45.31%] [G loss: 2.606782]\n",
      "epoch:17 step:13591 [D loss: 0.542423, acc: 68.75%] [G loss: 2.808794]\n",
      "epoch:17 step:13592 [D loss: 0.922483, acc: 41.41%] [G loss: 2.644502]\n",
      "epoch:17 step:13593 [D loss: 0.662837, acc: 60.16%] [G loss: 2.357920]\n",
      "epoch:17 step:13594 [D loss: 0.624949, acc: 61.72%] [G loss: 2.643963]\n",
      "epoch:17 step:13595 [D loss: 0.728026, acc: 45.31%] [G loss: 2.526571]\n",
      "epoch:17 step:13596 [D loss: 0.715079, acc: 57.03%] [G loss: 2.278045]\n",
      "epoch:17 step:13597 [D loss: 0.557499, acc: 71.09%] [G loss: 2.849879]\n",
      "epoch:17 step:13598 [D loss: 0.853188, acc: 37.50%] [G loss: 2.940288]\n",
      "epoch:17 step:13599 [D loss: 0.540447, acc: 76.56%] [G loss: 2.045649]\n",
      "epoch:17 step:13600 [D loss: 0.588841, acc: 72.66%] [G loss: 2.324579]\n",
      "epoch:17 step:13601 [D loss: 0.667490, acc: 57.03%] [G loss: 2.328560]\n",
      "epoch:17 step:13602 [D loss: 0.555837, acc: 75.00%] [G loss: 3.014835]\n",
      "epoch:17 step:13603 [D loss: 0.527237, acc: 77.34%] [G loss: 2.504530]\n",
      "epoch:17 step:13604 [D loss: 0.662492, acc: 60.94%] [G loss: 2.850988]\n",
      "epoch:17 step:13605 [D loss: 0.786674, acc: 50.78%] [G loss: 2.387154]\n",
      "epoch:17 step:13606 [D loss: 0.594907, acc: 63.28%] [G loss: 1.666492]\n",
      "epoch:17 step:13607 [D loss: 0.363326, acc: 87.50%] [G loss: 2.340369]\n",
      "epoch:17 step:13608 [D loss: 0.616260, acc: 60.94%] [G loss: 2.794919]\n",
      "epoch:17 step:13609 [D loss: 0.463001, acc: 83.59%] [G loss: 2.524633]\n",
      "epoch:17 step:13610 [D loss: 0.369843, acc: 92.19%] [G loss: 2.769604]\n",
      "epoch:17 step:13611 [D loss: 0.414700, acc: 90.62%] [G loss: 3.302059]\n",
      "epoch:17 step:13612 [D loss: 0.386616, acc: 85.16%] [G loss: 3.092681]\n",
      "epoch:17 step:13613 [D loss: 0.845653, acc: 45.31%] [G loss: 3.023212]\n",
      "epoch:17 step:13614 [D loss: 0.713992, acc: 54.69%] [G loss: 2.288503]\n",
      "epoch:17 step:13615 [D loss: 0.339174, acc: 93.75%] [G loss: 2.556669]\n",
      "epoch:17 step:13616 [D loss: 0.631522, acc: 58.59%] [G loss: 2.407293]\n",
      "epoch:17 step:13617 [D loss: 0.530796, acc: 76.56%] [G loss: 2.913947]\n",
      "epoch:17 step:13618 [D loss: 0.354723, acc: 95.31%] [G loss: 3.416138]\n",
      "epoch:17 step:13619 [D loss: 0.611060, acc: 65.62%] [G loss: 2.637165]\n",
      "epoch:17 step:13620 [D loss: 0.403835, acc: 85.16%] [G loss: 3.421043]\n",
      "epoch:17 step:13621 [D loss: 0.602224, acc: 73.44%] [G loss: 2.962057]\n",
      "epoch:17 step:13622 [D loss: 0.609594, acc: 60.16%] [G loss: 2.277169]\n",
      "epoch:17 step:13623 [D loss: 0.373372, acc: 92.97%] [G loss: 3.512037]\n",
      "epoch:17 step:13624 [D loss: 0.425882, acc: 86.72%] [G loss: 2.677170]\n",
      "epoch:17 step:13625 [D loss: 0.427311, acc: 82.03%] [G loss: 3.216405]\n",
      "epoch:17 step:13626 [D loss: 0.511900, acc: 75.78%] [G loss: 2.982802]\n",
      "epoch:17 step:13627 [D loss: 0.756229, acc: 49.22%] [G loss: 2.329514]\n",
      "epoch:17 step:13628 [D loss: 0.826168, acc: 49.22%] [G loss: 2.218899]\n",
      "epoch:17 step:13629 [D loss: 0.854820, acc: 51.56%] [G loss: 2.474238]\n",
      "epoch:17 step:13630 [D loss: 0.377886, acc: 89.84%] [G loss: 2.759859]\n",
      "epoch:17 step:13631 [D loss: 0.796105, acc: 45.31%] [G loss: 1.963076]\n",
      "epoch:17 step:13632 [D loss: 0.710845, acc: 53.91%] [G loss: 2.496829]\n",
      "epoch:17 step:13633 [D loss: 0.761301, acc: 45.31%] [G loss: 2.277728]\n",
      "epoch:17 step:13634 [D loss: 0.456560, acc: 85.94%] [G loss: 2.882728]\n",
      "epoch:17 step:13635 [D loss: 0.665615, acc: 53.91%] [G loss: 3.645808]\n",
      "epoch:17 step:13636 [D loss: 0.698026, acc: 54.69%] [G loss: 2.786276]\n",
      "epoch:17 step:13637 [D loss: 0.335233, acc: 92.97%] [G loss: 3.353364]\n",
      "epoch:17 step:13638 [D loss: 0.526798, acc: 72.66%] [G loss: 2.804883]\n",
      "epoch:17 step:13639 [D loss: 0.740438, acc: 54.69%] [G loss: 1.824705]\n",
      "epoch:17 step:13640 [D loss: 0.262226, acc: 97.66%] [G loss: 3.668309]\n",
      "epoch:17 step:13641 [D loss: 0.372871, acc: 92.97%] [G loss: 2.780025]\n",
      "epoch:17 step:13642 [D loss: 0.511483, acc: 81.25%] [G loss: 2.188603]\n",
      "epoch:17 step:13643 [D loss: 0.618700, acc: 59.38%] [G loss: 2.006796]\n",
      "epoch:17 step:13644 [D loss: 0.614502, acc: 62.50%] [G loss: 2.838526]\n",
      "epoch:17 step:13645 [D loss: 0.318290, acc: 89.06%] [G loss: 2.720515]\n",
      "epoch:17 step:13646 [D loss: 0.372843, acc: 89.84%] [G loss: 2.139895]\n",
      "epoch:17 step:13647 [D loss: 0.705918, acc: 59.38%] [G loss: 3.020284]\n",
      "epoch:17 step:13648 [D loss: 0.353454, acc: 91.41%] [G loss: 1.970221]\n",
      "epoch:17 step:13649 [D loss: 0.486528, acc: 73.44%] [G loss: 2.142981]\n",
      "epoch:17 step:13650 [D loss: 0.571174, acc: 73.44%] [G loss: 2.807218]\n",
      "epoch:17 step:13651 [D loss: 0.382402, acc: 87.50%] [G loss: 3.115163]\n",
      "epoch:17 step:13652 [D loss: 0.689423, acc: 58.59%] [G loss: 2.715973]\n",
      "epoch:17 step:13653 [D loss: 0.667137, acc: 60.16%] [G loss: 2.870110]\n",
      "epoch:17 step:13654 [D loss: 0.631096, acc: 58.59%] [G loss: 2.828192]\n",
      "epoch:17 step:13655 [D loss: 0.549530, acc: 77.34%] [G loss: 2.324235]\n",
      "epoch:17 step:13656 [D loss: 0.728909, acc: 56.25%] [G loss: 2.472709]\n",
      "epoch:17 step:13657 [D loss: 0.606196, acc: 66.41%] [G loss: 2.918613]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13658 [D loss: 0.600157, acc: 67.19%] [G loss: 2.898602]\n",
      "epoch:17 step:13659 [D loss: 0.883736, acc: 39.06%] [G loss: 3.149456]\n",
      "epoch:17 step:13660 [D loss: 0.575461, acc: 71.88%] [G loss: 3.226514]\n",
      "epoch:17 step:13661 [D loss: 0.728674, acc: 57.03%] [G loss: 2.376769]\n",
      "epoch:17 step:13662 [D loss: 0.332697, acc: 95.31%] [G loss: 2.815566]\n",
      "epoch:17 step:13663 [D loss: 0.960923, acc: 38.28%] [G loss: 2.825130]\n",
      "epoch:17 step:13664 [D loss: 0.510909, acc: 71.88%] [G loss: 3.235376]\n",
      "epoch:17 step:13665 [D loss: 0.679194, acc: 59.38%] [G loss: 2.369733]\n",
      "epoch:17 step:13666 [D loss: 0.591078, acc: 64.84%] [G loss: 2.479553]\n",
      "epoch:17 step:13667 [D loss: 0.719320, acc: 53.91%] [G loss: 3.480487]\n",
      "epoch:17 step:13668 [D loss: 1.188447, acc: 32.81%] [G loss: 2.462446]\n",
      "epoch:17 step:13669 [D loss: 0.298577, acc: 94.53%] [G loss: 2.948135]\n",
      "epoch:17 step:13670 [D loss: 0.199789, acc: 100.00%] [G loss: 2.715428]\n",
      "epoch:17 step:13671 [D loss: 0.615554, acc: 63.28%] [G loss: 2.358557]\n",
      "epoch:17 step:13672 [D loss: 0.501724, acc: 78.12%] [G loss: 1.941975]\n",
      "epoch:17 step:13673 [D loss: 0.773737, acc: 50.00%] [G loss: 1.867726]\n",
      "epoch:17 step:13674 [D loss: 1.176814, acc: 21.09%] [G loss: 2.312054]\n",
      "epoch:17 step:13675 [D loss: 0.425341, acc: 88.28%] [G loss: 2.084398]\n",
      "epoch:17 step:13676 [D loss: 0.628690, acc: 65.62%] [G loss: 2.320101]\n",
      "epoch:17 step:13677 [D loss: 0.291316, acc: 96.09%] [G loss: 2.975496]\n",
      "epoch:17 step:13678 [D loss: 0.302465, acc: 91.41%] [G loss: 4.317508]\n",
      "epoch:17 step:13679 [D loss: 0.395898, acc: 86.72%] [G loss: 3.486870]\n",
      "epoch:17 step:13680 [D loss: 0.744056, acc: 53.12%] [G loss: 2.211069]\n",
      "epoch:17 step:13681 [D loss: 0.439229, acc: 83.59%] [G loss: 2.428141]\n",
      "epoch:17 step:13682 [D loss: 0.516033, acc: 73.44%] [G loss: 2.370394]\n",
      "epoch:17 step:13683 [D loss: 0.379008, acc: 89.84%] [G loss: 2.510299]\n",
      "epoch:17 step:13684 [D loss: 0.530648, acc: 78.12%] [G loss: 2.482489]\n",
      "epoch:17 step:13685 [D loss: 0.312551, acc: 96.09%] [G loss: 3.356202]\n",
      "epoch:17 step:13686 [D loss: 0.441118, acc: 85.94%] [G loss: 2.502308]\n",
      "epoch:17 step:13687 [D loss: 0.684009, acc: 53.91%] [G loss: 2.300447]\n",
      "epoch:17 step:13688 [D loss: 0.344522, acc: 92.97%] [G loss: 2.989746]\n",
      "epoch:17 step:13689 [D loss: 0.396622, acc: 89.84%] [G loss: 2.792177]\n",
      "epoch:17 step:13690 [D loss: 0.439530, acc: 85.94%] [G loss: 2.554737]\n",
      "epoch:17 step:13691 [D loss: 0.407251, acc: 85.16%] [G loss: 2.991906]\n",
      "epoch:17 step:13692 [D loss: 0.437678, acc: 82.81%] [G loss: 2.071860]\n",
      "epoch:17 step:13693 [D loss: 0.299113, acc: 95.31%] [G loss: 3.345026]\n",
      "epoch:17 step:13694 [D loss: 0.576936, acc: 72.66%] [G loss: 2.341753]\n",
      "epoch:17 step:13695 [D loss: 0.262852, acc: 92.97%] [G loss: 2.925489]\n",
      "epoch:17 step:13696 [D loss: 0.587173, acc: 71.09%] [G loss: 2.525658]\n",
      "epoch:17 step:13697 [D loss: 0.962764, acc: 22.66%] [G loss: 2.801414]\n",
      "epoch:17 step:13698 [D loss: 0.794782, acc: 48.44%] [G loss: 3.314641]\n",
      "epoch:17 step:13699 [D loss: 0.364134, acc: 91.41%] [G loss: 2.977415]\n",
      "epoch:17 step:13700 [D loss: 0.690508, acc: 57.81%] [G loss: 1.915994]\n",
      "epoch:17 step:13701 [D loss: 0.459983, acc: 75.00%] [G loss: 2.770895]\n",
      "epoch:17 step:13702 [D loss: 0.721925, acc: 56.25%] [G loss: 3.022753]\n",
      "epoch:17 step:13703 [D loss: 0.499759, acc: 81.25%] [G loss: 2.297408]\n",
      "epoch:17 step:13704 [D loss: 0.291311, acc: 96.09%] [G loss: 2.913298]\n",
      "epoch:17 step:13705 [D loss: 0.441839, acc: 89.06%] [G loss: 2.504391]\n",
      "epoch:17 step:13706 [D loss: 0.626868, acc: 62.50%] [G loss: 2.777051]\n",
      "epoch:17 step:13707 [D loss: 0.931947, acc: 50.78%] [G loss: 2.542902]\n",
      "epoch:17 step:13708 [D loss: 0.338928, acc: 89.06%] [G loss: 4.256887]\n",
      "epoch:17 step:13709 [D loss: 0.327340, acc: 88.28%] [G loss: 3.259607]\n",
      "epoch:17 step:13710 [D loss: 0.671248, acc: 57.03%] [G loss: 3.293460]\n",
      "epoch:17 step:13711 [D loss: 0.428781, acc: 85.94%] [G loss: 3.264737]\n",
      "epoch:17 step:13712 [D loss: 0.986707, acc: 38.28%] [G loss: 2.610571]\n",
      "epoch:17 step:13713 [D loss: 0.488034, acc: 81.25%] [G loss: 3.379631]\n",
      "epoch:17 step:13714 [D loss: 0.622504, acc: 64.84%] [G loss: 2.748547]\n",
      "epoch:17 step:13715 [D loss: 0.654091, acc: 59.38%] [G loss: 2.608061]\n",
      "epoch:17 step:13716 [D loss: 0.343196, acc: 85.94%] [G loss: 2.807332]\n",
      "epoch:17 step:13717 [D loss: 0.808454, acc: 42.97%] [G loss: 2.957897]\n",
      "epoch:17 step:13718 [D loss: 0.474898, acc: 82.81%] [G loss: 3.252264]\n",
      "epoch:17 step:13719 [D loss: 0.455966, acc: 83.59%] [G loss: 3.035799]\n",
      "epoch:17 step:13720 [D loss: 0.777523, acc: 42.97%] [G loss: 2.320117]\n",
      "epoch:17 step:13721 [D loss: 0.899744, acc: 35.16%] [G loss: 2.713014]\n",
      "epoch:17 step:13722 [D loss: 1.040251, acc: 17.19%] [G loss: 2.508861]\n",
      "epoch:17 step:13723 [D loss: 0.477583, acc: 79.69%] [G loss: 2.394475]\n",
      "epoch:17 step:13724 [D loss: 0.668484, acc: 58.59%] [G loss: 2.436586]\n",
      "epoch:17 step:13725 [D loss: 0.234620, acc: 98.44%] [G loss: 3.532114]\n",
      "epoch:17 step:13726 [D loss: 0.434890, acc: 84.38%] [G loss: 3.043675]\n",
      "epoch:17 step:13727 [D loss: 0.652905, acc: 66.41%] [G loss: 4.121115]\n",
      "epoch:17 step:13728 [D loss: 0.293666, acc: 95.31%] [G loss: 2.470136]\n",
      "epoch:17 step:13729 [D loss: 0.367230, acc: 96.09%] [G loss: 2.427845]\n",
      "epoch:17 step:13730 [D loss: 1.104584, acc: 31.25%] [G loss: 2.520783]\n",
      "epoch:17 step:13731 [D loss: 0.580431, acc: 71.88%] [G loss: 2.026026]\n",
      "epoch:17 step:13732 [D loss: 0.659856, acc: 57.03%] [G loss: 2.467000]\n",
      "epoch:17 step:13733 [D loss: 0.836450, acc: 40.62%] [G loss: 2.900763]\n",
      "epoch:17 step:13734 [D loss: 0.962281, acc: 42.97%] [G loss: 4.106671]\n",
      "epoch:17 step:13735 [D loss: 0.573244, acc: 71.09%] [G loss: 2.724612]\n",
      "epoch:17 step:13736 [D loss: 0.571811, acc: 74.22%] [G loss: 2.692253]\n",
      "epoch:17 step:13737 [D loss: 0.529574, acc: 78.12%] [G loss: 3.133490]\n",
      "epoch:17 step:13738 [D loss: 0.492340, acc: 80.47%] [G loss: 2.467872]\n",
      "epoch:17 step:13739 [D loss: 0.454768, acc: 82.81%] [G loss: 2.840383]\n",
      "epoch:17 step:13740 [D loss: 0.452535, acc: 85.16%] [G loss: 2.856346]\n",
      "epoch:17 step:13741 [D loss: 0.463930, acc: 80.47%] [G loss: 3.098251]\n",
      "epoch:17 step:13742 [D loss: 0.651972, acc: 64.84%] [G loss: 2.111652]\n",
      "epoch:17 step:13743 [D loss: 0.455571, acc: 74.22%] [G loss: 2.784090]\n",
      "epoch:17 step:13744 [D loss: 0.504808, acc: 80.47%] [G loss: 2.227216]\n",
      "epoch:17 step:13745 [D loss: 0.670195, acc: 59.38%] [G loss: 2.131111]\n",
      "epoch:17 step:13746 [D loss: 0.350896, acc: 95.31%] [G loss: 2.694441]\n",
      "epoch:17 step:13747 [D loss: 0.427788, acc: 85.16%] [G loss: 3.230137]\n",
      "epoch:17 step:13748 [D loss: 0.559845, acc: 61.72%] [G loss: 3.480232]\n",
      "epoch:17 step:13749 [D loss: 0.522791, acc: 79.69%] [G loss: 2.284805]\n",
      "epoch:17 step:13750 [D loss: 0.607908, acc: 71.09%] [G loss: 2.541110]\n",
      "epoch:17 step:13751 [D loss: 0.482149, acc: 82.03%] [G loss: 3.321249]\n",
      "epoch:17 step:13752 [D loss: 0.597178, acc: 68.75%] [G loss: 3.474380]\n",
      "epoch:17 step:13753 [D loss: 0.424215, acc: 88.28%] [G loss: 3.490330]\n",
      "epoch:17 step:13754 [D loss: 0.443007, acc: 67.19%] [G loss: 3.063686]\n",
      "epoch:17 step:13755 [D loss: 0.437784, acc: 78.91%] [G loss: 3.741611]\n",
      "epoch:17 step:13756 [D loss: 0.872745, acc: 43.75%] [G loss: 2.572627]\n",
      "epoch:17 step:13757 [D loss: 0.796031, acc: 46.09%] [G loss: 2.380743]\n",
      "epoch:17 step:13758 [D loss: 0.561996, acc: 75.00%] [G loss: 2.862848]\n",
      "epoch:17 step:13759 [D loss: 0.424267, acc: 92.19%] [G loss: 3.175258]\n",
      "epoch:17 step:13760 [D loss: 0.737972, acc: 57.81%] [G loss: 2.950563]\n",
      "epoch:17 step:13761 [D loss: 0.446483, acc: 74.22%] [G loss: 2.421934]\n",
      "epoch:17 step:13762 [D loss: 0.470021, acc: 82.81%] [G loss: 2.888408]\n",
      "epoch:17 step:13763 [D loss: 0.632290, acc: 57.81%] [G loss: 2.844826]\n",
      "epoch:17 step:13764 [D loss: 0.609300, acc: 69.53%] [G loss: 2.249522]\n",
      "epoch:17 step:13765 [D loss: 0.265663, acc: 94.53%] [G loss: 3.267618]\n",
      "epoch:17 step:13766 [D loss: 0.408196, acc: 85.16%] [G loss: 2.432791]\n",
      "epoch:17 step:13767 [D loss: 0.214965, acc: 98.44%] [G loss: 3.175350]\n",
      "epoch:17 step:13768 [D loss: 0.676675, acc: 59.38%] [G loss: 2.656365]\n",
      "epoch:17 step:13769 [D loss: 0.700849, acc: 57.81%] [G loss: 2.390169]\n",
      "epoch:17 step:13770 [D loss: 0.662866, acc: 60.94%] [G loss: 2.919034]\n",
      "epoch:17 step:13771 [D loss: 0.545528, acc: 65.62%] [G loss: 2.020855]\n",
      "epoch:17 step:13772 [D loss: 0.387000, acc: 87.50%] [G loss: 2.873402]\n",
      "epoch:17 step:13773 [D loss: 0.633165, acc: 63.28%] [G loss: 3.069346]\n",
      "epoch:17 step:13774 [D loss: 0.368729, acc: 85.94%] [G loss: 3.388388]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13775 [D loss: 0.481872, acc: 81.25%] [G loss: 3.200469]\n",
      "epoch:17 step:13776 [D loss: 0.899711, acc: 51.56%] [G loss: 2.952473]\n",
      "epoch:17 step:13777 [D loss: 0.867520, acc: 39.84%] [G loss: 1.934763]\n",
      "epoch:17 step:13778 [D loss: 0.328957, acc: 92.19%] [G loss: 3.424034]\n",
      "epoch:17 step:13779 [D loss: 0.602115, acc: 69.53%] [G loss: 2.483169]\n",
      "epoch:17 step:13780 [D loss: 0.412932, acc: 84.38%] [G loss: 2.785173]\n",
      "epoch:17 step:13781 [D loss: 0.635478, acc: 60.94%] [G loss: 2.182531]\n",
      "epoch:17 step:13782 [D loss: 0.551531, acc: 69.53%] [G loss: 2.705490]\n",
      "epoch:17 step:13783 [D loss: 0.564880, acc: 65.62%] [G loss: 3.786178]\n",
      "epoch:17 step:13784 [D loss: 0.368787, acc: 85.94%] [G loss: 2.882521]\n",
      "epoch:17 step:13785 [D loss: 0.256742, acc: 98.44%] [G loss: 2.268664]\n",
      "epoch:17 step:13786 [D loss: 0.437595, acc: 89.84%] [G loss: 3.072322]\n",
      "epoch:17 step:13787 [D loss: 0.263010, acc: 96.09%] [G loss: 3.358409]\n",
      "epoch:17 step:13788 [D loss: 0.602705, acc: 58.59%] [G loss: 3.942410]\n",
      "epoch:17 step:13789 [D loss: 0.358491, acc: 83.59%] [G loss: 2.714750]\n",
      "epoch:17 step:13790 [D loss: 0.806701, acc: 42.97%] [G loss: 2.897243]\n",
      "epoch:17 step:13791 [D loss: 0.832150, acc: 49.22%] [G loss: 3.063514]\n",
      "epoch:17 step:13792 [D loss: 0.356347, acc: 86.72%] [G loss: 2.335814]\n",
      "epoch:17 step:13793 [D loss: 0.719619, acc: 53.91%] [G loss: 2.107395]\n",
      "epoch:17 step:13794 [D loss: 0.152899, acc: 100.00%] [G loss: 3.194930]\n",
      "epoch:17 step:13795 [D loss: 0.386865, acc: 91.41%] [G loss: 2.536733]\n",
      "epoch:17 step:13796 [D loss: 0.486314, acc: 71.09%] [G loss: 2.800066]\n",
      "epoch:17 step:13797 [D loss: 0.752771, acc: 56.25%] [G loss: 2.453883]\n",
      "epoch:17 step:13798 [D loss: 0.428570, acc: 86.72%] [G loss: 3.413619]\n",
      "epoch:17 step:13799 [D loss: 0.802703, acc: 50.00%] [G loss: 2.318141]\n",
      "epoch:17 step:13800 [D loss: 0.438215, acc: 81.25%] [G loss: 3.005984]\n",
      "epoch:17 step:13801 [D loss: 0.887747, acc: 40.62%] [G loss: 2.104354]\n",
      "epoch:17 step:13802 [D loss: 0.478175, acc: 74.22%] [G loss: 3.523256]\n",
      "epoch:17 step:13803 [D loss: 0.884404, acc: 50.00%] [G loss: 2.109462]\n",
      "epoch:17 step:13804 [D loss: 0.516550, acc: 71.09%] [G loss: 3.067693]\n",
      "epoch:17 step:13805 [D loss: 0.502189, acc: 74.22%] [G loss: 3.593899]\n",
      "epoch:17 step:13806 [D loss: 0.480342, acc: 78.91%] [G loss: 3.040578]\n",
      "epoch:17 step:13807 [D loss: 0.385627, acc: 89.84%] [G loss: 2.974627]\n",
      "epoch:17 step:13808 [D loss: 0.862352, acc: 46.09%] [G loss: 4.399941]\n",
      "epoch:17 step:13809 [D loss: 0.681895, acc: 61.72%] [G loss: 2.592372]\n",
      "epoch:17 step:13810 [D loss: 0.564344, acc: 75.00%] [G loss: 2.981503]\n",
      "epoch:17 step:13811 [D loss: 0.728870, acc: 49.22%] [G loss: 2.194022]\n",
      "epoch:17 step:13812 [D loss: 0.697518, acc: 59.38%] [G loss: 2.600582]\n",
      "epoch:17 step:13813 [D loss: 0.172855, acc: 98.44%] [G loss: 3.039716]\n",
      "epoch:17 step:13814 [D loss: 0.523842, acc: 75.00%] [G loss: 2.690669]\n",
      "epoch:17 step:13815 [D loss: 0.448149, acc: 78.12%] [G loss: 2.935781]\n",
      "epoch:17 step:13816 [D loss: 0.812897, acc: 46.09%] [G loss: 2.963526]\n",
      "epoch:17 step:13817 [D loss: 0.544745, acc: 76.56%] [G loss: 2.454683]\n",
      "epoch:17 step:13818 [D loss: 0.510901, acc: 81.25%] [G loss: 2.857861]\n",
      "epoch:17 step:13819 [D loss: 0.734306, acc: 50.78%] [G loss: 3.467383]\n",
      "epoch:17 step:13820 [D loss: 0.558647, acc: 75.00%] [G loss: 2.483100]\n",
      "epoch:17 step:13821 [D loss: 0.374369, acc: 89.06%] [G loss: 2.488500]\n",
      "epoch:17 step:13822 [D loss: 0.721302, acc: 52.34%] [G loss: 1.903383]\n",
      "epoch:17 step:13823 [D loss: 0.312387, acc: 93.75%] [G loss: 2.939643]\n",
      "epoch:17 step:13824 [D loss: 0.333755, acc: 87.50%] [G loss: 4.083675]\n",
      "epoch:17 step:13825 [D loss: 1.448776, acc: 7.03%] [G loss: 1.785504]\n",
      "epoch:17 step:13826 [D loss: 0.745756, acc: 55.47%] [G loss: 3.435125]\n",
      "epoch:17 step:13827 [D loss: 0.528487, acc: 64.84%] [G loss: 2.912428]\n",
      "epoch:17 step:13828 [D loss: 0.812920, acc: 47.66%] [G loss: 2.916643]\n",
      "epoch:17 step:13829 [D loss: 0.966288, acc: 35.94%] [G loss: 3.261663]\n",
      "epoch:17 step:13830 [D loss: 0.699862, acc: 53.91%] [G loss: 2.831376]\n",
      "epoch:17 step:13831 [D loss: 0.364136, acc: 93.75%] [G loss: 3.043307]\n",
      "epoch:17 step:13832 [D loss: 0.460510, acc: 79.69%] [G loss: 3.178994]\n",
      "epoch:17 step:13833 [D loss: 0.678736, acc: 63.28%] [G loss: 2.427367]\n",
      "epoch:17 step:13834 [D loss: 0.554438, acc: 65.62%] [G loss: 1.740973]\n",
      "epoch:17 step:13835 [D loss: 0.570504, acc: 69.53%] [G loss: 3.019435]\n",
      "epoch:17 step:13836 [D loss: 0.437312, acc: 84.38%] [G loss: 2.945797]\n",
      "epoch:17 step:13837 [D loss: 0.493311, acc: 84.38%] [G loss: 3.609083]\n",
      "epoch:17 step:13838 [D loss: 0.461426, acc: 68.75%] [G loss: 3.163336]\n",
      "epoch:17 step:13839 [D loss: 0.383488, acc: 86.72%] [G loss: 2.675162]\n",
      "epoch:17 step:13840 [D loss: 0.745687, acc: 58.59%] [G loss: 2.118414]\n",
      "epoch:17 step:13841 [D loss: 0.305488, acc: 91.41%] [G loss: 2.539675]\n",
      "epoch:17 step:13842 [D loss: 0.683410, acc: 57.81%] [G loss: 1.933167]\n",
      "epoch:17 step:13843 [D loss: 0.725328, acc: 51.56%] [G loss: 2.228916]\n",
      "epoch:17 step:13844 [D loss: 0.560158, acc: 74.22%] [G loss: 3.213734]\n",
      "epoch:17 step:13845 [D loss: 0.538687, acc: 65.62%] [G loss: 3.098773]\n",
      "epoch:17 step:13846 [D loss: 0.559992, acc: 75.00%] [G loss: 2.598947]\n",
      "epoch:17 step:13847 [D loss: 0.566073, acc: 64.06%] [G loss: 2.282139]\n",
      "epoch:17 step:13848 [D loss: 0.460218, acc: 82.81%] [G loss: 2.966508]\n",
      "epoch:17 step:13849 [D loss: 0.232872, acc: 97.66%] [G loss: 2.707407]\n",
      "epoch:17 step:13850 [D loss: 0.218346, acc: 94.53%] [G loss: 3.168831]\n",
      "epoch:17 step:13851 [D loss: 0.760783, acc: 48.44%] [G loss: 2.352569]\n",
      "epoch:17 step:13852 [D loss: 0.393384, acc: 87.50%] [G loss: 2.871473]\n",
      "epoch:17 step:13853 [D loss: 0.491656, acc: 81.25%] [G loss: 2.842088]\n",
      "epoch:17 step:13854 [D loss: 0.631680, acc: 64.84%] [G loss: 3.026210]\n",
      "epoch:17 step:13855 [D loss: 0.623142, acc: 64.84%] [G loss: 2.609427]\n",
      "epoch:17 step:13856 [D loss: 0.709278, acc: 54.69%] [G loss: 2.069751]\n",
      "epoch:17 step:13857 [D loss: 0.715264, acc: 55.47%] [G loss: 3.046679]\n",
      "epoch:17 step:13858 [D loss: 0.482904, acc: 83.59%] [G loss: 3.749212]\n",
      "epoch:17 step:13859 [D loss: 0.439527, acc: 89.84%] [G loss: 2.290014]\n",
      "epoch:17 step:13860 [D loss: 0.323698, acc: 97.66%] [G loss: 2.708715]\n",
      "epoch:17 step:13861 [D loss: 0.550656, acc: 79.69%] [G loss: 2.558229]\n",
      "epoch:17 step:13862 [D loss: 0.774498, acc: 49.22%] [G loss: 2.173243]\n",
      "epoch:17 step:13863 [D loss: 0.397226, acc: 87.50%] [G loss: 3.131473]\n",
      "epoch:17 step:13864 [D loss: 0.429759, acc: 75.78%] [G loss: 2.620365]\n",
      "epoch:17 step:13865 [D loss: 0.674645, acc: 61.72%] [G loss: 3.543085]\n",
      "epoch:17 step:13866 [D loss: 1.032905, acc: 31.25%] [G loss: 1.892072]\n",
      "epoch:17 step:13867 [D loss: 0.899595, acc: 47.66%] [G loss: 2.551995]\n",
      "epoch:17 step:13868 [D loss: 0.799109, acc: 48.44%] [G loss: 2.101001]\n",
      "epoch:17 step:13869 [D loss: 0.546648, acc: 76.56%] [G loss: 2.513374]\n",
      "epoch:17 step:13870 [D loss: 0.927188, acc: 49.22%] [G loss: 4.237858]\n",
      "epoch:17 step:13871 [D loss: 0.729917, acc: 55.47%] [G loss: 2.341646]\n",
      "epoch:17 step:13872 [D loss: 0.443397, acc: 79.69%] [G loss: 2.697955]\n",
      "epoch:17 step:13873 [D loss: 0.514214, acc: 64.06%] [G loss: 4.185513]\n",
      "epoch:17 step:13874 [D loss: 0.480274, acc: 82.03%] [G loss: 3.227057]\n",
      "epoch:17 step:13875 [D loss: 0.830638, acc: 50.00%] [G loss: 2.185402]\n",
      "epoch:17 step:13876 [D loss: 0.572456, acc: 73.44%] [G loss: 2.397625]\n",
      "epoch:17 step:13877 [D loss: 0.341956, acc: 95.31%] [G loss: 2.731858]\n",
      "epoch:17 step:13878 [D loss: 0.439047, acc: 84.38%] [G loss: 3.149453]\n",
      "epoch:17 step:13879 [D loss: 0.411128, acc: 80.47%] [G loss: 2.748780]\n",
      "epoch:17 step:13880 [D loss: 0.695916, acc: 59.38%] [G loss: 1.837762]\n",
      "epoch:17 step:13881 [D loss: 1.019370, acc: 45.31%] [G loss: 1.618160]\n",
      "epoch:17 step:13882 [D loss: 0.285803, acc: 92.19%] [G loss: 2.463606]\n",
      "epoch:17 step:13883 [D loss: 0.339539, acc: 94.53%] [G loss: 2.811464]\n",
      "epoch:17 step:13884 [D loss: 0.700507, acc: 56.25%] [G loss: 1.670971]\n",
      "epoch:17 step:13885 [D loss: 0.297053, acc: 98.44%] [G loss: 2.607475]\n",
      "epoch:17 step:13886 [D loss: 1.169311, acc: 14.84%] [G loss: 1.494045]\n",
      "epoch:17 step:13887 [D loss: 0.885909, acc: 36.72%] [G loss: 2.591763]\n",
      "epoch:17 step:13888 [D loss: 0.458141, acc: 82.03%] [G loss: 2.854746]\n",
      "epoch:17 step:13889 [D loss: 0.625072, acc: 69.53%] [G loss: 2.668604]\n",
      "epoch:17 step:13890 [D loss: 1.050145, acc: 34.38%] [G loss: 2.458045]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13891 [D loss: 0.586170, acc: 67.97%] [G loss: 2.264760]\n",
      "epoch:17 step:13892 [D loss: 0.569069, acc: 71.88%] [G loss: 2.552113]\n",
      "epoch:17 step:13893 [D loss: 0.926640, acc: 30.47%] [G loss: 2.571010]\n",
      "epoch:17 step:13894 [D loss: 0.554378, acc: 73.44%] [G loss: 2.987850]\n",
      "epoch:17 step:13895 [D loss: 0.798932, acc: 42.19%] [G loss: 3.252628]\n",
      "epoch:17 step:13896 [D loss: 0.542306, acc: 70.31%] [G loss: 1.907476]\n",
      "epoch:17 step:13897 [D loss: 0.465154, acc: 85.94%] [G loss: 2.253316]\n",
      "epoch:17 step:13898 [D loss: 0.665007, acc: 59.38%] [G loss: 2.627101]\n",
      "epoch:17 step:13899 [D loss: 0.356998, acc: 92.97%] [G loss: 2.485231]\n",
      "epoch:17 step:13900 [D loss: 0.729839, acc: 53.12%] [G loss: 2.186090]\n",
      "epoch:17 step:13901 [D loss: 0.593600, acc: 70.31%] [G loss: 3.121156]\n",
      "epoch:17 step:13902 [D loss: 0.463245, acc: 82.03%] [G loss: 2.765132]\n",
      "epoch:17 step:13903 [D loss: 0.652823, acc: 57.81%] [G loss: 2.573982]\n",
      "epoch:17 step:13904 [D loss: 1.145978, acc: 21.09%] [G loss: 2.594878]\n",
      "epoch:17 step:13905 [D loss: 0.416734, acc: 85.16%] [G loss: 2.866492]\n",
      "epoch:17 step:13906 [D loss: 0.434592, acc: 82.81%] [G loss: 2.889718]\n",
      "epoch:17 step:13907 [D loss: 0.355869, acc: 92.97%] [G loss: 3.559576]\n",
      "epoch:17 step:13908 [D loss: 0.368945, acc: 91.41%] [G loss: 2.517688]\n",
      "epoch:17 step:13909 [D loss: 1.402213, acc: 8.59%] [G loss: 1.910425]\n",
      "epoch:17 step:13910 [D loss: 0.433360, acc: 87.50%] [G loss: 2.348705]\n",
      "epoch:17 step:13911 [D loss: 0.756073, acc: 45.31%] [G loss: 2.213684]\n",
      "epoch:17 step:13912 [D loss: 0.950274, acc: 32.03%] [G loss: 2.314184]\n",
      "epoch:17 step:13913 [D loss: 1.043820, acc: 30.47%] [G loss: 2.200475]\n",
      "epoch:17 step:13914 [D loss: 0.812531, acc: 50.00%] [G loss: 1.971578]\n",
      "epoch:17 step:13915 [D loss: 0.948357, acc: 40.62%] [G loss: 2.578079]\n",
      "epoch:17 step:13916 [D loss: 1.020694, acc: 30.47%] [G loss: 2.194073]\n",
      "epoch:17 step:13917 [D loss: 0.702242, acc: 60.94%] [G loss: 2.742916]\n",
      "epoch:17 step:13918 [D loss: 0.652749, acc: 61.72%] [G loss: 2.535127]\n",
      "epoch:17 step:13919 [D loss: 0.272471, acc: 96.09%] [G loss: 3.059226]\n",
      "epoch:17 step:13920 [D loss: 0.537643, acc: 74.22%] [G loss: 3.097783]\n",
      "epoch:17 step:13921 [D loss: 0.605332, acc: 65.62%] [G loss: 2.354207]\n",
      "epoch:17 step:13922 [D loss: 0.566730, acc: 72.66%] [G loss: 2.033249]\n",
      "epoch:17 step:13923 [D loss: 0.746769, acc: 50.78%] [G loss: 2.105057]\n",
      "epoch:17 step:13924 [D loss: 0.751203, acc: 49.22%] [G loss: 1.959726]\n",
      "epoch:17 step:13925 [D loss: 0.520021, acc: 75.78%] [G loss: 3.430448]\n",
      "epoch:17 step:13926 [D loss: 0.835445, acc: 41.41%] [G loss: 2.036312]\n",
      "epoch:17 step:13927 [D loss: 0.744806, acc: 50.00%] [G loss: 2.350994]\n",
      "epoch:17 step:13928 [D loss: 0.425860, acc: 82.03%] [G loss: 2.825551]\n",
      "epoch:17 step:13929 [D loss: 0.426878, acc: 84.38%] [G loss: 2.851713]\n",
      "epoch:17 step:13930 [D loss: 0.468537, acc: 83.59%] [G loss: 2.230322]\n",
      "epoch:17 step:13931 [D loss: 0.365903, acc: 94.53%] [G loss: 2.675314]\n",
      "epoch:17 step:13932 [D loss: 0.754062, acc: 50.00%] [G loss: 2.279829]\n",
      "epoch:17 step:13933 [D loss: 0.744421, acc: 52.34%] [G loss: 1.906483]\n",
      "epoch:17 step:13934 [D loss: 0.529128, acc: 75.00%] [G loss: 3.189370]\n",
      "epoch:17 step:13935 [D loss: 0.655508, acc: 65.62%] [G loss: 1.820201]\n",
      "epoch:17 step:13936 [D loss: 0.240876, acc: 97.66%] [G loss: 3.020923]\n",
      "epoch:17 step:13937 [D loss: 0.781831, acc: 47.66%] [G loss: 2.837973]\n",
      "epoch:17 step:13938 [D loss: 0.312318, acc: 95.31%] [G loss: 3.849151]\n",
      "epoch:17 step:13939 [D loss: 0.277643, acc: 95.31%] [G loss: 2.811607]\n",
      "epoch:17 step:13940 [D loss: 0.550995, acc: 72.66%] [G loss: 2.113873]\n",
      "epoch:17 step:13941 [D loss: 0.195981, acc: 98.44%] [G loss: 3.772493]\n",
      "epoch:17 step:13942 [D loss: 1.167176, acc: 19.53%] [G loss: 2.541367]\n",
      "epoch:17 step:13943 [D loss: 0.643791, acc: 60.16%] [G loss: 2.128743]\n",
      "epoch:17 step:13944 [D loss: 0.419190, acc: 83.59%] [G loss: 3.578484]\n",
      "epoch:17 step:13945 [D loss: 0.565268, acc: 71.09%] [G loss: 1.888293]\n",
      "epoch:17 step:13946 [D loss: 0.666772, acc: 57.81%] [G loss: 2.297521]\n",
      "epoch:17 step:13947 [D loss: 0.834936, acc: 45.31%] [G loss: 2.089838]\n",
      "epoch:17 step:13948 [D loss: 0.613794, acc: 67.97%] [G loss: 2.295521]\n",
      "epoch:17 step:13949 [D loss: 0.636403, acc: 64.84%] [G loss: 1.716296]\n",
      "epoch:17 step:13950 [D loss: 0.716662, acc: 55.47%] [G loss: 2.314130]\n",
      "epoch:17 step:13951 [D loss: 0.314277, acc: 95.31%] [G loss: 2.778441]\n",
      "epoch:17 step:13952 [D loss: 0.410549, acc: 89.84%] [G loss: 2.589278]\n",
      "epoch:17 step:13953 [D loss: 0.575219, acc: 73.44%] [G loss: 2.559412]\n",
      "epoch:17 step:13954 [D loss: 0.387724, acc: 85.16%] [G loss: 3.156159]\n",
      "epoch:17 step:13955 [D loss: 0.869406, acc: 33.59%] [G loss: 2.706135]\n",
      "epoch:17 step:13956 [D loss: 0.389425, acc: 85.94%] [G loss: 2.541284]\n",
      "epoch:17 step:13957 [D loss: 0.719283, acc: 49.22%] [G loss: 2.741823]\n",
      "epoch:17 step:13958 [D loss: 0.535012, acc: 80.47%] [G loss: 2.519397]\n",
      "epoch:17 step:13959 [D loss: 0.849993, acc: 46.88%] [G loss: 2.917138]\n",
      "epoch:17 step:13960 [D loss: 0.626082, acc: 66.41%] [G loss: 2.279738]\n",
      "epoch:17 step:13961 [D loss: 0.953112, acc: 34.38%] [G loss: 2.501667]\n",
      "epoch:17 step:13962 [D loss: 0.697927, acc: 54.69%] [G loss: 2.443025]\n",
      "epoch:17 step:13963 [D loss: 0.409974, acc: 88.28%] [G loss: 1.735975]\n",
      "epoch:17 step:13964 [D loss: 0.443600, acc: 81.25%] [G loss: 2.672787]\n",
      "epoch:17 step:13965 [D loss: 0.506441, acc: 77.34%] [G loss: 3.109668]\n",
      "epoch:17 step:13966 [D loss: 0.509303, acc: 76.56%] [G loss: 2.781195]\n",
      "epoch:17 step:13967 [D loss: 0.671620, acc: 63.28%] [G loss: 2.178544]\n",
      "epoch:17 step:13968 [D loss: 0.414031, acc: 83.59%] [G loss: 2.450625]\n",
      "epoch:17 step:13969 [D loss: 0.611740, acc: 66.41%] [G loss: 2.637379]\n",
      "epoch:17 step:13970 [D loss: 0.589465, acc: 70.31%] [G loss: 2.533838]\n",
      "epoch:17 step:13971 [D loss: 0.242245, acc: 93.75%] [G loss: 2.520447]\n",
      "epoch:17 step:13972 [D loss: 0.302142, acc: 92.19%] [G loss: 2.470928]\n",
      "epoch:17 step:13973 [D loss: 0.486173, acc: 84.38%] [G loss: 2.030534]\n",
      "epoch:17 step:13974 [D loss: 0.514929, acc: 72.66%] [G loss: 2.737479]\n",
      "epoch:17 step:13975 [D loss: 0.512229, acc: 82.81%] [G loss: 2.639971]\n",
      "epoch:17 step:13976 [D loss: 0.711145, acc: 57.81%] [G loss: 2.629533]\n",
      "epoch:17 step:13977 [D loss: 0.505710, acc: 78.12%] [G loss: 2.653068]\n",
      "epoch:17 step:13978 [D loss: 0.317224, acc: 93.75%] [G loss: 2.569667]\n",
      "epoch:17 step:13979 [D loss: 0.431185, acc: 80.47%] [G loss: 3.889997]\n",
      "epoch:17 step:13980 [D loss: 0.709727, acc: 56.25%] [G loss: 3.346927]\n",
      "epoch:17 step:13981 [D loss: 0.407169, acc: 89.84%] [G loss: 2.532637]\n",
      "epoch:17 step:13982 [D loss: 0.767412, acc: 50.78%] [G loss: 2.248343]\n",
      "epoch:17 step:13983 [D loss: 0.755851, acc: 50.78%] [G loss: 1.860006]\n",
      "epoch:17 step:13984 [D loss: 0.833336, acc: 42.19%] [G loss: 2.500662]\n",
      "epoch:17 step:13985 [D loss: 0.580194, acc: 71.09%] [G loss: 2.327341]\n",
      "epoch:17 step:13986 [D loss: 0.528762, acc: 78.91%] [G loss: 2.136825]\n",
      "epoch:17 step:13987 [D loss: 0.784822, acc: 50.00%] [G loss: 2.335451]\n",
      "epoch:17 step:13988 [D loss: 0.361386, acc: 88.28%] [G loss: 3.914191]\n",
      "epoch:17 step:13989 [D loss: 0.343181, acc: 93.75%] [G loss: 3.942650]\n",
      "epoch:17 step:13990 [D loss: 0.651030, acc: 57.81%] [G loss: 2.326434]\n",
      "epoch:17 step:13991 [D loss: 0.310951, acc: 95.31%] [G loss: 2.876678]\n",
      "epoch:17 step:13992 [D loss: 0.699449, acc: 57.81%] [G loss: 2.465928]\n",
      "epoch:17 step:13993 [D loss: 0.859125, acc: 47.66%] [G loss: 2.518974]\n",
      "epoch:17 step:13994 [D loss: 0.392142, acc: 91.41%] [G loss: 2.938311]\n",
      "epoch:17 step:13995 [D loss: 0.759243, acc: 52.34%] [G loss: 2.474343]\n",
      "epoch:17 step:13996 [D loss: 0.369792, acc: 92.19%] [G loss: 2.685585]\n",
      "epoch:17 step:13997 [D loss: 0.713913, acc: 53.12%] [G loss: 2.558677]\n",
      "epoch:17 step:13998 [D loss: 0.651613, acc: 68.75%] [G loss: 2.506218]\n",
      "epoch:17 step:13999 [D loss: 0.373513, acc: 92.19%] [G loss: 2.382576]\n",
      "epoch:17 step:14000 [D loss: 0.440249, acc: 86.72%] [G loss: 2.759703]\n",
      "epoch:17 step:14001 [D loss: 0.578344, acc: 69.53%] [G loss: 2.926802]\n",
      "epoch:17 step:14002 [D loss: 0.605774, acc: 71.09%] [G loss: 2.321233]\n",
      "epoch:17 step:14003 [D loss: 0.476435, acc: 78.91%] [G loss: 3.576901]\n",
      "epoch:17 step:14004 [D loss: 0.770332, acc: 49.22%] [G loss: 3.294466]\n",
      "epoch:17 step:14005 [D loss: 0.206561, acc: 97.66%] [G loss: 2.653372]\n",
      "epoch:17 step:14006 [D loss: 0.537973, acc: 72.66%] [G loss: 2.662499]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:14007 [D loss: 0.547920, acc: 74.22%] [G loss: 2.359530]\n",
      "epoch:17 step:14008 [D loss: 0.453991, acc: 80.47%] [G loss: 4.000462]\n",
      "epoch:17 step:14009 [D loss: 0.417762, acc: 85.94%] [G loss: 2.141228]\n",
      "epoch:17 step:14010 [D loss: 0.465136, acc: 78.91%] [G loss: 3.117714]\n",
      "epoch:17 step:14011 [D loss: 0.290059, acc: 92.19%] [G loss: 3.222586]\n",
      "epoch:17 step:14012 [D loss: 0.705108, acc: 54.69%] [G loss: 2.731204]\n",
      "epoch:17 step:14013 [D loss: 0.690473, acc: 54.69%] [G loss: 2.810273]\n",
      "epoch:17 step:14014 [D loss: 0.361763, acc: 84.38%] [G loss: 3.204915]\n",
      "epoch:17 step:14015 [D loss: 0.763091, acc: 50.00%] [G loss: 2.747585]\n",
      "epoch:17 step:14016 [D loss: 0.490511, acc: 78.12%] [G loss: 2.309576]\n",
      "epoch:17 step:14017 [D loss: 0.478455, acc: 81.25%] [G loss: 1.932513]\n",
      "epoch:17 step:14018 [D loss: 0.332041, acc: 93.75%] [G loss: 3.237194]\n",
      "epoch:17 step:14019 [D loss: 0.681218, acc: 60.16%] [G loss: 2.371429]\n",
      "epoch:17 step:14020 [D loss: 0.502376, acc: 68.75%] [G loss: 2.576958]\n",
      "epoch:17 step:14021 [D loss: 0.524922, acc: 74.22%] [G loss: 3.104595]\n",
      "epoch:17 step:14022 [D loss: 0.470962, acc: 80.47%] [G loss: 2.911779]\n",
      "epoch:17 step:14023 [D loss: 0.341948, acc: 92.97%] [G loss: 3.668865]\n",
      "epoch:17 step:14024 [D loss: 0.622882, acc: 67.97%] [G loss: 3.003883]\n",
      "epoch:17 step:14025 [D loss: 0.370342, acc: 85.94%] [G loss: 3.954029]\n",
      "epoch:17 step:14026 [D loss: 0.653880, acc: 64.06%] [G loss: 3.147421]\n",
      "epoch:17 step:14027 [D loss: 0.865977, acc: 48.44%] [G loss: 2.032564]\n",
      "epoch:17 step:14028 [D loss: 0.914032, acc: 41.41%] [G loss: 1.750653]\n",
      "epoch:17 step:14029 [D loss: 0.621583, acc: 66.41%] [G loss: 2.668742]\n",
      "epoch:17 step:14030 [D loss: 0.240967, acc: 96.88%] [G loss: 3.443653]\n",
      "epoch:17 step:14031 [D loss: 0.472929, acc: 78.91%] [G loss: 3.387634]\n",
      "epoch:17 step:14032 [D loss: 0.402214, acc: 74.22%] [G loss: 3.546635]\n",
      "epoch:17 step:14033 [D loss: 0.333160, acc: 95.31%] [G loss: 3.059027]\n",
      "epoch:17 step:14034 [D loss: 0.716086, acc: 58.59%] [G loss: 2.018832]\n",
      "epoch:17 step:14035 [D loss: 0.540129, acc: 71.88%] [G loss: 3.797077]\n",
      "epoch:17 step:14036 [D loss: 0.919219, acc: 30.47%] [G loss: 2.645997]\n",
      "epoch:17 step:14037 [D loss: 0.179588, acc: 100.00%] [G loss: 4.082696]\n",
      "epoch:17 step:14038 [D loss: 0.462056, acc: 67.97%] [G loss: 2.994543]\n",
      "epoch:17 step:14039 [D loss: 0.565203, acc: 71.88%] [G loss: 3.273018]\n",
      "epoch:17 step:14040 [D loss: 0.170055, acc: 99.22%] [G loss: 3.059209]\n",
      "epoch:17 step:14041 [D loss: 0.700026, acc: 57.81%] [G loss: 2.633124]\n",
      "epoch:17 step:14042 [D loss: 0.436615, acc: 86.72%] [G loss: 2.807676]\n",
      "epoch:17 step:14043 [D loss: 0.568310, acc: 71.09%] [G loss: 2.204612]\n",
      "epoch:17 step:14044 [D loss: 0.699300, acc: 60.16%] [G loss: 2.320248]\n",
      "epoch:17 step:14045 [D loss: 0.506356, acc: 67.19%] [G loss: 3.496432]\n",
      "epoch:17 step:14046 [D loss: 0.891536, acc: 36.72%] [G loss: 2.503395]\n",
      "epoch:17 step:14047 [D loss: 0.304761, acc: 95.31%] [G loss: 3.262659]\n",
      "epoch:17 step:14048 [D loss: 1.117310, acc: 32.81%] [G loss: 2.003003]\n",
      "epoch:17 step:14049 [D loss: 0.385524, acc: 89.06%] [G loss: 3.397898]\n",
      "epoch:17 step:14050 [D loss: 0.653847, acc: 58.59%] [G loss: 4.627659]\n",
      "epoch:17 step:14051 [D loss: 0.682027, acc: 57.03%] [G loss: 3.011956]\n",
      "epoch:17 step:14052 [D loss: 0.513805, acc: 72.66%] [G loss: 2.448596]\n",
      "epoch:17 step:14053 [D loss: 0.527833, acc: 75.00%] [G loss: 3.577338]\n",
      "epoch:17 step:14054 [D loss: 0.716017, acc: 48.44%] [G loss: 1.967546]\n",
      "epoch:17 step:14055 [D loss: 0.522575, acc: 73.44%] [G loss: 2.818298]\n",
      "epoch:17 step:14056 [D loss: 0.898141, acc: 36.72%] [G loss: 1.969912]\n",
      "epoch:17 step:14057 [D loss: 0.809686, acc: 42.97%] [G loss: 2.216226]\n",
      "epoch:17 step:14058 [D loss: 0.510003, acc: 74.22%] [G loss: 2.651425]\n",
      "epoch:18 step:14059 [D loss: 0.362519, acc: 89.84%] [G loss: 3.062075]\n",
      "epoch:18 step:14060 [D loss: 0.185553, acc: 99.22%] [G loss: 4.356199]\n",
      "epoch:18 step:14061 [D loss: 0.467483, acc: 82.03%] [G loss: 3.027132]\n",
      "epoch:18 step:14062 [D loss: 0.528745, acc: 68.75%] [G loss: 2.600768]\n",
      "epoch:18 step:14063 [D loss: 0.390434, acc: 87.50%] [G loss: 2.656300]\n",
      "epoch:18 step:14064 [D loss: 0.470297, acc: 84.38%] [G loss: 3.367343]\n",
      "epoch:18 step:14065 [D loss: 0.556073, acc: 79.69%] [G loss: 3.036105]\n",
      "epoch:18 step:14066 [D loss: 0.383691, acc: 78.12%] [G loss: 2.093131]\n",
      "epoch:18 step:14067 [D loss: 0.670854, acc: 57.81%] [G loss: 2.437042]\n",
      "epoch:18 step:14068 [D loss: 1.006953, acc: 48.44%] [G loss: 2.552240]\n",
      "epoch:18 step:14069 [D loss: 0.401949, acc: 85.94%] [G loss: 1.960083]\n",
      "epoch:18 step:14070 [D loss: 0.246776, acc: 95.31%] [G loss: 3.204361]\n",
      "epoch:18 step:14071 [D loss: 0.370511, acc: 89.06%] [G loss: 2.779416]\n",
      "epoch:18 step:14072 [D loss: 0.478862, acc: 75.00%] [G loss: 3.283207]\n",
      "epoch:18 step:14073 [D loss: 0.980899, acc: 47.66%] [G loss: 2.867892]\n",
      "epoch:18 step:14074 [D loss: 0.514163, acc: 78.12%] [G loss: 1.958499]\n",
      "epoch:18 step:14075 [D loss: 0.306020, acc: 89.84%] [G loss: 2.702352]\n",
      "epoch:18 step:14076 [D loss: 0.388561, acc: 90.62%] [G loss: 2.078157]\n",
      "epoch:18 step:14077 [D loss: 0.631537, acc: 67.19%] [G loss: 2.384916]\n",
      "epoch:18 step:14078 [D loss: 0.979000, acc: 31.25%] [G loss: 2.683528]\n",
      "epoch:18 step:14079 [D loss: 0.416692, acc: 84.38%] [G loss: 1.806883]\n",
      "epoch:18 step:14080 [D loss: 0.627659, acc: 62.50%] [G loss: 2.617485]\n",
      "epoch:18 step:14081 [D loss: 1.086348, acc: 21.88%] [G loss: 2.702098]\n",
      "epoch:18 step:14082 [D loss: 0.779244, acc: 53.91%] [G loss: 3.167224]\n",
      "epoch:18 step:14083 [D loss: 0.348312, acc: 84.38%] [G loss: 2.925221]\n",
      "epoch:18 step:14084 [D loss: 0.659138, acc: 57.81%] [G loss: 2.654265]\n",
      "epoch:18 step:14085 [D loss: 0.384828, acc: 85.16%] [G loss: 3.263585]\n",
      "epoch:18 step:14086 [D loss: 0.424015, acc: 89.06%] [G loss: 2.830202]\n",
      "epoch:18 step:14087 [D loss: 0.603465, acc: 68.75%] [G loss: 2.883911]\n",
      "epoch:18 step:14088 [D loss: 0.436193, acc: 87.50%] [G loss: 3.741621]\n",
      "epoch:18 step:14089 [D loss: 0.310270, acc: 83.59%] [G loss: 4.463133]\n",
      "epoch:18 step:14090 [D loss: 0.404487, acc: 85.94%] [G loss: 3.155479]\n",
      "epoch:18 step:14091 [D loss: 0.475922, acc: 83.59%] [G loss: 2.883429]\n",
      "epoch:18 step:14092 [D loss: 0.703637, acc: 58.59%] [G loss: 2.710099]\n",
      "epoch:18 step:14093 [D loss: 1.066471, acc: 42.97%] [G loss: 1.809787]\n",
      "epoch:18 step:14094 [D loss: 0.341471, acc: 92.97%] [G loss: 2.520409]\n",
      "epoch:18 step:14095 [D loss: 0.417632, acc: 79.69%] [G loss: 4.108696]\n",
      "epoch:18 step:14096 [D loss: 0.459398, acc: 82.03%] [G loss: 3.571612]\n",
      "epoch:18 step:14097 [D loss: 0.369741, acc: 91.41%] [G loss: 2.676599]\n",
      "epoch:18 step:14098 [D loss: 0.546514, acc: 73.44%] [G loss: 2.665990]\n",
      "epoch:18 step:14099 [D loss: 0.228426, acc: 96.88%] [G loss: 3.190365]\n",
      "epoch:18 step:14100 [D loss: 0.577285, acc: 66.41%] [G loss: 2.300188]\n",
      "epoch:18 step:14101 [D loss: 0.453344, acc: 75.78%] [G loss: 3.560079]\n",
      "epoch:18 step:14102 [D loss: 0.577009, acc: 70.31%] [G loss: 3.040655]\n",
      "epoch:18 step:14103 [D loss: 0.598215, acc: 61.72%] [G loss: 2.741864]\n",
      "epoch:18 step:14104 [D loss: 0.415976, acc: 77.34%] [G loss: 2.924667]\n",
      "epoch:18 step:14105 [D loss: 0.400245, acc: 87.50%] [G loss: 2.583862]\n",
      "epoch:18 step:14106 [D loss: 0.452610, acc: 89.84%] [G loss: 2.009599]\n",
      "epoch:18 step:14107 [D loss: 0.774362, acc: 45.31%] [G loss: 2.560051]\n",
      "epoch:18 step:14108 [D loss: 0.433217, acc: 87.50%] [G loss: 2.488075]\n",
      "epoch:18 step:14109 [D loss: 0.440064, acc: 86.72%] [G loss: 2.473615]\n",
      "epoch:18 step:14110 [D loss: 0.743434, acc: 53.91%] [G loss: 2.681682]\n",
      "epoch:18 step:14111 [D loss: 0.773880, acc: 49.22%] [G loss: 2.806407]\n",
      "epoch:18 step:14112 [D loss: 0.760937, acc: 50.78%] [G loss: 2.100952]\n",
      "epoch:18 step:14113 [D loss: 0.471742, acc: 82.03%] [G loss: 2.404376]\n",
      "epoch:18 step:14114 [D loss: 0.368127, acc: 90.62%] [G loss: 1.992880]\n",
      "epoch:18 step:14115 [D loss: 0.835027, acc: 46.88%] [G loss: 2.635432]\n",
      "epoch:18 step:14116 [D loss: 0.579312, acc: 69.53%] [G loss: 2.996885]\n",
      "epoch:18 step:14117 [D loss: 0.559531, acc: 64.84%] [G loss: 3.094956]\n",
      "epoch:18 step:14118 [D loss: 0.369065, acc: 88.28%] [G loss: 2.172175]\n",
      "epoch:18 step:14119 [D loss: 0.884165, acc: 45.31%] [G loss: 2.606003]\n",
      "epoch:18 step:14120 [D loss: 0.661280, acc: 58.59%] [G loss: 2.065688]\n",
      "epoch:18 step:14121 [D loss: 0.464694, acc: 81.25%] [G loss: 2.566329]\n",
      "epoch:18 step:14122 [D loss: 0.534922, acc: 75.00%] [G loss: 2.721552]\n",
      "epoch:18 step:14123 [D loss: 0.379858, acc: 87.50%] [G loss: 2.953630]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14124 [D loss: 0.659159, acc: 62.50%] [G loss: 3.168980]\n",
      "epoch:18 step:14125 [D loss: 1.129184, acc: 11.72%] [G loss: 1.948609]\n",
      "epoch:18 step:14126 [D loss: 0.675085, acc: 59.38%] [G loss: 2.392603]\n",
      "epoch:18 step:14127 [D loss: 0.661397, acc: 54.69%] [G loss: 2.382148]\n",
      "epoch:18 step:14128 [D loss: 0.466446, acc: 75.00%] [G loss: 3.085130]\n",
      "epoch:18 step:14129 [D loss: 0.777791, acc: 49.22%] [G loss: 2.371872]\n",
      "epoch:18 step:14130 [D loss: 1.116339, acc: 20.31%] [G loss: 2.121213]\n",
      "epoch:18 step:14131 [D loss: 0.657785, acc: 57.81%] [G loss: 1.949672]\n",
      "epoch:18 step:14132 [D loss: 0.363940, acc: 91.41%] [G loss: 3.518424]\n",
      "epoch:18 step:14133 [D loss: 0.509054, acc: 77.34%] [G loss: 2.655849]\n",
      "epoch:18 step:14134 [D loss: 1.014698, acc: 26.56%] [G loss: 2.766260]\n",
      "epoch:18 step:14135 [D loss: 0.747653, acc: 54.69%] [G loss: 1.806846]\n",
      "epoch:18 step:14136 [D loss: 0.487428, acc: 83.59%] [G loss: 2.397772]\n",
      "epoch:18 step:14137 [D loss: 0.598357, acc: 67.19%] [G loss: 2.557431]\n",
      "epoch:18 step:14138 [D loss: 0.947948, acc: 37.50%] [G loss: 2.811502]\n",
      "epoch:18 step:14139 [D loss: 0.423754, acc: 89.84%] [G loss: 2.452541]\n",
      "epoch:18 step:14140 [D loss: 0.358550, acc: 85.16%] [G loss: 3.233929]\n",
      "epoch:18 step:14141 [D loss: 0.495263, acc: 77.34%] [G loss: 2.484468]\n",
      "epoch:18 step:14142 [D loss: 1.290500, acc: 5.47%] [G loss: 2.011002]\n",
      "epoch:18 step:14143 [D loss: 0.448112, acc: 78.91%] [G loss: 2.753596]\n",
      "epoch:18 step:14144 [D loss: 0.301190, acc: 95.31%] [G loss: 3.099049]\n",
      "epoch:18 step:14145 [D loss: 0.459783, acc: 82.81%] [G loss: 3.940573]\n",
      "epoch:18 step:14146 [D loss: 0.302742, acc: 96.09%] [G loss: 2.643796]\n",
      "epoch:18 step:14147 [D loss: 0.278223, acc: 93.75%] [G loss: 2.706402]\n",
      "epoch:18 step:14148 [D loss: 0.653631, acc: 60.94%] [G loss: 2.307469]\n",
      "epoch:18 step:14149 [D loss: 0.312723, acc: 98.44%] [G loss: 2.613565]\n",
      "epoch:18 step:14150 [D loss: 0.639369, acc: 63.28%] [G loss: 2.536249]\n",
      "epoch:18 step:14151 [D loss: 0.543717, acc: 78.12%] [G loss: 2.880805]\n",
      "epoch:18 step:14152 [D loss: 0.532152, acc: 69.53%] [G loss: 3.174442]\n",
      "epoch:18 step:14153 [D loss: 0.731784, acc: 53.91%] [G loss: 2.015535]\n",
      "epoch:18 step:14154 [D loss: 0.611504, acc: 67.19%] [G loss: 2.014155]\n",
      "epoch:18 step:14155 [D loss: 0.697889, acc: 56.25%] [G loss: 2.012617]\n",
      "epoch:18 step:14156 [D loss: 0.670264, acc: 59.38%] [G loss: 1.788091]\n",
      "epoch:18 step:14157 [D loss: 0.427590, acc: 85.16%] [G loss: 2.750674]\n",
      "epoch:18 step:14158 [D loss: 0.873983, acc: 49.22%] [G loss: 2.677234]\n",
      "epoch:18 step:14159 [D loss: 0.326937, acc: 93.75%] [G loss: 2.629000]\n",
      "epoch:18 step:14160 [D loss: 0.293990, acc: 91.41%] [G loss: 2.535178]\n",
      "epoch:18 step:14161 [D loss: 0.515048, acc: 70.31%] [G loss: 2.428684]\n",
      "epoch:18 step:14162 [D loss: 0.665487, acc: 59.38%] [G loss: 2.792554]\n",
      "epoch:18 step:14163 [D loss: 0.656734, acc: 62.50%] [G loss: 2.099965]\n",
      "epoch:18 step:14164 [D loss: 0.669144, acc: 60.94%] [G loss: 2.190036]\n",
      "epoch:18 step:14165 [D loss: 0.702531, acc: 61.72%] [G loss: 2.452454]\n",
      "epoch:18 step:14166 [D loss: 0.615223, acc: 66.41%] [G loss: 1.913244]\n",
      "epoch:18 step:14167 [D loss: 1.039639, acc: 28.12%] [G loss: 3.109566]\n",
      "epoch:18 step:14168 [D loss: 0.288496, acc: 95.31%] [G loss: 3.841230]\n",
      "epoch:18 step:14169 [D loss: 0.547555, acc: 78.91%] [G loss: 3.047187]\n",
      "epoch:18 step:14170 [D loss: 0.489764, acc: 82.81%] [G loss: 3.211247]\n",
      "epoch:18 step:14171 [D loss: 1.089888, acc: 30.47%] [G loss: 2.578821]\n",
      "epoch:18 step:14172 [D loss: 0.247870, acc: 98.44%] [G loss: 2.795513]\n",
      "epoch:18 step:14173 [D loss: 1.158754, acc: 25.78%] [G loss: 2.011670]\n",
      "epoch:18 step:14174 [D loss: 0.505207, acc: 78.91%] [G loss: 2.799094]\n",
      "epoch:18 step:14175 [D loss: 0.611717, acc: 60.94%] [G loss: 2.507407]\n",
      "epoch:18 step:14176 [D loss: 0.288165, acc: 89.84%] [G loss: 3.648394]\n",
      "epoch:18 step:14177 [D loss: 0.763840, acc: 50.00%] [G loss: 2.537517]\n",
      "epoch:18 step:14178 [D loss: 0.365322, acc: 92.19%] [G loss: 2.620458]\n",
      "epoch:18 step:14179 [D loss: 0.330217, acc: 92.19%] [G loss: 2.739776]\n",
      "epoch:18 step:14180 [D loss: 0.298932, acc: 96.88%] [G loss: 3.659091]\n",
      "epoch:18 step:14181 [D loss: 0.350042, acc: 91.41%] [G loss: 3.046954]\n",
      "epoch:18 step:14182 [D loss: 0.415804, acc: 84.38%] [G loss: 3.263415]\n",
      "epoch:18 step:14183 [D loss: 0.542753, acc: 73.44%] [G loss: 2.478979]\n",
      "epoch:18 step:14184 [D loss: 0.742842, acc: 50.78%] [G loss: 2.758448]\n",
      "epoch:18 step:14185 [D loss: 0.263021, acc: 99.22%] [G loss: 3.003085]\n",
      "epoch:18 step:14186 [D loss: 0.646956, acc: 57.03%] [G loss: 3.074153]\n",
      "epoch:18 step:14187 [D loss: 0.369913, acc: 92.97%] [G loss: 2.069526]\n",
      "epoch:18 step:14188 [D loss: 0.883837, acc: 40.62%] [G loss: 3.014181]\n",
      "epoch:18 step:14189 [D loss: 0.358658, acc: 92.19%] [G loss: 2.523711]\n",
      "epoch:18 step:14190 [D loss: 0.776863, acc: 42.97%] [G loss: 2.533206]\n",
      "epoch:18 step:14191 [D loss: 0.948952, acc: 45.31%] [G loss: 2.609746]\n",
      "epoch:18 step:14192 [D loss: 0.310795, acc: 96.88%] [G loss: 3.239077]\n",
      "epoch:18 step:14193 [D loss: 0.515246, acc: 81.25%] [G loss: 2.330240]\n",
      "epoch:18 step:14194 [D loss: 0.394249, acc: 94.53%] [G loss: 2.912969]\n",
      "epoch:18 step:14195 [D loss: 0.572125, acc: 66.41%] [G loss: 2.147788]\n",
      "epoch:18 step:14196 [D loss: 0.638563, acc: 60.94%] [G loss: 2.386229]\n",
      "epoch:18 step:14197 [D loss: 0.466137, acc: 81.25%] [G loss: 2.418433]\n",
      "epoch:18 step:14198 [D loss: 0.641303, acc: 57.81%] [G loss: 2.137744]\n",
      "epoch:18 step:14199 [D loss: 0.928138, acc: 38.28%] [G loss: 2.759375]\n",
      "epoch:18 step:14200 [D loss: 0.563856, acc: 72.66%] [G loss: 2.700545]\n",
      "epoch:18 step:14201 [D loss: 0.778072, acc: 48.44%] [G loss: 1.660175]\n",
      "epoch:18 step:14202 [D loss: 0.362688, acc: 92.97%] [G loss: 2.491015]\n",
      "epoch:18 step:14203 [D loss: 0.431121, acc: 87.50%] [G loss: 2.974973]\n",
      "epoch:18 step:14204 [D loss: 0.451558, acc: 82.03%] [G loss: 2.497813]\n",
      "epoch:18 step:14205 [D loss: 0.933428, acc: 43.75%] [G loss: 1.912453]\n",
      "epoch:18 step:14206 [D loss: 0.441384, acc: 85.94%] [G loss: 3.155445]\n",
      "epoch:18 step:14207 [D loss: 0.578506, acc: 75.78%] [G loss: 3.200168]\n",
      "epoch:18 step:14208 [D loss: 0.668912, acc: 57.81%] [G loss: 3.071292]\n",
      "epoch:18 step:14209 [D loss: 0.498664, acc: 78.91%] [G loss: 2.368677]\n",
      "epoch:18 step:14210 [D loss: 0.764595, acc: 49.22%] [G loss: 2.723235]\n",
      "epoch:18 step:14211 [D loss: 0.486388, acc: 83.59%] [G loss: 2.444350]\n",
      "epoch:18 step:14212 [D loss: 0.496993, acc: 67.19%] [G loss: 2.770662]\n",
      "epoch:18 step:14213 [D loss: 0.373904, acc: 93.75%] [G loss: 2.372506]\n",
      "epoch:18 step:14214 [D loss: 0.461609, acc: 80.47%] [G loss: 2.203272]\n",
      "epoch:18 step:14215 [D loss: 0.652791, acc: 64.06%] [G loss: 2.906343]\n",
      "epoch:18 step:14216 [D loss: 0.697267, acc: 53.12%] [G loss: 2.678665]\n",
      "epoch:18 step:14217 [D loss: 0.514644, acc: 73.44%] [G loss: 2.836098]\n",
      "epoch:18 step:14218 [D loss: 0.686431, acc: 60.94%] [G loss: 2.906321]\n",
      "epoch:18 step:14219 [D loss: 0.616443, acc: 68.75%] [G loss: 3.573455]\n",
      "epoch:18 step:14220 [D loss: 0.207647, acc: 99.22%] [G loss: 3.724485]\n",
      "epoch:18 step:14221 [D loss: 0.348758, acc: 92.97%] [G loss: 3.593410]\n",
      "epoch:18 step:14222 [D loss: 0.389920, acc: 88.28%] [G loss: 2.798371]\n",
      "epoch:18 step:14223 [D loss: 0.403632, acc: 90.62%] [G loss: 3.110814]\n",
      "epoch:18 step:14224 [D loss: 0.437419, acc: 88.28%] [G loss: 3.575044]\n",
      "epoch:18 step:14225 [D loss: 0.573796, acc: 68.75%] [G loss: 3.200957]\n",
      "epoch:18 step:14226 [D loss: 0.132477, acc: 100.00%] [G loss: 2.771288]\n",
      "epoch:18 step:14227 [D loss: 0.625767, acc: 64.84%] [G loss: 2.571589]\n",
      "epoch:18 step:14228 [D loss: 0.551987, acc: 75.00%] [G loss: 3.118759]\n",
      "epoch:18 step:14229 [D loss: 0.588514, acc: 60.16%] [G loss: 2.791995]\n",
      "epoch:18 step:14230 [D loss: 0.422645, acc: 81.25%] [G loss: 2.601802]\n",
      "epoch:18 step:14231 [D loss: 1.391489, acc: 5.47%] [G loss: 1.430763]\n",
      "epoch:18 step:14232 [D loss: 0.420374, acc: 89.84%] [G loss: 2.233857]\n",
      "epoch:18 step:14233 [D loss: 0.168313, acc: 99.22%] [G loss: 3.047201]\n",
      "epoch:18 step:14234 [D loss: 0.886322, acc: 32.81%] [G loss: 2.407058]\n",
      "epoch:18 step:14235 [D loss: 0.351721, acc: 92.19%] [G loss: 3.059126]\n",
      "epoch:18 step:14236 [D loss: 0.974734, acc: 32.03%] [G loss: 1.856763]\n",
      "epoch:18 step:14237 [D loss: 0.814883, acc: 42.19%] [G loss: 1.774110]\n",
      "epoch:18 step:14238 [D loss: 0.945706, acc: 29.69%] [G loss: 2.245179]\n",
      "epoch:18 step:14239 [D loss: 0.207104, acc: 96.88%] [G loss: 4.386382]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14240 [D loss: 0.324383, acc: 93.75%] [G loss: 2.604162]\n",
      "epoch:18 step:14241 [D loss: 0.464533, acc: 77.34%] [G loss: 2.984391]\n",
      "epoch:18 step:14242 [D loss: 0.371916, acc: 82.81%] [G loss: 3.476440]\n",
      "epoch:18 step:14243 [D loss: 0.511042, acc: 71.09%] [G loss: 4.338996]\n",
      "epoch:18 step:14244 [D loss: 0.416779, acc: 84.38%] [G loss: 2.285536]\n",
      "epoch:18 step:14245 [D loss: 0.540544, acc: 67.19%] [G loss: 3.062864]\n",
      "epoch:18 step:14246 [D loss: 0.493090, acc: 85.94%] [G loss: 3.144357]\n",
      "epoch:18 step:14247 [D loss: 0.217103, acc: 100.00%] [G loss: 3.882741]\n",
      "epoch:18 step:14248 [D loss: 0.750120, acc: 54.69%] [G loss: 3.144192]\n",
      "epoch:18 step:14249 [D loss: 0.559881, acc: 67.97%] [G loss: 2.896410]\n",
      "epoch:18 step:14250 [D loss: 0.486208, acc: 82.03%] [G loss: 3.064146]\n",
      "epoch:18 step:14251 [D loss: 0.394046, acc: 92.19%] [G loss: 2.945599]\n",
      "epoch:18 step:14252 [D loss: 0.541927, acc: 78.91%] [G loss: 3.408166]\n",
      "epoch:18 step:14253 [D loss: 0.604308, acc: 66.41%] [G loss: 2.605002]\n",
      "epoch:18 step:14254 [D loss: 0.526103, acc: 71.88%] [G loss: 2.535389]\n",
      "epoch:18 step:14255 [D loss: 0.592623, acc: 61.72%] [G loss: 2.235908]\n",
      "epoch:18 step:14256 [D loss: 0.549573, acc: 71.09%] [G loss: 2.812963]\n",
      "epoch:18 step:14257 [D loss: 1.157910, acc: 13.28%] [G loss: 2.199068]\n",
      "epoch:18 step:14258 [D loss: 0.688074, acc: 62.50%] [G loss: 2.862867]\n",
      "epoch:18 step:14259 [D loss: 0.383700, acc: 81.25%] [G loss: 2.370665]\n",
      "epoch:18 step:14260 [D loss: 1.273058, acc: 24.22%] [G loss: 1.635546]\n",
      "epoch:18 step:14261 [D loss: 0.743998, acc: 52.34%] [G loss: 2.511102]\n",
      "epoch:18 step:14262 [D loss: 0.373334, acc: 92.97%] [G loss: 3.557512]\n",
      "epoch:18 step:14263 [D loss: 0.738517, acc: 52.34%] [G loss: 2.378358]\n",
      "epoch:18 step:14264 [D loss: 0.951132, acc: 33.59%] [G loss: 3.627144]\n",
      "epoch:18 step:14265 [D loss: 0.296586, acc: 96.09%] [G loss: 2.962995]\n",
      "epoch:18 step:14266 [D loss: 0.304198, acc: 93.75%] [G loss: 3.329415]\n",
      "epoch:18 step:14267 [D loss: 0.354060, acc: 96.09%] [G loss: 2.685771]\n",
      "epoch:18 step:14268 [D loss: 0.221620, acc: 96.88%] [G loss: 4.161086]\n",
      "epoch:18 step:14269 [D loss: 0.345316, acc: 96.88%] [G loss: 2.984233]\n",
      "epoch:18 step:14270 [D loss: 0.559091, acc: 69.53%] [G loss: 3.042088]\n",
      "epoch:18 step:14271 [D loss: 0.825965, acc: 46.88%] [G loss: 4.236791]\n",
      "epoch:18 step:14272 [D loss: 0.524534, acc: 71.88%] [G loss: 2.681431]\n",
      "epoch:18 step:14273 [D loss: 0.503109, acc: 86.72%] [G loss: 2.611865]\n",
      "epoch:18 step:14274 [D loss: 0.190266, acc: 100.00%] [G loss: 4.138842]\n",
      "epoch:18 step:14275 [D loss: 0.402901, acc: 79.69%] [G loss: 2.906035]\n",
      "epoch:18 step:14276 [D loss: 0.668480, acc: 56.25%] [G loss: 2.625699]\n",
      "epoch:18 step:14277 [D loss: 0.272959, acc: 96.88%] [G loss: 3.465927]\n",
      "epoch:18 step:14278 [D loss: 0.471082, acc: 85.94%] [G loss: 2.482105]\n",
      "epoch:18 step:14279 [D loss: 0.711252, acc: 57.81%] [G loss: 2.782840]\n",
      "epoch:18 step:14280 [D loss: 0.641343, acc: 64.06%] [G loss: 3.131362]\n",
      "epoch:18 step:14281 [D loss: 0.387767, acc: 89.84%] [G loss: 2.358127]\n",
      "epoch:18 step:14282 [D loss: 0.553604, acc: 73.44%] [G loss: 2.580921]\n",
      "epoch:18 step:14283 [D loss: 0.601518, acc: 63.28%] [G loss: 2.364394]\n",
      "epoch:18 step:14284 [D loss: 0.526818, acc: 64.84%] [G loss: 3.616539]\n",
      "epoch:18 step:14285 [D loss: 0.612042, acc: 71.09%] [G loss: 3.101924]\n",
      "epoch:18 step:14286 [D loss: 0.453695, acc: 82.81%] [G loss: 1.983090]\n",
      "epoch:18 step:14287 [D loss: 0.725893, acc: 52.34%] [G loss: 2.768381]\n",
      "epoch:18 step:14288 [D loss: 0.365005, acc: 89.84%] [G loss: 3.763518]\n",
      "epoch:18 step:14289 [D loss: 0.792118, acc: 51.56%] [G loss: 2.656984]\n",
      "epoch:18 step:14290 [D loss: 0.626337, acc: 55.47%] [G loss: 2.867736]\n",
      "epoch:18 step:14291 [D loss: 0.524122, acc: 70.31%] [G loss: 2.748787]\n",
      "epoch:18 step:14292 [D loss: 0.657650, acc: 60.16%] [G loss: 3.068285]\n",
      "epoch:18 step:14293 [D loss: 0.585496, acc: 75.78%] [G loss: 3.004589]\n",
      "epoch:18 step:14294 [D loss: 0.847002, acc: 35.16%] [G loss: 2.812502]\n",
      "epoch:18 step:14295 [D loss: 0.471574, acc: 73.44%] [G loss: 2.981179]\n",
      "epoch:18 step:14296 [D loss: 0.496710, acc: 78.91%] [G loss: 3.233132]\n",
      "epoch:18 step:14297 [D loss: 0.349435, acc: 92.97%] [G loss: 3.444171]\n",
      "epoch:18 step:14298 [D loss: 0.683041, acc: 62.50%] [G loss: 2.532748]\n",
      "epoch:18 step:14299 [D loss: 0.383181, acc: 87.50%] [G loss: 3.154771]\n",
      "epoch:18 step:14300 [D loss: 0.697164, acc: 56.25%] [G loss: 2.663270]\n",
      "epoch:18 step:14301 [D loss: 0.294664, acc: 98.44%] [G loss: 2.946836]\n",
      "epoch:18 step:14302 [D loss: 0.819666, acc: 47.66%] [G loss: 2.355724]\n",
      "epoch:18 step:14303 [D loss: 1.094262, acc: 29.69%] [G loss: 2.578037]\n",
      "epoch:18 step:14304 [D loss: 0.638489, acc: 66.41%] [G loss: 2.354172]\n",
      "epoch:18 step:14305 [D loss: 0.552055, acc: 69.53%] [G loss: 2.625961]\n",
      "epoch:18 step:14306 [D loss: 0.294062, acc: 93.75%] [G loss: 1.998876]\n",
      "epoch:18 step:14307 [D loss: 0.384712, acc: 88.28%] [G loss: 2.821072]\n",
      "epoch:18 step:14308 [D loss: 0.776007, acc: 52.34%] [G loss: 3.396122]\n",
      "epoch:18 step:14309 [D loss: 0.426377, acc: 84.38%] [G loss: 3.192775]\n",
      "epoch:18 step:14310 [D loss: 0.391543, acc: 83.59%] [G loss: 3.360208]\n",
      "epoch:18 step:14311 [D loss: 0.608516, acc: 61.72%] [G loss: 2.703782]\n",
      "epoch:18 step:14312 [D loss: 0.280185, acc: 86.72%] [G loss: 3.255933]\n",
      "epoch:18 step:14313 [D loss: 0.395031, acc: 81.25%] [G loss: 2.528267]\n",
      "epoch:18 step:14314 [D loss: 0.246336, acc: 98.44%] [G loss: 2.736791]\n",
      "epoch:18 step:14315 [D loss: 0.905123, acc: 40.62%] [G loss: 3.322535]\n",
      "epoch:18 step:14316 [D loss: 0.758802, acc: 50.00%] [G loss: 2.462562]\n",
      "epoch:18 step:14317 [D loss: 0.386469, acc: 87.50%] [G loss: 1.974440]\n",
      "epoch:18 step:14318 [D loss: 0.458046, acc: 76.56%] [G loss: 2.407270]\n",
      "epoch:18 step:14319 [D loss: 0.577427, acc: 69.53%] [G loss: 2.454820]\n",
      "epoch:18 step:14320 [D loss: 0.243017, acc: 97.66%] [G loss: 3.227854]\n",
      "epoch:18 step:14321 [D loss: 0.987060, acc: 35.94%] [G loss: 1.962781]\n",
      "epoch:18 step:14322 [D loss: 0.526947, acc: 79.69%] [G loss: 2.774616]\n",
      "epoch:18 step:14323 [D loss: 0.190133, acc: 99.22%] [G loss: 3.105971]\n",
      "epoch:18 step:14324 [D loss: 0.677145, acc: 58.59%] [G loss: 2.529400]\n",
      "epoch:18 step:14325 [D loss: 1.413595, acc: 36.72%] [G loss: 2.044267]\n",
      "epoch:18 step:14326 [D loss: 0.438156, acc: 87.50%] [G loss: 4.132010]\n",
      "epoch:18 step:14327 [D loss: 0.981352, acc: 27.34%] [G loss: 2.888976]\n",
      "epoch:18 step:14328 [D loss: 0.449435, acc: 74.22%] [G loss: 3.447866]\n",
      "epoch:18 step:14329 [D loss: 0.735276, acc: 51.56%] [G loss: 2.418617]\n",
      "epoch:18 step:14330 [D loss: 1.225480, acc: 20.31%] [G loss: 3.181099]\n",
      "epoch:18 step:14331 [D loss: 0.696483, acc: 59.38%] [G loss: 2.882953]\n",
      "epoch:18 step:14332 [D loss: 0.414886, acc: 82.03%] [G loss: 2.218207]\n",
      "epoch:18 step:14333 [D loss: 0.943922, acc: 23.44%] [G loss: 3.078398]\n",
      "epoch:18 step:14334 [D loss: 0.540906, acc: 76.56%] [G loss: 3.146594]\n",
      "epoch:18 step:14335 [D loss: 0.432166, acc: 82.81%] [G loss: 2.929421]\n",
      "epoch:18 step:14336 [D loss: 0.279167, acc: 99.22%] [G loss: 3.533609]\n",
      "epoch:18 step:14337 [D loss: 0.274859, acc: 96.88%] [G loss: 2.669108]\n",
      "epoch:18 step:14338 [D loss: 0.504571, acc: 78.91%] [G loss: 2.718723]\n",
      "epoch:18 step:14339 [D loss: 0.726849, acc: 54.69%] [G loss: 2.289779]\n",
      "epoch:18 step:14340 [D loss: 0.823308, acc: 46.09%] [G loss: 2.420920]\n",
      "epoch:18 step:14341 [D loss: 0.548644, acc: 70.31%] [G loss: 3.871715]\n",
      "epoch:18 step:14342 [D loss: 0.391987, acc: 92.19%] [G loss: 2.938743]\n",
      "epoch:18 step:14343 [D loss: 0.392350, acc: 89.84%] [G loss: 2.930959]\n",
      "epoch:18 step:14344 [D loss: 0.366210, acc: 85.94%] [G loss: 3.333425]\n",
      "epoch:18 step:14345 [D loss: 0.262618, acc: 98.44%] [G loss: 2.439751]\n",
      "epoch:18 step:14346 [D loss: 0.419248, acc: 82.81%] [G loss: 3.705200]\n",
      "epoch:18 step:14347 [D loss: 0.286425, acc: 96.88%] [G loss: 1.887099]\n",
      "epoch:18 step:14348 [D loss: 0.496011, acc: 72.66%] [G loss: 2.413121]\n",
      "epoch:18 step:14349 [D loss: 0.495732, acc: 68.75%] [G loss: 3.236802]\n",
      "epoch:18 step:14350 [D loss: 0.622096, acc: 63.28%] [G loss: 2.315246]\n",
      "epoch:18 step:14351 [D loss: 0.970462, acc: 50.78%] [G loss: 3.019215]\n",
      "epoch:18 step:14352 [D loss: 0.689409, acc: 61.72%] [G loss: 2.328346]\n",
      "epoch:18 step:14353 [D loss: 1.208036, acc: 25.00%] [G loss: 1.906847]\n",
      "epoch:18 step:14354 [D loss: 0.151776, acc: 99.22%] [G loss: 3.588540]\n",
      "epoch:18 step:14355 [D loss: 0.620688, acc: 63.28%] [G loss: 1.964360]\n",
      "epoch:18 step:14356 [D loss: 0.345911, acc: 94.53%] [G loss: 3.088473]\n",
      "epoch:18 step:14357 [D loss: 0.369003, acc: 91.41%] [G loss: 2.949640]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14358 [D loss: 1.082938, acc: 39.84%] [G loss: 2.079083]\n",
      "epoch:18 step:14359 [D loss: 1.251465, acc: 17.97%] [G loss: 2.238345]\n",
      "epoch:18 step:14360 [D loss: 0.489466, acc: 75.78%] [G loss: 2.344791]\n",
      "epoch:18 step:14361 [D loss: 0.231162, acc: 96.88%] [G loss: 3.377489]\n",
      "epoch:18 step:14362 [D loss: 0.433190, acc: 85.16%] [G loss: 2.607714]\n",
      "epoch:18 step:14363 [D loss: 0.807778, acc: 46.09%] [G loss: 2.484626]\n",
      "epoch:18 step:14364 [D loss: 0.651968, acc: 67.97%] [G loss: 2.221541]\n",
      "epoch:18 step:14365 [D loss: 0.291379, acc: 96.88%] [G loss: 2.455095]\n",
      "epoch:18 step:14366 [D loss: 0.652116, acc: 64.84%] [G loss: 1.759037]\n",
      "epoch:18 step:14367 [D loss: 0.429908, acc: 85.16%] [G loss: 2.390538]\n",
      "epoch:18 step:14368 [D loss: 0.523803, acc: 75.78%] [G loss: 3.133862]\n",
      "epoch:18 step:14369 [D loss: 0.529591, acc: 68.75%] [G loss: 2.261930]\n",
      "epoch:18 step:14370 [D loss: 0.491889, acc: 74.22%] [G loss: 3.252637]\n",
      "epoch:18 step:14371 [D loss: 0.667748, acc: 56.25%] [G loss: 2.843872]\n",
      "epoch:18 step:14372 [D loss: 0.540248, acc: 73.44%] [G loss: 1.773074]\n",
      "epoch:18 step:14373 [D loss: 1.073468, acc: 50.00%] [G loss: 2.246116]\n",
      "epoch:18 step:14374 [D loss: 0.601882, acc: 59.38%] [G loss: 2.333536]\n",
      "epoch:18 step:14375 [D loss: 0.584686, acc: 75.00%] [G loss: 2.923511]\n",
      "epoch:18 step:14376 [D loss: 0.737631, acc: 54.69%] [G loss: 2.379159]\n",
      "epoch:18 step:14377 [D loss: 0.562460, acc: 69.53%] [G loss: 2.646616]\n",
      "epoch:18 step:14378 [D loss: 0.388357, acc: 84.38%] [G loss: 2.869261]\n",
      "epoch:18 step:14379 [D loss: 0.615173, acc: 61.72%] [G loss: 3.218386]\n",
      "epoch:18 step:14380 [D loss: 0.672567, acc: 58.59%] [G loss: 2.770568]\n",
      "epoch:18 step:14381 [D loss: 0.714180, acc: 50.00%] [G loss: 2.336202]\n",
      "epoch:18 step:14382 [D loss: 0.562308, acc: 70.31%] [G loss: 2.602148]\n",
      "epoch:18 step:14383 [D loss: 0.617438, acc: 65.62%] [G loss: 2.688558]\n",
      "epoch:18 step:14384 [D loss: 0.571579, acc: 75.78%] [G loss: 2.535203]\n",
      "epoch:18 step:14385 [D loss: 0.751813, acc: 57.03%] [G loss: 2.492217]\n",
      "epoch:18 step:14386 [D loss: 0.337382, acc: 94.53%] [G loss: 4.460941]\n",
      "epoch:18 step:14387 [D loss: 0.846455, acc: 46.88%] [G loss: 2.631827]\n",
      "epoch:18 step:14388 [D loss: 0.726083, acc: 55.47%] [G loss: 2.497834]\n",
      "epoch:18 step:14389 [D loss: 0.638884, acc: 63.28%] [G loss: 3.635236]\n",
      "epoch:18 step:14390 [D loss: 0.427072, acc: 88.28%] [G loss: 3.068161]\n",
      "epoch:18 step:14391 [D loss: 0.496824, acc: 63.28%] [G loss: 3.500183]\n",
      "epoch:18 step:14392 [D loss: 0.530073, acc: 77.34%] [G loss: 2.517861]\n",
      "epoch:18 step:14393 [D loss: 0.301315, acc: 97.66%] [G loss: 3.905839]\n",
      "epoch:18 step:14394 [D loss: 0.965946, acc: 50.78%] [G loss: 3.203511]\n",
      "epoch:18 step:14395 [D loss: 0.554225, acc: 77.34%] [G loss: 2.798436]\n",
      "epoch:18 step:14396 [D loss: 0.575687, acc: 65.62%] [G loss: 2.192231]\n",
      "epoch:18 step:14397 [D loss: 0.845684, acc: 37.50%] [G loss: 2.225221]\n",
      "epoch:18 step:14398 [D loss: 0.368903, acc: 86.72%] [G loss: 2.463892]\n",
      "epoch:18 step:14399 [D loss: 0.476115, acc: 86.72%] [G loss: 2.923349]\n",
      "epoch:18 step:14400 [D loss: 0.303297, acc: 91.41%] [G loss: 2.581349]\n",
      "epoch:18 step:14401 [D loss: 0.201994, acc: 99.22%] [G loss: 3.023223]\n",
      "epoch:18 step:14402 [D loss: 0.364949, acc: 90.62%] [G loss: 3.592305]\n",
      "epoch:18 step:14403 [D loss: 0.475257, acc: 82.81%] [G loss: 2.044658]\n",
      "epoch:18 step:14404 [D loss: 0.403459, acc: 90.62%] [G loss: 3.446626]\n",
      "epoch:18 step:14405 [D loss: 0.241670, acc: 96.88%] [G loss: 3.104435]\n",
      "epoch:18 step:14406 [D loss: 0.399063, acc: 89.84%] [G loss: 3.166078]\n",
      "epoch:18 step:14407 [D loss: 0.253561, acc: 97.66%] [G loss: 2.804025]\n",
      "epoch:18 step:14408 [D loss: 0.356205, acc: 89.06%] [G loss: 2.397748]\n",
      "epoch:18 step:14409 [D loss: 0.838584, acc: 42.97%] [G loss: 2.023794]\n",
      "epoch:18 step:14410 [D loss: 0.210490, acc: 98.44%] [G loss: 2.957645]\n",
      "epoch:18 step:14411 [D loss: 0.448460, acc: 83.59%] [G loss: 2.976860]\n",
      "epoch:18 step:14412 [D loss: 0.965553, acc: 45.31%] [G loss: 3.080179]\n",
      "epoch:18 step:14413 [D loss: 0.789729, acc: 43.75%] [G loss: 2.788294]\n",
      "epoch:18 step:14414 [D loss: 0.824945, acc: 52.34%] [G loss: 2.504548]\n",
      "epoch:18 step:14415 [D loss: 0.310663, acc: 97.66%] [G loss: 3.699825]\n",
      "epoch:18 step:14416 [D loss: 0.958763, acc: 36.72%] [G loss: 2.238893]\n",
      "epoch:18 step:14417 [D loss: 0.789682, acc: 42.97%] [G loss: 2.294786]\n",
      "epoch:18 step:14418 [D loss: 0.833513, acc: 52.34%] [G loss: 2.692262]\n",
      "epoch:18 step:14419 [D loss: 0.445295, acc: 90.62%] [G loss: 2.767815]\n",
      "epoch:18 step:14420 [D loss: 0.479378, acc: 79.69%] [G loss: 2.841982]\n",
      "epoch:18 step:14421 [D loss: 0.717839, acc: 57.03%] [G loss: 2.897909]\n",
      "epoch:18 step:14422 [D loss: 0.614941, acc: 64.84%] [G loss: 3.428432]\n",
      "epoch:18 step:14423 [D loss: 0.440164, acc: 76.56%] [G loss: 3.216452]\n",
      "epoch:18 step:14424 [D loss: 0.882812, acc: 31.25%] [G loss: 2.362383]\n",
      "epoch:18 step:14425 [D loss: 0.335299, acc: 94.53%] [G loss: 2.738678]\n",
      "epoch:18 step:14426 [D loss: 0.497593, acc: 78.91%] [G loss: 2.791897]\n",
      "epoch:18 step:14427 [D loss: 0.425208, acc: 76.56%] [G loss: 3.107183]\n",
      "epoch:18 step:14428 [D loss: 0.577591, acc: 63.28%] [G loss: 3.155988]\n",
      "epoch:18 step:14429 [D loss: 0.397704, acc: 91.41%] [G loss: 3.112042]\n",
      "epoch:18 step:14430 [D loss: 0.413402, acc: 88.28%] [G loss: 3.938885]\n",
      "epoch:18 step:14431 [D loss: 1.060635, acc: 47.66%] [G loss: 2.494166]\n",
      "epoch:18 step:14432 [D loss: 0.280357, acc: 96.09%] [G loss: 3.623858]\n",
      "epoch:18 step:14433 [D loss: 0.625212, acc: 58.59%] [G loss: 2.334144]\n",
      "epoch:18 step:14434 [D loss: 0.254824, acc: 97.66%] [G loss: 2.910263]\n",
      "epoch:18 step:14435 [D loss: 0.254159, acc: 95.31%] [G loss: 2.685356]\n",
      "epoch:18 step:14436 [D loss: 0.420990, acc: 89.06%] [G loss: 3.189314]\n",
      "epoch:18 step:14437 [D loss: 0.250197, acc: 96.88%] [G loss: 3.271546]\n",
      "epoch:18 step:14438 [D loss: 0.471050, acc: 78.91%] [G loss: 4.584145]\n",
      "epoch:18 step:14439 [D loss: 0.732862, acc: 55.47%] [G loss: 2.527565]\n",
      "epoch:18 step:14440 [D loss: 0.399835, acc: 78.91%] [G loss: 3.016630]\n",
      "epoch:18 step:14441 [D loss: 0.443271, acc: 88.28%] [G loss: 3.059517]\n",
      "epoch:18 step:14442 [D loss: 0.192318, acc: 97.66%] [G loss: 3.516425]\n",
      "epoch:18 step:14443 [D loss: 0.715405, acc: 54.69%] [G loss: 2.774269]\n",
      "epoch:18 step:14444 [D loss: 0.768429, acc: 53.91%] [G loss: 2.508402]\n",
      "epoch:18 step:14445 [D loss: 0.752853, acc: 48.44%] [G loss: 2.333208]\n",
      "epoch:18 step:14446 [D loss: 1.074257, acc: 25.00%] [G loss: 2.506448]\n",
      "epoch:18 step:14447 [D loss: 0.681296, acc: 61.72%] [G loss: 3.500350]\n",
      "epoch:18 step:14448 [D loss: 0.408255, acc: 92.97%] [G loss: 2.149540]\n",
      "epoch:18 step:14449 [D loss: 1.021368, acc: 48.44%] [G loss: 2.181186]\n",
      "epoch:18 step:14450 [D loss: 0.514204, acc: 64.84%] [G loss: 2.765087]\n",
      "epoch:18 step:14451 [D loss: 0.498132, acc: 72.66%] [G loss: 2.534724]\n",
      "epoch:18 step:14452 [D loss: 0.440622, acc: 81.25%] [G loss: 2.348143]\n",
      "epoch:18 step:14453 [D loss: 0.721201, acc: 56.25%] [G loss: 2.472605]\n",
      "epoch:18 step:14454 [D loss: 0.527358, acc: 70.31%] [G loss: 2.321767]\n",
      "epoch:18 step:14455 [D loss: 0.835837, acc: 47.66%] [G loss: 1.986089]\n",
      "epoch:18 step:14456 [D loss: 0.424862, acc: 90.62%] [G loss: 3.266855]\n",
      "epoch:18 step:14457 [D loss: 0.251431, acc: 98.44%] [G loss: 2.898815]\n",
      "epoch:18 step:14458 [D loss: 0.402600, acc: 87.50%] [G loss: 2.632879]\n",
      "epoch:18 step:14459 [D loss: 0.364383, acc: 95.31%] [G loss: 3.551316]\n",
      "epoch:18 step:14460 [D loss: 0.534944, acc: 68.75%] [G loss: 3.217251]\n",
      "epoch:18 step:14461 [D loss: 0.394672, acc: 91.41%] [G loss: 3.300345]\n",
      "epoch:18 step:14462 [D loss: 0.612770, acc: 63.28%] [G loss: 2.286968]\n",
      "epoch:18 step:14463 [D loss: 0.618973, acc: 64.84%] [G loss: 2.865357]\n",
      "epoch:18 step:14464 [D loss: 0.618672, acc: 67.97%] [G loss: 2.642060]\n",
      "epoch:18 step:14465 [D loss: 0.638191, acc: 62.50%] [G loss: 2.210260]\n",
      "epoch:18 step:14466 [D loss: 0.374875, acc: 85.94%] [G loss: 2.559928]\n",
      "epoch:18 step:14467 [D loss: 0.526139, acc: 70.31%] [G loss: 2.613164]\n",
      "epoch:18 step:14468 [D loss: 0.457944, acc: 85.94%] [G loss: 3.582820]\n",
      "epoch:18 step:14469 [D loss: 0.486562, acc: 81.25%] [G loss: 2.898772]\n",
      "epoch:18 step:14470 [D loss: 0.570417, acc: 73.44%] [G loss: 3.167383]\n",
      "epoch:18 step:14471 [D loss: 0.743601, acc: 53.12%] [G loss: 2.893250]\n",
      "epoch:18 step:14472 [D loss: 0.601294, acc: 68.75%] [G loss: 3.392223]\n",
      "epoch:18 step:14473 [D loss: 0.669387, acc: 64.06%] [G loss: 2.778615]\n",
      "epoch:18 step:14474 [D loss: 0.485673, acc: 80.47%] [G loss: 2.752250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14475 [D loss: 0.555375, acc: 71.88%] [G loss: 2.359633]\n",
      "epoch:18 step:14476 [D loss: 0.306516, acc: 96.88%] [G loss: 2.986994]\n",
      "epoch:18 step:14477 [D loss: 0.542262, acc: 68.75%] [G loss: 2.941375]\n",
      "epoch:18 step:14478 [D loss: 0.551284, acc: 68.75%] [G loss: 3.035760]\n",
      "epoch:18 step:14479 [D loss: 0.669567, acc: 63.28%] [G loss: 2.341731]\n",
      "epoch:18 step:14480 [D loss: 0.407736, acc: 90.62%] [G loss: 2.439953]\n",
      "epoch:18 step:14481 [D loss: 0.333551, acc: 88.28%] [G loss: 2.974288]\n",
      "epoch:18 step:14482 [D loss: 0.458610, acc: 82.03%] [G loss: 3.318699]\n",
      "epoch:18 step:14483 [D loss: 0.837008, acc: 49.22%] [G loss: 2.431038]\n",
      "epoch:18 step:14484 [D loss: 0.497778, acc: 82.03%] [G loss: 3.106055]\n",
      "epoch:18 step:14485 [D loss: 0.384398, acc: 90.62%] [G loss: 2.989745]\n",
      "epoch:18 step:14486 [D loss: 0.686580, acc: 60.94%] [G loss: 3.021601]\n",
      "epoch:18 step:14487 [D loss: 0.180216, acc: 97.66%] [G loss: 4.357830]\n",
      "epoch:18 step:14488 [D loss: 0.927466, acc: 39.84%] [G loss: 2.957749]\n",
      "epoch:18 step:14489 [D loss: 0.581875, acc: 66.41%] [G loss: 3.900851]\n",
      "epoch:18 step:14490 [D loss: 0.242265, acc: 91.41%] [G loss: 3.231777]\n",
      "epoch:18 step:14491 [D loss: 0.764275, acc: 45.31%] [G loss: 2.857183]\n",
      "epoch:18 step:14492 [D loss: 0.437566, acc: 89.84%] [G loss: 1.982517]\n",
      "epoch:18 step:14493 [D loss: 0.363305, acc: 82.81%] [G loss: 1.915606]\n",
      "epoch:18 step:14494 [D loss: 0.668340, acc: 58.59%] [G loss: 2.067744]\n",
      "epoch:18 step:14495 [D loss: 1.328051, acc: 8.59%] [G loss: 2.901238]\n",
      "epoch:18 step:14496 [D loss: 0.244999, acc: 98.44%] [G loss: 3.261459]\n",
      "epoch:18 step:14497 [D loss: 0.631430, acc: 59.38%] [G loss: 2.853603]\n",
      "epoch:18 step:14498 [D loss: 0.701342, acc: 54.69%] [G loss: 2.325864]\n",
      "epoch:18 step:14499 [D loss: 0.445849, acc: 89.06%] [G loss: 2.943343]\n",
      "epoch:18 step:14500 [D loss: 0.658821, acc: 63.28%] [G loss: 2.268368]\n",
      "epoch:18 step:14501 [D loss: 0.761918, acc: 46.88%] [G loss: 3.194028]\n",
      "epoch:18 step:14502 [D loss: 0.637653, acc: 62.50%] [G loss: 3.220364]\n",
      "epoch:18 step:14503 [D loss: 0.655952, acc: 57.03%] [G loss: 1.959750]\n",
      "epoch:18 step:14504 [D loss: 0.359052, acc: 94.53%] [G loss: 2.612606]\n",
      "epoch:18 step:14505 [D loss: 0.732234, acc: 54.69%] [G loss: 2.266819]\n",
      "epoch:18 step:14506 [D loss: 0.347938, acc: 92.97%] [G loss: 4.456929]\n",
      "epoch:18 step:14507 [D loss: 0.351588, acc: 89.06%] [G loss: 2.989601]\n",
      "epoch:18 step:14508 [D loss: 0.542524, acc: 75.78%] [G loss: 3.289932]\n",
      "epoch:18 step:14509 [D loss: 0.295008, acc: 96.88%] [G loss: 2.888013]\n",
      "epoch:18 step:14510 [D loss: 0.309683, acc: 89.84%] [G loss: 2.726979]\n",
      "epoch:18 step:14511 [D loss: 0.556218, acc: 79.69%] [G loss: 1.890769]\n",
      "epoch:18 step:14512 [D loss: 0.677417, acc: 57.03%] [G loss: 2.299400]\n",
      "epoch:18 step:14513 [D loss: 0.375393, acc: 93.75%] [G loss: 2.905861]\n",
      "epoch:18 step:14514 [D loss: 0.821516, acc: 46.09%] [G loss: 3.360352]\n",
      "epoch:18 step:14515 [D loss: 0.750179, acc: 53.91%] [G loss: 2.992824]\n",
      "epoch:18 step:14516 [D loss: 0.808790, acc: 51.56%] [G loss: 3.703687]\n",
      "epoch:18 step:14517 [D loss: 0.699969, acc: 56.25%] [G loss: 3.024963]\n",
      "epoch:18 step:14518 [D loss: 0.366178, acc: 88.28%] [G loss: 2.692073]\n",
      "epoch:18 step:14519 [D loss: 0.475007, acc: 84.38%] [G loss: 2.624705]\n",
      "epoch:18 step:14520 [D loss: 0.303279, acc: 94.53%] [G loss: 4.372975]\n",
      "epoch:18 step:14521 [D loss: 0.807777, acc: 50.78%] [G loss: 3.217666]\n",
      "epoch:18 step:14522 [D loss: 0.251557, acc: 96.88%] [G loss: 3.287032]\n",
      "epoch:18 step:14523 [D loss: 0.342227, acc: 90.62%] [G loss: 2.420139]\n",
      "epoch:18 step:14524 [D loss: 0.090832, acc: 100.00%] [G loss: 4.283102]\n",
      "epoch:18 step:14525 [D loss: 0.546854, acc: 75.78%] [G loss: 3.070166]\n",
      "epoch:18 step:14526 [D loss: 0.851748, acc: 47.66%] [G loss: 2.800665]\n",
      "epoch:18 step:14527 [D loss: 0.550441, acc: 65.62%] [G loss: 3.226282]\n",
      "epoch:18 step:14528 [D loss: 0.448328, acc: 68.75%] [G loss: 3.236042]\n",
      "epoch:18 step:14529 [D loss: 0.630239, acc: 60.94%] [G loss: 2.847541]\n",
      "epoch:18 step:14530 [D loss: 0.501197, acc: 83.59%] [G loss: 3.030315]\n",
      "epoch:18 step:14531 [D loss: 0.393346, acc: 88.28%] [G loss: 2.630099]\n",
      "epoch:18 step:14532 [D loss: 0.548310, acc: 76.56%] [G loss: 3.083909]\n",
      "epoch:18 step:14533 [D loss: 0.273045, acc: 88.28%] [G loss: 3.373065]\n",
      "epoch:18 step:14534 [D loss: 0.597303, acc: 61.72%] [G loss: 3.062668]\n",
      "epoch:18 step:14535 [D loss: 0.278337, acc: 96.09%] [G loss: 3.262322]\n",
      "epoch:18 step:14536 [D loss: 0.402852, acc: 89.06%] [G loss: 3.233487]\n",
      "epoch:18 step:14537 [D loss: 0.541446, acc: 64.84%] [G loss: 4.581157]\n",
      "epoch:18 step:14538 [D loss: 0.855069, acc: 50.78%] [G loss: 2.347613]\n",
      "epoch:18 step:14539 [D loss: 0.576380, acc: 71.88%] [G loss: 2.015315]\n",
      "epoch:18 step:14540 [D loss: 0.811630, acc: 51.56%] [G loss: 2.674627]\n",
      "epoch:18 step:14541 [D loss: 0.972522, acc: 39.84%] [G loss: 1.971060]\n",
      "epoch:18 step:14542 [D loss: 0.756719, acc: 57.81%] [G loss: 2.743738]\n",
      "epoch:18 step:14543 [D loss: 1.047866, acc: 34.38%] [G loss: 2.510240]\n",
      "epoch:18 step:14544 [D loss: 0.513386, acc: 69.53%] [G loss: 2.234955]\n",
      "epoch:18 step:14545 [D loss: 0.851143, acc: 49.22%] [G loss: 2.147470]\n",
      "epoch:18 step:14546 [D loss: 0.556933, acc: 71.09%] [G loss: 2.739538]\n",
      "epoch:18 step:14547 [D loss: 0.434357, acc: 84.38%] [G loss: 3.461303]\n",
      "epoch:18 step:14548 [D loss: 0.483147, acc: 82.03%] [G loss: 3.759571]\n",
      "epoch:18 step:14549 [D loss: 0.439638, acc: 75.78%] [G loss: 2.925883]\n",
      "epoch:18 step:14550 [D loss: 0.145044, acc: 100.00%] [G loss: 3.788241]\n",
      "epoch:18 step:14551 [D loss: 0.677289, acc: 60.16%] [G loss: 3.742278]\n",
      "epoch:18 step:14552 [D loss: 0.254485, acc: 100.00%] [G loss: 3.677205]\n",
      "epoch:18 step:14553 [D loss: 0.284896, acc: 96.88%] [G loss: 2.922485]\n",
      "epoch:18 step:14554 [D loss: 0.239892, acc: 98.44%] [G loss: 2.516829]\n",
      "epoch:18 step:14555 [D loss: 0.299408, acc: 92.97%] [G loss: 3.452616]\n",
      "epoch:18 step:14556 [D loss: 0.353060, acc: 85.94%] [G loss: 3.842846]\n",
      "epoch:18 step:14557 [D loss: 0.894786, acc: 42.97%] [G loss: 2.364713]\n",
      "epoch:18 step:14558 [D loss: 0.978409, acc: 30.47%] [G loss: 2.206741]\n",
      "epoch:18 step:14559 [D loss: 0.315791, acc: 92.19%] [G loss: 2.689363]\n",
      "epoch:18 step:14560 [D loss: 0.577167, acc: 69.53%] [G loss: 2.832886]\n",
      "epoch:18 step:14561 [D loss: 0.461686, acc: 83.59%] [G loss: 2.305137]\n",
      "epoch:18 step:14562 [D loss: 0.352797, acc: 89.06%] [G loss: 3.194036]\n",
      "epoch:18 step:14563 [D loss: 0.382602, acc: 88.28%] [G loss: 3.982639]\n",
      "epoch:18 step:14564 [D loss: 0.786885, acc: 52.34%] [G loss: 3.275303]\n",
      "epoch:18 step:14565 [D loss: 0.414187, acc: 84.38%] [G loss: 3.067968]\n",
      "epoch:18 step:14566 [D loss: 0.399164, acc: 83.59%] [G loss: 2.941214]\n",
      "epoch:18 step:14567 [D loss: 0.405769, acc: 87.50%] [G loss: 3.919381]\n",
      "epoch:18 step:14568 [D loss: 0.257893, acc: 93.75%] [G loss: 4.617627]\n",
      "epoch:18 step:14569 [D loss: 0.285196, acc: 88.28%] [G loss: 3.895311]\n",
      "epoch:18 step:14570 [D loss: 0.189869, acc: 98.44%] [G loss: 3.361989]\n",
      "epoch:18 step:14571 [D loss: 0.869293, acc: 46.09%] [G loss: 1.998165]\n",
      "epoch:18 step:14572 [D loss: 1.215599, acc: 10.94%] [G loss: 2.059666]\n",
      "epoch:18 step:14573 [D loss: 0.336461, acc: 90.62%] [G loss: 2.645825]\n",
      "epoch:18 step:14574 [D loss: 0.753915, acc: 53.12%] [G loss: 4.169084]\n",
      "epoch:18 step:14575 [D loss: 0.531466, acc: 67.97%] [G loss: 3.062955]\n",
      "epoch:18 step:14576 [D loss: 0.601678, acc: 66.41%] [G loss: 2.992630]\n",
      "epoch:18 step:14577 [D loss: 0.699555, acc: 52.34%] [G loss: 2.782363]\n",
      "epoch:18 step:14578 [D loss: 0.458496, acc: 86.72%] [G loss: 3.921614]\n",
      "epoch:18 step:14579 [D loss: 1.168406, acc: 47.66%] [G loss: 1.945158]\n",
      "epoch:18 step:14580 [D loss: 0.548942, acc: 74.22%] [G loss: 2.105344]\n",
      "epoch:18 step:14581 [D loss: 0.795966, acc: 39.06%] [G loss: 2.845997]\n",
      "epoch:18 step:14582 [D loss: 0.906150, acc: 31.25%] [G loss: 1.601655]\n",
      "epoch:18 step:14583 [D loss: 0.352912, acc: 92.19%] [G loss: 2.434939]\n",
      "epoch:18 step:14584 [D loss: 0.826633, acc: 42.97%] [G loss: 2.558362]\n",
      "epoch:18 step:14585 [D loss: 0.996161, acc: 46.09%] [G loss: 2.715116]\n",
      "epoch:18 step:14586 [D loss: 0.543069, acc: 65.62%] [G loss: 3.160073]\n",
      "epoch:18 step:14587 [D loss: 0.399126, acc: 78.91%] [G loss: 2.687901]\n",
      "epoch:18 step:14588 [D loss: 0.670212, acc: 55.47%] [G loss: 2.577773]\n",
      "epoch:18 step:14589 [D loss: 0.514347, acc: 77.34%] [G loss: 2.430943]\n",
      "epoch:18 step:14590 [D loss: 0.824293, acc: 36.72%] [G loss: 1.965523]\n",
      "epoch:18 step:14591 [D loss: 0.692463, acc: 52.34%] [G loss: 2.571883]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14592 [D loss: 0.581820, acc: 72.66%] [G loss: 2.845908]\n",
      "epoch:18 step:14593 [D loss: 0.829333, acc: 41.41%] [G loss: 2.814833]\n",
      "epoch:18 step:14594 [D loss: 0.425978, acc: 76.56%] [G loss: 3.350473]\n",
      "epoch:18 step:14595 [D loss: 1.075350, acc: 16.41%] [G loss: 2.411292]\n",
      "epoch:18 step:14596 [D loss: 0.264695, acc: 94.53%] [G loss: 4.454186]\n",
      "epoch:18 step:14597 [D loss: 0.654058, acc: 60.94%] [G loss: 2.975815]\n",
      "epoch:18 step:14598 [D loss: 0.441310, acc: 82.81%] [G loss: 2.864482]\n",
      "epoch:18 step:14599 [D loss: 0.722967, acc: 52.34%] [G loss: 2.802352]\n",
      "epoch:18 step:14600 [D loss: 0.530832, acc: 78.12%] [G loss: 2.638822]\n",
      "epoch:18 step:14601 [D loss: 0.665260, acc: 60.94%] [G loss: 3.096813]\n",
      "epoch:18 step:14602 [D loss: 0.569857, acc: 64.84%] [G loss: 4.122264]\n",
      "epoch:18 step:14603 [D loss: 0.364343, acc: 91.41%] [G loss: 4.125030]\n",
      "epoch:18 step:14604 [D loss: 0.335274, acc: 96.88%] [G loss: 3.053119]\n",
      "epoch:18 step:14605 [D loss: 0.313465, acc: 95.31%] [G loss: 3.210216]\n",
      "epoch:18 step:14606 [D loss: 0.494637, acc: 83.59%] [G loss: 3.014613]\n",
      "epoch:18 step:14607 [D loss: 0.497849, acc: 78.91%] [G loss: 2.708579]\n",
      "epoch:18 step:14608 [D loss: 0.192898, acc: 97.66%] [G loss: 4.370762]\n",
      "epoch:18 step:14609 [D loss: 0.319456, acc: 96.88%] [G loss: 2.761516]\n",
      "epoch:18 step:14610 [D loss: 0.525984, acc: 78.12%] [G loss: 2.499796]\n",
      "epoch:18 step:14611 [D loss: 0.457029, acc: 78.91%] [G loss: 3.049277]\n",
      "epoch:18 step:14612 [D loss: 0.326485, acc: 93.75%] [G loss: 2.988210]\n",
      "epoch:18 step:14613 [D loss: 0.470775, acc: 78.91%] [G loss: 1.964348]\n",
      "epoch:18 step:14614 [D loss: 1.014219, acc: 21.09%] [G loss: 2.704092]\n",
      "epoch:18 step:14615 [D loss: 0.512784, acc: 71.09%] [G loss: 2.255639]\n",
      "epoch:18 step:14616 [D loss: 0.811420, acc: 50.78%] [G loss: 2.907517]\n",
      "epoch:18 step:14617 [D loss: 0.451818, acc: 82.03%] [G loss: 2.809959]\n",
      "epoch:18 step:14618 [D loss: 0.524279, acc: 78.91%] [G loss: 2.943951]\n",
      "epoch:18 step:14619 [D loss: 0.452384, acc: 75.00%] [G loss: 3.624029]\n",
      "epoch:18 step:14620 [D loss: 0.527399, acc: 75.78%] [G loss: 3.469150]\n",
      "epoch:18 step:14621 [D loss: 1.129044, acc: 12.50%] [G loss: 3.130605]\n",
      "epoch:18 step:14622 [D loss: 0.530411, acc: 70.31%] [G loss: 2.896466]\n",
      "epoch:18 step:14623 [D loss: 0.315028, acc: 84.38%] [G loss: 5.511140]\n",
      "epoch:18 step:14624 [D loss: 0.567376, acc: 71.88%] [G loss: 2.702678]\n",
      "epoch:18 step:14625 [D loss: 0.440329, acc: 85.94%] [G loss: 2.561564]\n",
      "epoch:18 step:14626 [D loss: 0.523821, acc: 78.12%] [G loss: 3.057622]\n",
      "epoch:18 step:14627 [D loss: 0.446251, acc: 78.91%] [G loss: 2.326799]\n",
      "epoch:18 step:14628 [D loss: 0.439788, acc: 84.38%] [G loss: 3.499444]\n",
      "epoch:18 step:14629 [D loss: 0.604135, acc: 71.09%] [G loss: 2.549006]\n",
      "epoch:18 step:14630 [D loss: 0.659620, acc: 57.81%] [G loss: 3.190453]\n",
      "epoch:18 step:14631 [D loss: 0.489343, acc: 68.75%] [G loss: 2.876752]\n",
      "epoch:18 step:14632 [D loss: 0.667212, acc: 60.16%] [G loss: 1.974075]\n",
      "epoch:18 step:14633 [D loss: 0.379995, acc: 89.06%] [G loss: 3.185331]\n",
      "epoch:18 step:14634 [D loss: 0.361289, acc: 92.97%] [G loss: 2.716379]\n",
      "epoch:18 step:14635 [D loss: 0.694370, acc: 57.81%] [G loss: 2.715853]\n",
      "epoch:18 step:14636 [D loss: 0.480276, acc: 76.56%] [G loss: 2.966508]\n",
      "epoch:18 step:14637 [D loss: 0.525091, acc: 73.44%] [G loss: 2.214065]\n",
      "epoch:18 step:14638 [D loss: 1.340662, acc: 21.88%] [G loss: 1.985678]\n",
      "epoch:18 step:14639 [D loss: 0.504741, acc: 80.47%] [G loss: 3.706622]\n",
      "epoch:18 step:14640 [D loss: 0.352708, acc: 91.41%] [G loss: 2.702474]\n",
      "epoch:18 step:14641 [D loss: 0.649518, acc: 65.62%] [G loss: 2.776582]\n",
      "epoch:18 step:14642 [D loss: 0.688559, acc: 57.03%] [G loss: 3.606973]\n",
      "epoch:18 step:14643 [D loss: 0.319371, acc: 93.75%] [G loss: 3.949553]\n",
      "epoch:18 step:14644 [D loss: 0.236714, acc: 97.66%] [G loss: 3.443816]\n",
      "epoch:18 step:14645 [D loss: 0.461674, acc: 81.25%] [G loss: 3.419739]\n",
      "epoch:18 step:14646 [D loss: 0.436864, acc: 85.94%] [G loss: 3.002709]\n",
      "epoch:18 step:14647 [D loss: 0.948528, acc: 48.44%] [G loss: 2.271888]\n",
      "epoch:18 step:14648 [D loss: 0.405758, acc: 91.41%] [G loss: 3.174495]\n",
      "epoch:18 step:14649 [D loss: 0.379673, acc: 90.62%] [G loss: 2.518954]\n",
      "epoch:18 step:14650 [D loss: 0.459345, acc: 76.56%] [G loss: 3.116414]\n",
      "epoch:18 step:14651 [D loss: 1.181056, acc: 15.62%] [G loss: 2.514046]\n",
      "epoch:18 step:14652 [D loss: 0.284274, acc: 94.53%] [G loss: 3.461255]\n",
      "epoch:18 step:14653 [D loss: 0.566260, acc: 71.88%] [G loss: 3.454342]\n",
      "epoch:18 step:14654 [D loss: 0.779247, acc: 49.22%] [G loss: 3.234488]\n",
      "epoch:18 step:14655 [D loss: 0.173405, acc: 99.22%] [G loss: 3.619576]\n",
      "epoch:18 step:14656 [D loss: 0.721527, acc: 57.81%] [G loss: 2.880107]\n",
      "epoch:18 step:14657 [D loss: 0.447316, acc: 84.38%] [G loss: 3.188106]\n",
      "epoch:18 step:14658 [D loss: 0.358264, acc: 92.19%] [G loss: 2.730689]\n",
      "epoch:18 step:14659 [D loss: 0.621950, acc: 64.84%] [G loss: 3.115867]\n",
      "epoch:18 step:14660 [D loss: 0.599961, acc: 72.66%] [G loss: 3.169564]\n",
      "epoch:18 step:14661 [D loss: 0.394232, acc: 73.44%] [G loss: 4.210345]\n",
      "epoch:18 step:14662 [D loss: 0.274832, acc: 94.53%] [G loss: 3.348836]\n",
      "epoch:18 step:14663 [D loss: 0.666134, acc: 56.25%] [G loss: 2.963439]\n",
      "epoch:18 step:14664 [D loss: 0.518844, acc: 71.09%] [G loss: 2.747039]\n",
      "epoch:18 step:14665 [D loss: 0.406868, acc: 79.69%] [G loss: 2.716492]\n",
      "epoch:18 step:14666 [D loss: 0.242261, acc: 100.00%] [G loss: 2.571052]\n",
      "epoch:18 step:14667 [D loss: 0.781494, acc: 52.34%] [G loss: 2.262347]\n",
      "epoch:18 step:14668 [D loss: 0.670187, acc: 58.59%] [G loss: 2.872196]\n",
      "epoch:18 step:14669 [D loss: 0.554366, acc: 70.31%] [G loss: 3.011973]\n",
      "epoch:18 step:14670 [D loss: 0.444454, acc: 90.62%] [G loss: 3.301744]\n",
      "epoch:18 step:14671 [D loss: 0.747471, acc: 47.66%] [G loss: 3.419252]\n",
      "epoch:18 step:14672 [D loss: 0.306223, acc: 93.75%] [G loss: 3.326589]\n",
      "epoch:18 step:14673 [D loss: 0.803419, acc: 54.69%] [G loss: 2.336915]\n",
      "epoch:18 step:14674 [D loss: 0.918840, acc: 34.38%] [G loss: 2.481665]\n",
      "epoch:18 step:14675 [D loss: 0.727497, acc: 55.47%] [G loss: 2.563510]\n",
      "epoch:18 step:14676 [D loss: 0.488374, acc: 77.34%] [G loss: 2.517983]\n",
      "epoch:18 step:14677 [D loss: 0.942738, acc: 37.50%] [G loss: 2.255784]\n",
      "epoch:18 step:14678 [D loss: 0.565604, acc: 71.09%] [G loss: 4.227392]\n",
      "epoch:18 step:14679 [D loss: 0.213264, acc: 98.44%] [G loss: 2.868095]\n",
      "epoch:18 step:14680 [D loss: 0.468530, acc: 82.03%] [G loss: 4.051981]\n",
      "epoch:18 step:14681 [D loss: 0.513467, acc: 75.00%] [G loss: 3.438175]\n",
      "epoch:18 step:14682 [D loss: 0.444777, acc: 81.25%] [G loss: 2.848511]\n",
      "epoch:18 step:14683 [D loss: 0.461502, acc: 85.94%] [G loss: 2.582724]\n",
      "epoch:18 step:14684 [D loss: 0.459128, acc: 87.50%] [G loss: 2.795463]\n",
      "epoch:18 step:14685 [D loss: 0.501289, acc: 80.47%] [G loss: 2.334239]\n",
      "epoch:18 step:14686 [D loss: 0.638405, acc: 62.50%] [G loss: 3.381899]\n",
      "epoch:18 step:14687 [D loss: 0.379944, acc: 93.75%] [G loss: 3.731902]\n",
      "epoch:18 step:14688 [D loss: 0.200277, acc: 100.00%] [G loss: 3.637342]\n",
      "epoch:18 step:14689 [D loss: 0.625705, acc: 69.53%] [G loss: 3.155118]\n",
      "epoch:18 step:14690 [D loss: 0.502676, acc: 70.31%] [G loss: 2.289322]\n",
      "epoch:18 step:14691 [D loss: 0.517747, acc: 76.56%] [G loss: 2.647600]\n",
      "epoch:18 step:14692 [D loss: 0.799131, acc: 48.44%] [G loss: 2.751039]\n",
      "epoch:18 step:14693 [D loss: 0.362216, acc: 95.31%] [G loss: 3.875489]\n",
      "epoch:18 step:14694 [D loss: 0.302486, acc: 96.88%] [G loss: 2.128263]\n",
      "epoch:18 step:14695 [D loss: 0.792331, acc: 42.97%] [G loss: 3.673148]\n",
      "epoch:18 step:14696 [D loss: 0.654211, acc: 59.38%] [G loss: 2.236339]\n",
      "epoch:18 step:14697 [D loss: 0.615480, acc: 67.19%] [G loss: 2.729048]\n",
      "epoch:18 step:14698 [D loss: 0.265863, acc: 96.09%] [G loss: 2.382870]\n",
      "epoch:18 step:14699 [D loss: 0.787783, acc: 53.12%] [G loss: 2.418325]\n",
      "epoch:18 step:14700 [D loss: 0.495977, acc: 74.22%] [G loss: 3.189756]\n",
      "epoch:18 step:14701 [D loss: 0.532376, acc: 73.44%] [G loss: 3.273980]\n",
      "epoch:18 step:14702 [D loss: 0.236885, acc: 95.31%] [G loss: 2.726545]\n",
      "epoch:18 step:14703 [D loss: 0.871209, acc: 31.25%] [G loss: 2.924709]\n",
      "epoch:18 step:14704 [D loss: 0.531643, acc: 77.34%] [G loss: 2.297207]\n",
      "epoch:18 step:14705 [D loss: 0.598569, acc: 66.41%] [G loss: 3.583049]\n",
      "epoch:18 step:14706 [D loss: 0.270373, acc: 98.44%] [G loss: 3.694016]\n",
      "epoch:18 step:14707 [D loss: 0.538691, acc: 67.97%] [G loss: 2.700145]\n",
      "epoch:18 step:14708 [D loss: 0.318067, acc: 94.53%] [G loss: 2.227425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14709 [D loss: 0.615688, acc: 69.53%] [G loss: 3.578857]\n",
      "epoch:18 step:14710 [D loss: 0.799758, acc: 48.44%] [G loss: 2.921226]\n",
      "epoch:18 step:14711 [D loss: 0.206468, acc: 97.66%] [G loss: 4.008401]\n",
      "epoch:18 step:14712 [D loss: 0.569863, acc: 67.19%] [G loss: 2.427476]\n",
      "epoch:18 step:14713 [D loss: 0.269210, acc: 96.88%] [G loss: 5.391793]\n",
      "epoch:18 step:14714 [D loss: 0.917816, acc: 47.66%] [G loss: 2.661024]\n",
      "epoch:18 step:14715 [D loss: 0.306879, acc: 94.53%] [G loss: 3.252674]\n",
      "epoch:18 step:14716 [D loss: 0.803416, acc: 52.34%] [G loss: 2.919361]\n",
      "epoch:18 step:14717 [D loss: 0.495258, acc: 76.56%] [G loss: 2.897195]\n",
      "epoch:18 step:14718 [D loss: 0.628518, acc: 66.41%] [G loss: 2.749980]\n",
      "epoch:18 step:14719 [D loss: 0.469295, acc: 75.78%] [G loss: 2.990070]\n",
      "epoch:18 step:14720 [D loss: 0.301832, acc: 94.53%] [G loss: 3.976302]\n",
      "epoch:18 step:14721 [D loss: 0.384374, acc: 85.16%] [G loss: 3.545189]\n",
      "epoch:18 step:14722 [D loss: 0.440233, acc: 80.47%] [G loss: 2.269158]\n",
      "epoch:18 step:14723 [D loss: 0.467409, acc: 77.34%] [G loss: 3.530735]\n",
      "epoch:18 step:14724 [D loss: 0.210030, acc: 97.66%] [G loss: 3.258300]\n",
      "epoch:18 step:14725 [D loss: 0.135823, acc: 100.00%] [G loss: 4.624063]\n",
      "epoch:18 step:14726 [D loss: 0.497775, acc: 79.69%] [G loss: 4.311042]\n",
      "epoch:18 step:14727 [D loss: 0.560078, acc: 67.97%] [G loss: 2.900982]\n",
      "epoch:18 step:14728 [D loss: 1.100487, acc: 50.00%] [G loss: 3.237344]\n",
      "epoch:18 step:14729 [D loss: 0.825000, acc: 51.56%] [G loss: 2.732492]\n",
      "epoch:18 step:14730 [D loss: 0.442529, acc: 84.38%] [G loss: 2.872793]\n",
      "epoch:18 step:14731 [D loss: 0.448785, acc: 80.47%] [G loss: 2.883636]\n",
      "epoch:18 step:14732 [D loss: 0.442721, acc: 83.59%] [G loss: 2.545144]\n",
      "epoch:18 step:14733 [D loss: 0.362421, acc: 89.06%] [G loss: 3.639784]\n",
      "epoch:18 step:14734 [D loss: 0.299566, acc: 93.75%] [G loss: 4.116862]\n",
      "epoch:18 step:14735 [D loss: 0.306789, acc: 92.97%] [G loss: 3.703108]\n",
      "epoch:18 step:14736 [D loss: 0.333026, acc: 91.41%] [G loss: 3.660996]\n",
      "epoch:18 step:14737 [D loss: 0.408068, acc: 78.91%] [G loss: 2.692145]\n",
      "epoch:18 step:14738 [D loss: 0.844809, acc: 49.22%] [G loss: 2.663574]\n",
      "epoch:18 step:14739 [D loss: 0.175875, acc: 99.22%] [G loss: 4.389620]\n",
      "epoch:18 step:14740 [D loss: 0.581675, acc: 62.50%] [G loss: 3.397325]\n",
      "epoch:18 step:14741 [D loss: 0.328720, acc: 87.50%] [G loss: 3.339003]\n",
      "epoch:18 step:14742 [D loss: 0.842279, acc: 41.41%] [G loss: 2.667117]\n",
      "epoch:18 step:14743 [D loss: 0.327344, acc: 91.41%] [G loss: 3.414696]\n",
      "epoch:18 step:14744 [D loss: 0.281852, acc: 91.41%] [G loss: 2.680728]\n",
      "epoch:18 step:14745 [D loss: 0.265981, acc: 96.09%] [G loss: 3.677858]\n",
      "epoch:18 step:14746 [D loss: 0.707676, acc: 51.56%] [G loss: 3.968657]\n",
      "epoch:18 step:14747 [D loss: 0.203035, acc: 97.66%] [G loss: 3.598245]\n",
      "epoch:18 step:14748 [D loss: 0.309651, acc: 94.53%] [G loss: 4.719408]\n",
      "epoch:18 step:14749 [D loss: 0.349238, acc: 83.59%] [G loss: 2.700805]\n",
      "epoch:18 step:14750 [D loss: 0.662433, acc: 59.38%] [G loss: 2.836950]\n",
      "epoch:18 step:14751 [D loss: 0.199824, acc: 99.22%] [G loss: 3.282587]\n",
      "epoch:18 step:14752 [D loss: 0.171818, acc: 98.44%] [G loss: 3.622694]\n",
      "epoch:18 step:14753 [D loss: 0.576114, acc: 71.88%] [G loss: 1.935868]\n",
      "epoch:18 step:14754 [D loss: 0.923840, acc: 50.78%] [G loss: 2.959679]\n",
      "epoch:18 step:14755 [D loss: 0.301419, acc: 94.53%] [G loss: 2.509193]\n",
      "epoch:18 step:14756 [D loss: 0.782206, acc: 53.91%] [G loss: 2.801194]\n",
      "epoch:18 step:14757 [D loss: 0.555172, acc: 71.09%] [G loss: 2.348715]\n",
      "epoch:18 step:14758 [D loss: 0.338280, acc: 94.53%] [G loss: 3.120041]\n",
      "epoch:18 step:14759 [D loss: 0.302100, acc: 87.50%] [G loss: 2.369144]\n",
      "epoch:18 step:14760 [D loss: 0.232655, acc: 96.88%] [G loss: 3.043037]\n",
      "epoch:18 step:14761 [D loss: 0.667322, acc: 60.94%] [G loss: 2.142316]\n",
      "epoch:18 step:14762 [D loss: 0.299597, acc: 96.88%] [G loss: 2.407443]\n",
      "epoch:18 step:14763 [D loss: 0.520903, acc: 78.12%] [G loss: 2.100771]\n",
      "epoch:18 step:14764 [D loss: 0.540318, acc: 70.31%] [G loss: 3.092502]\n",
      "epoch:18 step:14765 [D loss: 1.279951, acc: 29.69%] [G loss: 1.753917]\n",
      "epoch:18 step:14766 [D loss: 0.396862, acc: 87.50%] [G loss: 2.550035]\n",
      "epoch:18 step:14767 [D loss: 0.676234, acc: 61.72%] [G loss: 2.715010]\n",
      "epoch:18 step:14768 [D loss: 0.663929, acc: 56.25%] [G loss: 3.917125]\n",
      "epoch:18 step:14769 [D loss: 0.202082, acc: 97.66%] [G loss: 3.246095]\n",
      "epoch:18 step:14770 [D loss: 0.383004, acc: 91.41%] [G loss: 2.729509]\n",
      "epoch:18 step:14771 [D loss: 1.017636, acc: 34.38%] [G loss: 3.124445]\n",
      "epoch:18 step:14772 [D loss: 0.573725, acc: 67.97%] [G loss: 2.859928]\n",
      "epoch:18 step:14773 [D loss: 0.702753, acc: 58.59%] [G loss: 3.683412]\n",
      "epoch:18 step:14774 [D loss: 0.618317, acc: 64.84%] [G loss: 3.457534]\n",
      "epoch:18 step:14775 [D loss: 0.458746, acc: 75.00%] [G loss: 2.502425]\n",
      "epoch:18 step:14776 [D loss: 0.848053, acc: 51.56%] [G loss: 3.132226]\n",
      "epoch:18 step:14777 [D loss: 0.379032, acc: 84.38%] [G loss: 4.984703]\n",
      "epoch:18 step:14778 [D loss: 1.352419, acc: 19.53%] [G loss: 3.015101]\n",
      "epoch:18 step:14779 [D loss: 0.597620, acc: 63.28%] [G loss: 2.843688]\n",
      "epoch:18 step:14780 [D loss: 0.536716, acc: 80.47%] [G loss: 2.932514]\n",
      "epoch:18 step:14781 [D loss: 0.245576, acc: 97.66%] [G loss: 3.542502]\n",
      "epoch:18 step:14782 [D loss: 0.544687, acc: 73.44%] [G loss: 3.040443]\n",
      "epoch:18 step:14783 [D loss: 0.257046, acc: 98.44%] [G loss: 3.470086]\n",
      "epoch:18 step:14784 [D loss: 0.294267, acc: 94.53%] [G loss: 3.333646]\n",
      "epoch:18 step:14785 [D loss: 0.458379, acc: 77.34%] [G loss: 3.345572]\n",
      "epoch:18 step:14786 [D loss: 0.479650, acc: 75.00%] [G loss: 2.744382]\n",
      "epoch:18 step:14787 [D loss: 0.449931, acc: 90.62%] [G loss: 3.394819]\n",
      "epoch:18 step:14788 [D loss: 0.615100, acc: 68.75%] [G loss: 3.104236]\n",
      "epoch:18 step:14789 [D loss: 0.364789, acc: 93.75%] [G loss: 2.926639]\n",
      "epoch:18 step:14790 [D loss: 0.256636, acc: 94.53%] [G loss: 2.540138]\n",
      "epoch:18 step:14791 [D loss: 0.350435, acc: 94.53%] [G loss: 3.022612]\n",
      "epoch:18 step:14792 [D loss: 0.437721, acc: 77.34%] [G loss: 2.736683]\n",
      "epoch:18 step:14793 [D loss: 0.112511, acc: 100.00%] [G loss: 4.691134]\n",
      "epoch:18 step:14794 [D loss: 0.547758, acc: 74.22%] [G loss: 2.476827]\n",
      "epoch:18 step:14795 [D loss: 0.372501, acc: 95.31%] [G loss: 3.708954]\n",
      "epoch:18 step:14796 [D loss: 0.545863, acc: 71.88%] [G loss: 3.328660]\n",
      "epoch:18 step:14797 [D loss: 0.213448, acc: 97.66%] [G loss: 3.822837]\n",
      "epoch:18 step:14798 [D loss: 0.653086, acc: 63.28%] [G loss: 3.051724]\n",
      "epoch:18 step:14799 [D loss: 0.405468, acc: 77.34%] [G loss: 3.826480]\n",
      "epoch:18 step:14800 [D loss: 0.409252, acc: 74.22%] [G loss: 2.222693]\n",
      "epoch:18 step:14801 [D loss: 0.647020, acc: 60.94%] [G loss: 3.057465]\n",
      "epoch:18 step:14802 [D loss: 0.629654, acc: 65.62%] [G loss: 3.688255]\n",
      "epoch:18 step:14803 [D loss: 0.290954, acc: 92.97%] [G loss: 3.274030]\n",
      "epoch:18 step:14804 [D loss: 0.584936, acc: 70.31%] [G loss: 2.122542]\n",
      "epoch:18 step:14805 [D loss: 0.881252, acc: 42.97%] [G loss: 2.790600]\n",
      "epoch:18 step:14806 [D loss: 0.505636, acc: 65.62%] [G loss: 3.188728]\n",
      "epoch:18 step:14807 [D loss: 0.934771, acc: 49.22%] [G loss: 2.385343]\n",
      "epoch:18 step:14808 [D loss: 0.904385, acc: 37.50%] [G loss: 2.309190]\n",
      "epoch:18 step:14809 [D loss: 0.687232, acc: 63.28%] [G loss: 3.084744]\n",
      "epoch:18 step:14810 [D loss: 0.555906, acc: 75.00%] [G loss: 3.439662]\n",
      "epoch:18 step:14811 [D loss: 0.281976, acc: 96.88%] [G loss: 3.672374]\n",
      "epoch:18 step:14812 [D loss: 0.641010, acc: 63.28%] [G loss: 2.902710]\n",
      "epoch:18 step:14813 [D loss: 0.553107, acc: 70.31%] [G loss: 3.585506]\n",
      "epoch:18 step:14814 [D loss: 0.504288, acc: 75.78%] [G loss: 2.918480]\n",
      "epoch:18 step:14815 [D loss: 1.087545, acc: 50.00%] [G loss: 3.738816]\n",
      "epoch:18 step:14816 [D loss: 0.309003, acc: 91.41%] [G loss: 3.784843]\n",
      "epoch:18 step:14817 [D loss: 0.322661, acc: 91.41%] [G loss: 2.933680]\n",
      "epoch:18 step:14818 [D loss: 0.591210, acc: 61.72%] [G loss: 2.869728]\n",
      "epoch:18 step:14819 [D loss: 0.708350, acc: 55.47%] [G loss: 2.319706]\n",
      "epoch:18 step:14820 [D loss: 0.635945, acc: 59.38%] [G loss: 3.038393]\n",
      "epoch:18 step:14821 [D loss: 0.825569, acc: 40.62%] [G loss: 3.089647]\n",
      "epoch:18 step:14822 [D loss: 0.490729, acc: 75.78%] [G loss: 2.994327]\n",
      "epoch:18 step:14823 [D loss: 0.507789, acc: 80.47%] [G loss: 2.963555]\n",
      "epoch:18 step:14824 [D loss: 0.362304, acc: 85.16%] [G loss: 3.133406]\n",
      "epoch:18 step:14825 [D loss: 0.240699, acc: 98.44%] [G loss: 4.329538]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14826 [D loss: 0.471081, acc: 78.12%] [G loss: 2.936616]\n",
      "epoch:18 step:14827 [D loss: 0.486135, acc: 79.69%] [G loss: 3.310205]\n",
      "epoch:18 step:14828 [D loss: 0.359600, acc: 92.97%] [G loss: 2.881745]\n",
      "epoch:18 step:14829 [D loss: 0.964790, acc: 45.31%] [G loss: 3.167851]\n",
      "epoch:18 step:14830 [D loss: 0.636963, acc: 62.50%] [G loss: 3.160722]\n",
      "epoch:18 step:14831 [D loss: 0.133610, acc: 100.00%] [G loss: 4.146637]\n",
      "epoch:18 step:14832 [D loss: 0.351999, acc: 83.59%] [G loss: 4.126923]\n",
      "epoch:18 step:14833 [D loss: 0.751612, acc: 50.78%] [G loss: 2.929761]\n",
      "epoch:18 step:14834 [D loss: 0.288993, acc: 95.31%] [G loss: 3.549499]\n",
      "epoch:18 step:14835 [D loss: 0.877766, acc: 39.06%] [G loss: 2.298487]\n",
      "epoch:18 step:14836 [D loss: 0.570194, acc: 71.88%] [G loss: 2.561969]\n",
      "epoch:18 step:14837 [D loss: 0.543902, acc: 71.88%] [G loss: 2.492091]\n",
      "epoch:18 step:14838 [D loss: 0.549761, acc: 69.53%] [G loss: 2.125954]\n",
      "epoch:18 step:14839 [D loss: 0.503806, acc: 82.81%] [G loss: 3.933397]\n",
      "epoch:19 step:14840 [D loss: 0.324236, acc: 91.41%] [G loss: 2.481494]\n",
      "epoch:19 step:14841 [D loss: 0.298308, acc: 94.53%] [G loss: 2.710789]\n",
      "epoch:19 step:14842 [D loss: 0.879551, acc: 43.75%] [G loss: 3.570377]\n",
      "epoch:19 step:14843 [D loss: 0.647056, acc: 57.03%] [G loss: 2.398268]\n",
      "epoch:19 step:14844 [D loss: 0.173940, acc: 98.44%] [G loss: 3.802540]\n",
      "epoch:19 step:14845 [D loss: 0.408178, acc: 86.72%] [G loss: 3.251840]\n",
      "epoch:19 step:14846 [D loss: 0.439078, acc: 81.25%] [G loss: 4.044323]\n",
      "epoch:19 step:14847 [D loss: 0.698337, acc: 58.59%] [G loss: 2.888202]\n",
      "epoch:19 step:14848 [D loss: 0.400428, acc: 84.38%] [G loss: 2.990825]\n",
      "epoch:19 step:14849 [D loss: 0.450526, acc: 80.47%] [G loss: 2.856896]\n",
      "epoch:19 step:14850 [D loss: 0.762074, acc: 46.09%] [G loss: 3.429944]\n",
      "epoch:19 step:14851 [D loss: 0.552596, acc: 73.44%] [G loss: 2.657943]\n",
      "epoch:19 step:14852 [D loss: 0.340990, acc: 93.75%] [G loss: 2.582405]\n",
      "epoch:19 step:14853 [D loss: 0.685399, acc: 53.12%] [G loss: 2.326056]\n",
      "epoch:19 step:14854 [D loss: 0.898188, acc: 36.72%] [G loss: 2.641037]\n",
      "epoch:19 step:14855 [D loss: 1.649883, acc: 3.12%] [G loss: 2.556239]\n",
      "epoch:19 step:14856 [D loss: 0.230365, acc: 96.88%] [G loss: 2.639317]\n",
      "epoch:19 step:14857 [D loss: 0.462950, acc: 85.94%] [G loss: 3.276223]\n",
      "epoch:19 step:14858 [D loss: 0.944567, acc: 29.69%] [G loss: 4.214512]\n",
      "epoch:19 step:14859 [D loss: 0.669470, acc: 59.38%] [G loss: 2.468803]\n",
      "epoch:19 step:14860 [D loss: 0.514381, acc: 78.12%] [G loss: 2.973222]\n",
      "epoch:19 step:14861 [D loss: 0.719659, acc: 54.69%] [G loss: 4.231555]\n",
      "epoch:19 step:14862 [D loss: 0.370551, acc: 91.41%] [G loss: 2.529376]\n",
      "epoch:19 step:14863 [D loss: 0.354340, acc: 89.84%] [G loss: 3.724792]\n",
      "epoch:19 step:14864 [D loss: 0.288307, acc: 96.88%] [G loss: 3.351093]\n",
      "epoch:19 step:14865 [D loss: 0.839453, acc: 46.09%] [G loss: 2.783392]\n",
      "epoch:19 step:14866 [D loss: 0.320443, acc: 96.88%] [G loss: 3.274543]\n",
      "epoch:19 step:14867 [D loss: 0.579785, acc: 69.53%] [G loss: 3.016723]\n",
      "epoch:19 step:14868 [D loss: 0.347085, acc: 94.53%] [G loss: 2.647626]\n",
      "epoch:19 step:14869 [D loss: 0.544620, acc: 68.75%] [G loss: 2.704585]\n",
      "epoch:19 step:14870 [D loss: 0.338842, acc: 84.38%] [G loss: 3.337862]\n",
      "epoch:19 step:14871 [D loss: 0.301596, acc: 90.62%] [G loss: 2.929319]\n",
      "epoch:19 step:14872 [D loss: 0.814240, acc: 50.00%] [G loss: 2.844131]\n",
      "epoch:19 step:14873 [D loss: 0.572914, acc: 70.31%] [G loss: 2.398091]\n",
      "epoch:19 step:14874 [D loss: 0.768778, acc: 50.00%] [G loss: 2.369595]\n",
      "epoch:19 step:14875 [D loss: 0.649193, acc: 60.16%] [G loss: 3.430014]\n",
      "epoch:19 step:14876 [D loss: 0.743076, acc: 52.34%] [G loss: 2.635328]\n",
      "epoch:19 step:14877 [D loss: 0.649806, acc: 60.16%] [G loss: 3.571949]\n",
      "epoch:19 step:14878 [D loss: 0.768033, acc: 46.88%] [G loss: 2.393399]\n",
      "epoch:19 step:14879 [D loss: 0.339447, acc: 87.50%] [G loss: 2.902916]\n",
      "epoch:19 step:14880 [D loss: 0.169016, acc: 96.88%] [G loss: 2.818839]\n",
      "epoch:19 step:14881 [D loss: 0.444576, acc: 83.59%] [G loss: 2.266176]\n",
      "epoch:19 step:14882 [D loss: 0.840610, acc: 50.78%] [G loss: 2.740295]\n",
      "epoch:19 step:14883 [D loss: 0.622420, acc: 64.06%] [G loss: 3.131237]\n",
      "epoch:19 step:14884 [D loss: 0.400884, acc: 89.06%] [G loss: 3.786715]\n",
      "epoch:19 step:14885 [D loss: 0.471171, acc: 78.12%] [G loss: 2.828530]\n",
      "epoch:19 step:14886 [D loss: 0.566517, acc: 68.75%] [G loss: 2.653211]\n",
      "epoch:19 step:14887 [D loss: 0.477470, acc: 82.81%] [G loss: 2.650243]\n",
      "epoch:19 step:14888 [D loss: 0.935932, acc: 50.78%] [G loss: 2.141186]\n",
      "epoch:19 step:14889 [D loss: 0.608202, acc: 60.16%] [G loss: 2.302761]\n",
      "epoch:19 step:14890 [D loss: 0.630406, acc: 61.72%] [G loss: 2.558880]\n",
      "epoch:19 step:14891 [D loss: 0.378352, acc: 95.31%] [G loss: 3.425957]\n",
      "epoch:19 step:14892 [D loss: 1.056737, acc: 36.72%] [G loss: 2.994126]\n",
      "epoch:19 step:14893 [D loss: 1.104526, acc: 17.19%] [G loss: 2.529688]\n",
      "epoch:19 step:14894 [D loss: 0.422971, acc: 90.62%] [G loss: 3.440958]\n",
      "epoch:19 step:14895 [D loss: 0.637500, acc: 61.72%] [G loss: 1.513969]\n",
      "epoch:19 step:14896 [D loss: 0.421067, acc: 88.28%] [G loss: 2.876450]\n",
      "epoch:19 step:14897 [D loss: 0.657344, acc: 57.81%] [G loss: 2.564164]\n",
      "epoch:19 step:14898 [D loss: 0.630880, acc: 69.53%] [G loss: 3.042783]\n",
      "epoch:19 step:14899 [D loss: 0.324401, acc: 91.41%] [G loss: 1.898601]\n",
      "epoch:19 step:14900 [D loss: 0.329796, acc: 89.84%] [G loss: 2.629625]\n",
      "epoch:19 step:14901 [D loss: 0.687037, acc: 59.38%] [G loss: 2.688783]\n",
      "epoch:19 step:14902 [D loss: 0.343335, acc: 94.53%] [G loss: 3.020633]\n",
      "epoch:19 step:14903 [D loss: 0.285230, acc: 97.66%] [G loss: 3.315083]\n",
      "epoch:19 step:14904 [D loss: 0.645440, acc: 65.62%] [G loss: 3.738990]\n",
      "epoch:19 step:14905 [D loss: 0.658186, acc: 63.28%] [G loss: 2.880240]\n",
      "epoch:19 step:14906 [D loss: 0.895962, acc: 44.53%] [G loss: 3.479722]\n",
      "epoch:19 step:14907 [D loss: 0.347427, acc: 89.06%] [G loss: 2.692559]\n",
      "epoch:19 step:14908 [D loss: 0.368930, acc: 89.06%] [G loss: 2.915230]\n",
      "epoch:19 step:14909 [D loss: 0.147439, acc: 97.66%] [G loss: 3.133665]\n",
      "epoch:19 step:14910 [D loss: 1.283324, acc: 13.28%] [G loss: 3.264145]\n",
      "epoch:19 step:14911 [D loss: 0.734396, acc: 59.38%] [G loss: 2.301869]\n",
      "epoch:19 step:14912 [D loss: 0.409084, acc: 91.41%] [G loss: 2.662862]\n",
      "epoch:19 step:14913 [D loss: 0.619549, acc: 59.38%] [G loss: 1.820580]\n",
      "epoch:19 step:14914 [D loss: 0.155947, acc: 99.22%] [G loss: 3.432489]\n",
      "epoch:19 step:14915 [D loss: 0.403229, acc: 79.69%] [G loss: 3.511515]\n",
      "epoch:19 step:14916 [D loss: 0.927798, acc: 39.84%] [G loss: 2.290071]\n",
      "epoch:19 step:14917 [D loss: 0.633196, acc: 58.59%] [G loss: 2.412754]\n",
      "epoch:19 step:14918 [D loss: 0.401002, acc: 83.59%] [G loss: 3.721206]\n",
      "epoch:19 step:14919 [D loss: 0.843260, acc: 39.84%] [G loss: 2.865892]\n",
      "epoch:19 step:14920 [D loss: 0.449040, acc: 88.28%] [G loss: 2.408807]\n",
      "epoch:19 step:14921 [D loss: 0.519539, acc: 76.56%] [G loss: 3.108835]\n",
      "epoch:19 step:14922 [D loss: 0.471103, acc: 84.38%] [G loss: 3.036966]\n",
      "epoch:19 step:14923 [D loss: 0.716228, acc: 54.69%] [G loss: 2.743965]\n",
      "epoch:19 step:14924 [D loss: 0.873072, acc: 40.62%] [G loss: 2.836917]\n",
      "epoch:19 step:14925 [D loss: 0.236804, acc: 98.44%] [G loss: 2.561025]\n",
      "epoch:19 step:14926 [D loss: 0.833613, acc: 36.72%] [G loss: 2.188771]\n",
      "epoch:19 step:14927 [D loss: 0.483203, acc: 76.56%] [G loss: 2.303937]\n",
      "epoch:19 step:14928 [D loss: 0.345559, acc: 92.97%] [G loss: 3.857115]\n",
      "epoch:19 step:14929 [D loss: 0.283037, acc: 92.19%] [G loss: 2.802130]\n",
      "epoch:19 step:14930 [D loss: 0.626140, acc: 65.62%] [G loss: 2.726285]\n",
      "epoch:19 step:14931 [D loss: 0.687805, acc: 54.69%] [G loss: 1.833830]\n",
      "epoch:19 step:14932 [D loss: 0.369822, acc: 89.06%] [G loss: 4.264544]\n",
      "epoch:19 step:14933 [D loss: 0.821098, acc: 38.28%] [G loss: 2.559332]\n",
      "epoch:19 step:14934 [D loss: 0.240257, acc: 100.00%] [G loss: 2.966501]\n",
      "epoch:19 step:14935 [D loss: 0.372453, acc: 87.50%] [G loss: 3.832657]\n",
      "epoch:19 step:14936 [D loss: 0.252463, acc: 96.88%] [G loss: 2.764629]\n",
      "epoch:19 step:14937 [D loss: 0.762243, acc: 50.78%] [G loss: 2.200221]\n",
      "epoch:19 step:14938 [D loss: 1.037706, acc: 50.00%] [G loss: 2.589837]\n",
      "epoch:19 step:14939 [D loss: 0.557974, acc: 72.66%] [G loss: 2.729360]\n",
      "epoch:19 step:14940 [D loss: 0.386854, acc: 81.25%] [G loss: 2.817085]\n",
      "epoch:19 step:14941 [D loss: 0.235232, acc: 92.19%] [G loss: 3.710196]\n",
      "epoch:19 step:14942 [D loss: 0.735626, acc: 58.59%] [G loss: 3.779424]\n",
      "epoch:19 step:14943 [D loss: 0.401359, acc: 91.41%] [G loss: 2.148520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:14944 [D loss: 0.228377, acc: 93.75%] [G loss: 3.325049]\n",
      "epoch:19 step:14945 [D loss: 0.244402, acc: 97.66%] [G loss: 2.992021]\n",
      "epoch:19 step:14946 [D loss: 0.450337, acc: 80.47%] [G loss: 2.671629]\n",
      "epoch:19 step:14947 [D loss: 0.381388, acc: 90.62%] [G loss: 2.839965]\n",
      "epoch:19 step:14948 [D loss: 0.580671, acc: 70.31%] [G loss: 2.523334]\n",
      "epoch:19 step:14949 [D loss: 0.244908, acc: 99.22%] [G loss: 3.445079]\n",
      "epoch:19 step:14950 [D loss: 0.467549, acc: 81.25%] [G loss: 2.809051]\n",
      "epoch:19 step:14951 [D loss: 0.756090, acc: 52.34%] [G loss: 2.854003]\n",
      "epoch:19 step:14952 [D loss: 0.538145, acc: 74.22%] [G loss: 3.171590]\n",
      "epoch:19 step:14953 [D loss: 0.626585, acc: 61.72%] [G loss: 2.900349]\n",
      "epoch:19 step:14954 [D loss: 0.357029, acc: 91.41%] [G loss: 2.262269]\n",
      "epoch:19 step:14955 [D loss: 0.608796, acc: 67.97%] [G loss: 3.635380]\n",
      "epoch:19 step:14956 [D loss: 0.593761, acc: 66.41%] [G loss: 3.120465]\n",
      "epoch:19 step:14957 [D loss: 0.869836, acc: 32.81%] [G loss: 2.344265]\n",
      "epoch:19 step:14958 [D loss: 0.306303, acc: 89.84%] [G loss: 2.693066]\n",
      "epoch:19 step:14959 [D loss: 0.359773, acc: 92.19%] [G loss: 3.556304]\n",
      "epoch:19 step:14960 [D loss: 0.461386, acc: 87.50%] [G loss: 1.822393]\n",
      "epoch:19 step:14961 [D loss: 0.221864, acc: 100.00%] [G loss: 2.960574]\n",
      "epoch:19 step:14962 [D loss: 0.363717, acc: 94.53%] [G loss: 2.158069]\n",
      "epoch:19 step:14963 [D loss: 0.783590, acc: 42.19%] [G loss: 2.041186]\n",
      "epoch:19 step:14964 [D loss: 0.469730, acc: 72.66%] [G loss: 3.702769]\n",
      "epoch:19 step:14965 [D loss: 0.750740, acc: 51.56%] [G loss: 1.908276]\n",
      "epoch:19 step:14966 [D loss: 0.176208, acc: 100.00%] [G loss: 3.598526]\n",
      "epoch:19 step:14967 [D loss: 0.944237, acc: 50.00%] [G loss: 3.067066]\n",
      "epoch:19 step:14968 [D loss: 0.542865, acc: 62.50%] [G loss: 2.850552]\n",
      "epoch:19 step:14969 [D loss: 0.847634, acc: 43.75%] [G loss: 2.322965]\n",
      "epoch:19 step:14970 [D loss: 0.547473, acc: 78.91%] [G loss: 2.781557]\n",
      "epoch:19 step:14971 [D loss: 0.973056, acc: 32.81%] [G loss: 1.826085]\n",
      "epoch:19 step:14972 [D loss: 0.583852, acc: 68.75%] [G loss: 3.699435]\n",
      "epoch:19 step:14973 [D loss: 0.570448, acc: 71.09%] [G loss: 3.528379]\n",
      "epoch:19 step:14974 [D loss: 0.852675, acc: 43.75%] [G loss: 3.126412]\n",
      "epoch:19 step:14975 [D loss: 0.458506, acc: 85.94%] [G loss: 2.450144]\n",
      "epoch:19 step:14976 [D loss: 0.320698, acc: 96.88%] [G loss: 3.043326]\n",
      "epoch:19 step:14977 [D loss: 1.158380, acc: 13.28%] [G loss: 2.647740]\n",
      "epoch:19 step:14978 [D loss: 0.510670, acc: 74.22%] [G loss: 2.812331]\n",
      "epoch:19 step:14979 [D loss: 0.368921, acc: 88.28%] [G loss: 2.524738]\n",
      "epoch:19 step:14980 [D loss: 1.077880, acc: 35.16%] [G loss: 2.410980]\n",
      "epoch:19 step:14981 [D loss: 0.664001, acc: 64.84%] [G loss: 3.722817]\n",
      "epoch:19 step:14982 [D loss: 0.407285, acc: 91.41%] [G loss: 3.076849]\n",
      "epoch:19 step:14983 [D loss: 0.527756, acc: 73.44%] [G loss: 3.004435]\n",
      "epoch:19 step:14984 [D loss: 0.499944, acc: 79.69%] [G loss: 2.623581]\n",
      "epoch:19 step:14985 [D loss: 0.584604, acc: 65.62%] [G loss: 2.753081]\n",
      "epoch:19 step:14986 [D loss: 0.441092, acc: 78.91%] [G loss: 2.804830]\n",
      "epoch:19 step:14987 [D loss: 0.529694, acc: 74.22%] [G loss: 2.327523]\n",
      "epoch:19 step:14988 [D loss: 0.642548, acc: 58.59%] [G loss: 2.367222]\n",
      "epoch:19 step:14989 [D loss: 0.611328, acc: 59.38%] [G loss: 2.372113]\n",
      "epoch:19 step:14990 [D loss: 0.772559, acc: 52.34%] [G loss: 2.431881]\n",
      "epoch:19 step:14991 [D loss: 0.563315, acc: 57.03%] [G loss: 2.636561]\n",
      "epoch:19 step:14992 [D loss: 0.352292, acc: 92.97%] [G loss: 3.098130]\n",
      "epoch:19 step:14993 [D loss: 0.460368, acc: 69.53%] [G loss: 2.952510]\n",
      "epoch:19 step:14994 [D loss: 0.404840, acc: 87.50%] [G loss: 3.034224]\n",
      "epoch:19 step:14995 [D loss: 0.407020, acc: 90.62%] [G loss: 2.754143]\n",
      "epoch:19 step:14996 [D loss: 0.267938, acc: 93.75%] [G loss: 2.303423]\n",
      "epoch:19 step:14997 [D loss: 0.579014, acc: 69.53%] [G loss: 2.955514]\n",
      "epoch:19 step:14998 [D loss: 0.254455, acc: 94.53%] [G loss: 3.174756]\n",
      "epoch:19 step:14999 [D loss: 0.504288, acc: 65.62%] [G loss: 2.438426]\n",
      "epoch:19 step:15000 [D loss: 1.022450, acc: 50.00%] [G loss: 2.389679]\n",
      "epoch:19 step:15001 [D loss: 0.489321, acc: 67.97%] [G loss: 2.276339]\n",
      "epoch:19 step:15002 [D loss: 0.395721, acc: 89.06%] [G loss: 2.238492]\n",
      "epoch:19 step:15003 [D loss: 0.332118, acc: 87.50%] [G loss: 2.481784]\n",
      "epoch:19 step:15004 [D loss: 0.536807, acc: 74.22%] [G loss: 3.041244]\n",
      "epoch:19 step:15005 [D loss: 1.219504, acc: 14.06%] [G loss: 2.696631]\n",
      "epoch:19 step:15006 [D loss: 0.332300, acc: 90.62%] [G loss: 2.258787]\n",
      "epoch:19 step:15007 [D loss: 0.399358, acc: 82.03%] [G loss: 3.309349]\n",
      "epoch:19 step:15008 [D loss: 0.820628, acc: 49.22%] [G loss: 2.188120]\n",
      "epoch:19 step:15009 [D loss: 0.621242, acc: 67.97%] [G loss: 2.635150]\n",
      "epoch:19 step:15010 [D loss: 0.629910, acc: 67.19%] [G loss: 2.729103]\n",
      "epoch:19 step:15011 [D loss: 0.397268, acc: 81.25%] [G loss: 3.535456]\n",
      "epoch:19 step:15012 [D loss: 0.656078, acc: 68.75%] [G loss: 3.140510]\n",
      "epoch:19 step:15013 [D loss: 0.438639, acc: 87.50%] [G loss: 2.945424]\n",
      "epoch:19 step:15014 [D loss: 0.574650, acc: 67.19%] [G loss: 2.672227]\n",
      "epoch:19 step:15015 [D loss: 0.528322, acc: 62.50%] [G loss: 4.577926]\n",
      "epoch:19 step:15016 [D loss: 0.748892, acc: 54.69%] [G loss: 2.642501]\n",
      "epoch:19 step:15017 [D loss: 0.943185, acc: 31.25%] [G loss: 2.798634]\n",
      "epoch:19 step:15018 [D loss: 0.724713, acc: 50.00%] [G loss: 2.641187]\n",
      "epoch:19 step:15019 [D loss: 0.783304, acc: 51.56%] [G loss: 3.179091]\n",
      "epoch:19 step:15020 [D loss: 0.385244, acc: 85.16%] [G loss: 4.177739]\n",
      "epoch:19 step:15021 [D loss: 0.301587, acc: 92.97%] [G loss: 3.390902]\n",
      "epoch:19 step:15022 [D loss: 0.265974, acc: 96.88%] [G loss: 2.989457]\n",
      "epoch:19 step:15023 [D loss: 0.605096, acc: 62.50%] [G loss: 2.968166]\n",
      "epoch:19 step:15024 [D loss: 0.468939, acc: 82.81%] [G loss: 3.529036]\n",
      "epoch:19 step:15025 [D loss: 0.671727, acc: 60.94%] [G loss: 2.567645]\n",
      "epoch:19 step:15026 [D loss: 0.188706, acc: 100.00%] [G loss: 2.359506]\n",
      "epoch:19 step:15027 [D loss: 0.509260, acc: 72.66%] [G loss: 2.369168]\n",
      "epoch:19 step:15028 [D loss: 0.184198, acc: 98.44%] [G loss: 4.285469]\n",
      "epoch:19 step:15029 [D loss: 0.531265, acc: 74.22%] [G loss: 3.317814]\n",
      "epoch:19 step:15030 [D loss: 0.599244, acc: 61.72%] [G loss: 2.852458]\n",
      "epoch:19 step:15031 [D loss: 0.774532, acc: 56.25%] [G loss: 2.494643]\n",
      "epoch:19 step:15032 [D loss: 0.702073, acc: 60.94%] [G loss: 3.045408]\n",
      "epoch:19 step:15033 [D loss: 0.604049, acc: 67.19%] [G loss: 3.423206]\n",
      "epoch:19 step:15034 [D loss: 0.341639, acc: 91.41%] [G loss: 2.270524]\n",
      "epoch:19 step:15035 [D loss: 0.479758, acc: 82.03%] [G loss: 2.558329]\n",
      "epoch:19 step:15036 [D loss: 0.381779, acc: 89.06%] [G loss: 2.206841]\n",
      "epoch:19 step:15037 [D loss: 0.188544, acc: 100.00%] [G loss: 3.111632]\n",
      "epoch:19 step:15038 [D loss: 0.640520, acc: 62.50%] [G loss: 3.067180]\n",
      "epoch:19 step:15039 [D loss: 0.570200, acc: 60.16%] [G loss: 3.137534]\n",
      "epoch:19 step:15040 [D loss: 0.308014, acc: 95.31%] [G loss: 2.766490]\n",
      "epoch:19 step:15041 [D loss: 1.252737, acc: 46.09%] [G loss: 1.803265]\n",
      "epoch:19 step:15042 [D loss: 0.421003, acc: 82.03%] [G loss: 2.243985]\n",
      "epoch:19 step:15043 [D loss: 0.590446, acc: 68.75%] [G loss: 2.799475]\n",
      "epoch:19 step:15044 [D loss: 0.819096, acc: 54.69%] [G loss: 2.952378]\n",
      "epoch:19 step:15045 [D loss: 0.699057, acc: 61.72%] [G loss: 2.955896]\n",
      "epoch:19 step:15046 [D loss: 0.903299, acc: 35.16%] [G loss: 2.307761]\n",
      "epoch:19 step:15047 [D loss: 0.384809, acc: 82.03%] [G loss: 2.521821]\n",
      "epoch:19 step:15048 [D loss: 0.444580, acc: 84.38%] [G loss: 4.385441]\n",
      "epoch:19 step:15049 [D loss: 0.324090, acc: 92.19%] [G loss: 2.974947]\n",
      "epoch:19 step:15050 [D loss: 0.584367, acc: 73.44%] [G loss: 2.960873]\n",
      "epoch:19 step:15051 [D loss: 0.899646, acc: 28.12%] [G loss: 1.901262]\n",
      "epoch:19 step:15052 [D loss: 0.611597, acc: 60.16%] [G loss: 2.897855]\n",
      "epoch:19 step:15053 [D loss: 0.788649, acc: 53.12%] [G loss: 2.764825]\n",
      "epoch:19 step:15054 [D loss: 0.535906, acc: 77.34%] [G loss: 2.891805]\n",
      "epoch:19 step:15055 [D loss: 0.316555, acc: 96.88%] [G loss: 3.375481]\n",
      "epoch:19 step:15056 [D loss: 0.511207, acc: 58.59%] [G loss: 3.490296]\n",
      "epoch:19 step:15057 [D loss: 0.504834, acc: 72.66%] [G loss: 2.887175]\n",
      "epoch:19 step:15058 [D loss: 0.211694, acc: 98.44%] [G loss: 4.541305]\n",
      "epoch:19 step:15059 [D loss: 0.652998, acc: 60.16%] [G loss: 2.371155]\n",
      "epoch:19 step:15060 [D loss: 0.517833, acc: 77.34%] [G loss: 2.348639]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15061 [D loss: 0.712285, acc: 53.91%] [G loss: 2.833061]\n",
      "epoch:19 step:15062 [D loss: 0.656653, acc: 58.59%] [G loss: 2.466504]\n",
      "epoch:19 step:15063 [D loss: 0.593567, acc: 69.53%] [G loss: 2.931214]\n",
      "epoch:19 step:15064 [D loss: 0.644775, acc: 65.62%] [G loss: 2.300682]\n",
      "epoch:19 step:15065 [D loss: 0.702530, acc: 51.56%] [G loss: 2.783756]\n",
      "epoch:19 step:15066 [D loss: 0.979695, acc: 21.09%] [G loss: 2.274817]\n",
      "epoch:19 step:15067 [D loss: 0.663560, acc: 57.81%] [G loss: 2.860813]\n",
      "epoch:19 step:15068 [D loss: 0.574834, acc: 64.06%] [G loss: 3.397899]\n",
      "epoch:19 step:15069 [D loss: 0.851194, acc: 53.12%] [G loss: 2.745388]\n",
      "epoch:19 step:15070 [D loss: 0.318484, acc: 99.22%] [G loss: 1.789393]\n",
      "epoch:19 step:15071 [D loss: 0.939206, acc: 44.53%] [G loss: 2.741128]\n",
      "epoch:19 step:15072 [D loss: 0.273518, acc: 96.88%] [G loss: 2.891413]\n",
      "epoch:19 step:15073 [D loss: 0.369323, acc: 86.72%] [G loss: 3.525729]\n",
      "epoch:19 step:15074 [D loss: 0.566758, acc: 62.50%] [G loss: 3.048717]\n",
      "epoch:19 step:15075 [D loss: 0.703916, acc: 59.38%] [G loss: 2.242894]\n",
      "epoch:19 step:15076 [D loss: 0.413235, acc: 86.72%] [G loss: 2.670862]\n",
      "epoch:19 step:15077 [D loss: 0.349010, acc: 92.97%] [G loss: 3.324574]\n",
      "epoch:19 step:15078 [D loss: 0.721807, acc: 53.12%] [G loss: 3.408452]\n",
      "epoch:19 step:15079 [D loss: 1.012030, acc: 28.12%] [G loss: 2.621586]\n",
      "epoch:19 step:15080 [D loss: 0.491511, acc: 77.34%] [G loss: 3.788341]\n",
      "epoch:19 step:15081 [D loss: 0.448844, acc: 89.06%] [G loss: 2.427820]\n",
      "epoch:19 step:15082 [D loss: 0.519052, acc: 69.53%] [G loss: 3.430759]\n",
      "epoch:19 step:15083 [D loss: 0.776695, acc: 46.09%] [G loss: 2.519295]\n",
      "epoch:19 step:15084 [D loss: 0.492894, acc: 67.19%] [G loss: 4.016820]\n",
      "epoch:19 step:15085 [D loss: 0.507440, acc: 77.34%] [G loss: 2.493387]\n",
      "epoch:19 step:15086 [D loss: 0.355440, acc: 91.41%] [G loss: 2.192029]\n",
      "epoch:19 step:15087 [D loss: 0.492127, acc: 74.22%] [G loss: 3.964245]\n",
      "epoch:19 step:15088 [D loss: 0.206697, acc: 99.22%] [G loss: 5.768082]\n",
      "epoch:19 step:15089 [D loss: 0.726925, acc: 53.12%] [G loss: 3.462799]\n",
      "epoch:19 step:15090 [D loss: 0.235174, acc: 96.88%] [G loss: 3.063104]\n",
      "epoch:19 step:15091 [D loss: 0.488519, acc: 74.22%] [G loss: 2.885587]\n",
      "epoch:19 step:15092 [D loss: 0.523259, acc: 73.44%] [G loss: 2.701487]\n",
      "epoch:19 step:15093 [D loss: 0.736399, acc: 56.25%] [G loss: 1.822796]\n",
      "epoch:19 step:15094 [D loss: 0.472305, acc: 78.12%] [G loss: 3.807943]\n",
      "epoch:19 step:15095 [D loss: 0.431489, acc: 80.47%] [G loss: 3.763493]\n",
      "epoch:19 step:15096 [D loss: 0.616630, acc: 65.62%] [G loss: 2.537106]\n",
      "epoch:19 step:15097 [D loss: 0.461766, acc: 83.59%] [G loss: 2.116995]\n",
      "epoch:19 step:15098 [D loss: 0.384231, acc: 89.84%] [G loss: 1.858505]\n",
      "epoch:19 step:15099 [D loss: 0.373018, acc: 90.62%] [G loss: 2.588906]\n",
      "epoch:19 step:15100 [D loss: 0.413523, acc: 82.81%] [G loss: 2.244050]\n",
      "epoch:19 step:15101 [D loss: 0.344905, acc: 93.75%] [G loss: 3.074836]\n",
      "epoch:19 step:15102 [D loss: 1.076364, acc: 42.19%] [G loss: 2.946184]\n",
      "epoch:19 step:15103 [D loss: 0.756304, acc: 53.91%] [G loss: 2.384692]\n",
      "epoch:19 step:15104 [D loss: 0.258173, acc: 97.66%] [G loss: 4.565190]\n",
      "epoch:19 step:15105 [D loss: 0.762090, acc: 50.00%] [G loss: 2.532535]\n",
      "epoch:19 step:15106 [D loss: 1.894813, acc: 27.34%] [G loss: 2.088240]\n",
      "epoch:19 step:15107 [D loss: 0.542614, acc: 77.34%] [G loss: 2.550593]\n",
      "epoch:19 step:15108 [D loss: 0.814178, acc: 49.22%] [G loss: 1.981779]\n",
      "epoch:19 step:15109 [D loss: 0.564447, acc: 64.06%] [G loss: 2.275584]\n",
      "epoch:19 step:15110 [D loss: 0.907201, acc: 32.03%] [G loss: 3.009926]\n",
      "epoch:19 step:15111 [D loss: 0.772256, acc: 48.44%] [G loss: 2.590013]\n",
      "epoch:19 step:15112 [D loss: 0.554921, acc: 78.12%] [G loss: 2.838443]\n",
      "epoch:19 step:15113 [D loss: 0.797910, acc: 52.34%] [G loss: 3.414625]\n",
      "epoch:19 step:15114 [D loss: 0.663285, acc: 59.38%] [G loss: 3.145552]\n",
      "epoch:19 step:15115 [D loss: 0.713689, acc: 53.91%] [G loss: 3.510001]\n",
      "epoch:19 step:15116 [D loss: 0.691600, acc: 53.12%] [G loss: 2.714181]\n",
      "epoch:19 step:15117 [D loss: 0.510100, acc: 67.19%] [G loss: 2.869792]\n",
      "epoch:19 step:15118 [D loss: 0.711929, acc: 55.47%] [G loss: 2.469766]\n",
      "epoch:19 step:15119 [D loss: 0.627635, acc: 60.94%] [G loss: 2.117571]\n",
      "epoch:19 step:15120 [D loss: 0.708166, acc: 58.59%] [G loss: 3.098395]\n",
      "epoch:19 step:15121 [D loss: 0.807497, acc: 51.56%] [G loss: 2.614334]\n",
      "epoch:19 step:15122 [D loss: 0.322903, acc: 94.53%] [G loss: 2.765358]\n",
      "epoch:19 step:15123 [D loss: 0.374138, acc: 90.62%] [G loss: 3.047418]\n",
      "epoch:19 step:15124 [D loss: 0.719773, acc: 57.03%] [G loss: 2.313546]\n",
      "epoch:19 step:15125 [D loss: 0.813461, acc: 43.75%] [G loss: 3.095488]\n",
      "epoch:19 step:15126 [D loss: 0.339226, acc: 95.31%] [G loss: 2.960159]\n",
      "epoch:19 step:15127 [D loss: 0.908622, acc: 34.38%] [G loss: 2.268014]\n",
      "epoch:19 step:15128 [D loss: 0.498447, acc: 84.38%] [G loss: 2.964479]\n",
      "epoch:19 step:15129 [D loss: 0.387897, acc: 89.84%] [G loss: 3.169388]\n",
      "epoch:19 step:15130 [D loss: 0.577100, acc: 77.34%] [G loss: 2.750548]\n",
      "epoch:19 step:15131 [D loss: 0.624942, acc: 62.50%] [G loss: 3.531481]\n",
      "epoch:19 step:15132 [D loss: 0.251280, acc: 98.44%] [G loss: 3.234676]\n",
      "epoch:19 step:15133 [D loss: 0.306330, acc: 95.31%] [G loss: 2.691563]\n",
      "epoch:19 step:15134 [D loss: 0.529288, acc: 78.12%] [G loss: 3.436815]\n",
      "epoch:19 step:15135 [D loss: 0.436323, acc: 81.25%] [G loss: 2.522825]\n",
      "epoch:19 step:15136 [D loss: 0.804777, acc: 49.22%] [G loss: 3.412690]\n",
      "epoch:19 step:15137 [D loss: 0.425489, acc: 83.59%] [G loss: 3.129167]\n",
      "epoch:19 step:15138 [D loss: 0.439594, acc: 85.94%] [G loss: 3.225146]\n",
      "epoch:19 step:15139 [D loss: 0.544739, acc: 77.34%] [G loss: 2.185142]\n",
      "epoch:19 step:15140 [D loss: 0.518618, acc: 75.00%] [G loss: 2.620405]\n",
      "epoch:19 step:15141 [D loss: 0.714619, acc: 56.25%] [G loss: 2.643759]\n",
      "epoch:19 step:15142 [D loss: 0.591303, acc: 60.94%] [G loss: 2.973992]\n",
      "epoch:19 step:15143 [D loss: 0.520619, acc: 74.22%] [G loss: 2.636363]\n",
      "epoch:19 step:15144 [D loss: 0.526935, acc: 73.44%] [G loss: 3.884350]\n",
      "epoch:19 step:15145 [D loss: 0.366116, acc: 90.62%] [G loss: 3.417425]\n",
      "epoch:19 step:15146 [D loss: 0.584355, acc: 67.19%] [G loss: 3.027664]\n",
      "epoch:19 step:15147 [D loss: 0.464688, acc: 76.56%] [G loss: 2.212435]\n",
      "epoch:19 step:15148 [D loss: 0.459171, acc: 89.84%] [G loss: 3.742526]\n",
      "epoch:19 step:15149 [D loss: 0.333789, acc: 82.03%] [G loss: 4.856688]\n",
      "epoch:19 step:15150 [D loss: 0.306959, acc: 90.62%] [G loss: 3.448943]\n",
      "epoch:19 step:15151 [D loss: 0.585070, acc: 67.97%] [G loss: 2.684583]\n",
      "epoch:19 step:15152 [D loss: 0.512926, acc: 73.44%] [G loss: 1.978135]\n",
      "epoch:19 step:15153 [D loss: 0.304712, acc: 97.66%] [G loss: 3.418677]\n",
      "epoch:19 step:15154 [D loss: 1.049448, acc: 37.50%] [G loss: 3.139826]\n",
      "epoch:19 step:15155 [D loss: 0.358383, acc: 96.09%] [G loss: 3.508093]\n",
      "epoch:19 step:15156 [D loss: 0.701194, acc: 55.47%] [G loss: 4.008349]\n",
      "epoch:19 step:15157 [D loss: 0.623206, acc: 62.50%] [G loss: 2.515695]\n",
      "epoch:19 step:15158 [D loss: 1.015832, acc: 21.09%] [G loss: 3.410883]\n",
      "epoch:19 step:15159 [D loss: 0.726660, acc: 53.91%] [G loss: 2.528546]\n",
      "epoch:19 step:15160 [D loss: 0.916861, acc: 36.72%] [G loss: 2.755151]\n",
      "epoch:19 step:15161 [D loss: 0.252861, acc: 98.44%] [G loss: 2.595381]\n",
      "epoch:19 step:15162 [D loss: 0.536698, acc: 78.12%] [G loss: 1.726739]\n",
      "epoch:19 step:15163 [D loss: 0.245492, acc: 96.09%] [G loss: 3.136764]\n",
      "epoch:19 step:15164 [D loss: 0.748226, acc: 56.25%] [G loss: 2.429814]\n",
      "epoch:19 step:15165 [D loss: 0.282157, acc: 95.31%] [G loss: 4.107990]\n",
      "epoch:19 step:15166 [D loss: 0.415599, acc: 87.50%] [G loss: 3.525103]\n",
      "epoch:19 step:15167 [D loss: 0.557927, acc: 70.31%] [G loss: 2.937292]\n",
      "epoch:19 step:15168 [D loss: 0.413657, acc: 76.56%] [G loss: 2.392265]\n",
      "epoch:19 step:15169 [D loss: 0.669376, acc: 63.28%] [G loss: 3.028404]\n",
      "epoch:19 step:15170 [D loss: 0.368789, acc: 88.28%] [G loss: 3.366122]\n",
      "epoch:19 step:15171 [D loss: 0.977401, acc: 24.22%] [G loss: 2.931049]\n",
      "epoch:19 step:15172 [D loss: 0.223191, acc: 99.22%] [G loss: 3.457897]\n",
      "epoch:19 step:15173 [D loss: 0.270611, acc: 96.09%] [G loss: 4.347844]\n",
      "epoch:19 step:15174 [D loss: 0.282910, acc: 93.75%] [G loss: 3.012393]\n",
      "epoch:19 step:15175 [D loss: 0.468054, acc: 84.38%] [G loss: 2.592975]\n",
      "epoch:19 step:15176 [D loss: 0.684638, acc: 59.38%] [G loss: 2.364635]\n",
      "epoch:19 step:15177 [D loss: 0.643590, acc: 58.59%] [G loss: 2.206751]\n",
      "epoch:19 step:15178 [D loss: 0.455482, acc: 83.59%] [G loss: 3.436488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15179 [D loss: 0.938494, acc: 31.25%] [G loss: 3.935432]\n",
      "epoch:19 step:15180 [D loss: 0.621586, acc: 64.06%] [G loss: 3.090075]\n",
      "epoch:19 step:15181 [D loss: 0.331114, acc: 93.75%] [G loss: 3.199774]\n",
      "epoch:19 step:15182 [D loss: 0.662435, acc: 60.16%] [G loss: 2.646774]\n",
      "epoch:19 step:15183 [D loss: 0.693883, acc: 57.03%] [G loss: 2.983919]\n",
      "epoch:19 step:15184 [D loss: 0.911020, acc: 34.38%] [G loss: 2.324095]\n",
      "epoch:19 step:15185 [D loss: 0.788738, acc: 46.88%] [G loss: 2.457030]\n",
      "epoch:19 step:15186 [D loss: 0.553832, acc: 78.12%] [G loss: 2.843606]\n",
      "epoch:19 step:15187 [D loss: 0.747093, acc: 50.78%] [G loss: 3.048632]\n",
      "epoch:19 step:15188 [D loss: 0.439411, acc: 84.38%] [G loss: 3.072627]\n",
      "epoch:19 step:15189 [D loss: 1.425908, acc: 18.75%] [G loss: 2.213979]\n",
      "epoch:19 step:15190 [D loss: 0.405704, acc: 89.06%] [G loss: 2.140391]\n",
      "epoch:19 step:15191 [D loss: 0.145589, acc: 99.22%] [G loss: 4.053953]\n",
      "epoch:19 step:15192 [D loss: 0.573989, acc: 66.41%] [G loss: 2.480250]\n",
      "epoch:19 step:15193 [D loss: 0.470760, acc: 85.16%] [G loss: 2.785662]\n",
      "epoch:19 step:15194 [D loss: 0.512990, acc: 78.12%] [G loss: 2.850721]\n",
      "epoch:19 step:15195 [D loss: 0.374989, acc: 88.28%] [G loss: 3.191125]\n",
      "epoch:19 step:15196 [D loss: 0.408147, acc: 80.47%] [G loss: 2.983952]\n",
      "epoch:19 step:15197 [D loss: 0.458041, acc: 85.16%] [G loss: 2.242884]\n",
      "epoch:19 step:15198 [D loss: 1.137798, acc: 24.22%] [G loss: 1.894458]\n",
      "epoch:19 step:15199 [D loss: 0.661709, acc: 61.72%] [G loss: 2.318007]\n",
      "epoch:19 step:15200 [D loss: 0.654251, acc: 61.72%] [G loss: 2.764719]\n",
      "epoch:19 step:15201 [D loss: 0.332207, acc: 88.28%] [G loss: 2.814764]\n",
      "epoch:19 step:15202 [D loss: 0.576276, acc: 68.75%] [G loss: 2.411052]\n",
      "epoch:19 step:15203 [D loss: 0.424877, acc: 75.78%] [G loss: 3.652081]\n",
      "epoch:19 step:15204 [D loss: 0.263045, acc: 96.88%] [G loss: 4.739133]\n",
      "epoch:19 step:15205 [D loss: 1.359800, acc: 28.91%] [G loss: 3.702648]\n",
      "epoch:19 step:15206 [D loss: 0.392332, acc: 89.84%] [G loss: 2.627871]\n",
      "epoch:19 step:15207 [D loss: 0.461884, acc: 82.81%] [G loss: 2.921903]\n",
      "epoch:19 step:15208 [D loss: 0.487012, acc: 77.34%] [G loss: 4.210443]\n",
      "epoch:19 step:15209 [D loss: 0.262494, acc: 96.09%] [G loss: 3.577295]\n",
      "epoch:19 step:15210 [D loss: 0.382109, acc: 86.72%] [G loss: 3.903309]\n",
      "epoch:19 step:15211 [D loss: 1.250347, acc: 35.94%] [G loss: 2.584385]\n",
      "epoch:19 step:15212 [D loss: 1.087134, acc: 17.19%] [G loss: 2.481058]\n",
      "epoch:19 step:15213 [D loss: 0.216632, acc: 99.22%] [G loss: 3.682058]\n",
      "epoch:19 step:15214 [D loss: 0.384709, acc: 89.06%] [G loss: 3.853061]\n",
      "epoch:19 step:15215 [D loss: 0.546056, acc: 72.66%] [G loss: 3.642600]\n",
      "epoch:19 step:15216 [D loss: 0.805230, acc: 45.31%] [G loss: 2.237511]\n",
      "epoch:19 step:15217 [D loss: 0.337918, acc: 89.06%] [G loss: 3.042078]\n",
      "epoch:19 step:15218 [D loss: 0.785520, acc: 49.22%] [G loss: 3.453657]\n",
      "epoch:19 step:15219 [D loss: 0.554464, acc: 71.88%] [G loss: 3.005410]\n",
      "epoch:19 step:15220 [D loss: 0.558374, acc: 69.53%] [G loss: 3.357929]\n",
      "epoch:19 step:15221 [D loss: 0.421062, acc: 88.28%] [G loss: 2.753113]\n",
      "epoch:19 step:15222 [D loss: 0.548109, acc: 75.00%] [G loss: 2.597254]\n",
      "epoch:19 step:15223 [D loss: 0.415750, acc: 89.06%] [G loss: 2.616877]\n",
      "epoch:19 step:15224 [D loss: 0.416020, acc: 87.50%] [G loss: 2.951242]\n",
      "epoch:19 step:15225 [D loss: 0.855036, acc: 43.75%] [G loss: 3.679875]\n",
      "epoch:19 step:15226 [D loss: 0.750718, acc: 51.56%] [G loss: 2.038165]\n",
      "epoch:19 step:15227 [D loss: 0.405569, acc: 89.84%] [G loss: 2.513410]\n",
      "epoch:19 step:15228 [D loss: 0.800130, acc: 47.66%] [G loss: 1.949710]\n",
      "epoch:19 step:15229 [D loss: 0.332205, acc: 93.75%] [G loss: 2.732073]\n",
      "epoch:19 step:15230 [D loss: 0.513996, acc: 75.78%] [G loss: 2.715950]\n",
      "epoch:19 step:15231 [D loss: 0.413603, acc: 82.03%] [G loss: 2.907778]\n",
      "epoch:19 step:15232 [D loss: 0.635084, acc: 64.06%] [G loss: 2.728526]\n",
      "epoch:19 step:15233 [D loss: 0.393089, acc: 88.28%] [G loss: 2.270831]\n",
      "epoch:19 step:15234 [D loss: 0.316383, acc: 92.19%] [G loss: 3.006804]\n",
      "epoch:19 step:15235 [D loss: 0.837997, acc: 43.75%] [G loss: 3.919258]\n",
      "epoch:19 step:15236 [D loss: 0.832787, acc: 39.84%] [G loss: 2.812587]\n",
      "epoch:19 step:15237 [D loss: 0.830643, acc: 46.09%] [G loss: 3.104799]\n",
      "epoch:19 step:15238 [D loss: 0.593751, acc: 72.66%] [G loss: 3.194337]\n",
      "epoch:19 step:15239 [D loss: 0.460310, acc: 82.03%] [G loss: 3.216939]\n",
      "epoch:19 step:15240 [D loss: 0.597008, acc: 73.44%] [G loss: 3.290220]\n",
      "epoch:19 step:15241 [D loss: 0.799193, acc: 42.97%] [G loss: 2.810240]\n",
      "epoch:19 step:15242 [D loss: 0.773167, acc: 53.91%] [G loss: 2.231642]\n",
      "epoch:19 step:15243 [D loss: 0.411142, acc: 83.59%] [G loss: 3.325579]\n",
      "epoch:19 step:15244 [D loss: 0.553659, acc: 75.78%] [G loss: 2.862192]\n",
      "epoch:19 step:15245 [D loss: 0.342024, acc: 86.72%] [G loss: 3.637113]\n",
      "epoch:19 step:15246 [D loss: 0.571615, acc: 74.22%] [G loss: 3.154545]\n",
      "epoch:19 step:15247 [D loss: 0.538154, acc: 68.75%] [G loss: 3.312635]\n",
      "epoch:19 step:15248 [D loss: 0.369015, acc: 82.81%] [G loss: 3.056899]\n",
      "epoch:19 step:15249 [D loss: 0.554956, acc: 75.78%] [G loss: 3.350696]\n",
      "epoch:19 step:15250 [D loss: 0.670049, acc: 54.69%] [G loss: 2.403222]\n",
      "epoch:19 step:15251 [D loss: 0.739141, acc: 52.34%] [G loss: 2.519518]\n",
      "epoch:19 step:15252 [D loss: 0.709930, acc: 60.16%] [G loss: 2.918348]\n",
      "epoch:19 step:15253 [D loss: 0.837014, acc: 44.53%] [G loss: 2.928322]\n",
      "epoch:19 step:15254 [D loss: 0.797463, acc: 41.41%] [G loss: 3.030038]\n",
      "epoch:19 step:15255 [D loss: 0.691677, acc: 56.25%] [G loss: 3.777507]\n",
      "epoch:19 step:15256 [D loss: 0.258189, acc: 89.06%] [G loss: 3.337388]\n",
      "epoch:19 step:15257 [D loss: 0.403019, acc: 89.84%] [G loss: 3.678648]\n",
      "epoch:19 step:15258 [D loss: 0.418828, acc: 88.28%] [G loss: 3.167038]\n",
      "epoch:19 step:15259 [D loss: 0.396577, acc: 89.84%] [G loss: 3.149554]\n",
      "epoch:19 step:15260 [D loss: 0.459898, acc: 75.00%] [G loss: 2.711988]\n",
      "epoch:19 step:15261 [D loss: 0.168395, acc: 100.00%] [G loss: 2.438210]\n",
      "epoch:19 step:15262 [D loss: 0.626604, acc: 64.06%] [G loss: 2.166348]\n",
      "epoch:19 step:15263 [D loss: 0.689600, acc: 57.03%] [G loss: 3.033072]\n",
      "epoch:19 step:15264 [D loss: 0.460292, acc: 85.94%] [G loss: 2.809618]\n",
      "epoch:19 step:15265 [D loss: 0.491720, acc: 75.00%] [G loss: 3.241219]\n",
      "epoch:19 step:15266 [D loss: 0.344131, acc: 92.97%] [G loss: 2.997678]\n",
      "epoch:19 step:15267 [D loss: 0.743626, acc: 56.25%] [G loss: 2.456002]\n",
      "epoch:19 step:15268 [D loss: 0.664990, acc: 53.91%] [G loss: 3.141380]\n",
      "epoch:19 step:15269 [D loss: 0.560041, acc: 60.16%] [G loss: 2.316849]\n",
      "epoch:19 step:15270 [D loss: 0.461508, acc: 82.03%] [G loss: 3.301759]\n",
      "epoch:19 step:15271 [D loss: 0.779726, acc: 56.25%] [G loss: 1.882559]\n",
      "epoch:19 step:15272 [D loss: 0.401896, acc: 87.50%] [G loss: 2.760308]\n",
      "epoch:19 step:15273 [D loss: 0.171507, acc: 98.44%] [G loss: 3.266169]\n",
      "epoch:19 step:15274 [D loss: 0.252008, acc: 97.66%] [G loss: 3.313614]\n",
      "epoch:19 step:15275 [D loss: 0.730162, acc: 49.22%] [G loss: 3.798545]\n",
      "epoch:19 step:15276 [D loss: 0.723100, acc: 53.12%] [G loss: 3.210778]\n",
      "epoch:19 step:15277 [D loss: 0.548001, acc: 75.78%] [G loss: 2.478523]\n",
      "epoch:19 step:15278 [D loss: 0.686510, acc: 59.38%] [G loss: 2.250188]\n",
      "epoch:19 step:15279 [D loss: 0.693167, acc: 54.69%] [G loss: 2.222281]\n",
      "epoch:19 step:15280 [D loss: 0.484547, acc: 81.25%] [G loss: 2.959388]\n",
      "epoch:19 step:15281 [D loss: 0.348944, acc: 92.97%] [G loss: 3.635735]\n",
      "epoch:19 step:15282 [D loss: 0.938994, acc: 29.69%] [G loss: 3.079834]\n",
      "epoch:19 step:15283 [D loss: 0.297783, acc: 89.84%] [G loss: 2.496560]\n",
      "epoch:19 step:15284 [D loss: 0.515588, acc: 78.91%] [G loss: 1.724243]\n",
      "epoch:19 step:15285 [D loss: 0.860780, acc: 51.56%] [G loss: 4.092900]\n",
      "epoch:19 step:15286 [D loss: 0.496906, acc: 81.25%] [G loss: 2.920987]\n",
      "epoch:19 step:15287 [D loss: 0.621000, acc: 67.19%] [G loss: 4.086969]\n",
      "epoch:19 step:15288 [D loss: 0.449210, acc: 80.47%] [G loss: 2.469362]\n",
      "epoch:19 step:15289 [D loss: 0.591034, acc: 75.00%] [G loss: 3.453258]\n",
      "epoch:19 step:15290 [D loss: 0.685794, acc: 59.38%] [G loss: 2.861305]\n",
      "epoch:19 step:15291 [D loss: 0.727922, acc: 56.25%] [G loss: 2.495311]\n",
      "epoch:19 step:15292 [D loss: 0.208843, acc: 98.44%] [G loss: 3.593117]\n",
      "epoch:19 step:15293 [D loss: 0.436659, acc: 85.16%] [G loss: 3.531898]\n",
      "epoch:19 step:15294 [D loss: 0.488105, acc: 76.56%] [G loss: 3.426490]\n",
      "epoch:19 step:15295 [D loss: 0.706442, acc: 59.38%] [G loss: 2.581268]\n",
      "epoch:19 step:15296 [D loss: 0.448692, acc: 85.94%] [G loss: 3.413675]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15297 [D loss: 0.586152, acc: 67.19%] [G loss: 3.049250]\n",
      "epoch:19 step:15298 [D loss: 0.575248, acc: 71.88%] [G loss: 2.930262]\n",
      "epoch:19 step:15299 [D loss: 0.407364, acc: 87.50%] [G loss: 2.866365]\n",
      "epoch:19 step:15300 [D loss: 0.424104, acc: 78.91%] [G loss: 2.190626]\n",
      "epoch:19 step:15301 [D loss: 0.264711, acc: 95.31%] [G loss: 3.820635]\n",
      "epoch:19 step:15302 [D loss: 0.561735, acc: 73.44%] [G loss: 3.160942]\n",
      "epoch:19 step:15303 [D loss: 0.421950, acc: 89.84%] [G loss: 3.191921]\n",
      "epoch:19 step:15304 [D loss: 0.634961, acc: 64.84%] [G loss: 2.906094]\n",
      "epoch:19 step:15305 [D loss: 0.175199, acc: 99.22%] [G loss: 4.628987]\n",
      "epoch:19 step:15306 [D loss: 0.537365, acc: 67.19%] [G loss: 3.448243]\n",
      "epoch:19 step:15307 [D loss: 0.361612, acc: 93.75%] [G loss: 3.333334]\n",
      "epoch:19 step:15308 [D loss: 0.425252, acc: 81.25%] [G loss: 4.325653]\n",
      "epoch:19 step:15309 [D loss: 0.501204, acc: 82.03%] [G loss: 2.680662]\n",
      "epoch:19 step:15310 [D loss: 0.235919, acc: 96.88%] [G loss: 3.794141]\n",
      "epoch:19 step:15311 [D loss: 1.130456, acc: 25.00%] [G loss: 2.732324]\n",
      "epoch:19 step:15312 [D loss: 0.648224, acc: 58.59%] [G loss: 2.257984]\n",
      "epoch:19 step:15313 [D loss: 0.438456, acc: 83.59%] [G loss: 3.532022]\n",
      "epoch:19 step:15314 [D loss: 0.388002, acc: 90.62%] [G loss: 4.024213]\n",
      "epoch:19 step:15315 [D loss: 0.633955, acc: 62.50%] [G loss: 3.401317]\n",
      "epoch:19 step:15316 [D loss: 0.570165, acc: 64.84%] [G loss: 2.877211]\n",
      "epoch:19 step:15317 [D loss: 0.456391, acc: 88.28%] [G loss: 3.464680]\n",
      "epoch:19 step:15318 [D loss: 0.919397, acc: 32.03%] [G loss: 5.237915]\n",
      "epoch:19 step:15319 [D loss: 0.613555, acc: 64.84%] [G loss: 2.939950]\n",
      "epoch:19 step:15320 [D loss: 0.450203, acc: 85.94%] [G loss: 2.249415]\n",
      "epoch:19 step:15321 [D loss: 0.625937, acc: 62.50%] [G loss: 2.655231]\n",
      "epoch:19 step:15322 [D loss: 1.010696, acc: 29.69%] [G loss: 2.136508]\n",
      "epoch:19 step:15323 [D loss: 0.747579, acc: 49.22%] [G loss: 3.162864]\n",
      "epoch:19 step:15324 [D loss: 0.888490, acc: 35.16%] [G loss: 2.800063]\n",
      "epoch:19 step:15325 [D loss: 0.504704, acc: 79.69%] [G loss: 2.702989]\n",
      "epoch:19 step:15326 [D loss: 0.521480, acc: 78.91%] [G loss: 3.040037]\n",
      "epoch:19 step:15327 [D loss: 0.773832, acc: 47.66%] [G loss: 2.968755]\n",
      "epoch:19 step:15328 [D loss: 0.443683, acc: 83.59%] [G loss: 3.703097]\n",
      "epoch:19 step:15329 [D loss: 0.311010, acc: 96.88%] [G loss: 3.320311]\n",
      "epoch:19 step:15330 [D loss: 0.916790, acc: 43.75%] [G loss: 2.874925]\n",
      "epoch:19 step:15331 [D loss: 0.304375, acc: 95.31%] [G loss: 2.938334]\n",
      "epoch:19 step:15332 [D loss: 0.311519, acc: 92.97%] [G loss: 3.627789]\n",
      "epoch:19 step:15333 [D loss: 0.253891, acc: 97.66%] [G loss: 2.227981]\n",
      "epoch:19 step:15334 [D loss: 0.387992, acc: 88.28%] [G loss: 4.310294]\n",
      "epoch:19 step:15335 [D loss: 0.445886, acc: 85.94%] [G loss: 2.742485]\n",
      "epoch:19 step:15336 [D loss: 0.278776, acc: 95.31%] [G loss: 5.156235]\n",
      "epoch:19 step:15337 [D loss: 0.374945, acc: 77.34%] [G loss: 3.668203]\n",
      "epoch:19 step:15338 [D loss: 0.568711, acc: 67.19%] [G loss: 2.199588]\n",
      "epoch:19 step:15339 [D loss: 0.511589, acc: 76.56%] [G loss: 3.682050]\n",
      "epoch:19 step:15340 [D loss: 0.217233, acc: 99.22%] [G loss: 3.325121]\n",
      "epoch:19 step:15341 [D loss: 0.599137, acc: 69.53%] [G loss: 3.093488]\n",
      "epoch:19 step:15342 [D loss: 0.532284, acc: 69.53%] [G loss: 2.715277]\n",
      "epoch:19 step:15343 [D loss: 0.563096, acc: 71.88%] [G loss: 2.818991]\n",
      "epoch:19 step:15344 [D loss: 0.516652, acc: 78.91%] [G loss: 2.967259]\n",
      "epoch:19 step:15345 [D loss: 0.898581, acc: 46.09%] [G loss: 3.065204]\n",
      "epoch:19 step:15346 [D loss: 0.451660, acc: 87.50%] [G loss: 2.609174]\n",
      "epoch:19 step:15347 [D loss: 0.231877, acc: 97.66%] [G loss: 5.306164]\n",
      "epoch:19 step:15348 [D loss: 0.606744, acc: 68.75%] [G loss: 3.241683]\n",
      "epoch:19 step:15349 [D loss: 0.481779, acc: 81.25%] [G loss: 2.252733]\n",
      "epoch:19 step:15350 [D loss: 0.219408, acc: 96.88%] [G loss: 4.856290]\n",
      "epoch:19 step:15351 [D loss: 0.527335, acc: 77.34%] [G loss: 2.490246]\n",
      "epoch:19 step:15352 [D loss: 0.749750, acc: 53.91%] [G loss: 3.440468]\n",
      "epoch:19 step:15353 [D loss: 1.001729, acc: 31.25%] [G loss: 3.811264]\n",
      "epoch:19 step:15354 [D loss: 0.203016, acc: 98.44%] [G loss: 3.554724]\n",
      "epoch:19 step:15355 [D loss: 0.389078, acc: 89.06%] [G loss: 3.229429]\n",
      "epoch:19 step:15356 [D loss: 0.176875, acc: 97.66%] [G loss: 4.986410]\n",
      "epoch:19 step:15357 [D loss: 0.711788, acc: 58.59%] [G loss: 3.740237]\n",
      "epoch:19 step:15358 [D loss: 0.763031, acc: 48.44%] [G loss: 2.794019]\n",
      "epoch:19 step:15359 [D loss: 0.477059, acc: 78.91%] [G loss: 3.024601]\n",
      "epoch:19 step:15360 [D loss: 0.326754, acc: 93.75%] [G loss: 2.667991]\n",
      "epoch:19 step:15361 [D loss: 1.011899, acc: 27.34%] [G loss: 2.338703]\n",
      "epoch:19 step:15362 [D loss: 1.440333, acc: 7.03%] [G loss: 2.694123]\n",
      "epoch:19 step:15363 [D loss: 1.313944, acc: 12.50%] [G loss: 2.108134]\n",
      "epoch:19 step:15364 [D loss: 0.590287, acc: 71.09%] [G loss: 3.331729]\n",
      "epoch:19 step:15365 [D loss: 1.193917, acc: 22.66%] [G loss: 2.343232]\n",
      "epoch:19 step:15366 [D loss: 0.528286, acc: 68.75%] [G loss: 2.579984]\n",
      "epoch:19 step:15367 [D loss: 0.476605, acc: 85.16%] [G loss: 3.439229]\n",
      "epoch:19 step:15368 [D loss: 0.806385, acc: 45.31%] [G loss: 2.638131]\n",
      "epoch:19 step:15369 [D loss: 0.492009, acc: 82.03%] [G loss: 3.677626]\n",
      "epoch:19 step:15370 [D loss: 0.561232, acc: 64.84%] [G loss: 3.074281]\n",
      "epoch:19 step:15371 [D loss: 0.822582, acc: 45.31%] [G loss: 2.717993]\n",
      "epoch:19 step:15372 [D loss: 0.740101, acc: 54.69%] [G loss: 2.189308]\n",
      "epoch:19 step:15373 [D loss: 0.472646, acc: 85.16%] [G loss: 3.402048]\n",
      "epoch:19 step:15374 [D loss: 0.954589, acc: 27.34%] [G loss: 2.017261]\n",
      "epoch:19 step:15375 [D loss: 0.219345, acc: 99.22%] [G loss: 3.996516]\n",
      "epoch:19 step:15376 [D loss: 0.543409, acc: 68.75%] [G loss: 4.255326]\n",
      "epoch:19 step:15377 [D loss: 0.450919, acc: 80.47%] [G loss: 3.223100]\n",
      "epoch:19 step:15378 [D loss: 0.749280, acc: 54.69%] [G loss: 2.271339]\n",
      "epoch:19 step:15379 [D loss: 0.700436, acc: 54.69%] [G loss: 2.871685]\n",
      "epoch:19 step:15380 [D loss: 0.537152, acc: 71.09%] [G loss: 2.861597]\n",
      "epoch:19 step:15381 [D loss: 0.274171, acc: 94.53%] [G loss: 2.428191]\n",
      "epoch:19 step:15382 [D loss: 0.492955, acc: 71.09%] [G loss: 3.317580]\n",
      "epoch:19 step:15383 [D loss: 0.521776, acc: 76.56%] [G loss: 3.414730]\n",
      "epoch:19 step:15384 [D loss: 0.386559, acc: 82.81%] [G loss: 3.209920]\n",
      "epoch:19 step:15385 [D loss: 0.444886, acc: 87.50%] [G loss: 3.540575]\n",
      "epoch:19 step:15386 [D loss: 0.768910, acc: 53.12%] [G loss: 2.614650]\n",
      "epoch:19 step:15387 [D loss: 0.423737, acc: 77.34%] [G loss: 3.788936]\n",
      "epoch:19 step:15388 [D loss: 0.577772, acc: 71.88%] [G loss: 2.870210]\n",
      "epoch:19 step:15389 [D loss: 0.270427, acc: 96.09%] [G loss: 5.111150]\n",
      "epoch:19 step:15390 [D loss: 0.182436, acc: 98.44%] [G loss: 3.409683]\n",
      "epoch:19 step:15391 [D loss: 1.127939, acc: 24.22%] [G loss: 1.940081]\n",
      "epoch:19 step:15392 [D loss: 0.505662, acc: 78.91%] [G loss: 3.121351]\n",
      "epoch:19 step:15393 [D loss: 0.386631, acc: 77.34%] [G loss: 4.987838]\n",
      "epoch:19 step:15394 [D loss: 0.774826, acc: 53.91%] [G loss: 2.770297]\n",
      "epoch:19 step:15395 [D loss: 0.347435, acc: 92.97%] [G loss: 3.841692]\n",
      "epoch:19 step:15396 [D loss: 0.605028, acc: 59.38%] [G loss: 3.110261]\n",
      "epoch:19 step:15397 [D loss: 0.776402, acc: 49.22%] [G loss: 2.701085]\n",
      "epoch:19 step:15398 [D loss: 0.322813, acc: 96.09%] [G loss: 2.924754]\n",
      "epoch:19 step:15399 [D loss: 0.304003, acc: 97.66%] [G loss: 2.498356]\n",
      "epoch:19 step:15400 [D loss: 0.472962, acc: 80.47%] [G loss: 2.756550]\n",
      "epoch:19 step:15401 [D loss: 0.274116, acc: 96.88%] [G loss: 2.823312]\n",
      "epoch:19 step:15402 [D loss: 0.912716, acc: 31.25%] [G loss: 3.412425]\n",
      "epoch:19 step:15403 [D loss: 0.613913, acc: 66.41%] [G loss: 2.730480]\n",
      "epoch:19 step:15404 [D loss: 0.476934, acc: 80.47%] [G loss: 3.361938]\n",
      "epoch:19 step:15405 [D loss: 0.681233, acc: 57.81%] [G loss: 3.127695]\n",
      "epoch:19 step:15406 [D loss: 0.864554, acc: 43.75%] [G loss: 2.943798]\n",
      "epoch:19 step:15407 [D loss: 0.373831, acc: 92.19%] [G loss: 2.954690]\n",
      "epoch:19 step:15408 [D loss: 0.218365, acc: 97.66%] [G loss: 3.675795]\n",
      "epoch:19 step:15409 [D loss: 0.736054, acc: 51.56%] [G loss: 2.655669]\n",
      "epoch:19 step:15410 [D loss: 0.768874, acc: 41.41%] [G loss: 3.269359]\n",
      "epoch:19 step:15411 [D loss: 0.595214, acc: 70.31%] [G loss: 3.213315]\n",
      "epoch:19 step:15412 [D loss: 0.492464, acc: 77.34%] [G loss: 2.618501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15413 [D loss: 1.026648, acc: 24.22%] [G loss: 2.953746]\n",
      "epoch:19 step:15414 [D loss: 0.642110, acc: 65.62%] [G loss: 2.885673]\n",
      "epoch:19 step:15415 [D loss: 0.475391, acc: 75.00%] [G loss: 2.785318]\n",
      "epoch:19 step:15416 [D loss: 0.541074, acc: 66.41%] [G loss: 3.316446]\n",
      "epoch:19 step:15417 [D loss: 0.762728, acc: 57.03%] [G loss: 2.639956]\n",
      "epoch:19 step:15418 [D loss: 0.444904, acc: 75.78%] [G loss: 2.580281]\n",
      "epoch:19 step:15419 [D loss: 0.295794, acc: 96.88%] [G loss: 3.039539]\n",
      "epoch:19 step:15420 [D loss: 0.268067, acc: 96.09%] [G loss: 2.394289]\n",
      "epoch:19 step:15421 [D loss: 0.194246, acc: 98.44%] [G loss: 2.706302]\n",
      "epoch:19 step:15422 [D loss: 0.365636, acc: 85.16%] [G loss: 3.696708]\n",
      "epoch:19 step:15423 [D loss: 0.273867, acc: 94.53%] [G loss: 3.138847]\n",
      "epoch:19 step:15424 [D loss: 0.365927, acc: 92.19%] [G loss: 2.717551]\n",
      "epoch:19 step:15425 [D loss: 0.644322, acc: 62.50%] [G loss: 2.705097]\n",
      "epoch:19 step:15426 [D loss: 0.321599, acc: 95.31%] [G loss: 2.496964]\n",
      "epoch:19 step:15427 [D loss: 0.656434, acc: 64.84%] [G loss: 3.166507]\n",
      "epoch:19 step:15428 [D loss: 0.994797, acc: 25.00%] [G loss: 1.461267]\n",
      "epoch:19 step:15429 [D loss: 1.114894, acc: 28.91%] [G loss: 2.940236]\n",
      "epoch:19 step:15430 [D loss: 0.544980, acc: 74.22%] [G loss: 2.164386]\n",
      "epoch:19 step:15431 [D loss: 0.755404, acc: 53.12%] [G loss: 1.681016]\n",
      "epoch:19 step:15432 [D loss: 0.417513, acc: 71.88%] [G loss: 3.474798]\n",
      "epoch:19 step:15433 [D loss: 0.674908, acc: 60.94%] [G loss: 3.401284]\n",
      "epoch:19 step:15434 [D loss: 0.761053, acc: 51.56%] [G loss: 2.823001]\n",
      "epoch:19 step:15435 [D loss: 0.529840, acc: 75.78%] [G loss: 2.598490]\n",
      "epoch:19 step:15436 [D loss: 0.436830, acc: 78.91%] [G loss: 3.552677]\n",
      "epoch:19 step:15437 [D loss: 0.747242, acc: 47.66%] [G loss: 2.671504]\n",
      "epoch:19 step:15438 [D loss: 0.823971, acc: 49.22%] [G loss: 3.194191]\n",
      "epoch:19 step:15439 [D loss: 0.326774, acc: 87.50%] [G loss: 2.697927]\n",
      "epoch:19 step:15440 [D loss: 0.377208, acc: 82.81%] [G loss: 3.662553]\n",
      "epoch:19 step:15441 [D loss: 0.298049, acc: 87.50%] [G loss: 3.830702]\n",
      "epoch:19 step:15442 [D loss: 0.880863, acc: 50.78%] [G loss: 3.018357]\n",
      "epoch:19 step:15443 [D loss: 0.329623, acc: 92.97%] [G loss: 3.937515]\n",
      "epoch:19 step:15444 [D loss: 0.285046, acc: 91.41%] [G loss: 3.404105]\n",
      "epoch:19 step:15445 [D loss: 0.281005, acc: 98.44%] [G loss: 3.699728]\n",
      "epoch:19 step:15446 [D loss: 0.541249, acc: 71.09%] [G loss: 2.776845]\n",
      "epoch:19 step:15447 [D loss: 0.346077, acc: 93.75%] [G loss: 1.847360]\n",
      "epoch:19 step:15448 [D loss: 0.741811, acc: 50.00%] [G loss: 2.239828]\n",
      "epoch:19 step:15449 [D loss: 0.416894, acc: 89.06%] [G loss: 3.740407]\n",
      "epoch:19 step:15450 [D loss: 0.588878, acc: 69.53%] [G loss: 3.012003]\n",
      "epoch:19 step:15451 [D loss: 0.510822, acc: 77.34%] [G loss: 2.723873]\n",
      "epoch:19 step:15452 [D loss: 1.103777, acc: 24.22%] [G loss: 3.037269]\n",
      "epoch:19 step:15453 [D loss: 0.342932, acc: 93.75%] [G loss: 4.355603]\n",
      "epoch:19 step:15454 [D loss: 0.646052, acc: 65.62%] [G loss: 3.008284]\n",
      "epoch:19 step:15455 [D loss: 0.422923, acc: 82.03%] [G loss: 2.484047]\n",
      "epoch:19 step:15456 [D loss: 0.287224, acc: 96.09%] [G loss: 3.360809]\n",
      "epoch:19 step:15457 [D loss: 0.356484, acc: 85.94%] [G loss: 3.441965]\n",
      "epoch:19 step:15458 [D loss: 0.774521, acc: 50.00%] [G loss: 2.119282]\n",
      "epoch:19 step:15459 [D loss: 0.744773, acc: 42.97%] [G loss: 3.146777]\n",
      "epoch:19 step:15460 [D loss: 0.407680, acc: 86.72%] [G loss: 2.813287]\n",
      "epoch:19 step:15461 [D loss: 0.577466, acc: 69.53%] [G loss: 2.497685]\n",
      "epoch:19 step:15462 [D loss: 0.828455, acc: 48.44%] [G loss: 3.664060]\n",
      "epoch:19 step:15463 [D loss: 0.380923, acc: 88.28%] [G loss: 3.372835]\n",
      "epoch:19 step:15464 [D loss: 0.383255, acc: 89.84%] [G loss: 3.518278]\n",
      "epoch:19 step:15465 [D loss: 0.541273, acc: 68.75%] [G loss: 2.201796]\n",
      "epoch:19 step:15466 [D loss: 0.450395, acc: 83.59%] [G loss: 2.626940]\n",
      "epoch:19 step:15467 [D loss: 0.736142, acc: 57.03%] [G loss: 2.967853]\n",
      "epoch:19 step:15468 [D loss: 0.576944, acc: 69.53%] [G loss: 2.946156]\n",
      "epoch:19 step:15469 [D loss: 0.236630, acc: 100.00%] [G loss: 4.140656]\n",
      "epoch:19 step:15470 [D loss: 0.562448, acc: 72.66%] [G loss: 2.630878]\n",
      "epoch:19 step:15471 [D loss: 0.303768, acc: 92.19%] [G loss: 2.588820]\n",
      "epoch:19 step:15472 [D loss: 0.653241, acc: 63.28%] [G loss: 4.719098]\n",
      "epoch:19 step:15473 [D loss: 0.765874, acc: 54.69%] [G loss: 2.596878]\n",
      "epoch:19 step:15474 [D loss: 0.513447, acc: 78.91%] [G loss: 3.098883]\n",
      "epoch:19 step:15475 [D loss: 0.286182, acc: 97.66%] [G loss: 3.017711]\n",
      "epoch:19 step:15476 [D loss: 0.482798, acc: 82.81%] [G loss: 2.675229]\n",
      "epoch:19 step:15477 [D loss: 0.384793, acc: 89.06%] [G loss: 3.491100]\n",
      "epoch:19 step:15478 [D loss: 0.747063, acc: 47.66%] [G loss: 3.095036]\n",
      "epoch:19 step:15479 [D loss: 0.607873, acc: 64.06%] [G loss: 3.583309]\n",
      "epoch:19 step:15480 [D loss: 0.540392, acc: 67.19%] [G loss: 2.614903]\n",
      "epoch:19 step:15481 [D loss: 0.455030, acc: 81.25%] [G loss: 3.198972]\n",
      "epoch:19 step:15482 [D loss: 0.282475, acc: 92.97%] [G loss: 3.925018]\n",
      "epoch:19 step:15483 [D loss: 0.401381, acc: 84.38%] [G loss: 3.403776]\n",
      "epoch:19 step:15484 [D loss: 0.439796, acc: 85.94%] [G loss: 2.649079]\n",
      "epoch:19 step:15485 [D loss: 0.348317, acc: 93.75%] [G loss: 3.896461]\n",
      "epoch:19 step:15486 [D loss: 1.491625, acc: 7.03%] [G loss: 2.566927]\n",
      "epoch:19 step:15487 [D loss: 0.333304, acc: 92.19%] [G loss: 2.285503]\n",
      "epoch:19 step:15488 [D loss: 0.475605, acc: 77.34%] [G loss: 3.173371]\n",
      "epoch:19 step:15489 [D loss: 0.810913, acc: 46.88%] [G loss: 2.358966]\n",
      "epoch:19 step:15490 [D loss: 0.559577, acc: 71.88%] [G loss: 2.490040]\n",
      "epoch:19 step:15491 [D loss: 0.417001, acc: 86.72%] [G loss: 2.694004]\n",
      "epoch:19 step:15492 [D loss: 0.319042, acc: 96.09%] [G loss: 3.534821]\n",
      "epoch:19 step:15493 [D loss: 0.403837, acc: 86.72%] [G loss: 3.062786]\n",
      "epoch:19 step:15494 [D loss: 0.194823, acc: 98.44%] [G loss: 2.986486]\n",
      "epoch:19 step:15495 [D loss: 1.089219, acc: 24.22%] [G loss: 2.102169]\n",
      "epoch:19 step:15496 [D loss: 0.541719, acc: 67.19%] [G loss: 3.278758]\n",
      "epoch:19 step:15497 [D loss: 0.276375, acc: 92.19%] [G loss: 2.725083]\n",
      "epoch:19 step:15498 [D loss: 0.411444, acc: 92.19%] [G loss: 2.848424]\n",
      "epoch:19 step:15499 [D loss: 0.302142, acc: 90.62%] [G loss: 3.083300]\n",
      "epoch:19 step:15500 [D loss: 0.329975, acc: 89.06%] [G loss: 3.651853]\n",
      "epoch:19 step:15501 [D loss: 0.212298, acc: 98.44%] [G loss: 4.755339]\n",
      "epoch:19 step:15502 [D loss: 0.439288, acc: 88.28%] [G loss: 2.752154]\n",
      "epoch:19 step:15503 [D loss: 0.329853, acc: 93.75%] [G loss: 3.138471]\n",
      "epoch:19 step:15504 [D loss: 0.725419, acc: 61.72%] [G loss: 3.021963]\n",
      "epoch:19 step:15505 [D loss: 0.961591, acc: 32.81%] [G loss: 3.412685]\n",
      "epoch:19 step:15506 [D loss: 0.698320, acc: 55.47%] [G loss: 4.583525]\n",
      "epoch:19 step:15507 [D loss: 0.747353, acc: 51.56%] [G loss: 2.951676]\n",
      "epoch:19 step:15508 [D loss: 0.505871, acc: 61.72%] [G loss: 2.953832]\n",
      "epoch:19 step:15509 [D loss: 0.602820, acc: 64.84%] [G loss: 2.854903]\n",
      "epoch:19 step:15510 [D loss: 0.719675, acc: 46.88%] [G loss: 3.079942]\n",
      "epoch:19 step:15511 [D loss: 0.904300, acc: 30.47%] [G loss: 2.421860]\n",
      "epoch:19 step:15512 [D loss: 0.612797, acc: 64.06%] [G loss: 2.546597]\n",
      "epoch:19 step:15513 [D loss: 0.718141, acc: 55.47%] [G loss: 2.655377]\n",
      "epoch:19 step:15514 [D loss: 0.703952, acc: 58.59%] [G loss: 2.872317]\n",
      "epoch:19 step:15515 [D loss: 0.531728, acc: 78.12%] [G loss: 2.648066]\n",
      "epoch:19 step:15516 [D loss: 0.183433, acc: 99.22%] [G loss: 2.986248]\n",
      "epoch:19 step:15517 [D loss: 0.375098, acc: 89.84%] [G loss: 2.659222]\n",
      "epoch:19 step:15518 [D loss: 0.389888, acc: 89.06%] [G loss: 2.988835]\n",
      "epoch:19 step:15519 [D loss: 0.474978, acc: 65.62%] [G loss: 2.689245]\n",
      "epoch:19 step:15520 [D loss: 0.345026, acc: 86.72%] [G loss: 4.071395]\n",
      "epoch:19 step:15521 [D loss: 0.243027, acc: 96.88%] [G loss: 2.490850]\n",
      "epoch:19 step:15522 [D loss: 0.252694, acc: 95.31%] [G loss: 4.002711]\n",
      "epoch:19 step:15523 [D loss: 0.654560, acc: 57.03%] [G loss: 3.040556]\n",
      "epoch:19 step:15524 [D loss: 0.443663, acc: 80.47%] [G loss: 3.211324]\n",
      "epoch:19 step:15525 [D loss: 0.625689, acc: 54.69%] [G loss: 5.058556]\n",
      "epoch:19 step:15526 [D loss: 0.216216, acc: 99.22%] [G loss: 3.404798]\n",
      "epoch:19 step:15527 [D loss: 0.381429, acc: 81.25%] [G loss: 3.538198]\n",
      "epoch:19 step:15528 [D loss: 0.325950, acc: 92.97%] [G loss: 3.317519]\n",
      "epoch:19 step:15529 [D loss: 0.138098, acc: 100.00%] [G loss: 4.702184]\n",
      "epoch:19 step:15530 [D loss: 0.436323, acc: 83.59%] [G loss: 2.449954]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15531 [D loss: 0.996928, acc: 39.84%] [G loss: 4.244050]\n",
      "epoch:19 step:15532 [D loss: 0.678524, acc: 57.03%] [G loss: 2.635330]\n",
      "epoch:19 step:15533 [D loss: 0.540049, acc: 71.09%] [G loss: 2.557326]\n",
      "epoch:19 step:15534 [D loss: 0.627212, acc: 64.06%] [G loss: 2.462468]\n",
      "epoch:19 step:15535 [D loss: 0.818750, acc: 40.62%] [G loss: 3.028682]\n",
      "epoch:19 step:15536 [D loss: 0.522032, acc: 76.56%] [G loss: 4.081162]\n",
      "epoch:19 step:15537 [D loss: 0.687688, acc: 57.81%] [G loss: 2.294270]\n",
      "epoch:19 step:15538 [D loss: 0.649288, acc: 67.97%] [G loss: 2.680975]\n",
      "epoch:19 step:15539 [D loss: 0.751441, acc: 49.22%] [G loss: 2.738959]\n",
      "epoch:19 step:15540 [D loss: 0.417124, acc: 73.44%] [G loss: 2.973723]\n",
      "epoch:19 step:15541 [D loss: 0.592830, acc: 63.28%] [G loss: 3.265540]\n",
      "epoch:19 step:15542 [D loss: 0.713604, acc: 56.25%] [G loss: 2.984230]\n",
      "epoch:19 step:15543 [D loss: 0.894724, acc: 31.25%] [G loss: 2.444312]\n",
      "epoch:19 step:15544 [D loss: 0.507018, acc: 66.41%] [G loss: 3.285087]\n",
      "epoch:19 step:15545 [D loss: 0.606112, acc: 67.97%] [G loss: 3.419031]\n",
      "epoch:19 step:15546 [D loss: 0.482071, acc: 73.44%] [G loss: 2.762921]\n",
      "epoch:19 step:15547 [D loss: 0.321381, acc: 92.19%] [G loss: 3.100621]\n",
      "epoch:19 step:15548 [D loss: 0.656521, acc: 61.72%] [G loss: 3.610111]\n",
      "epoch:19 step:15549 [D loss: 0.686923, acc: 57.03%] [G loss: 3.869276]\n",
      "epoch:19 step:15550 [D loss: 0.339613, acc: 84.38%] [G loss: 3.815083]\n",
      "epoch:19 step:15551 [D loss: 0.350558, acc: 90.62%] [G loss: 4.186368]\n",
      "epoch:19 step:15552 [D loss: 0.359610, acc: 91.41%] [G loss: 3.426157]\n",
      "epoch:19 step:15553 [D loss: 0.467686, acc: 83.59%] [G loss: 3.163965]\n",
      "epoch:19 step:15554 [D loss: 0.486000, acc: 82.81%] [G loss: 2.960101]\n",
      "epoch:19 step:15555 [D loss: 0.535183, acc: 71.09%] [G loss: 2.255539]\n",
      "epoch:19 step:15556 [D loss: 0.602879, acc: 66.41%] [G loss: 2.363627]\n",
      "epoch:19 step:15557 [D loss: 0.365412, acc: 93.75%] [G loss: 3.251118]\n",
      "epoch:19 step:15558 [D loss: 0.392255, acc: 88.28%] [G loss: 3.954886]\n",
      "epoch:19 step:15559 [D loss: 0.498506, acc: 79.69%] [G loss: 2.402808]\n",
      "epoch:19 step:15560 [D loss: 0.333469, acc: 96.09%] [G loss: 2.900961]\n",
      "epoch:19 step:15561 [D loss: 0.392900, acc: 92.19%] [G loss: 2.591085]\n",
      "epoch:19 step:15562 [D loss: 0.290484, acc: 96.88%] [G loss: 3.089681]\n",
      "epoch:19 step:15563 [D loss: 0.434567, acc: 80.47%] [G loss: 3.192644]\n",
      "epoch:19 step:15564 [D loss: 0.392412, acc: 82.03%] [G loss: 2.432563]\n",
      "epoch:19 step:15565 [D loss: 0.502708, acc: 84.38%] [G loss: 2.296096]\n",
      "epoch:19 step:15566 [D loss: 0.441762, acc: 83.59%] [G loss: 3.120970]\n",
      "epoch:19 step:15567 [D loss: 0.127921, acc: 100.00%] [G loss: 4.187409]\n",
      "epoch:19 step:15568 [D loss: 0.922015, acc: 47.66%] [G loss: 2.035735]\n",
      "epoch:19 step:15569 [D loss: 0.584685, acc: 65.62%] [G loss: 4.095050]\n",
      "epoch:19 step:15570 [D loss: 0.355189, acc: 96.09%] [G loss: 3.250206]\n",
      "epoch:19 step:15571 [D loss: 0.342961, acc: 87.50%] [G loss: 4.388006]\n",
      "epoch:19 step:15572 [D loss: 0.499361, acc: 80.47%] [G loss: 4.624354]\n",
      "epoch:19 step:15573 [D loss: 0.375853, acc: 88.28%] [G loss: 2.878493]\n",
      "epoch:19 step:15574 [D loss: 0.365475, acc: 86.72%] [G loss: 3.515967]\n",
      "epoch:19 step:15575 [D loss: 0.483760, acc: 71.88%] [G loss: 3.001016]\n",
      "epoch:19 step:15576 [D loss: 0.469034, acc: 84.38%] [G loss: 2.901602]\n",
      "epoch:19 step:15577 [D loss: 0.634417, acc: 60.94%] [G loss: 2.387975]\n",
      "epoch:19 step:15578 [D loss: 0.360914, acc: 93.75%] [G loss: 3.295526]\n",
      "epoch:19 step:15579 [D loss: 0.590209, acc: 69.53%] [G loss: 3.148322]\n",
      "epoch:19 step:15580 [D loss: 0.207377, acc: 99.22%] [G loss: 3.460669]\n",
      "epoch:19 step:15581 [D loss: 1.190070, acc: 29.69%] [G loss: 2.629970]\n",
      "epoch:19 step:15582 [D loss: 0.714115, acc: 53.91%] [G loss: 3.477253]\n",
      "epoch:19 step:15583 [D loss: 0.544853, acc: 75.78%] [G loss: 2.873207]\n",
      "epoch:19 step:15584 [D loss: 0.453264, acc: 83.59%] [G loss: 3.432443]\n",
      "epoch:19 step:15585 [D loss: 0.411697, acc: 89.84%] [G loss: 1.951611]\n",
      "epoch:19 step:15586 [D loss: 0.896119, acc: 39.06%] [G loss: 3.241688]\n",
      "epoch:19 step:15587 [D loss: 0.208244, acc: 97.66%] [G loss: 3.544518]\n",
      "epoch:19 step:15588 [D loss: 0.943649, acc: 38.28%] [G loss: 1.809900]\n",
      "epoch:19 step:15589 [D loss: 0.398832, acc: 87.50%] [G loss: 2.333808]\n",
      "epoch:19 step:15590 [D loss: 0.478748, acc: 64.06%] [G loss: 3.849470]\n",
      "epoch:19 step:15591 [D loss: 0.883525, acc: 50.00%] [G loss: 2.949994]\n",
      "epoch:19 step:15592 [D loss: 0.563250, acc: 74.22%] [G loss: 2.645292]\n",
      "epoch:19 step:15593 [D loss: 0.360709, acc: 89.84%] [G loss: 4.472044]\n",
      "epoch:19 step:15594 [D loss: 0.724959, acc: 60.94%] [G loss: 2.297054]\n",
      "epoch:19 step:15595 [D loss: 0.250470, acc: 96.88%] [G loss: 3.179006]\n",
      "epoch:19 step:15596 [D loss: 0.958891, acc: 34.38%] [G loss: 2.678343]\n",
      "epoch:19 step:15597 [D loss: 0.235206, acc: 95.31%] [G loss: 3.041882]\n",
      "epoch:19 step:15598 [D loss: 0.782053, acc: 45.31%] [G loss: 2.617297]\n",
      "epoch:19 step:15599 [D loss: 0.476977, acc: 85.94%] [G loss: 3.702439]\n",
      "epoch:19 step:15600 [D loss: 0.351781, acc: 89.06%] [G loss: 2.254620]\n",
      "epoch:19 step:15601 [D loss: 0.677159, acc: 62.50%] [G loss: 3.143406]\n",
      "epoch:19 step:15602 [D loss: 0.678035, acc: 60.94%] [G loss: 3.074091]\n",
      "epoch:19 step:15603 [D loss: 0.530082, acc: 78.12%] [G loss: 2.992183]\n",
      "epoch:19 step:15604 [D loss: 1.262210, acc: 12.50%] [G loss: 2.193978]\n",
      "epoch:19 step:15605 [D loss: 0.442757, acc: 82.81%] [G loss: 3.460554]\n",
      "epoch:19 step:15606 [D loss: 0.194503, acc: 100.00%] [G loss: 3.610038]\n",
      "epoch:19 step:15607 [D loss: 0.444228, acc: 82.81%] [G loss: 3.247018]\n",
      "epoch:19 step:15608 [D loss: 0.317935, acc: 92.97%] [G loss: 3.520381]\n",
      "epoch:19 step:15609 [D loss: 0.441653, acc: 82.81%] [G loss: 3.171861]\n",
      "epoch:19 step:15610 [D loss: 0.851054, acc: 42.19%] [G loss: 2.711123]\n",
      "epoch:19 step:15611 [D loss: 0.459328, acc: 82.03%] [G loss: 2.849571]\n",
      "epoch:19 step:15612 [D loss: 0.175630, acc: 100.00%] [G loss: 3.770488]\n",
      "epoch:19 step:15613 [D loss: 0.576502, acc: 73.44%] [G loss: 2.903391]\n",
      "epoch:19 step:15614 [D loss: 0.749928, acc: 57.03%] [G loss: 2.718464]\n",
      "epoch:19 step:15615 [D loss: 0.432692, acc: 87.50%] [G loss: 2.491435]\n",
      "epoch:19 step:15616 [D loss: 0.658283, acc: 62.50%] [G loss: 3.581219]\n",
      "epoch:19 step:15617 [D loss: 0.850175, acc: 45.31%] [G loss: 2.297596]\n",
      "epoch:19 step:15618 [D loss: 0.579839, acc: 67.97%] [G loss: 3.101282]\n",
      "epoch:19 step:15619 [D loss: 0.898887, acc: 38.28%] [G loss: 1.880703]\n",
      "epoch:19 step:15620 [D loss: 0.568578, acc: 72.66%] [G loss: 2.097077]\n",
      "epoch:20 step:15621 [D loss: 0.330644, acc: 93.75%] [G loss: 3.040418]\n",
      "epoch:20 step:15622 [D loss: 0.345396, acc: 89.84%] [G loss: 3.293109]\n",
      "epoch:20 step:15623 [D loss: 0.774025, acc: 49.22%] [G loss: 2.187019]\n",
      "epoch:20 step:15624 [D loss: 0.996778, acc: 28.12%] [G loss: 2.330175]\n",
      "epoch:20 step:15625 [D loss: 0.341295, acc: 96.88%] [G loss: 3.018546]\n",
      "epoch:20 step:15626 [D loss: 0.535676, acc: 66.41%] [G loss: 2.105103]\n",
      "epoch:20 step:15627 [D loss: 0.480598, acc: 78.91%] [G loss: 3.603594]\n",
      "epoch:20 step:15628 [D loss: 0.674364, acc: 57.03%] [G loss: 2.985663]\n",
      "epoch:20 step:15629 [D loss: 0.614388, acc: 57.03%] [G loss: 2.731312]\n",
      "epoch:20 step:15630 [D loss: 0.499240, acc: 75.00%] [G loss: 3.585368]\n",
      "epoch:20 step:15631 [D loss: 0.273244, acc: 97.66%] [G loss: 4.265344]\n",
      "epoch:20 step:15632 [D loss: 0.275467, acc: 96.88%] [G loss: 2.764389]\n",
      "epoch:20 step:15633 [D loss: 0.543236, acc: 75.00%] [G loss: 2.834527]\n",
      "epoch:20 step:15634 [D loss: 0.668607, acc: 64.06%] [G loss: 2.524820]\n",
      "epoch:20 step:15635 [D loss: 0.947681, acc: 29.69%] [G loss: 2.583167]\n",
      "epoch:20 step:15636 [D loss: 0.955449, acc: 31.25%] [G loss: 2.538700]\n",
      "epoch:20 step:15637 [D loss: 0.970981, acc: 29.69%] [G loss: 2.900445]\n",
      "epoch:20 step:15638 [D loss: 0.636086, acc: 60.94%] [G loss: 2.225308]\n",
      "epoch:20 step:15639 [D loss: 0.455144, acc: 87.50%] [G loss: 3.693357]\n",
      "epoch:20 step:15640 [D loss: 1.182631, acc: 22.66%] [G loss: 2.562407]\n",
      "epoch:20 step:15641 [D loss: 0.692692, acc: 53.12%] [G loss: 2.379454]\n",
      "epoch:20 step:15642 [D loss: 0.352749, acc: 91.41%] [G loss: 3.539379]\n",
      "epoch:20 step:15643 [D loss: 0.733997, acc: 49.22%] [G loss: 3.414133]\n",
      "epoch:20 step:15644 [D loss: 0.550639, acc: 71.88%] [G loss: 3.512872]\n",
      "epoch:20 step:15645 [D loss: 0.361425, acc: 80.47%] [G loss: 2.758513]\n",
      "epoch:20 step:15646 [D loss: 0.685871, acc: 60.94%] [G loss: 2.652919]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:15647 [D loss: 0.806086, acc: 52.34%] [G loss: 2.816785]\n",
      "epoch:20 step:15648 [D loss: 0.423779, acc: 74.22%] [G loss: 2.528718]\n",
      "epoch:20 step:15649 [D loss: 0.280968, acc: 95.31%] [G loss: 2.064931]\n",
      "epoch:20 step:15650 [D loss: 0.170871, acc: 100.00%] [G loss: 4.854803]\n",
      "epoch:20 step:15651 [D loss: 0.781239, acc: 40.62%] [G loss: 2.894337]\n",
      "epoch:20 step:15652 [D loss: 0.452433, acc: 78.91%] [G loss: 3.667740]\n",
      "epoch:20 step:15653 [D loss: 0.455531, acc: 77.34%] [G loss: 2.648575]\n",
      "epoch:20 step:15654 [D loss: 0.385854, acc: 90.62%] [G loss: 2.677787]\n",
      "epoch:20 step:15655 [D loss: 0.668499, acc: 65.62%] [G loss: 4.279392]\n",
      "epoch:20 step:15656 [D loss: 0.345064, acc: 89.84%] [G loss: 3.606739]\n",
      "epoch:20 step:15657 [D loss: 0.314015, acc: 96.09%] [G loss: 2.765304]\n",
      "epoch:20 step:15658 [D loss: 0.157103, acc: 97.66%] [G loss: 5.215959]\n",
      "epoch:20 step:15659 [D loss: 0.530492, acc: 63.28%] [G loss: 3.394009]\n",
      "epoch:20 step:15660 [D loss: 0.431714, acc: 88.28%] [G loss: 2.357598]\n",
      "epoch:20 step:15661 [D loss: 0.866775, acc: 45.31%] [G loss: 2.557821]\n",
      "epoch:20 step:15662 [D loss: 0.783031, acc: 50.00%] [G loss: 2.707395]\n",
      "epoch:20 step:15663 [D loss: 0.416067, acc: 85.16%] [G loss: 2.460217]\n",
      "epoch:20 step:15664 [D loss: 0.340152, acc: 89.84%] [G loss: 3.299366]\n",
      "epoch:20 step:15665 [D loss: 0.500627, acc: 72.66%] [G loss: 3.013245]\n",
      "epoch:20 step:15666 [D loss: 0.512912, acc: 65.62%] [G loss: 3.699599]\n",
      "epoch:20 step:15667 [D loss: 0.574010, acc: 73.44%] [G loss: 2.374919]\n",
      "epoch:20 step:15668 [D loss: 1.036759, acc: 40.62%] [G loss: 2.431512]\n",
      "epoch:20 step:15669 [D loss: 0.627217, acc: 67.19%] [G loss: 3.074735]\n",
      "epoch:20 step:15670 [D loss: 0.671848, acc: 60.16%] [G loss: 2.067300]\n",
      "epoch:20 step:15671 [D loss: 0.723894, acc: 50.00%] [G loss: 3.405824]\n",
      "epoch:20 step:15672 [D loss: 0.247855, acc: 97.66%] [G loss: 3.872086]\n",
      "epoch:20 step:15673 [D loss: 1.005848, acc: 41.41%] [G loss: 2.308748]\n",
      "epoch:20 step:15674 [D loss: 1.008693, acc: 51.56%] [G loss: 3.118441]\n",
      "epoch:20 step:15675 [D loss: 0.665005, acc: 61.72%] [G loss: 2.837082]\n",
      "epoch:20 step:15676 [D loss: 0.457038, acc: 84.38%] [G loss: 2.597368]\n",
      "epoch:20 step:15677 [D loss: 0.292425, acc: 96.88%] [G loss: 3.644303]\n",
      "epoch:20 step:15678 [D loss: 0.452928, acc: 82.81%] [G loss: 3.038224]\n",
      "epoch:20 step:15679 [D loss: 0.707702, acc: 60.16%] [G loss: 2.961601]\n",
      "epoch:20 step:15680 [D loss: 0.490519, acc: 78.12%] [G loss: 2.582855]\n",
      "epoch:20 step:15681 [D loss: 0.644348, acc: 62.50%] [G loss: 3.445886]\n",
      "epoch:20 step:15682 [D loss: 0.423101, acc: 76.56%] [G loss: 2.947558]\n",
      "epoch:20 step:15683 [D loss: 0.518128, acc: 75.78%] [G loss: 3.063014]\n",
      "epoch:20 step:15684 [D loss: 0.695185, acc: 60.94%] [G loss: 3.822824]\n",
      "epoch:20 step:15685 [D loss: 1.065731, acc: 25.00%] [G loss: 2.445002]\n",
      "epoch:20 step:15686 [D loss: 0.328674, acc: 93.75%] [G loss: 2.795795]\n",
      "epoch:20 step:15687 [D loss: 0.672371, acc: 61.72%] [G loss: 3.514342]\n",
      "epoch:20 step:15688 [D loss: 0.560451, acc: 69.53%] [G loss: 3.463228]\n",
      "epoch:20 step:15689 [D loss: 0.872328, acc: 37.50%] [G loss: 2.633662]\n",
      "epoch:20 step:15690 [D loss: 0.838128, acc: 39.84%] [G loss: 2.506342]\n",
      "epoch:20 step:15691 [D loss: 1.226832, acc: 31.25%] [G loss: 3.276838]\n",
      "epoch:20 step:15692 [D loss: 0.805672, acc: 52.34%] [G loss: 3.041870]\n",
      "epoch:20 step:15693 [D loss: 0.302557, acc: 89.84%] [G loss: 3.856311]\n",
      "epoch:20 step:15694 [D loss: 0.664298, acc: 58.59%] [G loss: 3.464421]\n",
      "epoch:20 step:15695 [D loss: 0.215722, acc: 97.66%] [G loss: 4.240205]\n",
      "epoch:20 step:15696 [D loss: 0.678307, acc: 56.25%] [G loss: 2.573461]\n",
      "epoch:20 step:15697 [D loss: 1.056887, acc: 21.09%] [G loss: 2.870198]\n",
      "epoch:20 step:15698 [D loss: 0.366376, acc: 89.84%] [G loss: 2.640381]\n",
      "epoch:20 step:15699 [D loss: 0.377746, acc: 90.62%] [G loss: 2.853361]\n",
      "epoch:20 step:15700 [D loss: 0.457428, acc: 71.88%] [G loss: 4.046672]\n",
      "epoch:20 step:15701 [D loss: 0.640940, acc: 57.81%] [G loss: 2.295548]\n",
      "epoch:20 step:15702 [D loss: 0.459712, acc: 78.12%] [G loss: 3.195765]\n",
      "epoch:20 step:15703 [D loss: 0.303867, acc: 96.88%] [G loss: 5.245025]\n",
      "epoch:20 step:15704 [D loss: 0.815504, acc: 50.00%] [G loss: 2.839824]\n",
      "epoch:20 step:15705 [D loss: 0.725905, acc: 54.69%] [G loss: 2.566568]\n",
      "epoch:20 step:15706 [D loss: 0.336065, acc: 92.19%] [G loss: 2.754762]\n",
      "epoch:20 step:15707 [D loss: 0.375839, acc: 85.16%] [G loss: 3.001621]\n",
      "epoch:20 step:15708 [D loss: 0.425067, acc: 73.44%] [G loss: 3.824210]\n",
      "epoch:20 step:15709 [D loss: 0.764682, acc: 52.34%] [G loss: 3.550139]\n",
      "epoch:20 step:15710 [D loss: 0.471404, acc: 77.34%] [G loss: 3.807317]\n",
      "epoch:20 step:15711 [D loss: 0.409113, acc: 88.28%] [G loss: 3.894365]\n",
      "epoch:20 step:15712 [D loss: 0.788299, acc: 50.00%] [G loss: 3.118180]\n",
      "epoch:20 step:15713 [D loss: 0.795231, acc: 51.56%] [G loss: 1.793515]\n",
      "epoch:20 step:15714 [D loss: 0.698701, acc: 55.47%] [G loss: 2.943084]\n",
      "epoch:20 step:15715 [D loss: 0.494418, acc: 83.59%] [G loss: 3.422112]\n",
      "epoch:20 step:15716 [D loss: 0.816204, acc: 53.12%] [G loss: 2.401433]\n",
      "epoch:20 step:15717 [D loss: 0.708317, acc: 47.66%] [G loss: 2.452729]\n",
      "epoch:20 step:15718 [D loss: 0.661521, acc: 59.38%] [G loss: 2.487446]\n",
      "epoch:20 step:15719 [D loss: 0.650410, acc: 64.84%] [G loss: 1.848107]\n",
      "epoch:20 step:15720 [D loss: 0.289453, acc: 96.88%] [G loss: 2.295074]\n",
      "epoch:20 step:15721 [D loss: 0.357495, acc: 85.16%] [G loss: 3.125554]\n",
      "epoch:20 step:15722 [D loss: 0.313771, acc: 96.88%] [G loss: 2.838678]\n",
      "epoch:20 step:15723 [D loss: 1.010513, acc: 22.66%] [G loss: 2.223740]\n",
      "epoch:20 step:15724 [D loss: 0.578482, acc: 60.16%] [G loss: 2.756538]\n",
      "epoch:20 step:15725 [D loss: 0.588921, acc: 60.16%] [G loss: 2.656689]\n",
      "epoch:20 step:15726 [D loss: 0.564793, acc: 67.97%] [G loss: 1.111740]\n",
      "epoch:20 step:15727 [D loss: 0.474905, acc: 85.94%] [G loss: 2.399119]\n",
      "epoch:20 step:15728 [D loss: 0.966962, acc: 35.16%] [G loss: 1.911480]\n",
      "epoch:20 step:15729 [D loss: 0.287849, acc: 91.41%] [G loss: 2.763281]\n",
      "epoch:20 step:15730 [D loss: 0.532951, acc: 68.75%] [G loss: 2.714374]\n",
      "epoch:20 step:15731 [D loss: 0.738028, acc: 50.00%] [G loss: 2.624562]\n",
      "epoch:20 step:15732 [D loss: 0.374678, acc: 89.84%] [G loss: 2.605539]\n",
      "epoch:20 step:15733 [D loss: 0.661510, acc: 54.69%] [G loss: 3.078386]\n",
      "epoch:20 step:15734 [D loss: 0.704854, acc: 53.12%] [G loss: 2.777954]\n",
      "epoch:20 step:15735 [D loss: 0.658667, acc: 57.81%] [G loss: 3.043023]\n",
      "epoch:20 step:15736 [D loss: 0.498692, acc: 75.78%] [G loss: 3.383158]\n",
      "epoch:20 step:15737 [D loss: 0.303552, acc: 96.09%] [G loss: 2.558961]\n",
      "epoch:20 step:15738 [D loss: 0.420072, acc: 81.25%] [G loss: 2.835366]\n",
      "epoch:20 step:15739 [D loss: 0.305471, acc: 91.41%] [G loss: 3.383514]\n",
      "epoch:20 step:15740 [D loss: 0.420056, acc: 84.38%] [G loss: 2.568872]\n",
      "epoch:20 step:15741 [D loss: 0.297825, acc: 90.62%] [G loss: 2.952795]\n",
      "epoch:20 step:15742 [D loss: 0.725971, acc: 51.56%] [G loss: 3.201417]\n",
      "epoch:20 step:15743 [D loss: 0.541944, acc: 70.31%] [G loss: 2.283601]\n",
      "epoch:20 step:15744 [D loss: 0.519181, acc: 77.34%] [G loss: 2.505539]\n",
      "epoch:20 step:15745 [D loss: 0.433693, acc: 89.84%] [G loss: 3.395970]\n",
      "epoch:20 step:15746 [D loss: 0.489008, acc: 77.34%] [G loss: 2.573700]\n",
      "epoch:20 step:15747 [D loss: 0.206831, acc: 98.44%] [G loss: 2.684327]\n",
      "epoch:20 step:15748 [D loss: 0.286192, acc: 96.09%] [G loss: 3.750783]\n",
      "epoch:20 step:15749 [D loss: 0.792885, acc: 48.44%] [G loss: 2.335378]\n",
      "epoch:20 step:15750 [D loss: 0.838177, acc: 39.84%] [G loss: 2.233455]\n",
      "epoch:20 step:15751 [D loss: 0.692709, acc: 60.16%] [G loss: 1.980115]\n",
      "epoch:20 step:15752 [D loss: 0.573150, acc: 74.22%] [G loss: 2.476914]\n",
      "epoch:20 step:15753 [D loss: 0.331952, acc: 84.38%] [G loss: 3.454177]\n",
      "epoch:20 step:15754 [D loss: 0.359794, acc: 92.19%] [G loss: 3.537260]\n",
      "epoch:20 step:15755 [D loss: 0.549543, acc: 63.28%] [G loss: 3.145808]\n",
      "epoch:20 step:15756 [D loss: 0.545177, acc: 64.06%] [G loss: 2.851896]\n",
      "epoch:20 step:15757 [D loss: 0.532003, acc: 76.56%] [G loss: 2.573650]\n",
      "epoch:20 step:15758 [D loss: 0.502286, acc: 78.91%] [G loss: 3.833354]\n",
      "epoch:20 step:15759 [D loss: 0.614797, acc: 72.66%] [G loss: 1.927002]\n",
      "epoch:20 step:15760 [D loss: 0.608109, acc: 64.84%] [G loss: 2.712034]\n",
      "epoch:20 step:15761 [D loss: 0.764907, acc: 48.44%] [G loss: 2.508985]\n",
      "epoch:20 step:15762 [D loss: 0.559897, acc: 71.88%] [G loss: 2.495411]\n",
      "epoch:20 step:15763 [D loss: 0.476000, acc: 82.03%] [G loss: 2.447131]\n",
      "epoch:20 step:15764 [D loss: 1.105522, acc: 29.69%] [G loss: 2.546529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:15765 [D loss: 0.617013, acc: 65.62%] [G loss: 3.555841]\n",
      "epoch:20 step:15766 [D loss: 0.371126, acc: 97.66%] [G loss: 2.059100]\n",
      "epoch:20 step:15767 [D loss: 0.550417, acc: 74.22%] [G loss: 3.260321]\n",
      "epoch:20 step:15768 [D loss: 0.541389, acc: 77.34%] [G loss: 2.742304]\n",
      "epoch:20 step:15769 [D loss: 0.727269, acc: 53.12%] [G loss: 2.842628]\n",
      "epoch:20 step:15770 [D loss: 0.720510, acc: 56.25%] [G loss: 3.042932]\n",
      "epoch:20 step:15771 [D loss: 0.610016, acc: 58.59%] [G loss: 2.409642]\n",
      "epoch:20 step:15772 [D loss: 0.768637, acc: 53.12%] [G loss: 2.931018]\n",
      "epoch:20 step:15773 [D loss: 0.853323, acc: 35.94%] [G loss: 2.448571]\n",
      "epoch:20 step:15774 [D loss: 0.351903, acc: 94.53%] [G loss: 3.256390]\n",
      "epoch:20 step:15775 [D loss: 0.633021, acc: 65.62%] [G loss: 3.388636]\n",
      "epoch:20 step:15776 [D loss: 0.511584, acc: 85.94%] [G loss: 2.572431]\n",
      "epoch:20 step:15777 [D loss: 0.266049, acc: 92.97%] [G loss: 3.380080]\n",
      "epoch:20 step:15778 [D loss: 0.380071, acc: 91.41%] [G loss: 3.583146]\n",
      "epoch:20 step:15779 [D loss: 0.372681, acc: 91.41%] [G loss: 4.495201]\n",
      "epoch:20 step:15780 [D loss: 0.505994, acc: 78.91%] [G loss: 4.316289]\n",
      "epoch:20 step:15781 [D loss: 0.305384, acc: 89.84%] [G loss: 3.789576]\n",
      "epoch:20 step:15782 [D loss: 0.294163, acc: 95.31%] [G loss: 3.247326]\n",
      "epoch:20 step:15783 [D loss: 0.740988, acc: 49.22%] [G loss: 2.070580]\n",
      "epoch:20 step:15784 [D loss: 0.557221, acc: 57.03%] [G loss: 2.584443]\n",
      "epoch:20 step:15785 [D loss: 0.533814, acc: 78.12%] [G loss: 3.171216]\n",
      "epoch:20 step:15786 [D loss: 1.135201, acc: 13.28%] [G loss: 2.442353]\n",
      "epoch:20 step:15787 [D loss: 0.625456, acc: 66.41%] [G loss: 2.876074]\n",
      "epoch:20 step:15788 [D loss: 0.436874, acc: 86.72%] [G loss: 2.726065]\n",
      "epoch:20 step:15789 [D loss: 0.582189, acc: 71.88%] [G loss: 2.988486]\n",
      "epoch:20 step:15790 [D loss: 0.303867, acc: 96.09%] [G loss: 2.374468]\n",
      "epoch:20 step:15791 [D loss: 0.571198, acc: 70.31%] [G loss: 2.147938]\n",
      "epoch:20 step:15792 [D loss: 0.797807, acc: 46.88%] [G loss: 2.020454]\n",
      "epoch:20 step:15793 [D loss: 0.588701, acc: 63.28%] [G loss: 3.629843]\n",
      "epoch:20 step:15794 [D loss: 0.499880, acc: 73.44%] [G loss: 1.609269]\n",
      "epoch:20 step:15795 [D loss: 0.511443, acc: 68.75%] [G loss: 3.770818]\n",
      "epoch:20 step:15796 [D loss: 0.702022, acc: 53.12%] [G loss: 3.149038]\n",
      "epoch:20 step:15797 [D loss: 0.330947, acc: 88.28%] [G loss: 4.116385]\n",
      "epoch:20 step:15798 [D loss: 1.022844, acc: 29.69%] [G loss: 2.953060]\n",
      "epoch:20 step:15799 [D loss: 0.727783, acc: 56.25%] [G loss: 4.502650]\n",
      "epoch:20 step:15800 [D loss: 0.548263, acc: 70.31%] [G loss: 1.816711]\n",
      "epoch:20 step:15801 [D loss: 0.255266, acc: 96.88%] [G loss: 2.874798]\n",
      "epoch:20 step:15802 [D loss: 0.755122, acc: 59.38%] [G loss: 3.132968]\n",
      "epoch:20 step:15803 [D loss: 0.554421, acc: 72.66%] [G loss: 2.398808]\n",
      "epoch:20 step:15804 [D loss: 0.322579, acc: 85.94%] [G loss: 2.457386]\n",
      "epoch:20 step:15805 [D loss: 0.645352, acc: 64.84%] [G loss: 2.626130]\n",
      "epoch:20 step:15806 [D loss: 0.641788, acc: 60.94%] [G loss: 1.972499]\n",
      "epoch:20 step:15807 [D loss: 0.430546, acc: 83.59%] [G loss: 3.047515]\n",
      "epoch:20 step:15808 [D loss: 0.777788, acc: 51.56%] [G loss: 3.909451]\n",
      "epoch:20 step:15809 [D loss: 0.307922, acc: 89.06%] [G loss: 3.833580]\n",
      "epoch:20 step:15810 [D loss: 0.467415, acc: 75.00%] [G loss: 3.163522]\n",
      "epoch:20 step:15811 [D loss: 0.365237, acc: 93.75%] [G loss: 1.857207]\n",
      "epoch:20 step:15812 [D loss: 0.916665, acc: 44.53%] [G loss: 2.037265]\n",
      "epoch:20 step:15813 [D loss: 0.491651, acc: 84.38%] [G loss: 2.268687]\n",
      "epoch:20 step:15814 [D loss: 0.794505, acc: 52.34%] [G loss: 2.034630]\n",
      "epoch:20 step:15815 [D loss: 0.573052, acc: 71.88%] [G loss: 2.871479]\n",
      "epoch:20 step:15816 [D loss: 1.039700, acc: 44.53%] [G loss: 2.210134]\n",
      "epoch:20 step:15817 [D loss: 0.461127, acc: 85.16%] [G loss: 2.830517]\n",
      "epoch:20 step:15818 [D loss: 0.441168, acc: 88.28%] [G loss: 2.431692]\n",
      "epoch:20 step:15819 [D loss: 0.749775, acc: 53.12%] [G loss: 3.023459]\n",
      "epoch:20 step:15820 [D loss: 0.341563, acc: 90.62%] [G loss: 4.541914]\n",
      "epoch:20 step:15821 [D loss: 0.308133, acc: 97.66%] [G loss: 3.372906]\n",
      "epoch:20 step:15822 [D loss: 0.745310, acc: 49.22%] [G loss: 2.572608]\n",
      "epoch:20 step:15823 [D loss: 0.479763, acc: 81.25%] [G loss: 2.420323]\n",
      "epoch:20 step:15824 [D loss: 0.166188, acc: 99.22%] [G loss: 3.263544]\n",
      "epoch:20 step:15825 [D loss: 0.645464, acc: 65.62%] [G loss: 3.559100]\n",
      "epoch:20 step:15826 [D loss: 0.375314, acc: 92.19%] [G loss: 3.626898]\n",
      "epoch:20 step:15827 [D loss: 0.719562, acc: 51.56%] [G loss: 1.645007]\n",
      "epoch:20 step:15828 [D loss: 0.528401, acc: 68.75%] [G loss: 3.217010]\n",
      "epoch:20 step:15829 [D loss: 0.654808, acc: 57.03%] [G loss: 3.006158]\n",
      "epoch:20 step:15830 [D loss: 0.434878, acc: 81.25%] [G loss: 3.471974]\n",
      "epoch:20 step:15831 [D loss: 0.234134, acc: 98.44%] [G loss: 3.641291]\n",
      "epoch:20 step:15832 [D loss: 0.205381, acc: 98.44%] [G loss: 3.450317]\n",
      "epoch:20 step:15833 [D loss: 0.661118, acc: 59.38%] [G loss: 2.779574]\n",
      "epoch:20 step:15834 [D loss: 0.232133, acc: 96.09%] [G loss: 3.359362]\n",
      "epoch:20 step:15835 [D loss: 0.213663, acc: 98.44%] [G loss: 3.819635]\n",
      "epoch:20 step:15836 [D loss: 0.221184, acc: 98.44%] [G loss: 4.707234]\n",
      "epoch:20 step:15837 [D loss: 0.437513, acc: 74.22%] [G loss: 3.226969]\n",
      "epoch:20 step:15838 [D loss: 0.778810, acc: 46.88%] [G loss: 2.617311]\n",
      "epoch:20 step:15839 [D loss: 0.343868, acc: 92.97%] [G loss: 5.265555]\n",
      "epoch:20 step:15840 [D loss: 0.497827, acc: 75.00%] [G loss: 3.516922]\n",
      "epoch:20 step:15841 [D loss: 0.613015, acc: 67.97%] [G loss: 2.541557]\n",
      "epoch:20 step:15842 [D loss: 0.446213, acc: 85.16%] [G loss: 2.960769]\n",
      "epoch:20 step:15843 [D loss: 0.411959, acc: 82.81%] [G loss: 2.378047]\n",
      "epoch:20 step:15844 [D loss: 0.597445, acc: 66.41%] [G loss: 1.922883]\n",
      "epoch:20 step:15845 [D loss: 0.252131, acc: 92.19%] [G loss: 3.484179]\n",
      "epoch:20 step:15846 [D loss: 0.654419, acc: 54.69%] [G loss: 3.022982]\n",
      "epoch:20 step:15847 [D loss: 0.398581, acc: 86.72%] [G loss: 3.073483]\n",
      "epoch:20 step:15848 [D loss: 0.583389, acc: 71.88%] [G loss: 3.688490]\n",
      "epoch:20 step:15849 [D loss: 0.395565, acc: 86.72%] [G loss: 4.015893]\n",
      "epoch:20 step:15850 [D loss: 0.694028, acc: 54.69%] [G loss: 3.123825]\n",
      "epoch:20 step:15851 [D loss: 0.384647, acc: 88.28%] [G loss: 3.215392]\n",
      "epoch:20 step:15852 [D loss: 0.478034, acc: 77.34%] [G loss: 2.898325]\n",
      "epoch:20 step:15853 [D loss: 0.625306, acc: 59.38%] [G loss: 3.634314]\n",
      "epoch:20 step:15854 [D loss: 0.650395, acc: 64.06%] [G loss: 3.600885]\n",
      "epoch:20 step:15855 [D loss: 0.606871, acc: 69.53%] [G loss: 3.058619]\n",
      "epoch:20 step:15856 [D loss: 0.348192, acc: 91.41%] [G loss: 2.995485]\n",
      "epoch:20 step:15857 [D loss: 0.428799, acc: 85.16%] [G loss: 4.056870]\n",
      "epoch:20 step:15858 [D loss: 0.324577, acc: 83.59%] [G loss: 3.651915]\n",
      "epoch:20 step:15859 [D loss: 0.455840, acc: 87.50%] [G loss: 2.474269]\n",
      "epoch:20 step:15860 [D loss: 1.219478, acc: 23.44%] [G loss: 2.596687]\n",
      "epoch:20 step:15861 [D loss: 0.323130, acc: 96.09%] [G loss: 2.535812]\n",
      "epoch:20 step:15862 [D loss: 0.614032, acc: 57.81%] [G loss: 3.980038]\n",
      "epoch:20 step:15863 [D loss: 0.328932, acc: 81.25%] [G loss: 3.517338]\n",
      "epoch:20 step:15864 [D loss: 0.533288, acc: 68.75%] [G loss: 3.529500]\n",
      "epoch:20 step:15865 [D loss: 0.597583, acc: 71.88%] [G loss: 2.762423]\n",
      "epoch:20 step:15866 [D loss: 0.639801, acc: 64.06%] [G loss: 2.173552]\n",
      "epoch:20 step:15867 [D loss: 0.726488, acc: 58.59%] [G loss: 3.601308]\n",
      "epoch:20 step:15868 [D loss: 0.134381, acc: 99.22%] [G loss: 2.397321]\n",
      "epoch:20 step:15869 [D loss: 1.081863, acc: 48.44%] [G loss: 2.935208]\n",
      "epoch:20 step:15870 [D loss: 0.204174, acc: 97.66%] [G loss: 3.206905]\n",
      "epoch:20 step:15871 [D loss: 0.467026, acc: 81.25%] [G loss: 3.014785]\n",
      "epoch:20 step:15872 [D loss: 0.453913, acc: 82.81%] [G loss: 3.612839]\n",
      "epoch:20 step:15873 [D loss: 0.639440, acc: 58.59%] [G loss: 2.301258]\n",
      "epoch:20 step:15874 [D loss: 0.291973, acc: 93.75%] [G loss: 2.703698]\n",
      "epoch:20 step:15875 [D loss: 0.264959, acc: 97.66%] [G loss: 1.816273]\n",
      "epoch:20 step:15876 [D loss: 0.457750, acc: 83.59%] [G loss: 3.063589]\n",
      "epoch:20 step:15877 [D loss: 1.073451, acc: 18.75%] [G loss: 2.641688]\n",
      "epoch:20 step:15878 [D loss: 0.766105, acc: 46.88%] [G loss: 2.906086]\n",
      "epoch:20 step:15879 [D loss: 0.432498, acc: 90.62%] [G loss: 2.613924]\n",
      "epoch:20 step:15880 [D loss: 0.525213, acc: 78.91%] [G loss: 2.586458]\n",
      "epoch:20 step:15881 [D loss: 0.304607, acc: 93.75%] [G loss: 1.966181]\n",
      "epoch:20 step:15882 [D loss: 0.156626, acc: 100.00%] [G loss: 3.519602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:15883 [D loss: 0.277668, acc: 95.31%] [G loss: 3.256580]\n",
      "epoch:20 step:15884 [D loss: 0.857644, acc: 44.53%] [G loss: 2.877927]\n",
      "epoch:20 step:15885 [D loss: 0.164018, acc: 99.22%] [G loss: 4.137821]\n",
      "epoch:20 step:15886 [D loss: 0.465669, acc: 75.78%] [G loss: 2.476171]\n",
      "epoch:20 step:15887 [D loss: 1.920930, acc: 3.12%] [G loss: 1.833537]\n",
      "epoch:20 step:15888 [D loss: 0.389803, acc: 85.94%] [G loss: 4.851275]\n",
      "epoch:20 step:15889 [D loss: 1.349797, acc: 21.09%] [G loss: 2.045837]\n",
      "epoch:20 step:15890 [D loss: 0.347071, acc: 94.53%] [G loss: 2.283631]\n",
      "epoch:20 step:15891 [D loss: 0.295275, acc: 96.09%] [G loss: 2.257068]\n",
      "epoch:20 step:15892 [D loss: 0.423571, acc: 82.03%] [G loss: 2.683609]\n",
      "epoch:20 step:15893 [D loss: 0.729232, acc: 53.12%] [G loss: 3.556474]\n",
      "epoch:20 step:15894 [D loss: 1.114697, acc: 13.28%] [G loss: 2.657068]\n",
      "epoch:20 step:15895 [D loss: 0.550564, acc: 77.34%] [G loss: 4.110754]\n",
      "epoch:20 step:15896 [D loss: 0.380293, acc: 91.41%] [G loss: 3.802914]\n",
      "epoch:20 step:15897 [D loss: 0.821866, acc: 42.97%] [G loss: 3.402291]\n",
      "epoch:20 step:15898 [D loss: 0.439244, acc: 89.84%] [G loss: 3.329628]\n",
      "epoch:20 step:15899 [D loss: 0.285470, acc: 97.66%] [G loss: 3.703061]\n",
      "epoch:20 step:15900 [D loss: 0.512315, acc: 80.47%] [G loss: 3.668576]\n",
      "epoch:20 step:15901 [D loss: 0.496595, acc: 74.22%] [G loss: 3.808117]\n",
      "epoch:20 step:15902 [D loss: 0.437161, acc: 72.66%] [G loss: 3.843896]\n",
      "epoch:20 step:15903 [D loss: 0.833678, acc: 52.34%] [G loss: 2.584924]\n",
      "epoch:20 step:15904 [D loss: 0.469286, acc: 84.38%] [G loss: 2.938595]\n",
      "epoch:20 step:15905 [D loss: 0.699655, acc: 54.69%] [G loss: 1.940023]\n",
      "epoch:20 step:15906 [D loss: 0.236202, acc: 98.44%] [G loss: 3.087881]\n",
      "epoch:20 step:15907 [D loss: 0.556271, acc: 71.09%] [G loss: 3.841537]\n",
      "epoch:20 step:15908 [D loss: 0.811339, acc: 42.97%] [G loss: 1.864559]\n",
      "epoch:20 step:15909 [D loss: 0.556902, acc: 69.53%] [G loss: 2.771067]\n",
      "epoch:20 step:15910 [D loss: 0.375469, acc: 79.69%] [G loss: 2.266243]\n",
      "epoch:20 step:15911 [D loss: 0.899887, acc: 35.94%] [G loss: 2.679825]\n",
      "epoch:20 step:15912 [D loss: 0.457141, acc: 82.03%] [G loss: 2.583797]\n",
      "epoch:20 step:15913 [D loss: 0.307603, acc: 84.38%] [G loss: 3.712270]\n",
      "epoch:20 step:15914 [D loss: 0.418048, acc: 88.28%] [G loss: 3.597813]\n",
      "epoch:20 step:15915 [D loss: 0.349674, acc: 94.53%] [G loss: 2.947025]\n",
      "epoch:20 step:15916 [D loss: 0.298105, acc: 96.09%] [G loss: 3.998780]\n",
      "epoch:20 step:15917 [D loss: 0.663349, acc: 57.81%] [G loss: 2.229504]\n",
      "epoch:20 step:15918 [D loss: 0.310740, acc: 94.53%] [G loss: 3.038929]\n",
      "epoch:20 step:15919 [D loss: 0.414429, acc: 89.06%] [G loss: 2.525779]\n",
      "epoch:20 step:15920 [D loss: 0.784328, acc: 45.31%] [G loss: 2.264369]\n",
      "epoch:20 step:15921 [D loss: 0.700434, acc: 57.81%] [G loss: 2.671458]\n",
      "epoch:20 step:15922 [D loss: 0.750150, acc: 51.56%] [G loss: 2.156325]\n",
      "epoch:20 step:15923 [D loss: 0.593528, acc: 64.06%] [G loss: 2.368759]\n",
      "epoch:20 step:15924 [D loss: 1.572882, acc: 8.59%] [G loss: 2.298949]\n",
      "epoch:20 step:15925 [D loss: 0.578092, acc: 63.28%] [G loss: 3.944453]\n",
      "epoch:20 step:15926 [D loss: 0.701190, acc: 58.59%] [G loss: 2.325404]\n",
      "epoch:20 step:15927 [D loss: 0.517346, acc: 77.34%] [G loss: 2.920640]\n",
      "epoch:20 step:15928 [D loss: 0.510832, acc: 78.91%] [G loss: 1.964537]\n",
      "epoch:20 step:15929 [D loss: 0.638246, acc: 64.06%] [G loss: 3.893616]\n",
      "epoch:20 step:15930 [D loss: 0.465054, acc: 71.09%] [G loss: 3.765290]\n",
      "epoch:20 step:15931 [D loss: 0.493799, acc: 85.16%] [G loss: 2.216096]\n",
      "epoch:20 step:15932 [D loss: 0.245566, acc: 97.66%] [G loss: 2.978268]\n",
      "epoch:20 step:15933 [D loss: 1.194163, acc: 11.72%] [G loss: 2.562876]\n",
      "epoch:20 step:15934 [D loss: 0.168047, acc: 100.00%] [G loss: 4.066998]\n",
      "epoch:20 step:15935 [D loss: 1.061415, acc: 32.81%] [G loss: 3.568781]\n",
      "epoch:20 step:15936 [D loss: 0.410109, acc: 79.69%] [G loss: 2.655767]\n",
      "epoch:20 step:15937 [D loss: 0.325298, acc: 96.09%] [G loss: 2.832379]\n",
      "epoch:20 step:15938 [D loss: 0.340016, acc: 94.53%] [G loss: 3.871709]\n",
      "epoch:20 step:15939 [D loss: 0.321529, acc: 95.31%] [G loss: 3.533800]\n",
      "epoch:20 step:15940 [D loss: 0.281510, acc: 93.75%] [G loss: 3.391479]\n",
      "epoch:20 step:15941 [D loss: 0.513435, acc: 78.12%] [G loss: 3.312354]\n",
      "epoch:20 step:15942 [D loss: 0.762889, acc: 55.47%] [G loss: 2.477472]\n",
      "epoch:20 step:15943 [D loss: 0.605283, acc: 67.19%] [G loss: 2.678771]\n",
      "epoch:20 step:15944 [D loss: 0.286540, acc: 89.84%] [G loss: 3.271205]\n",
      "epoch:20 step:15945 [D loss: 0.283406, acc: 96.88%] [G loss: 3.332824]\n",
      "epoch:20 step:15946 [D loss: 0.620307, acc: 57.03%] [G loss: 2.671859]\n",
      "epoch:20 step:15947 [D loss: 0.555383, acc: 71.88%] [G loss: 2.502830]\n",
      "epoch:20 step:15948 [D loss: 0.340379, acc: 85.94%] [G loss: 3.337873]\n",
      "epoch:20 step:15949 [D loss: 0.377530, acc: 78.91%] [G loss: 4.215216]\n",
      "epoch:20 step:15950 [D loss: 0.541346, acc: 75.78%] [G loss: 3.005709]\n",
      "epoch:20 step:15951 [D loss: 0.482591, acc: 72.66%] [G loss: 2.987415]\n",
      "epoch:20 step:15952 [D loss: 0.548925, acc: 67.19%] [G loss: 3.950878]\n",
      "epoch:20 step:15953 [D loss: 0.161196, acc: 100.00%] [G loss: 3.251958]\n",
      "epoch:20 step:15954 [D loss: 0.431055, acc: 83.59%] [G loss: 3.989146]\n",
      "epoch:20 step:15955 [D loss: 0.272162, acc: 94.53%] [G loss: 3.115358]\n",
      "epoch:20 step:15956 [D loss: 0.847784, acc: 53.12%] [G loss: 2.027852]\n",
      "epoch:20 step:15957 [D loss: 0.654471, acc: 60.94%] [G loss: 1.923750]\n",
      "epoch:20 step:15958 [D loss: 0.748583, acc: 54.69%] [G loss: 2.946575]\n",
      "epoch:20 step:15959 [D loss: 0.346960, acc: 95.31%] [G loss: 3.324707]\n",
      "epoch:20 step:15960 [D loss: 0.640035, acc: 60.16%] [G loss: 2.913198]\n",
      "epoch:20 step:15961 [D loss: 0.756130, acc: 50.00%] [G loss: 3.213635]\n",
      "epoch:20 step:15962 [D loss: 0.348705, acc: 89.06%] [G loss: 3.164292]\n",
      "epoch:20 step:15963 [D loss: 0.741416, acc: 54.69%] [G loss: 2.693583]\n",
      "epoch:20 step:15964 [D loss: 0.377778, acc: 92.19%] [G loss: 2.596540]\n",
      "epoch:20 step:15965 [D loss: 0.910322, acc: 33.59%] [G loss: 2.837657]\n",
      "epoch:20 step:15966 [D loss: 0.511360, acc: 76.56%] [G loss: 3.144027]\n",
      "epoch:20 step:15967 [D loss: 0.652794, acc: 57.81%] [G loss: 2.692697]\n",
      "epoch:20 step:15968 [D loss: 0.834192, acc: 40.62%] [G loss: 2.787658]\n",
      "epoch:20 step:15969 [D loss: 0.249219, acc: 95.31%] [G loss: 2.755969]\n",
      "epoch:20 step:15970 [D loss: 0.853493, acc: 50.78%] [G loss: 2.626808]\n",
      "epoch:20 step:15971 [D loss: 0.565734, acc: 74.22%] [G loss: 3.320808]\n",
      "epoch:20 step:15972 [D loss: 0.426769, acc: 87.50%] [G loss: 3.332870]\n",
      "epoch:20 step:15973 [D loss: 0.255841, acc: 96.09%] [G loss: 3.381150]\n",
      "epoch:20 step:15974 [D loss: 0.329196, acc: 88.28%] [G loss: 4.348848]\n",
      "epoch:20 step:15975 [D loss: 0.445248, acc: 86.72%] [G loss: 3.519344]\n",
      "epoch:20 step:15976 [D loss: 0.533372, acc: 75.78%] [G loss: 2.140760]\n",
      "epoch:20 step:15977 [D loss: 0.563780, acc: 62.50%] [G loss: 3.032969]\n",
      "epoch:20 step:15978 [D loss: 0.648325, acc: 62.50%] [G loss: 4.115602]\n",
      "epoch:20 step:15979 [D loss: 0.397001, acc: 87.50%] [G loss: 3.449359]\n",
      "epoch:20 step:15980 [D loss: 0.688656, acc: 54.69%] [G loss: 4.043033]\n",
      "epoch:20 step:15981 [D loss: 0.474650, acc: 85.94%] [G loss: 2.695710]\n",
      "epoch:20 step:15982 [D loss: 0.504013, acc: 79.69%] [G loss: 2.903078]\n",
      "epoch:20 step:15983 [D loss: 0.546612, acc: 70.31%] [G loss: 2.685081]\n",
      "epoch:20 step:15984 [D loss: 0.536971, acc: 69.53%] [G loss: 4.265434]\n",
      "epoch:20 step:15985 [D loss: 0.640525, acc: 58.59%] [G loss: 2.928355]\n",
      "epoch:20 step:15986 [D loss: 0.839073, acc: 50.00%] [G loss: 2.864937]\n",
      "epoch:20 step:15987 [D loss: 0.610389, acc: 68.75%] [G loss: 2.756376]\n",
      "epoch:20 step:15988 [D loss: 0.527548, acc: 75.78%] [G loss: 2.172585]\n",
      "epoch:20 step:15989 [D loss: 0.486971, acc: 81.25%] [G loss: 2.460026]\n",
      "epoch:20 step:15990 [D loss: 0.241255, acc: 92.19%] [G loss: 4.406889]\n",
      "epoch:20 step:15991 [D loss: 0.322720, acc: 93.75%] [G loss: 3.551143]\n",
      "epoch:20 step:15992 [D loss: 0.753688, acc: 45.31%] [G loss: 3.251830]\n",
      "epoch:20 step:15993 [D loss: 1.115971, acc: 19.53%] [G loss: 3.242026]\n",
      "epoch:20 step:15994 [D loss: 0.568785, acc: 69.53%] [G loss: 2.288586]\n",
      "epoch:20 step:15995 [D loss: 0.767385, acc: 48.44%] [G loss: 3.861859]\n",
      "epoch:20 step:15996 [D loss: 0.486779, acc: 77.34%] [G loss: 3.294529]\n",
      "epoch:20 step:15997 [D loss: 0.861534, acc: 48.44%] [G loss: 2.416863]\n",
      "epoch:20 step:15998 [D loss: 0.819259, acc: 45.31%] [G loss: 3.779799]\n",
      "epoch:20 step:15999 [D loss: 0.260235, acc: 97.66%] [G loss: 3.488864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:16000 [D loss: 0.383552, acc: 86.72%] [G loss: 3.302273]\n",
      "epoch:20 step:16001 [D loss: 0.568433, acc: 68.75%] [G loss: 2.772161]\n",
      "epoch:20 step:16002 [D loss: 0.566185, acc: 73.44%] [G loss: 3.156192]\n",
      "epoch:20 step:16003 [D loss: 0.746315, acc: 48.44%] [G loss: 1.968318]\n",
      "epoch:20 step:16004 [D loss: 0.321368, acc: 91.41%] [G loss: 3.796427]\n",
      "epoch:20 step:16005 [D loss: 0.288056, acc: 97.66%] [G loss: 3.131972]\n",
      "epoch:20 step:16006 [D loss: 0.757736, acc: 54.69%] [G loss: 2.726228]\n",
      "epoch:20 step:16007 [D loss: 0.539945, acc: 74.22%] [G loss: 3.095739]\n",
      "epoch:20 step:16008 [D loss: 0.425215, acc: 78.12%] [G loss: 2.350098]\n",
      "epoch:20 step:16009 [D loss: 0.933696, acc: 28.91%] [G loss: 2.677709]\n",
      "epoch:20 step:16010 [D loss: 0.222947, acc: 96.88%] [G loss: 3.642360]\n",
      "epoch:20 step:16011 [D loss: 0.639314, acc: 53.91%] [G loss: 3.719105]\n",
      "epoch:20 step:16012 [D loss: 0.179863, acc: 100.00%] [G loss: 3.354385]\n",
      "epoch:20 step:16013 [D loss: 1.130730, acc: 49.22%] [G loss: 2.501098]\n",
      "epoch:20 step:16014 [D loss: 0.385441, acc: 91.41%] [G loss: 4.218080]\n",
      "epoch:20 step:16015 [D loss: 0.559289, acc: 68.75%] [G loss: 2.787046]\n",
      "epoch:20 step:16016 [D loss: 0.512043, acc: 75.78%] [G loss: 3.328053]\n",
      "epoch:20 step:16017 [D loss: 0.617900, acc: 70.31%] [G loss: 2.677607]\n",
      "epoch:20 step:16018 [D loss: 0.174071, acc: 96.88%] [G loss: 3.564460]\n",
      "epoch:20 step:16019 [D loss: 0.464996, acc: 85.16%] [G loss: 4.477861]\n",
      "epoch:20 step:16020 [D loss: 0.226926, acc: 96.09%] [G loss: 5.860419]\n",
      "epoch:20 step:16021 [D loss: 0.377961, acc: 82.81%] [G loss: 5.666148]\n",
      "epoch:20 step:16022 [D loss: 0.603483, acc: 60.94%] [G loss: 2.324065]\n",
      "epoch:20 step:16023 [D loss: 0.488691, acc: 65.62%] [G loss: 3.903733]\n",
      "epoch:20 step:16024 [D loss: 0.176494, acc: 96.88%] [G loss: 3.600487]\n",
      "epoch:20 step:16025 [D loss: 0.849912, acc: 48.44%] [G loss: 2.230939]\n",
      "epoch:20 step:16026 [D loss: 0.338977, acc: 91.41%] [G loss: 3.184608]\n",
      "epoch:20 step:16027 [D loss: 0.411501, acc: 78.12%] [G loss: 2.136154]\n",
      "epoch:20 step:16028 [D loss: 0.216483, acc: 96.88%] [G loss: 3.286620]\n",
      "epoch:20 step:16029 [D loss: 0.919012, acc: 41.41%] [G loss: 3.015648]\n",
      "epoch:20 step:16030 [D loss: 0.711679, acc: 58.59%] [G loss: 2.493121]\n",
      "epoch:20 step:16031 [D loss: 0.935775, acc: 27.34%] [G loss: 2.221448]\n",
      "epoch:20 step:16032 [D loss: 0.487633, acc: 78.12%] [G loss: 2.498109]\n",
      "epoch:20 step:16033 [D loss: 0.443939, acc: 82.03%] [G loss: 4.078323]\n",
      "epoch:20 step:16034 [D loss: 0.778910, acc: 48.44%] [G loss: 2.810513]\n",
      "epoch:20 step:16035 [D loss: 0.772127, acc: 48.44%] [G loss: 2.558405]\n",
      "epoch:20 step:16036 [D loss: 0.564485, acc: 67.19%] [G loss: 3.212180]\n",
      "epoch:20 step:16037 [D loss: 0.615996, acc: 65.62%] [G loss: 2.873352]\n",
      "epoch:20 step:16038 [D loss: 0.288893, acc: 93.75%] [G loss: 3.299999]\n",
      "epoch:20 step:16039 [D loss: 0.514365, acc: 76.56%] [G loss: 3.079434]\n",
      "epoch:20 step:16040 [D loss: 1.009673, acc: 30.47%] [G loss: 2.494273]\n",
      "epoch:20 step:16041 [D loss: 0.497384, acc: 82.03%] [G loss: 3.109757]\n",
      "epoch:20 step:16042 [D loss: 0.434182, acc: 75.78%] [G loss: 4.157282]\n",
      "epoch:20 step:16043 [D loss: 0.554143, acc: 73.44%] [G loss: 3.119677]\n",
      "epoch:20 step:16044 [D loss: 0.502279, acc: 78.12%] [G loss: 3.745899]\n",
      "epoch:20 step:16045 [D loss: 0.336065, acc: 90.62%] [G loss: 3.713238]\n",
      "epoch:20 step:16046 [D loss: 0.638076, acc: 60.16%] [G loss: 2.296069]\n",
      "epoch:20 step:16047 [D loss: 0.278797, acc: 96.88%] [G loss: 3.383710]\n",
      "epoch:20 step:16048 [D loss: 0.913506, acc: 40.62%] [G loss: 2.748910]\n",
      "epoch:20 step:16049 [D loss: 0.333881, acc: 91.41%] [G loss: 3.529716]\n",
      "epoch:20 step:16050 [D loss: 0.525602, acc: 74.22%] [G loss: 2.284956]\n",
      "epoch:20 step:16051 [D loss: 0.800156, acc: 49.22%] [G loss: 3.102657]\n",
      "epoch:20 step:16052 [D loss: 0.493618, acc: 82.03%] [G loss: 3.368311]\n",
      "epoch:20 step:16053 [D loss: 0.649063, acc: 55.47%] [G loss: 2.899730]\n",
      "epoch:20 step:16054 [D loss: 0.357876, acc: 89.84%] [G loss: 2.595405]\n",
      "epoch:20 step:16055 [D loss: 0.774290, acc: 53.91%] [G loss: 2.010151]\n",
      "epoch:20 step:16056 [D loss: 0.440666, acc: 71.88%] [G loss: 3.457107]\n",
      "epoch:20 step:16057 [D loss: 1.100638, acc: 23.44%] [G loss: 1.780450]\n",
      "epoch:20 step:16058 [D loss: 0.455672, acc: 84.38%] [G loss: 2.439282]\n",
      "epoch:20 step:16059 [D loss: 0.546588, acc: 67.97%] [G loss: 3.500346]\n",
      "epoch:20 step:16060 [D loss: 0.860607, acc: 47.66%] [G loss: 1.900446]\n",
      "epoch:20 step:16061 [D loss: 0.603685, acc: 69.53%] [G loss: 2.624003]\n",
      "epoch:20 step:16062 [D loss: 0.437520, acc: 86.72%] [G loss: 3.337567]\n",
      "epoch:20 step:16063 [D loss: 0.479305, acc: 75.78%] [G loss: 3.598661]\n",
      "epoch:20 step:16064 [D loss: 0.515845, acc: 76.56%] [G loss: 2.557968]\n",
      "epoch:20 step:16065 [D loss: 0.847211, acc: 47.66%] [G loss: 1.475932]\n",
      "epoch:20 step:16066 [D loss: 0.415698, acc: 87.50%] [G loss: 4.176195]\n",
      "epoch:20 step:16067 [D loss: 0.796244, acc: 50.00%] [G loss: 2.448088]\n",
      "epoch:20 step:16068 [D loss: 0.199969, acc: 99.22%] [G loss: 4.622281]\n",
      "epoch:20 step:16069 [D loss: 0.565420, acc: 70.31%] [G loss: 2.408585]\n",
      "epoch:20 step:16070 [D loss: 0.213402, acc: 98.44%] [G loss: 2.478078]\n",
      "epoch:20 step:16071 [D loss: 0.616350, acc: 64.84%] [G loss: 3.585336]\n",
      "epoch:20 step:16072 [D loss: 0.240780, acc: 98.44%] [G loss: 3.589057]\n",
      "epoch:20 step:16073 [D loss: 1.146634, acc: 21.09%] [G loss: 2.984881]\n",
      "epoch:20 step:16074 [D loss: 0.896426, acc: 49.22%] [G loss: 2.495653]\n",
      "epoch:20 step:16075 [D loss: 0.660795, acc: 58.59%] [G loss: 4.322827]\n",
      "epoch:20 step:16076 [D loss: 0.808287, acc: 51.56%] [G loss: 3.284015]\n",
      "epoch:20 step:16077 [D loss: 0.316405, acc: 97.66%] [G loss: 3.702934]\n",
      "epoch:20 step:16078 [D loss: 0.445470, acc: 77.34%] [G loss: 3.329551]\n",
      "epoch:20 step:16079 [D loss: 0.486072, acc: 83.59%] [G loss: 3.254506]\n",
      "epoch:20 step:16080 [D loss: 0.300143, acc: 92.19%] [G loss: 4.300491]\n",
      "epoch:20 step:16081 [D loss: 0.821341, acc: 43.75%] [G loss: 3.399717]\n",
      "epoch:20 step:16082 [D loss: 0.495495, acc: 70.31%] [G loss: 3.250931]\n",
      "epoch:20 step:16083 [D loss: 0.314556, acc: 95.31%] [G loss: 3.233595]\n",
      "epoch:20 step:16084 [D loss: 0.253585, acc: 97.66%] [G loss: 2.640199]\n",
      "epoch:20 step:16085 [D loss: 0.937461, acc: 40.62%] [G loss: 4.104678]\n",
      "epoch:20 step:16086 [D loss: 0.245013, acc: 96.88%] [G loss: 3.111513]\n",
      "epoch:20 step:16087 [D loss: 0.610913, acc: 69.53%] [G loss: 2.513906]\n",
      "epoch:20 step:16088 [D loss: 0.588058, acc: 68.75%] [G loss: 2.548093]\n",
      "epoch:20 step:16089 [D loss: 0.524434, acc: 75.00%] [G loss: 2.201991]\n",
      "epoch:20 step:16090 [D loss: 0.137182, acc: 100.00%] [G loss: 3.440278]\n",
      "epoch:20 step:16091 [D loss: 0.479302, acc: 79.69%] [G loss: 3.586238]\n",
      "epoch:20 step:16092 [D loss: 0.609476, acc: 61.72%] [G loss: 2.866540]\n",
      "epoch:20 step:16093 [D loss: 0.499241, acc: 67.97%] [G loss: 2.691423]\n",
      "epoch:20 step:16094 [D loss: 0.485828, acc: 72.66%] [G loss: 2.789698]\n",
      "epoch:20 step:16095 [D loss: 0.570548, acc: 73.44%] [G loss: 2.779523]\n",
      "epoch:20 step:16096 [D loss: 0.456807, acc: 86.72%] [G loss: 2.575361]\n",
      "epoch:20 step:16097 [D loss: 0.252115, acc: 96.88%] [G loss: 3.233136]\n",
      "epoch:20 step:16098 [D loss: 0.193989, acc: 99.22%] [G loss: 3.931188]\n",
      "epoch:20 step:16099 [D loss: 0.419597, acc: 86.72%] [G loss: 2.781960]\n",
      "epoch:20 step:16100 [D loss: 0.564684, acc: 69.53%] [G loss: 2.613391]\n",
      "epoch:20 step:16101 [D loss: 0.684660, acc: 57.03%] [G loss: 1.963394]\n",
      "epoch:20 step:16102 [D loss: 0.814476, acc: 48.44%] [G loss: 2.745441]\n",
      "epoch:20 step:16103 [D loss: 0.377566, acc: 92.97%] [G loss: 3.430690]\n",
      "epoch:20 step:16104 [D loss: 0.693585, acc: 60.94%] [G loss: 2.057886]\n",
      "epoch:20 step:16105 [D loss: 1.147830, acc: 27.34%] [G loss: 2.398267]\n",
      "epoch:20 step:16106 [D loss: 0.622000, acc: 67.19%] [G loss: 3.848338]\n",
      "epoch:20 step:16107 [D loss: 0.527746, acc: 75.00%] [G loss: 3.354470]\n",
      "epoch:20 step:16108 [D loss: 0.441476, acc: 80.47%] [G loss: 3.004656]\n",
      "epoch:20 step:16109 [D loss: 0.109873, acc: 100.00%] [G loss: 3.969693]\n",
      "epoch:20 step:16110 [D loss: 0.265086, acc: 90.62%] [G loss: 3.978105]\n",
      "epoch:20 step:16111 [D loss: 0.699088, acc: 57.03%] [G loss: 3.103548]\n",
      "epoch:20 step:16112 [D loss: 0.150304, acc: 99.22%] [G loss: 3.687943]\n",
      "epoch:20 step:16113 [D loss: 0.694113, acc: 57.81%] [G loss: 3.263690]\n",
      "epoch:20 step:16114 [D loss: 0.568542, acc: 71.88%] [G loss: 2.059994]\n",
      "epoch:20 step:16115 [D loss: 0.272629, acc: 96.88%] [G loss: 2.591552]\n",
      "epoch:20 step:16116 [D loss: 0.596587, acc: 68.75%] [G loss: 3.646281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:16117 [D loss: 0.223895, acc: 95.31%] [G loss: 5.102892]\n",
      "epoch:20 step:16118 [D loss: 0.569219, acc: 73.44%] [G loss: 3.867320]\n",
      "epoch:20 step:16119 [D loss: 0.643581, acc: 57.03%] [G loss: 2.904234]\n",
      "epoch:20 step:16120 [D loss: 0.443408, acc: 83.59%] [G loss: 2.802828]\n",
      "epoch:20 step:16121 [D loss: 0.293019, acc: 96.88%] [G loss: 2.989829]\n",
      "epoch:20 step:16122 [D loss: 0.480708, acc: 80.47%] [G loss: 3.847962]\n",
      "epoch:20 step:16123 [D loss: 0.401589, acc: 87.50%] [G loss: 2.958292]\n",
      "epoch:20 step:16124 [D loss: 0.536720, acc: 77.34%] [G loss: 2.874829]\n",
      "epoch:20 step:16125 [D loss: 0.335884, acc: 93.75%] [G loss: 3.066254]\n",
      "epoch:20 step:16126 [D loss: 0.656833, acc: 61.72%] [G loss: 3.577260]\n",
      "epoch:20 step:16127 [D loss: 0.410812, acc: 79.69%] [G loss: 2.921936]\n",
      "epoch:20 step:16128 [D loss: 0.382163, acc: 86.72%] [G loss: 2.942124]\n",
      "epoch:20 step:16129 [D loss: 0.538425, acc: 75.00%] [G loss: 3.160311]\n",
      "epoch:20 step:16130 [D loss: 0.251451, acc: 94.53%] [G loss: 4.074091]\n",
      "epoch:20 step:16131 [D loss: 0.269818, acc: 90.62%] [G loss: 4.937896]\n",
      "epoch:20 step:16132 [D loss: 0.380111, acc: 80.47%] [G loss: 3.104759]\n",
      "epoch:20 step:16133 [D loss: 0.776938, acc: 55.47%] [G loss: 2.774181]\n",
      "epoch:20 step:16134 [D loss: 0.775431, acc: 47.66%] [G loss: 3.291697]\n",
      "epoch:20 step:16135 [D loss: 0.698758, acc: 56.25%] [G loss: 2.074974]\n",
      "epoch:20 step:16136 [D loss: 0.526509, acc: 72.66%] [G loss: 3.670831]\n",
      "epoch:20 step:16137 [D loss: 0.182396, acc: 99.22%] [G loss: 3.432872]\n",
      "epoch:20 step:16138 [D loss: 0.869211, acc: 42.19%] [G loss: 3.121471]\n",
      "epoch:20 step:16139 [D loss: 1.060044, acc: 48.44%] [G loss: 2.706823]\n",
      "epoch:20 step:16140 [D loss: 0.665594, acc: 64.84%] [G loss: 3.167800]\n",
      "epoch:20 step:16141 [D loss: 0.489570, acc: 67.97%] [G loss: 3.015109]\n",
      "epoch:20 step:16142 [D loss: 0.997248, acc: 38.28%] [G loss: 1.988987]\n",
      "epoch:20 step:16143 [D loss: 0.793522, acc: 52.34%] [G loss: 2.880564]\n",
      "epoch:20 step:16144 [D loss: 0.630712, acc: 61.72%] [G loss: 2.489270]\n",
      "epoch:20 step:16145 [D loss: 0.346900, acc: 91.41%] [G loss: 3.456657]\n",
      "epoch:20 step:16146 [D loss: 1.169011, acc: 17.97%] [G loss: 1.798268]\n",
      "epoch:20 step:16147 [D loss: 0.551195, acc: 71.09%] [G loss: 2.654015]\n",
      "epoch:20 step:16148 [D loss: 0.394229, acc: 86.72%] [G loss: 2.110500]\n",
      "epoch:20 step:16149 [D loss: 0.740716, acc: 58.59%] [G loss: 2.554599]\n",
      "epoch:20 step:16150 [D loss: 0.409930, acc: 88.28%] [G loss: 3.478361]\n",
      "epoch:20 step:16151 [D loss: 0.757112, acc: 47.66%] [G loss: 2.692584]\n",
      "epoch:20 step:16152 [D loss: 1.069154, acc: 36.72%] [G loss: 3.363256]\n",
      "epoch:20 step:16153 [D loss: 0.692086, acc: 54.69%] [G loss: 3.162506]\n",
      "epoch:20 step:16154 [D loss: 0.543630, acc: 73.44%] [G loss: 2.763335]\n",
      "epoch:20 step:16155 [D loss: 0.871369, acc: 35.94%] [G loss: 2.113441]\n",
      "epoch:20 step:16156 [D loss: 0.186928, acc: 99.22%] [G loss: 3.454531]\n",
      "epoch:20 step:16157 [D loss: 0.656646, acc: 66.41%] [G loss: 2.888196]\n",
      "epoch:20 step:16158 [D loss: 0.233350, acc: 94.53%] [G loss: 3.476353]\n",
      "epoch:20 step:16159 [D loss: 0.796476, acc: 49.22%] [G loss: 1.961611]\n",
      "epoch:20 step:16160 [D loss: 0.513625, acc: 77.34%] [G loss: 2.730612]\n",
      "epoch:20 step:16161 [D loss: 0.327415, acc: 92.97%] [G loss: 3.369603]\n",
      "epoch:20 step:16162 [D loss: 0.370181, acc: 92.19%] [G loss: 3.259458]\n",
      "epoch:20 step:16163 [D loss: 0.339291, acc: 89.06%] [G loss: 3.101360]\n",
      "epoch:20 step:16164 [D loss: 1.177882, acc: 36.72%] [G loss: 2.782866]\n",
      "epoch:20 step:16165 [D loss: 0.465004, acc: 81.25%] [G loss: 2.737214]\n",
      "epoch:20 step:16166 [D loss: 0.654069, acc: 60.94%] [G loss: 2.448176]\n",
      "epoch:20 step:16167 [D loss: 0.372186, acc: 89.84%] [G loss: 3.032568]\n",
      "epoch:20 step:16168 [D loss: 0.668043, acc: 58.59%] [G loss: 3.381394]\n",
      "epoch:20 step:16169 [D loss: 1.019243, acc: 24.22%] [G loss: 2.932883]\n",
      "epoch:20 step:16170 [D loss: 0.295900, acc: 92.97%] [G loss: 3.284655]\n",
      "epoch:20 step:16171 [D loss: 0.371268, acc: 87.50%] [G loss: 2.656022]\n",
      "epoch:20 step:16172 [D loss: 0.908125, acc: 42.19%] [G loss: 2.519049]\n",
      "epoch:20 step:16173 [D loss: 0.494540, acc: 81.25%] [G loss: 3.112818]\n",
      "epoch:20 step:16174 [D loss: 0.558697, acc: 65.62%] [G loss: 2.431347]\n",
      "epoch:20 step:16175 [D loss: 0.379799, acc: 88.28%] [G loss: 2.420278]\n",
      "epoch:20 step:16176 [D loss: 0.750020, acc: 51.56%] [G loss: 3.542941]\n",
      "epoch:20 step:16177 [D loss: 0.400576, acc: 82.81%] [G loss: 3.458335]\n",
      "epoch:20 step:16178 [D loss: 0.601009, acc: 67.97%] [G loss: 3.076002]\n",
      "epoch:20 step:16179 [D loss: 0.436512, acc: 73.44%] [G loss: 3.920032]\n",
      "epoch:20 step:16180 [D loss: 0.396407, acc: 82.03%] [G loss: 4.322126]\n",
      "epoch:20 step:16181 [D loss: 0.224935, acc: 96.88%] [G loss: 3.111048]\n",
      "epoch:20 step:16182 [D loss: 0.923133, acc: 35.16%] [G loss: 2.970805]\n",
      "epoch:20 step:16183 [D loss: 0.710381, acc: 53.91%] [G loss: 3.209311]\n",
      "epoch:20 step:16184 [D loss: 0.354403, acc: 89.84%] [G loss: 3.647402]\n",
      "epoch:20 step:16185 [D loss: 0.600238, acc: 64.84%] [G loss: 2.697304]\n",
      "epoch:20 step:16186 [D loss: 0.409962, acc: 83.59%] [G loss: 3.035471]\n",
      "epoch:20 step:16187 [D loss: 0.899834, acc: 31.25%] [G loss: 3.202446]\n",
      "epoch:20 step:16188 [D loss: 0.557758, acc: 72.66%] [G loss: 3.248819]\n",
      "epoch:20 step:16189 [D loss: 0.125064, acc: 100.00%] [G loss: 3.679672]\n",
      "epoch:20 step:16190 [D loss: 0.334999, acc: 89.06%] [G loss: 4.457426]\n",
      "epoch:20 step:16191 [D loss: 0.595126, acc: 67.19%] [G loss: 3.705827]\n",
      "epoch:20 step:16192 [D loss: 0.360228, acc: 80.47%] [G loss: 3.614686]\n",
      "epoch:20 step:16193 [D loss: 0.293430, acc: 91.41%] [G loss: 3.777754]\n",
      "epoch:20 step:16194 [D loss: 0.331525, acc: 94.53%] [G loss: 3.561073]\n",
      "epoch:20 step:16195 [D loss: 1.310442, acc: 39.06%] [G loss: 1.815676]\n",
      "epoch:20 step:16196 [D loss: 0.420042, acc: 84.38%] [G loss: 3.543622]\n",
      "epoch:20 step:16197 [D loss: 0.760761, acc: 53.91%] [G loss: 2.855409]\n",
      "epoch:20 step:16198 [D loss: 0.336785, acc: 92.97%] [G loss: 3.381172]\n",
      "epoch:20 step:16199 [D loss: 0.403086, acc: 77.34%] [G loss: 3.310542]\n",
      "epoch:20 step:16200 [D loss: 0.375384, acc: 83.59%] [G loss: 3.031125]\n",
      "epoch:20 step:16201 [D loss: 0.928997, acc: 39.84%] [G loss: 2.750059]\n",
      "epoch:20 step:16202 [D loss: 0.435881, acc: 82.03%] [G loss: 3.058487]\n",
      "epoch:20 step:16203 [D loss: 0.343266, acc: 87.50%] [G loss: 2.946946]\n",
      "epoch:20 step:16204 [D loss: 0.474106, acc: 77.34%] [G loss: 2.926280]\n",
      "epoch:20 step:16205 [D loss: 0.515623, acc: 82.03%] [G loss: 3.952202]\n",
      "epoch:20 step:16206 [D loss: 0.365584, acc: 91.41%] [G loss: 4.423017]\n",
      "epoch:20 step:16207 [D loss: 0.422221, acc: 81.25%] [G loss: 1.926996]\n",
      "epoch:20 step:16208 [D loss: 0.230853, acc: 98.44%] [G loss: 2.604509]\n",
      "epoch:20 step:16209 [D loss: 0.998330, acc: 22.66%] [G loss: 3.512321]\n",
      "epoch:20 step:16210 [D loss: 0.530392, acc: 77.34%] [G loss: 2.251368]\n",
      "epoch:20 step:16211 [D loss: 0.557286, acc: 74.22%] [G loss: 2.505860]\n",
      "epoch:20 step:16212 [D loss: 0.616164, acc: 65.62%] [G loss: 2.550131]\n",
      "epoch:20 step:16213 [D loss: 0.692913, acc: 53.91%] [G loss: 3.355300]\n",
      "epoch:20 step:16214 [D loss: 0.306342, acc: 96.09%] [G loss: 3.131490]\n",
      "epoch:20 step:16215 [D loss: 0.455005, acc: 88.28%] [G loss: 3.010972]\n",
      "epoch:20 step:16216 [D loss: 0.930144, acc: 50.78%] [G loss: 3.308384]\n",
      "epoch:20 step:16217 [D loss: 0.353233, acc: 90.62%] [G loss: 3.019192]\n",
      "epoch:20 step:16218 [D loss: 0.628281, acc: 60.16%] [G loss: 3.313500]\n",
      "epoch:20 step:16219 [D loss: 0.988635, acc: 25.00%] [G loss: 2.619616]\n",
      "epoch:20 step:16220 [D loss: 0.608893, acc: 65.62%] [G loss: 2.185772]\n",
      "epoch:20 step:16221 [D loss: 0.634753, acc: 62.50%] [G loss: 3.296607]\n",
      "epoch:20 step:16222 [D loss: 0.563073, acc: 64.84%] [G loss: 3.255001]\n",
      "epoch:20 step:16223 [D loss: 0.717029, acc: 53.91%] [G loss: 3.289213]\n",
      "epoch:20 step:16224 [D loss: 0.373027, acc: 92.19%] [G loss: 3.198161]\n",
      "epoch:20 step:16225 [D loss: 0.356314, acc: 84.38%] [G loss: 2.601411]\n",
      "epoch:20 step:16226 [D loss: 0.589295, acc: 69.53%] [G loss: 3.465903]\n",
      "epoch:20 step:16227 [D loss: 0.447059, acc: 80.47%] [G loss: 3.121223]\n",
      "epoch:20 step:16228 [D loss: 0.487037, acc: 78.91%] [G loss: 2.703140]\n",
      "epoch:20 step:16229 [D loss: 0.462702, acc: 82.81%] [G loss: 3.541295]\n",
      "epoch:20 step:16230 [D loss: 0.552531, acc: 66.41%] [G loss: 3.128516]\n",
      "epoch:20 step:16231 [D loss: 0.684789, acc: 60.94%] [G loss: 3.048118]\n",
      "epoch:20 step:16232 [D loss: 0.572872, acc: 64.84%] [G loss: 3.195327]\n",
      "epoch:20 step:16233 [D loss: 0.566590, acc: 75.00%] [G loss: 2.217460]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:16234 [D loss: 0.295841, acc: 95.31%] [G loss: 2.433059]\n",
      "epoch:20 step:16235 [D loss: 0.637040, acc: 60.94%] [G loss: 2.152912]\n",
      "epoch:20 step:16236 [D loss: 0.733066, acc: 53.12%] [G loss: 3.125188]\n",
      "epoch:20 step:16237 [D loss: 0.426905, acc: 77.34%] [G loss: 3.276657]\n",
      "epoch:20 step:16238 [D loss: 0.166482, acc: 100.00%] [G loss: 2.738462]\n",
      "epoch:20 step:16239 [D loss: 0.801234, acc: 44.53%] [G loss: 3.531468]\n",
      "epoch:20 step:16240 [D loss: 0.327559, acc: 93.75%] [G loss: 2.398082]\n",
      "epoch:20 step:16241 [D loss: 0.427973, acc: 86.72%] [G loss: 3.133063]\n",
      "epoch:20 step:16242 [D loss: 0.523583, acc: 74.22%] [G loss: 3.034423]\n",
      "epoch:20 step:16243 [D loss: 0.438060, acc: 82.03%] [G loss: 2.087771]\n",
      "epoch:20 step:16244 [D loss: 0.436920, acc: 86.72%] [G loss: 3.837244]\n",
      "epoch:20 step:16245 [D loss: 0.865879, acc: 40.62%] [G loss: 3.399202]\n",
      "epoch:20 step:16246 [D loss: 0.464632, acc: 82.81%] [G loss: 2.701429]\n",
      "epoch:20 step:16247 [D loss: 0.802356, acc: 46.09%] [G loss: 2.382791]\n",
      "epoch:20 step:16248 [D loss: 0.403739, acc: 88.28%] [G loss: 4.045967]\n",
      "epoch:20 step:16249 [D loss: 0.438908, acc: 85.16%] [G loss: 3.121956]\n",
      "epoch:20 step:16250 [D loss: 0.339384, acc: 88.28%] [G loss: 3.543769]\n",
      "epoch:20 step:16251 [D loss: 0.336574, acc: 93.75%] [G loss: 3.750729]\n",
      "epoch:20 step:16252 [D loss: 1.022605, acc: 45.31%] [G loss: 3.675041]\n",
      "epoch:20 step:16253 [D loss: 0.192047, acc: 100.00%] [G loss: 3.205412]\n",
      "epoch:20 step:16254 [D loss: 0.453063, acc: 82.03%] [G loss: 2.430350]\n",
      "epoch:20 step:16255 [D loss: 0.492495, acc: 75.78%] [G loss: 3.829974]\n",
      "epoch:20 step:16256 [D loss: 0.573511, acc: 64.84%] [G loss: 2.646259]\n",
      "epoch:20 step:16257 [D loss: 0.302817, acc: 87.50%] [G loss: 2.261902]\n",
      "epoch:20 step:16258 [D loss: 0.413619, acc: 88.28%] [G loss: 3.068769]\n",
      "epoch:20 step:16259 [D loss: 0.837323, acc: 39.84%] [G loss: 3.279825]\n",
      "epoch:20 step:16260 [D loss: 0.136647, acc: 99.22%] [G loss: 4.014838]\n",
      "epoch:20 step:16261 [D loss: 0.471907, acc: 72.66%] [G loss: 3.452414]\n",
      "epoch:20 step:16262 [D loss: 1.293965, acc: 48.44%] [G loss: 2.970737]\n",
      "epoch:20 step:16263 [D loss: 0.525708, acc: 75.00%] [G loss: 3.278473]\n",
      "epoch:20 step:16264 [D loss: 0.363489, acc: 89.06%] [G loss: 2.859502]\n",
      "epoch:20 step:16265 [D loss: 0.619124, acc: 64.06%] [G loss: 3.047055]\n",
      "epoch:20 step:16266 [D loss: 0.912194, acc: 31.25%] [G loss: 2.803755]\n",
      "epoch:20 step:16267 [D loss: 0.433416, acc: 78.91%] [G loss: 2.826501]\n",
      "epoch:20 step:16268 [D loss: 0.462516, acc: 84.38%] [G loss: 2.703290]\n",
      "epoch:20 step:16269 [D loss: 0.370807, acc: 93.75%] [G loss: 2.715137]\n",
      "epoch:20 step:16270 [D loss: 0.223461, acc: 99.22%] [G loss: 4.186948]\n",
      "epoch:20 step:16271 [D loss: 0.523097, acc: 70.31%] [G loss: 3.698507]\n",
      "epoch:20 step:16272 [D loss: 0.451596, acc: 75.78%] [G loss: 3.761884]\n",
      "epoch:20 step:16273 [D loss: 0.417163, acc: 89.06%] [G loss: 3.834923]\n",
      "epoch:20 step:16274 [D loss: 0.109545, acc: 100.00%] [G loss: 3.009012]\n",
      "epoch:20 step:16275 [D loss: 0.294472, acc: 92.97%] [G loss: 2.978921]\n",
      "epoch:20 step:16276 [D loss: 0.877903, acc: 33.59%] [G loss: 2.733217]\n",
      "epoch:20 step:16277 [D loss: 0.332853, acc: 93.75%] [G loss: 3.629478]\n",
      "epoch:20 step:16278 [D loss: 0.689059, acc: 54.69%] [G loss: 2.804075]\n",
      "epoch:20 step:16279 [D loss: 0.504706, acc: 77.34%] [G loss: 2.172056]\n",
      "epoch:20 step:16280 [D loss: 0.236739, acc: 97.66%] [G loss: 3.355906]\n",
      "epoch:20 step:16281 [D loss: 0.381799, acc: 92.19%] [G loss: 3.164712]\n",
      "epoch:20 step:16282 [D loss: 0.447802, acc: 82.81%] [G loss: 3.829288]\n",
      "epoch:20 step:16283 [D loss: 0.354042, acc: 92.97%] [G loss: 2.906905]\n",
      "epoch:20 step:16284 [D loss: 0.385162, acc: 89.84%] [G loss: 2.442826]\n",
      "epoch:20 step:16285 [D loss: 0.876558, acc: 43.75%] [G loss: 3.601537]\n",
      "epoch:20 step:16286 [D loss: 0.427872, acc: 82.03%] [G loss: 2.632403]\n",
      "epoch:20 step:16287 [D loss: 0.178058, acc: 100.00%] [G loss: 4.477800]\n",
      "epoch:20 step:16288 [D loss: 0.540951, acc: 64.84%] [G loss: 4.301467]\n",
      "epoch:20 step:16289 [D loss: 0.630342, acc: 65.62%] [G loss: 2.759206]\n",
      "epoch:20 step:16290 [D loss: 0.442908, acc: 71.09%] [G loss: 3.513124]\n",
      "epoch:20 step:16291 [D loss: 0.255661, acc: 95.31%] [G loss: 3.066146]\n",
      "epoch:20 step:16292 [D loss: 0.416162, acc: 86.72%] [G loss: 2.623367]\n",
      "epoch:20 step:16293 [D loss: 0.424081, acc: 88.28%] [G loss: 2.879827]\n",
      "epoch:20 step:16294 [D loss: 0.776654, acc: 52.34%] [G loss: 3.444912]\n",
      "epoch:20 step:16295 [D loss: 0.216653, acc: 98.44%] [G loss: 2.723621]\n",
      "epoch:20 step:16296 [D loss: 0.373258, acc: 92.19%] [G loss: 4.023694]\n",
      "epoch:20 step:16297 [D loss: 0.279927, acc: 94.53%] [G loss: 3.400253]\n",
      "epoch:20 step:16298 [D loss: 0.526278, acc: 69.53%] [G loss: 3.612882]\n",
      "epoch:20 step:16299 [D loss: 0.232828, acc: 100.00%] [G loss: 3.171448]\n",
      "epoch:20 step:16300 [D loss: 0.467640, acc: 85.94%] [G loss: 2.179400]\n",
      "epoch:20 step:16301 [D loss: 0.557000, acc: 75.00%] [G loss: 2.730969]\n",
      "epoch:20 step:16302 [D loss: 0.561517, acc: 78.91%] [G loss: 4.133183]\n",
      "epoch:20 step:16303 [D loss: 0.424963, acc: 86.72%] [G loss: 4.802186]\n",
      "epoch:20 step:16304 [D loss: 1.410305, acc: 10.94%] [G loss: 3.510294]\n",
      "epoch:20 step:16305 [D loss: 0.161215, acc: 100.00%] [G loss: 2.830099]\n",
      "epoch:20 step:16306 [D loss: 0.216305, acc: 96.88%] [G loss: 2.254719]\n",
      "epoch:20 step:16307 [D loss: 0.704917, acc: 55.47%] [G loss: 2.913166]\n",
      "epoch:20 step:16308 [D loss: 0.346644, acc: 94.53%] [G loss: 3.053114]\n",
      "epoch:20 step:16309 [D loss: 0.388639, acc: 78.12%] [G loss: 3.904473]\n",
      "epoch:20 step:16310 [D loss: 0.429550, acc: 71.88%] [G loss: 4.040475]\n",
      "epoch:20 step:16311 [D loss: 0.241410, acc: 96.09%] [G loss: 3.034184]\n",
      "epoch:20 step:16312 [D loss: 0.586730, acc: 67.19%] [G loss: 2.654076]\n",
      "epoch:20 step:16313 [D loss: 0.587077, acc: 72.66%] [G loss: 4.593962]\n",
      "epoch:20 step:16314 [D loss: 0.427155, acc: 86.72%] [G loss: 3.015464]\n",
      "epoch:20 step:16315 [D loss: 0.246341, acc: 98.44%] [G loss: 2.743059]\n",
      "epoch:20 step:16316 [D loss: 0.647903, acc: 59.38%] [G loss: 2.705942]\n",
      "epoch:20 step:16317 [D loss: 1.062970, acc: 35.94%] [G loss: 2.701507]\n",
      "epoch:20 step:16318 [D loss: 0.899686, acc: 29.69%] [G loss: 2.920452]\n",
      "epoch:20 step:16319 [D loss: 0.567361, acc: 63.28%] [G loss: 3.215532]\n",
      "epoch:20 step:16320 [D loss: 0.898580, acc: 49.22%] [G loss: 2.642617]\n",
      "epoch:20 step:16321 [D loss: 0.213312, acc: 97.66%] [G loss: 2.929232]\n",
      "epoch:20 step:16322 [D loss: 0.480588, acc: 79.69%] [G loss: 4.143006]\n",
      "epoch:20 step:16323 [D loss: 0.252977, acc: 98.44%] [G loss: 5.003047]\n",
      "epoch:20 step:16324 [D loss: 0.433754, acc: 86.72%] [G loss: 4.377609]\n",
      "epoch:20 step:16325 [D loss: 0.361788, acc: 92.97%] [G loss: 3.392607]\n",
      "epoch:20 step:16326 [D loss: 0.427247, acc: 89.06%] [G loss: 2.928757]\n",
      "epoch:20 step:16327 [D loss: 0.557914, acc: 66.41%] [G loss: 2.922782]\n",
      "epoch:20 step:16328 [D loss: 0.243109, acc: 95.31%] [G loss: 2.654643]\n",
      "epoch:20 step:16329 [D loss: 0.644560, acc: 62.50%] [G loss: 2.837164]\n",
      "epoch:20 step:16330 [D loss: 0.229830, acc: 96.88%] [G loss: 3.277106]\n",
      "epoch:20 step:16331 [D loss: 0.294475, acc: 91.41%] [G loss: 3.773307]\n",
      "epoch:20 step:16332 [D loss: 0.210883, acc: 96.09%] [G loss: 2.545377]\n",
      "epoch:20 step:16333 [D loss: 0.490538, acc: 83.59%] [G loss: 3.367738]\n",
      "epoch:20 step:16334 [D loss: 0.298993, acc: 96.88%] [G loss: 3.033898]\n",
      "epoch:20 step:16335 [D loss: 0.599299, acc: 66.41%] [G loss: 3.219683]\n",
      "epoch:20 step:16336 [D loss: 0.599681, acc: 65.62%] [G loss: 3.320976]\n",
      "epoch:20 step:16337 [D loss: 0.559928, acc: 74.22%] [G loss: 3.753250]\n",
      "epoch:20 step:16338 [D loss: 0.380400, acc: 80.47%] [G loss: 3.018548]\n",
      "epoch:20 step:16339 [D loss: 0.129809, acc: 100.00%] [G loss: 3.945774]\n",
      "epoch:20 step:16340 [D loss: 0.579827, acc: 64.84%] [G loss: 4.220784]\n",
      "epoch:20 step:16341 [D loss: 0.430357, acc: 74.22%] [G loss: 4.064721]\n",
      "epoch:20 step:16342 [D loss: 0.650623, acc: 57.03%] [G loss: 2.249702]\n",
      "epoch:20 step:16343 [D loss: 0.130848, acc: 99.22%] [G loss: 4.225959]\n",
      "epoch:20 step:16344 [D loss: 0.541208, acc: 66.41%] [G loss: 2.876879]\n",
      "epoch:20 step:16345 [D loss: 0.407114, acc: 84.38%] [G loss: 3.957536]\n",
      "epoch:20 step:16346 [D loss: 0.295024, acc: 88.28%] [G loss: 3.227992]\n",
      "epoch:20 step:16347 [D loss: 0.414610, acc: 86.72%] [G loss: 3.902975]\n",
      "epoch:20 step:16348 [D loss: 0.539080, acc: 67.97%] [G loss: 3.927057]\n",
      "epoch:20 step:16349 [D loss: 0.204516, acc: 98.44%] [G loss: 3.270364]\n",
      "epoch:20 step:16350 [D loss: 0.700770, acc: 60.16%] [G loss: 3.880058]\n",
      "epoch:20 step:16351 [D loss: 0.336127, acc: 86.72%] [G loss: 3.178634]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:16352 [D loss: 0.649109, acc: 60.16%] [G loss: 3.190567]\n",
      "epoch:20 step:16353 [D loss: 0.386519, acc: 94.53%] [G loss: 3.154135]\n",
      "epoch:20 step:16354 [D loss: 0.561206, acc: 61.72%] [G loss: 2.809460]\n",
      "epoch:20 step:16355 [D loss: 0.915287, acc: 50.78%] [G loss: 3.403288]\n",
      "epoch:20 step:16356 [D loss: 0.287209, acc: 96.88%] [G loss: 2.632254]\n",
      "epoch:20 step:16357 [D loss: 0.323113, acc: 92.19%] [G loss: 3.497980]\n",
      "epoch:20 step:16358 [D loss: 0.913112, acc: 39.84%] [G loss: 3.179466]\n",
      "epoch:20 step:16359 [D loss: 0.253796, acc: 97.66%] [G loss: 3.287017]\n",
      "epoch:20 step:16360 [D loss: 1.021030, acc: 30.47%] [G loss: 2.957963]\n",
      "epoch:20 step:16361 [D loss: 0.195117, acc: 99.22%] [G loss: 3.452648]\n",
      "epoch:20 step:16362 [D loss: 0.831948, acc: 46.88%] [G loss: 4.031498]\n",
      "epoch:20 step:16363 [D loss: 0.184113, acc: 95.31%] [G loss: 4.948390]\n",
      "epoch:20 step:16364 [D loss: 0.650831, acc: 60.94%] [G loss: 2.824836]\n",
      "epoch:20 step:16365 [D loss: 0.552552, acc: 68.75%] [G loss: 2.514339]\n",
      "epoch:20 step:16366 [D loss: 0.263809, acc: 91.41%] [G loss: 4.237395]\n",
      "epoch:20 step:16367 [D loss: 0.732277, acc: 62.50%] [G loss: 3.616511]\n",
      "epoch:20 step:16368 [D loss: 0.093479, acc: 99.22%] [G loss: 4.448146]\n",
      "epoch:20 step:16369 [D loss: 0.637311, acc: 67.19%] [G loss: 3.306728]\n",
      "epoch:20 step:16370 [D loss: 0.172025, acc: 97.66%] [G loss: 3.914999]\n",
      "epoch:20 step:16371 [D loss: 0.736699, acc: 57.81%] [G loss: 3.643031]\n",
      "epoch:20 step:16372 [D loss: 0.401197, acc: 81.25%] [G loss: 2.971323]\n",
      "epoch:20 step:16373 [D loss: 0.580333, acc: 67.19%] [G loss: 3.234818]\n",
      "epoch:20 step:16374 [D loss: 0.565279, acc: 67.19%] [G loss: 2.954936]\n",
      "epoch:20 step:16375 [D loss: 0.692537, acc: 56.25%] [G loss: 4.270841]\n",
      "epoch:20 step:16376 [D loss: 0.755981, acc: 53.12%] [G loss: 3.013107]\n",
      "epoch:20 step:16377 [D loss: 0.558429, acc: 66.41%] [G loss: 3.480636]\n",
      "epoch:20 step:16378 [D loss: 0.312306, acc: 91.41%] [G loss: 4.990804]\n",
      "epoch:20 step:16379 [D loss: 0.357409, acc: 92.19%] [G loss: 3.910193]\n",
      "epoch:20 step:16380 [D loss: 1.302524, acc: 50.00%] [G loss: 3.333365]\n",
      "epoch:20 step:16381 [D loss: 0.479849, acc: 65.62%] [G loss: 2.868410]\n",
      "epoch:20 step:16382 [D loss: 0.524016, acc: 79.69%] [G loss: 2.788298]\n",
      "epoch:20 step:16383 [D loss: 0.693914, acc: 64.06%] [G loss: 3.050971]\n",
      "epoch:20 step:16384 [D loss: 0.682946, acc: 57.81%] [G loss: 2.690046]\n",
      "epoch:20 step:16385 [D loss: 0.403104, acc: 79.69%] [G loss: 2.973915]\n",
      "epoch:20 step:16386 [D loss: 0.512254, acc: 67.97%] [G loss: 2.801805]\n",
      "epoch:20 step:16387 [D loss: 0.199919, acc: 98.44%] [G loss: 3.145602]\n",
      "epoch:20 step:16388 [D loss: 0.179258, acc: 99.22%] [G loss: 4.118059]\n",
      "epoch:20 step:16389 [D loss: 0.774581, acc: 43.75%] [G loss: 2.649722]\n",
      "epoch:20 step:16390 [D loss: 0.236621, acc: 97.66%] [G loss: 3.049252]\n",
      "epoch:20 step:16391 [D loss: 0.723153, acc: 53.91%] [G loss: 3.680518]\n",
      "epoch:20 step:16392 [D loss: 0.238075, acc: 98.44%] [G loss: 3.515548]\n",
      "epoch:20 step:16393 [D loss: 0.225178, acc: 95.31%] [G loss: 4.505175]\n",
      "epoch:20 step:16394 [D loss: 0.281290, acc: 97.66%] [G loss: 4.359196]\n",
      "epoch:20 step:16395 [D loss: 0.201142, acc: 96.09%] [G loss: 4.376944]\n",
      "epoch:20 step:16396 [D loss: 0.636605, acc: 64.84%] [G loss: 3.865947]\n",
      "epoch:20 step:16397 [D loss: 0.904415, acc: 43.75%] [G loss: 3.941023]\n",
      "epoch:20 step:16398 [D loss: 0.410648, acc: 74.22%] [G loss: 3.574043]\n",
      "epoch:20 step:16399 [D loss: 0.600484, acc: 71.88%] [G loss: 2.031558]\n",
      "epoch:20 step:16400 [D loss: 0.693902, acc: 60.16%] [G loss: 2.776936]\n",
      "epoch:20 step:16401 [D loss: 0.315772, acc: 93.75%] [G loss: 3.108431]\n",
      "epoch:21 step:16402 [D loss: 0.204527, acc: 98.44%] [G loss: 3.240902]\n",
      "epoch:21 step:16403 [D loss: 0.141338, acc: 98.44%] [G loss: 3.023411]\n",
      "epoch:21 step:16404 [D loss: 0.804218, acc: 46.88%] [G loss: 2.348014]\n",
      "epoch:21 step:16405 [D loss: 0.439216, acc: 87.50%] [G loss: 2.620574]\n",
      "epoch:21 step:16406 [D loss: 0.636945, acc: 58.59%] [G loss: 2.873343]\n",
      "epoch:21 step:16407 [D loss: 0.550645, acc: 72.66%] [G loss: 3.688339]\n",
      "epoch:21 step:16408 [D loss: 0.447994, acc: 87.50%] [G loss: 2.848001]\n",
      "epoch:21 step:16409 [D loss: 0.317348, acc: 93.75%] [G loss: 3.752272]\n",
      "epoch:21 step:16410 [D loss: 0.745269, acc: 56.25%] [G loss: 3.902076]\n",
      "epoch:21 step:16411 [D loss: 0.493976, acc: 78.91%] [G loss: 3.840724]\n",
      "epoch:21 step:16412 [D loss: 0.314754, acc: 92.97%] [G loss: 3.147246]\n",
      "epoch:21 step:16413 [D loss: 0.356057, acc: 82.03%] [G loss: 4.250648]\n",
      "epoch:21 step:16414 [D loss: 0.185793, acc: 97.66%] [G loss: 2.407289]\n",
      "epoch:21 step:16415 [D loss: 0.468116, acc: 79.69%] [G loss: 3.219927]\n",
      "epoch:21 step:16416 [D loss: 0.471924, acc: 79.69%] [G loss: 2.577029]\n",
      "epoch:21 step:16417 [D loss: 1.145314, acc: 14.84%] [G loss: 2.499584]\n",
      "epoch:21 step:16418 [D loss: 0.143784, acc: 97.66%] [G loss: 2.664706]\n",
      "epoch:21 step:16419 [D loss: 0.406820, acc: 84.38%] [G loss: 2.439803]\n",
      "epoch:21 step:16420 [D loss: 1.101625, acc: 34.38%] [G loss: 3.952799]\n",
      "epoch:21 step:16421 [D loss: 0.361507, acc: 91.41%] [G loss: 3.996952]\n",
      "epoch:21 step:16422 [D loss: 0.233198, acc: 96.09%] [G loss: 3.424677]\n",
      "epoch:21 step:16423 [D loss: 0.806981, acc: 52.34%] [G loss: 2.411339]\n",
      "epoch:21 step:16424 [D loss: 0.781003, acc: 46.09%] [G loss: 2.561101]\n",
      "epoch:21 step:16425 [D loss: 0.342821, acc: 90.62%] [G loss: 3.712482]\n",
      "epoch:21 step:16426 [D loss: 0.225095, acc: 98.44%] [G loss: 3.095654]\n",
      "epoch:21 step:16427 [D loss: 0.655767, acc: 55.47%] [G loss: 2.056984]\n",
      "epoch:21 step:16428 [D loss: 0.328112, acc: 91.41%] [G loss: 4.302677]\n",
      "epoch:21 step:16429 [D loss: 0.801588, acc: 52.34%] [G loss: 5.112674]\n",
      "epoch:21 step:16430 [D loss: 1.019556, acc: 50.00%] [G loss: 2.376451]\n",
      "epoch:21 step:16431 [D loss: 0.304626, acc: 93.75%] [G loss: 4.108827]\n",
      "epoch:21 step:16432 [D loss: 0.900841, acc: 32.81%] [G loss: 2.552321]\n",
      "epoch:21 step:16433 [D loss: 0.464675, acc: 71.88%] [G loss: 4.066883]\n",
      "epoch:21 step:16434 [D loss: 0.451973, acc: 76.56%] [G loss: 5.214633]\n",
      "epoch:21 step:16435 [D loss: 0.313974, acc: 93.75%] [G loss: 3.701383]\n",
      "epoch:21 step:16436 [D loss: 0.226804, acc: 96.09%] [G loss: 4.814731]\n",
      "epoch:21 step:16437 [D loss: 0.421883, acc: 76.56%] [G loss: 5.340559]\n",
      "epoch:21 step:16438 [D loss: 0.503052, acc: 83.59%] [G loss: 4.924376]\n",
      "epoch:21 step:16439 [D loss: 0.283799, acc: 90.62%] [G loss: 3.701802]\n",
      "epoch:21 step:16440 [D loss: 0.364615, acc: 88.28%] [G loss: 3.052508]\n",
      "epoch:21 step:16441 [D loss: 0.672163, acc: 62.50%] [G loss: 3.790159]\n",
      "epoch:21 step:16442 [D loss: 0.109869, acc: 99.22%] [G loss: 2.280712]\n",
      "epoch:21 step:16443 [D loss: 0.352340, acc: 89.84%] [G loss: 2.989090]\n",
      "epoch:21 step:16444 [D loss: 0.749574, acc: 52.34%] [G loss: 3.418666]\n",
      "epoch:21 step:16445 [D loss: 0.500816, acc: 65.62%] [G loss: 3.711213]\n",
      "epoch:21 step:16446 [D loss: 0.187742, acc: 97.66%] [G loss: 4.703689]\n",
      "epoch:21 step:16447 [D loss: 0.419966, acc: 84.38%] [G loss: 4.150952]\n",
      "epoch:21 step:16448 [D loss: 0.669318, acc: 60.16%] [G loss: 1.788862]\n",
      "epoch:21 step:16449 [D loss: 0.608874, acc: 67.19%] [G loss: 2.061760]\n",
      "epoch:21 step:16450 [D loss: 0.600645, acc: 72.66%] [G loss: 3.120266]\n",
      "epoch:21 step:16451 [D loss: 0.406987, acc: 89.06%] [G loss: 2.563295]\n",
      "epoch:21 step:16452 [D loss: 0.413500, acc: 84.38%] [G loss: 2.845839]\n",
      "epoch:21 step:16453 [D loss: 0.144348, acc: 99.22%] [G loss: 2.151973]\n",
      "epoch:21 step:16454 [D loss: 1.473087, acc: 8.59%] [G loss: 3.071653]\n",
      "epoch:21 step:16455 [D loss: 0.397808, acc: 82.81%] [G loss: 1.931525]\n",
      "epoch:21 step:16456 [D loss: 0.578833, acc: 69.53%] [G loss: 2.993743]\n",
      "epoch:21 step:16457 [D loss: 1.310722, acc: 6.25%] [G loss: 2.173663]\n",
      "epoch:21 step:16458 [D loss: 0.689187, acc: 57.03%] [G loss: 3.066695]\n",
      "epoch:21 step:16459 [D loss: 0.384270, acc: 88.28%] [G loss: 3.408413]\n",
      "epoch:21 step:16460 [D loss: 1.137050, acc: 35.94%] [G loss: 2.644767]\n",
      "epoch:21 step:16461 [D loss: 0.703142, acc: 59.38%] [G loss: 2.186728]\n",
      "epoch:21 step:16462 [D loss: 0.256740, acc: 95.31%] [G loss: 3.730067]\n",
      "epoch:21 step:16463 [D loss: 0.276146, acc: 89.06%] [G loss: 2.820725]\n",
      "epoch:21 step:16464 [D loss: 0.132046, acc: 99.22%] [G loss: 3.152794]\n",
      "epoch:21 step:16465 [D loss: 0.918895, acc: 48.44%] [G loss: 2.446361]\n",
      "epoch:21 step:16466 [D loss: 0.646474, acc: 63.28%] [G loss: 2.778285]\n",
      "epoch:21 step:16467 [D loss: 0.500654, acc: 82.81%] [G loss: 2.396551]\n",
      "epoch:21 step:16468 [D loss: 0.959047, acc: 36.72%] [G loss: 2.845969]\n",
      "epoch:21 step:16469 [D loss: 0.597386, acc: 65.62%] [G loss: 2.866960]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16470 [D loss: 0.816367, acc: 53.12%] [G loss: 2.799836]\n",
      "epoch:21 step:16471 [D loss: 0.537850, acc: 82.03%] [G loss: 4.732423]\n",
      "epoch:21 step:16472 [D loss: 1.374136, acc: 48.44%] [G loss: 2.708049]\n",
      "epoch:21 step:16473 [D loss: 0.601760, acc: 66.41%] [G loss: 3.686800]\n",
      "epoch:21 step:16474 [D loss: 0.525838, acc: 62.50%] [G loss: 3.537683]\n",
      "epoch:21 step:16475 [D loss: 0.501134, acc: 70.31%] [G loss: 2.685168]\n",
      "epoch:21 step:16476 [D loss: 0.323013, acc: 96.09%] [G loss: 3.304704]\n",
      "epoch:21 step:16477 [D loss: 0.644383, acc: 60.94%] [G loss: 3.608817]\n",
      "epoch:21 step:16478 [D loss: 0.486252, acc: 79.69%] [G loss: 3.460998]\n",
      "epoch:21 step:16479 [D loss: 0.530317, acc: 76.56%] [G loss: 2.776716]\n",
      "epoch:21 step:16480 [D loss: 0.330692, acc: 92.97%] [G loss: 3.657802]\n",
      "epoch:21 step:16481 [D loss: 0.472411, acc: 78.12%] [G loss: 3.096087]\n",
      "epoch:21 step:16482 [D loss: 0.375738, acc: 79.69%] [G loss: 5.180220]\n",
      "epoch:21 step:16483 [D loss: 0.482062, acc: 64.84%] [G loss: 3.639309]\n",
      "epoch:21 step:16484 [D loss: 0.343231, acc: 94.53%] [G loss: 3.435476]\n",
      "epoch:21 step:16485 [D loss: 0.590086, acc: 61.72%] [G loss: 3.225429]\n",
      "epoch:21 step:16486 [D loss: 0.522903, acc: 74.22%] [G loss: 2.253662]\n",
      "epoch:21 step:16487 [D loss: 0.669843, acc: 61.72%] [G loss: 2.957504]\n",
      "epoch:21 step:16488 [D loss: 0.573859, acc: 70.31%] [G loss: 2.360840]\n",
      "epoch:21 step:16489 [D loss: 0.444263, acc: 79.69%] [G loss: 4.163585]\n",
      "epoch:21 step:16490 [D loss: 0.367670, acc: 92.19%] [G loss: 3.065760]\n",
      "epoch:21 step:16491 [D loss: 0.360319, acc: 92.19%] [G loss: 2.581748]\n",
      "epoch:21 step:16492 [D loss: 0.465522, acc: 80.47%] [G loss: 2.602168]\n",
      "epoch:21 step:16493 [D loss: 0.520822, acc: 78.12%] [G loss: 1.974210]\n",
      "epoch:21 step:16494 [D loss: 0.588550, acc: 68.75%] [G loss: 3.049820]\n",
      "epoch:21 step:16495 [D loss: 0.786430, acc: 41.41%] [G loss: 2.964376]\n",
      "epoch:21 step:16496 [D loss: 0.415556, acc: 78.91%] [G loss: 2.504046]\n",
      "epoch:21 step:16497 [D loss: 0.694015, acc: 53.91%] [G loss: 2.657312]\n",
      "epoch:21 step:16498 [D loss: 1.010756, acc: 30.47%] [G loss: 2.492071]\n",
      "epoch:21 step:16499 [D loss: 0.673014, acc: 57.03%] [G loss: 3.107388]\n",
      "epoch:21 step:16500 [D loss: 0.775461, acc: 39.06%] [G loss: 4.283869]\n",
      "epoch:21 step:16501 [D loss: 0.385820, acc: 82.03%] [G loss: 2.789279]\n",
      "epoch:21 step:16502 [D loss: 0.297982, acc: 95.31%] [G loss: 4.113432]\n",
      "epoch:21 step:16503 [D loss: 0.477310, acc: 76.56%] [G loss: 3.608805]\n",
      "epoch:21 step:16504 [D loss: 0.270558, acc: 94.53%] [G loss: 3.888230]\n",
      "epoch:21 step:16505 [D loss: 0.274987, acc: 98.44%] [G loss: 3.572888]\n",
      "epoch:21 step:16506 [D loss: 0.488238, acc: 72.66%] [G loss: 4.144428]\n",
      "epoch:21 step:16507 [D loss: 0.490335, acc: 83.59%] [G loss: 3.013904]\n",
      "epoch:21 step:16508 [D loss: 0.363611, acc: 93.75%] [G loss: 3.527254]\n",
      "epoch:21 step:16509 [D loss: 0.534005, acc: 71.09%] [G loss: 3.552336]\n",
      "epoch:21 step:16510 [D loss: 1.304560, acc: 9.38%] [G loss: 2.087043]\n",
      "epoch:21 step:16511 [D loss: 0.280265, acc: 92.19%] [G loss: 2.763627]\n",
      "epoch:21 step:16512 [D loss: 0.467326, acc: 84.38%] [G loss: 3.749075]\n",
      "epoch:21 step:16513 [D loss: 0.459193, acc: 85.94%] [G loss: 3.684997]\n",
      "epoch:21 step:16514 [D loss: 0.879581, acc: 39.84%] [G loss: 3.118075]\n",
      "epoch:21 step:16515 [D loss: 0.216721, acc: 98.44%] [G loss: 4.369500]\n",
      "epoch:21 step:16516 [D loss: 0.700464, acc: 56.25%] [G loss: 2.673214]\n",
      "epoch:21 step:16517 [D loss: 0.598292, acc: 64.06%] [G loss: 2.523225]\n",
      "epoch:21 step:16518 [D loss: 0.407630, acc: 85.16%] [G loss: 3.845886]\n",
      "epoch:21 step:16519 [D loss: 0.737645, acc: 46.09%] [G loss: 2.874007]\n",
      "epoch:21 step:16520 [D loss: 0.435371, acc: 80.47%] [G loss: 3.529999]\n",
      "epoch:21 step:16521 [D loss: 0.644276, acc: 60.94%] [G loss: 2.688121]\n",
      "epoch:21 step:16522 [D loss: 0.256960, acc: 97.66%] [G loss: 3.343989]\n",
      "epoch:21 step:16523 [D loss: 0.273922, acc: 91.41%] [G loss: 3.648783]\n",
      "epoch:21 step:16524 [D loss: 0.200629, acc: 96.88%] [G loss: 3.260398]\n",
      "epoch:21 step:16525 [D loss: 0.842964, acc: 43.75%] [G loss: 2.036102]\n",
      "epoch:21 step:16526 [D loss: 0.579364, acc: 68.75%] [G loss: 2.781250]\n",
      "epoch:21 step:16527 [D loss: 0.565646, acc: 73.44%] [G loss: 1.371366]\n",
      "epoch:21 step:16528 [D loss: 0.229020, acc: 96.88%] [G loss: 2.867774]\n",
      "epoch:21 step:16529 [D loss: 0.401921, acc: 88.28%] [G loss: 2.871987]\n",
      "epoch:21 step:16530 [D loss: 0.931584, acc: 40.62%] [G loss: 3.574945]\n",
      "epoch:21 step:16531 [D loss: 0.727120, acc: 48.44%] [G loss: 3.625088]\n",
      "epoch:21 step:16532 [D loss: 0.494462, acc: 67.19%] [G loss: 2.274241]\n",
      "epoch:21 step:16533 [D loss: 0.713439, acc: 61.72%] [G loss: 3.397712]\n",
      "epoch:21 step:16534 [D loss: 0.190761, acc: 98.44%] [G loss: 3.748280]\n",
      "epoch:21 step:16535 [D loss: 0.356814, acc: 90.62%] [G loss: 3.188747]\n",
      "epoch:21 step:16536 [D loss: 0.307905, acc: 95.31%] [G loss: 4.404224]\n",
      "epoch:21 step:16537 [D loss: 0.633665, acc: 64.84%] [G loss: 2.923120]\n",
      "epoch:21 step:16538 [D loss: 0.182311, acc: 99.22%] [G loss: 3.230083]\n",
      "epoch:21 step:16539 [D loss: 1.009156, acc: 25.78%] [G loss: 3.559000]\n",
      "epoch:21 step:16540 [D loss: 0.275944, acc: 95.31%] [G loss: 3.296710]\n",
      "epoch:21 step:16541 [D loss: 0.375089, acc: 89.84%] [G loss: 3.316848]\n",
      "epoch:21 step:16542 [D loss: 0.576469, acc: 66.41%] [G loss: 2.831613]\n",
      "epoch:21 step:16543 [D loss: 1.144785, acc: 24.22%] [G loss: 3.687403]\n",
      "epoch:21 step:16544 [D loss: 0.301328, acc: 96.09%] [G loss: 3.468222]\n",
      "epoch:21 step:16545 [D loss: 0.455275, acc: 81.25%] [G loss: 2.875861]\n",
      "epoch:21 step:16546 [D loss: 0.290204, acc: 94.53%] [G loss: 4.935349]\n",
      "epoch:21 step:16547 [D loss: 0.412478, acc: 86.72%] [G loss: 2.886713]\n",
      "epoch:21 step:16548 [D loss: 0.554187, acc: 70.31%] [G loss: 3.791440]\n",
      "epoch:21 step:16549 [D loss: 0.214414, acc: 98.44%] [G loss: 5.146912]\n",
      "epoch:21 step:16550 [D loss: 0.332029, acc: 88.28%] [G loss: 3.168331]\n",
      "epoch:21 step:16551 [D loss: 0.235468, acc: 95.31%] [G loss: 3.650933]\n",
      "epoch:21 step:16552 [D loss: 0.341270, acc: 90.62%] [G loss: 3.488854]\n",
      "epoch:21 step:16553 [D loss: 0.696484, acc: 55.47%] [G loss: 2.842395]\n",
      "epoch:21 step:16554 [D loss: 0.667852, acc: 59.38%] [G loss: 3.121955]\n",
      "epoch:21 step:16555 [D loss: 0.704515, acc: 59.38%] [G loss: 2.584628]\n",
      "epoch:21 step:16556 [D loss: 0.265141, acc: 95.31%] [G loss: 4.632489]\n",
      "epoch:21 step:16557 [D loss: 0.360970, acc: 93.75%] [G loss: 3.393422]\n",
      "epoch:21 step:16558 [D loss: 0.315911, acc: 95.31%] [G loss: 2.615566]\n",
      "epoch:21 step:16559 [D loss: 0.527252, acc: 71.88%] [G loss: 3.154773]\n",
      "epoch:21 step:16560 [D loss: 0.634177, acc: 57.81%] [G loss: 3.591675]\n",
      "epoch:21 step:16561 [D loss: 0.789276, acc: 44.53%] [G loss: 1.957972]\n",
      "epoch:21 step:16562 [D loss: 0.479340, acc: 74.22%] [G loss: 2.091752]\n",
      "epoch:21 step:16563 [D loss: 0.292893, acc: 96.88%] [G loss: 2.748928]\n",
      "epoch:21 step:16564 [D loss: 0.676225, acc: 64.06%] [G loss: 2.673854]\n",
      "epoch:21 step:16565 [D loss: 0.509177, acc: 69.53%] [G loss: 3.018733]\n",
      "epoch:21 step:16566 [D loss: 0.421339, acc: 91.41%] [G loss: 2.213944]\n",
      "epoch:21 step:16567 [D loss: 0.359057, acc: 92.97%] [G loss: 3.145635]\n",
      "epoch:21 step:16568 [D loss: 0.796064, acc: 49.22%] [G loss: 2.847866]\n",
      "epoch:21 step:16569 [D loss: 0.290262, acc: 98.44%] [G loss: 3.352426]\n",
      "epoch:21 step:16570 [D loss: 0.362232, acc: 89.84%] [G loss: 3.465868]\n",
      "epoch:21 step:16571 [D loss: 0.468239, acc: 79.69%] [G loss: 2.820062]\n",
      "epoch:21 step:16572 [D loss: 0.554625, acc: 73.44%] [G loss: 3.093621]\n",
      "epoch:21 step:16573 [D loss: 0.251224, acc: 97.66%] [G loss: 2.442062]\n",
      "epoch:21 step:16574 [D loss: 1.366428, acc: 10.16%] [G loss: 2.073642]\n",
      "epoch:21 step:16575 [D loss: 0.267491, acc: 92.19%] [G loss: 3.614995]\n",
      "epoch:21 step:16576 [D loss: 0.184325, acc: 97.66%] [G loss: 4.070378]\n",
      "epoch:21 step:16577 [D loss: 0.665316, acc: 68.75%] [G loss: 4.311032]\n",
      "epoch:21 step:16578 [D loss: 0.715075, acc: 53.91%] [G loss: 2.570923]\n",
      "epoch:21 step:16579 [D loss: 0.689818, acc: 55.47%] [G loss: 3.176233]\n",
      "epoch:21 step:16580 [D loss: 0.347424, acc: 92.97%] [G loss: 2.498938]\n",
      "epoch:21 step:16581 [D loss: 0.613107, acc: 67.97%] [G loss: 3.116340]\n",
      "epoch:21 step:16582 [D loss: 0.514034, acc: 74.22%] [G loss: 3.055305]\n",
      "epoch:21 step:16583 [D loss: 0.356043, acc: 93.75%] [G loss: 3.272263]\n",
      "epoch:21 step:16584 [D loss: 0.778248, acc: 52.34%] [G loss: 3.919409]\n",
      "epoch:21 step:16585 [D loss: 0.555792, acc: 69.53%] [G loss: 3.084969]\n",
      "epoch:21 step:16586 [D loss: 0.840451, acc: 52.34%] [G loss: 4.170000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16587 [D loss: 0.351126, acc: 86.72%] [G loss: 3.484156]\n",
      "epoch:21 step:16588 [D loss: 0.361448, acc: 85.16%] [G loss: 3.936046]\n",
      "epoch:21 step:16589 [D loss: 0.271854, acc: 96.88%] [G loss: 3.134053]\n",
      "epoch:21 step:16590 [D loss: 0.077377, acc: 100.00%] [G loss: 6.869989]\n",
      "epoch:21 step:16591 [D loss: 0.878819, acc: 34.38%] [G loss: 4.097492]\n",
      "epoch:21 step:16592 [D loss: 0.490424, acc: 73.44%] [G loss: 4.823474]\n",
      "epoch:21 step:16593 [D loss: 0.504782, acc: 74.22%] [G loss: 3.533358]\n",
      "epoch:21 step:16594 [D loss: 0.410822, acc: 86.72%] [G loss: 2.945153]\n",
      "epoch:21 step:16595 [D loss: 0.503974, acc: 76.56%] [G loss: 3.321157]\n",
      "epoch:21 step:16596 [D loss: 0.291040, acc: 95.31%] [G loss: 3.586738]\n",
      "epoch:21 step:16597 [D loss: 0.866940, acc: 41.41%] [G loss: 3.306317]\n",
      "epoch:21 step:16598 [D loss: 0.366505, acc: 94.53%] [G loss: 5.270166]\n",
      "epoch:21 step:16599 [D loss: 0.319281, acc: 98.44%] [G loss: 2.977351]\n",
      "epoch:21 step:16600 [D loss: 0.843348, acc: 42.19%] [G loss: 2.695992]\n",
      "epoch:21 step:16601 [D loss: 0.415252, acc: 77.34%] [G loss: 2.949657]\n",
      "epoch:21 step:16602 [D loss: 0.729377, acc: 53.12%] [G loss: 3.670232]\n",
      "epoch:21 step:16603 [D loss: 0.749786, acc: 57.81%] [G loss: 4.486964]\n",
      "epoch:21 step:16604 [D loss: 0.450113, acc: 85.94%] [G loss: 4.472276]\n",
      "epoch:21 step:16605 [D loss: 0.237010, acc: 98.44%] [G loss: 2.763103]\n",
      "epoch:21 step:16606 [D loss: 0.690943, acc: 57.03%] [G loss: 3.320578]\n",
      "epoch:21 step:16607 [D loss: 0.520612, acc: 67.19%] [G loss: 2.730580]\n",
      "epoch:21 step:16608 [D loss: 0.459029, acc: 75.00%] [G loss: 3.128207]\n",
      "epoch:21 step:16609 [D loss: 0.589392, acc: 59.38%] [G loss: 2.886130]\n",
      "epoch:21 step:16610 [D loss: 0.418567, acc: 77.34%] [G loss: 4.260969]\n",
      "epoch:21 step:16611 [D loss: 0.279444, acc: 93.75%] [G loss: 2.188171]\n",
      "epoch:21 step:16612 [D loss: 0.457750, acc: 85.16%] [G loss: 3.728852]\n",
      "epoch:21 step:16613 [D loss: 0.690631, acc: 62.50%] [G loss: 2.622544]\n",
      "epoch:21 step:16614 [D loss: 0.469731, acc: 71.88%] [G loss: 4.473179]\n",
      "epoch:21 step:16615 [D loss: 0.373496, acc: 89.06%] [G loss: 3.976050]\n",
      "epoch:21 step:16616 [D loss: 0.314779, acc: 95.31%] [G loss: 2.750631]\n",
      "epoch:21 step:16617 [D loss: 0.315235, acc: 92.19%] [G loss: 3.827053]\n",
      "epoch:21 step:16618 [D loss: 0.646959, acc: 53.91%] [G loss: 4.137527]\n",
      "epoch:21 step:16619 [D loss: 0.588023, acc: 70.31%] [G loss: 3.344001]\n",
      "epoch:21 step:16620 [D loss: 0.383572, acc: 78.12%] [G loss: 2.383945]\n",
      "epoch:21 step:16621 [D loss: 0.419002, acc: 75.00%] [G loss: 3.878779]\n",
      "epoch:21 step:16622 [D loss: 1.244040, acc: 27.34%] [G loss: 2.633142]\n",
      "epoch:21 step:16623 [D loss: 0.513222, acc: 82.03%] [G loss: 4.701735]\n",
      "epoch:21 step:16624 [D loss: 0.519140, acc: 72.66%] [G loss: 2.396483]\n",
      "epoch:21 step:16625 [D loss: 0.641483, acc: 57.81%] [G loss: 3.729264]\n",
      "epoch:21 step:16626 [D loss: 0.206913, acc: 98.44%] [G loss: 3.889119]\n",
      "epoch:21 step:16627 [D loss: 0.466294, acc: 67.19%] [G loss: 2.391739]\n",
      "epoch:21 step:16628 [D loss: 0.750075, acc: 52.34%] [G loss: 4.246598]\n",
      "epoch:21 step:16629 [D loss: 0.201422, acc: 97.66%] [G loss: 3.785148]\n",
      "epoch:21 step:16630 [D loss: 0.545432, acc: 60.16%] [G loss: 3.524848]\n",
      "epoch:21 step:16631 [D loss: 0.546719, acc: 75.00%] [G loss: 3.319806]\n",
      "epoch:21 step:16632 [D loss: 0.355517, acc: 88.28%] [G loss: 2.669769]\n",
      "epoch:21 step:16633 [D loss: 0.855718, acc: 35.94%] [G loss: 3.585209]\n",
      "epoch:21 step:16634 [D loss: 0.392665, acc: 83.59%] [G loss: 4.014459]\n",
      "epoch:21 step:16635 [D loss: 0.606303, acc: 64.06%] [G loss: 3.656104]\n",
      "epoch:21 step:16636 [D loss: 0.653279, acc: 61.72%] [G loss: 3.604840]\n",
      "epoch:21 step:16637 [D loss: 0.388732, acc: 94.53%] [G loss: 3.029272]\n",
      "epoch:21 step:16638 [D loss: 0.830727, acc: 43.75%] [G loss: 3.279491]\n",
      "epoch:21 step:16639 [D loss: 0.206196, acc: 99.22%] [G loss: 3.580702]\n",
      "epoch:21 step:16640 [D loss: 0.514041, acc: 78.91%] [G loss: 3.907034]\n",
      "epoch:21 step:16641 [D loss: 0.681671, acc: 60.94%] [G loss: 2.816022]\n",
      "epoch:21 step:16642 [D loss: 0.225535, acc: 98.44%] [G loss: 3.119074]\n",
      "epoch:21 step:16643 [D loss: 0.404856, acc: 77.34%] [G loss: 4.218345]\n",
      "epoch:21 step:16644 [D loss: 0.478383, acc: 74.22%] [G loss: 3.394450]\n",
      "epoch:21 step:16645 [D loss: 0.209620, acc: 99.22%] [G loss: 3.106914]\n",
      "epoch:21 step:16646 [D loss: 1.208054, acc: 11.72%] [G loss: 3.738319]\n",
      "epoch:21 step:16647 [D loss: 0.527726, acc: 74.22%] [G loss: 2.801017]\n",
      "epoch:21 step:16648 [D loss: 0.422582, acc: 87.50%] [G loss: 3.503060]\n",
      "epoch:21 step:16649 [D loss: 0.703843, acc: 54.69%] [G loss: 3.827976]\n",
      "epoch:21 step:16650 [D loss: 0.126795, acc: 100.00%] [G loss: 4.278492]\n",
      "epoch:21 step:16651 [D loss: 0.346645, acc: 89.84%] [G loss: 4.521435]\n",
      "epoch:21 step:16652 [D loss: 0.221832, acc: 97.66%] [G loss: 3.232465]\n",
      "epoch:21 step:16653 [D loss: 0.155136, acc: 98.44%] [G loss: 3.913843]\n",
      "epoch:21 step:16654 [D loss: 0.708748, acc: 54.69%] [G loss: 3.209909]\n",
      "epoch:21 step:16655 [D loss: 0.315584, acc: 92.97%] [G loss: 2.647535]\n",
      "epoch:21 step:16656 [D loss: 0.390965, acc: 91.41%] [G loss: 2.642924]\n",
      "epoch:21 step:16657 [D loss: 0.416209, acc: 92.19%] [G loss: 4.853265]\n",
      "epoch:21 step:16658 [D loss: 1.604084, acc: 3.91%] [G loss: 3.228402]\n",
      "epoch:21 step:16659 [D loss: 0.685293, acc: 61.72%] [G loss: 2.922194]\n",
      "epoch:21 step:16660 [D loss: 0.188773, acc: 97.66%] [G loss: 3.134230]\n",
      "epoch:21 step:16661 [D loss: 0.215372, acc: 96.88%] [G loss: 2.658237]\n",
      "epoch:21 step:16662 [D loss: 0.427952, acc: 71.09%] [G loss: 3.034142]\n",
      "epoch:21 step:16663 [D loss: 0.246874, acc: 95.31%] [G loss: 3.977328]\n",
      "epoch:21 step:16664 [D loss: 0.503536, acc: 67.19%] [G loss: 3.049224]\n",
      "epoch:21 step:16665 [D loss: 0.282970, acc: 96.09%] [G loss: 2.650244]\n",
      "epoch:21 step:16666 [D loss: 0.246642, acc: 95.31%] [G loss: 3.177436]\n",
      "epoch:21 step:16667 [D loss: 0.333200, acc: 93.75%] [G loss: 2.915349]\n",
      "epoch:21 step:16668 [D loss: 1.531431, acc: 6.25%] [G loss: 1.904961]\n",
      "epoch:21 step:16669 [D loss: 1.495659, acc: 46.88%] [G loss: 2.250864]\n",
      "epoch:21 step:16670 [D loss: 0.658651, acc: 60.94%] [G loss: 2.634514]\n",
      "epoch:21 step:16671 [D loss: 0.397352, acc: 91.41%] [G loss: 3.550381]\n",
      "epoch:21 step:16672 [D loss: 0.394193, acc: 78.91%] [G loss: 3.965715]\n",
      "epoch:21 step:16673 [D loss: 1.228051, acc: 50.00%] [G loss: 2.727296]\n",
      "epoch:21 step:16674 [D loss: 0.452282, acc: 82.81%] [G loss: 3.664867]\n",
      "epoch:21 step:16675 [D loss: 0.829236, acc: 46.09%] [G loss: 3.681580]\n",
      "epoch:21 step:16676 [D loss: 0.659929, acc: 55.47%] [G loss: 2.642293]\n",
      "epoch:21 step:16677 [D loss: 0.463070, acc: 71.88%] [G loss: 3.686500]\n",
      "epoch:21 step:16678 [D loss: 0.637896, acc: 62.50%] [G loss: 2.851012]\n",
      "epoch:21 step:16679 [D loss: 0.419332, acc: 75.78%] [G loss: 4.712976]\n",
      "epoch:21 step:16680 [D loss: 0.741888, acc: 57.03%] [G loss: 3.112209]\n",
      "epoch:21 step:16681 [D loss: 0.627271, acc: 66.41%] [G loss: 3.673573]\n",
      "epoch:21 step:16682 [D loss: 0.407237, acc: 90.62%] [G loss: 4.060471]\n",
      "epoch:21 step:16683 [D loss: 0.372887, acc: 82.03%] [G loss: 2.459278]\n",
      "epoch:21 step:16684 [D loss: 0.774845, acc: 50.00%] [G loss: 2.498707]\n",
      "epoch:21 step:16685 [D loss: 0.370470, acc: 89.84%] [G loss: 3.405717]\n",
      "epoch:21 step:16686 [D loss: 0.220507, acc: 95.31%] [G loss: 3.603487]\n",
      "epoch:21 step:16687 [D loss: 0.424909, acc: 87.50%] [G loss: 4.234239]\n",
      "epoch:21 step:16688 [D loss: 0.511832, acc: 66.41%] [G loss: 2.819592]\n",
      "epoch:21 step:16689 [D loss: 0.821902, acc: 44.53%] [G loss: 3.140733]\n",
      "epoch:21 step:16690 [D loss: 0.394230, acc: 88.28%] [G loss: 3.464424]\n",
      "epoch:21 step:16691 [D loss: 0.318146, acc: 94.53%] [G loss: 3.379375]\n",
      "epoch:21 step:16692 [D loss: 0.476067, acc: 75.78%] [G loss: 3.194840]\n",
      "epoch:21 step:16693 [D loss: 0.423102, acc: 82.81%] [G loss: 2.224303]\n",
      "epoch:21 step:16694 [D loss: 0.234864, acc: 100.00%] [G loss: 3.625922]\n",
      "epoch:21 step:16695 [D loss: 0.587790, acc: 68.75%] [G loss: 3.666234]\n",
      "epoch:21 step:16696 [D loss: 0.190419, acc: 97.66%] [G loss: 4.187621]\n",
      "epoch:21 step:16697 [D loss: 0.607400, acc: 65.62%] [G loss: 3.803726]\n",
      "epoch:21 step:16698 [D loss: 0.901147, acc: 34.38%] [G loss: 3.059956]\n",
      "epoch:21 step:16699 [D loss: 0.307359, acc: 95.31%] [G loss: 2.931183]\n",
      "epoch:21 step:16700 [D loss: 0.245817, acc: 94.53%] [G loss: 3.436669]\n",
      "epoch:21 step:16701 [D loss: 0.400307, acc: 89.84%] [G loss: 3.194304]\n",
      "epoch:21 step:16702 [D loss: 0.680707, acc: 56.25%] [G loss: 4.282061]\n",
      "epoch:21 step:16703 [D loss: 0.394628, acc: 86.72%] [G loss: 3.771571]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16704 [D loss: 0.693070, acc: 60.16%] [G loss: 2.586298]\n",
      "epoch:21 step:16705 [D loss: 0.997909, acc: 20.31%] [G loss: 2.928796]\n",
      "epoch:21 step:16706 [D loss: 0.370720, acc: 91.41%] [G loss: 3.973636]\n",
      "epoch:21 step:16707 [D loss: 0.727916, acc: 58.59%] [G loss: 2.585603]\n",
      "epoch:21 step:16708 [D loss: 0.095116, acc: 100.00%] [G loss: 4.223271]\n",
      "epoch:21 step:16709 [D loss: 0.421475, acc: 84.38%] [G loss: 2.706870]\n",
      "epoch:21 step:16710 [D loss: 0.493300, acc: 78.12%] [G loss: 2.590652]\n",
      "epoch:21 step:16711 [D loss: 0.320362, acc: 90.62%] [G loss: 3.473298]\n",
      "epoch:21 step:16712 [D loss: 0.314005, acc: 95.31%] [G loss: 2.780352]\n",
      "epoch:21 step:16713 [D loss: 0.512510, acc: 75.00%] [G loss: 2.717983]\n",
      "epoch:21 step:16714 [D loss: 0.553799, acc: 71.09%] [G loss: 3.511426]\n",
      "epoch:21 step:16715 [D loss: 0.241799, acc: 99.22%] [G loss: 4.180556]\n",
      "epoch:21 step:16716 [D loss: 0.559215, acc: 64.06%] [G loss: 4.194968]\n",
      "epoch:21 step:16717 [D loss: 0.461788, acc: 74.22%] [G loss: 3.287017]\n",
      "epoch:21 step:16718 [D loss: 0.294317, acc: 92.97%] [G loss: 3.531759]\n",
      "epoch:21 step:16719 [D loss: 0.510359, acc: 73.44%] [G loss: 3.544404]\n",
      "epoch:21 step:16720 [D loss: 0.631446, acc: 63.28%] [G loss: 3.360144]\n",
      "epoch:21 step:16721 [D loss: 0.336868, acc: 91.41%] [G loss: 3.199250]\n",
      "epoch:21 step:16722 [D loss: 0.392605, acc: 89.06%] [G loss: 2.529060]\n",
      "epoch:21 step:16723 [D loss: 0.454570, acc: 82.81%] [G loss: 3.422137]\n",
      "epoch:21 step:16724 [D loss: 0.247814, acc: 95.31%] [G loss: 3.494238]\n",
      "epoch:21 step:16725 [D loss: 0.608538, acc: 71.88%] [G loss: 3.118720]\n",
      "epoch:21 step:16726 [D loss: 0.502666, acc: 72.66%] [G loss: 3.137664]\n",
      "epoch:21 step:16727 [D loss: 0.405924, acc: 77.34%] [G loss: 2.810778]\n",
      "epoch:21 step:16728 [D loss: 0.297037, acc: 92.19%] [G loss: 2.580507]\n",
      "epoch:21 step:16729 [D loss: 0.329718, acc: 96.09%] [G loss: 3.843317]\n",
      "epoch:21 step:16730 [D loss: 0.516120, acc: 76.56%] [G loss: 3.204688]\n",
      "epoch:21 step:16731 [D loss: 0.389127, acc: 91.41%] [G loss: 5.548557]\n",
      "epoch:21 step:16732 [D loss: 0.260589, acc: 93.75%] [G loss: 2.866553]\n",
      "epoch:21 step:16733 [D loss: 0.387817, acc: 88.28%] [G loss: 3.576556]\n",
      "epoch:21 step:16734 [D loss: 0.165491, acc: 98.44%] [G loss: 5.060962]\n",
      "epoch:21 step:16735 [D loss: 0.498418, acc: 75.78%] [G loss: 3.453181]\n",
      "epoch:21 step:16736 [D loss: 0.051511, acc: 100.00%] [G loss: 3.213017]\n",
      "epoch:21 step:16737 [D loss: 1.112935, acc: 18.75%] [G loss: 4.616817]\n",
      "epoch:21 step:16738 [D loss: 0.175446, acc: 97.66%] [G loss: 2.456608]\n",
      "epoch:21 step:16739 [D loss: 0.313638, acc: 87.50%] [G loss: 2.892324]\n",
      "epoch:21 step:16740 [D loss: 0.554172, acc: 64.84%] [G loss: 2.594551]\n",
      "epoch:21 step:16741 [D loss: 0.784026, acc: 46.88%] [G loss: 2.380595]\n",
      "epoch:21 step:16742 [D loss: 0.098541, acc: 100.00%] [G loss: 4.392129]\n",
      "epoch:21 step:16743 [D loss: 0.482046, acc: 79.69%] [G loss: 2.276176]\n",
      "epoch:21 step:16744 [D loss: 0.654315, acc: 57.81%] [G loss: 3.982237]\n",
      "epoch:21 step:16745 [D loss: 0.370966, acc: 92.19%] [G loss: 2.751189]\n",
      "epoch:21 step:16746 [D loss: 0.564065, acc: 67.19%] [G loss: 3.084138]\n",
      "epoch:21 step:16747 [D loss: 0.669335, acc: 58.59%] [G loss: 2.739918]\n",
      "epoch:21 step:16748 [D loss: 0.458429, acc: 88.28%] [G loss: 2.699503]\n",
      "epoch:21 step:16749 [D loss: 1.091432, acc: 45.31%] [G loss: 3.753253]\n",
      "epoch:21 step:16750 [D loss: 0.569687, acc: 66.41%] [G loss: 3.059346]\n",
      "epoch:21 step:16751 [D loss: 0.289881, acc: 94.53%] [G loss: 2.871217]\n",
      "epoch:21 step:16752 [D loss: 0.720511, acc: 58.59%] [G loss: 2.080439]\n",
      "epoch:21 step:16753 [D loss: 0.137766, acc: 100.00%] [G loss: 3.186219]\n",
      "epoch:21 step:16754 [D loss: 0.598173, acc: 64.06%] [G loss: 3.653884]\n",
      "epoch:21 step:16755 [D loss: 0.834767, acc: 44.53%] [G loss: 2.854977]\n",
      "epoch:21 step:16756 [D loss: 0.716104, acc: 47.66%] [G loss: 2.468624]\n",
      "epoch:21 step:16757 [D loss: 0.415281, acc: 78.12%] [G loss: 2.485004]\n",
      "epoch:21 step:16758 [D loss: 0.510005, acc: 75.00%] [G loss: 3.575160]\n",
      "epoch:21 step:16759 [D loss: 0.460802, acc: 82.03%] [G loss: 3.484979]\n",
      "epoch:21 step:16760 [D loss: 0.587459, acc: 70.31%] [G loss: 4.007482]\n",
      "epoch:21 step:16761 [D loss: 0.470603, acc: 77.34%] [G loss: 2.764596]\n",
      "epoch:21 step:16762 [D loss: 0.416850, acc: 78.12%] [G loss: 4.854241]\n",
      "epoch:21 step:16763 [D loss: 0.623029, acc: 58.59%] [G loss: 1.928254]\n",
      "epoch:21 step:16764 [D loss: 0.169245, acc: 100.00%] [G loss: 2.988897]\n",
      "epoch:21 step:16765 [D loss: 0.201317, acc: 99.22%] [G loss: 5.362191]\n",
      "epoch:21 step:16766 [D loss: 0.631483, acc: 64.06%] [G loss: 3.130146]\n",
      "epoch:21 step:16767 [D loss: 0.365041, acc: 82.81%] [G loss: 3.235524]\n",
      "epoch:21 step:16768 [D loss: 0.652313, acc: 59.38%] [G loss: 2.441874]\n",
      "epoch:21 step:16769 [D loss: 0.483559, acc: 79.69%] [G loss: 2.837276]\n",
      "epoch:21 step:16770 [D loss: 0.585866, acc: 68.75%] [G loss: 3.177411]\n",
      "epoch:21 step:16771 [D loss: 0.223339, acc: 92.97%] [G loss: 3.319993]\n",
      "epoch:21 step:16772 [D loss: 0.246636, acc: 96.88%] [G loss: 3.412395]\n",
      "epoch:21 step:16773 [D loss: 0.363991, acc: 91.41%] [G loss: 2.909626]\n",
      "epoch:21 step:16774 [D loss: 2.416648, acc: 2.34%] [G loss: 3.205024]\n",
      "epoch:21 step:16775 [D loss: 0.790933, acc: 53.12%] [G loss: 3.116424]\n",
      "epoch:21 step:16776 [D loss: 0.501497, acc: 75.78%] [G loss: 3.556267]\n",
      "epoch:21 step:16777 [D loss: 0.816992, acc: 50.78%] [G loss: 3.374432]\n",
      "epoch:21 step:16778 [D loss: 0.611021, acc: 63.28%] [G loss: 2.550223]\n",
      "epoch:21 step:16779 [D loss: 0.614565, acc: 64.84%] [G loss: 4.606286]\n",
      "epoch:21 step:16780 [D loss: 0.346539, acc: 90.62%] [G loss: 3.598942]\n",
      "epoch:21 step:16781 [D loss: 0.352436, acc: 92.97%] [G loss: 2.492134]\n",
      "epoch:21 step:16782 [D loss: 0.442032, acc: 87.50%] [G loss: 3.704716]\n",
      "epoch:21 step:16783 [D loss: 0.488568, acc: 75.78%] [G loss: 3.215000]\n",
      "epoch:21 step:16784 [D loss: 0.604691, acc: 67.19%] [G loss: 4.127056]\n",
      "epoch:21 step:16785 [D loss: 0.306274, acc: 93.75%] [G loss: 3.026321]\n",
      "epoch:21 step:16786 [D loss: 0.208988, acc: 96.88%] [G loss: 4.518952]\n",
      "epoch:21 step:16787 [D loss: 0.679471, acc: 57.03%] [G loss: 3.226775]\n",
      "epoch:21 step:16788 [D loss: 0.626185, acc: 66.41%] [G loss: 2.813332]\n",
      "epoch:21 step:16789 [D loss: 0.444050, acc: 77.34%] [G loss: 2.678495]\n",
      "epoch:21 step:16790 [D loss: 0.845822, acc: 43.75%] [G loss: 2.427082]\n",
      "epoch:21 step:16791 [D loss: 0.523942, acc: 75.00%] [G loss: 3.623527]\n",
      "epoch:21 step:16792 [D loss: 0.506828, acc: 68.75%] [G loss: 2.648736]\n",
      "epoch:21 step:16793 [D loss: 0.247495, acc: 97.66%] [G loss: 6.329496]\n",
      "epoch:21 step:16794 [D loss: 0.322676, acc: 92.97%] [G loss: 4.129541]\n",
      "epoch:21 step:16795 [D loss: 0.325536, acc: 91.41%] [G loss: 3.814131]\n",
      "epoch:21 step:16796 [D loss: 0.413568, acc: 86.72%] [G loss: 2.506232]\n",
      "epoch:21 step:16797 [D loss: 0.397084, acc: 92.97%] [G loss: 3.444743]\n",
      "epoch:21 step:16798 [D loss: 0.783536, acc: 50.78%] [G loss: 2.629204]\n",
      "epoch:21 step:16799 [D loss: 0.308407, acc: 96.09%] [G loss: 2.782580]\n",
      "epoch:21 step:16800 [D loss: 0.676096, acc: 57.03%] [G loss: 3.947356]\n",
      "epoch:21 step:16801 [D loss: 0.117611, acc: 100.00%] [G loss: 3.566368]\n",
      "epoch:21 step:16802 [D loss: 0.106770, acc: 100.00%] [G loss: 4.091765]\n",
      "epoch:21 step:16803 [D loss: 0.558082, acc: 73.44%] [G loss: 3.261324]\n",
      "epoch:21 step:16804 [D loss: 1.043569, acc: 21.88%] [G loss: 3.094289]\n",
      "epoch:21 step:16805 [D loss: 0.230095, acc: 97.66%] [G loss: 3.234607]\n",
      "epoch:21 step:16806 [D loss: 0.363134, acc: 92.19%] [G loss: 2.708335]\n",
      "epoch:21 step:16807 [D loss: 0.331495, acc: 92.97%] [G loss: 3.548715]\n",
      "epoch:21 step:16808 [D loss: 0.403073, acc: 85.16%] [G loss: 2.636170]\n",
      "epoch:21 step:16809 [D loss: 1.377119, acc: 50.00%] [G loss: 2.990726]\n",
      "epoch:21 step:16810 [D loss: 0.365979, acc: 80.47%] [G loss: 2.888469]\n",
      "epoch:21 step:16811 [D loss: 0.568926, acc: 69.53%] [G loss: 4.156269]\n",
      "epoch:21 step:16812 [D loss: 0.549738, acc: 75.00%] [G loss: 3.717994]\n",
      "epoch:21 step:16813 [D loss: 0.659768, acc: 62.50%] [G loss: 3.586405]\n",
      "epoch:21 step:16814 [D loss: 0.517440, acc: 75.78%] [G loss: 3.009896]\n",
      "epoch:21 step:16815 [D loss: 0.788628, acc: 49.22%] [G loss: 2.444160]\n",
      "epoch:21 step:16816 [D loss: 0.542643, acc: 67.97%] [G loss: 3.516453]\n",
      "epoch:21 step:16817 [D loss: 0.412518, acc: 85.94%] [G loss: 3.941847]\n",
      "epoch:21 step:16818 [D loss: 0.548667, acc: 65.62%] [G loss: 3.859755]\n",
      "epoch:21 step:16819 [D loss: 0.444250, acc: 89.84%] [G loss: 3.677996]\n",
      "epoch:21 step:16820 [D loss: 0.868150, acc: 48.44%] [G loss: 3.247795]\n",
      "epoch:21 step:16821 [D loss: 1.052265, acc: 21.09%] [G loss: 2.946425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16822 [D loss: 0.350572, acc: 90.62%] [G loss: 3.480848]\n",
      "epoch:21 step:16823 [D loss: 0.347405, acc: 92.19%] [G loss: 3.315938]\n",
      "epoch:21 step:16824 [D loss: 0.608355, acc: 69.53%] [G loss: 3.209053]\n",
      "epoch:21 step:16825 [D loss: 0.198439, acc: 96.88%] [G loss: 5.143282]\n",
      "epoch:21 step:16826 [D loss: 0.362199, acc: 91.41%] [G loss: 4.164561]\n",
      "epoch:21 step:16827 [D loss: 0.346370, acc: 91.41%] [G loss: 4.366257]\n",
      "epoch:21 step:16828 [D loss: 0.202894, acc: 97.66%] [G loss: 3.592796]\n",
      "epoch:21 step:16829 [D loss: 0.621667, acc: 64.06%] [G loss: 3.750862]\n",
      "epoch:21 step:16830 [D loss: 0.352260, acc: 84.38%] [G loss: 2.806369]\n",
      "epoch:21 step:16831 [D loss: 0.249446, acc: 89.84%] [G loss: 2.721680]\n",
      "epoch:21 step:16832 [D loss: 0.363503, acc: 90.62%] [G loss: 4.958902]\n",
      "epoch:21 step:16833 [D loss: 0.194996, acc: 98.44%] [G loss: 2.878471]\n",
      "epoch:21 step:16834 [D loss: 0.197380, acc: 96.88%] [G loss: 4.170126]\n",
      "epoch:21 step:16835 [D loss: 0.173912, acc: 99.22%] [G loss: 5.093033]\n",
      "epoch:21 step:16836 [D loss: 0.211958, acc: 97.66%] [G loss: 2.914278]\n",
      "epoch:21 step:16837 [D loss: 0.397692, acc: 89.06%] [G loss: 2.538206]\n",
      "epoch:21 step:16838 [D loss: 0.823056, acc: 43.75%] [G loss: 3.177094]\n",
      "epoch:21 step:16839 [D loss: 0.727208, acc: 54.69%] [G loss: 3.120908]\n",
      "epoch:21 step:16840 [D loss: 0.199607, acc: 96.88%] [G loss: 5.627416]\n",
      "epoch:21 step:16841 [D loss: 0.857886, acc: 46.09%] [G loss: 4.320916]\n",
      "epoch:21 step:16842 [D loss: 0.779537, acc: 50.78%] [G loss: 3.200702]\n",
      "epoch:21 step:16843 [D loss: 0.417415, acc: 88.28%] [G loss: 4.043771]\n",
      "epoch:21 step:16844 [D loss: 0.543190, acc: 71.09%] [G loss: 3.739786]\n",
      "epoch:21 step:16845 [D loss: 0.758211, acc: 53.91%] [G loss: 3.140826]\n",
      "epoch:21 step:16846 [D loss: 0.721507, acc: 50.00%] [G loss: 3.434347]\n",
      "epoch:21 step:16847 [D loss: 0.267969, acc: 95.31%] [G loss: 3.868032]\n",
      "epoch:21 step:16848 [D loss: 0.409038, acc: 82.03%] [G loss: 3.498338]\n",
      "epoch:21 step:16849 [D loss: 0.677782, acc: 57.03%] [G loss: 3.596566]\n",
      "epoch:21 step:16850 [D loss: 0.436594, acc: 85.16%] [G loss: 3.387647]\n",
      "epoch:21 step:16851 [D loss: 0.229592, acc: 98.44%] [G loss: 4.111572]\n",
      "epoch:21 step:16852 [D loss: 0.056737, acc: 100.00%] [G loss: 4.455366]\n",
      "epoch:21 step:16853 [D loss: 0.494158, acc: 77.34%] [G loss: 4.917933]\n",
      "epoch:21 step:16854 [D loss: 0.392371, acc: 87.50%] [G loss: 5.667975]\n",
      "epoch:21 step:16855 [D loss: 0.410626, acc: 86.72%] [G loss: 4.529491]\n",
      "epoch:21 step:16856 [D loss: 0.780514, acc: 52.34%] [G loss: 2.330695]\n",
      "epoch:21 step:16857 [D loss: 1.046705, acc: 31.25%] [G loss: 3.664698]\n",
      "epoch:21 step:16858 [D loss: 0.235993, acc: 97.66%] [G loss: 3.715205]\n",
      "epoch:21 step:16859 [D loss: 0.327595, acc: 82.81%] [G loss: 3.627157]\n",
      "epoch:21 step:16860 [D loss: 0.410149, acc: 82.81%] [G loss: 3.681332]\n",
      "epoch:21 step:16861 [D loss: 0.225503, acc: 97.66%] [G loss: 3.602108]\n",
      "epoch:21 step:16862 [D loss: 0.210941, acc: 96.88%] [G loss: 4.798270]\n",
      "epoch:21 step:16863 [D loss: 0.033507, acc: 100.00%] [G loss: 3.865600]\n",
      "epoch:21 step:16864 [D loss: 0.581666, acc: 69.53%] [G loss: 4.272839]\n",
      "epoch:21 step:16865 [D loss: 0.491078, acc: 82.03%] [G loss: 4.047039]\n",
      "epoch:21 step:16866 [D loss: 0.405313, acc: 85.16%] [G loss: 3.718292]\n",
      "epoch:21 step:16867 [D loss: 0.049357, acc: 100.00%] [G loss: 3.698404]\n",
      "epoch:21 step:16868 [D loss: 0.351509, acc: 90.62%] [G loss: 3.716074]\n",
      "epoch:21 step:16869 [D loss: 0.360642, acc: 89.84%] [G loss: 3.636074]\n",
      "epoch:21 step:16870 [D loss: 0.529289, acc: 73.44%] [G loss: 3.502696]\n",
      "epoch:21 step:16871 [D loss: 0.136580, acc: 100.00%] [G loss: 2.675697]\n",
      "epoch:21 step:16872 [D loss: 0.516696, acc: 76.56%] [G loss: 2.529056]\n",
      "epoch:21 step:16873 [D loss: 1.208911, acc: 15.62%] [G loss: 2.743336]\n",
      "epoch:21 step:16874 [D loss: 0.863598, acc: 39.84%] [G loss: 2.694654]\n",
      "epoch:21 step:16875 [D loss: 0.436360, acc: 70.31%] [G loss: 4.535113]\n",
      "epoch:21 step:16876 [D loss: 0.239340, acc: 97.66%] [G loss: 2.867704]\n",
      "epoch:21 step:16877 [D loss: 0.863708, acc: 45.31%] [G loss: 4.048019]\n",
      "epoch:21 step:16878 [D loss: 0.189766, acc: 99.22%] [G loss: 3.116644]\n",
      "epoch:21 step:16879 [D loss: 0.251067, acc: 96.88%] [G loss: 3.638669]\n",
      "epoch:21 step:16880 [D loss: 0.341441, acc: 83.59%] [G loss: 4.647315]\n",
      "epoch:21 step:16881 [D loss: 0.484461, acc: 77.34%] [G loss: 3.146401]\n",
      "epoch:21 step:16882 [D loss: 0.463784, acc: 83.59%] [G loss: 3.478827]\n",
      "epoch:21 step:16883 [D loss: 0.386606, acc: 89.84%] [G loss: 2.989428]\n",
      "epoch:21 step:16884 [D loss: 0.383820, acc: 78.12%] [G loss: 3.979669]\n",
      "epoch:21 step:16885 [D loss: 0.241939, acc: 95.31%] [G loss: 4.073012]\n",
      "epoch:21 step:16886 [D loss: 0.900751, acc: 51.56%] [G loss: 2.211910]\n",
      "epoch:21 step:16887 [D loss: 0.346121, acc: 90.62%] [G loss: 4.781435]\n",
      "epoch:21 step:16888 [D loss: 0.615824, acc: 64.06%] [G loss: 3.816017]\n",
      "epoch:21 step:16889 [D loss: 0.374070, acc: 88.28%] [G loss: 2.722003]\n",
      "epoch:21 step:16890 [D loss: 0.435256, acc: 79.69%] [G loss: 4.695086]\n",
      "epoch:21 step:16891 [D loss: 0.219747, acc: 98.44%] [G loss: 4.222632]\n",
      "epoch:21 step:16892 [D loss: 0.890856, acc: 51.56%] [G loss: 3.685170]\n",
      "epoch:21 step:16893 [D loss: 0.341233, acc: 82.03%] [G loss: 2.172623]\n",
      "epoch:21 step:16894 [D loss: 0.227687, acc: 98.44%] [G loss: 3.699338]\n",
      "epoch:21 step:16895 [D loss: 0.418268, acc: 90.62%] [G loss: 2.912389]\n",
      "epoch:21 step:16896 [D loss: 0.242618, acc: 95.31%] [G loss: 2.181933]\n",
      "epoch:21 step:16897 [D loss: 0.311266, acc: 94.53%] [G loss: 3.956278]\n",
      "epoch:21 step:16898 [D loss: 0.058135, acc: 100.00%] [G loss: 4.313011]\n",
      "epoch:21 step:16899 [D loss: 0.601176, acc: 67.19%] [G loss: 4.080040]\n",
      "epoch:21 step:16900 [D loss: 0.437062, acc: 86.72%] [G loss: 3.954292]\n",
      "epoch:21 step:16901 [D loss: 0.977226, acc: 28.91%] [G loss: 2.885657]\n",
      "epoch:21 step:16902 [D loss: 0.664638, acc: 61.72%] [G loss: 3.164270]\n",
      "epoch:21 step:16903 [D loss: 0.295515, acc: 90.62%] [G loss: 2.810173]\n",
      "epoch:21 step:16904 [D loss: 0.718931, acc: 48.44%] [G loss: 3.089221]\n",
      "epoch:21 step:16905 [D loss: 0.567705, acc: 71.88%] [G loss: 3.113336]\n",
      "epoch:21 step:16906 [D loss: 0.233143, acc: 95.31%] [G loss: 4.320129]\n",
      "epoch:21 step:16907 [D loss: 0.291053, acc: 91.41%] [G loss: 3.626061]\n",
      "epoch:21 step:16908 [D loss: 1.026375, acc: 41.41%] [G loss: 2.735240]\n",
      "epoch:21 step:16909 [D loss: 0.401483, acc: 89.06%] [G loss: 3.014772]\n",
      "epoch:21 step:16910 [D loss: 0.293410, acc: 92.19%] [G loss: 2.411231]\n",
      "epoch:21 step:16911 [D loss: 0.491945, acc: 71.88%] [G loss: 5.649759]\n",
      "epoch:21 step:16912 [D loss: 0.200397, acc: 97.66%] [G loss: 4.688334]\n",
      "epoch:21 step:16913 [D loss: 0.761802, acc: 55.47%] [G loss: 5.322702]\n",
      "epoch:21 step:16914 [D loss: 0.958693, acc: 31.25%] [G loss: 3.760251]\n",
      "epoch:21 step:16915 [D loss: 0.305972, acc: 91.41%] [G loss: 3.149646]\n",
      "epoch:21 step:16916 [D loss: 0.703671, acc: 61.72%] [G loss: 3.997776]\n",
      "epoch:21 step:16917 [D loss: 0.452138, acc: 84.38%] [G loss: 3.347751]\n",
      "epoch:21 step:16918 [D loss: 0.206181, acc: 95.31%] [G loss: 3.974607]\n",
      "epoch:21 step:16919 [D loss: 0.569480, acc: 68.75%] [G loss: 3.971377]\n",
      "epoch:21 step:16920 [D loss: 0.419385, acc: 71.09%] [G loss: 3.598395]\n",
      "epoch:21 step:16921 [D loss: 0.860533, acc: 51.56%] [G loss: 2.304773]\n",
      "epoch:21 step:16922 [D loss: 0.506853, acc: 68.75%] [G loss: 3.989614]\n",
      "epoch:21 step:16923 [D loss: 0.927866, acc: 51.56%] [G loss: 4.003898]\n",
      "epoch:21 step:16924 [D loss: 0.728054, acc: 50.78%] [G loss: 3.283114]\n",
      "epoch:21 step:16925 [D loss: 0.393653, acc: 90.62%] [G loss: 2.637330]\n",
      "epoch:21 step:16926 [D loss: 0.250413, acc: 97.66%] [G loss: 3.265786]\n",
      "epoch:21 step:16927 [D loss: 0.931820, acc: 49.22%] [G loss: 2.556903]\n",
      "epoch:21 step:16928 [D loss: 0.642952, acc: 58.59%] [G loss: 3.478867]\n",
      "epoch:21 step:16929 [D loss: 0.481863, acc: 72.66%] [G loss: 3.467691]\n",
      "epoch:21 step:16930 [D loss: 0.545710, acc: 66.41%] [G loss: 3.761796]\n",
      "epoch:21 step:16931 [D loss: 0.646440, acc: 63.28%] [G loss: 4.519177]\n",
      "epoch:21 step:16932 [D loss: 0.259838, acc: 96.88%] [G loss: 3.637949]\n",
      "epoch:21 step:16933 [D loss: 0.574899, acc: 67.97%] [G loss: 3.759240]\n",
      "epoch:21 step:16934 [D loss: 0.325747, acc: 93.75%] [G loss: 3.916724]\n",
      "epoch:21 step:16935 [D loss: 0.341215, acc: 93.75%] [G loss: 3.727206]\n",
      "epoch:21 step:16936 [D loss: 0.357561, acc: 92.97%] [G loss: 3.016349]\n",
      "epoch:21 step:16937 [D loss: 0.137014, acc: 99.22%] [G loss: 4.359859]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16938 [D loss: 0.226290, acc: 98.44%] [G loss: 3.995740]\n",
      "epoch:21 step:16939 [D loss: 0.383627, acc: 85.16%] [G loss: 4.433948]\n",
      "epoch:21 step:16940 [D loss: 0.702132, acc: 59.38%] [G loss: 3.439149]\n",
      "epoch:21 step:16941 [D loss: 0.569821, acc: 63.28%] [G loss: 3.617396]\n",
      "epoch:21 step:16942 [D loss: 0.112086, acc: 100.00%] [G loss: 3.763304]\n",
      "epoch:21 step:16943 [D loss: 0.545293, acc: 67.19%] [G loss: 3.007119]\n",
      "epoch:21 step:16944 [D loss: 0.408880, acc: 85.94%] [G loss: 2.361879]\n",
      "epoch:21 step:16945 [D loss: 0.897252, acc: 36.72%] [G loss: 2.852956]\n",
      "epoch:21 step:16946 [D loss: 0.457893, acc: 83.59%] [G loss: 3.225490]\n",
      "epoch:21 step:16947 [D loss: 0.308425, acc: 92.97%] [G loss: 4.339433]\n",
      "epoch:21 step:16948 [D loss: 0.243021, acc: 94.53%] [G loss: 2.648301]\n",
      "epoch:21 step:16949 [D loss: 0.638885, acc: 65.62%] [G loss: 3.303417]\n",
      "epoch:21 step:16950 [D loss: 0.761870, acc: 53.91%] [G loss: 2.980469]\n",
      "epoch:21 step:16951 [D loss: 0.162126, acc: 99.22%] [G loss: 3.961878]\n",
      "epoch:21 step:16952 [D loss: 0.186503, acc: 99.22%] [G loss: 3.327175]\n",
      "epoch:21 step:16953 [D loss: 0.272871, acc: 96.88%] [G loss: 3.872239]\n",
      "epoch:21 step:16954 [D loss: 0.781700, acc: 50.78%] [G loss: 2.720562]\n",
      "epoch:21 step:16955 [D loss: 0.424758, acc: 77.34%] [G loss: 3.956426]\n",
      "epoch:21 step:16956 [D loss: 0.268035, acc: 97.66%] [G loss: 2.692887]\n",
      "epoch:21 step:16957 [D loss: 0.555146, acc: 71.88%] [G loss: 3.227992]\n",
      "epoch:21 step:16958 [D loss: 0.905887, acc: 39.06%] [G loss: 2.989865]\n",
      "epoch:21 step:16959 [D loss: 0.428278, acc: 78.12%] [G loss: 4.707304]\n",
      "epoch:21 step:16960 [D loss: 0.179306, acc: 98.44%] [G loss: 3.056249]\n",
      "epoch:21 step:16961 [D loss: 0.479903, acc: 78.91%] [G loss: 3.166472]\n",
      "epoch:21 step:16962 [D loss: 0.811970, acc: 49.22%] [G loss: 3.690103]\n",
      "epoch:21 step:16963 [D loss: 0.440281, acc: 82.03%] [G loss: 2.460500]\n",
      "epoch:21 step:16964 [D loss: 1.063906, acc: 42.19%] [G loss: 4.172855]\n",
      "epoch:21 step:16965 [D loss: 0.201273, acc: 99.22%] [G loss: 3.735003]\n",
      "epoch:21 step:16966 [D loss: 0.411898, acc: 71.09%] [G loss: 4.741507]\n",
      "epoch:21 step:16967 [D loss: 0.474381, acc: 68.75%] [G loss: 4.581954]\n",
      "epoch:21 step:16968 [D loss: 0.856621, acc: 46.09%] [G loss: 3.675227]\n",
      "epoch:21 step:16969 [D loss: 0.465019, acc: 75.00%] [G loss: 3.403166]\n",
      "epoch:21 step:16970 [D loss: 0.047348, acc: 100.00%] [G loss: 5.788720]\n",
      "epoch:21 step:16971 [D loss: 0.594816, acc: 67.97%] [G loss: 2.977610]\n",
      "epoch:21 step:16972 [D loss: 0.852475, acc: 43.75%] [G loss: 2.798688]\n",
      "epoch:21 step:16973 [D loss: 0.390296, acc: 88.28%] [G loss: 3.169108]\n",
      "epoch:21 step:16974 [D loss: 0.769523, acc: 56.25%] [G loss: 3.333721]\n",
      "epoch:21 step:16975 [D loss: 0.381318, acc: 81.25%] [G loss: 3.928589]\n",
      "epoch:21 step:16976 [D loss: 0.456498, acc: 71.09%] [G loss: 3.105597]\n",
      "epoch:21 step:16977 [D loss: 0.517712, acc: 67.19%] [G loss: 2.377586]\n",
      "epoch:21 step:16978 [D loss: 0.992062, acc: 31.25%] [G loss: 2.230217]\n",
      "epoch:21 step:16979 [D loss: 0.847970, acc: 42.97%] [G loss: 2.855711]\n",
      "epoch:21 step:16980 [D loss: 0.396301, acc: 82.03%] [G loss: 3.148502]\n",
      "epoch:21 step:16981 [D loss: 0.386975, acc: 88.28%] [G loss: 2.587896]\n",
      "epoch:21 step:16982 [D loss: 0.456393, acc: 66.41%] [G loss: 3.274555]\n",
      "epoch:21 step:16983 [D loss: 1.196973, acc: 24.22%] [G loss: 2.790916]\n",
      "epoch:21 step:16984 [D loss: 0.476484, acc: 75.78%] [G loss: 3.260113]\n",
      "epoch:21 step:16985 [D loss: 0.556239, acc: 66.41%] [G loss: 3.491060]\n",
      "epoch:21 step:16986 [D loss: 0.437355, acc: 71.88%] [G loss: 3.688634]\n",
      "epoch:21 step:16987 [D loss: 0.497046, acc: 76.56%] [G loss: 3.332185]\n",
      "epoch:21 step:16988 [D loss: 0.454182, acc: 81.25%] [G loss: 3.832726]\n",
      "epoch:21 step:16989 [D loss: 0.514076, acc: 73.44%] [G loss: 3.263598]\n",
      "epoch:21 step:16990 [D loss: 1.612978, acc: 3.91%] [G loss: 2.609097]\n",
      "epoch:21 step:16991 [D loss: 0.691467, acc: 59.38%] [G loss: 2.858664]\n",
      "epoch:21 step:16992 [D loss: 0.660514, acc: 58.59%] [G loss: 3.071213]\n",
      "epoch:21 step:16993 [D loss: 0.728052, acc: 55.47%] [G loss: 3.446314]\n",
      "epoch:21 step:16994 [D loss: 0.795213, acc: 53.12%] [G loss: 3.586661]\n",
      "epoch:21 step:16995 [D loss: 0.193786, acc: 96.88%] [G loss: 2.181871]\n",
      "epoch:21 step:16996 [D loss: 0.597468, acc: 67.97%] [G loss: 3.726406]\n",
      "epoch:21 step:16997 [D loss: 0.305976, acc: 89.06%] [G loss: 3.451120]\n",
      "epoch:21 step:16998 [D loss: 0.403975, acc: 86.72%] [G loss: 3.803570]\n",
      "epoch:21 step:16999 [D loss: 0.675926, acc: 58.59%] [G loss: 4.864988]\n",
      "epoch:21 step:17000 [D loss: 1.074807, acc: 42.97%] [G loss: 3.005973]\n",
      "epoch:21 step:17001 [D loss: 0.279709, acc: 94.53%] [G loss: 2.943009]\n",
      "epoch:21 step:17002 [D loss: 0.533434, acc: 74.22%] [G loss: 3.752269]\n",
      "epoch:21 step:17003 [D loss: 0.491376, acc: 81.25%] [G loss: 3.459963]\n",
      "epoch:21 step:17004 [D loss: 0.966779, acc: 24.22%] [G loss: 3.104046]\n",
      "epoch:21 step:17005 [D loss: 0.586260, acc: 71.09%] [G loss: 2.819873]\n",
      "epoch:21 step:17006 [D loss: 0.545721, acc: 75.00%] [G loss: 2.391857]\n",
      "epoch:21 step:17007 [D loss: 0.559765, acc: 72.66%] [G loss: 2.963689]\n",
      "epoch:21 step:17008 [D loss: 0.606235, acc: 67.97%] [G loss: 2.089447]\n",
      "epoch:21 step:17009 [D loss: 0.584588, acc: 66.41%] [G loss: 3.407043]\n",
      "epoch:21 step:17010 [D loss: 0.497089, acc: 82.03%] [G loss: 2.976140]\n",
      "epoch:21 step:17011 [D loss: 0.398573, acc: 90.62%] [G loss: 3.010663]\n",
      "epoch:21 step:17012 [D loss: 0.729887, acc: 53.12%] [G loss: 2.842111]\n",
      "epoch:21 step:17013 [D loss: 0.903048, acc: 35.16%] [G loss: 2.801908]\n",
      "epoch:21 step:17014 [D loss: 0.574073, acc: 71.88%] [G loss: 3.079873]\n",
      "epoch:21 step:17015 [D loss: 0.330254, acc: 94.53%] [G loss: 4.493062]\n",
      "epoch:21 step:17016 [D loss: 0.345456, acc: 92.97%] [G loss: 2.776803]\n",
      "epoch:21 step:17017 [D loss: 1.596493, acc: 3.91%] [G loss: 2.835226]\n",
      "epoch:21 step:17018 [D loss: 0.405769, acc: 90.62%] [G loss: 4.187827]\n",
      "epoch:21 step:17019 [D loss: 0.491846, acc: 79.69%] [G loss: 3.557911]\n",
      "epoch:21 step:17020 [D loss: 0.181376, acc: 99.22%] [G loss: 3.817795]\n",
      "epoch:21 step:17021 [D loss: 0.842312, acc: 52.34%] [G loss: 3.063687]\n",
      "epoch:21 step:17022 [D loss: 0.225835, acc: 97.66%] [G loss: 4.556000]\n",
      "epoch:21 step:17023 [D loss: 0.659209, acc: 57.81%] [G loss: 1.976230]\n",
      "epoch:21 step:17024 [D loss: 0.741183, acc: 51.56%] [G loss: 3.091345]\n",
      "epoch:21 step:17025 [D loss: 0.559342, acc: 71.09%] [G loss: 4.296736]\n",
      "epoch:21 step:17026 [D loss: 0.639660, acc: 64.84%] [G loss: 3.045796]\n",
      "epoch:21 step:17027 [D loss: 0.486855, acc: 83.59%] [G loss: 4.155358]\n",
      "epoch:21 step:17028 [D loss: 0.458823, acc: 72.66%] [G loss: 3.442316]\n",
      "epoch:21 step:17029 [D loss: 0.978515, acc: 35.16%] [G loss: 4.635880]\n",
      "epoch:21 step:17030 [D loss: 0.438074, acc: 83.59%] [G loss: 3.352928]\n",
      "epoch:21 step:17031 [D loss: 0.419451, acc: 85.94%] [G loss: 3.474620]\n",
      "epoch:21 step:17032 [D loss: 0.340337, acc: 92.97%] [G loss: 3.189801]\n",
      "epoch:21 step:17033 [D loss: 0.925518, acc: 30.47%] [G loss: 2.907416]\n",
      "epoch:21 step:17034 [D loss: 0.320028, acc: 93.75%] [G loss: 4.486207]\n",
      "epoch:21 step:17035 [D loss: 0.556647, acc: 67.97%] [G loss: 2.742695]\n",
      "epoch:21 step:17036 [D loss: 0.468740, acc: 80.47%] [G loss: 2.786109]\n",
      "epoch:21 step:17037 [D loss: 0.930784, acc: 53.12%] [G loss: 2.020892]\n",
      "epoch:21 step:17038 [D loss: 0.383473, acc: 89.84%] [G loss: 2.908218]\n",
      "epoch:21 step:17039 [D loss: 1.282040, acc: 44.53%] [G loss: 2.558041]\n",
      "epoch:21 step:17040 [D loss: 0.934810, acc: 39.06%] [G loss: 1.625719]\n",
      "epoch:21 step:17041 [D loss: 0.419984, acc: 89.06%] [G loss: 3.419153]\n",
      "epoch:21 step:17042 [D loss: 0.266267, acc: 95.31%] [G loss: 3.630522]\n",
      "epoch:21 step:17043 [D loss: 0.880275, acc: 38.28%] [G loss: 2.759541]\n",
      "epoch:21 step:17044 [D loss: 0.440524, acc: 82.81%] [G loss: 3.211675]\n",
      "epoch:21 step:17045 [D loss: 0.250871, acc: 96.09%] [G loss: 3.385177]\n",
      "epoch:21 step:17046 [D loss: 0.430414, acc: 86.72%] [G loss: 3.426170]\n",
      "epoch:21 step:17047 [D loss: 0.889186, acc: 37.50%] [G loss: 2.344393]\n",
      "epoch:21 step:17048 [D loss: 0.274069, acc: 96.88%] [G loss: 3.679715]\n",
      "epoch:21 step:17049 [D loss: 0.265246, acc: 98.44%] [G loss: 2.876290]\n",
      "epoch:21 step:17050 [D loss: 0.207998, acc: 94.53%] [G loss: 3.199068]\n",
      "epoch:21 step:17051 [D loss: 0.111807, acc: 100.00%] [G loss: 2.814676]\n",
      "epoch:21 step:17052 [D loss: 0.262127, acc: 94.53%] [G loss: 3.027329]\n",
      "epoch:21 step:17053 [D loss: 0.742607, acc: 55.47%] [G loss: 3.499811]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:17054 [D loss: 0.509506, acc: 78.12%] [G loss: 3.239152]\n",
      "epoch:21 step:17055 [D loss: 0.576452, acc: 61.72%] [G loss: 3.841443]\n",
      "epoch:21 step:17056 [D loss: 0.150783, acc: 99.22%] [G loss: 3.550006]\n",
      "epoch:21 step:17057 [D loss: 1.125596, acc: 23.44%] [G loss: 2.679965]\n",
      "epoch:21 step:17058 [D loss: 0.628535, acc: 56.25%] [G loss: 3.685404]\n",
      "epoch:21 step:17059 [D loss: 0.800309, acc: 44.53%] [G loss: 3.536904]\n",
      "epoch:21 step:17060 [D loss: 0.357126, acc: 89.84%] [G loss: 3.916915]\n",
      "epoch:21 step:17061 [D loss: 0.433366, acc: 79.69%] [G loss: 5.586010]\n",
      "epoch:21 step:17062 [D loss: 0.482620, acc: 83.59%] [G loss: 3.146143]\n",
      "epoch:21 step:17063 [D loss: 0.657249, acc: 53.91%] [G loss: 3.983306]\n",
      "epoch:21 step:17064 [D loss: 0.405329, acc: 72.66%] [G loss: 3.238228]\n",
      "epoch:21 step:17065 [D loss: 0.203516, acc: 98.44%] [G loss: 3.740669]\n",
      "epoch:21 step:17066 [D loss: 1.194668, acc: 32.03%] [G loss: 3.617529]\n",
      "epoch:21 step:17067 [D loss: 0.351949, acc: 92.19%] [G loss: 4.052467]\n",
      "epoch:21 step:17068 [D loss: 0.201633, acc: 99.22%] [G loss: 5.017547]\n",
      "epoch:21 step:17069 [D loss: 0.440137, acc: 83.59%] [G loss: 3.985827]\n",
      "epoch:21 step:17070 [D loss: 0.417983, acc: 90.62%] [G loss: 3.012272]\n",
      "epoch:21 step:17071 [D loss: 0.363692, acc: 94.53%] [G loss: 4.033543]\n",
      "epoch:21 step:17072 [D loss: 0.221080, acc: 100.00%] [G loss: 3.359199]\n",
      "epoch:21 step:17073 [D loss: 0.442627, acc: 86.72%] [G loss: 3.802251]\n",
      "epoch:21 step:17074 [D loss: 0.409632, acc: 74.22%] [G loss: 2.607284]\n",
      "epoch:21 step:17075 [D loss: 0.291670, acc: 92.19%] [G loss: 3.539629]\n",
      "epoch:21 step:17076 [D loss: 0.760000, acc: 54.69%] [G loss: 3.962063]\n",
      "epoch:21 step:17077 [D loss: 0.414146, acc: 87.50%] [G loss: 3.101350]\n",
      "epoch:21 step:17078 [D loss: 0.275024, acc: 96.88%] [G loss: 3.784818]\n",
      "epoch:21 step:17079 [D loss: 0.333026, acc: 87.50%] [G loss: 4.058535]\n",
      "epoch:21 step:17080 [D loss: 0.454627, acc: 79.69%] [G loss: 3.941318]\n",
      "epoch:21 step:17081 [D loss: 0.208976, acc: 97.66%] [G loss: 2.982481]\n",
      "epoch:21 step:17082 [D loss: 0.188677, acc: 99.22%] [G loss: 2.962831]\n",
      "epoch:21 step:17083 [D loss: 0.679024, acc: 59.38%] [G loss: 3.304721]\n",
      "epoch:21 step:17084 [D loss: 0.309997, acc: 92.97%] [G loss: 3.433445]\n",
      "epoch:21 step:17085 [D loss: 0.483949, acc: 82.03%] [G loss: 3.888330]\n",
      "epoch:21 step:17086 [D loss: 0.404752, acc: 83.59%] [G loss: 3.202024]\n",
      "epoch:21 step:17087 [D loss: 0.809686, acc: 51.56%] [G loss: 2.482779]\n",
      "epoch:21 step:17088 [D loss: 0.748042, acc: 50.00%] [G loss: 4.739660]\n",
      "epoch:21 step:17089 [D loss: 0.788940, acc: 44.53%] [G loss: 3.179269]\n",
      "epoch:21 step:17090 [D loss: 1.335734, acc: 12.50%] [G loss: 3.681629]\n",
      "epoch:21 step:17091 [D loss: 0.251461, acc: 99.22%] [G loss: 3.652656]\n",
      "epoch:21 step:17092 [D loss: 0.443393, acc: 70.31%] [G loss: 4.037314]\n",
      "epoch:21 step:17093 [D loss: 0.433716, acc: 81.25%] [G loss: 3.456612]\n",
      "epoch:21 step:17094 [D loss: 0.513713, acc: 73.44%] [G loss: 4.071830]\n",
      "epoch:21 step:17095 [D loss: 0.522764, acc: 80.47%] [G loss: 3.281649]\n",
      "epoch:21 step:17096 [D loss: 0.395898, acc: 91.41%] [G loss: 2.971996]\n",
      "epoch:21 step:17097 [D loss: 0.600315, acc: 70.31%] [G loss: 3.709692]\n",
      "epoch:21 step:17098 [D loss: 1.151264, acc: 29.69%] [G loss: 3.879241]\n",
      "epoch:21 step:17099 [D loss: 0.319933, acc: 94.53%] [G loss: 3.183389]\n",
      "epoch:21 step:17100 [D loss: 1.013180, acc: 25.78%] [G loss: 2.135317]\n",
      "epoch:21 step:17101 [D loss: 0.825897, acc: 50.00%] [G loss: 1.763994]\n",
      "epoch:21 step:17102 [D loss: 0.539933, acc: 72.66%] [G loss: 2.988586]\n",
      "epoch:21 step:17103 [D loss: 0.424269, acc: 85.94%] [G loss: 2.498444]\n",
      "epoch:21 step:17104 [D loss: 0.700356, acc: 53.12%] [G loss: 2.850629]\n",
      "epoch:21 step:17105 [D loss: 0.460702, acc: 83.59%] [G loss: 4.750359]\n",
      "epoch:21 step:17106 [D loss: 0.484852, acc: 77.34%] [G loss: 3.884123]\n",
      "epoch:21 step:17107 [D loss: 0.613098, acc: 60.94%] [G loss: 2.752224]\n",
      "epoch:21 step:17108 [D loss: 0.741295, acc: 51.56%] [G loss: 2.533984]\n",
      "epoch:21 step:17109 [D loss: 0.418684, acc: 77.34%] [G loss: 3.072248]\n",
      "epoch:21 step:17110 [D loss: 0.299053, acc: 96.88%] [G loss: 3.176853]\n",
      "epoch:21 step:17111 [D loss: 0.780169, acc: 50.00%] [G loss: 3.060478]\n",
      "epoch:21 step:17112 [D loss: 0.127761, acc: 100.00%] [G loss: 3.226244]\n",
      "epoch:21 step:17113 [D loss: 0.653007, acc: 61.72%] [G loss: 2.640263]\n",
      "epoch:21 step:17114 [D loss: 0.486069, acc: 68.75%] [G loss: 3.522531]\n",
      "epoch:21 step:17115 [D loss: 0.579775, acc: 70.31%] [G loss: 3.829832]\n",
      "epoch:21 step:17116 [D loss: 0.572653, acc: 64.84%] [G loss: 1.776833]\n",
      "epoch:21 step:17117 [D loss: 0.196583, acc: 99.22%] [G loss: 4.182716]\n",
      "epoch:21 step:17118 [D loss: 0.363146, acc: 90.62%] [G loss: 3.809998]\n",
      "epoch:21 step:17119 [D loss: 0.735339, acc: 47.66%] [G loss: 2.852778]\n",
      "epoch:21 step:17120 [D loss: 0.402145, acc: 75.78%] [G loss: 5.180314]\n",
      "epoch:21 step:17121 [D loss: 0.637137, acc: 60.94%] [G loss: 3.482115]\n",
      "epoch:21 step:17122 [D loss: 0.534299, acc: 60.16%] [G loss: 2.560778]\n",
      "epoch:21 step:17123 [D loss: 0.660865, acc: 60.16%] [G loss: 2.532297]\n",
      "epoch:21 step:17124 [D loss: 0.131489, acc: 99.22%] [G loss: 5.063129]\n",
      "epoch:21 step:17125 [D loss: 0.730677, acc: 52.34%] [G loss: 4.270903]\n",
      "epoch:21 step:17126 [D loss: 0.502172, acc: 77.34%] [G loss: 2.927443]\n",
      "epoch:21 step:17127 [D loss: 0.212127, acc: 99.22%] [G loss: 4.532799]\n",
      "epoch:21 step:17128 [D loss: 0.437912, acc: 88.28%] [G loss: 3.198869]\n",
      "epoch:21 step:17129 [D loss: 0.806799, acc: 50.78%] [G loss: 3.643690]\n",
      "epoch:21 step:17130 [D loss: 0.279649, acc: 89.84%] [G loss: 3.808874]\n",
      "epoch:21 step:17131 [D loss: 0.515953, acc: 77.34%] [G loss: 2.244028]\n",
      "epoch:21 step:17132 [D loss: 0.770468, acc: 49.22%] [G loss: 1.930735]\n",
      "epoch:21 step:17133 [D loss: 0.299003, acc: 86.72%] [G loss: 3.522223]\n",
      "epoch:21 step:17134 [D loss: 0.718321, acc: 51.56%] [G loss: 3.250922]\n",
      "epoch:21 step:17135 [D loss: 0.571658, acc: 67.19%] [G loss: 3.360233]\n",
      "epoch:21 step:17136 [D loss: 0.733646, acc: 54.69%] [G loss: 2.966481]\n",
      "epoch:21 step:17137 [D loss: 0.628725, acc: 67.19%] [G loss: 3.083267]\n",
      "epoch:21 step:17138 [D loss: 0.303585, acc: 90.62%] [G loss: 4.129552]\n",
      "epoch:21 step:17139 [D loss: 0.579552, acc: 66.41%] [G loss: 4.662010]\n",
      "epoch:21 step:17140 [D loss: 0.539065, acc: 64.84%] [G loss: 4.020062]\n",
      "epoch:21 step:17141 [D loss: 0.223207, acc: 97.66%] [G loss: 3.960027]\n",
      "epoch:21 step:17142 [D loss: 0.196160, acc: 97.66%] [G loss: 3.208918]\n",
      "epoch:21 step:17143 [D loss: 0.723729, acc: 56.25%] [G loss: 3.443320]\n",
      "epoch:21 step:17144 [D loss: 0.529054, acc: 68.75%] [G loss: 2.498581]\n",
      "epoch:21 step:17145 [D loss: 0.595729, acc: 67.97%] [G loss: 2.044842]\n",
      "epoch:21 step:17146 [D loss: 0.183851, acc: 98.44%] [G loss: 2.634029]\n",
      "epoch:21 step:17147 [D loss: 0.408964, acc: 91.41%] [G loss: 3.150059]\n",
      "epoch:21 step:17148 [D loss: 0.484495, acc: 78.91%] [G loss: 2.795328]\n",
      "epoch:21 step:17149 [D loss: 0.146367, acc: 98.44%] [G loss: 3.841068]\n",
      "epoch:21 step:17150 [D loss: 0.619189, acc: 60.16%] [G loss: 3.095901]\n",
      "epoch:21 step:17151 [D loss: 0.429372, acc: 78.12%] [G loss: 2.809453]\n",
      "epoch:21 step:17152 [D loss: 0.591679, acc: 66.41%] [G loss: 3.301087]\n",
      "epoch:21 step:17153 [D loss: 0.239288, acc: 96.09%] [G loss: 2.730618]\n",
      "epoch:21 step:17154 [D loss: 0.442944, acc: 82.81%] [G loss: 3.645132]\n",
      "epoch:21 step:17155 [D loss: 0.322727, acc: 92.19%] [G loss: 5.526555]\n",
      "epoch:21 step:17156 [D loss: 0.338355, acc: 82.81%] [G loss: 2.819769]\n",
      "epoch:21 step:17157 [D loss: 0.735884, acc: 49.22%] [G loss: 4.228905]\n",
      "epoch:21 step:17158 [D loss: 0.689417, acc: 60.16%] [G loss: 3.250472]\n",
      "epoch:21 step:17159 [D loss: 0.327465, acc: 85.94%] [G loss: 3.373377]\n",
      "epoch:21 step:17160 [D loss: 0.651654, acc: 61.72%] [G loss: 4.121109]\n",
      "epoch:21 step:17161 [D loss: 0.065784, acc: 100.00%] [G loss: 5.447516]\n",
      "epoch:21 step:17162 [D loss: 0.648016, acc: 59.38%] [G loss: 3.557200]\n",
      "epoch:21 step:17163 [D loss: 0.589908, acc: 71.09%] [G loss: 3.121614]\n",
      "epoch:21 step:17164 [D loss: 0.377649, acc: 87.50%] [G loss: 5.042859]\n",
      "epoch:21 step:17165 [D loss: 0.183637, acc: 100.00%] [G loss: 2.981097]\n",
      "epoch:21 step:17166 [D loss: 0.738281, acc: 54.69%] [G loss: 2.327431]\n",
      "epoch:21 step:17167 [D loss: 0.222539, acc: 99.22%] [G loss: 3.232222]\n",
      "epoch:21 step:17168 [D loss: 0.280314, acc: 96.88%] [G loss: 3.307112]\n",
      "epoch:21 step:17169 [D loss: 0.615516, acc: 67.19%] [G loss: 2.882371]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:17170 [D loss: 0.427317, acc: 82.81%] [G loss: 2.533196]\n",
      "epoch:21 step:17171 [D loss: 0.169160, acc: 97.66%] [G loss: 3.281153]\n",
      "epoch:21 step:17172 [D loss: 0.382544, acc: 75.00%] [G loss: 2.723284]\n",
      "epoch:21 step:17173 [D loss: 0.861728, acc: 50.00%] [G loss: 3.907113]\n",
      "epoch:21 step:17174 [D loss: 0.055399, acc: 100.00%] [G loss: 4.064729]\n",
      "epoch:21 step:17175 [D loss: 0.543596, acc: 71.88%] [G loss: 4.315676]\n",
      "epoch:21 step:17176 [D loss: 0.536334, acc: 68.75%] [G loss: 5.000628]\n",
      "epoch:21 step:17177 [D loss: 0.324831, acc: 96.88%] [G loss: 2.657114]\n",
      "epoch:21 step:17178 [D loss: 1.383601, acc: 20.31%] [G loss: 3.650273]\n",
      "epoch:21 step:17179 [D loss: 0.409449, acc: 84.38%] [G loss: 2.705452]\n",
      "epoch:21 step:17180 [D loss: 0.979198, acc: 53.12%] [G loss: 2.954454]\n",
      "epoch:21 step:17181 [D loss: 0.268679, acc: 96.88%] [G loss: 4.824592]\n",
      "epoch:21 step:17182 [D loss: 0.918286, acc: 51.56%] [G loss: 2.883008]\n",
      "epoch:22 step:17183 [D loss: 0.201204, acc: 97.66%] [G loss: 3.819765]\n",
      "epoch:22 step:17184 [D loss: 0.497341, acc: 78.12%] [G loss: 3.067741]\n",
      "epoch:22 step:17185 [D loss: 0.367074, acc: 85.94%] [G loss: 3.817530]\n",
      "epoch:22 step:17186 [D loss: 0.529860, acc: 75.78%] [G loss: 3.476545]\n",
      "epoch:22 step:17187 [D loss: 0.282331, acc: 96.09%] [G loss: 3.421975]\n",
      "epoch:22 step:17188 [D loss: 0.708018, acc: 53.91%] [G loss: 3.715295]\n",
      "epoch:22 step:17189 [D loss: 0.443229, acc: 82.03%] [G loss: 3.811364]\n",
      "epoch:22 step:17190 [D loss: 0.582720, acc: 64.06%] [G loss: 4.276990]\n",
      "epoch:22 step:17191 [D loss: 0.299743, acc: 93.75%] [G loss: 3.710428]\n",
      "epoch:22 step:17192 [D loss: 0.455868, acc: 80.47%] [G loss: 4.396711]\n",
      "epoch:22 step:17193 [D loss: 0.400138, acc: 89.84%] [G loss: 2.725625]\n",
      "epoch:22 step:17194 [D loss: 0.542704, acc: 67.19%] [G loss: 2.797585]\n",
      "epoch:22 step:17195 [D loss: 0.660568, acc: 56.25%] [G loss: 3.800164]\n",
      "epoch:22 step:17196 [D loss: 0.360498, acc: 82.03%] [G loss: 4.208161]\n",
      "epoch:22 step:17197 [D loss: 0.921182, acc: 32.81%] [G loss: 2.789206]\n",
      "epoch:22 step:17198 [D loss: 0.881182, acc: 37.50%] [G loss: 2.754670]\n",
      "epoch:22 step:17199 [D loss: 0.227140, acc: 100.00%] [G loss: 3.184947]\n",
      "epoch:22 step:17200 [D loss: 0.394534, acc: 87.50%] [G loss: 4.874502]\n",
      "epoch:22 step:17201 [D loss: 0.303282, acc: 97.66%] [G loss: 3.967261]\n",
      "epoch:22 step:17202 [D loss: 0.553187, acc: 73.44%] [G loss: 3.850885]\n",
      "epoch:22 step:17203 [D loss: 0.136399, acc: 99.22%] [G loss: 3.469487]\n",
      "epoch:22 step:17204 [D loss: 0.294196, acc: 95.31%] [G loss: 3.128794]\n",
      "epoch:22 step:17205 [D loss: 0.451147, acc: 87.50%] [G loss: 3.634502]\n",
      "epoch:22 step:17206 [D loss: 0.357240, acc: 84.38%] [G loss: 4.093318]\n",
      "epoch:22 step:17207 [D loss: 0.348913, acc: 91.41%] [G loss: 3.454655]\n",
      "epoch:22 step:17208 [D loss: 0.531354, acc: 75.00%] [G loss: 3.409708]\n",
      "epoch:22 step:17209 [D loss: 0.405427, acc: 89.06%] [G loss: 3.127831]\n",
      "epoch:22 step:17210 [D loss: 0.968827, acc: 35.16%] [G loss: 5.180099]\n",
      "epoch:22 step:17211 [D loss: 0.463874, acc: 73.44%] [G loss: 2.774290]\n",
      "epoch:22 step:17212 [D loss: 0.098007, acc: 100.00%] [G loss: 5.064049]\n",
      "epoch:22 step:17213 [D loss: 0.789143, acc: 54.69%] [G loss: 2.936660]\n",
      "epoch:22 step:17214 [D loss: 0.276744, acc: 92.97%] [G loss: 4.348619]\n",
      "epoch:22 step:17215 [D loss: 0.533513, acc: 78.12%] [G loss: 3.984958]\n",
      "epoch:22 step:17216 [D loss: 0.314276, acc: 89.06%] [G loss: 4.249726]\n",
      "epoch:22 step:17217 [D loss: 0.339880, acc: 78.91%] [G loss: 3.994109]\n",
      "epoch:22 step:17218 [D loss: 0.207400, acc: 94.53%] [G loss: 3.612332]\n",
      "epoch:22 step:17219 [D loss: 0.572273, acc: 64.06%] [G loss: 2.629571]\n",
      "epoch:22 step:17220 [D loss: 0.590375, acc: 67.19%] [G loss: 3.209569]\n",
      "epoch:22 step:17221 [D loss: 0.319526, acc: 95.31%] [G loss: 4.617213]\n",
      "epoch:22 step:17222 [D loss: 0.618589, acc: 60.16%] [G loss: 3.260698]\n",
      "epoch:22 step:17223 [D loss: 0.585846, acc: 65.62%] [G loss: 4.075898]\n",
      "epoch:22 step:17224 [D loss: 0.715539, acc: 53.91%] [G loss: 3.561253]\n",
      "epoch:22 step:17225 [D loss: 0.143269, acc: 100.00%] [G loss: 3.325816]\n",
      "epoch:22 step:17226 [D loss: 0.435264, acc: 79.69%] [G loss: 3.452978]\n",
      "epoch:22 step:17227 [D loss: 0.279409, acc: 92.97%] [G loss: 3.453664]\n",
      "epoch:22 step:17228 [D loss: 0.208004, acc: 93.75%] [G loss: 5.552670]\n",
      "epoch:22 step:17229 [D loss: 0.717752, acc: 56.25%] [G loss: 3.027502]\n",
      "epoch:22 step:17230 [D loss: 0.411983, acc: 90.62%] [G loss: 2.450882]\n",
      "epoch:22 step:17231 [D loss: 0.200744, acc: 99.22%] [G loss: 2.705580]\n",
      "epoch:22 step:17232 [D loss: 0.664502, acc: 63.28%] [G loss: 2.236911]\n",
      "epoch:22 step:17233 [D loss: 0.377423, acc: 89.06%] [G loss: 3.562099]\n",
      "epoch:22 step:17234 [D loss: 0.396955, acc: 85.16%] [G loss: 2.523629]\n",
      "epoch:22 step:17235 [D loss: 1.466553, acc: 9.38%] [G loss: 2.876907]\n",
      "epoch:22 step:17236 [D loss: 0.964625, acc: 36.72%] [G loss: 2.673414]\n",
      "epoch:22 step:17237 [D loss: 0.281816, acc: 96.09%] [G loss: 2.917469]\n",
      "epoch:22 step:17238 [D loss: 0.901000, acc: 37.50%] [G loss: 2.032006]\n",
      "epoch:22 step:17239 [D loss: 0.318600, acc: 82.81%] [G loss: 2.804794]\n",
      "epoch:22 step:17240 [D loss: 0.265176, acc: 94.53%] [G loss: 2.966846]\n",
      "epoch:22 step:17241 [D loss: 0.831025, acc: 52.34%] [G loss: 2.858572]\n",
      "epoch:22 step:17242 [D loss: 0.167492, acc: 99.22%] [G loss: 2.740745]\n",
      "epoch:22 step:17243 [D loss: 0.586309, acc: 68.75%] [G loss: 3.399850]\n",
      "epoch:22 step:17244 [D loss: 1.028783, acc: 52.34%] [G loss: 5.872566]\n",
      "epoch:22 step:17245 [D loss: 0.412763, acc: 78.12%] [G loss: 3.848892]\n",
      "epoch:22 step:17246 [D loss: 0.279582, acc: 96.09%] [G loss: 3.833482]\n",
      "epoch:22 step:17247 [D loss: 0.182654, acc: 98.44%] [G loss: 4.160295]\n",
      "epoch:22 step:17248 [D loss: 0.359072, acc: 93.75%] [G loss: 4.202644]\n",
      "epoch:22 step:17249 [D loss: 0.297071, acc: 90.62%] [G loss: 4.932433]\n",
      "epoch:22 step:17250 [D loss: 0.309683, acc: 93.75%] [G loss: 3.371210]\n",
      "epoch:22 step:17251 [D loss: 0.826143, acc: 51.56%] [G loss: 3.312641]\n",
      "epoch:22 step:17252 [D loss: 0.393193, acc: 85.94%] [G loss: 1.931826]\n",
      "epoch:22 step:17253 [D loss: 0.686653, acc: 53.91%] [G loss: 2.314600]\n",
      "epoch:22 step:17254 [D loss: 0.850786, acc: 50.78%] [G loss: 3.051090]\n",
      "epoch:22 step:17255 [D loss: 0.435693, acc: 70.31%] [G loss: 3.507919]\n",
      "epoch:22 step:17256 [D loss: 0.431002, acc: 75.00%] [G loss: 3.555065]\n",
      "epoch:22 step:17257 [D loss: 0.172012, acc: 99.22%] [G loss: 3.465318]\n",
      "epoch:22 step:17258 [D loss: 0.379852, acc: 84.38%] [G loss: 3.742113]\n",
      "epoch:22 step:17259 [D loss: 0.852689, acc: 39.84%] [G loss: 3.635114]\n",
      "epoch:22 step:17260 [D loss: 0.324296, acc: 91.41%] [G loss: 3.657301]\n",
      "epoch:22 step:17261 [D loss: 0.605592, acc: 65.62%] [G loss: 3.854439]\n",
      "epoch:22 step:17262 [D loss: 0.369752, acc: 83.59%] [G loss: 3.175466]\n",
      "epoch:22 step:17263 [D loss: 0.343526, acc: 85.16%] [G loss: 2.801411]\n",
      "epoch:22 step:17264 [D loss: 0.230117, acc: 96.88%] [G loss: 3.449644]\n",
      "epoch:22 step:17265 [D loss: 0.516984, acc: 67.97%] [G loss: 4.604156]\n",
      "epoch:22 step:17266 [D loss: 1.061297, acc: 45.31%] [G loss: 4.717664]\n",
      "epoch:22 step:17267 [D loss: 0.617066, acc: 65.62%] [G loss: 4.033823]\n",
      "epoch:22 step:17268 [D loss: 0.329491, acc: 92.19%] [G loss: 2.985915]\n",
      "epoch:22 step:17269 [D loss: 1.027747, acc: 22.66%] [G loss: 2.736253]\n",
      "epoch:22 step:17270 [D loss: 0.319846, acc: 92.19%] [G loss: 2.416437]\n",
      "epoch:22 step:17271 [D loss: 0.168583, acc: 98.44%] [G loss: 3.917251]\n",
      "epoch:22 step:17272 [D loss: 0.193350, acc: 98.44%] [G loss: 2.811007]\n",
      "epoch:22 step:17273 [D loss: 0.536528, acc: 76.56%] [G loss: 3.675786]\n",
      "epoch:22 step:17274 [D loss: 0.436859, acc: 86.72%] [G loss: 3.796854]\n",
      "epoch:22 step:17275 [D loss: 1.181685, acc: 44.53%] [G loss: 4.637537]\n",
      "epoch:22 step:17276 [D loss: 0.672734, acc: 57.03%] [G loss: 2.084753]\n",
      "epoch:22 step:17277 [D loss: 0.915766, acc: 45.31%] [G loss: 3.618108]\n",
      "epoch:22 step:17278 [D loss: 0.443214, acc: 77.34%] [G loss: 3.234910]\n",
      "epoch:22 step:17279 [D loss: 0.413806, acc: 85.94%] [G loss: 1.985089]\n",
      "epoch:22 step:17280 [D loss: 1.001278, acc: 47.66%] [G loss: 2.324770]\n",
      "epoch:22 step:17281 [D loss: 0.570133, acc: 62.50%] [G loss: 3.261059]\n",
      "epoch:22 step:17282 [D loss: 0.257873, acc: 96.09%] [G loss: 3.556136]\n",
      "epoch:22 step:17283 [D loss: 0.913605, acc: 48.44%] [G loss: 4.114585]\n",
      "epoch:22 step:17284 [D loss: 0.187834, acc: 96.88%] [G loss: 3.179362]\n",
      "epoch:22 step:17285 [D loss: 1.068567, acc: 25.00%] [G loss: 2.506112]\n",
      "epoch:22 step:17286 [D loss: 0.474915, acc: 76.56%] [G loss: 2.593872]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17287 [D loss: 0.953483, acc: 37.50%] [G loss: 3.072846]\n",
      "epoch:22 step:17288 [D loss: 0.590762, acc: 67.19%] [G loss: 2.433744]\n",
      "epoch:22 step:17289 [D loss: 0.755994, acc: 53.91%] [G loss: 2.633893]\n",
      "epoch:22 step:17290 [D loss: 0.351100, acc: 88.28%] [G loss: 2.663340]\n",
      "epoch:22 step:17291 [D loss: 0.496072, acc: 71.09%] [G loss: 3.799285]\n",
      "epoch:22 step:17292 [D loss: 0.432582, acc: 82.03%] [G loss: 4.013955]\n",
      "epoch:22 step:17293 [D loss: 0.763717, acc: 52.34%] [G loss: 2.878597]\n",
      "epoch:22 step:17294 [D loss: 0.305047, acc: 96.88%] [G loss: 3.162136]\n",
      "epoch:22 step:17295 [D loss: 0.191679, acc: 99.22%] [G loss: 3.128966]\n",
      "epoch:22 step:17296 [D loss: 0.346599, acc: 82.03%] [G loss: 4.330356]\n",
      "epoch:22 step:17297 [D loss: 0.706175, acc: 55.47%] [G loss: 2.719729]\n",
      "epoch:22 step:17298 [D loss: 0.932014, acc: 46.88%] [G loss: 2.325347]\n",
      "epoch:22 step:17299 [D loss: 0.486680, acc: 82.81%] [G loss: 4.246252]\n",
      "epoch:22 step:17300 [D loss: 0.611792, acc: 64.06%] [G loss: 4.014802]\n",
      "epoch:22 step:17301 [D loss: 0.354341, acc: 93.75%] [G loss: 3.726859]\n",
      "epoch:22 step:17302 [D loss: 0.678545, acc: 60.16%] [G loss: 3.125635]\n",
      "epoch:22 step:17303 [D loss: 0.229626, acc: 96.88%] [G loss: 5.253051]\n",
      "epoch:22 step:17304 [D loss: 0.345826, acc: 82.81%] [G loss: 3.475101]\n",
      "epoch:22 step:17305 [D loss: 0.614070, acc: 66.41%] [G loss: 3.055516]\n",
      "epoch:22 step:17306 [D loss: 0.206256, acc: 93.75%] [G loss: 5.259411]\n",
      "epoch:22 step:17307 [D loss: 0.972184, acc: 47.66%] [G loss: 3.874218]\n",
      "epoch:22 step:17308 [D loss: 0.727648, acc: 50.00%] [G loss: 2.867474]\n",
      "epoch:22 step:17309 [D loss: 0.313029, acc: 96.88%] [G loss: 2.898440]\n",
      "epoch:22 step:17310 [D loss: 0.166331, acc: 99.22%] [G loss: 3.559695]\n",
      "epoch:22 step:17311 [D loss: 0.436028, acc: 85.94%] [G loss: 2.968765]\n",
      "epoch:22 step:17312 [D loss: 0.783554, acc: 45.31%] [G loss: 2.967901]\n",
      "epoch:22 step:17313 [D loss: 0.264861, acc: 90.62%] [G loss: 2.554529]\n",
      "epoch:22 step:17314 [D loss: 0.459903, acc: 78.12%] [G loss: 3.294903]\n",
      "epoch:22 step:17315 [D loss: 0.322653, acc: 96.88%] [G loss: 2.873720]\n",
      "epoch:22 step:17316 [D loss: 1.060147, acc: 32.81%] [G loss: 3.651110]\n",
      "epoch:22 step:17317 [D loss: 0.369571, acc: 89.06%] [G loss: 2.072438]\n",
      "epoch:22 step:17318 [D loss: 0.114575, acc: 100.00%] [G loss: 3.929225]\n",
      "epoch:22 step:17319 [D loss: 0.969163, acc: 34.38%] [G loss: 2.611218]\n",
      "epoch:22 step:17320 [D loss: 0.508294, acc: 70.31%] [G loss: 3.231294]\n",
      "epoch:22 step:17321 [D loss: 0.353542, acc: 89.06%] [G loss: 3.569813]\n",
      "epoch:22 step:17322 [D loss: 0.772850, acc: 51.56%] [G loss: 2.708438]\n",
      "epoch:22 step:17323 [D loss: 0.494425, acc: 78.91%] [G loss: 3.333680]\n",
      "epoch:22 step:17324 [D loss: 0.356233, acc: 92.19%] [G loss: 3.240143]\n",
      "epoch:22 step:17325 [D loss: 0.585672, acc: 67.97%] [G loss: 3.401386]\n",
      "epoch:22 step:17326 [D loss: 0.278789, acc: 96.09%] [G loss: 3.883146]\n",
      "epoch:22 step:17327 [D loss: 0.423846, acc: 79.69%] [G loss: 2.833180]\n",
      "epoch:22 step:17328 [D loss: 0.537490, acc: 71.09%] [G loss: 3.780961]\n",
      "epoch:22 step:17329 [D loss: 0.724060, acc: 53.91%] [G loss: 2.733258]\n",
      "epoch:22 step:17330 [D loss: 0.248416, acc: 94.53%] [G loss: 2.917883]\n",
      "epoch:22 step:17331 [D loss: 0.361551, acc: 92.19%] [G loss: 3.260854]\n",
      "epoch:22 step:17332 [D loss: 0.298279, acc: 95.31%] [G loss: 2.913814]\n",
      "epoch:22 step:17333 [D loss: 0.296696, acc: 96.09%] [G loss: 2.091716]\n",
      "epoch:22 step:17334 [D loss: 1.196147, acc: 18.75%] [G loss: 3.087218]\n",
      "epoch:22 step:17335 [D loss: 0.581498, acc: 62.50%] [G loss: 2.926164]\n",
      "epoch:22 step:17336 [D loss: 0.637430, acc: 59.38%] [G loss: 3.201007]\n",
      "epoch:22 step:17337 [D loss: 1.119509, acc: 25.00%] [G loss: 2.553842]\n",
      "epoch:22 step:17338 [D loss: 0.506799, acc: 76.56%] [G loss: 3.002608]\n",
      "epoch:22 step:17339 [D loss: 0.522286, acc: 70.31%] [G loss: 3.092813]\n",
      "epoch:22 step:17340 [D loss: 0.198623, acc: 95.31%] [G loss: 4.307575]\n",
      "epoch:22 step:17341 [D loss: 0.408441, acc: 82.03%] [G loss: 5.044730]\n",
      "epoch:22 step:17342 [D loss: 0.518845, acc: 81.25%] [G loss: 3.424100]\n",
      "epoch:22 step:17343 [D loss: 0.172159, acc: 99.22%] [G loss: 4.181186]\n",
      "epoch:22 step:17344 [D loss: 0.275986, acc: 89.84%] [G loss: 4.061779]\n",
      "epoch:22 step:17345 [D loss: 0.188917, acc: 99.22%] [G loss: 5.013483]\n",
      "epoch:22 step:17346 [D loss: 0.222912, acc: 98.44%] [G loss: 2.951225]\n",
      "epoch:22 step:17347 [D loss: 0.602500, acc: 64.84%] [G loss: 2.509145]\n",
      "epoch:22 step:17348 [D loss: 0.368121, acc: 94.53%] [G loss: 2.968014]\n",
      "epoch:22 step:17349 [D loss: 0.650030, acc: 65.62%] [G loss: 3.133837]\n",
      "epoch:22 step:17350 [D loss: 0.691455, acc: 57.03%] [G loss: 3.217148]\n",
      "epoch:22 step:17351 [D loss: 0.552166, acc: 71.88%] [G loss: 1.944418]\n",
      "epoch:22 step:17352 [D loss: 0.548094, acc: 70.31%] [G loss: 3.301527]\n",
      "epoch:22 step:17353 [D loss: 0.755424, acc: 46.88%] [G loss: 2.408825]\n",
      "epoch:22 step:17354 [D loss: 0.309181, acc: 96.88%] [G loss: 4.093932]\n",
      "epoch:22 step:17355 [D loss: 0.611038, acc: 64.84%] [G loss: 3.844958]\n",
      "epoch:22 step:17356 [D loss: 0.237577, acc: 99.22%] [G loss: 3.704118]\n",
      "epoch:22 step:17357 [D loss: 0.245783, acc: 96.09%] [G loss: 3.347563]\n",
      "epoch:22 step:17358 [D loss: 0.353010, acc: 90.62%] [G loss: 2.660265]\n",
      "epoch:22 step:17359 [D loss: 0.275444, acc: 97.66%] [G loss: 3.811087]\n",
      "epoch:22 step:17360 [D loss: 0.482593, acc: 79.69%] [G loss: 3.121974]\n",
      "epoch:22 step:17361 [D loss: 0.578986, acc: 60.94%] [G loss: 3.039910]\n",
      "epoch:22 step:17362 [D loss: 0.396562, acc: 78.12%] [G loss: 6.790866]\n",
      "epoch:22 step:17363 [D loss: 0.708506, acc: 57.03%] [G loss: 4.445430]\n",
      "epoch:22 step:17364 [D loss: 0.644785, acc: 59.38%] [G loss: 3.661633]\n",
      "epoch:22 step:17365 [D loss: 0.955893, acc: 29.69%] [G loss: 3.674412]\n",
      "epoch:22 step:17366 [D loss: 0.234621, acc: 100.00%] [G loss: 3.460414]\n",
      "epoch:22 step:17367 [D loss: 0.592923, acc: 63.28%] [G loss: 2.698607]\n",
      "epoch:22 step:17368 [D loss: 0.329664, acc: 89.06%] [G loss: 4.468633]\n",
      "epoch:22 step:17369 [D loss: 0.244992, acc: 89.06%] [G loss: 4.732971]\n",
      "epoch:22 step:17370 [D loss: 0.395495, acc: 77.34%] [G loss: 3.614429]\n",
      "epoch:22 step:17371 [D loss: 0.241066, acc: 96.88%] [G loss: 3.305556]\n",
      "epoch:22 step:17372 [D loss: 0.457788, acc: 71.88%] [G loss: 4.219171]\n",
      "epoch:22 step:17373 [D loss: 0.320802, acc: 92.19%] [G loss: 3.371543]\n",
      "epoch:22 step:17374 [D loss: 0.501593, acc: 68.75%] [G loss: 3.570889]\n",
      "epoch:22 step:17375 [D loss: 0.772148, acc: 51.56%] [G loss: 3.263061]\n",
      "epoch:22 step:17376 [D loss: 0.193262, acc: 98.44%] [G loss: 3.364854]\n",
      "epoch:22 step:17377 [D loss: 0.962646, acc: 37.50%] [G loss: 2.517244]\n",
      "epoch:22 step:17378 [D loss: 0.662507, acc: 60.16%] [G loss: 2.275297]\n",
      "epoch:22 step:17379 [D loss: 0.933446, acc: 45.31%] [G loss: 4.732741]\n",
      "epoch:22 step:17380 [D loss: 0.184443, acc: 96.88%] [G loss: 4.744339]\n",
      "epoch:22 step:17381 [D loss: 0.844767, acc: 44.53%] [G loss: 2.389584]\n",
      "epoch:22 step:17382 [D loss: 0.109104, acc: 100.00%] [G loss: 3.543633]\n",
      "epoch:22 step:17383 [D loss: 0.456468, acc: 69.53%] [G loss: 3.078160]\n",
      "epoch:22 step:17384 [D loss: 0.342652, acc: 96.09%] [G loss: 2.697459]\n",
      "epoch:22 step:17385 [D loss: 0.454156, acc: 75.00%] [G loss: 2.181731]\n",
      "epoch:22 step:17386 [D loss: 0.367390, acc: 89.84%] [G loss: 2.391870]\n",
      "epoch:22 step:17387 [D loss: 0.835273, acc: 50.00%] [G loss: 3.372990]\n",
      "epoch:22 step:17388 [D loss: 0.633959, acc: 61.72%] [G loss: 2.785888]\n",
      "epoch:22 step:17389 [D loss: 0.601202, acc: 64.84%] [G loss: 2.671764]\n",
      "epoch:22 step:17390 [D loss: 1.173434, acc: 32.03%] [G loss: 3.683464]\n",
      "epoch:22 step:17391 [D loss: 0.344016, acc: 96.88%] [G loss: 3.183335]\n",
      "epoch:22 step:17392 [D loss: 0.479816, acc: 62.50%] [G loss: 3.103598]\n",
      "epoch:22 step:17393 [D loss: 1.218215, acc: 19.53%] [G loss: 2.175188]\n",
      "epoch:22 step:17394 [D loss: 0.507631, acc: 75.00%] [G loss: 3.623635]\n",
      "epoch:22 step:17395 [D loss: 0.679394, acc: 59.38%] [G loss: 2.190993]\n",
      "epoch:22 step:17396 [D loss: 0.635683, acc: 66.41%] [G loss: 3.740821]\n",
      "epoch:22 step:17397 [D loss: 0.440378, acc: 82.81%] [G loss: 2.871872]\n",
      "epoch:22 step:17398 [D loss: 0.769233, acc: 52.34%] [G loss: 3.752010]\n",
      "epoch:22 step:17399 [D loss: 0.498951, acc: 79.69%] [G loss: 2.610120]\n",
      "epoch:22 step:17400 [D loss: 0.424744, acc: 84.38%] [G loss: 2.774003]\n",
      "epoch:22 step:17401 [D loss: 1.074664, acc: 32.81%] [G loss: 3.433268]\n",
      "epoch:22 step:17402 [D loss: 1.272918, acc: 10.16%] [G loss: 4.245568]\n",
      "epoch:22 step:17403 [D loss: 0.611510, acc: 64.84%] [G loss: 3.174288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17404 [D loss: 0.616613, acc: 70.31%] [G loss: 4.179418]\n",
      "epoch:22 step:17405 [D loss: 0.630442, acc: 54.69%] [G loss: 4.153608]\n",
      "epoch:22 step:17406 [D loss: 0.326133, acc: 87.50%] [G loss: 4.364343]\n",
      "epoch:22 step:17407 [D loss: 0.526888, acc: 74.22%] [G loss: 2.876254]\n",
      "epoch:22 step:17408 [D loss: 0.398461, acc: 91.41%] [G loss: 3.838358]\n",
      "epoch:22 step:17409 [D loss: 0.371203, acc: 89.84%] [G loss: 3.678216]\n",
      "epoch:22 step:17410 [D loss: 0.656802, acc: 64.84%] [G loss: 3.214880]\n",
      "epoch:22 step:17411 [D loss: 0.223882, acc: 98.44%] [G loss: 4.011788]\n",
      "epoch:22 step:17412 [D loss: 0.455474, acc: 82.81%] [G loss: 3.411426]\n",
      "epoch:22 step:17413 [D loss: 0.389739, acc: 86.72%] [G loss: 3.709899]\n",
      "epoch:22 step:17414 [D loss: 0.549456, acc: 64.06%] [G loss: 3.271130]\n",
      "epoch:22 step:17415 [D loss: 0.355147, acc: 88.28%] [G loss: 4.149989]\n",
      "epoch:22 step:17416 [D loss: 0.715690, acc: 55.47%] [G loss: 4.385596]\n",
      "epoch:22 step:17417 [D loss: 0.284842, acc: 92.97%] [G loss: 3.066933]\n",
      "epoch:22 step:17418 [D loss: 0.870481, acc: 40.62%] [G loss: 4.339370]\n",
      "epoch:22 step:17419 [D loss: 0.487267, acc: 74.22%] [G loss: 3.163225]\n",
      "epoch:22 step:17420 [D loss: 0.330591, acc: 92.19%] [G loss: 3.589666]\n",
      "epoch:22 step:17421 [D loss: 0.728461, acc: 54.69%] [G loss: 2.841125]\n",
      "epoch:22 step:17422 [D loss: 0.963914, acc: 36.72%] [G loss: 2.718152]\n",
      "epoch:22 step:17423 [D loss: 0.596063, acc: 64.84%] [G loss: 2.789219]\n",
      "epoch:22 step:17424 [D loss: 0.277123, acc: 96.09%] [G loss: 2.986577]\n",
      "epoch:22 step:17425 [D loss: 0.526991, acc: 75.00%] [G loss: 3.184545]\n",
      "epoch:22 step:17426 [D loss: 0.300622, acc: 93.75%] [G loss: 4.097915]\n",
      "epoch:22 step:17427 [D loss: 0.729390, acc: 55.47%] [G loss: 2.885190]\n",
      "epoch:22 step:17428 [D loss: 0.660083, acc: 59.38%] [G loss: 2.789887]\n",
      "epoch:22 step:17429 [D loss: 0.676020, acc: 57.81%] [G loss: 2.318260]\n",
      "epoch:22 step:17430 [D loss: 0.459917, acc: 78.91%] [G loss: 3.218470]\n",
      "epoch:22 step:17431 [D loss: 0.172074, acc: 100.00%] [G loss: 4.758620]\n",
      "epoch:22 step:17432 [D loss: 0.599692, acc: 65.62%] [G loss: 3.697672]\n",
      "epoch:22 step:17433 [D loss: 0.421230, acc: 75.78%] [G loss: 2.888994]\n",
      "epoch:22 step:17434 [D loss: 0.530603, acc: 75.78%] [G loss: 2.421063]\n",
      "epoch:22 step:17435 [D loss: 0.596529, acc: 70.31%] [G loss: 2.855970]\n",
      "epoch:22 step:17436 [D loss: 0.352493, acc: 94.53%] [G loss: 3.917637]\n",
      "epoch:22 step:17437 [D loss: 0.520706, acc: 78.91%] [G loss: 3.848497]\n",
      "epoch:22 step:17438 [D loss: 0.617549, acc: 56.25%] [G loss: 4.536060]\n",
      "epoch:22 step:17439 [D loss: 0.583127, acc: 74.22%] [G loss: 3.073945]\n",
      "epoch:22 step:17440 [D loss: 0.675807, acc: 58.59%] [G loss: 2.815300]\n",
      "epoch:22 step:17441 [D loss: 0.402748, acc: 89.84%] [G loss: 3.086564]\n",
      "epoch:22 step:17442 [D loss: 0.636603, acc: 62.50%] [G loss: 3.250304]\n",
      "epoch:22 step:17443 [D loss: 0.166870, acc: 97.66%] [G loss: 3.311974]\n",
      "epoch:22 step:17444 [D loss: 0.408986, acc: 75.78%] [G loss: 3.719789]\n",
      "epoch:22 step:17445 [D loss: 0.851502, acc: 47.66%] [G loss: 3.312280]\n",
      "epoch:22 step:17446 [D loss: 0.717905, acc: 52.34%] [G loss: 2.289503]\n",
      "epoch:22 step:17447 [D loss: 0.316985, acc: 90.62%] [G loss: 2.970187]\n",
      "epoch:22 step:17448 [D loss: 1.022471, acc: 32.81%] [G loss: 3.344795]\n",
      "epoch:22 step:17449 [D loss: 1.181430, acc: 17.97%] [G loss: 2.640852]\n",
      "epoch:22 step:17450 [D loss: 0.486112, acc: 72.66%] [G loss: 3.577880]\n",
      "epoch:22 step:17451 [D loss: 0.491758, acc: 64.06%] [G loss: 5.517399]\n",
      "epoch:22 step:17452 [D loss: 0.674781, acc: 64.06%] [G loss: 2.464341]\n",
      "epoch:22 step:17453 [D loss: 0.178066, acc: 99.22%] [G loss: 3.515821]\n",
      "epoch:22 step:17454 [D loss: 0.169115, acc: 100.00%] [G loss: 5.291445]\n",
      "epoch:22 step:17455 [D loss: 0.442313, acc: 82.81%] [G loss: 3.550547]\n",
      "epoch:22 step:17456 [D loss: 0.301536, acc: 91.41%] [G loss: 4.152634]\n",
      "epoch:22 step:17457 [D loss: 0.577898, acc: 70.31%] [G loss: 2.913096]\n",
      "epoch:22 step:17458 [D loss: 0.401917, acc: 89.06%] [G loss: 2.410642]\n",
      "epoch:22 step:17459 [D loss: 0.582745, acc: 71.09%] [G loss: 3.050501]\n",
      "epoch:22 step:17460 [D loss: 0.288059, acc: 94.53%] [G loss: 3.907427]\n",
      "epoch:22 step:17461 [D loss: 0.353815, acc: 92.97%] [G loss: 3.946926]\n",
      "epoch:22 step:17462 [D loss: 0.662666, acc: 56.25%] [G loss: 3.898059]\n",
      "epoch:22 step:17463 [D loss: 0.319747, acc: 89.06%] [G loss: 3.740237]\n",
      "epoch:22 step:17464 [D loss: 0.288506, acc: 96.09%] [G loss: 4.162432]\n",
      "epoch:22 step:17465 [D loss: 0.908669, acc: 41.41%] [G loss: 1.747758]\n",
      "epoch:22 step:17466 [D loss: 0.725297, acc: 52.34%] [G loss: 3.738334]\n",
      "epoch:22 step:17467 [D loss: 0.967557, acc: 43.75%] [G loss: 3.508753]\n",
      "epoch:22 step:17468 [D loss: 0.941356, acc: 46.88%] [G loss: 3.279653]\n",
      "epoch:22 step:17469 [D loss: 1.217516, acc: 16.41%] [G loss: 3.298983]\n",
      "epoch:22 step:17470 [D loss: 0.637753, acc: 64.06%] [G loss: 3.240179]\n",
      "epoch:22 step:17471 [D loss: 0.390071, acc: 82.03%] [G loss: 3.851176]\n",
      "epoch:22 step:17472 [D loss: 0.507839, acc: 67.19%] [G loss: 2.753542]\n",
      "epoch:22 step:17473 [D loss: 0.511179, acc: 71.88%] [G loss: 2.862016]\n",
      "epoch:22 step:17474 [D loss: 0.623448, acc: 60.16%] [G loss: 3.763839]\n",
      "epoch:22 step:17475 [D loss: 0.359863, acc: 85.94%] [G loss: 4.276185]\n",
      "epoch:22 step:17476 [D loss: 0.510189, acc: 75.78%] [G loss: 4.686517]\n",
      "epoch:22 step:17477 [D loss: 0.260979, acc: 96.09%] [G loss: 3.238012]\n",
      "epoch:22 step:17478 [D loss: 0.329440, acc: 90.62%] [G loss: 3.857542]\n",
      "epoch:22 step:17479 [D loss: 1.588150, acc: 5.47%] [G loss: 2.881024]\n",
      "epoch:22 step:17480 [D loss: 0.316474, acc: 95.31%] [G loss: 2.588078]\n",
      "epoch:22 step:17481 [D loss: 0.386090, acc: 86.72%] [G loss: 3.835395]\n",
      "epoch:22 step:17482 [D loss: 0.679983, acc: 53.12%] [G loss: 4.206866]\n",
      "epoch:22 step:17483 [D loss: 0.635937, acc: 60.94%] [G loss: 3.305339]\n",
      "epoch:22 step:17484 [D loss: 0.370951, acc: 89.06%] [G loss: 3.007755]\n",
      "epoch:22 step:17485 [D loss: 0.505693, acc: 75.78%] [G loss: 2.065699]\n",
      "epoch:22 step:17486 [D loss: 0.492287, acc: 81.25%] [G loss: 3.545804]\n",
      "epoch:22 step:17487 [D loss: 0.782536, acc: 53.91%] [G loss: 3.203628]\n",
      "epoch:22 step:17488 [D loss: 0.432218, acc: 85.16%] [G loss: 2.333985]\n",
      "epoch:22 step:17489 [D loss: 1.096480, acc: 32.81%] [G loss: 3.309555]\n",
      "epoch:22 step:17490 [D loss: 0.321889, acc: 92.19%] [G loss: 3.355906]\n",
      "epoch:22 step:17491 [D loss: 0.671922, acc: 61.72%] [G loss: 2.760028]\n",
      "epoch:22 step:17492 [D loss: 0.323699, acc: 85.94%] [G loss: 4.328363]\n",
      "epoch:22 step:17493 [D loss: 0.276692, acc: 97.66%] [G loss: 2.942425]\n",
      "epoch:22 step:17494 [D loss: 0.950116, acc: 32.81%] [G loss: 3.112733]\n",
      "epoch:22 step:17495 [D loss: 0.507385, acc: 68.75%] [G loss: 4.757717]\n",
      "epoch:22 step:17496 [D loss: 0.273629, acc: 96.09%] [G loss: 4.422008]\n",
      "epoch:22 step:17497 [D loss: 0.740738, acc: 54.69%] [G loss: 3.943603]\n",
      "epoch:22 step:17498 [D loss: 0.843133, acc: 51.56%] [G loss: 3.168534]\n",
      "epoch:22 step:17499 [D loss: 0.521376, acc: 81.25%] [G loss: 3.994443]\n",
      "epoch:22 step:17500 [D loss: 1.024650, acc: 24.22%] [G loss: 3.133641]\n",
      "epoch:22 step:17501 [D loss: 0.421026, acc: 78.91%] [G loss: 2.986653]\n",
      "epoch:22 step:17502 [D loss: 0.777492, acc: 52.34%] [G loss: 4.365207]\n",
      "epoch:22 step:17503 [D loss: 0.492267, acc: 83.59%] [G loss: 2.422483]\n",
      "epoch:22 step:17504 [D loss: 0.681331, acc: 57.03%] [G loss: 2.667013]\n",
      "epoch:22 step:17505 [D loss: 0.716619, acc: 55.47%] [G loss: 2.929157]\n",
      "epoch:22 step:17506 [D loss: 0.578612, acc: 71.09%] [G loss: 2.669316]\n",
      "epoch:22 step:17507 [D loss: 0.781093, acc: 42.97%] [G loss: 3.166158]\n",
      "epoch:22 step:17508 [D loss: 1.177991, acc: 26.56%] [G loss: 2.576862]\n",
      "epoch:22 step:17509 [D loss: 0.251055, acc: 96.09%] [G loss: 3.409853]\n",
      "epoch:22 step:17510 [D loss: 0.575381, acc: 68.75%] [G loss: 2.191842]\n",
      "epoch:22 step:17511 [D loss: 0.316662, acc: 95.31%] [G loss: 2.607768]\n",
      "epoch:22 step:17512 [D loss: 0.633757, acc: 60.94%] [G loss: 2.861010]\n",
      "epoch:22 step:17513 [D loss: 0.838113, acc: 50.00%] [G loss: 2.937461]\n",
      "epoch:22 step:17514 [D loss: 0.450501, acc: 75.00%] [G loss: 3.653102]\n",
      "epoch:22 step:17515 [D loss: 0.501498, acc: 63.28%] [G loss: 3.833233]\n",
      "epoch:22 step:17516 [D loss: 0.495888, acc: 75.00%] [G loss: 3.904548]\n",
      "epoch:22 step:17517 [D loss: 0.224508, acc: 98.44%] [G loss: 4.036901]\n",
      "epoch:22 step:17518 [D loss: 0.556836, acc: 63.28%] [G loss: 3.714487]\n",
      "epoch:22 step:17519 [D loss: 0.902736, acc: 50.78%] [G loss: 1.685773]\n",
      "epoch:22 step:17520 [D loss: 0.356243, acc: 90.62%] [G loss: 3.146769]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17521 [D loss: 0.222354, acc: 97.66%] [G loss: 3.986978]\n",
      "epoch:22 step:17522 [D loss: 1.160120, acc: 14.06%] [G loss: 4.006107]\n",
      "epoch:22 step:17523 [D loss: 0.300316, acc: 96.88%] [G loss: 2.475427]\n",
      "epoch:22 step:17524 [D loss: 0.839983, acc: 46.88%] [G loss: 4.888701]\n",
      "epoch:22 step:17525 [D loss: 0.551120, acc: 71.09%] [G loss: 3.613988]\n",
      "epoch:22 step:17526 [D loss: 0.406805, acc: 89.06%] [G loss: 3.815922]\n",
      "epoch:22 step:17527 [D loss: 0.615545, acc: 67.19%] [G loss: 2.585136]\n",
      "epoch:22 step:17528 [D loss: 0.229978, acc: 95.31%] [G loss: 4.209681]\n",
      "epoch:22 step:17529 [D loss: 0.218416, acc: 95.31%] [G loss: 3.472240]\n",
      "epoch:22 step:17530 [D loss: 0.545368, acc: 76.56%] [G loss: 4.384311]\n",
      "epoch:22 step:17531 [D loss: 0.723823, acc: 54.69%] [G loss: 2.966101]\n",
      "epoch:22 step:17532 [D loss: 0.454594, acc: 89.84%] [G loss: 3.563037]\n",
      "epoch:22 step:17533 [D loss: 0.714414, acc: 50.00%] [G loss: 2.648451]\n",
      "epoch:22 step:17534 [D loss: 0.496207, acc: 71.88%] [G loss: 3.141177]\n",
      "epoch:22 step:17535 [D loss: 0.378084, acc: 78.91%] [G loss: 3.272414]\n",
      "epoch:22 step:17536 [D loss: 0.601640, acc: 71.09%] [G loss: 2.378553]\n",
      "epoch:22 step:17537 [D loss: 0.753569, acc: 51.56%] [G loss: 2.361731]\n",
      "epoch:22 step:17538 [D loss: 0.984229, acc: 47.66%] [G loss: 2.188184]\n",
      "epoch:22 step:17539 [D loss: 0.337986, acc: 86.72%] [G loss: 4.392115]\n",
      "epoch:22 step:17540 [D loss: 0.653913, acc: 58.59%] [G loss: 3.268291]\n",
      "epoch:22 step:17541 [D loss: 0.370484, acc: 86.72%] [G loss: 3.355031]\n",
      "epoch:22 step:17542 [D loss: 0.671356, acc: 59.38%] [G loss: 4.150395]\n",
      "epoch:22 step:17543 [D loss: 0.602562, acc: 63.28%] [G loss: 2.429380]\n",
      "epoch:22 step:17544 [D loss: 0.437643, acc: 84.38%] [G loss: 2.609014]\n",
      "epoch:22 step:17545 [D loss: 0.150853, acc: 100.00%] [G loss: 5.374948]\n",
      "epoch:22 step:17546 [D loss: 0.363189, acc: 88.28%] [G loss: 3.363663]\n",
      "epoch:22 step:17547 [D loss: 0.494075, acc: 78.12%] [G loss: 2.988688]\n",
      "epoch:22 step:17548 [D loss: 0.897859, acc: 49.22%] [G loss: 2.856929]\n",
      "epoch:22 step:17549 [D loss: 0.641110, acc: 64.84%] [G loss: 2.656283]\n",
      "epoch:22 step:17550 [D loss: 0.826612, acc: 48.44%] [G loss: 2.783741]\n",
      "epoch:22 step:17551 [D loss: 0.607262, acc: 64.06%] [G loss: 3.267657]\n",
      "epoch:22 step:17552 [D loss: 0.303826, acc: 95.31%] [G loss: 3.978545]\n",
      "epoch:22 step:17553 [D loss: 0.596701, acc: 68.75%] [G loss: 2.793470]\n",
      "epoch:22 step:17554 [D loss: 0.355479, acc: 91.41%] [G loss: 2.545330]\n",
      "epoch:22 step:17555 [D loss: 0.342815, acc: 92.97%] [G loss: 2.528614]\n",
      "epoch:22 step:17556 [D loss: 0.151015, acc: 100.00%] [G loss: 3.442744]\n",
      "epoch:22 step:17557 [D loss: 0.431313, acc: 84.38%] [G loss: 3.933270]\n",
      "epoch:22 step:17558 [D loss: 0.359224, acc: 89.06%] [G loss: 3.544111]\n",
      "epoch:22 step:17559 [D loss: 0.376279, acc: 89.84%] [G loss: 4.427959]\n",
      "epoch:22 step:17560 [D loss: 0.173850, acc: 100.00%] [G loss: 1.905889]\n",
      "epoch:22 step:17561 [D loss: 0.227982, acc: 99.22%] [G loss: 3.871682]\n",
      "epoch:22 step:17562 [D loss: 0.214813, acc: 99.22%] [G loss: 3.447917]\n",
      "epoch:22 step:17563 [D loss: 0.384798, acc: 82.81%] [G loss: 3.555783]\n",
      "epoch:22 step:17564 [D loss: 0.317900, acc: 92.19%] [G loss: 2.011057]\n",
      "epoch:22 step:17565 [D loss: 1.153487, acc: 25.00%] [G loss: 3.356574]\n",
      "epoch:22 step:17566 [D loss: 0.218630, acc: 99.22%] [G loss: 3.834721]\n",
      "epoch:22 step:17567 [D loss: 0.539334, acc: 78.91%] [G loss: 4.114774]\n",
      "epoch:22 step:17568 [D loss: 0.312076, acc: 90.62%] [G loss: 3.670378]\n",
      "epoch:22 step:17569 [D loss: 0.569786, acc: 69.53%] [G loss: 3.150905]\n",
      "epoch:22 step:17570 [D loss: 0.379375, acc: 94.53%] [G loss: 3.260023]\n",
      "epoch:22 step:17571 [D loss: 0.369625, acc: 89.84%] [G loss: 2.793830]\n",
      "epoch:22 step:17572 [D loss: 0.320700, acc: 95.31%] [G loss: 3.188940]\n",
      "epoch:22 step:17573 [D loss: 1.018562, acc: 30.47%] [G loss: 3.208801]\n",
      "epoch:22 step:17574 [D loss: 0.336861, acc: 92.97%] [G loss: 4.109175]\n",
      "epoch:22 step:17575 [D loss: 0.915808, acc: 35.16%] [G loss: 3.681548]\n",
      "epoch:22 step:17576 [D loss: 0.416599, acc: 90.62%] [G loss: 3.262780]\n",
      "epoch:22 step:17577 [D loss: 0.802660, acc: 42.97%] [G loss: 4.406168]\n",
      "epoch:22 step:17578 [D loss: 0.368633, acc: 82.81%] [G loss: 3.078429]\n",
      "epoch:22 step:17579 [D loss: 0.567657, acc: 58.59%] [G loss: 2.898339]\n",
      "epoch:22 step:17580 [D loss: 0.547637, acc: 74.22%] [G loss: 3.192199]\n",
      "epoch:22 step:17581 [D loss: 0.451747, acc: 70.31%] [G loss: 3.588877]\n",
      "epoch:22 step:17582 [D loss: 0.326948, acc: 97.66%] [G loss: 3.690004]\n",
      "epoch:22 step:17583 [D loss: 0.168985, acc: 100.00%] [G loss: 6.123735]\n",
      "epoch:22 step:17584 [D loss: 0.178103, acc: 98.44%] [G loss: 3.691532]\n",
      "epoch:22 step:17585 [D loss: 0.530497, acc: 71.88%] [G loss: 3.569316]\n",
      "epoch:22 step:17586 [D loss: 0.980576, acc: 29.69%] [G loss: 2.083129]\n",
      "epoch:22 step:17587 [D loss: 0.390508, acc: 87.50%] [G loss: 3.966244]\n",
      "epoch:22 step:17588 [D loss: 0.489192, acc: 72.66%] [G loss: 2.868375]\n",
      "epoch:22 step:17589 [D loss: 0.216833, acc: 98.44%] [G loss: 3.488671]\n",
      "epoch:22 step:17590 [D loss: 0.270055, acc: 92.19%] [G loss: 3.955856]\n",
      "epoch:22 step:17591 [D loss: 0.238640, acc: 96.09%] [G loss: 2.332392]\n",
      "epoch:22 step:17592 [D loss: 0.363543, acc: 76.56%] [G loss: 3.196227]\n",
      "epoch:22 step:17593 [D loss: 0.480818, acc: 73.44%] [G loss: 3.917209]\n",
      "epoch:22 step:17594 [D loss: 0.642363, acc: 63.28%] [G loss: 3.083047]\n",
      "epoch:22 step:17595 [D loss: 0.749793, acc: 53.12%] [G loss: 2.532521]\n",
      "epoch:22 step:17596 [D loss: 0.727413, acc: 51.56%] [G loss: 2.931186]\n",
      "epoch:22 step:17597 [D loss: 0.481892, acc: 85.16%] [G loss: 2.594467]\n",
      "epoch:22 step:17598 [D loss: 0.129837, acc: 100.00%] [G loss: 2.684898]\n",
      "epoch:22 step:17599 [D loss: 0.280019, acc: 92.19%] [G loss: 4.752136]\n",
      "epoch:22 step:17600 [D loss: 0.471506, acc: 73.44%] [G loss: 3.162851]\n",
      "epoch:22 step:17601 [D loss: 0.657259, acc: 56.25%] [G loss: 2.915411]\n",
      "epoch:22 step:17602 [D loss: 1.348966, acc: 25.78%] [G loss: 2.855479]\n",
      "epoch:22 step:17603 [D loss: 0.748886, acc: 55.47%] [G loss: 2.630356]\n",
      "epoch:22 step:17604 [D loss: 0.133654, acc: 100.00%] [G loss: 2.921224]\n",
      "epoch:22 step:17605 [D loss: 0.531349, acc: 71.09%] [G loss: 3.844491]\n",
      "epoch:22 step:17606 [D loss: 0.714478, acc: 60.16%] [G loss: 3.984550]\n",
      "epoch:22 step:17607 [D loss: 0.373094, acc: 90.62%] [G loss: 4.048030]\n",
      "epoch:22 step:17608 [D loss: 0.248083, acc: 96.09%] [G loss: 2.800684]\n",
      "epoch:22 step:17609 [D loss: 0.406938, acc: 85.16%] [G loss: 3.018214]\n",
      "epoch:22 step:17610 [D loss: 0.699472, acc: 56.25%] [G loss: 4.085762]\n",
      "epoch:22 step:17611 [D loss: 0.505323, acc: 77.34%] [G loss: 3.570829]\n",
      "epoch:22 step:17612 [D loss: 0.703054, acc: 54.69%] [G loss: 3.487086]\n",
      "epoch:22 step:17613 [D loss: 0.757712, acc: 56.25%] [G loss: 3.907102]\n",
      "epoch:22 step:17614 [D loss: 0.389905, acc: 89.84%] [G loss: 3.739058]\n",
      "epoch:22 step:17615 [D loss: 0.118754, acc: 100.00%] [G loss: 1.934839]\n",
      "epoch:22 step:17616 [D loss: 0.248807, acc: 96.09%] [G loss: 2.741295]\n",
      "epoch:22 step:17617 [D loss: 0.577549, acc: 65.62%] [G loss: 3.477157]\n",
      "epoch:22 step:17618 [D loss: 0.673666, acc: 61.72%] [G loss: 3.644475]\n",
      "epoch:22 step:17619 [D loss: 0.314962, acc: 94.53%] [G loss: 3.122757]\n",
      "epoch:22 step:17620 [D loss: 0.384744, acc: 89.84%] [G loss: 3.052183]\n",
      "epoch:22 step:17621 [D loss: 0.263047, acc: 94.53%] [G loss: 3.376571]\n",
      "epoch:22 step:17622 [D loss: 1.461698, acc: 4.69%] [G loss: 2.392489]\n",
      "epoch:22 step:17623 [D loss: 0.574274, acc: 71.09%] [G loss: 3.347640]\n",
      "epoch:22 step:17624 [D loss: 0.463014, acc: 79.69%] [G loss: 2.388477]\n",
      "epoch:22 step:17625 [D loss: 0.601202, acc: 72.66%] [G loss: 2.739286]\n",
      "epoch:22 step:17626 [D loss: 0.512461, acc: 78.91%] [G loss: 3.833721]\n",
      "epoch:22 step:17627 [D loss: 0.325235, acc: 93.75%] [G loss: 1.989645]\n",
      "epoch:22 step:17628 [D loss: 0.529442, acc: 60.94%] [G loss: 5.470936]\n",
      "epoch:22 step:17629 [D loss: 0.777052, acc: 48.44%] [G loss: 2.879524]\n",
      "epoch:22 step:17630 [D loss: 0.185908, acc: 97.66%] [G loss: 2.355324]\n",
      "epoch:22 step:17631 [D loss: 0.226532, acc: 98.44%] [G loss: 3.751951]\n",
      "epoch:22 step:17632 [D loss: 0.225060, acc: 96.09%] [G loss: 4.248381]\n",
      "epoch:22 step:17633 [D loss: 0.431511, acc: 88.28%] [G loss: 4.103668]\n",
      "epoch:22 step:17634 [D loss: 0.379235, acc: 90.62%] [G loss: 3.412980]\n",
      "epoch:22 step:17635 [D loss: 0.482001, acc: 78.91%] [G loss: 3.739642]\n",
      "epoch:22 step:17636 [D loss: 0.112902, acc: 100.00%] [G loss: 2.231228]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17637 [D loss: 0.819074, acc: 50.78%] [G loss: 2.852071]\n",
      "epoch:22 step:17638 [D loss: 0.265830, acc: 95.31%] [G loss: 3.011452]\n",
      "epoch:22 step:17639 [D loss: 0.220517, acc: 96.09%] [G loss: 3.443284]\n",
      "epoch:22 step:17640 [D loss: 0.392113, acc: 86.72%] [G loss: 4.600490]\n",
      "epoch:22 step:17641 [D loss: 0.865127, acc: 44.53%] [G loss: 2.276402]\n",
      "epoch:22 step:17642 [D loss: 0.235454, acc: 96.88%] [G loss: 3.772989]\n",
      "epoch:22 step:17643 [D loss: 0.464010, acc: 86.72%] [G loss: 3.628557]\n",
      "epoch:22 step:17644 [D loss: 0.509346, acc: 66.41%] [G loss: 4.905175]\n",
      "epoch:22 step:17645 [D loss: 0.409753, acc: 74.22%] [G loss: 5.177727]\n",
      "epoch:22 step:17646 [D loss: 0.201898, acc: 99.22%] [G loss: 3.956146]\n",
      "epoch:22 step:17647 [D loss: 0.532041, acc: 67.19%] [G loss: 3.220372]\n",
      "epoch:22 step:17648 [D loss: 0.058815, acc: 100.00%] [G loss: 7.402381]\n",
      "epoch:22 step:17649 [D loss: 0.990601, acc: 21.88%] [G loss: 2.886330]\n",
      "epoch:22 step:17650 [D loss: 0.949733, acc: 50.00%] [G loss: 4.444292]\n",
      "epoch:22 step:17651 [D loss: 0.550434, acc: 60.16%] [G loss: 3.941356]\n",
      "epoch:22 step:17652 [D loss: 0.358223, acc: 90.62%] [G loss: 3.870000]\n",
      "epoch:22 step:17653 [D loss: 0.268112, acc: 96.88%] [G loss: 4.811728]\n",
      "epoch:22 step:17654 [D loss: 0.976461, acc: 28.91%] [G loss: 2.664131]\n",
      "epoch:22 step:17655 [D loss: 1.548069, acc: 3.12%] [G loss: 3.307319]\n",
      "epoch:22 step:17656 [D loss: 0.568930, acc: 63.28%] [G loss: 2.225124]\n",
      "epoch:22 step:17657 [D loss: 0.644349, acc: 58.59%] [G loss: 4.041083]\n",
      "epoch:22 step:17658 [D loss: 1.221999, acc: 22.66%] [G loss: 3.678660]\n",
      "epoch:22 step:17659 [D loss: 0.274175, acc: 96.09%] [G loss: 2.608576]\n",
      "epoch:22 step:17660 [D loss: 0.611512, acc: 65.62%] [G loss: 3.644141]\n",
      "epoch:22 step:17661 [D loss: 0.577257, acc: 67.19%] [G loss: 2.682397]\n",
      "epoch:22 step:17662 [D loss: 0.292344, acc: 95.31%] [G loss: 3.495853]\n",
      "epoch:22 step:17663 [D loss: 0.419446, acc: 82.03%] [G loss: 2.942192]\n",
      "epoch:22 step:17664 [D loss: 0.747089, acc: 52.34%] [G loss: 3.200884]\n",
      "epoch:22 step:17665 [D loss: 0.657527, acc: 59.38%] [G loss: 3.213266]\n",
      "epoch:22 step:17666 [D loss: 0.413997, acc: 89.06%] [G loss: 3.109039]\n",
      "epoch:22 step:17667 [D loss: 1.089846, acc: 35.16%] [G loss: 2.154542]\n",
      "epoch:22 step:17668 [D loss: 0.819800, acc: 37.50%] [G loss: 3.095029]\n",
      "epoch:22 step:17669 [D loss: 0.356660, acc: 92.19%] [G loss: 2.872000]\n",
      "epoch:22 step:17670 [D loss: 0.558989, acc: 71.88%] [G loss: 4.436506]\n",
      "epoch:22 step:17671 [D loss: 0.224193, acc: 98.44%] [G loss: 3.554071]\n",
      "epoch:22 step:17672 [D loss: 0.084980, acc: 100.00%] [G loss: 4.423118]\n",
      "epoch:22 step:17673 [D loss: 0.611894, acc: 65.62%] [G loss: 3.680530]\n",
      "epoch:22 step:17674 [D loss: 0.679055, acc: 57.81%] [G loss: 3.136542]\n",
      "epoch:22 step:17675 [D loss: 0.528044, acc: 75.78%] [G loss: 3.155224]\n",
      "epoch:22 step:17676 [D loss: 0.251234, acc: 96.09%] [G loss: 3.942826]\n",
      "epoch:22 step:17677 [D loss: 0.877799, acc: 51.56%] [G loss: 4.272900]\n",
      "epoch:22 step:17678 [D loss: 0.774371, acc: 50.78%] [G loss: 2.714806]\n",
      "epoch:22 step:17679 [D loss: 0.166851, acc: 99.22%] [G loss: 5.111599]\n",
      "epoch:22 step:17680 [D loss: 0.433567, acc: 89.06%] [G loss: 2.725473]\n",
      "epoch:22 step:17681 [D loss: 0.161229, acc: 99.22%] [G loss: 3.526447]\n",
      "epoch:22 step:17682 [D loss: 1.000506, acc: 43.75%] [G loss: 4.136614]\n",
      "epoch:22 step:17683 [D loss: 0.332741, acc: 95.31%] [G loss: 3.557925]\n",
      "epoch:22 step:17684 [D loss: 0.336661, acc: 90.62%] [G loss: 3.559865]\n",
      "epoch:22 step:17685 [D loss: 0.513650, acc: 77.34%] [G loss: 3.006333]\n",
      "epoch:22 step:17686 [D loss: 0.610065, acc: 55.47%] [G loss: 6.150747]\n",
      "epoch:22 step:17687 [D loss: 0.321106, acc: 92.97%] [G loss: 3.817935]\n",
      "epoch:22 step:17688 [D loss: 0.450518, acc: 77.34%] [G loss: 3.178254]\n",
      "epoch:22 step:17689 [D loss: 0.380615, acc: 94.53%] [G loss: 2.056811]\n",
      "epoch:22 step:17690 [D loss: 0.391637, acc: 89.84%] [G loss: 2.841423]\n",
      "epoch:22 step:17691 [D loss: 0.202081, acc: 99.22%] [G loss: 3.535991]\n",
      "epoch:22 step:17692 [D loss: 0.502137, acc: 78.12%] [G loss: 3.158686]\n",
      "epoch:22 step:17693 [D loss: 0.307565, acc: 85.16%] [G loss: 5.779207]\n",
      "epoch:22 step:17694 [D loss: 0.350873, acc: 87.50%] [G loss: 4.287213]\n",
      "epoch:22 step:17695 [D loss: 0.629992, acc: 59.38%] [G loss: 4.700609]\n",
      "epoch:22 step:17696 [D loss: 0.691271, acc: 53.91%] [G loss: 3.091202]\n",
      "epoch:22 step:17697 [D loss: 0.275427, acc: 97.66%] [G loss: 3.444426]\n",
      "epoch:22 step:17698 [D loss: 0.607222, acc: 68.75%] [G loss: 3.692672]\n",
      "epoch:22 step:17699 [D loss: 0.402808, acc: 73.44%] [G loss: 4.756380]\n",
      "epoch:22 step:17700 [D loss: 0.452234, acc: 77.34%] [G loss: 2.883232]\n",
      "epoch:22 step:17701 [D loss: 0.505882, acc: 80.47%] [G loss: 2.907862]\n",
      "epoch:22 step:17702 [D loss: 0.225000, acc: 97.66%] [G loss: 5.005679]\n",
      "epoch:22 step:17703 [D loss: 0.962796, acc: 36.72%] [G loss: 3.517310]\n",
      "epoch:22 step:17704 [D loss: 0.686284, acc: 55.47%] [G loss: 3.534848]\n",
      "epoch:22 step:17705 [D loss: 0.859932, acc: 48.44%] [G loss: 2.503506]\n",
      "epoch:22 step:17706 [D loss: 0.732182, acc: 53.91%] [G loss: 2.972961]\n",
      "epoch:22 step:17707 [D loss: 0.383319, acc: 87.50%] [G loss: 1.852763]\n",
      "epoch:22 step:17708 [D loss: 0.448635, acc: 75.00%] [G loss: 2.578393]\n",
      "epoch:22 step:17709 [D loss: 1.011230, acc: 46.09%] [G loss: 3.298971]\n",
      "epoch:22 step:17710 [D loss: 0.304509, acc: 94.53%] [G loss: 2.731563]\n",
      "epoch:22 step:17711 [D loss: 0.392348, acc: 86.72%] [G loss: 3.229542]\n",
      "epoch:22 step:17712 [D loss: 0.511339, acc: 68.75%] [G loss: 3.053356]\n",
      "epoch:22 step:17713 [D loss: 0.520220, acc: 75.78%] [G loss: 3.939437]\n",
      "epoch:22 step:17714 [D loss: 0.747995, acc: 53.91%] [G loss: 3.816266]\n",
      "epoch:22 step:17715 [D loss: 0.862035, acc: 48.44%] [G loss: 3.159319]\n",
      "epoch:22 step:17716 [D loss: 0.164336, acc: 98.44%] [G loss: 4.476904]\n",
      "epoch:22 step:17717 [D loss: 0.515222, acc: 71.09%] [G loss: 2.842775]\n",
      "epoch:22 step:17718 [D loss: 0.461937, acc: 84.38%] [G loss: 3.049156]\n",
      "epoch:22 step:17719 [D loss: 0.602087, acc: 62.50%] [G loss: 2.909773]\n",
      "epoch:22 step:17720 [D loss: 0.444255, acc: 71.09%] [G loss: 3.671488]\n",
      "epoch:22 step:17721 [D loss: 0.768034, acc: 50.00%] [G loss: 3.190263]\n",
      "epoch:22 step:17722 [D loss: 0.689238, acc: 55.47%] [G loss: 3.452251]\n",
      "epoch:22 step:17723 [D loss: 0.406112, acc: 89.06%] [G loss: 3.149405]\n",
      "epoch:22 step:17724 [D loss: 0.680412, acc: 57.03%] [G loss: 6.015257]\n",
      "epoch:22 step:17725 [D loss: 0.694775, acc: 54.69%] [G loss: 2.652427]\n",
      "epoch:22 step:17726 [D loss: 0.377069, acc: 88.28%] [G loss: 2.798823]\n",
      "epoch:22 step:17727 [D loss: 0.533182, acc: 77.34%] [G loss: 3.630545]\n",
      "epoch:22 step:17728 [D loss: 0.287400, acc: 96.88%] [G loss: 3.689835]\n",
      "epoch:22 step:17729 [D loss: 0.334652, acc: 87.50%] [G loss: 3.796146]\n",
      "epoch:22 step:17730 [D loss: 0.487498, acc: 77.34%] [G loss: 4.120047]\n",
      "epoch:22 step:17731 [D loss: 0.318281, acc: 90.62%] [G loss: 3.642808]\n",
      "epoch:22 step:17732 [D loss: 0.615023, acc: 62.50%] [G loss: 2.474672]\n",
      "epoch:22 step:17733 [D loss: 0.293918, acc: 95.31%] [G loss: 3.327938]\n",
      "epoch:22 step:17734 [D loss: 0.960958, acc: 28.12%] [G loss: 1.454486]\n",
      "epoch:22 step:17735 [D loss: 0.477391, acc: 85.16%] [G loss: 4.881435]\n",
      "epoch:22 step:17736 [D loss: 0.689253, acc: 53.12%] [G loss: 2.585170]\n",
      "epoch:22 step:17737 [D loss: 0.189161, acc: 98.44%] [G loss: 4.168608]\n",
      "epoch:22 step:17738 [D loss: 0.421061, acc: 74.22%] [G loss: 4.682811]\n",
      "epoch:22 step:17739 [D loss: 0.603031, acc: 64.84%] [G loss: 3.645545]\n",
      "epoch:22 step:17740 [D loss: 0.606477, acc: 68.75%] [G loss: 3.322964]\n",
      "epoch:22 step:17741 [D loss: 0.264064, acc: 92.97%] [G loss: 3.409493]\n",
      "epoch:22 step:17742 [D loss: 0.316860, acc: 94.53%] [G loss: 3.470050]\n",
      "epoch:22 step:17743 [D loss: 0.440522, acc: 81.25%] [G loss: 3.028187]\n",
      "epoch:22 step:17744 [D loss: 0.172142, acc: 97.66%] [G loss: 4.655342]\n",
      "epoch:22 step:17745 [D loss: 0.773613, acc: 51.56%] [G loss: 2.276902]\n",
      "epoch:22 step:17746 [D loss: 0.264424, acc: 96.88%] [G loss: 4.738318]\n",
      "epoch:22 step:17747 [D loss: 0.421009, acc: 87.50%] [G loss: 4.434237]\n",
      "epoch:22 step:17748 [D loss: 0.276130, acc: 95.31%] [G loss: 3.024776]\n",
      "epoch:22 step:17749 [D loss: 0.809838, acc: 40.62%] [G loss: 3.321639]\n",
      "epoch:22 step:17750 [D loss: 0.390113, acc: 88.28%] [G loss: 2.969303]\n",
      "epoch:22 step:17751 [D loss: 0.270665, acc: 98.44%] [G loss: 3.851430]\n",
      "epoch:22 step:17752 [D loss: 0.369387, acc: 82.03%] [G loss: 2.912147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17753 [D loss: 0.638614, acc: 63.28%] [G loss: 2.471098]\n",
      "epoch:22 step:17754 [D loss: 0.352632, acc: 92.19%] [G loss: 3.135617]\n",
      "epoch:22 step:17755 [D loss: 0.546276, acc: 72.66%] [G loss: 3.603292]\n",
      "epoch:22 step:17756 [D loss: 0.898362, acc: 38.28%] [G loss: 3.164572]\n",
      "epoch:22 step:17757 [D loss: 0.502774, acc: 78.91%] [G loss: 3.688282]\n",
      "epoch:22 step:17758 [D loss: 0.673065, acc: 54.69%] [G loss: 2.234133]\n",
      "epoch:22 step:17759 [D loss: 0.417012, acc: 82.81%] [G loss: 3.335254]\n",
      "epoch:22 step:17760 [D loss: 0.560486, acc: 64.84%] [G loss: 2.134594]\n",
      "epoch:22 step:17761 [D loss: 0.751551, acc: 52.34%] [G loss: 3.719586]\n",
      "epoch:22 step:17762 [D loss: 0.601104, acc: 64.06%] [G loss: 4.937123]\n",
      "epoch:22 step:17763 [D loss: 0.518137, acc: 67.19%] [G loss: 3.906574]\n",
      "epoch:22 step:17764 [D loss: 0.330885, acc: 93.75%] [G loss: 2.206719]\n",
      "epoch:22 step:17765 [D loss: 0.789275, acc: 49.22%] [G loss: 3.820885]\n",
      "epoch:22 step:17766 [D loss: 0.262281, acc: 93.75%] [G loss: 4.025126]\n",
      "epoch:22 step:17767 [D loss: 0.482734, acc: 76.56%] [G loss: 3.771059]\n",
      "epoch:22 step:17768 [D loss: 0.326402, acc: 93.75%] [G loss: 4.093160]\n",
      "epoch:22 step:17769 [D loss: 0.628881, acc: 65.62%] [G loss: 3.315598]\n",
      "epoch:22 step:17770 [D loss: 0.697911, acc: 57.03%] [G loss: 3.027386]\n",
      "epoch:22 step:17771 [D loss: 0.707100, acc: 60.16%] [G loss: 3.471335]\n",
      "epoch:22 step:17772 [D loss: 0.286268, acc: 93.75%] [G loss: 3.049474]\n",
      "epoch:22 step:17773 [D loss: 0.626095, acc: 63.28%] [G loss: 4.225997]\n",
      "epoch:22 step:17774 [D loss: 0.788222, acc: 53.12%] [G loss: 3.438073]\n",
      "epoch:22 step:17775 [D loss: 0.418675, acc: 84.38%] [G loss: 3.011108]\n",
      "epoch:22 step:17776 [D loss: 0.278537, acc: 97.66%] [G loss: 3.335564]\n",
      "epoch:22 step:17777 [D loss: 0.831444, acc: 43.75%] [G loss: 3.681866]\n",
      "epoch:22 step:17778 [D loss: 0.854411, acc: 50.78%] [G loss: 2.835617]\n",
      "epoch:22 step:17779 [D loss: 0.352109, acc: 89.84%] [G loss: 3.328437]\n",
      "epoch:22 step:17780 [D loss: 0.914637, acc: 49.22%] [G loss: 4.340585]\n",
      "epoch:22 step:17781 [D loss: 0.190414, acc: 98.44%] [G loss: 3.990220]\n",
      "epoch:22 step:17782 [D loss: 0.199102, acc: 99.22%] [G loss: 3.337871]\n",
      "epoch:22 step:17783 [D loss: 0.338783, acc: 86.72%] [G loss: 3.428073]\n",
      "epoch:22 step:17784 [D loss: 0.641935, acc: 65.62%] [G loss: 3.214338]\n",
      "epoch:22 step:17785 [D loss: 1.139936, acc: 27.34%] [G loss: 2.321346]\n",
      "epoch:22 step:17786 [D loss: 0.289392, acc: 92.97%] [G loss: 3.555346]\n",
      "epoch:22 step:17787 [D loss: 0.282860, acc: 92.97%] [G loss: 2.796949]\n",
      "epoch:22 step:17788 [D loss: 0.339926, acc: 89.84%] [G loss: 3.164347]\n",
      "epoch:22 step:17789 [D loss: 0.667494, acc: 60.16%] [G loss: 2.681076]\n",
      "epoch:22 step:17790 [D loss: 0.728076, acc: 56.25%] [G loss: 4.013492]\n",
      "epoch:22 step:17791 [D loss: 0.149472, acc: 99.22%] [G loss: 3.192574]\n",
      "epoch:22 step:17792 [D loss: 0.722420, acc: 55.47%] [G loss: 3.040447]\n",
      "epoch:22 step:17793 [D loss: 0.434286, acc: 81.25%] [G loss: 2.286899]\n",
      "epoch:22 step:17794 [D loss: 0.704701, acc: 53.12%] [G loss: 4.016527]\n",
      "epoch:22 step:17795 [D loss: 0.664893, acc: 64.06%] [G loss: 2.892920]\n",
      "epoch:22 step:17796 [D loss: 0.328461, acc: 92.19%] [G loss: 3.365652]\n",
      "epoch:22 step:17797 [D loss: 0.491120, acc: 82.81%] [G loss: 2.001243]\n",
      "epoch:22 step:17798 [D loss: 0.593105, acc: 60.16%] [G loss: 3.362776]\n",
      "epoch:22 step:17799 [D loss: 0.852569, acc: 39.06%] [G loss: 2.963202]\n",
      "epoch:22 step:17800 [D loss: 0.648666, acc: 59.38%] [G loss: 3.181795]\n",
      "epoch:22 step:17801 [D loss: 0.600428, acc: 57.81%] [G loss: 4.746644]\n",
      "epoch:22 step:17802 [D loss: 0.268025, acc: 95.31%] [G loss: 2.686071]\n",
      "epoch:22 step:17803 [D loss: 0.593162, acc: 69.53%] [G loss: 2.979975]\n",
      "epoch:22 step:17804 [D loss: 0.891806, acc: 43.75%] [G loss: 2.805350]\n",
      "epoch:22 step:17805 [D loss: 0.568166, acc: 68.75%] [G loss: 3.963665]\n",
      "epoch:22 step:17806 [D loss: 0.590726, acc: 66.41%] [G loss: 4.631297]\n",
      "epoch:22 step:17807 [D loss: 0.252366, acc: 97.66%] [G loss: 3.974041]\n",
      "epoch:22 step:17808 [D loss: 0.965365, acc: 28.12%] [G loss: 3.691329]\n",
      "epoch:22 step:17809 [D loss: 0.479998, acc: 70.31%] [G loss: 2.958113]\n",
      "epoch:22 step:17810 [D loss: 0.213925, acc: 98.44%] [G loss: 4.841921]\n",
      "epoch:22 step:17811 [D loss: 0.198956, acc: 99.22%] [G loss: 3.186868]\n",
      "epoch:22 step:17812 [D loss: 0.411818, acc: 71.09%] [G loss: 3.942148]\n",
      "epoch:22 step:17813 [D loss: 0.422314, acc: 89.84%] [G loss: 3.486896]\n",
      "epoch:22 step:17814 [D loss: 1.157478, acc: 16.41%] [G loss: 3.040780]\n",
      "epoch:22 step:17815 [D loss: 0.399320, acc: 89.06%] [G loss: 3.038521]\n",
      "epoch:22 step:17816 [D loss: 0.512110, acc: 68.75%] [G loss: 4.472497]\n",
      "epoch:22 step:17817 [D loss: 0.277803, acc: 97.66%] [G loss: 4.562766]\n",
      "epoch:22 step:17818 [D loss: 0.340247, acc: 89.84%] [G loss: 4.356242]\n",
      "epoch:22 step:17819 [D loss: 0.348901, acc: 92.19%] [G loss: 2.616734]\n",
      "epoch:22 step:17820 [D loss: 0.688733, acc: 58.59%] [G loss: 3.180734]\n",
      "epoch:22 step:17821 [D loss: 0.366594, acc: 85.16%] [G loss: 4.533078]\n",
      "epoch:22 step:17822 [D loss: 1.044581, acc: 51.56%] [G loss: 4.123772]\n",
      "epoch:22 step:17823 [D loss: 0.256119, acc: 94.53%] [G loss: 4.029032]\n",
      "epoch:22 step:17824 [D loss: 1.163485, acc: 26.56%] [G loss: 4.083638]\n",
      "epoch:22 step:17825 [D loss: 0.198123, acc: 100.00%] [G loss: 4.599740]\n",
      "epoch:22 step:17826 [D loss: 0.144014, acc: 99.22%] [G loss: 3.881802]\n",
      "epoch:22 step:17827 [D loss: 1.401437, acc: 45.31%] [G loss: 1.493867]\n",
      "epoch:22 step:17828 [D loss: 0.231657, acc: 99.22%] [G loss: 4.724085]\n",
      "epoch:22 step:17829 [D loss: 0.795450, acc: 49.22%] [G loss: 3.200831]\n",
      "epoch:22 step:17830 [D loss: 0.503589, acc: 71.88%] [G loss: 3.683459]\n",
      "epoch:22 step:17831 [D loss: 0.608571, acc: 66.41%] [G loss: 2.736394]\n",
      "epoch:22 step:17832 [D loss: 0.259913, acc: 96.88%] [G loss: 2.811462]\n",
      "epoch:22 step:17833 [D loss: 1.046665, acc: 45.31%] [G loss: 2.852655]\n",
      "epoch:22 step:17834 [D loss: 0.328056, acc: 89.84%] [G loss: 3.926105]\n",
      "epoch:22 step:17835 [D loss: 0.269666, acc: 95.31%] [G loss: 2.764124]\n",
      "epoch:22 step:17836 [D loss: 0.283996, acc: 93.75%] [G loss: 3.437334]\n",
      "epoch:22 step:17837 [D loss: 0.114725, acc: 100.00%] [G loss: 4.596067]\n",
      "epoch:22 step:17838 [D loss: 0.719464, acc: 55.47%] [G loss: 3.147048]\n",
      "epoch:22 step:17839 [D loss: 0.116341, acc: 99.22%] [G loss: 3.564304]\n",
      "epoch:22 step:17840 [D loss: 0.357014, acc: 88.28%] [G loss: 2.770010]\n",
      "epoch:22 step:17841 [D loss: 0.278748, acc: 94.53%] [G loss: 3.949923]\n",
      "epoch:22 step:17842 [D loss: 0.444198, acc: 85.94%] [G loss: 3.507465]\n",
      "epoch:22 step:17843 [D loss: 0.848359, acc: 52.34%] [G loss: 3.774618]\n",
      "epoch:22 step:17844 [D loss: 0.441582, acc: 70.31%] [G loss: 3.276930]\n",
      "epoch:22 step:17845 [D loss: 0.307702, acc: 95.31%] [G loss: 4.564609]\n",
      "epoch:22 step:17846 [D loss: 0.611479, acc: 64.84%] [G loss: 5.358758]\n",
      "epoch:22 step:17847 [D loss: 0.945223, acc: 35.16%] [G loss: 2.360985]\n",
      "epoch:22 step:17848 [D loss: 0.643698, acc: 64.84%] [G loss: 2.108218]\n",
      "epoch:22 step:17849 [D loss: 0.389902, acc: 89.06%] [G loss: 4.353825]\n",
      "epoch:22 step:17850 [D loss: 0.468731, acc: 80.47%] [G loss: 3.230347]\n",
      "epoch:22 step:17851 [D loss: 0.391050, acc: 81.25%] [G loss: 2.740684]\n",
      "epoch:22 step:17852 [D loss: 0.370069, acc: 86.72%] [G loss: 2.354058]\n",
      "epoch:22 step:17853 [D loss: 0.749354, acc: 50.00%] [G loss: 2.828197]\n",
      "epoch:22 step:17854 [D loss: 0.275109, acc: 95.31%] [G loss: 3.663407]\n",
      "epoch:22 step:17855 [D loss: 0.568574, acc: 71.88%] [G loss: 3.259732]\n",
      "epoch:22 step:17856 [D loss: 0.538004, acc: 73.44%] [G loss: 2.653173]\n",
      "epoch:22 step:17857 [D loss: 0.456639, acc: 89.06%] [G loss: 3.181858]\n",
      "epoch:22 step:17858 [D loss: 0.609309, acc: 71.09%] [G loss: 3.515854]\n",
      "epoch:22 step:17859 [D loss: 0.127061, acc: 100.00%] [G loss: 3.118831]\n",
      "epoch:22 step:17860 [D loss: 0.474226, acc: 77.34%] [G loss: 3.256221]\n",
      "epoch:22 step:17861 [D loss: 0.758173, acc: 58.59%] [G loss: 2.762890]\n",
      "epoch:22 step:17862 [D loss: 0.293059, acc: 92.97%] [G loss: 3.994692]\n",
      "epoch:22 step:17863 [D loss: 0.253006, acc: 97.66%] [G loss: 3.969441]\n",
      "epoch:22 step:17864 [D loss: 0.599740, acc: 61.72%] [G loss: 4.248324]\n",
      "epoch:22 step:17865 [D loss: 0.487194, acc: 78.12%] [G loss: 3.484402]\n",
      "epoch:22 step:17866 [D loss: 0.326525, acc: 96.09%] [G loss: 2.677874]\n",
      "epoch:22 step:17867 [D loss: 0.906560, acc: 39.84%] [G loss: 4.023564]\n",
      "epoch:22 step:17868 [D loss: 0.770240, acc: 49.22%] [G loss: 2.721944]\n",
      "epoch:22 step:17869 [D loss: 0.666863, acc: 61.72%] [G loss: 3.087794]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17870 [D loss: 0.330632, acc: 92.19%] [G loss: 3.195859]\n",
      "epoch:22 step:17871 [D loss: 0.381911, acc: 82.03%] [G loss: 3.117274]\n",
      "epoch:22 step:17872 [D loss: 0.060070, acc: 100.00%] [G loss: 4.076191]\n",
      "epoch:22 step:17873 [D loss: 1.316964, acc: 46.88%] [G loss: 5.466506]\n",
      "epoch:22 step:17874 [D loss: 0.585792, acc: 68.75%] [G loss: 4.278407]\n",
      "epoch:22 step:17875 [D loss: 0.085277, acc: 100.00%] [G loss: 5.175156]\n",
      "epoch:22 step:17876 [D loss: 0.443945, acc: 68.75%] [G loss: 3.269756]\n",
      "epoch:22 step:17877 [D loss: 0.761601, acc: 56.25%] [G loss: 3.378634]\n",
      "epoch:22 step:17878 [D loss: 0.387480, acc: 82.03%] [G loss: 3.925130]\n",
      "epoch:22 step:17879 [D loss: 0.305796, acc: 85.94%] [G loss: 3.504665]\n",
      "epoch:22 step:17880 [D loss: 0.482046, acc: 71.09%] [G loss: 3.722782]\n",
      "epoch:22 step:17881 [D loss: 1.436292, acc: 48.44%] [G loss: 1.845844]\n",
      "epoch:22 step:17882 [D loss: 0.240986, acc: 96.88%] [G loss: 4.763571]\n",
      "epoch:22 step:17883 [D loss: 0.923384, acc: 39.06%] [G loss: 2.235405]\n",
      "epoch:22 step:17884 [D loss: 0.231693, acc: 95.31%] [G loss: 3.786765]\n",
      "epoch:22 step:17885 [D loss: 0.853226, acc: 49.22%] [G loss: 3.093046]\n",
      "epoch:22 step:17886 [D loss: 0.377555, acc: 86.72%] [G loss: 4.315967]\n",
      "epoch:22 step:17887 [D loss: 0.492334, acc: 82.03%] [G loss: 4.347784]\n",
      "epoch:22 step:17888 [D loss: 0.283805, acc: 97.66%] [G loss: 3.146121]\n",
      "epoch:22 step:17889 [D loss: 0.606107, acc: 67.19%] [G loss: 2.093668]\n",
      "epoch:22 step:17890 [D loss: 0.397675, acc: 80.47%] [G loss: 4.579794]\n",
      "epoch:22 step:17891 [D loss: 0.594851, acc: 75.78%] [G loss: 3.257292]\n",
      "epoch:22 step:17892 [D loss: 0.539132, acc: 70.31%] [G loss: 3.363715]\n",
      "epoch:22 step:17893 [D loss: 0.157826, acc: 98.44%] [G loss: 4.153397]\n",
      "epoch:22 step:17894 [D loss: 0.354202, acc: 88.28%] [G loss: 3.884176]\n",
      "epoch:22 step:17895 [D loss: 0.278274, acc: 96.88%] [G loss: 3.753453]\n",
      "epoch:22 step:17896 [D loss: 0.841995, acc: 50.78%] [G loss: 1.950360]\n",
      "epoch:22 step:17897 [D loss: 0.595390, acc: 64.84%] [G loss: 3.151593]\n",
      "epoch:22 step:17898 [D loss: 0.934408, acc: 33.59%] [G loss: 2.567456]\n",
      "epoch:22 step:17899 [D loss: 0.365819, acc: 92.19%] [G loss: 2.657887]\n",
      "epoch:22 step:17900 [D loss: 0.608808, acc: 67.19%] [G loss: 2.559279]\n",
      "epoch:22 step:17901 [D loss: 0.359106, acc: 96.09%] [G loss: 3.177170]\n",
      "epoch:22 step:17902 [D loss: 1.212525, acc: 23.44%] [G loss: 3.071280]\n",
      "epoch:22 step:17903 [D loss: 0.657249, acc: 62.50%] [G loss: 3.103548]\n",
      "epoch:22 step:17904 [D loss: 0.191125, acc: 97.66%] [G loss: 3.087074]\n",
      "epoch:22 step:17905 [D loss: 0.087083, acc: 100.00%] [G loss: 4.178143]\n",
      "epoch:22 step:17906 [D loss: 0.598734, acc: 63.28%] [G loss: 3.990018]\n",
      "epoch:22 step:17907 [D loss: 0.781918, acc: 48.44%] [G loss: 2.714319]\n",
      "epoch:22 step:17908 [D loss: 0.400945, acc: 89.06%] [G loss: 4.102367]\n",
      "epoch:22 step:17909 [D loss: 1.065886, acc: 18.75%] [G loss: 2.199718]\n",
      "epoch:22 step:17910 [D loss: 0.714560, acc: 55.47%] [G loss: 2.420828]\n",
      "epoch:22 step:17911 [D loss: 0.372310, acc: 91.41%] [G loss: 3.264155]\n",
      "epoch:22 step:17912 [D loss: 0.602044, acc: 70.31%] [G loss: 3.381929]\n",
      "epoch:22 step:17913 [D loss: 0.284214, acc: 96.88%] [G loss: 3.559118]\n",
      "epoch:22 step:17914 [D loss: 0.425301, acc: 85.16%] [G loss: 2.566558]\n",
      "epoch:22 step:17915 [D loss: 0.473700, acc: 80.47%] [G loss: 3.385140]\n",
      "epoch:22 step:17916 [D loss: 0.402641, acc: 87.50%] [G loss: 2.562648]\n",
      "epoch:22 step:17917 [D loss: 0.409789, acc: 78.91%] [G loss: 4.053370]\n",
      "epoch:22 step:17918 [D loss: 0.234498, acc: 91.41%] [G loss: 5.956421]\n",
      "epoch:22 step:17919 [D loss: 0.776266, acc: 54.69%] [G loss: 4.450286]\n",
      "epoch:22 step:17920 [D loss: 0.570118, acc: 70.31%] [G loss: 3.227825]\n",
      "epoch:22 step:17921 [D loss: 0.514672, acc: 74.22%] [G loss: 3.507610]\n",
      "epoch:22 step:17922 [D loss: 0.181937, acc: 100.00%] [G loss: 3.120230]\n",
      "epoch:22 step:17923 [D loss: 0.352763, acc: 85.16%] [G loss: 5.315114]\n",
      "epoch:22 step:17924 [D loss: 0.542370, acc: 64.06%] [G loss: 4.076034]\n",
      "epoch:22 step:17925 [D loss: 0.368617, acc: 89.84%] [G loss: 3.251714]\n",
      "epoch:22 step:17926 [D loss: 0.680633, acc: 57.03%] [G loss: 2.292504]\n",
      "epoch:22 step:17927 [D loss: 0.526052, acc: 76.56%] [G loss: 3.708825]\n",
      "epoch:22 step:17928 [D loss: 0.455258, acc: 77.34%] [G loss: 3.335193]\n",
      "epoch:22 step:17929 [D loss: 0.581164, acc: 67.97%] [G loss: 5.304104]\n",
      "epoch:22 step:17930 [D loss: 0.416910, acc: 89.06%] [G loss: 2.427069]\n",
      "epoch:22 step:17931 [D loss: 0.528703, acc: 69.53%] [G loss: 3.994514]\n",
      "epoch:22 step:17932 [D loss: 0.614482, acc: 69.53%] [G loss: 3.465983]\n",
      "epoch:22 step:17933 [D loss: 1.114974, acc: 22.66%] [G loss: 2.602413]\n",
      "epoch:22 step:17934 [D loss: 0.532228, acc: 71.88%] [G loss: 2.105989]\n",
      "epoch:22 step:17935 [D loss: 0.404642, acc: 85.16%] [G loss: 4.569064]\n",
      "epoch:22 step:17936 [D loss: 0.716029, acc: 59.38%] [G loss: 4.755694]\n",
      "epoch:22 step:17937 [D loss: 0.343015, acc: 91.41%] [G loss: 4.145409]\n",
      "epoch:22 step:17938 [D loss: 1.306513, acc: 48.44%] [G loss: 3.118867]\n",
      "epoch:22 step:17939 [D loss: 0.550548, acc: 69.53%] [G loss: 3.817802]\n",
      "epoch:22 step:17940 [D loss: 0.516492, acc: 80.47%] [G loss: 3.782207]\n",
      "epoch:22 step:17941 [D loss: 0.662246, acc: 59.38%] [G loss: 3.419624]\n",
      "epoch:22 step:17942 [D loss: 0.070255, acc: 100.00%] [G loss: 5.061335]\n",
      "epoch:22 step:17943 [D loss: 0.298217, acc: 96.09%] [G loss: 3.968294]\n",
      "epoch:22 step:17944 [D loss: 0.135249, acc: 97.66%] [G loss: 4.882926]\n",
      "epoch:22 step:17945 [D loss: 0.524611, acc: 67.19%] [G loss: 3.339509]\n",
      "epoch:22 step:17946 [D loss: 0.167138, acc: 99.22%] [G loss: 3.729497]\n",
      "epoch:22 step:17947 [D loss: 0.552077, acc: 69.53%] [G loss: 3.437622]\n",
      "epoch:22 step:17948 [D loss: 0.250006, acc: 96.88%] [G loss: 3.491490]\n",
      "epoch:22 step:17949 [D loss: 0.368350, acc: 90.62%] [G loss: 4.071026]\n",
      "epoch:22 step:17950 [D loss: 0.339823, acc: 93.75%] [G loss: 5.287337]\n",
      "epoch:22 step:17951 [D loss: 0.584520, acc: 57.03%] [G loss: 5.839703]\n",
      "epoch:22 step:17952 [D loss: 0.484299, acc: 71.09%] [G loss: 4.769914]\n",
      "epoch:22 step:17953 [D loss: 0.159926, acc: 100.00%] [G loss: 2.974907]\n",
      "epoch:22 step:17954 [D loss: 0.941122, acc: 37.50%] [G loss: 3.314434]\n",
      "epoch:22 step:17955 [D loss: 0.251988, acc: 91.41%] [G loss: 5.696706]\n",
      "epoch:22 step:17956 [D loss: 0.163647, acc: 98.44%] [G loss: 5.002664]\n",
      "epoch:22 step:17957 [D loss: 0.310725, acc: 92.19%] [G loss: 3.621707]\n",
      "epoch:22 step:17958 [D loss: 0.396504, acc: 78.91%] [G loss: 3.572819]\n",
      "epoch:22 step:17959 [D loss: 0.874357, acc: 52.34%] [G loss: 3.360351]\n",
      "epoch:22 step:17960 [D loss: 0.818740, acc: 49.22%] [G loss: 2.661865]\n",
      "epoch:22 step:17961 [D loss: 0.562669, acc: 71.88%] [G loss: 5.416553]\n",
      "epoch:22 step:17962 [D loss: 0.251166, acc: 92.19%] [G loss: 3.146865]\n",
      "epoch:22 step:17963 [D loss: 0.349607, acc: 93.75%] [G loss: 3.698919]\n",
      "epoch:23 step:17964 [D loss: 0.587399, acc: 70.31%] [G loss: 3.563180]\n",
      "epoch:23 step:17965 [D loss: 0.181930, acc: 99.22%] [G loss: 3.956133]\n",
      "epoch:23 step:17966 [D loss: 0.865676, acc: 37.50%] [G loss: 3.377285]\n",
      "epoch:23 step:17967 [D loss: 0.775600, acc: 53.12%] [G loss: 2.614146]\n",
      "epoch:23 step:17968 [D loss: 0.237532, acc: 96.09%] [G loss: 2.538973]\n",
      "epoch:23 step:17969 [D loss: 0.295631, acc: 92.97%] [G loss: 3.148684]\n",
      "epoch:23 step:17970 [D loss: 0.796614, acc: 52.34%] [G loss: 4.643286]\n",
      "epoch:23 step:17971 [D loss: 0.437154, acc: 87.50%] [G loss: 3.469834]\n",
      "epoch:23 step:17972 [D loss: 0.347130, acc: 85.94%] [G loss: 3.097209]\n",
      "epoch:23 step:17973 [D loss: 0.534759, acc: 71.88%] [G loss: 4.425201]\n",
      "epoch:23 step:17974 [D loss: 0.523646, acc: 77.34%] [G loss: 2.541154]\n",
      "epoch:23 step:17975 [D loss: 0.510439, acc: 69.53%] [G loss: 3.393493]\n",
      "epoch:23 step:17976 [D loss: 0.249351, acc: 96.09%] [G loss: 4.055517]\n",
      "epoch:23 step:17977 [D loss: 0.647098, acc: 64.06%] [G loss: 2.786499]\n",
      "epoch:23 step:17978 [D loss: 0.592405, acc: 74.22%] [G loss: 3.885227]\n",
      "epoch:23 step:17979 [D loss: 0.549478, acc: 66.41%] [G loss: 3.275053]\n",
      "epoch:23 step:17980 [D loss: 0.172415, acc: 99.22%] [G loss: 4.837099]\n",
      "epoch:23 step:17981 [D loss: 0.334526, acc: 92.97%] [G loss: 3.251570]\n",
      "epoch:23 step:17982 [D loss: 0.846266, acc: 52.34%] [G loss: 1.993625]\n",
      "epoch:23 step:17983 [D loss: 0.872134, acc: 51.56%] [G loss: 3.278871]\n",
      "epoch:23 step:17984 [D loss: 0.640124, acc: 61.72%] [G loss: 2.920043]\n",
      "epoch:23 step:17985 [D loss: 0.466965, acc: 81.25%] [G loss: 4.394310]\n",
      "epoch:23 step:17986 [D loss: 0.287472, acc: 91.41%] [G loss: 3.739822]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:17987 [D loss: 0.383610, acc: 89.06%] [G loss: 5.576345]\n",
      "epoch:23 step:17988 [D loss: 0.369761, acc: 92.97%] [G loss: 3.271976]\n",
      "epoch:23 step:17989 [D loss: 1.325784, acc: 17.19%] [G loss: 3.014255]\n",
      "epoch:23 step:17990 [D loss: 0.648144, acc: 60.16%] [G loss: 2.337095]\n",
      "epoch:23 step:17991 [D loss: 0.666634, acc: 59.38%] [G loss: 3.071504]\n",
      "epoch:23 step:17992 [D loss: 0.337919, acc: 92.97%] [G loss: 2.788747]\n",
      "epoch:23 step:17993 [D loss: 0.183969, acc: 100.00%] [G loss: 4.127659]\n",
      "epoch:23 step:17994 [D loss: 0.380112, acc: 78.12%] [G loss: 5.108532]\n",
      "epoch:23 step:17995 [D loss: 0.208330, acc: 96.88%] [G loss: 4.469777]\n",
      "epoch:23 step:17996 [D loss: 0.291942, acc: 93.75%] [G loss: 4.182154]\n",
      "epoch:23 step:17997 [D loss: 0.422583, acc: 73.44%] [G loss: 2.931643]\n",
      "epoch:23 step:17998 [D loss: 0.294470, acc: 89.84%] [G loss: 4.380297]\n",
      "epoch:23 step:17999 [D loss: 0.149153, acc: 100.00%] [G loss: 2.829050]\n",
      "epoch:23 step:18000 [D loss: 0.655916, acc: 61.72%] [G loss: 4.009773]\n",
      "epoch:23 step:18001 [D loss: 0.386250, acc: 86.72%] [G loss: 5.139815]\n",
      "epoch:23 step:18002 [D loss: 0.383232, acc: 89.84%] [G loss: 3.159439]\n",
      "epoch:23 step:18003 [D loss: 0.817004, acc: 40.62%] [G loss: 3.477663]\n",
      "epoch:23 step:18004 [D loss: 0.162208, acc: 100.00%] [G loss: 3.799372]\n",
      "epoch:23 step:18005 [D loss: 0.627225, acc: 63.28%] [G loss: 2.928047]\n",
      "epoch:23 step:18006 [D loss: 0.345469, acc: 93.75%] [G loss: 2.569047]\n",
      "epoch:23 step:18007 [D loss: 0.555451, acc: 74.22%] [G loss: 2.697698]\n",
      "epoch:23 step:18008 [D loss: 0.290892, acc: 94.53%] [G loss: 3.000350]\n",
      "epoch:23 step:18009 [D loss: 0.222627, acc: 95.31%] [G loss: 4.521525]\n",
      "epoch:23 step:18010 [D loss: 0.648590, acc: 62.50%] [G loss: 2.891646]\n",
      "epoch:23 step:18011 [D loss: 0.750408, acc: 56.25%] [G loss: 3.844609]\n",
      "epoch:23 step:18012 [D loss: 0.319076, acc: 89.06%] [G loss: 2.204645]\n",
      "epoch:23 step:18013 [D loss: 0.490292, acc: 79.69%] [G loss: 2.469924]\n",
      "epoch:23 step:18014 [D loss: 0.436117, acc: 84.38%] [G loss: 2.859264]\n",
      "epoch:23 step:18015 [D loss: 0.362417, acc: 92.97%] [G loss: 2.613854]\n",
      "epoch:23 step:18016 [D loss: 0.696774, acc: 57.81%] [G loss: 5.225260]\n",
      "epoch:23 step:18017 [D loss: 0.760150, acc: 50.00%] [G loss: 3.581898]\n",
      "epoch:23 step:18018 [D loss: 0.360571, acc: 91.41%] [G loss: 5.707706]\n",
      "epoch:23 step:18019 [D loss: 0.361783, acc: 94.53%] [G loss: 2.648822]\n",
      "epoch:23 step:18020 [D loss: 0.294647, acc: 92.19%] [G loss: 3.728830]\n",
      "epoch:23 step:18021 [D loss: 0.565741, acc: 70.31%] [G loss: 2.970676]\n",
      "epoch:23 step:18022 [D loss: 0.162450, acc: 99.22%] [G loss: 3.188988]\n",
      "epoch:23 step:18023 [D loss: 0.156005, acc: 100.00%] [G loss: 4.191721]\n",
      "epoch:23 step:18024 [D loss: 0.462046, acc: 83.59%] [G loss: 3.859463]\n",
      "epoch:23 step:18025 [D loss: 0.836657, acc: 43.75%] [G loss: 4.031170]\n",
      "epoch:23 step:18026 [D loss: 0.109239, acc: 100.00%] [G loss: 3.082744]\n",
      "epoch:23 step:18027 [D loss: 0.909021, acc: 36.72%] [G loss: 3.614604]\n",
      "epoch:23 step:18028 [D loss: 0.728650, acc: 51.56%] [G loss: 3.951105]\n",
      "epoch:23 step:18029 [D loss: 1.387557, acc: 12.50%] [G loss: 3.085887]\n",
      "epoch:23 step:18030 [D loss: 0.678512, acc: 60.94%] [G loss: 2.452551]\n",
      "epoch:23 step:18031 [D loss: 0.358484, acc: 92.97%] [G loss: 3.597384]\n",
      "epoch:23 step:18032 [D loss: 0.388455, acc: 86.72%] [G loss: 3.164461]\n",
      "epoch:23 step:18033 [D loss: 0.594833, acc: 75.00%] [G loss: 3.920351]\n",
      "epoch:23 step:18034 [D loss: 1.082960, acc: 17.19%] [G loss: 2.161713]\n",
      "epoch:23 step:18035 [D loss: 0.242885, acc: 96.09%] [G loss: 2.906515]\n",
      "epoch:23 step:18036 [D loss: 0.450339, acc: 88.28%] [G loss: 3.882540]\n",
      "epoch:23 step:18037 [D loss: 0.390955, acc: 85.94%] [G loss: 3.125468]\n",
      "epoch:23 step:18038 [D loss: 0.561003, acc: 61.72%] [G loss: 3.061761]\n",
      "epoch:23 step:18039 [D loss: 0.109775, acc: 100.00%] [G loss: 4.657904]\n",
      "epoch:23 step:18040 [D loss: 0.737068, acc: 49.22%] [G loss: 5.058839]\n",
      "epoch:23 step:18041 [D loss: 0.597710, acc: 65.62%] [G loss: 3.358490]\n",
      "epoch:23 step:18042 [D loss: 0.284231, acc: 89.84%] [G loss: 3.793510]\n",
      "epoch:23 step:18043 [D loss: 0.569845, acc: 67.19%] [G loss: 3.770498]\n",
      "epoch:23 step:18044 [D loss: 0.648892, acc: 61.72%] [G loss: 4.288400]\n",
      "epoch:23 step:18045 [D loss: 0.387246, acc: 87.50%] [G loss: 3.052602]\n",
      "epoch:23 step:18046 [D loss: 0.379537, acc: 85.94%] [G loss: 3.799606]\n",
      "epoch:23 step:18047 [D loss: 0.260755, acc: 96.09%] [G loss: 2.207565]\n",
      "epoch:23 step:18048 [D loss: 0.271424, acc: 92.97%] [G loss: 4.017560]\n",
      "epoch:23 step:18049 [D loss: 0.355019, acc: 89.06%] [G loss: 3.469805]\n",
      "epoch:23 step:18050 [D loss: 0.249356, acc: 98.44%] [G loss: 3.292346]\n",
      "epoch:23 step:18051 [D loss: 0.352719, acc: 82.81%] [G loss: 4.960614]\n",
      "epoch:23 step:18052 [D loss: 0.419284, acc: 75.78%] [G loss: 4.521679]\n",
      "epoch:23 step:18053 [D loss: 0.618208, acc: 64.84%] [G loss: 3.275958]\n",
      "epoch:23 step:18054 [D loss: 0.418802, acc: 89.84%] [G loss: 3.013273]\n",
      "epoch:23 step:18055 [D loss: 0.273942, acc: 96.88%] [G loss: 3.647760]\n",
      "epoch:23 step:18056 [D loss: 0.773327, acc: 51.56%] [G loss: 3.593812]\n",
      "epoch:23 step:18057 [D loss: 1.175937, acc: 13.28%] [G loss: 2.906544]\n",
      "epoch:23 step:18058 [D loss: 0.436609, acc: 82.81%] [G loss: 3.052308]\n",
      "epoch:23 step:18059 [D loss: 0.263056, acc: 93.75%] [G loss: 3.315006]\n",
      "epoch:23 step:18060 [D loss: 0.697440, acc: 55.47%] [G loss: 4.923275]\n",
      "epoch:23 step:18061 [D loss: 0.871718, acc: 42.97%] [G loss: 2.563664]\n",
      "epoch:23 step:18062 [D loss: 0.378264, acc: 84.38%] [G loss: 4.307189]\n",
      "epoch:23 step:18063 [D loss: 0.613906, acc: 64.84%] [G loss: 3.649386]\n",
      "epoch:23 step:18064 [D loss: 0.432921, acc: 91.41%] [G loss: 2.892229]\n",
      "epoch:23 step:18065 [D loss: 0.490754, acc: 82.03%] [G loss: 2.611236]\n",
      "epoch:23 step:18066 [D loss: 0.568648, acc: 65.62%] [G loss: 3.840350]\n",
      "epoch:23 step:18067 [D loss: 0.381928, acc: 89.84%] [G loss: 3.589705]\n",
      "epoch:23 step:18068 [D loss: 0.687393, acc: 55.47%] [G loss: 1.974871]\n",
      "epoch:23 step:18069 [D loss: 0.658249, acc: 65.62%] [G loss: 4.405229]\n",
      "epoch:23 step:18070 [D loss: 0.293863, acc: 92.19%] [G loss: 2.719179]\n",
      "epoch:23 step:18071 [D loss: 0.637426, acc: 65.62%] [G loss: 3.642046]\n",
      "epoch:23 step:18072 [D loss: 0.289369, acc: 96.09%] [G loss: 1.685969]\n",
      "epoch:23 step:18073 [D loss: 0.236865, acc: 96.09%] [G loss: 4.023741]\n",
      "epoch:23 step:18074 [D loss: 0.308135, acc: 92.19%] [G loss: 4.005816]\n",
      "epoch:23 step:18075 [D loss: 0.290626, acc: 94.53%] [G loss: 3.103318]\n",
      "epoch:23 step:18076 [D loss: 0.437328, acc: 83.59%] [G loss: 4.550565]\n",
      "epoch:23 step:18077 [D loss: 0.399903, acc: 91.41%] [G loss: 3.010115]\n",
      "epoch:23 step:18078 [D loss: 0.441727, acc: 74.22%] [G loss: 3.549056]\n",
      "epoch:23 step:18079 [D loss: 0.280275, acc: 95.31%] [G loss: 3.912202]\n",
      "epoch:23 step:18080 [D loss: 0.499373, acc: 79.69%] [G loss: 2.909396]\n",
      "epoch:23 step:18081 [D loss: 0.675828, acc: 57.03%] [G loss: 3.336109]\n",
      "epoch:23 step:18082 [D loss: 0.608957, acc: 60.16%] [G loss: 3.699799]\n",
      "epoch:23 step:18083 [D loss: 0.604443, acc: 67.19%] [G loss: 4.118722]\n",
      "epoch:23 step:18084 [D loss: 0.417928, acc: 89.84%] [G loss: 3.306946]\n",
      "epoch:23 step:18085 [D loss: 0.165024, acc: 99.22%] [G loss: 4.222925]\n",
      "epoch:23 step:18086 [D loss: 0.391601, acc: 91.41%] [G loss: 3.473208]\n",
      "epoch:23 step:18087 [D loss: 1.102399, acc: 21.09%] [G loss: 3.299147]\n",
      "epoch:23 step:18088 [D loss: 0.825338, acc: 41.41%] [G loss: 3.116830]\n",
      "epoch:23 step:18089 [D loss: 0.650261, acc: 64.06%] [G loss: 3.447254]\n",
      "epoch:23 step:18090 [D loss: 0.110708, acc: 100.00%] [G loss: 5.528229]\n",
      "epoch:23 step:18091 [D loss: 0.723403, acc: 52.34%] [G loss: 2.974634]\n",
      "epoch:23 step:18092 [D loss: 0.352819, acc: 92.97%] [G loss: 3.352998]\n",
      "epoch:23 step:18093 [D loss: 0.514842, acc: 62.50%] [G loss: 4.700733]\n",
      "epoch:23 step:18094 [D loss: 0.558727, acc: 61.72%] [G loss: 4.232855]\n",
      "epoch:23 step:18095 [D loss: 0.300800, acc: 93.75%] [G loss: 2.214036]\n",
      "epoch:23 step:18096 [D loss: 0.835959, acc: 50.00%] [G loss: 2.659918]\n",
      "epoch:23 step:18097 [D loss: 0.160928, acc: 99.22%] [G loss: 4.575442]\n",
      "epoch:23 step:18098 [D loss: 0.386892, acc: 82.81%] [G loss: 4.239409]\n",
      "epoch:23 step:18099 [D loss: 0.294705, acc: 95.31%] [G loss: 3.829658]\n",
      "epoch:23 step:18100 [D loss: 0.415283, acc: 88.28%] [G loss: 4.416028]\n",
      "epoch:23 step:18101 [D loss: 0.591678, acc: 66.41%] [G loss: 3.522679]\n",
      "epoch:23 step:18102 [D loss: 0.666955, acc: 60.16%] [G loss: 3.006117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18103 [D loss: 0.604241, acc: 70.31%] [G loss: 2.555590]\n",
      "epoch:23 step:18104 [D loss: 0.634959, acc: 59.38%] [G loss: 4.406813]\n",
      "epoch:23 step:18105 [D loss: 0.630188, acc: 60.94%] [G loss: 3.064279]\n",
      "epoch:23 step:18106 [D loss: 0.592232, acc: 72.66%] [G loss: 3.582009]\n",
      "epoch:23 step:18107 [D loss: 0.864962, acc: 46.09%] [G loss: 2.412273]\n",
      "epoch:23 step:18108 [D loss: 0.695435, acc: 53.12%] [G loss: 3.138765]\n",
      "epoch:23 step:18109 [D loss: 0.365329, acc: 92.97%] [G loss: 3.747236]\n",
      "epoch:23 step:18110 [D loss: 0.625288, acc: 60.94%] [G loss: 2.737585]\n",
      "epoch:23 step:18111 [D loss: 0.114247, acc: 100.00%] [G loss: 4.026100]\n",
      "epoch:23 step:18112 [D loss: 0.499627, acc: 78.91%] [G loss: 2.534155]\n",
      "epoch:23 step:18113 [D loss: 0.896248, acc: 32.03%] [G loss: 3.097467]\n",
      "epoch:23 step:18114 [D loss: 0.387958, acc: 84.38%] [G loss: 3.520873]\n",
      "epoch:23 step:18115 [D loss: 0.516329, acc: 70.31%] [G loss: 3.180189]\n",
      "epoch:23 step:18116 [D loss: 0.623077, acc: 59.38%] [G loss: 2.450296]\n",
      "epoch:23 step:18117 [D loss: 0.355500, acc: 92.19%] [G loss: 4.436579]\n",
      "epoch:23 step:18118 [D loss: 0.904320, acc: 50.00%] [G loss: 2.935631]\n",
      "epoch:23 step:18119 [D loss: 0.343920, acc: 82.81%] [G loss: 2.929529]\n",
      "epoch:23 step:18120 [D loss: 1.088265, acc: 20.31%] [G loss: 4.075965]\n",
      "epoch:23 step:18121 [D loss: 0.430087, acc: 82.81%] [G loss: 4.145692]\n",
      "epoch:23 step:18122 [D loss: 0.358499, acc: 92.19%] [G loss: 4.271982]\n",
      "epoch:23 step:18123 [D loss: 0.727848, acc: 57.03%] [G loss: 2.324160]\n",
      "epoch:23 step:18124 [D loss: 0.540608, acc: 73.44%] [G loss: 3.747718]\n",
      "epoch:23 step:18125 [D loss: 0.563588, acc: 59.38%] [G loss: 3.540949]\n",
      "epoch:23 step:18126 [D loss: 0.404865, acc: 85.94%] [G loss: 4.441871]\n",
      "epoch:23 step:18127 [D loss: 0.495452, acc: 82.03%] [G loss: 3.736722]\n",
      "epoch:23 step:18128 [D loss: 0.378382, acc: 87.50%] [G loss: 3.812558]\n",
      "epoch:23 step:18129 [D loss: 0.700330, acc: 60.94%] [G loss: 3.069036]\n",
      "epoch:23 step:18130 [D loss: 0.342837, acc: 87.50%] [G loss: 2.618226]\n",
      "epoch:23 step:18131 [D loss: 0.346076, acc: 89.84%] [G loss: 2.452315]\n",
      "epoch:23 step:18132 [D loss: 0.675628, acc: 60.94%] [G loss: 3.078432]\n",
      "epoch:23 step:18133 [D loss: 0.375202, acc: 88.28%] [G loss: 3.488364]\n",
      "epoch:23 step:18134 [D loss: 0.683451, acc: 58.59%] [G loss: 3.666833]\n",
      "epoch:23 step:18135 [D loss: 0.241502, acc: 97.66%] [G loss: 2.160737]\n",
      "epoch:23 step:18136 [D loss: 0.546052, acc: 67.19%] [G loss: 4.262531]\n",
      "epoch:23 step:18137 [D loss: 0.300338, acc: 96.88%] [G loss: 4.477705]\n",
      "epoch:23 step:18138 [D loss: 0.210100, acc: 96.09%] [G loss: 3.663170]\n",
      "epoch:23 step:18139 [D loss: 0.914922, acc: 51.56%] [G loss: 4.868968]\n",
      "epoch:23 step:18140 [D loss: 0.420367, acc: 81.25%] [G loss: 2.555163]\n",
      "epoch:23 step:18141 [D loss: 0.412445, acc: 78.12%] [G loss: 2.757451]\n",
      "epoch:23 step:18142 [D loss: 0.461415, acc: 77.34%] [G loss: 3.667572]\n",
      "epoch:23 step:18143 [D loss: 0.488935, acc: 78.91%] [G loss: 4.716719]\n",
      "epoch:23 step:18144 [D loss: 0.174697, acc: 98.44%] [G loss: 3.440152]\n",
      "epoch:23 step:18145 [D loss: 0.721604, acc: 57.81%] [G loss: 3.015290]\n",
      "epoch:23 step:18146 [D loss: 0.353256, acc: 89.84%] [G loss: 2.988589]\n",
      "epoch:23 step:18147 [D loss: 0.309283, acc: 91.41%] [G loss: 5.048766]\n",
      "epoch:23 step:18148 [D loss: 0.514529, acc: 71.88%] [G loss: 4.598125]\n",
      "epoch:23 step:18149 [D loss: 0.338853, acc: 89.84%] [G loss: 2.764823]\n",
      "epoch:23 step:18150 [D loss: 0.692261, acc: 57.03%] [G loss: 4.770232]\n",
      "epoch:23 step:18151 [D loss: 0.315956, acc: 93.75%] [G loss: 3.701269]\n",
      "epoch:23 step:18152 [D loss: 0.090301, acc: 99.22%] [G loss: 6.605945]\n",
      "epoch:23 step:18153 [D loss: 0.659402, acc: 53.12%] [G loss: 5.463747]\n",
      "epoch:23 step:18154 [D loss: 0.480395, acc: 80.47%] [G loss: 5.094417]\n",
      "epoch:23 step:18155 [D loss: 0.235821, acc: 97.66%] [G loss: 3.540365]\n",
      "epoch:23 step:18156 [D loss: 0.303420, acc: 94.53%] [G loss: 3.271871]\n",
      "epoch:23 step:18157 [D loss: 0.514006, acc: 80.47%] [G loss: 2.993219]\n",
      "epoch:23 step:18158 [D loss: 0.224962, acc: 90.62%] [G loss: 4.750038]\n",
      "epoch:23 step:18159 [D loss: 0.671736, acc: 57.03%] [G loss: 2.416125]\n",
      "epoch:23 step:18160 [D loss: 0.250717, acc: 96.88%] [G loss: 3.883189]\n",
      "epoch:23 step:18161 [D loss: 0.321918, acc: 93.75%] [G loss: 3.606214]\n",
      "epoch:23 step:18162 [D loss: 1.086742, acc: 24.22%] [G loss: 5.688012]\n",
      "epoch:23 step:18163 [D loss: 0.184036, acc: 98.44%] [G loss: 3.409943]\n",
      "epoch:23 step:18164 [D loss: 0.476103, acc: 74.22%] [G loss: 3.040930]\n",
      "epoch:23 step:18165 [D loss: 0.494192, acc: 64.84%] [G loss: 4.450881]\n",
      "epoch:23 step:18166 [D loss: 0.572288, acc: 64.06%] [G loss: 2.772159]\n",
      "epoch:23 step:18167 [D loss: 0.295767, acc: 89.84%] [G loss: 3.373180]\n",
      "epoch:23 step:18168 [D loss: 0.746884, acc: 51.56%] [G loss: 4.427214]\n",
      "epoch:23 step:18169 [D loss: 0.527228, acc: 78.12%] [G loss: 4.444474]\n",
      "epoch:23 step:18170 [D loss: 0.974149, acc: 33.59%] [G loss: 2.688549]\n",
      "epoch:23 step:18171 [D loss: 0.330924, acc: 89.06%] [G loss: 3.978962]\n",
      "epoch:23 step:18172 [D loss: 0.547974, acc: 70.31%] [G loss: 4.009829]\n",
      "epoch:23 step:18173 [D loss: 0.190861, acc: 98.44%] [G loss: 6.275724]\n",
      "epoch:23 step:18174 [D loss: 0.338365, acc: 95.31%] [G loss: 3.874995]\n",
      "epoch:23 step:18175 [D loss: 0.248684, acc: 98.44%] [G loss: 2.823874]\n",
      "epoch:23 step:18176 [D loss: 0.430274, acc: 72.66%] [G loss: 5.784754]\n",
      "epoch:23 step:18177 [D loss: 0.907004, acc: 51.56%] [G loss: 4.807812]\n",
      "epoch:23 step:18178 [D loss: 0.288830, acc: 96.88%] [G loss: 3.773767]\n",
      "epoch:23 step:18179 [D loss: 0.111267, acc: 100.00%] [G loss: 5.140577]\n",
      "epoch:23 step:18180 [D loss: 0.336038, acc: 90.62%] [G loss: 4.380136]\n",
      "epoch:23 step:18181 [D loss: 0.299628, acc: 95.31%] [G loss: 3.253426]\n",
      "epoch:23 step:18182 [D loss: 0.456102, acc: 82.03%] [G loss: 3.425189]\n",
      "epoch:23 step:18183 [D loss: 0.632627, acc: 64.84%] [G loss: 3.375382]\n",
      "epoch:23 step:18184 [D loss: 0.495408, acc: 82.81%] [G loss: 4.238971]\n",
      "epoch:23 step:18185 [D loss: 0.440124, acc: 71.09%] [G loss: 3.816866]\n",
      "epoch:23 step:18186 [D loss: 0.799458, acc: 47.66%] [G loss: 3.356712]\n",
      "epoch:23 step:18187 [D loss: 0.898228, acc: 39.06%] [G loss: 3.886113]\n",
      "epoch:23 step:18188 [D loss: 0.348453, acc: 92.97%] [G loss: 3.171955]\n",
      "epoch:23 step:18189 [D loss: 0.414979, acc: 81.25%] [G loss: 3.393009]\n",
      "epoch:23 step:18190 [D loss: 0.302776, acc: 97.66%] [G loss: 3.481988]\n",
      "epoch:23 step:18191 [D loss: 0.953883, acc: 50.78%] [G loss: 3.581462]\n",
      "epoch:23 step:18192 [D loss: 0.359638, acc: 84.38%] [G loss: 3.306426]\n",
      "epoch:23 step:18193 [D loss: 0.570776, acc: 68.75%] [G loss: 2.586497]\n",
      "epoch:23 step:18194 [D loss: 0.435755, acc: 85.94%] [G loss: 4.228516]\n",
      "epoch:23 step:18195 [D loss: 0.864354, acc: 47.66%] [G loss: 3.163552]\n",
      "epoch:23 step:18196 [D loss: 0.133624, acc: 99.22%] [G loss: 3.904702]\n",
      "epoch:23 step:18197 [D loss: 1.374416, acc: 11.72%] [G loss: 4.343079]\n",
      "epoch:23 step:18198 [D loss: 0.320272, acc: 87.50%] [G loss: 3.580454]\n",
      "epoch:23 step:18199 [D loss: 0.167508, acc: 98.44%] [G loss: 3.741312]\n",
      "epoch:23 step:18200 [D loss: 0.613261, acc: 61.72%] [G loss: 4.552629]\n",
      "epoch:23 step:18201 [D loss: 0.987276, acc: 30.47%] [G loss: 3.012199]\n",
      "epoch:23 step:18202 [D loss: 0.248027, acc: 97.66%] [G loss: 3.973451]\n",
      "epoch:23 step:18203 [D loss: 0.783134, acc: 51.56%] [G loss: 4.364060]\n",
      "epoch:23 step:18204 [D loss: 0.453854, acc: 78.91%] [G loss: 4.155703]\n",
      "epoch:23 step:18205 [D loss: 0.382207, acc: 79.69%] [G loss: 4.111656]\n",
      "epoch:23 step:18206 [D loss: 0.299455, acc: 92.19%] [G loss: 4.432372]\n",
      "epoch:23 step:18207 [D loss: 0.212519, acc: 99.22%] [G loss: 3.976023]\n",
      "epoch:23 step:18208 [D loss: 1.386005, acc: 21.09%] [G loss: 3.057636]\n",
      "epoch:23 step:18209 [D loss: 1.315490, acc: 21.09%] [G loss: 2.934131]\n",
      "epoch:23 step:18210 [D loss: 0.744287, acc: 57.03%] [G loss: 2.378827]\n",
      "epoch:23 step:18211 [D loss: 0.874774, acc: 33.59%] [G loss: 3.304907]\n",
      "epoch:23 step:18212 [D loss: 0.199195, acc: 99.22%] [G loss: 2.736151]\n",
      "epoch:23 step:18213 [D loss: 0.289825, acc: 95.31%] [G loss: 2.568399]\n",
      "epoch:23 step:18214 [D loss: 0.262997, acc: 98.44%] [G loss: 3.999139]\n",
      "epoch:23 step:18215 [D loss: 0.067748, acc: 99.22%] [G loss: 4.150147]\n",
      "epoch:23 step:18216 [D loss: 0.604022, acc: 67.97%] [G loss: 2.678245]\n",
      "epoch:23 step:18217 [D loss: 0.236128, acc: 97.66%] [G loss: 2.639755]\n",
      "epoch:23 step:18218 [D loss: 0.208376, acc: 99.22%] [G loss: 2.843944]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18219 [D loss: 0.469125, acc: 75.00%] [G loss: 2.407525]\n",
      "epoch:23 step:18220 [D loss: 0.744614, acc: 49.22%] [G loss: 2.534602]\n",
      "epoch:23 step:18221 [D loss: 0.792364, acc: 50.78%] [G loss: 2.959263]\n",
      "epoch:23 step:18222 [D loss: 0.932203, acc: 49.22%] [G loss: 4.738795]\n",
      "epoch:23 step:18223 [D loss: 0.403599, acc: 78.91%] [G loss: 3.170576]\n",
      "epoch:23 step:18224 [D loss: 0.334801, acc: 89.84%] [G loss: 4.296140]\n",
      "epoch:23 step:18225 [D loss: 0.272456, acc: 92.19%] [G loss: 3.315958]\n",
      "epoch:23 step:18226 [D loss: 0.280846, acc: 92.19%] [G loss: 3.482947]\n",
      "epoch:23 step:18227 [D loss: 0.374456, acc: 88.28%] [G loss: 5.717259]\n",
      "epoch:23 step:18228 [D loss: 0.544654, acc: 75.78%] [G loss: 3.526104]\n",
      "epoch:23 step:18229 [D loss: 0.363401, acc: 89.84%] [G loss: 2.833466]\n",
      "epoch:23 step:18230 [D loss: 1.484759, acc: 5.47%] [G loss: 3.403048]\n",
      "epoch:23 step:18231 [D loss: 0.273074, acc: 94.53%] [G loss: 4.620488]\n",
      "epoch:23 step:18232 [D loss: 1.149922, acc: 16.41%] [G loss: 3.029434]\n",
      "epoch:23 step:18233 [D loss: 0.488955, acc: 74.22%] [G loss: 4.832212]\n",
      "epoch:23 step:18234 [D loss: 0.497199, acc: 79.69%] [G loss: 2.398931]\n",
      "epoch:23 step:18235 [D loss: 0.569932, acc: 60.16%] [G loss: 4.079636]\n",
      "epoch:23 step:18236 [D loss: 0.394083, acc: 86.72%] [G loss: 3.746943]\n",
      "epoch:23 step:18237 [D loss: 0.374097, acc: 88.28%] [G loss: 4.889879]\n",
      "epoch:23 step:18238 [D loss: 0.403104, acc: 87.50%] [G loss: 3.167124]\n",
      "epoch:23 step:18239 [D loss: 0.622720, acc: 68.75%] [G loss: 2.706829]\n",
      "epoch:23 step:18240 [D loss: 0.638179, acc: 58.59%] [G loss: 3.530453]\n",
      "epoch:23 step:18241 [D loss: 0.841463, acc: 52.34%] [G loss: 3.428484]\n",
      "epoch:23 step:18242 [D loss: 0.257566, acc: 97.66%] [G loss: 3.084365]\n",
      "epoch:23 step:18243 [D loss: 0.664408, acc: 56.25%] [G loss: 3.524481]\n",
      "epoch:23 step:18244 [D loss: 0.160897, acc: 99.22%] [G loss: 3.331692]\n",
      "epoch:23 step:18245 [D loss: 1.442034, acc: 20.31%] [G loss: 1.954551]\n",
      "epoch:23 step:18246 [D loss: 0.120211, acc: 98.44%] [G loss: 4.078446]\n",
      "epoch:23 step:18247 [D loss: 0.469868, acc: 82.03%] [G loss: 2.349362]\n",
      "epoch:23 step:18248 [D loss: 0.243860, acc: 96.09%] [G loss: 3.402592]\n",
      "epoch:23 step:18249 [D loss: 0.302123, acc: 89.84%] [G loss: 4.442825]\n",
      "epoch:23 step:18250 [D loss: 0.449931, acc: 83.59%] [G loss: 3.116491]\n",
      "epoch:23 step:18251 [D loss: 0.285487, acc: 91.41%] [G loss: 4.419226]\n",
      "epoch:23 step:18252 [D loss: 0.460586, acc: 78.12%] [G loss: 2.951724]\n",
      "epoch:23 step:18253 [D loss: 0.474236, acc: 78.12%] [G loss: 3.957198]\n",
      "epoch:23 step:18254 [D loss: 0.433124, acc: 83.59%] [G loss: 3.140606]\n",
      "epoch:23 step:18255 [D loss: 0.432812, acc: 89.06%] [G loss: 1.873734]\n",
      "epoch:23 step:18256 [D loss: 0.446721, acc: 80.47%] [G loss: 2.681149]\n",
      "epoch:23 step:18257 [D loss: 0.159476, acc: 100.00%] [G loss: 3.198267]\n",
      "epoch:23 step:18258 [D loss: 0.442756, acc: 85.94%] [G loss: 1.870850]\n",
      "epoch:23 step:18259 [D loss: 0.138565, acc: 100.00%] [G loss: 4.337706]\n",
      "epoch:23 step:18260 [D loss: 0.416704, acc: 84.38%] [G loss: 4.165669]\n",
      "epoch:23 step:18261 [D loss: 0.247527, acc: 98.44%] [G loss: 2.715274]\n",
      "epoch:23 step:18262 [D loss: 1.233960, acc: 50.00%] [G loss: 3.092034]\n",
      "epoch:23 step:18263 [D loss: 0.833885, acc: 53.12%] [G loss: 2.713860]\n",
      "epoch:23 step:18264 [D loss: 0.429185, acc: 85.94%] [G loss: 3.103477]\n",
      "epoch:23 step:18265 [D loss: 0.331369, acc: 92.19%] [G loss: 2.550065]\n",
      "epoch:23 step:18266 [D loss: 0.739251, acc: 54.69%] [G loss: 2.719409]\n",
      "epoch:23 step:18267 [D loss: 0.528204, acc: 70.31%] [G loss: 3.250218]\n",
      "epoch:23 step:18268 [D loss: 1.248298, acc: 12.50%] [G loss: 2.093671]\n",
      "epoch:23 step:18269 [D loss: 0.394014, acc: 96.09%] [G loss: 4.322062]\n",
      "epoch:23 step:18270 [D loss: 0.445686, acc: 71.88%] [G loss: 4.202038]\n",
      "epoch:23 step:18271 [D loss: 0.816044, acc: 54.69%] [G loss: 3.135519]\n",
      "epoch:23 step:18272 [D loss: 0.377599, acc: 91.41%] [G loss: 2.421010]\n",
      "epoch:23 step:18273 [D loss: 0.216103, acc: 94.53%] [G loss: 3.512598]\n",
      "epoch:23 step:18274 [D loss: 1.279595, acc: 6.25%] [G loss: 3.097799]\n",
      "epoch:23 step:18275 [D loss: 0.903037, acc: 41.41%] [G loss: 3.058191]\n",
      "epoch:23 step:18276 [D loss: 0.935481, acc: 50.00%] [G loss: 5.938889]\n",
      "epoch:23 step:18277 [D loss: 0.418556, acc: 70.31%] [G loss: 3.776712]\n",
      "epoch:23 step:18278 [D loss: 0.829469, acc: 40.62%] [G loss: 3.177557]\n",
      "epoch:23 step:18279 [D loss: 0.368434, acc: 93.75%] [G loss: 3.101090]\n",
      "epoch:23 step:18280 [D loss: 0.970860, acc: 42.97%] [G loss: 4.613433]\n",
      "epoch:23 step:18281 [D loss: 0.486745, acc: 79.69%] [G loss: 3.586974]\n",
      "epoch:23 step:18282 [D loss: 0.888732, acc: 31.25%] [G loss: 2.979877]\n",
      "epoch:23 step:18283 [D loss: 0.734159, acc: 50.00%] [G loss: 3.904291]\n",
      "epoch:23 step:18284 [D loss: 0.346400, acc: 92.97%] [G loss: 3.360999]\n",
      "epoch:23 step:18285 [D loss: 0.341561, acc: 92.19%] [G loss: 2.803211]\n",
      "epoch:23 step:18286 [D loss: 0.193134, acc: 93.75%] [G loss: 2.265682]\n",
      "epoch:23 step:18287 [D loss: 0.437499, acc: 85.94%] [G loss: 3.879715]\n",
      "epoch:23 step:18288 [D loss: 0.497966, acc: 74.22%] [G loss: 2.570877]\n",
      "epoch:23 step:18289 [D loss: 0.380989, acc: 90.62%] [G loss: 2.343267]\n",
      "epoch:23 step:18290 [D loss: 0.292439, acc: 98.44%] [G loss: 2.423240]\n",
      "epoch:23 step:18291 [D loss: 1.119991, acc: 16.41%] [G loss: 4.292370]\n",
      "epoch:23 step:18292 [D loss: 0.323083, acc: 93.75%] [G loss: 3.391819]\n",
      "epoch:23 step:18293 [D loss: 0.481476, acc: 82.81%] [G loss: 5.046686]\n",
      "epoch:23 step:18294 [D loss: 0.341132, acc: 94.53%] [G loss: 3.713943]\n",
      "epoch:23 step:18295 [D loss: 0.491916, acc: 80.47%] [G loss: 3.093890]\n",
      "epoch:23 step:18296 [D loss: 0.148378, acc: 100.00%] [G loss: 4.790204]\n",
      "epoch:23 step:18297 [D loss: 0.352323, acc: 89.06%] [G loss: 2.888609]\n",
      "epoch:23 step:18298 [D loss: 0.097416, acc: 100.00%] [G loss: 4.318247]\n",
      "epoch:23 step:18299 [D loss: 1.242569, acc: 10.94%] [G loss: 2.747113]\n",
      "epoch:23 step:18300 [D loss: 0.496436, acc: 74.22%] [G loss: 2.406108]\n",
      "epoch:23 step:18301 [D loss: 0.669879, acc: 59.38%] [G loss: 3.805752]\n",
      "epoch:23 step:18302 [D loss: 0.204691, acc: 96.09%] [G loss: 4.875157]\n",
      "epoch:23 step:18303 [D loss: 0.862008, acc: 44.53%] [G loss: 2.189725]\n",
      "epoch:23 step:18304 [D loss: 0.376660, acc: 86.72%] [G loss: 3.686172]\n",
      "epoch:23 step:18305 [D loss: 0.608559, acc: 67.19%] [G loss: 2.817563]\n",
      "epoch:23 step:18306 [D loss: 0.743668, acc: 55.47%] [G loss: 4.309478]\n",
      "epoch:23 step:18307 [D loss: 0.883929, acc: 51.56%] [G loss: 2.895644]\n",
      "epoch:23 step:18308 [D loss: 0.139695, acc: 100.00%] [G loss: 3.441432]\n",
      "epoch:23 step:18309 [D loss: 0.297484, acc: 97.66%] [G loss: 3.442239]\n",
      "epoch:23 step:18310 [D loss: 0.349129, acc: 92.19%] [G loss: 4.030776]\n",
      "epoch:23 step:18311 [D loss: 1.935315, acc: 1.56%] [G loss: 3.499395]\n",
      "epoch:23 step:18312 [D loss: 0.535607, acc: 64.84%] [G loss: 5.014241]\n",
      "epoch:23 step:18313 [D loss: 0.522651, acc: 66.41%] [G loss: 4.665639]\n",
      "epoch:23 step:18314 [D loss: 0.594731, acc: 63.28%] [G loss: 3.257617]\n",
      "epoch:23 step:18315 [D loss: 0.167063, acc: 99.22%] [G loss: 4.877777]\n",
      "epoch:23 step:18316 [D loss: 0.438048, acc: 72.66%] [G loss: 3.757412]\n",
      "epoch:23 step:18317 [D loss: 0.780704, acc: 46.09%] [G loss: 3.135548]\n",
      "epoch:23 step:18318 [D loss: 0.430103, acc: 78.12%] [G loss: 4.838950]\n",
      "epoch:23 step:18319 [D loss: 0.436831, acc: 85.16%] [G loss: 3.310148]\n",
      "epoch:23 step:18320 [D loss: 0.181448, acc: 98.44%] [G loss: 4.423426]\n",
      "epoch:23 step:18321 [D loss: 0.561679, acc: 66.41%] [G loss: 3.116664]\n",
      "epoch:23 step:18322 [D loss: 0.623265, acc: 60.94%] [G loss: 3.131465]\n",
      "epoch:23 step:18323 [D loss: 0.470237, acc: 82.03%] [G loss: 1.941623]\n",
      "epoch:23 step:18324 [D loss: 0.529244, acc: 71.88%] [G loss: 3.059008]\n",
      "epoch:23 step:18325 [D loss: 0.823927, acc: 50.00%] [G loss: 2.739411]\n",
      "epoch:23 step:18326 [D loss: 0.352799, acc: 83.59%] [G loss: 3.574475]\n",
      "epoch:23 step:18327 [D loss: 0.416268, acc: 89.84%] [G loss: 3.374439]\n",
      "epoch:23 step:18328 [D loss: 0.701973, acc: 57.03%] [G loss: 3.283947]\n",
      "epoch:23 step:18329 [D loss: 0.364511, acc: 87.50%] [G loss: 4.834002]\n",
      "epoch:23 step:18330 [D loss: 0.493259, acc: 77.34%] [G loss: 2.485495]\n",
      "epoch:23 step:18331 [D loss: 0.460637, acc: 79.69%] [G loss: 2.930158]\n",
      "epoch:23 step:18332 [D loss: 0.169737, acc: 99.22%] [G loss: 3.678359]\n",
      "epoch:23 step:18333 [D loss: 0.180300, acc: 97.66%] [G loss: 5.539308]\n",
      "epoch:23 step:18334 [D loss: 0.756200, acc: 53.12%] [G loss: 4.081222]\n",
      "epoch:23 step:18335 [D loss: 0.970103, acc: 40.62%] [G loss: 2.896935]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18336 [D loss: 0.440780, acc: 79.69%] [G loss: 3.858777]\n",
      "epoch:23 step:18337 [D loss: 0.175255, acc: 98.44%] [G loss: 3.446412]\n",
      "epoch:23 step:18338 [D loss: 0.323471, acc: 88.28%] [G loss: 3.423702]\n",
      "epoch:23 step:18339 [D loss: 0.145961, acc: 100.00%] [G loss: 3.093870]\n",
      "epoch:23 step:18340 [D loss: 1.168941, acc: 14.06%] [G loss: 2.899294]\n",
      "epoch:23 step:18341 [D loss: 0.284636, acc: 92.19%] [G loss: 3.743570]\n",
      "epoch:23 step:18342 [D loss: 0.344236, acc: 89.84%] [G loss: 3.454016]\n",
      "epoch:23 step:18343 [D loss: 0.454758, acc: 85.16%] [G loss: 3.309000]\n",
      "epoch:23 step:18344 [D loss: 0.321774, acc: 94.53%] [G loss: 3.430982]\n",
      "epoch:23 step:18345 [D loss: 0.770074, acc: 51.56%] [G loss: 3.200579]\n",
      "epoch:23 step:18346 [D loss: 1.451256, acc: 16.41%] [G loss: 2.561869]\n",
      "epoch:23 step:18347 [D loss: 0.305385, acc: 91.41%] [G loss: 3.218772]\n",
      "epoch:23 step:18348 [D loss: 0.268221, acc: 94.53%] [G loss: 3.317390]\n",
      "epoch:23 step:18349 [D loss: 0.823870, acc: 53.91%] [G loss: 3.123559]\n",
      "epoch:23 step:18350 [D loss: 0.463698, acc: 82.03%] [G loss: 3.273390]\n",
      "epoch:23 step:18351 [D loss: 0.389185, acc: 88.28%] [G loss: 3.415464]\n",
      "epoch:23 step:18352 [D loss: 0.534552, acc: 64.84%] [G loss: 4.013166]\n",
      "epoch:23 step:18353 [D loss: 0.620160, acc: 67.97%] [G loss: 3.680028]\n",
      "epoch:23 step:18354 [D loss: 1.007407, acc: 50.00%] [G loss: 4.704851]\n",
      "epoch:23 step:18355 [D loss: 0.535269, acc: 64.06%] [G loss: 4.330931]\n",
      "epoch:23 step:18356 [D loss: 0.736284, acc: 52.34%] [G loss: 5.357385]\n",
      "epoch:23 step:18357 [D loss: 0.330034, acc: 93.75%] [G loss: 3.366441]\n",
      "epoch:23 step:18358 [D loss: 0.597828, acc: 59.38%] [G loss: 2.348081]\n",
      "epoch:23 step:18359 [D loss: 0.513598, acc: 78.91%] [G loss: 3.732583]\n",
      "epoch:23 step:18360 [D loss: 0.468319, acc: 80.47%] [G loss: 3.864276]\n",
      "epoch:23 step:18361 [D loss: 0.366722, acc: 78.12%] [G loss: 4.299367]\n",
      "epoch:23 step:18362 [D loss: 0.692995, acc: 57.03%] [G loss: 4.050065]\n",
      "epoch:23 step:18363 [D loss: 0.288245, acc: 96.88%] [G loss: 3.511558]\n",
      "epoch:23 step:18364 [D loss: 0.523880, acc: 64.84%] [G loss: 5.025015]\n",
      "epoch:23 step:18365 [D loss: 0.455365, acc: 80.47%] [G loss: 3.803989]\n",
      "epoch:23 step:18366 [D loss: 0.737781, acc: 57.81%] [G loss: 3.276861]\n",
      "epoch:23 step:18367 [D loss: 0.616692, acc: 64.84%] [G loss: 2.849262]\n",
      "epoch:23 step:18368 [D loss: 0.889822, acc: 45.31%] [G loss: 3.679627]\n",
      "epoch:23 step:18369 [D loss: 0.232892, acc: 93.75%] [G loss: 3.741858]\n",
      "epoch:23 step:18370 [D loss: 0.449201, acc: 86.72%] [G loss: 2.042501]\n",
      "epoch:23 step:18371 [D loss: 0.541824, acc: 73.44%] [G loss: 4.017540]\n",
      "epoch:23 step:18372 [D loss: 0.303764, acc: 92.19%] [G loss: 3.953653]\n",
      "epoch:23 step:18373 [D loss: 0.129871, acc: 100.00%] [G loss: 6.014247]\n",
      "epoch:23 step:18374 [D loss: 0.095597, acc: 100.00%] [G loss: 4.067668]\n",
      "epoch:23 step:18375 [D loss: 0.719749, acc: 53.12%] [G loss: 3.255787]\n",
      "epoch:23 step:18376 [D loss: 0.256082, acc: 97.66%] [G loss: 4.144012]\n",
      "epoch:23 step:18377 [D loss: 0.323567, acc: 92.19%] [G loss: 2.590731]\n",
      "epoch:23 step:18378 [D loss: 0.234317, acc: 99.22%] [G loss: 3.610307]\n",
      "epoch:23 step:18379 [D loss: 0.293480, acc: 96.09%] [G loss: 2.650274]\n",
      "epoch:23 step:18380 [D loss: 0.276522, acc: 87.50%] [G loss: 4.586352]\n",
      "epoch:23 step:18381 [D loss: 0.449631, acc: 73.44%] [G loss: 3.425816]\n",
      "epoch:23 step:18382 [D loss: 0.703293, acc: 53.91%] [G loss: 3.367996]\n",
      "epoch:23 step:18383 [D loss: 0.800430, acc: 50.00%] [G loss: 4.864219]\n",
      "epoch:23 step:18384 [D loss: 0.874803, acc: 51.56%] [G loss: 4.063472]\n",
      "epoch:23 step:18385 [D loss: 0.357537, acc: 93.75%] [G loss: 3.323682]\n",
      "epoch:23 step:18386 [D loss: 0.736133, acc: 52.34%] [G loss: 3.879989]\n",
      "epoch:23 step:18387 [D loss: 0.532560, acc: 71.09%] [G loss: 3.023774]\n",
      "epoch:23 step:18388 [D loss: 0.537249, acc: 70.31%] [G loss: 4.258397]\n",
      "epoch:23 step:18389 [D loss: 0.380213, acc: 90.62%] [G loss: 4.639880]\n",
      "epoch:23 step:18390 [D loss: 0.367883, acc: 89.84%] [G loss: 4.660994]\n",
      "epoch:23 step:18391 [D loss: 0.429371, acc: 82.03%] [G loss: 3.254933]\n",
      "epoch:23 step:18392 [D loss: 0.604334, acc: 64.06%] [G loss: 4.064310]\n",
      "epoch:23 step:18393 [D loss: 1.144957, acc: 33.59%] [G loss: 2.854084]\n",
      "epoch:23 step:18394 [D loss: 0.559535, acc: 72.66%] [G loss: 3.457076]\n",
      "epoch:23 step:18395 [D loss: 0.606739, acc: 65.62%] [G loss: 3.205396]\n",
      "epoch:23 step:18396 [D loss: 0.341576, acc: 86.72%] [G loss: 5.674819]\n",
      "epoch:23 step:18397 [D loss: 0.240392, acc: 99.22%] [G loss: 4.221609]\n",
      "epoch:23 step:18398 [D loss: 0.477844, acc: 85.94%] [G loss: 5.597049]\n",
      "epoch:23 step:18399 [D loss: 0.934564, acc: 34.38%] [G loss: 2.344589]\n",
      "epoch:23 step:18400 [D loss: 0.364374, acc: 93.75%] [G loss: 3.405984]\n",
      "epoch:23 step:18401 [D loss: 0.196834, acc: 98.44%] [G loss: 2.564716]\n",
      "epoch:23 step:18402 [D loss: 0.139144, acc: 98.44%] [G loss: 3.240384]\n",
      "epoch:23 step:18403 [D loss: 0.379840, acc: 90.62%] [G loss: 3.450783]\n",
      "epoch:23 step:18404 [D loss: 0.282096, acc: 96.88%] [G loss: 3.133684]\n",
      "epoch:23 step:18405 [D loss: 1.005120, acc: 39.06%] [G loss: 2.809793]\n",
      "epoch:23 step:18406 [D loss: 0.240672, acc: 99.22%] [G loss: 4.392323]\n",
      "epoch:23 step:18407 [D loss: 0.338180, acc: 92.97%] [G loss: 3.934020]\n",
      "epoch:23 step:18408 [D loss: 0.473094, acc: 74.22%] [G loss: 3.521493]\n",
      "epoch:23 step:18409 [D loss: 0.400953, acc: 88.28%] [G loss: 3.979448]\n",
      "epoch:23 step:18410 [D loss: 0.581695, acc: 71.88%] [G loss: 3.276553]\n",
      "epoch:23 step:18411 [D loss: 0.449856, acc: 80.47%] [G loss: 4.394171]\n",
      "epoch:23 step:18412 [D loss: 0.469459, acc: 81.25%] [G loss: 4.116028]\n",
      "epoch:23 step:18413 [D loss: 0.490194, acc: 78.12%] [G loss: 4.410336]\n",
      "epoch:23 step:18414 [D loss: 0.533913, acc: 73.44%] [G loss: 3.780516]\n",
      "epoch:23 step:18415 [D loss: 0.292911, acc: 98.44%] [G loss: 3.180323]\n",
      "epoch:23 step:18416 [D loss: 0.468172, acc: 72.66%] [G loss: 4.880899]\n",
      "epoch:23 step:18417 [D loss: 0.645132, acc: 58.59%] [G loss: 2.674747]\n",
      "epoch:23 step:18418 [D loss: 0.470536, acc: 73.44%] [G loss: 3.263207]\n",
      "epoch:23 step:18419 [D loss: 0.839966, acc: 39.06%] [G loss: 2.543796]\n",
      "epoch:23 step:18420 [D loss: 0.582290, acc: 69.53%] [G loss: 3.836814]\n",
      "epoch:23 step:18421 [D loss: 0.263743, acc: 96.09%] [G loss: 4.360005]\n",
      "epoch:23 step:18422 [D loss: 0.722188, acc: 53.91%] [G loss: 3.704680]\n",
      "epoch:23 step:18423 [D loss: 0.262116, acc: 97.66%] [G loss: 3.220988]\n",
      "epoch:23 step:18424 [D loss: 0.465932, acc: 86.72%] [G loss: 4.454008]\n",
      "epoch:23 step:18425 [D loss: 0.178963, acc: 100.00%] [G loss: 3.692559]\n",
      "epoch:23 step:18426 [D loss: 0.343181, acc: 95.31%] [G loss: 3.733976]\n",
      "epoch:23 step:18427 [D loss: 0.738303, acc: 51.56%] [G loss: 2.988321]\n",
      "epoch:23 step:18428 [D loss: 0.482218, acc: 65.62%] [G loss: 3.178967]\n",
      "epoch:23 step:18429 [D loss: 0.092217, acc: 100.00%] [G loss: 5.994065]\n",
      "epoch:23 step:18430 [D loss: 0.609481, acc: 64.06%] [G loss: 2.936100]\n",
      "epoch:23 step:18431 [D loss: 0.960131, acc: 35.94%] [G loss: 4.111103]\n",
      "epoch:23 step:18432 [D loss: 0.520030, acc: 76.56%] [G loss: 4.601682]\n",
      "epoch:23 step:18433 [D loss: 0.126198, acc: 100.00%] [G loss: 4.496823]\n",
      "epoch:23 step:18434 [D loss: 0.898666, acc: 38.28%] [G loss: 2.908488]\n",
      "epoch:23 step:18435 [D loss: 0.396783, acc: 81.25%] [G loss: 3.985741]\n",
      "epoch:23 step:18436 [D loss: 0.566729, acc: 67.19%] [G loss: 4.579497]\n",
      "epoch:23 step:18437 [D loss: 0.663218, acc: 56.25%] [G loss: 2.920667]\n",
      "epoch:23 step:18438 [D loss: 0.316235, acc: 96.09%] [G loss: 2.100560]\n",
      "epoch:23 step:18439 [D loss: 0.478869, acc: 76.56%] [G loss: 4.228456]\n",
      "epoch:23 step:18440 [D loss: 0.221854, acc: 97.66%] [G loss: 3.187566]\n",
      "epoch:23 step:18441 [D loss: 0.556207, acc: 75.00%] [G loss: 2.843102]\n",
      "epoch:23 step:18442 [D loss: 0.568719, acc: 75.78%] [G loss: 3.628986]\n",
      "epoch:23 step:18443 [D loss: 0.808999, acc: 45.31%] [G loss: 3.087212]\n",
      "epoch:23 step:18444 [D loss: 0.392968, acc: 91.41%] [G loss: 4.196812]\n",
      "epoch:23 step:18445 [D loss: 0.543408, acc: 72.66%] [G loss: 4.680144]\n",
      "epoch:23 step:18446 [D loss: 0.888922, acc: 32.81%] [G loss: 3.318177]\n",
      "epoch:23 step:18447 [D loss: 0.643929, acc: 64.06%] [G loss: 3.316470]\n",
      "epoch:23 step:18448 [D loss: 0.587592, acc: 71.88%] [G loss: 3.601964]\n",
      "epoch:23 step:18449 [D loss: 0.224416, acc: 94.53%] [G loss: 3.514350]\n",
      "epoch:23 step:18450 [D loss: 0.622086, acc: 68.75%] [G loss: 2.903210]\n",
      "epoch:23 step:18451 [D loss: 0.423655, acc: 81.25%] [G loss: 4.764263]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18452 [D loss: 0.164445, acc: 100.00%] [G loss: 4.519907]\n",
      "epoch:23 step:18453 [D loss: 0.140182, acc: 98.44%] [G loss: 4.326463]\n",
      "epoch:23 step:18454 [D loss: 0.455502, acc: 72.66%] [G loss: 3.285089]\n",
      "epoch:23 step:18455 [D loss: 0.188443, acc: 98.44%] [G loss: 5.206177]\n",
      "epoch:23 step:18456 [D loss: 0.407463, acc: 87.50%] [G loss: 4.287587]\n",
      "epoch:23 step:18457 [D loss: 0.941374, acc: 50.00%] [G loss: 2.390342]\n",
      "epoch:23 step:18458 [D loss: 0.414815, acc: 87.50%] [G loss: 1.957898]\n",
      "epoch:23 step:18459 [D loss: 0.710801, acc: 53.12%] [G loss: 4.252873]\n",
      "epoch:23 step:18460 [D loss: 0.177448, acc: 98.44%] [G loss: 5.704732]\n",
      "epoch:23 step:18461 [D loss: 0.385130, acc: 85.94%] [G loss: 3.694575]\n",
      "epoch:23 step:18462 [D loss: 0.418567, acc: 74.22%] [G loss: 5.726519]\n",
      "epoch:23 step:18463 [D loss: 0.356403, acc: 90.62%] [G loss: 4.670254]\n",
      "epoch:23 step:18464 [D loss: 0.234109, acc: 100.00%] [G loss: 3.751405]\n",
      "epoch:23 step:18465 [D loss: 0.573852, acc: 66.41%] [G loss: 3.214785]\n",
      "epoch:23 step:18466 [D loss: 0.290456, acc: 91.41%] [G loss: 6.009914]\n",
      "epoch:23 step:18467 [D loss: 0.615618, acc: 68.75%] [G loss: 3.643405]\n",
      "epoch:23 step:18468 [D loss: 0.320807, acc: 93.75%] [G loss: 2.558959]\n",
      "epoch:23 step:18469 [D loss: 0.419312, acc: 85.94%] [G loss: 3.269814]\n",
      "epoch:23 step:18470 [D loss: 0.622853, acc: 61.72%] [G loss: 2.394041]\n",
      "epoch:23 step:18471 [D loss: 0.230109, acc: 100.00%] [G loss: 5.638919]\n",
      "epoch:23 step:18472 [D loss: 1.079426, acc: 16.41%] [G loss: 2.363121]\n",
      "epoch:23 step:18473 [D loss: 0.536585, acc: 71.88%] [G loss: 3.992831]\n",
      "epoch:23 step:18474 [D loss: 0.421299, acc: 75.78%] [G loss: 5.203406]\n",
      "epoch:23 step:18475 [D loss: 0.319581, acc: 87.50%] [G loss: 4.661515]\n",
      "epoch:23 step:18476 [D loss: 0.779364, acc: 52.34%] [G loss: 4.283685]\n",
      "epoch:23 step:18477 [D loss: 0.924706, acc: 28.91%] [G loss: 4.758978]\n",
      "epoch:23 step:18478 [D loss: 0.276420, acc: 93.75%] [G loss: 3.312784]\n",
      "epoch:23 step:18479 [D loss: 0.601498, acc: 62.50%] [G loss: 3.394490]\n",
      "epoch:23 step:18480 [D loss: 0.113966, acc: 100.00%] [G loss: 3.336535]\n",
      "epoch:23 step:18481 [D loss: 0.291882, acc: 96.88%] [G loss: 3.237844]\n",
      "epoch:23 step:18482 [D loss: 0.471796, acc: 69.53%] [G loss: 4.191205]\n",
      "epoch:23 step:18483 [D loss: 0.450762, acc: 81.25%] [G loss: 3.336282]\n",
      "epoch:23 step:18484 [D loss: 0.196141, acc: 96.88%] [G loss: 3.259134]\n",
      "epoch:23 step:18485 [D loss: 0.589722, acc: 63.28%] [G loss: 3.031779]\n",
      "epoch:23 step:18486 [D loss: 1.201979, acc: 25.78%] [G loss: 3.671536]\n",
      "epoch:23 step:18487 [D loss: 0.453812, acc: 85.94%] [G loss: 4.354401]\n",
      "epoch:23 step:18488 [D loss: 0.931755, acc: 45.31%] [G loss: 3.683557]\n",
      "epoch:23 step:18489 [D loss: 1.113067, acc: 32.03%] [G loss: 3.236480]\n",
      "epoch:23 step:18490 [D loss: 0.249304, acc: 91.41%] [G loss: 3.981934]\n",
      "epoch:23 step:18491 [D loss: 0.559025, acc: 60.94%] [G loss: 4.247137]\n",
      "epoch:23 step:18492 [D loss: 0.398490, acc: 85.16%] [G loss: 3.668763]\n",
      "epoch:23 step:18493 [D loss: 0.356203, acc: 91.41%] [G loss: 4.224578]\n",
      "epoch:23 step:18494 [D loss: 0.664952, acc: 57.03%] [G loss: 2.947939]\n",
      "epoch:23 step:18495 [D loss: 0.557824, acc: 71.88%] [G loss: 2.849579]\n",
      "epoch:23 step:18496 [D loss: 0.410094, acc: 86.72%] [G loss: 3.475119]\n",
      "epoch:23 step:18497 [D loss: 0.342938, acc: 93.75%] [G loss: 2.697582]\n",
      "epoch:23 step:18498 [D loss: 0.647527, acc: 57.03%] [G loss: 2.973914]\n",
      "epoch:23 step:18499 [D loss: 0.206006, acc: 96.88%] [G loss: 5.450195]\n",
      "epoch:23 step:18500 [D loss: 0.523353, acc: 66.41%] [G loss: 3.795606]\n",
      "epoch:23 step:18501 [D loss: 0.202665, acc: 97.66%] [G loss: 4.005226]\n",
      "epoch:23 step:18502 [D loss: 1.133767, acc: 29.69%] [G loss: 3.915856]\n",
      "epoch:23 step:18503 [D loss: 0.391643, acc: 89.06%] [G loss: 4.428647]\n",
      "epoch:23 step:18504 [D loss: 0.325695, acc: 89.06%] [G loss: 3.179485]\n",
      "epoch:23 step:18505 [D loss: 0.329841, acc: 93.75%] [G loss: 2.294569]\n",
      "epoch:23 step:18506 [D loss: 0.660427, acc: 57.81%] [G loss: 3.867426]\n",
      "epoch:23 step:18507 [D loss: 0.806074, acc: 53.12%] [G loss: 4.054351]\n",
      "epoch:23 step:18508 [D loss: 0.377270, acc: 75.78%] [G loss: 4.690074]\n",
      "epoch:23 step:18509 [D loss: 0.472059, acc: 76.56%] [G loss: 4.567128]\n",
      "epoch:23 step:18510 [D loss: 0.453017, acc: 82.81%] [G loss: 3.565571]\n",
      "epoch:23 step:18511 [D loss: 0.630434, acc: 60.94%] [G loss: 4.001437]\n",
      "epoch:23 step:18512 [D loss: 0.587324, acc: 71.09%] [G loss: 3.311828]\n",
      "epoch:23 step:18513 [D loss: 0.184996, acc: 99.22%] [G loss: 4.835515]\n",
      "epoch:23 step:18514 [D loss: 0.342720, acc: 88.28%] [G loss: 2.456012]\n",
      "epoch:23 step:18515 [D loss: 1.026449, acc: 45.31%] [G loss: 3.030164]\n",
      "epoch:23 step:18516 [D loss: 0.301318, acc: 93.75%] [G loss: 5.033709]\n",
      "epoch:23 step:18517 [D loss: 0.390904, acc: 81.25%] [G loss: 2.248930]\n",
      "epoch:23 step:18518 [D loss: 0.402810, acc: 82.03%] [G loss: 4.758905]\n",
      "epoch:23 step:18519 [D loss: 0.473267, acc: 71.09%] [G loss: 3.393990]\n",
      "epoch:23 step:18520 [D loss: 0.308480, acc: 86.72%] [G loss: 6.396473]\n",
      "epoch:23 step:18521 [D loss: 0.448078, acc: 84.38%] [G loss: 2.853731]\n",
      "epoch:23 step:18522 [D loss: 0.207425, acc: 98.44%] [G loss: 4.634017]\n",
      "epoch:23 step:18523 [D loss: 0.474785, acc: 85.16%] [G loss: 4.125206]\n",
      "epoch:23 step:18524 [D loss: 1.188500, acc: 17.19%] [G loss: 2.936210]\n",
      "epoch:23 step:18525 [D loss: 1.239131, acc: 14.84%] [G loss: 4.637551]\n",
      "epoch:23 step:18526 [D loss: 0.154976, acc: 98.44%] [G loss: 3.334998]\n",
      "epoch:23 step:18527 [D loss: 0.216251, acc: 98.44%] [G loss: 4.031704]\n",
      "epoch:23 step:18528 [D loss: 0.276669, acc: 97.66%] [G loss: 3.267564]\n",
      "epoch:23 step:18529 [D loss: 0.338235, acc: 88.28%] [G loss: 4.004325]\n",
      "epoch:23 step:18530 [D loss: 0.498801, acc: 82.03%] [G loss: 5.291511]\n",
      "epoch:23 step:18531 [D loss: 0.299844, acc: 85.94%] [G loss: 5.142292]\n",
      "epoch:23 step:18532 [D loss: 0.262255, acc: 94.53%] [G loss: 3.326214]\n",
      "epoch:23 step:18533 [D loss: 0.398228, acc: 93.75%] [G loss: 2.900410]\n",
      "epoch:23 step:18534 [D loss: 0.323862, acc: 85.94%] [G loss: 4.021143]\n",
      "epoch:23 step:18535 [D loss: 0.211245, acc: 98.44%] [G loss: 3.310145]\n",
      "epoch:23 step:18536 [D loss: 0.420451, acc: 85.16%] [G loss: 3.649455]\n",
      "epoch:23 step:18537 [D loss: 0.503385, acc: 78.12%] [G loss: 3.005120]\n",
      "epoch:23 step:18538 [D loss: 0.120571, acc: 100.00%] [G loss: 3.685732]\n",
      "epoch:23 step:18539 [D loss: 0.760306, acc: 53.12%] [G loss: 3.222421]\n",
      "epoch:23 step:18540 [D loss: 0.773523, acc: 56.25%] [G loss: 2.424245]\n",
      "epoch:23 step:18541 [D loss: 0.662035, acc: 60.94%] [G loss: 3.128103]\n",
      "epoch:23 step:18542 [D loss: 0.254501, acc: 93.75%] [G loss: 3.621933]\n",
      "epoch:23 step:18543 [D loss: 0.578382, acc: 60.16%] [G loss: 3.366032]\n",
      "epoch:23 step:18544 [D loss: 0.229352, acc: 98.44%] [G loss: 4.426941]\n",
      "epoch:23 step:18545 [D loss: 0.563342, acc: 78.12%] [G loss: 3.855220]\n",
      "epoch:23 step:18546 [D loss: 0.554443, acc: 74.22%] [G loss: 4.005485]\n",
      "epoch:23 step:18547 [D loss: 0.475424, acc: 72.66%] [G loss: 3.952991]\n",
      "epoch:23 step:18548 [D loss: 0.426419, acc: 71.88%] [G loss: 4.836955]\n",
      "epoch:23 step:18549 [D loss: 0.588120, acc: 57.03%] [G loss: 4.886209]\n",
      "epoch:23 step:18550 [D loss: 0.489149, acc: 66.41%] [G loss: 4.362895]\n",
      "epoch:23 step:18551 [D loss: 0.393805, acc: 84.38%] [G loss: 3.450262]\n",
      "epoch:23 step:18552 [D loss: 0.321340, acc: 86.72%] [G loss: 4.377324]\n",
      "epoch:23 step:18553 [D loss: 0.369078, acc: 82.03%] [G loss: 2.889451]\n",
      "epoch:23 step:18554 [D loss: 0.410879, acc: 73.44%] [G loss: 2.981537]\n",
      "epoch:23 step:18555 [D loss: 0.499010, acc: 77.34%] [G loss: 2.520372]\n",
      "epoch:23 step:18556 [D loss: 0.734136, acc: 53.91%] [G loss: 3.437312]\n",
      "epoch:23 step:18557 [D loss: 1.293952, acc: 12.50%] [G loss: 2.670761]\n",
      "epoch:23 step:18558 [D loss: 0.467943, acc: 78.12%] [G loss: 4.500480]\n",
      "epoch:23 step:18559 [D loss: 1.235797, acc: 18.75%] [G loss: 3.602440]\n",
      "epoch:23 step:18560 [D loss: 0.312072, acc: 91.41%] [G loss: 3.778837]\n",
      "epoch:23 step:18561 [D loss: 0.304235, acc: 96.88%] [G loss: 3.611928]\n",
      "epoch:23 step:18562 [D loss: 0.680163, acc: 57.81%] [G loss: 3.758042]\n",
      "epoch:23 step:18563 [D loss: 0.557971, acc: 76.56%] [G loss: 4.703243]\n",
      "epoch:23 step:18564 [D loss: 0.220341, acc: 98.44%] [G loss: 3.663343]\n",
      "epoch:23 step:18565 [D loss: 0.220082, acc: 98.44%] [G loss: 5.098858]\n",
      "epoch:23 step:18566 [D loss: 0.440145, acc: 75.00%] [G loss: 2.469066]\n",
      "epoch:23 step:18567 [D loss: 0.421796, acc: 86.72%] [G loss: 4.616689]\n",
      "epoch:23 step:18568 [D loss: 0.362390, acc: 92.97%] [G loss: 3.535370]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18569 [D loss: 0.457076, acc: 79.69%] [G loss: 3.497217]\n",
      "epoch:23 step:18570 [D loss: 0.837293, acc: 42.97%] [G loss: 4.253122]\n",
      "epoch:23 step:18571 [D loss: 0.585034, acc: 66.41%] [G loss: 3.129398]\n",
      "epoch:23 step:18572 [D loss: 0.444920, acc: 78.12%] [G loss: 4.543266]\n",
      "epoch:23 step:18573 [D loss: 1.124849, acc: 37.50%] [G loss: 3.107813]\n",
      "epoch:23 step:18574 [D loss: 0.765363, acc: 55.47%] [G loss: 3.777776]\n",
      "epoch:23 step:18575 [D loss: 0.312757, acc: 95.31%] [G loss: 3.908716]\n",
      "epoch:23 step:18576 [D loss: 0.477234, acc: 79.69%] [G loss: 2.237929]\n",
      "epoch:23 step:18577 [D loss: 0.219321, acc: 97.66%] [G loss: 4.635401]\n",
      "epoch:23 step:18578 [D loss: 0.420296, acc: 85.16%] [G loss: 3.838757]\n",
      "epoch:23 step:18579 [D loss: 0.723294, acc: 57.81%] [G loss: 4.924032]\n",
      "epoch:23 step:18580 [D loss: 0.699069, acc: 62.50%] [G loss: 3.710479]\n",
      "epoch:23 step:18581 [D loss: 0.352729, acc: 80.47%] [G loss: 2.585284]\n",
      "epoch:23 step:18582 [D loss: 0.641794, acc: 60.16%] [G loss: 3.310297]\n",
      "epoch:23 step:18583 [D loss: 0.567697, acc: 66.41%] [G loss: 2.354546]\n",
      "epoch:23 step:18584 [D loss: 0.377831, acc: 78.91%] [G loss: 2.482350]\n",
      "epoch:23 step:18585 [D loss: 0.480908, acc: 78.12%] [G loss: 3.171874]\n",
      "epoch:23 step:18586 [D loss: 0.586373, acc: 70.31%] [G loss: 2.210103]\n",
      "epoch:23 step:18587 [D loss: 0.082230, acc: 100.00%] [G loss: 3.693291]\n",
      "epoch:23 step:18588 [D loss: 0.570008, acc: 67.19%] [G loss: 2.798105]\n",
      "epoch:23 step:18589 [D loss: 0.476698, acc: 78.91%] [G loss: 2.557840]\n",
      "epoch:23 step:18590 [D loss: 0.523194, acc: 75.78%] [G loss: 2.403556]\n",
      "epoch:23 step:18591 [D loss: 0.368014, acc: 82.81%] [G loss: 3.039192]\n",
      "epoch:23 step:18592 [D loss: 0.633755, acc: 64.84%] [G loss: 4.257866]\n",
      "epoch:23 step:18593 [D loss: 0.604228, acc: 65.62%] [G loss: 3.525083]\n",
      "epoch:23 step:18594 [D loss: 0.201136, acc: 96.88%] [G loss: 3.763347]\n",
      "epoch:23 step:18595 [D loss: 0.695197, acc: 53.91%] [G loss: 3.704223]\n",
      "epoch:23 step:18596 [D loss: 0.347581, acc: 88.28%] [G loss: 4.908172]\n",
      "epoch:23 step:18597 [D loss: 0.839072, acc: 40.62%] [G loss: 3.803397]\n",
      "epoch:23 step:18598 [D loss: 0.408327, acc: 85.16%] [G loss: 3.090370]\n",
      "epoch:23 step:18599 [D loss: 0.383719, acc: 91.41%] [G loss: 3.000242]\n",
      "epoch:23 step:18600 [D loss: 1.531041, acc: 5.47%] [G loss: 4.825810]\n",
      "epoch:23 step:18601 [D loss: 1.270033, acc: 31.25%] [G loss: 3.037159]\n",
      "epoch:23 step:18602 [D loss: 0.862213, acc: 46.88%] [G loss: 3.588060]\n",
      "epoch:23 step:18603 [D loss: 0.362163, acc: 89.06%] [G loss: 4.293196]\n",
      "epoch:23 step:18604 [D loss: 0.613045, acc: 71.88%] [G loss: 2.817145]\n",
      "epoch:23 step:18605 [D loss: 0.410558, acc: 82.81%] [G loss: 5.016739]\n",
      "epoch:23 step:18606 [D loss: 0.462991, acc: 77.34%] [G loss: 2.909992]\n",
      "epoch:23 step:18607 [D loss: 0.334812, acc: 93.75%] [G loss: 4.288996]\n",
      "epoch:23 step:18608 [D loss: 0.694382, acc: 59.38%] [G loss: 3.379328]\n",
      "epoch:23 step:18609 [D loss: 0.819388, acc: 43.75%] [G loss: 3.850276]\n",
      "epoch:23 step:18610 [D loss: 0.520444, acc: 79.69%] [G loss: 3.509480]\n",
      "epoch:23 step:18611 [D loss: 0.429931, acc: 87.50%] [G loss: 4.417040]\n",
      "epoch:23 step:18612 [D loss: 0.167019, acc: 98.44%] [G loss: 3.472573]\n",
      "epoch:23 step:18613 [D loss: 0.366581, acc: 88.28%] [G loss: 3.637770]\n",
      "epoch:23 step:18614 [D loss: 0.321036, acc: 96.09%] [G loss: 5.179562]\n",
      "epoch:23 step:18615 [D loss: 1.236521, acc: 31.25%] [G loss: 2.617607]\n",
      "epoch:23 step:18616 [D loss: 0.399448, acc: 86.72%] [G loss: 4.991956]\n",
      "epoch:23 step:18617 [D loss: 0.328445, acc: 85.94%] [G loss: 4.290587]\n",
      "epoch:23 step:18618 [D loss: 0.312045, acc: 97.66%] [G loss: 3.363791]\n",
      "epoch:23 step:18619 [D loss: 1.413208, acc: 7.81%] [G loss: 3.678596]\n",
      "epoch:23 step:18620 [D loss: 0.181452, acc: 96.88%] [G loss: 3.903628]\n",
      "epoch:23 step:18621 [D loss: 0.551315, acc: 66.41%] [G loss: 3.577812]\n",
      "epoch:23 step:18622 [D loss: 0.180308, acc: 98.44%] [G loss: 3.932355]\n",
      "epoch:23 step:18623 [D loss: 0.491681, acc: 64.84%] [G loss: 4.133838]\n",
      "epoch:23 step:18624 [D loss: 0.575899, acc: 64.84%] [G loss: 4.113485]\n",
      "epoch:23 step:18625 [D loss: 0.332677, acc: 88.28%] [G loss: 3.306619]\n",
      "epoch:23 step:18626 [D loss: 0.349437, acc: 89.84%] [G loss: 3.277186]\n",
      "epoch:23 step:18627 [D loss: 0.588513, acc: 71.09%] [G loss: 5.047619]\n",
      "epoch:23 step:18628 [D loss: 0.727241, acc: 56.25%] [G loss: 4.025790]\n",
      "epoch:23 step:18629 [D loss: 0.669818, acc: 60.16%] [G loss: 3.919266]\n",
      "epoch:23 step:18630 [D loss: 0.111740, acc: 100.00%] [G loss: 5.235504]\n",
      "epoch:23 step:18631 [D loss: 0.791172, acc: 48.44%] [G loss: 4.975984]\n",
      "epoch:23 step:18632 [D loss: 0.400461, acc: 85.94%] [G loss: 3.080826]\n",
      "epoch:23 step:18633 [D loss: 0.838948, acc: 52.34%] [G loss: 5.231607]\n",
      "epoch:23 step:18634 [D loss: 0.523895, acc: 67.97%] [G loss: 4.578780]\n",
      "epoch:23 step:18635 [D loss: 0.630145, acc: 62.50%] [G loss: 4.864375]\n",
      "epoch:23 step:18636 [D loss: 0.844518, acc: 39.84%] [G loss: 3.554227]\n",
      "epoch:23 step:18637 [D loss: 0.245803, acc: 99.22%] [G loss: 4.178737]\n",
      "epoch:23 step:18638 [D loss: 0.385303, acc: 90.62%] [G loss: 3.921853]\n",
      "epoch:23 step:18639 [D loss: 0.323868, acc: 94.53%] [G loss: 4.133405]\n",
      "epoch:23 step:18640 [D loss: 0.262305, acc: 95.31%] [G loss: 3.995464]\n",
      "epoch:23 step:18641 [D loss: 0.335403, acc: 85.94%] [G loss: 3.479089]\n",
      "epoch:23 step:18642 [D loss: 0.291251, acc: 93.75%] [G loss: 3.406408]\n",
      "epoch:23 step:18643 [D loss: 0.356633, acc: 88.28%] [G loss: 2.595834]\n",
      "epoch:23 step:18644 [D loss: 0.173146, acc: 99.22%] [G loss: 5.329327]\n",
      "epoch:23 step:18645 [D loss: 0.389034, acc: 78.91%] [G loss: 3.373559]\n",
      "epoch:23 step:18646 [D loss: 0.184790, acc: 98.44%] [G loss: 3.521700]\n",
      "epoch:23 step:18647 [D loss: 1.118142, acc: 38.28%] [G loss: 2.415766]\n",
      "epoch:23 step:18648 [D loss: 0.200764, acc: 96.88%] [G loss: 2.974795]\n",
      "epoch:23 step:18649 [D loss: 0.286377, acc: 94.53%] [G loss: 4.843109]\n",
      "epoch:23 step:18650 [D loss: 0.696329, acc: 60.94%] [G loss: 5.273849]\n",
      "epoch:23 step:18651 [D loss: 0.160489, acc: 96.09%] [G loss: 5.356204]\n",
      "epoch:23 step:18652 [D loss: 0.414171, acc: 75.78%] [G loss: 3.781455]\n",
      "epoch:23 step:18653 [D loss: 0.136589, acc: 98.44%] [G loss: 5.063954]\n",
      "epoch:23 step:18654 [D loss: 0.254956, acc: 92.19%] [G loss: 3.809301]\n",
      "epoch:23 step:18655 [D loss: 1.300757, acc: 17.19%] [G loss: 4.387072]\n",
      "epoch:23 step:18656 [D loss: 0.369447, acc: 78.12%] [G loss: 3.129813]\n",
      "epoch:23 step:18657 [D loss: 0.417252, acc: 86.72%] [G loss: 2.906856]\n",
      "epoch:23 step:18658 [D loss: 0.891878, acc: 45.31%] [G loss: 2.758892]\n",
      "epoch:23 step:18659 [D loss: 0.353927, acc: 92.97%] [G loss: 3.074780]\n",
      "epoch:23 step:18660 [D loss: 0.390179, acc: 78.91%] [G loss: 3.934547]\n",
      "epoch:23 step:18661 [D loss: 0.758927, acc: 53.12%] [G loss: 2.343649]\n",
      "epoch:23 step:18662 [D loss: 0.210029, acc: 96.88%] [G loss: 5.760384]\n",
      "epoch:23 step:18663 [D loss: 0.443804, acc: 83.59%] [G loss: 2.998865]\n",
      "epoch:23 step:18664 [D loss: 1.336616, acc: 12.50%] [G loss: 2.682673]\n",
      "epoch:23 step:18665 [D loss: 0.535492, acc: 76.56%] [G loss: 3.685160]\n",
      "epoch:23 step:18666 [D loss: 0.816370, acc: 52.34%] [G loss: 3.826283]\n",
      "epoch:23 step:18667 [D loss: 0.611895, acc: 56.25%] [G loss: 2.008721]\n",
      "epoch:23 step:18668 [D loss: 0.576157, acc: 58.59%] [G loss: 5.513031]\n",
      "epoch:23 step:18669 [D loss: 1.517835, acc: 50.00%] [G loss: 1.904801]\n",
      "epoch:23 step:18670 [D loss: 0.102934, acc: 100.00%] [G loss: 4.300047]\n",
      "epoch:23 step:18671 [D loss: 0.767306, acc: 50.00%] [G loss: 1.504370]\n",
      "epoch:23 step:18672 [D loss: 0.224786, acc: 97.66%] [G loss: 4.147079]\n",
      "epoch:23 step:18673 [D loss: 0.759673, acc: 47.66%] [G loss: 2.493972]\n",
      "epoch:23 step:18674 [D loss: 0.329492, acc: 89.06%] [G loss: 4.518454]\n",
      "epoch:23 step:18675 [D loss: 0.268431, acc: 94.53%] [G loss: 3.110780]\n",
      "epoch:23 step:18676 [D loss: 0.352699, acc: 86.72%] [G loss: 2.181620]\n",
      "epoch:23 step:18677 [D loss: 0.200364, acc: 98.44%] [G loss: 2.842775]\n",
      "epoch:23 step:18678 [D loss: 0.514405, acc: 70.31%] [G loss: 3.101611]\n",
      "epoch:23 step:18679 [D loss: 0.567959, acc: 61.72%] [G loss: 3.995372]\n",
      "epoch:23 step:18680 [D loss: 0.727446, acc: 56.25%] [G loss: 3.129370]\n",
      "epoch:23 step:18681 [D loss: 0.602287, acc: 63.28%] [G loss: 3.873747]\n",
      "epoch:23 step:18682 [D loss: 0.646208, acc: 54.69%] [G loss: 5.420100]\n",
      "epoch:23 step:18683 [D loss: 0.578616, acc: 70.31%] [G loss: 3.322628]\n",
      "epoch:23 step:18684 [D loss: 0.399157, acc: 82.81%] [G loss: 2.905717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18685 [D loss: 0.786104, acc: 51.56%] [G loss: 2.574677]\n",
      "epoch:23 step:18686 [D loss: 0.346558, acc: 85.94%] [G loss: 4.296958]\n",
      "epoch:23 step:18687 [D loss: 0.417017, acc: 80.47%] [G loss: 3.615153]\n",
      "epoch:23 step:18688 [D loss: 0.148272, acc: 100.00%] [G loss: 4.182332]\n",
      "epoch:23 step:18689 [D loss: 0.218001, acc: 95.31%] [G loss: 4.950550]\n",
      "epoch:23 step:18690 [D loss: 0.577292, acc: 68.75%] [G loss: 3.621618]\n",
      "epoch:23 step:18691 [D loss: 0.149952, acc: 98.44%] [G loss: 3.099063]\n",
      "epoch:23 step:18692 [D loss: 0.460636, acc: 81.25%] [G loss: 3.867481]\n",
      "epoch:23 step:18693 [D loss: 0.626674, acc: 66.41%] [G loss: 4.107440]\n",
      "epoch:23 step:18694 [D loss: 0.389579, acc: 86.72%] [G loss: 4.099024]\n",
      "epoch:23 step:18695 [D loss: 0.525463, acc: 75.78%] [G loss: 3.678282]\n",
      "epoch:23 step:18696 [D loss: 1.332792, acc: 20.31%] [G loss: 3.418936]\n",
      "epoch:23 step:18697 [D loss: 0.487601, acc: 73.44%] [G loss: 5.034242]\n",
      "epoch:23 step:18698 [D loss: 0.627921, acc: 53.12%] [G loss: 2.866225]\n",
      "epoch:23 step:18699 [D loss: 0.335169, acc: 89.06%] [G loss: 2.408277]\n",
      "epoch:23 step:18700 [D loss: 0.365638, acc: 87.50%] [G loss: 4.912553]\n",
      "epoch:23 step:18701 [D loss: 0.184099, acc: 99.22%] [G loss: 2.925945]\n",
      "epoch:23 step:18702 [D loss: 0.578660, acc: 64.84%] [G loss: 3.950575]\n",
      "epoch:23 step:18703 [D loss: 0.194350, acc: 98.44%] [G loss: 4.114353]\n",
      "epoch:23 step:18704 [D loss: 0.114849, acc: 100.00%] [G loss: 5.021468]\n",
      "epoch:23 step:18705 [D loss: 0.306826, acc: 89.84%] [G loss: 4.230071]\n",
      "epoch:23 step:18706 [D loss: 0.567199, acc: 59.38%] [G loss: 2.810869]\n",
      "epoch:23 step:18707 [D loss: 0.212257, acc: 97.66%] [G loss: 4.979985]\n",
      "epoch:23 step:18708 [D loss: 0.516729, acc: 82.81%] [G loss: 3.967348]\n",
      "epoch:23 step:18709 [D loss: 0.325188, acc: 87.50%] [G loss: 3.860595]\n",
      "epoch:23 step:18710 [D loss: 0.286842, acc: 95.31%] [G loss: 3.512453]\n",
      "epoch:23 step:18711 [D loss: 0.653058, acc: 56.25%] [G loss: 5.395145]\n",
      "epoch:23 step:18712 [D loss: 0.587415, acc: 71.88%] [G loss: 2.840544]\n",
      "epoch:23 step:18713 [D loss: 1.233891, acc: 50.78%] [G loss: 2.525926]\n",
      "epoch:23 step:18714 [D loss: 1.082779, acc: 47.66%] [G loss: 3.540658]\n",
      "epoch:23 step:18715 [D loss: 0.925880, acc: 43.75%] [G loss: 3.578182]\n",
      "epoch:23 step:18716 [D loss: 0.314992, acc: 92.97%] [G loss: 2.408252]\n",
      "epoch:23 step:18717 [D loss: 0.334634, acc: 91.41%] [G loss: 3.680850]\n",
      "epoch:23 step:18718 [D loss: 0.420702, acc: 75.00%] [G loss: 4.674907]\n",
      "epoch:23 step:18719 [D loss: 0.936178, acc: 34.38%] [G loss: 4.428565]\n",
      "epoch:23 step:18720 [D loss: 0.277458, acc: 96.09%] [G loss: 2.400224]\n",
      "epoch:23 step:18721 [D loss: 0.612697, acc: 62.50%] [G loss: 3.767765]\n",
      "epoch:23 step:18722 [D loss: 0.318029, acc: 91.41%] [G loss: 4.672603]\n",
      "epoch:23 step:18723 [D loss: 0.262615, acc: 96.09%] [G loss: 5.575131]\n",
      "epoch:23 step:18724 [D loss: 0.323076, acc: 80.47%] [G loss: 3.326843]\n",
      "epoch:23 step:18725 [D loss: 0.211579, acc: 94.53%] [G loss: 4.485209]\n",
      "epoch:23 step:18726 [D loss: 0.874384, acc: 47.66%] [G loss: 2.773142]\n",
      "epoch:23 step:18727 [D loss: 0.310390, acc: 92.19%] [G loss: 3.385174]\n",
      "epoch:23 step:18728 [D loss: 0.253575, acc: 95.31%] [G loss: 3.420171]\n",
      "epoch:23 step:18729 [D loss: 0.638450, acc: 55.47%] [G loss: 3.516634]\n",
      "epoch:23 step:18730 [D loss: 0.428923, acc: 82.81%] [G loss: 4.829754]\n",
      "epoch:23 step:18731 [D loss: 0.662551, acc: 60.16%] [G loss: 4.852119]\n",
      "epoch:23 step:18732 [D loss: 0.376622, acc: 91.41%] [G loss: 3.456960]\n",
      "epoch:23 step:18733 [D loss: 0.646999, acc: 58.59%] [G loss: 4.252412]\n",
      "epoch:23 step:18734 [D loss: 0.765319, acc: 57.03%] [G loss: 3.923052]\n",
      "epoch:23 step:18735 [D loss: 0.650337, acc: 61.72%] [G loss: 2.851408]\n",
      "epoch:23 step:18736 [D loss: 0.024734, acc: 100.00%] [G loss: 5.451912]\n",
      "epoch:23 step:18737 [D loss: 0.113266, acc: 100.00%] [G loss: 5.052666]\n",
      "epoch:23 step:18738 [D loss: 0.515785, acc: 82.03%] [G loss: 5.135968]\n",
      "epoch:23 step:18739 [D loss: 0.409363, acc: 84.38%] [G loss: 3.631327]\n",
      "epoch:23 step:18740 [D loss: 0.563661, acc: 74.22%] [G loss: 3.360007]\n",
      "epoch:23 step:18741 [D loss: 0.926718, acc: 44.53%] [G loss: 4.627830]\n",
      "epoch:23 step:18742 [D loss: 0.899718, acc: 46.88%] [G loss: 3.117794]\n",
      "epoch:23 step:18743 [D loss: 0.333198, acc: 91.41%] [G loss: 3.168469]\n",
      "epoch:23 step:18744 [D loss: 0.770401, acc: 53.12%] [G loss: 3.422816]\n",
      "epoch:24 step:18745 [D loss: 0.484239, acc: 79.69%] [G loss: 2.668244]\n",
      "epoch:24 step:18746 [D loss: 0.392313, acc: 83.59%] [G loss: 3.377201]\n",
      "epoch:24 step:18747 [D loss: 0.318474, acc: 93.75%] [G loss: 4.041724]\n",
      "epoch:24 step:18748 [D loss: 0.701543, acc: 56.25%] [G loss: 5.633109]\n",
      "epoch:24 step:18749 [D loss: 0.338509, acc: 85.94%] [G loss: 4.995824]\n",
      "epoch:24 step:18750 [D loss: 0.869091, acc: 42.19%] [G loss: 3.897775]\n",
      "epoch:24 step:18751 [D loss: 0.326485, acc: 94.53%] [G loss: 3.682826]\n",
      "epoch:24 step:18752 [D loss: 0.481780, acc: 80.47%] [G loss: 4.828644]\n",
      "epoch:24 step:18753 [D loss: 1.177230, acc: 28.91%] [G loss: 3.283619]\n",
      "epoch:24 step:18754 [D loss: 0.169850, acc: 98.44%] [G loss: 3.348961]\n",
      "epoch:24 step:18755 [D loss: 0.174848, acc: 99.22%] [G loss: 3.376218]\n",
      "epoch:24 step:18756 [D loss: 0.419879, acc: 86.72%] [G loss: 3.724136]\n",
      "epoch:24 step:18757 [D loss: 0.851847, acc: 46.09%] [G loss: 3.804607]\n",
      "epoch:24 step:18758 [D loss: 0.188811, acc: 97.66%] [G loss: 4.703152]\n",
      "epoch:24 step:18759 [D loss: 0.420702, acc: 82.03%] [G loss: 3.267953]\n",
      "epoch:24 step:18760 [D loss: 1.036830, acc: 27.34%] [G loss: 3.028640]\n",
      "epoch:24 step:18761 [D loss: 0.509725, acc: 82.81%] [G loss: 5.120152]\n",
      "epoch:24 step:18762 [D loss: 0.320078, acc: 91.41%] [G loss: 3.109462]\n",
      "epoch:24 step:18763 [D loss: 0.926130, acc: 33.59%] [G loss: 3.421557]\n",
      "epoch:24 step:18764 [D loss: 0.526158, acc: 76.56%] [G loss: 3.688275]\n",
      "epoch:24 step:18765 [D loss: 0.371315, acc: 87.50%] [G loss: 3.890232]\n",
      "epoch:24 step:18766 [D loss: 0.343613, acc: 83.59%] [G loss: 6.164810]\n",
      "epoch:24 step:18767 [D loss: 0.464807, acc: 84.38%] [G loss: 2.508340]\n",
      "epoch:24 step:18768 [D loss: 0.541372, acc: 73.44%] [G loss: 4.923232]\n",
      "epoch:24 step:18769 [D loss: 0.361976, acc: 90.62%] [G loss: 4.067863]\n",
      "epoch:24 step:18770 [D loss: 0.300106, acc: 96.09%] [G loss: 3.811702]\n",
      "epoch:24 step:18771 [D loss: 0.616109, acc: 64.84%] [G loss: 2.853072]\n",
      "epoch:24 step:18772 [D loss: 0.258192, acc: 93.75%] [G loss: 3.155112]\n",
      "epoch:24 step:18773 [D loss: 0.685953, acc: 61.72%] [G loss: 2.959103]\n",
      "epoch:24 step:18774 [D loss: 0.338831, acc: 89.84%] [G loss: 3.416475]\n",
      "epoch:24 step:18775 [D loss: 0.549071, acc: 72.66%] [G loss: 4.143964]\n",
      "epoch:24 step:18776 [D loss: 0.439524, acc: 78.91%] [G loss: 3.350687]\n",
      "epoch:24 step:18777 [D loss: 0.495988, acc: 77.34%] [G loss: 2.582363]\n",
      "epoch:24 step:18778 [D loss: 0.427849, acc: 72.66%] [G loss: 4.666236]\n",
      "epoch:24 step:18779 [D loss: 0.364236, acc: 89.84%] [G loss: 2.821226]\n",
      "epoch:24 step:18780 [D loss: 0.651130, acc: 58.59%] [G loss: 2.959397]\n",
      "epoch:24 step:18781 [D loss: 0.192631, acc: 100.00%] [G loss: 2.595680]\n",
      "epoch:24 step:18782 [D loss: 1.191792, acc: 16.41%] [G loss: 4.244368]\n",
      "epoch:24 step:18783 [D loss: 0.421684, acc: 89.84%] [G loss: 3.661918]\n",
      "epoch:24 step:18784 [D loss: 0.945789, acc: 29.69%] [G loss: 2.476763]\n",
      "epoch:24 step:18785 [D loss: 0.412495, acc: 88.28%] [G loss: 2.664501]\n",
      "epoch:24 step:18786 [D loss: 0.538176, acc: 70.31%] [G loss: 3.823756]\n",
      "epoch:24 step:18787 [D loss: 0.828691, acc: 45.31%] [G loss: 2.356872]\n",
      "epoch:24 step:18788 [D loss: 0.240132, acc: 96.09%] [G loss: 2.252470]\n",
      "epoch:24 step:18789 [D loss: 0.505521, acc: 79.69%] [G loss: 3.981534]\n",
      "epoch:24 step:18790 [D loss: 0.665041, acc: 57.81%] [G loss: 2.740182]\n",
      "epoch:24 step:18791 [D loss: 0.531178, acc: 64.06%] [G loss: 2.798359]\n",
      "epoch:24 step:18792 [D loss: 1.303603, acc: 13.28%] [G loss: 3.920541]\n",
      "epoch:24 step:18793 [D loss: 0.418350, acc: 72.66%] [G loss: 3.316068]\n",
      "epoch:24 step:18794 [D loss: 0.184062, acc: 96.09%] [G loss: 3.585879]\n",
      "epoch:24 step:18795 [D loss: 0.714461, acc: 53.12%] [G loss: 3.836246]\n",
      "epoch:24 step:18796 [D loss: 0.451592, acc: 80.47%] [G loss: 3.662158]\n",
      "epoch:24 step:18797 [D loss: 0.181615, acc: 99.22%] [G loss: 2.805532]\n",
      "epoch:24 step:18798 [D loss: 1.084067, acc: 22.66%] [G loss: 3.164312]\n",
      "epoch:24 step:18799 [D loss: 0.236010, acc: 96.09%] [G loss: 3.903731]\n",
      "epoch:24 step:18800 [D loss: 0.571873, acc: 66.41%] [G loss: 2.216082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:18801 [D loss: 0.535757, acc: 75.78%] [G loss: 2.160027]\n",
      "epoch:24 step:18802 [D loss: 0.392147, acc: 92.19%] [G loss: 4.039431]\n",
      "epoch:24 step:18803 [D loss: 0.237612, acc: 89.84%] [G loss: 5.190096]\n",
      "epoch:24 step:18804 [D loss: 0.262269, acc: 98.44%] [G loss: 4.141678]\n",
      "epoch:24 step:18805 [D loss: 0.432709, acc: 73.44%] [G loss: 5.112144]\n",
      "epoch:24 step:18806 [D loss: 0.183522, acc: 100.00%] [G loss: 3.249618]\n",
      "epoch:24 step:18807 [D loss: 0.507594, acc: 61.72%] [G loss: 3.023136]\n",
      "epoch:24 step:18808 [D loss: 0.976555, acc: 39.06%] [G loss: 3.032801]\n",
      "epoch:24 step:18809 [D loss: 0.315345, acc: 94.53%] [G loss: 3.075520]\n",
      "epoch:24 step:18810 [D loss: 0.410024, acc: 81.25%] [G loss: 4.941452]\n",
      "epoch:24 step:18811 [D loss: 0.157398, acc: 98.44%] [G loss: 3.887447]\n",
      "epoch:24 step:18812 [D loss: 0.410815, acc: 84.38%] [G loss: 3.127178]\n",
      "epoch:24 step:18813 [D loss: 0.099082, acc: 100.00%] [G loss: 4.502672]\n",
      "epoch:24 step:18814 [D loss: 0.480140, acc: 80.47%] [G loss: 4.470097]\n",
      "epoch:24 step:18815 [D loss: 0.879403, acc: 50.00%] [G loss: 1.908154]\n",
      "epoch:24 step:18816 [D loss: 0.717476, acc: 53.91%] [G loss: 4.219177]\n",
      "epoch:24 step:18817 [D loss: 0.229364, acc: 96.88%] [G loss: 2.679553]\n",
      "epoch:24 step:18818 [D loss: 1.014645, acc: 31.25%] [G loss: 3.204214]\n",
      "epoch:24 step:18819 [D loss: 0.567545, acc: 69.53%] [G loss: 3.910015]\n",
      "epoch:24 step:18820 [D loss: 0.399031, acc: 73.44%] [G loss: 3.891720]\n",
      "epoch:24 step:18821 [D loss: 1.414312, acc: 8.59%] [G loss: 3.071188]\n",
      "epoch:24 step:18822 [D loss: 0.348836, acc: 87.50%] [G loss: 4.407271]\n",
      "epoch:24 step:18823 [D loss: 0.195541, acc: 100.00%] [G loss: 3.656439]\n",
      "epoch:24 step:18824 [D loss: 0.573817, acc: 68.75%] [G loss: 3.202086]\n",
      "epoch:24 step:18825 [D loss: 0.517526, acc: 57.81%] [G loss: 5.133350]\n",
      "epoch:24 step:18826 [D loss: 0.308212, acc: 94.53%] [G loss: 3.275843]\n",
      "epoch:24 step:18827 [D loss: 0.884590, acc: 53.12%] [G loss: 2.222136]\n",
      "epoch:24 step:18828 [D loss: 0.615412, acc: 72.66%] [G loss: 4.399234]\n",
      "epoch:24 step:18829 [D loss: 0.457880, acc: 82.81%] [G loss: 2.615081]\n",
      "epoch:24 step:18830 [D loss: 0.790441, acc: 53.12%] [G loss: 4.695009]\n",
      "epoch:24 step:18831 [D loss: 0.531278, acc: 75.00%] [G loss: 2.388367]\n",
      "epoch:24 step:18832 [D loss: 0.488523, acc: 71.09%] [G loss: 3.518241]\n",
      "epoch:24 step:18833 [D loss: 0.128446, acc: 100.00%] [G loss: 4.676930]\n",
      "epoch:24 step:18834 [D loss: 0.475192, acc: 72.66%] [G loss: 2.795815]\n",
      "epoch:24 step:18835 [D loss: 0.578770, acc: 67.19%] [G loss: 3.811777]\n",
      "epoch:24 step:18836 [D loss: 0.093822, acc: 99.22%] [G loss: 4.589658]\n",
      "epoch:24 step:18837 [D loss: 0.323119, acc: 92.19%] [G loss: 3.463404]\n",
      "epoch:24 step:18838 [D loss: 0.298131, acc: 93.75%] [G loss: 3.044939]\n",
      "epoch:24 step:18839 [D loss: 0.293564, acc: 88.28%] [G loss: 3.102260]\n",
      "epoch:24 step:18840 [D loss: 0.404571, acc: 83.59%] [G loss: 4.060580]\n",
      "epoch:24 step:18841 [D loss: 0.577271, acc: 68.75%] [G loss: 4.140598]\n",
      "epoch:24 step:18842 [D loss: 0.119607, acc: 100.00%] [G loss: 3.462704]\n",
      "epoch:24 step:18843 [D loss: 0.798281, acc: 50.00%] [G loss: 3.171243]\n",
      "epoch:24 step:18844 [D loss: 0.207687, acc: 96.09%] [G loss: 4.039904]\n",
      "epoch:24 step:18845 [D loss: 0.265091, acc: 95.31%] [G loss: 2.523103]\n",
      "epoch:24 step:18846 [D loss: 0.952888, acc: 49.22%] [G loss: 3.893663]\n",
      "epoch:24 step:18847 [D loss: 1.257102, acc: 39.06%] [G loss: 2.228034]\n",
      "epoch:24 step:18848 [D loss: 0.183973, acc: 96.09%] [G loss: 3.295821]\n",
      "epoch:24 step:18849 [D loss: 0.440087, acc: 87.50%] [G loss: 3.190141]\n",
      "epoch:24 step:18850 [D loss: 0.683442, acc: 60.94%] [G loss: 2.622885]\n",
      "epoch:24 step:18851 [D loss: 0.750916, acc: 54.69%] [G loss: 2.335434]\n",
      "epoch:24 step:18852 [D loss: 0.487913, acc: 74.22%] [G loss: 3.151515]\n",
      "epoch:24 step:18853 [D loss: 0.719564, acc: 60.16%] [G loss: 3.075206]\n",
      "epoch:24 step:18854 [D loss: 0.382767, acc: 87.50%] [G loss: 3.298132]\n",
      "epoch:24 step:18855 [D loss: 0.339662, acc: 87.50%] [G loss: 2.646894]\n",
      "epoch:24 step:18856 [D loss: 0.353006, acc: 91.41%] [G loss: 3.488228]\n",
      "epoch:24 step:18857 [D loss: 0.370167, acc: 87.50%] [G loss: 2.896341]\n",
      "epoch:24 step:18858 [D loss: 0.503495, acc: 76.56%] [G loss: 4.177389]\n",
      "epoch:24 step:18859 [D loss: 1.095183, acc: 25.78%] [G loss: 3.653823]\n",
      "epoch:24 step:18860 [D loss: 0.975937, acc: 39.84%] [G loss: 4.831090]\n",
      "epoch:24 step:18861 [D loss: 0.181344, acc: 99.22%] [G loss: 4.650521]\n",
      "epoch:24 step:18862 [D loss: 0.418496, acc: 85.94%] [G loss: 3.459144]\n",
      "epoch:24 step:18863 [D loss: 0.333087, acc: 82.03%] [G loss: 2.959022]\n",
      "epoch:24 step:18864 [D loss: 0.383800, acc: 86.72%] [G loss: 5.705888]\n",
      "epoch:24 step:18865 [D loss: 0.347851, acc: 95.31%] [G loss: 3.137637]\n",
      "epoch:24 step:18866 [D loss: 0.282545, acc: 95.31%] [G loss: 4.237308]\n",
      "epoch:24 step:18867 [D loss: 0.132836, acc: 98.44%] [G loss: 3.975320]\n",
      "epoch:24 step:18868 [D loss: 0.753790, acc: 60.16%] [G loss: 3.590878]\n",
      "epoch:24 step:18869 [D loss: 0.294856, acc: 96.09%] [G loss: 4.283933]\n",
      "epoch:24 step:18870 [D loss: 0.214213, acc: 97.66%] [G loss: 5.014393]\n",
      "epoch:24 step:18871 [D loss: 0.350436, acc: 92.19%] [G loss: 3.626380]\n",
      "epoch:24 step:18872 [D loss: 0.296186, acc: 91.41%] [G loss: 3.379277]\n",
      "epoch:24 step:18873 [D loss: 0.630145, acc: 63.28%] [G loss: 2.725543]\n",
      "epoch:24 step:18874 [D loss: 1.324898, acc: 15.62%] [G loss: 3.215240]\n",
      "epoch:24 step:18875 [D loss: 1.506015, acc: 25.00%] [G loss: 3.017595]\n",
      "epoch:24 step:18876 [D loss: 0.620208, acc: 63.28%] [G loss: 2.327764]\n",
      "epoch:24 step:18877 [D loss: 0.219659, acc: 98.44%] [G loss: 3.511227]\n",
      "epoch:24 step:18878 [D loss: 0.483681, acc: 75.00%] [G loss: 3.635846]\n",
      "epoch:24 step:18879 [D loss: 0.237262, acc: 93.75%] [G loss: 4.270655]\n",
      "epoch:24 step:18880 [D loss: 0.529999, acc: 77.34%] [G loss: 4.463071]\n",
      "epoch:24 step:18881 [D loss: 0.258896, acc: 97.66%] [G loss: 4.475531]\n",
      "epoch:24 step:18882 [D loss: 0.301881, acc: 90.62%] [G loss: 3.497547]\n",
      "epoch:24 step:18883 [D loss: 0.313510, acc: 95.31%] [G loss: 3.926126]\n",
      "epoch:24 step:18884 [D loss: 0.675199, acc: 64.84%] [G loss: 2.736840]\n",
      "epoch:24 step:18885 [D loss: 0.626114, acc: 64.06%] [G loss: 2.921746]\n",
      "epoch:24 step:18886 [D loss: 0.436705, acc: 87.50%] [G loss: 2.689078]\n",
      "epoch:24 step:18887 [D loss: 0.284832, acc: 89.06%] [G loss: 3.785752]\n",
      "epoch:24 step:18888 [D loss: 0.843023, acc: 49.22%] [G loss: 3.233881]\n",
      "epoch:24 step:18889 [D loss: 0.233723, acc: 96.88%] [G loss: 3.217836]\n",
      "epoch:24 step:18890 [D loss: 0.142135, acc: 98.44%] [G loss: 3.783292]\n",
      "epoch:24 step:18891 [D loss: 0.794977, acc: 51.56%] [G loss: 2.849308]\n",
      "epoch:24 step:18892 [D loss: 0.212083, acc: 97.66%] [G loss: 2.649594]\n",
      "epoch:24 step:18893 [D loss: 0.500157, acc: 80.47%] [G loss: 3.137028]\n",
      "epoch:24 step:18894 [D loss: 0.219468, acc: 96.88%] [G loss: 4.599586]\n",
      "epoch:24 step:18895 [D loss: 0.298311, acc: 93.75%] [G loss: 2.828224]\n",
      "epoch:24 step:18896 [D loss: 1.697883, acc: 32.03%] [G loss: 2.013048]\n",
      "epoch:24 step:18897 [D loss: 0.434703, acc: 89.06%] [G loss: 4.165010]\n",
      "epoch:24 step:18898 [D loss: 0.455509, acc: 87.50%] [G loss: 3.081124]\n",
      "epoch:24 step:18899 [D loss: 0.646557, acc: 60.94%] [G loss: 2.670514]\n",
      "epoch:24 step:18900 [D loss: 0.474893, acc: 82.03%] [G loss: 3.534525]\n",
      "epoch:24 step:18901 [D loss: 0.336022, acc: 92.19%] [G loss: 3.851231]\n",
      "epoch:24 step:18902 [D loss: 0.676445, acc: 60.16%] [G loss: 4.131730]\n",
      "epoch:24 step:18903 [D loss: 0.207280, acc: 100.00%] [G loss: 5.300986]\n",
      "epoch:24 step:18904 [D loss: 0.744839, acc: 50.00%] [G loss: 3.205892]\n",
      "epoch:24 step:18905 [D loss: 1.096913, acc: 39.84%] [G loss: 3.774781]\n",
      "epoch:24 step:18906 [D loss: 0.101091, acc: 99.22%] [G loss: 4.266832]\n",
      "epoch:24 step:18907 [D loss: 0.804563, acc: 50.78%] [G loss: 2.517437]\n",
      "epoch:24 step:18908 [D loss: 0.244898, acc: 95.31%] [G loss: 4.733658]\n",
      "epoch:24 step:18909 [D loss: 0.403400, acc: 77.34%] [G loss: 4.110747]\n",
      "epoch:24 step:18910 [D loss: 0.509945, acc: 76.56%] [G loss: 3.431323]\n",
      "epoch:24 step:18911 [D loss: 0.871560, acc: 47.66%] [G loss: 2.773980]\n",
      "epoch:24 step:18912 [D loss: 0.874369, acc: 42.19%] [G loss: 3.135375]\n",
      "epoch:24 step:18913 [D loss: 0.326292, acc: 96.09%] [G loss: 3.096219]\n",
      "epoch:24 step:18914 [D loss: 0.767505, acc: 56.25%] [G loss: 4.100488]\n",
      "epoch:24 step:18915 [D loss: 1.070859, acc: 30.47%] [G loss: 3.252186]\n",
      "epoch:24 step:18916 [D loss: 0.248498, acc: 95.31%] [G loss: 3.214662]\n",
      "epoch:24 step:18917 [D loss: 0.503077, acc: 69.53%] [G loss: 2.253751]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:18918 [D loss: 0.392240, acc: 90.62%] [G loss: 4.056384]\n",
      "epoch:24 step:18919 [D loss: 0.162386, acc: 98.44%] [G loss: 3.446571]\n",
      "epoch:24 step:18920 [D loss: 0.330792, acc: 93.75%] [G loss: 4.502466]\n",
      "epoch:24 step:18921 [D loss: 0.154030, acc: 100.00%] [G loss: 4.962808]\n",
      "epoch:24 step:18922 [D loss: 0.958027, acc: 42.97%] [G loss: 3.191117]\n",
      "epoch:24 step:18923 [D loss: 0.285513, acc: 96.09%] [G loss: 3.487777]\n",
      "epoch:24 step:18924 [D loss: 0.471131, acc: 81.25%] [G loss: 5.063852]\n",
      "epoch:24 step:18925 [D loss: 0.290667, acc: 96.88%] [G loss: 2.648610]\n",
      "epoch:24 step:18926 [D loss: 0.252177, acc: 95.31%] [G loss: 5.449403]\n",
      "epoch:24 step:18927 [D loss: 0.237114, acc: 95.31%] [G loss: 3.771966]\n",
      "epoch:24 step:18928 [D loss: 0.302566, acc: 92.19%] [G loss: 3.493515]\n",
      "epoch:24 step:18929 [D loss: 0.301037, acc: 85.94%] [G loss: 4.797627]\n",
      "epoch:24 step:18930 [D loss: 0.189839, acc: 99.22%] [G loss: 3.406114]\n",
      "epoch:24 step:18931 [D loss: 0.492790, acc: 70.31%] [G loss: 3.670334]\n",
      "epoch:24 step:18932 [D loss: 0.494765, acc: 76.56%] [G loss: 4.219037]\n",
      "epoch:24 step:18933 [D loss: 0.049762, acc: 100.00%] [G loss: 6.865925]\n",
      "epoch:24 step:18934 [D loss: 0.671795, acc: 57.81%] [G loss: 4.708568]\n",
      "epoch:24 step:18935 [D loss: 0.205221, acc: 96.88%] [G loss: 3.517479]\n",
      "epoch:24 step:18936 [D loss: 0.539062, acc: 70.31%] [G loss: 3.401155]\n",
      "epoch:24 step:18937 [D loss: 0.385552, acc: 85.94%] [G loss: 3.741575]\n",
      "epoch:24 step:18938 [D loss: 0.399925, acc: 75.78%] [G loss: 6.011027]\n",
      "epoch:24 step:18939 [D loss: 0.573476, acc: 69.53%] [G loss: 3.547736]\n",
      "epoch:24 step:18940 [D loss: 0.413195, acc: 89.06%] [G loss: 4.172208]\n",
      "epoch:24 step:18941 [D loss: 0.173098, acc: 97.66%] [G loss: 3.787439]\n",
      "epoch:24 step:18942 [D loss: 0.753461, acc: 53.91%] [G loss: 4.375458]\n",
      "epoch:24 step:18943 [D loss: 0.370041, acc: 78.12%] [G loss: 3.827499]\n",
      "epoch:24 step:18944 [D loss: 0.395761, acc: 83.59%] [G loss: 3.860100]\n",
      "epoch:24 step:18945 [D loss: 1.234620, acc: 19.53%] [G loss: 2.679785]\n",
      "epoch:24 step:18946 [D loss: 1.306476, acc: 10.16%] [G loss: 2.403245]\n",
      "epoch:24 step:18947 [D loss: 0.617361, acc: 62.50%] [G loss: 2.622120]\n",
      "epoch:24 step:18948 [D loss: 0.394551, acc: 85.16%] [G loss: 3.187072]\n",
      "epoch:24 step:18949 [D loss: 0.366171, acc: 90.62%] [G loss: 3.408522]\n",
      "epoch:24 step:18950 [D loss: 1.092832, acc: 49.22%] [G loss: 3.303021]\n",
      "epoch:24 step:18951 [D loss: 0.616000, acc: 60.94%] [G loss: 5.696028]\n",
      "epoch:24 step:18952 [D loss: 0.269387, acc: 92.19%] [G loss: 4.447330]\n",
      "epoch:24 step:18953 [D loss: 0.846559, acc: 45.31%] [G loss: 3.098948]\n",
      "epoch:24 step:18954 [D loss: 0.285456, acc: 91.41%] [G loss: 3.468838]\n",
      "epoch:24 step:18955 [D loss: 0.710490, acc: 57.03%] [G loss: 2.824034]\n",
      "epoch:24 step:18956 [D loss: 0.163918, acc: 99.22%] [G loss: 4.899884]\n",
      "epoch:24 step:18957 [D loss: 0.739697, acc: 52.34%] [G loss: 5.480758]\n",
      "epoch:24 step:18958 [D loss: 0.254447, acc: 91.41%] [G loss: 2.784340]\n",
      "epoch:24 step:18959 [D loss: 0.436980, acc: 74.22%] [G loss: 3.175857]\n",
      "epoch:24 step:18960 [D loss: 0.353597, acc: 84.38%] [G loss: 3.327647]\n",
      "epoch:24 step:18961 [D loss: 0.783498, acc: 54.69%] [G loss: 2.797132]\n",
      "epoch:24 step:18962 [D loss: 0.275116, acc: 87.50%] [G loss: 4.030800]\n",
      "epoch:24 step:18963 [D loss: 0.526074, acc: 73.44%] [G loss: 3.163816]\n",
      "epoch:24 step:18964 [D loss: 0.421634, acc: 84.38%] [G loss: 3.336144]\n",
      "epoch:24 step:18965 [D loss: 0.806551, acc: 48.44%] [G loss: 3.483057]\n",
      "epoch:24 step:18966 [D loss: 0.519453, acc: 75.78%] [G loss: 4.017624]\n",
      "epoch:24 step:18967 [D loss: 0.467294, acc: 78.91%] [G loss: 4.487754]\n",
      "epoch:24 step:18968 [D loss: 0.572045, acc: 71.09%] [G loss: 2.299746]\n",
      "epoch:24 step:18969 [D loss: 0.325075, acc: 96.09%] [G loss: 2.880743]\n",
      "epoch:24 step:18970 [D loss: 0.634205, acc: 62.50%] [G loss: 2.140792]\n",
      "epoch:24 step:18971 [D loss: 0.273679, acc: 96.09%] [G loss: 4.365826]\n",
      "epoch:24 step:18972 [D loss: 0.463115, acc: 66.41%] [G loss: 6.554483]\n",
      "epoch:24 step:18973 [D loss: 0.356687, acc: 92.19%] [G loss: 2.222634]\n",
      "epoch:24 step:18974 [D loss: 0.748538, acc: 48.44%] [G loss: 5.334043]\n",
      "epoch:24 step:18975 [D loss: 0.418104, acc: 82.81%] [G loss: 3.378089]\n",
      "epoch:24 step:18976 [D loss: 0.882433, acc: 39.06%] [G loss: 3.385600]\n",
      "epoch:24 step:18977 [D loss: 0.243914, acc: 97.66%] [G loss: 3.904870]\n",
      "epoch:24 step:18978 [D loss: 0.938058, acc: 35.94%] [G loss: 5.442190]\n",
      "epoch:24 step:18979 [D loss: 0.173731, acc: 98.44%] [G loss: 5.096093]\n",
      "epoch:24 step:18980 [D loss: 0.396245, acc: 85.94%] [G loss: 3.489108]\n",
      "epoch:24 step:18981 [D loss: 0.635833, acc: 67.97%] [G loss: 3.507184]\n",
      "epoch:24 step:18982 [D loss: 0.791459, acc: 55.47%] [G loss: 3.286838]\n",
      "epoch:24 step:18983 [D loss: 0.188120, acc: 96.88%] [G loss: 3.659582]\n",
      "epoch:24 step:18984 [D loss: 1.521143, acc: 10.16%] [G loss: 3.875661]\n",
      "epoch:24 step:18985 [D loss: 0.273693, acc: 95.31%] [G loss: 2.757630]\n",
      "epoch:24 step:18986 [D loss: 0.286322, acc: 96.88%] [G loss: 3.849931]\n",
      "epoch:24 step:18987 [D loss: 0.231914, acc: 96.88%] [G loss: 3.219142]\n",
      "epoch:24 step:18988 [D loss: 0.072939, acc: 100.00%] [G loss: 4.405548]\n",
      "epoch:24 step:18989 [D loss: 0.986715, acc: 23.44%] [G loss: 3.254816]\n",
      "epoch:24 step:18990 [D loss: 0.304387, acc: 89.06%] [G loss: 3.978504]\n",
      "epoch:24 step:18991 [D loss: 0.606434, acc: 68.75%] [G loss: 2.960164]\n",
      "epoch:24 step:18992 [D loss: 0.257763, acc: 89.06%] [G loss: 4.001433]\n",
      "epoch:24 step:18993 [D loss: 0.306737, acc: 86.72%] [G loss: 4.152676]\n",
      "epoch:24 step:18994 [D loss: 0.995346, acc: 48.44%] [G loss: 2.483351]\n",
      "epoch:24 step:18995 [D loss: 0.223545, acc: 98.44%] [G loss: 5.589499]\n",
      "epoch:24 step:18996 [D loss: 0.584634, acc: 60.94%] [G loss: 3.529421]\n",
      "epoch:24 step:18997 [D loss: 0.422382, acc: 71.09%] [G loss: 3.353494]\n",
      "epoch:24 step:18998 [D loss: 0.273516, acc: 92.19%] [G loss: 3.633446]\n",
      "epoch:24 step:18999 [D loss: 0.362307, acc: 85.16%] [G loss: 3.547632]\n",
      "epoch:24 step:19000 [D loss: 0.361405, acc: 92.97%] [G loss: 2.818942]\n",
      "epoch:24 step:19001 [D loss: 1.526294, acc: 21.09%] [G loss: 3.723129]\n",
      "epoch:24 step:19002 [D loss: 0.895399, acc: 32.03%] [G loss: 2.897166]\n",
      "epoch:24 step:19003 [D loss: 0.407124, acc: 83.59%] [G loss: 2.870318]\n",
      "epoch:24 step:19004 [D loss: 0.589500, acc: 65.62%] [G loss: 3.422713]\n",
      "epoch:24 step:19005 [D loss: 0.342398, acc: 93.75%] [G loss: 3.518556]\n",
      "epoch:24 step:19006 [D loss: 0.291703, acc: 89.06%] [G loss: 4.208430]\n",
      "epoch:24 step:19007 [D loss: 0.646581, acc: 58.59%] [G loss: 3.159964]\n",
      "epoch:24 step:19008 [D loss: 0.804473, acc: 50.00%] [G loss: 3.912125]\n",
      "epoch:24 step:19009 [D loss: 0.528764, acc: 75.00%] [G loss: 3.912572]\n",
      "epoch:24 step:19010 [D loss: 0.756577, acc: 56.25%] [G loss: 4.083881]\n",
      "epoch:24 step:19011 [D loss: 0.870474, acc: 37.50%] [G loss: 3.678071]\n",
      "epoch:24 step:19012 [D loss: 0.782813, acc: 51.56%] [G loss: 3.022097]\n",
      "epoch:24 step:19013 [D loss: 1.323955, acc: 7.03%] [G loss: 2.225378]\n",
      "epoch:24 step:19014 [D loss: 0.392712, acc: 92.19%] [G loss: 3.460092]\n",
      "epoch:24 step:19015 [D loss: 0.549573, acc: 74.22%] [G loss: 3.023182]\n",
      "epoch:24 step:19016 [D loss: 0.600060, acc: 57.81%] [G loss: 5.015042]\n",
      "epoch:24 step:19017 [D loss: 0.731236, acc: 51.56%] [G loss: 4.003078]\n",
      "epoch:24 step:19018 [D loss: 0.364287, acc: 91.41%] [G loss: 3.120906]\n",
      "epoch:24 step:19019 [D loss: 0.373198, acc: 85.16%] [G loss: 2.329564]\n",
      "epoch:24 step:19020 [D loss: 0.687253, acc: 57.03%] [G loss: 2.888879]\n",
      "epoch:24 step:19021 [D loss: 0.625782, acc: 67.97%] [G loss: 1.936661]\n",
      "epoch:24 step:19022 [D loss: 0.256042, acc: 96.09%] [G loss: 3.734456]\n",
      "epoch:24 step:19023 [D loss: 0.558618, acc: 76.56%] [G loss: 3.296212]\n",
      "epoch:24 step:19024 [D loss: 0.227217, acc: 94.53%] [G loss: 3.896988]\n",
      "epoch:24 step:19025 [D loss: 0.525936, acc: 82.03%] [G loss: 3.421889]\n",
      "epoch:24 step:19026 [D loss: 0.937050, acc: 28.12%] [G loss: 3.910809]\n",
      "epoch:24 step:19027 [D loss: 0.571500, acc: 67.97%] [G loss: 3.027142]\n",
      "epoch:24 step:19028 [D loss: 0.253819, acc: 94.53%] [G loss: 4.608681]\n",
      "epoch:24 step:19029 [D loss: 0.804296, acc: 50.78%] [G loss: 3.888990]\n",
      "epoch:24 step:19030 [D loss: 0.480355, acc: 85.94%] [G loss: 3.863584]\n",
      "epoch:24 step:19031 [D loss: 0.607823, acc: 64.06%] [G loss: 3.529546]\n",
      "epoch:24 step:19032 [D loss: 0.840977, acc: 39.84%] [G loss: 3.785259]\n",
      "epoch:24 step:19033 [D loss: 0.625921, acc: 62.50%] [G loss: 3.062276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19034 [D loss: 0.397509, acc: 93.75%] [G loss: 3.018869]\n",
      "epoch:24 step:19035 [D loss: 0.675247, acc: 63.28%] [G loss: 3.114537]\n",
      "epoch:24 step:19036 [D loss: 0.774386, acc: 53.91%] [G loss: 2.299587]\n",
      "epoch:24 step:19037 [D loss: 0.305999, acc: 93.75%] [G loss: 3.036314]\n",
      "epoch:24 step:19038 [D loss: 0.959447, acc: 35.16%] [G loss: 3.393591]\n",
      "epoch:24 step:19039 [D loss: 0.418584, acc: 84.38%] [G loss: 4.113395]\n",
      "epoch:24 step:19040 [D loss: 0.337920, acc: 92.19%] [G loss: 4.196977]\n",
      "epoch:24 step:19041 [D loss: 0.811521, acc: 38.28%] [G loss: 2.537903]\n",
      "epoch:24 step:19042 [D loss: 0.314419, acc: 90.62%] [G loss: 3.826802]\n",
      "epoch:24 step:19043 [D loss: 0.313344, acc: 96.88%] [G loss: 3.117296]\n",
      "epoch:24 step:19044 [D loss: 0.628450, acc: 64.06%] [G loss: 4.241459]\n",
      "epoch:24 step:19045 [D loss: 0.378646, acc: 92.19%] [G loss: 3.656619]\n",
      "epoch:24 step:19046 [D loss: 0.319632, acc: 96.88%] [G loss: 3.031829]\n",
      "epoch:24 step:19047 [D loss: 1.038924, acc: 25.00%] [G loss: 3.809760]\n",
      "epoch:24 step:19048 [D loss: 0.218748, acc: 95.31%] [G loss: 3.599822]\n",
      "epoch:24 step:19049 [D loss: 0.287175, acc: 96.88%] [G loss: 4.002231]\n",
      "epoch:24 step:19050 [D loss: 0.676434, acc: 60.94%] [G loss: 2.764520]\n",
      "epoch:24 step:19051 [D loss: 0.621839, acc: 67.19%] [G loss: 2.629604]\n",
      "epoch:24 step:19052 [D loss: 0.375377, acc: 81.25%] [G loss: 2.478914]\n",
      "epoch:24 step:19053 [D loss: 0.873212, acc: 35.16%] [G loss: 1.487010]\n",
      "epoch:24 step:19054 [D loss: 0.148612, acc: 100.00%] [G loss: 4.931962]\n",
      "epoch:24 step:19055 [D loss: 0.339903, acc: 86.72%] [G loss: 4.135175]\n",
      "epoch:24 step:19056 [D loss: 0.538119, acc: 72.66%] [G loss: 2.958448]\n",
      "epoch:24 step:19057 [D loss: 0.527486, acc: 64.06%] [G loss: 3.273994]\n",
      "epoch:24 step:19058 [D loss: 0.274780, acc: 92.97%] [G loss: 2.838513]\n",
      "epoch:24 step:19059 [D loss: 0.763655, acc: 50.00%] [G loss: 2.983805]\n",
      "epoch:24 step:19060 [D loss: 0.435534, acc: 83.59%] [G loss: 3.031320]\n",
      "epoch:24 step:19061 [D loss: 0.496287, acc: 73.44%] [G loss: 3.698291]\n",
      "epoch:24 step:19062 [D loss: 0.375532, acc: 88.28%] [G loss: 3.268608]\n",
      "epoch:24 step:19063 [D loss: 0.927431, acc: 35.94%] [G loss: 3.411481]\n",
      "epoch:24 step:19064 [D loss: 0.584604, acc: 68.75%] [G loss: 2.531265]\n",
      "epoch:24 step:19065 [D loss: 1.060840, acc: 24.22%] [G loss: 3.014765]\n",
      "epoch:24 step:19066 [D loss: 0.268576, acc: 99.22%] [G loss: 3.806714]\n",
      "epoch:24 step:19067 [D loss: 0.655558, acc: 59.38%] [G loss: 5.429607]\n",
      "epoch:24 step:19068 [D loss: 0.783013, acc: 53.12%] [G loss: 3.159457]\n",
      "epoch:24 step:19069 [D loss: 0.813651, acc: 56.25%] [G loss: 3.489266]\n",
      "epoch:24 step:19070 [D loss: 0.348666, acc: 92.19%] [G loss: 2.655565]\n",
      "epoch:24 step:19071 [D loss: 0.421206, acc: 87.50%] [G loss: 2.692424]\n",
      "epoch:24 step:19072 [D loss: 0.838325, acc: 42.97%] [G loss: 2.760854]\n",
      "epoch:24 step:19073 [D loss: 0.370979, acc: 89.84%] [G loss: 3.918101]\n",
      "epoch:24 step:19074 [D loss: 0.840480, acc: 52.34%] [G loss: 3.820677]\n",
      "epoch:24 step:19075 [D loss: 0.417143, acc: 77.34%] [G loss: 2.150694]\n",
      "epoch:24 step:19076 [D loss: 0.562723, acc: 72.66%] [G loss: 3.469685]\n",
      "epoch:24 step:19077 [D loss: 0.117489, acc: 99.22%] [G loss: 5.556091]\n",
      "epoch:24 step:19078 [D loss: 0.596395, acc: 67.97%] [G loss: 3.623515]\n",
      "epoch:24 step:19079 [D loss: 0.200416, acc: 100.00%] [G loss: 4.767293]\n",
      "epoch:24 step:19080 [D loss: 0.290972, acc: 96.09%] [G loss: 4.343340]\n",
      "epoch:24 step:19081 [D loss: 0.351921, acc: 89.84%] [G loss: 3.103854]\n",
      "epoch:24 step:19082 [D loss: 0.271649, acc: 94.53%] [G loss: 3.670682]\n",
      "epoch:24 step:19083 [D loss: 0.347352, acc: 94.53%] [G loss: 3.423022]\n",
      "epoch:24 step:19084 [D loss: 1.176541, acc: 18.75%] [G loss: 4.265871]\n",
      "epoch:24 step:19085 [D loss: 0.417100, acc: 80.47%] [G loss: 4.460330]\n",
      "epoch:24 step:19086 [D loss: 0.484964, acc: 70.31%] [G loss: 4.341917]\n",
      "epoch:24 step:19087 [D loss: 0.443169, acc: 84.38%] [G loss: 3.857378]\n",
      "epoch:24 step:19088 [D loss: 0.459402, acc: 67.19%] [G loss: 3.286607]\n",
      "epoch:24 step:19089 [D loss: 0.291723, acc: 86.72%] [G loss: 3.047483]\n",
      "epoch:24 step:19090 [D loss: 0.546500, acc: 66.41%] [G loss: 2.461036]\n",
      "epoch:24 step:19091 [D loss: 0.325049, acc: 90.62%] [G loss: 3.384423]\n",
      "epoch:24 step:19092 [D loss: 0.436730, acc: 68.75%] [G loss: 3.566006]\n",
      "epoch:24 step:19093 [D loss: 0.226895, acc: 99.22%] [G loss: 3.049416]\n",
      "epoch:24 step:19094 [D loss: 0.421954, acc: 86.72%] [G loss: 3.336864]\n",
      "epoch:24 step:19095 [D loss: 0.802000, acc: 49.22%] [G loss: 2.961249]\n",
      "epoch:24 step:19096 [D loss: 0.466997, acc: 77.34%] [G loss: 5.323752]\n",
      "epoch:24 step:19097 [D loss: 0.281161, acc: 92.97%] [G loss: 4.473251]\n",
      "epoch:24 step:19098 [D loss: 0.602341, acc: 62.50%] [G loss: 2.906182]\n",
      "epoch:24 step:19099 [D loss: 0.787401, acc: 51.56%] [G loss: 2.510861]\n",
      "epoch:24 step:19100 [D loss: 0.395621, acc: 83.59%] [G loss: 2.171388]\n",
      "epoch:24 step:19101 [D loss: 0.891440, acc: 39.06%] [G loss: 3.947491]\n",
      "epoch:24 step:19102 [D loss: 0.490763, acc: 81.25%] [G loss: 2.939125]\n",
      "epoch:24 step:19103 [D loss: 0.746587, acc: 51.56%] [G loss: 2.709734]\n",
      "epoch:24 step:19104 [D loss: 0.862474, acc: 48.44%] [G loss: 3.350373]\n",
      "epoch:24 step:19105 [D loss: 0.546028, acc: 71.88%] [G loss: 2.345460]\n",
      "epoch:24 step:19106 [D loss: 0.416666, acc: 89.84%] [G loss: 3.953212]\n",
      "epoch:24 step:19107 [D loss: 0.535407, acc: 76.56%] [G loss: 3.223611]\n",
      "epoch:24 step:19108 [D loss: 0.355801, acc: 94.53%] [G loss: 2.306405]\n",
      "epoch:24 step:19109 [D loss: 0.627171, acc: 64.84%] [G loss: 3.179326]\n",
      "epoch:24 step:19110 [D loss: 0.277632, acc: 96.09%] [G loss: 2.393829]\n",
      "epoch:24 step:19111 [D loss: 1.169823, acc: 9.38%] [G loss: 2.994107]\n",
      "epoch:24 step:19112 [D loss: 0.257507, acc: 93.75%] [G loss: 4.204380]\n",
      "epoch:24 step:19113 [D loss: 0.580668, acc: 64.84%] [G loss: 4.316983]\n",
      "epoch:24 step:19114 [D loss: 0.540227, acc: 75.00%] [G loss: 4.319937]\n",
      "epoch:24 step:19115 [D loss: 0.887546, acc: 46.88%] [G loss: 5.098886]\n",
      "epoch:24 step:19116 [D loss: 0.557852, acc: 69.53%] [G loss: 2.063443]\n",
      "epoch:24 step:19117 [D loss: 1.224777, acc: 29.69%] [G loss: 3.171767]\n",
      "epoch:24 step:19118 [D loss: 0.120429, acc: 100.00%] [G loss: 3.986407]\n",
      "epoch:24 step:19119 [D loss: 0.441807, acc: 89.06%] [G loss: 4.095096]\n",
      "epoch:24 step:19120 [D loss: 0.345278, acc: 85.94%] [G loss: 4.906333]\n",
      "epoch:24 step:19121 [D loss: 0.414780, acc: 84.38%] [G loss: 2.789860]\n",
      "epoch:24 step:19122 [D loss: 0.362927, acc: 87.50%] [G loss: 3.565794]\n",
      "epoch:24 step:19123 [D loss: 0.372881, acc: 88.28%] [G loss: 3.877684]\n",
      "epoch:24 step:19124 [D loss: 0.527375, acc: 64.06%] [G loss: 3.823381]\n",
      "epoch:24 step:19125 [D loss: 0.300256, acc: 87.50%] [G loss: 2.488546]\n",
      "epoch:24 step:19126 [D loss: 0.278530, acc: 92.19%] [G loss: 3.538081]\n",
      "epoch:24 step:19127 [D loss: 0.193068, acc: 99.22%] [G loss: 4.305048]\n",
      "epoch:24 step:19128 [D loss: 0.646381, acc: 58.59%] [G loss: 2.483363]\n",
      "epoch:24 step:19129 [D loss: 0.267010, acc: 95.31%] [G loss: 4.792972]\n",
      "epoch:24 step:19130 [D loss: 0.510696, acc: 74.22%] [G loss: 3.367928]\n",
      "epoch:24 step:19131 [D loss: 0.188820, acc: 99.22%] [G loss: 4.457520]\n",
      "epoch:24 step:19132 [D loss: 0.357845, acc: 92.19%] [G loss: 2.323586]\n",
      "epoch:24 step:19133 [D loss: 0.622926, acc: 65.62%] [G loss: 3.661257]\n",
      "epoch:24 step:19134 [D loss: 0.595808, acc: 61.72%] [G loss: 4.199813]\n",
      "epoch:24 step:19135 [D loss: 0.374129, acc: 79.69%] [G loss: 4.563611]\n",
      "epoch:24 step:19136 [D loss: 0.148163, acc: 98.44%] [G loss: 5.132565]\n",
      "epoch:24 step:19137 [D loss: 0.977459, acc: 52.34%] [G loss: 4.238732]\n",
      "epoch:24 step:19138 [D loss: 0.270807, acc: 93.75%] [G loss: 5.020498]\n",
      "epoch:24 step:19139 [D loss: 0.173113, acc: 100.00%] [G loss: 3.207626]\n",
      "epoch:24 step:19140 [D loss: 0.179644, acc: 97.66%] [G loss: 5.357289]\n",
      "epoch:24 step:19141 [D loss: 0.515319, acc: 77.34%] [G loss: 2.656040]\n",
      "epoch:24 step:19142 [D loss: 0.301541, acc: 92.19%] [G loss: 2.691538]\n",
      "epoch:24 step:19143 [D loss: 0.260509, acc: 93.75%] [G loss: 3.608589]\n",
      "epoch:24 step:19144 [D loss: 0.322292, acc: 85.16%] [G loss: 2.342275]\n",
      "epoch:24 step:19145 [D loss: 0.438269, acc: 78.91%] [G loss: 4.679677]\n",
      "epoch:24 step:19146 [D loss: 0.262592, acc: 95.31%] [G loss: 4.695223]\n",
      "epoch:24 step:19147 [D loss: 0.380894, acc: 90.62%] [G loss: 4.321512]\n",
      "epoch:24 step:19148 [D loss: 0.277865, acc: 98.44%] [G loss: 3.183662]\n",
      "epoch:24 step:19149 [D loss: 0.558157, acc: 69.53%] [G loss: 3.361124]\n",
      "epoch:24 step:19150 [D loss: 0.664861, acc: 64.06%] [G loss: 3.582542]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19151 [D loss: 0.406413, acc: 90.62%] [G loss: 3.279490]\n",
      "epoch:24 step:19152 [D loss: 0.269858, acc: 96.88%] [G loss: 4.401092]\n",
      "epoch:24 step:19153 [D loss: 0.274867, acc: 89.84%] [G loss: 3.001156]\n",
      "epoch:24 step:19154 [D loss: 0.623857, acc: 67.19%] [G loss: 3.257125]\n",
      "epoch:24 step:19155 [D loss: 0.860065, acc: 48.44%] [G loss: 4.229821]\n",
      "epoch:24 step:19156 [D loss: 0.244428, acc: 92.19%] [G loss: 4.130450]\n",
      "epoch:24 step:19157 [D loss: 0.194877, acc: 98.44%] [G loss: 2.414466]\n",
      "epoch:24 step:19158 [D loss: 0.872977, acc: 34.38%] [G loss: 2.927581]\n",
      "epoch:24 step:19159 [D loss: 0.197703, acc: 97.66%] [G loss: 3.452055]\n",
      "epoch:24 step:19160 [D loss: 0.244701, acc: 96.09%] [G loss: 5.127914]\n",
      "epoch:24 step:19161 [D loss: 0.131706, acc: 100.00%] [G loss: 3.608819]\n",
      "epoch:24 step:19162 [D loss: 0.100612, acc: 100.00%] [G loss: 4.889094]\n",
      "epoch:24 step:19163 [D loss: 0.277034, acc: 96.88%] [G loss: 2.755729]\n",
      "epoch:24 step:19164 [D loss: 0.361557, acc: 90.62%] [G loss: 5.044508]\n",
      "epoch:24 step:19165 [D loss: 0.370239, acc: 90.62%] [G loss: 3.891389]\n",
      "epoch:24 step:19166 [D loss: 0.359401, acc: 90.62%] [G loss: 2.991934]\n",
      "epoch:24 step:19167 [D loss: 0.298414, acc: 89.84%] [G loss: 4.195697]\n",
      "epoch:24 step:19168 [D loss: 0.230114, acc: 98.44%] [G loss: 4.555723]\n",
      "epoch:24 step:19169 [D loss: 0.470603, acc: 78.91%] [G loss: 3.746243]\n",
      "epoch:24 step:19170 [D loss: 0.241693, acc: 99.22%] [G loss: 3.345624]\n",
      "epoch:24 step:19171 [D loss: 0.266634, acc: 95.31%] [G loss: 4.320549]\n",
      "epoch:24 step:19172 [D loss: 0.117053, acc: 98.44%] [G loss: 3.601589]\n",
      "epoch:24 step:19173 [D loss: 0.205214, acc: 96.09%] [G loss: 3.961848]\n",
      "epoch:24 step:19174 [D loss: 0.285072, acc: 96.09%] [G loss: 4.472078]\n",
      "epoch:24 step:19175 [D loss: 0.421698, acc: 87.50%] [G loss: 5.834533]\n",
      "epoch:24 step:19176 [D loss: 0.204179, acc: 99.22%] [G loss: 3.027594]\n",
      "epoch:24 step:19177 [D loss: 0.613682, acc: 61.72%] [G loss: 4.328676]\n",
      "epoch:24 step:19178 [D loss: 0.166271, acc: 99.22%] [G loss: 4.993275]\n",
      "epoch:24 step:19179 [D loss: 0.301499, acc: 96.09%] [G loss: 5.067887]\n",
      "epoch:24 step:19180 [D loss: 1.277126, acc: 41.41%] [G loss: 4.520096]\n",
      "epoch:24 step:19181 [D loss: 0.967544, acc: 25.78%] [G loss: 2.697031]\n",
      "epoch:24 step:19182 [D loss: 0.657943, acc: 56.25%] [G loss: 3.735956]\n",
      "epoch:24 step:19183 [D loss: 0.665627, acc: 58.59%] [G loss: 4.202684]\n",
      "epoch:24 step:19184 [D loss: 0.588304, acc: 68.75%] [G loss: 3.396616]\n",
      "epoch:24 step:19185 [D loss: 0.653512, acc: 67.19%] [G loss: 4.177508]\n",
      "epoch:24 step:19186 [D loss: 0.550248, acc: 68.75%] [G loss: 2.599979]\n",
      "epoch:24 step:19187 [D loss: 0.744363, acc: 50.78%] [G loss: 3.394650]\n",
      "epoch:24 step:19188 [D loss: 0.101644, acc: 100.00%] [G loss: 4.095816]\n",
      "epoch:24 step:19189 [D loss: 0.346987, acc: 92.19%] [G loss: 3.530987]\n",
      "epoch:24 step:19190 [D loss: 0.203103, acc: 99.22%] [G loss: 2.769460]\n",
      "epoch:24 step:19191 [D loss: 0.579210, acc: 58.59%] [G loss: 6.280632]\n",
      "epoch:24 step:19192 [D loss: 0.341735, acc: 82.81%] [G loss: 5.224079]\n",
      "epoch:24 step:19193 [D loss: 0.770642, acc: 57.81%] [G loss: 3.484797]\n",
      "epoch:24 step:19194 [D loss: 0.205086, acc: 95.31%] [G loss: 5.714104]\n",
      "epoch:24 step:19195 [D loss: 0.368871, acc: 89.84%] [G loss: 3.121668]\n",
      "epoch:24 step:19196 [D loss: 0.814750, acc: 46.88%] [G loss: 4.264413]\n",
      "epoch:24 step:19197 [D loss: 0.257954, acc: 96.09%] [G loss: 4.518373]\n",
      "epoch:24 step:19198 [D loss: 0.595675, acc: 62.50%] [G loss: 3.611599]\n",
      "epoch:24 step:19199 [D loss: 0.843909, acc: 52.34%] [G loss: 3.781422]\n",
      "epoch:24 step:19200 [D loss: 0.725586, acc: 58.59%] [G loss: 3.304931]\n",
      "epoch:24 step:19201 [D loss: 0.318577, acc: 95.31%] [G loss: 4.130089]\n",
      "epoch:24 step:19202 [D loss: 0.874139, acc: 50.78%] [G loss: 4.225454]\n",
      "epoch:24 step:19203 [D loss: 0.240417, acc: 93.75%] [G loss: 2.845633]\n",
      "epoch:24 step:19204 [D loss: 0.422042, acc: 89.84%] [G loss: 3.010607]\n",
      "epoch:24 step:19205 [D loss: 0.138093, acc: 100.00%] [G loss: 2.699790]\n",
      "epoch:24 step:19206 [D loss: 0.179928, acc: 97.66%] [G loss: 4.038608]\n",
      "epoch:24 step:19207 [D loss: 0.575072, acc: 73.44%] [G loss: 2.923418]\n",
      "epoch:24 step:19208 [D loss: 0.587419, acc: 67.97%] [G loss: 3.363488]\n",
      "epoch:24 step:19209 [D loss: 0.472762, acc: 73.44%] [G loss: 3.363050]\n",
      "epoch:24 step:19210 [D loss: 0.197050, acc: 97.66%] [G loss: 6.577849]\n",
      "epoch:24 step:19211 [D loss: 0.244619, acc: 98.44%] [G loss: 3.531729]\n",
      "epoch:24 step:19212 [D loss: 0.330804, acc: 90.62%] [G loss: 4.077943]\n",
      "epoch:24 step:19213 [D loss: 0.550494, acc: 62.50%] [G loss: 3.040020]\n",
      "epoch:24 step:19214 [D loss: 0.110648, acc: 100.00%] [G loss: 4.151405]\n",
      "epoch:24 step:19215 [D loss: 0.395917, acc: 73.44%] [G loss: 4.561828]\n",
      "epoch:24 step:19216 [D loss: 0.317310, acc: 92.97%] [G loss: 4.043460]\n",
      "epoch:24 step:19217 [D loss: 0.363841, acc: 89.06%] [G loss: 4.173187]\n",
      "epoch:24 step:19218 [D loss: 0.842421, acc: 52.34%] [G loss: 4.545532]\n",
      "epoch:24 step:19219 [D loss: 0.308995, acc: 90.62%] [G loss: 2.905920]\n",
      "epoch:24 step:19220 [D loss: 0.180623, acc: 99.22%] [G loss: 3.508487]\n",
      "epoch:24 step:19221 [D loss: 0.264970, acc: 95.31%] [G loss: 2.887566]\n",
      "epoch:24 step:19222 [D loss: 0.156489, acc: 98.44%] [G loss: 3.836513]\n",
      "epoch:24 step:19223 [D loss: 0.339739, acc: 92.19%] [G loss: 3.046477]\n",
      "epoch:24 step:19224 [D loss: 0.156010, acc: 100.00%] [G loss: 3.974104]\n",
      "epoch:24 step:19225 [D loss: 1.463788, acc: 13.28%] [G loss: 3.696122]\n",
      "epoch:24 step:19226 [D loss: 1.016052, acc: 32.81%] [G loss: 5.520852]\n",
      "epoch:24 step:19227 [D loss: 0.550237, acc: 71.88%] [G loss: 3.848005]\n",
      "epoch:24 step:19228 [D loss: 0.720449, acc: 57.81%] [G loss: 3.453211]\n",
      "epoch:24 step:19229 [D loss: 0.218724, acc: 98.44%] [G loss: 4.996921]\n",
      "epoch:24 step:19230 [D loss: 0.693778, acc: 57.03%] [G loss: 3.825346]\n",
      "epoch:24 step:19231 [D loss: 0.124086, acc: 98.44%] [G loss: 3.312887]\n",
      "epoch:24 step:19232 [D loss: 0.215119, acc: 99.22%] [G loss: 3.368459]\n",
      "epoch:24 step:19233 [D loss: 0.381291, acc: 89.06%] [G loss: 4.107008]\n",
      "epoch:24 step:19234 [D loss: 0.202459, acc: 97.66%] [G loss: 5.074972]\n",
      "epoch:24 step:19235 [D loss: 0.476759, acc: 73.44%] [G loss: 4.592972]\n",
      "epoch:24 step:19236 [D loss: 0.104976, acc: 100.00%] [G loss: 3.435032]\n",
      "epoch:24 step:19237 [D loss: 0.391195, acc: 85.94%] [G loss: 4.341837]\n",
      "epoch:24 step:19238 [D loss: 0.244604, acc: 97.66%] [G loss: 4.681711]\n",
      "epoch:24 step:19239 [D loss: 0.280363, acc: 98.44%] [G loss: 5.110075]\n",
      "epoch:24 step:19240 [D loss: 0.083161, acc: 99.22%] [G loss: 4.239652]\n",
      "epoch:24 step:19241 [D loss: 0.026859, acc: 100.00%] [G loss: 4.539849]\n",
      "epoch:24 step:19242 [D loss: 0.368472, acc: 88.28%] [G loss: 2.937087]\n",
      "epoch:24 step:19243 [D loss: 0.238385, acc: 94.53%] [G loss: 3.863175]\n",
      "epoch:24 step:19244 [D loss: 0.197516, acc: 100.00%] [G loss: 3.204480]\n",
      "epoch:24 step:19245 [D loss: 0.190805, acc: 96.88%] [G loss: 3.765090]\n",
      "epoch:24 step:19246 [D loss: 0.567921, acc: 62.50%] [G loss: 2.333619]\n",
      "epoch:24 step:19247 [D loss: 0.423006, acc: 75.00%] [G loss: 3.427519]\n",
      "epoch:24 step:19248 [D loss: 0.359010, acc: 86.72%] [G loss: 1.937541]\n",
      "epoch:24 step:19249 [D loss: 0.290026, acc: 92.19%] [G loss: 3.415666]\n",
      "epoch:24 step:19250 [D loss: 0.215172, acc: 96.88%] [G loss: 1.978703]\n",
      "epoch:24 step:19251 [D loss: 0.316435, acc: 81.25%] [G loss: 3.938737]\n",
      "epoch:24 step:19252 [D loss: 0.548147, acc: 76.56%] [G loss: 3.856165]\n",
      "epoch:24 step:19253 [D loss: 0.700286, acc: 53.12%] [G loss: 3.688211]\n",
      "epoch:24 step:19254 [D loss: 0.112893, acc: 100.00%] [G loss: 3.279547]\n",
      "epoch:24 step:19255 [D loss: 0.114177, acc: 100.00%] [G loss: 4.540167]\n",
      "epoch:24 step:19256 [D loss: 0.208259, acc: 99.22%] [G loss: 5.170140]\n",
      "epoch:24 step:19257 [D loss: 1.261619, acc: 40.62%] [G loss: 3.739706]\n",
      "epoch:24 step:19258 [D loss: 1.485037, acc: 7.81%] [G loss: 4.296321]\n",
      "epoch:24 step:19259 [D loss: 0.303765, acc: 88.28%] [G loss: 2.458676]\n",
      "epoch:24 step:19260 [D loss: 0.193731, acc: 97.66%] [G loss: 4.728029]\n",
      "epoch:24 step:19261 [D loss: 0.141056, acc: 99.22%] [G loss: 5.936200]\n",
      "epoch:24 step:19262 [D loss: 0.300416, acc: 96.09%] [G loss: 2.571455]\n",
      "epoch:24 step:19263 [D loss: 0.826326, acc: 46.09%] [G loss: 3.739916]\n",
      "epoch:24 step:19264 [D loss: 0.063222, acc: 100.00%] [G loss: 4.291743]\n",
      "epoch:24 step:19265 [D loss: 1.214801, acc: 50.00%] [G loss: 3.936376]\n",
      "epoch:24 step:19266 [D loss: 0.766359, acc: 54.69%] [G loss: 2.942847]\n",
      "epoch:24 step:19267 [D loss: 0.997652, acc: 25.78%] [G loss: 3.751925]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19268 [D loss: 0.144352, acc: 98.44%] [G loss: 3.347206]\n",
      "epoch:24 step:19269 [D loss: 0.597652, acc: 65.62%] [G loss: 3.645433]\n",
      "epoch:24 step:19270 [D loss: 1.149987, acc: 37.50%] [G loss: 3.375892]\n",
      "epoch:24 step:19271 [D loss: 0.229653, acc: 96.09%] [G loss: 3.626835]\n",
      "epoch:24 step:19272 [D loss: 0.388079, acc: 91.41%] [G loss: 2.675153]\n",
      "epoch:24 step:19273 [D loss: 0.435861, acc: 70.31%] [G loss: 3.374603]\n",
      "epoch:24 step:19274 [D loss: 0.343174, acc: 90.62%] [G loss: 3.990627]\n",
      "epoch:24 step:19275 [D loss: 0.714330, acc: 62.50%] [G loss: 3.210861]\n",
      "epoch:24 step:19276 [D loss: 0.611757, acc: 60.94%] [G loss: 3.440207]\n",
      "epoch:24 step:19277 [D loss: 0.502569, acc: 69.53%] [G loss: 2.736904]\n",
      "epoch:24 step:19278 [D loss: 0.158962, acc: 98.44%] [G loss: 3.597977]\n",
      "epoch:24 step:19279 [D loss: 0.419682, acc: 81.25%] [G loss: 3.738590]\n",
      "epoch:24 step:19280 [D loss: 0.316012, acc: 89.84%] [G loss: 3.972017]\n",
      "epoch:24 step:19281 [D loss: 0.548289, acc: 69.53%] [G loss: 2.897082]\n",
      "epoch:24 step:19282 [D loss: 0.090435, acc: 100.00%] [G loss: 4.387726]\n",
      "epoch:24 step:19283 [D loss: 0.591657, acc: 60.94%] [G loss: 4.445533]\n",
      "epoch:24 step:19284 [D loss: 0.721285, acc: 53.12%] [G loss: 4.075109]\n",
      "epoch:24 step:19285 [D loss: 0.370314, acc: 92.19%] [G loss: 3.749821]\n",
      "epoch:24 step:19286 [D loss: 1.198511, acc: 17.19%] [G loss: 4.178576]\n",
      "epoch:24 step:19287 [D loss: 0.852663, acc: 49.22%] [G loss: 2.347362]\n",
      "epoch:24 step:19288 [D loss: 0.958731, acc: 43.75%] [G loss: 4.280266]\n",
      "epoch:24 step:19289 [D loss: 0.405669, acc: 87.50%] [G loss: 2.818270]\n",
      "epoch:24 step:19290 [D loss: 0.549077, acc: 66.41%] [G loss: 4.371032]\n",
      "epoch:24 step:19291 [D loss: 0.855734, acc: 39.84%] [G loss: 2.833270]\n",
      "epoch:24 step:19292 [D loss: 0.266683, acc: 94.53%] [G loss: 5.028330]\n",
      "epoch:24 step:19293 [D loss: 0.629734, acc: 57.81%] [G loss: 3.457204]\n",
      "epoch:24 step:19294 [D loss: 0.521064, acc: 73.44%] [G loss: 3.343374]\n",
      "epoch:24 step:19295 [D loss: 0.743507, acc: 53.12%] [G loss: 2.941814]\n",
      "epoch:24 step:19296 [D loss: 0.414431, acc: 89.06%] [G loss: 1.727994]\n",
      "epoch:24 step:19297 [D loss: 0.591263, acc: 60.94%] [G loss: 5.153104]\n",
      "epoch:24 step:19298 [D loss: 0.444801, acc: 81.25%] [G loss: 3.395630]\n",
      "epoch:24 step:19299 [D loss: 0.092197, acc: 99.22%] [G loss: 5.856586]\n",
      "epoch:24 step:19300 [D loss: 0.134593, acc: 99.22%] [G loss: 5.056315]\n",
      "epoch:24 step:19301 [D loss: 0.417010, acc: 87.50%] [G loss: 2.952158]\n",
      "epoch:24 step:19302 [D loss: 0.540715, acc: 71.88%] [G loss: 4.207983]\n",
      "epoch:24 step:19303 [D loss: 0.245870, acc: 96.09%] [G loss: 3.431021]\n",
      "epoch:24 step:19304 [D loss: 0.539109, acc: 60.16%] [G loss: 3.377173]\n",
      "epoch:24 step:19305 [D loss: 0.198438, acc: 96.88%] [G loss: 3.804376]\n",
      "epoch:24 step:19306 [D loss: 1.066294, acc: 21.09%] [G loss: 3.585770]\n",
      "epoch:24 step:19307 [D loss: 1.149853, acc: 18.75%] [G loss: 4.111964]\n",
      "epoch:24 step:19308 [D loss: 0.383633, acc: 81.25%] [G loss: 3.866185]\n",
      "epoch:24 step:19309 [D loss: 0.330393, acc: 87.50%] [G loss: 2.825479]\n",
      "epoch:24 step:19310 [D loss: 0.964825, acc: 48.44%] [G loss: 4.526299]\n",
      "epoch:24 step:19311 [D loss: 0.818443, acc: 41.41%] [G loss: 3.666274]\n",
      "epoch:24 step:19312 [D loss: 0.308117, acc: 92.97%] [G loss: 2.813443]\n",
      "epoch:24 step:19313 [D loss: 0.109934, acc: 100.00%] [G loss: 4.391682]\n",
      "epoch:24 step:19314 [D loss: 0.298733, acc: 95.31%] [G loss: 2.520535]\n",
      "epoch:24 step:19315 [D loss: 0.469202, acc: 78.12%] [G loss: 3.402422]\n",
      "epoch:24 step:19316 [D loss: 0.321985, acc: 87.50%] [G loss: 4.998441]\n",
      "epoch:24 step:19317 [D loss: 0.263231, acc: 95.31%] [G loss: 4.572789]\n",
      "epoch:24 step:19318 [D loss: 0.797587, acc: 42.97%] [G loss: 3.323363]\n",
      "epoch:24 step:19319 [D loss: 0.319150, acc: 94.53%] [G loss: 3.804794]\n",
      "epoch:24 step:19320 [D loss: 0.872638, acc: 52.34%] [G loss: 1.903140]\n",
      "epoch:24 step:19321 [D loss: 0.379443, acc: 82.81%] [G loss: 2.513379]\n",
      "epoch:24 step:19322 [D loss: 0.374903, acc: 78.12%] [G loss: 3.552851]\n",
      "epoch:24 step:19323 [D loss: 0.488976, acc: 79.69%] [G loss: 2.769974]\n",
      "epoch:24 step:19324 [D loss: 0.613802, acc: 64.06%] [G loss: 2.747118]\n",
      "epoch:24 step:19325 [D loss: 0.249133, acc: 92.97%] [G loss: 3.187023]\n",
      "epoch:24 step:19326 [D loss: 0.280386, acc: 96.09%] [G loss: 3.176708]\n",
      "epoch:24 step:19327 [D loss: 0.267513, acc: 92.19%] [G loss: 2.305337]\n",
      "epoch:24 step:19328 [D loss: 0.475149, acc: 88.28%] [G loss: 3.484125]\n",
      "epoch:24 step:19329 [D loss: 0.886656, acc: 47.66%] [G loss: 2.854495]\n",
      "epoch:24 step:19330 [D loss: 0.184539, acc: 100.00%] [G loss: 3.327663]\n",
      "epoch:24 step:19331 [D loss: 0.301912, acc: 86.72%] [G loss: 4.561393]\n",
      "epoch:24 step:19332 [D loss: 0.498230, acc: 73.44%] [G loss: 3.305760]\n",
      "epoch:24 step:19333 [D loss: 0.780318, acc: 48.44%] [G loss: 4.171283]\n",
      "epoch:24 step:19334 [D loss: 0.551749, acc: 67.97%] [G loss: 1.841540]\n",
      "epoch:24 step:19335 [D loss: 0.337225, acc: 95.31%] [G loss: 3.136108]\n",
      "epoch:24 step:19336 [D loss: 0.839579, acc: 44.53%] [G loss: 4.144341]\n",
      "epoch:24 step:19337 [D loss: 0.342493, acc: 91.41%] [G loss: 3.525521]\n",
      "epoch:24 step:19338 [D loss: 0.843575, acc: 48.44%] [G loss: 3.685997]\n",
      "epoch:24 step:19339 [D loss: 0.271231, acc: 96.09%] [G loss: 4.533736]\n",
      "epoch:24 step:19340 [D loss: 0.340686, acc: 87.50%] [G loss: 3.324095]\n",
      "epoch:24 step:19341 [D loss: 0.242205, acc: 96.09%] [G loss: 3.442084]\n",
      "epoch:24 step:19342 [D loss: 0.194162, acc: 98.44%] [G loss: 3.852146]\n",
      "epoch:24 step:19343 [D loss: 0.600911, acc: 62.50%] [G loss: 3.761210]\n",
      "epoch:24 step:19344 [D loss: 0.471626, acc: 77.34%] [G loss: 3.238372]\n",
      "epoch:24 step:19345 [D loss: 0.421304, acc: 75.00%] [G loss: 3.130514]\n",
      "epoch:24 step:19346 [D loss: 0.870457, acc: 39.84%] [G loss: 2.931400]\n",
      "epoch:24 step:19347 [D loss: 0.809338, acc: 48.44%] [G loss: 3.453514]\n",
      "epoch:24 step:19348 [D loss: 0.371211, acc: 93.75%] [G loss: 3.323945]\n",
      "epoch:24 step:19349 [D loss: 0.214484, acc: 99.22%] [G loss: 4.392967]\n",
      "epoch:24 step:19350 [D loss: 0.394857, acc: 87.50%] [G loss: 4.138427]\n",
      "epoch:24 step:19351 [D loss: 0.350417, acc: 89.84%] [G loss: 5.522095]\n",
      "epoch:24 step:19352 [D loss: 0.488186, acc: 80.47%] [G loss: 3.898283]\n",
      "epoch:24 step:19353 [D loss: 0.526468, acc: 74.22%] [G loss: 2.268125]\n",
      "epoch:24 step:19354 [D loss: 0.480035, acc: 67.97%] [G loss: 5.124707]\n",
      "epoch:24 step:19355 [D loss: 0.404984, acc: 84.38%] [G loss: 4.250896]\n",
      "epoch:24 step:19356 [D loss: 0.165562, acc: 96.88%] [G loss: 4.368041]\n",
      "epoch:24 step:19357 [D loss: 1.007566, acc: 29.69%] [G loss: 3.680227]\n",
      "epoch:24 step:19358 [D loss: 0.595638, acc: 58.59%] [G loss: 2.921974]\n",
      "epoch:24 step:19359 [D loss: 0.215536, acc: 99.22%] [G loss: 2.618733]\n",
      "epoch:24 step:19360 [D loss: 0.649125, acc: 60.16%] [G loss: 3.031579]\n",
      "epoch:24 step:19361 [D loss: 0.452916, acc: 82.81%] [G loss: 3.468971]\n",
      "epoch:24 step:19362 [D loss: 0.349543, acc: 92.97%] [G loss: 2.410389]\n",
      "epoch:24 step:19363 [D loss: 0.226386, acc: 97.66%] [G loss: 3.529783]\n",
      "epoch:24 step:19364 [D loss: 1.054279, acc: 39.84%] [G loss: 3.031489]\n",
      "epoch:24 step:19365 [D loss: 0.216495, acc: 93.75%] [G loss: 1.983257]\n",
      "epoch:24 step:19366 [D loss: 0.876223, acc: 49.22%] [G loss: 5.221788]\n",
      "epoch:24 step:19367 [D loss: 1.446554, acc: 50.00%] [G loss: 1.971385]\n",
      "epoch:24 step:19368 [D loss: 0.306394, acc: 90.62%] [G loss: 2.882577]\n",
      "epoch:24 step:19369 [D loss: 0.162772, acc: 98.44%] [G loss: 5.477820]\n",
      "epoch:24 step:19370 [D loss: 0.879583, acc: 48.44%] [G loss: 2.360196]\n",
      "epoch:24 step:19371 [D loss: 0.273331, acc: 96.88%] [G loss: 4.364611]\n",
      "epoch:24 step:19372 [D loss: 0.428695, acc: 85.94%] [G loss: 2.696423]\n",
      "epoch:24 step:19373 [D loss: 0.782414, acc: 50.78%] [G loss: 2.986559]\n",
      "epoch:24 step:19374 [D loss: 0.335011, acc: 92.19%] [G loss: 2.883932]\n",
      "epoch:24 step:19375 [D loss: 0.668022, acc: 60.94%] [G loss: 3.699551]\n",
      "epoch:24 step:19376 [D loss: 0.391566, acc: 89.84%] [G loss: 2.659937]\n",
      "epoch:24 step:19377 [D loss: 0.646865, acc: 63.28%] [G loss: 4.756495]\n",
      "epoch:24 step:19378 [D loss: 0.630744, acc: 64.84%] [G loss: 3.677788]\n",
      "epoch:24 step:19379 [D loss: 0.438934, acc: 81.25%] [G loss: 2.060780]\n",
      "epoch:24 step:19380 [D loss: 0.278324, acc: 92.19%] [G loss: 3.647837]\n",
      "epoch:24 step:19381 [D loss: 0.933650, acc: 37.50%] [G loss: 1.964178]\n",
      "epoch:24 step:19382 [D loss: 0.449117, acc: 80.47%] [G loss: 4.030254]\n",
      "epoch:24 step:19383 [D loss: 0.581323, acc: 65.62%] [G loss: 2.288128]\n",
      "epoch:24 step:19384 [D loss: 0.327775, acc: 91.41%] [G loss: 5.676289]\n",
      "epoch:24 step:19385 [D loss: 0.277433, acc: 92.97%] [G loss: 3.384698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19386 [D loss: 0.427376, acc: 81.25%] [G loss: 3.417325]\n",
      "epoch:24 step:19387 [D loss: 0.974880, acc: 50.78%] [G loss: 3.398447]\n",
      "epoch:24 step:19388 [D loss: 0.296657, acc: 92.19%] [G loss: 4.126816]\n",
      "epoch:24 step:19389 [D loss: 0.221177, acc: 96.88%] [G loss: 5.908746]\n",
      "epoch:24 step:19390 [D loss: 0.903066, acc: 32.03%] [G loss: 3.227727]\n",
      "epoch:24 step:19391 [D loss: 0.222743, acc: 96.88%] [G loss: 2.218831]\n",
      "epoch:24 step:19392 [D loss: 1.565629, acc: 5.47%] [G loss: 5.093471]\n",
      "epoch:24 step:19393 [D loss: 0.801083, acc: 52.34%] [G loss: 3.561301]\n",
      "epoch:24 step:19394 [D loss: 0.311391, acc: 91.41%] [G loss: 3.834429]\n",
      "epoch:24 step:19395 [D loss: 0.446384, acc: 87.50%] [G loss: 3.777509]\n",
      "epoch:24 step:19396 [D loss: 0.490891, acc: 82.81%] [G loss: 3.059882]\n",
      "epoch:24 step:19397 [D loss: 0.155777, acc: 99.22%] [G loss: 2.638683]\n",
      "epoch:24 step:19398 [D loss: 0.372602, acc: 87.50%] [G loss: 3.323920]\n",
      "epoch:24 step:19399 [D loss: 0.099589, acc: 99.22%] [G loss: 5.762216]\n",
      "epoch:24 step:19400 [D loss: 0.870358, acc: 40.62%] [G loss: 4.574421]\n",
      "epoch:24 step:19401 [D loss: 0.379520, acc: 78.91%] [G loss: 3.879799]\n",
      "epoch:24 step:19402 [D loss: 0.629212, acc: 58.59%] [G loss: 3.838700]\n",
      "epoch:24 step:19403 [D loss: 0.266510, acc: 96.88%] [G loss: 3.644076]\n",
      "epoch:24 step:19404 [D loss: 0.665268, acc: 52.34%] [G loss: 4.124002]\n",
      "epoch:24 step:19405 [D loss: 0.247449, acc: 97.66%] [G loss: 3.670340]\n",
      "epoch:24 step:19406 [D loss: 0.818134, acc: 42.97%] [G loss: 3.438180]\n",
      "epoch:24 step:19407 [D loss: 0.153008, acc: 99.22%] [G loss: 4.423516]\n",
      "epoch:24 step:19408 [D loss: 0.353961, acc: 89.06%] [G loss: 3.966729]\n",
      "epoch:24 step:19409 [D loss: 0.765170, acc: 47.66%] [G loss: 3.011529]\n",
      "epoch:24 step:19410 [D loss: 0.432310, acc: 75.78%] [G loss: 4.531276]\n",
      "epoch:24 step:19411 [D loss: 0.162835, acc: 97.66%] [G loss: 5.249727]\n",
      "epoch:24 step:19412 [D loss: 1.195782, acc: 50.78%] [G loss: 3.305928]\n",
      "epoch:24 step:19413 [D loss: 0.219212, acc: 96.09%] [G loss: 3.983649]\n",
      "epoch:24 step:19414 [D loss: 0.384456, acc: 81.25%] [G loss: 5.170550]\n",
      "epoch:24 step:19415 [D loss: 0.957193, acc: 50.00%] [G loss: 3.043532]\n",
      "epoch:24 step:19416 [D loss: 0.239456, acc: 96.88%] [G loss: 4.493740]\n",
      "epoch:24 step:19417 [D loss: 0.534611, acc: 64.06%] [G loss: 3.918186]\n",
      "epoch:24 step:19418 [D loss: 0.717683, acc: 57.03%] [G loss: 3.577943]\n",
      "epoch:24 step:19419 [D loss: 0.558162, acc: 66.41%] [G loss: 2.719301]\n",
      "epoch:24 step:19420 [D loss: 0.153300, acc: 99.22%] [G loss: 2.320304]\n",
      "epoch:24 step:19421 [D loss: 0.240081, acc: 98.44%] [G loss: 4.667041]\n",
      "epoch:24 step:19422 [D loss: 0.428464, acc: 85.16%] [G loss: 4.699336]\n",
      "epoch:24 step:19423 [D loss: 0.517605, acc: 66.41%] [G loss: 2.840851]\n",
      "epoch:24 step:19424 [D loss: 0.304771, acc: 94.53%] [G loss: 2.200978]\n",
      "epoch:24 step:19425 [D loss: 0.162744, acc: 99.22%] [G loss: 3.581231]\n",
      "epoch:24 step:19426 [D loss: 0.527215, acc: 60.94%] [G loss: 4.293918]\n",
      "epoch:24 step:19427 [D loss: 1.188436, acc: 50.00%] [G loss: 1.826253]\n",
      "epoch:24 step:19428 [D loss: 0.964906, acc: 42.19%] [G loss: 4.645221]\n",
      "epoch:24 step:19429 [D loss: 0.517544, acc: 71.88%] [G loss: 4.561711]\n",
      "epoch:24 step:19430 [D loss: 0.780841, acc: 47.66%] [G loss: 3.305899]\n",
      "epoch:24 step:19431 [D loss: 0.275238, acc: 93.75%] [G loss: 4.737057]\n",
      "epoch:24 step:19432 [D loss: 0.438743, acc: 83.59%] [G loss: 3.380306]\n",
      "epoch:24 step:19433 [D loss: 0.874475, acc: 42.19%] [G loss: 2.842987]\n",
      "epoch:24 step:19434 [D loss: 0.165667, acc: 99.22%] [G loss: 4.724236]\n",
      "epoch:24 step:19435 [D loss: 0.304628, acc: 92.19%] [G loss: 2.934789]\n",
      "epoch:24 step:19436 [D loss: 0.404809, acc: 83.59%] [G loss: 3.566727]\n",
      "epoch:24 step:19437 [D loss: 0.448336, acc: 85.16%] [G loss: 3.258002]\n",
      "epoch:24 step:19438 [D loss: 0.635934, acc: 61.72%] [G loss: 4.549512]\n",
      "epoch:24 step:19439 [D loss: 0.267319, acc: 95.31%] [G loss: 3.394760]\n",
      "epoch:24 step:19440 [D loss: 0.235021, acc: 96.88%] [G loss: 3.709254]\n",
      "epoch:24 step:19441 [D loss: 0.598763, acc: 68.75%] [G loss: 3.372698]\n",
      "epoch:24 step:19442 [D loss: 0.284726, acc: 95.31%] [G loss: 5.348698]\n",
      "epoch:24 step:19443 [D loss: 0.294526, acc: 85.16%] [G loss: 5.191203]\n",
      "epoch:24 step:19444 [D loss: 1.189157, acc: 49.22%] [G loss: 2.339356]\n",
      "epoch:24 step:19445 [D loss: 1.019989, acc: 46.09%] [G loss: 2.588231]\n",
      "epoch:24 step:19446 [D loss: 0.396711, acc: 77.34%] [G loss: 4.830971]\n",
      "epoch:24 step:19447 [D loss: 0.847784, acc: 46.88%] [G loss: 3.597616]\n",
      "epoch:24 step:19448 [D loss: 0.272716, acc: 92.19%] [G loss: 5.838346]\n",
      "epoch:24 step:19449 [D loss: 0.136297, acc: 98.44%] [G loss: 2.264259]\n",
      "epoch:24 step:19450 [D loss: 0.360734, acc: 89.84%] [G loss: 3.546149]\n",
      "epoch:24 step:19451 [D loss: 0.631242, acc: 57.03%] [G loss: 3.334336]\n",
      "epoch:24 step:19452 [D loss: 0.540610, acc: 62.50%] [G loss: 4.434086]\n",
      "epoch:24 step:19453 [D loss: 0.252994, acc: 95.31%] [G loss: 4.845510]\n",
      "epoch:24 step:19454 [D loss: 1.045030, acc: 42.19%] [G loss: 3.917965]\n",
      "epoch:24 step:19455 [D loss: 0.196250, acc: 99.22%] [G loss: 5.021289]\n",
      "epoch:24 step:19456 [D loss: 0.252903, acc: 94.53%] [G loss: 4.701741]\n",
      "epoch:24 step:19457 [D loss: 0.449715, acc: 77.34%] [G loss: 4.207465]\n",
      "epoch:24 step:19458 [D loss: 0.256919, acc: 97.66%] [G loss: 2.933971]\n",
      "epoch:24 step:19459 [D loss: 0.972235, acc: 39.06%] [G loss: 1.905715]\n",
      "epoch:24 step:19460 [D loss: 0.071018, acc: 100.00%] [G loss: 4.515501]\n",
      "epoch:24 step:19461 [D loss: 1.131100, acc: 13.28%] [G loss: 2.838297]\n",
      "epoch:24 step:19462 [D loss: 0.416976, acc: 88.28%] [G loss: 3.889774]\n",
      "epoch:24 step:19463 [D loss: 0.629940, acc: 64.84%] [G loss: 2.968246]\n",
      "epoch:24 step:19464 [D loss: 0.343905, acc: 93.75%] [G loss: 3.159581]\n",
      "epoch:24 step:19465 [D loss: 0.407895, acc: 78.91%] [G loss: 3.696707]\n",
      "epoch:24 step:19466 [D loss: 1.147918, acc: 48.44%] [G loss: 2.967505]\n",
      "epoch:24 step:19467 [D loss: 0.066644, acc: 100.00%] [G loss: 3.259454]\n",
      "epoch:24 step:19468 [D loss: 0.720600, acc: 53.12%] [G loss: 4.178925]\n",
      "epoch:24 step:19469 [D loss: 0.256425, acc: 94.53%] [G loss: 3.535696]\n",
      "epoch:24 step:19470 [D loss: 0.436199, acc: 74.22%] [G loss: 3.805411]\n",
      "epoch:24 step:19471 [D loss: 0.780514, acc: 57.03%] [G loss: 4.509104]\n",
      "epoch:24 step:19472 [D loss: 0.408945, acc: 86.72%] [G loss: 3.084426]\n",
      "epoch:24 step:19473 [D loss: 0.247740, acc: 96.88%] [G loss: 2.711857]\n",
      "epoch:24 step:19474 [D loss: 0.559207, acc: 73.44%] [G loss: 4.116469]\n",
      "epoch:24 step:19475 [D loss: 0.632647, acc: 67.97%] [G loss: 2.953215]\n",
      "epoch:24 step:19476 [D loss: 0.824170, acc: 43.75%] [G loss: 3.095330]\n",
      "epoch:24 step:19477 [D loss: 1.254532, acc: 46.88%] [G loss: 3.224247]\n",
      "epoch:24 step:19478 [D loss: 0.382192, acc: 82.81%] [G loss: 2.596939]\n",
      "epoch:24 step:19479 [D loss: 0.305887, acc: 96.88%] [G loss: 2.869680]\n",
      "epoch:24 step:19480 [D loss: 0.105372, acc: 100.00%] [G loss: 3.413934]\n",
      "epoch:24 step:19481 [D loss: 0.346713, acc: 91.41%] [G loss: 4.640894]\n",
      "epoch:24 step:19482 [D loss: 0.453353, acc: 78.91%] [G loss: 3.744170]\n",
      "epoch:24 step:19483 [D loss: 0.270829, acc: 96.88%] [G loss: 3.973865]\n",
      "epoch:24 step:19484 [D loss: 0.251014, acc: 96.09%] [G loss: 2.474013]\n",
      "epoch:24 step:19485 [D loss: 0.135713, acc: 99.22%] [G loss: 4.262150]\n",
      "epoch:24 step:19486 [D loss: 0.813546, acc: 42.97%] [G loss: 4.491662]\n",
      "epoch:24 step:19487 [D loss: 0.203368, acc: 96.88%] [G loss: 3.514488]\n",
      "epoch:24 step:19488 [D loss: 0.990964, acc: 31.25%] [G loss: 3.174678]\n",
      "epoch:24 step:19489 [D loss: 0.535067, acc: 69.53%] [G loss: 3.928587]\n",
      "epoch:24 step:19490 [D loss: 0.334824, acc: 96.09%] [G loss: 2.951847]\n",
      "epoch:24 step:19491 [D loss: 0.655350, acc: 59.38%] [G loss: 4.765557]\n",
      "epoch:24 step:19492 [D loss: 0.165765, acc: 97.66%] [G loss: 3.987642]\n",
      "epoch:24 step:19493 [D loss: 0.402059, acc: 91.41%] [G loss: 3.663573]\n",
      "epoch:24 step:19494 [D loss: 0.438432, acc: 83.59%] [G loss: 2.718555]\n",
      "epoch:24 step:19495 [D loss: 0.504081, acc: 68.75%] [G loss: 3.154295]\n",
      "epoch:24 step:19496 [D loss: 0.103665, acc: 100.00%] [G loss: 4.142973]\n",
      "epoch:24 step:19497 [D loss: 0.994055, acc: 50.00%] [G loss: 2.398915]\n",
      "epoch:24 step:19498 [D loss: 0.339512, acc: 93.75%] [G loss: 2.035744]\n",
      "epoch:24 step:19499 [D loss: 0.824567, acc: 53.12%] [G loss: 3.403264]\n",
      "epoch:24 step:19500 [D loss: 0.233270, acc: 97.66%] [G loss: 3.855885]\n",
      "epoch:24 step:19501 [D loss: 0.156336, acc: 97.66%] [G loss: 2.571823]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19502 [D loss: 0.504772, acc: 72.66%] [G loss: 2.840474]\n",
      "epoch:24 step:19503 [D loss: 0.432911, acc: 73.44%] [G loss: 3.063809]\n",
      "epoch:24 step:19504 [D loss: 0.148803, acc: 98.44%] [G loss: 5.356606]\n",
      "epoch:24 step:19505 [D loss: 0.639767, acc: 59.38%] [G loss: 3.302281]\n",
      "epoch:24 step:19506 [D loss: 0.795179, acc: 50.00%] [G loss: 2.946356]\n",
      "epoch:24 step:19507 [D loss: 0.252249, acc: 92.97%] [G loss: 3.631506]\n",
      "epoch:24 step:19508 [D loss: 0.189408, acc: 99.22%] [G loss: 3.899819]\n",
      "epoch:24 step:19509 [D loss: 0.481860, acc: 75.78%] [G loss: 2.215620]\n",
      "epoch:24 step:19510 [D loss: 0.352013, acc: 92.19%] [G loss: 3.959834]\n",
      "epoch:24 step:19511 [D loss: 0.137300, acc: 100.00%] [G loss: 4.066648]\n",
      "epoch:24 step:19512 [D loss: 0.521537, acc: 79.69%] [G loss: 4.672154]\n",
      "epoch:24 step:19513 [D loss: 0.450236, acc: 85.94%] [G loss: 3.242021]\n",
      "epoch:24 step:19514 [D loss: 0.674475, acc: 57.81%] [G loss: 4.312127]\n",
      "epoch:24 step:19515 [D loss: 0.331023, acc: 83.59%] [G loss: 4.439884]\n",
      "epoch:24 step:19516 [D loss: 1.000162, acc: 35.16%] [G loss: 3.164799]\n",
      "epoch:24 step:19517 [D loss: 0.315273, acc: 82.81%] [G loss: 4.549870]\n",
      "epoch:24 step:19518 [D loss: 0.806508, acc: 53.12%] [G loss: 3.467409]\n",
      "epoch:24 step:19519 [D loss: 0.679706, acc: 60.94%] [G loss: 3.558606]\n",
      "epoch:24 step:19520 [D loss: 0.297413, acc: 95.31%] [G loss: 4.764739]\n",
      "epoch:24 step:19521 [D loss: 0.431233, acc: 88.28%] [G loss: 2.415242]\n",
      "epoch:24 step:19522 [D loss: 0.340921, acc: 93.75%] [G loss: 5.294209]\n",
      "epoch:24 step:19523 [D loss: 0.609269, acc: 64.84%] [G loss: 3.303995]\n",
      "epoch:24 step:19524 [D loss: 0.489654, acc: 78.12%] [G loss: 4.164861]\n",
      "epoch:24 step:19525 [D loss: 0.737711, acc: 53.12%] [G loss: 4.854577]\n",
      "epoch:25 step:19526 [D loss: 0.134426, acc: 99.22%] [G loss: 4.789576]\n",
      "epoch:25 step:19527 [D loss: 0.312776, acc: 94.53%] [G loss: 3.804437]\n",
      "epoch:25 step:19528 [D loss: 0.653128, acc: 55.47%] [G loss: 3.819942]\n",
      "epoch:25 step:19529 [D loss: 0.480729, acc: 84.38%] [G loss: 3.678088]\n",
      "epoch:25 step:19530 [D loss: 0.427065, acc: 82.03%] [G loss: 3.652479]\n",
      "epoch:25 step:19531 [D loss: 0.267980, acc: 94.53%] [G loss: 3.945327]\n",
      "epoch:25 step:19532 [D loss: 0.299425, acc: 92.19%] [G loss: 3.118793]\n",
      "epoch:25 step:19533 [D loss: 0.589150, acc: 75.00%] [G loss: 3.671670]\n",
      "epoch:25 step:19534 [D loss: 0.983290, acc: 36.72%] [G loss: 2.754131]\n",
      "epoch:25 step:19535 [D loss: 0.285525, acc: 97.66%] [G loss: 3.048806]\n",
      "epoch:25 step:19536 [D loss: 0.370461, acc: 87.50%] [G loss: 3.922213]\n",
      "epoch:25 step:19537 [D loss: 0.329398, acc: 92.97%] [G loss: 3.552382]\n",
      "epoch:25 step:19538 [D loss: 0.137984, acc: 100.00%] [G loss: 2.798306]\n",
      "epoch:25 step:19539 [D loss: 0.571872, acc: 71.88%] [G loss: 3.389978]\n",
      "epoch:25 step:19540 [D loss: 0.388707, acc: 91.41%] [G loss: 3.896749]\n",
      "epoch:25 step:19541 [D loss: 0.567822, acc: 75.78%] [G loss: 2.451251]\n",
      "epoch:25 step:19542 [D loss: 0.399951, acc: 82.03%] [G loss: 3.088897]\n",
      "epoch:25 step:19543 [D loss: 0.601099, acc: 60.94%] [G loss: 2.785458]\n",
      "epoch:25 step:19544 [D loss: 0.548032, acc: 74.22%] [G loss: 3.476113]\n",
      "epoch:25 step:19545 [D loss: 0.438196, acc: 88.28%] [G loss: 2.379364]\n",
      "epoch:25 step:19546 [D loss: 0.082104, acc: 99.22%] [G loss: 3.329037]\n",
      "epoch:25 step:19547 [D loss: 0.493240, acc: 75.78%] [G loss: 3.793543]\n",
      "epoch:25 step:19548 [D loss: 0.595166, acc: 71.09%] [G loss: 4.480158]\n",
      "epoch:25 step:19549 [D loss: 0.264196, acc: 92.97%] [G loss: 3.220590]\n",
      "epoch:25 step:19550 [D loss: 0.320327, acc: 93.75%] [G loss: 4.378497]\n",
      "epoch:25 step:19551 [D loss: 1.661309, acc: 30.47%] [G loss: 3.239372]\n",
      "epoch:25 step:19552 [D loss: 0.591626, acc: 71.09%] [G loss: 2.756220]\n",
      "epoch:25 step:19553 [D loss: 0.588162, acc: 68.75%] [G loss: 2.170060]\n",
      "epoch:25 step:19554 [D loss: 0.542477, acc: 75.00%] [G loss: 3.081595]\n",
      "epoch:25 step:19555 [D loss: 0.324007, acc: 90.62%] [G loss: 3.921633]\n",
      "epoch:25 step:19556 [D loss: 0.592351, acc: 61.72%] [G loss: 4.171383]\n",
      "epoch:25 step:19557 [D loss: 0.781288, acc: 50.78%] [G loss: 4.946120]\n",
      "epoch:25 step:19558 [D loss: 0.625422, acc: 63.28%] [G loss: 3.795815]\n",
      "epoch:25 step:19559 [D loss: 0.379474, acc: 91.41%] [G loss: 5.212343]\n",
      "epoch:25 step:19560 [D loss: 0.223728, acc: 95.31%] [G loss: 3.534009]\n",
      "epoch:25 step:19561 [D loss: 0.313110, acc: 91.41%] [G loss: 2.640224]\n",
      "epoch:25 step:19562 [D loss: 0.378925, acc: 87.50%] [G loss: 3.736618]\n",
      "epoch:25 step:19563 [D loss: 1.496881, acc: 24.22%] [G loss: 2.116966]\n",
      "epoch:25 step:19564 [D loss: 1.112638, acc: 18.75%] [G loss: 3.512950]\n",
      "epoch:25 step:19565 [D loss: 0.225542, acc: 97.66%] [G loss: 2.972883]\n",
      "epoch:25 step:19566 [D loss: 0.461219, acc: 72.66%] [G loss: 2.799131]\n",
      "epoch:25 step:19567 [D loss: 0.327503, acc: 80.47%] [G loss: 4.588404]\n",
      "epoch:25 step:19568 [D loss: 0.396778, acc: 84.38%] [G loss: 3.484766]\n",
      "epoch:25 step:19569 [D loss: 0.795031, acc: 53.12%] [G loss: 2.499917]\n",
      "epoch:25 step:19570 [D loss: 0.247559, acc: 94.53%] [G loss: 4.450238]\n",
      "epoch:25 step:19571 [D loss: 0.771304, acc: 53.91%] [G loss: 3.027960]\n",
      "epoch:25 step:19572 [D loss: 1.025131, acc: 22.66%] [G loss: 3.785992]\n",
      "epoch:25 step:19573 [D loss: 0.457043, acc: 79.69%] [G loss: 4.255750]\n",
      "epoch:25 step:19574 [D loss: 0.343752, acc: 79.69%] [G loss: 3.511598]\n",
      "epoch:25 step:19575 [D loss: 1.077296, acc: 21.88%] [G loss: 2.552789]\n",
      "epoch:25 step:19576 [D loss: 0.468127, acc: 70.31%] [G loss: 3.924445]\n",
      "epoch:25 step:19577 [D loss: 0.300044, acc: 95.31%] [G loss: 3.402987]\n",
      "epoch:25 step:19578 [D loss: 0.461801, acc: 71.88%] [G loss: 5.130074]\n",
      "epoch:25 step:19579 [D loss: 0.643689, acc: 60.16%] [G loss: 3.111261]\n",
      "epoch:25 step:19580 [D loss: 0.729054, acc: 59.38%] [G loss: 3.574384]\n",
      "epoch:25 step:19581 [D loss: 0.512088, acc: 71.88%] [G loss: 4.180561]\n",
      "epoch:25 step:19582 [D loss: 0.500914, acc: 68.75%] [G loss: 4.308438]\n",
      "epoch:25 step:19583 [D loss: 0.849347, acc: 43.75%] [G loss: 3.168397]\n",
      "epoch:25 step:19584 [D loss: 0.653497, acc: 57.81%] [G loss: 4.146684]\n",
      "epoch:25 step:19585 [D loss: 0.674164, acc: 57.81%] [G loss: 4.091827]\n",
      "epoch:25 step:19586 [D loss: 0.214767, acc: 94.53%] [G loss: 4.112378]\n",
      "epoch:25 step:19587 [D loss: 1.137620, acc: 27.34%] [G loss: 3.080982]\n",
      "epoch:25 step:19588 [D loss: 0.266015, acc: 96.09%] [G loss: 5.257167]\n",
      "epoch:25 step:19589 [D loss: 0.564108, acc: 65.62%] [G loss: 3.695274]\n",
      "epoch:25 step:19590 [D loss: 0.232552, acc: 95.31%] [G loss: 3.970680]\n",
      "epoch:25 step:19591 [D loss: 0.236585, acc: 94.53%] [G loss: 2.959358]\n",
      "epoch:25 step:19592 [D loss: 0.955466, acc: 49.22%] [G loss: 2.953091]\n",
      "epoch:25 step:19593 [D loss: 0.457967, acc: 76.56%] [G loss: 2.293695]\n",
      "epoch:25 step:19594 [D loss: 0.442942, acc: 70.31%] [G loss: 3.348607]\n",
      "epoch:25 step:19595 [D loss: 0.339766, acc: 88.28%] [G loss: 5.400151]\n",
      "epoch:25 step:19596 [D loss: 0.470051, acc: 65.62%] [G loss: 3.991330]\n",
      "epoch:25 step:19597 [D loss: 0.881361, acc: 47.66%] [G loss: 2.669016]\n",
      "epoch:25 step:19598 [D loss: 0.299062, acc: 92.19%] [G loss: 4.365777]\n",
      "epoch:25 step:19599 [D loss: 0.218627, acc: 93.75%] [G loss: 4.068207]\n",
      "epoch:25 step:19600 [D loss: 0.295123, acc: 96.09%] [G loss: 2.482001]\n",
      "epoch:25 step:19601 [D loss: 0.270079, acc: 96.09%] [G loss: 2.578349]\n",
      "epoch:25 step:19602 [D loss: 0.538270, acc: 73.44%] [G loss: 3.723392]\n",
      "epoch:25 step:19603 [D loss: 0.339867, acc: 88.28%] [G loss: 4.206861]\n",
      "epoch:25 step:19604 [D loss: 0.336721, acc: 80.47%] [G loss: 3.622030]\n",
      "epoch:25 step:19605 [D loss: 0.745625, acc: 46.09%] [G loss: 3.247201]\n",
      "epoch:25 step:19606 [D loss: 0.227375, acc: 97.66%] [G loss: 2.867524]\n",
      "epoch:25 step:19607 [D loss: 0.384097, acc: 80.47%] [G loss: 3.524635]\n",
      "epoch:25 step:19608 [D loss: 0.452298, acc: 83.59%] [G loss: 2.560846]\n",
      "epoch:25 step:19609 [D loss: 0.681061, acc: 55.47%] [G loss: 2.338944]\n",
      "epoch:25 step:19610 [D loss: 0.350741, acc: 95.31%] [G loss: 3.701661]\n",
      "epoch:25 step:19611 [D loss: 0.508961, acc: 75.00%] [G loss: 3.656537]\n",
      "epoch:25 step:19612 [D loss: 0.241611, acc: 97.66%] [G loss: 3.421563]\n",
      "epoch:25 step:19613 [D loss: 0.571188, acc: 74.22%] [G loss: 3.325263]\n",
      "epoch:25 step:19614 [D loss: 0.027092, acc: 100.00%] [G loss: 6.737315]\n",
      "epoch:25 step:19615 [D loss: 0.763822, acc: 48.44%] [G loss: 3.142215]\n",
      "epoch:25 step:19616 [D loss: 1.018006, acc: 39.84%] [G loss: 4.028178]\n",
      "epoch:25 step:19617 [D loss: 0.381977, acc: 86.72%] [G loss: 6.021863]\n",
      "epoch:25 step:19618 [D loss: 0.748504, acc: 48.44%] [G loss: 3.200839]\n",
      "epoch:25 step:19619 [D loss: 0.498946, acc: 71.09%] [G loss: 3.781247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:19620 [D loss: 0.435496, acc: 76.56%] [G loss: 4.027493]\n",
      "epoch:25 step:19621 [D loss: 0.493247, acc: 72.66%] [G loss: 3.473947]\n",
      "epoch:25 step:19622 [D loss: 0.789913, acc: 50.78%] [G loss: 4.106493]\n",
      "epoch:25 step:19623 [D loss: 0.914240, acc: 50.78%] [G loss: 3.285340]\n",
      "epoch:25 step:19624 [D loss: 0.097411, acc: 100.00%] [G loss: 4.728747]\n",
      "epoch:25 step:19625 [D loss: 0.372607, acc: 78.91%] [G loss: 2.819068]\n",
      "epoch:25 step:19626 [D loss: 0.122333, acc: 99.22%] [G loss: 4.207220]\n",
      "epoch:25 step:19627 [D loss: 0.212700, acc: 97.66%] [G loss: 4.288539]\n",
      "epoch:25 step:19628 [D loss: 0.538660, acc: 62.50%] [G loss: 2.031139]\n",
      "epoch:25 step:19629 [D loss: 0.481129, acc: 84.38%] [G loss: 3.084698]\n",
      "epoch:25 step:19630 [D loss: 0.421188, acc: 70.31%] [G loss: 3.344829]\n",
      "epoch:25 step:19631 [D loss: 0.763319, acc: 46.09%] [G loss: 3.316254]\n",
      "epoch:25 step:19632 [D loss: 0.421320, acc: 85.94%] [G loss: 2.926811]\n",
      "epoch:25 step:19633 [D loss: 0.187702, acc: 100.00%] [G loss: 3.741899]\n",
      "epoch:25 step:19634 [D loss: 0.525702, acc: 66.41%] [G loss: 3.394070]\n",
      "epoch:25 step:19635 [D loss: 0.217785, acc: 97.66%] [G loss: 3.993916]\n",
      "epoch:25 step:19636 [D loss: 0.619863, acc: 61.72%] [G loss: 3.741407]\n",
      "epoch:25 step:19637 [D loss: 0.192538, acc: 98.44%] [G loss: 3.360502]\n",
      "epoch:25 step:19638 [D loss: 0.422105, acc: 85.94%] [G loss: 4.732021]\n",
      "epoch:25 step:19639 [D loss: 0.100597, acc: 99.22%] [G loss: 4.456989]\n",
      "epoch:25 step:19640 [D loss: 0.706653, acc: 56.25%] [G loss: 3.103256]\n",
      "epoch:25 step:19641 [D loss: 0.358105, acc: 82.03%] [G loss: 2.810389]\n",
      "epoch:25 step:19642 [D loss: 0.715319, acc: 53.12%] [G loss: 3.118331]\n",
      "epoch:25 step:19643 [D loss: 0.430049, acc: 82.03%] [G loss: 2.972430]\n",
      "epoch:25 step:19644 [D loss: 0.121308, acc: 99.22%] [G loss: 3.184581]\n",
      "epoch:25 step:19645 [D loss: 0.399521, acc: 91.41%] [G loss: 2.835416]\n",
      "epoch:25 step:19646 [D loss: 0.533959, acc: 67.97%] [G loss: 3.211888]\n",
      "epoch:25 step:19647 [D loss: 0.246253, acc: 93.75%] [G loss: 3.362479]\n",
      "epoch:25 step:19648 [D loss: 0.445475, acc: 79.69%] [G loss: 4.801874]\n",
      "epoch:25 step:19649 [D loss: 0.992018, acc: 50.00%] [G loss: 4.545353]\n",
      "epoch:25 step:19650 [D loss: 0.797794, acc: 55.47%] [G loss: 2.222509]\n",
      "epoch:25 step:19651 [D loss: 0.460220, acc: 69.53%] [G loss: 2.213010]\n",
      "epoch:25 step:19652 [D loss: 0.183155, acc: 98.44%] [G loss: 3.424987]\n",
      "epoch:25 step:19653 [D loss: 0.553240, acc: 69.53%] [G loss: 4.138127]\n",
      "epoch:25 step:19654 [D loss: 0.332842, acc: 89.06%] [G loss: 3.045338]\n",
      "epoch:25 step:19655 [D loss: 0.383472, acc: 85.94%] [G loss: 4.423615]\n",
      "epoch:25 step:19656 [D loss: 0.277182, acc: 97.66%] [G loss: 3.324272]\n",
      "epoch:25 step:19657 [D loss: 0.233498, acc: 95.31%] [G loss: 4.269192]\n",
      "epoch:25 step:19658 [D loss: 0.433183, acc: 82.03%] [G loss: 4.170516]\n",
      "epoch:25 step:19659 [D loss: 0.329165, acc: 85.94%] [G loss: 6.003147]\n",
      "epoch:25 step:19660 [D loss: 0.196486, acc: 99.22%] [G loss: 2.931376]\n",
      "epoch:25 step:19661 [D loss: 0.229510, acc: 94.53%] [G loss: 4.600604]\n",
      "epoch:25 step:19662 [D loss: 0.464421, acc: 75.00%] [G loss: 5.213072]\n",
      "epoch:25 step:19663 [D loss: 0.218764, acc: 98.44%] [G loss: 3.688015]\n",
      "epoch:25 step:19664 [D loss: 0.143741, acc: 100.00%] [G loss: 3.149918]\n",
      "epoch:25 step:19665 [D loss: 0.282406, acc: 88.28%] [G loss: 5.722315]\n",
      "epoch:25 step:19666 [D loss: 0.697017, acc: 57.03%] [G loss: 2.117860]\n",
      "epoch:25 step:19667 [D loss: 0.556311, acc: 76.56%] [G loss: 3.515771]\n",
      "epoch:25 step:19668 [D loss: 0.181942, acc: 100.00%] [G loss: 2.620950]\n",
      "epoch:25 step:19669 [D loss: 0.537697, acc: 75.78%] [G loss: 3.267028]\n",
      "epoch:25 step:19670 [D loss: 0.066949, acc: 100.00%] [G loss: 3.695719]\n",
      "epoch:25 step:19671 [D loss: 0.149544, acc: 100.00%] [G loss: 3.421603]\n",
      "epoch:25 step:19672 [D loss: 0.356642, acc: 90.62%] [G loss: 2.376810]\n",
      "epoch:25 step:19673 [D loss: 0.559218, acc: 65.62%] [G loss: 4.243498]\n",
      "epoch:25 step:19674 [D loss: 0.162481, acc: 98.44%] [G loss: 3.541370]\n",
      "epoch:25 step:19675 [D loss: 0.688610, acc: 56.25%] [G loss: 3.517310]\n",
      "epoch:25 step:19676 [D loss: 0.904740, acc: 52.34%] [G loss: 5.253244]\n",
      "epoch:25 step:19677 [D loss: 0.609868, acc: 67.19%] [G loss: 2.641204]\n",
      "epoch:25 step:19678 [D loss: 0.353100, acc: 92.19%] [G loss: 4.071253]\n",
      "epoch:25 step:19679 [D loss: 0.173080, acc: 98.44%] [G loss: 3.411741]\n",
      "epoch:25 step:19680 [D loss: 1.206046, acc: 19.53%] [G loss: 3.670484]\n",
      "epoch:25 step:19681 [D loss: 0.147895, acc: 100.00%] [G loss: 5.146127]\n",
      "epoch:25 step:19682 [D loss: 0.400973, acc: 83.59%] [G loss: 3.738474]\n",
      "epoch:25 step:19683 [D loss: 0.445085, acc: 73.44%] [G loss: 4.769140]\n",
      "epoch:25 step:19684 [D loss: 0.802776, acc: 49.22%] [G loss: 4.743866]\n",
      "epoch:25 step:19685 [D loss: 0.248561, acc: 94.53%] [G loss: 2.219961]\n",
      "epoch:25 step:19686 [D loss: 0.504798, acc: 74.22%] [G loss: 3.793102]\n",
      "epoch:25 step:19687 [D loss: 0.058046, acc: 100.00%] [G loss: 6.482615]\n",
      "epoch:25 step:19688 [D loss: 0.380255, acc: 88.28%] [G loss: 3.335521]\n",
      "epoch:25 step:19689 [D loss: 0.319573, acc: 94.53%] [G loss: 3.560853]\n",
      "epoch:25 step:19690 [D loss: 0.728226, acc: 53.12%] [G loss: 2.404927]\n",
      "epoch:25 step:19691 [D loss: 0.303134, acc: 95.31%] [G loss: 3.555593]\n",
      "epoch:25 step:19692 [D loss: 0.616539, acc: 63.28%] [G loss: 4.017077]\n",
      "epoch:25 step:19693 [D loss: 0.433770, acc: 85.16%] [G loss: 4.418617]\n",
      "epoch:25 step:19694 [D loss: 0.295535, acc: 88.28%] [G loss: 4.452960]\n",
      "epoch:25 step:19695 [D loss: 0.269049, acc: 96.88%] [G loss: 3.796595]\n",
      "epoch:25 step:19696 [D loss: 0.612284, acc: 64.06%] [G loss: 3.660475]\n",
      "epoch:25 step:19697 [D loss: 0.213298, acc: 95.31%] [G loss: 3.647744]\n",
      "epoch:25 step:19698 [D loss: 1.560284, acc: 4.69%] [G loss: 3.648743]\n",
      "epoch:25 step:19699 [D loss: 0.093368, acc: 99.22%] [G loss: 3.734097]\n",
      "epoch:25 step:19700 [D loss: 0.487370, acc: 66.41%] [G loss: 4.351965]\n",
      "epoch:25 step:19701 [D loss: 0.268403, acc: 96.88%] [G loss: 3.082829]\n",
      "epoch:25 step:19702 [D loss: 0.203344, acc: 96.88%] [G loss: 3.891036]\n",
      "epoch:25 step:19703 [D loss: 1.050039, acc: 41.41%] [G loss: 1.843843]\n",
      "epoch:25 step:19704 [D loss: 0.687714, acc: 53.12%] [G loss: 3.446246]\n",
      "epoch:25 step:19705 [D loss: 0.627776, acc: 66.41%] [G loss: 2.922373]\n",
      "epoch:25 step:19706 [D loss: 0.499312, acc: 67.19%] [G loss: 4.044454]\n",
      "epoch:25 step:19707 [D loss: 0.610248, acc: 61.72%] [G loss: 3.659076]\n",
      "epoch:25 step:19708 [D loss: 0.618754, acc: 61.72%] [G loss: 2.470076]\n",
      "epoch:25 step:19709 [D loss: 1.045470, acc: 50.00%] [G loss: 2.930195]\n",
      "epoch:25 step:19710 [D loss: 0.517771, acc: 81.25%] [G loss: 2.292609]\n",
      "epoch:25 step:19711 [D loss: 0.222552, acc: 94.53%] [G loss: 4.832594]\n",
      "epoch:25 step:19712 [D loss: 0.483198, acc: 79.69%] [G loss: 4.182049]\n",
      "epoch:25 step:19713 [D loss: 0.484300, acc: 68.75%] [G loss: 4.791545]\n",
      "epoch:25 step:19714 [D loss: 0.037591, acc: 100.00%] [G loss: 6.646035]\n",
      "epoch:25 step:19715 [D loss: 0.496199, acc: 80.47%] [G loss: 3.328904]\n",
      "epoch:25 step:19716 [D loss: 0.444494, acc: 85.94%] [G loss: 2.731999]\n",
      "epoch:25 step:19717 [D loss: 0.456292, acc: 66.41%] [G loss: 4.060432]\n",
      "epoch:25 step:19718 [D loss: 0.868528, acc: 40.62%] [G loss: 2.992740]\n",
      "epoch:25 step:19719 [D loss: 0.621220, acc: 62.50%] [G loss: 4.768086]\n",
      "epoch:25 step:19720 [D loss: 0.626914, acc: 67.97%] [G loss: 3.390944]\n",
      "epoch:25 step:19721 [D loss: 0.314606, acc: 82.81%] [G loss: 4.187015]\n",
      "epoch:25 step:19722 [D loss: 0.384490, acc: 75.78%] [G loss: 3.682038]\n",
      "epoch:25 step:19723 [D loss: 0.091643, acc: 100.00%] [G loss: 6.899821]\n",
      "epoch:25 step:19724 [D loss: 0.234352, acc: 96.09%] [G loss: 3.296290]\n",
      "epoch:25 step:19725 [D loss: 0.301045, acc: 92.19%] [G loss: 3.331469]\n",
      "epoch:25 step:19726 [D loss: 0.463176, acc: 79.69%] [G loss: 3.214297]\n",
      "epoch:25 step:19727 [D loss: 0.977167, acc: 33.59%] [G loss: 3.324693]\n",
      "epoch:25 step:19728 [D loss: 0.848452, acc: 47.66%] [G loss: 3.537740]\n",
      "epoch:25 step:19729 [D loss: 0.546635, acc: 62.50%] [G loss: 3.066053]\n",
      "epoch:25 step:19730 [D loss: 0.501763, acc: 64.84%] [G loss: 3.243720]\n",
      "epoch:25 step:19731 [D loss: 0.120805, acc: 99.22%] [G loss: 3.523914]\n",
      "epoch:25 step:19732 [D loss: 1.062523, acc: 16.41%] [G loss: 4.776126]\n",
      "epoch:25 step:19733 [D loss: 0.455201, acc: 83.59%] [G loss: 3.874826]\n",
      "epoch:25 step:19734 [D loss: 1.363586, acc: 14.06%] [G loss: 3.570166]\n",
      "epoch:25 step:19735 [D loss: 0.105622, acc: 100.00%] [G loss: 3.581644]\n",
      "epoch:25 step:19736 [D loss: 0.333616, acc: 89.84%] [G loss: 2.461003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:19737 [D loss: 0.496715, acc: 74.22%] [G loss: 3.851832]\n",
      "epoch:25 step:19738 [D loss: 0.984055, acc: 51.56%] [G loss: 3.728974]\n",
      "epoch:25 step:19739 [D loss: 0.230907, acc: 97.66%] [G loss: 3.949492]\n",
      "epoch:25 step:19740 [D loss: 0.273716, acc: 97.66%] [G loss: 2.861255]\n",
      "epoch:25 step:19741 [D loss: 0.173433, acc: 100.00%] [G loss: 4.775708]\n",
      "epoch:25 step:19742 [D loss: 0.143950, acc: 100.00%] [G loss: 3.139645]\n",
      "epoch:25 step:19743 [D loss: 0.338823, acc: 83.59%] [G loss: 3.819993]\n",
      "epoch:25 step:19744 [D loss: 0.777106, acc: 53.91%] [G loss: 2.091232]\n",
      "epoch:25 step:19745 [D loss: 0.496899, acc: 64.06%] [G loss: 3.422365]\n",
      "epoch:25 step:19746 [D loss: 0.185724, acc: 100.00%] [G loss: 3.609210]\n",
      "epoch:25 step:19747 [D loss: 0.906621, acc: 39.84%] [G loss: 2.511101]\n",
      "epoch:25 step:19748 [D loss: 0.844537, acc: 41.41%] [G loss: 3.785129]\n",
      "epoch:25 step:19749 [D loss: 1.644588, acc: 8.59%] [G loss: 2.921305]\n",
      "epoch:25 step:19750 [D loss: 0.157022, acc: 99.22%] [G loss: 2.921525]\n",
      "epoch:25 step:19751 [D loss: 0.434556, acc: 86.72%] [G loss: 3.881084]\n",
      "epoch:25 step:19752 [D loss: 0.355918, acc: 92.19%] [G loss: 5.215895]\n",
      "epoch:25 step:19753 [D loss: 1.518914, acc: 38.28%] [G loss: 3.256444]\n",
      "epoch:25 step:19754 [D loss: 0.378874, acc: 82.81%] [G loss: 2.997839]\n",
      "epoch:25 step:19755 [D loss: 0.169915, acc: 98.44%] [G loss: 4.427643]\n",
      "epoch:25 step:19756 [D loss: 0.482586, acc: 75.78%] [G loss: 4.945914]\n",
      "epoch:25 step:19757 [D loss: 0.611777, acc: 71.88%] [G loss: 4.343651]\n",
      "epoch:25 step:19758 [D loss: 0.203350, acc: 98.44%] [G loss: 4.716914]\n",
      "epoch:25 step:19759 [D loss: 0.658344, acc: 58.59%] [G loss: 3.681539]\n",
      "epoch:25 step:19760 [D loss: 0.504910, acc: 78.91%] [G loss: 3.959522]\n",
      "epoch:25 step:19761 [D loss: 0.774360, acc: 55.47%] [G loss: 4.123835]\n",
      "epoch:25 step:19762 [D loss: 0.184623, acc: 96.88%] [G loss: 6.316475]\n",
      "epoch:25 step:19763 [D loss: 0.685228, acc: 55.47%] [G loss: 3.877707]\n",
      "epoch:25 step:19764 [D loss: 0.726047, acc: 55.47%] [G loss: 5.585114]\n",
      "epoch:25 step:19765 [D loss: 0.899751, acc: 44.53%] [G loss: 3.523601]\n",
      "epoch:25 step:19766 [D loss: 0.551717, acc: 70.31%] [G loss: 3.136859]\n",
      "epoch:25 step:19767 [D loss: 0.161082, acc: 98.44%] [G loss: 5.220015]\n",
      "epoch:25 step:19768 [D loss: 0.618535, acc: 56.25%] [G loss: 3.450160]\n",
      "epoch:25 step:19769 [D loss: 0.466653, acc: 84.38%] [G loss: 4.405663]\n",
      "epoch:25 step:19770 [D loss: 1.001997, acc: 24.22%] [G loss: 4.348466]\n",
      "epoch:25 step:19771 [D loss: 0.715268, acc: 55.47%] [G loss: 1.791172]\n",
      "epoch:25 step:19772 [D loss: 0.676666, acc: 54.69%] [G loss: 2.929314]\n",
      "epoch:25 step:19773 [D loss: 0.403211, acc: 78.12%] [G loss: 4.669547]\n",
      "epoch:25 step:19774 [D loss: 0.272480, acc: 93.75%] [G loss: 5.349604]\n",
      "epoch:25 step:19775 [D loss: 0.347396, acc: 91.41%] [G loss: 3.997747]\n",
      "epoch:25 step:19776 [D loss: 0.397557, acc: 75.78%] [G loss: 5.551501]\n",
      "epoch:25 step:19777 [D loss: 0.128269, acc: 99.22%] [G loss: 4.390680]\n",
      "epoch:25 step:19778 [D loss: 0.847494, acc: 47.66%] [G loss: 3.002951]\n",
      "epoch:25 step:19779 [D loss: 0.350308, acc: 94.53%] [G loss: 1.912358]\n",
      "epoch:25 step:19780 [D loss: 0.574162, acc: 67.97%] [G loss: 3.795828]\n",
      "epoch:25 step:19781 [D loss: 0.324251, acc: 89.06%] [G loss: 2.571868]\n",
      "epoch:25 step:19782 [D loss: 0.112261, acc: 100.00%] [G loss: 3.897816]\n",
      "epoch:25 step:19783 [D loss: 0.832626, acc: 39.84%] [G loss: 4.216743]\n",
      "epoch:25 step:19784 [D loss: 0.478423, acc: 64.84%] [G loss: 4.595639]\n",
      "epoch:25 step:19785 [D loss: 0.327957, acc: 97.66%] [G loss: 3.458238]\n",
      "epoch:25 step:19786 [D loss: 0.296295, acc: 94.53%] [G loss: 2.383593]\n",
      "epoch:25 step:19787 [D loss: 0.269807, acc: 90.62%] [G loss: 3.794443]\n",
      "epoch:25 step:19788 [D loss: 0.398115, acc: 76.56%] [G loss: 3.570077]\n",
      "epoch:25 step:19789 [D loss: 0.267536, acc: 95.31%] [G loss: 5.437874]\n",
      "epoch:25 step:19790 [D loss: 0.651415, acc: 62.50%] [G loss: 3.533029]\n",
      "epoch:25 step:19791 [D loss: 0.361025, acc: 89.84%] [G loss: 5.180920]\n",
      "epoch:25 step:19792 [D loss: 1.934400, acc: 3.91%] [G loss: 2.635106]\n",
      "epoch:25 step:19793 [D loss: 0.714712, acc: 56.25%] [G loss: 4.810894]\n",
      "epoch:25 step:19794 [D loss: 0.346632, acc: 88.28%] [G loss: 4.153902]\n",
      "epoch:25 step:19795 [D loss: 0.385897, acc: 80.47%] [G loss: 2.266573]\n",
      "epoch:25 step:19796 [D loss: 0.323797, acc: 84.38%] [G loss: 4.116900]\n",
      "epoch:25 step:19797 [D loss: 0.274925, acc: 89.06%] [G loss: 3.736273]\n",
      "epoch:25 step:19798 [D loss: 0.596666, acc: 61.72%] [G loss: 2.197513]\n",
      "epoch:25 step:19799 [D loss: 0.452402, acc: 85.94%] [G loss: 3.116160]\n",
      "epoch:25 step:19800 [D loss: 0.401702, acc: 83.59%] [G loss: 1.733162]\n",
      "epoch:25 step:19801 [D loss: 0.470342, acc: 82.81%] [G loss: 3.100938]\n",
      "epoch:25 step:19802 [D loss: 0.671598, acc: 55.47%] [G loss: 3.728173]\n",
      "epoch:25 step:19803 [D loss: 0.458870, acc: 67.97%] [G loss: 4.903652]\n",
      "epoch:25 step:19804 [D loss: 0.628800, acc: 60.16%] [G loss: 3.959739]\n",
      "epoch:25 step:19805 [D loss: 0.347692, acc: 88.28%] [G loss: 3.707634]\n",
      "epoch:25 step:19806 [D loss: 0.553077, acc: 78.12%] [G loss: 2.571072]\n",
      "epoch:25 step:19807 [D loss: 0.819519, acc: 52.34%] [G loss: 2.384624]\n",
      "epoch:25 step:19808 [D loss: 0.660105, acc: 62.50%] [G loss: 3.601609]\n",
      "epoch:25 step:19809 [D loss: 0.313763, acc: 91.41%] [G loss: 4.412657]\n",
      "epoch:25 step:19810 [D loss: 0.397217, acc: 89.06%] [G loss: 3.387269]\n",
      "epoch:25 step:19811 [D loss: 0.383873, acc: 85.94%] [G loss: 1.954022]\n",
      "epoch:25 step:19812 [D loss: 0.563140, acc: 70.31%] [G loss: 3.288750]\n",
      "epoch:25 step:19813 [D loss: 0.325294, acc: 96.09%] [G loss: 2.519634]\n",
      "epoch:25 step:19814 [D loss: 0.344351, acc: 91.41%] [G loss: 4.254983]\n",
      "epoch:25 step:19815 [D loss: 0.244970, acc: 96.88%] [G loss: 2.573199]\n",
      "epoch:25 step:19816 [D loss: 0.681690, acc: 63.28%] [G loss: 3.841743]\n",
      "epoch:25 step:19817 [D loss: 0.514487, acc: 72.66%] [G loss: 4.877409]\n",
      "epoch:25 step:19818 [D loss: 0.571624, acc: 64.06%] [G loss: 3.645787]\n",
      "epoch:25 step:19819 [D loss: 0.450897, acc: 85.16%] [G loss: 3.976861]\n",
      "epoch:25 step:19820 [D loss: 0.406976, acc: 89.84%] [G loss: 3.252640]\n",
      "epoch:25 step:19821 [D loss: 0.482719, acc: 66.41%] [G loss: 4.129022]\n",
      "epoch:25 step:19822 [D loss: 1.085887, acc: 24.22%] [G loss: 4.857777]\n",
      "epoch:25 step:19823 [D loss: 0.315328, acc: 92.19%] [G loss: 3.852583]\n",
      "epoch:25 step:19824 [D loss: 0.398774, acc: 81.25%] [G loss: 4.156820]\n",
      "epoch:25 step:19825 [D loss: 0.622195, acc: 65.62%] [G loss: 4.853220]\n",
      "epoch:25 step:19826 [D loss: 0.340189, acc: 88.28%] [G loss: 3.422523]\n",
      "epoch:25 step:19827 [D loss: 0.378246, acc: 91.41%] [G loss: 3.413887]\n",
      "epoch:25 step:19828 [D loss: 0.302421, acc: 94.53%] [G loss: 3.152854]\n",
      "epoch:25 step:19829 [D loss: 0.489458, acc: 82.81%] [G loss: 3.558721]\n",
      "epoch:25 step:19830 [D loss: 0.634756, acc: 65.62%] [G loss: 2.477128]\n",
      "epoch:25 step:19831 [D loss: 0.207876, acc: 99.22%] [G loss: 3.381911]\n",
      "epoch:25 step:19832 [D loss: 0.634912, acc: 60.16%] [G loss: 2.655932]\n",
      "epoch:25 step:19833 [D loss: 0.283301, acc: 92.97%] [G loss: 5.464126]\n",
      "epoch:25 step:19834 [D loss: 0.120554, acc: 99.22%] [G loss: 5.236949]\n",
      "epoch:25 step:19835 [D loss: 0.165418, acc: 100.00%] [G loss: 3.602912]\n",
      "epoch:25 step:19836 [D loss: 0.122794, acc: 99.22%] [G loss: 4.980224]\n",
      "epoch:25 step:19837 [D loss: 0.586306, acc: 68.75%] [G loss: 2.710007]\n",
      "epoch:25 step:19838 [D loss: 0.725283, acc: 60.16%] [G loss: 2.884846]\n",
      "epoch:25 step:19839 [D loss: 0.139665, acc: 100.00%] [G loss: 3.558893]\n",
      "epoch:25 step:19840 [D loss: 0.371434, acc: 83.59%] [G loss: 3.800459]\n",
      "epoch:25 step:19841 [D loss: 0.459060, acc: 74.22%] [G loss: 4.297482]\n",
      "epoch:25 step:19842 [D loss: 0.097203, acc: 100.00%] [G loss: 4.696204]\n",
      "epoch:25 step:19843 [D loss: 0.660935, acc: 65.62%] [G loss: 2.857318]\n",
      "epoch:25 step:19844 [D loss: 0.283553, acc: 96.09%] [G loss: 5.029443]\n",
      "epoch:25 step:19845 [D loss: 1.110489, acc: 21.09%] [G loss: 3.442716]\n",
      "epoch:25 step:19846 [D loss: 0.655469, acc: 61.72%] [G loss: 3.007749]\n",
      "epoch:25 step:19847 [D loss: 0.545616, acc: 71.88%] [G loss: 4.319984]\n",
      "epoch:25 step:19848 [D loss: 0.213686, acc: 97.66%] [G loss: 4.396677]\n",
      "epoch:25 step:19849 [D loss: 0.366501, acc: 78.12%] [G loss: 4.595751]\n",
      "epoch:25 step:19850 [D loss: 0.530767, acc: 60.94%] [G loss: 4.541668]\n",
      "epoch:25 step:19851 [D loss: 0.299665, acc: 90.62%] [G loss: 3.331945]\n",
      "epoch:25 step:19852 [D loss: 0.637832, acc: 64.06%] [G loss: 3.767686]\n",
      "epoch:25 step:19853 [D loss: 0.737541, acc: 53.91%] [G loss: 3.302723]\n",
      "epoch:25 step:19854 [D loss: 0.234109, acc: 96.88%] [G loss: 3.816198]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:19855 [D loss: 0.444541, acc: 67.97%] [G loss: 4.026031]\n",
      "epoch:25 step:19856 [D loss: 0.838650, acc: 47.66%] [G loss: 2.357376]\n",
      "epoch:25 step:19857 [D loss: 0.776786, acc: 41.41%] [G loss: 4.502934]\n",
      "epoch:25 step:19858 [D loss: 0.073562, acc: 100.00%] [G loss: 5.437550]\n",
      "epoch:25 step:19859 [D loss: 0.498493, acc: 76.56%] [G loss: 3.681696]\n",
      "epoch:25 step:19860 [D loss: 0.502144, acc: 64.84%] [G loss: 5.457484]\n",
      "epoch:25 step:19861 [D loss: 0.623750, acc: 58.59%] [G loss: 4.387786]\n",
      "epoch:25 step:19862 [D loss: 0.613939, acc: 54.69%] [G loss: 3.917490]\n",
      "epoch:25 step:19863 [D loss: 0.314326, acc: 89.06%] [G loss: 4.977563]\n",
      "epoch:25 step:19864 [D loss: 0.179848, acc: 96.88%] [G loss: 1.874048]\n",
      "epoch:25 step:19865 [D loss: 0.648871, acc: 58.59%] [G loss: 5.162728]\n",
      "epoch:25 step:19866 [D loss: 0.481962, acc: 66.41%] [G loss: 3.357706]\n",
      "epoch:25 step:19867 [D loss: 0.332604, acc: 89.84%] [G loss: 3.634711]\n",
      "epoch:25 step:19868 [D loss: 0.279286, acc: 95.31%] [G loss: 3.806394]\n",
      "epoch:25 step:19869 [D loss: 1.058345, acc: 39.84%] [G loss: 2.775269]\n",
      "epoch:25 step:19870 [D loss: 0.510997, acc: 65.62%] [G loss: 3.083682]\n",
      "epoch:25 step:19871 [D loss: 0.243319, acc: 98.44%] [G loss: 3.626398]\n",
      "epoch:25 step:19872 [D loss: 0.103044, acc: 100.00%] [G loss: 2.848675]\n",
      "epoch:25 step:19873 [D loss: 0.527490, acc: 75.00%] [G loss: 5.194979]\n",
      "epoch:25 step:19874 [D loss: 0.643115, acc: 63.28%] [G loss: 3.628113]\n",
      "epoch:25 step:19875 [D loss: 0.192841, acc: 96.09%] [G loss: 3.077820]\n",
      "epoch:25 step:19876 [D loss: 0.869409, acc: 39.06%] [G loss: 3.195024]\n",
      "epoch:25 step:19877 [D loss: 0.258517, acc: 92.19%] [G loss: 3.658571]\n",
      "epoch:25 step:19878 [D loss: 0.408347, acc: 90.62%] [G loss: 3.635518]\n",
      "epoch:25 step:19879 [D loss: 0.437284, acc: 72.66%] [G loss: 4.529411]\n",
      "epoch:25 step:19880 [D loss: 0.473453, acc: 67.19%] [G loss: 6.591305]\n",
      "epoch:25 step:19881 [D loss: 0.228734, acc: 94.53%] [G loss: 5.837550]\n",
      "epoch:25 step:19882 [D loss: 0.808600, acc: 50.78%] [G loss: 2.161058]\n",
      "epoch:25 step:19883 [D loss: 0.094259, acc: 100.00%] [G loss: 5.209526]\n",
      "epoch:25 step:19884 [D loss: 0.513199, acc: 75.78%] [G loss: 3.236253]\n",
      "epoch:25 step:19885 [D loss: 0.489105, acc: 75.78%] [G loss: 3.419844]\n",
      "epoch:25 step:19886 [D loss: 0.886131, acc: 35.94%] [G loss: 6.298676]\n",
      "epoch:25 step:19887 [D loss: 0.383142, acc: 86.72%] [G loss: 2.452083]\n",
      "epoch:25 step:19888 [D loss: 0.935413, acc: 38.28%] [G loss: 3.579117]\n",
      "epoch:25 step:19889 [D loss: 0.249649, acc: 94.53%] [G loss: 4.014494]\n",
      "epoch:25 step:19890 [D loss: 0.459447, acc: 72.66%] [G loss: 5.234252]\n",
      "epoch:25 step:19891 [D loss: 0.548203, acc: 73.44%] [G loss: 3.654256]\n",
      "epoch:25 step:19892 [D loss: 0.185408, acc: 99.22%] [G loss: 3.526237]\n",
      "epoch:25 step:19893 [D loss: 0.189167, acc: 98.44%] [G loss: 2.925272]\n",
      "epoch:25 step:19894 [D loss: 0.219763, acc: 98.44%] [G loss: 2.652238]\n",
      "epoch:25 step:19895 [D loss: 0.208465, acc: 99.22%] [G loss: 4.391624]\n",
      "epoch:25 step:19896 [D loss: 0.289572, acc: 94.53%] [G loss: 5.125323]\n",
      "epoch:25 step:19897 [D loss: 0.726783, acc: 48.44%] [G loss: 2.529473]\n",
      "epoch:25 step:19898 [D loss: 1.075558, acc: 15.62%] [G loss: 3.179178]\n",
      "epoch:25 step:19899 [D loss: 0.126563, acc: 100.00%] [G loss: 6.684476]\n",
      "epoch:25 step:19900 [D loss: 0.471501, acc: 74.22%] [G loss: 4.506587]\n",
      "epoch:25 step:19901 [D loss: 0.826212, acc: 42.19%] [G loss: 4.689986]\n",
      "epoch:25 step:19902 [D loss: 0.305375, acc: 89.84%] [G loss: 3.257385]\n",
      "epoch:25 step:19903 [D loss: 0.270808, acc: 88.28%] [G loss: 5.354897]\n",
      "epoch:25 step:19904 [D loss: 0.903889, acc: 50.00%] [G loss: 5.217340]\n",
      "epoch:25 step:19905 [D loss: 0.172757, acc: 98.44%] [G loss: 5.274939]\n",
      "epoch:25 step:19906 [D loss: 0.642958, acc: 61.72%] [G loss: 3.595704]\n",
      "epoch:25 step:19907 [D loss: 0.716242, acc: 59.38%] [G loss: 4.845420]\n",
      "epoch:25 step:19908 [D loss: 0.785219, acc: 50.00%] [G loss: 2.621970]\n",
      "epoch:25 step:19909 [D loss: 0.461051, acc: 71.09%] [G loss: 3.987900]\n",
      "epoch:25 step:19910 [D loss: 0.272956, acc: 98.44%] [G loss: 3.858944]\n",
      "epoch:25 step:19911 [D loss: 0.308628, acc: 95.31%] [G loss: 3.715189]\n",
      "epoch:25 step:19912 [D loss: 0.737317, acc: 53.12%] [G loss: 4.252794]\n",
      "epoch:25 step:19913 [D loss: 0.492106, acc: 71.88%] [G loss: 3.323593]\n",
      "epoch:25 step:19914 [D loss: 0.829863, acc: 52.34%] [G loss: 2.742501]\n",
      "epoch:25 step:19915 [D loss: 0.301565, acc: 90.62%] [G loss: 4.281702]\n",
      "epoch:25 step:19916 [D loss: 0.827678, acc: 54.69%] [G loss: 3.630362]\n",
      "epoch:25 step:19917 [D loss: 0.312219, acc: 92.19%] [G loss: 3.116635]\n",
      "epoch:25 step:19918 [D loss: 0.687771, acc: 53.91%] [G loss: 5.639849]\n",
      "epoch:25 step:19919 [D loss: 0.331899, acc: 94.53%] [G loss: 3.950187]\n",
      "epoch:25 step:19920 [D loss: 1.025999, acc: 30.47%] [G loss: 4.147022]\n",
      "epoch:25 step:19921 [D loss: 1.277725, acc: 17.97%] [G loss: 4.172533]\n",
      "epoch:25 step:19922 [D loss: 0.344372, acc: 78.91%] [G loss: 4.872571]\n",
      "epoch:25 step:19923 [D loss: 0.428686, acc: 86.72%] [G loss: 2.970909]\n",
      "epoch:25 step:19924 [D loss: 0.272352, acc: 92.97%] [G loss: 5.433401]\n",
      "epoch:25 step:19925 [D loss: 0.291187, acc: 93.75%] [G loss: 5.226027]\n",
      "epoch:25 step:19926 [D loss: 0.347380, acc: 78.91%] [G loss: 5.829670]\n",
      "epoch:25 step:19927 [D loss: 0.276215, acc: 98.44%] [G loss: 3.285654]\n",
      "epoch:25 step:19928 [D loss: 1.039636, acc: 51.56%] [G loss: 4.136854]\n",
      "epoch:25 step:19929 [D loss: 0.232944, acc: 96.88%] [G loss: 4.021890]\n",
      "epoch:25 step:19930 [D loss: 0.264760, acc: 94.53%] [G loss: 3.384919]\n",
      "epoch:25 step:19931 [D loss: 0.493728, acc: 74.22%] [G loss: 4.331682]\n",
      "epoch:25 step:19932 [D loss: 0.437033, acc: 85.16%] [G loss: 2.953326]\n",
      "epoch:25 step:19933 [D loss: 0.268176, acc: 96.09%] [G loss: 3.919027]\n",
      "epoch:25 step:19934 [D loss: 0.642677, acc: 60.16%] [G loss: 4.210473]\n",
      "epoch:25 step:19935 [D loss: 0.216491, acc: 96.09%] [G loss: 5.342258]\n",
      "epoch:25 step:19936 [D loss: 0.367575, acc: 85.94%] [G loss: 2.538295]\n",
      "epoch:25 step:19937 [D loss: 0.308025, acc: 95.31%] [G loss: 4.390871]\n",
      "epoch:25 step:19938 [D loss: 0.547878, acc: 75.78%] [G loss: 4.867817]\n",
      "epoch:25 step:19939 [D loss: 0.584240, acc: 68.75%] [G loss: 4.313928]\n",
      "epoch:25 step:19940 [D loss: 0.576870, acc: 75.78%] [G loss: 4.454257]\n",
      "epoch:25 step:19941 [D loss: 0.233444, acc: 99.22%] [G loss: 4.258517]\n",
      "epoch:25 step:19942 [D loss: 0.173509, acc: 96.88%] [G loss: 4.513404]\n",
      "epoch:25 step:19943 [D loss: 0.163279, acc: 100.00%] [G loss: 2.318602]\n",
      "epoch:25 step:19944 [D loss: 0.353457, acc: 90.62%] [G loss: 3.920005]\n",
      "epoch:25 step:19945 [D loss: 1.133046, acc: 31.25%] [G loss: 2.785796]\n",
      "epoch:25 step:19946 [D loss: 0.229095, acc: 96.88%] [G loss: 3.502294]\n",
      "epoch:25 step:19947 [D loss: 0.079342, acc: 100.00%] [G loss: 6.397215]\n",
      "epoch:25 step:19948 [D loss: 0.495656, acc: 60.94%] [G loss: 3.348760]\n",
      "epoch:25 step:19949 [D loss: 0.280647, acc: 95.31%] [G loss: 4.091357]\n",
      "epoch:25 step:19950 [D loss: 0.370178, acc: 82.03%] [G loss: 4.090853]\n",
      "epoch:25 step:19951 [D loss: 0.360196, acc: 82.81%] [G loss: 5.164312]\n",
      "epoch:25 step:19952 [D loss: 0.191877, acc: 100.00%] [G loss: 4.332164]\n",
      "epoch:25 step:19953 [D loss: 0.816120, acc: 44.53%] [G loss: 3.212220]\n",
      "epoch:25 step:19954 [D loss: 0.309834, acc: 88.28%] [G loss: 5.959261]\n",
      "epoch:25 step:19955 [D loss: 0.090387, acc: 100.00%] [G loss: 4.440606]\n",
      "epoch:25 step:19956 [D loss: 0.401199, acc: 87.50%] [G loss: 1.983719]\n",
      "epoch:25 step:19957 [D loss: 0.953792, acc: 38.28%] [G loss: 2.643075]\n",
      "epoch:25 step:19958 [D loss: 0.158610, acc: 99.22%] [G loss: 4.889539]\n",
      "epoch:25 step:19959 [D loss: 0.408433, acc: 71.09%] [G loss: 5.477684]\n",
      "epoch:25 step:19960 [D loss: 0.093992, acc: 100.00%] [G loss: 5.131521]\n",
      "epoch:25 step:19961 [D loss: 1.111326, acc: 50.00%] [G loss: 3.279305]\n",
      "epoch:25 step:19962 [D loss: 0.242523, acc: 98.44%] [G loss: 3.538370]\n",
      "epoch:25 step:19963 [D loss: 0.655326, acc: 61.72%] [G loss: 3.834739]\n",
      "epoch:25 step:19964 [D loss: 0.880627, acc: 52.34%] [G loss: 3.264737]\n",
      "epoch:25 step:19965 [D loss: 0.197138, acc: 98.44%] [G loss: 3.849183]\n",
      "epoch:25 step:19966 [D loss: 0.730368, acc: 55.47%] [G loss: 3.755577]\n",
      "epoch:25 step:19967 [D loss: 0.201102, acc: 96.88%] [G loss: 2.018229]\n",
      "epoch:25 step:19968 [D loss: 0.558681, acc: 64.06%] [G loss: 6.107781]\n",
      "epoch:25 step:19969 [D loss: 0.391883, acc: 79.69%] [G loss: 3.552576]\n",
      "epoch:25 step:19970 [D loss: 2.237041, acc: 0.00%] [G loss: 1.752162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:19971 [D loss: 0.195770, acc: 98.44%] [G loss: 4.023975]\n",
      "epoch:25 step:19972 [D loss: 0.326193, acc: 95.31%] [G loss: 4.677616]\n",
      "epoch:25 step:19973 [D loss: 0.295965, acc: 96.88%] [G loss: 4.018642]\n",
      "epoch:25 step:19974 [D loss: 0.170046, acc: 97.66%] [G loss: 2.953035]\n",
      "epoch:25 step:19975 [D loss: 0.424046, acc: 83.59%] [G loss: 4.656874]\n",
      "epoch:25 step:19976 [D loss: 0.498997, acc: 82.03%] [G loss: 3.194852]\n",
      "epoch:25 step:19977 [D loss: 0.537282, acc: 76.56%] [G loss: 3.927501]\n",
      "epoch:25 step:19978 [D loss: 0.908670, acc: 47.66%] [G loss: 3.593756]\n",
      "epoch:25 step:19979 [D loss: 0.758959, acc: 53.12%] [G loss: 3.979038]\n",
      "epoch:25 step:19980 [D loss: 0.319186, acc: 94.53%] [G loss: 2.654261]\n",
      "epoch:25 step:19981 [D loss: 0.433072, acc: 78.12%] [G loss: 5.245276]\n",
      "epoch:25 step:19982 [D loss: 0.513681, acc: 79.69%] [G loss: 4.471097]\n",
      "epoch:25 step:19983 [D loss: 0.444913, acc: 85.16%] [G loss: 3.618892]\n",
      "epoch:25 step:19984 [D loss: 0.330158, acc: 89.06%] [G loss: 2.519794]\n",
      "epoch:25 step:19985 [D loss: 0.979853, acc: 50.78%] [G loss: 2.633614]\n",
      "epoch:25 step:19986 [D loss: 0.114807, acc: 100.00%] [G loss: 4.449086]\n",
      "epoch:25 step:19987 [D loss: 0.061723, acc: 100.00%] [G loss: 4.137467]\n",
      "epoch:25 step:19988 [D loss: 0.712671, acc: 59.38%] [G loss: 4.599751]\n",
      "epoch:25 step:19989 [D loss: 0.219818, acc: 99.22%] [G loss: 3.281951]\n",
      "epoch:25 step:19990 [D loss: 0.222727, acc: 98.44%] [G loss: 3.835347]\n",
      "epoch:25 step:19991 [D loss: 0.061348, acc: 100.00%] [G loss: 4.734825]\n",
      "epoch:25 step:19992 [D loss: 0.343211, acc: 80.47%] [G loss: 4.194634]\n",
      "epoch:25 step:19993 [D loss: 0.531917, acc: 79.69%] [G loss: 4.477990]\n",
      "epoch:25 step:19994 [D loss: 0.514688, acc: 73.44%] [G loss: 2.378815]\n",
      "epoch:25 step:19995 [D loss: 0.294326, acc: 89.06%] [G loss: 3.613846]\n",
      "epoch:25 step:19996 [D loss: 0.795440, acc: 54.69%] [G loss: 4.502804]\n",
      "epoch:25 step:19997 [D loss: 0.108823, acc: 100.00%] [G loss: 3.731074]\n",
      "epoch:25 step:19998 [D loss: 0.334293, acc: 92.19%] [G loss: 4.279282]\n",
      "epoch:25 step:19999 [D loss: 0.883116, acc: 48.44%] [G loss: 4.029516]\n",
      "epoch:25 step:20000 [D loss: 0.270753, acc: 96.88%] [G loss: 3.157784]\n",
      "epoch:25 step:20001 [D loss: 0.279313, acc: 85.94%] [G loss: 4.118150]\n",
      "epoch:25 step:20002 [D loss: 0.553309, acc: 75.00%] [G loss: 3.936849]\n",
      "epoch:25 step:20003 [D loss: 0.586907, acc: 68.75%] [G loss: 4.487617]\n",
      "epoch:25 step:20004 [D loss: 0.401719, acc: 91.41%] [G loss: 3.382725]\n",
      "epoch:25 step:20005 [D loss: 0.410269, acc: 89.06%] [G loss: 5.546762]\n",
      "epoch:25 step:20006 [D loss: 0.511799, acc: 77.34%] [G loss: 2.979682]\n",
      "epoch:25 step:20007 [D loss: 0.102669, acc: 100.00%] [G loss: 4.453802]\n",
      "epoch:25 step:20008 [D loss: 0.784435, acc: 51.56%] [G loss: 3.253704]\n",
      "epoch:25 step:20009 [D loss: 0.414687, acc: 85.16%] [G loss: 2.958853]\n",
      "epoch:25 step:20010 [D loss: 1.178136, acc: 48.44%] [G loss: 4.478632]\n",
      "epoch:25 step:20011 [D loss: 0.259420, acc: 94.53%] [G loss: 4.890367]\n",
      "epoch:25 step:20012 [D loss: 0.203753, acc: 98.44%] [G loss: 3.973487]\n",
      "epoch:25 step:20013 [D loss: 0.382462, acc: 87.50%] [G loss: 2.963137]\n",
      "epoch:25 step:20014 [D loss: 0.810786, acc: 53.91%] [G loss: 3.187279]\n",
      "epoch:25 step:20015 [D loss: 0.096316, acc: 100.00%] [G loss: 3.804158]\n",
      "epoch:25 step:20016 [D loss: 0.897435, acc: 50.78%] [G loss: 5.301929]\n",
      "epoch:25 step:20017 [D loss: 0.178234, acc: 99.22%] [G loss: 3.579525]\n",
      "epoch:25 step:20018 [D loss: 0.565151, acc: 70.31%] [G loss: 4.559506]\n",
      "epoch:25 step:20019 [D loss: 0.497637, acc: 71.09%] [G loss: 3.696434]\n",
      "epoch:25 step:20020 [D loss: 0.240873, acc: 98.44%] [G loss: 4.316839]\n",
      "epoch:25 step:20021 [D loss: 0.232876, acc: 97.66%] [G loss: 2.727966]\n",
      "epoch:25 step:20022 [D loss: 0.072053, acc: 100.00%] [G loss: 4.055533]\n",
      "epoch:25 step:20023 [D loss: 0.309548, acc: 94.53%] [G loss: 4.275454]\n",
      "epoch:25 step:20024 [D loss: 0.347192, acc: 92.97%] [G loss: 3.527966]\n",
      "epoch:25 step:20025 [D loss: 0.767159, acc: 54.69%] [G loss: 4.622169]\n",
      "epoch:25 step:20026 [D loss: 0.509346, acc: 62.50%] [G loss: 4.691089]\n",
      "epoch:25 step:20027 [D loss: 0.875837, acc: 44.53%] [G loss: 3.448357]\n",
      "epoch:25 step:20028 [D loss: 0.729978, acc: 54.69%] [G loss: 4.637407]\n",
      "epoch:25 step:20029 [D loss: 1.127244, acc: 32.81%] [G loss: 1.780637]\n",
      "epoch:25 step:20030 [D loss: 0.601583, acc: 70.31%] [G loss: 2.365103]\n",
      "epoch:25 step:20031 [D loss: 0.454992, acc: 75.00%] [G loss: 3.675602]\n",
      "epoch:25 step:20032 [D loss: 1.119143, acc: 46.88%] [G loss: 4.079423]\n",
      "epoch:25 step:20033 [D loss: 0.291872, acc: 92.19%] [G loss: 2.683387]\n",
      "epoch:25 step:20034 [D loss: 0.491131, acc: 74.22%] [G loss: 3.204289]\n",
      "epoch:25 step:20035 [D loss: 0.226301, acc: 93.75%] [G loss: 4.465415]\n",
      "epoch:25 step:20036 [D loss: 0.091020, acc: 99.22%] [G loss: 4.670765]\n",
      "epoch:25 step:20037 [D loss: 0.269555, acc: 90.62%] [G loss: 3.717278]\n",
      "epoch:25 step:20038 [D loss: 0.450667, acc: 82.03%] [G loss: 4.546394]\n",
      "epoch:25 step:20039 [D loss: 0.697148, acc: 57.03%] [G loss: 3.765190]\n",
      "epoch:25 step:20040 [D loss: 0.366749, acc: 85.16%] [G loss: 3.991478]\n",
      "epoch:25 step:20041 [D loss: 0.549223, acc: 73.44%] [G loss: 3.102622]\n",
      "epoch:25 step:20042 [D loss: 0.063918, acc: 100.00%] [G loss: 3.675009]\n",
      "epoch:25 step:20043 [D loss: 0.296516, acc: 96.09%] [G loss: 3.464499]\n",
      "epoch:25 step:20044 [D loss: 0.685121, acc: 52.34%] [G loss: 4.015903]\n",
      "epoch:25 step:20045 [D loss: 0.481690, acc: 81.25%] [G loss: 3.805755]\n",
      "epoch:25 step:20046 [D loss: 0.370087, acc: 80.47%] [G loss: 3.155375]\n",
      "epoch:25 step:20047 [D loss: 0.763792, acc: 52.34%] [G loss: 4.435187]\n",
      "epoch:25 step:20048 [D loss: 0.280828, acc: 88.28%] [G loss: 3.888242]\n",
      "epoch:25 step:20049 [D loss: 1.098436, acc: 49.22%] [G loss: 3.644675]\n",
      "epoch:25 step:20050 [D loss: 0.166404, acc: 98.44%] [G loss: 3.282131]\n",
      "epoch:25 step:20051 [D loss: 1.244692, acc: 25.78%] [G loss: 4.455913]\n",
      "epoch:25 step:20052 [D loss: 0.158495, acc: 96.88%] [G loss: 5.786973]\n",
      "epoch:25 step:20053 [D loss: 0.240400, acc: 98.44%] [G loss: 3.883944]\n",
      "epoch:25 step:20054 [D loss: 0.434401, acc: 84.38%] [G loss: 4.216111]\n",
      "epoch:25 step:20055 [D loss: 0.202036, acc: 98.44%] [G loss: 4.227751]\n",
      "epoch:25 step:20056 [D loss: 0.877763, acc: 33.59%] [G loss: 3.373075]\n",
      "epoch:25 step:20057 [D loss: 1.132050, acc: 19.53%] [G loss: 3.696309]\n",
      "epoch:25 step:20058 [D loss: 0.372167, acc: 85.94%] [G loss: 3.371526]\n",
      "epoch:25 step:20059 [D loss: 0.487214, acc: 70.31%] [G loss: 3.416731]\n",
      "epoch:25 step:20060 [D loss: 0.435810, acc: 70.31%] [G loss: 5.480366]\n",
      "epoch:25 step:20061 [D loss: 0.079435, acc: 100.00%] [G loss: 4.547060]\n",
      "epoch:25 step:20062 [D loss: 0.425948, acc: 89.06%] [G loss: 6.509364]\n",
      "epoch:25 step:20063 [D loss: 0.336552, acc: 85.94%] [G loss: 3.798716]\n",
      "epoch:25 step:20064 [D loss: 0.326541, acc: 91.41%] [G loss: 3.578041]\n",
      "epoch:25 step:20065 [D loss: 0.752735, acc: 55.47%] [G loss: 2.773888]\n",
      "epoch:25 step:20066 [D loss: 0.340492, acc: 82.81%] [G loss: 4.555197]\n",
      "epoch:25 step:20067 [D loss: 0.095452, acc: 99.22%] [G loss: 4.935637]\n",
      "epoch:25 step:20068 [D loss: 0.730084, acc: 54.69%] [G loss: 3.660439]\n",
      "epoch:25 step:20069 [D loss: 0.782863, acc: 52.34%] [G loss: 6.114672]\n",
      "epoch:25 step:20070 [D loss: 0.809356, acc: 53.12%] [G loss: 5.024284]\n",
      "epoch:25 step:20071 [D loss: 0.817230, acc: 51.56%] [G loss: 2.315416]\n",
      "epoch:25 step:20072 [D loss: 0.210830, acc: 96.09%] [G loss: 5.408168]\n",
      "epoch:25 step:20073 [D loss: 0.547083, acc: 65.62%] [G loss: 4.218955]\n",
      "epoch:25 step:20074 [D loss: 0.741188, acc: 57.81%] [G loss: 3.698130]\n",
      "epoch:25 step:20075 [D loss: 0.447093, acc: 70.31%] [G loss: 3.349025]\n",
      "epoch:25 step:20076 [D loss: 0.047447, acc: 100.00%] [G loss: 3.141813]\n",
      "epoch:25 step:20077 [D loss: 0.627276, acc: 64.84%] [G loss: 2.547441]\n",
      "epoch:25 step:20078 [D loss: 0.451932, acc: 76.56%] [G loss: 2.899193]\n",
      "epoch:25 step:20079 [D loss: 0.500887, acc: 71.88%] [G loss: 3.992769]\n",
      "epoch:25 step:20080 [D loss: 0.086305, acc: 100.00%] [G loss: 5.307025]\n",
      "epoch:25 step:20081 [D loss: 0.859962, acc: 49.22%] [G loss: 4.028656]\n",
      "epoch:25 step:20082 [D loss: 0.351389, acc: 87.50%] [G loss: 4.429529]\n",
      "epoch:25 step:20083 [D loss: 0.534599, acc: 64.84%] [G loss: 3.194243]\n",
      "epoch:25 step:20084 [D loss: 0.216976, acc: 96.88%] [G loss: 3.606317]\n",
      "epoch:25 step:20085 [D loss: 1.686044, acc: 2.34%] [G loss: 4.422341]\n",
      "epoch:25 step:20086 [D loss: 0.491752, acc: 79.69%] [G loss: 3.637727]\n",
      "epoch:25 step:20087 [D loss: 0.503029, acc: 73.44%] [G loss: 2.750552]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:20088 [D loss: 0.510317, acc: 77.34%] [G loss: 2.891711]\n",
      "epoch:25 step:20089 [D loss: 0.185483, acc: 99.22%] [G loss: 2.486164]\n",
      "epoch:25 step:20090 [D loss: 0.287620, acc: 96.09%] [G loss: 3.790708]\n",
      "epoch:25 step:20091 [D loss: 0.184482, acc: 99.22%] [G loss: 4.266922]\n",
      "epoch:25 step:20092 [D loss: 0.781081, acc: 49.22%] [G loss: 3.883722]\n",
      "epoch:25 step:20093 [D loss: 0.165565, acc: 96.09%] [G loss: 5.117075]\n",
      "epoch:25 step:20094 [D loss: 0.144426, acc: 98.44%] [G loss: 1.988837]\n",
      "epoch:25 step:20095 [D loss: 0.407656, acc: 82.03%] [G loss: 5.072988]\n",
      "epoch:25 step:20096 [D loss: 0.320849, acc: 96.88%] [G loss: 3.626919]\n",
      "epoch:25 step:20097 [D loss: 0.150083, acc: 98.44%] [G loss: 4.773492]\n",
      "epoch:25 step:20098 [D loss: 0.283264, acc: 94.53%] [G loss: 2.927666]\n",
      "epoch:25 step:20099 [D loss: 1.035052, acc: 23.44%] [G loss: 3.287248]\n",
      "epoch:25 step:20100 [D loss: 0.415189, acc: 86.72%] [G loss: 2.888384]\n",
      "epoch:25 step:20101 [D loss: 0.164041, acc: 99.22%] [G loss: 4.163343]\n",
      "epoch:25 step:20102 [D loss: 0.400034, acc: 89.84%] [G loss: 4.453836]\n",
      "epoch:25 step:20103 [D loss: 0.288095, acc: 97.66%] [G loss: 3.783755]\n",
      "epoch:25 step:20104 [D loss: 0.460927, acc: 82.81%] [G loss: 2.851211]\n",
      "epoch:25 step:20105 [D loss: 0.563326, acc: 71.09%] [G loss: 4.641773]\n",
      "epoch:25 step:20106 [D loss: 0.218129, acc: 96.88%] [G loss: 3.057254]\n",
      "epoch:25 step:20107 [D loss: 0.669014, acc: 61.72%] [G loss: 2.999184]\n",
      "epoch:25 step:20108 [D loss: 0.412776, acc: 86.72%] [G loss: 4.457651]\n",
      "epoch:25 step:20109 [D loss: 0.416685, acc: 82.81%] [G loss: 3.863845]\n",
      "epoch:25 step:20110 [D loss: 0.676989, acc: 63.28%] [G loss: 3.804520]\n",
      "epoch:25 step:20111 [D loss: 0.642083, acc: 56.25%] [G loss: 4.254646]\n",
      "epoch:25 step:20112 [D loss: 0.444821, acc: 79.69%] [G loss: 3.292241]\n",
      "epoch:25 step:20113 [D loss: 0.744732, acc: 54.69%] [G loss: 3.049352]\n",
      "epoch:25 step:20114 [D loss: 0.317443, acc: 82.03%] [G loss: 4.213091]\n",
      "epoch:25 step:20115 [D loss: 0.474011, acc: 73.44%] [G loss: 3.980053]\n",
      "epoch:25 step:20116 [D loss: 1.069298, acc: 48.44%] [G loss: 2.696619]\n",
      "epoch:25 step:20117 [D loss: 0.422437, acc: 89.84%] [G loss: 3.040617]\n",
      "epoch:25 step:20118 [D loss: 0.222145, acc: 97.66%] [G loss: 3.297452]\n",
      "epoch:25 step:20119 [D loss: 1.240857, acc: 12.50%] [G loss: 4.424104]\n",
      "epoch:25 step:20120 [D loss: 0.346869, acc: 93.75%] [G loss: 4.749991]\n",
      "epoch:25 step:20121 [D loss: 0.182480, acc: 97.66%] [G loss: 3.236139]\n",
      "epoch:25 step:20122 [D loss: 0.560135, acc: 75.00%] [G loss: 4.928054]\n",
      "epoch:25 step:20123 [D loss: 0.404253, acc: 82.81%] [G loss: 2.249127]\n",
      "epoch:25 step:20124 [D loss: 0.669849, acc: 57.03%] [G loss: 5.342904]\n",
      "epoch:25 step:20125 [D loss: 0.651782, acc: 58.59%] [G loss: 2.916344]\n",
      "epoch:25 step:20126 [D loss: 0.428823, acc: 85.16%] [G loss: 4.113558]\n",
      "epoch:25 step:20127 [D loss: 0.284550, acc: 93.75%] [G loss: 3.277468]\n",
      "epoch:25 step:20128 [D loss: 0.888327, acc: 50.78%] [G loss: 4.712327]\n",
      "epoch:25 step:20129 [D loss: 0.291641, acc: 98.44%] [G loss: 3.333290]\n",
      "epoch:25 step:20130 [D loss: 0.645647, acc: 61.72%] [G loss: 4.958441]\n",
      "epoch:25 step:20131 [D loss: 0.236994, acc: 95.31%] [G loss: 3.096150]\n",
      "epoch:25 step:20132 [D loss: 0.368290, acc: 89.06%] [G loss: 5.060742]\n",
      "epoch:25 step:20133 [D loss: 1.043403, acc: 32.03%] [G loss: 2.130127]\n",
      "epoch:25 step:20134 [D loss: 0.401532, acc: 85.94%] [G loss: 5.855862]\n",
      "epoch:25 step:20135 [D loss: 0.383519, acc: 87.50%] [G loss: 5.118608]\n",
      "epoch:25 step:20136 [D loss: 0.748797, acc: 55.47%] [G loss: 3.393114]\n",
      "epoch:25 step:20137 [D loss: 0.702908, acc: 60.94%] [G loss: 4.511863]\n",
      "epoch:25 step:20138 [D loss: 0.313073, acc: 96.88%] [G loss: 2.120686]\n",
      "epoch:25 step:20139 [D loss: 0.636850, acc: 57.03%] [G loss: 4.867414]\n",
      "epoch:25 step:20140 [D loss: 0.584589, acc: 64.84%] [G loss: 3.664108]\n",
      "epoch:25 step:20141 [D loss: 0.767379, acc: 52.34%] [G loss: 4.377394]\n",
      "epoch:25 step:20142 [D loss: 1.018989, acc: 48.44%] [G loss: 2.236515]\n",
      "epoch:25 step:20143 [D loss: 0.364014, acc: 82.03%] [G loss: 3.459300]\n",
      "epoch:25 step:20144 [D loss: 0.609375, acc: 64.06%] [G loss: 5.357965]\n",
      "epoch:25 step:20145 [D loss: 0.584025, acc: 70.31%] [G loss: 2.821993]\n",
      "epoch:25 step:20146 [D loss: 0.758157, acc: 56.25%] [G loss: 4.047290]\n",
      "epoch:25 step:20147 [D loss: 0.876930, acc: 50.78%] [G loss: 2.953447]\n",
      "epoch:25 step:20148 [D loss: 0.198493, acc: 97.66%] [G loss: 2.905712]\n",
      "epoch:25 step:20149 [D loss: 0.526377, acc: 75.78%] [G loss: 3.146136]\n",
      "epoch:25 step:20150 [D loss: 0.403137, acc: 82.81%] [G loss: 4.171271]\n",
      "epoch:25 step:20151 [D loss: 1.016357, acc: 25.78%] [G loss: 3.062612]\n",
      "epoch:25 step:20152 [D loss: 0.680205, acc: 57.03%] [G loss: 4.480707]\n",
      "epoch:25 step:20153 [D loss: 0.322654, acc: 85.94%] [G loss: 3.574267]\n",
      "epoch:25 step:20154 [D loss: 0.338542, acc: 89.84%] [G loss: 3.156119]\n",
      "epoch:25 step:20155 [D loss: 0.042777, acc: 100.00%] [G loss: 5.237880]\n",
      "epoch:25 step:20156 [D loss: 0.288314, acc: 94.53%] [G loss: 3.523930]\n",
      "epoch:25 step:20157 [D loss: 0.485850, acc: 78.12%] [G loss: 5.196993]\n",
      "epoch:25 step:20158 [D loss: 0.106265, acc: 99.22%] [G loss: 4.641776]\n",
      "epoch:25 step:20159 [D loss: 0.467357, acc: 81.25%] [G loss: 2.431709]\n",
      "epoch:25 step:20160 [D loss: 0.200059, acc: 96.88%] [G loss: 3.937610]\n",
      "epoch:25 step:20161 [D loss: 1.344850, acc: 49.22%] [G loss: 3.309988]\n",
      "epoch:25 step:20162 [D loss: 1.348914, acc: 14.84%] [G loss: 2.598194]\n",
      "epoch:25 step:20163 [D loss: 0.463562, acc: 82.03%] [G loss: 2.238557]\n",
      "epoch:25 step:20164 [D loss: 0.667804, acc: 60.94%] [G loss: 4.485987]\n",
      "epoch:25 step:20165 [D loss: 0.282868, acc: 95.31%] [G loss: 4.387037]\n",
      "epoch:25 step:20166 [D loss: 0.728978, acc: 53.12%] [G loss: 3.893630]\n",
      "epoch:25 step:20167 [D loss: 0.356385, acc: 81.25%] [G loss: 3.577944]\n",
      "epoch:25 step:20168 [D loss: 0.189709, acc: 97.66%] [G loss: 2.790841]\n",
      "epoch:25 step:20169 [D loss: 0.541971, acc: 78.12%] [G loss: 3.388549]\n",
      "epoch:25 step:20170 [D loss: 0.183437, acc: 99.22%] [G loss: 3.042120]\n",
      "epoch:25 step:20171 [D loss: 0.251008, acc: 96.09%] [G loss: 4.724585]\n",
      "epoch:25 step:20172 [D loss: 0.659615, acc: 53.91%] [G loss: 3.517384]\n",
      "epoch:25 step:20173 [D loss: 0.591477, acc: 71.09%] [G loss: 4.870531]\n",
      "epoch:25 step:20174 [D loss: 0.395267, acc: 76.56%] [G loss: 4.369799]\n",
      "epoch:25 step:20175 [D loss: 0.295551, acc: 91.41%] [G loss: 4.011724]\n",
      "epoch:25 step:20176 [D loss: 0.939983, acc: 41.41%] [G loss: 3.608434]\n",
      "epoch:25 step:20177 [D loss: 0.408445, acc: 85.16%] [G loss: 2.775582]\n",
      "epoch:25 step:20178 [D loss: 0.189553, acc: 99.22%] [G loss: 5.194866]\n",
      "epoch:25 step:20179 [D loss: 0.375533, acc: 90.62%] [G loss: 4.967347]\n",
      "epoch:25 step:20180 [D loss: 0.063569, acc: 100.00%] [G loss: 6.036132]\n",
      "epoch:25 step:20181 [D loss: 0.410894, acc: 88.28%] [G loss: 2.274366]\n",
      "epoch:25 step:20182 [D loss: 0.396666, acc: 75.78%] [G loss: 5.289739]\n",
      "epoch:25 step:20183 [D loss: 0.607885, acc: 63.28%] [G loss: 4.387099]\n",
      "epoch:25 step:20184 [D loss: 0.475418, acc: 85.16%] [G loss: 5.175060]\n",
      "epoch:25 step:20185 [D loss: 0.156682, acc: 97.66%] [G loss: 4.080533]\n",
      "epoch:25 step:20186 [D loss: 0.492842, acc: 71.88%] [G loss: 4.032541]\n",
      "epoch:25 step:20187 [D loss: 0.614109, acc: 64.06%] [G loss: 3.382135]\n",
      "epoch:25 step:20188 [D loss: 0.331175, acc: 87.50%] [G loss: 4.619030]\n",
      "epoch:25 step:20189 [D loss: 0.384396, acc: 88.28%] [G loss: 3.476788]\n",
      "epoch:25 step:20190 [D loss: 1.359391, acc: 13.28%] [G loss: 2.506642]\n",
      "epoch:25 step:20191 [D loss: 0.426232, acc: 85.16%] [G loss: 1.870853]\n",
      "epoch:25 step:20192 [D loss: 0.341802, acc: 92.97%] [G loss: 3.888068]\n",
      "epoch:25 step:20193 [D loss: 0.320996, acc: 92.97%] [G loss: 3.068061]\n",
      "epoch:25 step:20194 [D loss: 0.442019, acc: 82.03%] [G loss: 4.020871]\n",
      "epoch:25 step:20195 [D loss: 0.279915, acc: 96.09%] [G loss: 3.434730]\n",
      "epoch:25 step:20196 [D loss: 0.546744, acc: 76.56%] [G loss: 3.303670]\n",
      "epoch:25 step:20197 [D loss: 0.327729, acc: 91.41%] [G loss: 3.210996]\n",
      "epoch:25 step:20198 [D loss: 0.333034, acc: 92.19%] [G loss: 3.953780]\n",
      "epoch:25 step:20199 [D loss: 0.335190, acc: 90.62%] [G loss: 3.744337]\n",
      "epoch:25 step:20200 [D loss: 0.218733, acc: 98.44%] [G loss: 4.595551]\n",
      "epoch:25 step:20201 [D loss: 0.558754, acc: 63.28%] [G loss: 4.659501]\n",
      "epoch:25 step:20202 [D loss: 0.139062, acc: 99.22%] [G loss: 2.702080]\n",
      "epoch:25 step:20203 [D loss: 0.802193, acc: 49.22%] [G loss: 3.446410]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:20204 [D loss: 0.402216, acc: 91.41%] [G loss: 3.483557]\n",
      "epoch:25 step:20205 [D loss: 0.398104, acc: 73.44%] [G loss: 3.336423]\n",
      "epoch:25 step:20206 [D loss: 0.192932, acc: 96.88%] [G loss: 4.032310]\n",
      "epoch:25 step:20207 [D loss: 1.017706, acc: 50.78%] [G loss: 2.825010]\n",
      "epoch:25 step:20208 [D loss: 0.204266, acc: 95.31%] [G loss: 4.024145]\n",
      "epoch:25 step:20209 [D loss: 0.558370, acc: 72.66%] [G loss: 3.839799]\n",
      "epoch:25 step:20210 [D loss: 0.313578, acc: 94.53%] [G loss: 3.826516]\n",
      "epoch:25 step:20211 [D loss: 0.462063, acc: 76.56%] [G loss: 4.610291]\n",
      "epoch:25 step:20212 [D loss: 0.602142, acc: 64.84%] [G loss: 4.122070]\n",
      "epoch:25 step:20213 [D loss: 1.071242, acc: 38.28%] [G loss: 1.348629]\n",
      "epoch:25 step:20214 [D loss: 1.412202, acc: 52.34%] [G loss: 5.256297]\n",
      "epoch:25 step:20215 [D loss: 0.888365, acc: 50.78%] [G loss: 4.970157]\n",
      "epoch:25 step:20216 [D loss: 0.323588, acc: 91.41%] [G loss: 2.705510]\n",
      "epoch:25 step:20217 [D loss: 0.606045, acc: 63.28%] [G loss: 4.744488]\n",
      "epoch:25 step:20218 [D loss: 0.558570, acc: 64.06%] [G loss: 4.986245]\n",
      "epoch:25 step:20219 [D loss: 0.351724, acc: 89.06%] [G loss: 4.151161]\n",
      "epoch:25 step:20220 [D loss: 0.434475, acc: 74.22%] [G loss: 4.494056]\n",
      "epoch:25 step:20221 [D loss: 0.647289, acc: 57.81%] [G loss: 2.758736]\n",
      "epoch:25 step:20222 [D loss: 0.346961, acc: 85.16%] [G loss: 3.550406]\n",
      "epoch:25 step:20223 [D loss: 0.282118, acc: 97.66%] [G loss: 4.794346]\n",
      "epoch:25 step:20224 [D loss: 0.942163, acc: 32.81%] [G loss: 5.754964]\n",
      "epoch:25 step:20225 [D loss: 0.412816, acc: 84.38%] [G loss: 3.866425]\n",
      "epoch:25 step:20226 [D loss: 0.730705, acc: 55.47%] [G loss: 3.328807]\n",
      "epoch:25 step:20227 [D loss: 0.260643, acc: 91.41%] [G loss: 3.969540]\n",
      "epoch:25 step:20228 [D loss: 0.316775, acc: 92.19%] [G loss: 4.629969]\n",
      "epoch:25 step:20229 [D loss: 0.804918, acc: 54.69%] [G loss: 3.039220]\n",
      "epoch:25 step:20230 [D loss: 0.725495, acc: 54.69%] [G loss: 4.599168]\n",
      "epoch:25 step:20231 [D loss: 0.555586, acc: 72.66%] [G loss: 3.971753]\n",
      "epoch:25 step:20232 [D loss: 0.360056, acc: 92.97%] [G loss: 2.204221]\n",
      "epoch:25 step:20233 [D loss: 0.516071, acc: 72.66%] [G loss: 2.370950]\n",
      "epoch:25 step:20234 [D loss: 0.126777, acc: 100.00%] [G loss: 4.566670]\n",
      "epoch:25 step:20235 [D loss: 0.351492, acc: 88.28%] [G loss: 3.029480]\n",
      "epoch:25 step:20236 [D loss: 0.120826, acc: 99.22%] [G loss: 5.788960]\n",
      "epoch:25 step:20237 [D loss: 0.391408, acc: 84.38%] [G loss: 4.679779]\n",
      "epoch:25 step:20238 [D loss: 0.702359, acc: 58.59%] [G loss: 2.908678]\n",
      "epoch:25 step:20239 [D loss: 0.222520, acc: 96.09%] [G loss: 2.904125]\n",
      "epoch:25 step:20240 [D loss: 0.766813, acc: 50.78%] [G loss: 2.747869]\n",
      "epoch:25 step:20241 [D loss: 0.203221, acc: 96.88%] [G loss: 2.108719]\n",
      "epoch:25 step:20242 [D loss: 0.367582, acc: 91.41%] [G loss: 2.991356]\n",
      "epoch:25 step:20243 [D loss: 0.433917, acc: 74.22%] [G loss: 3.816056]\n",
      "epoch:25 step:20244 [D loss: 0.438693, acc: 83.59%] [G loss: 3.375521]\n",
      "epoch:25 step:20245 [D loss: 0.841040, acc: 37.50%] [G loss: 2.416728]\n",
      "epoch:25 step:20246 [D loss: 0.378937, acc: 79.69%] [G loss: 4.702437]\n",
      "epoch:25 step:20247 [D loss: 0.844659, acc: 52.34%] [G loss: 2.384040]\n",
      "epoch:25 step:20248 [D loss: 0.282849, acc: 91.41%] [G loss: 3.365424]\n",
      "epoch:25 step:20249 [D loss: 0.525291, acc: 67.19%] [G loss: 3.314437]\n",
      "epoch:25 step:20250 [D loss: 0.402068, acc: 79.69%] [G loss: 4.871300]\n",
      "epoch:25 step:20251 [D loss: 0.511122, acc: 68.75%] [G loss: 4.143956]\n",
      "epoch:25 step:20252 [D loss: 0.100713, acc: 100.00%] [G loss: 6.431013]\n",
      "epoch:25 step:20253 [D loss: 0.175939, acc: 98.44%] [G loss: 3.513630]\n",
      "epoch:25 step:20254 [D loss: 0.601130, acc: 63.28%] [G loss: 3.184577]\n",
      "epoch:25 step:20255 [D loss: 0.884049, acc: 37.50%] [G loss: 3.420995]\n",
      "epoch:25 step:20256 [D loss: 1.051268, acc: 19.53%] [G loss: 3.389471]\n",
      "epoch:25 step:20257 [D loss: 0.992337, acc: 28.91%] [G loss: 2.862477]\n",
      "epoch:25 step:20258 [D loss: 0.176256, acc: 99.22%] [G loss: 4.073998]\n",
      "epoch:25 step:20259 [D loss: 0.275527, acc: 91.41%] [G loss: 2.862047]\n",
      "epoch:25 step:20260 [D loss: 0.310920, acc: 85.94%] [G loss: 2.181210]\n",
      "epoch:25 step:20261 [D loss: 0.090184, acc: 100.00%] [G loss: 2.785782]\n",
      "epoch:25 step:20262 [D loss: 0.241881, acc: 97.66%] [G loss: 3.400014]\n",
      "epoch:25 step:20263 [D loss: 0.524341, acc: 73.44%] [G loss: 4.659958]\n",
      "epoch:25 step:20264 [D loss: 0.196917, acc: 100.00%] [G loss: 3.689116]\n",
      "epoch:25 step:20265 [D loss: 0.999332, acc: 27.34%] [G loss: 4.279705]\n",
      "epoch:25 step:20266 [D loss: 0.157908, acc: 99.22%] [G loss: 4.536552]\n",
      "epoch:25 step:20267 [D loss: 1.158669, acc: 33.59%] [G loss: 2.744095]\n",
      "epoch:25 step:20268 [D loss: 0.234334, acc: 96.09%] [G loss: 3.909675]\n",
      "epoch:25 step:20269 [D loss: 0.728083, acc: 54.69%] [G loss: 4.786849]\n",
      "epoch:25 step:20270 [D loss: 0.508429, acc: 78.91%] [G loss: 3.266304]\n",
      "epoch:25 step:20271 [D loss: 0.327917, acc: 95.31%] [G loss: 5.742819]\n",
      "epoch:25 step:20272 [D loss: 0.152085, acc: 99.22%] [G loss: 5.534220]\n",
      "epoch:25 step:20273 [D loss: 0.465239, acc: 82.03%] [G loss: 4.840967]\n",
      "epoch:25 step:20274 [D loss: 0.154372, acc: 99.22%] [G loss: 3.689116]\n",
      "epoch:25 step:20275 [D loss: 0.794615, acc: 46.88%] [G loss: 4.290051]\n",
      "epoch:25 step:20276 [D loss: 0.414035, acc: 86.72%] [G loss: 3.533724]\n",
      "epoch:25 step:20277 [D loss: 0.602188, acc: 62.50%] [G loss: 2.921569]\n",
      "epoch:25 step:20278 [D loss: 0.830898, acc: 54.69%] [G loss: 5.644881]\n",
      "epoch:25 step:20279 [D loss: 0.094286, acc: 100.00%] [G loss: 7.179780]\n",
      "epoch:25 step:20280 [D loss: 0.201048, acc: 98.44%] [G loss: 6.328867]\n",
      "epoch:25 step:20281 [D loss: 0.960580, acc: 50.00%] [G loss: 5.782669]\n",
      "epoch:25 step:20282 [D loss: 1.265364, acc: 21.88%] [G loss: 3.956478]\n",
      "epoch:25 step:20283 [D loss: 0.085702, acc: 100.00%] [G loss: 4.335801]\n",
      "epoch:25 step:20284 [D loss: 0.652351, acc: 57.03%] [G loss: 6.944591]\n",
      "epoch:25 step:20285 [D loss: 0.129108, acc: 99.22%] [G loss: 4.460310]\n",
      "epoch:25 step:20286 [D loss: 0.986787, acc: 51.56%] [G loss: 3.368450]\n",
      "epoch:25 step:20287 [D loss: 0.225600, acc: 96.88%] [G loss: 4.550701]\n",
      "epoch:25 step:20288 [D loss: 0.401926, acc: 74.22%] [G loss: 3.874207]\n",
      "epoch:25 step:20289 [D loss: 0.566030, acc: 62.50%] [G loss: 2.347560]\n",
      "epoch:25 step:20290 [D loss: 0.446742, acc: 82.03%] [G loss: 2.707556]\n",
      "epoch:25 step:20291 [D loss: 0.453097, acc: 81.25%] [G loss: 4.159373]\n",
      "epoch:25 step:20292 [D loss: 0.228848, acc: 99.22%] [G loss: 3.677145]\n",
      "epoch:25 step:20293 [D loss: 0.426271, acc: 89.06%] [G loss: 2.114529]\n",
      "epoch:25 step:20294 [D loss: 0.365441, acc: 92.19%] [G loss: 3.290005]\n",
      "epoch:25 step:20295 [D loss: 0.129157, acc: 98.44%] [G loss: 3.811846]\n",
      "epoch:25 step:20296 [D loss: 0.186102, acc: 100.00%] [G loss: 4.068585]\n",
      "epoch:25 step:20297 [D loss: 0.385482, acc: 79.69%] [G loss: 2.837431]\n",
      "epoch:25 step:20298 [D loss: 0.335591, acc: 78.12%] [G loss: 5.228071]\n",
      "epoch:25 step:20299 [D loss: 0.374997, acc: 95.31%] [G loss: 3.947459]\n",
      "epoch:25 step:20300 [D loss: 0.266281, acc: 92.19%] [G loss: 4.284852]\n",
      "epoch:25 step:20301 [D loss: 0.451255, acc: 68.75%] [G loss: 5.671979]\n",
      "epoch:25 step:20302 [D loss: 0.641486, acc: 57.81%] [G loss: 4.899033]\n",
      "epoch:25 step:20303 [D loss: 0.761399, acc: 57.03%] [G loss: 3.182491]\n",
      "epoch:25 step:20304 [D loss: 0.672129, acc: 54.69%] [G loss: 3.474012]\n",
      "epoch:25 step:20305 [D loss: 1.631056, acc: 39.84%] [G loss: 2.533951]\n",
      "epoch:25 step:20306 [D loss: 0.175691, acc: 97.66%] [G loss: 2.801377]\n",
      "epoch:26 step:20307 [D loss: 0.301302, acc: 94.53%] [G loss: 3.324028]\n",
      "epoch:26 step:20308 [D loss: 0.419462, acc: 83.59%] [G loss: 6.141639]\n",
      "epoch:26 step:20309 [D loss: 0.400895, acc: 91.41%] [G loss: 5.198195]\n",
      "epoch:26 step:20310 [D loss: 0.184726, acc: 99.22%] [G loss: 2.758766]\n",
      "epoch:26 step:20311 [D loss: 0.506673, acc: 68.75%] [G loss: 5.008897]\n",
      "epoch:26 step:20312 [D loss: 1.044253, acc: 38.28%] [G loss: 2.522759]\n",
      "epoch:26 step:20313 [D loss: 0.471082, acc: 79.69%] [G loss: 2.861384]\n",
      "epoch:26 step:20314 [D loss: 0.676637, acc: 58.59%] [G loss: 5.849389]\n",
      "epoch:26 step:20315 [D loss: 1.032153, acc: 43.75%] [G loss: 5.224562]\n",
      "epoch:26 step:20316 [D loss: 0.428743, acc: 88.28%] [G loss: 4.183997]\n",
      "epoch:26 step:20317 [D loss: 0.392637, acc: 82.81%] [G loss: 2.592348]\n",
      "epoch:26 step:20318 [D loss: 0.409351, acc: 89.06%] [G loss: 3.727486]\n",
      "epoch:26 step:20319 [D loss: 0.449279, acc: 81.25%] [G loss: 4.993745]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20320 [D loss: 0.154782, acc: 99.22%] [G loss: 3.219715]\n",
      "epoch:26 step:20321 [D loss: 1.288479, acc: 13.28%] [G loss: 3.744459]\n",
      "epoch:26 step:20322 [D loss: 0.136189, acc: 99.22%] [G loss: 3.091861]\n",
      "epoch:26 step:20323 [D loss: 0.361342, acc: 91.41%] [G loss: 4.697740]\n",
      "epoch:26 step:20324 [D loss: 0.816774, acc: 49.22%] [G loss: 2.857993]\n",
      "epoch:26 step:20325 [D loss: 0.315474, acc: 94.53%] [G loss: 3.178854]\n",
      "epoch:26 step:20326 [D loss: 0.542707, acc: 78.12%] [G loss: 3.319839]\n",
      "epoch:26 step:20327 [D loss: 0.384461, acc: 88.28%] [G loss: 5.016753]\n",
      "epoch:26 step:20328 [D loss: 0.853201, acc: 41.41%] [G loss: 3.235828]\n",
      "epoch:26 step:20329 [D loss: 0.410845, acc: 83.59%] [G loss: 2.589766]\n",
      "epoch:26 step:20330 [D loss: 0.336342, acc: 87.50%] [G loss: 3.011664]\n",
      "epoch:26 step:20331 [D loss: 0.225283, acc: 97.66%] [G loss: 5.300959]\n",
      "epoch:26 step:20332 [D loss: 0.476573, acc: 78.12%] [G loss: 3.038201]\n",
      "epoch:26 step:20333 [D loss: 0.233010, acc: 97.66%] [G loss: 5.346244]\n",
      "epoch:26 step:20334 [D loss: 0.280268, acc: 90.62%] [G loss: 3.715587]\n",
      "epoch:26 step:20335 [D loss: 0.291079, acc: 87.50%] [G loss: 3.680498]\n",
      "epoch:26 step:20336 [D loss: 0.509121, acc: 60.94%] [G loss: 3.824913]\n",
      "epoch:26 step:20337 [D loss: 0.662676, acc: 64.06%] [G loss: 3.221272]\n",
      "epoch:26 step:20338 [D loss: 0.909305, acc: 48.44%] [G loss: 4.876139]\n",
      "epoch:26 step:20339 [D loss: 0.397678, acc: 77.34%] [G loss: 3.590427]\n",
      "epoch:26 step:20340 [D loss: 0.295948, acc: 96.88%] [G loss: 2.239122]\n",
      "epoch:26 step:20341 [D loss: 0.973268, acc: 45.31%] [G loss: 2.961005]\n",
      "epoch:26 step:20342 [D loss: 0.248241, acc: 92.19%] [G loss: 2.594939]\n",
      "epoch:26 step:20343 [D loss: 0.397609, acc: 89.84%] [G loss: 3.593912]\n",
      "epoch:26 step:20344 [D loss: 0.386141, acc: 89.06%] [G loss: 3.148280]\n",
      "epoch:26 step:20345 [D loss: 0.238950, acc: 92.19%] [G loss: 3.051746]\n",
      "epoch:26 step:20346 [D loss: 0.829839, acc: 52.34%] [G loss: 3.471395]\n",
      "epoch:26 step:20347 [D loss: 0.456276, acc: 78.12%] [G loss: 3.620744]\n",
      "epoch:26 step:20348 [D loss: 0.513107, acc: 72.66%] [G loss: 5.350556]\n",
      "epoch:26 step:20349 [D loss: 0.517809, acc: 63.28%] [G loss: 3.461648]\n",
      "epoch:26 step:20350 [D loss: 0.517636, acc: 61.72%] [G loss: 3.555508]\n",
      "epoch:26 step:20351 [D loss: 0.575024, acc: 68.75%] [G loss: 2.969848]\n",
      "epoch:26 step:20352 [D loss: 0.346992, acc: 82.03%] [G loss: 3.537823]\n",
      "epoch:26 step:20353 [D loss: 0.355780, acc: 77.34%] [G loss: 3.686743]\n",
      "epoch:26 step:20354 [D loss: 1.083470, acc: 29.69%] [G loss: 4.889869]\n",
      "epoch:26 step:20355 [D loss: 0.991116, acc: 25.78%] [G loss: 4.241939]\n",
      "epoch:26 step:20356 [D loss: 0.776440, acc: 47.66%] [G loss: 3.964525]\n",
      "epoch:26 step:20357 [D loss: 0.407775, acc: 83.59%] [G loss: 5.221247]\n",
      "epoch:26 step:20358 [D loss: 0.391733, acc: 89.06%] [G loss: 4.219202]\n",
      "epoch:26 step:20359 [D loss: 0.246796, acc: 97.66%] [G loss: 4.882023]\n",
      "epoch:26 step:20360 [D loss: 0.750629, acc: 50.78%] [G loss: 3.687739]\n",
      "epoch:26 step:20361 [D loss: 0.260445, acc: 97.66%] [G loss: 3.727825]\n",
      "epoch:26 step:20362 [D loss: 0.330902, acc: 85.16%] [G loss: 5.287580]\n",
      "epoch:26 step:20363 [D loss: 0.183312, acc: 97.66%] [G loss: 3.329525]\n",
      "epoch:26 step:20364 [D loss: 0.471360, acc: 75.00%] [G loss: 4.486212]\n",
      "epoch:26 step:20365 [D loss: 0.371998, acc: 84.38%] [G loss: 4.132454]\n",
      "epoch:26 step:20366 [D loss: 0.274684, acc: 95.31%] [G loss: 4.711473]\n",
      "epoch:26 step:20367 [D loss: 0.561392, acc: 60.94%] [G loss: 5.178377]\n",
      "epoch:26 step:20368 [D loss: 0.780971, acc: 56.25%] [G loss: 4.149064]\n",
      "epoch:26 step:20369 [D loss: 0.188990, acc: 98.44%] [G loss: 2.258991]\n",
      "epoch:26 step:20370 [D loss: 0.879619, acc: 46.09%] [G loss: 4.848387]\n",
      "epoch:26 step:20371 [D loss: 1.006173, acc: 29.69%] [G loss: 3.629751]\n",
      "epoch:26 step:20372 [D loss: 0.544537, acc: 71.88%] [G loss: 2.948526]\n",
      "epoch:26 step:20373 [D loss: 0.535959, acc: 75.78%] [G loss: 4.611157]\n",
      "epoch:26 step:20374 [D loss: 0.287305, acc: 87.50%] [G loss: 3.073004]\n",
      "epoch:26 step:20375 [D loss: 0.264567, acc: 94.53%] [G loss: 5.345845]\n",
      "epoch:26 step:20376 [D loss: 0.474488, acc: 82.03%] [G loss: 2.988829]\n",
      "epoch:26 step:20377 [D loss: 0.485213, acc: 78.12%] [G loss: 1.546338]\n",
      "epoch:26 step:20378 [D loss: 1.185281, acc: 15.62%] [G loss: 4.305943]\n",
      "epoch:26 step:20379 [D loss: 0.375608, acc: 85.16%] [G loss: 2.576681]\n",
      "epoch:26 step:20380 [D loss: 0.255979, acc: 97.66%] [G loss: 2.699079]\n",
      "epoch:26 step:20381 [D loss: 0.202755, acc: 98.44%] [G loss: 4.611621]\n",
      "epoch:26 step:20382 [D loss: 0.440737, acc: 80.47%] [G loss: 5.439713]\n",
      "epoch:26 step:20383 [D loss: 0.761668, acc: 53.91%] [G loss: 4.665016]\n",
      "epoch:26 step:20384 [D loss: 0.315582, acc: 87.50%] [G loss: 5.955297]\n",
      "epoch:26 step:20385 [D loss: 0.564369, acc: 74.22%] [G loss: 5.745439]\n",
      "epoch:26 step:20386 [D loss: 0.523004, acc: 74.22%] [G loss: 4.325865]\n",
      "epoch:26 step:20387 [D loss: 0.450794, acc: 74.22%] [G loss: 5.298404]\n",
      "epoch:26 step:20388 [D loss: 0.676463, acc: 59.38%] [G loss: 4.539983]\n",
      "epoch:26 step:20389 [D loss: 0.186066, acc: 98.44%] [G loss: 2.663386]\n",
      "epoch:26 step:20390 [D loss: 0.390585, acc: 74.22%] [G loss: 2.643982]\n",
      "epoch:26 step:20391 [D loss: 1.353289, acc: 13.28%] [G loss: 4.168506]\n",
      "epoch:26 step:20392 [D loss: 0.570774, acc: 70.31%] [G loss: 3.676957]\n",
      "epoch:26 step:20393 [D loss: 0.346065, acc: 85.16%] [G loss: 5.322588]\n",
      "epoch:26 step:20394 [D loss: 0.708883, acc: 54.69%] [G loss: 4.047179]\n",
      "epoch:26 step:20395 [D loss: 0.308105, acc: 92.97%] [G loss: 3.655047]\n",
      "epoch:26 step:20396 [D loss: 0.595236, acc: 69.53%] [G loss: 5.039824]\n",
      "epoch:26 step:20397 [D loss: 0.197164, acc: 98.44%] [G loss: 4.988917]\n",
      "epoch:26 step:20398 [D loss: 0.598458, acc: 65.62%] [G loss: 3.873168]\n",
      "epoch:26 step:20399 [D loss: 0.808753, acc: 45.31%] [G loss: 3.896531]\n",
      "epoch:26 step:20400 [D loss: 0.938575, acc: 31.25%] [G loss: 2.818634]\n",
      "epoch:26 step:20401 [D loss: 1.265623, acc: 37.50%] [G loss: 3.607697]\n",
      "epoch:26 step:20402 [D loss: 0.233932, acc: 96.09%] [G loss: 3.594848]\n",
      "epoch:26 step:20403 [D loss: 0.519273, acc: 78.91%] [G loss: 3.052237]\n",
      "epoch:26 step:20404 [D loss: 0.557325, acc: 64.84%] [G loss: 2.066388]\n",
      "epoch:26 step:20405 [D loss: 0.213031, acc: 99.22%] [G loss: 4.317560]\n",
      "epoch:26 step:20406 [D loss: 0.706706, acc: 55.47%] [G loss: 2.992717]\n",
      "epoch:26 step:20407 [D loss: 0.209069, acc: 98.44%] [G loss: 3.879229]\n",
      "epoch:26 step:20408 [D loss: 0.659582, acc: 59.38%] [G loss: 4.480967]\n",
      "epoch:26 step:20409 [D loss: 1.701504, acc: 6.25%] [G loss: 3.857759]\n",
      "epoch:26 step:20410 [D loss: 0.830105, acc: 53.12%] [G loss: 3.393844]\n",
      "epoch:26 step:20411 [D loss: 0.175459, acc: 99.22%] [G loss: 2.864842]\n",
      "epoch:26 step:20412 [D loss: 0.312237, acc: 92.97%] [G loss: 4.585445]\n",
      "epoch:26 step:20413 [D loss: 0.300846, acc: 96.88%] [G loss: 5.169205]\n",
      "epoch:26 step:20414 [D loss: 0.359846, acc: 91.41%] [G loss: 3.621152]\n",
      "epoch:26 step:20415 [D loss: 0.508913, acc: 80.47%] [G loss: 2.116428]\n",
      "epoch:26 step:20416 [D loss: 0.429132, acc: 81.25%] [G loss: 1.619286]\n",
      "epoch:26 step:20417 [D loss: 0.425908, acc: 83.59%] [G loss: 5.495202]\n",
      "epoch:26 step:20418 [D loss: 0.238633, acc: 96.09%] [G loss: 2.710955]\n",
      "epoch:26 step:20419 [D loss: 0.283873, acc: 96.09%] [G loss: 4.009223]\n",
      "epoch:26 step:20420 [D loss: 0.545488, acc: 71.09%] [G loss: 3.517338]\n",
      "epoch:26 step:20421 [D loss: 0.332262, acc: 92.97%] [G loss: 2.203258]\n",
      "epoch:26 step:20422 [D loss: 0.890587, acc: 45.31%] [G loss: 3.197457]\n",
      "epoch:26 step:20423 [D loss: 0.180868, acc: 99.22%] [G loss: 3.910292]\n",
      "epoch:26 step:20424 [D loss: 0.728427, acc: 58.59%] [G loss: 3.299884]\n",
      "epoch:26 step:20425 [D loss: 0.401494, acc: 91.41%] [G loss: 4.749667]\n",
      "epoch:26 step:20426 [D loss: 0.576931, acc: 74.22%] [G loss: 4.737034]\n",
      "epoch:26 step:20427 [D loss: 0.209113, acc: 98.44%] [G loss: 4.925480]\n",
      "epoch:26 step:20428 [D loss: 0.062602, acc: 100.00%] [G loss: 7.705828]\n",
      "epoch:26 step:20429 [D loss: 0.492101, acc: 81.25%] [G loss: 3.569791]\n",
      "epoch:26 step:20430 [D loss: 0.938959, acc: 46.09%] [G loss: 5.247110]\n",
      "epoch:26 step:20431 [D loss: 0.541364, acc: 71.88%] [G loss: 3.488702]\n",
      "epoch:26 step:20432 [D loss: 0.224311, acc: 98.44%] [G loss: 2.785013]\n",
      "epoch:26 step:20433 [D loss: 0.327028, acc: 85.94%] [G loss: 3.152315]\n",
      "epoch:26 step:20434 [D loss: 0.171311, acc: 99.22%] [G loss: 4.088646]\n",
      "epoch:26 step:20435 [D loss: 0.566250, acc: 69.53%] [G loss: 3.626576]\n",
      "epoch:26 step:20436 [D loss: 0.247082, acc: 96.09%] [G loss: 4.170481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20437 [D loss: 0.335599, acc: 90.62%] [G loss: 3.547057]\n",
      "epoch:26 step:20438 [D loss: 0.441974, acc: 85.94%] [G loss: 4.263088]\n",
      "epoch:26 step:20439 [D loss: 0.732894, acc: 50.00%] [G loss: 3.254115]\n",
      "epoch:26 step:20440 [D loss: 0.397240, acc: 86.72%] [G loss: 4.627718]\n",
      "epoch:26 step:20441 [D loss: 0.803508, acc: 53.12%] [G loss: 4.031461]\n",
      "epoch:26 step:20442 [D loss: 0.177922, acc: 100.00%] [G loss: 4.010355]\n",
      "epoch:26 step:20443 [D loss: 0.607463, acc: 64.84%] [G loss: 5.021110]\n",
      "epoch:26 step:20444 [D loss: 0.637573, acc: 67.19%] [G loss: 3.063459]\n",
      "epoch:26 step:20445 [D loss: 0.470173, acc: 70.31%] [G loss: 2.677491]\n",
      "epoch:26 step:20446 [D loss: 0.697823, acc: 59.38%] [G loss: 2.433511]\n",
      "epoch:26 step:20447 [D loss: 0.692875, acc: 53.91%] [G loss: 4.983705]\n",
      "epoch:26 step:20448 [D loss: 0.435277, acc: 82.81%] [G loss: 4.610401]\n",
      "epoch:26 step:20449 [D loss: 0.595377, acc: 62.50%] [G loss: 4.539430]\n",
      "epoch:26 step:20450 [D loss: 0.148256, acc: 100.00%] [G loss: 2.438941]\n",
      "epoch:26 step:20451 [D loss: 0.566244, acc: 75.00%] [G loss: 2.583508]\n",
      "epoch:26 step:20452 [D loss: 0.576721, acc: 64.06%] [G loss: 3.356917]\n",
      "epoch:26 step:20453 [D loss: 0.653876, acc: 65.62%] [G loss: 4.743626]\n",
      "epoch:26 step:20454 [D loss: 0.854678, acc: 51.56%] [G loss: 4.410718]\n",
      "epoch:26 step:20455 [D loss: 1.185335, acc: 48.44%] [G loss: 3.570019]\n",
      "epoch:26 step:20456 [D loss: 0.603151, acc: 61.72%] [G loss: 2.607852]\n",
      "epoch:26 step:20457 [D loss: 0.618220, acc: 63.28%] [G loss: 5.216063]\n",
      "epoch:26 step:20458 [D loss: 0.372191, acc: 78.91%] [G loss: 4.246055]\n",
      "epoch:26 step:20459 [D loss: 0.681300, acc: 60.16%] [G loss: 2.883516]\n",
      "epoch:26 step:20460 [D loss: 0.211344, acc: 98.44%] [G loss: 3.759057]\n",
      "epoch:26 step:20461 [D loss: 0.766943, acc: 54.69%] [G loss: 2.133440]\n",
      "epoch:26 step:20462 [D loss: 0.384631, acc: 84.38%] [G loss: 2.958070]\n",
      "epoch:26 step:20463 [D loss: 0.574358, acc: 71.88%] [G loss: 4.190875]\n",
      "epoch:26 step:20464 [D loss: 0.355942, acc: 86.72%] [G loss: 4.689366]\n",
      "epoch:26 step:20465 [D loss: 0.190527, acc: 96.88%] [G loss: 4.751585]\n",
      "epoch:26 step:20466 [D loss: 1.311487, acc: 35.16%] [G loss: 4.988661]\n",
      "epoch:26 step:20467 [D loss: 0.384853, acc: 91.41%] [G loss: 4.256925]\n",
      "epoch:26 step:20468 [D loss: 0.249603, acc: 98.44%] [G loss: 3.431170]\n",
      "epoch:26 step:20469 [D loss: 0.235475, acc: 98.44%] [G loss: 4.649592]\n",
      "epoch:26 step:20470 [D loss: 0.282445, acc: 92.19%] [G loss: 4.438370]\n",
      "epoch:26 step:20471 [D loss: 0.737027, acc: 58.59%] [G loss: 2.551528]\n",
      "epoch:26 step:20472 [D loss: 0.340321, acc: 92.97%] [G loss: 4.704021]\n",
      "epoch:26 step:20473 [D loss: 0.376158, acc: 90.62%] [G loss: 5.746393]\n",
      "epoch:26 step:20474 [D loss: 0.351478, acc: 91.41%] [G loss: 2.841187]\n",
      "epoch:26 step:20475 [D loss: 0.296035, acc: 97.66%] [G loss: 3.304092]\n",
      "epoch:26 step:20476 [D loss: 0.443943, acc: 85.94%] [G loss: 2.336537]\n",
      "epoch:26 step:20477 [D loss: 0.909335, acc: 35.94%] [G loss: 3.706760]\n",
      "epoch:26 step:20478 [D loss: 0.271627, acc: 91.41%] [G loss: 4.881106]\n",
      "epoch:26 step:20479 [D loss: 0.419175, acc: 86.72%] [G loss: 2.961198]\n",
      "epoch:26 step:20480 [D loss: 0.312403, acc: 84.38%] [G loss: 3.375508]\n",
      "epoch:26 step:20481 [D loss: 0.434714, acc: 67.97%] [G loss: 4.745773]\n",
      "epoch:26 step:20482 [D loss: 0.778935, acc: 53.91%] [G loss: 4.702140]\n",
      "epoch:26 step:20483 [D loss: 0.316415, acc: 85.94%] [G loss: 3.304730]\n",
      "epoch:26 step:20484 [D loss: 0.302770, acc: 93.75%] [G loss: 2.929843]\n",
      "epoch:26 step:20485 [D loss: 0.363565, acc: 92.97%] [G loss: 3.920021]\n",
      "epoch:26 step:20486 [D loss: 0.301994, acc: 95.31%] [G loss: 1.901381]\n",
      "epoch:26 step:20487 [D loss: 0.471417, acc: 66.41%] [G loss: 4.021361]\n",
      "epoch:26 step:20488 [D loss: 0.385429, acc: 82.81%] [G loss: 4.261261]\n",
      "epoch:26 step:20489 [D loss: 0.666028, acc: 60.94%] [G loss: 5.636442]\n",
      "epoch:26 step:20490 [D loss: 0.630435, acc: 60.94%] [G loss: 4.149114]\n",
      "epoch:26 step:20491 [D loss: 0.794097, acc: 50.78%] [G loss: 2.745837]\n",
      "epoch:26 step:20492 [D loss: 0.157211, acc: 97.66%] [G loss: 4.395418]\n",
      "epoch:26 step:20493 [D loss: 0.716703, acc: 53.12%] [G loss: 6.272021]\n",
      "epoch:26 step:20494 [D loss: 0.184091, acc: 100.00%] [G loss: 2.930781]\n",
      "epoch:26 step:20495 [D loss: 0.205125, acc: 95.31%] [G loss: 5.830812]\n",
      "epoch:26 step:20496 [D loss: 0.574077, acc: 71.09%] [G loss: 4.120192]\n",
      "epoch:26 step:20497 [D loss: 0.120997, acc: 98.44%] [G loss: 5.023484]\n",
      "epoch:26 step:20498 [D loss: 1.235531, acc: 14.84%] [G loss: 3.826836]\n",
      "epoch:26 step:20499 [D loss: 0.645415, acc: 57.81%] [G loss: 3.338027]\n",
      "epoch:26 step:20500 [D loss: 0.286038, acc: 92.19%] [G loss: 2.878894]\n",
      "epoch:26 step:20501 [D loss: 0.939798, acc: 35.94%] [G loss: 3.948310]\n",
      "epoch:26 step:20502 [D loss: 0.559432, acc: 69.53%] [G loss: 3.224109]\n",
      "epoch:26 step:20503 [D loss: 0.216646, acc: 98.44%] [G loss: 4.700416]\n",
      "epoch:26 step:20504 [D loss: 0.072263, acc: 100.00%] [G loss: 3.179054]\n",
      "epoch:26 step:20505 [D loss: 1.016688, acc: 29.69%] [G loss: 2.193736]\n",
      "epoch:26 step:20506 [D loss: 0.516245, acc: 75.00%] [G loss: 3.833934]\n",
      "epoch:26 step:20507 [D loss: 0.212926, acc: 99.22%] [G loss: 2.741414]\n",
      "epoch:26 step:20508 [D loss: 0.705286, acc: 54.69%] [G loss: 3.404328]\n",
      "epoch:26 step:20509 [D loss: 0.427819, acc: 85.16%] [G loss: 3.555409]\n",
      "epoch:26 step:20510 [D loss: 0.734997, acc: 55.47%] [G loss: 3.550392]\n",
      "epoch:26 step:20511 [D loss: 0.105471, acc: 99.22%] [G loss: 5.509194]\n",
      "epoch:26 step:20512 [D loss: 1.009639, acc: 48.44%] [G loss: 5.868892]\n",
      "epoch:26 step:20513 [D loss: 0.838877, acc: 50.78%] [G loss: 3.079240]\n",
      "epoch:26 step:20514 [D loss: 0.355147, acc: 94.53%] [G loss: 4.879354]\n",
      "epoch:26 step:20515 [D loss: 0.813197, acc: 52.34%] [G loss: 4.291093]\n",
      "epoch:26 step:20516 [D loss: 0.800412, acc: 48.44%] [G loss: 4.337081]\n",
      "epoch:26 step:20517 [D loss: 0.238190, acc: 97.66%] [G loss: 3.376428]\n",
      "epoch:26 step:20518 [D loss: 0.164883, acc: 98.44%] [G loss: 4.935640]\n",
      "epoch:26 step:20519 [D loss: 0.475417, acc: 84.38%] [G loss: 5.345826]\n",
      "epoch:26 step:20520 [D loss: 0.309688, acc: 93.75%] [G loss: 4.760022]\n",
      "epoch:26 step:20521 [D loss: 0.176142, acc: 99.22%] [G loss: 3.788089]\n",
      "epoch:26 step:20522 [D loss: 0.746765, acc: 51.56%] [G loss: 3.752743]\n",
      "epoch:26 step:20523 [D loss: 0.561167, acc: 60.94%] [G loss: 4.241735]\n",
      "epoch:26 step:20524 [D loss: 0.239018, acc: 96.88%] [G loss: 4.127049]\n",
      "epoch:26 step:20525 [D loss: 0.414806, acc: 84.38%] [G loss: 4.168918]\n",
      "epoch:26 step:20526 [D loss: 0.467015, acc: 68.75%] [G loss: 3.018592]\n",
      "epoch:26 step:20527 [D loss: 1.280945, acc: 35.16%] [G loss: 3.143413]\n",
      "epoch:26 step:20528 [D loss: 0.356594, acc: 96.09%] [G loss: 3.030317]\n",
      "epoch:26 step:20529 [D loss: 1.445485, acc: 19.53%] [G loss: 2.975888]\n",
      "epoch:26 step:20530 [D loss: 0.242001, acc: 92.19%] [G loss: 3.525019]\n",
      "epoch:26 step:20531 [D loss: 0.211334, acc: 98.44%] [G loss: 2.424433]\n",
      "epoch:26 step:20532 [D loss: 0.274305, acc: 92.97%] [G loss: 5.070048]\n",
      "epoch:26 step:20533 [D loss: 0.538310, acc: 63.28%] [G loss: 4.014066]\n",
      "epoch:26 step:20534 [D loss: 0.081186, acc: 100.00%] [G loss: 2.660254]\n",
      "epoch:26 step:20535 [D loss: 0.323286, acc: 92.19%] [G loss: 5.099183]\n",
      "epoch:26 step:20536 [D loss: 0.335614, acc: 90.62%] [G loss: 4.144896]\n",
      "epoch:26 step:20537 [D loss: 0.138706, acc: 97.66%] [G loss: 3.754407]\n",
      "epoch:26 step:20538 [D loss: 0.436501, acc: 76.56%] [G loss: 3.706349]\n",
      "epoch:26 step:20539 [D loss: 0.443878, acc: 72.66%] [G loss: 3.040233]\n",
      "epoch:26 step:20540 [D loss: 0.504015, acc: 84.38%] [G loss: 2.993087]\n",
      "epoch:26 step:20541 [D loss: 0.541634, acc: 71.88%] [G loss: 3.363773]\n",
      "epoch:26 step:20542 [D loss: 1.085736, acc: 29.69%] [G loss: 3.374187]\n",
      "epoch:26 step:20543 [D loss: 0.550987, acc: 75.00%] [G loss: 1.953842]\n",
      "epoch:26 step:20544 [D loss: 0.437319, acc: 78.91%] [G loss: 3.266008]\n",
      "epoch:26 step:20545 [D loss: 0.518036, acc: 65.62%] [G loss: 5.006251]\n",
      "epoch:26 step:20546 [D loss: 0.270343, acc: 92.97%] [G loss: 3.946882]\n",
      "epoch:26 step:20547 [D loss: 0.335249, acc: 93.75%] [G loss: 4.212654]\n",
      "epoch:26 step:20548 [D loss: 0.144206, acc: 100.00%] [G loss: 5.408254]\n",
      "epoch:26 step:20549 [D loss: 0.750449, acc: 53.91%] [G loss: 4.077935]\n",
      "epoch:26 step:20550 [D loss: 0.473830, acc: 70.31%] [G loss: 3.985766]\n",
      "epoch:26 step:20551 [D loss: 0.348976, acc: 88.28%] [G loss: 3.025814]\n",
      "epoch:26 step:20552 [D loss: 1.027909, acc: 32.03%] [G loss: 3.762934]\n",
      "epoch:26 step:20553 [D loss: 0.794840, acc: 50.00%] [G loss: 3.674667]\n",
      "epoch:26 step:20554 [D loss: 0.359899, acc: 89.06%] [G loss: 3.609494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20555 [D loss: 0.143899, acc: 100.00%] [G loss: 2.795839]\n",
      "epoch:26 step:20556 [D loss: 0.184759, acc: 98.44%] [G loss: 3.636056]\n",
      "epoch:26 step:20557 [D loss: 0.115031, acc: 100.00%] [G loss: 6.568746]\n",
      "epoch:26 step:20558 [D loss: 0.144659, acc: 100.00%] [G loss: 4.541059]\n",
      "epoch:26 step:20559 [D loss: 0.371556, acc: 84.38%] [G loss: 3.482485]\n",
      "epoch:26 step:20560 [D loss: 0.173678, acc: 99.22%] [G loss: 4.380368]\n",
      "epoch:26 step:20561 [D loss: 0.429473, acc: 77.34%] [G loss: 3.094943]\n",
      "epoch:26 step:20562 [D loss: 0.636277, acc: 53.12%] [G loss: 3.450848]\n",
      "epoch:26 step:20563 [D loss: 0.534852, acc: 68.75%] [G loss: 4.167708]\n",
      "epoch:26 step:20564 [D loss: 0.358135, acc: 89.84%] [G loss: 4.617549]\n",
      "epoch:26 step:20565 [D loss: 0.612559, acc: 57.03%] [G loss: 3.673912]\n",
      "epoch:26 step:20566 [D loss: 0.370844, acc: 86.72%] [G loss: 4.139904]\n",
      "epoch:26 step:20567 [D loss: 0.357069, acc: 95.31%] [G loss: 2.375771]\n",
      "epoch:26 step:20568 [D loss: 0.202160, acc: 98.44%] [G loss: 4.657537]\n",
      "epoch:26 step:20569 [D loss: 0.568440, acc: 67.97%] [G loss: 2.688359]\n",
      "epoch:26 step:20570 [D loss: 0.245358, acc: 97.66%] [G loss: 5.349903]\n",
      "epoch:26 step:20571 [D loss: 0.298534, acc: 96.09%] [G loss: 4.540572]\n",
      "epoch:26 step:20572 [D loss: 0.864927, acc: 39.84%] [G loss: 4.419817]\n",
      "epoch:26 step:20573 [D loss: 0.617789, acc: 62.50%] [G loss: 4.088508]\n",
      "epoch:26 step:20574 [D loss: 0.391382, acc: 89.84%] [G loss: 2.482400]\n",
      "epoch:26 step:20575 [D loss: 0.864067, acc: 37.50%] [G loss: 2.241231]\n",
      "epoch:26 step:20576 [D loss: 0.552797, acc: 75.00%] [G loss: 4.569044]\n",
      "epoch:26 step:20577 [D loss: 0.614740, acc: 53.91%] [G loss: 5.027921]\n",
      "epoch:26 step:20578 [D loss: 0.728891, acc: 54.69%] [G loss: 4.422751]\n",
      "epoch:26 step:20579 [D loss: 0.288033, acc: 96.09%] [G loss: 3.033547]\n",
      "epoch:26 step:20580 [D loss: 0.612467, acc: 56.25%] [G loss: 5.069295]\n",
      "epoch:26 step:20581 [D loss: 0.482007, acc: 81.25%] [G loss: 2.265506]\n",
      "epoch:26 step:20582 [D loss: 0.565173, acc: 70.31%] [G loss: 3.014743]\n",
      "epoch:26 step:20583 [D loss: 0.654346, acc: 61.72%] [G loss: 4.404901]\n",
      "epoch:26 step:20584 [D loss: 0.226118, acc: 96.09%] [G loss: 4.136343]\n",
      "epoch:26 step:20585 [D loss: 0.519527, acc: 71.09%] [G loss: 4.389044]\n",
      "epoch:26 step:20586 [D loss: 0.261677, acc: 96.09%] [G loss: 3.811571]\n",
      "epoch:26 step:20587 [D loss: 0.929233, acc: 34.38%] [G loss: 3.928604]\n",
      "epoch:26 step:20588 [D loss: 0.895732, acc: 27.34%] [G loss: 3.241277]\n",
      "epoch:26 step:20589 [D loss: 0.332085, acc: 84.38%] [G loss: 3.449964]\n",
      "epoch:26 step:20590 [D loss: 0.372541, acc: 90.62%] [G loss: 4.192075]\n",
      "epoch:26 step:20591 [D loss: 0.500470, acc: 70.31%] [G loss: 4.334788]\n",
      "epoch:26 step:20592 [D loss: 0.395391, acc: 88.28%] [G loss: 4.113927]\n",
      "epoch:26 step:20593 [D loss: 0.700384, acc: 55.47%] [G loss: 3.215220]\n",
      "epoch:26 step:20594 [D loss: 0.659167, acc: 60.16%] [G loss: 3.791201]\n",
      "epoch:26 step:20595 [D loss: 0.211229, acc: 97.66%] [G loss: 3.591365]\n",
      "epoch:26 step:20596 [D loss: 0.953828, acc: 44.53%] [G loss: 1.965216]\n",
      "epoch:26 step:20597 [D loss: 0.694578, acc: 57.81%] [G loss: 4.617238]\n",
      "epoch:26 step:20598 [D loss: 0.222576, acc: 96.09%] [G loss: 3.923243]\n",
      "epoch:26 step:20599 [D loss: 0.638627, acc: 57.81%] [G loss: 3.328203]\n",
      "epoch:26 step:20600 [D loss: 0.280162, acc: 96.88%] [G loss: 2.729974]\n",
      "epoch:26 step:20601 [D loss: 0.371515, acc: 74.22%] [G loss: 3.842285]\n",
      "epoch:26 step:20602 [D loss: 0.598253, acc: 57.81%] [G loss: 3.820378]\n",
      "epoch:26 step:20603 [D loss: 0.580828, acc: 67.97%] [G loss: 3.493428]\n",
      "epoch:26 step:20604 [D loss: 0.205069, acc: 99.22%] [G loss: 4.518375]\n",
      "epoch:26 step:20605 [D loss: 0.246668, acc: 96.88%] [G loss: 3.390697]\n",
      "epoch:26 step:20606 [D loss: 0.709881, acc: 61.72%] [G loss: 3.865187]\n",
      "epoch:26 step:20607 [D loss: 0.230497, acc: 97.66%] [G loss: 3.172310]\n",
      "epoch:26 step:20608 [D loss: 0.632627, acc: 68.75%] [G loss: 3.794284]\n",
      "epoch:26 step:20609 [D loss: 0.281834, acc: 98.44%] [G loss: 2.161208]\n",
      "epoch:26 step:20610 [D loss: 0.289701, acc: 92.19%] [G loss: 4.356946]\n",
      "epoch:26 step:20611 [D loss: 0.338013, acc: 86.72%] [G loss: 4.602469]\n",
      "epoch:26 step:20612 [D loss: 0.516184, acc: 75.78%] [G loss: 3.362563]\n",
      "epoch:26 step:20613 [D loss: 0.334852, acc: 92.97%] [G loss: 3.061946]\n",
      "epoch:26 step:20614 [D loss: 0.480158, acc: 85.16%] [G loss: 3.701970]\n",
      "epoch:26 step:20615 [D loss: 1.295033, acc: 14.06%] [G loss: 4.545908]\n",
      "epoch:26 step:20616 [D loss: 0.281350, acc: 92.19%] [G loss: 3.244691]\n",
      "epoch:26 step:20617 [D loss: 0.955590, acc: 41.41%] [G loss: 2.965520]\n",
      "epoch:26 step:20618 [D loss: 0.909730, acc: 35.94%] [G loss: 3.738242]\n",
      "epoch:26 step:20619 [D loss: 0.349485, acc: 87.50%] [G loss: 5.550176]\n",
      "epoch:26 step:20620 [D loss: 0.389213, acc: 80.47%] [G loss: 4.040722]\n",
      "epoch:26 step:20621 [D loss: 0.705788, acc: 53.12%] [G loss: 3.784947]\n",
      "epoch:26 step:20622 [D loss: 0.730825, acc: 60.94%] [G loss: 4.332376]\n",
      "epoch:26 step:20623 [D loss: 0.285045, acc: 93.75%] [G loss: 3.937874]\n",
      "epoch:26 step:20624 [D loss: 0.091132, acc: 99.22%] [G loss: 5.419452]\n",
      "epoch:26 step:20625 [D loss: 0.233055, acc: 95.31%] [G loss: 4.467428]\n",
      "epoch:26 step:20626 [D loss: 0.372786, acc: 88.28%] [G loss: 2.841537]\n",
      "epoch:26 step:20627 [D loss: 0.456290, acc: 84.38%] [G loss: 4.101583]\n",
      "epoch:26 step:20628 [D loss: 0.131216, acc: 99.22%] [G loss: 4.975321]\n",
      "epoch:26 step:20629 [D loss: 0.494089, acc: 80.47%] [G loss: 3.361563]\n",
      "epoch:26 step:20630 [D loss: 0.421364, acc: 72.66%] [G loss: 4.644247]\n",
      "epoch:26 step:20631 [D loss: 0.461340, acc: 87.50%] [G loss: 2.531140]\n",
      "epoch:26 step:20632 [D loss: 0.775511, acc: 50.78%] [G loss: 3.447409]\n",
      "epoch:26 step:20633 [D loss: 0.117608, acc: 100.00%] [G loss: 4.417363]\n",
      "epoch:26 step:20634 [D loss: 0.398383, acc: 90.62%] [G loss: 5.297060]\n",
      "epoch:26 step:20635 [D loss: 0.323771, acc: 92.19%] [G loss: 4.673245]\n",
      "epoch:26 step:20636 [D loss: 0.212933, acc: 98.44%] [G loss: 3.940783]\n",
      "epoch:26 step:20637 [D loss: 0.369457, acc: 85.16%] [G loss: 3.655678]\n",
      "epoch:26 step:20638 [D loss: 0.393855, acc: 89.06%] [G loss: 4.440401]\n",
      "epoch:26 step:20639 [D loss: 0.276881, acc: 86.72%] [G loss: 5.568181]\n",
      "epoch:26 step:20640 [D loss: 0.279083, acc: 85.94%] [G loss: 4.448693]\n",
      "epoch:26 step:20641 [D loss: 0.156514, acc: 97.66%] [G loss: 5.359951]\n",
      "epoch:26 step:20642 [D loss: 0.099119, acc: 99.22%] [G loss: 4.659737]\n",
      "epoch:26 step:20643 [D loss: 0.445536, acc: 85.94%] [G loss: 3.277660]\n",
      "epoch:26 step:20644 [D loss: 0.713338, acc: 57.81%] [G loss: 3.357660]\n",
      "epoch:26 step:20645 [D loss: 1.004644, acc: 49.22%] [G loss: 3.904742]\n",
      "epoch:26 step:20646 [D loss: 0.527924, acc: 62.50%] [G loss: 5.389789]\n",
      "epoch:26 step:20647 [D loss: 0.330177, acc: 89.06%] [G loss: 3.707381]\n",
      "epoch:26 step:20648 [D loss: 0.356316, acc: 87.50%] [G loss: 4.821785]\n",
      "epoch:26 step:20649 [D loss: 0.396216, acc: 73.44%] [G loss: 5.335999]\n",
      "epoch:26 step:20650 [D loss: 0.245769, acc: 98.44%] [G loss: 3.585976]\n",
      "epoch:26 step:20651 [D loss: 0.431778, acc: 85.16%] [G loss: 3.879675]\n",
      "epoch:26 step:20652 [D loss: 0.660021, acc: 58.59%] [G loss: 3.690130]\n",
      "epoch:26 step:20653 [D loss: 0.264601, acc: 94.53%] [G loss: 4.148896]\n",
      "epoch:26 step:20654 [D loss: 0.182186, acc: 97.66%] [G loss: 4.425963]\n",
      "epoch:26 step:20655 [D loss: 0.807361, acc: 49.22%] [G loss: 4.370675]\n",
      "epoch:26 step:20656 [D loss: 0.793254, acc: 46.88%] [G loss: 4.805134]\n",
      "epoch:26 step:20657 [D loss: 0.434995, acc: 75.78%] [G loss: 3.769782]\n",
      "epoch:26 step:20658 [D loss: 0.038332, acc: 100.00%] [G loss: 4.573969]\n",
      "epoch:26 step:20659 [D loss: 0.408671, acc: 78.12%] [G loss: 4.025544]\n",
      "epoch:26 step:20660 [D loss: 0.718599, acc: 54.69%] [G loss: 3.164537]\n",
      "epoch:26 step:20661 [D loss: 0.610078, acc: 66.41%] [G loss: 3.362119]\n",
      "epoch:26 step:20662 [D loss: 0.524735, acc: 55.47%] [G loss: 4.199238]\n",
      "epoch:26 step:20663 [D loss: 0.669381, acc: 60.94%] [G loss: 4.598795]\n",
      "epoch:26 step:20664 [D loss: 0.422198, acc: 89.84%] [G loss: 3.978378]\n",
      "epoch:26 step:20665 [D loss: 0.321156, acc: 92.97%] [G loss: 2.039091]\n",
      "epoch:26 step:20666 [D loss: 1.214937, acc: 19.53%] [G loss: 3.201265]\n",
      "epoch:26 step:20667 [D loss: 0.390233, acc: 90.62%] [G loss: 4.120451]\n",
      "epoch:26 step:20668 [D loss: 0.576098, acc: 73.44%] [G loss: 4.531775]\n",
      "epoch:26 step:20669 [D loss: 0.236207, acc: 96.09%] [G loss: 4.795763]\n",
      "epoch:26 step:20670 [D loss: 0.457804, acc: 83.59%] [G loss: 4.763696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20671 [D loss: 0.472169, acc: 84.38%] [G loss: 2.842349]\n",
      "epoch:26 step:20672 [D loss: 0.285153, acc: 93.75%] [G loss: 3.794353]\n",
      "epoch:26 step:20673 [D loss: 0.522390, acc: 71.88%] [G loss: 3.435496]\n",
      "epoch:26 step:20674 [D loss: 0.567098, acc: 69.53%] [G loss: 2.645718]\n",
      "epoch:26 step:20675 [D loss: 0.500917, acc: 76.56%] [G loss: 3.720374]\n",
      "epoch:26 step:20676 [D loss: 0.089770, acc: 100.00%] [G loss: 3.017923]\n",
      "epoch:26 step:20677 [D loss: 0.598632, acc: 68.75%] [G loss: 5.200969]\n",
      "epoch:26 step:20678 [D loss: 0.429186, acc: 85.94%] [G loss: 4.982713]\n",
      "epoch:26 step:20679 [D loss: 0.529991, acc: 73.44%] [G loss: 4.190050]\n",
      "epoch:26 step:20680 [D loss: 0.097821, acc: 100.00%] [G loss: 5.391048]\n",
      "epoch:26 step:20681 [D loss: 0.183477, acc: 97.66%] [G loss: 3.048233]\n",
      "epoch:26 step:20682 [D loss: 0.074193, acc: 100.00%] [G loss: 3.259389]\n",
      "epoch:26 step:20683 [D loss: 0.567161, acc: 62.50%] [G loss: 3.723336]\n",
      "epoch:26 step:20684 [D loss: 0.258961, acc: 99.22%] [G loss: 3.620509]\n",
      "epoch:26 step:20685 [D loss: 0.216395, acc: 98.44%] [G loss: 4.204253]\n",
      "epoch:26 step:20686 [D loss: 0.213422, acc: 98.44%] [G loss: 3.015633]\n",
      "epoch:26 step:20687 [D loss: 0.469991, acc: 78.12%] [G loss: 3.885460]\n",
      "epoch:26 step:20688 [D loss: 0.827480, acc: 53.91%] [G loss: 3.731527]\n",
      "epoch:26 step:20689 [D loss: 0.236706, acc: 96.88%] [G loss: 3.689302]\n",
      "epoch:26 step:20690 [D loss: 0.164393, acc: 100.00%] [G loss: 2.978626]\n",
      "epoch:26 step:20691 [D loss: 0.628920, acc: 58.59%] [G loss: 3.330336]\n",
      "epoch:26 step:20692 [D loss: 0.319256, acc: 88.28%] [G loss: 5.701151]\n",
      "epoch:26 step:20693 [D loss: 0.201744, acc: 96.09%] [G loss: 4.196139]\n",
      "epoch:26 step:20694 [D loss: 0.521581, acc: 67.97%] [G loss: 2.449770]\n",
      "epoch:26 step:20695 [D loss: 0.372133, acc: 87.50%] [G loss: 4.559338]\n",
      "epoch:26 step:20696 [D loss: 1.639387, acc: 10.16%] [G loss: 4.235967]\n",
      "epoch:26 step:20697 [D loss: 0.240309, acc: 94.53%] [G loss: 3.100796]\n",
      "epoch:26 step:20698 [D loss: 0.733893, acc: 54.69%] [G loss: 3.380074]\n",
      "epoch:26 step:20699 [D loss: 0.322239, acc: 92.19%] [G loss: 3.159203]\n",
      "epoch:26 step:20700 [D loss: 0.450502, acc: 82.03%] [G loss: 3.771951]\n",
      "epoch:26 step:20701 [D loss: 0.236383, acc: 97.66%] [G loss: 4.295392]\n",
      "epoch:26 step:20702 [D loss: 0.532997, acc: 77.34%] [G loss: 4.185688]\n",
      "epoch:26 step:20703 [D loss: 0.892724, acc: 49.22%] [G loss: 2.942703]\n",
      "epoch:26 step:20704 [D loss: 0.301213, acc: 90.62%] [G loss: 4.975498]\n",
      "epoch:26 step:20705 [D loss: 0.431804, acc: 88.28%] [G loss: 4.070660]\n",
      "epoch:26 step:20706 [D loss: 0.607244, acc: 67.19%] [G loss: 4.764038]\n",
      "epoch:26 step:20707 [D loss: 0.264511, acc: 92.19%] [G loss: 5.357066]\n",
      "epoch:26 step:20708 [D loss: 0.286867, acc: 84.38%] [G loss: 4.781691]\n",
      "epoch:26 step:20709 [D loss: 0.342103, acc: 82.81%] [G loss: 4.786881]\n",
      "epoch:26 step:20710 [D loss: 0.229150, acc: 95.31%] [G loss: 4.725575]\n",
      "epoch:26 step:20711 [D loss: 0.842743, acc: 51.56%] [G loss: 3.130136]\n",
      "epoch:26 step:20712 [D loss: 0.347380, acc: 89.06%] [G loss: 3.077743]\n",
      "epoch:26 step:20713 [D loss: 0.561430, acc: 71.88%] [G loss: 2.544545]\n",
      "epoch:26 step:20714 [D loss: 0.404088, acc: 85.94%] [G loss: 3.691473]\n",
      "epoch:26 step:20715 [D loss: 0.518148, acc: 78.12%] [G loss: 3.228391]\n",
      "epoch:26 step:20716 [D loss: 0.476052, acc: 78.12%] [G loss: 4.700574]\n",
      "epoch:26 step:20717 [D loss: 0.577776, acc: 71.09%] [G loss: 3.936141]\n",
      "epoch:26 step:20718 [D loss: 0.023783, acc: 100.00%] [G loss: 5.564896]\n",
      "epoch:26 step:20719 [D loss: 0.377238, acc: 84.38%] [G loss: 4.486076]\n",
      "epoch:26 step:20720 [D loss: 0.206367, acc: 96.88%] [G loss: 4.875791]\n",
      "epoch:26 step:20721 [D loss: 0.826904, acc: 52.34%] [G loss: 4.688527]\n",
      "epoch:26 step:20722 [D loss: 0.523112, acc: 59.38%] [G loss: 4.322340]\n",
      "epoch:26 step:20723 [D loss: 0.702354, acc: 54.69%] [G loss: 3.803520]\n",
      "epoch:26 step:20724 [D loss: 0.649665, acc: 53.12%] [G loss: 3.509731]\n",
      "epoch:26 step:20725 [D loss: 0.522963, acc: 60.16%] [G loss: 5.788478]\n",
      "epoch:26 step:20726 [D loss: 0.439132, acc: 68.75%] [G loss: 6.619776]\n",
      "epoch:26 step:20727 [D loss: 0.625305, acc: 63.28%] [G loss: 4.363358]\n",
      "epoch:26 step:20728 [D loss: 0.151096, acc: 100.00%] [G loss: 4.869843]\n",
      "epoch:26 step:20729 [D loss: 0.173426, acc: 96.88%] [G loss: 4.420991]\n",
      "epoch:26 step:20730 [D loss: 0.277380, acc: 95.31%] [G loss: 3.064683]\n",
      "epoch:26 step:20731 [D loss: 0.258597, acc: 97.66%] [G loss: 2.917386]\n",
      "epoch:26 step:20732 [D loss: 0.333592, acc: 85.94%] [G loss: 2.607348]\n",
      "epoch:26 step:20733 [D loss: 0.868778, acc: 42.97%] [G loss: 3.440835]\n",
      "epoch:26 step:20734 [D loss: 0.500609, acc: 67.97%] [G loss: 3.993128]\n",
      "epoch:26 step:20735 [D loss: 0.157920, acc: 98.44%] [G loss: 3.751333]\n",
      "epoch:26 step:20736 [D loss: 0.183444, acc: 98.44%] [G loss: 4.872797]\n",
      "epoch:26 step:20737 [D loss: 0.656757, acc: 59.38%] [G loss: 3.254503]\n",
      "epoch:26 step:20738 [D loss: 0.248291, acc: 99.22%] [G loss: 4.418483]\n",
      "epoch:26 step:20739 [D loss: 0.432854, acc: 81.25%] [G loss: 6.376958]\n",
      "epoch:26 step:20740 [D loss: 0.297299, acc: 95.31%] [G loss: 2.943439]\n",
      "epoch:26 step:20741 [D loss: 0.347543, acc: 86.72%] [G loss: 4.255158]\n",
      "epoch:26 step:20742 [D loss: 0.655874, acc: 59.38%] [G loss: 3.963876]\n",
      "epoch:26 step:20743 [D loss: 1.328999, acc: 44.53%] [G loss: 3.721364]\n",
      "epoch:26 step:20744 [D loss: 0.867598, acc: 32.03%] [G loss: 3.955032]\n",
      "epoch:26 step:20745 [D loss: 0.620867, acc: 61.72%] [G loss: 3.775309]\n",
      "epoch:26 step:20746 [D loss: 0.769519, acc: 48.44%] [G loss: 2.694641]\n",
      "epoch:26 step:20747 [D loss: 0.370077, acc: 75.78%] [G loss: 6.217196]\n",
      "epoch:26 step:20748 [D loss: 0.347986, acc: 92.19%] [G loss: 3.868698]\n",
      "epoch:26 step:20749 [D loss: 0.241216, acc: 97.66%] [G loss: 4.656919]\n",
      "epoch:26 step:20750 [D loss: 0.816525, acc: 50.78%] [G loss: 2.920025]\n",
      "epoch:26 step:20751 [D loss: 0.741089, acc: 53.12%] [G loss: 2.041413]\n",
      "epoch:26 step:20752 [D loss: 0.284215, acc: 95.31%] [G loss: 4.011184]\n",
      "epoch:26 step:20753 [D loss: 0.681875, acc: 57.81%] [G loss: 4.755383]\n",
      "epoch:26 step:20754 [D loss: 0.207675, acc: 97.66%] [G loss: 2.879980]\n",
      "epoch:26 step:20755 [D loss: 0.155176, acc: 100.00%] [G loss: 4.042282]\n",
      "epoch:26 step:20756 [D loss: 0.291024, acc: 90.62%] [G loss: 4.532995]\n",
      "epoch:26 step:20757 [D loss: 0.297327, acc: 82.81%] [G loss: 5.737665]\n",
      "epoch:26 step:20758 [D loss: 0.384702, acc: 89.06%] [G loss: 4.013424]\n",
      "epoch:26 step:20759 [D loss: 0.521918, acc: 69.53%] [G loss: 3.914825]\n",
      "epoch:26 step:20760 [D loss: 0.483595, acc: 76.56%] [G loss: 3.003306]\n",
      "epoch:26 step:20761 [D loss: 0.360375, acc: 94.53%] [G loss: 3.846813]\n",
      "epoch:26 step:20762 [D loss: 1.227807, acc: 44.53%] [G loss: 4.428667]\n",
      "epoch:26 step:20763 [D loss: 0.447631, acc: 67.97%] [G loss: 3.603251]\n",
      "epoch:26 step:20764 [D loss: 0.158358, acc: 98.44%] [G loss: 4.138585]\n",
      "epoch:26 step:20765 [D loss: 0.734949, acc: 51.56%] [G loss: 2.676615]\n",
      "epoch:26 step:20766 [D loss: 0.756243, acc: 46.09%] [G loss: 3.294245]\n",
      "epoch:26 step:20767 [D loss: 0.223097, acc: 98.44%] [G loss: 4.156456]\n",
      "epoch:26 step:20768 [D loss: 0.225135, acc: 96.88%] [G loss: 3.587743]\n",
      "epoch:26 step:20769 [D loss: 0.547775, acc: 78.12%] [G loss: 5.024460]\n",
      "epoch:26 step:20770 [D loss: 0.665163, acc: 67.19%] [G loss: 3.336049]\n",
      "epoch:26 step:20771 [D loss: 0.349919, acc: 83.59%] [G loss: 3.975316]\n",
      "epoch:26 step:20772 [D loss: 0.322780, acc: 84.38%] [G loss: 5.127666]\n",
      "epoch:26 step:20773 [D loss: 0.304006, acc: 94.53%] [G loss: 2.886253]\n",
      "epoch:26 step:20774 [D loss: 0.825467, acc: 37.50%] [G loss: 4.169020]\n",
      "epoch:26 step:20775 [D loss: 0.789211, acc: 54.69%] [G loss: 4.722236]\n",
      "epoch:26 step:20776 [D loss: 0.126145, acc: 100.00%] [G loss: 5.055959]\n",
      "epoch:26 step:20777 [D loss: 0.303396, acc: 84.38%] [G loss: 6.171084]\n",
      "epoch:26 step:20778 [D loss: 0.650577, acc: 61.72%] [G loss: 4.892985]\n",
      "epoch:26 step:20779 [D loss: 0.715363, acc: 58.59%] [G loss: 2.243850]\n",
      "epoch:26 step:20780 [D loss: 0.491538, acc: 78.91%] [G loss: 3.661152]\n",
      "epoch:26 step:20781 [D loss: 0.362174, acc: 81.25%] [G loss: 4.352541]\n",
      "epoch:26 step:20782 [D loss: 0.378714, acc: 87.50%] [G loss: 3.313175]\n",
      "epoch:26 step:20783 [D loss: 0.257201, acc: 92.19%] [G loss: 4.541893]\n",
      "epoch:26 step:20784 [D loss: 0.257679, acc: 93.75%] [G loss: 5.048992]\n",
      "epoch:26 step:20785 [D loss: 1.397661, acc: 11.72%] [G loss: 4.620297]\n",
      "epoch:26 step:20786 [D loss: 0.154994, acc: 96.88%] [G loss: 4.174600]\n",
      "epoch:26 step:20787 [D loss: 0.742061, acc: 52.34%] [G loss: 4.562771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20788 [D loss: 0.452903, acc: 76.56%] [G loss: 4.398804]\n",
      "epoch:26 step:20789 [D loss: 0.187803, acc: 98.44%] [G loss: 3.692269]\n",
      "epoch:26 step:20790 [D loss: 0.206950, acc: 98.44%] [G loss: 4.149311]\n",
      "epoch:26 step:20791 [D loss: 0.462948, acc: 67.19%] [G loss: 3.305671]\n",
      "epoch:26 step:20792 [D loss: 0.887796, acc: 39.06%] [G loss: 2.532253]\n",
      "epoch:26 step:20793 [D loss: 0.540202, acc: 75.00%] [G loss: 4.089247]\n",
      "epoch:26 step:20794 [D loss: 0.450614, acc: 82.81%] [G loss: 4.382017]\n",
      "epoch:26 step:20795 [D loss: 0.409674, acc: 91.41%] [G loss: 3.616385]\n",
      "epoch:26 step:20796 [D loss: 0.093873, acc: 100.00%] [G loss: 5.117275]\n",
      "epoch:26 step:20797 [D loss: 0.718175, acc: 59.38%] [G loss: 3.674931]\n",
      "epoch:26 step:20798 [D loss: 0.487793, acc: 78.91%] [G loss: 3.189999]\n",
      "epoch:26 step:20799 [D loss: 0.373424, acc: 79.69%] [G loss: 3.936658]\n",
      "epoch:26 step:20800 [D loss: 0.351192, acc: 92.19%] [G loss: 4.993355]\n",
      "epoch:26 step:20801 [D loss: 0.455742, acc: 85.94%] [G loss: 3.360250]\n",
      "epoch:26 step:20802 [D loss: 0.365161, acc: 87.50%] [G loss: 2.183892]\n",
      "epoch:26 step:20803 [D loss: 0.270408, acc: 89.84%] [G loss: 5.572889]\n",
      "epoch:26 step:20804 [D loss: 0.672131, acc: 57.81%] [G loss: 3.364827]\n",
      "epoch:26 step:20805 [D loss: 0.229499, acc: 96.88%] [G loss: 3.534695]\n",
      "epoch:26 step:20806 [D loss: 0.160253, acc: 100.00%] [G loss: 4.609380]\n",
      "epoch:26 step:20807 [D loss: 0.166244, acc: 99.22%] [G loss: 4.303116]\n",
      "epoch:26 step:20808 [D loss: 0.263779, acc: 95.31%] [G loss: 3.782774]\n",
      "epoch:26 step:20809 [D loss: 1.746285, acc: 25.78%] [G loss: 2.945649]\n",
      "epoch:26 step:20810 [D loss: 0.244336, acc: 93.75%] [G loss: 3.820757]\n",
      "epoch:26 step:20811 [D loss: 0.314326, acc: 92.97%] [G loss: 3.900535]\n",
      "epoch:26 step:20812 [D loss: 0.317988, acc: 94.53%] [G loss: 4.556921]\n",
      "epoch:26 step:20813 [D loss: 0.283271, acc: 92.19%] [G loss: 3.300759]\n",
      "epoch:26 step:20814 [D loss: 0.203157, acc: 97.66%] [G loss: 3.992001]\n",
      "epoch:26 step:20815 [D loss: 0.428441, acc: 67.97%] [G loss: 3.363583]\n",
      "epoch:26 step:20816 [D loss: 0.499073, acc: 71.88%] [G loss: 3.227025]\n",
      "epoch:26 step:20817 [D loss: 0.061910, acc: 100.00%] [G loss: 7.517854]\n",
      "epoch:26 step:20818 [D loss: 0.288099, acc: 96.09%] [G loss: 3.817435]\n",
      "epoch:26 step:20819 [D loss: 1.623799, acc: 42.19%] [G loss: 3.504806]\n",
      "epoch:26 step:20820 [D loss: 0.228356, acc: 98.44%] [G loss: 4.704541]\n",
      "epoch:26 step:20821 [D loss: 1.320081, acc: 48.44%] [G loss: 2.674529]\n",
      "epoch:26 step:20822 [D loss: 0.677993, acc: 57.03%] [G loss: 4.388481]\n",
      "epoch:26 step:20823 [D loss: 0.843395, acc: 51.56%] [G loss: 4.928777]\n",
      "epoch:26 step:20824 [D loss: 0.338300, acc: 84.38%] [G loss: 3.644095]\n",
      "epoch:26 step:20825 [D loss: 0.910097, acc: 48.44%] [G loss: 4.013456]\n",
      "epoch:26 step:20826 [D loss: 1.098669, acc: 21.88%] [G loss: 4.540923]\n",
      "epoch:26 step:20827 [D loss: 0.359730, acc: 84.38%] [G loss: 3.871636]\n",
      "epoch:26 step:20828 [D loss: 1.271301, acc: 14.84%] [G loss: 2.989624]\n",
      "epoch:26 step:20829 [D loss: 0.682497, acc: 62.50%] [G loss: 3.799142]\n",
      "epoch:26 step:20830 [D loss: 0.539056, acc: 62.50%] [G loss: 3.925864]\n",
      "epoch:26 step:20831 [D loss: 0.899156, acc: 52.34%] [G loss: 3.259902]\n",
      "epoch:26 step:20832 [D loss: 0.809320, acc: 37.50%] [G loss: 2.505985]\n",
      "epoch:26 step:20833 [D loss: 0.387819, acc: 89.06%] [G loss: 3.639117]\n",
      "epoch:26 step:20834 [D loss: 0.509701, acc: 64.06%] [G loss: 3.676420]\n",
      "epoch:26 step:20835 [D loss: 0.255779, acc: 96.88%] [G loss: 3.582893]\n",
      "epoch:26 step:20836 [D loss: 0.850853, acc: 52.34%] [G loss: 2.527144]\n",
      "epoch:26 step:20837 [D loss: 0.739768, acc: 53.91%] [G loss: 5.304757]\n",
      "epoch:26 step:20838 [D loss: 0.907617, acc: 34.38%] [G loss: 3.457858]\n",
      "epoch:26 step:20839 [D loss: 0.866853, acc: 51.56%] [G loss: 5.185470]\n",
      "epoch:26 step:20840 [D loss: 0.504955, acc: 71.09%] [G loss: 2.449396]\n",
      "epoch:26 step:20841 [D loss: 0.468279, acc: 89.06%] [G loss: 4.581948]\n",
      "epoch:26 step:20842 [D loss: 0.113613, acc: 99.22%] [G loss: 5.407374]\n",
      "epoch:26 step:20843 [D loss: 0.151735, acc: 99.22%] [G loss: 3.628682]\n",
      "epoch:26 step:20844 [D loss: 0.188228, acc: 100.00%] [G loss: 4.626823]\n",
      "epoch:26 step:20845 [D loss: 0.586491, acc: 67.19%] [G loss: 3.111803]\n",
      "epoch:26 step:20846 [D loss: 0.474868, acc: 82.81%] [G loss: 4.784087]\n",
      "epoch:26 step:20847 [D loss: 0.150221, acc: 99.22%] [G loss: 4.128373]\n",
      "epoch:26 step:20848 [D loss: 0.313975, acc: 93.75%] [G loss: 3.715239]\n",
      "epoch:26 step:20849 [D loss: 0.126370, acc: 99.22%] [G loss: 3.159837]\n",
      "epoch:26 step:20850 [D loss: 0.497486, acc: 68.75%] [G loss: 4.162281]\n",
      "epoch:26 step:20851 [D loss: 0.114853, acc: 100.00%] [G loss: 2.839329]\n",
      "epoch:26 step:20852 [D loss: 0.655156, acc: 57.81%] [G loss: 3.396687]\n",
      "epoch:26 step:20853 [D loss: 0.264466, acc: 94.53%] [G loss: 3.061459]\n",
      "epoch:26 step:20854 [D loss: 0.113110, acc: 100.00%] [G loss: 4.821176]\n",
      "epoch:26 step:20855 [D loss: 0.742992, acc: 55.47%] [G loss: 3.119070]\n",
      "epoch:26 step:20856 [D loss: 0.403374, acc: 88.28%] [G loss: 4.533695]\n",
      "epoch:26 step:20857 [D loss: 0.592575, acc: 67.19%] [G loss: 5.082086]\n",
      "epoch:26 step:20858 [D loss: 0.413786, acc: 90.62%] [G loss: 3.315686]\n",
      "epoch:26 step:20859 [D loss: 0.237533, acc: 95.31%] [G loss: 4.466020]\n",
      "epoch:26 step:20860 [D loss: 0.383591, acc: 86.72%] [G loss: 3.049984]\n",
      "epoch:26 step:20861 [D loss: 0.151157, acc: 99.22%] [G loss: 4.980220]\n",
      "epoch:26 step:20862 [D loss: 0.315908, acc: 91.41%] [G loss: 4.466102]\n",
      "epoch:26 step:20863 [D loss: 0.662671, acc: 62.50%] [G loss: 3.627710]\n",
      "epoch:26 step:20864 [D loss: 0.922836, acc: 29.69%] [G loss: 4.186196]\n",
      "epoch:26 step:20865 [D loss: 0.212969, acc: 96.88%] [G loss: 2.558495]\n",
      "epoch:26 step:20866 [D loss: 0.298164, acc: 90.62%] [G loss: 4.906048]\n",
      "epoch:26 step:20867 [D loss: 0.680921, acc: 57.81%] [G loss: 2.165290]\n",
      "epoch:26 step:20868 [D loss: 0.560995, acc: 57.81%] [G loss: 5.898149]\n",
      "epoch:26 step:20869 [D loss: 0.999033, acc: 46.88%] [G loss: 3.041125]\n",
      "epoch:26 step:20870 [D loss: 0.969454, acc: 51.56%] [G loss: 4.176462]\n",
      "epoch:26 step:20871 [D loss: 0.486269, acc: 71.09%] [G loss: 4.167423]\n",
      "epoch:26 step:20872 [D loss: 0.407289, acc: 78.12%] [G loss: 4.411676]\n",
      "epoch:26 step:20873 [D loss: 0.789957, acc: 42.19%] [G loss: 4.309008]\n",
      "epoch:26 step:20874 [D loss: 0.299136, acc: 89.84%] [G loss: 4.883800]\n",
      "epoch:26 step:20875 [D loss: 0.375236, acc: 86.72%] [G loss: 4.843425]\n",
      "epoch:26 step:20876 [D loss: 0.979054, acc: 32.81%] [G loss: 3.542931]\n",
      "epoch:26 step:20877 [D loss: 0.508932, acc: 74.22%] [G loss: 3.180082]\n",
      "epoch:26 step:20878 [D loss: 0.458021, acc: 70.31%] [G loss: 5.409398]\n",
      "epoch:26 step:20879 [D loss: 0.196405, acc: 99.22%] [G loss: 3.662613]\n",
      "epoch:26 step:20880 [D loss: 1.082421, acc: 50.00%] [G loss: 5.426061]\n",
      "epoch:26 step:20881 [D loss: 1.092008, acc: 46.88%] [G loss: 3.222835]\n",
      "epoch:26 step:20882 [D loss: 0.544631, acc: 61.72%] [G loss: 4.890712]\n",
      "epoch:26 step:20883 [D loss: 0.817125, acc: 47.66%] [G loss: 4.602015]\n",
      "epoch:26 step:20884 [D loss: 0.551115, acc: 63.28%] [G loss: 5.306478]\n",
      "epoch:26 step:20885 [D loss: 0.667271, acc: 62.50%] [G loss: 3.726449]\n",
      "epoch:26 step:20886 [D loss: 0.218247, acc: 92.97%] [G loss: 5.358651]\n",
      "epoch:26 step:20887 [D loss: 0.174283, acc: 97.66%] [G loss: 4.707875]\n",
      "epoch:26 step:20888 [D loss: 0.150905, acc: 99.22%] [G loss: 3.873589]\n",
      "epoch:26 step:20889 [D loss: 0.215032, acc: 96.09%] [G loss: 3.205047]\n",
      "epoch:26 step:20890 [D loss: 0.307984, acc: 96.88%] [G loss: 2.732084]\n",
      "epoch:26 step:20891 [D loss: 0.219161, acc: 97.66%] [G loss: 1.607046]\n",
      "epoch:26 step:20892 [D loss: 0.128075, acc: 100.00%] [G loss: 4.091096]\n",
      "epoch:26 step:20893 [D loss: 0.302141, acc: 87.50%] [G loss: 3.269290]\n",
      "epoch:26 step:20894 [D loss: 0.149686, acc: 100.00%] [G loss: 4.659939]\n",
      "epoch:26 step:20895 [D loss: 0.948135, acc: 28.12%] [G loss: 3.902800]\n",
      "epoch:26 step:20896 [D loss: 0.561821, acc: 67.97%] [G loss: 3.882230]\n",
      "epoch:26 step:20897 [D loss: 0.221313, acc: 99.22%] [G loss: 2.579327]\n",
      "epoch:26 step:20898 [D loss: 0.329679, acc: 82.81%] [G loss: 4.908763]\n",
      "epoch:26 step:20899 [D loss: 0.807448, acc: 53.12%] [G loss: 2.226389]\n",
      "epoch:26 step:20900 [D loss: 0.251619, acc: 95.31%] [G loss: 3.307885]\n",
      "epoch:26 step:20901 [D loss: 0.359595, acc: 78.91%] [G loss: 4.625782]\n",
      "epoch:26 step:20902 [D loss: 0.574964, acc: 63.28%] [G loss: 3.917613]\n",
      "epoch:26 step:20903 [D loss: 0.248825, acc: 96.09%] [G loss: 4.512920]\n",
      "epoch:26 step:20904 [D loss: 0.348581, acc: 89.06%] [G loss: 3.791318]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20905 [D loss: 0.129183, acc: 100.00%] [G loss: 3.668083]\n",
      "epoch:26 step:20906 [D loss: 1.045039, acc: 42.19%] [G loss: 3.288477]\n",
      "epoch:26 step:20907 [D loss: 0.502921, acc: 79.69%] [G loss: 3.186914]\n",
      "epoch:26 step:20908 [D loss: 0.203910, acc: 96.88%] [G loss: 3.414311]\n",
      "epoch:26 step:20909 [D loss: 0.714462, acc: 56.25%] [G loss: 4.805423]\n",
      "epoch:26 step:20910 [D loss: 0.567297, acc: 64.84%] [G loss: 2.310932]\n",
      "epoch:26 step:20911 [D loss: 0.556827, acc: 67.19%] [G loss: 3.424288]\n",
      "epoch:26 step:20912 [D loss: 0.219304, acc: 99.22%] [G loss: 3.756720]\n",
      "epoch:26 step:20913 [D loss: 0.811180, acc: 48.44%] [G loss: 3.638185]\n",
      "epoch:26 step:20914 [D loss: 0.268535, acc: 98.44%] [G loss: 3.693128]\n",
      "epoch:26 step:20915 [D loss: 0.838086, acc: 50.78%] [G loss: 1.625640]\n",
      "epoch:26 step:20916 [D loss: 0.347512, acc: 80.47%] [G loss: 7.017522]\n",
      "epoch:26 step:20917 [D loss: 0.386383, acc: 87.50%] [G loss: 4.748848]\n",
      "epoch:26 step:20918 [D loss: 0.547772, acc: 73.44%] [G loss: 4.226067]\n",
      "epoch:26 step:20919 [D loss: 0.395193, acc: 89.84%] [G loss: 4.406292]\n",
      "epoch:26 step:20920 [D loss: 1.047603, acc: 50.00%] [G loss: 4.509299]\n",
      "epoch:26 step:20921 [D loss: 0.169623, acc: 97.66%] [G loss: 4.230491]\n",
      "epoch:26 step:20922 [D loss: 0.614488, acc: 64.84%] [G loss: 5.244727]\n",
      "epoch:26 step:20923 [D loss: 0.434138, acc: 78.12%] [G loss: 5.200134]\n",
      "epoch:26 step:20924 [D loss: 0.220709, acc: 95.31%] [G loss: 3.464822]\n",
      "epoch:26 step:20925 [D loss: 0.572841, acc: 61.72%] [G loss: 4.712604]\n",
      "epoch:26 step:20926 [D loss: 0.186156, acc: 99.22%] [G loss: 4.168019]\n",
      "epoch:26 step:20927 [D loss: 0.901601, acc: 49.22%] [G loss: 4.194476]\n",
      "epoch:26 step:20928 [D loss: 1.235288, acc: 10.16%] [G loss: 4.462433]\n",
      "epoch:26 step:20929 [D loss: 0.303700, acc: 93.75%] [G loss: 3.771439]\n",
      "epoch:26 step:20930 [D loss: 0.156707, acc: 98.44%] [G loss: 4.151855]\n",
      "epoch:26 step:20931 [D loss: 0.342091, acc: 89.84%] [G loss: 2.794939]\n",
      "epoch:26 step:20932 [D loss: 0.727449, acc: 51.56%] [G loss: 4.024357]\n",
      "epoch:26 step:20933 [D loss: 0.441606, acc: 82.81%] [G loss: 2.867472]\n",
      "epoch:26 step:20934 [D loss: 0.376323, acc: 83.59%] [G loss: 4.195003]\n",
      "epoch:26 step:20935 [D loss: 0.341850, acc: 92.97%] [G loss: 3.775678]\n",
      "epoch:26 step:20936 [D loss: 0.177165, acc: 99.22%] [G loss: 3.996527]\n",
      "epoch:26 step:20937 [D loss: 0.391352, acc: 79.69%] [G loss: 4.378102]\n",
      "epoch:26 step:20938 [D loss: 0.249466, acc: 96.09%] [G loss: 5.353201]\n",
      "epoch:26 step:20939 [D loss: 0.045643, acc: 100.00%] [G loss: 4.396732]\n",
      "epoch:26 step:20940 [D loss: 1.000206, acc: 26.56%] [G loss: 3.697649]\n",
      "epoch:26 step:20941 [D loss: 0.352568, acc: 93.75%] [G loss: 3.789176]\n",
      "epoch:26 step:20942 [D loss: 0.432121, acc: 82.03%] [G loss: 3.610882]\n",
      "epoch:26 step:20943 [D loss: 1.307866, acc: 50.00%] [G loss: 3.600894]\n",
      "epoch:26 step:20944 [D loss: 0.386340, acc: 89.84%] [G loss: 3.314903]\n",
      "epoch:26 step:20945 [D loss: 0.777402, acc: 50.78%] [G loss: 6.237363]\n",
      "epoch:26 step:20946 [D loss: 0.069021, acc: 100.00%] [G loss: 3.005035]\n",
      "epoch:26 step:20947 [D loss: 0.962276, acc: 30.47%] [G loss: 5.089386]\n",
      "epoch:26 step:20948 [D loss: 0.336324, acc: 88.28%] [G loss: 3.094366]\n",
      "epoch:26 step:20949 [D loss: 0.179658, acc: 100.00%] [G loss: 3.414361]\n",
      "epoch:26 step:20950 [D loss: 0.297357, acc: 95.31%] [G loss: 2.870553]\n",
      "epoch:26 step:20951 [D loss: 0.610274, acc: 67.19%] [G loss: 4.305101]\n",
      "epoch:26 step:20952 [D loss: 0.350213, acc: 92.19%] [G loss: 3.302753]\n",
      "epoch:26 step:20953 [D loss: 0.387904, acc: 89.06%] [G loss: 4.516049]\n",
      "epoch:26 step:20954 [D loss: 0.593204, acc: 68.75%] [G loss: 4.497449]\n",
      "epoch:26 step:20955 [D loss: 0.837386, acc: 32.03%] [G loss: 3.650768]\n",
      "epoch:26 step:20956 [D loss: 0.630230, acc: 59.38%] [G loss: 4.054351]\n",
      "epoch:26 step:20957 [D loss: 0.488889, acc: 79.69%] [G loss: 3.917235]\n",
      "epoch:26 step:20958 [D loss: 0.374333, acc: 82.81%] [G loss: 3.281680]\n",
      "epoch:26 step:20959 [D loss: 0.232059, acc: 96.88%] [G loss: 3.615738]\n",
      "epoch:26 step:20960 [D loss: 0.491876, acc: 75.00%] [G loss: 2.604813]\n",
      "epoch:26 step:20961 [D loss: 0.115017, acc: 99.22%] [G loss: 4.250718]\n",
      "epoch:26 step:20962 [D loss: 1.122493, acc: 25.78%] [G loss: 4.178521]\n",
      "epoch:26 step:20963 [D loss: 0.294735, acc: 91.41%] [G loss: 4.209748]\n",
      "epoch:26 step:20964 [D loss: 0.701234, acc: 57.81%] [G loss: 4.938202]\n",
      "epoch:26 step:20965 [D loss: 0.374079, acc: 92.19%] [G loss: 4.602079]\n",
      "epoch:26 step:20966 [D loss: 0.291152, acc: 89.06%] [G loss: 5.433417]\n",
      "epoch:26 step:20967 [D loss: 0.508090, acc: 82.81%] [G loss: 4.075613]\n",
      "epoch:26 step:20968 [D loss: 0.423944, acc: 85.16%] [G loss: 3.260731]\n",
      "epoch:26 step:20969 [D loss: 0.275510, acc: 96.88%] [G loss: 3.607941]\n",
      "epoch:26 step:20970 [D loss: 0.528671, acc: 71.88%] [G loss: 3.308222]\n",
      "epoch:26 step:20971 [D loss: 0.802169, acc: 53.91%] [G loss: 3.404639]\n",
      "epoch:26 step:20972 [D loss: 0.894091, acc: 48.44%] [G loss: 2.848989]\n",
      "epoch:26 step:20973 [D loss: 0.070091, acc: 99.22%] [G loss: 6.030468]\n",
      "epoch:26 step:20974 [D loss: 1.027973, acc: 39.06%] [G loss: 4.082024]\n",
      "epoch:26 step:20975 [D loss: 0.184268, acc: 96.88%] [G loss: 5.696041]\n",
      "epoch:26 step:20976 [D loss: 0.246255, acc: 97.66%] [G loss: 2.396880]\n",
      "epoch:26 step:20977 [D loss: 1.420001, acc: 7.81%] [G loss: 3.217589]\n",
      "epoch:26 step:20978 [D loss: 0.270691, acc: 93.75%] [G loss: 3.929375]\n",
      "epoch:26 step:20979 [D loss: 0.482041, acc: 81.25%] [G loss: 3.792521]\n",
      "epoch:26 step:20980 [D loss: 0.507734, acc: 67.97%] [G loss: 2.983886]\n",
      "epoch:26 step:20981 [D loss: 0.610561, acc: 62.50%] [G loss: 4.150369]\n",
      "epoch:26 step:20982 [D loss: 0.710103, acc: 53.12%] [G loss: 3.089079]\n",
      "epoch:26 step:20983 [D loss: 0.483961, acc: 78.91%] [G loss: 4.428145]\n",
      "epoch:26 step:20984 [D loss: 0.409779, acc: 79.69%] [G loss: 3.209301]\n",
      "epoch:26 step:20985 [D loss: 0.931330, acc: 39.84%] [G loss: 1.767414]\n",
      "epoch:26 step:20986 [D loss: 0.630947, acc: 61.72%] [G loss: 3.421057]\n",
      "epoch:26 step:20987 [D loss: 0.126647, acc: 100.00%] [G loss: 3.994945]\n",
      "epoch:26 step:20988 [D loss: 0.304106, acc: 92.97%] [G loss: 3.080759]\n",
      "epoch:26 step:20989 [D loss: 0.572317, acc: 64.84%] [G loss: 2.900673]\n",
      "epoch:26 step:20990 [D loss: 0.632429, acc: 60.94%] [G loss: 4.713945]\n",
      "epoch:26 step:20991 [D loss: 0.847769, acc: 40.62%] [G loss: 4.718903]\n",
      "epoch:26 step:20992 [D loss: 0.136304, acc: 100.00%] [G loss: 3.625627]\n",
      "epoch:26 step:20993 [D loss: 0.261474, acc: 92.19%] [G loss: 2.380558]\n",
      "epoch:26 step:20994 [D loss: 0.393459, acc: 78.12%] [G loss: 2.634789]\n",
      "epoch:26 step:20995 [D loss: 0.310042, acc: 87.50%] [G loss: 4.874352]\n",
      "epoch:26 step:20996 [D loss: 0.234651, acc: 98.44%] [G loss: 4.974646]\n",
      "epoch:26 step:20997 [D loss: 0.937415, acc: 39.06%] [G loss: 2.834423]\n",
      "epoch:26 step:20998 [D loss: 0.679623, acc: 60.16%] [G loss: 3.466662]\n",
      "epoch:26 step:20999 [D loss: 0.677393, acc: 53.12%] [G loss: 3.101816]\n",
      "epoch:26 step:21000 [D loss: 0.859478, acc: 42.19%] [G loss: 2.403584]\n",
      "epoch:26 step:21001 [D loss: 0.571227, acc: 71.88%] [G loss: 3.831996]\n",
      "epoch:26 step:21002 [D loss: 1.143673, acc: 14.84%] [G loss: 2.912080]\n",
      "epoch:26 step:21003 [D loss: 0.250020, acc: 97.66%] [G loss: 4.556967]\n",
      "epoch:26 step:21004 [D loss: 0.287052, acc: 94.53%] [G loss: 3.194217]\n",
      "epoch:26 step:21005 [D loss: 0.176364, acc: 99.22%] [G loss: 3.971523]\n",
      "epoch:26 step:21006 [D loss: 0.315158, acc: 84.38%] [G loss: 3.692246]\n",
      "epoch:26 step:21007 [D loss: 0.660597, acc: 53.12%] [G loss: 2.721702]\n",
      "epoch:26 step:21008 [D loss: 0.481860, acc: 71.09%] [G loss: 3.547817]\n",
      "epoch:26 step:21009 [D loss: 0.568903, acc: 61.72%] [G loss: 2.791658]\n",
      "epoch:26 step:21010 [D loss: 0.486990, acc: 75.00%] [G loss: 4.033514]\n",
      "epoch:26 step:21011 [D loss: 0.665567, acc: 55.47%] [G loss: 3.649880]\n",
      "epoch:26 step:21012 [D loss: 0.490081, acc: 72.66%] [G loss: 4.036232]\n",
      "epoch:26 step:21013 [D loss: 0.227836, acc: 94.53%] [G loss: 4.958567]\n",
      "epoch:26 step:21014 [D loss: 0.915487, acc: 48.44%] [G loss: 1.858303]\n",
      "epoch:26 step:21015 [D loss: 0.423675, acc: 75.00%] [G loss: 2.921409]\n",
      "epoch:26 step:21016 [D loss: 0.806111, acc: 50.00%] [G loss: 4.755583]\n",
      "epoch:26 step:21017 [D loss: 0.333506, acc: 84.38%] [G loss: 7.708424]\n",
      "epoch:26 step:21018 [D loss: 0.418729, acc: 81.25%] [G loss: 4.882522]\n",
      "epoch:26 step:21019 [D loss: 0.153574, acc: 99.22%] [G loss: 5.271570]\n",
      "epoch:26 step:21020 [D loss: 0.213033, acc: 96.88%] [G loss: 2.410656]\n",
      "epoch:26 step:21021 [D loss: 0.767817, acc: 50.00%] [G loss: 5.044384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:21022 [D loss: 0.291516, acc: 92.97%] [G loss: 3.674984]\n",
      "epoch:26 step:21023 [D loss: 0.165602, acc: 99.22%] [G loss: 5.938186]\n",
      "epoch:26 step:21024 [D loss: 0.164084, acc: 99.22%] [G loss: 3.450044]\n",
      "epoch:26 step:21025 [D loss: 0.164544, acc: 98.44%] [G loss: 2.481120]\n",
      "epoch:26 step:21026 [D loss: 0.261830, acc: 91.41%] [G loss: 2.972711]\n",
      "epoch:26 step:21027 [D loss: 1.246454, acc: 40.62%] [G loss: 2.822464]\n",
      "epoch:26 step:21028 [D loss: 0.175795, acc: 97.66%] [G loss: 3.863318]\n",
      "epoch:26 step:21029 [D loss: 0.084396, acc: 100.00%] [G loss: 5.406327]\n",
      "epoch:26 step:21030 [D loss: 0.516540, acc: 67.19%] [G loss: 3.110328]\n",
      "epoch:26 step:21031 [D loss: 0.367562, acc: 89.84%] [G loss: 3.820560]\n",
      "epoch:26 step:21032 [D loss: 0.291359, acc: 92.97%] [G loss: 5.161916]\n",
      "epoch:26 step:21033 [D loss: 0.411088, acc: 82.81%] [G loss: 3.874541]\n",
      "epoch:26 step:21034 [D loss: 0.234281, acc: 93.75%] [G loss: 5.716747]\n",
      "epoch:26 step:21035 [D loss: 0.306236, acc: 89.06%] [G loss: 3.267878]\n",
      "epoch:26 step:21036 [D loss: 0.949647, acc: 34.38%] [G loss: 2.955631]\n",
      "epoch:26 step:21037 [D loss: 0.189650, acc: 97.66%] [G loss: 3.482789]\n",
      "epoch:26 step:21038 [D loss: 0.368174, acc: 89.84%] [G loss: 4.559093]\n",
      "epoch:26 step:21039 [D loss: 0.255607, acc: 96.88%] [G loss: 1.954545]\n",
      "epoch:26 step:21040 [D loss: 0.275161, acc: 92.19%] [G loss: 5.090606]\n",
      "epoch:26 step:21041 [D loss: 0.430330, acc: 85.94%] [G loss: 2.800562]\n",
      "epoch:26 step:21042 [D loss: 0.330497, acc: 88.28%] [G loss: 3.680376]\n",
      "epoch:26 step:21043 [D loss: 0.413620, acc: 81.25%] [G loss: 2.751891]\n",
      "epoch:26 step:21044 [D loss: 0.203084, acc: 95.31%] [G loss: 3.989130]\n",
      "epoch:26 step:21045 [D loss: 0.292655, acc: 95.31%] [G loss: 4.378929]\n",
      "epoch:26 step:21046 [D loss: 0.109763, acc: 100.00%] [G loss: 4.631306]\n",
      "epoch:26 step:21047 [D loss: 1.800874, acc: 50.00%] [G loss: 2.817549]\n",
      "epoch:26 step:21048 [D loss: 0.597827, acc: 67.97%] [G loss: 3.598917]\n",
      "epoch:26 step:21049 [D loss: 0.223716, acc: 92.97%] [G loss: 6.331548]\n",
      "epoch:26 step:21050 [D loss: 1.251543, acc: 32.03%] [G loss: 4.553830]\n",
      "epoch:26 step:21051 [D loss: 0.565465, acc: 70.31%] [G loss: 4.158321]\n",
      "epoch:26 step:21052 [D loss: 0.154028, acc: 99.22%] [G loss: 4.620594]\n",
      "epoch:26 step:21053 [D loss: 0.612824, acc: 64.06%] [G loss: 4.276902]\n",
      "epoch:26 step:21054 [D loss: 0.158348, acc: 99.22%] [G loss: 4.542954]\n",
      "epoch:26 step:21055 [D loss: 0.595848, acc: 65.62%] [G loss: 4.626700]\n",
      "epoch:26 step:21056 [D loss: 0.682022, acc: 57.81%] [G loss: 3.566803]\n",
      "epoch:26 step:21057 [D loss: 0.586925, acc: 67.19%] [G loss: 3.441404]\n",
      "epoch:26 step:21058 [D loss: 0.289021, acc: 89.06%] [G loss: 3.704969]\n",
      "epoch:26 step:21059 [D loss: 0.243538, acc: 89.84%] [G loss: 5.997165]\n",
      "epoch:26 step:21060 [D loss: 0.534737, acc: 75.00%] [G loss: 4.288612]\n",
      "epoch:26 step:21061 [D loss: 0.215360, acc: 96.09%] [G loss: 2.981246]\n",
      "epoch:26 step:21062 [D loss: 0.536341, acc: 65.62%] [G loss: 3.926256]\n",
      "epoch:26 step:21063 [D loss: 1.020130, acc: 49.22%] [G loss: 5.239211]\n",
      "epoch:26 step:21064 [D loss: 1.188286, acc: 50.00%] [G loss: 2.244416]\n",
      "epoch:26 step:21065 [D loss: 0.286305, acc: 87.50%] [G loss: 3.904459]\n",
      "epoch:26 step:21066 [D loss: 0.138006, acc: 100.00%] [G loss: 6.883796]\n",
      "epoch:26 step:21067 [D loss: 0.389599, acc: 83.59%] [G loss: 4.097162]\n",
      "epoch:26 step:21068 [D loss: 0.108571, acc: 100.00%] [G loss: 6.827546]\n",
      "epoch:26 step:21069 [D loss: 0.608145, acc: 65.62%] [G loss: 4.061979]\n",
      "epoch:26 step:21070 [D loss: 0.366872, acc: 89.84%] [G loss: 3.838975]\n",
      "epoch:26 step:21071 [D loss: 0.280867, acc: 92.97%] [G loss: 2.857568]\n",
      "epoch:26 step:21072 [D loss: 0.383556, acc: 87.50%] [G loss: 3.989872]\n",
      "epoch:26 step:21073 [D loss: 0.057528, acc: 100.00%] [G loss: 3.583075]\n",
      "epoch:26 step:21074 [D loss: 0.307357, acc: 92.97%] [G loss: 4.642232]\n",
      "epoch:26 step:21075 [D loss: 0.352091, acc: 92.19%] [G loss: 2.728397]\n",
      "epoch:26 step:21076 [D loss: 0.718546, acc: 55.47%] [G loss: 3.458496]\n",
      "epoch:26 step:21077 [D loss: 0.575777, acc: 57.81%] [G loss: 4.032825]\n",
      "epoch:26 step:21078 [D loss: 0.281685, acc: 91.41%] [G loss: 5.493467]\n",
      "epoch:26 step:21079 [D loss: 0.112689, acc: 99.22%] [G loss: 6.237974]\n",
      "epoch:26 step:21080 [D loss: 0.285537, acc: 95.31%] [G loss: 4.692662]\n",
      "epoch:26 step:21081 [D loss: 0.628077, acc: 63.28%] [G loss: 4.433639]\n",
      "epoch:26 step:21082 [D loss: 0.208598, acc: 100.00%] [G loss: 2.755386]\n",
      "epoch:26 step:21083 [D loss: 0.494475, acc: 68.75%] [G loss: 4.292328]\n",
      "epoch:26 step:21084 [D loss: 0.855762, acc: 53.91%] [G loss: 3.791255]\n",
      "epoch:26 step:21085 [D loss: 0.232176, acc: 98.44%] [G loss: 2.204749]\n",
      "epoch:26 step:21086 [D loss: 0.336346, acc: 86.72%] [G loss: 3.383230]\n",
      "epoch:26 step:21087 [D loss: 0.451240, acc: 72.66%] [G loss: 2.213920]\n",
      "epoch:27 step:21088 [D loss: 0.321637, acc: 94.53%] [G loss: 4.213081]\n",
      "epoch:27 step:21089 [D loss: 0.407845, acc: 89.06%] [G loss: 4.328250]\n",
      "epoch:27 step:21090 [D loss: 0.534721, acc: 71.09%] [G loss: 3.864248]\n",
      "epoch:27 step:21091 [D loss: 0.456796, acc: 72.66%] [G loss: 3.071327]\n",
      "epoch:27 step:21092 [D loss: 0.111762, acc: 100.00%] [G loss: 3.643355]\n",
      "epoch:27 step:21093 [D loss: 0.405041, acc: 82.03%] [G loss: 3.081726]\n",
      "epoch:27 step:21094 [D loss: 0.316836, acc: 85.16%] [G loss: 4.254559]\n",
      "epoch:27 step:21095 [D loss: 0.823109, acc: 48.44%] [G loss: 4.018219]\n",
      "epoch:27 step:21096 [D loss: 0.225929, acc: 94.53%] [G loss: 3.672708]\n",
      "epoch:27 step:21097 [D loss: 0.579689, acc: 61.72%] [G loss: 3.599167]\n",
      "epoch:27 step:21098 [D loss: 0.342356, acc: 79.69%] [G loss: 7.342492]\n",
      "epoch:27 step:21099 [D loss: 0.178869, acc: 99.22%] [G loss: 3.853663]\n",
      "epoch:27 step:21100 [D loss: 0.312075, acc: 89.84%] [G loss: 2.845421]\n",
      "epoch:27 step:21101 [D loss: 0.672021, acc: 60.94%] [G loss: 4.180136]\n",
      "epoch:27 step:21102 [D loss: 0.663377, acc: 57.03%] [G loss: 3.184719]\n",
      "epoch:27 step:21103 [D loss: 0.511065, acc: 74.22%] [G loss: 2.662440]\n",
      "epoch:27 step:21104 [D loss: 0.894523, acc: 50.00%] [G loss: 2.876293]\n",
      "epoch:27 step:21105 [D loss: 0.194365, acc: 94.53%] [G loss: 4.902956]\n",
      "epoch:27 step:21106 [D loss: 0.608929, acc: 64.84%] [G loss: 4.654998]\n",
      "epoch:27 step:21107 [D loss: 0.978353, acc: 48.44%] [G loss: 4.873745]\n",
      "epoch:27 step:21108 [D loss: 0.027119, acc: 100.00%] [G loss: 5.553319]\n",
      "epoch:27 step:21109 [D loss: 0.323293, acc: 83.59%] [G loss: 4.293478]\n",
      "epoch:27 step:21110 [D loss: 0.509947, acc: 80.47%] [G loss: 4.866594]\n",
      "epoch:27 step:21111 [D loss: 0.462952, acc: 78.12%] [G loss: 3.017309]\n",
      "epoch:27 step:21112 [D loss: 0.310992, acc: 84.38%] [G loss: 3.433466]\n",
      "epoch:27 step:21113 [D loss: 0.594556, acc: 70.31%] [G loss: 3.715162]\n",
      "epoch:27 step:21114 [D loss: 0.109190, acc: 100.00%] [G loss: 2.622834]\n",
      "epoch:27 step:21115 [D loss: 0.220807, acc: 96.09%] [G loss: 3.595388]\n",
      "epoch:27 step:21116 [D loss: 0.105277, acc: 99.22%] [G loss: 4.000603]\n",
      "epoch:27 step:21117 [D loss: 0.134904, acc: 100.00%] [G loss: 2.727988]\n",
      "epoch:27 step:21118 [D loss: 0.313761, acc: 95.31%] [G loss: 3.076141]\n",
      "epoch:27 step:21119 [D loss: 0.142078, acc: 99.22%] [G loss: 2.168449]\n",
      "epoch:27 step:21120 [D loss: 0.092593, acc: 100.00%] [G loss: 4.031862]\n",
      "epoch:27 step:21121 [D loss: 0.143664, acc: 99.22%] [G loss: 4.808811]\n",
      "epoch:27 step:21122 [D loss: 0.715626, acc: 57.81%] [G loss: 3.037313]\n",
      "epoch:27 step:21123 [D loss: 0.461239, acc: 77.34%] [G loss: 4.071632]\n",
      "epoch:27 step:21124 [D loss: 0.601545, acc: 65.62%] [G loss: 4.032044]\n",
      "epoch:27 step:21125 [D loss: 1.103046, acc: 36.72%] [G loss: 2.586487]\n",
      "epoch:27 step:21126 [D loss: 0.648629, acc: 57.03%] [G loss: 5.437894]\n",
      "epoch:27 step:21127 [D loss: 0.824846, acc: 53.12%] [G loss: 2.864071]\n",
      "epoch:27 step:21128 [D loss: 0.249966, acc: 93.75%] [G loss: 6.039437]\n",
      "epoch:27 step:21129 [D loss: 0.235516, acc: 93.75%] [G loss: 6.919770]\n",
      "epoch:27 step:21130 [D loss: 0.947674, acc: 35.16%] [G loss: 3.282704]\n",
      "epoch:27 step:21131 [D loss: 0.410579, acc: 76.56%] [G loss: 3.591371]\n",
      "epoch:27 step:21132 [D loss: 0.395735, acc: 76.56%] [G loss: 3.582193]\n",
      "epoch:27 step:21133 [D loss: 0.156665, acc: 98.44%] [G loss: 5.955516]\n",
      "epoch:27 step:21134 [D loss: 0.662320, acc: 56.25%] [G loss: 5.125693]\n",
      "epoch:27 step:21135 [D loss: 0.248541, acc: 96.09%] [G loss: 5.092873]\n",
      "epoch:27 step:21136 [D loss: 1.403075, acc: 50.00%] [G loss: 3.547011]\n",
      "epoch:27 step:21137 [D loss: 0.254448, acc: 98.44%] [G loss: 4.347609]\n",
      "epoch:27 step:21138 [D loss: 0.526025, acc: 70.31%] [G loss: 5.732775]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21139 [D loss: 0.464444, acc: 83.59%] [G loss: 3.635800]\n",
      "epoch:27 step:21140 [D loss: 0.871811, acc: 42.97%] [G loss: 5.023127]\n",
      "epoch:27 step:21141 [D loss: 1.269930, acc: 17.97%] [G loss: 4.009121]\n",
      "epoch:27 step:21142 [D loss: 0.584048, acc: 69.53%] [G loss: 3.317928]\n",
      "epoch:27 step:21143 [D loss: 0.154093, acc: 99.22%] [G loss: 4.098563]\n",
      "epoch:27 step:21144 [D loss: 0.429064, acc: 79.69%] [G loss: 2.987916]\n",
      "epoch:27 step:21145 [D loss: 0.416102, acc: 74.22%] [G loss: 3.918546]\n",
      "epoch:27 step:21146 [D loss: 0.457390, acc: 69.53%] [G loss: 2.780204]\n",
      "epoch:27 step:21147 [D loss: 0.140580, acc: 100.00%] [G loss: 3.374563]\n",
      "epoch:27 step:21148 [D loss: 0.477044, acc: 67.97%] [G loss: 4.201346]\n",
      "epoch:27 step:21149 [D loss: 0.491101, acc: 71.88%] [G loss: 4.568272]\n",
      "epoch:27 step:21150 [D loss: 0.535637, acc: 81.25%] [G loss: 6.299090]\n",
      "epoch:27 step:21151 [D loss: 0.744329, acc: 53.12%] [G loss: 3.197363]\n",
      "epoch:27 step:21152 [D loss: 0.393333, acc: 88.28%] [G loss: 4.938685]\n",
      "epoch:27 step:21153 [D loss: 0.644258, acc: 63.28%] [G loss: 5.465489]\n",
      "epoch:27 step:21154 [D loss: 0.090917, acc: 100.00%] [G loss: 4.419954]\n",
      "epoch:27 step:21155 [D loss: 0.819291, acc: 46.88%] [G loss: 3.757560]\n",
      "epoch:27 step:21156 [D loss: 0.289571, acc: 92.97%] [G loss: 3.663311]\n",
      "epoch:27 step:21157 [D loss: 0.587087, acc: 61.72%] [G loss: 5.946843]\n",
      "epoch:27 step:21158 [D loss: 0.332953, acc: 92.19%] [G loss: 3.688967]\n",
      "epoch:27 step:21159 [D loss: 1.377875, acc: 36.72%] [G loss: 2.367917]\n",
      "epoch:27 step:21160 [D loss: 0.201350, acc: 98.44%] [G loss: 4.523551]\n",
      "epoch:27 step:21161 [D loss: 0.596142, acc: 65.62%] [G loss: 3.719274]\n",
      "epoch:27 step:21162 [D loss: 0.187166, acc: 95.31%] [G loss: 6.741639]\n",
      "epoch:27 step:21163 [D loss: 0.461623, acc: 78.91%] [G loss: 4.776780]\n",
      "epoch:27 step:21164 [D loss: 0.402347, acc: 75.00%] [G loss: 4.123269]\n",
      "epoch:27 step:21165 [D loss: 0.058550, acc: 100.00%] [G loss: 6.340015]\n",
      "epoch:27 step:21166 [D loss: 0.307479, acc: 87.50%] [G loss: 3.804678]\n",
      "epoch:27 step:21167 [D loss: 0.462533, acc: 74.22%] [G loss: 4.645878]\n",
      "epoch:27 step:21168 [D loss: 0.677121, acc: 65.62%] [G loss: 6.293925]\n",
      "epoch:27 step:21169 [D loss: 0.252275, acc: 92.97%] [G loss: 4.179738]\n",
      "epoch:27 step:21170 [D loss: 0.658392, acc: 63.28%] [G loss: 3.528151]\n",
      "epoch:27 step:21171 [D loss: 0.933148, acc: 49.22%] [G loss: 4.096783]\n",
      "epoch:27 step:21172 [D loss: 0.403596, acc: 87.50%] [G loss: 5.112229]\n",
      "epoch:27 step:21173 [D loss: 0.296757, acc: 80.47%] [G loss: 5.329175]\n",
      "epoch:27 step:21174 [D loss: 0.267689, acc: 97.66%] [G loss: 4.500220]\n",
      "epoch:27 step:21175 [D loss: 0.327334, acc: 85.16%] [G loss: 3.069192]\n",
      "epoch:27 step:21176 [D loss: 0.032224, acc: 100.00%] [G loss: 6.546885]\n",
      "epoch:27 step:21177 [D loss: 0.795666, acc: 51.56%] [G loss: 4.635219]\n",
      "epoch:27 step:21178 [D loss: 0.406463, acc: 81.25%] [G loss: 6.212012]\n",
      "epoch:27 step:21179 [D loss: 0.704016, acc: 55.47%] [G loss: 5.356559]\n",
      "epoch:27 step:21180 [D loss: 0.469431, acc: 71.09%] [G loss: 4.969722]\n",
      "epoch:27 step:21181 [D loss: 0.294076, acc: 94.53%] [G loss: 4.364254]\n",
      "epoch:27 step:21182 [D loss: 0.435520, acc: 81.25%] [G loss: 5.784484]\n",
      "epoch:27 step:21183 [D loss: 0.539042, acc: 67.97%] [G loss: 4.695987]\n",
      "epoch:27 step:21184 [D loss: 0.505064, acc: 75.00%] [G loss: 4.311743]\n",
      "epoch:27 step:21185 [D loss: 0.489281, acc: 78.91%] [G loss: 3.066606]\n",
      "epoch:27 step:21186 [D loss: 0.761478, acc: 53.12%] [G loss: 3.824236]\n",
      "epoch:27 step:21187 [D loss: 1.031243, acc: 50.78%] [G loss: 4.199528]\n",
      "epoch:27 step:21188 [D loss: 0.334994, acc: 91.41%] [G loss: 4.999912]\n",
      "epoch:27 step:21189 [D loss: 0.628590, acc: 63.28%] [G loss: 4.130436]\n",
      "epoch:27 step:21190 [D loss: 0.989049, acc: 31.25%] [G loss: 3.695795]\n",
      "epoch:27 step:21191 [D loss: 0.947484, acc: 50.00%] [G loss: 5.152030]\n",
      "epoch:27 step:21192 [D loss: 0.717656, acc: 53.91%] [G loss: 4.389924]\n",
      "epoch:27 step:21193 [D loss: 0.207601, acc: 99.22%] [G loss: 2.708973]\n",
      "epoch:27 step:21194 [D loss: 0.152756, acc: 99.22%] [G loss: 4.161100]\n",
      "epoch:27 step:21195 [D loss: 0.540921, acc: 78.12%] [G loss: 5.204006]\n",
      "epoch:27 step:21196 [D loss: 0.208468, acc: 95.31%] [G loss: 3.448972]\n",
      "epoch:27 step:21197 [D loss: 1.227086, acc: 14.84%] [G loss: 4.363333]\n",
      "epoch:27 step:21198 [D loss: 1.361786, acc: 28.12%] [G loss: 5.507894]\n",
      "epoch:27 step:21199 [D loss: 0.089401, acc: 100.00%] [G loss: 3.798843]\n",
      "epoch:27 step:21200 [D loss: 0.275714, acc: 96.09%] [G loss: 3.785906]\n",
      "epoch:27 step:21201 [D loss: 0.394067, acc: 87.50%] [G loss: 5.390699]\n",
      "epoch:27 step:21202 [D loss: 0.487217, acc: 78.91%] [G loss: 4.865122]\n",
      "epoch:27 step:21203 [D loss: 0.531799, acc: 76.56%] [G loss: 4.291503]\n",
      "epoch:27 step:21204 [D loss: 0.289654, acc: 96.09%] [G loss: 3.754663]\n",
      "epoch:27 step:21205 [D loss: 0.565025, acc: 71.09%] [G loss: 2.403726]\n",
      "epoch:27 step:21206 [D loss: 0.078565, acc: 100.00%] [G loss: 4.850498]\n",
      "epoch:27 step:21207 [D loss: 0.676669, acc: 60.16%] [G loss: 3.857631]\n",
      "epoch:27 step:21208 [D loss: 0.219949, acc: 96.88%] [G loss: 3.406221]\n",
      "epoch:27 step:21209 [D loss: 0.647282, acc: 57.03%] [G loss: 4.891160]\n",
      "epoch:27 step:21210 [D loss: 0.170284, acc: 98.44%] [G loss: 2.912601]\n",
      "epoch:27 step:21211 [D loss: 0.462256, acc: 75.00%] [G loss: 5.941226]\n",
      "epoch:27 step:21212 [D loss: 0.606749, acc: 61.72%] [G loss: 3.351518]\n",
      "epoch:27 step:21213 [D loss: 0.573677, acc: 67.19%] [G loss: 5.506058]\n",
      "epoch:27 step:21214 [D loss: 0.733077, acc: 54.69%] [G loss: 4.882910]\n",
      "epoch:27 step:21215 [D loss: 0.133857, acc: 100.00%] [G loss: 6.253269]\n",
      "epoch:27 step:21216 [D loss: 0.879872, acc: 39.84%] [G loss: 5.121076]\n",
      "epoch:27 step:21217 [D loss: 0.574008, acc: 63.28%] [G loss: 3.755437]\n",
      "epoch:27 step:21218 [D loss: 0.117582, acc: 99.22%] [G loss: 4.069380]\n",
      "epoch:27 step:21219 [D loss: 0.559436, acc: 72.66%] [G loss: 3.337829]\n",
      "epoch:27 step:21220 [D loss: 0.430773, acc: 87.50%] [G loss: 2.638561]\n",
      "epoch:27 step:21221 [D loss: 0.460555, acc: 86.72%] [G loss: 3.217891]\n",
      "epoch:27 step:21222 [D loss: 0.234024, acc: 93.75%] [G loss: 5.597443]\n",
      "epoch:27 step:21223 [D loss: 0.841776, acc: 52.34%] [G loss: 6.033583]\n",
      "epoch:27 step:21224 [D loss: 0.162522, acc: 99.22%] [G loss: 3.991643]\n",
      "epoch:27 step:21225 [D loss: 1.413627, acc: 9.38%] [G loss: 3.694132]\n",
      "epoch:27 step:21226 [D loss: 0.245233, acc: 94.53%] [G loss: 2.808636]\n",
      "epoch:27 step:21227 [D loss: 0.674692, acc: 59.38%] [G loss: 3.850892]\n",
      "epoch:27 step:21228 [D loss: 0.481766, acc: 79.69%] [G loss: 1.719957]\n",
      "epoch:27 step:21229 [D loss: 0.202945, acc: 97.66%] [G loss: 4.690553]\n",
      "epoch:27 step:21230 [D loss: 0.678784, acc: 60.16%] [G loss: 2.753084]\n",
      "epoch:27 step:21231 [D loss: 0.327769, acc: 91.41%] [G loss: 3.546459]\n",
      "epoch:27 step:21232 [D loss: 0.318671, acc: 93.75%] [G loss: 3.377068]\n",
      "epoch:27 step:21233 [D loss: 0.852542, acc: 46.88%] [G loss: 4.650771]\n",
      "epoch:27 step:21234 [D loss: 0.495842, acc: 73.44%] [G loss: 3.947958]\n",
      "epoch:27 step:21235 [D loss: 0.405709, acc: 89.06%] [G loss: 2.947006]\n",
      "epoch:27 step:21236 [D loss: 1.026248, acc: 50.78%] [G loss: 3.100718]\n",
      "epoch:27 step:21237 [D loss: 0.477174, acc: 74.22%] [G loss: 2.443841]\n",
      "epoch:27 step:21238 [D loss: 0.513875, acc: 71.09%] [G loss: 3.839268]\n",
      "epoch:27 step:21239 [D loss: 1.095672, acc: 28.91%] [G loss: 2.623949]\n",
      "epoch:27 step:21240 [D loss: 0.469969, acc: 80.47%] [G loss: 3.201610]\n",
      "epoch:27 step:21241 [D loss: 0.229916, acc: 95.31%] [G loss: 2.758153]\n",
      "epoch:27 step:21242 [D loss: 0.350278, acc: 91.41%] [G loss: 2.987478]\n",
      "epoch:27 step:21243 [D loss: 0.494091, acc: 74.22%] [G loss: 6.025609]\n",
      "epoch:27 step:21244 [D loss: 0.753681, acc: 56.25%] [G loss: 5.128870]\n",
      "epoch:27 step:21245 [D loss: 0.673523, acc: 58.59%] [G loss: 2.869297]\n",
      "epoch:27 step:21246 [D loss: 0.458032, acc: 78.12%] [G loss: 3.923512]\n",
      "epoch:27 step:21247 [D loss: 0.671893, acc: 56.25%] [G loss: 3.913256]\n",
      "epoch:27 step:21248 [D loss: 0.388061, acc: 88.28%] [G loss: 4.187858]\n",
      "epoch:27 step:21249 [D loss: 0.137112, acc: 100.00%] [G loss: 3.192464]\n",
      "epoch:27 step:21250 [D loss: 0.324095, acc: 94.53%] [G loss: 4.809348]\n",
      "epoch:27 step:21251 [D loss: 0.273138, acc: 92.97%] [G loss: 5.576602]\n",
      "epoch:27 step:21252 [D loss: 0.382452, acc: 76.56%] [G loss: 4.154825]\n",
      "epoch:27 step:21253 [D loss: 0.425660, acc: 79.69%] [G loss: 4.368214]\n",
      "epoch:27 step:21254 [D loss: 0.853303, acc: 50.78%] [G loss: 2.592452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21255 [D loss: 0.209575, acc: 95.31%] [G loss: 4.800979]\n",
      "epoch:27 step:21256 [D loss: 0.524260, acc: 78.91%] [G loss: 6.401967]\n",
      "epoch:27 step:21257 [D loss: 0.222690, acc: 95.31%] [G loss: 2.229203]\n",
      "epoch:27 step:21258 [D loss: 0.416214, acc: 86.72%] [G loss: 4.122879]\n",
      "epoch:27 step:21259 [D loss: 0.592571, acc: 67.19%] [G loss: 4.354525]\n",
      "epoch:27 step:21260 [D loss: 0.376806, acc: 89.06%] [G loss: 3.238620]\n",
      "epoch:27 step:21261 [D loss: 0.255962, acc: 95.31%] [G loss: 6.511142]\n",
      "epoch:27 step:21262 [D loss: 0.132594, acc: 100.00%] [G loss: 4.141110]\n",
      "epoch:27 step:21263 [D loss: 0.719095, acc: 54.69%] [G loss: 2.863396]\n",
      "epoch:27 step:21264 [D loss: 0.323016, acc: 92.97%] [G loss: 4.892592]\n",
      "epoch:27 step:21265 [D loss: 0.482964, acc: 77.34%] [G loss: 4.019024]\n",
      "epoch:27 step:21266 [D loss: 0.209631, acc: 96.88%] [G loss: 3.539237]\n",
      "epoch:27 step:21267 [D loss: 0.890912, acc: 37.50%] [G loss: 4.575177]\n",
      "epoch:27 step:21268 [D loss: 0.445100, acc: 84.38%] [G loss: 2.650764]\n",
      "epoch:27 step:21269 [D loss: 0.192746, acc: 96.88%] [G loss: 4.863344]\n",
      "epoch:27 step:21270 [D loss: 1.170972, acc: 24.22%] [G loss: 5.385680]\n",
      "epoch:27 step:21271 [D loss: 0.243400, acc: 96.88%] [G loss: 4.418768]\n",
      "epoch:27 step:21272 [D loss: 0.324344, acc: 94.53%] [G loss: 4.380319]\n",
      "epoch:27 step:21273 [D loss: 0.687475, acc: 54.69%] [G loss: 4.669025]\n",
      "epoch:27 step:21274 [D loss: 0.116680, acc: 100.00%] [G loss: 5.354355]\n",
      "epoch:27 step:21275 [D loss: 0.749038, acc: 54.69%] [G loss: 5.340162]\n",
      "epoch:27 step:21276 [D loss: 0.036285, acc: 100.00%] [G loss: 5.940749]\n",
      "epoch:27 step:21277 [D loss: 0.779379, acc: 50.00%] [G loss: 4.542695]\n",
      "epoch:27 step:21278 [D loss: 0.241636, acc: 93.75%] [G loss: 3.434341]\n",
      "epoch:27 step:21279 [D loss: 0.362966, acc: 90.62%] [G loss: 4.543800]\n",
      "epoch:27 step:21280 [D loss: 0.548030, acc: 74.22%] [G loss: 3.674657]\n",
      "epoch:27 step:21281 [D loss: 0.112304, acc: 100.00%] [G loss: 3.599249]\n",
      "epoch:27 step:21282 [D loss: 0.534685, acc: 70.31%] [G loss: 5.022290]\n",
      "epoch:27 step:21283 [D loss: 0.562797, acc: 74.22%] [G loss: 2.616887]\n",
      "epoch:27 step:21284 [D loss: 0.145074, acc: 99.22%] [G loss: 3.302291]\n",
      "epoch:27 step:21285 [D loss: 0.371648, acc: 86.72%] [G loss: 3.171820]\n",
      "epoch:27 step:21286 [D loss: 0.060331, acc: 100.00%] [G loss: 4.126152]\n",
      "epoch:27 step:21287 [D loss: 0.368421, acc: 92.19%] [G loss: 4.906769]\n",
      "epoch:27 step:21288 [D loss: 0.271954, acc: 96.88%] [G loss: 2.300288]\n",
      "epoch:27 step:21289 [D loss: 1.576104, acc: 32.81%] [G loss: 4.878177]\n",
      "epoch:27 step:21290 [D loss: 0.986250, acc: 28.12%] [G loss: 3.178573]\n",
      "epoch:27 step:21291 [D loss: 0.403861, acc: 85.16%] [G loss: 4.092290]\n",
      "epoch:27 step:21292 [D loss: 0.424596, acc: 85.16%] [G loss: 3.900983]\n",
      "epoch:27 step:21293 [D loss: 0.418152, acc: 90.62%] [G loss: 2.518785]\n",
      "epoch:27 step:21294 [D loss: 0.832152, acc: 47.66%] [G loss: 3.934789]\n",
      "epoch:27 step:21295 [D loss: 0.395401, acc: 75.00%] [G loss: 4.150508]\n",
      "epoch:27 step:21296 [D loss: 0.479556, acc: 82.03%] [G loss: 3.778001]\n",
      "epoch:27 step:21297 [D loss: 0.638762, acc: 67.97%] [G loss: 6.648706]\n",
      "epoch:27 step:21298 [D loss: 0.753914, acc: 53.12%] [G loss: 5.400226]\n",
      "epoch:27 step:21299 [D loss: 0.416355, acc: 77.34%] [G loss: 4.030453]\n",
      "epoch:27 step:21300 [D loss: 0.370093, acc: 76.56%] [G loss: 3.927190]\n",
      "epoch:27 step:21301 [D loss: 0.451114, acc: 78.12%] [G loss: 4.927819]\n",
      "epoch:27 step:21302 [D loss: 0.097016, acc: 99.22%] [G loss: 4.572245]\n",
      "epoch:27 step:21303 [D loss: 0.604495, acc: 55.47%] [G loss: 4.586668]\n",
      "epoch:27 step:21304 [D loss: 1.061405, acc: 42.97%] [G loss: 4.949601]\n",
      "epoch:27 step:21305 [D loss: 0.116614, acc: 100.00%] [G loss: 5.128820]\n",
      "epoch:27 step:21306 [D loss: 0.310794, acc: 95.31%] [G loss: 3.914786]\n",
      "epoch:27 step:21307 [D loss: 0.474179, acc: 81.25%] [G loss: 3.824339]\n",
      "epoch:27 step:21308 [D loss: 0.469215, acc: 72.66%] [G loss: 3.719517]\n",
      "epoch:27 step:21309 [D loss: 1.011047, acc: 47.66%] [G loss: 3.396348]\n",
      "epoch:27 step:21310 [D loss: 0.248297, acc: 95.31%] [G loss: 3.482745]\n",
      "epoch:27 step:21311 [D loss: 0.477457, acc: 82.81%] [G loss: 4.398019]\n",
      "epoch:27 step:21312 [D loss: 0.194597, acc: 99.22%] [G loss: 3.522938]\n",
      "epoch:27 step:21313 [D loss: 0.433478, acc: 79.69%] [G loss: 3.304989]\n",
      "epoch:27 step:21314 [D loss: 0.273631, acc: 86.72%] [G loss: 5.140669]\n",
      "epoch:27 step:21315 [D loss: 0.282547, acc: 99.22%] [G loss: 2.689590]\n",
      "epoch:27 step:21316 [D loss: 0.120475, acc: 100.00%] [G loss: 4.583114]\n",
      "epoch:27 step:21317 [D loss: 0.898574, acc: 50.78%] [G loss: 4.640987]\n",
      "epoch:27 step:21318 [D loss: 0.560008, acc: 71.88%] [G loss: 4.511157]\n",
      "epoch:27 step:21319 [D loss: 0.425304, acc: 85.16%] [G loss: 5.307710]\n",
      "epoch:27 step:21320 [D loss: 0.112833, acc: 100.00%] [G loss: 4.099205]\n",
      "epoch:27 step:21321 [D loss: 0.308841, acc: 92.97%] [G loss: 3.901784]\n",
      "epoch:27 step:21322 [D loss: 0.373867, acc: 89.06%] [G loss: 4.445672]\n",
      "epoch:27 step:21323 [D loss: 0.545414, acc: 69.53%] [G loss: 2.146165]\n",
      "epoch:27 step:21324 [D loss: 1.252601, acc: 48.44%] [G loss: 3.794845]\n",
      "epoch:27 step:21325 [D loss: 0.558982, acc: 71.88%] [G loss: 4.593514]\n",
      "epoch:27 step:21326 [D loss: 0.491144, acc: 67.97%] [G loss: 6.159401]\n",
      "epoch:27 step:21327 [D loss: 0.508267, acc: 78.12%] [G loss: 4.481730]\n",
      "epoch:27 step:21328 [D loss: 0.306681, acc: 90.62%] [G loss: 3.421291]\n",
      "epoch:27 step:21329 [D loss: 0.411072, acc: 73.44%] [G loss: 4.563867]\n",
      "epoch:27 step:21330 [D loss: 0.286559, acc: 95.31%] [G loss: 3.085656]\n",
      "epoch:27 step:21331 [D loss: 0.804788, acc: 42.97%] [G loss: 4.807750]\n",
      "epoch:27 step:21332 [D loss: 1.434225, acc: 35.16%] [G loss: 2.911936]\n",
      "epoch:27 step:21333 [D loss: 1.535006, acc: 21.88%] [G loss: 5.299992]\n",
      "epoch:27 step:21334 [D loss: 0.699429, acc: 57.03%] [G loss: 3.210261]\n",
      "epoch:27 step:21335 [D loss: 0.441722, acc: 78.91%] [G loss: 3.264541]\n",
      "epoch:27 step:21336 [D loss: 0.409650, acc: 75.00%] [G loss: 4.486966]\n",
      "epoch:27 step:21337 [D loss: 0.630200, acc: 67.19%] [G loss: 3.776868]\n",
      "epoch:27 step:21338 [D loss: 0.281748, acc: 95.31%] [G loss: 3.340489]\n",
      "epoch:27 step:21339 [D loss: 0.311659, acc: 92.19%] [G loss: 3.623920]\n",
      "epoch:27 step:21340 [D loss: 0.501484, acc: 76.56%] [G loss: 3.783131]\n",
      "epoch:27 step:21341 [D loss: 0.181711, acc: 96.09%] [G loss: 2.698204]\n",
      "epoch:27 step:21342 [D loss: 0.389281, acc: 78.91%] [G loss: 2.551870]\n",
      "epoch:27 step:21343 [D loss: 0.361467, acc: 87.50%] [G loss: 2.186809]\n",
      "epoch:27 step:21344 [D loss: 0.590892, acc: 64.84%] [G loss: 4.326636]\n",
      "epoch:27 step:21345 [D loss: 0.162631, acc: 98.44%] [G loss: 4.928372]\n",
      "epoch:27 step:21346 [D loss: 0.874273, acc: 51.56%] [G loss: 2.398722]\n",
      "epoch:27 step:21347 [D loss: 0.126963, acc: 100.00%] [G loss: 3.474064]\n",
      "epoch:27 step:21348 [D loss: 0.757844, acc: 46.88%] [G loss: 3.711165]\n",
      "epoch:27 step:21349 [D loss: 0.149212, acc: 99.22%] [G loss: 5.089447]\n",
      "epoch:27 step:21350 [D loss: 1.074065, acc: 26.56%] [G loss: 4.254652]\n",
      "epoch:27 step:21351 [D loss: 0.411164, acc: 87.50%] [G loss: 2.468833]\n",
      "epoch:27 step:21352 [D loss: 0.676334, acc: 60.16%] [G loss: 3.804727]\n",
      "epoch:27 step:21353 [D loss: 0.564180, acc: 70.31%] [G loss: 2.312561]\n",
      "epoch:27 step:21354 [D loss: 1.266355, acc: 23.44%] [G loss: 3.502410]\n",
      "epoch:27 step:21355 [D loss: 1.104689, acc: 23.44%] [G loss: 3.021302]\n",
      "epoch:27 step:21356 [D loss: 0.925149, acc: 44.53%] [G loss: 5.321954]\n",
      "epoch:27 step:21357 [D loss: 0.343550, acc: 89.84%] [G loss: 4.117392]\n",
      "epoch:27 step:21358 [D loss: 0.430560, acc: 82.03%] [G loss: 3.818553]\n",
      "epoch:27 step:21359 [D loss: 0.116026, acc: 100.00%] [G loss: 3.474032]\n",
      "epoch:27 step:21360 [D loss: 0.799856, acc: 50.00%] [G loss: 2.587883]\n",
      "epoch:27 step:21361 [D loss: 0.664652, acc: 60.16%] [G loss: 4.636053]\n",
      "epoch:27 step:21362 [D loss: 0.467041, acc: 75.00%] [G loss: 3.824380]\n",
      "epoch:27 step:21363 [D loss: 0.282194, acc: 92.97%] [G loss: 3.276163]\n",
      "epoch:27 step:21364 [D loss: 0.280048, acc: 92.97%] [G loss: 4.199344]\n",
      "epoch:27 step:21365 [D loss: 0.685215, acc: 57.03%] [G loss: 4.263164]\n",
      "epoch:27 step:21366 [D loss: 0.182872, acc: 99.22%] [G loss: 3.004326]\n",
      "epoch:27 step:21367 [D loss: 0.418129, acc: 82.81%] [G loss: 3.641223]\n",
      "epoch:27 step:21368 [D loss: 1.476856, acc: 27.34%] [G loss: 5.154387]\n",
      "epoch:27 step:21369 [D loss: 0.698624, acc: 55.47%] [G loss: 3.881466]\n",
      "epoch:27 step:21370 [D loss: 0.926628, acc: 43.75%] [G loss: 4.461140]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21371 [D loss: 0.470601, acc: 81.25%] [G loss: 5.342872]\n",
      "epoch:27 step:21372 [D loss: 0.160865, acc: 100.00%] [G loss: 3.577810]\n",
      "epoch:27 step:21373 [D loss: 0.449672, acc: 86.72%] [G loss: 4.478012]\n",
      "epoch:27 step:21374 [D loss: 0.678901, acc: 62.50%] [G loss: 3.725583]\n",
      "epoch:27 step:21375 [D loss: 0.649754, acc: 58.59%] [G loss: 3.075902]\n",
      "epoch:27 step:21376 [D loss: 0.283841, acc: 96.09%] [G loss: 2.968562]\n",
      "epoch:27 step:21377 [D loss: 0.228872, acc: 93.75%] [G loss: 2.348166]\n",
      "epoch:27 step:21378 [D loss: 0.186170, acc: 100.00%] [G loss: 3.348199]\n",
      "epoch:27 step:21379 [D loss: 0.247157, acc: 96.88%] [G loss: 2.788040]\n",
      "epoch:27 step:21380 [D loss: 0.330542, acc: 95.31%] [G loss: 3.004153]\n",
      "epoch:27 step:21381 [D loss: 0.209177, acc: 97.66%] [G loss: 3.805749]\n",
      "epoch:27 step:21382 [D loss: 0.468275, acc: 77.34%] [G loss: 2.053367]\n",
      "epoch:27 step:21383 [D loss: 0.380327, acc: 76.56%] [G loss: 4.586903]\n",
      "epoch:27 step:21384 [D loss: 0.149456, acc: 96.09%] [G loss: 4.528014]\n",
      "epoch:27 step:21385 [D loss: 0.334812, acc: 92.97%] [G loss: 3.802811]\n",
      "epoch:27 step:21386 [D loss: 0.659948, acc: 57.81%] [G loss: 4.676464]\n",
      "epoch:27 step:21387 [D loss: 0.707211, acc: 59.38%] [G loss: 2.359055]\n",
      "epoch:27 step:21388 [D loss: 0.538707, acc: 74.22%] [G loss: 3.156103]\n",
      "epoch:27 step:21389 [D loss: 0.485777, acc: 85.16%] [G loss: 3.431154]\n",
      "epoch:27 step:21390 [D loss: 0.436816, acc: 79.69%] [G loss: 6.032783]\n",
      "epoch:27 step:21391 [D loss: 1.029165, acc: 28.12%] [G loss: 2.860613]\n",
      "epoch:27 step:21392 [D loss: 0.089358, acc: 100.00%] [G loss: 6.823559]\n",
      "epoch:27 step:21393 [D loss: 0.249226, acc: 94.53%] [G loss: 3.793715]\n",
      "epoch:27 step:21394 [D loss: 0.508486, acc: 72.66%] [G loss: 3.423038]\n",
      "epoch:27 step:21395 [D loss: 0.462471, acc: 67.19%] [G loss: 4.007563]\n",
      "epoch:27 step:21396 [D loss: 0.828131, acc: 56.25%] [G loss: 2.524470]\n",
      "epoch:27 step:21397 [D loss: 0.680661, acc: 55.47%] [G loss: 4.837974]\n",
      "epoch:27 step:21398 [D loss: 0.569578, acc: 60.94%] [G loss: 5.135947]\n",
      "epoch:27 step:21399 [D loss: 0.733789, acc: 49.22%] [G loss: 2.472811]\n",
      "epoch:27 step:21400 [D loss: 0.394559, acc: 85.94%] [G loss: 3.991868]\n",
      "epoch:27 step:21401 [D loss: 0.166417, acc: 100.00%] [G loss: 4.100226]\n",
      "epoch:27 step:21402 [D loss: 0.444703, acc: 85.16%] [G loss: 6.059565]\n",
      "epoch:27 step:21403 [D loss: 0.463219, acc: 84.38%] [G loss: 3.727892]\n",
      "epoch:27 step:21404 [D loss: 0.496618, acc: 67.97%] [G loss: 5.702670]\n",
      "epoch:27 step:21405 [D loss: 0.210533, acc: 99.22%] [G loss: 5.209140]\n",
      "epoch:27 step:21406 [D loss: 0.406031, acc: 85.16%] [G loss: 3.140764]\n",
      "epoch:27 step:21407 [D loss: 0.796958, acc: 45.31%] [G loss: 3.574643]\n",
      "epoch:27 step:21408 [D loss: 0.456268, acc: 85.16%] [G loss: 2.394922]\n",
      "epoch:27 step:21409 [D loss: 0.209155, acc: 100.00%] [G loss: 4.385642]\n",
      "epoch:27 step:21410 [D loss: 0.666089, acc: 55.47%] [G loss: 3.773037]\n",
      "epoch:27 step:21411 [D loss: 0.313253, acc: 93.75%] [G loss: 3.417491]\n",
      "epoch:27 step:21412 [D loss: 0.192778, acc: 98.44%] [G loss: 4.735565]\n",
      "epoch:27 step:21413 [D loss: 0.216842, acc: 97.66%] [G loss: 3.952232]\n",
      "epoch:27 step:21414 [D loss: 0.258204, acc: 96.88%] [G loss: 4.172191]\n",
      "epoch:27 step:21415 [D loss: 0.702319, acc: 60.16%] [G loss: 3.842811]\n",
      "epoch:27 step:21416 [D loss: 0.402455, acc: 79.69%] [G loss: 5.451224]\n",
      "epoch:27 step:21417 [D loss: 0.415244, acc: 88.28%] [G loss: 4.533906]\n",
      "epoch:27 step:21418 [D loss: 0.218518, acc: 99.22%] [G loss: 2.289720]\n",
      "epoch:27 step:21419 [D loss: 1.157379, acc: 25.00%] [G loss: 3.806894]\n",
      "epoch:27 step:21420 [D loss: 0.068270, acc: 100.00%] [G loss: 4.550812]\n",
      "epoch:27 step:21421 [D loss: 0.265612, acc: 96.09%] [G loss: 5.255614]\n",
      "epoch:27 step:21422 [D loss: 0.232778, acc: 96.09%] [G loss: 4.755690]\n",
      "epoch:27 step:21423 [D loss: 0.170738, acc: 99.22%] [G loss: 3.821017]\n",
      "epoch:27 step:21424 [D loss: 0.368470, acc: 79.69%] [G loss: 2.918530]\n",
      "epoch:27 step:21425 [D loss: 0.469295, acc: 72.66%] [G loss: 3.776827]\n",
      "epoch:27 step:21426 [D loss: 0.099672, acc: 100.00%] [G loss: 5.700399]\n",
      "epoch:27 step:21427 [D loss: 0.555270, acc: 60.16%] [G loss: 3.270414]\n",
      "epoch:27 step:21428 [D loss: 0.321906, acc: 91.41%] [G loss: 3.449665]\n",
      "epoch:27 step:21429 [D loss: 0.534209, acc: 68.75%] [G loss: 4.913034]\n",
      "epoch:27 step:21430 [D loss: 0.372910, acc: 89.84%] [G loss: 4.731045]\n",
      "epoch:27 step:21431 [D loss: 0.412041, acc: 87.50%] [G loss: 2.925504]\n",
      "epoch:27 step:21432 [D loss: 0.423906, acc: 77.34%] [G loss: 3.436244]\n",
      "epoch:27 step:21433 [D loss: 0.827001, acc: 48.44%] [G loss: 3.249984]\n",
      "epoch:27 step:21434 [D loss: 0.366352, acc: 87.50%] [G loss: 4.205354]\n",
      "epoch:27 step:21435 [D loss: 0.357011, acc: 91.41%] [G loss: 3.794678]\n",
      "epoch:27 step:21436 [D loss: 0.322554, acc: 88.28%] [G loss: 5.641047]\n",
      "epoch:27 step:21437 [D loss: 0.377798, acc: 76.56%] [G loss: 3.920968]\n",
      "epoch:27 step:21438 [D loss: 0.581774, acc: 60.94%] [G loss: 4.242383]\n",
      "epoch:27 step:21439 [D loss: 0.850533, acc: 51.56%] [G loss: 3.597729]\n",
      "epoch:27 step:21440 [D loss: 0.907019, acc: 47.66%] [G loss: 4.939003]\n",
      "epoch:27 step:21441 [D loss: 0.771969, acc: 50.78%] [G loss: 4.635369]\n",
      "epoch:27 step:21442 [D loss: 0.793168, acc: 46.09%] [G loss: 5.140747]\n",
      "epoch:27 step:21443 [D loss: 0.195956, acc: 98.44%] [G loss: 3.826982]\n",
      "epoch:27 step:21444 [D loss: 0.478523, acc: 72.66%] [G loss: 4.923768]\n",
      "epoch:27 step:21445 [D loss: 0.214502, acc: 96.88%] [G loss: 6.286906]\n",
      "epoch:27 step:21446 [D loss: 0.188063, acc: 99.22%] [G loss: 3.547099]\n",
      "epoch:27 step:21447 [D loss: 0.297418, acc: 86.72%] [G loss: 3.171798]\n",
      "epoch:27 step:21448 [D loss: 0.431170, acc: 83.59%] [G loss: 3.442169]\n",
      "epoch:27 step:21449 [D loss: 0.159461, acc: 99.22%] [G loss: 3.609387]\n",
      "epoch:27 step:21450 [D loss: 0.687582, acc: 58.59%] [G loss: 2.874679]\n",
      "epoch:27 step:21451 [D loss: 0.203900, acc: 94.53%] [G loss: 4.018494]\n",
      "epoch:27 step:21452 [D loss: 0.311940, acc: 96.88%] [G loss: 5.482750]\n",
      "epoch:27 step:21453 [D loss: 0.705364, acc: 55.47%] [G loss: 5.470594]\n",
      "epoch:27 step:21454 [D loss: 0.567129, acc: 68.75%] [G loss: 3.591380]\n",
      "epoch:27 step:21455 [D loss: 0.097634, acc: 100.00%] [G loss: 3.094758]\n",
      "epoch:27 step:21456 [D loss: 0.296680, acc: 92.97%] [G loss: 4.532551]\n",
      "epoch:27 step:21457 [D loss: 0.399588, acc: 87.50%] [G loss: 3.703732]\n",
      "epoch:27 step:21458 [D loss: 0.189975, acc: 98.44%] [G loss: 4.470410]\n",
      "epoch:27 step:21459 [D loss: 0.945746, acc: 52.34%] [G loss: 3.952688]\n",
      "epoch:27 step:21460 [D loss: 0.775562, acc: 51.56%] [G loss: 4.047849]\n",
      "epoch:27 step:21461 [D loss: 0.425788, acc: 71.09%] [G loss: 4.286051]\n",
      "epoch:27 step:21462 [D loss: 0.138395, acc: 99.22%] [G loss: 6.243557]\n",
      "epoch:27 step:21463 [D loss: 0.152513, acc: 99.22%] [G loss: 5.990643]\n",
      "epoch:27 step:21464 [D loss: 0.609199, acc: 64.84%] [G loss: 5.344974]\n",
      "epoch:27 step:21465 [D loss: 0.088027, acc: 100.00%] [G loss: 4.889686]\n",
      "epoch:27 step:21466 [D loss: 0.122472, acc: 100.00%] [G loss: 4.875312]\n",
      "epoch:27 step:21467 [D loss: 0.388651, acc: 78.91%] [G loss: 3.515082]\n",
      "epoch:27 step:21468 [D loss: 0.251080, acc: 95.31%] [G loss: 3.437714]\n",
      "epoch:27 step:21469 [D loss: 0.296830, acc: 94.53%] [G loss: 2.950245]\n",
      "epoch:27 step:21470 [D loss: 0.922080, acc: 50.00%] [G loss: 4.838197]\n",
      "epoch:27 step:21471 [D loss: 0.403350, acc: 74.22%] [G loss: 5.226175]\n",
      "epoch:27 step:21472 [D loss: 0.319633, acc: 95.31%] [G loss: 2.938278]\n",
      "epoch:27 step:21473 [D loss: 0.330698, acc: 93.75%] [G loss: 5.128863]\n",
      "epoch:27 step:21474 [D loss: 0.887190, acc: 37.50%] [G loss: 1.813956]\n",
      "epoch:27 step:21475 [D loss: 0.515178, acc: 76.56%] [G loss: 3.486305]\n",
      "epoch:27 step:21476 [D loss: 0.258388, acc: 96.09%] [G loss: 3.088257]\n",
      "epoch:27 step:21477 [D loss: 0.238682, acc: 95.31%] [G loss: 5.057747]\n",
      "epoch:27 step:21478 [D loss: 0.968294, acc: 39.06%] [G loss: 3.414912]\n",
      "epoch:27 step:21479 [D loss: 0.459168, acc: 78.91%] [G loss: 3.890761]\n",
      "epoch:27 step:21480 [D loss: 0.748240, acc: 53.12%] [G loss: 4.512099]\n",
      "epoch:27 step:21481 [D loss: 0.098468, acc: 100.00%] [G loss: 4.128140]\n",
      "epoch:27 step:21482 [D loss: 0.646831, acc: 64.84%] [G loss: 5.108697]\n",
      "epoch:27 step:21483 [D loss: 0.732116, acc: 53.12%] [G loss: 3.515764]\n",
      "epoch:27 step:21484 [D loss: 0.341222, acc: 92.19%] [G loss: 3.040962]\n",
      "epoch:27 step:21485 [D loss: 0.313528, acc: 92.19%] [G loss: 4.312384]\n",
      "epoch:27 step:21486 [D loss: 0.214983, acc: 96.88%] [G loss: 3.434516]\n",
      "epoch:27 step:21487 [D loss: 0.149585, acc: 100.00%] [G loss: 4.826533]\n",
      "epoch:27 step:21488 [D loss: 0.098826, acc: 99.22%] [G loss: 4.361786]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21489 [D loss: 0.195031, acc: 98.44%] [G loss: 3.751608]\n",
      "epoch:27 step:21490 [D loss: 0.380418, acc: 85.94%] [G loss: 4.154991]\n",
      "epoch:27 step:21491 [D loss: 0.421258, acc: 89.06%] [G loss: 2.922888]\n",
      "epoch:27 step:21492 [D loss: 0.188431, acc: 98.44%] [G loss: 3.137602]\n",
      "epoch:27 step:21493 [D loss: 0.814090, acc: 52.34%] [G loss: 4.186412]\n",
      "epoch:27 step:21494 [D loss: 0.552687, acc: 75.78%] [G loss: 3.650968]\n",
      "epoch:27 step:21495 [D loss: 0.109989, acc: 100.00%] [G loss: 4.377961]\n",
      "epoch:27 step:21496 [D loss: 0.941174, acc: 48.44%] [G loss: 2.735280]\n",
      "epoch:27 step:21497 [D loss: 0.471210, acc: 71.09%] [G loss: 1.970803]\n",
      "epoch:27 step:21498 [D loss: 0.965393, acc: 40.62%] [G loss: 3.490196]\n",
      "epoch:27 step:21499 [D loss: 0.391185, acc: 90.62%] [G loss: 4.341650]\n",
      "epoch:27 step:21500 [D loss: 0.287396, acc: 92.97%] [G loss: 4.318365]\n",
      "epoch:27 step:21501 [D loss: 0.591287, acc: 59.38%] [G loss: 4.423779]\n",
      "epoch:27 step:21502 [D loss: 0.518057, acc: 59.38%] [G loss: 5.406105]\n",
      "epoch:27 step:21503 [D loss: 1.234383, acc: 49.22%] [G loss: 2.581794]\n",
      "epoch:27 step:21504 [D loss: 0.645137, acc: 69.53%] [G loss: 5.583259]\n",
      "epoch:27 step:21505 [D loss: 0.753536, acc: 51.56%] [G loss: 3.505373]\n",
      "epoch:27 step:21506 [D loss: 0.719484, acc: 56.25%] [G loss: 3.264895]\n",
      "epoch:27 step:21507 [D loss: 0.679019, acc: 57.03%] [G loss: 3.252269]\n",
      "epoch:27 step:21508 [D loss: 0.648356, acc: 61.72%] [G loss: 4.792709]\n",
      "epoch:27 step:21509 [D loss: 0.515583, acc: 71.09%] [G loss: 3.296398]\n",
      "epoch:27 step:21510 [D loss: 1.024334, acc: 25.00%] [G loss: 3.154252]\n",
      "epoch:27 step:21511 [D loss: 0.373628, acc: 88.28%] [G loss: 2.978783]\n",
      "epoch:27 step:21512 [D loss: 0.518211, acc: 70.31%] [G loss: 3.783172]\n",
      "epoch:27 step:21513 [D loss: 0.285899, acc: 96.09%] [G loss: 4.438477]\n",
      "epoch:27 step:21514 [D loss: 0.396930, acc: 86.72%] [G loss: 4.066690]\n",
      "epoch:27 step:21515 [D loss: 0.137721, acc: 99.22%] [G loss: 5.137498]\n",
      "epoch:27 step:21516 [D loss: 0.297413, acc: 92.97%] [G loss: 4.898039]\n",
      "epoch:27 step:21517 [D loss: 0.369644, acc: 83.59%] [G loss: 5.655134]\n",
      "epoch:27 step:21518 [D loss: 0.121210, acc: 100.00%] [G loss: 3.943726]\n",
      "epoch:27 step:21519 [D loss: 0.988036, acc: 31.25%] [G loss: 4.113012]\n",
      "epoch:27 step:21520 [D loss: 0.210118, acc: 94.53%] [G loss: 3.985402]\n",
      "epoch:27 step:21521 [D loss: 0.399876, acc: 83.59%] [G loss: 4.246059]\n",
      "epoch:27 step:21522 [D loss: 0.309722, acc: 95.31%] [G loss: 6.192733]\n",
      "epoch:27 step:21523 [D loss: 0.205481, acc: 96.09%] [G loss: 2.441869]\n",
      "epoch:27 step:21524 [D loss: 0.352582, acc: 90.62%] [G loss: 2.599256]\n",
      "epoch:27 step:21525 [D loss: 0.276004, acc: 97.66%] [G loss: 3.012321]\n",
      "epoch:27 step:21526 [D loss: 0.185662, acc: 99.22%] [G loss: 3.071385]\n",
      "epoch:27 step:21527 [D loss: 0.746872, acc: 56.25%] [G loss: 2.524411]\n",
      "epoch:27 step:21528 [D loss: 0.163676, acc: 98.44%] [G loss: 3.013263]\n",
      "epoch:27 step:21529 [D loss: 0.239497, acc: 97.66%] [G loss: 2.849742]\n",
      "epoch:27 step:21530 [D loss: 0.264057, acc: 95.31%] [G loss: 4.489393]\n",
      "epoch:27 step:21531 [D loss: 0.236613, acc: 98.44%] [G loss: 3.229496]\n",
      "epoch:27 step:21532 [D loss: 0.309305, acc: 94.53%] [G loss: 4.414217]\n",
      "epoch:27 step:21533 [D loss: 0.197963, acc: 96.09%] [G loss: 3.400712]\n",
      "epoch:27 step:21534 [D loss: 0.486205, acc: 81.25%] [G loss: 5.400288]\n",
      "epoch:27 step:21535 [D loss: 0.218055, acc: 98.44%] [G loss: 4.582566]\n",
      "epoch:27 step:21536 [D loss: 0.591038, acc: 65.62%] [G loss: 4.008266]\n",
      "epoch:27 step:21537 [D loss: 0.630313, acc: 64.84%] [G loss: 6.114162]\n",
      "epoch:27 step:21538 [D loss: 0.558605, acc: 71.09%] [G loss: 3.517996]\n",
      "epoch:27 step:21539 [D loss: 0.548695, acc: 59.38%] [G loss: 3.974910]\n",
      "epoch:27 step:21540 [D loss: 0.433616, acc: 83.59%] [G loss: 3.291737]\n",
      "epoch:27 step:21541 [D loss: 0.226241, acc: 98.44%] [G loss: 4.891816]\n",
      "epoch:27 step:21542 [D loss: 0.238437, acc: 98.44%] [G loss: 5.006029]\n",
      "epoch:27 step:21543 [D loss: 1.028970, acc: 29.69%] [G loss: 4.294381]\n",
      "epoch:27 step:21544 [D loss: 0.421564, acc: 86.72%] [G loss: 4.073726]\n",
      "epoch:27 step:21545 [D loss: 0.289412, acc: 94.53%] [G loss: 2.617425]\n",
      "epoch:27 step:21546 [D loss: 0.257895, acc: 92.19%] [G loss: 4.009335]\n",
      "epoch:27 step:21547 [D loss: 0.381370, acc: 88.28%] [G loss: 3.829933]\n",
      "epoch:27 step:21548 [D loss: 0.205463, acc: 98.44%] [G loss: 4.780787]\n",
      "epoch:27 step:21549 [D loss: 0.062373, acc: 100.00%] [G loss: 3.901870]\n",
      "epoch:27 step:21550 [D loss: 0.445389, acc: 72.66%] [G loss: 5.443299]\n",
      "epoch:27 step:21551 [D loss: 0.157577, acc: 99.22%] [G loss: 4.017400]\n",
      "epoch:27 step:21552 [D loss: 0.128500, acc: 100.00%] [G loss: 3.056652]\n",
      "epoch:27 step:21553 [D loss: 0.293267, acc: 88.28%] [G loss: 5.126677]\n",
      "epoch:27 step:21554 [D loss: 0.165316, acc: 99.22%] [G loss: 5.378014]\n",
      "epoch:27 step:21555 [D loss: 0.726204, acc: 53.91%] [G loss: 4.741927]\n",
      "epoch:27 step:21556 [D loss: 0.314678, acc: 86.72%] [G loss: 3.380240]\n",
      "epoch:27 step:21557 [D loss: 0.234744, acc: 96.09%] [G loss: 2.232608]\n",
      "epoch:27 step:21558 [D loss: 0.363207, acc: 82.03%] [G loss: 4.171047]\n",
      "epoch:27 step:21559 [D loss: 0.543279, acc: 75.78%] [G loss: 4.499381]\n",
      "epoch:27 step:21560 [D loss: 0.791611, acc: 44.53%] [G loss: 4.883447]\n",
      "epoch:27 step:21561 [D loss: 0.588054, acc: 63.28%] [G loss: 3.034736]\n",
      "epoch:27 step:21562 [D loss: 0.341608, acc: 92.97%] [G loss: 4.684589]\n",
      "epoch:27 step:21563 [D loss: 0.059786, acc: 100.00%] [G loss: 5.144544]\n",
      "epoch:27 step:21564 [D loss: 0.556998, acc: 67.97%] [G loss: 2.642724]\n",
      "epoch:27 step:21565 [D loss: 0.422831, acc: 78.12%] [G loss: 3.561831]\n",
      "epoch:27 step:21566 [D loss: 1.109232, acc: 14.84%] [G loss: 5.795664]\n",
      "epoch:27 step:21567 [D loss: 0.116994, acc: 100.00%] [G loss: 2.117725]\n",
      "epoch:27 step:21568 [D loss: 0.208903, acc: 99.22%] [G loss: 3.211732]\n",
      "epoch:27 step:21569 [D loss: 0.185555, acc: 98.44%] [G loss: 3.973528]\n",
      "epoch:27 step:21570 [D loss: 0.188202, acc: 99.22%] [G loss: 5.618204]\n",
      "epoch:27 step:21571 [D loss: 0.423285, acc: 87.50%] [G loss: 3.268799]\n",
      "epoch:27 step:21572 [D loss: 0.620434, acc: 59.38%] [G loss: 5.929638]\n",
      "epoch:27 step:21573 [D loss: 0.472862, acc: 66.41%] [G loss: 3.815684]\n",
      "epoch:27 step:21574 [D loss: 0.469639, acc: 70.31%] [G loss: 4.082822]\n",
      "epoch:27 step:21575 [D loss: 0.131272, acc: 100.00%] [G loss: 5.617147]\n",
      "epoch:27 step:21576 [D loss: 0.336697, acc: 80.47%] [G loss: 3.297335]\n",
      "epoch:27 step:21577 [D loss: 0.418180, acc: 73.44%] [G loss: 6.016752]\n",
      "epoch:27 step:21578 [D loss: 0.162905, acc: 98.44%] [G loss: 3.634696]\n",
      "epoch:27 step:21579 [D loss: 0.194474, acc: 99.22%] [G loss: 4.465470]\n",
      "epoch:27 step:21580 [D loss: 0.539163, acc: 72.66%] [G loss: 3.970924]\n",
      "epoch:27 step:21581 [D loss: 0.247889, acc: 95.31%] [G loss: 6.410882]\n",
      "epoch:27 step:21582 [D loss: 0.224111, acc: 97.66%] [G loss: 4.932668]\n",
      "epoch:27 step:21583 [D loss: 0.117010, acc: 99.22%] [G loss: 4.315306]\n",
      "epoch:27 step:21584 [D loss: 0.342846, acc: 82.81%] [G loss: 3.573298]\n",
      "epoch:27 step:21585 [D loss: 0.656367, acc: 67.19%] [G loss: 3.521611]\n",
      "epoch:27 step:21586 [D loss: 0.570822, acc: 69.53%] [G loss: 3.577187]\n",
      "epoch:27 step:21587 [D loss: 0.430236, acc: 85.16%] [G loss: 3.956993]\n",
      "epoch:27 step:21588 [D loss: 1.081117, acc: 43.75%] [G loss: 3.468033]\n",
      "epoch:27 step:21589 [D loss: 0.223310, acc: 96.09%] [G loss: 4.173283]\n",
      "epoch:27 step:21590 [D loss: 1.176406, acc: 45.31%] [G loss: 5.200315]\n",
      "epoch:27 step:21591 [D loss: 0.679566, acc: 57.81%] [G loss: 4.421579]\n",
      "epoch:27 step:21592 [D loss: 0.693821, acc: 56.25%] [G loss: 4.412155]\n",
      "epoch:27 step:21593 [D loss: 0.252923, acc: 95.31%] [G loss: 3.458693]\n",
      "epoch:27 step:21594 [D loss: 0.437182, acc: 83.59%] [G loss: 2.745166]\n",
      "epoch:27 step:21595 [D loss: 0.128091, acc: 99.22%] [G loss: 3.409949]\n",
      "epoch:27 step:21596 [D loss: 0.658666, acc: 59.38%] [G loss: 3.923589]\n",
      "epoch:27 step:21597 [D loss: 0.578165, acc: 68.75%] [G loss: 3.218003]\n",
      "epoch:27 step:21598 [D loss: 0.171063, acc: 96.88%] [G loss: 7.185222]\n",
      "epoch:27 step:21599 [D loss: 0.630446, acc: 61.72%] [G loss: 5.196533]\n",
      "epoch:27 step:21600 [D loss: 0.443101, acc: 82.03%] [G loss: 5.199012]\n",
      "epoch:27 step:21601 [D loss: 0.724094, acc: 53.91%] [G loss: 2.898097]\n",
      "epoch:27 step:21602 [D loss: 1.408752, acc: 47.66%] [G loss: 1.778069]\n",
      "epoch:27 step:21603 [D loss: 0.280603, acc: 86.72%] [G loss: 5.412564]\n",
      "epoch:27 step:21604 [D loss: 0.241775, acc: 96.09%] [G loss: 4.943009]\n",
      "epoch:27 step:21605 [D loss: 0.278083, acc: 92.97%] [G loss: 4.999011]\n",
      "epoch:27 step:21606 [D loss: 0.435206, acc: 69.53%] [G loss: 5.965079]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21607 [D loss: 0.597559, acc: 69.53%] [G loss: 4.705339]\n",
      "epoch:27 step:21608 [D loss: 0.849382, acc: 51.56%] [G loss: 2.903563]\n",
      "epoch:27 step:21609 [D loss: 0.832518, acc: 56.25%] [G loss: 3.582213]\n",
      "epoch:27 step:21610 [D loss: 0.222886, acc: 95.31%] [G loss: 5.689537]\n",
      "epoch:27 step:21611 [D loss: 0.681210, acc: 57.03%] [G loss: 4.348153]\n",
      "epoch:27 step:21612 [D loss: 0.169580, acc: 96.88%] [G loss: 1.992788]\n",
      "epoch:27 step:21613 [D loss: 1.083199, acc: 27.34%] [G loss: 4.279671]\n",
      "epoch:27 step:21614 [D loss: 0.417030, acc: 82.03%] [G loss: 3.421981]\n",
      "epoch:27 step:21615 [D loss: 0.105902, acc: 100.00%] [G loss: 3.996318]\n",
      "epoch:27 step:21616 [D loss: 0.442785, acc: 84.38%] [G loss: 2.620273]\n",
      "epoch:27 step:21617 [D loss: 0.470832, acc: 82.81%] [G loss: 4.086407]\n",
      "epoch:27 step:21618 [D loss: 0.960113, acc: 32.81%] [G loss: 5.578413]\n",
      "epoch:27 step:21619 [D loss: 0.432511, acc: 76.56%] [G loss: 3.428182]\n",
      "epoch:27 step:21620 [D loss: 0.515852, acc: 78.12%] [G loss: 4.543580]\n",
      "epoch:27 step:21621 [D loss: 1.197641, acc: 50.00%] [G loss: 3.930116]\n",
      "epoch:27 step:21622 [D loss: 0.789338, acc: 46.88%] [G loss: 3.165218]\n",
      "epoch:27 step:21623 [D loss: 0.118658, acc: 99.22%] [G loss: 5.497976]\n",
      "epoch:27 step:21624 [D loss: 0.126602, acc: 99.22%] [G loss: 7.866504]\n",
      "epoch:27 step:21625 [D loss: 0.377214, acc: 88.28%] [G loss: 6.713728]\n",
      "epoch:27 step:21626 [D loss: 0.259544, acc: 97.66%] [G loss: 3.639724]\n",
      "epoch:27 step:21627 [D loss: 0.262972, acc: 95.31%] [G loss: 3.635764]\n",
      "epoch:27 step:21628 [D loss: 0.654244, acc: 64.06%] [G loss: 3.061885]\n",
      "epoch:27 step:21629 [D loss: 0.175978, acc: 98.44%] [G loss: 4.102473]\n",
      "epoch:27 step:21630 [D loss: 0.905398, acc: 52.34%] [G loss: 6.357959]\n",
      "epoch:27 step:21631 [D loss: 0.383650, acc: 82.03%] [G loss: 3.705781]\n",
      "epoch:27 step:21632 [D loss: 0.153973, acc: 100.00%] [G loss: 4.945830]\n",
      "epoch:27 step:21633 [D loss: 0.299782, acc: 97.66%] [G loss: 2.722825]\n",
      "epoch:27 step:21634 [D loss: 0.244635, acc: 95.31%] [G loss: 2.041917]\n",
      "epoch:27 step:21635 [D loss: 0.211959, acc: 97.66%] [G loss: 2.736786]\n",
      "epoch:27 step:21636 [D loss: 0.247505, acc: 98.44%] [G loss: 3.134255]\n",
      "epoch:27 step:21637 [D loss: 0.085909, acc: 100.00%] [G loss: 4.875360]\n",
      "epoch:27 step:21638 [D loss: 0.136134, acc: 99.22%] [G loss: 3.745845]\n",
      "epoch:27 step:21639 [D loss: 0.210506, acc: 95.31%] [G loss: 3.669712]\n",
      "epoch:27 step:21640 [D loss: 0.440607, acc: 80.47%] [G loss: 3.467026]\n",
      "epoch:27 step:21641 [D loss: 0.179186, acc: 97.66%] [G loss: 3.291736]\n",
      "epoch:27 step:21642 [D loss: 0.238492, acc: 90.62%] [G loss: 4.125305]\n",
      "epoch:27 step:21643 [D loss: 1.193825, acc: 35.94%] [G loss: 2.133413]\n",
      "epoch:27 step:21644 [D loss: 0.917605, acc: 51.56%] [G loss: 4.998485]\n",
      "epoch:27 step:21645 [D loss: 0.269243, acc: 92.97%] [G loss: 3.869591]\n",
      "epoch:27 step:21646 [D loss: 0.370856, acc: 89.06%] [G loss: 4.891851]\n",
      "epoch:27 step:21647 [D loss: 0.321230, acc: 88.28%] [G loss: 4.536546]\n",
      "epoch:27 step:21648 [D loss: 0.474820, acc: 71.88%] [G loss: 3.926403]\n",
      "epoch:27 step:21649 [D loss: 0.807395, acc: 50.00%] [G loss: 3.733454]\n",
      "epoch:27 step:21650 [D loss: 0.354444, acc: 92.19%] [G loss: 4.245014]\n",
      "epoch:27 step:21651 [D loss: 0.301521, acc: 93.75%] [G loss: 5.817040]\n",
      "epoch:27 step:21652 [D loss: 0.340940, acc: 89.84%] [G loss: 3.534396]\n",
      "epoch:27 step:21653 [D loss: 0.190483, acc: 98.44%] [G loss: 4.368112]\n",
      "epoch:27 step:21654 [D loss: 0.183337, acc: 97.66%] [G loss: 2.875190]\n",
      "epoch:27 step:21655 [D loss: 0.239451, acc: 95.31%] [G loss: 3.918046]\n",
      "epoch:27 step:21656 [D loss: 1.322112, acc: 34.38%] [G loss: 3.464837]\n",
      "epoch:27 step:21657 [D loss: 0.778770, acc: 55.47%] [G loss: 3.406032]\n",
      "epoch:27 step:21658 [D loss: 0.270904, acc: 96.88%] [G loss: 2.990052]\n",
      "epoch:27 step:21659 [D loss: 0.412543, acc: 75.78%] [G loss: 3.654913]\n",
      "epoch:27 step:21660 [D loss: 0.792819, acc: 53.12%] [G loss: 5.302722]\n",
      "epoch:27 step:21661 [D loss: 1.076767, acc: 36.72%] [G loss: 4.308584]\n",
      "epoch:27 step:21662 [D loss: 0.395711, acc: 80.47%] [G loss: 3.484470]\n",
      "epoch:27 step:21663 [D loss: 0.363010, acc: 90.62%] [G loss: 4.022028]\n",
      "epoch:27 step:21664 [D loss: 0.488901, acc: 74.22%] [G loss: 5.404388]\n",
      "epoch:27 step:21665 [D loss: 0.175869, acc: 96.09%] [G loss: 5.847464]\n",
      "epoch:27 step:21666 [D loss: 0.512582, acc: 77.34%] [G loss: 3.241867]\n",
      "epoch:27 step:21667 [D loss: 0.569279, acc: 67.97%] [G loss: 4.428053]\n",
      "epoch:27 step:21668 [D loss: 0.218682, acc: 95.31%] [G loss: 3.689342]\n",
      "epoch:27 step:21669 [D loss: 0.257879, acc: 92.19%] [G loss: 4.240526]\n",
      "epoch:27 step:21670 [D loss: 0.560093, acc: 61.72%] [G loss: 3.731198]\n",
      "epoch:27 step:21671 [D loss: 0.324601, acc: 90.62%] [G loss: 3.601293]\n",
      "epoch:27 step:21672 [D loss: 0.297982, acc: 92.19%] [G loss: 4.163245]\n",
      "epoch:27 step:21673 [D loss: 0.543092, acc: 69.53%] [G loss: 1.792640]\n",
      "epoch:27 step:21674 [D loss: 0.265336, acc: 89.84%] [G loss: 4.898392]\n",
      "epoch:27 step:21675 [D loss: 0.488678, acc: 79.69%] [G loss: 4.255777]\n",
      "epoch:27 step:21676 [D loss: 0.366300, acc: 86.72%] [G loss: 3.298897]\n",
      "epoch:27 step:21677 [D loss: 0.396057, acc: 82.81%] [G loss: 3.446435]\n",
      "epoch:27 step:21678 [D loss: 0.465467, acc: 83.59%] [G loss: 1.901873]\n",
      "epoch:27 step:21679 [D loss: 0.612061, acc: 67.19%] [G loss: 3.698588]\n",
      "epoch:27 step:21680 [D loss: 0.716460, acc: 64.06%] [G loss: 5.487542]\n",
      "epoch:27 step:21681 [D loss: 0.179660, acc: 97.66%] [G loss: 3.507759]\n",
      "epoch:27 step:21682 [D loss: 0.517611, acc: 71.09%] [G loss: 3.939816]\n",
      "epoch:27 step:21683 [D loss: 0.426629, acc: 84.38%] [G loss: 3.336840]\n",
      "epoch:27 step:21684 [D loss: 0.252706, acc: 97.66%] [G loss: 4.833441]\n",
      "epoch:27 step:21685 [D loss: 0.189271, acc: 98.44%] [G loss: 3.421587]\n",
      "epoch:27 step:21686 [D loss: 0.517548, acc: 72.66%] [G loss: 3.684922]\n",
      "epoch:27 step:21687 [D loss: 0.311981, acc: 94.53%] [G loss: 5.183690]\n",
      "epoch:27 step:21688 [D loss: 0.213954, acc: 95.31%] [G loss: 3.944605]\n",
      "epoch:27 step:21689 [D loss: 0.392191, acc: 79.69%] [G loss: 2.322925]\n",
      "epoch:27 step:21690 [D loss: 0.358879, acc: 90.62%] [G loss: 3.287561]\n",
      "epoch:27 step:21691 [D loss: 0.888784, acc: 42.97%] [G loss: 3.255944]\n",
      "epoch:27 step:21692 [D loss: 0.545516, acc: 61.72%] [G loss: 5.316772]\n",
      "epoch:27 step:21693 [D loss: 0.139214, acc: 99.22%] [G loss: 3.933658]\n",
      "epoch:27 step:21694 [D loss: 0.774836, acc: 53.12%] [G loss: 4.303008]\n",
      "epoch:27 step:21695 [D loss: 0.282457, acc: 95.31%] [G loss: 4.717604]\n",
      "epoch:27 step:21696 [D loss: 0.493704, acc: 75.00%] [G loss: 3.516151]\n",
      "epoch:27 step:21697 [D loss: 0.450520, acc: 86.72%] [G loss: 3.802979]\n",
      "epoch:27 step:21698 [D loss: 0.642038, acc: 60.94%] [G loss: 4.011484]\n",
      "epoch:27 step:21699 [D loss: 0.192295, acc: 99.22%] [G loss: 4.530555]\n",
      "epoch:27 step:21700 [D loss: 0.995152, acc: 26.56%] [G loss: 3.490737]\n",
      "epoch:27 step:21701 [D loss: 0.325216, acc: 82.03%] [G loss: 3.755467]\n",
      "epoch:27 step:21702 [D loss: 0.223271, acc: 99.22%] [G loss: 3.222297]\n",
      "epoch:27 step:21703 [D loss: 0.526635, acc: 75.00%] [G loss: 4.289706]\n",
      "epoch:27 step:21704 [D loss: 0.268886, acc: 95.31%] [G loss: 3.151933]\n",
      "epoch:27 step:21705 [D loss: 0.328527, acc: 90.62%] [G loss: 3.474189]\n",
      "epoch:27 step:21706 [D loss: 0.483887, acc: 78.12%] [G loss: 3.905972]\n",
      "epoch:27 step:21707 [D loss: 0.066746, acc: 100.00%] [G loss: 2.868650]\n",
      "epoch:27 step:21708 [D loss: 2.053345, acc: 5.47%] [G loss: 4.696344]\n",
      "epoch:27 step:21709 [D loss: 0.457595, acc: 72.66%] [G loss: 5.042912]\n",
      "epoch:27 step:21710 [D loss: 0.370978, acc: 83.59%] [G loss: 3.198520]\n",
      "epoch:27 step:21711 [D loss: 0.579551, acc: 62.50%] [G loss: 4.272304]\n",
      "epoch:27 step:21712 [D loss: 0.373939, acc: 88.28%] [G loss: 4.031111]\n",
      "epoch:27 step:21713 [D loss: 0.928810, acc: 34.38%] [G loss: 3.477650]\n",
      "epoch:27 step:21714 [D loss: 0.263572, acc: 89.84%] [G loss: 3.846452]\n",
      "epoch:27 step:21715 [D loss: 0.139043, acc: 98.44%] [G loss: 4.316993]\n",
      "epoch:27 step:21716 [D loss: 0.491246, acc: 69.53%] [G loss: 2.393236]\n",
      "epoch:27 step:21717 [D loss: 0.162290, acc: 99.22%] [G loss: 6.208701]\n",
      "epoch:27 step:21718 [D loss: 0.346962, acc: 81.25%] [G loss: 4.094786]\n",
      "epoch:27 step:21719 [D loss: 0.147264, acc: 97.66%] [G loss: 5.185843]\n",
      "epoch:27 step:21720 [D loss: 0.535659, acc: 62.50%] [G loss: 5.557636]\n",
      "epoch:27 step:21721 [D loss: 0.396754, acc: 75.00%] [G loss: 5.601002]\n",
      "epoch:27 step:21722 [D loss: 0.198695, acc: 100.00%] [G loss: 3.923197]\n",
      "epoch:27 step:21723 [D loss: 0.606577, acc: 59.38%] [G loss: 3.815719]\n",
      "epoch:27 step:21724 [D loss: 0.303217, acc: 92.97%] [G loss: 4.064801]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21725 [D loss: 0.357185, acc: 88.28%] [G loss: 2.854606]\n",
      "epoch:27 step:21726 [D loss: 0.627757, acc: 64.06%] [G loss: 4.761629]\n",
      "epoch:27 step:21727 [D loss: 0.800002, acc: 53.12%] [G loss: 3.238436]\n",
      "epoch:27 step:21728 [D loss: 0.504711, acc: 81.25%] [G loss: 2.754224]\n",
      "epoch:27 step:21729 [D loss: 1.057590, acc: 48.44%] [G loss: 3.672178]\n",
      "epoch:27 step:21730 [D loss: 0.164947, acc: 99.22%] [G loss: 3.625251]\n",
      "epoch:27 step:21731 [D loss: 0.412716, acc: 78.12%] [G loss: 4.472451]\n",
      "epoch:27 step:21732 [D loss: 1.039614, acc: 26.56%] [G loss: 4.193892]\n",
      "epoch:27 step:21733 [D loss: 0.966942, acc: 45.31%] [G loss: 2.461486]\n",
      "epoch:27 step:21734 [D loss: 0.578157, acc: 66.41%] [G loss: 4.826745]\n",
      "epoch:27 step:21735 [D loss: 0.432879, acc: 80.47%] [G loss: 3.783488]\n",
      "epoch:27 step:21736 [D loss: 0.465088, acc: 82.03%] [G loss: 3.544254]\n",
      "epoch:27 step:21737 [D loss: 0.375964, acc: 90.62%] [G loss: 6.870107]\n",
      "epoch:27 step:21738 [D loss: 0.301594, acc: 85.94%] [G loss: 4.213526]\n",
      "epoch:27 step:21739 [D loss: 0.394039, acc: 82.03%] [G loss: 3.283652]\n",
      "epoch:27 step:21740 [D loss: 0.209188, acc: 93.75%] [G loss: 5.728652]\n",
      "epoch:27 step:21741 [D loss: 0.567176, acc: 72.66%] [G loss: 4.428098]\n",
      "epoch:27 step:21742 [D loss: 0.356526, acc: 83.59%] [G loss: 4.610228]\n",
      "epoch:27 step:21743 [D loss: 0.833786, acc: 44.53%] [G loss: 5.149772]\n",
      "epoch:27 step:21744 [D loss: 0.237804, acc: 97.66%] [G loss: 3.786320]\n",
      "epoch:27 step:21745 [D loss: 0.653637, acc: 57.03%] [G loss: 3.087059]\n",
      "epoch:27 step:21746 [D loss: 0.249846, acc: 96.09%] [G loss: 5.803712]\n",
      "epoch:27 step:21747 [D loss: 0.313178, acc: 94.53%] [G loss: 2.830066]\n",
      "epoch:27 step:21748 [D loss: 0.183286, acc: 97.66%] [G loss: 7.278998]\n",
      "epoch:27 step:21749 [D loss: 0.254408, acc: 96.09%] [G loss: 4.012427]\n",
      "epoch:27 step:21750 [D loss: 0.240370, acc: 96.09%] [G loss: 3.968021]\n",
      "epoch:27 step:21751 [D loss: 0.324971, acc: 94.53%] [G loss: 4.472230]\n",
      "epoch:27 step:21752 [D loss: 0.241342, acc: 99.22%] [G loss: 3.004624]\n",
      "epoch:27 step:21753 [D loss: 0.400027, acc: 89.06%] [G loss: 3.200737]\n",
      "epoch:27 step:21754 [D loss: 0.138952, acc: 100.00%] [G loss: 4.301643]\n",
      "epoch:27 step:21755 [D loss: 0.306401, acc: 92.97%] [G loss: 2.930652]\n",
      "epoch:27 step:21756 [D loss: 0.892759, acc: 54.69%] [G loss: 3.215570]\n",
      "epoch:27 step:21757 [D loss: 0.808685, acc: 53.91%] [G loss: 3.215283]\n",
      "epoch:27 step:21758 [D loss: 0.287586, acc: 90.62%] [G loss: 3.897106]\n",
      "epoch:27 step:21759 [D loss: 0.201720, acc: 98.44%] [G loss: 4.051465]\n",
      "epoch:27 step:21760 [D loss: 0.578952, acc: 67.19%] [G loss: 4.013240]\n",
      "epoch:27 step:21761 [D loss: 0.573215, acc: 57.81%] [G loss: 4.174555]\n",
      "epoch:27 step:21762 [D loss: 0.224813, acc: 92.97%] [G loss: 4.905056]\n",
      "epoch:27 step:21763 [D loss: 0.242783, acc: 96.88%] [G loss: 3.968002]\n",
      "epoch:27 step:21764 [D loss: 1.043537, acc: 50.00%] [G loss: 3.905699]\n",
      "epoch:27 step:21765 [D loss: 0.173523, acc: 97.66%] [G loss: 2.296799]\n",
      "epoch:27 step:21766 [D loss: 0.705565, acc: 58.59%] [G loss: 4.763052]\n",
      "epoch:27 step:21767 [D loss: 0.420986, acc: 78.12%] [G loss: 3.230097]\n",
      "epoch:27 step:21768 [D loss: 0.077418, acc: 100.00%] [G loss: 3.852303]\n",
      "epoch:27 step:21769 [D loss: 0.326664, acc: 85.16%] [G loss: 3.961809]\n",
      "epoch:27 step:21770 [D loss: 0.587862, acc: 60.16%] [G loss: 2.659557]\n",
      "epoch:27 step:21771 [D loss: 0.092881, acc: 98.44%] [G loss: 2.104800]\n",
      "epoch:27 step:21772 [D loss: 0.258668, acc: 97.66%] [G loss: 3.268509]\n",
      "epoch:27 step:21773 [D loss: 0.221164, acc: 98.44%] [G loss: 4.023248]\n",
      "epoch:27 step:21774 [D loss: 0.558764, acc: 64.06%] [G loss: 3.027257]\n",
      "epoch:27 step:21775 [D loss: 0.861486, acc: 30.47%] [G loss: 3.805273]\n",
      "epoch:27 step:21776 [D loss: 0.543166, acc: 61.72%] [G loss: 3.867039]\n",
      "epoch:27 step:21777 [D loss: 0.165775, acc: 100.00%] [G loss: 5.075220]\n",
      "epoch:27 step:21778 [D loss: 0.227099, acc: 95.31%] [G loss: 3.332961]\n",
      "epoch:27 step:21779 [D loss: 1.277575, acc: 37.50%] [G loss: 4.236553]\n",
      "epoch:27 step:21780 [D loss: 0.238330, acc: 94.53%] [G loss: 2.722855]\n",
      "epoch:27 step:21781 [D loss: 0.405117, acc: 81.25%] [G loss: 4.876933]\n",
      "epoch:27 step:21782 [D loss: 0.121950, acc: 99.22%] [G loss: 4.232422]\n",
      "epoch:27 step:21783 [D loss: 0.435537, acc: 85.94%] [G loss: 4.982555]\n",
      "epoch:27 step:21784 [D loss: 1.048962, acc: 31.25%] [G loss: 4.619338]\n",
      "epoch:27 step:21785 [D loss: 0.892391, acc: 41.41%] [G loss: 3.916615]\n",
      "epoch:27 step:21786 [D loss: 0.697994, acc: 58.59%] [G loss: 5.911426]\n",
      "epoch:27 step:21787 [D loss: 0.813836, acc: 46.09%] [G loss: 4.559708]\n",
      "epoch:27 step:21788 [D loss: 0.598500, acc: 59.38%] [G loss: 2.784150]\n",
      "epoch:27 step:21789 [D loss: 0.290662, acc: 98.44%] [G loss: 4.373271]\n",
      "epoch:27 step:21790 [D loss: 0.752577, acc: 49.22%] [G loss: 2.742755]\n",
      "epoch:27 step:21791 [D loss: 0.345611, acc: 91.41%] [G loss: 1.120352]\n",
      "epoch:27 step:21792 [D loss: 0.772534, acc: 47.66%] [G loss: 3.479675]\n",
      "epoch:27 step:21793 [D loss: 0.496892, acc: 80.47%] [G loss: 3.410712]\n",
      "epoch:27 step:21794 [D loss: 1.205566, acc: 32.81%] [G loss: 4.624124]\n",
      "epoch:27 step:21795 [D loss: 0.281523, acc: 86.72%] [G loss: 5.476086]\n",
      "epoch:27 step:21796 [D loss: 0.410332, acc: 78.91%] [G loss: 4.849717]\n",
      "epoch:27 step:21797 [D loss: 0.340035, acc: 90.62%] [G loss: 3.934583]\n",
      "epoch:27 step:21798 [D loss: 0.099862, acc: 99.22%] [G loss: 4.755328]\n",
      "epoch:27 step:21799 [D loss: 0.510313, acc: 78.91%] [G loss: 3.542981]\n",
      "epoch:27 step:21800 [D loss: 0.066480, acc: 100.00%] [G loss: 5.151368]\n",
      "epoch:27 step:21801 [D loss: 0.543974, acc: 64.06%] [G loss: 4.502645]\n",
      "epoch:27 step:21802 [D loss: 0.697073, acc: 54.69%] [G loss: 3.983165]\n",
      "epoch:27 step:21803 [D loss: 0.604422, acc: 60.16%] [G loss: 5.594269]\n",
      "epoch:27 step:21804 [D loss: 0.232216, acc: 96.88%] [G loss: 4.812615]\n",
      "epoch:27 step:21805 [D loss: 0.295123, acc: 90.62%] [G loss: 4.043063]\n",
      "epoch:27 step:21806 [D loss: 0.400104, acc: 88.28%] [G loss: 3.857770]\n",
      "epoch:27 step:21807 [D loss: 0.741661, acc: 53.91%] [G loss: 3.731915]\n",
      "epoch:27 step:21808 [D loss: 0.696692, acc: 60.94%] [G loss: 3.230463]\n",
      "epoch:27 step:21809 [D loss: 0.508689, acc: 72.66%] [G loss: 3.514558]\n",
      "epoch:27 step:21810 [D loss: 0.920863, acc: 50.00%] [G loss: 3.848176]\n",
      "epoch:27 step:21811 [D loss: 0.913943, acc: 39.06%] [G loss: 3.231559]\n",
      "epoch:27 step:21812 [D loss: 0.642559, acc: 64.06%] [G loss: 4.338443]\n",
      "epoch:27 step:21813 [D loss: 0.192744, acc: 97.66%] [G loss: 4.562630]\n",
      "epoch:27 step:21814 [D loss: 0.684628, acc: 55.47%] [G loss: 4.021912]\n",
      "epoch:27 step:21815 [D loss: 0.267411, acc: 96.09%] [G loss: 4.652293]\n",
      "epoch:27 step:21816 [D loss: 0.366629, acc: 94.53%] [G loss: 5.246977]\n",
      "epoch:27 step:21817 [D loss: 1.109084, acc: 45.31%] [G loss: 3.430676]\n",
      "epoch:27 step:21818 [D loss: 0.741085, acc: 52.34%] [G loss: 2.776754]\n",
      "epoch:27 step:21819 [D loss: 0.625516, acc: 62.50%] [G loss: 3.124775]\n",
      "epoch:27 step:21820 [D loss: 0.636883, acc: 56.25%] [G loss: 5.021019]\n",
      "epoch:27 step:21821 [D loss: 0.568330, acc: 69.53%] [G loss: 4.911844]\n",
      "epoch:27 step:21822 [D loss: 0.128466, acc: 99.22%] [G loss: 4.100100]\n",
      "epoch:27 step:21823 [D loss: 0.278267, acc: 93.75%] [G loss: 3.944375]\n",
      "epoch:27 step:21824 [D loss: 0.189968, acc: 99.22%] [G loss: 2.583452]\n",
      "epoch:27 step:21825 [D loss: 0.747227, acc: 46.09%] [G loss: 4.889152]\n",
      "epoch:27 step:21826 [D loss: 0.284079, acc: 98.44%] [G loss: 3.737006]\n",
      "epoch:27 step:21827 [D loss: 0.329807, acc: 79.69%] [G loss: 3.864218]\n",
      "epoch:27 step:21828 [D loss: 0.608475, acc: 62.50%] [G loss: 5.003743]\n",
      "epoch:27 step:21829 [D loss: 0.444825, acc: 85.94%] [G loss: 3.572037]\n",
      "epoch:27 step:21830 [D loss: 0.413762, acc: 89.84%] [G loss: 2.840389]\n",
      "epoch:27 step:21831 [D loss: 0.554953, acc: 66.41%] [G loss: 3.468524]\n",
      "epoch:27 step:21832 [D loss: 1.094494, acc: 39.06%] [G loss: 5.446489]\n",
      "epoch:27 step:21833 [D loss: 0.111304, acc: 99.22%] [G loss: 3.508070]\n",
      "epoch:27 step:21834 [D loss: 0.828382, acc: 50.78%] [G loss: 3.705344]\n",
      "epoch:27 step:21835 [D loss: 0.135319, acc: 98.44%] [G loss: 3.282427]\n",
      "epoch:27 step:21836 [D loss: 0.363125, acc: 82.03%] [G loss: 4.691029]\n",
      "epoch:27 step:21837 [D loss: 0.541588, acc: 75.00%] [G loss: 4.999867]\n",
      "epoch:27 step:21838 [D loss: 0.435476, acc: 84.38%] [G loss: 2.298898]\n",
      "epoch:27 step:21839 [D loss: 0.692023, acc: 56.25%] [G loss: 5.248970]\n",
      "epoch:27 step:21840 [D loss: 0.661302, acc: 57.03%] [G loss: 4.426415]\n",
      "epoch:27 step:21841 [D loss: 0.178005, acc: 99.22%] [G loss: 4.966232]\n",
      "epoch:27 step:21842 [D loss: 0.280247, acc: 94.53%] [G loss: 5.387910]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21843 [D loss: 0.337176, acc: 79.69%] [G loss: 5.312134]\n",
      "epoch:27 step:21844 [D loss: 0.470560, acc: 78.91%] [G loss: 4.072183]\n",
      "epoch:27 step:21845 [D loss: 0.183732, acc: 98.44%] [G loss: 2.382856]\n",
      "epoch:27 step:21846 [D loss: 0.302736, acc: 96.88%] [G loss: 2.911533]\n",
      "epoch:27 step:21847 [D loss: 0.050872, acc: 100.00%] [G loss: 8.241330]\n",
      "epoch:27 step:21848 [D loss: 0.746489, acc: 57.03%] [G loss: 3.717350]\n",
      "epoch:27 step:21849 [D loss: 0.480611, acc: 72.66%] [G loss: 3.849987]\n",
      "epoch:27 step:21850 [D loss: 0.230586, acc: 97.66%] [G loss: 4.236202]\n",
      "epoch:27 step:21851 [D loss: 0.358662, acc: 82.03%] [G loss: 3.470341]\n",
      "epoch:27 step:21852 [D loss: 0.819766, acc: 52.34%] [G loss: 4.158775]\n",
      "epoch:27 step:21853 [D loss: 0.201188, acc: 96.09%] [G loss: 3.346858]\n",
      "epoch:27 step:21854 [D loss: 0.060541, acc: 100.00%] [G loss: 3.768434]\n",
      "epoch:27 step:21855 [D loss: 0.145284, acc: 98.44%] [G loss: 3.014715]\n",
      "epoch:27 step:21856 [D loss: 0.680314, acc: 63.28%] [G loss: 2.326761]\n",
      "epoch:27 step:21857 [D loss: 0.450191, acc: 80.47%] [G loss: 2.758910]\n",
      "epoch:27 step:21858 [D loss: 0.178344, acc: 98.44%] [G loss: 4.059441]\n",
      "epoch:27 step:21859 [D loss: 0.412098, acc: 78.12%] [G loss: 4.211691]\n",
      "epoch:27 step:21860 [D loss: 0.053096, acc: 100.00%] [G loss: 5.303527]\n",
      "epoch:27 step:21861 [D loss: 0.105293, acc: 100.00%] [G loss: 4.948427]\n",
      "epoch:27 step:21862 [D loss: 1.036717, acc: 45.31%] [G loss: 4.159205]\n",
      "epoch:27 step:21863 [D loss: 0.304272, acc: 91.41%] [G loss: 4.025648]\n",
      "epoch:27 step:21864 [D loss: 0.426954, acc: 82.81%] [G loss: 3.987653]\n",
      "epoch:27 step:21865 [D loss: 0.262690, acc: 92.19%] [G loss: 6.809648]\n",
      "epoch:27 step:21866 [D loss: 0.377843, acc: 89.06%] [G loss: 4.294565]\n",
      "epoch:27 step:21867 [D loss: 0.344757, acc: 91.41%] [G loss: 3.695457]\n",
      "epoch:27 step:21868 [D loss: 0.298509, acc: 87.50%] [G loss: 3.901126]\n",
      "epoch:28 step:21869 [D loss: 0.552750, acc: 71.88%] [G loss: 3.245989]\n",
      "epoch:28 step:21870 [D loss: 0.299060, acc: 89.06%] [G loss: 3.459359]\n",
      "epoch:28 step:21871 [D loss: 0.509458, acc: 65.62%] [G loss: 4.870036]\n",
      "epoch:28 step:21872 [D loss: 0.399826, acc: 89.84%] [G loss: 2.636641]\n",
      "epoch:28 step:21873 [D loss: 0.747543, acc: 51.56%] [G loss: 4.972661]\n",
      "epoch:28 step:21874 [D loss: 0.490250, acc: 75.78%] [G loss: 3.493329]\n",
      "epoch:28 step:21875 [D loss: 0.334540, acc: 92.19%] [G loss: 3.968966]\n",
      "epoch:28 step:21876 [D loss: 0.354987, acc: 82.03%] [G loss: 4.491338]\n",
      "epoch:28 step:21877 [D loss: 0.410882, acc: 70.31%] [G loss: 4.666775]\n",
      "epoch:28 step:21878 [D loss: 0.241323, acc: 89.84%] [G loss: 3.139197]\n",
      "epoch:28 step:21879 [D loss: 0.464139, acc: 78.12%] [G loss: 2.954939]\n",
      "epoch:28 step:21880 [D loss: 0.220388, acc: 99.22%] [G loss: 5.649127]\n",
      "epoch:28 step:21881 [D loss: 0.768651, acc: 53.91%] [G loss: 4.270498]\n",
      "epoch:28 step:21882 [D loss: 0.078358, acc: 100.00%] [G loss: 4.590969]\n",
      "epoch:28 step:21883 [D loss: 0.778591, acc: 52.34%] [G loss: 3.592149]\n",
      "epoch:28 step:21884 [D loss: 0.481194, acc: 79.69%] [G loss: 4.200904]\n",
      "epoch:28 step:21885 [D loss: 0.642260, acc: 63.28%] [G loss: 4.050336]\n",
      "epoch:28 step:21886 [D loss: 0.104881, acc: 98.44%] [G loss: 6.035361]\n",
      "epoch:28 step:21887 [D loss: 0.322063, acc: 92.19%] [G loss: 3.379285]\n",
      "epoch:28 step:21888 [D loss: 0.676993, acc: 57.03%] [G loss: 4.103739]\n",
      "epoch:28 step:21889 [D loss: 0.421396, acc: 85.16%] [G loss: 3.582617]\n",
      "epoch:28 step:21890 [D loss: 0.366978, acc: 73.44%] [G loss: 4.544727]\n",
      "epoch:28 step:21891 [D loss: 0.738909, acc: 55.47%] [G loss: 4.883918]\n",
      "epoch:28 step:21892 [D loss: 0.351990, acc: 85.16%] [G loss: 3.540473]\n",
      "epoch:28 step:21893 [D loss: 0.166956, acc: 98.44%] [G loss: 4.825897]\n",
      "epoch:28 step:21894 [D loss: 0.181258, acc: 98.44%] [G loss: 4.652966]\n",
      "epoch:28 step:21895 [D loss: 0.497180, acc: 83.59%] [G loss: 2.584804]\n",
      "epoch:28 step:21896 [D loss: 0.873480, acc: 39.84%] [G loss: 5.125070]\n",
      "epoch:28 step:21897 [D loss: 0.332990, acc: 92.97%] [G loss: 3.100559]\n",
      "epoch:28 step:21898 [D loss: 0.373402, acc: 85.16%] [G loss: 3.849069]\n",
      "epoch:28 step:21899 [D loss: 0.186396, acc: 98.44%] [G loss: 2.631054]\n",
      "epoch:28 step:21900 [D loss: 0.454214, acc: 76.56%] [G loss: 4.183675]\n",
      "epoch:28 step:21901 [D loss: 0.421463, acc: 89.06%] [G loss: 4.165406]\n",
      "epoch:28 step:21902 [D loss: 0.279710, acc: 96.09%] [G loss: 4.453689]\n",
      "epoch:28 step:21903 [D loss: 0.772345, acc: 53.91%] [G loss: 3.975342]\n",
      "epoch:28 step:21904 [D loss: 0.419489, acc: 85.94%] [G loss: 5.877192]\n",
      "epoch:28 step:21905 [D loss: 0.462973, acc: 82.81%] [G loss: 4.156890]\n",
      "epoch:28 step:21906 [D loss: 0.462684, acc: 79.69%] [G loss: 4.449603]\n",
      "epoch:28 step:21907 [D loss: 0.593075, acc: 67.19%] [G loss: 4.339686]\n",
      "epoch:28 step:21908 [D loss: 0.315199, acc: 92.19%] [G loss: 3.544090]\n",
      "epoch:28 step:21909 [D loss: 0.180288, acc: 100.00%] [G loss: 2.843227]\n",
      "epoch:28 step:21910 [D loss: 0.820264, acc: 47.66%] [G loss: 5.944444]\n",
      "epoch:28 step:21911 [D loss: 0.651887, acc: 58.59%] [G loss: 2.988084]\n",
      "epoch:28 step:21912 [D loss: 0.087774, acc: 100.00%] [G loss: 4.498775]\n",
      "epoch:28 step:21913 [D loss: 0.173283, acc: 100.00%] [G loss: 3.579477]\n",
      "epoch:28 step:21914 [D loss: 0.398300, acc: 86.72%] [G loss: 4.182820]\n",
      "epoch:28 step:21915 [D loss: 0.276125, acc: 95.31%] [G loss: 3.210557]\n",
      "epoch:28 step:21916 [D loss: 0.534928, acc: 72.66%] [G loss: 5.790089]\n",
      "epoch:28 step:21917 [D loss: 0.624078, acc: 60.16%] [G loss: 1.910067]\n",
      "epoch:28 step:21918 [D loss: 1.148968, acc: 49.22%] [G loss: 2.303452]\n",
      "epoch:28 step:21919 [D loss: 0.613805, acc: 61.72%] [G loss: 4.400993]\n",
      "epoch:28 step:21920 [D loss: 0.248255, acc: 96.09%] [G loss: 5.246706]\n",
      "epoch:28 step:21921 [D loss: 0.296980, acc: 91.41%] [G loss: 4.035989]\n",
      "epoch:28 step:21922 [D loss: 1.223623, acc: 24.22%] [G loss: 6.258054]\n",
      "epoch:28 step:21923 [D loss: 0.109354, acc: 98.44%] [G loss: 3.571486]\n",
      "epoch:28 step:21924 [D loss: 0.400084, acc: 84.38%] [G loss: 6.234921]\n",
      "epoch:28 step:21925 [D loss: 0.659853, acc: 58.59%] [G loss: 2.921287]\n",
      "epoch:28 step:21926 [D loss: 0.182605, acc: 100.00%] [G loss: 4.933987]\n",
      "epoch:28 step:21927 [D loss: 0.334565, acc: 91.41%] [G loss: 4.418027]\n",
      "epoch:28 step:21928 [D loss: 0.601072, acc: 74.22%] [G loss: 3.478812]\n",
      "epoch:28 step:21929 [D loss: 0.186127, acc: 97.66%] [G loss: 3.287556]\n",
      "epoch:28 step:21930 [D loss: 0.432934, acc: 86.72%] [G loss: 2.815987]\n",
      "epoch:28 step:21931 [D loss: 0.257248, acc: 96.09%] [G loss: 4.525877]\n",
      "epoch:28 step:21932 [D loss: 0.198100, acc: 100.00%] [G loss: 2.152398]\n",
      "epoch:28 step:21933 [D loss: 0.261931, acc: 89.84%] [G loss: 5.762287]\n",
      "epoch:28 step:21934 [D loss: 0.647437, acc: 63.28%] [G loss: 5.901834]\n",
      "epoch:28 step:21935 [D loss: 0.400391, acc: 74.22%] [G loss: 3.779690]\n",
      "epoch:28 step:21936 [D loss: 0.416098, acc: 86.72%] [G loss: 3.152505]\n",
      "epoch:28 step:21937 [D loss: 0.609953, acc: 59.38%] [G loss: 3.234972]\n",
      "epoch:28 step:21938 [D loss: 0.291142, acc: 87.50%] [G loss: 4.749445]\n",
      "epoch:28 step:21939 [D loss: 1.369610, acc: 19.53%] [G loss: 4.259010]\n",
      "epoch:28 step:21940 [D loss: 0.757466, acc: 53.12%] [G loss: 2.725324]\n",
      "epoch:28 step:21941 [D loss: 0.395442, acc: 85.16%] [G loss: 3.170581]\n",
      "epoch:28 step:21942 [D loss: 0.290910, acc: 85.16%] [G loss: 7.274089]\n",
      "epoch:28 step:21943 [D loss: 0.142871, acc: 100.00%] [G loss: 4.264957]\n",
      "epoch:28 step:21944 [D loss: 0.094128, acc: 100.00%] [G loss: 6.654255]\n",
      "epoch:28 step:21945 [D loss: 0.821791, acc: 54.69%] [G loss: 5.631823]\n",
      "epoch:28 step:21946 [D loss: 0.316885, acc: 81.25%] [G loss: 4.857551]\n",
      "epoch:28 step:21947 [D loss: 0.643534, acc: 62.50%] [G loss: 4.439178]\n",
      "epoch:28 step:21948 [D loss: 0.388336, acc: 87.50%] [G loss: 5.021809]\n",
      "epoch:28 step:21949 [D loss: 0.151727, acc: 97.66%] [G loss: 4.045347]\n",
      "epoch:28 step:21950 [D loss: 0.646927, acc: 55.47%] [G loss: 4.653906]\n",
      "epoch:28 step:21951 [D loss: 0.426770, acc: 75.00%] [G loss: 5.514082]\n",
      "epoch:28 step:21952 [D loss: 0.545689, acc: 62.50%] [G loss: 6.890945]\n",
      "epoch:28 step:21953 [D loss: 0.300417, acc: 92.19%] [G loss: 4.428687]\n",
      "epoch:28 step:21954 [D loss: 0.561909, acc: 68.75%] [G loss: 5.517636]\n",
      "epoch:28 step:21955 [D loss: 0.278511, acc: 94.53%] [G loss: 3.672908]\n",
      "epoch:28 step:21956 [D loss: 0.671218, acc: 60.16%] [G loss: 3.723657]\n",
      "epoch:28 step:21957 [D loss: 0.113446, acc: 98.44%] [G loss: 6.967220]\n",
      "epoch:28 step:21958 [D loss: 0.578133, acc: 68.75%] [G loss: 4.170405]\n",
      "epoch:28 step:21959 [D loss: 0.152673, acc: 96.09%] [G loss: 5.577962]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:21960 [D loss: 0.187505, acc: 99.22%] [G loss: 5.376189]\n",
      "epoch:28 step:21961 [D loss: 0.692725, acc: 55.47%] [G loss: 4.428794]\n",
      "epoch:28 step:21962 [D loss: 0.214150, acc: 98.44%] [G loss: 4.001041]\n",
      "epoch:28 step:21963 [D loss: 0.257784, acc: 96.88%] [G loss: 3.455226]\n",
      "epoch:28 step:21964 [D loss: 0.945957, acc: 39.84%] [G loss: 3.618016]\n",
      "epoch:28 step:21965 [D loss: 0.850451, acc: 46.09%] [G loss: 3.337334]\n",
      "epoch:28 step:21966 [D loss: 0.524950, acc: 76.56%] [G loss: 4.719997]\n",
      "epoch:28 step:21967 [D loss: 1.471661, acc: 20.31%] [G loss: 4.289852]\n",
      "epoch:28 step:21968 [D loss: 0.242061, acc: 96.88%] [G loss: 3.676551]\n",
      "epoch:28 step:21969 [D loss: 0.162613, acc: 98.44%] [G loss: 4.900712]\n",
      "epoch:28 step:21970 [D loss: 0.151298, acc: 97.66%] [G loss: 4.937836]\n",
      "epoch:28 step:21971 [D loss: 1.122939, acc: 32.81%] [G loss: 2.814213]\n",
      "epoch:28 step:21972 [D loss: 0.165518, acc: 98.44%] [G loss: 4.483412]\n",
      "epoch:28 step:21973 [D loss: 0.118368, acc: 98.44%] [G loss: 3.389161]\n",
      "epoch:28 step:21974 [D loss: 0.694488, acc: 56.25%] [G loss: 4.609974]\n",
      "epoch:28 step:21975 [D loss: 0.525814, acc: 78.12%] [G loss: 4.059477]\n",
      "epoch:28 step:21976 [D loss: 0.571639, acc: 74.22%] [G loss: 3.926352]\n",
      "epoch:28 step:21977 [D loss: 1.929583, acc: 9.38%] [G loss: 3.268687]\n",
      "epoch:28 step:21978 [D loss: 0.542437, acc: 78.12%] [G loss: 3.788384]\n",
      "epoch:28 step:21979 [D loss: 0.408363, acc: 78.91%] [G loss: 5.091357]\n",
      "epoch:28 step:21980 [D loss: 0.408162, acc: 84.38%] [G loss: 3.681071]\n",
      "epoch:28 step:21981 [D loss: 0.372737, acc: 90.62%] [G loss: 4.425996]\n",
      "epoch:28 step:21982 [D loss: 0.393282, acc: 76.56%] [G loss: 3.432757]\n",
      "epoch:28 step:21983 [D loss: 0.135782, acc: 97.66%] [G loss: 7.651731]\n",
      "epoch:28 step:21984 [D loss: 0.488495, acc: 72.66%] [G loss: 4.071664]\n",
      "epoch:28 step:21985 [D loss: 0.398453, acc: 85.94%] [G loss: 3.232333]\n",
      "epoch:28 step:21986 [D loss: 0.195589, acc: 97.66%] [G loss: 3.694907]\n",
      "epoch:28 step:21987 [D loss: 0.402526, acc: 86.72%] [G loss: 5.659714]\n",
      "epoch:28 step:21988 [D loss: 0.136282, acc: 100.00%] [G loss: 5.707875]\n",
      "epoch:28 step:21989 [D loss: 0.186112, acc: 100.00%] [G loss: 5.205984]\n",
      "epoch:28 step:21990 [D loss: 0.092241, acc: 100.00%] [G loss: 7.271545]\n",
      "epoch:28 step:21991 [D loss: 0.112623, acc: 99.22%] [G loss: 5.255537]\n",
      "epoch:28 step:21992 [D loss: 0.422213, acc: 78.91%] [G loss: 3.213593]\n",
      "epoch:28 step:21993 [D loss: 0.390525, acc: 86.72%] [G loss: 2.200690]\n",
      "epoch:28 step:21994 [D loss: 0.604590, acc: 67.19%] [G loss: 3.083490]\n",
      "epoch:28 step:21995 [D loss: 0.867297, acc: 50.78%] [G loss: 4.304111]\n",
      "epoch:28 step:21996 [D loss: 0.143693, acc: 99.22%] [G loss: 3.820811]\n",
      "epoch:28 step:21997 [D loss: 0.744370, acc: 54.69%] [G loss: 5.426531]\n",
      "epoch:28 step:21998 [D loss: 0.746885, acc: 55.47%] [G loss: 5.643941]\n",
      "epoch:28 step:21999 [D loss: 0.600500, acc: 60.16%] [G loss: 3.867589]\n",
      "epoch:28 step:22000 [D loss: 0.257576, acc: 90.62%] [G loss: 3.609408]\n",
      "epoch:28 step:22001 [D loss: 0.485769, acc: 67.19%] [G loss: 4.742023]\n",
      "epoch:28 step:22002 [D loss: 0.111885, acc: 100.00%] [G loss: 4.965460]\n",
      "epoch:28 step:22003 [D loss: 0.464310, acc: 69.53%] [G loss: 5.012018]\n",
      "epoch:28 step:22004 [D loss: 0.123588, acc: 100.00%] [G loss: 8.841223]\n",
      "epoch:28 step:22005 [D loss: 0.454173, acc: 73.44%] [G loss: 3.709461]\n",
      "epoch:28 step:22006 [D loss: 0.164554, acc: 96.88%] [G loss: 5.358744]\n",
      "epoch:28 step:22007 [D loss: 0.474696, acc: 75.00%] [G loss: 3.627982]\n",
      "epoch:28 step:22008 [D loss: 0.356344, acc: 92.97%] [G loss: 3.653375]\n",
      "epoch:28 step:22009 [D loss: 1.541178, acc: 28.12%] [G loss: 2.025733]\n",
      "epoch:28 step:22010 [D loss: 0.467019, acc: 70.31%] [G loss: 5.943967]\n",
      "epoch:28 step:22011 [D loss: 0.764740, acc: 53.91%] [G loss: 4.442659]\n",
      "epoch:28 step:22012 [D loss: 0.273533, acc: 94.53%] [G loss: 4.608858]\n",
      "epoch:28 step:22013 [D loss: 0.169090, acc: 99.22%] [G loss: 4.914232]\n",
      "epoch:28 step:22014 [D loss: 0.498518, acc: 72.66%] [G loss: 3.553438]\n",
      "epoch:28 step:22015 [D loss: 0.198496, acc: 98.44%] [G loss: 4.051885]\n",
      "epoch:28 step:22016 [D loss: 0.941466, acc: 46.88%] [G loss: 4.081083]\n",
      "epoch:28 step:22017 [D loss: 0.359951, acc: 78.91%] [G loss: 3.811734]\n",
      "epoch:28 step:22018 [D loss: 0.351913, acc: 92.19%] [G loss: 2.922224]\n",
      "epoch:28 step:22019 [D loss: 0.495471, acc: 68.75%] [G loss: 3.662314]\n",
      "epoch:28 step:22020 [D loss: 0.471319, acc: 81.25%] [G loss: 5.987603]\n",
      "epoch:28 step:22021 [D loss: 0.412146, acc: 74.22%] [G loss: 6.209063]\n",
      "epoch:28 step:22022 [D loss: 0.057618, acc: 100.00%] [G loss: 5.318282]\n",
      "epoch:28 step:22023 [D loss: 0.131306, acc: 100.00%] [G loss: 3.184368]\n",
      "epoch:28 step:22024 [D loss: 0.055781, acc: 100.00%] [G loss: 4.813263]\n",
      "epoch:28 step:22025 [D loss: 0.148261, acc: 97.66%] [G loss: 3.916101]\n",
      "epoch:28 step:22026 [D loss: 0.280279, acc: 96.09%] [G loss: 4.965247]\n",
      "epoch:28 step:22027 [D loss: 0.146312, acc: 98.44%] [G loss: 5.526278]\n",
      "epoch:28 step:22028 [D loss: 0.411150, acc: 73.44%] [G loss: 3.450723]\n",
      "epoch:28 step:22029 [D loss: 0.397752, acc: 86.72%] [G loss: 4.369003]\n",
      "epoch:28 step:22030 [D loss: 0.307016, acc: 93.75%] [G loss: 4.223454]\n",
      "epoch:28 step:22031 [D loss: 0.615002, acc: 57.81%] [G loss: 5.215109]\n",
      "epoch:28 step:22032 [D loss: 0.257548, acc: 96.88%] [G loss: 4.259112]\n",
      "epoch:28 step:22033 [D loss: 0.432810, acc: 75.00%] [G loss: 3.896052]\n",
      "epoch:28 step:22034 [D loss: 0.535727, acc: 65.62%] [G loss: 4.859596]\n",
      "epoch:28 step:22035 [D loss: 0.560846, acc: 70.31%] [G loss: 3.013651]\n",
      "epoch:28 step:22036 [D loss: 0.302558, acc: 92.97%] [G loss: 2.776595]\n",
      "epoch:28 step:22037 [D loss: 1.273685, acc: 25.78%] [G loss: 5.373046]\n",
      "epoch:28 step:22038 [D loss: 0.358287, acc: 89.84%] [G loss: 3.170727]\n",
      "epoch:28 step:22039 [D loss: 1.594673, acc: 10.16%] [G loss: 4.275050]\n",
      "epoch:28 step:22040 [D loss: 0.434377, acc: 85.16%] [G loss: 6.311310]\n",
      "epoch:28 step:22041 [D loss: 0.478077, acc: 73.44%] [G loss: 4.619805]\n",
      "epoch:28 step:22042 [D loss: 0.083571, acc: 98.44%] [G loss: 3.452015]\n",
      "epoch:28 step:22043 [D loss: 0.320052, acc: 87.50%] [G loss: 3.184095]\n",
      "epoch:28 step:22044 [D loss: 0.619779, acc: 65.62%] [G loss: 5.611291]\n",
      "epoch:28 step:22045 [D loss: 0.057017, acc: 100.00%] [G loss: 4.229253]\n",
      "epoch:28 step:22046 [D loss: 0.268235, acc: 98.44%] [G loss: 3.002229]\n",
      "epoch:28 step:22047 [D loss: 0.558962, acc: 71.09%] [G loss: 4.695992]\n",
      "epoch:28 step:22048 [D loss: 0.665444, acc: 60.16%] [G loss: 2.770511]\n",
      "epoch:28 step:22049 [D loss: 0.075467, acc: 100.00%] [G loss: 5.406512]\n",
      "epoch:28 step:22050 [D loss: 0.601271, acc: 66.41%] [G loss: 4.394337]\n",
      "epoch:28 step:22051 [D loss: 1.116372, acc: 20.31%] [G loss: 4.619434]\n",
      "epoch:28 step:22052 [D loss: 0.180525, acc: 97.66%] [G loss: 5.370044]\n",
      "epoch:28 step:22053 [D loss: 0.563856, acc: 69.53%] [G loss: 2.475939]\n",
      "epoch:28 step:22054 [D loss: 0.432225, acc: 71.09%] [G loss: 4.890328]\n",
      "epoch:28 step:22055 [D loss: 0.988551, acc: 37.50%] [G loss: 4.712646]\n",
      "epoch:28 step:22056 [D loss: 0.423033, acc: 87.50%] [G loss: 2.611952]\n",
      "epoch:28 step:22057 [D loss: 0.152769, acc: 100.00%] [G loss: 4.431849]\n",
      "epoch:28 step:22058 [D loss: 1.574389, acc: 50.00%] [G loss: 5.629760]\n",
      "epoch:28 step:22059 [D loss: 1.291971, acc: 45.31%] [G loss: 2.849855]\n",
      "epoch:28 step:22060 [D loss: 0.055662, acc: 100.00%] [G loss: 3.609638]\n",
      "epoch:28 step:22061 [D loss: 0.693314, acc: 56.25%] [G loss: 3.258463]\n",
      "epoch:28 step:22062 [D loss: 0.689417, acc: 60.94%] [G loss: 3.896713]\n",
      "epoch:28 step:22063 [D loss: 0.440785, acc: 87.50%] [G loss: 5.939784]\n",
      "epoch:28 step:22064 [D loss: 0.211318, acc: 97.66%] [G loss: 4.858943]\n",
      "epoch:28 step:22065 [D loss: 0.592442, acc: 70.31%] [G loss: 5.074809]\n",
      "epoch:28 step:22066 [D loss: 0.117155, acc: 99.22%] [G loss: 4.692483]\n",
      "epoch:28 step:22067 [D loss: 0.794031, acc: 43.75%] [G loss: 2.641479]\n",
      "epoch:28 step:22068 [D loss: 0.109256, acc: 99.22%] [G loss: 3.890548]\n",
      "epoch:28 step:22069 [D loss: 0.683876, acc: 61.72%] [G loss: 4.533590]\n",
      "epoch:28 step:22070 [D loss: 0.263475, acc: 95.31%] [G loss: 4.150631]\n",
      "epoch:28 step:22071 [D loss: 0.612654, acc: 64.06%] [G loss: 1.878383]\n",
      "epoch:28 step:22072 [D loss: 0.449036, acc: 75.00%] [G loss: 2.200680]\n",
      "epoch:28 step:22073 [D loss: 0.937819, acc: 52.34%] [G loss: 3.263311]\n",
      "epoch:28 step:22074 [D loss: 0.489793, acc: 77.34%] [G loss: 5.730137]\n",
      "epoch:28 step:22075 [D loss: 0.824275, acc: 46.09%] [G loss: 3.310058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22076 [D loss: 0.216361, acc: 96.88%] [G loss: 5.924606]\n",
      "epoch:28 step:22077 [D loss: 0.554799, acc: 75.00%] [G loss: 3.812881]\n",
      "epoch:28 step:22078 [D loss: 0.344101, acc: 94.53%] [G loss: 2.410106]\n",
      "epoch:28 step:22079 [D loss: 0.777625, acc: 53.91%] [G loss: 4.259477]\n",
      "epoch:28 step:22080 [D loss: 1.059628, acc: 44.53%] [G loss: 3.986722]\n",
      "epoch:28 step:22081 [D loss: 1.015903, acc: 50.78%] [G loss: 4.372760]\n",
      "epoch:28 step:22082 [D loss: 0.233242, acc: 94.53%] [G loss: 2.033792]\n",
      "epoch:28 step:22083 [D loss: 0.443751, acc: 85.16%] [G loss: 3.611825]\n",
      "epoch:28 step:22084 [D loss: 0.498858, acc: 78.91%] [G loss: 4.345822]\n",
      "epoch:28 step:22085 [D loss: 0.533206, acc: 71.88%] [G loss: 3.200872]\n",
      "epoch:28 step:22086 [D loss: 0.121620, acc: 100.00%] [G loss: 5.919520]\n",
      "epoch:28 step:22087 [D loss: 0.237364, acc: 92.97%] [G loss: 2.880395]\n",
      "epoch:28 step:22088 [D loss: 0.418016, acc: 87.50%] [G loss: 4.282814]\n",
      "epoch:28 step:22089 [D loss: 1.183118, acc: 19.53%] [G loss: 2.653046]\n",
      "epoch:28 step:22090 [D loss: 0.294254, acc: 94.53%] [G loss: 2.957392]\n",
      "epoch:28 step:22091 [D loss: 0.500044, acc: 76.56%] [G loss: 2.401011]\n",
      "epoch:28 step:22092 [D loss: 0.572764, acc: 64.84%] [G loss: 3.474973]\n",
      "epoch:28 step:22093 [D loss: 0.136593, acc: 99.22%] [G loss: 3.352398]\n",
      "epoch:28 step:22094 [D loss: 0.879323, acc: 51.56%] [G loss: 2.750924]\n",
      "epoch:28 step:22095 [D loss: 0.420651, acc: 88.28%] [G loss: 6.861409]\n",
      "epoch:28 step:22096 [D loss: 0.459310, acc: 82.03%] [G loss: 5.238398]\n",
      "epoch:28 step:22097 [D loss: 0.254983, acc: 91.41%] [G loss: 3.446672]\n",
      "epoch:28 step:22098 [D loss: 0.221159, acc: 99.22%] [G loss: 4.666736]\n",
      "epoch:28 step:22099 [D loss: 0.545513, acc: 64.06%] [G loss: 2.865899]\n",
      "epoch:28 step:22100 [D loss: 0.388854, acc: 83.59%] [G loss: 4.439536]\n",
      "epoch:28 step:22101 [D loss: 0.173634, acc: 96.09%] [G loss: 2.145250]\n",
      "epoch:28 step:22102 [D loss: 0.325058, acc: 90.62%] [G loss: 4.641786]\n",
      "epoch:28 step:22103 [D loss: 0.461598, acc: 73.44%] [G loss: 4.758931]\n",
      "epoch:28 step:22104 [D loss: 0.103874, acc: 99.22%] [G loss: 4.253224]\n",
      "epoch:28 step:22105 [D loss: 0.203529, acc: 98.44%] [G loss: 3.174256]\n",
      "epoch:28 step:22106 [D loss: 0.729307, acc: 53.91%] [G loss: 6.169062]\n",
      "epoch:28 step:22107 [D loss: 0.284279, acc: 98.44%] [G loss: 4.299374]\n",
      "epoch:28 step:22108 [D loss: 0.661464, acc: 57.81%] [G loss: 6.564226]\n",
      "epoch:28 step:22109 [D loss: 0.354709, acc: 89.06%] [G loss: 4.223045]\n",
      "epoch:28 step:22110 [D loss: 0.235892, acc: 96.88%] [G loss: 2.790906]\n",
      "epoch:28 step:22111 [D loss: 0.373524, acc: 87.50%] [G loss: 2.673478]\n",
      "epoch:28 step:22112 [D loss: 0.253789, acc: 97.66%] [G loss: 4.185843]\n",
      "epoch:28 step:22113 [D loss: 0.371721, acc: 89.06%] [G loss: 2.822332]\n",
      "epoch:28 step:22114 [D loss: 0.350872, acc: 90.62%] [G loss: 4.087989]\n",
      "epoch:28 step:22115 [D loss: 0.584016, acc: 66.41%] [G loss: 4.810468]\n",
      "epoch:28 step:22116 [D loss: 0.419441, acc: 89.06%] [G loss: 2.340962]\n",
      "epoch:28 step:22117 [D loss: 0.199617, acc: 98.44%] [G loss: 3.838161]\n",
      "epoch:28 step:22118 [D loss: 0.205445, acc: 99.22%] [G loss: 3.689585]\n",
      "epoch:28 step:22119 [D loss: 0.052506, acc: 100.00%] [G loss: 4.414182]\n",
      "epoch:28 step:22120 [D loss: 0.620991, acc: 65.62%] [G loss: 5.712665]\n",
      "epoch:28 step:22121 [D loss: 0.310246, acc: 90.62%] [G loss: 3.497956]\n",
      "epoch:28 step:22122 [D loss: 0.298103, acc: 95.31%] [G loss: 4.975516]\n",
      "epoch:28 step:22123 [D loss: 0.496258, acc: 67.19%] [G loss: 4.723845]\n",
      "epoch:28 step:22124 [D loss: 0.358683, acc: 88.28%] [G loss: 3.702563]\n",
      "epoch:28 step:22125 [D loss: 0.277014, acc: 93.75%] [G loss: 6.154498]\n",
      "epoch:28 step:22126 [D loss: 0.512898, acc: 71.88%] [G loss: 5.864523]\n",
      "epoch:28 step:22127 [D loss: 0.178499, acc: 98.44%] [G loss: 2.572686]\n",
      "epoch:28 step:22128 [D loss: 0.211090, acc: 99.22%] [G loss: 3.823645]\n",
      "epoch:28 step:22129 [D loss: 0.499436, acc: 75.78%] [G loss: 4.357422]\n",
      "epoch:28 step:22130 [D loss: 0.136940, acc: 100.00%] [G loss: 7.067212]\n",
      "epoch:28 step:22131 [D loss: 0.303927, acc: 88.28%] [G loss: 4.738911]\n",
      "epoch:28 step:22132 [D loss: 0.360663, acc: 80.47%] [G loss: 4.316607]\n",
      "epoch:28 step:22133 [D loss: 0.418055, acc: 71.09%] [G loss: 4.200269]\n",
      "epoch:28 step:22134 [D loss: 1.710991, acc: 50.00%] [G loss: 2.503070]\n",
      "epoch:28 step:22135 [D loss: 0.930074, acc: 40.62%] [G loss: 4.572062]\n",
      "epoch:28 step:22136 [D loss: 0.591492, acc: 62.50%] [G loss: 4.011760]\n",
      "epoch:28 step:22137 [D loss: 0.892671, acc: 50.78%] [G loss: 4.418283]\n",
      "epoch:28 step:22138 [D loss: 0.154631, acc: 100.00%] [G loss: 4.739644]\n",
      "epoch:28 step:22139 [D loss: 0.384008, acc: 74.22%] [G loss: 3.030237]\n",
      "epoch:28 step:22140 [D loss: 0.473075, acc: 71.09%] [G loss: 5.188166]\n",
      "epoch:28 step:22141 [D loss: 0.393825, acc: 88.28%] [G loss: 3.746715]\n",
      "epoch:28 step:22142 [D loss: 0.354706, acc: 83.59%] [G loss: 4.909775]\n",
      "epoch:28 step:22143 [D loss: 0.410111, acc: 83.59%] [G loss: 2.087362]\n",
      "epoch:28 step:22144 [D loss: 0.293506, acc: 94.53%] [G loss: 5.027566]\n",
      "epoch:28 step:22145 [D loss: 0.970355, acc: 39.84%] [G loss: 5.753530]\n",
      "epoch:28 step:22146 [D loss: 0.282326, acc: 91.41%] [G loss: 4.854980]\n",
      "epoch:28 step:22147 [D loss: 0.315085, acc: 94.53%] [G loss: 3.171344]\n",
      "epoch:28 step:22148 [D loss: 0.300815, acc: 88.28%] [G loss: 4.625491]\n",
      "epoch:28 step:22149 [D loss: 0.278622, acc: 96.09%] [G loss: 4.407478]\n",
      "epoch:28 step:22150 [D loss: 0.345959, acc: 92.19%] [G loss: 3.530117]\n",
      "epoch:28 step:22151 [D loss: 0.709511, acc: 59.38%] [G loss: 3.489625]\n",
      "epoch:28 step:22152 [D loss: 0.658559, acc: 60.16%] [G loss: 5.477669]\n",
      "epoch:28 step:22153 [D loss: 0.340734, acc: 93.75%] [G loss: 2.495258]\n",
      "epoch:28 step:22154 [D loss: 0.338713, acc: 88.28%] [G loss: 4.199933]\n",
      "epoch:28 step:22155 [D loss: 0.703520, acc: 52.34%] [G loss: 4.194705]\n",
      "epoch:28 step:22156 [D loss: 0.350213, acc: 86.72%] [G loss: 4.903755]\n",
      "epoch:28 step:22157 [D loss: 0.228405, acc: 97.66%] [G loss: 3.572931]\n",
      "epoch:28 step:22158 [D loss: 0.282425, acc: 96.88%] [G loss: 4.831396]\n",
      "epoch:28 step:22159 [D loss: 0.866176, acc: 33.59%] [G loss: 3.948251]\n",
      "epoch:28 step:22160 [D loss: 0.134170, acc: 96.88%] [G loss: 4.817089]\n",
      "epoch:28 step:22161 [D loss: 0.561789, acc: 68.75%] [G loss: 4.032374]\n",
      "epoch:28 step:22162 [D loss: 0.288652, acc: 91.41%] [G loss: 3.941895]\n",
      "epoch:28 step:22163 [D loss: 0.442955, acc: 71.88%] [G loss: 3.917006]\n",
      "epoch:28 step:22164 [D loss: 0.186522, acc: 99.22%] [G loss: 4.915143]\n",
      "epoch:28 step:22165 [D loss: 0.896254, acc: 53.91%] [G loss: 5.055697]\n",
      "epoch:28 step:22166 [D loss: 0.429941, acc: 74.22%] [G loss: 4.057523]\n",
      "epoch:28 step:22167 [D loss: 0.330659, acc: 92.19%] [G loss: 5.938503]\n",
      "epoch:28 step:22168 [D loss: 0.237807, acc: 96.88%] [G loss: 3.982178]\n",
      "epoch:28 step:22169 [D loss: 0.548068, acc: 67.19%] [G loss: 4.613579]\n",
      "epoch:28 step:22170 [D loss: 0.715150, acc: 60.94%] [G loss: 2.118660]\n",
      "epoch:28 step:22171 [D loss: 0.441296, acc: 82.03%] [G loss: 2.865616]\n",
      "epoch:28 step:22172 [D loss: 0.922216, acc: 46.09%] [G loss: 4.835716]\n",
      "epoch:28 step:22173 [D loss: 0.495224, acc: 73.44%] [G loss: 3.106626]\n",
      "epoch:28 step:22174 [D loss: 1.195115, acc: 47.66%] [G loss: 4.272723]\n",
      "epoch:28 step:22175 [D loss: 0.332543, acc: 86.72%] [G loss: 3.408042]\n",
      "epoch:28 step:22176 [D loss: 0.169935, acc: 98.44%] [G loss: 5.707838]\n",
      "epoch:28 step:22177 [D loss: 0.653567, acc: 62.50%] [G loss: 4.343691]\n",
      "epoch:28 step:22178 [D loss: 0.370193, acc: 80.47%] [G loss: 3.278588]\n",
      "epoch:28 step:22179 [D loss: 0.157806, acc: 100.00%] [G loss: 3.786939]\n",
      "epoch:28 step:22180 [D loss: 0.932739, acc: 46.88%] [G loss: 5.415655]\n",
      "epoch:28 step:22181 [D loss: 0.463897, acc: 73.44%] [G loss: 4.362778]\n",
      "epoch:28 step:22182 [D loss: 0.346657, acc: 83.59%] [G loss: 4.618812]\n",
      "epoch:28 step:22183 [D loss: 0.059218, acc: 100.00%] [G loss: 6.171303]\n",
      "epoch:28 step:22184 [D loss: 0.313037, acc: 89.06%] [G loss: 4.593885]\n",
      "epoch:28 step:22185 [D loss: 0.285390, acc: 92.19%] [G loss: 4.617954]\n",
      "epoch:28 step:22186 [D loss: 0.366318, acc: 90.62%] [G loss: 3.224683]\n",
      "epoch:28 step:22187 [D loss: 0.320418, acc: 87.50%] [G loss: 4.789287]\n",
      "epoch:28 step:22188 [D loss: 0.901462, acc: 37.50%] [G loss: 4.413625]\n",
      "epoch:28 step:22189 [D loss: 0.282911, acc: 92.97%] [G loss: 2.441749]\n",
      "epoch:28 step:22190 [D loss: 0.285152, acc: 87.50%] [G loss: 5.879623]\n",
      "epoch:28 step:22191 [D loss: 0.201840, acc: 98.44%] [G loss: 3.636290]\n",
      "epoch:28 step:22192 [D loss: 0.217913, acc: 98.44%] [G loss: 5.167943]\n",
      "epoch:28 step:22193 [D loss: 0.433290, acc: 87.50%] [G loss: 6.602630]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22194 [D loss: 0.368097, acc: 89.84%] [G loss: 4.087798]\n",
      "epoch:28 step:22195 [D loss: 0.368311, acc: 82.03%] [G loss: 5.683740]\n",
      "epoch:28 step:22196 [D loss: 0.383162, acc: 80.47%] [G loss: 4.915329]\n",
      "epoch:28 step:22197 [D loss: 0.604098, acc: 59.38%] [G loss: 3.176588]\n",
      "epoch:28 step:22198 [D loss: 0.663862, acc: 58.59%] [G loss: 3.987300]\n",
      "epoch:28 step:22199 [D loss: 0.183268, acc: 98.44%] [G loss: 3.908137]\n",
      "epoch:28 step:22200 [D loss: 0.605011, acc: 59.38%] [G loss: 4.711813]\n",
      "epoch:28 step:22201 [D loss: 0.033538, acc: 100.00%] [G loss: 6.393778]\n",
      "epoch:28 step:22202 [D loss: 0.623710, acc: 62.50%] [G loss: 4.471885]\n",
      "epoch:28 step:22203 [D loss: 0.376462, acc: 81.25%] [G loss: 5.337767]\n",
      "epoch:28 step:22204 [D loss: 1.196621, acc: 26.56%] [G loss: 3.871694]\n",
      "epoch:28 step:22205 [D loss: 0.363005, acc: 93.75%] [G loss: 5.448000]\n",
      "epoch:28 step:22206 [D loss: 1.110903, acc: 21.09%] [G loss: 3.794047]\n",
      "epoch:28 step:22207 [D loss: 0.197376, acc: 99.22%] [G loss: 5.992348]\n",
      "epoch:28 step:22208 [D loss: 0.785994, acc: 53.91%] [G loss: 5.285500]\n",
      "epoch:28 step:22209 [D loss: 0.446549, acc: 82.03%] [G loss: 4.631993]\n",
      "epoch:28 step:22210 [D loss: 0.475193, acc: 80.47%] [G loss: 4.395780]\n",
      "epoch:28 step:22211 [D loss: 0.748751, acc: 53.12%] [G loss: 4.500396]\n",
      "epoch:28 step:22212 [D loss: 0.071979, acc: 100.00%] [G loss: 6.016363]\n",
      "epoch:28 step:22213 [D loss: 0.264251, acc: 93.75%] [G loss: 4.570768]\n",
      "epoch:28 step:22214 [D loss: 0.196908, acc: 92.97%] [G loss: 4.858070]\n",
      "epoch:28 step:22215 [D loss: 0.248171, acc: 91.41%] [G loss: 5.439401]\n",
      "epoch:28 step:22216 [D loss: 0.615450, acc: 59.38%] [G loss: 3.230633]\n",
      "epoch:28 step:22217 [D loss: 0.250167, acc: 96.09%] [G loss: 3.022872]\n",
      "epoch:28 step:22218 [D loss: 0.802686, acc: 55.47%] [G loss: 6.859357]\n",
      "epoch:28 step:22219 [D loss: 1.200931, acc: 47.66%] [G loss: 2.352628]\n",
      "epoch:28 step:22220 [D loss: 0.132096, acc: 100.00%] [G loss: 4.712069]\n",
      "epoch:28 step:22221 [D loss: 0.491165, acc: 78.12%] [G loss: 3.450147]\n",
      "epoch:28 step:22222 [D loss: 0.455764, acc: 83.59%] [G loss: 4.654738]\n",
      "epoch:28 step:22223 [D loss: 0.261150, acc: 96.88%] [G loss: 4.390950]\n",
      "epoch:28 step:22224 [D loss: 0.183880, acc: 99.22%] [G loss: 2.280799]\n",
      "epoch:28 step:22225 [D loss: 0.408459, acc: 89.06%] [G loss: 4.565774]\n",
      "epoch:28 step:22226 [D loss: 0.190621, acc: 96.88%] [G loss: 5.330676]\n",
      "epoch:28 step:22227 [D loss: 0.393428, acc: 87.50%] [G loss: 3.191773]\n",
      "epoch:28 step:22228 [D loss: 0.503839, acc: 77.34%] [G loss: 5.151981]\n",
      "epoch:28 step:22229 [D loss: 0.996207, acc: 50.00%] [G loss: 2.918692]\n",
      "epoch:28 step:22230 [D loss: 0.068477, acc: 100.00%] [G loss: 2.987220]\n",
      "epoch:28 step:22231 [D loss: 0.308610, acc: 85.16%] [G loss: 3.143259]\n",
      "epoch:28 step:22232 [D loss: 0.426521, acc: 76.56%] [G loss: 4.011220]\n",
      "epoch:28 step:22233 [D loss: 0.105899, acc: 99.22%] [G loss: 3.895064]\n",
      "epoch:28 step:22234 [D loss: 0.380307, acc: 78.91%] [G loss: 5.213261]\n",
      "epoch:28 step:22235 [D loss: 1.197175, acc: 46.09%] [G loss: 3.167647]\n",
      "epoch:28 step:22236 [D loss: 0.554269, acc: 76.56%] [G loss: 3.009162]\n",
      "epoch:28 step:22237 [D loss: 0.357841, acc: 89.84%] [G loss: 4.235547]\n",
      "epoch:28 step:22238 [D loss: 0.213449, acc: 98.44%] [G loss: 5.618354]\n",
      "epoch:28 step:22239 [D loss: 0.528839, acc: 67.97%] [G loss: 4.200494]\n",
      "epoch:28 step:22240 [D loss: 0.137022, acc: 98.44%] [G loss: 3.238540]\n",
      "epoch:28 step:22241 [D loss: 0.180493, acc: 98.44%] [G loss: 2.289610]\n",
      "epoch:28 step:22242 [D loss: 0.358916, acc: 91.41%] [G loss: 4.204685]\n",
      "epoch:28 step:22243 [D loss: 0.640989, acc: 67.97%] [G loss: 4.224589]\n",
      "epoch:28 step:22244 [D loss: 0.181656, acc: 97.66%] [G loss: 4.938879]\n",
      "epoch:28 step:22245 [D loss: 0.499593, acc: 69.53%] [G loss: 4.298441]\n",
      "epoch:28 step:22246 [D loss: 0.130623, acc: 99.22%] [G loss: 4.026061]\n",
      "epoch:28 step:22247 [D loss: 0.103548, acc: 100.00%] [G loss: 3.452799]\n",
      "epoch:28 step:22248 [D loss: 0.331836, acc: 89.84%] [G loss: 5.020610]\n",
      "epoch:28 step:22249 [D loss: 0.448898, acc: 71.09%] [G loss: 3.186029]\n",
      "epoch:28 step:22250 [D loss: 1.073053, acc: 50.00%] [G loss: 6.026391]\n",
      "epoch:28 step:22251 [D loss: 0.637205, acc: 63.28%] [G loss: 3.124358]\n",
      "epoch:28 step:22252 [D loss: 0.499992, acc: 64.06%] [G loss: 5.018662]\n",
      "epoch:28 step:22253 [D loss: 0.990115, acc: 47.66%] [G loss: 2.427231]\n",
      "epoch:28 step:22254 [D loss: 0.368493, acc: 86.72%] [G loss: 3.918286]\n",
      "epoch:28 step:22255 [D loss: 0.905398, acc: 35.94%] [G loss: 5.380098]\n",
      "epoch:28 step:22256 [D loss: 0.531562, acc: 76.56%] [G loss: 4.119082]\n",
      "epoch:28 step:22257 [D loss: 0.629232, acc: 56.25%] [G loss: 2.724059]\n",
      "epoch:28 step:22258 [D loss: 0.154972, acc: 98.44%] [G loss: 4.028167]\n",
      "epoch:28 step:22259 [D loss: 0.706378, acc: 54.69%] [G loss: 2.672382]\n",
      "epoch:28 step:22260 [D loss: 0.424757, acc: 83.59%] [G loss: 3.159263]\n",
      "epoch:28 step:22261 [D loss: 0.479086, acc: 72.66%] [G loss: 3.599797]\n",
      "epoch:28 step:22262 [D loss: 0.539773, acc: 67.19%] [G loss: 6.176109]\n",
      "epoch:28 step:22263 [D loss: 0.513190, acc: 67.97%] [G loss: 3.844166]\n",
      "epoch:28 step:22264 [D loss: 0.500171, acc: 70.31%] [G loss: 3.766269]\n",
      "epoch:28 step:22265 [D loss: 0.505391, acc: 69.53%] [G loss: 3.944341]\n",
      "epoch:28 step:22266 [D loss: 0.289485, acc: 96.09%] [G loss: 4.190087]\n",
      "epoch:28 step:22267 [D loss: 0.482367, acc: 78.91%] [G loss: 3.245889]\n",
      "epoch:28 step:22268 [D loss: 0.401379, acc: 84.38%] [G loss: 5.516130]\n",
      "epoch:28 step:22269 [D loss: 0.041488, acc: 100.00%] [G loss: 5.430120]\n",
      "epoch:28 step:22270 [D loss: 0.179371, acc: 99.22%] [G loss: 4.528920]\n",
      "epoch:28 step:22271 [D loss: 0.451330, acc: 82.81%] [G loss: 4.612260]\n",
      "epoch:28 step:22272 [D loss: 0.655187, acc: 59.38%] [G loss: 2.684128]\n",
      "epoch:28 step:22273 [D loss: 0.980284, acc: 37.50%] [G loss: 5.483230]\n",
      "epoch:28 step:22274 [D loss: 0.243007, acc: 92.97%] [G loss: 4.881540]\n",
      "epoch:28 step:22275 [D loss: 0.666623, acc: 59.38%] [G loss: 3.645015]\n",
      "epoch:28 step:22276 [D loss: 0.466973, acc: 74.22%] [G loss: 4.492533]\n",
      "epoch:28 step:22277 [D loss: 0.675393, acc: 59.38%] [G loss: 3.988631]\n",
      "epoch:28 step:22278 [D loss: 0.485493, acc: 72.66%] [G loss: 3.958760]\n",
      "epoch:28 step:22279 [D loss: 0.508976, acc: 71.09%] [G loss: 5.507564]\n",
      "epoch:28 step:22280 [D loss: 0.134656, acc: 100.00%] [G loss: 5.773478]\n",
      "epoch:28 step:22281 [D loss: 0.214607, acc: 95.31%] [G loss: 5.265918]\n",
      "epoch:28 step:22282 [D loss: 0.303005, acc: 96.88%] [G loss: 4.211080]\n",
      "epoch:28 step:22283 [D loss: 0.189927, acc: 98.44%] [G loss: 4.342100]\n",
      "epoch:28 step:22284 [D loss: 0.512971, acc: 66.41%] [G loss: 4.580900]\n",
      "epoch:28 step:22285 [D loss: 0.126481, acc: 100.00%] [G loss: 3.695799]\n",
      "epoch:28 step:22286 [D loss: 0.054977, acc: 100.00%] [G loss: 4.550392]\n",
      "epoch:28 step:22287 [D loss: 0.898953, acc: 36.72%] [G loss: 4.089759]\n",
      "epoch:28 step:22288 [D loss: 0.235417, acc: 98.44%] [G loss: 3.936298]\n",
      "epoch:28 step:22289 [D loss: 0.328906, acc: 91.41%] [G loss: 4.127822]\n",
      "epoch:28 step:22290 [D loss: 0.200699, acc: 98.44%] [G loss: 3.284692]\n",
      "epoch:28 step:22291 [D loss: 0.616024, acc: 68.75%] [G loss: 3.531225]\n",
      "epoch:28 step:22292 [D loss: 0.897215, acc: 36.72%] [G loss: 3.819263]\n",
      "epoch:28 step:22293 [D loss: 0.181642, acc: 96.09%] [G loss: 3.996102]\n",
      "epoch:28 step:22294 [D loss: 0.432759, acc: 78.91%] [G loss: 4.719810]\n",
      "epoch:28 step:22295 [D loss: 0.531479, acc: 80.47%] [G loss: 5.318808]\n",
      "epoch:28 step:22296 [D loss: 0.306504, acc: 89.84%] [G loss: 4.176067]\n",
      "epoch:28 step:22297 [D loss: 0.182124, acc: 98.44%] [G loss: 5.012967]\n",
      "epoch:28 step:22298 [D loss: 0.209559, acc: 96.88%] [G loss: 5.133965]\n",
      "epoch:28 step:22299 [D loss: 0.473905, acc: 78.91%] [G loss: 5.636607]\n",
      "epoch:28 step:22300 [D loss: 0.553221, acc: 73.44%] [G loss: 4.859978]\n",
      "epoch:28 step:22301 [D loss: 0.779686, acc: 52.34%] [G loss: 5.654243]\n",
      "epoch:28 step:22302 [D loss: 0.155986, acc: 100.00%] [G loss: 3.573101]\n",
      "epoch:28 step:22303 [D loss: 0.254731, acc: 91.41%] [G loss: 4.498572]\n",
      "epoch:28 step:22304 [D loss: 0.820550, acc: 53.91%] [G loss: 5.905399]\n",
      "epoch:28 step:22305 [D loss: 0.721445, acc: 52.34%] [G loss: 4.535288]\n",
      "epoch:28 step:22306 [D loss: 0.377448, acc: 86.72%] [G loss: 5.666768]\n",
      "epoch:28 step:22307 [D loss: 0.569110, acc: 64.84%] [G loss: 4.876016]\n",
      "epoch:28 step:22308 [D loss: 1.230008, acc: 46.09%] [G loss: 3.480618]\n",
      "epoch:28 step:22309 [D loss: 0.255534, acc: 96.09%] [G loss: 3.433708]\n",
      "epoch:28 step:22310 [D loss: 0.682914, acc: 53.91%] [G loss: 4.430911]\n",
      "epoch:28 step:22311 [D loss: 0.221953, acc: 96.09%] [G loss: 5.328075]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22312 [D loss: 0.830129, acc: 46.88%] [G loss: 3.855507]\n",
      "epoch:28 step:22313 [D loss: 0.670818, acc: 52.34%] [G loss: 5.325744]\n",
      "epoch:28 step:22314 [D loss: 0.328309, acc: 89.84%] [G loss: 5.554633]\n",
      "epoch:28 step:22315 [D loss: 0.173848, acc: 98.44%] [G loss: 4.020278]\n",
      "epoch:28 step:22316 [D loss: 0.223678, acc: 95.31%] [G loss: 3.750403]\n",
      "epoch:28 step:22317 [D loss: 0.438197, acc: 81.25%] [G loss: 4.902437]\n",
      "epoch:28 step:22318 [D loss: 0.177059, acc: 99.22%] [G loss: 4.739160]\n",
      "epoch:28 step:22319 [D loss: 0.649844, acc: 60.94%] [G loss: 6.825602]\n",
      "epoch:28 step:22320 [D loss: 0.298167, acc: 95.31%] [G loss: 4.255782]\n",
      "epoch:28 step:22321 [D loss: 0.314769, acc: 94.53%] [G loss: 4.445126]\n",
      "epoch:28 step:22322 [D loss: 0.282096, acc: 95.31%] [G loss: 5.615504]\n",
      "epoch:28 step:22323 [D loss: 0.322024, acc: 81.25%] [G loss: 5.195454]\n",
      "epoch:28 step:22324 [D loss: 0.209500, acc: 96.09%] [G loss: 3.994884]\n",
      "epoch:28 step:22325 [D loss: 0.235317, acc: 98.44%] [G loss: 3.348377]\n",
      "epoch:28 step:22326 [D loss: 1.184168, acc: 50.00%] [G loss: 3.545715]\n",
      "epoch:28 step:22327 [D loss: 0.547362, acc: 72.66%] [G loss: 5.536791]\n",
      "epoch:28 step:22328 [D loss: 0.647299, acc: 57.81%] [G loss: 4.658629]\n",
      "epoch:28 step:22329 [D loss: 0.517945, acc: 64.06%] [G loss: 4.967604]\n",
      "epoch:28 step:22330 [D loss: 0.126817, acc: 99.22%] [G loss: 6.420702]\n",
      "epoch:28 step:22331 [D loss: 0.211864, acc: 96.88%] [G loss: 5.132849]\n",
      "epoch:28 step:22332 [D loss: 1.289083, acc: 12.50%] [G loss: 5.045954]\n",
      "epoch:28 step:22333 [D loss: 0.568412, acc: 68.75%] [G loss: 4.484402]\n",
      "epoch:28 step:22334 [D loss: 0.068748, acc: 100.00%] [G loss: 6.459064]\n",
      "epoch:28 step:22335 [D loss: 0.791498, acc: 50.78%] [G loss: 3.282278]\n",
      "epoch:28 step:22336 [D loss: 0.342050, acc: 89.84%] [G loss: 4.616934]\n",
      "epoch:28 step:22337 [D loss: 0.668632, acc: 57.81%] [G loss: 4.142939]\n",
      "epoch:28 step:22338 [D loss: 0.313698, acc: 89.06%] [G loss: 7.646848]\n",
      "epoch:28 step:22339 [D loss: 1.164121, acc: 48.44%] [G loss: 4.757748]\n",
      "epoch:28 step:22340 [D loss: 0.336832, acc: 89.06%] [G loss: 3.937397]\n",
      "epoch:28 step:22341 [D loss: 0.778360, acc: 53.91%] [G loss: 3.602706]\n",
      "epoch:28 step:22342 [D loss: 0.897281, acc: 53.12%] [G loss: 2.703578]\n",
      "epoch:28 step:22343 [D loss: 0.705027, acc: 57.03%] [G loss: 1.869832]\n",
      "epoch:28 step:22344 [D loss: 0.783791, acc: 50.78%] [G loss: 5.676532]\n",
      "epoch:28 step:22345 [D loss: 0.233699, acc: 96.09%] [G loss: 3.936403]\n",
      "epoch:28 step:22346 [D loss: 0.294656, acc: 96.88%] [G loss: 4.723727]\n",
      "epoch:28 step:22347 [D loss: 0.556047, acc: 78.12%] [G loss: 3.819867]\n",
      "epoch:28 step:22348 [D loss: 0.128368, acc: 99.22%] [G loss: 3.887353]\n",
      "epoch:28 step:22349 [D loss: 1.372538, acc: 13.28%] [G loss: 4.732685]\n",
      "epoch:28 step:22350 [D loss: 0.236889, acc: 96.88%] [G loss: 3.912436]\n",
      "epoch:28 step:22351 [D loss: 0.759470, acc: 49.22%] [G loss: 5.239164]\n",
      "epoch:28 step:22352 [D loss: 0.174690, acc: 98.44%] [G loss: 4.508913]\n",
      "epoch:28 step:22353 [D loss: 1.037888, acc: 46.09%] [G loss: 4.304879]\n",
      "epoch:28 step:22354 [D loss: 0.182286, acc: 98.44%] [G loss: 5.398077]\n",
      "epoch:28 step:22355 [D loss: 1.632075, acc: 50.00%] [G loss: 2.993427]\n",
      "epoch:28 step:22356 [D loss: 0.139331, acc: 100.00%] [G loss: 4.001410]\n",
      "epoch:28 step:22357 [D loss: 0.211554, acc: 92.97%] [G loss: 6.204115]\n",
      "epoch:28 step:22358 [D loss: 0.067817, acc: 99.22%] [G loss: 5.856239]\n",
      "epoch:28 step:22359 [D loss: 0.463800, acc: 73.44%] [G loss: 6.235528]\n",
      "epoch:28 step:22360 [D loss: 0.356785, acc: 78.12%] [G loss: 5.030052]\n",
      "epoch:28 step:22361 [D loss: 0.602923, acc: 63.28%] [G loss: 4.728385]\n",
      "epoch:28 step:22362 [D loss: 0.380229, acc: 73.44%] [G loss: 3.586520]\n",
      "epoch:28 step:22363 [D loss: 0.604905, acc: 66.41%] [G loss: 7.089827]\n",
      "epoch:28 step:22364 [D loss: 0.630800, acc: 57.03%] [G loss: 3.899960]\n",
      "epoch:28 step:22365 [D loss: 0.296787, acc: 84.38%] [G loss: 4.113247]\n",
      "epoch:28 step:22366 [D loss: 0.297937, acc: 83.59%] [G loss: 8.979723]\n",
      "epoch:28 step:22367 [D loss: 0.812435, acc: 52.34%] [G loss: 4.606766]\n",
      "epoch:28 step:22368 [D loss: 0.889464, acc: 39.06%] [G loss: 5.388300]\n",
      "epoch:28 step:22369 [D loss: 0.620510, acc: 60.16%] [G loss: 3.589488]\n",
      "epoch:28 step:22370 [D loss: 0.932606, acc: 45.31%] [G loss: 5.152364]\n",
      "epoch:28 step:22371 [D loss: 0.834268, acc: 42.19%] [G loss: 3.351307]\n",
      "epoch:28 step:22372 [D loss: 0.875462, acc: 35.16%] [G loss: 3.299893]\n",
      "epoch:28 step:22373 [D loss: 0.887999, acc: 53.12%] [G loss: 2.130603]\n",
      "epoch:28 step:22374 [D loss: 0.263522, acc: 89.06%] [G loss: 3.881488]\n",
      "epoch:28 step:22375 [D loss: 1.466778, acc: 36.72%] [G loss: 5.499439]\n",
      "epoch:28 step:22376 [D loss: 0.663980, acc: 58.59%] [G loss: 5.284478]\n",
      "epoch:28 step:22377 [D loss: 0.435151, acc: 73.44%] [G loss: 5.474233]\n",
      "epoch:28 step:22378 [D loss: 0.408576, acc: 87.50%] [G loss: 3.492788]\n",
      "epoch:28 step:22379 [D loss: 0.056953, acc: 100.00%] [G loss: 6.151681]\n",
      "epoch:28 step:22380 [D loss: 0.184314, acc: 98.44%] [G loss: 3.516762]\n",
      "epoch:28 step:22381 [D loss: 0.811429, acc: 43.75%] [G loss: 3.762382]\n",
      "epoch:28 step:22382 [D loss: 0.760334, acc: 52.34%] [G loss: 4.358524]\n",
      "epoch:28 step:22383 [D loss: 0.265124, acc: 89.84%] [G loss: 3.279830]\n",
      "epoch:28 step:22384 [D loss: 0.543006, acc: 66.41%] [G loss: 5.538271]\n",
      "epoch:28 step:22385 [D loss: 0.222713, acc: 94.53%] [G loss: 5.733129]\n",
      "epoch:28 step:22386 [D loss: 0.661435, acc: 59.38%] [G loss: 4.177558]\n",
      "epoch:28 step:22387 [D loss: 0.630528, acc: 60.16%] [G loss: 4.527717]\n",
      "epoch:28 step:22388 [D loss: 0.955650, acc: 38.28%] [G loss: 2.760596]\n",
      "epoch:28 step:22389 [D loss: 0.213469, acc: 98.44%] [G loss: 5.084706]\n",
      "epoch:28 step:22390 [D loss: 0.449415, acc: 75.78%] [G loss: 5.251439]\n",
      "epoch:28 step:22391 [D loss: 0.176469, acc: 94.53%] [G loss: 4.539862]\n",
      "epoch:28 step:22392 [D loss: 0.740969, acc: 54.69%] [G loss: 3.262351]\n",
      "epoch:28 step:22393 [D loss: 0.094770, acc: 100.00%] [G loss: 3.307296]\n",
      "epoch:28 step:22394 [D loss: 1.422021, acc: 32.81%] [G loss: 5.371220]\n",
      "epoch:28 step:22395 [D loss: 0.362955, acc: 89.06%] [G loss: 5.613154]\n",
      "epoch:28 step:22396 [D loss: 0.448547, acc: 71.88%] [G loss: 3.353518]\n",
      "epoch:28 step:22397 [D loss: 0.390725, acc: 91.41%] [G loss: 4.095343]\n",
      "epoch:28 step:22398 [D loss: 0.491607, acc: 75.00%] [G loss: 4.844371]\n",
      "epoch:28 step:22399 [D loss: 0.703091, acc: 53.91%] [G loss: 4.832188]\n",
      "epoch:28 step:22400 [D loss: 0.201597, acc: 98.44%] [G loss: 3.226911]\n",
      "epoch:28 step:22401 [D loss: 0.298523, acc: 92.97%] [G loss: 3.060822]\n",
      "epoch:28 step:22402 [D loss: 0.138903, acc: 100.00%] [G loss: 4.478118]\n",
      "epoch:28 step:22403 [D loss: 0.526092, acc: 75.00%] [G loss: 3.075190]\n",
      "epoch:28 step:22404 [D loss: 0.147103, acc: 100.00%] [G loss: 4.951248]\n",
      "epoch:28 step:22405 [D loss: 0.414618, acc: 81.25%] [G loss: 4.559634]\n",
      "epoch:28 step:22406 [D loss: 0.260072, acc: 96.88%] [G loss: 4.791244]\n",
      "epoch:28 step:22407 [D loss: 1.022148, acc: 49.22%] [G loss: 4.309291]\n",
      "epoch:28 step:22408 [D loss: 0.546585, acc: 75.00%] [G loss: 4.542108]\n",
      "epoch:28 step:22409 [D loss: 0.394574, acc: 78.12%] [G loss: 4.880937]\n",
      "epoch:28 step:22410 [D loss: 0.201724, acc: 98.44%] [G loss: 4.788083]\n",
      "epoch:28 step:22411 [D loss: 0.499619, acc: 73.44%] [G loss: 4.784451]\n",
      "epoch:28 step:22412 [D loss: 0.422185, acc: 77.34%] [G loss: 3.586898]\n",
      "epoch:28 step:22413 [D loss: 0.358366, acc: 89.84%] [G loss: 2.598701]\n",
      "epoch:28 step:22414 [D loss: 0.577492, acc: 60.16%] [G loss: 4.238391]\n",
      "epoch:28 step:22415 [D loss: 0.269473, acc: 91.41%] [G loss: 4.091096]\n",
      "epoch:28 step:22416 [D loss: 0.471462, acc: 71.09%] [G loss: 4.357332]\n",
      "epoch:28 step:22417 [D loss: 0.216097, acc: 97.66%] [G loss: 4.935652]\n",
      "epoch:28 step:22418 [D loss: 0.452721, acc: 82.81%] [G loss: 3.185500]\n",
      "epoch:28 step:22419 [D loss: 0.294384, acc: 88.28%] [G loss: 4.979503]\n",
      "epoch:28 step:22420 [D loss: 1.008972, acc: 26.56%] [G loss: 3.884418]\n",
      "epoch:28 step:22421 [D loss: 0.396169, acc: 84.38%] [G loss: 3.528578]\n",
      "epoch:28 step:22422 [D loss: 0.622758, acc: 64.84%] [G loss: 2.526263]\n",
      "epoch:28 step:22423 [D loss: 0.180687, acc: 98.44%] [G loss: 2.883043]\n",
      "epoch:28 step:22424 [D loss: 0.264516, acc: 94.53%] [G loss: 4.085686]\n",
      "epoch:28 step:22425 [D loss: 0.498901, acc: 71.88%] [G loss: 4.517199]\n",
      "epoch:28 step:22426 [D loss: 0.173351, acc: 98.44%] [G loss: 2.950003]\n",
      "epoch:28 step:22427 [D loss: 0.404993, acc: 82.81%] [G loss: 2.909762]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22428 [D loss: 0.097731, acc: 100.00%] [G loss: 6.388776]\n",
      "epoch:28 step:22429 [D loss: 0.628690, acc: 56.25%] [G loss: 3.225633]\n",
      "epoch:28 step:22430 [D loss: 0.596880, acc: 64.06%] [G loss: 3.306417]\n",
      "epoch:28 step:22431 [D loss: 0.394384, acc: 77.34%] [G loss: 5.060287]\n",
      "epoch:28 step:22432 [D loss: 0.584674, acc: 57.03%] [G loss: 4.415696]\n",
      "epoch:28 step:22433 [D loss: 0.093494, acc: 100.00%] [G loss: 4.752774]\n",
      "epoch:28 step:22434 [D loss: 0.317791, acc: 90.62%] [G loss: 4.046897]\n",
      "epoch:28 step:22435 [D loss: 0.277759, acc: 91.41%] [G loss: 5.245742]\n",
      "epoch:28 step:22436 [D loss: 0.142110, acc: 100.00%] [G loss: 4.766778]\n",
      "epoch:28 step:22437 [D loss: 1.053128, acc: 50.78%] [G loss: 3.737374]\n",
      "epoch:28 step:22438 [D loss: 0.551098, acc: 67.19%] [G loss: 5.606377]\n",
      "epoch:28 step:22439 [D loss: 0.401432, acc: 89.06%] [G loss: 3.434880]\n",
      "epoch:28 step:22440 [D loss: 0.578021, acc: 70.31%] [G loss: 5.399049]\n",
      "epoch:28 step:22441 [D loss: 0.399743, acc: 78.12%] [G loss: 4.227415]\n",
      "epoch:28 step:22442 [D loss: 0.488143, acc: 83.59%] [G loss: 2.330965]\n",
      "epoch:28 step:22443 [D loss: 0.478123, acc: 72.66%] [G loss: 2.643617]\n",
      "epoch:28 step:22444 [D loss: 0.235701, acc: 93.75%] [G loss: 3.563720]\n",
      "epoch:28 step:22445 [D loss: 0.259132, acc: 96.88%] [G loss: 5.076107]\n",
      "epoch:28 step:22446 [D loss: 0.223217, acc: 97.66%] [G loss: 4.309301]\n",
      "epoch:28 step:22447 [D loss: 0.504340, acc: 73.44%] [G loss: 3.209134]\n",
      "epoch:28 step:22448 [D loss: 0.489018, acc: 83.59%] [G loss: 4.461268]\n",
      "epoch:28 step:22449 [D loss: 0.786544, acc: 50.78%] [G loss: 4.189076]\n",
      "epoch:28 step:22450 [D loss: 0.886422, acc: 49.22%] [G loss: 5.219399]\n",
      "epoch:28 step:22451 [D loss: 0.720920, acc: 60.94%] [G loss: 4.359569]\n",
      "epoch:28 step:22452 [D loss: 0.689325, acc: 54.69%] [G loss: 4.693121]\n",
      "epoch:28 step:22453 [D loss: 0.125257, acc: 99.22%] [G loss: 5.426031]\n",
      "epoch:28 step:22454 [D loss: 0.502161, acc: 64.06%] [G loss: 5.491476]\n",
      "epoch:28 step:22455 [D loss: 0.345346, acc: 89.84%] [G loss: 4.876184]\n",
      "epoch:28 step:22456 [D loss: 0.210672, acc: 98.44%] [G loss: 4.192633]\n",
      "epoch:28 step:22457 [D loss: 0.564161, acc: 68.75%] [G loss: 3.525681]\n",
      "epoch:28 step:22458 [D loss: 0.309829, acc: 89.06%] [G loss: 4.405942]\n",
      "epoch:28 step:22459 [D loss: 0.420049, acc: 82.81%] [G loss: 2.674477]\n",
      "epoch:28 step:22460 [D loss: 0.418001, acc: 80.47%] [G loss: 5.170279]\n",
      "epoch:28 step:22461 [D loss: 0.898912, acc: 35.16%] [G loss: 4.104985]\n",
      "epoch:28 step:22462 [D loss: 0.273268, acc: 96.88%] [G loss: 2.762088]\n",
      "epoch:28 step:22463 [D loss: 0.072973, acc: 100.00%] [G loss: 5.256574]\n",
      "epoch:28 step:22464 [D loss: 0.427005, acc: 79.69%] [G loss: 5.406699]\n",
      "epoch:28 step:22465 [D loss: 0.858288, acc: 50.00%] [G loss: 5.947411]\n",
      "epoch:28 step:22466 [D loss: 0.100612, acc: 100.00%] [G loss: 6.459143]\n",
      "epoch:28 step:22467 [D loss: 0.760717, acc: 54.69%] [G loss: 5.740864]\n",
      "epoch:28 step:22468 [D loss: 0.809881, acc: 53.12%] [G loss: 2.482022]\n",
      "epoch:28 step:22469 [D loss: 0.495158, acc: 77.34%] [G loss: 1.844510]\n",
      "epoch:28 step:22470 [D loss: 0.462637, acc: 75.00%] [G loss: 3.138698]\n",
      "epoch:28 step:22471 [D loss: 0.922863, acc: 51.56%] [G loss: 4.660987]\n",
      "epoch:28 step:22472 [D loss: 0.334580, acc: 90.62%] [G loss: 3.503960]\n",
      "epoch:28 step:22473 [D loss: 0.374443, acc: 83.59%] [G loss: 3.569426]\n",
      "epoch:28 step:22474 [D loss: 0.318199, acc: 85.16%] [G loss: 3.551168]\n",
      "epoch:28 step:22475 [D loss: 0.178482, acc: 98.44%] [G loss: 2.765233]\n",
      "epoch:28 step:22476 [D loss: 0.172442, acc: 97.66%] [G loss: 4.489897]\n",
      "epoch:28 step:22477 [D loss: 0.192574, acc: 99.22%] [G loss: 4.274928]\n",
      "epoch:28 step:22478 [D loss: 0.108778, acc: 100.00%] [G loss: 3.826282]\n",
      "epoch:28 step:22479 [D loss: 0.547190, acc: 67.97%] [G loss: 4.945807]\n",
      "epoch:28 step:22480 [D loss: 0.232433, acc: 97.66%] [G loss: 4.396727]\n",
      "epoch:28 step:22481 [D loss: 0.427059, acc: 76.56%] [G loss: 2.004903]\n",
      "epoch:28 step:22482 [D loss: 0.370069, acc: 79.69%] [G loss: 4.617747]\n",
      "epoch:28 step:22483 [D loss: 0.148367, acc: 100.00%] [G loss: 4.576236]\n",
      "epoch:28 step:22484 [D loss: 0.818351, acc: 54.69%] [G loss: 4.773398]\n",
      "epoch:28 step:22485 [D loss: 0.846174, acc: 40.62%] [G loss: 4.384686]\n",
      "epoch:28 step:22486 [D loss: 0.505391, acc: 81.25%] [G loss: 3.328509]\n",
      "epoch:28 step:22487 [D loss: 0.533522, acc: 73.44%] [G loss: 5.207089]\n",
      "epoch:28 step:22488 [D loss: 0.408981, acc: 74.22%] [G loss: 2.800118]\n",
      "epoch:28 step:22489 [D loss: 0.472542, acc: 83.59%] [G loss: 5.172040]\n",
      "epoch:28 step:22490 [D loss: 0.206779, acc: 96.88%] [G loss: 4.173916]\n",
      "epoch:28 step:22491 [D loss: 0.188342, acc: 100.00%] [G loss: 4.149549]\n",
      "epoch:28 step:22492 [D loss: 0.700998, acc: 53.12%] [G loss: 6.915169]\n",
      "epoch:28 step:22493 [D loss: 0.701895, acc: 53.12%] [G loss: 4.237072]\n",
      "epoch:28 step:22494 [D loss: 0.340816, acc: 93.75%] [G loss: 5.491560]\n",
      "epoch:28 step:22495 [D loss: 0.504475, acc: 66.41%] [G loss: 4.258574]\n",
      "epoch:28 step:22496 [D loss: 0.215588, acc: 96.88%] [G loss: 4.248549]\n",
      "epoch:28 step:22497 [D loss: 0.158635, acc: 100.00%] [G loss: 3.698132]\n",
      "epoch:28 step:22498 [D loss: 0.118589, acc: 99.22%] [G loss: 6.016709]\n",
      "epoch:28 step:22499 [D loss: 0.318065, acc: 89.06%] [G loss: 4.527638]\n",
      "epoch:28 step:22500 [D loss: 0.514115, acc: 60.16%] [G loss: 5.135606]\n",
      "epoch:28 step:22501 [D loss: 0.503235, acc: 77.34%] [G loss: 4.459767]\n",
      "epoch:28 step:22502 [D loss: 2.029052, acc: 16.41%] [G loss: 3.854499]\n",
      "epoch:28 step:22503 [D loss: 0.159313, acc: 98.44%] [G loss: 2.491716]\n",
      "epoch:28 step:22504 [D loss: 1.355181, acc: 14.84%] [G loss: 5.334468]\n",
      "epoch:28 step:22505 [D loss: 0.409036, acc: 88.28%] [G loss: 2.652306]\n",
      "epoch:28 step:22506 [D loss: 1.078695, acc: 30.47%] [G loss: 3.230708]\n",
      "epoch:28 step:22507 [D loss: 0.284693, acc: 97.66%] [G loss: 3.068618]\n",
      "epoch:28 step:22508 [D loss: 0.282734, acc: 89.06%] [G loss: 4.866330]\n",
      "epoch:28 step:22509 [D loss: 0.417184, acc: 84.38%] [G loss: 4.857130]\n",
      "epoch:28 step:22510 [D loss: 1.022983, acc: 25.78%] [G loss: 4.853169]\n",
      "epoch:28 step:22511 [D loss: 0.176064, acc: 99.22%] [G loss: 4.676576]\n",
      "epoch:28 step:22512 [D loss: 0.175601, acc: 96.88%] [G loss: 4.773938]\n",
      "epoch:28 step:22513 [D loss: 0.365513, acc: 81.25%] [G loss: 5.639933]\n",
      "epoch:28 step:22514 [D loss: 0.335860, acc: 92.19%] [G loss: 3.086171]\n",
      "epoch:28 step:22515 [D loss: 0.517701, acc: 69.53%] [G loss: 4.999926]\n",
      "epoch:28 step:22516 [D loss: 0.186009, acc: 96.88%] [G loss: 4.370331]\n",
      "epoch:28 step:22517 [D loss: 0.536204, acc: 78.91%] [G loss: 3.705353]\n",
      "epoch:28 step:22518 [D loss: 0.744341, acc: 57.81%] [G loss: 2.005141]\n",
      "epoch:28 step:22519 [D loss: 0.504267, acc: 77.34%] [G loss: 5.040442]\n",
      "epoch:28 step:22520 [D loss: 0.405255, acc: 86.72%] [G loss: 3.677198]\n",
      "epoch:28 step:22521 [D loss: 0.142715, acc: 99.22%] [G loss: 4.361397]\n",
      "epoch:28 step:22522 [D loss: 0.153208, acc: 98.44%] [G loss: 5.840825]\n",
      "epoch:28 step:22523 [D loss: 0.218209, acc: 98.44%] [G loss: 6.051842]\n",
      "epoch:28 step:22524 [D loss: 0.362490, acc: 84.38%] [G loss: 4.291492]\n",
      "epoch:28 step:22525 [D loss: 0.427648, acc: 73.44%] [G loss: 3.959080]\n",
      "epoch:28 step:22526 [D loss: 0.541851, acc: 62.50%] [G loss: 2.990397]\n",
      "epoch:28 step:22527 [D loss: 0.440299, acc: 67.19%] [G loss: 4.603056]\n",
      "epoch:28 step:22528 [D loss: 0.509413, acc: 76.56%] [G loss: 5.325649]\n",
      "epoch:28 step:22529 [D loss: 0.232547, acc: 98.44%] [G loss: 4.865498]\n",
      "epoch:28 step:22530 [D loss: 0.386478, acc: 88.28%] [G loss: 2.615960]\n",
      "epoch:28 step:22531 [D loss: 0.717006, acc: 60.16%] [G loss: 3.972301]\n",
      "epoch:28 step:22532 [D loss: 0.188121, acc: 96.09%] [G loss: 3.069968]\n",
      "epoch:28 step:22533 [D loss: 0.496576, acc: 75.78%] [G loss: 3.175910]\n",
      "epoch:28 step:22534 [D loss: 0.320332, acc: 81.25%] [G loss: 4.444906]\n",
      "epoch:28 step:22535 [D loss: 0.097443, acc: 99.22%] [G loss: 6.157889]\n",
      "epoch:28 step:22536 [D loss: 0.160866, acc: 98.44%] [G loss: 3.977160]\n",
      "epoch:28 step:22537 [D loss: 0.679518, acc: 59.38%] [G loss: 4.271432]\n",
      "epoch:28 step:22538 [D loss: 0.568512, acc: 56.25%] [G loss: 3.949790]\n",
      "epoch:28 step:22539 [D loss: 0.738564, acc: 53.91%] [G loss: 5.086876]\n",
      "epoch:28 step:22540 [D loss: 0.309300, acc: 92.19%] [G loss: 4.819059]\n",
      "epoch:28 step:22541 [D loss: 1.598814, acc: 39.84%] [G loss: 4.442507]\n",
      "epoch:28 step:22542 [D loss: 0.253355, acc: 97.66%] [G loss: 2.446968]\n",
      "epoch:28 step:22543 [D loss: 0.361005, acc: 89.84%] [G loss: 2.219882]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22544 [D loss: 0.297212, acc: 96.09%] [G loss: 4.489736]\n",
      "epoch:28 step:22545 [D loss: 0.332127, acc: 89.06%] [G loss: 2.853430]\n",
      "epoch:28 step:22546 [D loss: 0.188133, acc: 100.00%] [G loss: 2.787968]\n",
      "epoch:28 step:22547 [D loss: 0.351636, acc: 92.19%] [G loss: 3.363711]\n",
      "epoch:28 step:22548 [D loss: 0.108364, acc: 100.00%] [G loss: 2.375378]\n",
      "epoch:28 step:22549 [D loss: 0.342718, acc: 89.06%] [G loss: 5.481782]\n",
      "epoch:28 step:22550 [D loss: 0.401412, acc: 87.50%] [G loss: 2.809700]\n",
      "epoch:28 step:22551 [D loss: 0.204981, acc: 99.22%] [G loss: 4.807573]\n",
      "epoch:28 step:22552 [D loss: 0.614365, acc: 59.38%] [G loss: 4.494775]\n",
      "epoch:28 step:22553 [D loss: 0.111309, acc: 100.00%] [G loss: 2.785623]\n",
      "epoch:28 step:22554 [D loss: 0.599433, acc: 66.41%] [G loss: 3.211934]\n",
      "epoch:28 step:22555 [D loss: 0.341025, acc: 90.62%] [G loss: 4.240727]\n",
      "epoch:28 step:22556 [D loss: 0.338207, acc: 92.19%] [G loss: 3.604558]\n",
      "epoch:28 step:22557 [D loss: 0.184108, acc: 98.44%] [G loss: 4.632208]\n",
      "epoch:28 step:22558 [D loss: 0.212838, acc: 94.53%] [G loss: 4.372597]\n",
      "epoch:28 step:22559 [D loss: 0.285880, acc: 84.38%] [G loss: 4.801940]\n",
      "epoch:28 step:22560 [D loss: 0.715486, acc: 56.25%] [G loss: 5.804549]\n",
      "epoch:28 step:22561 [D loss: 0.263497, acc: 95.31%] [G loss: 4.935033]\n",
      "epoch:28 step:22562 [D loss: 0.457203, acc: 75.00%] [G loss: 4.347499]\n",
      "epoch:28 step:22563 [D loss: 0.134013, acc: 98.44%] [G loss: 3.300135]\n",
      "epoch:28 step:22564 [D loss: 1.191613, acc: 40.62%] [G loss: 3.293890]\n",
      "epoch:28 step:22565 [D loss: 0.606275, acc: 64.84%] [G loss: 3.137028]\n",
      "epoch:28 step:22566 [D loss: 0.558841, acc: 68.75%] [G loss: 4.333843]\n",
      "epoch:28 step:22567 [D loss: 0.971754, acc: 40.62%] [G loss: 3.316214]\n",
      "epoch:28 step:22568 [D loss: 0.294438, acc: 87.50%] [G loss: 2.900751]\n",
      "epoch:28 step:22569 [D loss: 0.249188, acc: 96.88%] [G loss: 4.777713]\n",
      "epoch:28 step:22570 [D loss: 0.153803, acc: 97.66%] [G loss: 5.321068]\n",
      "epoch:28 step:22571 [D loss: 0.794198, acc: 56.25%] [G loss: 4.069979]\n",
      "epoch:28 step:22572 [D loss: 0.172024, acc: 98.44%] [G loss: 3.860189]\n",
      "epoch:28 step:22573 [D loss: 0.636507, acc: 60.94%] [G loss: 5.472158]\n",
      "epoch:28 step:22574 [D loss: 0.058354, acc: 100.00%] [G loss: 4.393991]\n",
      "epoch:28 step:22575 [D loss: 0.140589, acc: 99.22%] [G loss: 4.654478]\n",
      "epoch:28 step:22576 [D loss: 0.218231, acc: 94.53%] [G loss: 5.604584]\n",
      "epoch:28 step:22577 [D loss: 0.369994, acc: 83.59%] [G loss: 4.593088]\n",
      "epoch:28 step:22578 [D loss: 0.826167, acc: 50.00%] [G loss: 5.954496]\n",
      "epoch:28 step:22579 [D loss: 0.603763, acc: 57.81%] [G loss: 4.720214]\n",
      "epoch:28 step:22580 [D loss: 0.415363, acc: 79.69%] [G loss: 5.965686]\n",
      "epoch:28 step:22581 [D loss: 1.080009, acc: 28.91%] [G loss: 5.587777]\n",
      "epoch:28 step:22582 [D loss: 0.392205, acc: 81.25%] [G loss: 5.749939]\n",
      "epoch:28 step:22583 [D loss: 0.753034, acc: 53.12%] [G loss: 5.437957]\n",
      "epoch:28 step:22584 [D loss: 0.278400, acc: 96.09%] [G loss: 3.450751]\n",
      "epoch:28 step:22585 [D loss: 0.093541, acc: 99.22%] [G loss: 4.219533]\n",
      "epoch:28 step:22586 [D loss: 0.122080, acc: 100.00%] [G loss: 2.815883]\n",
      "epoch:28 step:22587 [D loss: 0.410038, acc: 82.03%] [G loss: 3.582392]\n",
      "epoch:28 step:22588 [D loss: 0.363637, acc: 83.59%] [G loss: 4.992899]\n",
      "epoch:28 step:22589 [D loss: 0.187464, acc: 96.88%] [G loss: 3.134089]\n",
      "epoch:28 step:22590 [D loss: 0.550448, acc: 66.41%] [G loss: 5.798452]\n",
      "epoch:28 step:22591 [D loss: 0.211323, acc: 96.09%] [G loss: 3.450487]\n",
      "epoch:28 step:22592 [D loss: 0.528186, acc: 71.09%] [G loss: 5.832389]\n",
      "epoch:28 step:22593 [D loss: 0.296256, acc: 89.84%] [G loss: 3.871881]\n",
      "epoch:28 step:22594 [D loss: 0.117615, acc: 99.22%] [G loss: 6.021469]\n",
      "epoch:28 step:22595 [D loss: 0.634287, acc: 60.94%] [G loss: 3.319957]\n",
      "epoch:28 step:22596 [D loss: 0.783035, acc: 48.44%] [G loss: 5.480510]\n",
      "epoch:28 step:22597 [D loss: 0.538195, acc: 72.66%] [G loss: 5.107801]\n",
      "epoch:28 step:22598 [D loss: 0.156415, acc: 98.44%] [G loss: 4.357932]\n",
      "epoch:28 step:22599 [D loss: 0.981646, acc: 33.59%] [G loss: 2.613048]\n",
      "epoch:28 step:22600 [D loss: 0.145819, acc: 99.22%] [G loss: 4.442931]\n",
      "epoch:28 step:22601 [D loss: 0.680811, acc: 62.50%] [G loss: 3.473534]\n",
      "epoch:28 step:22602 [D loss: 0.846854, acc: 52.34%] [G loss: 3.401504]\n",
      "epoch:28 step:22603 [D loss: 0.338663, acc: 88.28%] [G loss: 3.363788]\n",
      "epoch:28 step:22604 [D loss: 0.138565, acc: 100.00%] [G loss: 3.241464]\n",
      "epoch:28 step:22605 [D loss: 0.260328, acc: 92.97%] [G loss: 4.875814]\n",
      "epoch:28 step:22606 [D loss: 0.273071, acc: 95.31%] [G loss: 4.450048]\n",
      "epoch:28 step:22607 [D loss: 0.294461, acc: 95.31%] [G loss: 4.763807]\n",
      "epoch:28 step:22608 [D loss: 0.397339, acc: 86.72%] [G loss: 4.255557]\n",
      "epoch:28 step:22609 [D loss: 0.101645, acc: 100.00%] [G loss: 5.937037]\n",
      "epoch:28 step:22610 [D loss: 0.607810, acc: 61.72%] [G loss: 4.316048]\n",
      "epoch:28 step:22611 [D loss: 0.577407, acc: 64.84%] [G loss: 6.019164]\n",
      "epoch:28 step:22612 [D loss: 0.381794, acc: 83.59%] [G loss: 3.481295]\n",
      "epoch:28 step:22613 [D loss: 0.273215, acc: 94.53%] [G loss: 3.958209]\n",
      "epoch:28 step:22614 [D loss: 1.102180, acc: 25.00%] [G loss: 3.753996]\n",
      "epoch:28 step:22615 [D loss: 0.580046, acc: 57.03%] [G loss: 7.790168]\n",
      "epoch:28 step:22616 [D loss: 0.152240, acc: 98.44%] [G loss: 3.337175]\n",
      "epoch:28 step:22617 [D loss: 0.713514, acc: 53.91%] [G loss: 3.732287]\n",
      "epoch:28 step:22618 [D loss: 0.532884, acc: 75.78%] [G loss: 3.600688]\n",
      "epoch:28 step:22619 [D loss: 0.254875, acc: 96.88%] [G loss: 3.559377]\n",
      "epoch:28 step:22620 [D loss: 0.119498, acc: 99.22%] [G loss: 4.867446]\n",
      "epoch:28 step:22621 [D loss: 0.280490, acc: 94.53%] [G loss: 4.099255]\n",
      "epoch:28 step:22622 [D loss: 0.311529, acc: 94.53%] [G loss: 2.253594]\n",
      "epoch:28 step:22623 [D loss: 0.322216, acc: 87.50%] [G loss: 4.570904]\n",
      "epoch:28 step:22624 [D loss: 0.488355, acc: 71.09%] [G loss: 4.545576]\n",
      "epoch:28 step:22625 [D loss: 0.408411, acc: 86.72%] [G loss: 4.119653]\n",
      "epoch:28 step:22626 [D loss: 0.330712, acc: 86.72%] [G loss: 3.739939]\n",
      "epoch:28 step:22627 [D loss: 0.597646, acc: 61.72%] [G loss: 4.006929]\n",
      "epoch:28 step:22628 [D loss: 0.081766, acc: 100.00%] [G loss: 6.572328]\n",
      "epoch:28 step:22629 [D loss: 1.208784, acc: 21.09%] [G loss: 5.236597]\n",
      "epoch:28 step:22630 [D loss: 0.222346, acc: 96.09%] [G loss: 5.895619]\n",
      "epoch:28 step:22631 [D loss: 0.289548, acc: 88.28%] [G loss: 8.235849]\n",
      "epoch:28 step:22632 [D loss: 0.860922, acc: 50.00%] [G loss: 3.535757]\n",
      "epoch:28 step:22633 [D loss: 0.784372, acc: 58.59%] [G loss: 4.125886]\n",
      "epoch:28 step:22634 [D loss: 0.729447, acc: 52.34%] [G loss: 5.450244]\n",
      "epoch:28 step:22635 [D loss: 0.252010, acc: 93.75%] [G loss: 5.114380]\n",
      "epoch:28 step:22636 [D loss: 0.422595, acc: 85.16%] [G loss: 4.376196]\n",
      "epoch:28 step:22637 [D loss: 0.724159, acc: 58.59%] [G loss: 3.000790]\n",
      "epoch:28 step:22638 [D loss: 0.214041, acc: 96.09%] [G loss: 4.199463]\n",
      "epoch:28 step:22639 [D loss: 0.897158, acc: 50.78%] [G loss: 2.659367]\n",
      "epoch:28 step:22640 [D loss: 0.205797, acc: 96.88%] [G loss: 3.250896]\n",
      "epoch:28 step:22641 [D loss: 0.369448, acc: 76.56%] [G loss: 6.661912]\n",
      "epoch:28 step:22642 [D loss: 0.069649, acc: 100.00%] [G loss: 4.156981]\n",
      "epoch:28 step:22643 [D loss: 0.692836, acc: 57.81%] [G loss: 4.679004]\n",
      "epoch:28 step:22644 [D loss: 0.614304, acc: 68.75%] [G loss: 3.792391]\n",
      "epoch:28 step:22645 [D loss: 0.831797, acc: 45.31%] [G loss: 4.580526]\n",
      "epoch:28 step:22646 [D loss: 0.443580, acc: 84.38%] [G loss: 3.737360]\n",
      "epoch:28 step:22647 [D loss: 0.642529, acc: 61.72%] [G loss: 4.163481]\n",
      "epoch:28 step:22648 [D loss: 0.549502, acc: 67.19%] [G loss: 3.691272]\n",
      "epoch:28 step:22649 [D loss: 0.514145, acc: 64.84%] [G loss: 4.772343]\n",
      "epoch:29 step:22650 [D loss: 0.546225, acc: 78.91%] [G loss: 6.616593]\n",
      "epoch:29 step:22651 [D loss: 1.246575, acc: 46.88%] [G loss: 4.249518]\n",
      "epoch:29 step:22652 [D loss: 0.770456, acc: 46.88%] [G loss: 2.933197]\n",
      "epoch:29 step:22653 [D loss: 0.938703, acc: 50.78%] [G loss: 7.763124]\n",
      "epoch:29 step:22654 [D loss: 0.369182, acc: 78.91%] [G loss: 4.740563]\n",
      "epoch:29 step:22655 [D loss: 0.211555, acc: 96.88%] [G loss: 3.009054]\n",
      "epoch:29 step:22656 [D loss: 0.288742, acc: 93.75%] [G loss: 4.219955]\n",
      "epoch:29 step:22657 [D loss: 0.121360, acc: 99.22%] [G loss: 5.996919]\n",
      "epoch:29 step:22658 [D loss: 0.196743, acc: 99.22%] [G loss: 4.425586]\n",
      "epoch:29 step:22659 [D loss: 0.439367, acc: 83.59%] [G loss: 4.695157]\n",
      "epoch:29 step:22660 [D loss: 1.312254, acc: 48.44%] [G loss: 3.323891]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:22661 [D loss: 0.121984, acc: 98.44%] [G loss: 4.174259]\n",
      "epoch:29 step:22662 [D loss: 0.284103, acc: 89.84%] [G loss: 4.481232]\n",
      "epoch:29 step:22663 [D loss: 0.279937, acc: 92.97%] [G loss: 3.446476]\n",
      "epoch:29 step:22664 [D loss: 0.285375, acc: 95.31%] [G loss: 5.684228]\n",
      "epoch:29 step:22665 [D loss: 1.073195, acc: 28.91%] [G loss: 4.298160]\n",
      "epoch:29 step:22666 [D loss: 0.499291, acc: 64.06%] [G loss: 4.037431]\n",
      "epoch:29 step:22667 [D loss: 0.144962, acc: 99.22%] [G loss: 4.318735]\n",
      "epoch:29 step:22668 [D loss: 0.307009, acc: 95.31%] [G loss: 3.592894]\n",
      "epoch:29 step:22669 [D loss: 0.333640, acc: 92.97%] [G loss: 3.925130]\n",
      "epoch:29 step:22670 [D loss: 0.571443, acc: 73.44%] [G loss: 3.324594]\n",
      "epoch:29 step:22671 [D loss: 0.388763, acc: 85.16%] [G loss: 4.041334]\n",
      "epoch:29 step:22672 [D loss: 0.532727, acc: 78.91%] [G loss: 4.039327]\n",
      "epoch:29 step:22673 [D loss: 0.747082, acc: 51.56%] [G loss: 5.402590]\n",
      "epoch:29 step:22674 [D loss: 0.298679, acc: 95.31%] [G loss: 3.833519]\n",
      "epoch:29 step:22675 [D loss: 0.697964, acc: 55.47%] [G loss: 6.701909]\n",
      "epoch:29 step:22676 [D loss: 0.226040, acc: 96.88%] [G loss: 2.980603]\n",
      "epoch:29 step:22677 [D loss: 0.238144, acc: 96.09%] [G loss: 4.017230]\n",
      "epoch:29 step:22678 [D loss: 0.493691, acc: 67.19%] [G loss: 4.763130]\n",
      "epoch:29 step:22679 [D loss: 0.167934, acc: 100.00%] [G loss: 6.005384]\n",
      "epoch:29 step:22680 [D loss: 1.026142, acc: 46.88%] [G loss: 2.985003]\n",
      "epoch:29 step:22681 [D loss: 0.176346, acc: 96.88%] [G loss: 4.376163]\n",
      "epoch:29 step:22682 [D loss: 0.280895, acc: 88.28%] [G loss: 4.066700]\n",
      "epoch:29 step:22683 [D loss: 0.643069, acc: 67.19%] [G loss: 4.934979]\n",
      "epoch:29 step:22684 [D loss: 0.403934, acc: 87.50%] [G loss: 4.801853]\n",
      "epoch:29 step:22685 [D loss: 0.111632, acc: 100.00%] [G loss: 5.686093]\n",
      "epoch:29 step:22686 [D loss: 0.172940, acc: 98.44%] [G loss: 4.742661]\n",
      "epoch:29 step:22687 [D loss: 0.708782, acc: 55.47%] [G loss: 5.234291]\n",
      "epoch:29 step:22688 [D loss: 0.110729, acc: 99.22%] [G loss: 4.758089]\n",
      "epoch:29 step:22689 [D loss: 0.618692, acc: 60.94%] [G loss: 4.831882]\n",
      "epoch:29 step:22690 [D loss: 0.128099, acc: 100.00%] [G loss: 4.537664]\n",
      "epoch:29 step:22691 [D loss: 0.161471, acc: 97.66%] [G loss: 4.032018]\n",
      "epoch:29 step:22692 [D loss: 0.146191, acc: 99.22%] [G loss: 4.800938]\n",
      "epoch:29 step:22693 [D loss: 0.485329, acc: 75.78%] [G loss: 5.070245]\n",
      "epoch:29 step:22694 [D loss: 0.593879, acc: 61.72%] [G loss: 6.862694]\n",
      "epoch:29 step:22695 [D loss: 0.558292, acc: 57.81%] [G loss: 4.879616]\n",
      "epoch:29 step:22696 [D loss: 0.401477, acc: 80.47%] [G loss: 4.430866]\n",
      "epoch:29 step:22697 [D loss: 0.159841, acc: 98.44%] [G loss: 5.797203]\n",
      "epoch:29 step:22698 [D loss: 0.416112, acc: 72.66%] [G loss: 3.895883]\n",
      "epoch:29 step:22699 [D loss: 0.314382, acc: 89.06%] [G loss: 5.323321]\n",
      "epoch:29 step:22700 [D loss: 0.064639, acc: 100.00%] [G loss: 6.562431]\n",
      "epoch:29 step:22701 [D loss: 0.509862, acc: 67.97%] [G loss: 3.813518]\n",
      "epoch:29 step:22702 [D loss: 0.169358, acc: 100.00%] [G loss: 4.126299]\n",
      "epoch:29 step:22703 [D loss: 0.979167, acc: 49.22%] [G loss: 4.578577]\n",
      "epoch:29 step:22704 [D loss: 0.066402, acc: 100.00%] [G loss: 3.996362]\n",
      "epoch:29 step:22705 [D loss: 0.297507, acc: 89.84%] [G loss: 3.600453]\n",
      "epoch:29 step:22706 [D loss: 0.154374, acc: 98.44%] [G loss: 3.792333]\n",
      "epoch:29 step:22707 [D loss: 0.046260, acc: 100.00%] [G loss: 6.518538]\n",
      "epoch:29 step:22708 [D loss: 0.346231, acc: 88.28%] [G loss: 4.971275]\n",
      "epoch:29 step:22709 [D loss: 0.204695, acc: 98.44%] [G loss: 4.427122]\n",
      "epoch:29 step:22710 [D loss: 0.637712, acc: 62.50%] [G loss: 2.569186]\n",
      "epoch:29 step:22711 [D loss: 0.260209, acc: 91.41%] [G loss: 3.504309]\n",
      "epoch:29 step:22712 [D loss: 0.342477, acc: 84.38%] [G loss: 6.237185]\n",
      "epoch:29 step:22713 [D loss: 0.296775, acc: 85.16%] [G loss: 3.750146]\n",
      "epoch:29 step:22714 [D loss: 0.586359, acc: 66.41%] [G loss: 3.752220]\n",
      "epoch:29 step:22715 [D loss: 0.954563, acc: 49.22%] [G loss: 3.652077]\n",
      "epoch:29 step:22716 [D loss: 0.476255, acc: 67.19%] [G loss: 1.798536]\n",
      "epoch:29 step:22717 [D loss: 0.981592, acc: 45.31%] [G loss: 3.992351]\n",
      "epoch:29 step:22718 [D loss: 0.475097, acc: 69.53%] [G loss: 5.218066]\n",
      "epoch:29 step:22719 [D loss: 0.175154, acc: 100.00%] [G loss: 4.185280]\n",
      "epoch:29 step:22720 [D loss: 0.637394, acc: 64.84%] [G loss: 2.666243]\n",
      "epoch:29 step:22721 [D loss: 1.258248, acc: 42.97%] [G loss: 1.926805]\n",
      "epoch:29 step:22722 [D loss: 1.068383, acc: 23.44%] [G loss: 3.616065]\n",
      "epoch:29 step:22723 [D loss: 0.345132, acc: 92.19%] [G loss: 5.206308]\n",
      "epoch:29 step:22724 [D loss: 0.677707, acc: 59.38%] [G loss: 4.686366]\n",
      "epoch:29 step:22725 [D loss: 0.473515, acc: 77.34%] [G loss: 3.892744]\n",
      "epoch:29 step:22726 [D loss: 1.021644, acc: 36.72%] [G loss: 5.791582]\n",
      "epoch:29 step:22727 [D loss: 0.351071, acc: 89.84%] [G loss: 3.395774]\n",
      "epoch:29 step:22728 [D loss: 0.240719, acc: 100.00%] [G loss: 3.596619]\n",
      "epoch:29 step:22729 [D loss: 0.349227, acc: 79.69%] [G loss: 5.505280]\n",
      "epoch:29 step:22730 [D loss: 0.254725, acc: 97.66%] [G loss: 5.954022]\n",
      "epoch:29 step:22731 [D loss: 0.845524, acc: 50.78%] [G loss: 3.584978]\n",
      "epoch:29 step:22732 [D loss: 0.172019, acc: 96.88%] [G loss: 3.341873]\n",
      "epoch:29 step:22733 [D loss: 0.263818, acc: 93.75%] [G loss: 3.877872]\n",
      "epoch:29 step:22734 [D loss: 0.643306, acc: 61.72%] [G loss: 5.547738]\n",
      "epoch:29 step:22735 [D loss: 0.443013, acc: 78.91%] [G loss: 3.540555]\n",
      "epoch:29 step:22736 [D loss: 0.280803, acc: 97.66%] [G loss: 4.672122]\n",
      "epoch:29 step:22737 [D loss: 0.092168, acc: 100.00%] [G loss: 4.967974]\n",
      "epoch:29 step:22738 [D loss: 0.424921, acc: 78.91%] [G loss: 3.864731]\n",
      "epoch:29 step:22739 [D loss: 0.286741, acc: 85.94%] [G loss: 3.520279]\n",
      "epoch:29 step:22740 [D loss: 0.164120, acc: 98.44%] [G loss: 3.668256]\n",
      "epoch:29 step:22741 [D loss: 0.128474, acc: 98.44%] [G loss: 2.599273]\n",
      "epoch:29 step:22742 [D loss: 0.405287, acc: 89.06%] [G loss: 3.311758]\n",
      "epoch:29 step:22743 [D loss: 0.415783, acc: 82.81%] [G loss: 2.635315]\n",
      "epoch:29 step:22744 [D loss: 0.464595, acc: 82.81%] [G loss: 4.720592]\n",
      "epoch:29 step:22745 [D loss: 0.470063, acc: 75.78%] [G loss: 4.237780]\n",
      "epoch:29 step:22746 [D loss: 0.274795, acc: 96.09%] [G loss: 3.317060]\n",
      "epoch:29 step:22747 [D loss: 0.606292, acc: 67.97%] [G loss: 3.444538]\n",
      "epoch:29 step:22748 [D loss: 0.747034, acc: 51.56%] [G loss: 4.166147]\n",
      "epoch:29 step:22749 [D loss: 0.442974, acc: 75.00%] [G loss: 3.591692]\n",
      "epoch:29 step:22750 [D loss: 0.610783, acc: 65.62%] [G loss: 3.840811]\n",
      "epoch:29 step:22751 [D loss: 0.675072, acc: 53.91%] [G loss: 3.665159]\n",
      "epoch:29 step:22752 [D loss: 0.554072, acc: 59.38%] [G loss: 5.760947]\n",
      "epoch:29 step:22753 [D loss: 0.228031, acc: 95.31%] [G loss: 5.182587]\n",
      "epoch:29 step:22754 [D loss: 0.529639, acc: 60.94%] [G loss: 2.341142]\n",
      "epoch:29 step:22755 [D loss: 0.319540, acc: 95.31%] [G loss: 3.648484]\n",
      "epoch:29 step:22756 [D loss: 0.914005, acc: 32.03%] [G loss: 4.235698]\n",
      "epoch:29 step:22757 [D loss: 0.411055, acc: 82.03%] [G loss: 2.492732]\n",
      "epoch:29 step:22758 [D loss: 0.491241, acc: 76.56%] [G loss: 3.997888]\n",
      "epoch:29 step:22759 [D loss: 0.192342, acc: 99.22%] [G loss: 3.492623]\n",
      "epoch:29 step:22760 [D loss: 0.185472, acc: 96.88%] [G loss: 5.280907]\n",
      "epoch:29 step:22761 [D loss: 0.108234, acc: 100.00%] [G loss: 4.762648]\n",
      "epoch:29 step:22762 [D loss: 0.269560, acc: 95.31%] [G loss: 3.601317]\n",
      "epoch:29 step:22763 [D loss: 1.121498, acc: 50.00%] [G loss: 2.949256]\n",
      "epoch:29 step:22764 [D loss: 0.200041, acc: 96.88%] [G loss: 3.318515]\n",
      "epoch:29 step:22765 [D loss: 0.516687, acc: 78.12%] [G loss: 2.851877]\n",
      "epoch:29 step:22766 [D loss: 0.283028, acc: 87.50%] [G loss: 3.805764]\n",
      "epoch:29 step:22767 [D loss: 1.526424, acc: 46.09%] [G loss: 2.955954]\n",
      "epoch:29 step:22768 [D loss: 0.240771, acc: 98.44%] [G loss: 2.992089]\n",
      "epoch:29 step:22769 [D loss: 0.359099, acc: 81.25%] [G loss: 4.675277]\n",
      "epoch:29 step:22770 [D loss: 0.704646, acc: 54.69%] [G loss: 4.952832]\n",
      "epoch:29 step:22771 [D loss: 0.304138, acc: 86.72%] [G loss: 4.580809]\n",
      "epoch:29 step:22772 [D loss: 0.466441, acc: 72.66%] [G loss: 3.947900]\n",
      "epoch:29 step:22773 [D loss: 0.442449, acc: 75.00%] [G loss: 4.867285]\n",
      "epoch:29 step:22774 [D loss: 0.476927, acc: 78.12%] [G loss: 2.165317]\n",
      "epoch:29 step:22775 [D loss: 0.076424, acc: 100.00%] [G loss: 4.131814]\n",
      "epoch:29 step:22776 [D loss: 0.549928, acc: 68.75%] [G loss: 6.560398]\n",
      "epoch:29 step:22777 [D loss: 0.233718, acc: 97.66%] [G loss: 3.602264]\n",
      "epoch:29 step:22778 [D loss: 0.172750, acc: 97.66%] [G loss: 5.775314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:22779 [D loss: 0.287001, acc: 95.31%] [G loss: 4.167784]\n",
      "epoch:29 step:22780 [D loss: 0.592104, acc: 67.19%] [G loss: 5.251426]\n",
      "epoch:29 step:22781 [D loss: 0.263645, acc: 95.31%] [G loss: 4.506446]\n",
      "epoch:29 step:22782 [D loss: 0.164265, acc: 96.88%] [G loss: 5.865501]\n",
      "epoch:29 step:22783 [D loss: 0.450970, acc: 73.44%] [G loss: 4.983184]\n",
      "epoch:29 step:22784 [D loss: 0.540077, acc: 64.84%] [G loss: 4.413406]\n",
      "epoch:29 step:22785 [D loss: 0.048450, acc: 100.00%] [G loss: 6.596103]\n",
      "epoch:29 step:22786 [D loss: 0.518002, acc: 71.09%] [G loss: 3.664191]\n",
      "epoch:29 step:22787 [D loss: 0.303518, acc: 95.31%] [G loss: 4.778986]\n",
      "epoch:29 step:22788 [D loss: 0.626999, acc: 64.06%] [G loss: 4.638945]\n",
      "epoch:29 step:22789 [D loss: 0.425890, acc: 86.72%] [G loss: 4.078388]\n",
      "epoch:29 step:22790 [D loss: 0.437896, acc: 82.03%] [G loss: 2.558616]\n",
      "epoch:29 step:22791 [D loss: 0.114582, acc: 100.00%] [G loss: 3.907378]\n",
      "epoch:29 step:22792 [D loss: 0.281624, acc: 96.09%] [G loss: 2.603501]\n",
      "epoch:29 step:22793 [D loss: 0.593621, acc: 70.31%] [G loss: 4.571791]\n",
      "epoch:29 step:22794 [D loss: 0.272343, acc: 92.19%] [G loss: 5.005864]\n",
      "epoch:29 step:22795 [D loss: 0.587495, acc: 62.50%] [G loss: 2.347865]\n",
      "epoch:29 step:22796 [D loss: 0.299370, acc: 96.88%] [G loss: 4.220190]\n",
      "epoch:29 step:22797 [D loss: 0.667437, acc: 52.34%] [G loss: 4.519249]\n",
      "epoch:29 step:22798 [D loss: 0.267125, acc: 93.75%] [G loss: 3.126943]\n",
      "epoch:29 step:22799 [D loss: 0.390702, acc: 80.47%] [G loss: 6.571290]\n",
      "epoch:29 step:22800 [D loss: 0.245026, acc: 97.66%] [G loss: 4.910315]\n",
      "epoch:29 step:22801 [D loss: 0.289365, acc: 89.06%] [G loss: 4.971299]\n",
      "epoch:29 step:22802 [D loss: 0.540638, acc: 75.00%] [G loss: 4.900672]\n",
      "epoch:29 step:22803 [D loss: 1.047514, acc: 50.00%] [G loss: 3.484807]\n",
      "epoch:29 step:22804 [D loss: 0.459126, acc: 67.19%] [G loss: 4.452891]\n",
      "epoch:29 step:22805 [D loss: 0.570567, acc: 72.66%] [G loss: 3.687532]\n",
      "epoch:29 step:22806 [D loss: 0.322354, acc: 85.94%] [G loss: 4.945829]\n",
      "epoch:29 step:22807 [D loss: 0.095721, acc: 99.22%] [G loss: 5.250062]\n",
      "epoch:29 step:22808 [D loss: 0.487394, acc: 64.06%] [G loss: 7.325566]\n",
      "epoch:29 step:22809 [D loss: 0.929941, acc: 51.56%] [G loss: 3.127124]\n",
      "epoch:29 step:22810 [D loss: 0.266958, acc: 92.19%] [G loss: 6.649837]\n",
      "epoch:29 step:22811 [D loss: 0.181767, acc: 97.66%] [G loss: 5.087808]\n",
      "epoch:29 step:22812 [D loss: 0.176332, acc: 96.88%] [G loss: 3.388339]\n",
      "epoch:29 step:22813 [D loss: 1.282805, acc: 50.00%] [G loss: 4.491616]\n",
      "epoch:29 step:22814 [D loss: 0.464387, acc: 68.75%] [G loss: 2.685502]\n",
      "epoch:29 step:22815 [D loss: 0.555490, acc: 71.09%] [G loss: 4.283452]\n",
      "epoch:29 step:22816 [D loss: 0.626279, acc: 60.94%] [G loss: 4.251545]\n",
      "epoch:29 step:22817 [D loss: 0.155989, acc: 99.22%] [G loss: 3.466032]\n",
      "epoch:29 step:22818 [D loss: 0.332351, acc: 82.81%] [G loss: 4.384255]\n",
      "epoch:29 step:22819 [D loss: 0.459768, acc: 82.81%] [G loss: 2.399701]\n",
      "epoch:29 step:22820 [D loss: 0.092317, acc: 100.00%] [G loss: 3.897265]\n",
      "epoch:29 step:22821 [D loss: 1.091114, acc: 21.88%] [G loss: 4.168332]\n",
      "epoch:29 step:22822 [D loss: 0.800578, acc: 53.12%] [G loss: 2.478638]\n",
      "epoch:29 step:22823 [D loss: 0.437496, acc: 71.09%] [G loss: 5.018582]\n",
      "epoch:29 step:22824 [D loss: 0.077172, acc: 99.22%] [G loss: 4.454105]\n",
      "epoch:29 step:22825 [D loss: 0.856433, acc: 53.91%] [G loss: 4.224012]\n",
      "epoch:29 step:22826 [D loss: 0.274621, acc: 93.75%] [G loss: 3.300613]\n",
      "epoch:29 step:22827 [D loss: 0.447703, acc: 71.88%] [G loss: 4.153889]\n",
      "epoch:29 step:22828 [D loss: 0.533307, acc: 73.44%] [G loss: 5.598486]\n",
      "epoch:29 step:22829 [D loss: 0.364702, acc: 85.16%] [G loss: 2.486035]\n",
      "epoch:29 step:22830 [D loss: 0.228278, acc: 99.22%] [G loss: 3.016056]\n",
      "epoch:29 step:22831 [D loss: 0.527718, acc: 68.75%] [G loss: 4.116065]\n",
      "epoch:29 step:22832 [D loss: 0.641384, acc: 64.84%] [G loss: 3.052274]\n",
      "epoch:29 step:22833 [D loss: 0.469452, acc: 83.59%] [G loss: 4.120966]\n",
      "epoch:29 step:22834 [D loss: 0.098143, acc: 100.00%] [G loss: 5.586240]\n",
      "epoch:29 step:22835 [D loss: 0.113304, acc: 99.22%] [G loss: 4.990293]\n",
      "epoch:29 step:22836 [D loss: 0.087577, acc: 100.00%] [G loss: 4.946024]\n",
      "epoch:29 step:22837 [D loss: 0.227208, acc: 96.09%] [G loss: 3.885265]\n",
      "epoch:29 step:22838 [D loss: 0.500931, acc: 61.72%] [G loss: 5.443318]\n",
      "epoch:29 step:22839 [D loss: 0.427602, acc: 75.00%] [G loss: 4.303925]\n",
      "epoch:29 step:22840 [D loss: 0.521884, acc: 71.09%] [G loss: 2.814945]\n",
      "epoch:29 step:22841 [D loss: 0.627702, acc: 65.62%] [G loss: 4.687507]\n",
      "epoch:29 step:22842 [D loss: 0.372483, acc: 83.59%] [G loss: 2.480802]\n",
      "epoch:29 step:22843 [D loss: 0.030279, acc: 100.00%] [G loss: 5.165728]\n",
      "epoch:29 step:22844 [D loss: 1.027943, acc: 20.31%] [G loss: 5.215714]\n",
      "epoch:29 step:22845 [D loss: 0.730874, acc: 50.78%] [G loss: 5.875339]\n",
      "epoch:29 step:22846 [D loss: 0.292879, acc: 84.38%] [G loss: 4.849513]\n",
      "epoch:29 step:22847 [D loss: 0.767671, acc: 53.12%] [G loss: 2.761734]\n",
      "epoch:29 step:22848 [D loss: 0.686408, acc: 53.91%] [G loss: 5.634148]\n",
      "epoch:29 step:22849 [D loss: 0.461616, acc: 82.03%] [G loss: 6.116383]\n",
      "epoch:29 step:22850 [D loss: 0.709066, acc: 55.47%] [G loss: 3.150488]\n",
      "epoch:29 step:22851 [D loss: 0.518235, acc: 67.19%] [G loss: 3.624922]\n",
      "epoch:29 step:22852 [D loss: 0.090999, acc: 100.00%] [G loss: 2.704872]\n",
      "epoch:29 step:22853 [D loss: 0.286416, acc: 85.94%] [G loss: 4.087077]\n",
      "epoch:29 step:22854 [D loss: 0.110298, acc: 100.00%] [G loss: 4.119236]\n",
      "epoch:29 step:22855 [D loss: 0.072479, acc: 100.00%] [G loss: 4.626052]\n",
      "epoch:29 step:22856 [D loss: 0.361148, acc: 94.53%] [G loss: 3.211846]\n",
      "epoch:29 step:22857 [D loss: 0.182355, acc: 97.66%] [G loss: 3.967060]\n",
      "epoch:29 step:22858 [D loss: 0.539400, acc: 78.91%] [G loss: 2.745008]\n",
      "epoch:29 step:22859 [D loss: 0.498058, acc: 71.88%] [G loss: 3.393282]\n",
      "epoch:29 step:22860 [D loss: 0.142730, acc: 98.44%] [G loss: 2.780482]\n",
      "epoch:29 step:22861 [D loss: 0.204672, acc: 99.22%] [G loss: 4.142209]\n",
      "epoch:29 step:22862 [D loss: 0.110375, acc: 100.00%] [G loss: 5.400188]\n",
      "epoch:29 step:22863 [D loss: 0.465193, acc: 74.22%] [G loss: 5.428171]\n",
      "epoch:29 step:22864 [D loss: 0.401809, acc: 77.34%] [G loss: 5.479012]\n",
      "epoch:29 step:22865 [D loss: 0.153791, acc: 98.44%] [G loss: 4.469242]\n",
      "epoch:29 step:22866 [D loss: 0.106529, acc: 100.00%] [G loss: 4.793132]\n",
      "epoch:29 step:22867 [D loss: 0.593294, acc: 64.06%] [G loss: 2.954257]\n",
      "epoch:29 step:22868 [D loss: 0.043577, acc: 100.00%] [G loss: 3.128547]\n",
      "epoch:29 step:22869 [D loss: 0.732251, acc: 52.34%] [G loss: 4.303449]\n",
      "epoch:29 step:22870 [D loss: 0.391292, acc: 92.19%] [G loss: 4.760969]\n",
      "epoch:29 step:22871 [D loss: 0.440928, acc: 82.81%] [G loss: 2.679183]\n",
      "epoch:29 step:22872 [D loss: 0.505861, acc: 73.44%] [G loss: 3.503418]\n",
      "epoch:29 step:22873 [D loss: 0.759284, acc: 57.03%] [G loss: 5.203741]\n",
      "epoch:29 step:22874 [D loss: 1.461963, acc: 15.62%] [G loss: 4.546923]\n",
      "epoch:29 step:22875 [D loss: 0.492272, acc: 80.47%] [G loss: 3.829121]\n",
      "epoch:29 step:22876 [D loss: 0.146980, acc: 97.66%] [G loss: 4.191880]\n",
      "epoch:29 step:22877 [D loss: 0.105116, acc: 100.00%] [G loss: 5.283756]\n",
      "epoch:29 step:22878 [D loss: 0.482807, acc: 71.88%] [G loss: 4.628658]\n",
      "epoch:29 step:22879 [D loss: 0.237406, acc: 92.97%] [G loss: 3.960600]\n",
      "epoch:29 step:22880 [D loss: 0.209743, acc: 94.53%] [G loss: 3.103274]\n",
      "epoch:29 step:22881 [D loss: 1.368608, acc: 49.22%] [G loss: 2.555754]\n",
      "epoch:29 step:22882 [D loss: 0.330193, acc: 94.53%] [G loss: 4.281524]\n",
      "epoch:29 step:22883 [D loss: 0.249030, acc: 92.97%] [G loss: 4.969811]\n",
      "epoch:29 step:22884 [D loss: 1.176863, acc: 38.28%] [G loss: 3.476260]\n",
      "epoch:29 step:22885 [D loss: 0.991881, acc: 33.59%] [G loss: 4.142804]\n",
      "epoch:29 step:22886 [D loss: 2.148089, acc: 6.25%] [G loss: 3.796324]\n",
      "epoch:29 step:22887 [D loss: 0.072544, acc: 99.22%] [G loss: 5.818259]\n",
      "epoch:29 step:22888 [D loss: 0.392591, acc: 82.81%] [G loss: 3.613450]\n",
      "epoch:29 step:22889 [D loss: 0.421833, acc: 80.47%] [G loss: 4.377496]\n",
      "epoch:29 step:22890 [D loss: 0.706685, acc: 56.25%] [G loss: 3.863931]\n",
      "epoch:29 step:22891 [D loss: 0.022474, acc: 100.00%] [G loss: 5.487638]\n",
      "epoch:29 step:22892 [D loss: 0.213281, acc: 96.09%] [G loss: 2.741125]\n",
      "epoch:29 step:22893 [D loss: 0.200932, acc: 97.66%] [G loss: 2.642734]\n",
      "epoch:29 step:22894 [D loss: 0.319861, acc: 89.06%] [G loss: 3.786616]\n",
      "epoch:29 step:22895 [D loss: 1.400577, acc: 7.81%] [G loss: 5.361478]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:22896 [D loss: 0.240964, acc: 99.22%] [G loss: 3.335211]\n",
      "epoch:29 step:22897 [D loss: 0.056413, acc: 100.00%] [G loss: 4.703954]\n",
      "epoch:29 step:22898 [D loss: 0.303451, acc: 95.31%] [G loss: 3.497593]\n",
      "epoch:29 step:22899 [D loss: 0.107349, acc: 98.44%] [G loss: 4.099364]\n",
      "epoch:29 step:22900 [D loss: 0.105299, acc: 99.22%] [G loss: 3.424773]\n",
      "epoch:29 step:22901 [D loss: 0.793919, acc: 50.00%] [G loss: 3.314281]\n",
      "epoch:29 step:22902 [D loss: 0.510882, acc: 67.19%] [G loss: 3.585682]\n",
      "epoch:29 step:22903 [D loss: 0.676606, acc: 54.69%] [G loss: 4.071003]\n",
      "epoch:29 step:22904 [D loss: 0.100440, acc: 99.22%] [G loss: 3.461090]\n",
      "epoch:29 step:22905 [D loss: 0.245549, acc: 96.88%] [G loss: 2.859835]\n",
      "epoch:29 step:22906 [D loss: 0.676078, acc: 57.81%] [G loss: 3.991666]\n",
      "epoch:29 step:22907 [D loss: 0.148692, acc: 98.44%] [G loss: 3.039978]\n",
      "epoch:29 step:22908 [D loss: 0.296539, acc: 91.41%] [G loss: 4.245081]\n",
      "epoch:29 step:22909 [D loss: 0.265136, acc: 96.88%] [G loss: 3.094025]\n",
      "epoch:29 step:22910 [D loss: 0.177095, acc: 98.44%] [G loss: 2.983779]\n",
      "epoch:29 step:22911 [D loss: 0.157948, acc: 99.22%] [G loss: 4.216235]\n",
      "epoch:29 step:22912 [D loss: 0.933387, acc: 51.56%] [G loss: 4.863931]\n",
      "epoch:29 step:22913 [D loss: 0.474691, acc: 68.75%] [G loss: 3.115393]\n",
      "epoch:29 step:22914 [D loss: 0.062042, acc: 100.00%] [G loss: 4.933391]\n",
      "epoch:29 step:22915 [D loss: 0.875982, acc: 50.78%] [G loss: 4.961008]\n",
      "epoch:29 step:22916 [D loss: 1.204910, acc: 21.88%] [G loss: 4.669959]\n",
      "epoch:29 step:22917 [D loss: 0.215107, acc: 97.66%] [G loss: 4.193300]\n",
      "epoch:29 step:22918 [D loss: 0.183851, acc: 100.00%] [G loss: 3.479284]\n",
      "epoch:29 step:22919 [D loss: 0.666873, acc: 57.03%] [G loss: 3.551324]\n",
      "epoch:29 step:22920 [D loss: 0.505432, acc: 78.91%] [G loss: 3.817376]\n",
      "epoch:29 step:22921 [D loss: 0.402046, acc: 85.94%] [G loss: 4.400406]\n",
      "epoch:29 step:22922 [D loss: 0.203502, acc: 98.44%] [G loss: 2.679662]\n",
      "epoch:29 step:22923 [D loss: 0.271361, acc: 90.62%] [G loss: 4.696941]\n",
      "epoch:29 step:22924 [D loss: 0.365159, acc: 84.38%] [G loss: 2.688450]\n",
      "epoch:29 step:22925 [D loss: 0.406261, acc: 92.97%] [G loss: 3.832354]\n",
      "epoch:29 step:22926 [D loss: 1.067523, acc: 50.00%] [G loss: 2.798882]\n",
      "epoch:29 step:22927 [D loss: 0.820317, acc: 50.00%] [G loss: 4.491091]\n",
      "epoch:29 step:22928 [D loss: 0.790789, acc: 54.69%] [G loss: 2.922547]\n",
      "epoch:29 step:22929 [D loss: 1.056347, acc: 18.75%] [G loss: 3.365903]\n",
      "epoch:29 step:22930 [D loss: 0.626815, acc: 59.38%] [G loss: 3.931242]\n",
      "epoch:29 step:22931 [D loss: 0.497184, acc: 67.19%] [G loss: 5.799304]\n",
      "epoch:29 step:22932 [D loss: 0.814558, acc: 46.88%] [G loss: 4.241961]\n",
      "epoch:29 step:22933 [D loss: 0.393561, acc: 75.78%] [G loss: 3.478212]\n",
      "epoch:29 step:22934 [D loss: 0.219984, acc: 96.88%] [G loss: 4.479769]\n",
      "epoch:29 step:22935 [D loss: 0.173733, acc: 99.22%] [G loss: 3.910208]\n",
      "epoch:29 step:22936 [D loss: 0.753596, acc: 53.91%] [G loss: 3.721036]\n",
      "epoch:29 step:22937 [D loss: 0.844821, acc: 42.97%] [G loss: 5.316477]\n",
      "epoch:29 step:22938 [D loss: 0.695224, acc: 53.12%] [G loss: 5.004165]\n",
      "epoch:29 step:22939 [D loss: 0.688408, acc: 57.03%] [G loss: 4.282242]\n",
      "epoch:29 step:22940 [D loss: 1.060638, acc: 32.03%] [G loss: 3.957029]\n",
      "epoch:29 step:22941 [D loss: 0.178609, acc: 98.44%] [G loss: 3.840454]\n",
      "epoch:29 step:22942 [D loss: 0.220736, acc: 95.31%] [G loss: 3.913191]\n",
      "epoch:29 step:22943 [D loss: 0.655821, acc: 64.84%] [G loss: 2.011003]\n",
      "epoch:29 step:22944 [D loss: 0.709388, acc: 54.69%] [G loss: 2.878863]\n",
      "epoch:29 step:22945 [D loss: 0.093248, acc: 99.22%] [G loss: 6.389760]\n",
      "epoch:29 step:22946 [D loss: 0.806320, acc: 55.47%] [G loss: 2.184860]\n",
      "epoch:29 step:22947 [D loss: 0.293458, acc: 92.19%] [G loss: 4.936829]\n",
      "epoch:29 step:22948 [D loss: 0.250134, acc: 97.66%] [G loss: 4.605223]\n",
      "epoch:29 step:22949 [D loss: 0.948911, acc: 43.75%] [G loss: 2.439944]\n",
      "epoch:29 step:22950 [D loss: 0.837689, acc: 52.34%] [G loss: 4.787264]\n",
      "epoch:29 step:22951 [D loss: 0.291900, acc: 94.53%] [G loss: 4.406064]\n",
      "epoch:29 step:22952 [D loss: 0.631923, acc: 59.38%] [G loss: 3.235448]\n",
      "epoch:29 step:22953 [D loss: 0.255490, acc: 96.88%] [G loss: 3.973772]\n",
      "epoch:29 step:22954 [D loss: 1.061779, acc: 49.22%] [G loss: 6.427837]\n",
      "epoch:29 step:22955 [D loss: 0.232717, acc: 96.09%] [G loss: 3.351600]\n",
      "epoch:29 step:22956 [D loss: 0.219886, acc: 98.44%] [G loss: 3.525244]\n",
      "epoch:29 step:22957 [D loss: 0.114903, acc: 100.00%] [G loss: 4.446275]\n",
      "epoch:29 step:22958 [D loss: 0.865541, acc: 51.56%] [G loss: 2.391504]\n",
      "epoch:29 step:22959 [D loss: 0.048742, acc: 100.00%] [G loss: 3.998055]\n",
      "epoch:29 step:22960 [D loss: 0.408994, acc: 77.34%] [G loss: 5.324425]\n",
      "epoch:29 step:22961 [D loss: 0.446651, acc: 78.12%] [G loss: 2.587325]\n",
      "epoch:29 step:22962 [D loss: 0.425537, acc: 82.81%] [G loss: 4.455810]\n",
      "epoch:29 step:22963 [D loss: 0.128564, acc: 99.22%] [G loss: 5.193136]\n",
      "epoch:29 step:22964 [D loss: 1.693214, acc: 28.91%] [G loss: 5.111206]\n",
      "epoch:29 step:22965 [D loss: 1.043130, acc: 50.00%] [G loss: 3.936043]\n",
      "epoch:29 step:22966 [D loss: 0.384198, acc: 90.62%] [G loss: 4.163234]\n",
      "epoch:29 step:22967 [D loss: 0.234602, acc: 93.75%] [G loss: 4.337826]\n",
      "epoch:29 step:22968 [D loss: 0.386845, acc: 85.16%] [G loss: 4.853673]\n",
      "epoch:29 step:22969 [D loss: 0.638690, acc: 64.84%] [G loss: 3.180969]\n",
      "epoch:29 step:22970 [D loss: 0.191227, acc: 99.22%] [G loss: 4.495901]\n",
      "epoch:29 step:22971 [D loss: 0.150287, acc: 97.66%] [G loss: 3.860353]\n",
      "epoch:29 step:22972 [D loss: 0.271882, acc: 94.53%] [G loss: 3.268225]\n",
      "epoch:29 step:22973 [D loss: 0.347897, acc: 93.75%] [G loss: 2.045274]\n",
      "epoch:29 step:22974 [D loss: 0.194348, acc: 98.44%] [G loss: 5.174471]\n",
      "epoch:29 step:22975 [D loss: 0.092684, acc: 100.00%] [G loss: 4.492117]\n",
      "epoch:29 step:22976 [D loss: 0.137778, acc: 99.22%] [G loss: 3.579203]\n",
      "epoch:29 step:22977 [D loss: 0.184040, acc: 99.22%] [G loss: 2.746276]\n",
      "epoch:29 step:22978 [D loss: 0.410945, acc: 84.38%] [G loss: 5.826528]\n",
      "epoch:29 step:22979 [D loss: 0.530126, acc: 78.12%] [G loss: 4.728893]\n",
      "epoch:29 step:22980 [D loss: 0.521515, acc: 64.84%] [G loss: 7.316336]\n",
      "epoch:29 step:22981 [D loss: 0.552845, acc: 70.31%] [G loss: 4.736405]\n",
      "epoch:29 step:22982 [D loss: 0.295979, acc: 85.16%] [G loss: 6.430895]\n",
      "epoch:29 step:22983 [D loss: 0.223362, acc: 99.22%] [G loss: 5.530347]\n",
      "epoch:29 step:22984 [D loss: 0.182433, acc: 95.31%] [G loss: 4.774805]\n",
      "epoch:29 step:22985 [D loss: 0.523356, acc: 66.41%] [G loss: 5.987556]\n",
      "epoch:29 step:22986 [D loss: 0.668150, acc: 64.06%] [G loss: 5.005806]\n",
      "epoch:29 step:22987 [D loss: 0.362196, acc: 82.03%] [G loss: 3.862741]\n",
      "epoch:29 step:22988 [D loss: 0.284091, acc: 95.31%] [G loss: 6.169023]\n",
      "epoch:29 step:22989 [D loss: 0.491563, acc: 78.12%] [G loss: 2.839216]\n",
      "epoch:29 step:22990 [D loss: 0.349389, acc: 80.47%] [G loss: 4.286200]\n",
      "epoch:29 step:22991 [D loss: 0.246238, acc: 91.41%] [G loss: 3.804506]\n",
      "epoch:29 step:22992 [D loss: 0.389915, acc: 82.81%] [G loss: 4.131978]\n",
      "epoch:29 step:22993 [D loss: 0.259481, acc: 96.88%] [G loss: 5.240969]\n",
      "epoch:29 step:22994 [D loss: 0.176356, acc: 98.44%] [G loss: 3.108085]\n",
      "epoch:29 step:22995 [D loss: 0.649903, acc: 60.16%] [G loss: 4.760614]\n",
      "epoch:29 step:22996 [D loss: 0.221934, acc: 97.66%] [G loss: 4.074695]\n",
      "epoch:29 step:22997 [D loss: 0.745385, acc: 51.56%] [G loss: 4.124691]\n",
      "epoch:29 step:22998 [D loss: 1.054944, acc: 50.78%] [G loss: 2.268148]\n",
      "epoch:29 step:22999 [D loss: 0.077833, acc: 100.00%] [G loss: 4.499957]\n",
      "epoch:29 step:23000 [D loss: 0.709177, acc: 54.69%] [G loss: 3.851377]\n",
      "epoch:29 step:23001 [D loss: 0.446664, acc: 71.09%] [G loss: 4.662771]\n",
      "epoch:29 step:23002 [D loss: 0.119836, acc: 100.00%] [G loss: 5.225372]\n",
      "epoch:29 step:23003 [D loss: 0.242841, acc: 93.75%] [G loss: 2.713071]\n",
      "epoch:29 step:23004 [D loss: 0.532862, acc: 76.56%] [G loss: 3.323116]\n",
      "epoch:29 step:23005 [D loss: 0.949011, acc: 27.34%] [G loss: 2.993642]\n",
      "epoch:29 step:23006 [D loss: 0.426274, acc: 85.16%] [G loss: 2.319845]\n",
      "epoch:29 step:23007 [D loss: 0.515038, acc: 78.12%] [G loss: 4.261493]\n",
      "epoch:29 step:23008 [D loss: 0.419885, acc: 88.28%] [G loss: 2.833809]\n",
      "epoch:29 step:23009 [D loss: 0.972999, acc: 34.38%] [G loss: 3.538469]\n",
      "epoch:29 step:23010 [D loss: 0.512410, acc: 75.00%] [G loss: 4.329727]\n",
      "epoch:29 step:23011 [D loss: 0.444857, acc: 85.94%] [G loss: 4.352698]\n",
      "epoch:29 step:23012 [D loss: 0.583065, acc: 64.06%] [G loss: 4.753985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:23013 [D loss: 0.316877, acc: 97.66%] [G loss: 3.329608]\n",
      "epoch:29 step:23014 [D loss: 0.068369, acc: 100.00%] [G loss: 4.977949]\n",
      "epoch:29 step:23015 [D loss: 0.648423, acc: 61.72%] [G loss: 2.881237]\n",
      "epoch:29 step:23016 [D loss: 1.100818, acc: 48.44%] [G loss: 4.980034]\n",
      "epoch:29 step:23017 [D loss: 0.452074, acc: 85.16%] [G loss: 3.447739]\n",
      "epoch:29 step:23018 [D loss: 0.229910, acc: 94.53%] [G loss: 4.224412]\n",
      "epoch:29 step:23019 [D loss: 0.910186, acc: 50.00%] [G loss: 3.638499]\n",
      "epoch:29 step:23020 [D loss: 0.216280, acc: 98.44%] [G loss: 4.412738]\n",
      "epoch:29 step:23021 [D loss: 1.002215, acc: 50.78%] [G loss: 3.407443]\n",
      "epoch:29 step:23022 [D loss: 1.063080, acc: 28.91%] [G loss: 3.143199]\n",
      "epoch:29 step:23023 [D loss: 0.960859, acc: 50.00%] [G loss: 3.514496]\n",
      "epoch:29 step:23024 [D loss: 0.108215, acc: 100.00%] [G loss: 5.232065]\n",
      "epoch:29 step:23025 [D loss: 0.831284, acc: 50.78%] [G loss: 4.351479]\n",
      "epoch:29 step:23026 [D loss: 0.552487, acc: 70.31%] [G loss: 4.656403]\n",
      "epoch:29 step:23027 [D loss: 0.678044, acc: 56.25%] [G loss: 3.289479]\n",
      "epoch:29 step:23028 [D loss: 0.165997, acc: 99.22%] [G loss: 4.470490]\n",
      "epoch:29 step:23029 [D loss: 0.574451, acc: 61.72%] [G loss: 3.607622]\n",
      "epoch:29 step:23030 [D loss: 0.207859, acc: 98.44%] [G loss: 3.812138]\n",
      "epoch:29 step:23031 [D loss: 0.341308, acc: 88.28%] [G loss: 3.956996]\n",
      "epoch:29 step:23032 [D loss: 0.509274, acc: 69.53%] [G loss: 4.727778]\n",
      "epoch:29 step:23033 [D loss: 0.186419, acc: 98.44%] [G loss: 3.221558]\n",
      "epoch:29 step:23034 [D loss: 0.556500, acc: 68.75%] [G loss: 4.837581]\n",
      "epoch:29 step:23035 [D loss: 0.241576, acc: 96.09%] [G loss: 4.686281]\n",
      "epoch:29 step:23036 [D loss: 0.578861, acc: 62.50%] [G loss: 3.731283]\n",
      "epoch:29 step:23037 [D loss: 0.533323, acc: 80.47%] [G loss: 4.455620]\n",
      "epoch:29 step:23038 [D loss: 0.251960, acc: 95.31%] [G loss: 3.886364]\n",
      "epoch:29 step:23039 [D loss: 0.188224, acc: 99.22%] [G loss: 3.579177]\n",
      "epoch:29 step:23040 [D loss: 1.221216, acc: 14.06%] [G loss: 3.791988]\n",
      "epoch:29 step:23041 [D loss: 0.440856, acc: 82.81%] [G loss: 2.920271]\n",
      "epoch:29 step:23042 [D loss: 0.177678, acc: 99.22%] [G loss: 3.665434]\n",
      "epoch:29 step:23043 [D loss: 0.128503, acc: 98.44%] [G loss: 5.260142]\n",
      "epoch:29 step:23044 [D loss: 0.574952, acc: 64.84%] [G loss: 2.696665]\n",
      "epoch:29 step:23045 [D loss: 0.839996, acc: 42.97%] [G loss: 3.197371]\n",
      "epoch:29 step:23046 [D loss: 0.576699, acc: 60.94%] [G loss: 5.897334]\n",
      "epoch:29 step:23047 [D loss: 0.510108, acc: 71.88%] [G loss: 4.266730]\n",
      "epoch:29 step:23048 [D loss: 0.231754, acc: 98.44%] [G loss: 4.510137]\n",
      "epoch:29 step:23049 [D loss: 0.205283, acc: 96.88%] [G loss: 3.361851]\n",
      "epoch:29 step:23050 [D loss: 0.254994, acc: 89.06%] [G loss: 5.364786]\n",
      "epoch:29 step:23051 [D loss: 0.191125, acc: 99.22%] [G loss: 6.057855]\n",
      "epoch:29 step:23052 [D loss: 0.622412, acc: 58.59%] [G loss: 4.118803]\n",
      "epoch:29 step:23053 [D loss: 0.739974, acc: 54.69%] [G loss: 4.501245]\n",
      "epoch:29 step:23054 [D loss: 0.830552, acc: 50.78%] [G loss: 3.588467]\n",
      "epoch:29 step:23055 [D loss: 0.241595, acc: 96.09%] [G loss: 3.495946]\n",
      "epoch:29 step:23056 [D loss: 0.465285, acc: 72.66%] [G loss: 3.843799]\n",
      "epoch:29 step:23057 [D loss: 0.264232, acc: 92.19%] [G loss: 4.634373]\n",
      "epoch:29 step:23058 [D loss: 0.705231, acc: 53.12%] [G loss: 4.319741]\n",
      "epoch:29 step:23059 [D loss: 0.139654, acc: 98.44%] [G loss: 3.147797]\n",
      "epoch:29 step:23060 [D loss: 0.252789, acc: 98.44%] [G loss: 4.797078]\n",
      "epoch:29 step:23061 [D loss: 0.395494, acc: 89.06%] [G loss: 5.029966]\n",
      "epoch:29 step:23062 [D loss: 0.146947, acc: 100.00%] [G loss: 5.999745]\n",
      "epoch:29 step:23063 [D loss: 0.269599, acc: 95.31%] [G loss: 4.020640]\n",
      "epoch:29 step:23064 [D loss: 0.508650, acc: 71.09%] [G loss: 3.492270]\n",
      "epoch:29 step:23065 [D loss: 0.540018, acc: 73.44%] [G loss: 3.699086]\n",
      "epoch:29 step:23066 [D loss: 0.204651, acc: 98.44%] [G loss: 4.550866]\n",
      "epoch:29 step:23067 [D loss: 0.328703, acc: 91.41%] [G loss: 3.939076]\n",
      "epoch:29 step:23068 [D loss: 0.300450, acc: 96.09%] [G loss: 3.623744]\n",
      "epoch:29 step:23069 [D loss: 0.348519, acc: 82.81%] [G loss: 2.590098]\n",
      "epoch:29 step:23070 [D loss: 0.322395, acc: 92.97%] [G loss: 3.423952]\n",
      "epoch:29 step:23071 [D loss: 0.160665, acc: 100.00%] [G loss: 3.543249]\n",
      "epoch:29 step:23072 [D loss: 0.800016, acc: 52.34%] [G loss: 2.210588]\n",
      "epoch:29 step:23073 [D loss: 0.869454, acc: 47.66%] [G loss: 3.773854]\n",
      "epoch:29 step:23074 [D loss: 0.843990, acc: 50.78%] [G loss: 4.659238]\n",
      "epoch:29 step:23075 [D loss: 0.258202, acc: 95.31%] [G loss: 3.621065]\n",
      "epoch:29 step:23076 [D loss: 0.521552, acc: 65.62%] [G loss: 4.886065]\n",
      "epoch:29 step:23077 [D loss: 0.509305, acc: 80.47%] [G loss: 2.817485]\n",
      "epoch:29 step:23078 [D loss: 0.418635, acc: 83.59%] [G loss: 3.425464]\n",
      "epoch:29 step:23079 [D loss: 0.319969, acc: 91.41%] [G loss: 4.479984]\n",
      "epoch:29 step:23080 [D loss: 0.394382, acc: 82.03%] [G loss: 2.915306]\n",
      "epoch:29 step:23081 [D loss: 0.541152, acc: 68.75%] [G loss: 3.105840]\n",
      "epoch:29 step:23082 [D loss: 0.593138, acc: 58.59%] [G loss: 5.482957]\n",
      "epoch:29 step:23083 [D loss: 0.103285, acc: 99.22%] [G loss: 6.150196]\n",
      "epoch:29 step:23084 [D loss: 0.133206, acc: 100.00%] [G loss: 5.130635]\n",
      "epoch:29 step:23085 [D loss: 0.692985, acc: 59.38%] [G loss: 3.550418]\n",
      "epoch:29 step:23086 [D loss: 0.828219, acc: 42.97%] [G loss: 2.609886]\n",
      "epoch:29 step:23087 [D loss: 0.112802, acc: 100.00%] [G loss: 3.281142]\n",
      "epoch:29 step:23088 [D loss: 0.163805, acc: 98.44%] [G loss: 4.534081]\n",
      "epoch:29 step:23089 [D loss: 0.283192, acc: 89.84%] [G loss: 4.421529]\n",
      "epoch:29 step:23090 [D loss: 0.983264, acc: 49.22%] [G loss: 3.353051]\n",
      "epoch:29 step:23091 [D loss: 0.368532, acc: 90.62%] [G loss: 4.765219]\n",
      "epoch:29 step:23092 [D loss: 0.450120, acc: 85.16%] [G loss: 5.460550]\n",
      "epoch:29 step:23093 [D loss: 0.356308, acc: 85.16%] [G loss: 4.311630]\n",
      "epoch:29 step:23094 [D loss: 0.941677, acc: 47.66%] [G loss: 2.961045]\n",
      "epoch:29 step:23095 [D loss: 0.183341, acc: 100.00%] [G loss: 3.487259]\n",
      "epoch:29 step:23096 [D loss: 0.282393, acc: 98.44%] [G loss: 3.445656]\n",
      "epoch:29 step:23097 [D loss: 0.226791, acc: 96.88%] [G loss: 3.578196]\n",
      "epoch:29 step:23098 [D loss: 1.157573, acc: 28.12%] [G loss: 4.666166]\n",
      "epoch:29 step:23099 [D loss: 0.181552, acc: 99.22%] [G loss: 5.211325]\n",
      "epoch:29 step:23100 [D loss: 0.735524, acc: 53.12%] [G loss: 2.681147]\n",
      "epoch:29 step:23101 [D loss: 0.460826, acc: 76.56%] [G loss: 2.179848]\n",
      "epoch:29 step:23102 [D loss: 0.401785, acc: 87.50%] [G loss: 3.304513]\n",
      "epoch:29 step:23103 [D loss: 0.943737, acc: 26.56%] [G loss: 4.871921]\n",
      "epoch:29 step:23104 [D loss: 0.369090, acc: 84.38%] [G loss: 3.345559]\n",
      "epoch:29 step:23105 [D loss: 1.169640, acc: 20.31%] [G loss: 4.053524]\n",
      "epoch:29 step:23106 [D loss: 0.388408, acc: 78.91%] [G loss: 4.127810]\n",
      "epoch:29 step:23107 [D loss: 0.108612, acc: 99.22%] [G loss: 3.492676]\n",
      "epoch:29 step:23108 [D loss: 0.229909, acc: 97.66%] [G loss: 3.742881]\n",
      "epoch:29 step:23109 [D loss: 0.206573, acc: 96.88%] [G loss: 3.497018]\n",
      "epoch:29 step:23110 [D loss: 0.041523, acc: 100.00%] [G loss: 4.418833]\n",
      "epoch:29 step:23111 [D loss: 0.609661, acc: 61.72%] [G loss: 5.229885]\n",
      "epoch:29 step:23112 [D loss: 0.762986, acc: 51.56%] [G loss: 5.605427]\n",
      "epoch:29 step:23113 [D loss: 0.227267, acc: 92.97%] [G loss: 3.381026]\n",
      "epoch:29 step:23114 [D loss: 0.556183, acc: 67.97%] [G loss: 5.623136]\n",
      "epoch:29 step:23115 [D loss: 0.037410, acc: 100.00%] [G loss: 7.016624]\n",
      "epoch:29 step:23116 [D loss: 0.575996, acc: 57.81%] [G loss: 5.318613]\n",
      "epoch:29 step:23117 [D loss: 0.577189, acc: 67.97%] [G loss: 6.949033]\n",
      "epoch:29 step:23118 [D loss: 0.322335, acc: 93.75%] [G loss: 4.461308]\n",
      "epoch:29 step:23119 [D loss: 0.150383, acc: 97.66%] [G loss: 3.779881]\n",
      "epoch:29 step:23120 [D loss: 0.097218, acc: 100.00%] [G loss: 3.557093]\n",
      "epoch:29 step:23121 [D loss: 0.216759, acc: 99.22%] [G loss: 4.461572]\n",
      "epoch:29 step:23122 [D loss: 0.911665, acc: 44.53%] [G loss: 3.371175]\n",
      "epoch:29 step:23123 [D loss: 0.706398, acc: 54.69%] [G loss: 3.697011]\n",
      "epoch:29 step:23124 [D loss: 0.721973, acc: 53.91%] [G loss: 3.625912]\n",
      "epoch:29 step:23125 [D loss: 0.144676, acc: 98.44%] [G loss: 4.800788]\n",
      "epoch:29 step:23126 [D loss: 0.806138, acc: 52.34%] [G loss: 4.678848]\n",
      "epoch:29 step:23127 [D loss: 0.317996, acc: 96.09%] [G loss: 5.370498]\n",
      "epoch:29 step:23128 [D loss: 0.947948, acc: 51.56%] [G loss: 4.234538]\n",
      "epoch:29 step:23129 [D loss: 0.555814, acc: 67.19%] [G loss: 4.422758]\n",
      "epoch:29 step:23130 [D loss: 0.203036, acc: 98.44%] [G loss: 4.763755]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:23131 [D loss: 1.130311, acc: 27.34%] [G loss: 5.229471]\n",
      "epoch:29 step:23132 [D loss: 0.090623, acc: 100.00%] [G loss: 3.244109]\n",
      "epoch:29 step:23133 [D loss: 0.309021, acc: 88.28%] [G loss: 4.514396]\n",
      "epoch:29 step:23134 [D loss: 0.241308, acc: 92.19%] [G loss: 4.565396]\n",
      "epoch:29 step:23135 [D loss: 0.357052, acc: 91.41%] [G loss: 4.797473]\n",
      "epoch:29 step:23136 [D loss: 0.569772, acc: 68.75%] [G loss: 3.596121]\n",
      "epoch:29 step:23137 [D loss: 0.430979, acc: 82.81%] [G loss: 3.322129]\n",
      "epoch:29 step:23138 [D loss: 0.151336, acc: 96.88%] [G loss: 3.675693]\n",
      "epoch:29 step:23139 [D loss: 0.202084, acc: 95.31%] [G loss: 7.703509]\n",
      "epoch:29 step:23140 [D loss: 0.556543, acc: 66.41%] [G loss: 2.514032]\n",
      "epoch:29 step:23141 [D loss: 0.827759, acc: 48.44%] [G loss: 4.707274]\n",
      "epoch:29 step:23142 [D loss: 0.278812, acc: 91.41%] [G loss: 3.513994]\n",
      "epoch:29 step:23143 [D loss: 0.433915, acc: 84.38%] [G loss: 6.326117]\n",
      "epoch:29 step:23144 [D loss: 0.168247, acc: 99.22%] [G loss: 4.017161]\n",
      "epoch:29 step:23145 [D loss: 0.482644, acc: 83.59%] [G loss: 5.724994]\n",
      "epoch:29 step:23146 [D loss: 0.340210, acc: 92.97%] [G loss: 3.901653]\n",
      "epoch:29 step:23147 [D loss: 0.328567, acc: 95.31%] [G loss: 4.612857]\n",
      "epoch:29 step:23148 [D loss: 0.203899, acc: 95.31%] [G loss: 4.378273]\n",
      "epoch:29 step:23149 [D loss: 0.155328, acc: 99.22%] [G loss: 5.218645]\n",
      "epoch:29 step:23150 [D loss: 0.378709, acc: 89.06%] [G loss: 4.208558]\n",
      "epoch:29 step:23151 [D loss: 0.099605, acc: 100.00%] [G loss: 5.663373]\n",
      "epoch:29 step:23152 [D loss: 0.366882, acc: 89.06%] [G loss: 5.366188]\n",
      "epoch:29 step:23153 [D loss: 1.547783, acc: 38.28%] [G loss: 2.895357]\n",
      "epoch:29 step:23154 [D loss: 0.270625, acc: 92.19%] [G loss: 4.366569]\n",
      "epoch:29 step:23155 [D loss: 0.298218, acc: 91.41%] [G loss: 3.754917]\n",
      "epoch:29 step:23156 [D loss: 0.337578, acc: 82.03%] [G loss: 6.095681]\n",
      "epoch:29 step:23157 [D loss: 0.226675, acc: 95.31%] [G loss: 2.874615]\n",
      "epoch:29 step:23158 [D loss: 0.348143, acc: 79.69%] [G loss: 5.071864]\n",
      "epoch:29 step:23159 [D loss: 0.280216, acc: 92.97%] [G loss: 4.236414]\n",
      "epoch:29 step:23160 [D loss: 0.077762, acc: 99.22%] [G loss: 5.507411]\n",
      "epoch:29 step:23161 [D loss: 0.243541, acc: 93.75%] [G loss: 4.174350]\n",
      "epoch:29 step:23162 [D loss: 0.236309, acc: 96.09%] [G loss: 2.969397]\n",
      "epoch:29 step:23163 [D loss: 1.209867, acc: 14.06%] [G loss: 4.315360]\n",
      "epoch:29 step:23164 [D loss: 0.542287, acc: 64.06%] [G loss: 3.464588]\n",
      "epoch:29 step:23165 [D loss: 0.186254, acc: 99.22%] [G loss: 2.707852]\n",
      "epoch:29 step:23166 [D loss: 0.057690, acc: 100.00%] [G loss: 5.216926]\n",
      "epoch:29 step:23167 [D loss: 0.835587, acc: 50.78%] [G loss: 5.303808]\n",
      "epoch:29 step:23168 [D loss: 0.599769, acc: 63.28%] [G loss: 2.608019]\n",
      "epoch:29 step:23169 [D loss: 0.204507, acc: 97.66%] [G loss: 3.577723]\n",
      "epoch:29 step:23170 [D loss: 0.615413, acc: 61.72%] [G loss: 4.368855]\n",
      "epoch:29 step:23171 [D loss: 0.509919, acc: 78.91%] [G loss: 4.023285]\n",
      "epoch:29 step:23172 [D loss: 0.434856, acc: 85.16%] [G loss: 4.583995]\n",
      "epoch:29 step:23173 [D loss: 0.450368, acc: 84.38%] [G loss: 4.327319]\n",
      "epoch:29 step:23174 [D loss: 0.271568, acc: 93.75%] [G loss: 4.296487]\n",
      "epoch:29 step:23175 [D loss: 0.733113, acc: 53.91%] [G loss: 5.367213]\n",
      "epoch:29 step:23176 [D loss: 0.739553, acc: 53.91%] [G loss: 4.740444]\n",
      "epoch:29 step:23177 [D loss: 0.103039, acc: 99.22%] [G loss: 3.444707]\n",
      "epoch:29 step:23178 [D loss: 0.560744, acc: 76.56%] [G loss: 4.715775]\n",
      "epoch:29 step:23179 [D loss: 0.389074, acc: 81.25%] [G loss: 4.399267]\n",
      "epoch:29 step:23180 [D loss: 0.423315, acc: 89.06%] [G loss: 6.802193]\n",
      "epoch:29 step:23181 [D loss: 0.541237, acc: 75.00%] [G loss: 4.470525]\n",
      "epoch:29 step:23182 [D loss: 0.264302, acc: 87.50%] [G loss: 5.340600]\n",
      "epoch:29 step:23183 [D loss: 0.258479, acc: 94.53%] [G loss: 3.284849]\n",
      "epoch:29 step:23184 [D loss: 0.163347, acc: 99.22%] [G loss: 5.875272]\n",
      "epoch:29 step:23185 [D loss: 0.451088, acc: 73.44%] [G loss: 5.874396]\n",
      "epoch:29 step:23186 [D loss: 0.161322, acc: 99.22%] [G loss: 5.385224]\n",
      "epoch:29 step:23187 [D loss: 0.389353, acc: 85.16%] [G loss: 4.367740]\n",
      "epoch:29 step:23188 [D loss: 0.640067, acc: 67.97%] [G loss: 5.076624]\n",
      "epoch:29 step:23189 [D loss: 0.977999, acc: 50.00%] [G loss: 2.323940]\n",
      "epoch:29 step:23190 [D loss: 0.482596, acc: 70.31%] [G loss: 3.970491]\n",
      "epoch:29 step:23191 [D loss: 0.438480, acc: 74.22%] [G loss: 6.217734]\n",
      "epoch:29 step:23192 [D loss: 0.244642, acc: 97.66%] [G loss: 4.314001]\n",
      "epoch:29 step:23193 [D loss: 0.145856, acc: 99.22%] [G loss: 5.592494]\n",
      "epoch:29 step:23194 [D loss: 0.093565, acc: 99.22%] [G loss: 2.754238]\n",
      "epoch:29 step:23195 [D loss: 0.632295, acc: 62.50%] [G loss: 3.173996]\n",
      "epoch:29 step:23196 [D loss: 0.986032, acc: 38.28%] [G loss: 2.227954]\n",
      "epoch:29 step:23197 [D loss: 1.036591, acc: 22.66%] [G loss: 5.359045]\n",
      "epoch:29 step:23198 [D loss: 0.916551, acc: 42.97%] [G loss: 3.990321]\n",
      "epoch:29 step:23199 [D loss: 0.336978, acc: 87.50%] [G loss: 4.650843]\n",
      "epoch:29 step:23200 [D loss: 0.251558, acc: 96.88%] [G loss: 3.332445]\n",
      "epoch:29 step:23201 [D loss: 1.028625, acc: 31.25%] [G loss: 6.597194]\n",
      "epoch:29 step:23202 [D loss: 0.387019, acc: 88.28%] [G loss: 5.208745]\n",
      "epoch:29 step:23203 [D loss: 0.516058, acc: 77.34%] [G loss: 2.668425]\n",
      "epoch:29 step:23204 [D loss: 0.226178, acc: 92.97%] [G loss: 3.521122]\n",
      "epoch:29 step:23205 [D loss: 0.268768, acc: 98.44%] [G loss: 3.041111]\n",
      "epoch:29 step:23206 [D loss: 0.410317, acc: 82.81%] [G loss: 4.713537]\n",
      "epoch:29 step:23207 [D loss: 0.364225, acc: 83.59%] [G loss: 3.623526]\n",
      "epoch:29 step:23208 [D loss: 0.296026, acc: 89.06%] [G loss: 6.109566]\n",
      "epoch:29 step:23209 [D loss: 0.700646, acc: 57.81%] [G loss: 4.182695]\n",
      "epoch:29 step:23210 [D loss: 0.101636, acc: 100.00%] [G loss: 5.743993]\n",
      "epoch:29 step:23211 [D loss: 0.247121, acc: 96.09%] [G loss: 3.771867]\n",
      "epoch:29 step:23212 [D loss: 0.443571, acc: 82.03%] [G loss: 3.810220]\n",
      "epoch:29 step:23213 [D loss: 0.130051, acc: 100.00%] [G loss: 7.192041]\n",
      "epoch:29 step:23214 [D loss: 0.608838, acc: 60.94%] [G loss: 4.659312]\n",
      "epoch:29 step:23215 [D loss: 0.157057, acc: 98.44%] [G loss: 4.305397]\n",
      "epoch:29 step:23216 [D loss: 0.344752, acc: 90.62%] [G loss: 4.459875]\n",
      "epoch:29 step:23217 [D loss: 0.639360, acc: 61.72%] [G loss: 4.542274]\n",
      "epoch:29 step:23218 [D loss: 0.439333, acc: 85.16%] [G loss: 4.904663]\n",
      "epoch:29 step:23219 [D loss: 0.915818, acc: 53.12%] [G loss: 7.057103]\n",
      "epoch:29 step:23220 [D loss: 0.348469, acc: 88.28%] [G loss: 3.919350]\n",
      "epoch:29 step:23221 [D loss: 0.160119, acc: 99.22%] [G loss: 2.487415]\n",
      "epoch:29 step:23222 [D loss: 0.249502, acc: 96.09%] [G loss: 4.080619]\n",
      "epoch:29 step:23223 [D loss: 0.245803, acc: 97.66%] [G loss: 3.782144]\n",
      "epoch:29 step:23224 [D loss: 0.307503, acc: 88.28%] [G loss: 2.271635]\n",
      "epoch:29 step:23225 [D loss: 0.296904, acc: 89.06%] [G loss: 5.519579]\n",
      "epoch:29 step:23226 [D loss: 0.365558, acc: 92.97%] [G loss: 4.256045]\n",
      "epoch:29 step:23227 [D loss: 0.399752, acc: 87.50%] [G loss: 2.998289]\n",
      "epoch:29 step:23228 [D loss: 0.176509, acc: 97.66%] [G loss: 3.862785]\n",
      "epoch:29 step:23229 [D loss: 0.538875, acc: 75.00%] [G loss: 4.109601]\n",
      "epoch:29 step:23230 [D loss: 0.067850, acc: 99.22%] [G loss: 4.147596]\n",
      "epoch:29 step:23231 [D loss: 0.618157, acc: 62.50%] [G loss: 4.696820]\n",
      "epoch:29 step:23232 [D loss: 0.140086, acc: 100.00%] [G loss: 2.355577]\n",
      "epoch:29 step:23233 [D loss: 0.954389, acc: 33.59%] [G loss: 5.046597]\n",
      "epoch:29 step:23234 [D loss: 0.227652, acc: 96.88%] [G loss: 4.035973]\n",
      "epoch:29 step:23235 [D loss: 0.123275, acc: 100.00%] [G loss: 5.226119]\n",
      "epoch:29 step:23236 [D loss: 0.501881, acc: 75.78%] [G loss: 3.052867]\n",
      "epoch:29 step:23237 [D loss: 0.568019, acc: 75.78%] [G loss: 4.056833]\n",
      "epoch:29 step:23238 [D loss: 0.535618, acc: 75.00%] [G loss: 4.921810]\n",
      "epoch:29 step:23239 [D loss: 0.658195, acc: 58.59%] [G loss: 3.514331]\n",
      "epoch:29 step:23240 [D loss: 0.884703, acc: 53.12%] [G loss: 5.078208]\n",
      "epoch:29 step:23241 [D loss: 0.261900, acc: 93.75%] [G loss: 5.235022]\n",
      "epoch:29 step:23242 [D loss: 0.915653, acc: 37.50%] [G loss: 4.931308]\n",
      "epoch:29 step:23243 [D loss: 0.534221, acc: 78.12%] [G loss: 2.739640]\n",
      "epoch:29 step:23244 [D loss: 0.604488, acc: 61.72%] [G loss: 2.127397]\n",
      "epoch:29 step:23245 [D loss: 0.129351, acc: 100.00%] [G loss: 4.882121]\n",
      "epoch:29 step:23246 [D loss: 0.123923, acc: 99.22%] [G loss: 4.438347]\n",
      "epoch:29 step:23247 [D loss: 0.520350, acc: 67.19%] [G loss: 4.492733]\n",
      "epoch:29 step:23248 [D loss: 0.486971, acc: 85.94%] [G loss: 3.990407]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:23249 [D loss: 0.327997, acc: 93.75%] [G loss: 1.998566]\n",
      "epoch:29 step:23250 [D loss: 0.055061, acc: 100.00%] [G loss: 3.582379]\n",
      "epoch:29 step:23251 [D loss: 0.470323, acc: 87.50%] [G loss: 3.289993]\n",
      "epoch:29 step:23252 [D loss: 0.686599, acc: 58.59%] [G loss: 5.031303]\n",
      "epoch:29 step:23253 [D loss: 0.778053, acc: 46.88%] [G loss: 5.268393]\n",
      "epoch:29 step:23254 [D loss: 0.418973, acc: 72.66%] [G loss: 5.025053]\n",
      "epoch:29 step:23255 [D loss: 0.364187, acc: 78.91%] [G loss: 5.148772]\n",
      "epoch:29 step:23256 [D loss: 0.730078, acc: 54.69%] [G loss: 3.113159]\n",
      "epoch:29 step:23257 [D loss: 0.573769, acc: 71.09%] [G loss: 5.245721]\n",
      "epoch:29 step:23258 [D loss: 0.157685, acc: 96.88%] [G loss: 3.768906]\n",
      "epoch:29 step:23259 [D loss: 0.335106, acc: 85.94%] [G loss: 2.144935]\n",
      "epoch:29 step:23260 [D loss: 0.122629, acc: 99.22%] [G loss: 4.388760]\n",
      "epoch:29 step:23261 [D loss: 0.618729, acc: 61.72%] [G loss: 3.859891]\n",
      "epoch:29 step:23262 [D loss: 0.053895, acc: 100.00%] [G loss: 6.299066]\n",
      "epoch:29 step:23263 [D loss: 0.182064, acc: 99.22%] [G loss: 6.189000]\n",
      "epoch:29 step:23264 [D loss: 0.090352, acc: 100.00%] [G loss: 4.708801]\n",
      "epoch:29 step:23265 [D loss: 0.338570, acc: 86.72%] [G loss: 5.198171]\n",
      "epoch:29 step:23266 [D loss: 0.131817, acc: 99.22%] [G loss: 3.120888]\n",
      "epoch:29 step:23267 [D loss: 0.686697, acc: 52.34%] [G loss: 4.727042]\n",
      "epoch:29 step:23268 [D loss: 0.351509, acc: 91.41%] [G loss: 1.775416]\n",
      "epoch:29 step:23269 [D loss: 0.218798, acc: 97.66%] [G loss: 2.996181]\n",
      "epoch:29 step:23270 [D loss: 0.566025, acc: 70.31%] [G loss: 3.518394]\n",
      "epoch:29 step:23271 [D loss: 1.895937, acc: 25.00%] [G loss: 5.221302]\n",
      "epoch:29 step:23272 [D loss: 0.396345, acc: 89.06%] [G loss: 5.139776]\n",
      "epoch:29 step:23273 [D loss: 0.395562, acc: 78.91%] [G loss: 6.203985]\n",
      "epoch:29 step:23274 [D loss: 0.422847, acc: 81.25%] [G loss: 4.050191]\n",
      "epoch:29 step:23275 [D loss: 0.397161, acc: 82.03%] [G loss: 5.122545]\n",
      "epoch:29 step:23276 [D loss: 0.431246, acc: 79.69%] [G loss: 3.728675]\n",
      "epoch:29 step:23277 [D loss: 0.173823, acc: 100.00%] [G loss: 3.999602]\n",
      "epoch:29 step:23278 [D loss: 0.164632, acc: 98.44%] [G loss: 6.298705]\n",
      "epoch:29 step:23279 [D loss: 0.101543, acc: 99.22%] [G loss: 5.288488]\n",
      "epoch:29 step:23280 [D loss: 0.701275, acc: 55.47%] [G loss: 2.853318]\n",
      "epoch:29 step:23281 [D loss: 0.296102, acc: 89.84%] [G loss: 6.461381]\n",
      "epoch:29 step:23282 [D loss: 1.253161, acc: 42.19%] [G loss: 5.287276]\n",
      "epoch:29 step:23283 [D loss: 0.180786, acc: 98.44%] [G loss: 4.378014]\n",
      "epoch:29 step:23284 [D loss: 0.471347, acc: 78.91%] [G loss: 5.480944]\n",
      "epoch:29 step:23285 [D loss: 0.230807, acc: 93.75%] [G loss: 5.397161]\n",
      "epoch:29 step:23286 [D loss: 0.754297, acc: 50.78%] [G loss: 4.353015]\n",
      "epoch:29 step:23287 [D loss: 0.675841, acc: 59.38%] [G loss: 2.182963]\n",
      "epoch:29 step:23288 [D loss: 0.323981, acc: 91.41%] [G loss: 3.363797]\n",
      "epoch:29 step:23289 [D loss: 0.076571, acc: 100.00%] [G loss: 5.543736]\n",
      "epoch:29 step:23290 [D loss: 1.062003, acc: 25.00%] [G loss: 5.364083]\n",
      "epoch:29 step:23291 [D loss: 0.802449, acc: 46.09%] [G loss: 5.642908]\n",
      "epoch:29 step:23292 [D loss: 0.341460, acc: 89.84%] [G loss: 2.860058]\n",
      "epoch:29 step:23293 [D loss: 0.464303, acc: 75.00%] [G loss: 5.822088]\n",
      "epoch:29 step:23294 [D loss: 1.092327, acc: 41.41%] [G loss: 6.558569]\n",
      "epoch:29 step:23295 [D loss: 0.609083, acc: 67.97%] [G loss: 2.856043]\n",
      "epoch:29 step:23296 [D loss: 0.421874, acc: 80.47%] [G loss: 4.784349]\n",
      "epoch:29 step:23297 [D loss: 0.165285, acc: 100.00%] [G loss: 6.233408]\n",
      "epoch:29 step:23298 [D loss: 0.346951, acc: 81.25%] [G loss: 4.740293]\n",
      "epoch:29 step:23299 [D loss: 0.939886, acc: 39.84%] [G loss: 5.496449]\n",
      "epoch:29 step:23300 [D loss: 0.538512, acc: 70.31%] [G loss: 2.674072]\n",
      "epoch:29 step:23301 [D loss: 0.509376, acc: 80.47%] [G loss: 4.304799]\n",
      "epoch:29 step:23302 [D loss: 0.204259, acc: 99.22%] [G loss: 3.005073]\n",
      "epoch:29 step:23303 [D loss: 0.365052, acc: 89.06%] [G loss: 4.430254]\n",
      "epoch:29 step:23304 [D loss: 0.125972, acc: 99.22%] [G loss: 2.987530]\n",
      "epoch:29 step:23305 [D loss: 0.663126, acc: 60.16%] [G loss: 4.140283]\n",
      "epoch:29 step:23306 [D loss: 0.416879, acc: 70.31%] [G loss: 7.004590]\n",
      "epoch:29 step:23307 [D loss: 0.398646, acc: 85.16%] [G loss: 3.497552]\n",
      "epoch:29 step:23308 [D loss: 0.822120, acc: 51.56%] [G loss: 4.483411]\n",
      "epoch:29 step:23309 [D loss: 0.232187, acc: 97.66%] [G loss: 4.578279]\n",
      "epoch:29 step:23310 [D loss: 0.672859, acc: 61.72%] [G loss: 4.766800]\n",
      "epoch:29 step:23311 [D loss: 0.583771, acc: 64.84%] [G loss: 5.471380]\n",
      "epoch:29 step:23312 [D loss: 0.572413, acc: 64.84%] [G loss: 4.349477]\n",
      "epoch:29 step:23313 [D loss: 0.368454, acc: 77.34%] [G loss: 5.040453]\n",
      "epoch:29 step:23314 [D loss: 0.852068, acc: 31.25%] [G loss: 4.123755]\n",
      "epoch:29 step:23315 [D loss: 0.240045, acc: 96.09%] [G loss: 3.424409]\n",
      "epoch:29 step:23316 [D loss: 0.584702, acc: 60.16%] [G loss: 4.982791]\n",
      "epoch:29 step:23317 [D loss: 0.277552, acc: 85.16%] [G loss: 4.350257]\n",
      "epoch:29 step:23318 [D loss: 0.667649, acc: 62.50%] [G loss: 4.479279]\n",
      "epoch:29 step:23319 [D loss: 0.720603, acc: 57.81%] [G loss: 5.251574]\n",
      "epoch:29 step:23320 [D loss: 0.954120, acc: 36.72%] [G loss: 4.630077]\n",
      "epoch:29 step:23321 [D loss: 0.501861, acc: 81.25%] [G loss: 3.206518]\n",
      "epoch:29 step:23322 [D loss: 0.797417, acc: 52.34%] [G loss: 3.972232]\n",
      "epoch:29 step:23323 [D loss: 1.416134, acc: 25.00%] [G loss: 4.857799]\n",
      "epoch:29 step:23324 [D loss: 0.598555, acc: 67.97%] [G loss: 4.311895]\n",
      "epoch:29 step:23325 [D loss: 0.646974, acc: 59.38%] [G loss: 4.940927]\n",
      "epoch:29 step:23326 [D loss: 0.352463, acc: 90.62%] [G loss: 3.079634]\n",
      "epoch:29 step:23327 [D loss: 0.502669, acc: 67.97%] [G loss: 6.110478]\n",
      "epoch:29 step:23328 [D loss: 0.535004, acc: 71.88%] [G loss: 3.561762]\n",
      "epoch:29 step:23329 [D loss: 0.296340, acc: 95.31%] [G loss: 4.174361]\n",
      "epoch:29 step:23330 [D loss: 0.646900, acc: 70.31%] [G loss: 7.086274]\n",
      "epoch:29 step:23331 [D loss: 0.232278, acc: 92.97%] [G loss: 5.112517]\n",
      "epoch:29 step:23332 [D loss: 0.484439, acc: 74.22%] [G loss: 3.353326]\n",
      "epoch:29 step:23333 [D loss: 1.099878, acc: 50.00%] [G loss: 4.571675]\n",
      "epoch:29 step:23334 [D loss: 0.429743, acc: 68.75%] [G loss: 4.451793]\n",
      "epoch:29 step:23335 [D loss: 0.471010, acc: 76.56%] [G loss: 4.703916]\n",
      "epoch:29 step:23336 [D loss: 0.904810, acc: 53.91%] [G loss: 5.028570]\n",
      "epoch:29 step:23337 [D loss: 0.403087, acc: 77.34%] [G loss: 5.533564]\n",
      "epoch:29 step:23338 [D loss: 0.369085, acc: 90.62%] [G loss: 4.412520]\n",
      "epoch:29 step:23339 [D loss: 0.122875, acc: 100.00%] [G loss: 6.946186]\n",
      "epoch:29 step:23340 [D loss: 0.501984, acc: 75.78%] [G loss: 4.615987]\n",
      "epoch:29 step:23341 [D loss: 1.142111, acc: 48.44%] [G loss: 5.690165]\n",
      "epoch:29 step:23342 [D loss: 0.498520, acc: 63.28%] [G loss: 7.399363]\n",
      "epoch:29 step:23343 [D loss: 0.067936, acc: 100.00%] [G loss: 5.152107]\n",
      "epoch:29 step:23344 [D loss: 0.076451, acc: 100.00%] [G loss: 4.977345]\n",
      "epoch:29 step:23345 [D loss: 0.197030, acc: 99.22%] [G loss: 2.917854]\n",
      "epoch:29 step:23346 [D loss: 0.379972, acc: 87.50%] [G loss: 4.426925]\n",
      "epoch:29 step:23347 [D loss: 0.213659, acc: 99.22%] [G loss: 3.233284]\n",
      "epoch:29 step:23348 [D loss: 0.176357, acc: 100.00%] [G loss: 2.937210]\n",
      "epoch:29 step:23349 [D loss: 0.289389, acc: 91.41%] [G loss: 3.942892]\n",
      "epoch:29 step:23350 [D loss: 0.409449, acc: 75.00%] [G loss: 5.559002]\n",
      "epoch:29 step:23351 [D loss: 0.172719, acc: 99.22%] [G loss: 3.837328]\n",
      "epoch:29 step:23352 [D loss: 1.098589, acc: 50.00%] [G loss: 2.875484]\n",
      "epoch:29 step:23353 [D loss: 0.376756, acc: 82.81%] [G loss: 4.200620]\n",
      "epoch:29 step:23354 [D loss: 0.612354, acc: 64.84%] [G loss: 5.349715]\n",
      "epoch:29 step:23355 [D loss: 0.390413, acc: 85.94%] [G loss: 4.854448]\n",
      "epoch:29 step:23356 [D loss: 0.050751, acc: 100.00%] [G loss: 6.511696]\n",
      "epoch:29 step:23357 [D loss: 0.167687, acc: 96.88%] [G loss: 6.348699]\n",
      "epoch:29 step:23358 [D loss: 0.592511, acc: 61.72%] [G loss: 6.276139]\n",
      "epoch:29 step:23359 [D loss: 0.359993, acc: 88.28%] [G loss: 3.644283]\n",
      "epoch:29 step:23360 [D loss: 0.131991, acc: 98.44%] [G loss: 3.089121]\n",
      "epoch:29 step:23361 [D loss: 0.301784, acc: 90.62%] [G loss: 3.924944]\n",
      "epoch:29 step:23362 [D loss: 0.137305, acc: 100.00%] [G loss: 3.415898]\n",
      "epoch:29 step:23363 [D loss: 0.616980, acc: 55.47%] [G loss: 3.667622]\n",
      "epoch:29 step:23364 [D loss: 0.581876, acc: 66.41%] [G loss: 4.808867]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:23365 [D loss: 0.172174, acc: 99.22%] [G loss: 5.751388]\n",
      "epoch:29 step:23366 [D loss: 0.135864, acc: 99.22%] [G loss: 4.370101]\n",
      "epoch:29 step:23367 [D loss: 0.131146, acc: 98.44%] [G loss: 3.131267]\n",
      "epoch:29 step:23368 [D loss: 0.278846, acc: 93.75%] [G loss: 2.970582]\n",
      "epoch:29 step:23369 [D loss: 0.772883, acc: 54.69%] [G loss: 3.429289]\n",
      "epoch:29 step:23370 [D loss: 0.316347, acc: 94.53%] [G loss: 3.536938]\n",
      "epoch:29 step:23371 [D loss: 0.725059, acc: 59.38%] [G loss: 5.032452]\n",
      "epoch:29 step:23372 [D loss: 0.037194, acc: 100.00%] [G loss: 5.642761]\n",
      "epoch:29 step:23373 [D loss: 0.272984, acc: 95.31%] [G loss: 3.590559]\n",
      "epoch:29 step:23374 [D loss: 0.287554, acc: 98.44%] [G loss: 5.217981]\n",
      "epoch:29 step:23375 [D loss: 0.112715, acc: 100.00%] [G loss: 4.909518]\n",
      "epoch:29 step:23376 [D loss: 0.213518, acc: 99.22%] [G loss: 2.725003]\n",
      "epoch:29 step:23377 [D loss: 0.048869, acc: 100.00%] [G loss: 5.450119]\n",
      "epoch:29 step:23378 [D loss: 0.364609, acc: 85.94%] [G loss: 6.549629]\n",
      "epoch:29 step:23379 [D loss: 0.520327, acc: 75.78%] [G loss: 1.982189]\n",
      "epoch:29 step:23380 [D loss: 0.357020, acc: 92.19%] [G loss: 6.032160]\n",
      "epoch:29 step:23381 [D loss: 0.859171, acc: 49.22%] [G loss: 2.347698]\n",
      "epoch:29 step:23382 [D loss: 0.133941, acc: 96.88%] [G loss: 3.354568]\n",
      "epoch:29 step:23383 [D loss: 0.376695, acc: 78.91%] [G loss: 4.076289]\n",
      "epoch:29 step:23384 [D loss: 0.456152, acc: 82.81%] [G loss: 2.950951]\n",
      "epoch:29 step:23385 [D loss: 0.608585, acc: 64.06%] [G loss: 4.726994]\n",
      "epoch:29 step:23386 [D loss: 0.567622, acc: 72.66%] [G loss: 4.202158]\n",
      "epoch:29 step:23387 [D loss: 0.105507, acc: 100.00%] [G loss: 3.599746]\n",
      "epoch:29 step:23388 [D loss: 0.196072, acc: 98.44%] [G loss: 2.643210]\n",
      "epoch:29 step:23389 [D loss: 0.107277, acc: 99.22%] [G loss: 3.899386]\n",
      "epoch:29 step:23390 [D loss: 0.222046, acc: 96.88%] [G loss: 4.072312]\n",
      "epoch:29 step:23391 [D loss: 0.267969, acc: 95.31%] [G loss: 4.054132]\n",
      "epoch:29 step:23392 [D loss: 0.114045, acc: 100.00%] [G loss: 2.715573]\n",
      "epoch:29 step:23393 [D loss: 0.853670, acc: 50.78%] [G loss: 4.725301]\n",
      "epoch:29 step:23394 [D loss: 0.140913, acc: 99.22%] [G loss: 4.135014]\n",
      "epoch:29 step:23395 [D loss: 0.299662, acc: 89.84%] [G loss: 4.451288]\n",
      "epoch:29 step:23396 [D loss: 0.386881, acc: 89.06%] [G loss: 3.895560]\n",
      "epoch:29 step:23397 [D loss: 0.111324, acc: 99.22%] [G loss: 5.144389]\n",
      "epoch:29 step:23398 [D loss: 0.244135, acc: 92.97%] [G loss: 5.252471]\n",
      "epoch:29 step:23399 [D loss: 0.839982, acc: 53.12%] [G loss: 3.819463]\n",
      "epoch:29 step:23400 [D loss: 0.698992, acc: 55.47%] [G loss: 5.567589]\n",
      "epoch:29 step:23401 [D loss: 0.296762, acc: 82.03%] [G loss: 4.500291]\n",
      "epoch:29 step:23402 [D loss: 0.791940, acc: 46.09%] [G loss: 3.370163]\n",
      "epoch:29 step:23403 [D loss: 0.342462, acc: 83.59%] [G loss: 3.022036]\n",
      "epoch:29 step:23404 [D loss: 0.795794, acc: 50.00%] [G loss: 5.004090]\n",
      "epoch:29 step:23405 [D loss: 0.544192, acc: 67.19%] [G loss: 5.156381]\n",
      "epoch:29 step:23406 [D loss: 0.503663, acc: 64.06%] [G loss: 3.539297]\n",
      "epoch:29 step:23407 [D loss: 0.568860, acc: 76.56%] [G loss: 4.979034]\n",
      "epoch:29 step:23408 [D loss: 0.258058, acc: 95.31%] [G loss: 2.719667]\n",
      "epoch:29 step:23409 [D loss: 0.134478, acc: 98.44%] [G loss: 8.768079]\n",
      "epoch:29 step:23410 [D loss: 0.157118, acc: 98.44%] [G loss: 5.101264]\n",
      "epoch:29 step:23411 [D loss: 0.173936, acc: 96.88%] [G loss: 7.010757]\n",
      "epoch:29 step:23412 [D loss: 0.727877, acc: 59.38%] [G loss: 3.813889]\n",
      "epoch:29 step:23413 [D loss: 0.116710, acc: 98.44%] [G loss: 4.196801]\n",
      "epoch:29 step:23414 [D loss: 0.345621, acc: 90.62%] [G loss: 5.065605]\n",
      "epoch:29 step:23415 [D loss: 0.292319, acc: 91.41%] [G loss: 4.523809]\n",
      "epoch:29 step:23416 [D loss: 0.154002, acc: 98.44%] [G loss: 5.164928]\n",
      "epoch:29 step:23417 [D loss: 0.113355, acc: 97.66%] [G loss: 9.309826]\n",
      "epoch:29 step:23418 [D loss: 0.613840, acc: 56.25%] [G loss: 7.794030]\n",
      "epoch:29 step:23419 [D loss: 0.320954, acc: 82.03%] [G loss: 3.617110]\n",
      "epoch:29 step:23420 [D loss: 0.137176, acc: 98.44%] [G loss: 5.524157]\n",
      "epoch:29 step:23421 [D loss: 1.414808, acc: 44.53%] [G loss: 3.140149]\n",
      "epoch:29 step:23422 [D loss: 0.099274, acc: 100.00%] [G loss: 3.472005]\n",
      "epoch:29 step:23423 [D loss: 0.521396, acc: 72.66%] [G loss: 5.647802]\n",
      "epoch:29 step:23424 [D loss: 1.472875, acc: 10.94%] [G loss: 5.043187]\n",
      "epoch:29 step:23425 [D loss: 1.175832, acc: 28.91%] [G loss: 6.359308]\n",
      "epoch:29 step:23426 [D loss: 0.477286, acc: 71.88%] [G loss: 4.811560]\n",
      "epoch:29 step:23427 [D loss: 1.020943, acc: 50.78%] [G loss: 4.616978]\n",
      "epoch:29 step:23428 [D loss: 0.427554, acc: 83.59%] [G loss: 2.296040]\n",
      "epoch:29 step:23429 [D loss: 0.724382, acc: 54.69%] [G loss: 4.027471]\n",
      "epoch:29 step:23430 [D loss: 1.381983, acc: 50.00%] [G loss: 6.587284]\n",
      "epoch:30 step:23431 [D loss: 0.163612, acc: 97.66%] [G loss: 5.239112]\n",
      "epoch:30 step:23432 [D loss: 0.363680, acc: 79.69%] [G loss: 5.685018]\n",
      "epoch:30 step:23433 [D loss: 0.534389, acc: 72.66%] [G loss: 5.653250]\n",
      "epoch:30 step:23434 [D loss: 0.573736, acc: 66.41%] [G loss: 3.856653]\n",
      "epoch:30 step:23435 [D loss: 0.233024, acc: 97.66%] [G loss: 2.640274]\n",
      "epoch:30 step:23436 [D loss: 0.478558, acc: 71.09%] [G loss: 3.504493]\n",
      "epoch:30 step:23437 [D loss: 0.385004, acc: 89.06%] [G loss: 5.042680]\n",
      "epoch:30 step:23438 [D loss: 0.433443, acc: 89.06%] [G loss: 3.568416]\n",
      "epoch:30 step:23439 [D loss: 0.349534, acc: 86.72%] [G loss: 3.025760]\n",
      "epoch:30 step:23440 [D loss: 0.847070, acc: 42.19%] [G loss: 3.977944]\n",
      "epoch:30 step:23441 [D loss: 0.400250, acc: 75.78%] [G loss: 3.578330]\n",
      "epoch:30 step:23442 [D loss: 0.230161, acc: 92.19%] [G loss: 3.235900]\n",
      "epoch:30 step:23443 [D loss: 0.177848, acc: 96.88%] [G loss: 5.911455]\n",
      "epoch:30 step:23444 [D loss: 0.930589, acc: 50.78%] [G loss: 5.262950]\n",
      "epoch:30 step:23445 [D loss: 0.634432, acc: 64.84%] [G loss: 1.357607]\n",
      "epoch:30 step:23446 [D loss: 1.088887, acc: 24.22%] [G loss: 2.862067]\n",
      "epoch:30 step:23447 [D loss: 0.155931, acc: 99.22%] [G loss: 2.337560]\n",
      "epoch:30 step:23448 [D loss: 0.437341, acc: 85.16%] [G loss: 3.107483]\n",
      "epoch:30 step:23449 [D loss: 0.663375, acc: 56.25%] [G loss: 3.984566]\n",
      "epoch:30 step:23450 [D loss: 1.012695, acc: 50.78%] [G loss: 4.077111]\n",
      "epoch:30 step:23451 [D loss: 0.139665, acc: 100.00%] [G loss: 4.512915]\n",
      "epoch:30 step:23452 [D loss: 0.429516, acc: 81.25%] [G loss: 4.602425]\n",
      "epoch:30 step:23453 [D loss: 0.284328, acc: 95.31%] [G loss: 3.599902]\n",
      "epoch:30 step:23454 [D loss: 0.467545, acc: 85.16%] [G loss: 4.077834]\n",
      "epoch:30 step:23455 [D loss: 0.124118, acc: 98.44%] [G loss: 4.683727]\n",
      "epoch:30 step:23456 [D loss: 0.513661, acc: 62.50%] [G loss: 5.456655]\n",
      "epoch:30 step:23457 [D loss: 0.229849, acc: 95.31%] [G loss: 4.007812]\n",
      "epoch:30 step:23458 [D loss: 0.381400, acc: 77.34%] [G loss: 6.104262]\n",
      "epoch:30 step:23459 [D loss: 0.281133, acc: 92.97%] [G loss: 3.891262]\n",
      "epoch:30 step:23460 [D loss: 0.082699, acc: 100.00%] [G loss: 6.190254]\n",
      "epoch:30 step:23461 [D loss: 0.613237, acc: 59.38%] [G loss: 2.994919]\n",
      "epoch:30 step:23462 [D loss: 0.240853, acc: 96.09%] [G loss: 5.940368]\n",
      "epoch:30 step:23463 [D loss: 0.185401, acc: 96.88%] [G loss: 3.580805]\n",
      "epoch:30 step:23464 [D loss: 0.635694, acc: 59.38%] [G loss: 5.226168]\n",
      "epoch:30 step:23465 [D loss: 0.374816, acc: 92.97%] [G loss: 3.262021]\n",
      "epoch:30 step:23466 [D loss: 0.115351, acc: 100.00%] [G loss: 4.231760]\n",
      "epoch:30 step:23467 [D loss: 0.098504, acc: 100.00%] [G loss: 3.900144]\n",
      "epoch:30 step:23468 [D loss: 0.904479, acc: 52.34%] [G loss: 4.112176]\n",
      "epoch:30 step:23469 [D loss: 0.336272, acc: 87.50%] [G loss: 1.916534]\n",
      "epoch:30 step:23470 [D loss: 0.419725, acc: 75.00%] [G loss: 4.810253]\n",
      "epoch:30 step:23471 [D loss: 0.645815, acc: 57.03%] [G loss: 3.596000]\n",
      "epoch:30 step:23472 [D loss: 0.336601, acc: 95.31%] [G loss: 2.202074]\n",
      "epoch:30 step:23473 [D loss: 0.942558, acc: 38.28%] [G loss: 3.198340]\n",
      "epoch:30 step:23474 [D loss: 0.424677, acc: 83.59%] [G loss: 3.423180]\n",
      "epoch:30 step:23475 [D loss: 0.184116, acc: 99.22%] [G loss: 3.982477]\n",
      "epoch:30 step:23476 [D loss: 0.423519, acc: 81.25%] [G loss: 4.168934]\n",
      "epoch:30 step:23477 [D loss: 0.531185, acc: 75.78%] [G loss: 5.190187]\n",
      "epoch:30 step:23478 [D loss: 0.501438, acc: 70.31%] [G loss: 2.724625]\n",
      "epoch:30 step:23479 [D loss: 0.346134, acc: 91.41%] [G loss: 9.419728]\n",
      "epoch:30 step:23480 [D loss: 0.132375, acc: 99.22%] [G loss: 3.227518]\n",
      "epoch:30 step:23481 [D loss: 0.351288, acc: 92.19%] [G loss: 4.291499]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23482 [D loss: 0.243762, acc: 99.22%] [G loss: 3.465379]\n",
      "epoch:30 step:23483 [D loss: 0.231674, acc: 98.44%] [G loss: 2.773599]\n",
      "epoch:30 step:23484 [D loss: 0.411323, acc: 89.06%] [G loss: 3.801657]\n",
      "epoch:30 step:23485 [D loss: 0.404408, acc: 84.38%] [G loss: 3.931607]\n",
      "epoch:30 step:23486 [D loss: 0.352043, acc: 92.19%] [G loss: 5.056710]\n",
      "epoch:30 step:23487 [D loss: 0.326373, acc: 94.53%] [G loss: 1.992072]\n",
      "epoch:30 step:23488 [D loss: 0.285347, acc: 96.88%] [G loss: 3.917196]\n",
      "epoch:30 step:23489 [D loss: 0.886087, acc: 40.62%] [G loss: 2.744218]\n",
      "epoch:30 step:23490 [D loss: 0.814631, acc: 50.00%] [G loss: 4.492849]\n",
      "epoch:30 step:23491 [D loss: 0.203116, acc: 96.88%] [G loss: 3.984132]\n",
      "epoch:30 step:23492 [D loss: 0.439985, acc: 75.00%] [G loss: 4.421394]\n",
      "epoch:30 step:23493 [D loss: 0.580097, acc: 59.38%] [G loss: 4.838346]\n",
      "epoch:30 step:23494 [D loss: 0.670808, acc: 54.69%] [G loss: 5.053266]\n",
      "epoch:30 step:23495 [D loss: 0.276819, acc: 96.88%] [G loss: 3.328112]\n",
      "epoch:30 step:23496 [D loss: 0.164116, acc: 99.22%] [G loss: 5.380373]\n",
      "epoch:30 step:23497 [D loss: 0.366121, acc: 89.84%] [G loss: 4.150493]\n",
      "epoch:30 step:23498 [D loss: 1.476430, acc: 50.00%] [G loss: 1.969734]\n",
      "epoch:30 step:23499 [D loss: 0.366655, acc: 89.84%] [G loss: 4.402038]\n",
      "epoch:30 step:23500 [D loss: 0.629295, acc: 61.72%] [G loss: 4.479846]\n",
      "epoch:30 step:23501 [D loss: 0.182107, acc: 98.44%] [G loss: 3.989471]\n",
      "epoch:30 step:23502 [D loss: 0.788266, acc: 42.19%] [G loss: 2.249191]\n",
      "epoch:30 step:23503 [D loss: 0.083819, acc: 100.00%] [G loss: 3.543530]\n",
      "epoch:30 step:23504 [D loss: 0.841879, acc: 35.94%] [G loss: 5.745309]\n",
      "epoch:30 step:23505 [D loss: 0.456327, acc: 73.44%] [G loss: 4.162127]\n",
      "epoch:30 step:23506 [D loss: 0.317438, acc: 87.50%] [G loss: 3.457142]\n",
      "epoch:30 step:23507 [D loss: 0.663098, acc: 59.38%] [G loss: 4.804406]\n",
      "epoch:30 step:23508 [D loss: 0.249456, acc: 96.88%] [G loss: 5.253491]\n",
      "epoch:30 step:23509 [D loss: 0.041026, acc: 100.00%] [G loss: 7.660823]\n",
      "epoch:30 step:23510 [D loss: 0.305206, acc: 96.88%] [G loss: 4.542198]\n",
      "epoch:30 step:23511 [D loss: 0.162219, acc: 97.66%] [G loss: 5.319174]\n",
      "epoch:30 step:23512 [D loss: 0.430940, acc: 79.69%] [G loss: 2.906075]\n",
      "epoch:30 step:23513 [D loss: 0.133448, acc: 100.00%] [G loss: 4.127257]\n",
      "epoch:30 step:23514 [D loss: 0.544044, acc: 64.84%] [G loss: 2.745265]\n",
      "epoch:30 step:23515 [D loss: 0.482803, acc: 71.09%] [G loss: 4.346379]\n",
      "epoch:30 step:23516 [D loss: 0.447245, acc: 71.88%] [G loss: 3.523267]\n",
      "epoch:30 step:23517 [D loss: 1.334538, acc: 21.09%] [G loss: 7.316905]\n",
      "epoch:30 step:23518 [D loss: 0.237926, acc: 96.09%] [G loss: 3.712635]\n",
      "epoch:30 step:23519 [D loss: 0.677363, acc: 56.25%] [G loss: 3.772756]\n",
      "epoch:30 step:23520 [D loss: 0.341838, acc: 92.97%] [G loss: 4.712206]\n",
      "epoch:30 step:23521 [D loss: 0.390581, acc: 82.81%] [G loss: 5.608725]\n",
      "epoch:30 step:23522 [D loss: 0.345043, acc: 85.16%] [G loss: 3.075371]\n",
      "epoch:30 step:23523 [D loss: 0.509573, acc: 69.53%] [G loss: 6.904445]\n",
      "epoch:30 step:23524 [D loss: 0.599622, acc: 61.72%] [G loss: 4.811534]\n",
      "epoch:30 step:23525 [D loss: 0.476478, acc: 73.44%] [G loss: 4.737242]\n",
      "epoch:30 step:23526 [D loss: 0.756217, acc: 53.12%] [G loss: 3.257600]\n",
      "epoch:30 step:23527 [D loss: 0.560883, acc: 75.78%] [G loss: 2.774582]\n",
      "epoch:30 step:23528 [D loss: 0.393737, acc: 82.03%] [G loss: 4.081880]\n",
      "epoch:30 step:23529 [D loss: 0.425052, acc: 89.06%] [G loss: 5.682980]\n",
      "epoch:30 step:23530 [D loss: 0.265192, acc: 92.19%] [G loss: 4.875855]\n",
      "epoch:30 step:23531 [D loss: 0.121134, acc: 100.00%] [G loss: 4.062316]\n",
      "epoch:30 step:23532 [D loss: 0.137237, acc: 99.22%] [G loss: 4.260870]\n",
      "epoch:30 step:23533 [D loss: 0.200693, acc: 97.66%] [G loss: 6.967702]\n",
      "epoch:30 step:23534 [D loss: 0.545823, acc: 70.31%] [G loss: 4.029656]\n",
      "epoch:30 step:23535 [D loss: 0.077257, acc: 100.00%] [G loss: 5.413976]\n",
      "epoch:30 step:23536 [D loss: 0.097673, acc: 100.00%] [G loss: 4.325463]\n",
      "epoch:30 step:23537 [D loss: 0.761922, acc: 53.91%] [G loss: 3.843692]\n",
      "epoch:30 step:23538 [D loss: 0.412367, acc: 87.50%] [G loss: 3.561890]\n",
      "epoch:30 step:23539 [D loss: 0.257318, acc: 96.88%] [G loss: 5.282921]\n",
      "epoch:30 step:23540 [D loss: 0.246152, acc: 90.62%] [G loss: 5.524587]\n",
      "epoch:30 step:23541 [D loss: 0.207858, acc: 96.88%] [G loss: 4.952755]\n",
      "epoch:30 step:23542 [D loss: 0.196190, acc: 97.66%] [G loss: 3.671322]\n",
      "epoch:30 step:23543 [D loss: 0.252232, acc: 96.09%] [G loss: 4.510993]\n",
      "epoch:30 step:23544 [D loss: 0.056225, acc: 100.00%] [G loss: 2.564323]\n",
      "epoch:30 step:23545 [D loss: 0.744257, acc: 53.91%] [G loss: 5.647629]\n",
      "epoch:30 step:23546 [D loss: 0.096599, acc: 100.00%] [G loss: 5.816730]\n",
      "epoch:30 step:23547 [D loss: 0.134317, acc: 100.00%] [G loss: 3.715595]\n",
      "epoch:30 step:23548 [D loss: 0.185152, acc: 98.44%] [G loss: 3.477908]\n",
      "epoch:30 step:23549 [D loss: 0.585440, acc: 60.16%] [G loss: 4.167546]\n",
      "epoch:30 step:23550 [D loss: 0.453118, acc: 73.44%] [G loss: 5.907661]\n",
      "epoch:30 step:23551 [D loss: 0.608914, acc: 63.28%] [G loss: 3.164399]\n",
      "epoch:30 step:23552 [D loss: 0.092577, acc: 97.66%] [G loss: 6.646378]\n",
      "epoch:30 step:23553 [D loss: 0.370041, acc: 87.50%] [G loss: 4.035856]\n",
      "epoch:30 step:23554 [D loss: 0.814237, acc: 53.12%] [G loss: 5.444057]\n",
      "epoch:30 step:23555 [D loss: 0.174846, acc: 96.88%] [G loss: 4.213234]\n",
      "epoch:30 step:23556 [D loss: 0.505325, acc: 65.62%] [G loss: 4.528127]\n",
      "epoch:30 step:23557 [D loss: 1.054857, acc: 50.78%] [G loss: 4.742447]\n",
      "epoch:30 step:23558 [D loss: 0.539496, acc: 63.28%] [G loss: 4.697885]\n",
      "epoch:30 step:23559 [D loss: 0.669226, acc: 59.38%] [G loss: 5.789359]\n",
      "epoch:30 step:23560 [D loss: 1.565402, acc: 26.56%] [G loss: 3.823790]\n",
      "epoch:30 step:23561 [D loss: 0.705570, acc: 56.25%] [G loss: 1.977008]\n",
      "epoch:30 step:23562 [D loss: 0.960818, acc: 50.78%] [G loss: 5.982519]\n",
      "epoch:30 step:23563 [D loss: 0.389425, acc: 76.56%] [G loss: 4.571378]\n",
      "epoch:30 step:23564 [D loss: 0.175496, acc: 97.66%] [G loss: 6.529919]\n",
      "epoch:30 step:23565 [D loss: 0.255091, acc: 92.19%] [G loss: 4.677422]\n",
      "epoch:30 step:23566 [D loss: 0.238032, acc: 89.84%] [G loss: 7.928076]\n",
      "epoch:30 step:23567 [D loss: 0.234534, acc: 93.75%] [G loss: 5.653125]\n",
      "epoch:30 step:23568 [D loss: 0.440361, acc: 85.16%] [G loss: 3.207008]\n",
      "epoch:30 step:23569 [D loss: 0.830718, acc: 40.62%] [G loss: 2.962627]\n",
      "epoch:30 step:23570 [D loss: 0.436950, acc: 79.69%] [G loss: 3.396541]\n",
      "epoch:30 step:23571 [D loss: 0.899394, acc: 50.78%] [G loss: 6.170470]\n",
      "epoch:30 step:23572 [D loss: 0.135069, acc: 98.44%] [G loss: 3.948322]\n",
      "epoch:30 step:23573 [D loss: 0.200877, acc: 95.31%] [G loss: 4.643938]\n",
      "epoch:30 step:23574 [D loss: 0.397091, acc: 91.41%] [G loss: 4.095741]\n",
      "epoch:30 step:23575 [D loss: 0.449741, acc: 78.91%] [G loss: 2.873513]\n",
      "epoch:30 step:23576 [D loss: 0.260479, acc: 90.62%] [G loss: 5.114664]\n",
      "epoch:30 step:23577 [D loss: 0.311630, acc: 82.81%] [G loss: 4.746839]\n",
      "epoch:30 step:23578 [D loss: 0.336509, acc: 91.41%] [G loss: 5.393790]\n",
      "epoch:30 step:23579 [D loss: 0.289087, acc: 94.53%] [G loss: 3.166663]\n",
      "epoch:30 step:23580 [D loss: 1.217078, acc: 27.34%] [G loss: 2.929959]\n",
      "epoch:30 step:23581 [D loss: 0.426840, acc: 80.47%] [G loss: 4.935232]\n",
      "epoch:30 step:23582 [D loss: 0.134316, acc: 98.44%] [G loss: 3.008713]\n",
      "epoch:30 step:23583 [D loss: 0.341820, acc: 92.19%] [G loss: 4.619485]\n",
      "epoch:30 step:23584 [D loss: 0.111200, acc: 100.00%] [G loss: 4.173557]\n",
      "epoch:30 step:23585 [D loss: 0.645487, acc: 58.59%] [G loss: 4.437007]\n",
      "epoch:30 step:23586 [D loss: 0.349326, acc: 84.38%] [G loss: 5.465136]\n",
      "epoch:30 step:23587 [D loss: 0.235269, acc: 94.53%] [G loss: 3.874286]\n",
      "epoch:30 step:23588 [D loss: 0.593758, acc: 67.97%] [G loss: 3.196853]\n",
      "epoch:30 step:23589 [D loss: 0.361958, acc: 85.94%] [G loss: 3.542347]\n",
      "epoch:30 step:23590 [D loss: 0.349607, acc: 83.59%] [G loss: 5.923333]\n",
      "epoch:30 step:23591 [D loss: 0.369776, acc: 91.41%] [G loss: 4.222207]\n",
      "epoch:30 step:23592 [D loss: 0.144992, acc: 99.22%] [G loss: 5.499477]\n",
      "epoch:30 step:23593 [D loss: 0.719238, acc: 57.03%] [G loss: 4.267385]\n",
      "epoch:30 step:23594 [D loss: 0.393929, acc: 81.25%] [G loss: 4.561540]\n",
      "epoch:30 step:23595 [D loss: 0.631032, acc: 59.38%] [G loss: 4.776879]\n",
      "epoch:30 step:23596 [D loss: 0.454414, acc: 84.38%] [G loss: 6.106540]\n",
      "epoch:30 step:23597 [D loss: 0.148105, acc: 100.00%] [G loss: 5.673792]\n",
      "epoch:30 step:23598 [D loss: 0.457708, acc: 82.03%] [G loss: 2.770678]\n",
      "epoch:30 step:23599 [D loss: 0.669172, acc: 57.03%] [G loss: 4.245591]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23600 [D loss: 0.242743, acc: 94.53%] [G loss: 4.359220]\n",
      "epoch:30 step:23601 [D loss: 0.349918, acc: 79.69%] [G loss: 5.761697]\n",
      "epoch:30 step:23602 [D loss: 0.335873, acc: 92.97%] [G loss: 3.674060]\n",
      "epoch:30 step:23603 [D loss: 1.334382, acc: 14.84%] [G loss: 3.859428]\n",
      "epoch:30 step:23604 [D loss: 0.305547, acc: 88.28%] [G loss: 4.219591]\n",
      "epoch:30 step:23605 [D loss: 0.044977, acc: 100.00%] [G loss: 5.594321]\n",
      "epoch:30 step:23606 [D loss: 0.891202, acc: 51.56%] [G loss: 6.132782]\n",
      "epoch:30 step:23607 [D loss: 0.201865, acc: 98.44%] [G loss: 5.913265]\n",
      "epoch:30 step:23608 [D loss: 0.173331, acc: 99.22%] [G loss: 5.367130]\n",
      "epoch:30 step:23609 [D loss: 0.209878, acc: 97.66%] [G loss: 5.208335]\n",
      "epoch:30 step:23610 [D loss: 0.583228, acc: 67.19%] [G loss: 4.955454]\n",
      "epoch:30 step:23611 [D loss: 0.288038, acc: 87.50%] [G loss: 3.018626]\n",
      "epoch:30 step:23612 [D loss: 1.305544, acc: 28.91%] [G loss: 5.751010]\n",
      "epoch:30 step:23613 [D loss: 0.172717, acc: 97.66%] [G loss: 3.423832]\n",
      "epoch:30 step:23614 [D loss: 1.103847, acc: 15.62%] [G loss: 3.944430]\n",
      "epoch:30 step:23615 [D loss: 0.489681, acc: 67.19%] [G loss: 4.324917]\n",
      "epoch:30 step:23616 [D loss: 0.228733, acc: 96.09%] [G loss: 3.103055]\n",
      "epoch:30 step:23617 [D loss: 0.345301, acc: 83.59%] [G loss: 6.359961]\n",
      "epoch:30 step:23618 [D loss: 0.387745, acc: 89.06%] [G loss: 3.097796]\n",
      "epoch:30 step:23619 [D loss: 0.167217, acc: 97.66%] [G loss: 9.160575]\n",
      "epoch:30 step:23620 [D loss: 0.528900, acc: 78.12%] [G loss: 3.812450]\n",
      "epoch:30 step:23621 [D loss: 0.171394, acc: 97.66%] [G loss: 5.511141]\n",
      "epoch:30 step:23622 [D loss: 0.187339, acc: 96.88%] [G loss: 5.373236]\n",
      "epoch:30 step:23623 [D loss: 0.744199, acc: 50.78%] [G loss: 4.656793]\n",
      "epoch:30 step:23624 [D loss: 0.092003, acc: 100.00%] [G loss: 6.114007]\n",
      "epoch:30 step:23625 [D loss: 0.212007, acc: 98.44%] [G loss: 4.670741]\n",
      "epoch:30 step:23626 [D loss: 0.108157, acc: 99.22%] [G loss: 4.756414]\n",
      "epoch:30 step:23627 [D loss: 0.533722, acc: 64.84%] [G loss: 4.303946]\n",
      "epoch:30 step:23628 [D loss: 0.169041, acc: 99.22%] [G loss: 2.873229]\n",
      "epoch:30 step:23629 [D loss: 0.428605, acc: 72.66%] [G loss: 1.941092]\n",
      "epoch:30 step:23630 [D loss: 0.113505, acc: 100.00%] [G loss: 4.446233]\n",
      "epoch:30 step:23631 [D loss: 0.355604, acc: 85.16%] [G loss: 3.937877]\n",
      "epoch:30 step:23632 [D loss: 0.688307, acc: 56.25%] [G loss: 4.725080]\n",
      "epoch:30 step:23633 [D loss: 0.515778, acc: 67.97%] [G loss: 2.928012]\n",
      "epoch:30 step:23634 [D loss: 0.650844, acc: 67.19%] [G loss: 5.483565]\n",
      "epoch:30 step:23635 [D loss: 0.547134, acc: 67.19%] [G loss: 3.410451]\n",
      "epoch:30 step:23636 [D loss: 0.183530, acc: 97.66%] [G loss: 4.534038]\n",
      "epoch:30 step:23637 [D loss: 0.307859, acc: 86.72%] [G loss: 5.470846]\n",
      "epoch:30 step:23638 [D loss: 0.229726, acc: 96.88%] [G loss: 4.584035]\n",
      "epoch:30 step:23639 [D loss: 0.823149, acc: 43.75%] [G loss: 5.136136]\n",
      "epoch:30 step:23640 [D loss: 0.080212, acc: 99.22%] [G loss: 2.605804]\n",
      "epoch:30 step:23641 [D loss: 0.263043, acc: 89.84%] [G loss: 4.502878]\n",
      "epoch:30 step:23642 [D loss: 0.604558, acc: 55.47%] [G loss: 4.304245]\n",
      "epoch:30 step:23643 [D loss: 0.848221, acc: 41.41%] [G loss: 3.151855]\n",
      "epoch:30 step:23644 [D loss: 0.434459, acc: 78.12%] [G loss: 4.864511]\n",
      "epoch:30 step:23645 [D loss: 0.307150, acc: 92.97%] [G loss: 4.787615]\n",
      "epoch:30 step:23646 [D loss: 0.307925, acc: 93.75%] [G loss: 4.994969]\n",
      "epoch:30 step:23647 [D loss: 0.170523, acc: 96.09%] [G loss: 7.057269]\n",
      "epoch:30 step:23648 [D loss: 0.227686, acc: 93.75%] [G loss: 5.853861]\n",
      "epoch:30 step:23649 [D loss: 0.436490, acc: 75.00%] [G loss: 5.295405]\n",
      "epoch:30 step:23650 [D loss: 0.418493, acc: 87.50%] [G loss: 3.617515]\n",
      "epoch:30 step:23651 [D loss: 0.224690, acc: 96.88%] [G loss: 2.998781]\n",
      "epoch:30 step:23652 [D loss: 0.390431, acc: 87.50%] [G loss: 3.182376]\n",
      "epoch:30 step:23653 [D loss: 0.936630, acc: 37.50%] [G loss: 3.685671]\n",
      "epoch:30 step:23654 [D loss: 0.198548, acc: 96.09%] [G loss: 5.287665]\n",
      "epoch:30 step:23655 [D loss: 0.265476, acc: 91.41%] [G loss: 6.052486]\n",
      "epoch:30 step:23656 [D loss: 0.079119, acc: 100.00%] [G loss: 6.592628]\n",
      "epoch:30 step:23657 [D loss: 0.080195, acc: 99.22%] [G loss: 6.629145]\n",
      "epoch:30 step:23658 [D loss: 0.475723, acc: 78.91%] [G loss: 6.202942]\n",
      "epoch:30 step:23659 [D loss: 0.432870, acc: 87.50%] [G loss: 4.343014]\n",
      "epoch:30 step:23660 [D loss: 0.616249, acc: 66.41%] [G loss: 3.932370]\n",
      "epoch:30 step:23661 [D loss: 0.339096, acc: 91.41%] [G loss: 4.966577]\n",
      "epoch:30 step:23662 [D loss: 1.175993, acc: 50.00%] [G loss: 6.033914]\n",
      "epoch:30 step:23663 [D loss: 0.562727, acc: 63.28%] [G loss: 3.924579]\n",
      "epoch:30 step:23664 [D loss: 0.039112, acc: 100.00%] [G loss: 2.695287]\n",
      "epoch:30 step:23665 [D loss: 0.326704, acc: 86.72%] [G loss: 4.481437]\n",
      "epoch:30 step:23666 [D loss: 0.772671, acc: 51.56%] [G loss: 5.601439]\n",
      "epoch:30 step:23667 [D loss: 0.251700, acc: 94.53%] [G loss: 3.993187]\n",
      "epoch:30 step:23668 [D loss: 1.096790, acc: 21.09%] [G loss: 2.552769]\n",
      "epoch:30 step:23669 [D loss: 0.128606, acc: 100.00%] [G loss: 3.321617]\n",
      "epoch:30 step:23670 [D loss: 0.055723, acc: 100.00%] [G loss: 5.483278]\n",
      "epoch:30 step:23671 [D loss: 0.307995, acc: 93.75%] [G loss: 3.861320]\n",
      "epoch:30 step:23672 [D loss: 0.148053, acc: 98.44%] [G loss: 5.643630]\n",
      "epoch:30 step:23673 [D loss: 0.539479, acc: 72.66%] [G loss: 4.986786]\n",
      "epoch:30 step:23674 [D loss: 0.126933, acc: 99.22%] [G loss: 4.390924]\n",
      "epoch:30 step:23675 [D loss: 1.440033, acc: 9.38%] [G loss: 4.950520]\n",
      "epoch:30 step:23676 [D loss: 0.117643, acc: 100.00%] [G loss: 3.372366]\n",
      "epoch:30 step:23677 [D loss: 0.375105, acc: 89.84%] [G loss: 2.727459]\n",
      "epoch:30 step:23678 [D loss: 0.596201, acc: 64.84%] [G loss: 2.270316]\n",
      "epoch:30 step:23679 [D loss: 0.267280, acc: 97.66%] [G loss: 4.295074]\n",
      "epoch:30 step:23680 [D loss: 0.356422, acc: 92.19%] [G loss: 3.047147]\n",
      "epoch:30 step:23681 [D loss: 0.383731, acc: 75.78%] [G loss: 5.330590]\n",
      "epoch:30 step:23682 [D loss: 1.359891, acc: 50.00%] [G loss: 4.080894]\n",
      "epoch:30 step:23683 [D loss: 0.234550, acc: 95.31%] [G loss: 3.830037]\n",
      "epoch:30 step:23684 [D loss: 0.676566, acc: 58.59%] [G loss: 2.168593]\n",
      "epoch:30 step:23685 [D loss: 0.143569, acc: 96.88%] [G loss: 4.889640]\n",
      "epoch:30 step:23686 [D loss: 0.342058, acc: 91.41%] [G loss: 5.598171]\n",
      "epoch:30 step:23687 [D loss: 0.422657, acc: 78.12%] [G loss: 6.862811]\n",
      "epoch:30 step:23688 [D loss: 0.429452, acc: 75.78%] [G loss: 4.092162]\n",
      "epoch:30 step:23689 [D loss: 0.396800, acc: 91.41%] [G loss: 4.738736]\n",
      "epoch:30 step:23690 [D loss: 0.495977, acc: 63.28%] [G loss: 5.069067]\n",
      "epoch:30 step:23691 [D loss: 0.630963, acc: 68.75%] [G loss: 3.953295]\n",
      "epoch:30 step:23692 [D loss: 0.318438, acc: 89.06%] [G loss: 3.878947]\n",
      "epoch:30 step:23693 [D loss: 0.176261, acc: 99.22%] [G loss: 4.915178]\n",
      "epoch:30 step:23694 [D loss: 0.982196, acc: 45.31%] [G loss: 3.882201]\n",
      "epoch:30 step:23695 [D loss: 0.295755, acc: 93.75%] [G loss: 4.173940]\n",
      "epoch:30 step:23696 [D loss: 0.434671, acc: 71.88%] [G loss: 3.473096]\n",
      "epoch:30 step:23697 [D loss: 0.810227, acc: 49.22%] [G loss: 5.379595]\n",
      "epoch:30 step:23698 [D loss: 0.274752, acc: 94.53%] [G loss: 3.135206]\n",
      "epoch:30 step:23699 [D loss: 0.882537, acc: 51.56%] [G loss: 3.289778]\n",
      "epoch:30 step:23700 [D loss: 0.279641, acc: 95.31%] [G loss: 3.900788]\n",
      "epoch:30 step:23701 [D loss: 0.255184, acc: 92.19%] [G loss: 5.100399]\n",
      "epoch:30 step:23702 [D loss: 0.225818, acc: 95.31%] [G loss: 3.793359]\n",
      "epoch:30 step:23703 [D loss: 0.389243, acc: 89.84%] [G loss: 4.331288]\n",
      "epoch:30 step:23704 [D loss: 0.159319, acc: 98.44%] [G loss: 3.636159]\n",
      "epoch:30 step:23705 [D loss: 0.646929, acc: 55.47%] [G loss: 5.576380]\n",
      "epoch:30 step:23706 [D loss: 0.073937, acc: 100.00%] [G loss: 8.385642]\n",
      "epoch:30 step:23707 [D loss: 0.422490, acc: 82.81%] [G loss: 4.536718]\n",
      "epoch:30 step:23708 [D loss: 0.463524, acc: 66.41%] [G loss: 3.338333]\n",
      "epoch:30 step:23709 [D loss: 0.428590, acc: 78.91%] [G loss: 5.249900]\n",
      "epoch:30 step:23710 [D loss: 0.918926, acc: 47.66%] [G loss: 5.161245]\n",
      "epoch:30 step:23711 [D loss: 0.129118, acc: 99.22%] [G loss: 4.538665]\n",
      "epoch:30 step:23712 [D loss: 0.789737, acc: 55.47%] [G loss: 5.064666]\n",
      "epoch:30 step:23713 [D loss: 0.160799, acc: 99.22%] [G loss: 7.037396]\n",
      "epoch:30 step:23714 [D loss: 0.299694, acc: 92.97%] [G loss: 5.309525]\n",
      "epoch:30 step:23715 [D loss: 0.300091, acc: 93.75%] [G loss: 5.644747]\n",
      "epoch:30 step:23716 [D loss: 0.339886, acc: 85.94%] [G loss: 4.108865]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23717 [D loss: 0.145337, acc: 99.22%] [G loss: 6.167392]\n",
      "epoch:30 step:23718 [D loss: 0.343932, acc: 93.75%] [G loss: 3.181851]\n",
      "epoch:30 step:23719 [D loss: 0.304959, acc: 88.28%] [G loss: 2.981281]\n",
      "epoch:30 step:23720 [D loss: 0.613010, acc: 62.50%] [G loss: 2.866177]\n",
      "epoch:30 step:23721 [D loss: 0.371699, acc: 89.06%] [G loss: 3.481973]\n",
      "epoch:30 step:23722 [D loss: 0.482396, acc: 79.69%] [G loss: 6.715015]\n",
      "epoch:30 step:23723 [D loss: 0.087910, acc: 100.00%] [G loss: 4.265607]\n",
      "epoch:30 step:23724 [D loss: 0.203833, acc: 96.09%] [G loss: 6.157269]\n",
      "epoch:30 step:23725 [D loss: 0.256977, acc: 96.88%] [G loss: 3.300802]\n",
      "epoch:30 step:23726 [D loss: 0.246704, acc: 91.41%] [G loss: 6.941534]\n",
      "epoch:30 step:23727 [D loss: 0.221831, acc: 96.09%] [G loss: 4.413761]\n",
      "epoch:30 step:23728 [D loss: 0.185278, acc: 99.22%] [G loss: 5.671700]\n",
      "epoch:30 step:23729 [D loss: 0.466040, acc: 75.78%] [G loss: 3.532857]\n",
      "epoch:30 step:23730 [D loss: 0.399157, acc: 81.25%] [G loss: 3.702479]\n",
      "epoch:30 step:23731 [D loss: 0.449432, acc: 74.22%] [G loss: 4.782274]\n",
      "epoch:30 step:23732 [D loss: 0.406458, acc: 78.91%] [G loss: 4.923891]\n",
      "epoch:30 step:23733 [D loss: 0.702607, acc: 53.12%] [G loss: 4.684791]\n",
      "epoch:30 step:23734 [D loss: 0.166818, acc: 96.88%] [G loss: 6.406099]\n",
      "epoch:30 step:23735 [D loss: 0.602119, acc: 64.06%] [G loss: 5.230559]\n",
      "epoch:30 step:23736 [D loss: 0.725168, acc: 56.25%] [G loss: 5.089660]\n",
      "epoch:30 step:23737 [D loss: 0.180262, acc: 97.66%] [G loss: 4.626412]\n",
      "epoch:30 step:23738 [D loss: 0.810757, acc: 53.91%] [G loss: 5.363458]\n",
      "epoch:30 step:23739 [D loss: 0.446501, acc: 89.06%] [G loss: 4.168734]\n",
      "epoch:30 step:23740 [D loss: 0.076898, acc: 100.00%] [G loss: 4.681530]\n",
      "epoch:30 step:23741 [D loss: 0.819520, acc: 52.34%] [G loss: 3.978889]\n",
      "epoch:30 step:23742 [D loss: 0.369146, acc: 85.16%] [G loss: 3.227624]\n",
      "epoch:30 step:23743 [D loss: 0.132365, acc: 100.00%] [G loss: 6.519109]\n",
      "epoch:30 step:23744 [D loss: 0.107923, acc: 100.00%] [G loss: 8.009203]\n",
      "epoch:30 step:23745 [D loss: 0.683894, acc: 58.59%] [G loss: 5.389586]\n",
      "epoch:30 step:23746 [D loss: 0.464044, acc: 84.38%] [G loss: 6.287186]\n",
      "epoch:30 step:23747 [D loss: 0.215636, acc: 95.31%] [G loss: 6.490002]\n",
      "epoch:30 step:23748 [D loss: 0.231190, acc: 98.44%] [G loss: 3.963078]\n",
      "epoch:30 step:23749 [D loss: 0.950958, acc: 44.53%] [G loss: 5.251013]\n",
      "epoch:30 step:23750 [D loss: 0.246296, acc: 92.97%] [G loss: 3.447778]\n",
      "epoch:30 step:23751 [D loss: 0.663758, acc: 66.41%] [G loss: 5.969602]\n",
      "epoch:30 step:23752 [D loss: 0.175894, acc: 99.22%] [G loss: 5.581096]\n",
      "epoch:30 step:23753 [D loss: 0.425408, acc: 75.00%] [G loss: 3.478285]\n",
      "epoch:30 step:23754 [D loss: 0.756057, acc: 54.69%] [G loss: 4.918013]\n",
      "epoch:30 step:23755 [D loss: 0.203309, acc: 96.88%] [G loss: 4.904327]\n",
      "epoch:30 step:23756 [D loss: 0.432192, acc: 82.03%] [G loss: 4.557806]\n",
      "epoch:30 step:23757 [D loss: 0.140524, acc: 100.00%] [G loss: 4.156128]\n",
      "epoch:30 step:23758 [D loss: 0.391233, acc: 88.28%] [G loss: 5.549551]\n",
      "epoch:30 step:23759 [D loss: 0.059418, acc: 100.00%] [G loss: 5.620735]\n",
      "epoch:30 step:23760 [D loss: 0.611552, acc: 61.72%] [G loss: 6.171580]\n",
      "epoch:30 step:23761 [D loss: 0.118972, acc: 99.22%] [G loss: 5.116287]\n",
      "epoch:30 step:23762 [D loss: 0.867205, acc: 42.97%] [G loss: 5.828838]\n",
      "epoch:30 step:23763 [D loss: 0.010047, acc: 100.00%] [G loss: 8.566761]\n",
      "epoch:30 step:23764 [D loss: 0.158528, acc: 99.22%] [G loss: 4.216072]\n",
      "epoch:30 step:23765 [D loss: 0.121211, acc: 99.22%] [G loss: 4.088107]\n",
      "epoch:30 step:23766 [D loss: 0.869062, acc: 35.94%] [G loss: 5.419973]\n",
      "epoch:30 step:23767 [D loss: 0.337894, acc: 95.31%] [G loss: 2.631561]\n",
      "epoch:30 step:23768 [D loss: 0.330784, acc: 89.84%] [G loss: 4.243220]\n",
      "epoch:30 step:23769 [D loss: 0.144341, acc: 100.00%] [G loss: 4.876125]\n",
      "epoch:30 step:23770 [D loss: 0.293214, acc: 82.81%] [G loss: 7.399112]\n",
      "epoch:30 step:23771 [D loss: 0.287378, acc: 89.06%] [G loss: 4.245055]\n",
      "epoch:30 step:23772 [D loss: 0.361800, acc: 89.06%] [G loss: 4.478848]\n",
      "epoch:30 step:23773 [D loss: 0.208157, acc: 95.31%] [G loss: 4.967840]\n",
      "epoch:30 step:23774 [D loss: 0.245375, acc: 92.97%] [G loss: 7.101011]\n",
      "epoch:30 step:23775 [D loss: 0.806017, acc: 47.66%] [G loss: 2.963436]\n",
      "epoch:30 step:23776 [D loss: 0.633479, acc: 67.19%] [G loss: 3.933489]\n",
      "epoch:30 step:23777 [D loss: 0.146138, acc: 100.00%] [G loss: 4.265997]\n",
      "epoch:30 step:23778 [D loss: 0.464925, acc: 78.91%] [G loss: 5.722417]\n",
      "epoch:30 step:23779 [D loss: 1.301313, acc: 17.19%] [G loss: 4.617726]\n",
      "epoch:30 step:23780 [D loss: 0.157220, acc: 98.44%] [G loss: 4.482750]\n",
      "epoch:30 step:23781 [D loss: 0.376459, acc: 89.06%] [G loss: 4.028515]\n",
      "epoch:30 step:23782 [D loss: 0.169877, acc: 98.44%] [G loss: 5.217089]\n",
      "epoch:30 step:23783 [D loss: 0.527424, acc: 67.97%] [G loss: 4.110706]\n",
      "epoch:30 step:23784 [D loss: 0.340509, acc: 81.25%] [G loss: 5.418123]\n",
      "epoch:30 step:23785 [D loss: 0.363587, acc: 92.97%] [G loss: 3.110897]\n",
      "epoch:30 step:23786 [D loss: 0.522257, acc: 69.53%] [G loss: 5.474782]\n",
      "epoch:30 step:23787 [D loss: 0.446698, acc: 67.19%] [G loss: 5.087522]\n",
      "epoch:30 step:23788 [D loss: 0.420290, acc: 82.81%] [G loss: 3.513997]\n",
      "epoch:30 step:23789 [D loss: 0.498784, acc: 72.66%] [G loss: 3.689346]\n",
      "epoch:30 step:23790 [D loss: 0.284708, acc: 95.31%] [G loss: 7.556556]\n",
      "epoch:30 step:23791 [D loss: 0.806601, acc: 51.56%] [G loss: 4.264597]\n",
      "epoch:30 step:23792 [D loss: 1.368890, acc: 50.00%] [G loss: 3.736146]\n",
      "epoch:30 step:23793 [D loss: 1.018721, acc: 49.22%] [G loss: 5.016030]\n",
      "epoch:30 step:23794 [D loss: 0.400613, acc: 73.44%] [G loss: 5.082875]\n",
      "epoch:30 step:23795 [D loss: 0.474082, acc: 71.09%] [G loss: 5.006719]\n",
      "epoch:30 step:23796 [D loss: 1.320718, acc: 6.25%] [G loss: 4.334224]\n",
      "epoch:30 step:23797 [D loss: 0.096285, acc: 100.00%] [G loss: 4.103029]\n",
      "epoch:30 step:23798 [D loss: 0.190723, acc: 97.66%] [G loss: 3.255269]\n",
      "epoch:30 step:23799 [D loss: 0.180042, acc: 97.66%] [G loss: 6.164657]\n",
      "epoch:30 step:23800 [D loss: 0.687310, acc: 54.69%] [G loss: 3.651524]\n",
      "epoch:30 step:23801 [D loss: 0.402937, acc: 91.41%] [G loss: 5.383091]\n",
      "epoch:30 step:23802 [D loss: 0.605949, acc: 61.72%] [G loss: 6.286790]\n",
      "epoch:30 step:23803 [D loss: 1.410509, acc: 39.84%] [G loss: 4.245397]\n",
      "epoch:30 step:23804 [D loss: 1.042128, acc: 52.34%] [G loss: 4.278907]\n",
      "epoch:30 step:23805 [D loss: 0.102296, acc: 99.22%] [G loss: 4.207824]\n",
      "epoch:30 step:23806 [D loss: 0.263793, acc: 96.09%] [G loss: 5.041472]\n",
      "epoch:30 step:23807 [D loss: 0.318515, acc: 97.66%] [G loss: 2.540396]\n",
      "epoch:30 step:23808 [D loss: 0.098142, acc: 100.00%] [G loss: 5.668376]\n",
      "epoch:30 step:23809 [D loss: 0.157700, acc: 97.66%] [G loss: 5.066112]\n",
      "epoch:30 step:23810 [D loss: 0.171307, acc: 99.22%] [G loss: 3.361966]\n",
      "epoch:30 step:23811 [D loss: 0.149563, acc: 100.00%] [G loss: 5.411553]\n",
      "epoch:30 step:23812 [D loss: 0.288812, acc: 91.41%] [G loss: 5.738686]\n",
      "epoch:30 step:23813 [D loss: 0.859994, acc: 53.12%] [G loss: 4.865078]\n",
      "epoch:30 step:23814 [D loss: 0.117002, acc: 100.00%] [G loss: 4.914139]\n",
      "epoch:30 step:23815 [D loss: 0.437867, acc: 83.59%] [G loss: 4.379100]\n",
      "epoch:30 step:23816 [D loss: 0.379153, acc: 84.38%] [G loss: 4.229784]\n",
      "epoch:30 step:23817 [D loss: 1.174424, acc: 30.47%] [G loss: 5.779440]\n",
      "epoch:30 step:23818 [D loss: 0.419790, acc: 78.91%] [G loss: 4.522575]\n",
      "epoch:30 step:23819 [D loss: 1.165812, acc: 25.00%] [G loss: 3.346631]\n",
      "epoch:30 step:23820 [D loss: 0.191536, acc: 96.09%] [G loss: 5.556417]\n",
      "epoch:30 step:23821 [D loss: 0.398647, acc: 80.47%] [G loss: 5.094434]\n",
      "epoch:30 step:23822 [D loss: 0.648551, acc: 60.16%] [G loss: 3.141422]\n",
      "epoch:30 step:23823 [D loss: 0.157263, acc: 99.22%] [G loss: 6.075952]\n",
      "epoch:30 step:23824 [D loss: 0.219452, acc: 94.53%] [G loss: 3.715060]\n",
      "epoch:30 step:23825 [D loss: 0.201309, acc: 98.44%] [G loss: 5.684595]\n",
      "epoch:30 step:23826 [D loss: 0.633689, acc: 60.94%] [G loss: 3.665679]\n",
      "epoch:30 step:23827 [D loss: 0.248000, acc: 92.97%] [G loss: 4.945009]\n",
      "epoch:30 step:23828 [D loss: 0.151722, acc: 97.66%] [G loss: 4.189274]\n",
      "epoch:30 step:23829 [D loss: 0.615840, acc: 60.94%] [G loss: 5.440545]\n",
      "epoch:30 step:23830 [D loss: 0.268959, acc: 93.75%] [G loss: 3.547546]\n",
      "epoch:30 step:23831 [D loss: 0.139559, acc: 100.00%] [G loss: 5.084131]\n",
      "epoch:30 step:23832 [D loss: 0.344942, acc: 90.62%] [G loss: 4.874266]\n",
      "epoch:30 step:23833 [D loss: 0.489015, acc: 79.69%] [G loss: 4.766850]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23834 [D loss: 0.271591, acc: 92.97%] [G loss: 3.282800]\n",
      "epoch:30 step:23835 [D loss: 0.136444, acc: 99.22%] [G loss: 4.521163]\n",
      "epoch:30 step:23836 [D loss: 0.445274, acc: 68.75%] [G loss: 4.076702]\n",
      "epoch:30 step:23837 [D loss: 0.185309, acc: 99.22%] [G loss: 2.451112]\n",
      "epoch:30 step:23838 [D loss: 1.198171, acc: 30.47%] [G loss: 7.222044]\n",
      "epoch:30 step:23839 [D loss: 0.516938, acc: 74.22%] [G loss: 3.512271]\n",
      "epoch:30 step:23840 [D loss: 0.141093, acc: 99.22%] [G loss: 3.135298]\n",
      "epoch:30 step:23841 [D loss: 0.597456, acc: 71.88%] [G loss: 6.041326]\n",
      "epoch:30 step:23842 [D loss: 0.740083, acc: 48.44%] [G loss: 4.551159]\n",
      "epoch:30 step:23843 [D loss: 0.238034, acc: 96.88%] [G loss: 2.204529]\n",
      "epoch:30 step:23844 [D loss: 0.464853, acc: 80.47%] [G loss: 3.352983]\n",
      "epoch:30 step:23845 [D loss: 0.296531, acc: 93.75%] [G loss: 3.662527]\n",
      "epoch:30 step:23846 [D loss: 0.405722, acc: 86.72%] [G loss: 4.844712]\n",
      "epoch:30 step:23847 [D loss: 0.295554, acc: 96.09%] [G loss: 6.319209]\n",
      "epoch:30 step:23848 [D loss: 0.364726, acc: 89.06%] [G loss: 3.770422]\n",
      "epoch:30 step:23849 [D loss: 0.427249, acc: 81.25%] [G loss: 5.339952]\n",
      "epoch:30 step:23850 [D loss: 0.906050, acc: 35.94%] [G loss: 3.660369]\n",
      "epoch:30 step:23851 [D loss: 0.275370, acc: 93.75%] [G loss: 4.998394]\n",
      "epoch:30 step:23852 [D loss: 0.199186, acc: 100.00%] [G loss: 6.075364]\n",
      "epoch:30 step:23853 [D loss: 0.427726, acc: 81.25%] [G loss: 3.837989]\n",
      "epoch:30 step:23854 [D loss: 0.255221, acc: 96.09%] [G loss: 4.460476]\n",
      "epoch:30 step:23855 [D loss: 0.252132, acc: 96.09%] [G loss: 4.904708]\n",
      "epoch:30 step:23856 [D loss: 0.590537, acc: 57.03%] [G loss: 3.854107]\n",
      "epoch:30 step:23857 [D loss: 0.098305, acc: 100.00%] [G loss: 5.702187]\n",
      "epoch:30 step:23858 [D loss: 0.512340, acc: 64.06%] [G loss: 3.982490]\n",
      "epoch:30 step:23859 [D loss: 0.217628, acc: 96.88%] [G loss: 4.075058]\n",
      "epoch:30 step:23860 [D loss: 0.195643, acc: 97.66%] [G loss: 3.338934]\n",
      "epoch:30 step:23861 [D loss: 0.175416, acc: 99.22%] [G loss: 3.607687]\n",
      "epoch:30 step:23862 [D loss: 0.302597, acc: 87.50%] [G loss: 3.716338]\n",
      "epoch:30 step:23863 [D loss: 0.089361, acc: 100.00%] [G loss: 3.221843]\n",
      "epoch:30 step:23864 [D loss: 0.234294, acc: 92.19%] [G loss: 3.663235]\n",
      "epoch:30 step:23865 [D loss: 0.475002, acc: 68.75%] [G loss: 5.266249]\n",
      "epoch:30 step:23866 [D loss: 0.720409, acc: 58.59%] [G loss: 4.158504]\n",
      "epoch:30 step:23867 [D loss: 0.220642, acc: 94.53%] [G loss: 2.717033]\n",
      "epoch:30 step:23868 [D loss: 0.309030, acc: 92.19%] [G loss: 4.480619]\n",
      "epoch:30 step:23869 [D loss: 0.148309, acc: 99.22%] [G loss: 4.296925]\n",
      "epoch:30 step:23870 [D loss: 0.305838, acc: 91.41%] [G loss: 3.705070]\n",
      "epoch:30 step:23871 [D loss: 0.303179, acc: 90.62%] [G loss: 5.551790]\n",
      "epoch:30 step:23872 [D loss: 0.348059, acc: 91.41%] [G loss: 3.007564]\n",
      "epoch:30 step:23873 [D loss: 0.319051, acc: 92.19%] [G loss: 4.190572]\n",
      "epoch:30 step:23874 [D loss: 0.064449, acc: 100.00%] [G loss: 5.460918]\n",
      "epoch:30 step:23875 [D loss: 1.609974, acc: 12.50%] [G loss: 4.240624]\n",
      "epoch:30 step:23876 [D loss: 0.289341, acc: 87.50%] [G loss: 4.694304]\n",
      "epoch:30 step:23877 [D loss: 0.520539, acc: 71.88%] [G loss: 6.170451]\n",
      "epoch:30 step:23878 [D loss: 0.336505, acc: 92.19%] [G loss: 3.489260]\n",
      "epoch:30 step:23879 [D loss: 0.213628, acc: 99.22%] [G loss: 3.837300]\n",
      "epoch:30 step:23880 [D loss: 0.128881, acc: 99.22%] [G loss: 6.008558]\n",
      "epoch:30 step:23881 [D loss: 0.297117, acc: 93.75%] [G loss: 3.882702]\n",
      "epoch:30 step:23882 [D loss: 0.098909, acc: 99.22%] [G loss: 4.102029]\n",
      "epoch:30 step:23883 [D loss: 0.328717, acc: 94.53%] [G loss: 4.319287]\n",
      "epoch:30 step:23884 [D loss: 0.423153, acc: 88.28%] [G loss: 4.276780]\n",
      "epoch:30 step:23885 [D loss: 1.081067, acc: 27.34%] [G loss: 4.324812]\n",
      "epoch:30 step:23886 [D loss: 0.618669, acc: 66.41%] [G loss: 7.803692]\n",
      "epoch:30 step:23887 [D loss: 0.448406, acc: 76.56%] [G loss: 3.794401]\n",
      "epoch:30 step:23888 [D loss: 0.147227, acc: 99.22%] [G loss: 2.772795]\n",
      "epoch:30 step:23889 [D loss: 0.515736, acc: 71.88%] [G loss: 5.716781]\n",
      "epoch:30 step:23890 [D loss: 0.157823, acc: 96.09%] [G loss: 5.103550]\n",
      "epoch:30 step:23891 [D loss: 0.461390, acc: 71.09%] [G loss: 5.341364]\n",
      "epoch:30 step:23892 [D loss: 0.437386, acc: 82.81%] [G loss: 4.479928]\n",
      "epoch:30 step:23893 [D loss: 0.259095, acc: 96.09%] [G loss: 4.643460]\n",
      "epoch:30 step:23894 [D loss: 0.239336, acc: 93.75%] [G loss: 5.932752]\n",
      "epoch:30 step:23895 [D loss: 1.316462, acc: 47.66%] [G loss: 3.519152]\n",
      "epoch:30 step:23896 [D loss: 0.016457, acc: 100.00%] [G loss: 5.676843]\n",
      "epoch:30 step:23897 [D loss: 0.541998, acc: 63.28%] [G loss: 3.971667]\n",
      "epoch:30 step:23898 [D loss: 1.265867, acc: 18.75%] [G loss: 5.495109]\n",
      "epoch:30 step:23899 [D loss: 0.594077, acc: 67.97%] [G loss: 3.763803]\n",
      "epoch:30 step:23900 [D loss: 0.100366, acc: 100.00%] [G loss: 3.206985]\n",
      "epoch:30 step:23901 [D loss: 0.741149, acc: 57.81%] [G loss: 3.719960]\n",
      "epoch:30 step:23902 [D loss: 0.343756, acc: 92.97%] [G loss: 5.757235]\n",
      "epoch:30 step:23903 [D loss: 0.296267, acc: 90.62%] [G loss: 2.100377]\n",
      "epoch:30 step:23904 [D loss: 0.491120, acc: 81.25%] [G loss: 4.197822]\n",
      "epoch:30 step:23905 [D loss: 0.098317, acc: 99.22%] [G loss: 3.176503]\n",
      "epoch:30 step:23906 [D loss: 0.341638, acc: 91.41%] [G loss: 5.813532]\n",
      "epoch:30 step:23907 [D loss: 0.308007, acc: 85.16%] [G loss: 5.816883]\n",
      "epoch:30 step:23908 [D loss: 0.069934, acc: 100.00%] [G loss: 4.688024]\n",
      "epoch:30 step:23909 [D loss: 0.508308, acc: 67.97%] [G loss: 5.315341]\n",
      "epoch:30 step:23910 [D loss: 0.384852, acc: 82.03%] [G loss: 4.893260]\n",
      "epoch:30 step:23911 [D loss: 0.475393, acc: 77.34%] [G loss: 3.619127]\n",
      "epoch:30 step:23912 [D loss: 0.262162, acc: 90.62%] [G loss: 6.205994]\n",
      "epoch:30 step:23913 [D loss: 0.221495, acc: 92.19%] [G loss: 7.597875]\n",
      "epoch:30 step:23914 [D loss: 0.485864, acc: 78.91%] [G loss: 2.737451]\n",
      "epoch:30 step:23915 [D loss: 0.267679, acc: 93.75%] [G loss: 6.250902]\n",
      "epoch:30 step:23916 [D loss: 0.460487, acc: 75.00%] [G loss: 2.118723]\n",
      "epoch:30 step:23917 [D loss: 0.085959, acc: 100.00%] [G loss: 7.597792]\n",
      "epoch:30 step:23918 [D loss: 0.069425, acc: 100.00%] [G loss: 4.538177]\n",
      "epoch:30 step:23919 [D loss: 0.142469, acc: 100.00%] [G loss: 5.089708]\n",
      "epoch:30 step:23920 [D loss: 0.271438, acc: 85.94%] [G loss: 6.932965]\n",
      "epoch:30 step:23921 [D loss: 0.260496, acc: 91.41%] [G loss: 5.822372]\n",
      "epoch:30 step:23922 [D loss: 0.112528, acc: 99.22%] [G loss: 4.509327]\n",
      "epoch:30 step:23923 [D loss: 0.119064, acc: 100.00%] [G loss: 5.150037]\n",
      "epoch:30 step:23924 [D loss: 0.271991, acc: 97.66%] [G loss: 2.883928]\n",
      "epoch:30 step:23925 [D loss: 0.994724, acc: 21.88%] [G loss: 6.267073]\n",
      "epoch:30 step:23926 [D loss: 0.378832, acc: 89.84%] [G loss: 3.529393]\n",
      "epoch:30 step:23927 [D loss: 0.022373, acc: 100.00%] [G loss: 7.977609]\n",
      "epoch:30 step:23928 [D loss: 0.417230, acc: 75.00%] [G loss: 4.458013]\n",
      "epoch:30 step:23929 [D loss: 0.346659, acc: 93.75%] [G loss: 2.711295]\n",
      "epoch:30 step:23930 [D loss: 1.092551, acc: 42.97%] [G loss: 4.119815]\n",
      "epoch:30 step:23931 [D loss: 0.527947, acc: 80.47%] [G loss: 5.243189]\n",
      "epoch:30 step:23932 [D loss: 0.633869, acc: 58.59%] [G loss: 6.575392]\n",
      "epoch:30 step:23933 [D loss: 0.686379, acc: 60.16%] [G loss: 5.297319]\n",
      "epoch:30 step:23934 [D loss: 1.139470, acc: 49.22%] [G loss: 4.237647]\n",
      "epoch:30 step:23935 [D loss: 0.587409, acc: 57.81%] [G loss: 3.805851]\n",
      "epoch:30 step:23936 [D loss: 0.103931, acc: 100.00%] [G loss: 3.332791]\n",
      "epoch:30 step:23937 [D loss: 0.174550, acc: 96.88%] [G loss: 4.725000]\n",
      "epoch:30 step:23938 [D loss: 0.293700, acc: 96.09%] [G loss: 5.260323]\n",
      "epoch:30 step:23939 [D loss: 0.212580, acc: 95.31%] [G loss: 3.789996]\n",
      "epoch:30 step:23940 [D loss: 0.280370, acc: 96.88%] [G loss: 5.230689]\n",
      "epoch:30 step:23941 [D loss: 0.119224, acc: 99.22%] [G loss: 5.765790]\n",
      "epoch:30 step:23942 [D loss: 0.287722, acc: 90.62%] [G loss: 4.226130]\n",
      "epoch:30 step:23943 [D loss: 0.733060, acc: 57.81%] [G loss: 5.451820]\n",
      "epoch:30 step:23944 [D loss: 0.451345, acc: 71.88%] [G loss: 5.624876]\n",
      "epoch:30 step:23945 [D loss: 0.413943, acc: 76.56%] [G loss: 3.591272]\n",
      "epoch:30 step:23946 [D loss: 0.334055, acc: 92.19%] [G loss: 4.690463]\n",
      "epoch:30 step:23947 [D loss: 0.053289, acc: 100.00%] [G loss: 4.242672]\n",
      "epoch:30 step:23948 [D loss: 0.314133, acc: 92.97%] [G loss: 4.846357]\n",
      "epoch:30 step:23949 [D loss: 1.006163, acc: 40.62%] [G loss: 3.108234]\n",
      "epoch:30 step:23950 [D loss: 0.477762, acc: 81.25%] [G loss: 4.923054]\n",
      "epoch:30 step:23951 [D loss: 0.155709, acc: 97.66%] [G loss: 5.384182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23952 [D loss: 0.341611, acc: 81.25%] [G loss: 4.891011]\n",
      "epoch:30 step:23953 [D loss: 0.594177, acc: 63.28%] [G loss: 5.405375]\n",
      "epoch:30 step:23954 [D loss: 0.093191, acc: 99.22%] [G loss: 4.219466]\n",
      "epoch:30 step:23955 [D loss: 0.555976, acc: 68.75%] [G loss: 3.954146]\n",
      "epoch:30 step:23956 [D loss: 0.577690, acc: 61.72%] [G loss: 4.465662]\n",
      "epoch:30 step:23957 [D loss: 0.300768, acc: 85.94%] [G loss: 3.775559]\n",
      "epoch:30 step:23958 [D loss: 0.651167, acc: 58.59%] [G loss: 4.778789]\n",
      "epoch:30 step:23959 [D loss: 0.201898, acc: 95.31%] [G loss: 5.740091]\n",
      "epoch:30 step:23960 [D loss: 0.480685, acc: 78.91%] [G loss: 3.765404]\n",
      "epoch:30 step:23961 [D loss: 0.368061, acc: 81.25%] [G loss: 3.812983]\n",
      "epoch:30 step:23962 [D loss: 0.356027, acc: 92.19%] [G loss: 5.062330]\n",
      "epoch:30 step:23963 [D loss: 0.634456, acc: 58.59%] [G loss: 6.072476]\n",
      "epoch:30 step:23964 [D loss: 0.214302, acc: 95.31%] [G loss: 5.879171]\n",
      "epoch:30 step:23965 [D loss: 0.622313, acc: 68.75%] [G loss: 3.894187]\n",
      "epoch:30 step:23966 [D loss: 0.102512, acc: 99.22%] [G loss: 5.453357]\n",
      "epoch:30 step:23967 [D loss: 0.321185, acc: 95.31%] [G loss: 3.588471]\n",
      "epoch:30 step:23968 [D loss: 0.186748, acc: 99.22%] [G loss: 5.384965]\n",
      "epoch:30 step:23969 [D loss: 0.263376, acc: 96.09%] [G loss: 3.622526]\n",
      "epoch:30 step:23970 [D loss: 1.297638, acc: 13.28%] [G loss: 6.303493]\n",
      "epoch:30 step:23971 [D loss: 0.335252, acc: 82.03%] [G loss: 5.219689]\n",
      "epoch:30 step:23972 [D loss: 0.727013, acc: 53.91%] [G loss: 2.327238]\n",
      "epoch:30 step:23973 [D loss: 0.329757, acc: 89.06%] [G loss: 3.226768]\n",
      "epoch:30 step:23974 [D loss: 0.210786, acc: 96.09%] [G loss: 3.464093]\n",
      "epoch:30 step:23975 [D loss: 0.847341, acc: 52.34%] [G loss: 6.231351]\n",
      "epoch:30 step:23976 [D loss: 0.654255, acc: 57.03%] [G loss: 4.171370]\n",
      "epoch:30 step:23977 [D loss: 0.459588, acc: 85.94%] [G loss: 3.386592]\n",
      "epoch:30 step:23978 [D loss: 0.463607, acc: 74.22%] [G loss: 4.959584]\n",
      "epoch:30 step:23979 [D loss: 0.269386, acc: 95.31%] [G loss: 4.725320]\n",
      "epoch:30 step:23980 [D loss: 0.594736, acc: 61.72%] [G loss: 4.966674]\n",
      "epoch:30 step:23981 [D loss: 0.250479, acc: 96.88%] [G loss: 3.769857]\n",
      "epoch:30 step:23982 [D loss: 0.739726, acc: 53.12%] [G loss: 5.706328]\n",
      "epoch:30 step:23983 [D loss: 0.052799, acc: 100.00%] [G loss: 6.519881]\n",
      "epoch:30 step:23984 [D loss: 0.132601, acc: 100.00%] [G loss: 4.453751]\n",
      "epoch:30 step:23985 [D loss: 0.412781, acc: 71.88%] [G loss: 4.410253]\n",
      "epoch:30 step:23986 [D loss: 0.798679, acc: 52.34%] [G loss: 3.808918]\n",
      "epoch:30 step:23987 [D loss: 0.436398, acc: 82.81%] [G loss: 3.532774]\n",
      "epoch:30 step:23988 [D loss: 0.500184, acc: 69.53%] [G loss: 6.304473]\n",
      "epoch:30 step:23989 [D loss: 0.304500, acc: 91.41%] [G loss: 3.627723]\n",
      "epoch:30 step:23990 [D loss: 0.453099, acc: 75.78%] [G loss: 4.339360]\n",
      "epoch:30 step:23991 [D loss: 0.754780, acc: 52.34%] [G loss: 3.864278]\n",
      "epoch:30 step:23992 [D loss: 0.264681, acc: 88.28%] [G loss: 4.890740]\n",
      "epoch:30 step:23993 [D loss: 0.588426, acc: 63.28%] [G loss: 3.948442]\n",
      "epoch:30 step:23994 [D loss: 0.080559, acc: 100.00%] [G loss: 5.238064]\n",
      "epoch:30 step:23995 [D loss: 0.696269, acc: 51.56%] [G loss: 5.215158]\n",
      "epoch:30 step:23996 [D loss: 0.091589, acc: 100.00%] [G loss: 6.215221]\n",
      "epoch:30 step:23997 [D loss: 0.147579, acc: 96.88%] [G loss: 5.255877]\n",
      "epoch:30 step:23998 [D loss: 0.183533, acc: 99.22%] [G loss: 4.186473]\n",
      "epoch:30 step:23999 [D loss: 0.697640, acc: 57.03%] [G loss: 4.683509]\n",
      "epoch:30 step:24000 [D loss: 0.122287, acc: 99.22%] [G loss: 6.757990]\n",
      "epoch:30 step:24001 [D loss: 0.354043, acc: 88.28%] [G loss: 4.880642]\n",
      "epoch:30 step:24002 [D loss: 0.151436, acc: 99.22%] [G loss: 3.897226]\n",
      "epoch:30 step:24003 [D loss: 0.227716, acc: 96.88%] [G loss: 6.071624]\n",
      "epoch:30 step:24004 [D loss: 0.997069, acc: 37.50%] [G loss: 5.826671]\n",
      "epoch:30 step:24005 [D loss: 0.555231, acc: 63.28%] [G loss: 3.807203]\n",
      "epoch:30 step:24006 [D loss: 0.393189, acc: 89.84%] [G loss: 7.096087]\n",
      "epoch:30 step:24007 [D loss: 0.488717, acc: 71.88%] [G loss: 6.072935]\n",
      "epoch:30 step:24008 [D loss: 0.527670, acc: 70.31%] [G loss: 5.764627]\n",
      "epoch:30 step:24009 [D loss: 0.249787, acc: 94.53%] [G loss: 4.561109]\n",
      "epoch:30 step:24010 [D loss: 0.310236, acc: 83.59%] [G loss: 5.278480]\n",
      "epoch:30 step:24011 [D loss: 0.328247, acc: 92.97%] [G loss: 4.927893]\n",
      "epoch:30 step:24012 [D loss: 0.326929, acc: 89.06%] [G loss: 4.854144]\n",
      "epoch:30 step:24013 [D loss: 1.121826, acc: 18.75%] [G loss: 4.189361]\n",
      "epoch:30 step:24014 [D loss: 0.040746, acc: 100.00%] [G loss: 4.294947]\n",
      "epoch:30 step:24015 [D loss: 0.403885, acc: 73.44%] [G loss: 7.126580]\n",
      "epoch:30 step:24016 [D loss: 1.049116, acc: 49.22%] [G loss: 5.764627]\n",
      "epoch:30 step:24017 [D loss: 0.299713, acc: 93.75%] [G loss: 3.993407]\n",
      "epoch:30 step:24018 [D loss: 0.512032, acc: 72.66%] [G loss: 4.304749]\n",
      "epoch:30 step:24019 [D loss: 0.204682, acc: 97.66%] [G loss: 3.449359]\n",
      "epoch:30 step:24020 [D loss: 0.888894, acc: 46.09%] [G loss: 3.119861]\n",
      "epoch:30 step:24021 [D loss: 0.542747, acc: 73.44%] [G loss: 3.936859]\n",
      "epoch:30 step:24022 [D loss: 0.432092, acc: 71.88%] [G loss: 4.383560]\n",
      "epoch:30 step:24023 [D loss: 0.322669, acc: 93.75%] [G loss: 4.036205]\n",
      "epoch:30 step:24024 [D loss: 0.225765, acc: 94.53%] [G loss: 5.463885]\n",
      "epoch:30 step:24025 [D loss: 0.336391, acc: 87.50%] [G loss: 4.504848]\n",
      "epoch:30 step:24026 [D loss: 0.369525, acc: 88.28%] [G loss: 3.235506]\n",
      "epoch:30 step:24027 [D loss: 0.124331, acc: 100.00%] [G loss: 4.583876]\n",
      "epoch:30 step:24028 [D loss: 0.493498, acc: 70.31%] [G loss: 4.362523]\n",
      "epoch:30 step:24029 [D loss: 0.249677, acc: 98.44%] [G loss: 2.277421]\n",
      "epoch:30 step:24030 [D loss: 0.100973, acc: 100.00%] [G loss: 3.133312]\n",
      "epoch:30 step:24031 [D loss: 0.508309, acc: 72.66%] [G loss: 4.807552]\n",
      "epoch:30 step:24032 [D loss: 0.297389, acc: 90.62%] [G loss: 3.501579]\n",
      "epoch:30 step:24033 [D loss: 1.065068, acc: 42.19%] [G loss: 4.804461]\n",
      "epoch:30 step:24034 [D loss: 0.584569, acc: 64.84%] [G loss: 3.505952]\n",
      "epoch:30 step:24035 [D loss: 0.897563, acc: 49.22%] [G loss: 6.402541]\n",
      "epoch:30 step:24036 [D loss: 0.139424, acc: 99.22%] [G loss: 3.765584]\n",
      "epoch:30 step:24037 [D loss: 0.736946, acc: 53.91%] [G loss: 3.766291]\n",
      "epoch:30 step:24038 [D loss: 0.393236, acc: 88.28%] [G loss: 2.540383]\n",
      "epoch:30 step:24039 [D loss: 0.218020, acc: 96.09%] [G loss: 4.060891]\n",
      "epoch:30 step:24040 [D loss: 0.935103, acc: 36.72%] [G loss: 4.817846]\n",
      "epoch:30 step:24041 [D loss: 0.686871, acc: 56.25%] [G loss: 6.209726]\n",
      "epoch:30 step:24042 [D loss: 0.362650, acc: 89.84%] [G loss: 2.260774]\n",
      "epoch:30 step:24043 [D loss: 0.938473, acc: 50.00%] [G loss: 4.797915]\n",
      "epoch:30 step:24044 [D loss: 0.221825, acc: 93.75%] [G loss: 6.762301]\n",
      "epoch:30 step:24045 [D loss: 0.229877, acc: 96.09%] [G loss: 3.516886]\n",
      "epoch:30 step:24046 [D loss: 0.476397, acc: 78.12%] [G loss: 5.710879]\n",
      "epoch:30 step:24047 [D loss: 0.355387, acc: 86.72%] [G loss: 3.465381]\n",
      "epoch:30 step:24048 [D loss: 0.345623, acc: 85.94%] [G loss: 4.333663]\n",
      "epoch:30 step:24049 [D loss: 0.285157, acc: 95.31%] [G loss: 4.490800]\n",
      "epoch:30 step:24050 [D loss: 0.042496, acc: 100.00%] [G loss: 6.362695]\n",
      "epoch:30 step:24051 [D loss: 0.550407, acc: 67.97%] [G loss: 6.110114]\n",
      "epoch:30 step:24052 [D loss: 0.556621, acc: 63.28%] [G loss: 5.418851]\n",
      "epoch:30 step:24053 [D loss: 0.396526, acc: 78.91%] [G loss: 6.057056]\n",
      "epoch:30 step:24054 [D loss: 0.368914, acc: 74.22%] [G loss: 7.431105]\n",
      "epoch:30 step:24055 [D loss: 0.437038, acc: 75.78%] [G loss: 5.083155]\n",
      "epoch:30 step:24056 [D loss: 1.257675, acc: 44.53%] [G loss: 3.479434]\n",
      "epoch:30 step:24057 [D loss: 1.802036, acc: 7.81%] [G loss: 6.102839]\n",
      "epoch:30 step:24058 [D loss: 0.206233, acc: 95.31%] [G loss: 4.602988]\n",
      "epoch:30 step:24059 [D loss: 0.758933, acc: 46.88%] [G loss: 4.819457]\n",
      "epoch:30 step:24060 [D loss: 0.011032, acc: 100.00%] [G loss: 6.960853]\n",
      "epoch:30 step:24061 [D loss: 0.048372, acc: 100.00%] [G loss: 2.595395]\n",
      "epoch:30 step:24062 [D loss: 0.301624, acc: 94.53%] [G loss: 5.290160]\n",
      "epoch:30 step:24063 [D loss: 0.115903, acc: 100.00%] [G loss: 2.654287]\n",
      "epoch:30 step:24064 [D loss: 1.084812, acc: 43.75%] [G loss: 4.434510]\n",
      "epoch:30 step:24065 [D loss: 0.497452, acc: 66.41%] [G loss: 6.334062]\n",
      "epoch:30 step:24066 [D loss: 0.357757, acc: 88.28%] [G loss: 4.116208]\n",
      "epoch:30 step:24067 [D loss: 0.222426, acc: 97.66%] [G loss: 5.301812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:24068 [D loss: 0.654267, acc: 56.25%] [G loss: 7.206854]\n",
      "epoch:30 step:24069 [D loss: 1.043326, acc: 43.75%] [G loss: 4.954384]\n",
      "epoch:30 step:24070 [D loss: 0.191370, acc: 100.00%] [G loss: 3.960961]\n",
      "epoch:30 step:24071 [D loss: 0.271341, acc: 89.84%] [G loss: 3.300256]\n",
      "epoch:30 step:24072 [D loss: 0.351926, acc: 90.62%] [G loss: 5.172554]\n",
      "epoch:30 step:24073 [D loss: 0.452279, acc: 78.12%] [G loss: 3.884316]\n",
      "epoch:30 step:24074 [D loss: 0.354960, acc: 88.28%] [G loss: 4.026428]\n",
      "epoch:30 step:24075 [D loss: 0.427778, acc: 82.81%] [G loss: 4.923344]\n",
      "epoch:30 step:24076 [D loss: 0.313582, acc: 96.09%] [G loss: 3.877173]\n",
      "epoch:30 step:24077 [D loss: 0.269410, acc: 99.22%] [G loss: 4.850863]\n",
      "epoch:30 step:24078 [D loss: 0.589467, acc: 67.97%] [G loss: 4.039052]\n",
      "epoch:30 step:24079 [D loss: 0.386605, acc: 89.06%] [G loss: 4.270248]\n",
      "epoch:30 step:24080 [D loss: 0.254817, acc: 93.75%] [G loss: 2.626399]\n",
      "epoch:30 step:24081 [D loss: 0.271847, acc: 96.09%] [G loss: 3.800089]\n",
      "epoch:30 step:24082 [D loss: 0.691431, acc: 57.81%] [G loss: 3.920799]\n",
      "epoch:30 step:24083 [D loss: 0.161101, acc: 99.22%] [G loss: 7.248920]\n",
      "epoch:30 step:24084 [D loss: 0.074313, acc: 100.00%] [G loss: 5.565987]\n",
      "epoch:30 step:24085 [D loss: 0.459043, acc: 71.09%] [G loss: 6.173949]\n",
      "epoch:30 step:24086 [D loss: 0.737848, acc: 57.81%] [G loss: 4.009794]\n",
      "epoch:30 step:24087 [D loss: 0.375025, acc: 77.34%] [G loss: 6.296582]\n",
      "epoch:30 step:24088 [D loss: 0.729320, acc: 57.81%] [G loss: 3.994365]\n",
      "epoch:30 step:24089 [D loss: 0.163348, acc: 96.88%] [G loss: 6.283496]\n",
      "epoch:30 step:24090 [D loss: 0.271940, acc: 92.97%] [G loss: 4.971531]\n",
      "epoch:30 step:24091 [D loss: 0.286871, acc: 93.75%] [G loss: 5.097739]\n",
      "epoch:30 step:24092 [D loss: 0.369446, acc: 71.88%] [G loss: 3.534597]\n",
      "epoch:30 step:24093 [D loss: 0.435286, acc: 82.81%] [G loss: 4.427374]\n",
      "epoch:30 step:24094 [D loss: 0.345946, acc: 84.38%] [G loss: 5.341642]\n",
      "epoch:30 step:24095 [D loss: 0.673426, acc: 55.47%] [G loss: 2.728860]\n",
      "epoch:30 step:24096 [D loss: 0.294671, acc: 89.06%] [G loss: 5.440310]\n",
      "epoch:30 step:24097 [D loss: 0.126671, acc: 97.66%] [G loss: 3.265370]\n",
      "epoch:30 step:24098 [D loss: 0.753784, acc: 58.59%] [G loss: 4.966462]\n",
      "epoch:30 step:24099 [D loss: 0.423401, acc: 73.44%] [G loss: 3.623272]\n",
      "epoch:30 step:24100 [D loss: 0.184842, acc: 97.66%] [G loss: 3.443550]\n",
      "epoch:30 step:24101 [D loss: 0.366370, acc: 76.56%] [G loss: 6.690860]\n",
      "epoch:30 step:24102 [D loss: 0.262265, acc: 91.41%] [G loss: 6.528637]\n",
      "epoch:30 step:24103 [D loss: 0.795452, acc: 44.53%] [G loss: 4.452006]\n",
      "epoch:30 step:24104 [D loss: 0.449144, acc: 73.44%] [G loss: 1.536311]\n",
      "epoch:30 step:24105 [D loss: 0.243559, acc: 93.75%] [G loss: 4.423748]\n",
      "epoch:30 step:24106 [D loss: 0.465883, acc: 66.41%] [G loss: 5.451058]\n",
      "epoch:30 step:24107 [D loss: 0.304304, acc: 84.38%] [G loss: 3.498894]\n",
      "epoch:30 step:24108 [D loss: 0.048814, acc: 100.00%] [G loss: 2.012158]\n",
      "epoch:30 step:24109 [D loss: 0.483763, acc: 74.22%] [G loss: 3.365726]\n",
      "epoch:30 step:24110 [D loss: 1.754651, acc: 3.91%] [G loss: 3.044259]\n",
      "epoch:30 step:24111 [D loss: 0.081834, acc: 100.00%] [G loss: 6.320889]\n",
      "epoch:30 step:24112 [D loss: 1.929321, acc: 20.31%] [G loss: 5.095964]\n",
      "epoch:30 step:24113 [D loss: 0.548101, acc: 63.28%] [G loss: 4.508400]\n",
      "epoch:30 step:24114 [D loss: 0.781137, acc: 53.91%] [G loss: 5.500109]\n",
      "epoch:30 step:24115 [D loss: 0.179109, acc: 100.00%] [G loss: 4.370693]\n",
      "epoch:30 step:24116 [D loss: 0.080292, acc: 100.00%] [G loss: 3.657526]\n",
      "epoch:30 step:24117 [D loss: 0.571330, acc: 61.72%] [G loss: 6.260783]\n",
      "epoch:30 step:24118 [D loss: 0.127340, acc: 100.00%] [G loss: 2.178882]\n",
      "epoch:30 step:24119 [D loss: 1.127363, acc: 51.56%] [G loss: 4.135579]\n",
      "epoch:30 step:24120 [D loss: 0.566727, acc: 64.84%] [G loss: 5.815519]\n",
      "epoch:30 step:24121 [D loss: 0.399980, acc: 85.16%] [G loss: 2.201879]\n",
      "epoch:30 step:24122 [D loss: 0.786547, acc: 53.12%] [G loss: 3.748968]\n",
      "epoch:30 step:24123 [D loss: 0.407370, acc: 87.50%] [G loss: 3.077544]\n",
      "epoch:30 step:24124 [D loss: 0.239056, acc: 96.09%] [G loss: 3.752483]\n",
      "epoch:30 step:24125 [D loss: 0.162181, acc: 98.44%] [G loss: 4.204122]\n",
      "epoch:30 step:24126 [D loss: 0.930582, acc: 42.97%] [G loss: 3.258895]\n",
      "epoch:30 step:24127 [D loss: 0.204109, acc: 97.66%] [G loss: 4.354488]\n",
      "epoch:30 step:24128 [D loss: 0.366523, acc: 82.03%] [G loss: 3.965242]\n",
      "epoch:30 step:24129 [D loss: 0.539324, acc: 66.41%] [G loss: 6.634648]\n",
      "epoch:30 step:24130 [D loss: 0.941748, acc: 53.12%] [G loss: 3.364854]\n",
      "epoch:30 step:24131 [D loss: 0.209420, acc: 96.88%] [G loss: 3.624091]\n",
      "epoch:30 step:24132 [D loss: 0.434427, acc: 68.75%] [G loss: 6.973003]\n",
      "epoch:30 step:24133 [D loss: 0.231511, acc: 96.09%] [G loss: 5.001644]\n",
      "epoch:30 step:24134 [D loss: 0.440694, acc: 72.66%] [G loss: 4.236985]\n",
      "epoch:30 step:24135 [D loss: 0.054944, acc: 100.00%] [G loss: 3.685315]\n",
      "epoch:30 step:24136 [D loss: 0.130013, acc: 100.00%] [G loss: 4.043477]\n",
      "epoch:30 step:24137 [D loss: 0.201388, acc: 98.44%] [G loss: 2.555398]\n",
      "epoch:30 step:24138 [D loss: 0.453680, acc: 75.00%] [G loss: 4.630846]\n",
      "epoch:30 step:24139 [D loss: 0.700518, acc: 55.47%] [G loss: 4.383098]\n",
      "epoch:30 step:24140 [D loss: 0.186173, acc: 96.09%] [G loss: 2.293167]\n",
      "epoch:30 step:24141 [D loss: 0.188760, acc: 96.88%] [G loss: 4.002116]\n",
      "epoch:30 step:24142 [D loss: 0.247535, acc: 89.84%] [G loss: 4.011189]\n",
      "epoch:30 step:24143 [D loss: 0.075893, acc: 99.22%] [G loss: 3.833800]\n",
      "epoch:30 step:24144 [D loss: 0.249091, acc: 91.41%] [G loss: 1.977598]\n",
      "epoch:30 step:24145 [D loss: 0.584171, acc: 63.28%] [G loss: 2.997077]\n",
      "epoch:30 step:24146 [D loss: 0.550062, acc: 64.06%] [G loss: 5.295975]\n",
      "epoch:30 step:24147 [D loss: 0.059061, acc: 100.00%] [G loss: 5.609566]\n",
      "epoch:30 step:24148 [D loss: 0.223446, acc: 95.31%] [G loss: 7.186568]\n",
      "epoch:30 step:24149 [D loss: 0.878275, acc: 50.78%] [G loss: 7.504745]\n",
      "epoch:30 step:24150 [D loss: 0.276676, acc: 91.41%] [G loss: 3.965457]\n",
      "epoch:30 step:24151 [D loss: 0.626663, acc: 65.62%] [G loss: 3.578437]\n",
      "epoch:30 step:24152 [D loss: 0.731939, acc: 55.47%] [G loss: 3.144837]\n",
      "epoch:30 step:24153 [D loss: 0.114510, acc: 98.44%] [G loss: 3.834751]\n",
      "epoch:30 step:24154 [D loss: 0.468084, acc: 83.59%] [G loss: 7.779757]\n",
      "epoch:30 step:24155 [D loss: 0.207430, acc: 97.66%] [G loss: 5.333512]\n",
      "epoch:30 step:24156 [D loss: 0.081108, acc: 100.00%] [G loss: 4.573212]\n",
      "epoch:30 step:24157 [D loss: 0.257757, acc: 89.06%] [G loss: 4.083953]\n",
      "epoch:30 step:24158 [D loss: 0.345914, acc: 90.62%] [G loss: 4.535397]\n",
      "epoch:30 step:24159 [D loss: 0.569639, acc: 61.72%] [G loss: 3.540087]\n",
      "epoch:30 step:24160 [D loss: 0.307539, acc: 92.19%] [G loss: 2.457555]\n",
      "epoch:30 step:24161 [D loss: 0.427987, acc: 72.66%] [G loss: 4.655074]\n",
      "epoch:30 step:24162 [D loss: 0.158793, acc: 98.44%] [G loss: 4.518411]\n",
      "epoch:30 step:24163 [D loss: 0.154888, acc: 99.22%] [G loss: 4.352206]\n",
      "epoch:30 step:24164 [D loss: 0.693881, acc: 54.69%] [G loss: 5.751165]\n",
      "epoch:30 step:24165 [D loss: 0.056602, acc: 99.22%] [G loss: 3.659848]\n",
      "epoch:30 step:24166 [D loss: 0.346057, acc: 81.25%] [G loss: 4.621328]\n",
      "epoch:30 step:24167 [D loss: 0.288024, acc: 96.09%] [G loss: 5.379236]\n",
      "epoch:30 step:24168 [D loss: 0.879167, acc: 42.97%] [G loss: 4.994386]\n",
      "epoch:30 step:24169 [D loss: 0.130771, acc: 100.00%] [G loss: 5.558214]\n",
      "epoch:30 step:24170 [D loss: 0.559533, acc: 56.25%] [G loss: 6.666506]\n",
      "epoch:30 step:24171 [D loss: 0.161969, acc: 100.00%] [G loss: 6.077268]\n",
      "epoch:30 step:24172 [D loss: 1.255341, acc: 39.06%] [G loss: 6.449346]\n",
      "epoch:30 step:24173 [D loss: 0.104534, acc: 100.00%] [G loss: 2.894268]\n",
      "epoch:30 step:24174 [D loss: 0.162607, acc: 96.88%] [G loss: 5.539045]\n",
      "epoch:30 step:24175 [D loss: 0.495127, acc: 75.00%] [G loss: 2.648533]\n",
      "epoch:30 step:24176 [D loss: 0.268988, acc: 94.53%] [G loss: 4.287986]\n",
      "epoch:30 step:24177 [D loss: 0.533429, acc: 71.88%] [G loss: 3.496377]\n",
      "epoch:30 step:24178 [D loss: 0.184275, acc: 97.66%] [G loss: 5.505879]\n",
      "epoch:30 step:24179 [D loss: 0.256187, acc: 92.97%] [G loss: 4.351593]\n",
      "epoch:30 step:24180 [D loss: 0.480180, acc: 76.56%] [G loss: 4.175050]\n",
      "epoch:30 step:24181 [D loss: 0.827418, acc: 50.78%] [G loss: 5.767026]\n",
      "epoch:30 step:24182 [D loss: 0.057121, acc: 100.00%] [G loss: 3.592289]\n",
      "epoch:30 step:24183 [D loss: 1.107672, acc: 39.06%] [G loss: 6.463493]\n",
      "epoch:30 step:24184 [D loss: 0.195497, acc: 98.44%] [G loss: 3.953506]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:24185 [D loss: 0.095842, acc: 99.22%] [G loss: 3.359214]\n",
      "epoch:30 step:24186 [D loss: 0.602093, acc: 70.31%] [G loss: 2.881100]\n",
      "epoch:30 step:24187 [D loss: 0.178922, acc: 98.44%] [G loss: 3.086735]\n",
      "epoch:30 step:24188 [D loss: 0.434838, acc: 87.50%] [G loss: 5.141990]\n",
      "epoch:30 step:24189 [D loss: 0.279153, acc: 95.31%] [G loss: 3.035925]\n",
      "epoch:30 step:24190 [D loss: 0.260129, acc: 91.41%] [G loss: 6.114719]\n",
      "epoch:30 step:24191 [D loss: 0.168772, acc: 96.88%] [G loss: 5.195709]\n",
      "epoch:30 step:24192 [D loss: 0.574130, acc: 66.41%] [G loss: 5.370204]\n",
      "epoch:30 step:24193 [D loss: 1.018386, acc: 50.00%] [G loss: 3.075216]\n",
      "epoch:30 step:24194 [D loss: 0.346945, acc: 92.19%] [G loss: 3.867886]\n",
      "epoch:30 step:24195 [D loss: 0.358183, acc: 82.81%] [G loss: 3.686430]\n",
      "epoch:30 step:24196 [D loss: 0.218281, acc: 96.88%] [G loss: 4.200295]\n",
      "epoch:30 step:24197 [D loss: 0.181359, acc: 98.44%] [G loss: 4.193082]\n",
      "epoch:30 step:24198 [D loss: 0.233743, acc: 94.53%] [G loss: 3.540917]\n",
      "epoch:30 step:24199 [D loss: 0.964353, acc: 39.84%] [G loss: 3.368546]\n",
      "epoch:30 step:24200 [D loss: 0.724123, acc: 58.59%] [G loss: 4.466289]\n",
      "epoch:30 step:24201 [D loss: 0.797837, acc: 51.56%] [G loss: 4.294564]\n",
      "epoch:30 step:24202 [D loss: 0.300466, acc: 97.66%] [G loss: 3.459854]\n",
      "epoch:30 step:24203 [D loss: 0.119273, acc: 99.22%] [G loss: 6.753636]\n",
      "epoch:30 step:24204 [D loss: 0.279024, acc: 90.62%] [G loss: 5.589110]\n",
      "epoch:30 step:24205 [D loss: 0.340998, acc: 90.62%] [G loss: 4.416822]\n",
      "epoch:30 step:24206 [D loss: 0.616930, acc: 61.72%] [G loss: 5.420526]\n",
      "epoch:30 step:24207 [D loss: 0.520531, acc: 66.41%] [G loss: 5.440797]\n",
      "epoch:30 step:24208 [D loss: 0.621854, acc: 57.03%] [G loss: 5.073825]\n",
      "epoch:30 step:24209 [D loss: 0.381768, acc: 83.59%] [G loss: 5.385361]\n",
      "epoch:30 step:24210 [D loss: 0.764028, acc: 54.69%] [G loss: 3.852642]\n",
      "epoch:30 step:24211 [D loss: 0.415893, acc: 75.00%] [G loss: 6.799893]\n",
      "epoch:31 step:24212 [D loss: 0.288165, acc: 96.09%] [G loss: 4.603013]\n",
      "epoch:31 step:24213 [D loss: 0.134707, acc: 98.44%] [G loss: 4.434003]\n",
      "epoch:31 step:24214 [D loss: 0.468370, acc: 77.34%] [G loss: 3.863870]\n",
      "epoch:31 step:24215 [D loss: 0.052507, acc: 100.00%] [G loss: 4.396121]\n",
      "epoch:31 step:24216 [D loss: 0.407038, acc: 87.50%] [G loss: 3.526844]\n",
      "epoch:31 step:24217 [D loss: 0.126182, acc: 99.22%] [G loss: 3.346919]\n",
      "epoch:31 step:24218 [D loss: 0.659494, acc: 58.59%] [G loss: 3.231941]\n",
      "epoch:31 step:24219 [D loss: 0.942115, acc: 32.81%] [G loss: 3.833873]\n",
      "epoch:31 step:24220 [D loss: 0.286969, acc: 89.06%] [G loss: 5.043823]\n",
      "epoch:31 step:24221 [D loss: 0.198767, acc: 96.88%] [G loss: 5.106981]\n",
      "epoch:31 step:24222 [D loss: 0.439409, acc: 83.59%] [G loss: 4.297251]\n",
      "epoch:31 step:24223 [D loss: 0.170685, acc: 98.44%] [G loss: 3.565462]\n",
      "epoch:31 step:24224 [D loss: 0.131000, acc: 99.22%] [G loss: 5.138815]\n",
      "epoch:31 step:24225 [D loss: 0.154479, acc: 99.22%] [G loss: 4.347704]\n",
      "epoch:31 step:24226 [D loss: 2.041472, acc: 0.78%] [G loss: 3.634978]\n",
      "epoch:31 step:24227 [D loss: 0.968566, acc: 48.44%] [G loss: 4.589454]\n",
      "epoch:31 step:24228 [D loss: 0.473541, acc: 69.53%] [G loss: 3.805854]\n",
      "epoch:31 step:24229 [D loss: 0.226889, acc: 96.09%] [G loss: 2.973976]\n",
      "epoch:31 step:24230 [D loss: 0.140597, acc: 99.22%] [G loss: 2.945750]\n",
      "epoch:31 step:24231 [D loss: 1.170054, acc: 33.59%] [G loss: 2.770759]\n",
      "epoch:31 step:24232 [D loss: 0.261930, acc: 89.84%] [G loss: 4.200750]\n",
      "epoch:31 step:24233 [D loss: 0.121203, acc: 100.00%] [G loss: 2.977406]\n",
      "epoch:31 step:24234 [D loss: 0.023788, acc: 100.00%] [G loss: 4.673810]\n",
      "epoch:31 step:24235 [D loss: 0.387463, acc: 78.12%] [G loss: 3.894099]\n",
      "epoch:31 step:24236 [D loss: 0.808917, acc: 52.34%] [G loss: 4.470754]\n",
      "epoch:31 step:24237 [D loss: 0.717405, acc: 56.25%] [G loss: 2.660285]\n",
      "epoch:31 step:24238 [D loss: 0.774333, acc: 57.81%] [G loss: 4.259799]\n",
      "epoch:31 step:24239 [D loss: 0.253649, acc: 92.97%] [G loss: 5.584630]\n",
      "epoch:31 step:24240 [D loss: 0.122401, acc: 99.22%] [G loss: 4.633792]\n",
      "epoch:31 step:24241 [D loss: 0.094983, acc: 100.00%] [G loss: 4.662741]\n",
      "epoch:31 step:24242 [D loss: 0.883690, acc: 44.53%] [G loss: 6.845639]\n",
      "epoch:31 step:24243 [D loss: 0.644850, acc: 56.25%] [G loss: 3.371041]\n",
      "epoch:31 step:24244 [D loss: 0.678283, acc: 61.72%] [G loss: 5.091470]\n",
      "epoch:31 step:24245 [D loss: 0.212089, acc: 98.44%] [G loss: 2.703695]\n",
      "epoch:31 step:24246 [D loss: 0.694951, acc: 57.81%] [G loss: 3.738605]\n",
      "epoch:31 step:24247 [D loss: 0.125563, acc: 99.22%] [G loss: 5.609835]\n",
      "epoch:31 step:24248 [D loss: 0.321112, acc: 92.97%] [G loss: 4.609734]\n",
      "epoch:31 step:24249 [D loss: 0.563283, acc: 72.66%] [G loss: 4.738016]\n",
      "epoch:31 step:24250 [D loss: 0.220662, acc: 96.09%] [G loss: 5.416206]\n",
      "epoch:31 step:24251 [D loss: 0.374561, acc: 75.00%] [G loss: 4.251652]\n",
      "epoch:31 step:24252 [D loss: 0.717398, acc: 55.47%] [G loss: 3.964907]\n",
      "epoch:31 step:24253 [D loss: 0.227458, acc: 96.88%] [G loss: 4.817822]\n",
      "epoch:31 step:24254 [D loss: 0.511905, acc: 78.91%] [G loss: 3.156913]\n",
      "epoch:31 step:24255 [D loss: 1.057581, acc: 40.62%] [G loss: 4.042752]\n",
      "epoch:31 step:24256 [D loss: 0.252279, acc: 92.97%] [G loss: 3.488980]\n",
      "epoch:31 step:24257 [D loss: 0.306683, acc: 89.84%] [G loss: 6.344215]\n",
      "epoch:31 step:24258 [D loss: 0.696666, acc: 55.47%] [G loss: 3.947112]\n",
      "epoch:31 step:24259 [D loss: 0.658888, acc: 60.94%] [G loss: 3.105445]\n",
      "epoch:31 step:24260 [D loss: 0.696055, acc: 57.81%] [G loss: 5.659616]\n",
      "epoch:31 step:24261 [D loss: 0.372356, acc: 87.50%] [G loss: 5.150240]\n",
      "epoch:31 step:24262 [D loss: 0.397008, acc: 75.00%] [G loss: 5.075951]\n",
      "epoch:31 step:24263 [D loss: 0.109366, acc: 99.22%] [G loss: 3.259607]\n",
      "epoch:31 step:24264 [D loss: 0.760180, acc: 53.12%] [G loss: 3.455752]\n",
      "epoch:31 step:24265 [D loss: 0.351271, acc: 78.91%] [G loss: 5.272212]\n",
      "epoch:31 step:24266 [D loss: 0.422273, acc: 82.81%] [G loss: 4.521474]\n",
      "epoch:31 step:24267 [D loss: 0.458387, acc: 79.69%] [G loss: 5.664258]\n",
      "epoch:31 step:24268 [D loss: 0.532930, acc: 75.78%] [G loss: 4.481227]\n",
      "epoch:31 step:24269 [D loss: 0.374693, acc: 86.72%] [G loss: 7.093366]\n",
      "epoch:31 step:24270 [D loss: 0.542120, acc: 75.00%] [G loss: 4.189419]\n",
      "epoch:31 step:24271 [D loss: 0.563259, acc: 68.75%] [G loss: 4.500528]\n",
      "epoch:31 step:24272 [D loss: 0.084859, acc: 100.00%] [G loss: 4.285573]\n",
      "epoch:31 step:24273 [D loss: 0.482878, acc: 71.88%] [G loss: 5.432826]\n",
      "epoch:31 step:24274 [D loss: 0.383663, acc: 82.81%] [G loss: 3.843168]\n",
      "epoch:31 step:24275 [D loss: 1.147392, acc: 44.53%] [G loss: 5.388093]\n",
      "epoch:31 step:24276 [D loss: 0.259933, acc: 92.19%] [G loss: 4.654543]\n",
      "epoch:31 step:24277 [D loss: 0.422323, acc: 80.47%] [G loss: 3.145046]\n",
      "epoch:31 step:24278 [D loss: 0.638061, acc: 60.16%] [G loss: 3.126479]\n",
      "epoch:31 step:24279 [D loss: 0.775340, acc: 47.66%] [G loss: 5.493976]\n",
      "epoch:31 step:24280 [D loss: 0.212135, acc: 96.88%] [G loss: 3.936010]\n",
      "epoch:31 step:24281 [D loss: 0.469557, acc: 71.88%] [G loss: 3.275135]\n",
      "epoch:31 step:24282 [D loss: 0.634975, acc: 64.06%] [G loss: 3.510539]\n",
      "epoch:31 step:24283 [D loss: 0.285859, acc: 89.84%] [G loss: 3.728105]\n",
      "epoch:31 step:24284 [D loss: 0.346515, acc: 89.84%] [G loss: 4.312662]\n",
      "epoch:31 step:24285 [D loss: 0.107759, acc: 100.00%] [G loss: 4.154225]\n",
      "epoch:31 step:24286 [D loss: 0.347007, acc: 85.16%] [G loss: 3.553924]\n",
      "epoch:31 step:24287 [D loss: 0.169767, acc: 98.44%] [G loss: 4.214280]\n",
      "epoch:31 step:24288 [D loss: 0.289093, acc: 92.97%] [G loss: 4.967760]\n",
      "epoch:31 step:24289 [D loss: 0.100480, acc: 99.22%] [G loss: 2.938630]\n",
      "epoch:31 step:24290 [D loss: 0.504319, acc: 73.44%] [G loss: 4.546816]\n",
      "epoch:31 step:24291 [D loss: 1.121468, acc: 18.75%] [G loss: 4.311816]\n",
      "epoch:31 step:24292 [D loss: 0.400535, acc: 85.16%] [G loss: 8.229048]\n",
      "epoch:31 step:24293 [D loss: 0.659541, acc: 57.03%] [G loss: 3.837612]\n",
      "epoch:31 step:24294 [D loss: 0.459580, acc: 81.25%] [G loss: 4.473940]\n",
      "epoch:31 step:24295 [D loss: 0.759211, acc: 54.69%] [G loss: 5.413316]\n",
      "epoch:31 step:24296 [D loss: 0.309973, acc: 95.31%] [G loss: 4.844586]\n",
      "epoch:31 step:24297 [D loss: 1.528993, acc: 11.72%] [G loss: 5.069716]\n",
      "epoch:31 step:24298 [D loss: 0.207302, acc: 96.88%] [G loss: 4.158160]\n",
      "epoch:31 step:24299 [D loss: 0.324494, acc: 89.06%] [G loss: 4.760833]\n",
      "epoch:31 step:24300 [D loss: 0.356275, acc: 79.69%] [G loss: 5.211264]\n",
      "epoch:31 step:24301 [D loss: 0.376926, acc: 92.19%] [G loss: 4.946834]\n",
      "epoch:31 step:24302 [D loss: 0.121249, acc: 100.00%] [G loss: 3.540097]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24303 [D loss: 0.370063, acc: 89.06%] [G loss: 4.032169]\n",
      "epoch:31 step:24304 [D loss: 1.435854, acc: 18.75%] [G loss: 3.349254]\n",
      "epoch:31 step:24305 [D loss: 0.121022, acc: 100.00%] [G loss: 2.924773]\n",
      "epoch:31 step:24306 [D loss: 0.865641, acc: 51.56%] [G loss: 5.577080]\n",
      "epoch:31 step:24307 [D loss: 0.329702, acc: 92.19%] [G loss: 5.479233]\n",
      "epoch:31 step:24308 [D loss: 0.483965, acc: 69.53%] [G loss: 5.894904]\n",
      "epoch:31 step:24309 [D loss: 0.550896, acc: 73.44%] [G loss: 5.451203]\n",
      "epoch:31 step:24310 [D loss: 0.271195, acc: 92.97%] [G loss: 4.337424]\n",
      "epoch:31 step:24311 [D loss: 0.184661, acc: 97.66%] [G loss: 4.162229]\n",
      "epoch:31 step:24312 [D loss: 0.173245, acc: 98.44%] [G loss: 4.475809]\n",
      "epoch:31 step:24313 [D loss: 0.191621, acc: 99.22%] [G loss: 3.842830]\n",
      "epoch:31 step:24314 [D loss: 0.644298, acc: 62.50%] [G loss: 5.190607]\n",
      "epoch:31 step:24315 [D loss: 0.485328, acc: 79.69%] [G loss: 4.496917]\n",
      "epoch:31 step:24316 [D loss: 0.563628, acc: 63.28%] [G loss: 5.444668]\n",
      "epoch:31 step:24317 [D loss: 0.139934, acc: 99.22%] [G loss: 3.449212]\n",
      "epoch:31 step:24318 [D loss: 0.177528, acc: 99.22%] [G loss: 2.463729]\n",
      "epoch:31 step:24319 [D loss: 1.264596, acc: 37.50%] [G loss: 4.228852]\n",
      "epoch:31 step:24320 [D loss: 0.161428, acc: 98.44%] [G loss: 3.434148]\n",
      "epoch:31 step:24321 [D loss: 0.163384, acc: 100.00%] [G loss: 1.999675]\n",
      "epoch:31 step:24322 [D loss: 0.251443, acc: 95.31%] [G loss: 3.221358]\n",
      "epoch:31 step:24323 [D loss: 0.226700, acc: 95.31%] [G loss: 4.782672]\n",
      "epoch:31 step:24324 [D loss: 0.341509, acc: 89.06%] [G loss: 3.749440]\n",
      "epoch:31 step:24325 [D loss: 0.162445, acc: 99.22%] [G loss: 2.579892]\n",
      "epoch:31 step:24326 [D loss: 0.968819, acc: 48.44%] [G loss: 4.170950]\n",
      "epoch:31 step:24327 [D loss: 0.766805, acc: 53.91%] [G loss: 4.492295]\n",
      "epoch:31 step:24328 [D loss: 0.581248, acc: 69.53%] [G loss: 1.361081]\n",
      "epoch:31 step:24329 [D loss: 0.626009, acc: 62.50%] [G loss: 4.417310]\n",
      "epoch:31 step:24330 [D loss: 0.109274, acc: 100.00%] [G loss: 4.441387]\n",
      "epoch:31 step:24331 [D loss: 1.270728, acc: 42.19%] [G loss: 9.113125]\n",
      "epoch:31 step:24332 [D loss: 0.674062, acc: 57.03%] [G loss: 3.470053]\n",
      "epoch:31 step:24333 [D loss: 0.107925, acc: 99.22%] [G loss: 6.549683]\n",
      "epoch:31 step:24334 [D loss: 0.228903, acc: 97.66%] [G loss: 3.899024]\n",
      "epoch:31 step:24335 [D loss: 0.428971, acc: 87.50%] [G loss: 2.819263]\n",
      "epoch:31 step:24336 [D loss: 0.688257, acc: 57.81%] [G loss: 4.516958]\n",
      "epoch:31 step:24337 [D loss: 0.285608, acc: 94.53%] [G loss: 3.157682]\n",
      "epoch:31 step:24338 [D loss: 0.362614, acc: 86.72%] [G loss: 4.820093]\n",
      "epoch:31 step:24339 [D loss: 0.072075, acc: 100.00%] [G loss: 4.012176]\n",
      "epoch:31 step:24340 [D loss: 0.376450, acc: 91.41%] [G loss: 4.827235]\n",
      "epoch:31 step:24341 [D loss: 1.576359, acc: 6.25%] [G loss: 3.594445]\n",
      "epoch:31 step:24342 [D loss: 0.412705, acc: 82.81%] [G loss: 3.904823]\n",
      "epoch:31 step:24343 [D loss: 0.308700, acc: 92.19%] [G loss: 3.721862]\n",
      "epoch:31 step:24344 [D loss: 0.402079, acc: 83.59%] [G loss: 3.757631]\n",
      "epoch:31 step:24345 [D loss: 0.097832, acc: 100.00%] [G loss: 5.657892]\n",
      "epoch:31 step:24346 [D loss: 1.548579, acc: 5.47%] [G loss: 3.977147]\n",
      "epoch:31 step:24347 [D loss: 0.617522, acc: 67.19%] [G loss: 6.295583]\n",
      "epoch:31 step:24348 [D loss: 0.488436, acc: 78.12%] [G loss: 4.382599]\n",
      "epoch:31 step:24349 [D loss: 0.534135, acc: 67.97%] [G loss: 5.419194]\n",
      "epoch:31 step:24350 [D loss: 0.376909, acc: 84.38%] [G loss: 4.031397]\n",
      "epoch:31 step:24351 [D loss: 0.195958, acc: 96.09%] [G loss: 3.618517]\n",
      "epoch:31 step:24352 [D loss: 0.570964, acc: 69.53%] [G loss: 4.060140]\n",
      "epoch:31 step:24353 [D loss: 0.826770, acc: 52.34%] [G loss: 4.428689]\n",
      "epoch:31 step:24354 [D loss: 0.573696, acc: 67.19%] [G loss: 4.398614]\n",
      "epoch:31 step:24355 [D loss: 0.099412, acc: 99.22%] [G loss: 3.676241]\n",
      "epoch:31 step:24356 [D loss: 0.267229, acc: 97.66%] [G loss: 3.434552]\n",
      "epoch:31 step:24357 [D loss: 0.110195, acc: 100.00%] [G loss: 4.698623]\n",
      "epoch:31 step:24358 [D loss: 0.366915, acc: 89.06%] [G loss: 6.271522]\n",
      "epoch:31 step:24359 [D loss: 0.172545, acc: 96.88%] [G loss: 4.766294]\n",
      "epoch:31 step:24360 [D loss: 0.551581, acc: 71.09%] [G loss: 3.763407]\n",
      "epoch:31 step:24361 [D loss: 0.344876, acc: 84.38%] [G loss: 2.310845]\n",
      "epoch:31 step:24362 [D loss: 0.508387, acc: 77.34%] [G loss: 4.938180]\n",
      "epoch:31 step:24363 [D loss: 0.327468, acc: 96.09%] [G loss: 3.702680]\n",
      "epoch:31 step:24364 [D loss: 0.241301, acc: 93.75%] [G loss: 5.924831]\n",
      "epoch:31 step:24365 [D loss: 0.258443, acc: 91.41%] [G loss: 2.347557]\n",
      "epoch:31 step:24366 [D loss: 1.137300, acc: 47.66%] [G loss: 3.990236]\n",
      "epoch:31 step:24367 [D loss: 0.237560, acc: 95.31%] [G loss: 2.725366]\n",
      "epoch:31 step:24368 [D loss: 0.477259, acc: 63.28%] [G loss: 4.144957]\n",
      "epoch:31 step:24369 [D loss: 0.621009, acc: 61.72%] [G loss: 7.749656]\n",
      "epoch:31 step:24370 [D loss: 1.089356, acc: 51.56%] [G loss: 5.177935]\n",
      "epoch:31 step:24371 [D loss: 1.354922, acc: 10.94%] [G loss: 5.152169]\n",
      "epoch:31 step:24372 [D loss: 0.878941, acc: 50.78%] [G loss: 4.120724]\n",
      "epoch:31 step:24373 [D loss: 0.266803, acc: 89.06%] [G loss: 5.624674]\n",
      "epoch:31 step:24374 [D loss: 0.577196, acc: 59.38%] [G loss: 4.944382]\n",
      "epoch:31 step:24375 [D loss: 0.309881, acc: 85.16%] [G loss: 4.786796]\n",
      "epoch:31 step:24376 [D loss: 0.173501, acc: 98.44%] [G loss: 3.786728]\n",
      "epoch:31 step:24377 [D loss: 0.208222, acc: 96.09%] [G loss: 2.408778]\n",
      "epoch:31 step:24378 [D loss: 0.416708, acc: 83.59%] [G loss: 3.838229]\n",
      "epoch:31 step:24379 [D loss: 0.647674, acc: 59.38%] [G loss: 3.961417]\n",
      "epoch:31 step:24380 [D loss: 0.576307, acc: 68.75%] [G loss: 4.018464]\n",
      "epoch:31 step:24381 [D loss: 0.234059, acc: 96.09%] [G loss: 5.018517]\n",
      "epoch:31 step:24382 [D loss: 0.147201, acc: 99.22%] [G loss: 2.838221]\n",
      "epoch:31 step:24383 [D loss: 0.356695, acc: 93.75%] [G loss: 5.297304]\n",
      "epoch:31 step:24384 [D loss: 1.641521, acc: 37.50%] [G loss: 4.460756]\n",
      "epoch:31 step:24385 [D loss: 0.082541, acc: 100.00%] [G loss: 5.757851]\n",
      "epoch:31 step:24386 [D loss: 0.781490, acc: 55.47%] [G loss: 3.689275]\n",
      "epoch:31 step:24387 [D loss: 0.575733, acc: 69.53%] [G loss: 4.357130]\n",
      "epoch:31 step:24388 [D loss: 0.416119, acc: 72.66%] [G loss: 4.412798]\n",
      "epoch:31 step:24389 [D loss: 0.427589, acc: 78.91%] [G loss: 3.959883]\n",
      "epoch:31 step:24390 [D loss: 0.137965, acc: 98.44%] [G loss: 5.497890]\n",
      "epoch:31 step:24391 [D loss: 0.291980, acc: 96.88%] [G loss: 3.073057]\n",
      "epoch:31 step:24392 [D loss: 0.476226, acc: 71.88%] [G loss: 2.538042]\n",
      "epoch:31 step:24393 [D loss: 0.347962, acc: 90.62%] [G loss: 4.280706]\n",
      "epoch:31 step:24394 [D loss: 0.111107, acc: 100.00%] [G loss: 3.021892]\n",
      "epoch:31 step:24395 [D loss: 0.390276, acc: 89.84%] [G loss: 3.501782]\n",
      "epoch:31 step:24396 [D loss: 0.116199, acc: 99.22%] [G loss: 2.864032]\n",
      "epoch:31 step:24397 [D loss: 0.286781, acc: 96.09%] [G loss: 4.631224]\n",
      "epoch:31 step:24398 [D loss: 0.270619, acc: 96.09%] [G loss: 5.872523]\n",
      "epoch:31 step:24399 [D loss: 0.400997, acc: 89.06%] [G loss: 4.116199]\n",
      "epoch:31 step:24400 [D loss: 0.297137, acc: 90.62%] [G loss: 4.285264]\n",
      "epoch:31 step:24401 [D loss: 0.407588, acc: 77.34%] [G loss: 3.341295]\n",
      "epoch:31 step:24402 [D loss: 0.315040, acc: 96.09%] [G loss: 2.757212]\n",
      "epoch:31 step:24403 [D loss: 1.764207, acc: 40.62%] [G loss: 3.862484]\n",
      "epoch:31 step:24404 [D loss: 0.424815, acc: 85.94%] [G loss: 3.151888]\n",
      "epoch:31 step:24405 [D loss: 0.450662, acc: 67.19%] [G loss: 3.231724]\n",
      "epoch:31 step:24406 [D loss: 1.549974, acc: 9.38%] [G loss: 6.610324]\n",
      "epoch:31 step:24407 [D loss: 0.437323, acc: 87.50%] [G loss: 4.722196]\n",
      "epoch:31 step:24408 [D loss: 0.187041, acc: 97.66%] [G loss: 4.656759]\n",
      "epoch:31 step:24409 [D loss: 0.232688, acc: 93.75%] [G loss: 5.931904]\n",
      "epoch:31 step:24410 [D loss: 0.204283, acc: 100.00%] [G loss: 3.831892]\n",
      "epoch:31 step:24411 [D loss: 0.186344, acc: 98.44%] [G loss: 4.759739]\n",
      "epoch:31 step:24412 [D loss: 0.515847, acc: 74.22%] [G loss: 3.613508]\n",
      "epoch:31 step:24413 [D loss: 0.925993, acc: 43.75%] [G loss: 4.557943]\n",
      "epoch:31 step:24414 [D loss: 0.192101, acc: 97.66%] [G loss: 3.266650]\n",
      "epoch:31 step:24415 [D loss: 0.574439, acc: 65.62%] [G loss: 3.259986]\n",
      "epoch:31 step:24416 [D loss: 0.574510, acc: 69.53%] [G loss: 4.592904]\n",
      "epoch:31 step:24417 [D loss: 0.182981, acc: 100.00%] [G loss: 3.155416]\n",
      "epoch:31 step:24418 [D loss: 0.351984, acc: 85.16%] [G loss: 6.182770]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24419 [D loss: 0.185459, acc: 96.88%] [G loss: 3.306707]\n",
      "epoch:31 step:24420 [D loss: 0.347499, acc: 92.19%] [G loss: 6.475104]\n",
      "epoch:31 step:24421 [D loss: 0.172774, acc: 100.00%] [G loss: 4.225623]\n",
      "epoch:31 step:24422 [D loss: 0.496967, acc: 83.59%] [G loss: 3.113935]\n",
      "epoch:31 step:24423 [D loss: 0.154845, acc: 98.44%] [G loss: 5.887515]\n",
      "epoch:31 step:24424 [D loss: 0.430407, acc: 82.81%] [G loss: 4.783919]\n",
      "epoch:31 step:24425 [D loss: 0.191854, acc: 98.44%] [G loss: 5.160398]\n",
      "epoch:31 step:24426 [D loss: 0.414967, acc: 81.25%] [G loss: 3.905904]\n",
      "epoch:31 step:24427 [D loss: 0.387358, acc: 71.09%] [G loss: 5.256428]\n",
      "epoch:31 step:24428 [D loss: 0.958959, acc: 51.56%] [G loss: 3.483666]\n",
      "epoch:31 step:24429 [D loss: 0.592645, acc: 67.19%] [G loss: 4.943897]\n",
      "epoch:31 step:24430 [D loss: 0.481778, acc: 74.22%] [G loss: 3.587697]\n",
      "epoch:31 step:24431 [D loss: 0.122519, acc: 99.22%] [G loss: 5.764601]\n",
      "epoch:31 step:24432 [D loss: 0.330923, acc: 84.38%] [G loss: 2.819532]\n",
      "epoch:31 step:24433 [D loss: 0.241321, acc: 90.62%] [G loss: 5.109320]\n",
      "epoch:31 step:24434 [D loss: 1.048263, acc: 27.34%] [G loss: 5.567183]\n",
      "epoch:31 step:24435 [D loss: 0.242500, acc: 94.53%] [G loss: 4.038337]\n",
      "epoch:31 step:24436 [D loss: 0.178482, acc: 99.22%] [G loss: 3.087698]\n",
      "epoch:31 step:24437 [D loss: 0.126634, acc: 97.66%] [G loss: 3.033134]\n",
      "epoch:31 step:24438 [D loss: 0.253152, acc: 100.00%] [G loss: 2.989948]\n",
      "epoch:31 step:24439 [D loss: 0.242059, acc: 98.44%] [G loss: 3.218913]\n",
      "epoch:31 step:24440 [D loss: 0.377697, acc: 91.41%] [G loss: 4.526980]\n",
      "epoch:31 step:24441 [D loss: 0.252850, acc: 96.09%] [G loss: 4.681156]\n",
      "epoch:31 step:24442 [D loss: 0.143633, acc: 99.22%] [G loss: 1.884926]\n",
      "epoch:31 step:24443 [D loss: 0.661705, acc: 57.03%] [G loss: 3.585323]\n",
      "epoch:31 step:24444 [D loss: 0.344049, acc: 85.16%] [G loss: 4.157764]\n",
      "epoch:31 step:24445 [D loss: 0.671654, acc: 59.38%] [G loss: 6.861478]\n",
      "epoch:31 step:24446 [D loss: 0.593347, acc: 67.97%] [G loss: 4.196846]\n",
      "epoch:31 step:24447 [D loss: 0.228914, acc: 94.53%] [G loss: 4.072061]\n",
      "epoch:31 step:24448 [D loss: 0.809437, acc: 44.53%] [G loss: 4.093579]\n",
      "epoch:31 step:24449 [D loss: 0.291118, acc: 93.75%] [G loss: 6.532650]\n",
      "epoch:31 step:24450 [D loss: 0.322812, acc: 85.94%] [G loss: 4.551256]\n",
      "epoch:31 step:24451 [D loss: 0.421064, acc: 83.59%] [G loss: 4.925108]\n",
      "epoch:31 step:24452 [D loss: 0.500939, acc: 72.66%] [G loss: 3.959274]\n",
      "epoch:31 step:24453 [D loss: 0.277326, acc: 87.50%] [G loss: 6.428031]\n",
      "epoch:31 step:24454 [D loss: 0.547956, acc: 64.84%] [G loss: 4.616212]\n",
      "epoch:31 step:24455 [D loss: 0.109259, acc: 100.00%] [G loss: 4.958612]\n",
      "epoch:31 step:24456 [D loss: 0.522950, acc: 67.19%] [G loss: 5.448792]\n",
      "epoch:31 step:24457 [D loss: 0.878607, acc: 38.28%] [G loss: 5.308928]\n",
      "epoch:31 step:24458 [D loss: 0.782658, acc: 55.47%] [G loss: 2.952033]\n",
      "epoch:31 step:24459 [D loss: 1.197369, acc: 37.50%] [G loss: 2.007429]\n",
      "epoch:31 step:24460 [D loss: 0.166362, acc: 98.44%] [G loss: 6.467939]\n",
      "epoch:31 step:24461 [D loss: 0.456967, acc: 70.31%] [G loss: 5.348834]\n",
      "epoch:31 step:24462 [D loss: 0.302409, acc: 94.53%] [G loss: 3.253693]\n",
      "epoch:31 step:24463 [D loss: 0.721091, acc: 60.16%] [G loss: 4.684488]\n",
      "epoch:31 step:24464 [D loss: 0.262383, acc: 92.19%] [G loss: 2.472153]\n",
      "epoch:31 step:24465 [D loss: 0.256367, acc: 94.53%] [G loss: 4.392888]\n",
      "epoch:31 step:24466 [D loss: 0.128754, acc: 98.44%] [G loss: 5.952242]\n",
      "epoch:31 step:24467 [D loss: 0.364290, acc: 86.72%] [G loss: 4.054486]\n",
      "epoch:31 step:24468 [D loss: 0.789466, acc: 53.12%] [G loss: 5.104469]\n",
      "epoch:31 step:24469 [D loss: 0.345893, acc: 91.41%] [G loss: 4.821078]\n",
      "epoch:31 step:24470 [D loss: 0.453366, acc: 84.38%] [G loss: 3.863238]\n",
      "epoch:31 step:24471 [D loss: 0.376456, acc: 85.94%] [G loss: 3.926838]\n",
      "epoch:31 step:24472 [D loss: 0.440218, acc: 84.38%] [G loss: 4.938264]\n",
      "epoch:31 step:24473 [D loss: 0.101907, acc: 100.00%] [G loss: 4.752048]\n",
      "epoch:31 step:24474 [D loss: 0.138734, acc: 99.22%] [G loss: 3.814025]\n",
      "epoch:31 step:24475 [D loss: 0.533387, acc: 69.53%] [G loss: 2.150881]\n",
      "epoch:31 step:24476 [D loss: 0.577350, acc: 62.50%] [G loss: 4.772536]\n",
      "epoch:31 step:24477 [D loss: 0.193310, acc: 94.53%] [G loss: 4.505833]\n",
      "epoch:31 step:24478 [D loss: 0.429077, acc: 89.06%] [G loss: 3.120777]\n",
      "epoch:31 step:24479 [D loss: 0.510055, acc: 61.72%] [G loss: 4.900325]\n",
      "epoch:31 step:24480 [D loss: 0.380786, acc: 85.16%] [G loss: 4.839326]\n",
      "epoch:31 step:24481 [D loss: 0.414128, acc: 75.78%] [G loss: 3.802706]\n",
      "epoch:31 step:24482 [D loss: 0.810256, acc: 44.53%] [G loss: 6.459857]\n",
      "epoch:31 step:24483 [D loss: 0.601857, acc: 64.06%] [G loss: 3.136114]\n",
      "epoch:31 step:24484 [D loss: 0.392043, acc: 89.84%] [G loss: 4.639711]\n",
      "epoch:31 step:24485 [D loss: 0.201460, acc: 96.88%] [G loss: 4.231658]\n",
      "epoch:31 step:24486 [D loss: 0.509515, acc: 68.75%] [G loss: 4.996539]\n",
      "epoch:31 step:24487 [D loss: 0.636186, acc: 58.59%] [G loss: 4.938117]\n",
      "epoch:31 step:24488 [D loss: 0.332372, acc: 89.84%] [G loss: 3.108543]\n",
      "epoch:31 step:24489 [D loss: 0.283244, acc: 85.94%] [G loss: 2.923427]\n",
      "epoch:31 step:24490 [D loss: 0.314305, acc: 90.62%] [G loss: 4.220185]\n",
      "epoch:31 step:24491 [D loss: 0.107758, acc: 100.00%] [G loss: 5.447250]\n",
      "epoch:31 step:24492 [D loss: 1.048865, acc: 22.66%] [G loss: 4.025454]\n",
      "epoch:31 step:24493 [D loss: 0.229757, acc: 99.22%] [G loss: 2.528419]\n",
      "epoch:31 step:24494 [D loss: 0.305559, acc: 92.19%] [G loss: 4.268936]\n",
      "epoch:31 step:24495 [D loss: 0.201517, acc: 92.97%] [G loss: 4.059700]\n",
      "epoch:31 step:24496 [D loss: 0.486924, acc: 86.72%] [G loss: 5.865582]\n",
      "epoch:31 step:24497 [D loss: 0.147374, acc: 99.22%] [G loss: 4.000200]\n",
      "epoch:31 step:24498 [D loss: 0.432845, acc: 71.09%] [G loss: 4.761713]\n",
      "epoch:31 step:24499 [D loss: 0.542567, acc: 75.78%] [G loss: 5.967570]\n",
      "epoch:31 step:24500 [D loss: 0.277623, acc: 95.31%] [G loss: 3.329834]\n",
      "epoch:31 step:24501 [D loss: 0.390135, acc: 90.62%] [G loss: 7.580029]\n",
      "epoch:31 step:24502 [D loss: 0.428465, acc: 84.38%] [G loss: 4.276766]\n",
      "epoch:31 step:24503 [D loss: 0.338880, acc: 83.59%] [G loss: 2.936820]\n",
      "epoch:31 step:24504 [D loss: 0.490521, acc: 75.00%] [G loss: 8.243219]\n",
      "epoch:31 step:24505 [D loss: 0.475593, acc: 78.91%] [G loss: 4.201266]\n",
      "epoch:31 step:24506 [D loss: 0.353756, acc: 89.84%] [G loss: 3.236698]\n",
      "epoch:31 step:24507 [D loss: 0.203620, acc: 99.22%] [G loss: 2.600529]\n",
      "epoch:31 step:24508 [D loss: 0.878168, acc: 37.50%] [G loss: 4.666928]\n",
      "epoch:31 step:24509 [D loss: 0.682844, acc: 57.03%] [G loss: 5.307809]\n",
      "epoch:31 step:24510 [D loss: 0.153955, acc: 98.44%] [G loss: 4.466656]\n",
      "epoch:31 step:24511 [D loss: 0.540038, acc: 75.00%] [G loss: 5.044940]\n",
      "epoch:31 step:24512 [D loss: 0.247759, acc: 98.44%] [G loss: 5.565218]\n",
      "epoch:31 step:24513 [D loss: 0.120303, acc: 100.00%] [G loss: 3.044357]\n",
      "epoch:31 step:24514 [D loss: 0.928603, acc: 33.59%] [G loss: 5.350657]\n",
      "epoch:31 step:24515 [D loss: 0.347621, acc: 85.94%] [G loss: 3.673874]\n",
      "epoch:31 step:24516 [D loss: 0.211821, acc: 96.88%] [G loss: 2.984033]\n",
      "epoch:31 step:24517 [D loss: 0.545737, acc: 68.75%] [G loss: 4.214012]\n",
      "epoch:31 step:24518 [D loss: 0.649542, acc: 64.06%] [G loss: 4.592404]\n",
      "epoch:31 step:24519 [D loss: 0.242308, acc: 95.31%] [G loss: 5.852147]\n",
      "epoch:31 step:24520 [D loss: 0.296021, acc: 85.16%] [G loss: 4.706148]\n",
      "epoch:31 step:24521 [D loss: 0.195171, acc: 98.44%] [G loss: 4.880499]\n",
      "epoch:31 step:24522 [D loss: 0.273773, acc: 91.41%] [G loss: 5.309466]\n",
      "epoch:31 step:24523 [D loss: 0.690458, acc: 58.59%] [G loss: 4.441684]\n",
      "epoch:31 step:24524 [D loss: 0.178512, acc: 100.00%] [G loss: 2.546772]\n",
      "epoch:31 step:24525 [D loss: 0.187122, acc: 98.44%] [G loss: 5.103330]\n",
      "epoch:31 step:24526 [D loss: 0.213411, acc: 97.66%] [G loss: 4.126448]\n",
      "epoch:31 step:24527 [D loss: 0.091581, acc: 100.00%] [G loss: 6.466417]\n",
      "epoch:31 step:24528 [D loss: 0.357221, acc: 82.81%] [G loss: 4.278964]\n",
      "epoch:31 step:24529 [D loss: 0.054172, acc: 100.00%] [G loss: 5.311356]\n",
      "epoch:31 step:24530 [D loss: 0.366599, acc: 87.50%] [G loss: 4.036767]\n",
      "epoch:31 step:24531 [D loss: 0.841238, acc: 47.66%] [G loss: 6.102766]\n",
      "epoch:31 step:24532 [D loss: 0.251857, acc: 95.31%] [G loss: 5.214652]\n",
      "epoch:31 step:24533 [D loss: 0.503660, acc: 75.00%] [G loss: 5.903082]\n",
      "epoch:31 step:24534 [D loss: 0.220684, acc: 96.88%] [G loss: 3.467449]\n",
      "epoch:31 step:24535 [D loss: 0.352689, acc: 92.97%] [G loss: 3.481401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24536 [D loss: 0.243583, acc: 92.19%] [G loss: 6.925860]\n",
      "epoch:31 step:24537 [D loss: 0.510400, acc: 74.22%] [G loss: 5.024676]\n",
      "epoch:31 step:24538 [D loss: 0.234120, acc: 99.22%] [G loss: 3.528947]\n",
      "epoch:31 step:24539 [D loss: 1.605908, acc: 22.66%] [G loss: 3.620558]\n",
      "epoch:31 step:24540 [D loss: 0.127511, acc: 99.22%] [G loss: 5.510578]\n",
      "epoch:31 step:24541 [D loss: 0.624466, acc: 60.94%] [G loss: 3.852146]\n",
      "epoch:31 step:24542 [D loss: 0.914434, acc: 35.94%] [G loss: 6.275414]\n",
      "epoch:31 step:24543 [D loss: 0.132254, acc: 99.22%] [G loss: 4.334309]\n",
      "epoch:31 step:24544 [D loss: 0.297299, acc: 89.06%] [G loss: 4.011846]\n",
      "epoch:31 step:24545 [D loss: 0.101539, acc: 99.22%] [G loss: 5.484900]\n",
      "epoch:31 step:24546 [D loss: 0.089756, acc: 100.00%] [G loss: 5.577633]\n",
      "epoch:31 step:24547 [D loss: 0.110145, acc: 100.00%] [G loss: 5.108696]\n",
      "epoch:31 step:24548 [D loss: 0.809482, acc: 47.66%] [G loss: 7.825339]\n",
      "epoch:31 step:24549 [D loss: 0.723694, acc: 54.69%] [G loss: 4.181841]\n",
      "epoch:31 step:24550 [D loss: 0.436991, acc: 71.88%] [G loss: 5.313408]\n",
      "epoch:31 step:24551 [D loss: 0.811145, acc: 47.66%] [G loss: 5.212122]\n",
      "epoch:31 step:24552 [D loss: 0.078657, acc: 100.00%] [G loss: 5.996071]\n",
      "epoch:31 step:24553 [D loss: 1.060199, acc: 25.00%] [G loss: 3.171311]\n",
      "epoch:31 step:24554 [D loss: 0.208923, acc: 98.44%] [G loss: 2.774607]\n",
      "epoch:31 step:24555 [D loss: 0.282386, acc: 92.97%] [G loss: 3.708137]\n",
      "epoch:31 step:24556 [D loss: 0.683704, acc: 57.03%] [G loss: 4.947666]\n",
      "epoch:31 step:24557 [D loss: 0.384419, acc: 83.59%] [G loss: 4.275651]\n",
      "epoch:31 step:24558 [D loss: 0.360990, acc: 91.41%] [G loss: 3.691873]\n",
      "epoch:31 step:24559 [D loss: 0.215126, acc: 96.88%] [G loss: 2.261736]\n",
      "epoch:31 step:24560 [D loss: 0.419064, acc: 78.91%] [G loss: 5.097456]\n",
      "epoch:31 step:24561 [D loss: 0.320338, acc: 88.28%] [G loss: 3.890156]\n",
      "epoch:31 step:24562 [D loss: 0.180304, acc: 96.88%] [G loss: 3.198586]\n",
      "epoch:31 step:24563 [D loss: 0.259172, acc: 96.88%] [G loss: 6.236825]\n",
      "epoch:31 step:24564 [D loss: 0.252317, acc: 97.66%] [G loss: 2.208919]\n",
      "epoch:31 step:24565 [D loss: 0.530071, acc: 75.78%] [G loss: 4.204424]\n",
      "epoch:31 step:24566 [D loss: 0.139685, acc: 97.66%] [G loss: 5.540871]\n",
      "epoch:31 step:24567 [D loss: 0.122794, acc: 100.00%] [G loss: 4.009405]\n",
      "epoch:31 step:24568 [D loss: 0.461659, acc: 75.78%] [G loss: 5.454615]\n",
      "epoch:31 step:24569 [D loss: 0.597261, acc: 65.62%] [G loss: 6.662734]\n",
      "epoch:31 step:24570 [D loss: 0.455645, acc: 87.50%] [G loss: 3.018340]\n",
      "epoch:31 step:24571 [D loss: 0.147512, acc: 98.44%] [G loss: 3.963682]\n",
      "epoch:31 step:24572 [D loss: 0.679023, acc: 58.59%] [G loss: 4.533226]\n",
      "epoch:31 step:24573 [D loss: 0.284793, acc: 96.88%] [G loss: 4.031442]\n",
      "epoch:31 step:24574 [D loss: 0.251450, acc: 97.66%] [G loss: 4.122864]\n",
      "epoch:31 step:24575 [D loss: 0.055723, acc: 100.00%] [G loss: 3.914156]\n",
      "epoch:31 step:24576 [D loss: 0.382661, acc: 82.81%] [G loss: 4.601617]\n",
      "epoch:31 step:24577 [D loss: 0.188329, acc: 95.31%] [G loss: 4.447668]\n",
      "epoch:31 step:24578 [D loss: 0.728387, acc: 53.12%] [G loss: 2.551346]\n",
      "epoch:31 step:24579 [D loss: 0.365981, acc: 85.94%] [G loss: 6.596404]\n",
      "epoch:31 step:24580 [D loss: 0.160802, acc: 99.22%] [G loss: 3.962517]\n",
      "epoch:31 step:24581 [D loss: 0.054921, acc: 100.00%] [G loss: 2.736238]\n",
      "epoch:31 step:24582 [D loss: 0.332586, acc: 84.38%] [G loss: 4.459786]\n",
      "epoch:31 step:24583 [D loss: 0.308109, acc: 92.97%] [G loss: 3.106078]\n",
      "epoch:31 step:24584 [D loss: 1.892619, acc: 5.47%] [G loss: 5.008080]\n",
      "epoch:31 step:24585 [D loss: 0.768757, acc: 57.81%] [G loss: 5.218930]\n",
      "epoch:31 step:24586 [D loss: 1.034585, acc: 29.69%] [G loss: 6.779406]\n",
      "epoch:31 step:24587 [D loss: 0.060371, acc: 100.00%] [G loss: 4.702520]\n",
      "epoch:31 step:24588 [D loss: 0.464162, acc: 68.75%] [G loss: 4.232533]\n",
      "epoch:31 step:24589 [D loss: 0.128905, acc: 100.00%] [G loss: 4.340337]\n",
      "epoch:31 step:24590 [D loss: 0.134047, acc: 100.00%] [G loss: 7.799753]\n",
      "epoch:31 step:24591 [D loss: 0.695521, acc: 60.94%] [G loss: 4.231614]\n",
      "epoch:31 step:24592 [D loss: 0.838547, acc: 45.31%] [G loss: 5.656993]\n",
      "epoch:31 step:24593 [D loss: 0.209979, acc: 96.09%] [G loss: 5.090895]\n",
      "epoch:31 step:24594 [D loss: 1.001564, acc: 50.00%] [G loss: 5.540865]\n",
      "epoch:31 step:24595 [D loss: 0.337626, acc: 88.28%] [G loss: 3.317466]\n",
      "epoch:31 step:24596 [D loss: 0.424091, acc: 78.91%] [G loss: 4.896869]\n",
      "epoch:31 step:24597 [D loss: 0.336910, acc: 95.31%] [G loss: 4.873790]\n",
      "epoch:31 step:24598 [D loss: 0.447764, acc: 82.81%] [G loss: 5.032578]\n",
      "epoch:31 step:24599 [D loss: 0.344786, acc: 82.81%] [G loss: 6.331356]\n",
      "epoch:31 step:24600 [D loss: 0.154869, acc: 98.44%] [G loss: 3.588456]\n",
      "epoch:31 step:24601 [D loss: 0.331094, acc: 92.97%] [G loss: 4.786482]\n",
      "epoch:31 step:24602 [D loss: 0.292950, acc: 92.97%] [G loss: 2.427396]\n",
      "epoch:31 step:24603 [D loss: 0.235529, acc: 97.66%] [G loss: 5.270609]\n",
      "epoch:31 step:24604 [D loss: 0.663503, acc: 60.94%] [G loss: 3.158170]\n",
      "epoch:31 step:24605 [D loss: 0.478770, acc: 75.00%] [G loss: 3.241978]\n",
      "epoch:31 step:24606 [D loss: 0.220329, acc: 98.44%] [G loss: 2.712459]\n",
      "epoch:31 step:24607 [D loss: 1.171782, acc: 45.31%] [G loss: 3.869588]\n",
      "epoch:31 step:24608 [D loss: 1.103289, acc: 31.25%] [G loss: 5.112721]\n",
      "epoch:31 step:24609 [D loss: 0.154994, acc: 98.44%] [G loss: 4.655317]\n",
      "epoch:31 step:24610 [D loss: 0.724706, acc: 53.91%] [G loss: 3.100477]\n",
      "epoch:31 step:24611 [D loss: 0.426919, acc: 85.16%] [G loss: 6.175918]\n",
      "epoch:31 step:24612 [D loss: 0.072922, acc: 99.22%] [G loss: 3.354918]\n",
      "epoch:31 step:24613 [D loss: 0.289065, acc: 90.62%] [G loss: 4.187636]\n",
      "epoch:31 step:24614 [D loss: 0.203895, acc: 96.88%] [G loss: 4.959737]\n",
      "epoch:31 step:24615 [D loss: 0.754996, acc: 54.69%] [G loss: 5.683122]\n",
      "epoch:31 step:24616 [D loss: 0.815800, acc: 52.34%] [G loss: 3.829555]\n",
      "epoch:31 step:24617 [D loss: 0.417555, acc: 75.78%] [G loss: 3.093435]\n",
      "epoch:31 step:24618 [D loss: 0.423935, acc: 85.16%] [G loss: 3.724051]\n",
      "epoch:31 step:24619 [D loss: 0.803945, acc: 51.56%] [G loss: 5.054573]\n",
      "epoch:31 step:24620 [D loss: 1.081904, acc: 48.44%] [G loss: 6.033305]\n",
      "epoch:31 step:24621 [D loss: 0.204532, acc: 96.09%] [G loss: 3.795612]\n",
      "epoch:31 step:24622 [D loss: 0.164457, acc: 99.22%] [G loss: 5.590676]\n",
      "epoch:31 step:24623 [D loss: 0.359757, acc: 83.59%] [G loss: 4.465497]\n",
      "epoch:31 step:24624 [D loss: 0.122752, acc: 100.00%] [G loss: 3.803778]\n",
      "epoch:31 step:24625 [D loss: 0.192353, acc: 98.44%] [G loss: 4.601559]\n",
      "epoch:31 step:24626 [D loss: 0.077095, acc: 100.00%] [G loss: 5.535275]\n",
      "epoch:31 step:24627 [D loss: 0.211124, acc: 96.09%] [G loss: 6.172585]\n",
      "epoch:31 step:24628 [D loss: 0.463265, acc: 77.34%] [G loss: 5.004816]\n",
      "epoch:31 step:24629 [D loss: 0.178160, acc: 100.00%] [G loss: 6.392757]\n",
      "epoch:31 step:24630 [D loss: 0.249989, acc: 96.88%] [G loss: 5.158985]\n",
      "epoch:31 step:24631 [D loss: 0.267724, acc: 89.06%] [G loss: 3.582469]\n",
      "epoch:31 step:24632 [D loss: 0.480971, acc: 82.03%] [G loss: 3.671436]\n",
      "epoch:31 step:24633 [D loss: 0.825081, acc: 53.91%] [G loss: 4.157768]\n",
      "epoch:31 step:24634 [D loss: 0.441692, acc: 75.78%] [G loss: 3.595585]\n",
      "epoch:31 step:24635 [D loss: 0.374218, acc: 83.59%] [G loss: 5.372321]\n",
      "epoch:31 step:24636 [D loss: 0.655291, acc: 64.06%] [G loss: 3.424483]\n",
      "epoch:31 step:24637 [D loss: 0.255291, acc: 96.88%] [G loss: 3.024877]\n",
      "epoch:31 step:24638 [D loss: 0.635905, acc: 62.50%] [G loss: 3.905825]\n",
      "epoch:31 step:24639 [D loss: 0.339039, acc: 78.91%] [G loss: 5.470836]\n",
      "epoch:31 step:24640 [D loss: 0.863139, acc: 54.69%] [G loss: 2.838492]\n",
      "epoch:31 step:24641 [D loss: 0.579614, acc: 71.09%] [G loss: 4.423076]\n",
      "epoch:31 step:24642 [D loss: 0.202040, acc: 98.44%] [G loss: 4.250174]\n",
      "epoch:31 step:24643 [D loss: 1.120870, acc: 21.09%] [G loss: 4.510234]\n",
      "epoch:31 step:24644 [D loss: 0.297898, acc: 87.50%] [G loss: 5.744103]\n",
      "epoch:31 step:24645 [D loss: 0.159927, acc: 98.44%] [G loss: 8.184561]\n",
      "epoch:31 step:24646 [D loss: 0.314814, acc: 95.31%] [G loss: 4.425380]\n",
      "epoch:31 step:24647 [D loss: 0.649732, acc: 64.84%] [G loss: 4.629283]\n",
      "epoch:31 step:24648 [D loss: 0.900643, acc: 48.44%] [G loss: 5.702475]\n",
      "epoch:31 step:24649 [D loss: 0.651604, acc: 57.81%] [G loss: 6.184626]\n",
      "epoch:31 step:24650 [D loss: 0.472532, acc: 84.38%] [G loss: 3.876467]\n",
      "epoch:31 step:24651 [D loss: 0.298166, acc: 89.06%] [G loss: 3.636837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24652 [D loss: 0.270076, acc: 96.88%] [G loss: 4.510101]\n",
      "epoch:31 step:24653 [D loss: 0.193999, acc: 98.44%] [G loss: 3.588852]\n",
      "epoch:31 step:24654 [D loss: 0.301131, acc: 97.66%] [G loss: 3.982895]\n",
      "epoch:31 step:24655 [D loss: 0.280820, acc: 98.44%] [G loss: 4.240995]\n",
      "epoch:31 step:24656 [D loss: 1.026712, acc: 37.50%] [G loss: 6.362521]\n",
      "epoch:31 step:24657 [D loss: 0.633854, acc: 55.47%] [G loss: 5.646105]\n",
      "epoch:31 step:24658 [D loss: 0.232611, acc: 92.97%] [G loss: 4.559661]\n",
      "epoch:31 step:24659 [D loss: 0.776777, acc: 52.34%] [G loss: 7.488955]\n",
      "epoch:31 step:24660 [D loss: 0.521167, acc: 72.66%] [G loss: 7.000632]\n",
      "epoch:31 step:24661 [D loss: 0.174392, acc: 96.88%] [G loss: 6.826697]\n",
      "epoch:31 step:24662 [D loss: 0.170960, acc: 96.88%] [G loss: 4.310878]\n",
      "epoch:31 step:24663 [D loss: 0.142825, acc: 98.44%] [G loss: 4.539062]\n",
      "epoch:31 step:24664 [D loss: 0.150305, acc: 99.22%] [G loss: 4.875552]\n",
      "epoch:31 step:24665 [D loss: 0.178966, acc: 96.88%] [G loss: 2.825274]\n",
      "epoch:31 step:24666 [D loss: 0.755141, acc: 51.56%] [G loss: 3.899482]\n",
      "epoch:31 step:24667 [D loss: 0.432862, acc: 83.59%] [G loss: 4.736540]\n",
      "epoch:31 step:24668 [D loss: 0.406360, acc: 92.19%] [G loss: 7.408123]\n",
      "epoch:31 step:24669 [D loss: 1.178828, acc: 17.19%] [G loss: 3.525041]\n",
      "epoch:31 step:24670 [D loss: 0.138576, acc: 96.88%] [G loss: 8.022036]\n",
      "epoch:31 step:24671 [D loss: 0.370158, acc: 90.62%] [G loss: 3.965360]\n",
      "epoch:31 step:24672 [D loss: 0.087040, acc: 100.00%] [G loss: 6.354910]\n",
      "epoch:31 step:24673 [D loss: 0.099613, acc: 99.22%] [G loss: 6.000253]\n",
      "epoch:31 step:24674 [D loss: 0.161487, acc: 96.88%] [G loss: 4.782986]\n",
      "epoch:31 step:24675 [D loss: 0.261486, acc: 97.66%] [G loss: 2.555143]\n",
      "epoch:31 step:24676 [D loss: 0.493499, acc: 62.50%] [G loss: 4.061001]\n",
      "epoch:31 step:24677 [D loss: 0.439738, acc: 68.75%] [G loss: 5.510412]\n",
      "epoch:31 step:24678 [D loss: 0.518926, acc: 78.91%] [G loss: 3.261364]\n",
      "epoch:31 step:24679 [D loss: 0.214913, acc: 96.88%] [G loss: 5.977166]\n",
      "epoch:31 step:24680 [D loss: 0.801839, acc: 52.34%] [G loss: 3.896240]\n",
      "epoch:31 step:24681 [D loss: 0.222838, acc: 96.09%] [G loss: 6.026294]\n",
      "epoch:31 step:24682 [D loss: 0.082391, acc: 100.00%] [G loss: 4.611135]\n",
      "epoch:31 step:24683 [D loss: 0.219524, acc: 93.75%] [G loss: 3.875606]\n",
      "epoch:31 step:24684 [D loss: 0.285525, acc: 95.31%] [G loss: 3.861364]\n",
      "epoch:31 step:24685 [D loss: 0.422157, acc: 78.12%] [G loss: 2.946137]\n",
      "epoch:31 step:24686 [D loss: 0.414104, acc: 84.38%] [G loss: 4.930553]\n",
      "epoch:31 step:24687 [D loss: 0.530435, acc: 64.06%] [G loss: 3.539654]\n",
      "epoch:31 step:24688 [D loss: 0.435054, acc: 80.47%] [G loss: 2.768543]\n",
      "epoch:31 step:24689 [D loss: 0.124275, acc: 100.00%] [G loss: 5.390649]\n",
      "epoch:31 step:24690 [D loss: 0.426011, acc: 82.81%] [G loss: 5.158643]\n",
      "epoch:31 step:24691 [D loss: 0.264018, acc: 95.31%] [G loss: 6.424986]\n",
      "epoch:31 step:24692 [D loss: 0.991777, acc: 32.81%] [G loss: 4.013387]\n",
      "epoch:31 step:24693 [D loss: 1.199826, acc: 31.25%] [G loss: 7.009730]\n",
      "epoch:31 step:24694 [D loss: 0.441414, acc: 75.00%] [G loss: 4.777029]\n",
      "epoch:31 step:24695 [D loss: 0.744602, acc: 53.12%] [G loss: 6.698231]\n",
      "epoch:31 step:24696 [D loss: 0.393817, acc: 72.66%] [G loss: 5.098639]\n",
      "epoch:31 step:24697 [D loss: 0.846449, acc: 41.41%] [G loss: 5.316164]\n",
      "epoch:31 step:24698 [D loss: 1.011738, acc: 41.41%] [G loss: 4.428766]\n",
      "epoch:31 step:24699 [D loss: 0.067831, acc: 100.00%] [G loss: 5.515425]\n",
      "epoch:31 step:24700 [D loss: 0.615768, acc: 59.38%] [G loss: 6.088060]\n",
      "epoch:31 step:24701 [D loss: 0.532027, acc: 64.84%] [G loss: 3.185669]\n",
      "epoch:31 step:24702 [D loss: 0.242994, acc: 93.75%] [G loss: 5.172110]\n",
      "epoch:31 step:24703 [D loss: 0.230231, acc: 94.53%] [G loss: 5.923748]\n",
      "epoch:31 step:24704 [D loss: 0.483165, acc: 75.00%] [G loss: 3.901745]\n",
      "epoch:31 step:24705 [D loss: 0.229488, acc: 96.88%] [G loss: 4.084440]\n",
      "epoch:31 step:24706 [D loss: 0.331591, acc: 85.94%] [G loss: 2.104161]\n",
      "epoch:31 step:24707 [D loss: 0.494901, acc: 64.06%] [G loss: 4.424869]\n",
      "epoch:31 step:24708 [D loss: 0.147948, acc: 100.00%] [G loss: 7.557035]\n",
      "epoch:31 step:24709 [D loss: 0.097818, acc: 100.00%] [G loss: 6.090138]\n",
      "epoch:31 step:24710 [D loss: 0.445365, acc: 71.09%] [G loss: 6.060823]\n",
      "epoch:31 step:24711 [D loss: 0.836648, acc: 49.22%] [G loss: 4.225847]\n",
      "epoch:31 step:24712 [D loss: 0.140040, acc: 99.22%] [G loss: 4.760718]\n",
      "epoch:31 step:24713 [D loss: 0.102506, acc: 100.00%] [G loss: 4.359321]\n",
      "epoch:31 step:24714 [D loss: 0.473592, acc: 77.34%] [G loss: 4.423337]\n",
      "epoch:31 step:24715 [D loss: 0.627589, acc: 66.41%] [G loss: 4.448806]\n",
      "epoch:31 step:24716 [D loss: 0.860678, acc: 40.62%] [G loss: 6.161755]\n",
      "epoch:31 step:24717 [D loss: 0.472459, acc: 67.97%] [G loss: 2.264908]\n",
      "epoch:31 step:24718 [D loss: 0.310555, acc: 93.75%] [G loss: 6.727050]\n",
      "epoch:31 step:24719 [D loss: 0.556329, acc: 71.09%] [G loss: 5.631968]\n",
      "epoch:31 step:24720 [D loss: 0.450838, acc: 82.03%] [G loss: 3.470801]\n",
      "epoch:31 step:24721 [D loss: 0.380412, acc: 78.12%] [G loss: 4.907876]\n",
      "epoch:31 step:24722 [D loss: 0.194748, acc: 95.31%] [G loss: 7.658800]\n",
      "epoch:31 step:24723 [D loss: 0.428572, acc: 83.59%] [G loss: 4.980641]\n",
      "epoch:31 step:24724 [D loss: 0.831891, acc: 50.78%] [G loss: 5.813707]\n",
      "epoch:31 step:24725 [D loss: 0.231728, acc: 95.31%] [G loss: 3.760098]\n",
      "epoch:31 step:24726 [D loss: 0.286937, acc: 89.84%] [G loss: 3.973787]\n",
      "epoch:31 step:24727 [D loss: 0.611467, acc: 60.94%] [G loss: 4.853070]\n",
      "epoch:31 step:24728 [D loss: 0.043032, acc: 100.00%] [G loss: 8.578815]\n",
      "epoch:31 step:24729 [D loss: 0.457250, acc: 65.62%] [G loss: 6.489731]\n",
      "epoch:31 step:24730 [D loss: 0.750230, acc: 53.12%] [G loss: 6.360502]\n",
      "epoch:31 step:24731 [D loss: 0.378206, acc: 78.91%] [G loss: 4.635918]\n",
      "epoch:31 step:24732 [D loss: 0.063306, acc: 100.00%] [G loss: 4.279053]\n",
      "epoch:31 step:24733 [D loss: 0.234537, acc: 99.22%] [G loss: 3.540954]\n",
      "epoch:31 step:24734 [D loss: 0.266149, acc: 96.09%] [G loss: 5.187006]\n",
      "epoch:31 step:24735 [D loss: 0.402355, acc: 77.34%] [G loss: 2.982166]\n",
      "epoch:31 step:24736 [D loss: 0.791123, acc: 50.00%] [G loss: 6.254444]\n",
      "epoch:31 step:24737 [D loss: 0.737974, acc: 53.91%] [G loss: 5.253433]\n",
      "epoch:31 step:24738 [D loss: 0.111901, acc: 100.00%] [G loss: 7.116118]\n",
      "epoch:31 step:24739 [D loss: 0.158741, acc: 99.22%] [G loss: 4.892056]\n",
      "epoch:31 step:24740 [D loss: 1.161425, acc: 35.94%] [G loss: 4.065942]\n",
      "epoch:31 step:24741 [D loss: 0.645799, acc: 54.69%] [G loss: 5.236366]\n",
      "epoch:31 step:24742 [D loss: 0.306289, acc: 88.28%] [G loss: 4.885612]\n",
      "epoch:31 step:24743 [D loss: 0.237886, acc: 96.88%] [G loss: 5.577006]\n",
      "epoch:31 step:24744 [D loss: 0.728921, acc: 56.25%] [G loss: 4.521648]\n",
      "epoch:31 step:24745 [D loss: 0.453728, acc: 83.59%] [G loss: 3.802074]\n",
      "epoch:31 step:24746 [D loss: 0.657373, acc: 64.84%] [G loss: 3.000146]\n",
      "epoch:31 step:24747 [D loss: 0.146414, acc: 99.22%] [G loss: 6.094452]\n",
      "epoch:31 step:24748 [D loss: 0.112958, acc: 100.00%] [G loss: 4.855579]\n",
      "epoch:31 step:24749 [D loss: 0.223597, acc: 94.53%] [G loss: 4.253968]\n",
      "epoch:31 step:24750 [D loss: 0.501379, acc: 70.31%] [G loss: 5.074511]\n",
      "epoch:31 step:24751 [D loss: 1.168227, acc: 31.25%] [G loss: 5.412266]\n",
      "epoch:31 step:24752 [D loss: 0.192939, acc: 96.09%] [G loss: 3.669143]\n",
      "epoch:31 step:24753 [D loss: 0.293290, acc: 90.62%] [G loss: 5.905252]\n",
      "epoch:31 step:24754 [D loss: 0.138348, acc: 99.22%] [G loss: 6.961470]\n",
      "epoch:31 step:24755 [D loss: 0.276605, acc: 94.53%] [G loss: 5.069042]\n",
      "epoch:31 step:24756 [D loss: 0.942385, acc: 50.00%] [G loss: 4.319549]\n",
      "epoch:31 step:24757 [D loss: 0.105179, acc: 99.22%] [G loss: 4.629398]\n",
      "epoch:31 step:24758 [D loss: 0.464274, acc: 67.19%] [G loss: 6.654186]\n",
      "epoch:31 step:24759 [D loss: 0.330314, acc: 84.38%] [G loss: 5.765522]\n",
      "epoch:31 step:24760 [D loss: 0.155470, acc: 96.88%] [G loss: 3.564467]\n",
      "epoch:31 step:24761 [D loss: 0.500036, acc: 67.19%] [G loss: 5.854592]\n",
      "epoch:31 step:24762 [D loss: 0.856638, acc: 53.91%] [G loss: 4.182588]\n",
      "epoch:31 step:24763 [D loss: 1.249943, acc: 42.97%] [G loss: 4.625072]\n",
      "epoch:31 step:24764 [D loss: 0.655234, acc: 60.16%] [G loss: 1.973475]\n",
      "epoch:31 step:24765 [D loss: 0.650009, acc: 58.59%] [G loss: 4.502193]\n",
      "epoch:31 step:24766 [D loss: 0.050038, acc: 100.00%] [G loss: 5.667761]\n",
      "epoch:31 step:24767 [D loss: 0.764220, acc: 55.47%] [G loss: 6.218234]\n",
      "epoch:31 step:24768 [D loss: 0.579066, acc: 58.59%] [G loss: 2.253118]\n",
      "epoch:31 step:24769 [D loss: 0.082247, acc: 100.00%] [G loss: 5.468776]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24770 [D loss: 0.154062, acc: 99.22%] [G loss: 4.363508]\n",
      "epoch:31 step:24771 [D loss: 0.059688, acc: 100.00%] [G loss: 5.044233]\n",
      "epoch:31 step:24772 [D loss: 0.186741, acc: 96.88%] [G loss: 6.288932]\n",
      "epoch:31 step:24773 [D loss: 0.273886, acc: 92.97%] [G loss: 4.343576]\n",
      "epoch:31 step:24774 [D loss: 0.255741, acc: 92.19%] [G loss: 6.332970]\n",
      "epoch:31 step:24775 [D loss: 0.035800, acc: 100.00%] [G loss: 4.289293]\n",
      "epoch:31 step:24776 [D loss: 0.383143, acc: 89.84%] [G loss: 4.469623]\n",
      "epoch:31 step:24777 [D loss: 0.265663, acc: 97.66%] [G loss: 3.953696]\n",
      "epoch:31 step:24778 [D loss: 0.701020, acc: 57.81%] [G loss: 4.771639]\n",
      "epoch:31 step:24779 [D loss: 0.491720, acc: 69.53%] [G loss: 5.448846]\n",
      "epoch:31 step:24780 [D loss: 0.651023, acc: 53.91%] [G loss: 2.806111]\n",
      "epoch:31 step:24781 [D loss: 0.142123, acc: 98.44%] [G loss: 4.781566]\n",
      "epoch:31 step:24782 [D loss: 0.559393, acc: 75.00%] [G loss: 5.961360]\n",
      "epoch:31 step:24783 [D loss: 0.230585, acc: 96.09%] [G loss: 6.049953]\n",
      "epoch:31 step:24784 [D loss: 0.108169, acc: 100.00%] [G loss: 7.485378]\n",
      "epoch:31 step:24785 [D loss: 1.146484, acc: 18.75%] [G loss: 4.719336]\n",
      "epoch:31 step:24786 [D loss: 0.334951, acc: 92.97%] [G loss: 3.956119]\n",
      "epoch:31 step:24787 [D loss: 0.351172, acc: 88.28%] [G loss: 4.175493]\n",
      "epoch:31 step:24788 [D loss: 0.653850, acc: 56.25%] [G loss: 5.663613]\n",
      "epoch:31 step:24789 [D loss: 0.172836, acc: 98.44%] [G loss: 4.593022]\n",
      "epoch:31 step:24790 [D loss: 0.363371, acc: 89.84%] [G loss: 3.082160]\n",
      "epoch:31 step:24791 [D loss: 0.406643, acc: 79.69%] [G loss: 4.406569]\n",
      "epoch:31 step:24792 [D loss: 0.252551, acc: 98.44%] [G loss: 4.055413]\n",
      "epoch:31 step:24793 [D loss: 0.256333, acc: 91.41%] [G loss: 4.564780]\n",
      "epoch:31 step:24794 [D loss: 0.426929, acc: 84.38%] [G loss: 3.417789]\n",
      "epoch:31 step:24795 [D loss: 0.425074, acc: 74.22%] [G loss: 4.841191]\n",
      "epoch:31 step:24796 [D loss: 1.158716, acc: 26.56%] [G loss: 6.365069]\n",
      "epoch:31 step:24797 [D loss: 0.072217, acc: 100.00%] [G loss: 2.959098]\n",
      "epoch:31 step:24798 [D loss: 0.291032, acc: 90.62%] [G loss: 4.881548]\n",
      "epoch:31 step:24799 [D loss: 0.203218, acc: 99.22%] [G loss: 3.768876]\n",
      "epoch:31 step:24800 [D loss: 0.556448, acc: 67.19%] [G loss: 6.835529]\n",
      "epoch:31 step:24801 [D loss: 0.139940, acc: 100.00%] [G loss: 3.733949]\n",
      "epoch:31 step:24802 [D loss: 0.463058, acc: 88.28%] [G loss: 4.817698]\n",
      "epoch:31 step:24803 [D loss: 0.394493, acc: 86.72%] [G loss: 4.923986]\n",
      "epoch:31 step:24804 [D loss: 0.057646, acc: 100.00%] [G loss: 4.931719]\n",
      "epoch:31 step:24805 [D loss: 0.785626, acc: 50.78%] [G loss: 2.394606]\n",
      "epoch:31 step:24806 [D loss: 0.371576, acc: 84.38%] [G loss: 3.505404]\n",
      "epoch:31 step:24807 [D loss: 0.269076, acc: 96.88%] [G loss: 5.043181]\n",
      "epoch:31 step:24808 [D loss: 0.197222, acc: 98.44%] [G loss: 5.441491]\n",
      "epoch:31 step:24809 [D loss: 0.166783, acc: 98.44%] [G loss: 3.007585]\n",
      "epoch:31 step:24810 [D loss: 0.439768, acc: 79.69%] [G loss: 4.927873]\n",
      "epoch:31 step:24811 [D loss: 0.236317, acc: 96.09%] [G loss: 4.938498]\n",
      "epoch:31 step:24812 [D loss: 0.446251, acc: 68.75%] [G loss: 4.755497]\n",
      "epoch:31 step:24813 [D loss: 1.107185, acc: 28.12%] [G loss: 2.581389]\n",
      "epoch:31 step:24814 [D loss: 1.358482, acc: 42.97%] [G loss: 5.245908]\n",
      "epoch:31 step:24815 [D loss: 0.303564, acc: 93.75%] [G loss: 4.277843]\n",
      "epoch:31 step:24816 [D loss: 0.157960, acc: 100.00%] [G loss: 2.989257]\n",
      "epoch:31 step:24817 [D loss: 0.778887, acc: 50.78%] [G loss: 3.301708]\n",
      "epoch:31 step:24818 [D loss: 0.364099, acc: 80.47%] [G loss: 5.046954]\n",
      "epoch:31 step:24819 [D loss: 0.141601, acc: 100.00%] [G loss: 4.786294]\n",
      "epoch:31 step:24820 [D loss: 0.316625, acc: 86.72%] [G loss: 3.341375]\n",
      "epoch:31 step:24821 [D loss: 0.290176, acc: 95.31%] [G loss: 4.211095]\n",
      "epoch:31 step:24822 [D loss: 0.890217, acc: 40.62%] [G loss: 4.424112]\n",
      "epoch:31 step:24823 [D loss: 0.522352, acc: 76.56%] [G loss: 4.197978]\n",
      "epoch:31 step:24824 [D loss: 0.207693, acc: 95.31%] [G loss: 5.398459]\n",
      "epoch:31 step:24825 [D loss: 0.326611, acc: 87.50%] [G loss: 4.032141]\n",
      "epoch:31 step:24826 [D loss: 0.095704, acc: 100.00%] [G loss: 5.528575]\n",
      "epoch:31 step:24827 [D loss: 0.232250, acc: 97.66%] [G loss: 4.767616]\n",
      "epoch:31 step:24828 [D loss: 0.502208, acc: 73.44%] [G loss: 3.660422]\n",
      "epoch:31 step:24829 [D loss: 1.212626, acc: 49.22%] [G loss: 4.094607]\n",
      "epoch:31 step:24830 [D loss: 0.390445, acc: 82.03%] [G loss: 4.200262]\n",
      "epoch:31 step:24831 [D loss: 0.387339, acc: 78.12%] [G loss: 3.729130]\n",
      "epoch:31 step:24832 [D loss: 0.296046, acc: 93.75%] [G loss: 2.837647]\n",
      "epoch:31 step:24833 [D loss: 0.763241, acc: 56.25%] [G loss: 6.089882]\n",
      "epoch:31 step:24834 [D loss: 0.092347, acc: 100.00%] [G loss: 3.756955]\n",
      "epoch:31 step:24835 [D loss: 0.455065, acc: 75.78%] [G loss: 4.407308]\n",
      "epoch:31 step:24836 [D loss: 0.674813, acc: 53.91%] [G loss: 5.818805]\n",
      "epoch:31 step:24837 [D loss: 0.382509, acc: 82.81%] [G loss: 3.846797]\n",
      "epoch:31 step:24838 [D loss: 0.175385, acc: 98.44%] [G loss: 4.257084]\n",
      "epoch:31 step:24839 [D loss: 0.486016, acc: 67.97%] [G loss: 2.606635]\n",
      "epoch:31 step:24840 [D loss: 0.078165, acc: 100.00%] [G loss: 4.940559]\n",
      "epoch:31 step:24841 [D loss: 0.126710, acc: 99.22%] [G loss: 5.532249]\n",
      "epoch:31 step:24842 [D loss: 0.574736, acc: 66.41%] [G loss: 4.055264]\n",
      "epoch:31 step:24843 [D loss: 0.437285, acc: 68.75%] [G loss: 10.409506]\n",
      "epoch:31 step:24844 [D loss: 0.336810, acc: 85.94%] [G loss: 4.452228]\n",
      "epoch:31 step:24845 [D loss: 0.943879, acc: 34.38%] [G loss: 2.067638]\n",
      "epoch:31 step:24846 [D loss: 0.978944, acc: 27.34%] [G loss: 5.294720]\n",
      "epoch:31 step:24847 [D loss: 0.783476, acc: 53.12%] [G loss: 5.818029]\n",
      "epoch:31 step:24848 [D loss: 1.163004, acc: 47.66%] [G loss: 5.753654]\n",
      "epoch:31 step:24849 [D loss: 0.130847, acc: 97.66%] [G loss: 3.744266]\n",
      "epoch:31 step:24850 [D loss: 0.427683, acc: 78.91%] [G loss: 5.544422]\n",
      "epoch:31 step:24851 [D loss: 0.221170, acc: 98.44%] [G loss: 4.501760]\n",
      "epoch:31 step:24852 [D loss: 0.183359, acc: 100.00%] [G loss: 4.817092]\n",
      "epoch:31 step:24853 [D loss: 0.585379, acc: 69.53%] [G loss: 4.035013]\n",
      "epoch:31 step:24854 [D loss: 0.370664, acc: 79.69%] [G loss: 3.708312]\n",
      "epoch:31 step:24855 [D loss: 0.093789, acc: 100.00%] [G loss: 4.912814]\n",
      "epoch:31 step:24856 [D loss: 0.771716, acc: 51.56%] [G loss: 4.448239]\n",
      "epoch:31 step:24857 [D loss: 0.092230, acc: 100.00%] [G loss: 5.743266]\n",
      "epoch:31 step:24858 [D loss: 0.910691, acc: 50.00%] [G loss: 7.037465]\n",
      "epoch:31 step:24859 [D loss: 0.284608, acc: 92.97%] [G loss: 3.930617]\n",
      "epoch:31 step:24860 [D loss: 0.452674, acc: 83.59%] [G loss: 3.574655]\n",
      "epoch:31 step:24861 [D loss: 0.116347, acc: 100.00%] [G loss: 5.829162]\n",
      "epoch:31 step:24862 [D loss: 0.386146, acc: 85.16%] [G loss: 4.837978]\n",
      "epoch:31 step:24863 [D loss: 0.222146, acc: 96.09%] [G loss: 5.996772]\n",
      "epoch:31 step:24864 [D loss: 0.605007, acc: 61.72%] [G loss: 4.523843]\n",
      "epoch:31 step:24865 [D loss: 0.753846, acc: 51.56%] [G loss: 7.136123]\n",
      "epoch:31 step:24866 [D loss: 0.045505, acc: 100.00%] [G loss: 4.169755]\n",
      "epoch:31 step:24867 [D loss: 0.414523, acc: 78.91%] [G loss: 3.779593]\n",
      "epoch:31 step:24868 [D loss: 0.751863, acc: 50.78%] [G loss: 3.079533]\n",
      "epoch:31 step:24869 [D loss: 0.629780, acc: 64.84%] [G loss: 4.220037]\n",
      "epoch:31 step:24870 [D loss: 0.217604, acc: 93.75%] [G loss: 4.020852]\n",
      "epoch:31 step:24871 [D loss: 0.107637, acc: 99.22%] [G loss: 6.336250]\n",
      "epoch:31 step:24872 [D loss: 0.269820, acc: 94.53%] [G loss: 4.775297]\n",
      "epoch:31 step:24873 [D loss: 0.189855, acc: 97.66%] [G loss: 4.573167]\n",
      "epoch:31 step:24874 [D loss: 0.257708, acc: 90.62%] [G loss: 6.424301]\n",
      "epoch:31 step:24875 [D loss: 0.197429, acc: 99.22%] [G loss: 3.073705]\n",
      "epoch:31 step:24876 [D loss: 0.331334, acc: 91.41%] [G loss: 3.428596]\n",
      "epoch:31 step:24877 [D loss: 1.040395, acc: 49.22%] [G loss: 4.713464]\n",
      "epoch:31 step:24878 [D loss: 0.138667, acc: 99.22%] [G loss: 5.421145]\n",
      "epoch:31 step:24879 [D loss: 0.464339, acc: 77.34%] [G loss: 3.791184]\n",
      "epoch:31 step:24880 [D loss: 0.569358, acc: 68.75%] [G loss: 2.883038]\n",
      "epoch:31 step:24881 [D loss: 0.344217, acc: 83.59%] [G loss: 3.208767]\n",
      "epoch:31 step:24882 [D loss: 0.352278, acc: 89.06%] [G loss: 4.341018]\n",
      "epoch:31 step:24883 [D loss: 0.322421, acc: 83.59%] [G loss: 4.656090]\n",
      "epoch:31 step:24884 [D loss: 0.541429, acc: 78.12%] [G loss: 4.857101]\n",
      "epoch:31 step:24885 [D loss: 0.305177, acc: 96.09%] [G loss: 4.348218]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24886 [D loss: 0.271024, acc: 96.88%] [G loss: 3.660622]\n",
      "epoch:31 step:24887 [D loss: 0.415824, acc: 78.12%] [G loss: 6.565879]\n",
      "epoch:31 step:24888 [D loss: 0.295953, acc: 93.75%] [G loss: 4.407485]\n",
      "epoch:31 step:24889 [D loss: 0.423750, acc: 85.16%] [G loss: 4.061361]\n",
      "epoch:31 step:24890 [D loss: 0.157258, acc: 99.22%] [G loss: 5.730907]\n",
      "epoch:31 step:24891 [D loss: 0.067251, acc: 100.00%] [G loss: 4.148912]\n",
      "epoch:31 step:24892 [D loss: 0.168488, acc: 100.00%] [G loss: 6.477795]\n",
      "epoch:31 step:24893 [D loss: 0.278101, acc: 94.53%] [G loss: 7.116577]\n",
      "epoch:31 step:24894 [D loss: 0.181001, acc: 97.66%] [G loss: 3.953015]\n",
      "epoch:31 step:24895 [D loss: 1.958832, acc: 35.16%] [G loss: 3.740628]\n",
      "epoch:31 step:24896 [D loss: 0.383399, acc: 90.62%] [G loss: 3.478121]\n",
      "epoch:31 step:24897 [D loss: 1.104781, acc: 28.12%] [G loss: 4.928776]\n",
      "epoch:31 step:24898 [D loss: 0.286445, acc: 97.66%] [G loss: 4.508345]\n",
      "epoch:31 step:24899 [D loss: 1.343479, acc: 14.84%] [G loss: 4.194807]\n",
      "epoch:31 step:24900 [D loss: 0.383281, acc: 90.62%] [G loss: 3.087034]\n",
      "epoch:31 step:24901 [D loss: 0.105993, acc: 100.00%] [G loss: 5.242324]\n",
      "epoch:31 step:24902 [D loss: 0.298941, acc: 92.97%] [G loss: 4.797408]\n",
      "epoch:31 step:24903 [D loss: 1.010427, acc: 47.66%] [G loss: 4.740253]\n",
      "epoch:31 step:24904 [D loss: 0.696732, acc: 53.12%] [G loss: 4.374445]\n",
      "epoch:31 step:24905 [D loss: 0.394079, acc: 82.03%] [G loss: 2.443841]\n",
      "epoch:31 step:24906 [D loss: 0.131896, acc: 100.00%] [G loss: 5.552542]\n",
      "epoch:31 step:24907 [D loss: 0.331066, acc: 92.19%] [G loss: 5.499035]\n",
      "epoch:31 step:24908 [D loss: 0.237054, acc: 91.41%] [G loss: 4.213553]\n",
      "epoch:31 step:24909 [D loss: 0.260045, acc: 97.66%] [G loss: 5.435361]\n",
      "epoch:31 step:24910 [D loss: 0.370260, acc: 77.34%] [G loss: 6.329189]\n",
      "epoch:31 step:24911 [D loss: 0.425058, acc: 78.91%] [G loss: 5.607898]\n",
      "epoch:31 step:24912 [D loss: 0.242156, acc: 90.62%] [G loss: 4.105218]\n",
      "epoch:31 step:24913 [D loss: 0.330104, acc: 82.81%] [G loss: 5.161530]\n",
      "epoch:31 step:24914 [D loss: 0.338574, acc: 79.69%] [G loss: 4.086898]\n",
      "epoch:31 step:24915 [D loss: 0.239630, acc: 98.44%] [G loss: 3.275055]\n",
      "epoch:31 step:24916 [D loss: 0.762607, acc: 51.56%] [G loss: 6.419205]\n",
      "epoch:31 step:24917 [D loss: 0.374847, acc: 88.28%] [G loss: 5.138318]\n",
      "epoch:31 step:24918 [D loss: 0.394766, acc: 92.19%] [G loss: 3.428566]\n",
      "epoch:31 step:24919 [D loss: 0.375475, acc: 89.06%] [G loss: 5.535946]\n",
      "epoch:31 step:24920 [D loss: 0.260857, acc: 90.62%] [G loss: 5.126770]\n",
      "epoch:31 step:24921 [D loss: 1.513982, acc: 39.06%] [G loss: 5.305307]\n",
      "epoch:31 step:24922 [D loss: 0.125400, acc: 98.44%] [G loss: 3.387347]\n",
      "epoch:31 step:24923 [D loss: 0.428121, acc: 76.56%] [G loss: 6.028882]\n",
      "epoch:31 step:24924 [D loss: 0.800311, acc: 53.12%] [G loss: 3.775887]\n",
      "epoch:31 step:24925 [D loss: 0.815875, acc: 46.88%] [G loss: 2.482810]\n",
      "epoch:31 step:24926 [D loss: 0.125447, acc: 100.00%] [G loss: 4.199194]\n",
      "epoch:31 step:24927 [D loss: 0.065057, acc: 100.00%] [G loss: 1.945036]\n",
      "epoch:31 step:24928 [D loss: 0.645745, acc: 56.25%] [G loss: 3.924341]\n",
      "epoch:31 step:24929 [D loss: 0.301106, acc: 94.53%] [G loss: 3.439915]\n",
      "epoch:31 step:24930 [D loss: 0.122783, acc: 98.44%] [G loss: 3.695986]\n",
      "epoch:31 step:24931 [D loss: 0.843460, acc: 51.56%] [G loss: 4.988491]\n",
      "epoch:31 step:24932 [D loss: 0.612976, acc: 56.25%] [G loss: 3.142455]\n",
      "epoch:31 step:24933 [D loss: 0.205662, acc: 100.00%] [G loss: 3.854459]\n",
      "epoch:31 step:24934 [D loss: 0.188723, acc: 100.00%] [G loss: 6.014234]\n",
      "epoch:31 step:24935 [D loss: 0.414232, acc: 78.91%] [G loss: 4.400000]\n",
      "epoch:31 step:24936 [D loss: 0.185108, acc: 99.22%] [G loss: 4.929512]\n",
      "epoch:31 step:24937 [D loss: 0.055057, acc: 100.00%] [G loss: 7.055037]\n",
      "epoch:31 step:24938 [D loss: 0.892854, acc: 42.19%] [G loss: 5.148374]\n",
      "epoch:31 step:24939 [D loss: 0.244056, acc: 93.75%] [G loss: 5.668302]\n",
      "epoch:31 step:24940 [D loss: 0.656956, acc: 64.84%] [G loss: 4.607360]\n",
      "epoch:31 step:24941 [D loss: 1.122139, acc: 27.34%] [G loss: 5.468501]\n",
      "epoch:31 step:24942 [D loss: 1.357770, acc: 9.38%] [G loss: 5.223734]\n",
      "epoch:31 step:24943 [D loss: 0.176637, acc: 100.00%] [G loss: 4.475773]\n",
      "epoch:31 step:24944 [D loss: 0.183686, acc: 97.66%] [G loss: 2.466586]\n",
      "epoch:31 step:24945 [D loss: 1.170515, acc: 23.44%] [G loss: 5.422832]\n",
      "epoch:31 step:24946 [D loss: 0.276124, acc: 90.62%] [G loss: 2.977116]\n",
      "epoch:31 step:24947 [D loss: 0.064397, acc: 100.00%] [G loss: 6.729497]\n",
      "epoch:31 step:24948 [D loss: 0.538287, acc: 62.50%] [G loss: 6.310807]\n",
      "epoch:31 step:24949 [D loss: 0.168442, acc: 98.44%] [G loss: 4.929243]\n",
      "epoch:31 step:24950 [D loss: 0.133365, acc: 99.22%] [G loss: 2.636739]\n",
      "epoch:31 step:24951 [D loss: 0.107036, acc: 98.44%] [G loss: 5.558484]\n",
      "epoch:31 step:24952 [D loss: 0.188178, acc: 98.44%] [G loss: 5.382992]\n",
      "epoch:31 step:24953 [D loss: 0.362154, acc: 86.72%] [G loss: 4.729918]\n",
      "epoch:31 step:24954 [D loss: 0.211066, acc: 92.97%] [G loss: 3.417472]\n",
      "epoch:31 step:24955 [D loss: 0.868496, acc: 50.78%] [G loss: 4.252058]\n",
      "epoch:31 step:24956 [D loss: 0.105043, acc: 99.22%] [G loss: 3.576879]\n",
      "epoch:31 step:24957 [D loss: 0.170580, acc: 96.09%] [G loss: 4.399627]\n",
      "epoch:31 step:24958 [D loss: 0.545481, acc: 71.09%] [G loss: 4.100032]\n",
      "epoch:31 step:24959 [D loss: 0.079728, acc: 99.22%] [G loss: 3.631168]\n",
      "epoch:31 step:24960 [D loss: 0.218101, acc: 99.22%] [G loss: 4.370250]\n",
      "epoch:31 step:24961 [D loss: 0.324362, acc: 81.25%] [G loss: 6.542325]\n",
      "epoch:31 step:24962 [D loss: 0.981344, acc: 46.09%] [G loss: 4.060782]\n",
      "epoch:31 step:24963 [D loss: 0.599847, acc: 57.81%] [G loss: 6.338135]\n",
      "epoch:31 step:24964 [D loss: 0.449949, acc: 70.31%] [G loss: 4.270692]\n",
      "epoch:31 step:24965 [D loss: 0.435440, acc: 85.16%] [G loss: 3.414401]\n",
      "epoch:31 step:24966 [D loss: 0.235880, acc: 93.75%] [G loss: 2.990771]\n",
      "epoch:31 step:24967 [D loss: 0.680266, acc: 60.16%] [G loss: 4.676425]\n",
      "epoch:31 step:24968 [D loss: 0.297242, acc: 91.41%] [G loss: 3.532824]\n",
      "epoch:31 step:24969 [D loss: 0.321454, acc: 92.97%] [G loss: 4.715368]\n",
      "epoch:31 step:24970 [D loss: 0.462763, acc: 72.66%] [G loss: 4.296018]\n",
      "epoch:31 step:24971 [D loss: 0.065093, acc: 100.00%] [G loss: 6.573333]\n",
      "epoch:31 step:24972 [D loss: 1.894794, acc: 42.19%] [G loss: 3.525350]\n",
      "epoch:31 step:24973 [D loss: 0.553230, acc: 70.31%] [G loss: 1.826815]\n",
      "epoch:31 step:24974 [D loss: 0.115545, acc: 99.22%] [G loss: 4.354577]\n",
      "epoch:31 step:24975 [D loss: 0.353344, acc: 88.28%] [G loss: 3.549362]\n",
      "epoch:31 step:24976 [D loss: 0.875143, acc: 50.00%] [G loss: 4.063822]\n",
      "epoch:31 step:24977 [D loss: 0.577486, acc: 59.38%] [G loss: 5.776641]\n",
      "epoch:31 step:24978 [D loss: 0.084688, acc: 100.00%] [G loss: 6.107510]\n",
      "epoch:31 step:24979 [D loss: 0.107953, acc: 98.44%] [G loss: 4.747013]\n",
      "epoch:31 step:24980 [D loss: 0.676906, acc: 62.50%] [G loss: 6.069309]\n",
      "epoch:31 step:24981 [D loss: 0.116646, acc: 97.66%] [G loss: 3.913336]\n",
      "epoch:31 step:24982 [D loss: 0.200178, acc: 96.88%] [G loss: 4.015521]\n",
      "epoch:31 step:24983 [D loss: 0.273739, acc: 90.62%] [G loss: 5.280090]\n",
      "epoch:31 step:24984 [D loss: 0.032464, acc: 100.00%] [G loss: 7.654248]\n",
      "epoch:31 step:24985 [D loss: 0.096685, acc: 100.00%] [G loss: 5.386855]\n",
      "epoch:31 step:24986 [D loss: 0.791479, acc: 50.78%] [G loss: 4.764741]\n",
      "epoch:31 step:24987 [D loss: 0.062411, acc: 100.00%] [G loss: 5.314562]\n",
      "epoch:31 step:24988 [D loss: 0.330421, acc: 96.09%] [G loss: 3.300007]\n",
      "epoch:31 step:24989 [D loss: 0.141817, acc: 99.22%] [G loss: 5.624490]\n",
      "epoch:31 step:24990 [D loss: 0.828497, acc: 53.12%] [G loss: 4.616224]\n",
      "epoch:31 step:24991 [D loss: 0.329852, acc: 89.84%] [G loss: 4.987035]\n",
      "epoch:31 step:24992 [D loss: 0.407337, acc: 75.00%] [G loss: 4.790853]\n",
      "epoch:32 step:24993 [D loss: 0.080735, acc: 99.22%] [G loss: 4.703342]\n",
      "epoch:32 step:24994 [D loss: 0.234538, acc: 96.09%] [G loss: 3.035373]\n",
      "epoch:32 step:24995 [D loss: 0.270970, acc: 85.94%] [G loss: 4.944389]\n",
      "epoch:32 step:24996 [D loss: 0.849293, acc: 53.12%] [G loss: 2.861411]\n",
      "epoch:32 step:24997 [D loss: 0.190215, acc: 97.66%] [G loss: 4.486265]\n",
      "epoch:32 step:24998 [D loss: 0.094720, acc: 98.44%] [G loss: 6.383836]\n",
      "epoch:32 step:24999 [D loss: 0.718231, acc: 56.25%] [G loss: 6.351878]\n",
      "epoch:32 step:25000 [D loss: 1.380834, acc: 39.84%] [G loss: 6.778053]\n",
      "epoch:32 step:25001 [D loss: 0.389451, acc: 82.03%] [G loss: 4.873877]\n",
      "epoch:32 step:25002 [D loss: 0.115374, acc: 99.22%] [G loss: 4.373179]\n",
      "epoch:32 step:25003 [D loss: 0.194118, acc: 96.88%] [G loss: 4.415850]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25004 [D loss: 0.806894, acc: 53.91%] [G loss: 4.786690]\n",
      "epoch:32 step:25005 [D loss: 0.242016, acc: 96.88%] [G loss: 3.498653]\n",
      "epoch:32 step:25006 [D loss: 1.011823, acc: 30.47%] [G loss: 7.103398]\n",
      "epoch:32 step:25007 [D loss: 0.264092, acc: 96.09%] [G loss: 3.481828]\n",
      "epoch:32 step:25008 [D loss: 0.530576, acc: 71.88%] [G loss: 2.760889]\n",
      "epoch:32 step:25009 [D loss: 0.540131, acc: 66.41%] [G loss: 4.241742]\n",
      "epoch:32 step:25010 [D loss: 0.491277, acc: 73.44%] [G loss: 6.679101]\n",
      "epoch:32 step:25011 [D loss: 0.664299, acc: 61.72%] [G loss: 6.224221]\n",
      "epoch:32 step:25012 [D loss: 0.322222, acc: 95.31%] [G loss: 6.843767]\n",
      "epoch:32 step:25013 [D loss: 0.320971, acc: 84.38%] [G loss: 4.644408]\n",
      "epoch:32 step:25014 [D loss: 1.016319, acc: 47.66%] [G loss: 4.265454]\n",
      "epoch:32 step:25015 [D loss: 0.546957, acc: 64.84%] [G loss: 6.225347]\n",
      "epoch:32 step:25016 [D loss: 1.090384, acc: 25.78%] [G loss: 5.303731]\n",
      "epoch:32 step:25017 [D loss: 0.668938, acc: 61.72%] [G loss: 7.225748]\n",
      "epoch:32 step:25018 [D loss: 0.276994, acc: 87.50%] [G loss: 3.760546]\n",
      "epoch:32 step:25019 [D loss: 0.162447, acc: 95.31%] [G loss: 2.514886]\n",
      "epoch:32 step:25020 [D loss: 0.643872, acc: 61.72%] [G loss: 4.015595]\n",
      "epoch:32 step:25021 [D loss: 0.150323, acc: 98.44%] [G loss: 3.437289]\n",
      "epoch:32 step:25022 [D loss: 0.206805, acc: 96.09%] [G loss: 4.993550]\n",
      "epoch:32 step:25023 [D loss: 0.924337, acc: 32.81%] [G loss: 3.620502]\n",
      "epoch:32 step:25024 [D loss: 0.647349, acc: 55.47%] [G loss: 3.470701]\n",
      "epoch:32 step:25025 [D loss: 0.725711, acc: 57.03%] [G loss: 3.481735]\n",
      "epoch:32 step:25026 [D loss: 0.773381, acc: 48.44%] [G loss: 5.795315]\n",
      "epoch:32 step:25027 [D loss: 0.692683, acc: 60.94%] [G loss: 4.743373]\n",
      "epoch:32 step:25028 [D loss: 0.183884, acc: 94.53%] [G loss: 4.824167]\n",
      "epoch:32 step:25029 [D loss: 0.487185, acc: 79.69%] [G loss: 3.899695]\n",
      "epoch:32 step:25030 [D loss: 0.372314, acc: 87.50%] [G loss: 4.725454]\n",
      "epoch:32 step:25031 [D loss: 0.346898, acc: 83.59%] [G loss: 5.870886]\n",
      "epoch:32 step:25032 [D loss: 0.435713, acc: 78.91%] [G loss: 4.240124]\n",
      "epoch:32 step:25033 [D loss: 0.501258, acc: 68.75%] [G loss: 3.724161]\n",
      "epoch:32 step:25034 [D loss: 0.284541, acc: 87.50%] [G loss: 3.621066]\n",
      "epoch:32 step:25035 [D loss: 1.031964, acc: 50.00%] [G loss: 6.166674]\n",
      "epoch:32 step:25036 [D loss: 0.437454, acc: 73.44%] [G loss: 4.932506]\n",
      "epoch:32 step:25037 [D loss: 0.169541, acc: 96.88%] [G loss: 5.514870]\n",
      "epoch:32 step:25038 [D loss: 0.189659, acc: 97.66%] [G loss: 3.588979]\n",
      "epoch:32 step:25039 [D loss: 0.326101, acc: 89.84%] [G loss: 5.046919]\n",
      "epoch:32 step:25040 [D loss: 0.456900, acc: 86.72%] [G loss: 3.850992]\n",
      "epoch:32 step:25041 [D loss: 0.839747, acc: 52.34%] [G loss: 4.713885]\n",
      "epoch:32 step:25042 [D loss: 0.831461, acc: 50.00%] [G loss: 4.878386]\n",
      "epoch:32 step:25043 [D loss: 0.764678, acc: 48.44%] [G loss: 5.577718]\n",
      "epoch:32 step:25044 [D loss: 0.320952, acc: 87.50%] [G loss: 4.872672]\n",
      "epoch:32 step:25045 [D loss: 0.805164, acc: 42.97%] [G loss: 3.677412]\n",
      "epoch:32 step:25046 [D loss: 0.760861, acc: 48.44%] [G loss: 6.081103]\n",
      "epoch:32 step:25047 [D loss: 0.431540, acc: 85.94%] [G loss: 6.033004]\n",
      "epoch:32 step:25048 [D loss: 0.557780, acc: 75.78%] [G loss: 3.896501]\n",
      "epoch:32 step:25049 [D loss: 0.457488, acc: 83.59%] [G loss: 5.827501]\n",
      "epoch:32 step:25050 [D loss: 0.126976, acc: 96.88%] [G loss: 4.445476]\n",
      "epoch:32 step:25051 [D loss: 0.398858, acc: 79.69%] [G loss: 4.102345]\n",
      "epoch:32 step:25052 [D loss: 0.577218, acc: 70.31%] [G loss: 5.545729]\n",
      "epoch:32 step:25053 [D loss: 0.244481, acc: 93.75%] [G loss: 4.494132]\n",
      "epoch:32 step:25054 [D loss: 0.300536, acc: 89.06%] [G loss: 3.866445]\n",
      "epoch:32 step:25055 [D loss: 0.350633, acc: 92.19%] [G loss: 3.391500]\n",
      "epoch:32 step:25056 [D loss: 0.182696, acc: 97.66%] [G loss: 3.619994]\n",
      "epoch:32 step:25057 [D loss: 1.012731, acc: 40.62%] [G loss: 3.571953]\n",
      "epoch:32 step:25058 [D loss: 0.259076, acc: 93.75%] [G loss: 2.808460]\n",
      "epoch:32 step:25059 [D loss: 0.659348, acc: 57.03%] [G loss: 6.313521]\n",
      "epoch:32 step:25060 [D loss: 0.067078, acc: 100.00%] [G loss: 4.642120]\n",
      "epoch:32 step:25061 [D loss: 0.301828, acc: 92.97%] [G loss: 4.353692]\n",
      "epoch:32 step:25062 [D loss: 0.477800, acc: 81.25%] [G loss: 5.899756]\n",
      "epoch:32 step:25063 [D loss: 0.359279, acc: 79.69%] [G loss: 4.289739]\n",
      "epoch:32 step:25064 [D loss: 0.478764, acc: 78.12%] [G loss: 4.296314]\n",
      "epoch:32 step:25065 [D loss: 0.223042, acc: 98.44%] [G loss: 5.870974]\n",
      "epoch:32 step:25066 [D loss: 0.309311, acc: 93.75%] [G loss: 4.258634]\n",
      "epoch:32 step:25067 [D loss: 0.557510, acc: 64.06%] [G loss: 7.031005]\n",
      "epoch:32 step:25068 [D loss: 0.473835, acc: 72.66%] [G loss: 3.931024]\n",
      "epoch:32 step:25069 [D loss: 0.564285, acc: 72.66%] [G loss: 4.886593]\n",
      "epoch:32 step:25070 [D loss: 0.250032, acc: 97.66%] [G loss: 2.591976]\n",
      "epoch:32 step:25071 [D loss: 0.638381, acc: 64.06%] [G loss: 4.072234]\n",
      "epoch:32 step:25072 [D loss: 0.340898, acc: 88.28%] [G loss: 2.859541]\n",
      "epoch:32 step:25073 [D loss: 1.493046, acc: 12.50%] [G loss: 7.744739]\n",
      "epoch:32 step:25074 [D loss: 0.168741, acc: 97.66%] [G loss: 4.199871]\n",
      "epoch:32 step:25075 [D loss: 0.238677, acc: 92.19%] [G loss: 5.444290]\n",
      "epoch:32 step:25076 [D loss: 0.321412, acc: 96.09%] [G loss: 5.527341]\n",
      "epoch:32 step:25077 [D loss: 0.155423, acc: 98.44%] [G loss: 4.349853]\n",
      "epoch:32 step:25078 [D loss: 0.321880, acc: 90.62%] [G loss: 3.885304]\n",
      "epoch:32 step:25079 [D loss: 0.325060, acc: 89.84%] [G loss: 6.284742]\n",
      "epoch:32 step:25080 [D loss: 0.637289, acc: 57.81%] [G loss: 5.221248]\n",
      "epoch:32 step:25081 [D loss: 0.111429, acc: 99.22%] [G loss: 5.342799]\n",
      "epoch:32 step:25082 [D loss: 0.288786, acc: 92.19%] [G loss: 5.452672]\n",
      "epoch:32 step:25083 [D loss: 0.174582, acc: 97.66%] [G loss: 6.241947]\n",
      "epoch:32 step:25084 [D loss: 0.260419, acc: 97.66%] [G loss: 7.193508]\n",
      "epoch:32 step:25085 [D loss: 0.620479, acc: 63.28%] [G loss: 5.853813]\n",
      "epoch:32 step:25086 [D loss: 0.514965, acc: 67.97%] [G loss: 4.986109]\n",
      "epoch:32 step:25087 [D loss: 0.719065, acc: 53.91%] [G loss: 5.626413]\n",
      "epoch:32 step:25088 [D loss: 0.293391, acc: 93.75%] [G loss: 2.736823]\n",
      "epoch:32 step:25089 [D loss: 0.267497, acc: 95.31%] [G loss: 2.222453]\n",
      "epoch:32 step:25090 [D loss: 0.412869, acc: 78.12%] [G loss: 2.720107]\n",
      "epoch:32 step:25091 [D loss: 0.277105, acc: 94.53%] [G loss: 2.695526]\n",
      "epoch:32 step:25092 [D loss: 0.057778, acc: 100.00%] [G loss: 5.515162]\n",
      "epoch:32 step:25093 [D loss: 0.084594, acc: 100.00%] [G loss: 5.037809]\n",
      "epoch:32 step:25094 [D loss: 0.190750, acc: 96.09%] [G loss: 3.854499]\n",
      "epoch:32 step:25095 [D loss: 0.902155, acc: 53.12%] [G loss: 3.785071]\n",
      "epoch:32 step:25096 [D loss: 1.116383, acc: 48.44%] [G loss: 4.597950]\n",
      "epoch:32 step:25097 [D loss: 0.567088, acc: 61.72%] [G loss: 4.633417]\n",
      "epoch:32 step:25098 [D loss: 1.248843, acc: 15.62%] [G loss: 3.246130]\n",
      "epoch:32 step:25099 [D loss: 0.341469, acc: 85.94%] [G loss: 6.456772]\n",
      "epoch:32 step:25100 [D loss: 0.687844, acc: 56.25%] [G loss: 3.788803]\n",
      "epoch:32 step:25101 [D loss: 0.628358, acc: 57.03%] [G loss: 3.062734]\n",
      "epoch:32 step:25102 [D loss: 0.300748, acc: 88.28%] [G loss: 3.497871]\n",
      "epoch:32 step:25103 [D loss: 0.762297, acc: 55.47%] [G loss: 5.901186]\n",
      "epoch:32 step:25104 [D loss: 0.232565, acc: 96.09%] [G loss: 4.402586]\n",
      "epoch:32 step:25105 [D loss: 0.701301, acc: 55.47%] [G loss: 5.400541]\n",
      "epoch:32 step:25106 [D loss: 1.337946, acc: 42.19%] [G loss: 4.822915]\n",
      "epoch:32 step:25107 [D loss: 0.564721, acc: 75.00%] [G loss: 3.771983]\n",
      "epoch:32 step:25108 [D loss: 0.277077, acc: 92.97%] [G loss: 4.018332]\n",
      "epoch:32 step:25109 [D loss: 0.350796, acc: 85.16%] [G loss: 6.000086]\n",
      "epoch:32 step:25110 [D loss: 0.271906, acc: 86.72%] [G loss: 6.821104]\n",
      "epoch:32 step:25111 [D loss: 0.335355, acc: 92.97%] [G loss: 6.071808]\n",
      "epoch:32 step:25112 [D loss: 0.167675, acc: 99.22%] [G loss: 6.817508]\n",
      "epoch:32 step:25113 [D loss: 0.303877, acc: 86.72%] [G loss: 5.547268]\n",
      "epoch:32 step:25114 [D loss: 0.039433, acc: 99.22%] [G loss: 8.082194]\n",
      "epoch:32 step:25115 [D loss: 0.152621, acc: 97.66%] [G loss: 4.110952]\n",
      "epoch:32 step:25116 [D loss: 0.749255, acc: 46.88%] [G loss: 4.947372]\n",
      "epoch:32 step:25117 [D loss: 0.227431, acc: 97.66%] [G loss: 6.109242]\n",
      "epoch:32 step:25118 [D loss: 0.161012, acc: 97.66%] [G loss: 6.686002]\n",
      "epoch:32 step:25119 [D loss: 0.324955, acc: 85.16%] [G loss: 7.260695]\n",
      "epoch:32 step:25120 [D loss: 0.117855, acc: 100.00%] [G loss: 5.584151]\n",
      "epoch:32 step:25121 [D loss: 0.908574, acc: 51.56%] [G loss: 7.013387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25122 [D loss: 0.963940, acc: 51.56%] [G loss: 3.084311]\n",
      "epoch:32 step:25123 [D loss: 1.116398, acc: 25.00%] [G loss: 4.323430]\n",
      "epoch:32 step:25124 [D loss: 0.144928, acc: 100.00%] [G loss: 4.061787]\n",
      "epoch:32 step:25125 [D loss: 1.065573, acc: 49.22%] [G loss: 3.419395]\n",
      "epoch:32 step:25126 [D loss: 0.093464, acc: 99.22%] [G loss: 4.963214]\n",
      "epoch:32 step:25127 [D loss: 0.429313, acc: 82.81%] [G loss: 5.072914]\n",
      "epoch:32 step:25128 [D loss: 0.777329, acc: 46.88%] [G loss: 4.246450]\n",
      "epoch:32 step:25129 [D loss: 0.286063, acc: 96.09%] [G loss: 5.568774]\n",
      "epoch:32 step:25130 [D loss: 1.191860, acc: 27.34%] [G loss: 5.917232]\n",
      "epoch:32 step:25131 [D loss: 0.374000, acc: 88.28%] [G loss: 3.272804]\n",
      "epoch:32 step:25132 [D loss: 0.098439, acc: 100.00%] [G loss: 3.014552]\n",
      "epoch:32 step:25133 [D loss: 0.458583, acc: 85.16%] [G loss: 4.162164]\n",
      "epoch:32 step:25134 [D loss: 0.296680, acc: 94.53%] [G loss: 3.650025]\n",
      "epoch:32 step:25135 [D loss: 1.333794, acc: 19.53%] [G loss: 5.195615]\n",
      "epoch:32 step:25136 [D loss: 0.330306, acc: 92.19%] [G loss: 5.638175]\n",
      "epoch:32 step:25137 [D loss: 0.318485, acc: 92.19%] [G loss: 6.725539]\n",
      "epoch:32 step:25138 [D loss: 0.079008, acc: 100.00%] [G loss: 5.462735]\n",
      "epoch:32 step:25139 [D loss: 0.145643, acc: 100.00%] [G loss: 2.620474]\n",
      "epoch:32 step:25140 [D loss: 0.215816, acc: 98.44%] [G loss: 3.687034]\n",
      "epoch:32 step:25141 [D loss: 0.158020, acc: 100.00%] [G loss: 3.933167]\n",
      "epoch:32 step:25142 [D loss: 0.158798, acc: 98.44%] [G loss: 2.900381]\n",
      "epoch:32 step:25143 [D loss: 0.284343, acc: 86.72%] [G loss: 6.484335]\n",
      "epoch:32 step:25144 [D loss: 0.736208, acc: 48.44%] [G loss: 2.765016]\n",
      "epoch:32 step:25145 [D loss: 0.154449, acc: 100.00%] [G loss: 4.802414]\n",
      "epoch:32 step:25146 [D loss: 0.802319, acc: 48.44%] [G loss: 3.608613]\n",
      "epoch:32 step:25147 [D loss: 0.888557, acc: 53.91%] [G loss: 6.745702]\n",
      "epoch:32 step:25148 [D loss: 0.193091, acc: 100.00%] [G loss: 5.752275]\n",
      "epoch:32 step:25149 [D loss: 0.849515, acc: 53.91%] [G loss: 5.236390]\n",
      "epoch:32 step:25150 [D loss: 0.214278, acc: 92.19%] [G loss: 5.537855]\n",
      "epoch:32 step:25151 [D loss: 0.890844, acc: 36.72%] [G loss: 6.303292]\n",
      "epoch:32 step:25152 [D loss: 0.158726, acc: 99.22%] [G loss: 5.233611]\n",
      "epoch:32 step:25153 [D loss: 0.395225, acc: 79.69%] [G loss: 4.231648]\n",
      "epoch:32 step:25154 [D loss: 0.642512, acc: 58.59%] [G loss: 2.560644]\n",
      "epoch:32 step:25155 [D loss: 0.398175, acc: 90.62%] [G loss: 3.875346]\n",
      "epoch:32 step:25156 [D loss: 0.123211, acc: 99.22%] [G loss: 6.019093]\n",
      "epoch:32 step:25157 [D loss: 0.372953, acc: 78.12%] [G loss: 4.981905]\n",
      "epoch:32 step:25158 [D loss: 0.499926, acc: 74.22%] [G loss: 4.171962]\n",
      "epoch:32 step:25159 [D loss: 0.232163, acc: 95.31%] [G loss: 4.501635]\n",
      "epoch:32 step:25160 [D loss: 0.264249, acc: 94.53%] [G loss: 6.286701]\n",
      "epoch:32 step:25161 [D loss: 0.165822, acc: 97.66%] [G loss: 3.814952]\n",
      "epoch:32 step:25162 [D loss: 0.138697, acc: 100.00%] [G loss: 5.587487]\n",
      "epoch:32 step:25163 [D loss: 0.362303, acc: 79.69%] [G loss: 3.414992]\n",
      "epoch:32 step:25164 [D loss: 0.082581, acc: 100.00%] [G loss: 6.182839]\n",
      "epoch:32 step:25165 [D loss: 0.510129, acc: 64.84%] [G loss: 4.803212]\n",
      "epoch:32 step:25166 [D loss: 1.174934, acc: 49.22%] [G loss: 4.695091]\n",
      "epoch:32 step:25167 [D loss: 0.132538, acc: 97.66%] [G loss: 4.884350]\n",
      "epoch:32 step:25168 [D loss: 0.334529, acc: 92.97%] [G loss: 5.388356]\n",
      "epoch:32 step:25169 [D loss: 0.602928, acc: 71.09%] [G loss: 5.436233]\n",
      "epoch:32 step:25170 [D loss: 0.293044, acc: 95.31%] [G loss: 4.638265]\n",
      "epoch:32 step:25171 [D loss: 0.360444, acc: 86.72%] [G loss: 6.087965]\n",
      "epoch:32 step:25172 [D loss: 0.347690, acc: 75.00%] [G loss: 2.629302]\n",
      "epoch:32 step:25173 [D loss: 0.354490, acc: 84.38%] [G loss: 4.355093]\n",
      "epoch:32 step:25174 [D loss: 0.148654, acc: 99.22%] [G loss: 4.644976]\n",
      "epoch:32 step:25175 [D loss: 1.234094, acc: 46.88%] [G loss: 6.584273]\n",
      "epoch:32 step:25176 [D loss: 0.262070, acc: 95.31%] [G loss: 4.285793]\n",
      "epoch:32 step:25177 [D loss: 0.939983, acc: 50.78%] [G loss: 4.807331]\n",
      "epoch:32 step:25178 [D loss: 0.461433, acc: 71.09%] [G loss: 5.252139]\n",
      "epoch:32 step:25179 [D loss: 0.221564, acc: 96.88%] [G loss: 5.034459]\n",
      "epoch:32 step:25180 [D loss: 0.960765, acc: 50.78%] [G loss: 4.712347]\n",
      "epoch:32 step:25181 [D loss: 0.015969, acc: 100.00%] [G loss: 9.399070]\n",
      "epoch:32 step:25182 [D loss: 0.715346, acc: 54.69%] [G loss: 5.100029]\n",
      "epoch:32 step:25183 [D loss: 0.245038, acc: 96.88%] [G loss: 4.753334]\n",
      "epoch:32 step:25184 [D loss: 0.768007, acc: 56.25%] [G loss: 3.381569]\n",
      "epoch:32 step:25185 [D loss: 0.605368, acc: 68.75%] [G loss: 2.257142]\n",
      "epoch:32 step:25186 [D loss: 0.121915, acc: 100.00%] [G loss: 5.267047]\n",
      "epoch:32 step:25187 [D loss: 0.094922, acc: 99.22%] [G loss: 4.796973]\n",
      "epoch:32 step:25188 [D loss: 1.086390, acc: 35.16%] [G loss: 6.905240]\n",
      "epoch:32 step:25189 [D loss: 0.083049, acc: 100.00%] [G loss: 4.279642]\n",
      "epoch:32 step:25190 [D loss: 0.247894, acc: 93.75%] [G loss: 4.840270]\n",
      "epoch:32 step:25191 [D loss: 0.108016, acc: 99.22%] [G loss: 3.999079]\n",
      "epoch:32 step:25192 [D loss: 0.193948, acc: 97.66%] [G loss: 5.937905]\n",
      "epoch:32 step:25193 [D loss: 0.578134, acc: 65.62%] [G loss: 3.177740]\n",
      "epoch:32 step:25194 [D loss: 1.003856, acc: 49.22%] [G loss: 2.095301]\n",
      "epoch:32 step:25195 [D loss: 0.215756, acc: 97.66%] [G loss: 6.611818]\n",
      "epoch:32 step:25196 [D loss: 0.436900, acc: 83.59%] [G loss: 5.553639]\n",
      "epoch:32 step:25197 [D loss: 0.262334, acc: 88.28%] [G loss: 4.327168]\n",
      "epoch:32 step:25198 [D loss: 0.050650, acc: 100.00%] [G loss: 3.102601]\n",
      "epoch:32 step:25199 [D loss: 0.274679, acc: 91.41%] [G loss: 4.668997]\n",
      "epoch:32 step:25200 [D loss: 0.834491, acc: 53.12%] [G loss: 6.006209]\n",
      "epoch:32 step:25201 [D loss: 0.395837, acc: 76.56%] [G loss: 3.353718]\n",
      "epoch:32 step:25202 [D loss: 1.035147, acc: 49.22%] [G loss: 2.884466]\n",
      "epoch:32 step:25203 [D loss: 0.709191, acc: 55.47%] [G loss: 4.397717]\n",
      "epoch:32 step:25204 [D loss: 0.130731, acc: 100.00%] [G loss: 3.843048]\n",
      "epoch:32 step:25205 [D loss: 0.234063, acc: 93.75%] [G loss: 7.314664]\n",
      "epoch:32 step:25206 [D loss: 0.439175, acc: 83.59%] [G loss: 4.797046]\n",
      "epoch:32 step:25207 [D loss: 0.154546, acc: 99.22%] [G loss: 5.190104]\n",
      "epoch:32 step:25208 [D loss: 0.298190, acc: 90.62%] [G loss: 4.519903]\n",
      "epoch:32 step:25209 [D loss: 0.271367, acc: 90.62%] [G loss: 6.230467]\n",
      "epoch:32 step:25210 [D loss: 0.526774, acc: 69.53%] [G loss: 5.186878]\n",
      "epoch:32 step:25211 [D loss: 1.654572, acc: 49.22%] [G loss: 5.486275]\n",
      "epoch:32 step:25212 [D loss: 0.184801, acc: 97.66%] [G loss: 3.838636]\n",
      "epoch:32 step:25213 [D loss: 0.192505, acc: 97.66%] [G loss: 5.069808]\n",
      "epoch:32 step:25214 [D loss: 0.277250, acc: 92.19%] [G loss: 6.175871]\n",
      "epoch:32 step:25215 [D loss: 0.959380, acc: 50.78%] [G loss: 4.432320]\n",
      "epoch:32 step:25216 [D loss: 0.391267, acc: 80.47%] [G loss: 3.593196]\n",
      "epoch:32 step:25217 [D loss: 0.242472, acc: 96.09%] [G loss: 5.061582]\n",
      "epoch:32 step:25218 [D loss: 0.077265, acc: 100.00%] [G loss: 5.552866]\n",
      "epoch:32 step:25219 [D loss: 0.147396, acc: 97.66%] [G loss: 6.025349]\n",
      "epoch:32 step:25220 [D loss: 0.558285, acc: 64.84%] [G loss: 4.337726]\n",
      "epoch:32 step:25221 [D loss: 0.046381, acc: 100.00%] [G loss: 5.814502]\n",
      "epoch:32 step:25222 [D loss: 0.042741, acc: 100.00%] [G loss: 6.206147]\n",
      "epoch:32 step:25223 [D loss: 0.340859, acc: 85.16%] [G loss: 4.394529]\n",
      "epoch:32 step:25224 [D loss: 0.604253, acc: 66.41%] [G loss: 4.996745]\n",
      "epoch:32 step:25225 [D loss: 0.088275, acc: 100.00%] [G loss: 5.904453]\n",
      "epoch:32 step:25226 [D loss: 0.868023, acc: 43.75%] [G loss: 6.137148]\n",
      "epoch:32 step:25227 [D loss: 0.288529, acc: 92.97%] [G loss: 5.013355]\n",
      "epoch:32 step:25228 [D loss: 0.225232, acc: 97.66%] [G loss: 2.628260]\n",
      "epoch:32 step:25229 [D loss: 0.207869, acc: 97.66%] [G loss: 6.736554]\n",
      "epoch:32 step:25230 [D loss: 0.419275, acc: 82.81%] [G loss: 4.068170]\n",
      "epoch:32 step:25231 [D loss: 0.167762, acc: 96.88%] [G loss: 2.806849]\n",
      "epoch:32 step:25232 [D loss: 0.696668, acc: 57.81%] [G loss: 5.437412]\n",
      "epoch:32 step:25233 [D loss: 0.296231, acc: 92.97%] [G loss: 4.825338]\n",
      "epoch:32 step:25234 [D loss: 0.392653, acc: 73.44%] [G loss: 5.234279]\n",
      "epoch:32 step:25235 [D loss: 0.166683, acc: 96.09%] [G loss: 5.477778]\n",
      "epoch:32 step:25236 [D loss: 0.250122, acc: 96.09%] [G loss: 5.378640]\n",
      "epoch:32 step:25237 [D loss: 0.807917, acc: 42.19%] [G loss: 4.719416]\n",
      "epoch:32 step:25238 [D loss: 1.400461, acc: 24.22%] [G loss: 5.298792]\n",
      "epoch:32 step:25239 [D loss: 0.170068, acc: 100.00%] [G loss: 2.960734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25240 [D loss: 0.281225, acc: 92.97%] [G loss: 3.473113]\n",
      "epoch:32 step:25241 [D loss: 0.100821, acc: 100.00%] [G loss: 6.146363]\n",
      "epoch:32 step:25242 [D loss: 0.067975, acc: 100.00%] [G loss: 5.835250]\n",
      "epoch:32 step:25243 [D loss: 0.157274, acc: 97.66%] [G loss: 7.419549]\n",
      "epoch:32 step:25244 [D loss: 0.229477, acc: 96.09%] [G loss: 2.984871]\n",
      "epoch:32 step:25245 [D loss: 0.177789, acc: 98.44%] [G loss: 3.669002]\n",
      "epoch:32 step:25246 [D loss: 0.203783, acc: 97.66%] [G loss: 5.138705]\n",
      "epoch:32 step:25247 [D loss: 0.373760, acc: 78.12%] [G loss: 3.312283]\n",
      "epoch:32 step:25248 [D loss: 0.121124, acc: 99.22%] [G loss: 2.571825]\n",
      "epoch:32 step:25249 [D loss: 0.166214, acc: 97.66%] [G loss: 4.610726]\n",
      "epoch:32 step:25250 [D loss: 0.755759, acc: 54.69%] [G loss: 3.972991]\n",
      "epoch:32 step:25251 [D loss: 0.086342, acc: 100.00%] [G loss: 3.760970]\n",
      "epoch:32 step:25252 [D loss: 0.867197, acc: 52.34%] [G loss: 5.337312]\n",
      "epoch:32 step:25253 [D loss: 0.485734, acc: 69.53%] [G loss: 6.302320]\n",
      "epoch:32 step:25254 [D loss: 0.051180, acc: 100.00%] [G loss: 6.477350]\n",
      "epoch:32 step:25255 [D loss: 0.095283, acc: 100.00%] [G loss: 3.965820]\n",
      "epoch:32 step:25256 [D loss: 0.608601, acc: 68.75%] [G loss: 5.686510]\n",
      "epoch:32 step:25257 [D loss: 0.213797, acc: 96.88%] [G loss: 4.112056]\n",
      "epoch:32 step:25258 [D loss: 0.457174, acc: 72.66%] [G loss: 6.048702]\n",
      "epoch:32 step:25259 [D loss: 1.656722, acc: 50.00%] [G loss: 2.743437]\n",
      "epoch:32 step:25260 [D loss: 0.525646, acc: 69.53%] [G loss: 4.461223]\n",
      "epoch:32 step:25261 [D loss: 1.310973, acc: 31.25%] [G loss: 5.808139]\n",
      "epoch:32 step:25262 [D loss: 0.099378, acc: 100.00%] [G loss: 3.834236]\n",
      "epoch:32 step:25263 [D loss: 0.672329, acc: 55.47%] [G loss: 4.258201]\n",
      "epoch:32 step:25264 [D loss: 0.187495, acc: 98.44%] [G loss: 4.820953]\n",
      "epoch:32 step:25265 [D loss: 0.387819, acc: 86.72%] [G loss: 2.277173]\n",
      "epoch:32 step:25266 [D loss: 0.168823, acc: 99.22%] [G loss: 3.548052]\n",
      "epoch:32 step:25267 [D loss: 0.339969, acc: 85.94%] [G loss: 4.528290]\n",
      "epoch:32 step:25268 [D loss: 0.822347, acc: 51.56%] [G loss: 5.490022]\n",
      "epoch:32 step:25269 [D loss: 0.840318, acc: 54.69%] [G loss: 5.086067]\n",
      "epoch:32 step:25270 [D loss: 0.164239, acc: 97.66%] [G loss: 4.461219]\n",
      "epoch:32 step:25271 [D loss: 0.232567, acc: 95.31%] [G loss: 2.927569]\n",
      "epoch:32 step:25272 [D loss: 0.189346, acc: 100.00%] [G loss: 4.436388]\n",
      "epoch:32 step:25273 [D loss: 0.733555, acc: 53.91%] [G loss: 5.815832]\n",
      "epoch:32 step:25274 [D loss: 0.176821, acc: 97.66%] [G loss: 3.443314]\n",
      "epoch:32 step:25275 [D loss: 0.213168, acc: 97.66%] [G loss: 4.936644]\n",
      "epoch:32 step:25276 [D loss: 0.181777, acc: 96.09%] [G loss: 5.461606]\n",
      "epoch:32 step:25277 [D loss: 0.590259, acc: 67.97%] [G loss: 5.723745]\n",
      "epoch:32 step:25278 [D loss: 0.577895, acc: 70.31%] [G loss: 4.117559]\n",
      "epoch:32 step:25279 [D loss: 0.917848, acc: 51.56%] [G loss: 6.233945]\n",
      "epoch:32 step:25280 [D loss: 0.562639, acc: 60.94%] [G loss: 4.570856]\n",
      "epoch:32 step:25281 [D loss: 0.574494, acc: 71.09%] [G loss: 3.567930]\n",
      "epoch:32 step:25282 [D loss: 0.219742, acc: 96.88%] [G loss: 5.574027]\n",
      "epoch:32 step:25283 [D loss: 0.739431, acc: 50.78%] [G loss: 7.749449]\n",
      "epoch:32 step:25284 [D loss: 0.499499, acc: 70.31%] [G loss: 5.980198]\n",
      "epoch:32 step:25285 [D loss: 0.287292, acc: 91.41%] [G loss: 3.733122]\n",
      "epoch:32 step:25286 [D loss: 0.159283, acc: 97.66%] [G loss: 5.780056]\n",
      "epoch:32 step:25287 [D loss: 0.567826, acc: 60.94%] [G loss: 3.660394]\n",
      "epoch:32 step:25288 [D loss: 0.117251, acc: 100.00%] [G loss: 1.968307]\n",
      "epoch:32 step:25289 [D loss: 0.320699, acc: 92.97%] [G loss: 4.636520]\n",
      "epoch:32 step:25290 [D loss: 0.559713, acc: 64.06%] [G loss: 3.144321]\n",
      "epoch:32 step:25291 [D loss: 0.392331, acc: 76.56%] [G loss: 4.777944]\n",
      "epoch:32 step:25292 [D loss: 0.477807, acc: 71.88%] [G loss: 3.767265]\n",
      "epoch:32 step:25293 [D loss: 0.144167, acc: 99.22%] [G loss: 5.222335]\n",
      "epoch:32 step:25294 [D loss: 0.418392, acc: 89.06%] [G loss: 3.421686]\n",
      "epoch:32 step:25295 [D loss: 0.280411, acc: 95.31%] [G loss: 2.187707]\n",
      "epoch:32 step:25296 [D loss: 0.570238, acc: 60.16%] [G loss: 4.418424]\n",
      "epoch:32 step:25297 [D loss: 0.189508, acc: 93.75%] [G loss: 3.114716]\n",
      "epoch:32 step:25298 [D loss: 0.502281, acc: 75.00%] [G loss: 3.337178]\n",
      "epoch:32 step:25299 [D loss: 0.435227, acc: 73.44%] [G loss: 5.234393]\n",
      "epoch:32 step:25300 [D loss: 0.124371, acc: 100.00%] [G loss: 3.294238]\n",
      "epoch:32 step:25301 [D loss: 0.503049, acc: 67.19%] [G loss: 4.156363]\n",
      "epoch:32 step:25302 [D loss: 0.183361, acc: 98.44%] [G loss: 6.731188]\n",
      "epoch:32 step:25303 [D loss: 0.231249, acc: 92.97%] [G loss: 4.753953]\n",
      "epoch:32 step:25304 [D loss: 0.555337, acc: 71.09%] [G loss: 5.332844]\n",
      "epoch:32 step:25305 [D loss: 0.472796, acc: 70.31%] [G loss: 5.000232]\n",
      "epoch:32 step:25306 [D loss: 0.050167, acc: 99.22%] [G loss: 6.831146]\n",
      "epoch:32 step:25307 [D loss: 0.167360, acc: 96.09%] [G loss: 6.618556]\n",
      "epoch:32 step:25308 [D loss: 0.468484, acc: 85.16%] [G loss: 6.493556]\n",
      "epoch:32 step:25309 [D loss: 1.285461, acc: 48.44%] [G loss: 7.261247]\n",
      "epoch:32 step:25310 [D loss: 0.601743, acc: 64.06%] [G loss: 6.643048]\n",
      "epoch:32 step:25311 [D loss: 0.294524, acc: 92.19%] [G loss: 3.730366]\n",
      "epoch:32 step:25312 [D loss: 0.473870, acc: 78.12%] [G loss: 7.483877]\n",
      "epoch:32 step:25313 [D loss: 0.836541, acc: 51.56%] [G loss: 2.873909]\n",
      "epoch:32 step:25314 [D loss: 0.499117, acc: 75.78%] [G loss: 5.854197]\n",
      "epoch:32 step:25315 [D loss: 0.958261, acc: 46.88%] [G loss: 3.745180]\n",
      "epoch:32 step:25316 [D loss: 0.627986, acc: 57.81%] [G loss: 4.166052]\n",
      "epoch:32 step:25317 [D loss: 0.465598, acc: 70.31%] [G loss: 5.442933]\n",
      "epoch:32 step:25318 [D loss: 0.448609, acc: 76.56%] [G loss: 5.829509]\n",
      "epoch:32 step:25319 [D loss: 0.224819, acc: 96.09%] [G loss: 4.203695]\n",
      "epoch:32 step:25320 [D loss: 0.582417, acc: 57.81%] [G loss: 5.996684]\n",
      "epoch:32 step:25321 [D loss: 0.065195, acc: 100.00%] [G loss: 4.469692]\n",
      "epoch:32 step:25322 [D loss: 0.693747, acc: 57.81%] [G loss: 5.115729]\n",
      "epoch:32 step:25323 [D loss: 0.721132, acc: 59.38%] [G loss: 4.736318]\n",
      "epoch:32 step:25324 [D loss: 0.250307, acc: 96.09%] [G loss: 4.978479]\n",
      "epoch:32 step:25325 [D loss: 0.270113, acc: 91.41%] [G loss: 5.733418]\n",
      "epoch:32 step:25326 [D loss: 0.116878, acc: 99.22%] [G loss: 5.078569]\n",
      "epoch:32 step:25327 [D loss: 0.208706, acc: 97.66%] [G loss: 6.407585]\n",
      "epoch:32 step:25328 [D loss: 0.876502, acc: 51.56%] [G loss: 7.055197]\n",
      "epoch:32 step:25329 [D loss: 0.437176, acc: 85.16%] [G loss: 3.689016]\n",
      "epoch:32 step:25330 [D loss: 0.867457, acc: 50.00%] [G loss: 4.156432]\n",
      "epoch:32 step:25331 [D loss: 0.105091, acc: 98.44%] [G loss: 4.905820]\n",
      "epoch:32 step:25332 [D loss: 0.289158, acc: 87.50%] [G loss: 4.361637]\n",
      "epoch:32 step:25333 [D loss: 0.821460, acc: 42.19%] [G loss: 4.850527]\n",
      "epoch:32 step:25334 [D loss: 0.277530, acc: 96.88%] [G loss: 4.835724]\n",
      "epoch:32 step:25335 [D loss: 0.613453, acc: 63.28%] [G loss: 4.839679]\n",
      "epoch:32 step:25336 [D loss: 0.678118, acc: 60.16%] [G loss: 2.843096]\n",
      "epoch:32 step:25337 [D loss: 0.097578, acc: 100.00%] [G loss: 3.631224]\n",
      "epoch:32 step:25338 [D loss: 0.219581, acc: 96.88%] [G loss: 3.032137]\n",
      "epoch:32 step:25339 [D loss: 0.596388, acc: 73.44%] [G loss: 3.401713]\n",
      "epoch:32 step:25340 [D loss: 0.410537, acc: 86.72%] [G loss: 5.523809]\n",
      "epoch:32 step:25341 [D loss: 0.333331, acc: 84.38%] [G loss: 4.857672]\n",
      "epoch:32 step:25342 [D loss: 0.169533, acc: 97.66%] [G loss: 4.670558]\n",
      "epoch:32 step:25343 [D loss: 0.204860, acc: 97.66%] [G loss: 2.987117]\n",
      "epoch:32 step:25344 [D loss: 0.042246, acc: 100.00%] [G loss: 4.919959]\n",
      "epoch:32 step:25345 [D loss: 0.238018, acc: 93.75%] [G loss: 2.704175]\n",
      "epoch:32 step:25346 [D loss: 0.199340, acc: 97.66%] [G loss: 4.137577]\n",
      "epoch:32 step:25347 [D loss: 0.365980, acc: 89.84%] [G loss: 4.092753]\n",
      "epoch:32 step:25348 [D loss: 0.261935, acc: 96.88%] [G loss: 3.442545]\n",
      "epoch:32 step:25349 [D loss: 0.214340, acc: 96.88%] [G loss: 5.953189]\n",
      "epoch:32 step:25350 [D loss: 0.282256, acc: 94.53%] [G loss: 4.536008]\n",
      "epoch:32 step:25351 [D loss: 0.227193, acc: 92.97%] [G loss: 5.669992]\n",
      "epoch:32 step:25352 [D loss: 0.732552, acc: 55.47%] [G loss: 4.265083]\n",
      "epoch:32 step:25353 [D loss: 0.142597, acc: 98.44%] [G loss: 3.593864]\n",
      "epoch:32 step:25354 [D loss: 0.391954, acc: 82.81%] [G loss: 3.813644]\n",
      "epoch:32 step:25355 [D loss: 0.474925, acc: 67.97%] [G loss: 6.131457]\n",
      "epoch:32 step:25356 [D loss: 0.179968, acc: 97.66%] [G loss: 6.385765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25357 [D loss: 0.066830, acc: 100.00%] [G loss: 7.062339]\n",
      "epoch:32 step:25358 [D loss: 0.291541, acc: 96.09%] [G loss: 4.162393]\n",
      "epoch:32 step:25359 [D loss: 0.678867, acc: 53.12%] [G loss: 6.360240]\n",
      "epoch:32 step:25360 [D loss: 0.295736, acc: 96.09%] [G loss: 4.176274]\n",
      "epoch:32 step:25361 [D loss: 0.361397, acc: 81.25%] [G loss: 5.114046]\n",
      "epoch:32 step:25362 [D loss: 0.187863, acc: 99.22%] [G loss: 4.136809]\n",
      "epoch:32 step:25363 [D loss: 0.428438, acc: 89.06%] [G loss: 3.804400]\n",
      "epoch:32 step:25364 [D loss: 0.124148, acc: 100.00%] [G loss: 4.673732]\n",
      "epoch:32 step:25365 [D loss: 0.623514, acc: 64.06%] [G loss: 3.551484]\n",
      "epoch:32 step:25366 [D loss: 1.055801, acc: 49.22%] [G loss: 4.704734]\n",
      "epoch:32 step:25367 [D loss: 0.184469, acc: 96.88%] [G loss: 5.642807]\n",
      "epoch:32 step:25368 [D loss: 0.339872, acc: 87.50%] [G loss: 4.313335]\n",
      "epoch:32 step:25369 [D loss: 0.247163, acc: 93.75%] [G loss: 3.873239]\n",
      "epoch:32 step:25370 [D loss: 0.231290, acc: 97.66%] [G loss: 4.767878]\n",
      "epoch:32 step:25371 [D loss: 0.024285, acc: 100.00%] [G loss: 6.126510]\n",
      "epoch:32 step:25372 [D loss: 1.212708, acc: 32.81%] [G loss: 7.228209]\n",
      "epoch:32 step:25373 [D loss: 0.307399, acc: 83.59%] [G loss: 3.530897]\n",
      "epoch:32 step:25374 [D loss: 0.371412, acc: 88.28%] [G loss: 4.254129]\n",
      "epoch:32 step:25375 [D loss: 0.447307, acc: 83.59%] [G loss: 4.134887]\n",
      "epoch:32 step:25376 [D loss: 0.235203, acc: 94.53%] [G loss: 4.217598]\n",
      "epoch:32 step:25377 [D loss: 0.190586, acc: 97.66%] [G loss: 6.135662]\n",
      "epoch:32 step:25378 [D loss: 0.894330, acc: 50.78%] [G loss: 4.560395]\n",
      "epoch:32 step:25379 [D loss: 1.057796, acc: 46.88%] [G loss: 5.755906]\n",
      "epoch:32 step:25380 [D loss: 0.177535, acc: 97.66%] [G loss: 6.351540]\n",
      "epoch:32 step:25381 [D loss: 0.185121, acc: 99.22%] [G loss: 4.306641]\n",
      "epoch:32 step:25382 [D loss: 0.486053, acc: 79.69%] [G loss: 7.110897]\n",
      "epoch:32 step:25383 [D loss: 0.580916, acc: 73.44%] [G loss: 5.087660]\n",
      "epoch:32 step:25384 [D loss: 0.184125, acc: 99.22%] [G loss: 3.436679]\n",
      "epoch:32 step:25385 [D loss: 0.260312, acc: 94.53%] [G loss: 5.233531]\n",
      "epoch:32 step:25386 [D loss: 0.150689, acc: 99.22%] [G loss: 3.501788]\n",
      "epoch:32 step:25387 [D loss: 0.780688, acc: 52.34%] [G loss: 4.610759]\n",
      "epoch:32 step:25388 [D loss: 0.696438, acc: 58.59%] [G loss: 5.443302]\n",
      "epoch:32 step:25389 [D loss: 0.285405, acc: 89.84%] [G loss: 2.894671]\n",
      "epoch:32 step:25390 [D loss: 0.872323, acc: 53.12%] [G loss: 3.960960]\n",
      "epoch:32 step:25391 [D loss: 0.166724, acc: 98.44%] [G loss: 4.407528]\n",
      "epoch:32 step:25392 [D loss: 0.143409, acc: 100.00%] [G loss: 4.446349]\n",
      "epoch:32 step:25393 [D loss: 0.061454, acc: 100.00%] [G loss: 7.172640]\n",
      "epoch:32 step:25394 [D loss: 0.086965, acc: 100.00%] [G loss: 3.900628]\n",
      "epoch:32 step:25395 [D loss: 0.187040, acc: 99.22%] [G loss: 5.211986]\n",
      "epoch:32 step:25396 [D loss: 0.780644, acc: 53.12%] [G loss: 3.570852]\n",
      "epoch:32 step:25397 [D loss: 0.607999, acc: 62.50%] [G loss: 2.329687]\n",
      "epoch:32 step:25398 [D loss: 0.524027, acc: 71.88%] [G loss: 4.468791]\n",
      "epoch:32 step:25399 [D loss: 0.258875, acc: 96.09%] [G loss: 4.528647]\n",
      "epoch:32 step:25400 [D loss: 0.115194, acc: 98.44%] [G loss: 2.484926]\n",
      "epoch:32 step:25401 [D loss: 0.291291, acc: 89.06%] [G loss: 3.411313]\n",
      "epoch:32 step:25402 [D loss: 0.272284, acc: 88.28%] [G loss: 3.795223]\n",
      "epoch:32 step:25403 [D loss: 0.383779, acc: 82.03%] [G loss: 6.076480]\n",
      "epoch:32 step:25404 [D loss: 0.971749, acc: 49.22%] [G loss: 4.021860]\n",
      "epoch:32 step:25405 [D loss: 0.413958, acc: 82.81%] [G loss: 5.300917]\n",
      "epoch:32 step:25406 [D loss: 0.744363, acc: 54.69%] [G loss: 6.750776]\n",
      "epoch:32 step:25407 [D loss: 0.440897, acc: 80.47%] [G loss: 5.697618]\n",
      "epoch:32 step:25408 [D loss: 0.549350, acc: 67.19%] [G loss: 4.693267]\n",
      "epoch:32 step:25409 [D loss: 0.308463, acc: 86.72%] [G loss: 3.541864]\n",
      "epoch:32 step:25410 [D loss: 0.163576, acc: 98.44%] [G loss: 4.864772]\n",
      "epoch:32 step:25411 [D loss: 0.602751, acc: 57.81%] [G loss: 7.059791]\n",
      "epoch:32 step:25412 [D loss: 0.259242, acc: 96.88%] [G loss: 2.783893]\n",
      "epoch:32 step:25413 [D loss: 0.668819, acc: 57.81%] [G loss: 3.198436]\n",
      "epoch:32 step:25414 [D loss: 0.112599, acc: 98.44%] [G loss: 7.347037]\n",
      "epoch:32 step:25415 [D loss: 0.638680, acc: 60.94%] [G loss: 2.942760]\n",
      "epoch:32 step:25416 [D loss: 0.278688, acc: 91.41%] [G loss: 4.304192]\n",
      "epoch:32 step:25417 [D loss: 0.963236, acc: 47.66%] [G loss: 5.119424]\n",
      "epoch:32 step:25418 [D loss: 0.563100, acc: 67.97%] [G loss: 4.569063]\n",
      "epoch:32 step:25419 [D loss: 0.502837, acc: 64.84%] [G loss: 4.629715]\n",
      "epoch:32 step:25420 [D loss: 0.459977, acc: 75.78%] [G loss: 4.803627]\n",
      "epoch:32 step:25421 [D loss: 0.576841, acc: 71.09%] [G loss: 4.718629]\n",
      "epoch:32 step:25422 [D loss: 0.206907, acc: 97.66%] [G loss: 4.320948]\n",
      "epoch:32 step:25423 [D loss: 0.333722, acc: 82.81%] [G loss: 5.664559]\n",
      "epoch:32 step:25424 [D loss: 0.456001, acc: 83.59%] [G loss: 3.663757]\n",
      "epoch:32 step:25425 [D loss: 0.623897, acc: 59.38%] [G loss: 5.198852]\n",
      "epoch:32 step:25426 [D loss: 0.097016, acc: 100.00%] [G loss: 7.486776]\n",
      "epoch:32 step:25427 [D loss: 0.151376, acc: 97.66%] [G loss: 6.443096]\n",
      "epoch:32 step:25428 [D loss: 0.447607, acc: 79.69%] [G loss: 3.394059]\n",
      "epoch:32 step:25429 [D loss: 0.628507, acc: 61.72%] [G loss: 5.797903]\n",
      "epoch:32 step:25430 [D loss: 0.477176, acc: 81.25%] [G loss: 5.883237]\n",
      "epoch:32 step:25431 [D loss: 0.212743, acc: 96.88%] [G loss: 3.667758]\n",
      "epoch:32 step:25432 [D loss: 0.108947, acc: 99.22%] [G loss: 4.981866]\n",
      "epoch:32 step:25433 [D loss: 0.368598, acc: 78.12%] [G loss: 4.231080]\n",
      "epoch:32 step:25434 [D loss: 0.473802, acc: 71.09%] [G loss: 3.553466]\n",
      "epoch:32 step:25435 [D loss: 0.585327, acc: 73.44%] [G loss: 3.883822]\n",
      "epoch:32 step:25436 [D loss: 0.126704, acc: 97.66%] [G loss: 5.563577]\n",
      "epoch:32 step:25437 [D loss: 0.249920, acc: 96.88%] [G loss: 2.779927]\n",
      "epoch:32 step:25438 [D loss: 1.123579, acc: 49.22%] [G loss: 5.129642]\n",
      "epoch:32 step:25439 [D loss: 0.134242, acc: 100.00%] [G loss: 5.098122]\n",
      "epoch:32 step:25440 [D loss: 0.340381, acc: 76.56%] [G loss: 5.953209]\n",
      "epoch:32 step:25441 [D loss: 0.363834, acc: 78.91%] [G loss: 5.240087]\n",
      "epoch:32 step:25442 [D loss: 0.223568, acc: 94.53%] [G loss: 3.707865]\n",
      "epoch:32 step:25443 [D loss: 0.334668, acc: 93.75%] [G loss: 3.300486]\n",
      "epoch:32 step:25444 [D loss: 0.065895, acc: 100.00%] [G loss: 5.736494]\n",
      "epoch:32 step:25445 [D loss: 0.234317, acc: 96.09%] [G loss: 4.723702]\n",
      "epoch:32 step:25446 [D loss: 0.179799, acc: 99.22%] [G loss: 2.076795]\n",
      "epoch:32 step:25447 [D loss: 0.644762, acc: 64.06%] [G loss: 3.757645]\n",
      "epoch:32 step:25448 [D loss: 0.400495, acc: 78.12%] [G loss: 4.835583]\n",
      "epoch:32 step:25449 [D loss: 0.653586, acc: 59.38%] [G loss: 6.819894]\n",
      "epoch:32 step:25450 [D loss: 0.630072, acc: 60.94%] [G loss: 4.108039]\n",
      "epoch:32 step:25451 [D loss: 0.393859, acc: 85.16%] [G loss: 4.151731]\n",
      "epoch:32 step:25452 [D loss: 0.215742, acc: 92.97%] [G loss: 5.543148]\n",
      "epoch:32 step:25453 [D loss: 0.327040, acc: 91.41%] [G loss: 7.309305]\n",
      "epoch:32 step:25454 [D loss: 0.074960, acc: 100.00%] [G loss: 7.609252]\n",
      "epoch:32 step:25455 [D loss: 0.279698, acc: 96.88%] [G loss: 2.749053]\n",
      "epoch:32 step:25456 [D loss: 0.118495, acc: 100.00%] [G loss: 4.095271]\n",
      "epoch:32 step:25457 [D loss: 0.660427, acc: 57.03%] [G loss: 4.660745]\n",
      "epoch:32 step:25458 [D loss: 0.116219, acc: 99.22%] [G loss: 6.161243]\n",
      "epoch:32 step:25459 [D loss: 0.954422, acc: 50.78%] [G loss: 5.094789]\n",
      "epoch:32 step:25460 [D loss: 0.690960, acc: 56.25%] [G loss: 2.709312]\n",
      "epoch:32 step:25461 [D loss: 0.443655, acc: 68.75%] [G loss: 4.102613]\n",
      "epoch:32 step:25462 [D loss: 0.394640, acc: 71.09%] [G loss: 4.781905]\n",
      "epoch:32 step:25463 [D loss: 0.299414, acc: 81.25%] [G loss: 6.387531]\n",
      "epoch:32 step:25464 [D loss: 0.133324, acc: 100.00%] [G loss: 6.295505]\n",
      "epoch:32 step:25465 [D loss: 0.228128, acc: 93.75%] [G loss: 6.260359]\n",
      "epoch:32 step:25466 [D loss: 0.188707, acc: 98.44%] [G loss: 4.257650]\n",
      "epoch:32 step:25467 [D loss: 0.202529, acc: 99.22%] [G loss: 6.306698]\n",
      "epoch:32 step:25468 [D loss: 1.219454, acc: 19.53%] [G loss: 5.484911]\n",
      "epoch:32 step:25469 [D loss: 0.196774, acc: 96.09%] [G loss: 4.803623]\n",
      "epoch:32 step:25470 [D loss: 0.517203, acc: 65.62%] [G loss: 4.206543]\n",
      "epoch:32 step:25471 [D loss: 0.958197, acc: 41.41%] [G loss: 5.497934]\n",
      "epoch:32 step:25472 [D loss: 0.435308, acc: 71.88%] [G loss: 4.868602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25473 [D loss: 0.540880, acc: 73.44%] [G loss: 5.509514]\n",
      "epoch:32 step:25474 [D loss: 0.790132, acc: 54.69%] [G loss: 4.563218]\n",
      "epoch:32 step:25475 [D loss: 0.894946, acc: 50.00%] [G loss: 5.486411]\n",
      "epoch:32 step:25476 [D loss: 0.798532, acc: 53.91%] [G loss: 5.240166]\n",
      "epoch:32 step:25477 [D loss: 0.639031, acc: 61.72%] [G loss: 4.823515]\n",
      "epoch:32 step:25478 [D loss: 0.138703, acc: 99.22%] [G loss: 2.843934]\n",
      "epoch:32 step:25479 [D loss: 0.588436, acc: 60.16%] [G loss: 4.633289]\n",
      "epoch:32 step:25480 [D loss: 0.261553, acc: 96.88%] [G loss: 4.107436]\n",
      "epoch:32 step:25481 [D loss: 0.323221, acc: 87.50%] [G loss: 7.016999]\n",
      "epoch:32 step:25482 [D loss: 0.150979, acc: 96.88%] [G loss: 5.741850]\n",
      "epoch:32 step:25483 [D loss: 0.811116, acc: 56.25%] [G loss: 6.652579]\n",
      "epoch:32 step:25484 [D loss: 0.358978, acc: 79.69%] [G loss: 3.752128]\n",
      "epoch:32 step:25485 [D loss: 0.299805, acc: 89.06%] [G loss: 5.543034]\n",
      "epoch:32 step:25486 [D loss: 0.073182, acc: 100.00%] [G loss: 2.869953]\n",
      "epoch:32 step:25487 [D loss: 0.577056, acc: 69.53%] [G loss: 3.610909]\n",
      "epoch:32 step:25488 [D loss: 0.176779, acc: 97.66%] [G loss: 3.504923]\n",
      "epoch:32 step:25489 [D loss: 0.039488, acc: 100.00%] [G loss: 7.938650]\n",
      "epoch:32 step:25490 [D loss: 0.406105, acc: 79.69%] [G loss: 5.125370]\n",
      "epoch:32 step:25491 [D loss: 0.429506, acc: 87.50%] [G loss: 5.686088]\n",
      "epoch:32 step:25492 [D loss: 0.404647, acc: 81.25%] [G loss: 2.786734]\n",
      "epoch:32 step:25493 [D loss: 0.880143, acc: 42.97%] [G loss: 4.773582]\n",
      "epoch:32 step:25494 [D loss: 0.132887, acc: 100.00%] [G loss: 3.656499]\n",
      "epoch:32 step:25495 [D loss: 0.709795, acc: 59.38%] [G loss: 6.522650]\n",
      "epoch:32 step:25496 [D loss: 0.218726, acc: 96.88%] [G loss: 3.449192]\n",
      "epoch:32 step:25497 [D loss: 0.676872, acc: 61.72%] [G loss: 5.284632]\n",
      "epoch:32 step:25498 [D loss: 0.162237, acc: 98.44%] [G loss: 3.267270]\n",
      "epoch:32 step:25499 [D loss: 0.088955, acc: 100.00%] [G loss: 5.083928]\n",
      "epoch:32 step:25500 [D loss: 0.256538, acc: 92.97%] [G loss: 6.471442]\n",
      "epoch:32 step:25501 [D loss: 0.067333, acc: 100.00%] [G loss: 3.920863]\n",
      "epoch:32 step:25502 [D loss: 0.510148, acc: 76.56%] [G loss: 4.663240]\n",
      "epoch:32 step:25503 [D loss: 0.038036, acc: 100.00%] [G loss: 9.266274]\n",
      "epoch:32 step:25504 [D loss: 0.462595, acc: 74.22%] [G loss: 3.931679]\n",
      "epoch:32 step:25505 [D loss: 0.799932, acc: 53.91%] [G loss: 3.671584]\n",
      "epoch:32 step:25506 [D loss: 0.210951, acc: 95.31%] [G loss: 4.141933]\n",
      "epoch:32 step:25507 [D loss: 0.475660, acc: 71.88%] [G loss: 5.729367]\n",
      "epoch:32 step:25508 [D loss: 0.166154, acc: 99.22%] [G loss: 3.566429]\n",
      "epoch:32 step:25509 [D loss: 0.395891, acc: 72.66%] [G loss: 5.106441]\n",
      "epoch:32 step:25510 [D loss: 0.349458, acc: 92.19%] [G loss: 3.661961]\n",
      "epoch:32 step:25511 [D loss: 1.470612, acc: 46.09%] [G loss: 6.199149]\n",
      "epoch:32 step:25512 [D loss: 0.280964, acc: 97.66%] [G loss: 4.804304]\n",
      "epoch:32 step:25513 [D loss: 0.419723, acc: 76.56%] [G loss: 5.524382]\n",
      "epoch:32 step:25514 [D loss: 1.278262, acc: 19.53%] [G loss: 7.399784]\n",
      "epoch:32 step:25515 [D loss: 0.241683, acc: 97.66%] [G loss: 3.371308]\n",
      "epoch:32 step:25516 [D loss: 0.317060, acc: 95.31%] [G loss: 2.750048]\n",
      "epoch:32 step:25517 [D loss: 0.515174, acc: 75.78%] [G loss: 4.946281]\n",
      "epoch:32 step:25518 [D loss: 0.427134, acc: 85.16%] [G loss: 5.150152]\n",
      "epoch:32 step:25519 [D loss: 0.397240, acc: 83.59%] [G loss: 4.124211]\n",
      "epoch:32 step:25520 [D loss: 0.223605, acc: 93.75%] [G loss: 6.663826]\n",
      "epoch:32 step:25521 [D loss: 0.458663, acc: 80.47%] [G loss: 2.178265]\n",
      "epoch:32 step:25522 [D loss: 0.290844, acc: 90.62%] [G loss: 4.671069]\n",
      "epoch:32 step:25523 [D loss: 0.080995, acc: 100.00%] [G loss: 6.166474]\n",
      "epoch:32 step:25524 [D loss: 0.413796, acc: 87.50%] [G loss: 2.814383]\n",
      "epoch:32 step:25525 [D loss: 0.517177, acc: 63.28%] [G loss: 4.701566]\n",
      "epoch:32 step:25526 [D loss: 0.482885, acc: 74.22%] [G loss: 5.113739]\n",
      "epoch:32 step:25527 [D loss: 1.024637, acc: 34.38%] [G loss: 5.482939]\n",
      "epoch:32 step:25528 [D loss: 0.263975, acc: 91.41%] [G loss: 4.065083]\n",
      "epoch:32 step:25529 [D loss: 0.402739, acc: 75.78%] [G loss: 6.667073]\n",
      "epoch:32 step:25530 [D loss: 0.189993, acc: 96.09%] [G loss: 4.364089]\n",
      "epoch:32 step:25531 [D loss: 0.250223, acc: 92.97%] [G loss: 3.752814]\n",
      "epoch:32 step:25532 [D loss: 0.489978, acc: 69.53%] [G loss: 4.848850]\n",
      "epoch:32 step:25533 [D loss: 0.635343, acc: 61.72%] [G loss: 4.804762]\n",
      "epoch:32 step:25534 [D loss: 0.100437, acc: 100.00%] [G loss: 7.615674]\n",
      "epoch:32 step:25535 [D loss: 0.073863, acc: 100.00%] [G loss: 5.436084]\n",
      "epoch:32 step:25536 [D loss: 0.413900, acc: 81.25%] [G loss: 4.320594]\n",
      "epoch:32 step:25537 [D loss: 0.393092, acc: 85.16%] [G loss: 4.757864]\n",
      "epoch:32 step:25538 [D loss: 0.245703, acc: 93.75%] [G loss: 4.095261]\n",
      "epoch:32 step:25539 [D loss: 0.133562, acc: 99.22%] [G loss: 5.605851]\n",
      "epoch:32 step:25540 [D loss: 0.881685, acc: 47.66%] [G loss: 5.425353]\n",
      "epoch:32 step:25541 [D loss: 0.474664, acc: 76.56%] [G loss: 5.071611]\n",
      "epoch:32 step:25542 [D loss: 0.350509, acc: 81.25%] [G loss: 3.351456]\n",
      "epoch:32 step:25543 [D loss: 0.542097, acc: 74.22%] [G loss: 6.445623]\n",
      "epoch:32 step:25544 [D loss: 1.517766, acc: 13.28%] [G loss: 5.977467]\n",
      "epoch:32 step:25545 [D loss: 0.418886, acc: 85.16%] [G loss: 4.586734]\n",
      "epoch:32 step:25546 [D loss: 0.241847, acc: 97.66%] [G loss: 5.078908]\n",
      "epoch:32 step:25547 [D loss: 0.644663, acc: 55.47%] [G loss: 7.485433]\n",
      "epoch:32 step:25548 [D loss: 0.152588, acc: 100.00%] [G loss: 4.997529]\n",
      "epoch:32 step:25549 [D loss: 1.163846, acc: 50.00%] [G loss: 5.688946]\n",
      "epoch:32 step:25550 [D loss: 0.458028, acc: 82.81%] [G loss: 3.656841]\n",
      "epoch:32 step:25551 [D loss: 0.323913, acc: 82.03%] [G loss: 5.017220]\n",
      "epoch:32 step:25552 [D loss: 0.143955, acc: 98.44%] [G loss: 3.893300]\n",
      "epoch:32 step:25553 [D loss: 0.086218, acc: 97.66%] [G loss: 6.180956]\n",
      "epoch:32 step:25554 [D loss: 0.245321, acc: 95.31%] [G loss: 4.993437]\n",
      "epoch:32 step:25555 [D loss: 0.406833, acc: 89.06%] [G loss: 3.995080]\n",
      "epoch:32 step:25556 [D loss: 0.254065, acc: 93.75%] [G loss: 5.739460]\n",
      "epoch:32 step:25557 [D loss: 0.274734, acc: 90.62%] [G loss: 2.839592]\n",
      "epoch:32 step:25558 [D loss: 0.287619, acc: 93.75%] [G loss: 4.027335]\n",
      "epoch:32 step:25559 [D loss: 0.566017, acc: 73.44%] [G loss: 5.998217]\n",
      "epoch:32 step:25560 [D loss: 0.909521, acc: 42.97%] [G loss: 4.958505]\n",
      "epoch:32 step:25561 [D loss: 0.129745, acc: 99.22%] [G loss: 6.253592]\n",
      "epoch:32 step:25562 [D loss: 0.372252, acc: 90.62%] [G loss: 3.551053]\n",
      "epoch:32 step:25563 [D loss: 0.602825, acc: 63.28%] [G loss: 4.968435]\n",
      "epoch:32 step:25564 [D loss: 0.044586, acc: 100.00%] [G loss: 5.761038]\n",
      "epoch:32 step:25565 [D loss: 0.315168, acc: 93.75%] [G loss: 6.095387]\n",
      "epoch:32 step:25566 [D loss: 0.886255, acc: 39.06%] [G loss: 10.005775]\n",
      "epoch:32 step:25567 [D loss: 0.125830, acc: 100.00%] [G loss: 4.757775]\n",
      "epoch:32 step:25568 [D loss: 0.552549, acc: 64.84%] [G loss: 4.037515]\n",
      "epoch:32 step:25569 [D loss: 0.126382, acc: 98.44%] [G loss: 3.970073]\n",
      "epoch:32 step:25570 [D loss: 0.685461, acc: 57.81%] [G loss: 4.100493]\n",
      "epoch:32 step:25571 [D loss: 0.412816, acc: 86.72%] [G loss: 4.320922]\n",
      "epoch:32 step:25572 [D loss: 0.402558, acc: 77.34%] [G loss: 5.259884]\n",
      "epoch:32 step:25573 [D loss: 0.270657, acc: 96.88%] [G loss: 4.744884]\n",
      "epoch:32 step:25574 [D loss: 0.289805, acc: 87.50%] [G loss: 6.159541]\n",
      "epoch:32 step:25575 [D loss: 1.356797, acc: 45.31%] [G loss: 5.260803]\n",
      "epoch:32 step:25576 [D loss: 0.933060, acc: 50.78%] [G loss: 3.212587]\n",
      "epoch:32 step:25577 [D loss: 0.101319, acc: 100.00%] [G loss: 4.415947]\n",
      "epoch:32 step:25578 [D loss: 0.650796, acc: 59.38%] [G loss: 4.473510]\n",
      "epoch:32 step:25579 [D loss: 0.064099, acc: 100.00%] [G loss: 6.051425]\n",
      "epoch:32 step:25580 [D loss: 0.366642, acc: 88.28%] [G loss: 4.815337]\n",
      "epoch:32 step:25581 [D loss: 0.170588, acc: 98.44%] [G loss: 5.007883]\n",
      "epoch:32 step:25582 [D loss: 0.232825, acc: 97.66%] [G loss: 2.404993]\n",
      "epoch:32 step:25583 [D loss: 0.278369, acc: 95.31%] [G loss: 6.238241]\n",
      "epoch:32 step:25584 [D loss: 0.423510, acc: 88.28%] [G loss: 6.815508]\n",
      "epoch:32 step:25585 [D loss: 0.588301, acc: 57.03%] [G loss: 5.067383]\n",
      "epoch:32 step:25586 [D loss: 0.257656, acc: 89.84%] [G loss: 3.584021]\n",
      "epoch:32 step:25587 [D loss: 0.128907, acc: 100.00%] [G loss: 3.451029]\n",
      "epoch:32 step:25588 [D loss: 0.309781, acc: 89.84%] [G loss: 5.556050]\n",
      "epoch:32 step:25589 [D loss: 0.112512, acc: 99.22%] [G loss: 9.784771]\n",
      "epoch:32 step:25590 [D loss: 0.530801, acc: 59.38%] [G loss: 5.700000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25591 [D loss: 0.093976, acc: 100.00%] [G loss: 4.486124]\n",
      "epoch:32 step:25592 [D loss: 0.681997, acc: 57.81%] [G loss: 4.944301]\n",
      "epoch:32 step:25593 [D loss: 0.698792, acc: 57.81%] [G loss: 3.444585]\n",
      "epoch:32 step:25594 [D loss: 0.177381, acc: 97.66%] [G loss: 4.159216]\n",
      "epoch:32 step:25595 [D loss: 0.204526, acc: 99.22%] [G loss: 3.329126]\n",
      "epoch:32 step:25596 [D loss: 1.534685, acc: 8.59%] [G loss: 5.135528]\n",
      "epoch:32 step:25597 [D loss: 0.084749, acc: 99.22%] [G loss: 4.534162]\n",
      "epoch:32 step:25598 [D loss: 0.277605, acc: 95.31%] [G loss: 5.962039]\n",
      "epoch:32 step:25599 [D loss: 0.161103, acc: 99.22%] [G loss: 5.053134]\n",
      "epoch:32 step:25600 [D loss: 0.329733, acc: 84.38%] [G loss: 5.102719]\n",
      "epoch:32 step:25601 [D loss: 1.208210, acc: 45.31%] [G loss: 3.070856]\n",
      "epoch:32 step:25602 [D loss: 0.686042, acc: 57.03%] [G loss: 4.557372]\n",
      "epoch:32 step:25603 [D loss: 0.210613, acc: 97.66%] [G loss: 5.373554]\n",
      "epoch:32 step:25604 [D loss: 0.386574, acc: 91.41%] [G loss: 6.309525]\n",
      "epoch:32 step:25605 [D loss: 0.318446, acc: 90.62%] [G loss: 5.023700]\n",
      "epoch:32 step:25606 [D loss: 0.097291, acc: 99.22%] [G loss: 5.325759]\n",
      "epoch:32 step:25607 [D loss: 0.218344, acc: 97.66%] [G loss: 6.638186]\n",
      "epoch:32 step:25608 [D loss: 0.493306, acc: 77.34%] [G loss: 3.842140]\n",
      "epoch:32 step:25609 [D loss: 0.379429, acc: 86.72%] [G loss: 5.942488]\n",
      "epoch:32 step:25610 [D loss: 0.267435, acc: 95.31%] [G loss: 4.306557]\n",
      "epoch:32 step:25611 [D loss: 0.423153, acc: 75.78%] [G loss: 2.090883]\n",
      "epoch:32 step:25612 [D loss: 0.251826, acc: 97.66%] [G loss: 4.479485]\n",
      "epoch:32 step:25613 [D loss: 0.466374, acc: 67.97%] [G loss: 5.199505]\n",
      "epoch:32 step:25614 [D loss: 0.184972, acc: 100.00%] [G loss: 3.039768]\n",
      "epoch:32 step:25615 [D loss: 0.182037, acc: 97.66%] [G loss: 1.441196]\n",
      "epoch:32 step:25616 [D loss: 0.048438, acc: 100.00%] [G loss: 3.834236]\n",
      "epoch:32 step:25617 [D loss: 0.337633, acc: 85.94%] [G loss: 3.672569]\n",
      "epoch:32 step:25618 [D loss: 0.419213, acc: 85.94%] [G loss: 5.662063]\n",
      "epoch:32 step:25619 [D loss: 0.722474, acc: 53.91%] [G loss: 6.269732]\n",
      "epoch:32 step:25620 [D loss: 0.399278, acc: 86.72%] [G loss: 6.174298]\n",
      "epoch:32 step:25621 [D loss: 0.157416, acc: 96.88%] [G loss: 4.172226]\n",
      "epoch:32 step:25622 [D loss: 0.077266, acc: 99.22%] [G loss: 6.596798]\n",
      "epoch:32 step:25623 [D loss: 0.344003, acc: 94.53%] [G loss: 4.793954]\n",
      "epoch:32 step:25624 [D loss: 0.229363, acc: 98.44%] [G loss: 4.472241]\n",
      "epoch:32 step:25625 [D loss: 0.822456, acc: 46.88%] [G loss: 4.900976]\n",
      "epoch:32 step:25626 [D loss: 0.521787, acc: 76.56%] [G loss: 1.707300]\n",
      "epoch:32 step:25627 [D loss: 0.558940, acc: 62.50%] [G loss: 3.487476]\n",
      "epoch:32 step:25628 [D loss: 0.214886, acc: 95.31%] [G loss: 5.282127]\n",
      "epoch:32 step:25629 [D loss: 0.884897, acc: 51.56%] [G loss: 6.280403]\n",
      "epoch:32 step:25630 [D loss: 0.386085, acc: 89.84%] [G loss: 4.635564]\n",
      "epoch:32 step:25631 [D loss: 0.854831, acc: 53.91%] [G loss: 5.143242]\n",
      "epoch:32 step:25632 [D loss: 0.064681, acc: 99.22%] [G loss: 6.013865]\n",
      "epoch:32 step:25633 [D loss: 0.707176, acc: 57.03%] [G loss: 5.077431]\n",
      "epoch:32 step:25634 [D loss: 0.201003, acc: 98.44%] [G loss: 3.639763]\n",
      "epoch:32 step:25635 [D loss: 0.141611, acc: 98.44%] [G loss: 5.046447]\n",
      "epoch:32 step:25636 [D loss: 1.114982, acc: 50.78%] [G loss: 3.053558]\n",
      "epoch:32 step:25637 [D loss: 0.276661, acc: 89.06%] [G loss: 4.363510]\n",
      "epoch:32 step:25638 [D loss: 0.179530, acc: 100.00%] [G loss: 4.728690]\n",
      "epoch:32 step:25639 [D loss: 0.592417, acc: 58.59%] [G loss: 6.545025]\n",
      "epoch:32 step:25640 [D loss: 0.485618, acc: 63.28%] [G loss: 6.971201]\n",
      "epoch:32 step:25641 [D loss: 0.084546, acc: 100.00%] [G loss: 5.401530]\n",
      "epoch:32 step:25642 [D loss: 0.298155, acc: 94.53%] [G loss: 3.754384]\n",
      "epoch:32 step:25643 [D loss: 0.377123, acc: 90.62%] [G loss: 4.673559]\n",
      "epoch:32 step:25644 [D loss: 0.382990, acc: 76.56%] [G loss: 8.178625]\n",
      "epoch:32 step:25645 [D loss: 0.817444, acc: 50.78%] [G loss: 3.627308]\n",
      "epoch:32 step:25646 [D loss: 0.182802, acc: 99.22%] [G loss: 3.288724]\n",
      "epoch:32 step:25647 [D loss: 0.384012, acc: 80.47%] [G loss: 7.373397]\n",
      "epoch:32 step:25648 [D loss: 0.444871, acc: 83.59%] [G loss: 4.502614]\n",
      "epoch:32 step:25649 [D loss: 0.568108, acc: 72.66%] [G loss: 5.753167]\n",
      "epoch:32 step:25650 [D loss: 0.595713, acc: 67.19%] [G loss: 6.039559]\n",
      "epoch:32 step:25651 [D loss: 0.245578, acc: 96.09%] [G loss: 4.236923]\n",
      "epoch:32 step:25652 [D loss: 0.231446, acc: 100.00%] [G loss: 4.268513]\n",
      "epoch:32 step:25653 [D loss: 0.136523, acc: 98.44%] [G loss: 5.647950]\n",
      "epoch:32 step:25654 [D loss: 1.149175, acc: 39.06%] [G loss: 6.990825]\n",
      "epoch:32 step:25655 [D loss: 0.267138, acc: 89.84%] [G loss: 6.409264]\n",
      "epoch:32 step:25656 [D loss: 0.064083, acc: 100.00%] [G loss: 6.511893]\n",
      "epoch:32 step:25657 [D loss: 0.924528, acc: 32.81%] [G loss: 3.601886]\n",
      "epoch:32 step:25658 [D loss: 0.091187, acc: 100.00%] [G loss: 5.695602]\n",
      "epoch:32 step:25659 [D loss: 0.013813, acc: 100.00%] [G loss: 6.626652]\n",
      "epoch:32 step:25660 [D loss: 0.316527, acc: 94.53%] [G loss: 4.731889]\n",
      "epoch:32 step:25661 [D loss: 0.369155, acc: 93.75%] [G loss: 5.402456]\n",
      "epoch:32 step:25662 [D loss: 0.898636, acc: 46.88%] [G loss: 5.850775]\n",
      "epoch:32 step:25663 [D loss: 0.532379, acc: 71.88%] [G loss: 4.198641]\n",
      "epoch:32 step:25664 [D loss: 0.079692, acc: 100.00%] [G loss: 4.806182]\n",
      "epoch:32 step:25665 [D loss: 0.463097, acc: 67.97%] [G loss: 3.713798]\n",
      "epoch:32 step:25666 [D loss: 0.341852, acc: 88.28%] [G loss: 2.718344]\n",
      "epoch:32 step:25667 [D loss: 0.262991, acc: 97.66%] [G loss: 3.637108]\n",
      "epoch:32 step:25668 [D loss: 0.122585, acc: 98.44%] [G loss: 3.947269]\n",
      "epoch:32 step:25669 [D loss: 1.422476, acc: 12.50%] [G loss: 6.501154]\n",
      "epoch:32 step:25670 [D loss: 0.256579, acc: 90.62%] [G loss: 3.234404]\n",
      "epoch:32 step:25671 [D loss: 0.641963, acc: 61.72%] [G loss: 4.654341]\n",
      "epoch:32 step:25672 [D loss: 0.214771, acc: 96.88%] [G loss: 4.241049]\n",
      "epoch:32 step:25673 [D loss: 0.099512, acc: 100.00%] [G loss: 6.289761]\n",
      "epoch:32 step:25674 [D loss: 0.218160, acc: 94.53%] [G loss: 1.881615]\n",
      "epoch:32 step:25675 [D loss: 0.215625, acc: 96.09%] [G loss: 2.439693]\n",
      "epoch:32 step:25676 [D loss: 0.136580, acc: 99.22%] [G loss: 5.546892]\n",
      "epoch:32 step:25677 [D loss: 0.144949, acc: 100.00%] [G loss: 3.289656]\n",
      "epoch:32 step:25678 [D loss: 0.133403, acc: 99.22%] [G loss: 4.554198]\n",
      "epoch:32 step:25679 [D loss: 0.195441, acc: 98.44%] [G loss: 3.618743]\n",
      "epoch:32 step:25680 [D loss: 0.381665, acc: 78.91%] [G loss: 5.959967]\n",
      "epoch:32 step:25681 [D loss: 0.245794, acc: 94.53%] [G loss: 3.703456]\n",
      "epoch:32 step:25682 [D loss: 0.318974, acc: 85.94%] [G loss: 4.664759]\n",
      "epoch:32 step:25683 [D loss: 0.083701, acc: 100.00%] [G loss: 3.722097]\n",
      "epoch:32 step:25684 [D loss: 0.727230, acc: 56.25%] [G loss: 3.799981]\n",
      "epoch:32 step:25685 [D loss: 0.250138, acc: 95.31%] [G loss: 6.772479]\n",
      "epoch:32 step:25686 [D loss: 0.972526, acc: 50.00%] [G loss: 6.384058]\n",
      "epoch:32 step:25687 [D loss: 0.372315, acc: 79.69%] [G loss: 4.104605]\n",
      "epoch:32 step:25688 [D loss: 0.415463, acc: 71.09%] [G loss: 4.074218]\n",
      "epoch:32 step:25689 [D loss: 0.138703, acc: 99.22%] [G loss: 3.693582]\n",
      "epoch:32 step:25690 [D loss: 0.732092, acc: 54.69%] [G loss: 5.600785]\n",
      "epoch:32 step:25691 [D loss: 1.023777, acc: 35.16%] [G loss: 7.302888]\n",
      "epoch:32 step:25692 [D loss: 0.566446, acc: 62.50%] [G loss: 5.093963]\n",
      "epoch:32 step:25693 [D loss: 0.339233, acc: 81.25%] [G loss: 5.108029]\n",
      "epoch:32 step:25694 [D loss: 0.262496, acc: 90.62%] [G loss: 6.188564]\n",
      "epoch:32 step:25695 [D loss: 0.678701, acc: 60.94%] [G loss: 4.953838]\n",
      "epoch:32 step:25696 [D loss: 0.431477, acc: 70.31%] [G loss: 4.771786]\n",
      "epoch:32 step:25697 [D loss: 0.391173, acc: 70.31%] [G loss: 3.625826]\n",
      "epoch:32 step:25698 [D loss: 0.288107, acc: 90.62%] [G loss: 5.741596]\n",
      "epoch:32 step:25699 [D loss: 0.469766, acc: 76.56%] [G loss: 4.513442]\n",
      "epoch:32 step:25700 [D loss: 0.660646, acc: 54.69%] [G loss: 4.755093]\n",
      "epoch:32 step:25701 [D loss: 0.370184, acc: 88.28%] [G loss: 1.489425]\n",
      "epoch:32 step:25702 [D loss: 0.309602, acc: 92.19%] [G loss: 5.007877]\n",
      "epoch:32 step:25703 [D loss: 0.237372, acc: 94.53%] [G loss: 6.801232]\n",
      "epoch:32 step:25704 [D loss: 0.483071, acc: 71.88%] [G loss: 6.774177]\n",
      "epoch:32 step:25705 [D loss: 0.187634, acc: 99.22%] [G loss: 5.363665]\n",
      "epoch:32 step:25706 [D loss: 0.319268, acc: 91.41%] [G loss: 4.262789]\n",
      "epoch:32 step:25707 [D loss: 0.516843, acc: 75.00%] [G loss: 3.235025]\n",
      "epoch:32 step:25708 [D loss: 1.575852, acc: 11.72%] [G loss: 4.362271]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25709 [D loss: 0.303773, acc: 86.72%] [G loss: 4.997176]\n",
      "epoch:32 step:25710 [D loss: 0.634520, acc: 58.59%] [G loss: 3.643875]\n",
      "epoch:32 step:25711 [D loss: 0.148138, acc: 100.00%] [G loss: 3.948652]\n",
      "epoch:32 step:25712 [D loss: 1.027721, acc: 45.31%] [G loss: 4.852154]\n",
      "epoch:32 step:25713 [D loss: 0.613010, acc: 64.06%] [G loss: 2.953216]\n",
      "epoch:32 step:25714 [D loss: 0.904526, acc: 38.28%] [G loss: 5.361492]\n",
      "epoch:32 step:25715 [D loss: 0.097606, acc: 99.22%] [G loss: 8.532667]\n",
      "epoch:32 step:25716 [D loss: 0.663525, acc: 68.75%] [G loss: 5.013353]\n",
      "epoch:32 step:25717 [D loss: 0.503341, acc: 75.78%] [G loss: 3.858659]\n",
      "epoch:32 step:25718 [D loss: 0.032595, acc: 100.00%] [G loss: 6.554805]\n",
      "epoch:32 step:25719 [D loss: 0.070812, acc: 100.00%] [G loss: 2.858830]\n",
      "epoch:32 step:25720 [D loss: 0.849803, acc: 50.00%] [G loss: 6.506594]\n",
      "epoch:32 step:25721 [D loss: 0.252343, acc: 93.75%] [G loss: 2.937022]\n",
      "epoch:32 step:25722 [D loss: 0.311601, acc: 90.62%] [G loss: 4.106483]\n",
      "epoch:32 step:25723 [D loss: 0.212009, acc: 98.44%] [G loss: 4.304235]\n",
      "epoch:32 step:25724 [D loss: 0.500730, acc: 72.66%] [G loss: 6.341523]\n",
      "epoch:32 step:25725 [D loss: 0.777248, acc: 51.56%] [G loss: 3.927351]\n",
      "epoch:32 step:25726 [D loss: 0.243805, acc: 89.84%] [G loss: 5.928168]\n",
      "epoch:32 step:25727 [D loss: 0.129916, acc: 100.00%] [G loss: 6.517340]\n",
      "epoch:32 step:25728 [D loss: 0.732359, acc: 50.00%] [G loss: 3.299300]\n",
      "epoch:32 step:25729 [D loss: 0.184464, acc: 98.44%] [G loss: 5.882753]\n",
      "epoch:32 step:25730 [D loss: 0.653833, acc: 57.03%] [G loss: 7.533664]\n",
      "epoch:32 step:25731 [D loss: 0.805223, acc: 53.12%] [G loss: 4.289023]\n",
      "epoch:32 step:25732 [D loss: 0.874426, acc: 44.53%] [G loss: 6.026976]\n",
      "epoch:32 step:25733 [D loss: 0.531260, acc: 63.28%] [G loss: 5.084127]\n",
      "epoch:32 step:25734 [D loss: 0.229999, acc: 91.41%] [G loss: 5.863457]\n",
      "epoch:32 step:25735 [D loss: 0.141825, acc: 100.00%] [G loss: 2.425420]\n",
      "epoch:32 step:25736 [D loss: 0.190572, acc: 100.00%] [G loss: 4.815317]\n",
      "epoch:32 step:25737 [D loss: 0.299274, acc: 93.75%] [G loss: 5.651351]\n",
      "epoch:32 step:25738 [D loss: 0.227820, acc: 95.31%] [G loss: 4.735560]\n",
      "epoch:32 step:25739 [D loss: 0.340809, acc: 89.84%] [G loss: 6.051658]\n",
      "epoch:32 step:25740 [D loss: 0.494556, acc: 66.41%] [G loss: 5.850770]\n",
      "epoch:32 step:25741 [D loss: 0.876509, acc: 51.56%] [G loss: 6.502804]\n",
      "epoch:32 step:25742 [D loss: 0.438748, acc: 85.94%] [G loss: 3.787366]\n",
      "epoch:32 step:25743 [D loss: 0.488090, acc: 78.12%] [G loss: 4.450868]\n",
      "epoch:32 step:25744 [D loss: 0.310137, acc: 95.31%] [G loss: 4.319495]\n",
      "epoch:32 step:25745 [D loss: 0.235545, acc: 96.88%] [G loss: 5.358723]\n",
      "epoch:32 step:25746 [D loss: 0.752052, acc: 53.12%] [G loss: 4.756696]\n",
      "epoch:32 step:25747 [D loss: 1.079539, acc: 45.31%] [G loss: 3.445374]\n",
      "epoch:32 step:25748 [D loss: 0.417650, acc: 80.47%] [G loss: 4.040943]\n",
      "epoch:32 step:25749 [D loss: 0.891264, acc: 54.69%] [G loss: 6.649765]\n",
      "epoch:32 step:25750 [D loss: 0.668244, acc: 64.84%] [G loss: 3.601506]\n",
      "epoch:32 step:25751 [D loss: 0.561629, acc: 61.72%] [G loss: 4.138194]\n",
      "epoch:32 step:25752 [D loss: 0.106452, acc: 99.22%] [G loss: 6.706495]\n",
      "epoch:32 step:25753 [D loss: 0.638916, acc: 58.59%] [G loss: 4.556740]\n",
      "epoch:32 step:25754 [D loss: 0.227530, acc: 92.19%] [G loss: 5.016446]\n",
      "epoch:32 step:25755 [D loss: 0.371342, acc: 78.91%] [G loss: 3.877259]\n",
      "epoch:32 step:25756 [D loss: 0.268003, acc: 94.53%] [G loss: 3.461961]\n",
      "epoch:32 step:25757 [D loss: 0.103864, acc: 100.00%] [G loss: 5.709939]\n",
      "epoch:32 step:25758 [D loss: 1.093065, acc: 21.88%] [G loss: 5.764904]\n",
      "epoch:32 step:25759 [D loss: 0.483705, acc: 67.97%] [G loss: 4.002457]\n",
      "epoch:32 step:25760 [D loss: 0.327475, acc: 92.97%] [G loss: 5.430314]\n",
      "epoch:32 step:25761 [D loss: 1.012669, acc: 50.00%] [G loss: 4.715087]\n",
      "epoch:32 step:25762 [D loss: 0.265014, acc: 92.97%] [G loss: 5.285496]\n",
      "epoch:32 step:25763 [D loss: 0.236117, acc: 96.88%] [G loss: 3.373495]\n",
      "epoch:32 step:25764 [D loss: 0.693037, acc: 60.16%] [G loss: 5.825200]\n",
      "epoch:32 step:25765 [D loss: 0.409102, acc: 72.66%] [G loss: 5.869488]\n",
      "epoch:32 step:25766 [D loss: 0.181404, acc: 99.22%] [G loss: 4.779755]\n",
      "epoch:32 step:25767 [D loss: 0.907046, acc: 52.34%] [G loss: 6.440803]\n",
      "epoch:32 step:25768 [D loss: 0.174739, acc: 98.44%] [G loss: 3.937921]\n",
      "epoch:32 step:25769 [D loss: 1.030907, acc: 50.00%] [G loss: 2.478373]\n",
      "epoch:32 step:25770 [D loss: 1.492273, acc: 3.12%] [G loss: 3.918714]\n",
      "epoch:32 step:25771 [D loss: 0.722600, acc: 51.56%] [G loss: 6.063546]\n",
      "epoch:32 step:25772 [D loss: 0.268647, acc: 96.88%] [G loss: 7.214593]\n",
      "epoch:32 step:25773 [D loss: 0.338462, acc: 90.62%] [G loss: 4.101221]\n",
      "epoch:33 step:25774 [D loss: 0.194543, acc: 98.44%] [G loss: 4.447089]\n",
      "epoch:33 step:25775 [D loss: 0.413390, acc: 85.94%] [G loss: 4.881072]\n",
      "epoch:33 step:25776 [D loss: 0.688319, acc: 63.28%] [G loss: 6.637114]\n",
      "epoch:33 step:25777 [D loss: 0.814884, acc: 55.47%] [G loss: 4.657614]\n",
      "epoch:33 step:25778 [D loss: 0.348398, acc: 86.72%] [G loss: 7.826487]\n",
      "epoch:33 step:25779 [D loss: 0.542477, acc: 69.53%] [G loss: 6.108738]\n",
      "epoch:33 step:25780 [D loss: 0.206914, acc: 96.09%] [G loss: 3.764051]\n",
      "epoch:33 step:25781 [D loss: 0.561966, acc: 70.31%] [G loss: 4.578867]\n",
      "epoch:33 step:25782 [D loss: 0.229633, acc: 96.09%] [G loss: 6.862182]\n",
      "epoch:33 step:25783 [D loss: 0.490283, acc: 79.69%] [G loss: 4.856110]\n",
      "epoch:33 step:25784 [D loss: 0.180382, acc: 98.44%] [G loss: 6.000497]\n",
      "epoch:33 step:25785 [D loss: 0.222922, acc: 97.66%] [G loss: 5.823375]\n",
      "epoch:33 step:25786 [D loss: 0.097283, acc: 100.00%] [G loss: 2.754867]\n",
      "epoch:33 step:25787 [D loss: 0.071630, acc: 100.00%] [G loss: 3.517530]\n",
      "epoch:33 step:25788 [D loss: 0.668282, acc: 57.81%] [G loss: 6.779250]\n",
      "epoch:33 step:25789 [D loss: 0.087256, acc: 100.00%] [G loss: 5.415082]\n",
      "epoch:33 step:25790 [D loss: 0.688284, acc: 57.81%] [G loss: 3.147926]\n",
      "epoch:33 step:25791 [D loss: 0.427945, acc: 76.56%] [G loss: 4.411059]\n",
      "epoch:33 step:25792 [D loss: 0.077445, acc: 100.00%] [G loss: 3.873562]\n",
      "epoch:33 step:25793 [D loss: 0.656384, acc: 58.59%] [G loss: 3.649702]\n",
      "epoch:33 step:25794 [D loss: 0.810399, acc: 50.78%] [G loss: 5.710203]\n",
      "epoch:33 step:25795 [D loss: 0.381726, acc: 88.28%] [G loss: 5.365498]\n",
      "epoch:33 step:25796 [D loss: 0.250033, acc: 96.88%] [G loss: 2.701436]\n",
      "epoch:33 step:25797 [D loss: 0.407798, acc: 82.03%] [G loss: 4.200240]\n",
      "epoch:33 step:25798 [D loss: 0.679284, acc: 60.16%] [G loss: 2.144046]\n",
      "epoch:33 step:25799 [D loss: 0.177913, acc: 96.88%] [G loss: 2.961370]\n",
      "epoch:33 step:25800 [D loss: 0.415642, acc: 78.91%] [G loss: 5.849386]\n",
      "epoch:33 step:25801 [D loss: 0.663481, acc: 57.81%] [G loss: 4.393447]\n",
      "epoch:33 step:25802 [D loss: 0.146743, acc: 97.66%] [G loss: 6.393680]\n",
      "epoch:33 step:25803 [D loss: 0.052338, acc: 100.00%] [G loss: 6.124825]\n",
      "epoch:33 step:25804 [D loss: 0.103776, acc: 98.44%] [G loss: 4.353794]\n",
      "epoch:33 step:25805 [D loss: 0.879051, acc: 47.66%] [G loss: 3.958660]\n",
      "epoch:33 step:25806 [D loss: 0.165707, acc: 100.00%] [G loss: 4.776853]\n",
      "epoch:33 step:25807 [D loss: 0.096371, acc: 99.22%] [G loss: 8.305057]\n",
      "epoch:33 step:25808 [D loss: 0.587285, acc: 68.75%] [G loss: 4.544473]\n",
      "epoch:33 step:25809 [D loss: 1.159589, acc: 48.44%] [G loss: 4.935412]\n",
      "epoch:33 step:25810 [D loss: 0.240424, acc: 96.88%] [G loss: 3.078897]\n",
      "epoch:33 step:25811 [D loss: 0.852354, acc: 53.91%] [G loss: 8.032053]\n",
      "epoch:33 step:25812 [D loss: 0.631783, acc: 67.97%] [G loss: 5.288929]\n",
      "epoch:33 step:25813 [D loss: 0.332841, acc: 85.94%] [G loss: 5.208141]\n",
      "epoch:33 step:25814 [D loss: 0.487708, acc: 76.56%] [G loss: 5.617270]\n",
      "epoch:33 step:25815 [D loss: 1.030330, acc: 32.81%] [G loss: 4.426075]\n",
      "epoch:33 step:25816 [D loss: 0.128446, acc: 99.22%] [G loss: 7.796728]\n",
      "epoch:33 step:25817 [D loss: 0.462820, acc: 71.88%] [G loss: 4.666316]\n",
      "epoch:33 step:25818 [D loss: 0.289274, acc: 86.72%] [G loss: 3.896117]\n",
      "epoch:33 step:25819 [D loss: 0.202092, acc: 93.75%] [G loss: 3.867789]\n",
      "epoch:33 step:25820 [D loss: 0.807542, acc: 50.78%] [G loss: 5.678744]\n",
      "epoch:33 step:25821 [D loss: 0.520757, acc: 69.53%] [G loss: 6.977014]\n",
      "epoch:33 step:25822 [D loss: 0.451458, acc: 87.50%] [G loss: 2.785469]\n",
      "epoch:33 step:25823 [D loss: 0.185718, acc: 100.00%] [G loss: 3.542817]\n",
      "epoch:33 step:25824 [D loss: 0.336498, acc: 86.72%] [G loss: 5.909158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:25825 [D loss: 0.978947, acc: 44.53%] [G loss: 3.480178]\n",
      "epoch:33 step:25826 [D loss: 0.369156, acc: 85.94%] [G loss: 4.340005]\n",
      "epoch:33 step:25827 [D loss: 0.964990, acc: 44.53%] [G loss: 6.225416]\n",
      "epoch:33 step:25828 [D loss: 0.465028, acc: 81.25%] [G loss: 2.887459]\n",
      "epoch:33 step:25829 [D loss: 0.839754, acc: 51.56%] [G loss: 3.216822]\n",
      "epoch:33 step:25830 [D loss: 0.812414, acc: 53.91%] [G loss: 4.402959]\n",
      "epoch:33 step:25831 [D loss: 0.556817, acc: 67.19%] [G loss: 5.601910]\n",
      "epoch:33 step:25832 [D loss: 0.379566, acc: 81.25%] [G loss: 4.869380]\n",
      "epoch:33 step:25833 [D loss: 0.199480, acc: 95.31%] [G loss: 3.529306]\n",
      "epoch:33 step:25834 [D loss: 0.238769, acc: 92.19%] [G loss: 6.673296]\n",
      "epoch:33 step:25835 [D loss: 0.310566, acc: 92.19%] [G loss: 4.055319]\n",
      "epoch:33 step:25836 [D loss: 0.171323, acc: 97.66%] [G loss: 8.063532]\n",
      "epoch:33 step:25837 [D loss: 0.442581, acc: 72.66%] [G loss: 4.406950]\n",
      "epoch:33 step:25838 [D loss: 0.803065, acc: 49.22%] [G loss: 6.116508]\n",
      "epoch:33 step:25839 [D loss: 0.066840, acc: 100.00%] [G loss: 6.687365]\n",
      "epoch:33 step:25840 [D loss: 1.218868, acc: 35.94%] [G loss: 3.155944]\n",
      "epoch:33 step:25841 [D loss: 0.747840, acc: 53.91%] [G loss: 4.196476]\n",
      "epoch:33 step:25842 [D loss: 0.083806, acc: 100.00%] [G loss: 5.260822]\n",
      "epoch:33 step:25843 [D loss: 1.115317, acc: 48.44%] [G loss: 3.568953]\n",
      "epoch:33 step:25844 [D loss: 0.343400, acc: 82.03%] [G loss: 5.556225]\n",
      "epoch:33 step:25845 [D loss: 0.688320, acc: 58.59%] [G loss: 2.330186]\n",
      "epoch:33 step:25846 [D loss: 0.631603, acc: 62.50%] [G loss: 5.474864]\n",
      "epoch:33 step:25847 [D loss: 0.562069, acc: 74.22%] [G loss: 4.205353]\n",
      "epoch:33 step:25848 [D loss: 0.224120, acc: 95.31%] [G loss: 4.965322]\n",
      "epoch:33 step:25849 [D loss: 0.151329, acc: 97.66%] [G loss: 3.142009]\n",
      "epoch:33 step:25850 [D loss: 0.883480, acc: 51.56%] [G loss: 4.634874]\n",
      "epoch:33 step:25851 [D loss: 0.894767, acc: 52.34%] [G loss: 4.848264]\n",
      "epoch:33 step:25852 [D loss: 0.237049, acc: 96.09%] [G loss: 3.681189]\n",
      "epoch:33 step:25853 [D loss: 0.082353, acc: 98.44%] [G loss: 3.127625]\n",
      "epoch:33 step:25854 [D loss: 0.848992, acc: 42.97%] [G loss: 6.217328]\n",
      "epoch:33 step:25855 [D loss: 0.960413, acc: 28.12%] [G loss: 5.697425]\n",
      "epoch:33 step:25856 [D loss: 0.195092, acc: 97.66%] [G loss: 3.754797]\n",
      "epoch:33 step:25857 [D loss: 1.024667, acc: 32.03%] [G loss: 4.793999]\n",
      "epoch:33 step:25858 [D loss: 0.244432, acc: 96.88%] [G loss: 4.649142]\n",
      "epoch:33 step:25859 [D loss: 0.865455, acc: 50.00%] [G loss: 6.278466]\n",
      "epoch:33 step:25860 [D loss: 0.380112, acc: 89.06%] [G loss: 3.903577]\n",
      "epoch:33 step:25861 [D loss: 0.278063, acc: 90.62%] [G loss: 4.329294]\n",
      "epoch:33 step:25862 [D loss: 0.386112, acc: 73.44%] [G loss: 3.933553]\n",
      "epoch:33 step:25863 [D loss: 0.295988, acc: 85.16%] [G loss: 5.973048]\n",
      "epoch:33 step:25864 [D loss: 0.218655, acc: 93.75%] [G loss: 5.439837]\n",
      "epoch:33 step:25865 [D loss: 0.089370, acc: 98.44%] [G loss: 7.762716]\n",
      "epoch:33 step:25866 [D loss: 0.046834, acc: 100.00%] [G loss: 3.714240]\n",
      "epoch:33 step:25867 [D loss: 0.077429, acc: 100.00%] [G loss: 3.888558]\n",
      "epoch:33 step:25868 [D loss: 0.342990, acc: 81.25%] [G loss: 3.466092]\n",
      "epoch:33 step:25869 [D loss: 0.376063, acc: 87.50%] [G loss: 4.175982]\n",
      "epoch:33 step:25870 [D loss: 0.164650, acc: 97.66%] [G loss: 2.447191]\n",
      "epoch:33 step:25871 [D loss: 0.173428, acc: 98.44%] [G loss: 3.494773]\n",
      "epoch:33 step:25872 [D loss: 0.444459, acc: 66.41%] [G loss: 4.993008]\n",
      "epoch:33 step:25873 [D loss: 0.151269, acc: 96.88%] [G loss: 3.787852]\n",
      "epoch:33 step:25874 [D loss: 1.083840, acc: 14.84%] [G loss: 5.020216]\n",
      "epoch:33 step:25875 [D loss: 0.522758, acc: 69.53%] [G loss: 4.412808]\n",
      "epoch:33 step:25876 [D loss: 0.368721, acc: 85.94%] [G loss: 4.234735]\n",
      "epoch:33 step:25877 [D loss: 0.151393, acc: 96.88%] [G loss: 4.622707]\n",
      "epoch:33 step:25878 [D loss: 0.222491, acc: 96.88%] [G loss: 3.020676]\n",
      "epoch:33 step:25879 [D loss: 0.162799, acc: 99.22%] [G loss: 4.719892]\n",
      "epoch:33 step:25880 [D loss: 0.189222, acc: 95.31%] [G loss: 5.026349]\n",
      "epoch:33 step:25881 [D loss: 0.423873, acc: 84.38%] [G loss: 3.921776]\n",
      "epoch:33 step:25882 [D loss: 0.556685, acc: 68.75%] [G loss: 5.317924]\n",
      "epoch:33 step:25883 [D loss: 1.630603, acc: 44.53%] [G loss: 3.122876]\n",
      "epoch:33 step:25884 [D loss: 0.228813, acc: 98.44%] [G loss: 2.754788]\n",
      "epoch:33 step:25885 [D loss: 0.238079, acc: 95.31%] [G loss: 6.560303]\n",
      "epoch:33 step:25886 [D loss: 0.096310, acc: 99.22%] [G loss: 5.260710]\n",
      "epoch:33 step:25887 [D loss: 0.094747, acc: 99.22%] [G loss: 4.096305]\n",
      "epoch:33 step:25888 [D loss: 1.195584, acc: 24.22%] [G loss: 4.283794]\n",
      "epoch:33 step:25889 [D loss: 0.343772, acc: 89.84%] [G loss: 2.929787]\n",
      "epoch:33 step:25890 [D loss: 0.257011, acc: 96.09%] [G loss: 2.628495]\n",
      "epoch:33 step:25891 [D loss: 0.594573, acc: 60.94%] [G loss: 4.047285]\n",
      "epoch:33 step:25892 [D loss: 0.385426, acc: 83.59%] [G loss: 4.438338]\n",
      "epoch:33 step:25893 [D loss: 0.275506, acc: 94.53%] [G loss: 4.647509]\n",
      "epoch:33 step:25894 [D loss: 0.334575, acc: 82.03%] [G loss: 6.065049]\n",
      "epoch:33 step:25895 [D loss: 0.016558, acc: 100.00%] [G loss: 8.228660]\n",
      "epoch:33 step:25896 [D loss: 0.975656, acc: 50.00%] [G loss: 3.167019]\n",
      "epoch:33 step:25897 [D loss: 0.369315, acc: 92.97%] [G loss: 5.793539]\n",
      "epoch:33 step:25898 [D loss: 0.322352, acc: 87.50%] [G loss: 2.100944]\n",
      "epoch:33 step:25899 [D loss: 0.550361, acc: 75.00%] [G loss: 6.850690]\n",
      "epoch:33 step:25900 [D loss: 0.102013, acc: 100.00%] [G loss: 5.559562]\n",
      "epoch:33 step:25901 [D loss: 0.158930, acc: 100.00%] [G loss: 4.487430]\n",
      "epoch:33 step:25902 [D loss: 0.434317, acc: 85.16%] [G loss: 3.891982]\n",
      "epoch:33 step:25903 [D loss: 0.466713, acc: 75.00%] [G loss: 2.454323]\n",
      "epoch:33 step:25904 [D loss: 0.360808, acc: 82.03%] [G loss: 4.113293]\n",
      "epoch:33 step:25905 [D loss: 0.024087, acc: 100.00%] [G loss: 6.053376]\n",
      "epoch:33 step:25906 [D loss: 0.057152, acc: 100.00%] [G loss: 5.891704]\n",
      "epoch:33 step:25907 [D loss: 0.280579, acc: 96.88%] [G loss: 3.864266]\n",
      "epoch:33 step:25908 [D loss: 0.795139, acc: 54.69%] [G loss: 7.229992]\n",
      "epoch:33 step:25909 [D loss: 0.345377, acc: 81.25%] [G loss: 5.374685]\n",
      "epoch:33 step:25910 [D loss: 0.157029, acc: 100.00%] [G loss: 4.794351]\n",
      "epoch:33 step:25911 [D loss: 0.851272, acc: 45.31%] [G loss: 4.250088]\n",
      "epoch:33 step:25912 [D loss: 0.349551, acc: 87.50%] [G loss: 4.140137]\n",
      "epoch:33 step:25913 [D loss: 0.721992, acc: 55.47%] [G loss: 3.975557]\n",
      "epoch:33 step:25914 [D loss: 0.638749, acc: 63.28%] [G loss: 4.418767]\n",
      "epoch:33 step:25915 [D loss: 0.313396, acc: 87.50%] [G loss: 3.566913]\n",
      "epoch:33 step:25916 [D loss: 0.771839, acc: 53.12%] [G loss: 3.960594]\n",
      "epoch:33 step:25917 [D loss: 0.153515, acc: 99.22%] [G loss: 3.975368]\n",
      "epoch:33 step:25918 [D loss: 0.513810, acc: 70.31%] [G loss: 4.478379]\n",
      "epoch:33 step:25919 [D loss: 0.141988, acc: 99.22%] [G loss: 4.432459]\n",
      "epoch:33 step:25920 [D loss: 0.207449, acc: 91.41%] [G loss: 3.948158]\n",
      "epoch:33 step:25921 [D loss: 0.537934, acc: 65.62%] [G loss: 3.134345]\n",
      "epoch:33 step:25922 [D loss: 0.547770, acc: 71.88%] [G loss: 3.507598]\n",
      "epoch:33 step:25923 [D loss: 0.349390, acc: 92.19%] [G loss: 3.908372]\n",
      "epoch:33 step:25924 [D loss: 0.242177, acc: 94.53%] [G loss: 4.454363]\n",
      "epoch:33 step:25925 [D loss: 0.164263, acc: 99.22%] [G loss: 4.888687]\n",
      "epoch:33 step:25926 [D loss: 0.150196, acc: 96.88%] [G loss: 3.812034]\n",
      "epoch:33 step:25927 [D loss: 0.097485, acc: 100.00%] [G loss: 4.137862]\n",
      "epoch:33 step:25928 [D loss: 1.030692, acc: 50.00%] [G loss: 4.788296]\n",
      "epoch:33 step:25929 [D loss: 0.179534, acc: 97.66%] [G loss: 4.026219]\n",
      "epoch:33 step:25930 [D loss: 0.187119, acc: 96.09%] [G loss: 4.060701]\n",
      "epoch:33 step:25931 [D loss: 0.534009, acc: 71.88%] [G loss: 4.921057]\n",
      "epoch:33 step:25932 [D loss: 0.124525, acc: 98.44%] [G loss: 3.867800]\n",
      "epoch:33 step:25933 [D loss: 0.267459, acc: 94.53%] [G loss: 4.992062]\n",
      "epoch:33 step:25934 [D loss: 0.436599, acc: 85.16%] [G loss: 5.915619]\n",
      "epoch:33 step:25935 [D loss: 0.154091, acc: 99.22%] [G loss: 3.196687]\n",
      "epoch:33 step:25936 [D loss: 0.167742, acc: 98.44%] [G loss: 3.642810]\n",
      "epoch:33 step:25937 [D loss: 0.421203, acc: 74.22%] [G loss: 3.992431]\n",
      "epoch:33 step:25938 [D loss: 0.168629, acc: 99.22%] [G loss: 3.660645]\n",
      "epoch:33 step:25939 [D loss: 0.808336, acc: 42.19%] [G loss: 4.982168]\n",
      "epoch:33 step:25940 [D loss: 0.263498, acc: 94.53%] [G loss: 3.421009]\n",
      "epoch:33 step:25941 [D loss: 0.427995, acc: 75.78%] [G loss: 5.436350]\n",
      "epoch:33 step:25942 [D loss: 0.458578, acc: 71.09%] [G loss: 3.333524]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:25943 [D loss: 0.317608, acc: 85.94%] [G loss: 5.607640]\n",
      "epoch:33 step:25944 [D loss: 0.559029, acc: 67.97%] [G loss: 4.600478]\n",
      "epoch:33 step:25945 [D loss: 0.790262, acc: 46.88%] [G loss: 3.878272]\n",
      "epoch:33 step:25946 [D loss: 0.117277, acc: 100.00%] [G loss: 4.701816]\n",
      "epoch:33 step:25947 [D loss: 0.290084, acc: 86.72%] [G loss: 5.748581]\n",
      "epoch:33 step:25948 [D loss: 0.071476, acc: 100.00%] [G loss: 8.141389]\n",
      "epoch:33 step:25949 [D loss: 0.102698, acc: 100.00%] [G loss: 4.135981]\n",
      "epoch:33 step:25950 [D loss: 0.310014, acc: 89.84%] [G loss: 4.581765]\n",
      "epoch:33 step:25951 [D loss: 0.128995, acc: 97.66%] [G loss: 4.448745]\n",
      "epoch:33 step:25952 [D loss: 0.467084, acc: 81.25%] [G loss: 3.164360]\n",
      "epoch:33 step:25953 [D loss: 0.594254, acc: 62.50%] [G loss: 2.885856]\n",
      "epoch:33 step:25954 [D loss: 0.587352, acc: 61.72%] [G loss: 7.800313]\n",
      "epoch:33 step:25955 [D loss: 0.210254, acc: 99.22%] [G loss: 4.241572]\n",
      "epoch:33 step:25956 [D loss: 1.061596, acc: 39.84%] [G loss: 7.289319]\n",
      "epoch:33 step:25957 [D loss: 0.356078, acc: 80.47%] [G loss: 5.381332]\n",
      "epoch:33 step:25958 [D loss: 0.204599, acc: 98.44%] [G loss: 2.554652]\n",
      "epoch:33 step:25959 [D loss: 0.091769, acc: 100.00%] [G loss: 2.658407]\n",
      "epoch:33 step:25960 [D loss: 0.509645, acc: 68.75%] [G loss: 3.019989]\n",
      "epoch:33 step:25961 [D loss: 0.353439, acc: 85.16%] [G loss: 4.711267]\n",
      "epoch:33 step:25962 [D loss: 0.069906, acc: 100.00%] [G loss: 7.517897]\n",
      "epoch:33 step:25963 [D loss: 0.832559, acc: 42.19%] [G loss: 2.998732]\n",
      "epoch:33 step:25964 [D loss: 1.048513, acc: 29.69%] [G loss: 6.449293]\n",
      "epoch:33 step:25965 [D loss: 0.629523, acc: 64.84%] [G loss: 4.590217]\n",
      "epoch:33 step:25966 [D loss: 1.164015, acc: 29.69%] [G loss: 3.371863]\n",
      "epoch:33 step:25967 [D loss: 0.214378, acc: 96.09%] [G loss: 4.874913]\n",
      "epoch:33 step:25968 [D loss: 0.352335, acc: 87.50%] [G loss: 4.199924]\n",
      "epoch:33 step:25969 [D loss: 2.036563, acc: 4.69%] [G loss: 5.366578]\n",
      "epoch:33 step:25970 [D loss: 0.470799, acc: 72.66%] [G loss: 4.942774]\n",
      "epoch:33 step:25971 [D loss: 0.247546, acc: 96.09%] [G loss: 5.929163]\n",
      "epoch:33 step:25972 [D loss: 0.880754, acc: 53.12%] [G loss: 6.449837]\n",
      "epoch:33 step:25973 [D loss: 0.647465, acc: 60.94%] [G loss: 4.864015]\n",
      "epoch:33 step:25974 [D loss: 0.198002, acc: 97.66%] [G loss: 4.147327]\n",
      "epoch:33 step:25975 [D loss: 0.597577, acc: 68.75%] [G loss: 3.482582]\n",
      "epoch:33 step:25976 [D loss: 0.189101, acc: 99.22%] [G loss: 6.617201]\n",
      "epoch:33 step:25977 [D loss: 0.178463, acc: 100.00%] [G loss: 4.410727]\n",
      "epoch:33 step:25978 [D loss: 0.162372, acc: 99.22%] [G loss: 5.035900]\n",
      "epoch:33 step:25979 [D loss: 1.080857, acc: 30.47%] [G loss: 5.461926]\n",
      "epoch:33 step:25980 [D loss: 0.295519, acc: 84.38%] [G loss: 3.393513]\n",
      "epoch:33 step:25981 [D loss: 0.137914, acc: 98.44%] [G loss: 7.235928]\n",
      "epoch:33 step:25982 [D loss: 0.340739, acc: 91.41%] [G loss: 2.997963]\n",
      "epoch:33 step:25983 [D loss: 0.415224, acc: 84.38%] [G loss: 4.467246]\n",
      "epoch:33 step:25984 [D loss: 0.064749, acc: 100.00%] [G loss: 3.014515]\n",
      "epoch:33 step:25985 [D loss: 0.302042, acc: 92.19%] [G loss: 5.666190]\n",
      "epoch:33 step:25986 [D loss: 0.231198, acc: 95.31%] [G loss: 4.210769]\n",
      "epoch:33 step:25987 [D loss: 0.043315, acc: 100.00%] [G loss: 4.174389]\n",
      "epoch:33 step:25988 [D loss: 0.703285, acc: 53.91%] [G loss: 3.972904]\n",
      "epoch:33 step:25989 [D loss: 0.250544, acc: 97.66%] [G loss: 4.280619]\n",
      "epoch:33 step:25990 [D loss: 1.400407, acc: 50.00%] [G loss: 3.156170]\n",
      "epoch:33 step:25991 [D loss: 0.122080, acc: 99.22%] [G loss: 4.820035]\n",
      "epoch:33 step:25992 [D loss: 0.585842, acc: 71.88%] [G loss: 3.191737]\n",
      "epoch:33 step:25993 [D loss: 0.604851, acc: 59.38%] [G loss: 7.050111]\n",
      "epoch:33 step:25994 [D loss: 0.628485, acc: 57.03%] [G loss: 2.951735]\n",
      "epoch:33 step:25995 [D loss: 0.265368, acc: 95.31%] [G loss: 3.743423]\n",
      "epoch:33 step:25996 [D loss: 0.307180, acc: 94.53%] [G loss: 4.491518]\n",
      "epoch:33 step:25997 [D loss: 0.829679, acc: 41.41%] [G loss: 4.849826]\n",
      "epoch:33 step:25998 [D loss: 0.623467, acc: 67.19%] [G loss: 3.627008]\n",
      "epoch:33 step:25999 [D loss: 0.633879, acc: 59.38%] [G loss: 4.110519]\n",
      "epoch:33 step:26000 [D loss: 0.152563, acc: 100.00%] [G loss: 8.423459]\n",
      "epoch:33 step:26001 [D loss: 0.839673, acc: 42.97%] [G loss: 6.141910]\n",
      "epoch:33 step:26002 [D loss: 0.449903, acc: 88.28%] [G loss: 4.391561]\n",
      "epoch:33 step:26003 [D loss: 0.149333, acc: 98.44%] [G loss: 3.599991]\n",
      "epoch:33 step:26004 [D loss: 0.321415, acc: 92.97%] [G loss: 6.615208]\n",
      "epoch:33 step:26005 [D loss: 1.884637, acc: 16.41%] [G loss: 3.347894]\n",
      "epoch:33 step:26006 [D loss: 0.237267, acc: 95.31%] [G loss: 2.887911]\n",
      "epoch:33 step:26007 [D loss: 0.191890, acc: 100.00%] [G loss: 3.053691]\n",
      "epoch:33 step:26008 [D loss: 0.603393, acc: 61.72%] [G loss: 5.178444]\n",
      "epoch:33 step:26009 [D loss: 0.265583, acc: 98.44%] [G loss: 2.674827]\n",
      "epoch:33 step:26010 [D loss: 0.192220, acc: 98.44%] [G loss: 5.133613]\n",
      "epoch:33 step:26011 [D loss: 0.812167, acc: 52.34%] [G loss: 5.599599]\n",
      "epoch:33 step:26012 [D loss: 0.213772, acc: 94.53%] [G loss: 3.675712]\n",
      "epoch:33 step:26013 [D loss: 0.229711, acc: 92.97%] [G loss: 5.037293]\n",
      "epoch:33 step:26014 [D loss: 0.195134, acc: 97.66%] [G loss: 3.377486]\n",
      "epoch:33 step:26015 [D loss: 0.740729, acc: 53.12%] [G loss: 5.268649]\n",
      "epoch:33 step:26016 [D loss: 0.216341, acc: 96.88%] [G loss: 4.713033]\n",
      "epoch:33 step:26017 [D loss: 0.055605, acc: 100.00%] [G loss: 4.773275]\n",
      "epoch:33 step:26018 [D loss: 0.870862, acc: 43.75%] [G loss: 5.640412]\n",
      "epoch:33 step:26019 [D loss: 0.473969, acc: 76.56%] [G loss: 3.383908]\n",
      "epoch:33 step:26020 [D loss: 0.956319, acc: 40.62%] [G loss: 4.361823]\n",
      "epoch:33 step:26021 [D loss: 0.153372, acc: 95.31%] [G loss: 2.764909]\n",
      "epoch:33 step:26022 [D loss: 0.069578, acc: 100.00%] [G loss: 8.077154]\n",
      "epoch:33 step:26023 [D loss: 0.044441, acc: 100.00%] [G loss: 5.849027]\n",
      "epoch:33 step:26024 [D loss: 0.038898, acc: 100.00%] [G loss: 3.855859]\n",
      "epoch:33 step:26025 [D loss: 0.574258, acc: 62.50%] [G loss: 7.639604]\n",
      "epoch:33 step:26026 [D loss: 0.673138, acc: 58.59%] [G loss: 3.446074]\n",
      "epoch:33 step:26027 [D loss: 0.170581, acc: 97.66%] [G loss: 5.012265]\n",
      "epoch:33 step:26028 [D loss: 0.228182, acc: 92.97%] [G loss: 4.788023]\n",
      "epoch:33 step:26029 [D loss: 0.958399, acc: 50.78%] [G loss: 3.937926]\n",
      "epoch:33 step:26030 [D loss: 0.448620, acc: 74.22%] [G loss: 4.410821]\n",
      "epoch:33 step:26031 [D loss: 0.920105, acc: 44.53%] [G loss: 5.648583]\n",
      "epoch:33 step:26032 [D loss: 0.263812, acc: 98.44%] [G loss: 4.404484]\n",
      "epoch:33 step:26033 [D loss: 0.444546, acc: 72.66%] [G loss: 3.723709]\n",
      "epoch:33 step:26034 [D loss: 0.717647, acc: 54.69%] [G loss: 5.449856]\n",
      "epoch:33 step:26035 [D loss: 0.545723, acc: 69.53%] [G loss: 6.527528]\n",
      "epoch:33 step:26036 [D loss: 0.350072, acc: 81.25%] [G loss: 8.472640]\n",
      "epoch:33 step:26037 [D loss: 1.025375, acc: 22.66%] [G loss: 4.208697]\n",
      "epoch:33 step:26038 [D loss: 1.062691, acc: 23.44%] [G loss: 5.206314]\n",
      "epoch:33 step:26039 [D loss: 0.199263, acc: 98.44%] [G loss: 4.754366]\n",
      "epoch:33 step:26040 [D loss: 1.198814, acc: 15.62%] [G loss: 3.430158]\n",
      "epoch:33 step:26041 [D loss: 0.750219, acc: 50.78%] [G loss: 5.000463]\n",
      "epoch:33 step:26042 [D loss: 0.607700, acc: 57.81%] [G loss: 5.593381]\n",
      "epoch:33 step:26043 [D loss: 0.420573, acc: 85.94%] [G loss: 4.582056]\n",
      "epoch:33 step:26044 [D loss: 0.549184, acc: 71.09%] [G loss: 2.952673]\n",
      "epoch:33 step:26045 [D loss: 0.181257, acc: 98.44%] [G loss: 4.329246]\n",
      "epoch:33 step:26046 [D loss: 0.545507, acc: 73.44%] [G loss: 2.537221]\n",
      "epoch:33 step:26047 [D loss: 0.573918, acc: 67.19%] [G loss: 4.833246]\n",
      "epoch:33 step:26048 [D loss: 0.378374, acc: 76.56%] [G loss: 4.096222]\n",
      "epoch:33 step:26049 [D loss: 0.174203, acc: 96.09%] [G loss: 3.077315]\n",
      "epoch:33 step:26050 [D loss: 0.426798, acc: 71.09%] [G loss: 4.426329]\n",
      "epoch:33 step:26051 [D loss: 0.528080, acc: 58.59%] [G loss: 6.432648]\n",
      "epoch:33 step:26052 [D loss: 0.328682, acc: 92.19%] [G loss: 3.607345]\n",
      "epoch:33 step:26053 [D loss: 1.070679, acc: 33.59%] [G loss: 6.154646]\n",
      "epoch:33 step:26054 [D loss: 0.334104, acc: 93.75%] [G loss: 4.231896]\n",
      "epoch:33 step:26055 [D loss: 0.230378, acc: 98.44%] [G loss: 2.617226]\n",
      "epoch:33 step:26056 [D loss: 0.519806, acc: 70.31%] [G loss: 3.878162]\n",
      "epoch:33 step:26057 [D loss: 0.201168, acc: 96.09%] [G loss: 3.513252]\n",
      "epoch:33 step:26058 [D loss: 0.214911, acc: 99.22%] [G loss: 4.032527]\n",
      "epoch:33 step:26059 [D loss: 0.963772, acc: 32.03%] [G loss: 3.985930]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26060 [D loss: 0.299855, acc: 92.97%] [G loss: 3.666650]\n",
      "epoch:33 step:26061 [D loss: 0.207130, acc: 96.09%] [G loss: 5.665446]\n",
      "epoch:33 step:26062 [D loss: 0.081883, acc: 100.00%] [G loss: 5.947296]\n",
      "epoch:33 step:26063 [D loss: 0.452198, acc: 75.78%] [G loss: 4.527362]\n",
      "epoch:33 step:26064 [D loss: 0.461082, acc: 88.28%] [G loss: 4.300402]\n",
      "epoch:33 step:26065 [D loss: 0.189209, acc: 100.00%] [G loss: 4.974760]\n",
      "epoch:33 step:26066 [D loss: 0.154152, acc: 99.22%] [G loss: 6.364139]\n",
      "epoch:33 step:26067 [D loss: 0.560103, acc: 57.81%] [G loss: 2.947486]\n",
      "epoch:33 step:26068 [D loss: 0.250121, acc: 94.53%] [G loss: 3.018057]\n",
      "epoch:33 step:26069 [D loss: 0.227492, acc: 96.88%] [G loss: 5.329540]\n",
      "epoch:33 step:26070 [D loss: 0.894911, acc: 35.16%] [G loss: 6.589779]\n",
      "epoch:33 step:26071 [D loss: 0.164607, acc: 98.44%] [G loss: 2.705974]\n",
      "epoch:33 step:26072 [D loss: 0.238510, acc: 97.66%] [G loss: 5.453010]\n",
      "epoch:33 step:26073 [D loss: 0.747308, acc: 52.34%] [G loss: 4.306004]\n",
      "epoch:33 step:26074 [D loss: 0.093173, acc: 100.00%] [G loss: 4.113481]\n",
      "epoch:33 step:26075 [D loss: 0.231893, acc: 94.53%] [G loss: 4.374342]\n",
      "epoch:33 step:26076 [D loss: 0.690732, acc: 58.59%] [G loss: 4.863041]\n",
      "epoch:33 step:26077 [D loss: 0.189522, acc: 97.66%] [G loss: 5.140446]\n",
      "epoch:33 step:26078 [D loss: 0.393117, acc: 81.25%] [G loss: 3.643801]\n",
      "epoch:33 step:26079 [D loss: 0.419916, acc: 83.59%] [G loss: 6.002200]\n",
      "epoch:33 step:26080 [D loss: 0.175712, acc: 97.66%] [G loss: 3.330657]\n",
      "epoch:33 step:26081 [D loss: 0.638250, acc: 61.72%] [G loss: 4.184937]\n",
      "epoch:33 step:26082 [D loss: 0.586483, acc: 64.84%] [G loss: 2.359820]\n",
      "epoch:33 step:26083 [D loss: 0.230788, acc: 96.09%] [G loss: 5.083975]\n",
      "epoch:33 step:26084 [D loss: 0.064735, acc: 100.00%] [G loss: 3.634540]\n",
      "epoch:33 step:26085 [D loss: 0.248356, acc: 96.88%] [G loss: 4.960005]\n",
      "epoch:33 step:26086 [D loss: 0.642889, acc: 58.59%] [G loss: 4.610068]\n",
      "epoch:33 step:26087 [D loss: 0.150686, acc: 99.22%] [G loss: 4.547187]\n",
      "epoch:33 step:26088 [D loss: 0.205718, acc: 96.88%] [G loss: 3.652399]\n",
      "epoch:33 step:26089 [D loss: 0.802814, acc: 48.44%] [G loss: 5.508784]\n",
      "epoch:33 step:26090 [D loss: 0.335951, acc: 90.62%] [G loss: 4.568957]\n",
      "epoch:33 step:26091 [D loss: 0.720561, acc: 57.03%] [G loss: 5.572437]\n",
      "epoch:33 step:26092 [D loss: 0.707956, acc: 57.03%] [G loss: 5.553787]\n",
      "epoch:33 step:26093 [D loss: 0.650345, acc: 65.62%] [G loss: 4.247253]\n",
      "epoch:33 step:26094 [D loss: 0.435249, acc: 79.69%] [G loss: 3.843712]\n",
      "epoch:33 step:26095 [D loss: 0.070095, acc: 100.00%] [G loss: 4.302255]\n",
      "epoch:33 step:26096 [D loss: 0.870117, acc: 48.44%] [G loss: 4.862275]\n",
      "epoch:33 step:26097 [D loss: 0.255717, acc: 91.41%] [G loss: 2.955585]\n",
      "epoch:33 step:26098 [D loss: 0.354965, acc: 87.50%] [G loss: 5.890502]\n",
      "epoch:33 step:26099 [D loss: 0.854446, acc: 52.34%] [G loss: 3.180024]\n",
      "epoch:33 step:26100 [D loss: 0.140949, acc: 99.22%] [G loss: 4.967728]\n",
      "epoch:33 step:26101 [D loss: 0.402357, acc: 85.16%] [G loss: 5.098503]\n",
      "epoch:33 step:26102 [D loss: 0.123960, acc: 98.44%] [G loss: 5.514378]\n",
      "epoch:33 step:26103 [D loss: 0.256623, acc: 91.41%] [G loss: 4.605704]\n",
      "epoch:33 step:26104 [D loss: 0.164897, acc: 96.88%] [G loss: 2.073595]\n",
      "epoch:33 step:26105 [D loss: 0.598182, acc: 58.59%] [G loss: 3.443564]\n",
      "epoch:33 step:26106 [D loss: 0.052191, acc: 100.00%] [G loss: 6.433825]\n",
      "epoch:33 step:26107 [D loss: 0.242868, acc: 91.41%] [G loss: 3.160278]\n",
      "epoch:33 step:26108 [D loss: 0.225801, acc: 96.09%] [G loss: 5.178249]\n",
      "epoch:33 step:26109 [D loss: 0.062278, acc: 100.00%] [G loss: 2.443217]\n",
      "epoch:33 step:26110 [D loss: 0.951880, acc: 35.16%] [G loss: 6.977222]\n",
      "epoch:33 step:26111 [D loss: 0.117456, acc: 99.22%] [G loss: 4.905144]\n",
      "epoch:33 step:26112 [D loss: 0.685346, acc: 57.03%] [G loss: 4.288388]\n",
      "epoch:33 step:26113 [D loss: 0.181596, acc: 96.88%] [G loss: 3.979535]\n",
      "epoch:33 step:26114 [D loss: 0.304385, acc: 88.28%] [G loss: 5.935760]\n",
      "epoch:33 step:26115 [D loss: 0.435650, acc: 75.00%] [G loss: 4.449132]\n",
      "epoch:33 step:26116 [D loss: 0.380443, acc: 86.72%] [G loss: 4.762345]\n",
      "epoch:33 step:26117 [D loss: 0.250728, acc: 95.31%] [G loss: 5.441398]\n",
      "epoch:33 step:26118 [D loss: 0.081163, acc: 99.22%] [G loss: 4.236840]\n",
      "epoch:33 step:26119 [D loss: 0.941585, acc: 50.00%] [G loss: 4.322234]\n",
      "epoch:33 step:26120 [D loss: 1.181380, acc: 39.84%] [G loss: 4.154278]\n",
      "epoch:33 step:26121 [D loss: 0.102477, acc: 100.00%] [G loss: 5.436353]\n",
      "epoch:33 step:26122 [D loss: 0.486377, acc: 66.41%] [G loss: 8.152945]\n",
      "epoch:33 step:26123 [D loss: 1.164617, acc: 51.56%] [G loss: 5.090394]\n",
      "epoch:33 step:26124 [D loss: 1.002365, acc: 31.25%] [G loss: 3.849308]\n",
      "epoch:33 step:26125 [D loss: 0.072902, acc: 100.00%] [G loss: 5.252811]\n",
      "epoch:33 step:26126 [D loss: 0.060924, acc: 100.00%] [G loss: 5.974038]\n",
      "epoch:33 step:26127 [D loss: 0.742867, acc: 57.03%] [G loss: 4.713292]\n",
      "epoch:33 step:26128 [D loss: 0.292053, acc: 86.72%] [G loss: 5.186799]\n",
      "epoch:33 step:26129 [D loss: 0.161721, acc: 98.44%] [G loss: 2.984742]\n",
      "epoch:33 step:26130 [D loss: 0.155829, acc: 96.09%] [G loss: 5.830981]\n",
      "epoch:33 step:26131 [D loss: 0.066963, acc: 100.00%] [G loss: 4.932066]\n",
      "epoch:33 step:26132 [D loss: 0.547659, acc: 78.12%] [G loss: 3.793446]\n",
      "epoch:33 step:26133 [D loss: 0.760401, acc: 57.03%] [G loss: 3.632265]\n",
      "epoch:33 step:26134 [D loss: 0.824322, acc: 53.91%] [G loss: 5.658374]\n",
      "epoch:33 step:26135 [D loss: 0.699457, acc: 50.78%] [G loss: 4.140453]\n",
      "epoch:33 step:26136 [D loss: 1.016656, acc: 50.78%] [G loss: 6.792304]\n",
      "epoch:33 step:26137 [D loss: 0.378216, acc: 84.38%] [G loss: 6.127312]\n",
      "epoch:33 step:26138 [D loss: 0.156292, acc: 99.22%] [G loss: 2.179200]\n",
      "epoch:33 step:26139 [D loss: 0.283364, acc: 98.44%] [G loss: 4.158710]\n",
      "epoch:33 step:26140 [D loss: 0.707099, acc: 59.38%] [G loss: 5.616506]\n",
      "epoch:33 step:26141 [D loss: 0.138423, acc: 100.00%] [G loss: 7.358687]\n",
      "epoch:33 step:26142 [D loss: 0.078051, acc: 99.22%] [G loss: 6.107975]\n",
      "epoch:33 step:26143 [D loss: 0.283957, acc: 96.88%] [G loss: 5.452138]\n",
      "epoch:33 step:26144 [D loss: 0.400701, acc: 84.38%] [G loss: 4.813971]\n",
      "epoch:33 step:26145 [D loss: 0.198480, acc: 96.88%] [G loss: 6.083333]\n",
      "epoch:33 step:26146 [D loss: 0.704371, acc: 57.03%] [G loss: 7.036931]\n",
      "epoch:33 step:26147 [D loss: 0.444139, acc: 75.78%] [G loss: 3.544653]\n",
      "epoch:33 step:26148 [D loss: 0.307420, acc: 92.19%] [G loss: 5.823527]\n",
      "epoch:33 step:26149 [D loss: 0.368384, acc: 81.25%] [G loss: 5.419653]\n",
      "epoch:33 step:26150 [D loss: 0.683332, acc: 54.69%] [G loss: 3.587033]\n",
      "epoch:33 step:26151 [D loss: 0.064163, acc: 100.00%] [G loss: 3.615567]\n",
      "epoch:33 step:26152 [D loss: 0.612507, acc: 57.81%] [G loss: 7.104575]\n",
      "epoch:33 step:26153 [D loss: 0.192635, acc: 99.22%] [G loss: 6.037829]\n",
      "epoch:33 step:26154 [D loss: 0.272617, acc: 89.84%] [G loss: 4.331759]\n",
      "epoch:33 step:26155 [D loss: 0.224289, acc: 95.31%] [G loss: 3.475043]\n",
      "epoch:33 step:26156 [D loss: 0.166765, acc: 98.44%] [G loss: 3.589923]\n",
      "epoch:33 step:26157 [D loss: 0.426912, acc: 75.78%] [G loss: 3.415119]\n",
      "epoch:33 step:26158 [D loss: 0.150307, acc: 98.44%] [G loss: 4.245440]\n",
      "epoch:33 step:26159 [D loss: 0.398037, acc: 89.84%] [G loss: 3.579104]\n",
      "epoch:33 step:26160 [D loss: 0.267818, acc: 92.97%] [G loss: 2.398181]\n",
      "epoch:33 step:26161 [D loss: 0.466386, acc: 80.47%] [G loss: 4.406153]\n",
      "epoch:33 step:26162 [D loss: 0.118365, acc: 100.00%] [G loss: 6.647869]\n",
      "epoch:33 step:26163 [D loss: 0.317482, acc: 94.53%] [G loss: 6.284046]\n",
      "epoch:33 step:26164 [D loss: 0.319544, acc: 95.31%] [G loss: 6.323799]\n",
      "epoch:33 step:26165 [D loss: 0.486057, acc: 72.66%] [G loss: 3.526730]\n",
      "epoch:33 step:26166 [D loss: 1.096280, acc: 47.66%] [G loss: 2.616093]\n",
      "epoch:33 step:26167 [D loss: 0.334842, acc: 85.94%] [G loss: 5.489643]\n",
      "epoch:33 step:26168 [D loss: 0.458673, acc: 76.56%] [G loss: 2.996561]\n",
      "epoch:33 step:26169 [D loss: 0.493439, acc: 70.31%] [G loss: 6.234199]\n",
      "epoch:33 step:26170 [D loss: 0.359192, acc: 85.94%] [G loss: 4.280309]\n",
      "epoch:33 step:26171 [D loss: 0.442724, acc: 84.38%] [G loss: 4.320135]\n",
      "epoch:33 step:26172 [D loss: 0.458978, acc: 77.34%] [G loss: 3.670267]\n",
      "epoch:33 step:26173 [D loss: 0.280516, acc: 92.97%] [G loss: 4.285912]\n",
      "epoch:33 step:26174 [D loss: 0.169496, acc: 97.66%] [G loss: 5.681871]\n",
      "epoch:33 step:26175 [D loss: 0.476297, acc: 67.19%] [G loss: 8.559116]\n",
      "epoch:33 step:26176 [D loss: 0.549132, acc: 67.97%] [G loss: 3.638902]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26177 [D loss: 0.670047, acc: 57.81%] [G loss: 4.423249]\n",
      "epoch:33 step:26178 [D loss: 0.633148, acc: 60.16%] [G loss: 4.124195]\n",
      "epoch:33 step:26179 [D loss: 0.101123, acc: 99.22%] [G loss: 4.877411]\n",
      "epoch:33 step:26180 [D loss: 0.808872, acc: 53.91%] [G loss: 3.841512]\n",
      "epoch:33 step:26181 [D loss: 0.142058, acc: 98.44%] [G loss: 3.673870]\n",
      "epoch:33 step:26182 [D loss: 0.295061, acc: 95.31%] [G loss: 2.886899]\n",
      "epoch:33 step:26183 [D loss: 0.446564, acc: 72.66%] [G loss: 4.413513]\n",
      "epoch:33 step:26184 [D loss: 0.104593, acc: 100.00%] [G loss: 5.369062]\n",
      "epoch:33 step:26185 [D loss: 0.469537, acc: 75.78%] [G loss: 6.657377]\n",
      "epoch:33 step:26186 [D loss: 0.241412, acc: 93.75%] [G loss: 5.272621]\n",
      "epoch:33 step:26187 [D loss: 0.457899, acc: 72.66%] [G loss: 5.953874]\n",
      "epoch:33 step:26188 [D loss: 0.081404, acc: 100.00%] [G loss: 4.517477]\n",
      "epoch:33 step:26189 [D loss: 0.309516, acc: 93.75%] [G loss: 4.168526]\n",
      "epoch:33 step:26190 [D loss: 0.049013, acc: 100.00%] [G loss: 5.576488]\n",
      "epoch:33 step:26191 [D loss: 0.234854, acc: 92.19%] [G loss: 5.380515]\n",
      "epoch:33 step:26192 [D loss: 0.506810, acc: 66.41%] [G loss: 5.039471]\n",
      "epoch:33 step:26193 [D loss: 0.159135, acc: 99.22%] [G loss: 4.941620]\n",
      "epoch:33 step:26194 [D loss: 0.261948, acc: 92.97%] [G loss: 5.415864]\n",
      "epoch:33 step:26195 [D loss: 0.075934, acc: 100.00%] [G loss: 5.769845]\n",
      "epoch:33 step:26196 [D loss: 0.366734, acc: 91.41%] [G loss: 4.368150]\n",
      "epoch:33 step:26197 [D loss: 0.606484, acc: 63.28%] [G loss: 5.905889]\n",
      "epoch:33 step:26198 [D loss: 0.040186, acc: 100.00%] [G loss: 4.676106]\n",
      "epoch:33 step:26199 [D loss: 0.413233, acc: 75.00%] [G loss: 5.886303]\n",
      "epoch:33 step:26200 [D loss: 0.118424, acc: 99.22%] [G loss: 1.704302]\n",
      "epoch:33 step:26201 [D loss: 0.267809, acc: 89.84%] [G loss: 3.654251]\n",
      "epoch:33 step:26202 [D loss: 0.620015, acc: 57.81%] [G loss: 6.086360]\n",
      "epoch:33 step:26203 [D loss: 0.601009, acc: 66.41%] [G loss: 4.315722]\n",
      "epoch:33 step:26204 [D loss: 0.458360, acc: 71.88%] [G loss: 4.962200]\n",
      "epoch:33 step:26205 [D loss: 0.801805, acc: 51.56%] [G loss: 6.224058]\n",
      "epoch:33 step:26206 [D loss: 0.353870, acc: 91.41%] [G loss: 3.021207]\n",
      "epoch:33 step:26207 [D loss: 0.228511, acc: 98.44%] [G loss: 4.986282]\n",
      "epoch:33 step:26208 [D loss: 0.218607, acc: 96.09%] [G loss: 4.240529]\n",
      "epoch:33 step:26209 [D loss: 0.545976, acc: 69.53%] [G loss: 6.805732]\n",
      "epoch:33 step:26210 [D loss: 0.334609, acc: 92.19%] [G loss: 4.569225]\n",
      "epoch:33 step:26211 [D loss: 0.177446, acc: 100.00%] [G loss: 3.198485]\n",
      "epoch:33 step:26212 [D loss: 1.458580, acc: 17.97%] [G loss: 4.605451]\n",
      "epoch:33 step:26213 [D loss: 0.517401, acc: 72.66%] [G loss: 3.863447]\n",
      "epoch:33 step:26214 [D loss: 1.084548, acc: 42.19%] [G loss: 4.513952]\n",
      "epoch:33 step:26215 [D loss: 0.179655, acc: 98.44%] [G loss: 6.636643]\n",
      "epoch:33 step:26216 [D loss: 0.256118, acc: 96.09%] [G loss: 3.344848]\n",
      "epoch:33 step:26217 [D loss: 0.114466, acc: 98.44%] [G loss: 5.618596]\n",
      "epoch:33 step:26218 [D loss: 0.392388, acc: 89.84%] [G loss: 3.346854]\n",
      "epoch:33 step:26219 [D loss: 0.060379, acc: 99.22%] [G loss: 6.266032]\n",
      "epoch:33 step:26220 [D loss: 0.909934, acc: 47.66%] [G loss: 5.015560]\n",
      "epoch:33 step:26221 [D loss: 0.171343, acc: 98.44%] [G loss: 4.675890]\n",
      "epoch:33 step:26222 [D loss: 0.775235, acc: 51.56%] [G loss: 3.225535]\n",
      "epoch:33 step:26223 [D loss: 0.184914, acc: 98.44%] [G loss: 4.626280]\n",
      "epoch:33 step:26224 [D loss: 1.613639, acc: 7.81%] [G loss: 4.639174]\n",
      "epoch:33 step:26225 [D loss: 0.724200, acc: 55.47%] [G loss: 5.470099]\n",
      "epoch:33 step:26226 [D loss: 0.194707, acc: 98.44%] [G loss: 3.359647]\n",
      "epoch:33 step:26227 [D loss: 0.290426, acc: 96.88%] [G loss: 4.089101]\n",
      "epoch:33 step:26228 [D loss: 0.333852, acc: 92.97%] [G loss: 3.523164]\n",
      "epoch:33 step:26229 [D loss: 0.660577, acc: 62.50%] [G loss: 4.027440]\n",
      "epoch:33 step:26230 [D loss: 0.869304, acc: 50.78%] [G loss: 3.955987]\n",
      "epoch:33 step:26231 [D loss: 0.265785, acc: 95.31%] [G loss: 4.541697]\n",
      "epoch:33 step:26232 [D loss: 0.891877, acc: 46.88%] [G loss: 4.987059]\n",
      "epoch:33 step:26233 [D loss: 0.145866, acc: 98.44%] [G loss: 4.731750]\n",
      "epoch:33 step:26234 [D loss: 0.028222, acc: 100.00%] [G loss: 6.421946]\n",
      "epoch:33 step:26235 [D loss: 0.100539, acc: 99.22%] [G loss: 4.959610]\n",
      "epoch:33 step:26236 [D loss: 0.254958, acc: 95.31%] [G loss: 4.561836]\n",
      "epoch:33 step:26237 [D loss: 0.369897, acc: 91.41%] [G loss: 5.850975]\n",
      "epoch:33 step:26238 [D loss: 0.315986, acc: 85.94%] [G loss: 4.189468]\n",
      "epoch:33 step:26239 [D loss: 0.064413, acc: 100.00%] [G loss: 7.400598]\n",
      "epoch:33 step:26240 [D loss: 0.335882, acc: 83.59%] [G loss: 4.876897]\n",
      "epoch:33 step:26241 [D loss: 0.662392, acc: 59.38%] [G loss: 5.498397]\n",
      "epoch:33 step:26242 [D loss: 0.161825, acc: 100.00%] [G loss: 5.743219]\n",
      "epoch:33 step:26243 [D loss: 0.060881, acc: 100.00%] [G loss: 4.436164]\n",
      "epoch:33 step:26244 [D loss: 0.111216, acc: 99.22%] [G loss: 4.858549]\n",
      "epoch:33 step:26245 [D loss: 0.776943, acc: 53.12%] [G loss: 6.542111]\n",
      "epoch:33 step:26246 [D loss: 0.287975, acc: 92.97%] [G loss: 5.894637]\n",
      "epoch:33 step:26247 [D loss: 0.614678, acc: 57.03%] [G loss: 4.648303]\n",
      "epoch:33 step:26248 [D loss: 0.326271, acc: 83.59%] [G loss: 5.862127]\n",
      "epoch:33 step:26249 [D loss: 0.217148, acc: 95.31%] [G loss: 5.704269]\n",
      "epoch:33 step:26250 [D loss: 0.262131, acc: 93.75%] [G loss: 3.091478]\n",
      "epoch:33 step:26251 [D loss: 0.024201, acc: 100.00%] [G loss: 5.573883]\n",
      "epoch:33 step:26252 [D loss: 0.862819, acc: 44.53%] [G loss: 3.723307]\n",
      "epoch:33 step:26253 [D loss: 0.533739, acc: 71.09%] [G loss: 3.733628]\n",
      "epoch:33 step:26254 [D loss: 0.229666, acc: 96.09%] [G loss: 3.300406]\n",
      "epoch:33 step:26255 [D loss: 1.768551, acc: 14.06%] [G loss: 4.344725]\n",
      "epoch:33 step:26256 [D loss: 0.187843, acc: 97.66%] [G loss: 4.193341]\n",
      "epoch:33 step:26257 [D loss: 0.176775, acc: 97.66%] [G loss: 5.068997]\n",
      "epoch:33 step:26258 [D loss: 0.569214, acc: 66.41%] [G loss: 3.180476]\n",
      "epoch:33 step:26259 [D loss: 0.433161, acc: 73.44%] [G loss: 3.585133]\n",
      "epoch:33 step:26260 [D loss: 0.231808, acc: 96.88%] [G loss: 4.521440]\n",
      "epoch:33 step:26261 [D loss: 0.149010, acc: 100.00%] [G loss: 4.056817]\n",
      "epoch:33 step:26262 [D loss: 0.625533, acc: 60.16%] [G loss: 3.994403]\n",
      "epoch:33 step:26263 [D loss: 0.154871, acc: 96.88%] [G loss: 6.278652]\n",
      "epoch:33 step:26264 [D loss: 0.634778, acc: 60.94%] [G loss: 6.113442]\n",
      "epoch:33 step:26265 [D loss: 0.307754, acc: 92.97%] [G loss: 6.479728]\n",
      "epoch:33 step:26266 [D loss: 0.285458, acc: 92.19%] [G loss: 3.192373]\n",
      "epoch:33 step:26267 [D loss: 0.200985, acc: 97.66%] [G loss: 6.090694]\n",
      "epoch:33 step:26268 [D loss: 0.977609, acc: 42.97%] [G loss: 5.222508]\n",
      "epoch:33 step:26269 [D loss: 0.123773, acc: 97.66%] [G loss: 5.033952]\n",
      "epoch:33 step:26270 [D loss: 0.940838, acc: 50.00%] [G loss: 8.374542]\n",
      "epoch:33 step:26271 [D loss: 0.456456, acc: 73.44%] [G loss: 5.887096]\n",
      "epoch:33 step:26272 [D loss: 0.077139, acc: 99.22%] [G loss: 5.298627]\n",
      "epoch:33 step:26273 [D loss: 0.411641, acc: 78.12%] [G loss: 7.032745]\n",
      "epoch:33 step:26274 [D loss: 0.158012, acc: 97.66%] [G loss: 5.030208]\n",
      "epoch:33 step:26275 [D loss: 0.132486, acc: 100.00%] [G loss: 4.215539]\n",
      "epoch:33 step:26276 [D loss: 0.231572, acc: 93.75%] [G loss: 3.820497]\n",
      "epoch:33 step:26277 [D loss: 1.236578, acc: 21.88%] [G loss: 2.186333]\n",
      "epoch:33 step:26278 [D loss: 0.227544, acc: 95.31%] [G loss: 3.817439]\n",
      "epoch:33 step:26279 [D loss: 0.418461, acc: 80.47%] [G loss: 6.579350]\n",
      "epoch:33 step:26280 [D loss: 0.226685, acc: 97.66%] [G loss: 4.070401]\n",
      "epoch:33 step:26281 [D loss: 0.257446, acc: 96.88%] [G loss: 4.855081]\n",
      "epoch:33 step:26282 [D loss: 0.714284, acc: 54.69%] [G loss: 3.544018]\n",
      "epoch:33 step:26283 [D loss: 0.293740, acc: 96.09%] [G loss: 4.595730]\n",
      "epoch:33 step:26284 [D loss: 0.051475, acc: 100.00%] [G loss: 5.415315]\n",
      "epoch:33 step:26285 [D loss: 0.579218, acc: 62.50%] [G loss: 3.768547]\n",
      "epoch:33 step:26286 [D loss: 0.278859, acc: 87.50%] [G loss: 3.917826]\n",
      "epoch:33 step:26287 [D loss: 0.490906, acc: 77.34%] [G loss: 5.965907]\n",
      "epoch:33 step:26288 [D loss: 0.141762, acc: 100.00%] [G loss: 2.066652]\n",
      "epoch:33 step:26289 [D loss: 0.476296, acc: 71.09%] [G loss: 3.605055]\n",
      "epoch:33 step:26290 [D loss: 0.155579, acc: 99.22%] [G loss: 5.194947]\n",
      "epoch:33 step:26291 [D loss: 0.231164, acc: 92.97%] [G loss: 5.689106]\n",
      "epoch:33 step:26292 [D loss: 0.656900, acc: 65.62%] [G loss: 5.753029]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26293 [D loss: 0.212004, acc: 98.44%] [G loss: 4.834233]\n",
      "epoch:33 step:26294 [D loss: 0.177954, acc: 96.88%] [G loss: 2.818418]\n",
      "epoch:33 step:26295 [D loss: 0.523919, acc: 73.44%] [G loss: 3.682756]\n",
      "epoch:33 step:26296 [D loss: 0.174169, acc: 98.44%] [G loss: 2.700132]\n",
      "epoch:33 step:26297 [D loss: 0.146633, acc: 99.22%] [G loss: 5.744596]\n",
      "epoch:33 step:26298 [D loss: 0.443479, acc: 82.03%] [G loss: 3.097581]\n",
      "epoch:33 step:26299 [D loss: 0.662142, acc: 62.50%] [G loss: 6.267082]\n",
      "epoch:33 step:26300 [D loss: 0.455103, acc: 71.09%] [G loss: 4.817661]\n",
      "epoch:33 step:26301 [D loss: 0.101784, acc: 100.00%] [G loss: 3.732260]\n",
      "epoch:33 step:26302 [D loss: 0.205314, acc: 97.66%] [G loss: 2.179452]\n",
      "epoch:33 step:26303 [D loss: 0.182208, acc: 95.31%] [G loss: 3.703474]\n",
      "epoch:33 step:26304 [D loss: 0.067349, acc: 100.00%] [G loss: 4.232018]\n",
      "epoch:33 step:26305 [D loss: 0.508235, acc: 78.12%] [G loss: 4.338587]\n",
      "epoch:33 step:26306 [D loss: 0.336093, acc: 92.97%] [G loss: 5.600770]\n",
      "epoch:33 step:26307 [D loss: 0.110563, acc: 99.22%] [G loss: 2.404138]\n",
      "epoch:33 step:26308 [D loss: 0.725958, acc: 55.47%] [G loss: 4.297424]\n",
      "epoch:33 step:26309 [D loss: 1.240220, acc: 50.00%] [G loss: 4.999753]\n",
      "epoch:33 step:26310 [D loss: 0.091394, acc: 100.00%] [G loss: 4.813327]\n",
      "epoch:33 step:26311 [D loss: 0.166128, acc: 97.66%] [G loss: 4.343282]\n",
      "epoch:33 step:26312 [D loss: 1.130647, acc: 41.41%] [G loss: 6.070126]\n",
      "epoch:33 step:26313 [D loss: 0.121138, acc: 100.00%] [G loss: 3.183688]\n",
      "epoch:33 step:26314 [D loss: 0.127129, acc: 99.22%] [G loss: 4.372981]\n",
      "epoch:33 step:26315 [D loss: 0.041974, acc: 100.00%] [G loss: 4.677882]\n",
      "epoch:33 step:26316 [D loss: 0.787459, acc: 54.69%] [G loss: 4.974144]\n",
      "epoch:33 step:26317 [D loss: 0.449334, acc: 86.72%] [G loss: 4.115878]\n",
      "epoch:33 step:26318 [D loss: 1.418653, acc: 16.41%] [G loss: 5.607763]\n",
      "epoch:33 step:26319 [D loss: 0.770365, acc: 51.56%] [G loss: 6.030690]\n",
      "epoch:33 step:26320 [D loss: 0.460501, acc: 82.03%] [G loss: 6.350270]\n",
      "epoch:33 step:26321 [D loss: 0.262252, acc: 92.97%] [G loss: 5.004948]\n",
      "epoch:33 step:26322 [D loss: 0.735700, acc: 51.56%] [G loss: 3.584150]\n",
      "epoch:33 step:26323 [D loss: 0.601869, acc: 61.72%] [G loss: 6.696608]\n",
      "epoch:33 step:26324 [D loss: 0.039354, acc: 100.00%] [G loss: 4.863124]\n",
      "epoch:33 step:26325 [D loss: 0.374495, acc: 85.16%] [G loss: 3.952312]\n",
      "epoch:33 step:26326 [D loss: 0.459303, acc: 82.81%] [G loss: 4.077414]\n",
      "epoch:33 step:26327 [D loss: 0.699078, acc: 53.12%] [G loss: 4.757952]\n",
      "epoch:33 step:26328 [D loss: 0.045689, acc: 100.00%] [G loss: 6.628469]\n",
      "epoch:33 step:26329 [D loss: 0.138026, acc: 97.66%] [G loss: 3.562507]\n",
      "epoch:33 step:26330 [D loss: 0.212181, acc: 97.66%] [G loss: 6.028690]\n",
      "epoch:33 step:26331 [D loss: 0.807213, acc: 52.34%] [G loss: 6.872989]\n",
      "epoch:33 step:26332 [D loss: 0.915025, acc: 50.00%] [G loss: 3.658474]\n",
      "epoch:33 step:26333 [D loss: 0.166934, acc: 100.00%] [G loss: 4.906898]\n",
      "epoch:33 step:26334 [D loss: 0.490506, acc: 70.31%] [G loss: 8.255675]\n",
      "epoch:33 step:26335 [D loss: 0.804980, acc: 48.44%] [G loss: 7.506719]\n",
      "epoch:33 step:26336 [D loss: 0.482733, acc: 73.44%] [G loss: 4.132235]\n",
      "epoch:33 step:26337 [D loss: 0.033385, acc: 100.00%] [G loss: 4.085062]\n",
      "epoch:33 step:26338 [D loss: 0.243140, acc: 94.53%] [G loss: 5.744956]\n",
      "epoch:33 step:26339 [D loss: 0.225260, acc: 95.31%] [G loss: 4.418269]\n",
      "epoch:33 step:26340 [D loss: 1.435462, acc: 7.03%] [G loss: 6.375140]\n",
      "epoch:33 step:26341 [D loss: 1.327505, acc: 50.00%] [G loss: 1.895281]\n",
      "epoch:33 step:26342 [D loss: 0.042345, acc: 100.00%] [G loss: 5.871704]\n",
      "epoch:33 step:26343 [D loss: 0.322863, acc: 88.28%] [G loss: 3.895195]\n",
      "epoch:33 step:26344 [D loss: 0.239717, acc: 92.97%] [G loss: 4.992546]\n",
      "epoch:33 step:26345 [D loss: 0.980891, acc: 43.75%] [G loss: 6.531158]\n",
      "epoch:33 step:26346 [D loss: 0.464282, acc: 81.25%] [G loss: 3.487974]\n",
      "epoch:33 step:26347 [D loss: 0.826240, acc: 49.22%] [G loss: 5.185602]\n",
      "epoch:33 step:26348 [D loss: 0.485482, acc: 83.59%] [G loss: 5.917023]\n",
      "epoch:33 step:26349 [D loss: 0.608782, acc: 59.38%] [G loss: 6.648216]\n",
      "epoch:33 step:26350 [D loss: 0.244362, acc: 96.88%] [G loss: 5.541310]\n",
      "epoch:33 step:26351 [D loss: 0.663253, acc: 56.25%] [G loss: 5.090929]\n",
      "epoch:33 step:26352 [D loss: 0.313601, acc: 82.03%] [G loss: 4.079275]\n",
      "epoch:33 step:26353 [D loss: 0.151372, acc: 100.00%] [G loss: 2.041526]\n",
      "epoch:33 step:26354 [D loss: 0.314722, acc: 94.53%] [G loss: 6.834652]\n",
      "epoch:33 step:26355 [D loss: 0.656196, acc: 64.06%] [G loss: 3.318553]\n",
      "epoch:33 step:26356 [D loss: 0.300344, acc: 92.19%] [G loss: 5.380113]\n",
      "epoch:33 step:26357 [D loss: 0.307962, acc: 91.41%] [G loss: 4.654451]\n",
      "epoch:33 step:26358 [D loss: 0.275244, acc: 92.19%] [G loss: 6.580416]\n",
      "epoch:33 step:26359 [D loss: 0.136270, acc: 100.00%] [G loss: 5.155828]\n",
      "epoch:33 step:26360 [D loss: 0.388040, acc: 79.69%] [G loss: 5.049494]\n",
      "epoch:33 step:26361 [D loss: 0.817248, acc: 55.47%] [G loss: 5.483288]\n",
      "epoch:33 step:26362 [D loss: 0.585009, acc: 64.06%] [G loss: 4.229732]\n",
      "epoch:33 step:26363 [D loss: 0.134362, acc: 99.22%] [G loss: 3.457870]\n",
      "epoch:33 step:26364 [D loss: 0.377601, acc: 90.62%] [G loss: 5.935786]\n",
      "epoch:33 step:26365 [D loss: 0.462860, acc: 67.19%] [G loss: 5.214051]\n",
      "epoch:33 step:26366 [D loss: 0.318835, acc: 85.94%] [G loss: 4.982767]\n",
      "epoch:33 step:26367 [D loss: 0.835405, acc: 49.22%] [G loss: 5.288843]\n",
      "epoch:33 step:26368 [D loss: 0.622420, acc: 64.06%] [G loss: 4.827372]\n",
      "epoch:33 step:26369 [D loss: 1.216797, acc: 29.69%] [G loss: 3.895851]\n",
      "epoch:33 step:26370 [D loss: 0.367946, acc: 82.81%] [G loss: 5.617306]\n",
      "epoch:33 step:26371 [D loss: 0.131234, acc: 99.22%] [G loss: 6.154040]\n",
      "epoch:33 step:26372 [D loss: 0.260354, acc: 97.66%] [G loss: 3.711761]\n",
      "epoch:33 step:26373 [D loss: 1.297008, acc: 46.88%] [G loss: 4.727818]\n",
      "epoch:33 step:26374 [D loss: 0.098574, acc: 100.00%] [G loss: 4.139908]\n",
      "epoch:33 step:26375 [D loss: 0.800813, acc: 50.78%] [G loss: 4.775424]\n",
      "epoch:33 step:26376 [D loss: 0.326007, acc: 90.62%] [G loss: 4.226234]\n",
      "epoch:33 step:26377 [D loss: 0.404672, acc: 86.72%] [G loss: 1.716481]\n",
      "epoch:33 step:26378 [D loss: 0.202281, acc: 98.44%] [G loss: 3.520589]\n",
      "epoch:33 step:26379 [D loss: 0.234750, acc: 100.00%] [G loss: 3.183978]\n",
      "epoch:33 step:26380 [D loss: 0.273191, acc: 91.41%] [G loss: 5.499218]\n",
      "epoch:33 step:26381 [D loss: 0.568231, acc: 66.41%] [G loss: 3.792037]\n",
      "epoch:33 step:26382 [D loss: 0.451471, acc: 83.59%] [G loss: 5.389322]\n",
      "epoch:33 step:26383 [D loss: 0.284922, acc: 89.06%] [G loss: 3.630147]\n",
      "epoch:33 step:26384 [D loss: 0.239386, acc: 97.66%] [G loss: 4.692288]\n",
      "epoch:33 step:26385 [D loss: 0.481747, acc: 79.69%] [G loss: 4.896236]\n",
      "epoch:33 step:26386 [D loss: 0.494119, acc: 75.00%] [G loss: 3.280757]\n",
      "epoch:33 step:26387 [D loss: 0.667469, acc: 60.94%] [G loss: 6.403303]\n",
      "epoch:33 step:26388 [D loss: 0.241596, acc: 96.88%] [G loss: 5.002501]\n",
      "epoch:33 step:26389 [D loss: 0.687841, acc: 57.81%] [G loss: 5.489818]\n",
      "epoch:33 step:26390 [D loss: 0.216905, acc: 93.75%] [G loss: 7.642638]\n",
      "epoch:33 step:26391 [D loss: 0.068247, acc: 100.00%] [G loss: 4.332971]\n",
      "epoch:33 step:26392 [D loss: 0.221699, acc: 99.22%] [G loss: 4.781663]\n",
      "epoch:33 step:26393 [D loss: 0.113531, acc: 98.44%] [G loss: 4.528342]\n",
      "epoch:33 step:26394 [D loss: 0.424078, acc: 84.38%] [G loss: 3.790607]\n",
      "epoch:33 step:26395 [D loss: 0.437373, acc: 84.38%] [G loss: 6.466755]\n",
      "epoch:33 step:26396 [D loss: 0.099274, acc: 100.00%] [G loss: 2.889715]\n",
      "epoch:33 step:26397 [D loss: 0.247295, acc: 95.31%] [G loss: 5.370839]\n",
      "epoch:33 step:26398 [D loss: 0.118886, acc: 100.00%] [G loss: 3.309062]\n",
      "epoch:33 step:26399 [D loss: 0.375196, acc: 82.03%] [G loss: 4.585901]\n",
      "epoch:33 step:26400 [D loss: 0.343805, acc: 85.16%] [G loss: 4.522275]\n",
      "epoch:33 step:26401 [D loss: 0.527094, acc: 74.22%] [G loss: 4.115035]\n",
      "epoch:33 step:26402 [D loss: 0.229760, acc: 96.88%] [G loss: 4.550270]\n",
      "epoch:33 step:26403 [D loss: 0.067342, acc: 100.00%] [G loss: 7.667706]\n",
      "epoch:33 step:26404 [D loss: 0.143931, acc: 99.22%] [G loss: 3.768929]\n",
      "epoch:33 step:26405 [D loss: 0.046997, acc: 100.00%] [G loss: 6.784645]\n",
      "epoch:33 step:26406 [D loss: 0.240118, acc: 98.44%] [G loss: 5.523112]\n",
      "epoch:33 step:26407 [D loss: 0.917641, acc: 50.78%] [G loss: 3.816804]\n",
      "epoch:33 step:26408 [D loss: 0.646485, acc: 57.81%] [G loss: 12.182757]\n",
      "epoch:33 step:26409 [D loss: 0.126537, acc: 98.44%] [G loss: 5.752152]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26410 [D loss: 0.325454, acc: 81.25%] [G loss: 5.322436]\n",
      "epoch:33 step:26411 [D loss: 0.330449, acc: 83.59%] [G loss: 5.505385]\n",
      "epoch:33 step:26412 [D loss: 0.858846, acc: 42.97%] [G loss: 4.991623]\n",
      "epoch:33 step:26413 [D loss: 0.123708, acc: 99.22%] [G loss: 4.913432]\n",
      "epoch:33 step:26414 [D loss: 0.353809, acc: 95.31%] [G loss: 3.901088]\n",
      "epoch:33 step:26415 [D loss: 0.239132, acc: 98.44%] [G loss: 3.330340]\n",
      "epoch:33 step:26416 [D loss: 0.405652, acc: 72.66%] [G loss: 4.296827]\n",
      "epoch:33 step:26417 [D loss: 0.637439, acc: 67.97%] [G loss: 4.312724]\n",
      "epoch:33 step:26418 [D loss: 0.205122, acc: 94.53%] [G loss: 6.425575]\n",
      "epoch:33 step:26419 [D loss: 0.827109, acc: 51.56%] [G loss: 6.541120]\n",
      "epoch:33 step:26420 [D loss: 0.338482, acc: 91.41%] [G loss: 6.553603]\n",
      "epoch:33 step:26421 [D loss: 1.595826, acc: 49.22%] [G loss: 4.360623]\n",
      "epoch:33 step:26422 [D loss: 0.558855, acc: 63.28%] [G loss: 5.262086]\n",
      "epoch:33 step:26423 [D loss: 0.318397, acc: 87.50%] [G loss: 5.242901]\n",
      "epoch:33 step:26424 [D loss: 0.442291, acc: 75.00%] [G loss: 4.532288]\n",
      "epoch:33 step:26425 [D loss: 1.641831, acc: 48.44%] [G loss: 2.246736]\n",
      "epoch:33 step:26426 [D loss: 0.233614, acc: 97.66%] [G loss: 3.824736]\n",
      "epoch:33 step:26427 [D loss: 0.354593, acc: 80.47%] [G loss: 4.269724]\n",
      "epoch:33 step:26428 [D loss: 0.055311, acc: 100.00%] [G loss: 4.388607]\n",
      "epoch:33 step:26429 [D loss: 0.217373, acc: 96.09%] [G loss: 2.857893]\n",
      "epoch:33 step:26430 [D loss: 0.335123, acc: 86.72%] [G loss: 3.071024]\n",
      "epoch:33 step:26431 [D loss: 0.232437, acc: 95.31%] [G loss: 4.792595]\n",
      "epoch:33 step:26432 [D loss: 0.406419, acc: 86.72%] [G loss: 6.706065]\n",
      "epoch:33 step:26433 [D loss: 0.437206, acc: 73.44%] [G loss: 5.396272]\n",
      "epoch:33 step:26434 [D loss: 0.224874, acc: 94.53%] [G loss: 4.978154]\n",
      "epoch:33 step:26435 [D loss: 0.375586, acc: 80.47%] [G loss: 5.964457]\n",
      "epoch:33 step:26436 [D loss: 0.160830, acc: 99.22%] [G loss: 5.267042]\n",
      "epoch:33 step:26437 [D loss: 0.382298, acc: 79.69%] [G loss: 4.246113]\n",
      "epoch:33 step:26438 [D loss: 0.529787, acc: 60.16%] [G loss: 5.377642]\n",
      "epoch:33 step:26439 [D loss: 0.351268, acc: 91.41%] [G loss: 6.865805]\n",
      "epoch:33 step:26440 [D loss: 0.104750, acc: 98.44%] [G loss: 7.975107]\n",
      "epoch:33 step:26441 [D loss: 0.041640, acc: 100.00%] [G loss: 5.164771]\n",
      "epoch:33 step:26442 [D loss: 0.551748, acc: 73.44%] [G loss: 5.675415]\n",
      "epoch:33 step:26443 [D loss: 0.527944, acc: 73.44%] [G loss: 3.274700]\n",
      "epoch:33 step:26444 [D loss: 0.165949, acc: 100.00%] [G loss: 4.479448]\n",
      "epoch:33 step:26445 [D loss: 0.387282, acc: 80.47%] [G loss: 4.194311]\n",
      "epoch:33 step:26446 [D loss: 0.056971, acc: 100.00%] [G loss: 3.900921]\n",
      "epoch:33 step:26447 [D loss: 0.132890, acc: 99.22%] [G loss: 2.403357]\n",
      "epoch:33 step:26448 [D loss: 0.240305, acc: 92.97%] [G loss: 2.781815]\n",
      "epoch:33 step:26449 [D loss: 0.419073, acc: 78.91%] [G loss: 4.490106]\n",
      "epoch:33 step:26450 [D loss: 0.424327, acc: 83.59%] [G loss: 6.026999]\n",
      "epoch:33 step:26451 [D loss: 0.318417, acc: 85.94%] [G loss: 2.393046]\n",
      "epoch:33 step:26452 [D loss: 0.559100, acc: 62.50%] [G loss: 4.887264]\n",
      "epoch:33 step:26453 [D loss: 1.499260, acc: 25.00%] [G loss: 4.144691]\n",
      "epoch:33 step:26454 [D loss: 0.070899, acc: 99.22%] [G loss: 4.264184]\n",
      "epoch:33 step:26455 [D loss: 0.273873, acc: 95.31%] [G loss: 5.617293]\n",
      "epoch:33 step:26456 [D loss: 0.693729, acc: 56.25%] [G loss: 5.357876]\n",
      "epoch:33 step:26457 [D loss: 0.552122, acc: 70.31%] [G loss: 5.122355]\n",
      "epoch:33 step:26458 [D loss: 0.748209, acc: 57.03%] [G loss: 5.053494]\n",
      "epoch:33 step:26459 [D loss: 1.097128, acc: 21.09%] [G loss: 4.388110]\n",
      "epoch:33 step:26460 [D loss: 0.133390, acc: 100.00%] [G loss: 3.449197]\n",
      "epoch:33 step:26461 [D loss: 0.189046, acc: 96.09%] [G loss: 4.409524]\n",
      "epoch:33 step:26462 [D loss: 0.602976, acc: 65.62%] [G loss: 6.350478]\n",
      "epoch:33 step:26463 [D loss: 0.137439, acc: 100.00%] [G loss: 6.056188]\n",
      "epoch:33 step:26464 [D loss: 0.671068, acc: 57.03%] [G loss: 3.401634]\n",
      "epoch:33 step:26465 [D loss: 0.813491, acc: 52.34%] [G loss: 5.432075]\n",
      "epoch:33 step:26466 [D loss: 0.099311, acc: 100.00%] [G loss: 6.651484]\n",
      "epoch:33 step:26467 [D loss: 0.178434, acc: 95.31%] [G loss: 5.295901]\n",
      "epoch:33 step:26468 [D loss: 0.547532, acc: 73.44%] [G loss: 7.548927]\n",
      "epoch:33 step:26469 [D loss: 0.273918, acc: 89.06%] [G loss: 4.059111]\n",
      "epoch:33 step:26470 [D loss: 0.210254, acc: 96.88%] [G loss: 4.482009]\n",
      "epoch:33 step:26471 [D loss: 0.183247, acc: 100.00%] [G loss: 4.309136]\n",
      "epoch:33 step:26472 [D loss: 0.264770, acc: 96.88%] [G loss: 4.414119]\n",
      "epoch:33 step:26473 [D loss: 0.466843, acc: 68.75%] [G loss: 4.404094]\n",
      "epoch:33 step:26474 [D loss: 0.427568, acc: 79.69%] [G loss: 4.682737]\n",
      "epoch:33 step:26475 [D loss: 0.312363, acc: 85.16%] [G loss: 5.274917]\n",
      "epoch:33 step:26476 [D loss: 0.131557, acc: 100.00%] [G loss: 6.537986]\n",
      "epoch:33 step:26477 [D loss: 0.334385, acc: 93.75%] [G loss: 6.564728]\n",
      "epoch:33 step:26478 [D loss: 0.172882, acc: 98.44%] [G loss: 3.180427]\n",
      "epoch:33 step:26479 [D loss: 0.155470, acc: 98.44%] [G loss: 5.298280]\n",
      "epoch:33 step:26480 [D loss: 0.332987, acc: 87.50%] [G loss: 4.537562]\n",
      "epoch:33 step:26481 [D loss: 0.160276, acc: 97.66%] [G loss: 5.615255]\n",
      "epoch:33 step:26482 [D loss: 0.907026, acc: 39.06%] [G loss: 6.978916]\n",
      "epoch:33 step:26483 [D loss: 0.666976, acc: 63.28%] [G loss: 2.739682]\n",
      "epoch:33 step:26484 [D loss: 0.055576, acc: 100.00%] [G loss: 7.461553]\n",
      "epoch:33 step:26485 [D loss: 0.536894, acc: 64.06%] [G loss: 5.176941]\n",
      "epoch:33 step:26486 [D loss: 0.129113, acc: 99.22%] [G loss: 4.747477]\n",
      "epoch:33 step:26487 [D loss: 0.985540, acc: 50.00%] [G loss: 5.924424]\n",
      "epoch:33 step:26488 [D loss: 0.091093, acc: 100.00%] [G loss: 3.830762]\n",
      "epoch:33 step:26489 [D loss: 0.470713, acc: 78.91%] [G loss: 5.116362]\n",
      "epoch:33 step:26490 [D loss: 0.511593, acc: 82.03%] [G loss: 6.082711]\n",
      "epoch:33 step:26491 [D loss: 0.507196, acc: 76.56%] [G loss: 6.517743]\n",
      "epoch:33 step:26492 [D loss: 0.389377, acc: 88.28%] [G loss: 4.952127]\n",
      "epoch:33 step:26493 [D loss: 0.240072, acc: 99.22%] [G loss: 2.791505]\n",
      "epoch:33 step:26494 [D loss: 0.250975, acc: 94.53%] [G loss: 4.813452]\n",
      "epoch:33 step:26495 [D loss: 0.637162, acc: 64.84%] [G loss: 5.385881]\n",
      "epoch:33 step:26496 [D loss: 0.110605, acc: 100.00%] [G loss: 6.988543]\n",
      "epoch:33 step:26497 [D loss: 0.613345, acc: 63.28%] [G loss: 7.812423]\n",
      "epoch:33 step:26498 [D loss: 0.079503, acc: 100.00%] [G loss: 4.976295]\n",
      "epoch:33 step:26499 [D loss: 0.068587, acc: 99.22%] [G loss: 4.948682]\n",
      "epoch:33 step:26500 [D loss: 0.305341, acc: 94.53%] [G loss: 2.743598]\n",
      "epoch:33 step:26501 [D loss: 0.504835, acc: 64.06%] [G loss: 4.904354]\n",
      "epoch:33 step:26502 [D loss: 0.517751, acc: 64.06%] [G loss: 4.337875]\n",
      "epoch:33 step:26503 [D loss: 1.391845, acc: 46.88%] [G loss: 2.956126]\n",
      "epoch:33 step:26504 [D loss: 0.508563, acc: 64.06%] [G loss: 6.191688]\n",
      "epoch:33 step:26505 [D loss: 0.813555, acc: 53.12%] [G loss: 5.685147]\n",
      "epoch:33 step:26506 [D loss: 0.552503, acc: 67.97%] [G loss: 3.571274]\n",
      "epoch:33 step:26507 [D loss: 0.230397, acc: 96.09%] [G loss: 3.706896]\n",
      "epoch:33 step:26508 [D loss: 0.258635, acc: 99.22%] [G loss: 4.148535]\n",
      "epoch:33 step:26509 [D loss: 0.522902, acc: 75.00%] [G loss: 4.965095]\n",
      "epoch:33 step:26510 [D loss: 0.243062, acc: 91.41%] [G loss: 3.740160]\n",
      "epoch:33 step:26511 [D loss: 0.354872, acc: 82.03%] [G loss: 4.233699]\n",
      "epoch:33 step:26512 [D loss: 0.450754, acc: 82.81%] [G loss: 4.617660]\n",
      "epoch:33 step:26513 [D loss: 0.351070, acc: 89.06%] [G loss: 5.550271]\n",
      "epoch:33 step:26514 [D loss: 0.042340, acc: 100.00%] [G loss: 5.290663]\n",
      "epoch:33 step:26515 [D loss: 0.462592, acc: 82.03%] [G loss: 3.465678]\n",
      "epoch:33 step:26516 [D loss: 0.118211, acc: 98.44%] [G loss: 3.436963]\n",
      "epoch:33 step:26517 [D loss: 0.402181, acc: 89.06%] [G loss: 3.652778]\n",
      "epoch:33 step:26518 [D loss: 0.080192, acc: 100.00%] [G loss: 6.097289]\n",
      "epoch:33 step:26519 [D loss: 0.193132, acc: 95.31%] [G loss: 6.139076]\n",
      "epoch:33 step:26520 [D loss: 0.175394, acc: 97.66%] [G loss: 4.422007]\n",
      "epoch:33 step:26521 [D loss: 0.094706, acc: 100.00%] [G loss: 5.844679]\n",
      "epoch:33 step:26522 [D loss: 0.286825, acc: 91.41%] [G loss: 5.420907]\n",
      "epoch:33 step:26523 [D loss: 0.362875, acc: 94.53%] [G loss: 4.221726]\n",
      "epoch:33 step:26524 [D loss: 1.485652, acc: 20.31%] [G loss: 6.784779]\n",
      "epoch:33 step:26525 [D loss: 0.191270, acc: 97.66%] [G loss: 4.644037]\n",
      "epoch:33 step:26526 [D loss: 0.675596, acc: 54.69%] [G loss: 6.613553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26527 [D loss: 0.974491, acc: 48.44%] [G loss: 5.465119]\n",
      "epoch:33 step:26528 [D loss: 0.415000, acc: 73.44%] [G loss: 6.372653]\n",
      "epoch:33 step:26529 [D loss: 0.150978, acc: 99.22%] [G loss: 4.456889]\n",
      "epoch:33 step:26530 [D loss: 1.268243, acc: 44.53%] [G loss: 5.739472]\n",
      "epoch:33 step:26531 [D loss: 0.469239, acc: 82.03%] [G loss: 3.078186]\n",
      "epoch:33 step:26532 [D loss: 0.379244, acc: 87.50%] [G loss: 3.948350]\n",
      "epoch:33 step:26533 [D loss: 0.015380, acc: 100.00%] [G loss: 7.593529]\n",
      "epoch:33 step:26534 [D loss: 0.319594, acc: 82.03%] [G loss: 5.875490]\n",
      "epoch:33 step:26535 [D loss: 0.667704, acc: 60.94%] [G loss: 4.559566]\n",
      "epoch:33 step:26536 [D loss: 0.321759, acc: 82.03%] [G loss: 3.399638]\n",
      "epoch:33 step:26537 [D loss: 0.566806, acc: 64.84%] [G loss: 7.286059]\n",
      "epoch:33 step:26538 [D loss: 0.403659, acc: 85.94%] [G loss: 5.680685]\n",
      "epoch:33 step:26539 [D loss: 0.350611, acc: 89.84%] [G loss: 7.301232]\n",
      "epoch:33 step:26540 [D loss: 0.032894, acc: 100.00%] [G loss: 7.791530]\n",
      "epoch:33 step:26541 [D loss: 0.198527, acc: 98.44%] [G loss: 5.104501]\n",
      "epoch:33 step:26542 [D loss: 0.516157, acc: 78.12%] [G loss: 4.462365]\n",
      "epoch:33 step:26543 [D loss: 0.076033, acc: 100.00%] [G loss: 4.840851]\n",
      "epoch:33 step:26544 [D loss: 0.098489, acc: 99.22%] [G loss: 4.056828]\n",
      "epoch:33 step:26545 [D loss: 0.476535, acc: 77.34%] [G loss: 3.704059]\n",
      "epoch:33 step:26546 [D loss: 0.179908, acc: 99.22%] [G loss: 5.096898]\n",
      "epoch:33 step:26547 [D loss: 0.204004, acc: 98.44%] [G loss: 6.271049]\n",
      "epoch:33 step:26548 [D loss: 0.669687, acc: 61.72%] [G loss: 7.044271]\n",
      "epoch:33 step:26549 [D loss: 0.321674, acc: 90.62%] [G loss: 3.337651]\n",
      "epoch:33 step:26550 [D loss: 0.433964, acc: 81.25%] [G loss: 5.738960]\n",
      "epoch:33 step:26551 [D loss: 0.214742, acc: 99.22%] [G loss: 5.129532]\n",
      "epoch:33 step:26552 [D loss: 0.545154, acc: 68.75%] [G loss: 5.954237]\n",
      "epoch:33 step:26553 [D loss: 0.625026, acc: 69.53%] [G loss: 3.570064]\n",
      "epoch:33 step:26554 [D loss: 0.075215, acc: 100.00%] [G loss: 5.583273]\n",
      "epoch:34 step:26555 [D loss: 0.388962, acc: 91.41%] [G loss: 4.734637]\n",
      "epoch:34 step:26556 [D loss: 0.077397, acc: 100.00%] [G loss: 6.293537]\n",
      "epoch:34 step:26557 [D loss: 0.228724, acc: 96.09%] [G loss: 5.299247]\n",
      "epoch:34 step:26558 [D loss: 1.202232, acc: 50.00%] [G loss: 3.896409]\n",
      "epoch:34 step:26559 [D loss: 0.219262, acc: 95.31%] [G loss: 5.590024]\n",
      "epoch:34 step:26560 [D loss: 0.579254, acc: 64.06%] [G loss: 6.391887]\n",
      "epoch:34 step:26561 [D loss: 0.809575, acc: 52.34%] [G loss: 6.886312]\n",
      "epoch:34 step:26562 [D loss: 0.194191, acc: 100.00%] [G loss: 5.866795]\n",
      "epoch:34 step:26563 [D loss: 0.158694, acc: 99.22%] [G loss: 4.882969]\n",
      "epoch:34 step:26564 [D loss: 1.312072, acc: 13.28%] [G loss: 6.638879]\n",
      "epoch:34 step:26565 [D loss: 0.133382, acc: 100.00%] [G loss: 2.962555]\n",
      "epoch:34 step:26566 [D loss: 0.172538, acc: 100.00%] [G loss: 5.417377]\n",
      "epoch:34 step:26567 [D loss: 0.090390, acc: 100.00%] [G loss: 5.753084]\n",
      "epoch:34 step:26568 [D loss: 0.271371, acc: 96.09%] [G loss: 5.091509]\n",
      "epoch:34 step:26569 [D loss: 0.263640, acc: 94.53%] [G loss: 4.033263]\n",
      "epoch:34 step:26570 [D loss: 1.341879, acc: 50.00%] [G loss: 2.726814]\n",
      "epoch:34 step:26571 [D loss: 1.103558, acc: 30.47%] [G loss: 6.845144]\n",
      "epoch:34 step:26572 [D loss: 0.506954, acc: 68.75%] [G loss: 3.246121]\n",
      "epoch:34 step:26573 [D loss: 1.024607, acc: 35.94%] [G loss: 6.934260]\n",
      "epoch:34 step:26574 [D loss: 0.281177, acc: 91.41%] [G loss: 4.640337]\n",
      "epoch:34 step:26575 [D loss: 0.378972, acc: 84.38%] [G loss: 4.821322]\n",
      "epoch:34 step:26576 [D loss: 0.311892, acc: 86.72%] [G loss: 2.673800]\n",
      "epoch:34 step:26577 [D loss: 0.149264, acc: 97.66%] [G loss: 2.445873]\n",
      "epoch:34 step:26578 [D loss: 0.223619, acc: 95.31%] [G loss: 4.243173]\n",
      "epoch:34 step:26579 [D loss: 0.508915, acc: 67.97%] [G loss: 5.752140]\n",
      "epoch:34 step:26580 [D loss: 0.165423, acc: 100.00%] [G loss: 6.899173]\n",
      "epoch:34 step:26581 [D loss: 0.326777, acc: 82.03%] [G loss: 6.036328]\n",
      "epoch:34 step:26582 [D loss: 0.275821, acc: 92.97%] [G loss: 4.766539]\n",
      "epoch:34 step:26583 [D loss: 0.130638, acc: 98.44%] [G loss: 2.715232]\n",
      "epoch:34 step:26584 [D loss: 0.833777, acc: 51.56%] [G loss: 6.169026]\n",
      "epoch:34 step:26585 [D loss: 0.600284, acc: 61.72%] [G loss: 6.736176]\n",
      "epoch:34 step:26586 [D loss: 1.243573, acc: 25.78%] [G loss: 5.899316]\n",
      "epoch:34 step:26587 [D loss: 0.207651, acc: 98.44%] [G loss: 4.694789]\n",
      "epoch:34 step:26588 [D loss: 0.377264, acc: 77.34%] [G loss: 5.601106]\n",
      "epoch:34 step:26589 [D loss: 1.012820, acc: 31.25%] [G loss: 5.311536]\n",
      "epoch:34 step:26590 [D loss: 0.762151, acc: 52.34%] [G loss: 7.634218]\n",
      "epoch:34 step:26591 [D loss: 0.232029, acc: 94.53%] [G loss: 4.639472]\n",
      "epoch:34 step:26592 [D loss: 0.521525, acc: 75.00%] [G loss: 4.963137]\n",
      "epoch:34 step:26593 [D loss: 0.804670, acc: 50.78%] [G loss: 5.378210]\n",
      "epoch:34 step:26594 [D loss: 0.511786, acc: 67.19%] [G loss: 4.558847]\n",
      "epoch:34 step:26595 [D loss: 0.329954, acc: 89.84%] [G loss: 2.671554]\n",
      "epoch:34 step:26596 [D loss: 0.450270, acc: 85.16%] [G loss: 4.397683]\n",
      "epoch:34 step:26597 [D loss: 0.101462, acc: 99.22%] [G loss: 5.524642]\n",
      "epoch:34 step:26598 [D loss: 0.413758, acc: 71.88%] [G loss: 6.766012]\n",
      "epoch:34 step:26599 [D loss: 0.292583, acc: 92.19%] [G loss: 3.770016]\n",
      "epoch:34 step:26600 [D loss: 0.121880, acc: 98.44%] [G loss: 5.842540]\n",
      "epoch:34 step:26601 [D loss: 0.619886, acc: 66.41%] [G loss: 4.567234]\n",
      "epoch:34 step:26602 [D loss: 0.502235, acc: 64.84%] [G loss: 4.920963]\n",
      "epoch:34 step:26603 [D loss: 0.121258, acc: 99.22%] [G loss: 5.685759]\n",
      "epoch:34 step:26604 [D loss: 0.251005, acc: 92.19%] [G loss: 3.304586]\n",
      "epoch:34 step:26605 [D loss: 0.444337, acc: 71.09%] [G loss: 5.762461]\n",
      "epoch:34 step:26606 [D loss: 0.356886, acc: 85.94%] [G loss: 3.394557]\n",
      "epoch:34 step:26607 [D loss: 0.661610, acc: 60.94%] [G loss: 4.000130]\n",
      "epoch:34 step:26608 [D loss: 0.513337, acc: 67.97%] [G loss: 4.260778]\n",
      "epoch:34 step:26609 [D loss: 0.282923, acc: 95.31%] [G loss: 5.787612]\n",
      "epoch:34 step:26610 [D loss: 0.212590, acc: 96.88%] [G loss: 2.728299]\n",
      "epoch:34 step:26611 [D loss: 0.094724, acc: 100.00%] [G loss: 5.641675]\n",
      "epoch:34 step:26612 [D loss: 2.288232, acc: 2.34%] [G loss: 7.540470]\n",
      "epoch:34 step:26613 [D loss: 0.187202, acc: 98.44%] [G loss: 4.567744]\n",
      "epoch:34 step:26614 [D loss: 0.062884, acc: 100.00%] [G loss: 4.563838]\n",
      "epoch:34 step:26615 [D loss: 0.233627, acc: 96.09%] [G loss: 4.648445]\n",
      "epoch:34 step:26616 [D loss: 0.171667, acc: 99.22%] [G loss: 5.496578]\n",
      "epoch:34 step:26617 [D loss: 0.704141, acc: 51.56%] [G loss: 6.997154]\n",
      "epoch:34 step:26618 [D loss: 0.069521, acc: 100.00%] [G loss: 5.214296]\n",
      "epoch:34 step:26619 [D loss: 0.558961, acc: 75.00%] [G loss: 5.062079]\n",
      "epoch:34 step:26620 [D loss: 0.459601, acc: 75.00%] [G loss: 4.720206]\n",
      "epoch:34 step:26621 [D loss: 0.064946, acc: 100.00%] [G loss: 5.817649]\n",
      "epoch:34 step:26622 [D loss: 0.464746, acc: 69.53%] [G loss: 4.754732]\n",
      "epoch:34 step:26623 [D loss: 0.114908, acc: 100.00%] [G loss: 4.388981]\n",
      "epoch:34 step:26624 [D loss: 1.182673, acc: 21.09%] [G loss: 5.263494]\n",
      "epoch:34 step:26625 [D loss: 0.245024, acc: 94.53%] [G loss: 5.060025]\n",
      "epoch:34 step:26626 [D loss: 1.070874, acc: 50.00%] [G loss: 3.859374]\n",
      "epoch:34 step:26627 [D loss: 0.165004, acc: 98.44%] [G loss: 5.769565]\n",
      "epoch:34 step:26628 [D loss: 0.301923, acc: 93.75%] [G loss: 3.675109]\n",
      "epoch:34 step:26629 [D loss: 0.231768, acc: 97.66%] [G loss: 3.635413]\n",
      "epoch:34 step:26630 [D loss: 0.069547, acc: 99.22%] [G loss: 7.410883]\n",
      "epoch:34 step:26631 [D loss: 0.421375, acc: 84.38%] [G loss: 6.012687]\n",
      "epoch:34 step:26632 [D loss: 0.552921, acc: 62.50%] [G loss: 3.930329]\n",
      "epoch:34 step:26633 [D loss: 0.176849, acc: 98.44%] [G loss: 4.969493]\n",
      "epoch:34 step:26634 [D loss: 0.316661, acc: 81.25%] [G loss: 4.553338]\n",
      "epoch:34 step:26635 [D loss: 0.277789, acc: 89.06%] [G loss: 4.570592]\n",
      "epoch:34 step:26636 [D loss: 0.967685, acc: 41.41%] [G loss: 4.388060]\n",
      "epoch:34 step:26637 [D loss: 0.384877, acc: 92.97%] [G loss: 3.818496]\n",
      "epoch:34 step:26638 [D loss: 0.412038, acc: 74.22%] [G loss: 5.208241]\n",
      "epoch:34 step:26639 [D loss: 0.015277, acc: 100.00%] [G loss: 6.618307]\n",
      "epoch:34 step:26640 [D loss: 0.226680, acc: 97.66%] [G loss: 5.541361]\n",
      "epoch:34 step:26641 [D loss: 0.336771, acc: 91.41%] [G loss: 5.395782]\n",
      "epoch:34 step:26642 [D loss: 0.112347, acc: 99.22%] [G loss: 3.284264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:26643 [D loss: 0.383404, acc: 75.78%] [G loss: 5.966733]\n",
      "epoch:34 step:26644 [D loss: 0.390203, acc: 82.03%] [G loss: 4.892018]\n",
      "epoch:34 step:26645 [D loss: 0.187599, acc: 98.44%] [G loss: 3.852418]\n",
      "epoch:34 step:26646 [D loss: 0.206824, acc: 99.22%] [G loss: 6.982972]\n",
      "epoch:34 step:26647 [D loss: 0.412647, acc: 78.91%] [G loss: 6.682277]\n",
      "epoch:34 step:26648 [D loss: 0.102052, acc: 99.22%] [G loss: 5.441922]\n",
      "epoch:34 step:26649 [D loss: 0.028346, acc: 100.00%] [G loss: 5.751035]\n",
      "epoch:34 step:26650 [D loss: 1.067034, acc: 25.78%] [G loss: 5.505586]\n",
      "epoch:34 step:26651 [D loss: 0.530832, acc: 66.41%] [G loss: 2.790693]\n",
      "epoch:34 step:26652 [D loss: 0.129388, acc: 97.66%] [G loss: 5.193554]\n",
      "epoch:34 step:26653 [D loss: 1.043506, acc: 50.00%] [G loss: 7.328502]\n",
      "epoch:34 step:26654 [D loss: 0.270640, acc: 94.53%] [G loss: 3.911703]\n",
      "epoch:34 step:26655 [D loss: 0.497238, acc: 63.28%] [G loss: 3.397343]\n",
      "epoch:34 step:26656 [D loss: 0.512486, acc: 74.22%] [G loss: 5.817310]\n",
      "epoch:34 step:26657 [D loss: 0.309462, acc: 92.19%] [G loss: 6.184299]\n",
      "epoch:34 step:26658 [D loss: 0.676785, acc: 57.03%] [G loss: 6.022042]\n",
      "epoch:34 step:26659 [D loss: 0.061528, acc: 100.00%] [G loss: 4.121955]\n",
      "epoch:34 step:26660 [D loss: 0.193993, acc: 96.09%] [G loss: 6.306102]\n",
      "epoch:34 step:26661 [D loss: 0.489890, acc: 66.41%] [G loss: 5.632497]\n",
      "epoch:34 step:26662 [D loss: 0.237980, acc: 96.88%] [G loss: 5.843061]\n",
      "epoch:34 step:26663 [D loss: 0.564764, acc: 66.41%] [G loss: 3.698105]\n",
      "epoch:34 step:26664 [D loss: 0.508224, acc: 78.12%] [G loss: 6.064358]\n",
      "epoch:34 step:26665 [D loss: 0.076087, acc: 100.00%] [G loss: 3.564582]\n",
      "epoch:34 step:26666 [D loss: 0.142613, acc: 99.22%] [G loss: 3.884212]\n",
      "epoch:34 step:26667 [D loss: 0.127557, acc: 99.22%] [G loss: 4.204530]\n",
      "epoch:34 step:26668 [D loss: 0.276154, acc: 92.97%] [G loss: 4.605471]\n",
      "epoch:34 step:26669 [D loss: 0.309758, acc: 94.53%] [G loss: 4.229217]\n",
      "epoch:34 step:26670 [D loss: 0.237264, acc: 92.97%] [G loss: 7.344101]\n",
      "epoch:34 step:26671 [D loss: 0.924446, acc: 39.06%] [G loss: 3.377394]\n",
      "epoch:34 step:26672 [D loss: 0.110319, acc: 100.00%] [G loss: 5.386524]\n",
      "epoch:34 step:26673 [D loss: 0.344785, acc: 89.06%] [G loss: 4.373515]\n",
      "epoch:34 step:26674 [D loss: 0.291681, acc: 89.06%] [G loss: 6.311742]\n",
      "epoch:34 step:26675 [D loss: 0.976474, acc: 34.38%] [G loss: 5.600172]\n",
      "epoch:34 step:26676 [D loss: 0.095494, acc: 99.22%] [G loss: 5.235723]\n",
      "epoch:34 step:26677 [D loss: 0.387384, acc: 86.72%] [G loss: 5.509888]\n",
      "epoch:34 step:26678 [D loss: 0.903603, acc: 42.97%] [G loss: 6.767082]\n",
      "epoch:34 step:26679 [D loss: 1.091217, acc: 50.00%] [G loss: 3.476724]\n",
      "epoch:34 step:26680 [D loss: 0.189895, acc: 96.88%] [G loss: 4.373631]\n",
      "epoch:34 step:26681 [D loss: 0.232155, acc: 93.75%] [G loss: 6.221447]\n",
      "epoch:34 step:26682 [D loss: 0.120876, acc: 98.44%] [G loss: 6.631884]\n",
      "epoch:34 step:26683 [D loss: 0.231022, acc: 94.53%] [G loss: 4.654899]\n",
      "epoch:34 step:26684 [D loss: 0.265585, acc: 96.09%] [G loss: 5.535067]\n",
      "epoch:34 step:26685 [D loss: 0.086407, acc: 99.22%] [G loss: 7.920658]\n",
      "epoch:34 step:26686 [D loss: 0.270718, acc: 96.88%] [G loss: 2.842487]\n",
      "epoch:34 step:26687 [D loss: 0.301926, acc: 91.41%] [G loss: 5.686101]\n",
      "epoch:34 step:26688 [D loss: 0.666713, acc: 60.94%] [G loss: 7.107297]\n",
      "epoch:34 step:26689 [D loss: 0.968582, acc: 52.34%] [G loss: 4.402341]\n",
      "epoch:34 step:26690 [D loss: 0.126756, acc: 98.44%] [G loss: 6.342304]\n",
      "epoch:34 step:26691 [D loss: 0.217661, acc: 96.09%] [G loss: 3.980435]\n",
      "epoch:34 step:26692 [D loss: 0.361970, acc: 87.50%] [G loss: 4.722537]\n",
      "epoch:34 step:26693 [D loss: 0.855153, acc: 43.75%] [G loss: 7.580409]\n",
      "epoch:34 step:26694 [D loss: 0.426646, acc: 85.16%] [G loss: 3.477216]\n",
      "epoch:34 step:26695 [D loss: 0.432910, acc: 75.78%] [G loss: 4.536472]\n",
      "epoch:34 step:26696 [D loss: 1.615983, acc: 45.31%] [G loss: 3.477653]\n",
      "epoch:34 step:26697 [D loss: 0.225242, acc: 95.31%] [G loss: 4.472233]\n",
      "epoch:34 step:26698 [D loss: 0.182530, acc: 96.88%] [G loss: 3.906887]\n",
      "epoch:34 step:26699 [D loss: 0.357853, acc: 80.47%] [G loss: 6.592103]\n",
      "epoch:34 step:26700 [D loss: 0.347191, acc: 80.47%] [G loss: 5.449644]\n",
      "epoch:34 step:26701 [D loss: 0.205521, acc: 99.22%] [G loss: 3.878981]\n",
      "epoch:34 step:26702 [D loss: 0.464156, acc: 78.12%] [G loss: 3.572322]\n",
      "epoch:34 step:26703 [D loss: 0.094660, acc: 100.00%] [G loss: 4.459305]\n",
      "epoch:34 step:26704 [D loss: 0.892796, acc: 52.34%] [G loss: 5.485704]\n",
      "epoch:34 step:26705 [D loss: 0.421931, acc: 83.59%] [G loss: 5.487001]\n",
      "epoch:34 step:26706 [D loss: 0.135308, acc: 99.22%] [G loss: 3.709755]\n",
      "epoch:34 step:26707 [D loss: 0.220772, acc: 92.19%] [G loss: 5.157439]\n",
      "epoch:34 step:26708 [D loss: 0.618212, acc: 61.72%] [G loss: 4.404567]\n",
      "epoch:34 step:26709 [D loss: 0.208466, acc: 96.88%] [G loss: 7.616666]\n",
      "epoch:34 step:26710 [D loss: 0.667916, acc: 61.72%] [G loss: 5.674374]\n",
      "epoch:34 step:26711 [D loss: 0.502030, acc: 62.50%] [G loss: 3.893860]\n",
      "epoch:34 step:26712 [D loss: 0.485885, acc: 78.91%] [G loss: 6.282426]\n",
      "epoch:34 step:26713 [D loss: 0.660806, acc: 57.03%] [G loss: 4.466583]\n",
      "epoch:34 step:26714 [D loss: 1.050250, acc: 35.94%] [G loss: 5.259150]\n",
      "epoch:34 step:26715 [D loss: 0.033794, acc: 100.00%] [G loss: 6.987043]\n",
      "epoch:34 step:26716 [D loss: 0.044810, acc: 100.00%] [G loss: 5.776317]\n",
      "epoch:34 step:26717 [D loss: 0.512774, acc: 75.00%] [G loss: 4.608152]\n",
      "epoch:34 step:26718 [D loss: 0.480786, acc: 66.41%] [G loss: 3.643012]\n",
      "epoch:34 step:26719 [D loss: 0.325998, acc: 88.28%] [G loss: 5.519883]\n",
      "epoch:34 step:26720 [D loss: 1.791298, acc: 18.75%] [G loss: 7.003351]\n",
      "epoch:34 step:26721 [D loss: 0.628394, acc: 55.47%] [G loss: 4.464807]\n",
      "epoch:34 step:26722 [D loss: 0.361435, acc: 84.38%] [G loss: 3.957398]\n",
      "epoch:34 step:26723 [D loss: 0.133092, acc: 100.00%] [G loss: 3.787807]\n",
      "epoch:34 step:26724 [D loss: 0.321051, acc: 89.84%] [G loss: 3.297637]\n",
      "epoch:34 step:26725 [D loss: 0.057185, acc: 100.00%] [G loss: 3.276759]\n",
      "epoch:34 step:26726 [D loss: 0.490146, acc: 76.56%] [G loss: 4.963295]\n",
      "epoch:34 step:26727 [D loss: 0.306966, acc: 86.72%] [G loss: 3.105409]\n",
      "epoch:34 step:26728 [D loss: 0.136150, acc: 98.44%] [G loss: 6.699650]\n",
      "epoch:34 step:26729 [D loss: 0.103829, acc: 99.22%] [G loss: 6.627760]\n",
      "epoch:34 step:26730 [D loss: 0.088855, acc: 99.22%] [G loss: 4.953849]\n",
      "epoch:34 step:26731 [D loss: 0.973165, acc: 50.00%] [G loss: 4.406345]\n",
      "epoch:34 step:26732 [D loss: 0.363159, acc: 90.62%] [G loss: 5.279552]\n",
      "epoch:34 step:26733 [D loss: 0.568322, acc: 60.94%] [G loss: 5.514085]\n",
      "epoch:34 step:26734 [D loss: 0.138370, acc: 99.22%] [G loss: 6.153984]\n",
      "epoch:34 step:26735 [D loss: 0.062449, acc: 100.00%] [G loss: 3.515185]\n",
      "epoch:34 step:26736 [D loss: 0.169153, acc: 99.22%] [G loss: 4.824036]\n",
      "epoch:34 step:26737 [D loss: 0.519773, acc: 64.84%] [G loss: 3.607502]\n",
      "epoch:34 step:26738 [D loss: 0.831896, acc: 55.47%] [G loss: 4.200700]\n",
      "epoch:34 step:26739 [D loss: 0.604961, acc: 64.84%] [G loss: 5.923759]\n",
      "epoch:34 step:26740 [D loss: 0.256095, acc: 96.09%] [G loss: 4.917006]\n",
      "epoch:34 step:26741 [D loss: 0.106607, acc: 100.00%] [G loss: 5.752960]\n",
      "epoch:34 step:26742 [D loss: 0.596552, acc: 71.88%] [G loss: 5.446075]\n",
      "epoch:34 step:26743 [D loss: 0.079074, acc: 99.22%] [G loss: 5.720188]\n",
      "epoch:34 step:26744 [D loss: 0.621376, acc: 60.16%] [G loss: 5.057700]\n",
      "epoch:34 step:26745 [D loss: 0.497071, acc: 64.06%] [G loss: 5.636840]\n",
      "epoch:34 step:26746 [D loss: 0.629963, acc: 59.38%] [G loss: 7.201487]\n",
      "epoch:34 step:26747 [D loss: 0.072744, acc: 99.22%] [G loss: 6.765308]\n",
      "epoch:34 step:26748 [D loss: 0.169117, acc: 95.31%] [G loss: 5.516216]\n",
      "epoch:34 step:26749 [D loss: 0.270133, acc: 96.88%] [G loss: 4.928724]\n",
      "epoch:34 step:26750 [D loss: 1.509636, acc: 39.84%] [G loss: 4.373530]\n",
      "epoch:34 step:26751 [D loss: 0.094653, acc: 100.00%] [G loss: 4.849971]\n",
      "epoch:34 step:26752 [D loss: 0.202485, acc: 99.22%] [G loss: 5.274960]\n",
      "epoch:34 step:26753 [D loss: 0.778102, acc: 53.91%] [G loss: 7.282387]\n",
      "epoch:34 step:26754 [D loss: 0.780221, acc: 53.12%] [G loss: 3.234159]\n",
      "epoch:34 step:26755 [D loss: 0.182890, acc: 98.44%] [G loss: 5.357573]\n",
      "epoch:34 step:26756 [D loss: 0.848198, acc: 53.12%] [G loss: 7.614088]\n",
      "epoch:34 step:26757 [D loss: 0.819400, acc: 52.34%] [G loss: 2.484727]\n",
      "epoch:34 step:26758 [D loss: 0.220226, acc: 92.97%] [G loss: 6.609924]\n",
      "epoch:34 step:26759 [D loss: 0.120029, acc: 99.22%] [G loss: 4.903980]\n",
      "epoch:34 step:26760 [D loss: 0.216861, acc: 95.31%] [G loss: 6.218909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:26761 [D loss: 0.202124, acc: 96.09%] [G loss: 3.232324]\n",
      "epoch:34 step:26762 [D loss: 0.562809, acc: 64.06%] [G loss: 7.279817]\n",
      "epoch:34 step:26763 [D loss: 0.215477, acc: 98.44%] [G loss: 4.597860]\n",
      "epoch:34 step:26764 [D loss: 0.412765, acc: 79.69%] [G loss: 2.569272]\n",
      "epoch:34 step:26765 [D loss: 0.630220, acc: 63.28%] [G loss: 5.608087]\n",
      "epoch:34 step:26766 [D loss: 0.088066, acc: 97.66%] [G loss: 7.388178]\n",
      "epoch:34 step:26767 [D loss: 0.235223, acc: 95.31%] [G loss: 4.070199]\n",
      "epoch:34 step:26768 [D loss: 0.416540, acc: 76.56%] [G loss: 4.010689]\n",
      "epoch:34 step:26769 [D loss: 0.286898, acc: 94.53%] [G loss: 5.613974]\n",
      "epoch:34 step:26770 [D loss: 0.240835, acc: 94.53%] [G loss: 4.218254]\n",
      "epoch:34 step:26771 [D loss: 0.454523, acc: 81.25%] [G loss: 5.166831]\n",
      "epoch:34 step:26772 [D loss: 0.272287, acc: 90.62%] [G loss: 3.955445]\n",
      "epoch:34 step:26773 [D loss: 0.908321, acc: 50.00%] [G loss: 4.232960]\n",
      "epoch:34 step:26774 [D loss: 0.365344, acc: 79.69%] [G loss: 4.775753]\n",
      "epoch:34 step:26775 [D loss: 1.047408, acc: 48.44%] [G loss: 4.211252]\n",
      "epoch:34 step:26776 [D loss: 0.355050, acc: 85.94%] [G loss: 5.739802]\n",
      "epoch:34 step:26777 [D loss: 0.515264, acc: 75.78%] [G loss: 3.805995]\n",
      "epoch:34 step:26778 [D loss: 0.079285, acc: 100.00%] [G loss: 3.475850]\n",
      "epoch:34 step:26779 [D loss: 0.646542, acc: 60.16%] [G loss: 7.882069]\n",
      "epoch:34 step:26780 [D loss: 0.439255, acc: 71.09%] [G loss: 2.717476]\n",
      "epoch:34 step:26781 [D loss: 0.178649, acc: 97.66%] [G loss: 4.417110]\n",
      "epoch:34 step:26782 [D loss: 0.481997, acc: 72.66%] [G loss: 2.820058]\n",
      "epoch:34 step:26783 [D loss: 0.190639, acc: 96.09%] [G loss: 4.113689]\n",
      "epoch:34 step:26784 [D loss: 0.769611, acc: 54.69%] [G loss: 6.802599]\n",
      "epoch:34 step:26785 [D loss: 1.019264, acc: 50.00%] [G loss: 4.451742]\n",
      "epoch:34 step:26786 [D loss: 1.131535, acc: 27.34%] [G loss: 3.519006]\n",
      "epoch:34 step:26787 [D loss: 0.112107, acc: 100.00%] [G loss: 5.043678]\n",
      "epoch:34 step:26788 [D loss: 0.179116, acc: 98.44%] [G loss: 6.515388]\n",
      "epoch:34 step:26789 [D loss: 0.563501, acc: 71.88%] [G loss: 3.477439]\n",
      "epoch:34 step:26790 [D loss: 0.166917, acc: 98.44%] [G loss: 5.569953]\n",
      "epoch:34 step:26791 [D loss: 0.349430, acc: 92.19%] [G loss: 4.304809]\n",
      "epoch:34 step:26792 [D loss: 0.663292, acc: 58.59%] [G loss: 3.632649]\n",
      "epoch:34 step:26793 [D loss: 0.437247, acc: 71.09%] [G loss: 5.297341]\n",
      "epoch:34 step:26794 [D loss: 0.597019, acc: 70.31%] [G loss: 3.607927]\n",
      "epoch:34 step:26795 [D loss: 1.420028, acc: 50.78%] [G loss: 3.746558]\n",
      "epoch:34 step:26796 [D loss: 0.795010, acc: 53.12%] [G loss: 7.778346]\n",
      "epoch:34 step:26797 [D loss: 0.116925, acc: 100.00%] [G loss: 5.418459]\n",
      "epoch:34 step:26798 [D loss: 0.026068, acc: 100.00%] [G loss: 5.310430]\n",
      "epoch:34 step:26799 [D loss: 0.345031, acc: 92.97%] [G loss: 3.627321]\n",
      "epoch:34 step:26800 [D loss: 0.553625, acc: 70.31%] [G loss: 5.891335]\n",
      "epoch:34 step:26801 [D loss: 0.987977, acc: 38.28%] [G loss: 4.084356]\n",
      "epoch:34 step:26802 [D loss: 0.574204, acc: 63.28%] [G loss: 2.822948]\n",
      "epoch:34 step:26803 [D loss: 0.028434, acc: 100.00%] [G loss: 4.789897]\n",
      "epoch:34 step:26804 [D loss: 0.259282, acc: 89.06%] [G loss: 5.972060]\n",
      "epoch:34 step:26805 [D loss: 0.058691, acc: 100.00%] [G loss: 6.087081]\n",
      "epoch:34 step:26806 [D loss: 0.104717, acc: 99.22%] [G loss: 4.391557]\n",
      "epoch:34 step:26807 [D loss: 1.182317, acc: 39.06%] [G loss: 6.201200]\n",
      "epoch:34 step:26808 [D loss: 0.278529, acc: 91.41%] [G loss: 2.940853]\n",
      "epoch:34 step:26809 [D loss: 0.229732, acc: 93.75%] [G loss: 4.555734]\n",
      "epoch:34 step:26810 [D loss: 0.384478, acc: 86.72%] [G loss: 5.959431]\n",
      "epoch:34 step:26811 [D loss: 0.513336, acc: 67.97%] [G loss: 3.001836]\n",
      "epoch:34 step:26812 [D loss: 0.143319, acc: 96.88%] [G loss: 6.031551]\n",
      "epoch:34 step:26813 [D loss: 0.412618, acc: 78.91%] [G loss: 5.921120]\n",
      "epoch:34 step:26814 [D loss: 0.316319, acc: 83.59%] [G loss: 4.784647]\n",
      "epoch:34 step:26815 [D loss: 0.238608, acc: 92.19%] [G loss: 3.468453]\n",
      "epoch:34 step:26816 [D loss: 0.014592, acc: 100.00%] [G loss: 4.433232]\n",
      "epoch:34 step:26817 [D loss: 0.908430, acc: 46.09%] [G loss: 5.457117]\n",
      "epoch:34 step:26818 [D loss: 0.344507, acc: 86.72%] [G loss: 3.930267]\n",
      "epoch:34 step:26819 [D loss: 0.126021, acc: 99.22%] [G loss: 5.408929]\n",
      "epoch:34 step:26820 [D loss: 0.682832, acc: 60.94%] [G loss: 4.366309]\n",
      "epoch:34 step:26821 [D loss: 0.807566, acc: 47.66%] [G loss: 5.435652]\n",
      "epoch:34 step:26822 [D loss: 1.155358, acc: 21.88%] [G loss: 4.830523]\n",
      "epoch:34 step:26823 [D loss: 0.145268, acc: 98.44%] [G loss: 4.861965]\n",
      "epoch:34 step:26824 [D loss: 0.320979, acc: 92.97%] [G loss: 2.539794]\n",
      "epoch:34 step:26825 [D loss: 0.157547, acc: 96.88%] [G loss: 3.107907]\n",
      "epoch:34 step:26826 [D loss: 0.589113, acc: 57.03%] [G loss: 6.575144]\n",
      "epoch:34 step:26827 [D loss: 0.511455, acc: 73.44%] [G loss: 4.426558]\n",
      "epoch:34 step:26828 [D loss: 0.366674, acc: 81.25%] [G loss: 4.263084]\n",
      "epoch:34 step:26829 [D loss: 0.366659, acc: 84.38%] [G loss: 4.446770]\n",
      "epoch:34 step:26830 [D loss: 0.884213, acc: 50.00%] [G loss: 4.045279]\n",
      "epoch:34 step:26831 [D loss: 0.341184, acc: 87.50%] [G loss: 4.829563]\n",
      "epoch:34 step:26832 [D loss: 1.301939, acc: 50.00%] [G loss: 5.775002]\n",
      "epoch:34 step:26833 [D loss: 0.377495, acc: 85.94%] [G loss: 4.315270]\n",
      "epoch:34 step:26834 [D loss: 0.121926, acc: 99.22%] [G loss: 6.299839]\n",
      "epoch:34 step:26835 [D loss: 0.537674, acc: 68.75%] [G loss: 4.165256]\n",
      "epoch:34 step:26836 [D loss: 0.569687, acc: 71.09%] [G loss: 4.462522]\n",
      "epoch:34 step:26837 [D loss: 0.809965, acc: 42.19%] [G loss: 7.291297]\n",
      "epoch:34 step:26838 [D loss: 0.151034, acc: 98.44%] [G loss: 3.808187]\n",
      "epoch:34 step:26839 [D loss: 0.153145, acc: 100.00%] [G loss: 4.820280]\n",
      "epoch:34 step:26840 [D loss: 0.602252, acc: 68.75%] [G loss: 4.807028]\n",
      "epoch:34 step:26841 [D loss: 0.287706, acc: 89.06%] [G loss: 5.980976]\n",
      "epoch:34 step:26842 [D loss: 0.101071, acc: 100.00%] [G loss: 5.785889]\n",
      "epoch:34 step:26843 [D loss: 0.200387, acc: 98.44%] [G loss: 2.416280]\n",
      "epoch:34 step:26844 [D loss: 0.059290, acc: 100.00%] [G loss: 5.248093]\n",
      "epoch:34 step:26845 [D loss: 1.083303, acc: 28.91%] [G loss: 5.633618]\n",
      "epoch:34 step:26846 [D loss: 0.620035, acc: 56.25%] [G loss: 4.448326]\n",
      "epoch:34 step:26847 [D loss: 0.183344, acc: 98.44%] [G loss: 5.688570]\n",
      "epoch:34 step:26848 [D loss: 0.776086, acc: 54.69%] [G loss: 5.698006]\n",
      "epoch:34 step:26849 [D loss: 0.177469, acc: 95.31%] [G loss: 6.898611]\n",
      "epoch:34 step:26850 [D loss: 0.875204, acc: 53.91%] [G loss: 7.277716]\n",
      "epoch:34 step:26851 [D loss: 0.273709, acc: 92.97%] [G loss: 5.308178]\n",
      "epoch:34 step:26852 [D loss: 0.859668, acc: 47.66%] [G loss: 5.877840]\n",
      "epoch:34 step:26853 [D loss: 0.379921, acc: 84.38%] [G loss: 4.150734]\n",
      "epoch:34 step:26854 [D loss: 0.229437, acc: 97.66%] [G loss: 5.067695]\n",
      "epoch:34 step:26855 [D loss: 0.146882, acc: 100.00%] [G loss: 4.782587]\n",
      "epoch:34 step:26856 [D loss: 0.271000, acc: 97.66%] [G loss: 2.516209]\n",
      "epoch:34 step:26857 [D loss: 0.537705, acc: 78.12%] [G loss: 4.240387]\n",
      "epoch:34 step:26858 [D loss: 0.317063, acc: 95.31%] [G loss: 2.139913]\n",
      "epoch:34 step:26859 [D loss: 0.486827, acc: 68.75%] [G loss: 4.532743]\n",
      "epoch:34 step:26860 [D loss: 0.676920, acc: 60.16%] [G loss: 5.946063]\n",
      "epoch:34 step:26861 [D loss: 1.280656, acc: 50.78%] [G loss: 4.454170]\n",
      "epoch:34 step:26862 [D loss: 0.380685, acc: 89.06%] [G loss: 4.646160]\n",
      "epoch:34 step:26863 [D loss: 0.446739, acc: 67.19%] [G loss: 5.653243]\n",
      "epoch:34 step:26864 [D loss: 0.327330, acc: 83.59%] [G loss: 5.465072]\n",
      "epoch:34 step:26865 [D loss: 0.315413, acc: 92.19%] [G loss: 5.280288]\n",
      "epoch:34 step:26866 [D loss: 0.380355, acc: 77.34%] [G loss: 4.749314]\n",
      "epoch:34 step:26867 [D loss: 0.173021, acc: 98.44%] [G loss: 7.824903]\n",
      "epoch:34 step:26868 [D loss: 0.147926, acc: 99.22%] [G loss: 6.855574]\n",
      "epoch:34 step:26869 [D loss: 1.759320, acc: 37.50%] [G loss: 3.717342]\n",
      "epoch:34 step:26870 [D loss: 0.130828, acc: 100.00%] [G loss: 8.662705]\n",
      "epoch:34 step:26871 [D loss: 0.062235, acc: 100.00%] [G loss: 3.337791]\n",
      "epoch:34 step:26872 [D loss: 0.292010, acc: 89.06%] [G loss: 6.254341]\n",
      "epoch:34 step:26873 [D loss: 1.536702, acc: 5.47%] [G loss: 5.224585]\n",
      "epoch:34 step:26874 [D loss: 0.764142, acc: 54.69%] [G loss: 2.975090]\n",
      "epoch:34 step:26875 [D loss: 0.419683, acc: 86.72%] [G loss: 5.985275]\n",
      "epoch:34 step:26876 [D loss: 0.111864, acc: 99.22%] [G loss: 5.521571]\n",
      "epoch:34 step:26877 [D loss: 0.105733, acc: 100.00%] [G loss: 4.555880]\n",
      "epoch:34 step:26878 [D loss: 0.289564, acc: 94.53%] [G loss: 5.064998]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:26879 [D loss: 0.575303, acc: 67.97%] [G loss: 5.877768]\n",
      "epoch:34 step:26880 [D loss: 0.315813, acc: 94.53%] [G loss: 2.567391]\n",
      "epoch:34 step:26881 [D loss: 0.183894, acc: 96.09%] [G loss: 4.250913]\n",
      "epoch:34 step:26882 [D loss: 0.440518, acc: 70.31%] [G loss: 3.567674]\n",
      "epoch:34 step:26883 [D loss: 0.068187, acc: 100.00%] [G loss: 4.044085]\n",
      "epoch:34 step:26884 [D loss: 0.306153, acc: 86.72%] [G loss: 3.792689]\n",
      "epoch:34 step:26885 [D loss: 0.457922, acc: 78.12%] [G loss: 4.502178]\n",
      "epoch:34 step:26886 [D loss: 0.173801, acc: 98.44%] [G loss: 6.105164]\n",
      "epoch:34 step:26887 [D loss: 0.329428, acc: 82.81%] [G loss: 7.502907]\n",
      "epoch:34 step:26888 [D loss: 0.056479, acc: 100.00%] [G loss: 6.820817]\n",
      "epoch:34 step:26889 [D loss: 0.093314, acc: 99.22%] [G loss: 6.131647]\n",
      "epoch:34 step:26890 [D loss: 0.306128, acc: 92.19%] [G loss: 3.714942]\n",
      "epoch:34 step:26891 [D loss: 0.075149, acc: 100.00%] [G loss: 3.260157]\n",
      "epoch:34 step:26892 [D loss: 0.869700, acc: 35.94%] [G loss: 6.908055]\n",
      "epoch:34 step:26893 [D loss: 0.853025, acc: 50.78%] [G loss: 5.167420]\n",
      "epoch:34 step:26894 [D loss: 1.015363, acc: 51.56%] [G loss: 6.660818]\n",
      "epoch:34 step:26895 [D loss: 0.151277, acc: 99.22%] [G loss: 4.344553]\n",
      "epoch:34 step:26896 [D loss: 1.066292, acc: 32.03%] [G loss: 3.814281]\n",
      "epoch:34 step:26897 [D loss: 0.209302, acc: 97.66%] [G loss: 4.729507]\n",
      "epoch:34 step:26898 [D loss: 0.417817, acc: 82.81%] [G loss: 4.087248]\n",
      "epoch:34 step:26899 [D loss: 0.891691, acc: 46.09%] [G loss: 5.372532]\n",
      "epoch:34 step:26900 [D loss: 0.494878, acc: 78.91%] [G loss: 6.107185]\n",
      "epoch:34 step:26901 [D loss: 0.370255, acc: 85.16%] [G loss: 3.905187]\n",
      "epoch:34 step:26902 [D loss: 0.197956, acc: 99.22%] [G loss: 4.202507]\n",
      "epoch:34 step:26903 [D loss: 0.944066, acc: 38.28%] [G loss: 5.391648]\n",
      "epoch:34 step:26904 [D loss: 0.392117, acc: 86.72%] [G loss: 5.286602]\n",
      "epoch:34 step:26905 [D loss: 0.125165, acc: 100.00%] [G loss: 2.869643]\n",
      "epoch:34 step:26906 [D loss: 0.828031, acc: 53.12%] [G loss: 4.903073]\n",
      "epoch:34 step:26907 [D loss: 0.190458, acc: 96.88%] [G loss: 4.136215]\n",
      "epoch:34 step:26908 [D loss: 0.501107, acc: 67.97%] [G loss: 4.377585]\n",
      "epoch:34 step:26909 [D loss: 0.428464, acc: 75.78%] [G loss: 6.557174]\n",
      "epoch:34 step:26910 [D loss: 0.170091, acc: 99.22%] [G loss: 3.174917]\n",
      "epoch:34 step:26911 [D loss: 0.249232, acc: 90.62%] [G loss: 5.013920]\n",
      "epoch:34 step:26912 [D loss: 0.453591, acc: 71.09%] [G loss: 4.238061]\n",
      "epoch:34 step:26913 [D loss: 0.345576, acc: 80.47%] [G loss: 4.561481]\n",
      "epoch:34 step:26914 [D loss: 0.326953, acc: 88.28%] [G loss: 3.224721]\n",
      "epoch:34 step:26915 [D loss: 1.217930, acc: 40.62%] [G loss: 4.880939]\n",
      "epoch:34 step:26916 [D loss: 0.122744, acc: 97.66%] [G loss: 3.856611]\n",
      "epoch:34 step:26917 [D loss: 0.669042, acc: 57.03%] [G loss: 5.400821]\n",
      "epoch:34 step:26918 [D loss: 0.262216, acc: 96.09%] [G loss: 5.244791]\n",
      "epoch:34 step:26919 [D loss: 0.065372, acc: 100.00%] [G loss: 4.716231]\n",
      "epoch:34 step:26920 [D loss: 0.190611, acc: 98.44%] [G loss: 4.430839]\n",
      "epoch:34 step:26921 [D loss: 0.382328, acc: 91.41%] [G loss: 6.078115]\n",
      "epoch:34 step:26922 [D loss: 0.716693, acc: 53.91%] [G loss: 3.470574]\n",
      "epoch:34 step:26923 [D loss: 0.492973, acc: 69.53%] [G loss: 6.041352]\n",
      "epoch:34 step:26924 [D loss: 0.398792, acc: 75.78%] [G loss: 6.385038]\n",
      "epoch:34 step:26925 [D loss: 0.369772, acc: 90.62%] [G loss: 4.851761]\n",
      "epoch:34 step:26926 [D loss: 0.272671, acc: 96.09%] [G loss: 3.900213]\n",
      "epoch:34 step:26927 [D loss: 0.194184, acc: 100.00%] [G loss: 3.611156]\n",
      "epoch:34 step:26928 [D loss: 0.081444, acc: 100.00%] [G loss: 3.574597]\n",
      "epoch:34 step:26929 [D loss: 0.402701, acc: 74.22%] [G loss: 6.083712]\n",
      "epoch:34 step:26930 [D loss: 0.389304, acc: 89.84%] [G loss: 4.140494]\n",
      "epoch:34 step:26931 [D loss: 0.248645, acc: 89.06%] [G loss: 5.404569]\n",
      "epoch:34 step:26932 [D loss: 0.288654, acc: 96.88%] [G loss: 5.814247]\n",
      "epoch:34 step:26933 [D loss: 0.366583, acc: 82.03%] [G loss: 5.415871]\n",
      "epoch:34 step:26934 [D loss: 0.116970, acc: 100.00%] [G loss: 3.361549]\n",
      "epoch:34 step:26935 [D loss: 0.648829, acc: 61.72%] [G loss: 5.785118]\n",
      "epoch:34 step:26936 [D loss: 0.546663, acc: 64.06%] [G loss: 3.723056]\n",
      "epoch:34 step:26937 [D loss: 0.529809, acc: 64.06%] [G loss: 5.997957]\n",
      "epoch:34 step:26938 [D loss: 0.421950, acc: 84.38%] [G loss: 4.534042]\n",
      "epoch:34 step:26939 [D loss: 0.743911, acc: 50.00%] [G loss: 4.747859]\n",
      "epoch:34 step:26940 [D loss: 0.310066, acc: 90.62%] [G loss: 2.651935]\n",
      "epoch:34 step:26941 [D loss: 0.174617, acc: 97.66%] [G loss: 4.120404]\n",
      "epoch:34 step:26942 [D loss: 0.408195, acc: 87.50%] [G loss: 5.255054]\n",
      "epoch:34 step:26943 [D loss: 0.228399, acc: 97.66%] [G loss: 3.647254]\n",
      "epoch:34 step:26944 [D loss: 0.064411, acc: 100.00%] [G loss: 3.047985]\n",
      "epoch:34 step:26945 [D loss: 0.423833, acc: 84.38%] [G loss: 5.480098]\n",
      "epoch:34 step:26946 [D loss: 0.714300, acc: 53.91%] [G loss: 2.846206]\n",
      "epoch:34 step:26947 [D loss: 0.915619, acc: 51.56%] [G loss: 3.628178]\n",
      "epoch:34 step:26948 [D loss: 0.422705, acc: 89.06%] [G loss: 3.446268]\n",
      "epoch:34 step:26949 [D loss: 0.644062, acc: 62.50%] [G loss: 3.715860]\n",
      "epoch:34 step:26950 [D loss: 0.060680, acc: 100.00%] [G loss: 5.122833]\n",
      "epoch:34 step:26951 [D loss: 1.084311, acc: 47.66%] [G loss: 4.170809]\n",
      "epoch:34 step:26952 [D loss: 0.331811, acc: 82.81%] [G loss: 2.437711]\n",
      "epoch:34 step:26953 [D loss: 0.432135, acc: 70.31%] [G loss: 2.979161]\n",
      "epoch:34 step:26954 [D loss: 0.121885, acc: 100.00%] [G loss: 4.215205]\n",
      "epoch:34 step:26955 [D loss: 0.032667, acc: 100.00%] [G loss: 4.868951]\n",
      "epoch:34 step:26956 [D loss: 0.320121, acc: 87.50%] [G loss: 4.795934]\n",
      "epoch:34 step:26957 [D loss: 0.941051, acc: 52.34%] [G loss: 6.769024]\n",
      "epoch:34 step:26958 [D loss: 0.226146, acc: 96.09%] [G loss: 5.191194]\n",
      "epoch:34 step:26959 [D loss: 0.446034, acc: 71.88%] [G loss: 5.554863]\n",
      "epoch:34 step:26960 [D loss: 0.432029, acc: 85.94%] [G loss: 5.614583]\n",
      "epoch:34 step:26961 [D loss: 0.644160, acc: 66.41%] [G loss: 5.700528]\n",
      "epoch:34 step:26962 [D loss: 0.185299, acc: 100.00%] [G loss: 6.626467]\n",
      "epoch:34 step:26963 [D loss: 0.161704, acc: 97.66%] [G loss: 6.033955]\n",
      "epoch:34 step:26964 [D loss: 0.117565, acc: 100.00%] [G loss: 7.150274]\n",
      "epoch:34 step:26965 [D loss: 0.780736, acc: 52.34%] [G loss: 7.393448]\n",
      "epoch:34 step:26966 [D loss: 0.647986, acc: 58.59%] [G loss: 5.405020]\n",
      "epoch:34 step:26967 [D loss: 0.351238, acc: 89.06%] [G loss: 4.197399]\n",
      "epoch:34 step:26968 [D loss: 0.785639, acc: 54.69%] [G loss: 7.937029]\n",
      "epoch:34 step:26969 [D loss: 0.467906, acc: 79.69%] [G loss: 4.181388]\n",
      "epoch:34 step:26970 [D loss: 0.375038, acc: 91.41%] [G loss: 7.380973]\n",
      "epoch:34 step:26971 [D loss: 0.160523, acc: 97.66%] [G loss: 5.087049]\n",
      "epoch:34 step:26972 [D loss: 0.045189, acc: 98.44%] [G loss: 3.985786]\n",
      "epoch:34 step:26973 [D loss: 0.194257, acc: 96.88%] [G loss: 3.776655]\n",
      "epoch:34 step:26974 [D loss: 0.320626, acc: 86.72%] [G loss: 3.403470]\n",
      "epoch:34 step:26975 [D loss: 0.184106, acc: 100.00%] [G loss: 5.258986]\n",
      "epoch:34 step:26976 [D loss: 0.473797, acc: 79.69%] [G loss: 5.958318]\n",
      "epoch:34 step:26977 [D loss: 0.253022, acc: 96.88%] [G loss: 5.010197]\n",
      "epoch:34 step:26978 [D loss: 0.933158, acc: 36.72%] [G loss: 5.928473]\n",
      "epoch:34 step:26979 [D loss: 1.084684, acc: 17.19%] [G loss: 4.666881]\n",
      "epoch:34 step:26980 [D loss: 0.172952, acc: 99.22%] [G loss: 3.305691]\n",
      "epoch:34 step:26981 [D loss: 0.100693, acc: 99.22%] [G loss: 4.137175]\n",
      "epoch:34 step:26982 [D loss: 0.446779, acc: 76.56%] [G loss: 4.324167]\n",
      "epoch:34 step:26983 [D loss: 0.093547, acc: 100.00%] [G loss: 6.555767]\n",
      "epoch:34 step:26984 [D loss: 0.606621, acc: 62.50%] [G loss: 5.687003]\n",
      "epoch:34 step:26985 [D loss: 0.229311, acc: 95.31%] [G loss: 4.960512]\n",
      "epoch:34 step:26986 [D loss: 0.540915, acc: 72.66%] [G loss: 5.486746]\n",
      "epoch:34 step:26987 [D loss: 0.997852, acc: 51.56%] [G loss: 6.467008]\n",
      "epoch:34 step:26988 [D loss: 0.168064, acc: 98.44%] [G loss: 3.994633]\n",
      "epoch:34 step:26989 [D loss: 0.049904, acc: 100.00%] [G loss: 6.406657]\n",
      "epoch:34 step:26990 [D loss: 1.397786, acc: 50.00%] [G loss: 5.727032]\n",
      "epoch:34 step:26991 [D loss: 0.938444, acc: 37.50%] [G loss: 5.093241]\n",
      "epoch:34 step:26992 [D loss: 0.197692, acc: 95.31%] [G loss: 5.590725]\n",
      "epoch:34 step:26993 [D loss: 0.233123, acc: 95.31%] [G loss: 3.649123]\n",
      "epoch:34 step:26994 [D loss: 0.871779, acc: 50.00%] [G loss: 3.041817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:26995 [D loss: 0.259588, acc: 94.53%] [G loss: 5.191977]\n",
      "epoch:34 step:26996 [D loss: 0.359590, acc: 84.38%] [G loss: 1.628100]\n",
      "epoch:34 step:26997 [D loss: 0.613553, acc: 70.31%] [G loss: 4.010204]\n",
      "epoch:34 step:26998 [D loss: 0.152896, acc: 98.44%] [G loss: 4.789056]\n",
      "epoch:34 step:26999 [D loss: 0.186816, acc: 99.22%] [G loss: 3.406793]\n",
      "epoch:34 step:27000 [D loss: 0.189406, acc: 96.88%] [G loss: 6.844067]\n",
      "epoch:34 step:27001 [D loss: 0.142286, acc: 97.66%] [G loss: 5.926311]\n",
      "epoch:34 step:27002 [D loss: 0.897982, acc: 52.34%] [G loss: 4.438554]\n",
      "epoch:34 step:27003 [D loss: 0.427038, acc: 78.12%] [G loss: 4.361647]\n",
      "epoch:34 step:27004 [D loss: 0.171511, acc: 98.44%] [G loss: 4.020544]\n",
      "epoch:34 step:27005 [D loss: 0.318937, acc: 89.06%] [G loss: 4.196256]\n",
      "epoch:34 step:27006 [D loss: 0.161132, acc: 99.22%] [G loss: 2.932535]\n",
      "epoch:34 step:27007 [D loss: 1.022263, acc: 50.00%] [G loss: 4.885203]\n",
      "epoch:34 step:27008 [D loss: 0.823202, acc: 50.78%] [G loss: 5.221944]\n",
      "epoch:34 step:27009 [D loss: 0.593817, acc: 63.28%] [G loss: 5.258278]\n",
      "epoch:34 step:27010 [D loss: 0.302926, acc: 89.84%] [G loss: 4.454998]\n",
      "epoch:34 step:27011 [D loss: 1.224063, acc: 50.00%] [G loss: 6.087497]\n",
      "epoch:34 step:27012 [D loss: 0.702964, acc: 60.16%] [G loss: 5.907326]\n",
      "epoch:34 step:27013 [D loss: 1.153268, acc: 41.41%] [G loss: 3.453720]\n",
      "epoch:34 step:27014 [D loss: 0.679901, acc: 61.72%] [G loss: 5.598001]\n",
      "epoch:34 step:27015 [D loss: 0.033523, acc: 100.00%] [G loss: 6.473443]\n",
      "epoch:34 step:27016 [D loss: 0.768986, acc: 51.56%] [G loss: 3.920106]\n",
      "epoch:34 step:27017 [D loss: 0.268705, acc: 92.97%] [G loss: 4.301370]\n",
      "epoch:34 step:27018 [D loss: 0.113788, acc: 100.00%] [G loss: 6.771327]\n",
      "epoch:34 step:27019 [D loss: 0.207170, acc: 96.88%] [G loss: 5.085845]\n",
      "epoch:34 step:27020 [D loss: 0.051151, acc: 100.00%] [G loss: 6.858413]\n",
      "epoch:34 step:27021 [D loss: 0.458682, acc: 81.25%] [G loss: 5.224155]\n",
      "epoch:34 step:27022 [D loss: 0.323063, acc: 89.06%] [G loss: 4.400138]\n",
      "epoch:34 step:27023 [D loss: 0.421533, acc: 84.38%] [G loss: 4.626613]\n",
      "epoch:34 step:27024 [D loss: 0.167714, acc: 99.22%] [G loss: 5.189801]\n",
      "epoch:34 step:27025 [D loss: 0.472409, acc: 82.03%] [G loss: 4.449630]\n",
      "epoch:34 step:27026 [D loss: 0.033570, acc: 100.00%] [G loss: 5.228736]\n",
      "epoch:34 step:27027 [D loss: 0.585045, acc: 64.06%] [G loss: 5.807919]\n",
      "epoch:34 step:27028 [D loss: 1.233999, acc: 42.19%] [G loss: 4.917023]\n",
      "epoch:34 step:27029 [D loss: 0.713124, acc: 57.03%] [G loss: 3.503285]\n",
      "epoch:34 step:27030 [D loss: 0.122096, acc: 100.00%] [G loss: 5.646930]\n",
      "epoch:34 step:27031 [D loss: 0.611627, acc: 61.72%] [G loss: 5.266408]\n",
      "epoch:34 step:27032 [D loss: 0.131943, acc: 98.44%] [G loss: 5.426657]\n",
      "epoch:34 step:27033 [D loss: 0.460742, acc: 79.69%] [G loss: 4.909664]\n",
      "epoch:34 step:27034 [D loss: 0.694572, acc: 60.94%] [G loss: 4.956301]\n",
      "epoch:34 step:27035 [D loss: 0.422493, acc: 87.50%] [G loss: 6.369916]\n",
      "epoch:34 step:27036 [D loss: 0.705860, acc: 62.50%] [G loss: 5.226141]\n",
      "epoch:34 step:27037 [D loss: 0.641371, acc: 57.03%] [G loss: 6.164169]\n",
      "epoch:34 step:27038 [D loss: 0.295979, acc: 86.72%] [G loss: 6.570664]\n",
      "epoch:34 step:27039 [D loss: 0.819721, acc: 47.66%] [G loss: 3.175745]\n",
      "epoch:34 step:27040 [D loss: 0.171627, acc: 96.88%] [G loss: 5.628134]\n",
      "epoch:34 step:27041 [D loss: 0.961874, acc: 52.34%] [G loss: 5.094813]\n",
      "epoch:34 step:27042 [D loss: 0.477538, acc: 78.91%] [G loss: 5.083608]\n",
      "epoch:34 step:27043 [D loss: 0.517777, acc: 77.34%] [G loss: 6.000308]\n",
      "epoch:34 step:27044 [D loss: 0.019589, acc: 100.00%] [G loss: 6.733731]\n",
      "epoch:34 step:27045 [D loss: 0.887133, acc: 39.84%] [G loss: 5.857430]\n",
      "epoch:34 step:27046 [D loss: 0.309261, acc: 91.41%] [G loss: 6.900317]\n",
      "epoch:34 step:27047 [D loss: 1.422048, acc: 44.53%] [G loss: 6.117963]\n",
      "epoch:34 step:27048 [D loss: 0.376950, acc: 79.69%] [G loss: 4.536170]\n",
      "epoch:34 step:27049 [D loss: 0.612571, acc: 60.16%] [G loss: 3.176123]\n",
      "epoch:34 step:27050 [D loss: 0.464640, acc: 66.41%] [G loss: 5.033989]\n",
      "epoch:34 step:27051 [D loss: 0.101596, acc: 100.00%] [G loss: 4.988710]\n",
      "epoch:34 step:27052 [D loss: 0.145741, acc: 99.22%] [G loss: 4.598252]\n",
      "epoch:34 step:27053 [D loss: 0.363543, acc: 90.62%] [G loss: 4.395871]\n",
      "epoch:34 step:27054 [D loss: 0.368471, acc: 88.28%] [G loss: 2.994922]\n",
      "epoch:34 step:27055 [D loss: 0.483158, acc: 63.28%] [G loss: 7.064657]\n",
      "epoch:34 step:27056 [D loss: 0.156703, acc: 97.66%] [G loss: 5.892715]\n",
      "epoch:34 step:27057 [D loss: 0.095225, acc: 100.00%] [G loss: 4.930995]\n",
      "epoch:34 step:27058 [D loss: 0.315798, acc: 85.94%] [G loss: 7.659987]\n",
      "epoch:34 step:27059 [D loss: 0.683323, acc: 57.03%] [G loss: 5.002069]\n",
      "epoch:34 step:27060 [D loss: 0.041436, acc: 100.00%] [G loss: 6.527016]\n",
      "epoch:34 step:27061 [D loss: 0.444794, acc: 71.88%] [G loss: 5.452658]\n",
      "epoch:34 step:27062 [D loss: 0.438503, acc: 67.97%] [G loss: 4.208489]\n",
      "epoch:34 step:27063 [D loss: 0.272896, acc: 94.53%] [G loss: 3.852994]\n",
      "epoch:34 step:27064 [D loss: 0.659590, acc: 62.50%] [G loss: 4.811326]\n",
      "epoch:34 step:27065 [D loss: 0.132770, acc: 99.22%] [G loss: 10.281973]\n",
      "epoch:34 step:27066 [D loss: 0.268593, acc: 93.75%] [G loss: 4.512272]\n",
      "epoch:34 step:27067 [D loss: 0.475799, acc: 68.75%] [G loss: 7.464989]\n",
      "epoch:34 step:27068 [D loss: 0.131875, acc: 99.22%] [G loss: 3.828990]\n",
      "epoch:34 step:27069 [D loss: 0.176849, acc: 99.22%] [G loss: 4.263340]\n",
      "epoch:34 step:27070 [D loss: 0.738487, acc: 51.56%] [G loss: 3.749722]\n",
      "epoch:34 step:27071 [D loss: 0.023086, acc: 100.00%] [G loss: 5.803467]\n",
      "epoch:34 step:27072 [D loss: 0.179895, acc: 97.66%] [G loss: 3.586152]\n",
      "epoch:34 step:27073 [D loss: 0.784531, acc: 53.91%] [G loss: 5.481949]\n",
      "epoch:34 step:27074 [D loss: 0.229476, acc: 97.66%] [G loss: 5.272973]\n",
      "epoch:34 step:27075 [D loss: 0.430290, acc: 71.88%] [G loss: 3.754796]\n",
      "epoch:34 step:27076 [D loss: 0.595883, acc: 64.84%] [G loss: 4.907176]\n",
      "epoch:34 step:27077 [D loss: 0.118564, acc: 99.22%] [G loss: 4.775593]\n",
      "epoch:34 step:27078 [D loss: 0.300077, acc: 91.41%] [G loss: 2.797424]\n",
      "epoch:34 step:27079 [D loss: 0.619057, acc: 64.06%] [G loss: 5.288293]\n",
      "epoch:34 step:27080 [D loss: 0.078873, acc: 100.00%] [G loss: 6.078354]\n",
      "epoch:34 step:27081 [D loss: 0.385618, acc: 81.25%] [G loss: 4.281872]\n",
      "epoch:34 step:27082 [D loss: 0.760136, acc: 55.47%] [G loss: 3.299012]\n",
      "epoch:34 step:27083 [D loss: 0.173716, acc: 98.44%] [G loss: 4.218317]\n",
      "epoch:34 step:27084 [D loss: 0.581281, acc: 70.31%] [G loss: 7.470110]\n",
      "epoch:34 step:27085 [D loss: 0.122347, acc: 98.44%] [G loss: 6.180969]\n",
      "epoch:34 step:27086 [D loss: 0.139715, acc: 96.88%] [G loss: 6.263528]\n",
      "epoch:34 step:27087 [D loss: 0.213310, acc: 94.53%] [G loss: 4.788134]\n",
      "epoch:34 step:27088 [D loss: 0.305829, acc: 96.09%] [G loss: 5.591132]\n",
      "epoch:34 step:27089 [D loss: 0.497130, acc: 70.31%] [G loss: 5.243040]\n",
      "epoch:34 step:27090 [D loss: 0.307777, acc: 92.97%] [G loss: 3.347956]\n",
      "epoch:34 step:27091 [D loss: 0.625019, acc: 60.16%] [G loss: 5.738593]\n",
      "epoch:34 step:27092 [D loss: 0.217501, acc: 95.31%] [G loss: 3.208973]\n",
      "epoch:34 step:27093 [D loss: 0.180021, acc: 97.66%] [G loss: 3.272757]\n",
      "epoch:34 step:27094 [D loss: 0.153249, acc: 100.00%] [G loss: 5.713963]\n",
      "epoch:34 step:27095 [D loss: 0.207308, acc: 97.66%] [G loss: 5.170063]\n",
      "epoch:34 step:27096 [D loss: 0.263385, acc: 92.19%] [G loss: 3.756360]\n",
      "epoch:34 step:27097 [D loss: 0.379636, acc: 82.81%] [G loss: 4.095955]\n",
      "epoch:34 step:27098 [D loss: 0.370152, acc: 80.47%] [G loss: 4.018954]\n",
      "epoch:34 step:27099 [D loss: 0.364764, acc: 82.81%] [G loss: 6.722545]\n",
      "epoch:34 step:27100 [D loss: 0.291915, acc: 85.16%] [G loss: 6.092777]\n",
      "epoch:34 step:27101 [D loss: 0.140616, acc: 99.22%] [G loss: 7.380572]\n",
      "epoch:34 step:27102 [D loss: 0.421648, acc: 78.12%] [G loss: 6.527243]\n",
      "epoch:34 step:27103 [D loss: 0.496327, acc: 64.84%] [G loss: 5.791935]\n",
      "epoch:34 step:27104 [D loss: 0.119036, acc: 99.22%] [G loss: 3.715602]\n",
      "epoch:34 step:27105 [D loss: 0.186388, acc: 99.22%] [G loss: 5.995593]\n",
      "epoch:34 step:27106 [D loss: 0.305429, acc: 90.62%] [G loss: 3.230886]\n",
      "epoch:34 step:27107 [D loss: 0.447225, acc: 74.22%] [G loss: 7.091188]\n",
      "epoch:34 step:27108 [D loss: 0.297950, acc: 95.31%] [G loss: 4.039359]\n",
      "epoch:34 step:27109 [D loss: 0.168132, acc: 95.31%] [G loss: 4.104363]\n",
      "epoch:34 step:27110 [D loss: 0.118096, acc: 100.00%] [G loss: 6.199648]\n",
      "epoch:34 step:27111 [D loss: 0.090700, acc: 99.22%] [G loss: 4.817863]\n",
      "epoch:34 step:27112 [D loss: 0.259595, acc: 97.66%] [G loss: 3.630681]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:27113 [D loss: 0.143310, acc: 98.44%] [G loss: 5.264650]\n",
      "epoch:34 step:27114 [D loss: 0.112637, acc: 99.22%] [G loss: 6.315346]\n",
      "epoch:34 step:27115 [D loss: 0.579397, acc: 67.97%] [G loss: 4.832891]\n",
      "epoch:34 step:27116 [D loss: 0.596471, acc: 72.66%] [G loss: 5.828154]\n",
      "epoch:34 step:27117 [D loss: 0.782132, acc: 53.91%] [G loss: 4.296609]\n",
      "epoch:34 step:27118 [D loss: 0.074312, acc: 100.00%] [G loss: 3.892909]\n",
      "epoch:34 step:27119 [D loss: 0.674302, acc: 55.47%] [G loss: 5.848527]\n",
      "epoch:34 step:27120 [D loss: 0.106939, acc: 100.00%] [G loss: 6.440851]\n",
      "epoch:34 step:27121 [D loss: 0.771202, acc: 55.47%] [G loss: 6.809308]\n",
      "epoch:34 step:27122 [D loss: 0.534567, acc: 67.19%] [G loss: 5.655288]\n",
      "epoch:34 step:27123 [D loss: 0.035272, acc: 100.00%] [G loss: 6.998455]\n",
      "epoch:34 step:27124 [D loss: 0.353045, acc: 91.41%] [G loss: 5.493761]\n",
      "epoch:34 step:27125 [D loss: 0.309772, acc: 88.28%] [G loss: 5.722701]\n",
      "epoch:34 step:27126 [D loss: 0.222540, acc: 96.09%] [G loss: 4.564790]\n",
      "epoch:34 step:27127 [D loss: 1.006226, acc: 38.28%] [G loss: 5.405155]\n",
      "epoch:34 step:27128 [D loss: 0.857098, acc: 51.56%] [G loss: 4.182962]\n",
      "epoch:34 step:27129 [D loss: 0.181223, acc: 99.22%] [G loss: 2.853189]\n",
      "epoch:34 step:27130 [D loss: 0.264991, acc: 92.97%] [G loss: 4.497456]\n",
      "epoch:34 step:27131 [D loss: 0.351939, acc: 88.28%] [G loss: 3.740211]\n",
      "epoch:34 step:27132 [D loss: 0.119384, acc: 99.22%] [G loss: 5.317634]\n",
      "epoch:34 step:27133 [D loss: 0.659945, acc: 57.81%] [G loss: 4.890773]\n",
      "epoch:34 step:27134 [D loss: 0.552308, acc: 66.41%] [G loss: 4.408060]\n",
      "epoch:34 step:27135 [D loss: 0.072023, acc: 100.00%] [G loss: 4.803896]\n",
      "epoch:34 step:27136 [D loss: 0.541790, acc: 73.44%] [G loss: 3.196462]\n",
      "epoch:34 step:27137 [D loss: 0.341793, acc: 90.62%] [G loss: 4.770304]\n",
      "epoch:34 step:27138 [D loss: 1.617942, acc: 15.62%] [G loss: 5.026667]\n",
      "epoch:34 step:27139 [D loss: 0.425898, acc: 74.22%] [G loss: 2.549398]\n",
      "epoch:34 step:27140 [D loss: 0.178436, acc: 100.00%] [G loss: 5.561264]\n",
      "epoch:34 step:27141 [D loss: 0.100058, acc: 100.00%] [G loss: 6.057295]\n",
      "epoch:34 step:27142 [D loss: 1.112686, acc: 34.38%] [G loss: 3.605836]\n",
      "epoch:34 step:27143 [D loss: 0.461102, acc: 77.34%] [G loss: 4.726637]\n",
      "epoch:34 step:27144 [D loss: 0.119740, acc: 99.22%] [G loss: 4.513843]\n",
      "epoch:34 step:27145 [D loss: 0.304208, acc: 95.31%] [G loss: 5.155894]\n",
      "epoch:34 step:27146 [D loss: 0.340154, acc: 91.41%] [G loss: 4.052371]\n",
      "epoch:34 step:27147 [D loss: 0.302429, acc: 89.84%] [G loss: 4.916213]\n",
      "epoch:34 step:27148 [D loss: 0.449767, acc: 80.47%] [G loss: 5.109612]\n",
      "epoch:34 step:27149 [D loss: 0.544877, acc: 69.53%] [G loss: 4.479401]\n",
      "epoch:34 step:27150 [D loss: 0.195564, acc: 96.09%] [G loss: 5.220783]\n",
      "epoch:34 step:27151 [D loss: 0.760239, acc: 54.69%] [G loss: 6.508274]\n",
      "epoch:34 step:27152 [D loss: 0.119293, acc: 100.00%] [G loss: 6.005361]\n",
      "epoch:34 step:27153 [D loss: 0.376699, acc: 91.41%] [G loss: 1.713954]\n",
      "epoch:34 step:27154 [D loss: 0.283938, acc: 96.88%] [G loss: 4.356766]\n",
      "epoch:34 step:27155 [D loss: 0.257081, acc: 90.62%] [G loss: 4.450860]\n",
      "epoch:34 step:27156 [D loss: 0.650126, acc: 58.59%] [G loss: 5.706499]\n",
      "epoch:34 step:27157 [D loss: 0.132346, acc: 100.00%] [G loss: 5.520622]\n",
      "epoch:34 step:27158 [D loss: 0.619750, acc: 69.53%] [G loss: 3.979306]\n",
      "epoch:34 step:27159 [D loss: 0.113893, acc: 100.00%] [G loss: 6.577915]\n",
      "epoch:34 step:27160 [D loss: 0.299985, acc: 92.97%] [G loss: 6.180515]\n",
      "epoch:34 step:27161 [D loss: 0.045998, acc: 100.00%] [G loss: 4.604190]\n",
      "epoch:34 step:27162 [D loss: 0.460462, acc: 70.31%] [G loss: 5.798324]\n",
      "epoch:34 step:27163 [D loss: 0.022411, acc: 100.00%] [G loss: 5.923227]\n",
      "epoch:34 step:27164 [D loss: 1.009903, acc: 29.69%] [G loss: 5.160657]\n",
      "epoch:34 step:27165 [D loss: 0.413435, acc: 77.34%] [G loss: 4.477008]\n",
      "epoch:34 step:27166 [D loss: 0.239817, acc: 96.09%] [G loss: 3.847842]\n",
      "epoch:34 step:27167 [D loss: 0.668649, acc: 59.38%] [G loss: 3.071299]\n",
      "epoch:34 step:27168 [D loss: 0.074329, acc: 100.00%] [G loss: 5.521317]\n",
      "epoch:34 step:27169 [D loss: 0.166084, acc: 98.44%] [G loss: 4.495571]\n",
      "epoch:34 step:27170 [D loss: 1.027505, acc: 46.88%] [G loss: 5.501978]\n",
      "epoch:34 step:27171 [D loss: 0.393415, acc: 82.03%] [G loss: 4.733485]\n",
      "epoch:34 step:27172 [D loss: 0.373777, acc: 75.78%] [G loss: 5.349881]\n",
      "epoch:34 step:27173 [D loss: 1.009149, acc: 50.78%] [G loss: 4.535043]\n",
      "epoch:34 step:27174 [D loss: 0.058579, acc: 100.00%] [G loss: 2.911247]\n",
      "epoch:34 step:27175 [D loss: 1.314818, acc: 19.53%] [G loss: 4.846791]\n",
      "epoch:34 step:27176 [D loss: 0.276437, acc: 89.84%] [G loss: 3.246588]\n",
      "epoch:34 step:27177 [D loss: 0.809296, acc: 47.66%] [G loss: 4.793729]\n",
      "epoch:34 step:27178 [D loss: 0.078496, acc: 100.00%] [G loss: 6.061766]\n",
      "epoch:34 step:27179 [D loss: 0.304710, acc: 91.41%] [G loss: 3.567421]\n",
      "epoch:34 step:27180 [D loss: 1.414063, acc: 24.22%] [G loss: 4.824964]\n",
      "epoch:34 step:27181 [D loss: 0.332776, acc: 93.75%] [G loss: 5.992189]\n",
      "epoch:34 step:27182 [D loss: 0.385785, acc: 89.06%] [G loss: 5.203220]\n",
      "epoch:34 step:27183 [D loss: 0.181180, acc: 98.44%] [G loss: 3.796545]\n",
      "epoch:34 step:27184 [D loss: 0.085938, acc: 100.00%] [G loss: 7.314223]\n",
      "epoch:34 step:27185 [D loss: 0.268159, acc: 91.41%] [G loss: 5.679330]\n",
      "epoch:34 step:27186 [D loss: 0.404902, acc: 80.47%] [G loss: 4.562258]\n",
      "epoch:34 step:27187 [D loss: 0.400400, acc: 85.16%] [G loss: 4.197770]\n",
      "epoch:34 step:27188 [D loss: 1.574681, acc: 6.25%] [G loss: 3.819821]\n",
      "epoch:34 step:27189 [D loss: 0.410009, acc: 80.47%] [G loss: 4.889678]\n",
      "epoch:34 step:27190 [D loss: 0.943637, acc: 30.47%] [G loss: 6.956196]\n",
      "epoch:34 step:27191 [D loss: 0.709744, acc: 53.91%] [G loss: 6.224492]\n",
      "epoch:34 step:27192 [D loss: 0.054744, acc: 100.00%] [G loss: 5.521568]\n",
      "epoch:34 step:27193 [D loss: 0.591586, acc: 60.16%] [G loss: 3.841528]\n",
      "epoch:34 step:27194 [D loss: 0.169251, acc: 98.44%] [G loss: 3.886326]\n",
      "epoch:34 step:27195 [D loss: 0.243818, acc: 95.31%] [G loss: 4.791125]\n",
      "epoch:34 step:27196 [D loss: 0.690558, acc: 60.16%] [G loss: 2.112655]\n",
      "epoch:34 step:27197 [D loss: 0.299774, acc: 93.75%] [G loss: 4.688460]\n",
      "epoch:34 step:27198 [D loss: 0.206032, acc: 97.66%] [G loss: 5.764085]\n",
      "epoch:34 step:27199 [D loss: 0.174333, acc: 98.44%] [G loss: 5.200384]\n",
      "epoch:34 step:27200 [D loss: 0.251482, acc: 96.09%] [G loss: 5.160051]\n",
      "epoch:34 step:27201 [D loss: 0.493978, acc: 79.69%] [G loss: 5.017386]\n",
      "epoch:34 step:27202 [D loss: 0.515335, acc: 77.34%] [G loss: 5.201127]\n",
      "epoch:34 step:27203 [D loss: 0.092715, acc: 100.00%] [G loss: 5.241503]\n",
      "epoch:34 step:27204 [D loss: 0.639974, acc: 60.16%] [G loss: 3.145120]\n",
      "epoch:34 step:27205 [D loss: 0.144603, acc: 99.22%] [G loss: 4.771102]\n",
      "epoch:34 step:27206 [D loss: 1.370555, acc: 28.91%] [G loss: 7.459017]\n",
      "epoch:34 step:27207 [D loss: 0.223105, acc: 97.66%] [G loss: 4.212922]\n",
      "epoch:34 step:27208 [D loss: 0.565238, acc: 67.97%] [G loss: 4.684392]\n",
      "epoch:34 step:27209 [D loss: 0.150321, acc: 98.44%] [G loss: 4.027405]\n",
      "epoch:34 step:27210 [D loss: 0.590696, acc: 67.19%] [G loss: 4.721518]\n",
      "epoch:34 step:27211 [D loss: 0.524126, acc: 59.38%] [G loss: 4.973771]\n",
      "epoch:34 step:27212 [D loss: 0.668050, acc: 63.28%] [G loss: 8.249170]\n",
      "epoch:34 step:27213 [D loss: 0.256468, acc: 92.97%] [G loss: 2.784908]\n",
      "epoch:34 step:27214 [D loss: 0.149094, acc: 100.00%] [G loss: 5.756621]\n",
      "epoch:34 step:27215 [D loss: 0.303859, acc: 92.19%] [G loss: 5.514755]\n",
      "epoch:34 step:27216 [D loss: 0.179294, acc: 97.66%] [G loss: 4.991107]\n",
      "epoch:34 step:27217 [D loss: 0.412949, acc: 85.16%] [G loss: 7.862878]\n",
      "epoch:34 step:27218 [D loss: 0.113796, acc: 100.00%] [G loss: 5.135266]\n",
      "epoch:34 step:27219 [D loss: 0.291327, acc: 95.31%] [G loss: 3.760274]\n",
      "epoch:34 step:27220 [D loss: 0.256943, acc: 96.88%] [G loss: 4.136021]\n",
      "epoch:34 step:27221 [D loss: 0.534265, acc: 71.09%] [G loss: 6.536902]\n",
      "epoch:34 step:27222 [D loss: 0.695296, acc: 52.34%] [G loss: 7.166743]\n",
      "epoch:34 step:27223 [D loss: 0.564764, acc: 68.75%] [G loss: 6.980113]\n",
      "epoch:34 step:27224 [D loss: 1.080998, acc: 22.66%] [G loss: 5.251464]\n",
      "epoch:34 step:27225 [D loss: 0.210223, acc: 96.88%] [G loss: 5.469954]\n",
      "epoch:34 step:27226 [D loss: 0.303147, acc: 89.84%] [G loss: 4.170762]\n",
      "epoch:34 step:27227 [D loss: 0.155965, acc: 100.00%] [G loss: 3.808673]\n",
      "epoch:34 step:27228 [D loss: 0.282012, acc: 92.97%] [G loss: 3.900002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:27229 [D loss: 0.362736, acc: 82.03%] [G loss: 4.358989]\n",
      "epoch:34 step:27230 [D loss: 0.230520, acc: 94.53%] [G loss: 6.612801]\n",
      "epoch:34 step:27231 [D loss: 0.254513, acc: 94.53%] [G loss: 4.896925]\n",
      "epoch:34 step:27232 [D loss: 0.257961, acc: 92.19%] [G loss: 2.097605]\n",
      "epoch:34 step:27233 [D loss: 0.598698, acc: 59.38%] [G loss: 2.788397]\n",
      "epoch:34 step:27234 [D loss: 0.258626, acc: 90.62%] [G loss: 5.298909]\n",
      "epoch:34 step:27235 [D loss: 0.099434, acc: 100.00%] [G loss: 4.431647]\n",
      "epoch:34 step:27236 [D loss: 0.292046, acc: 95.31%] [G loss: 5.293170]\n",
      "epoch:34 step:27237 [D loss: 0.460404, acc: 76.56%] [G loss: 4.580597]\n",
      "epoch:34 step:27238 [D loss: 0.398459, acc: 89.84%] [G loss: 4.464545]\n",
      "epoch:34 step:27239 [D loss: 1.057423, acc: 26.56%] [G loss: 7.049187]\n",
      "epoch:34 step:27240 [D loss: 0.832985, acc: 53.91%] [G loss: 4.474246]\n",
      "epoch:34 step:27241 [D loss: 0.384917, acc: 82.03%] [G loss: 5.397286]\n",
      "epoch:34 step:27242 [D loss: 0.150962, acc: 98.44%] [G loss: 4.813406]\n",
      "epoch:34 step:27243 [D loss: 0.221212, acc: 94.53%] [G loss: 5.431250]\n",
      "epoch:34 step:27244 [D loss: 0.058492, acc: 100.00%] [G loss: 4.108473]\n",
      "epoch:34 step:27245 [D loss: 0.209457, acc: 96.09%] [G loss: 3.445609]\n",
      "epoch:34 step:27246 [D loss: 0.770425, acc: 53.91%] [G loss: 5.066054]\n",
      "epoch:34 step:27247 [D loss: 0.481049, acc: 70.31%] [G loss: 5.804443]\n",
      "epoch:34 step:27248 [D loss: 0.245940, acc: 92.97%] [G loss: 5.386585]\n",
      "epoch:34 step:27249 [D loss: 0.613204, acc: 57.81%] [G loss: 6.602318]\n",
      "epoch:34 step:27250 [D loss: 0.397234, acc: 81.25%] [G loss: 5.007880]\n",
      "epoch:34 step:27251 [D loss: 0.450344, acc: 69.53%] [G loss: 3.418518]\n",
      "epoch:34 step:27252 [D loss: 0.917399, acc: 50.00%] [G loss: 3.918206]\n",
      "epoch:34 step:27253 [D loss: 0.101141, acc: 100.00%] [G loss: 3.812831]\n",
      "epoch:34 step:27254 [D loss: 0.445395, acc: 75.00%] [G loss: 4.913349]\n",
      "epoch:34 step:27255 [D loss: 0.536458, acc: 68.75%] [G loss: 5.438903]\n",
      "epoch:34 step:27256 [D loss: 0.093120, acc: 100.00%] [G loss: 7.377770]\n",
      "epoch:34 step:27257 [D loss: 1.558081, acc: 50.00%] [G loss: 5.159368]\n",
      "epoch:34 step:27258 [D loss: 0.206300, acc: 95.31%] [G loss: 6.840451]\n",
      "epoch:34 step:27259 [D loss: 0.452517, acc: 66.41%] [G loss: 5.882517]\n",
      "epoch:34 step:27260 [D loss: 0.197276, acc: 95.31%] [G loss: 5.919737]\n",
      "epoch:34 step:27261 [D loss: 0.857022, acc: 52.34%] [G loss: 5.872288]\n",
      "epoch:34 step:27262 [D loss: 0.020159, acc: 100.00%] [G loss: 7.971617]\n",
      "epoch:34 step:27263 [D loss: 0.669414, acc: 58.59%] [G loss: 5.430552]\n",
      "epoch:34 step:27264 [D loss: 0.217556, acc: 96.09%] [G loss: 8.423470]\n",
      "epoch:34 step:27265 [D loss: 0.047164, acc: 100.00%] [G loss: 8.625595]\n",
      "epoch:34 step:27266 [D loss: 0.365098, acc: 82.03%] [G loss: 5.174591]\n",
      "epoch:34 step:27267 [D loss: 0.130647, acc: 100.00%] [G loss: 5.562473]\n",
      "epoch:34 step:27268 [D loss: 1.623010, acc: 46.88%] [G loss: 3.200392]\n",
      "epoch:34 step:27269 [D loss: 0.568150, acc: 62.50%] [G loss: 4.290620]\n",
      "epoch:34 step:27270 [D loss: 0.662107, acc: 56.25%] [G loss: 6.556150]\n",
      "epoch:34 step:27271 [D loss: 0.819309, acc: 53.91%] [G loss: 3.703114]\n",
      "epoch:34 step:27272 [D loss: 0.138906, acc: 100.00%] [G loss: 4.588225]\n",
      "epoch:34 step:27273 [D loss: 0.133785, acc: 98.44%] [G loss: 4.703547]\n",
      "epoch:34 step:27274 [D loss: 0.839131, acc: 46.09%] [G loss: 3.490068]\n",
      "epoch:34 step:27275 [D loss: 0.386653, acc: 86.72%] [G loss: 5.016671]\n",
      "epoch:34 step:27276 [D loss: 0.258753, acc: 94.53%] [G loss: 4.680748]\n",
      "epoch:34 step:27277 [D loss: 0.207442, acc: 93.75%] [G loss: 7.246379]\n",
      "epoch:34 step:27278 [D loss: 0.295465, acc: 93.75%] [G loss: 4.681539]\n",
      "epoch:34 step:27279 [D loss: 0.167786, acc: 98.44%] [G loss: 3.320965]\n",
      "epoch:34 step:27280 [D loss: 0.009092, acc: 100.00%] [G loss: 4.766914]\n",
      "epoch:34 step:27281 [D loss: 0.615565, acc: 64.06%] [G loss: 4.602557]\n",
      "epoch:34 step:27282 [D loss: 0.088764, acc: 100.00%] [G loss: 4.250752]\n",
      "epoch:34 step:27283 [D loss: 0.221663, acc: 96.88%] [G loss: 4.878342]\n",
      "epoch:34 step:27284 [D loss: 0.524103, acc: 75.00%] [G loss: 6.692018]\n",
      "epoch:34 step:27285 [D loss: 0.127449, acc: 97.66%] [G loss: 6.545670]\n",
      "epoch:34 step:27286 [D loss: 0.103304, acc: 99.22%] [G loss: 3.898493]\n",
      "epoch:34 step:27287 [D loss: 0.393614, acc: 91.41%] [G loss: 3.422191]\n",
      "epoch:34 step:27288 [D loss: 0.353854, acc: 78.12%] [G loss: 7.898819]\n",
      "epoch:34 step:27289 [D loss: 0.063902, acc: 100.00%] [G loss: 5.888546]\n",
      "epoch:34 step:27290 [D loss: 0.728223, acc: 52.34%] [G loss: 9.139151]\n",
      "epoch:34 step:27291 [D loss: 0.201622, acc: 97.66%] [G loss: 2.646275]\n",
      "epoch:34 step:27292 [D loss: 0.067848, acc: 99.22%] [G loss: 5.232888]\n",
      "epoch:34 step:27293 [D loss: 0.215647, acc: 92.97%] [G loss: 4.639672]\n",
      "epoch:34 step:27294 [D loss: 1.131667, acc: 49.22%] [G loss: 4.555222]\n",
      "epoch:34 step:27295 [D loss: 0.458999, acc: 70.31%] [G loss: 6.075537]\n",
      "epoch:34 step:27296 [D loss: 0.405147, acc: 83.59%] [G loss: 4.955257]\n",
      "epoch:34 step:27297 [D loss: 0.221197, acc: 96.09%] [G loss: 5.465178]\n",
      "epoch:34 step:27298 [D loss: 0.798940, acc: 56.25%] [G loss: 5.599896]\n",
      "epoch:34 step:27299 [D loss: 0.154830, acc: 96.88%] [G loss: 4.816233]\n",
      "epoch:34 step:27300 [D loss: 0.480737, acc: 74.22%] [G loss: 5.169341]\n",
      "epoch:34 step:27301 [D loss: 0.132761, acc: 99.22%] [G loss: 3.520208]\n",
      "epoch:34 step:27302 [D loss: 0.133760, acc: 99.22%] [G loss: 4.558902]\n",
      "epoch:34 step:27303 [D loss: 0.323292, acc: 94.53%] [G loss: 4.486089]\n",
      "epoch:34 step:27304 [D loss: 0.611888, acc: 71.88%] [G loss: 4.938401]\n",
      "epoch:34 step:27305 [D loss: 0.131011, acc: 99.22%] [G loss: 4.545423]\n",
      "epoch:34 step:27306 [D loss: 0.270967, acc: 93.75%] [G loss: 5.576813]\n",
      "epoch:34 step:27307 [D loss: 0.231418, acc: 97.66%] [G loss: 4.333461]\n",
      "epoch:34 step:27308 [D loss: 0.260020, acc: 96.88%] [G loss: 3.778362]\n",
      "epoch:34 step:27309 [D loss: 0.582047, acc: 60.94%] [G loss: 3.752074]\n",
      "epoch:34 step:27310 [D loss: 0.919656, acc: 50.00%] [G loss: 5.060069]\n",
      "epoch:34 step:27311 [D loss: 0.263788, acc: 96.09%] [G loss: 3.352053]\n",
      "epoch:34 step:27312 [D loss: 0.184697, acc: 96.09%] [G loss: 6.453962]\n",
      "epoch:34 step:27313 [D loss: 0.132742, acc: 100.00%] [G loss: 4.532940]\n",
      "epoch:34 step:27314 [D loss: 0.031691, acc: 100.00%] [G loss: 8.176707]\n",
      "epoch:34 step:27315 [D loss: 0.820498, acc: 52.34%] [G loss: 6.099311]\n",
      "epoch:34 step:27316 [D loss: 0.633611, acc: 57.81%] [G loss: 6.192458]\n",
      "epoch:34 step:27317 [D loss: 0.456585, acc: 71.09%] [G loss: 4.067264]\n",
      "epoch:34 step:27318 [D loss: 0.638732, acc: 60.16%] [G loss: 6.238584]\n",
      "epoch:34 step:27319 [D loss: 0.249683, acc: 92.97%] [G loss: 5.123306]\n",
      "epoch:34 step:27320 [D loss: 0.452171, acc: 69.53%] [G loss: 5.655847]\n",
      "epoch:34 step:27321 [D loss: 0.073596, acc: 100.00%] [G loss: 5.381512]\n",
      "epoch:34 step:27322 [D loss: 0.969421, acc: 50.78%] [G loss: 5.154737]\n",
      "epoch:34 step:27323 [D loss: 0.193494, acc: 94.53%] [G loss: 5.147365]\n",
      "epoch:34 step:27324 [D loss: 0.197349, acc: 94.53%] [G loss: 5.365252]\n",
      "epoch:34 step:27325 [D loss: 0.328376, acc: 88.28%] [G loss: 6.113243]\n",
      "epoch:34 step:27326 [D loss: 0.195872, acc: 96.09%] [G loss: 5.107568]\n",
      "epoch:34 step:27327 [D loss: 0.010309, acc: 100.00%] [G loss: 6.389479]\n",
      "epoch:34 step:27328 [D loss: 0.386497, acc: 75.78%] [G loss: 4.973147]\n",
      "epoch:34 step:27329 [D loss: 0.572642, acc: 60.16%] [G loss: 2.350807]\n",
      "epoch:34 step:27330 [D loss: 0.686118, acc: 54.69%] [G loss: 5.813159]\n",
      "epoch:34 step:27331 [D loss: 0.662258, acc: 58.59%] [G loss: 3.863242]\n",
      "epoch:34 step:27332 [D loss: 0.360175, acc: 91.41%] [G loss: 4.897534]\n",
      "epoch:34 step:27333 [D loss: 0.431874, acc: 78.12%] [G loss: 6.214778]\n",
      "epoch:34 step:27334 [D loss: 0.180523, acc: 97.66%] [G loss: 3.121372]\n",
      "epoch:34 step:27335 [D loss: 0.431197, acc: 82.81%] [G loss: 4.669363]\n",
      "epoch:35 step:27336 [D loss: 0.152615, acc: 99.22%] [G loss: 3.848648]\n",
      "epoch:35 step:27337 [D loss: 0.339293, acc: 90.62%] [G loss: 5.633825]\n",
      "epoch:35 step:27338 [D loss: 0.260697, acc: 95.31%] [G loss: 6.559056]\n",
      "epoch:35 step:27339 [D loss: 0.066337, acc: 100.00%] [G loss: 3.489111]\n",
      "epoch:35 step:27340 [D loss: 0.368884, acc: 79.69%] [G loss: 5.659612]\n",
      "epoch:35 step:27341 [D loss: 0.049477, acc: 100.00%] [G loss: 3.533666]\n",
      "epoch:35 step:27342 [D loss: 0.137046, acc: 99.22%] [G loss: 5.768730]\n",
      "epoch:35 step:27343 [D loss: 0.777940, acc: 52.34%] [G loss: 4.616517]\n",
      "epoch:35 step:27344 [D loss: 0.531081, acc: 80.47%] [G loss: 5.074631]\n",
      "epoch:35 step:27345 [D loss: 0.241553, acc: 92.19%] [G loss: 7.366431]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27346 [D loss: 0.087953, acc: 100.00%] [G loss: 3.398094]\n",
      "epoch:35 step:27347 [D loss: 0.112972, acc: 99.22%] [G loss: 4.516459]\n",
      "epoch:35 step:27348 [D loss: 0.473864, acc: 78.12%] [G loss: 4.830480]\n",
      "epoch:35 step:27349 [D loss: 0.360903, acc: 93.75%] [G loss: 6.225420]\n",
      "epoch:35 step:27350 [D loss: 1.095609, acc: 50.78%] [G loss: 4.077026]\n",
      "epoch:35 step:27351 [D loss: 0.266198, acc: 91.41%] [G loss: 3.945372]\n",
      "epoch:35 step:27352 [D loss: 0.398104, acc: 76.56%] [G loss: 4.131543]\n",
      "epoch:35 step:27353 [D loss: 0.445847, acc: 73.44%] [G loss: 4.083433]\n",
      "epoch:35 step:27354 [D loss: 0.146591, acc: 97.66%] [G loss: 4.580606]\n",
      "epoch:35 step:27355 [D loss: 0.159108, acc: 99.22%] [G loss: 5.032504]\n",
      "epoch:35 step:27356 [D loss: 1.294871, acc: 11.72%] [G loss: 5.074874]\n",
      "epoch:35 step:27357 [D loss: 0.202278, acc: 99.22%] [G loss: 4.860455]\n",
      "epoch:35 step:27358 [D loss: 0.255711, acc: 96.88%] [G loss: 1.736148]\n",
      "epoch:35 step:27359 [D loss: 1.119066, acc: 50.78%] [G loss: 5.242898]\n",
      "epoch:35 step:27360 [D loss: 0.242280, acc: 88.28%] [G loss: 7.278408]\n",
      "epoch:35 step:27361 [D loss: 0.548190, acc: 76.56%] [G loss: 4.972869]\n",
      "epoch:35 step:27362 [D loss: 0.251158, acc: 89.84%] [G loss: 4.774540]\n",
      "epoch:35 step:27363 [D loss: 0.177212, acc: 99.22%] [G loss: 3.592073]\n",
      "epoch:35 step:27364 [D loss: 0.537801, acc: 71.88%] [G loss: 6.082384]\n",
      "epoch:35 step:27365 [D loss: 0.684643, acc: 59.38%] [G loss: 7.100994]\n",
      "epoch:35 step:27366 [D loss: 0.036001, acc: 100.00%] [G loss: 3.856184]\n",
      "epoch:35 step:27367 [D loss: 0.514728, acc: 71.09%] [G loss: 4.509147]\n",
      "epoch:35 step:27368 [D loss: 0.351651, acc: 79.69%] [G loss: 5.305689]\n",
      "epoch:35 step:27369 [D loss: 0.212531, acc: 94.53%] [G loss: 6.475368]\n",
      "epoch:35 step:27370 [D loss: 0.786208, acc: 54.69%] [G loss: 5.927433]\n",
      "epoch:35 step:27371 [D loss: 0.481228, acc: 67.19%] [G loss: 5.302968]\n",
      "epoch:35 step:27372 [D loss: 0.154931, acc: 96.88%] [G loss: 4.630233]\n",
      "epoch:35 step:27373 [D loss: 0.141687, acc: 99.22%] [G loss: 4.534233]\n",
      "epoch:35 step:27374 [D loss: 0.610638, acc: 66.41%] [G loss: 7.628057]\n",
      "epoch:35 step:27375 [D loss: 0.162798, acc: 96.09%] [G loss: 6.711893]\n",
      "epoch:35 step:27376 [D loss: 0.711344, acc: 54.69%] [G loss: 6.982054]\n",
      "epoch:35 step:27377 [D loss: 0.552199, acc: 63.28%] [G loss: 5.335861]\n",
      "epoch:35 step:27378 [D loss: 0.290627, acc: 95.31%] [G loss: 2.541435]\n",
      "epoch:35 step:27379 [D loss: 0.693565, acc: 61.72%] [G loss: 4.379800]\n",
      "epoch:35 step:27380 [D loss: 0.182990, acc: 93.75%] [G loss: 3.556672]\n",
      "epoch:35 step:27381 [D loss: 0.166214, acc: 99.22%] [G loss: 4.662193]\n",
      "epoch:35 step:27382 [D loss: 0.101705, acc: 100.00%] [G loss: 5.725646]\n",
      "epoch:35 step:27383 [D loss: 0.304620, acc: 96.09%] [G loss: 3.798363]\n",
      "epoch:35 step:27384 [D loss: 0.536735, acc: 66.41%] [G loss: 3.666226]\n",
      "epoch:35 step:27385 [D loss: 0.288295, acc: 89.06%] [G loss: 2.684762]\n",
      "epoch:35 step:27386 [D loss: 0.232148, acc: 95.31%] [G loss: 3.048013]\n",
      "epoch:35 step:27387 [D loss: 0.267749, acc: 88.28%] [G loss: 5.132692]\n",
      "epoch:35 step:27388 [D loss: 0.450521, acc: 85.16%] [G loss: 5.032602]\n",
      "epoch:35 step:27389 [D loss: 0.108892, acc: 99.22%] [G loss: 3.583822]\n",
      "epoch:35 step:27390 [D loss: 0.859781, acc: 50.00%] [G loss: 3.277324]\n",
      "epoch:35 step:27391 [D loss: 0.248207, acc: 91.41%] [G loss: 4.144951]\n",
      "epoch:35 step:27392 [D loss: 0.334388, acc: 92.97%] [G loss: 3.602996]\n",
      "epoch:35 step:27393 [D loss: 0.310108, acc: 85.94%] [G loss: 6.027572]\n",
      "epoch:35 step:27394 [D loss: 0.417778, acc: 79.69%] [G loss: 3.186092]\n",
      "epoch:35 step:27395 [D loss: 1.017362, acc: 51.56%] [G loss: 4.261881]\n",
      "epoch:35 step:27396 [D loss: 1.233813, acc: 50.00%] [G loss: 6.426430]\n",
      "epoch:35 step:27397 [D loss: 0.190827, acc: 97.66%] [G loss: 6.783142]\n",
      "epoch:35 step:27398 [D loss: 0.855391, acc: 53.12%] [G loss: 5.304148]\n",
      "epoch:35 step:27399 [D loss: 0.730932, acc: 55.47%] [G loss: 4.218069]\n",
      "epoch:35 step:27400 [D loss: 0.735754, acc: 54.69%] [G loss: 7.088135]\n",
      "epoch:35 step:27401 [D loss: 0.141895, acc: 100.00%] [G loss: 4.516227]\n",
      "epoch:35 step:27402 [D loss: 0.112795, acc: 98.44%] [G loss: 4.917728]\n",
      "epoch:35 step:27403 [D loss: 0.245310, acc: 93.75%] [G loss: 3.637684]\n",
      "epoch:35 step:27404 [D loss: 0.554375, acc: 61.72%] [G loss: 6.163061]\n",
      "epoch:35 step:27405 [D loss: 0.732903, acc: 56.25%] [G loss: 5.482338]\n",
      "epoch:35 step:27406 [D loss: 0.604853, acc: 60.16%] [G loss: 4.891905]\n",
      "epoch:35 step:27407 [D loss: 0.425185, acc: 86.72%] [G loss: 6.407559]\n",
      "epoch:35 step:27408 [D loss: 0.326080, acc: 87.50%] [G loss: 2.029278]\n",
      "epoch:35 step:27409 [D loss: 0.212903, acc: 99.22%] [G loss: 4.495362]\n",
      "epoch:35 step:27410 [D loss: 0.407972, acc: 72.66%] [G loss: 6.648383]\n",
      "epoch:35 step:27411 [D loss: 0.275095, acc: 85.94%] [G loss: 3.592458]\n",
      "epoch:35 step:27412 [D loss: 0.107062, acc: 98.44%] [G loss: 5.475631]\n",
      "epoch:35 step:27413 [D loss: 0.391539, acc: 75.78%] [G loss: 4.865682]\n",
      "epoch:35 step:27414 [D loss: 0.229448, acc: 92.97%] [G loss: 7.118566]\n",
      "epoch:35 step:27415 [D loss: 1.036909, acc: 32.81%] [G loss: 5.703939]\n",
      "epoch:35 step:27416 [D loss: 0.759916, acc: 54.69%] [G loss: 5.776065]\n",
      "epoch:35 step:27417 [D loss: 0.250203, acc: 93.75%] [G loss: 5.532600]\n",
      "epoch:35 step:27418 [D loss: 1.021054, acc: 43.75%] [G loss: 8.794796]\n",
      "epoch:35 step:27419 [D loss: 0.439057, acc: 71.09%] [G loss: 3.702461]\n",
      "epoch:35 step:27420 [D loss: 0.129211, acc: 99.22%] [G loss: 5.074144]\n",
      "epoch:35 step:27421 [D loss: 0.339014, acc: 85.16%] [G loss: 6.612262]\n",
      "epoch:35 step:27422 [D loss: 0.296441, acc: 92.19%] [G loss: 3.841579]\n",
      "epoch:35 step:27423 [D loss: 0.317920, acc: 92.97%] [G loss: 5.390498]\n",
      "epoch:35 step:27424 [D loss: 0.300562, acc: 92.97%] [G loss: 5.743807]\n",
      "epoch:35 step:27425 [D loss: 0.063700, acc: 100.00%] [G loss: 5.510526]\n",
      "epoch:35 step:27426 [D loss: 0.135071, acc: 98.44%] [G loss: 7.062780]\n",
      "epoch:35 step:27427 [D loss: 0.644464, acc: 57.81%] [G loss: 4.719578]\n",
      "epoch:35 step:27428 [D loss: 1.212624, acc: 21.88%] [G loss: 4.098311]\n",
      "epoch:35 step:27429 [D loss: 0.272792, acc: 94.53%] [G loss: 4.648659]\n",
      "epoch:35 step:27430 [D loss: 0.083034, acc: 100.00%] [G loss: 5.074359]\n",
      "epoch:35 step:27431 [D loss: 0.326791, acc: 91.41%] [G loss: 4.235416]\n",
      "epoch:35 step:27432 [D loss: 0.734238, acc: 51.56%] [G loss: 4.623280]\n",
      "epoch:35 step:27433 [D loss: 0.480573, acc: 83.59%] [G loss: 4.376966]\n",
      "epoch:35 step:27434 [D loss: 0.435320, acc: 71.88%] [G loss: 6.922900]\n",
      "epoch:35 step:27435 [D loss: 0.940790, acc: 31.25%] [G loss: 2.233119]\n",
      "epoch:35 step:27436 [D loss: 0.538497, acc: 69.53%] [G loss: 3.919504]\n",
      "epoch:35 step:27437 [D loss: 0.278171, acc: 90.62%] [G loss: 4.452532]\n",
      "epoch:35 step:27438 [D loss: 0.406831, acc: 73.44%] [G loss: 4.614153]\n",
      "epoch:35 step:27439 [D loss: 0.138895, acc: 99.22%] [G loss: 7.693909]\n",
      "epoch:35 step:27440 [D loss: 0.364193, acc: 86.72%] [G loss: 4.004811]\n",
      "epoch:35 step:27441 [D loss: 0.200592, acc: 95.31%] [G loss: 3.432458]\n",
      "epoch:35 step:27442 [D loss: 0.082432, acc: 100.00%] [G loss: 4.553037]\n",
      "epoch:35 step:27443 [D loss: 0.049178, acc: 100.00%] [G loss: 4.658490]\n",
      "epoch:35 step:27444 [D loss: 1.130976, acc: 42.97%] [G loss: 3.102499]\n",
      "epoch:35 step:27445 [D loss: 0.247437, acc: 89.84%] [G loss: 5.671381]\n",
      "epoch:35 step:27446 [D loss: 0.563931, acc: 67.97%] [G loss: 2.766718]\n",
      "epoch:35 step:27447 [D loss: 0.104568, acc: 100.00%] [G loss: 4.477154]\n",
      "epoch:35 step:27448 [D loss: 0.381230, acc: 82.81%] [G loss: 4.127134]\n",
      "epoch:35 step:27449 [D loss: 0.478728, acc: 68.75%] [G loss: 4.421402]\n",
      "epoch:35 step:27450 [D loss: 0.263622, acc: 96.09%] [G loss: 3.461739]\n",
      "epoch:35 step:27451 [D loss: 0.657236, acc: 65.62%] [G loss: 6.693320]\n",
      "epoch:35 step:27452 [D loss: 0.144698, acc: 99.22%] [G loss: 3.211843]\n",
      "epoch:35 step:27453 [D loss: 0.179562, acc: 97.66%] [G loss: 2.778793]\n",
      "epoch:35 step:27454 [D loss: 0.398802, acc: 90.62%] [G loss: 5.152089]\n",
      "epoch:35 step:27455 [D loss: 0.149133, acc: 96.09%] [G loss: 3.415232]\n",
      "epoch:35 step:27456 [D loss: 0.126875, acc: 100.00%] [G loss: 3.394116]\n",
      "epoch:35 step:27457 [D loss: 0.189724, acc: 95.31%] [G loss: 4.079141]\n",
      "epoch:35 step:27458 [D loss: 0.176036, acc: 98.44%] [G loss: 2.556466]\n",
      "epoch:35 step:27459 [D loss: 0.237629, acc: 97.66%] [G loss: 4.452857]\n",
      "epoch:35 step:27460 [D loss: 0.136568, acc: 99.22%] [G loss: 4.696456]\n",
      "epoch:35 step:27461 [D loss: 0.245489, acc: 99.22%] [G loss: 7.354189]\n",
      "epoch:35 step:27462 [D loss: 0.100284, acc: 99.22%] [G loss: 5.165349]\n",
      "epoch:35 step:27463 [D loss: 0.124219, acc: 100.00%] [G loss: 6.732353]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27464 [D loss: 0.551531, acc: 67.19%] [G loss: 5.519891]\n",
      "epoch:35 step:27465 [D loss: 0.081876, acc: 100.00%] [G loss: 3.175108]\n",
      "epoch:35 step:27466 [D loss: 0.371057, acc: 89.06%] [G loss: 6.408188]\n",
      "epoch:35 step:27467 [D loss: 0.304886, acc: 89.06%] [G loss: 6.608685]\n",
      "epoch:35 step:27468 [D loss: 0.297116, acc: 89.06%] [G loss: 5.673723]\n",
      "epoch:35 step:27469 [D loss: 0.190421, acc: 97.66%] [G loss: 6.942406]\n",
      "epoch:35 step:27470 [D loss: 0.613886, acc: 64.06%] [G loss: 2.275997]\n",
      "epoch:35 step:27471 [D loss: 0.715718, acc: 58.59%] [G loss: 5.653674]\n",
      "epoch:35 step:27472 [D loss: 0.149083, acc: 97.66%] [G loss: 3.901759]\n",
      "epoch:35 step:27473 [D loss: 0.228051, acc: 97.66%] [G loss: 4.653478]\n",
      "epoch:35 step:27474 [D loss: 0.757151, acc: 48.44%] [G loss: 4.457378]\n",
      "epoch:35 step:27475 [D loss: 0.284499, acc: 91.41%] [G loss: 4.241439]\n",
      "epoch:35 step:27476 [D loss: 0.299493, acc: 94.53%] [G loss: 3.950692]\n",
      "epoch:35 step:27477 [D loss: 0.273127, acc: 93.75%] [G loss: 2.603354]\n",
      "epoch:35 step:27478 [D loss: 0.085033, acc: 99.22%] [G loss: 2.997060]\n",
      "epoch:35 step:27479 [D loss: 0.585588, acc: 68.75%] [G loss: 2.974802]\n",
      "epoch:35 step:27480 [D loss: 0.580954, acc: 65.62%] [G loss: 7.246522]\n",
      "epoch:35 step:27481 [D loss: 0.215396, acc: 94.53%] [G loss: 8.276237]\n",
      "epoch:35 step:27482 [D loss: 0.163056, acc: 100.00%] [G loss: 4.311598]\n",
      "epoch:35 step:27483 [D loss: 0.074868, acc: 99.22%] [G loss: 6.184244]\n",
      "epoch:35 step:27484 [D loss: 0.938395, acc: 48.44%] [G loss: 5.172066]\n",
      "epoch:35 step:27485 [D loss: 0.065409, acc: 99.22%] [G loss: 5.240836]\n",
      "epoch:35 step:27486 [D loss: 0.587058, acc: 67.19%] [G loss: 5.095865]\n",
      "epoch:35 step:27487 [D loss: 0.866419, acc: 46.88%] [G loss: 2.964545]\n",
      "epoch:35 step:27488 [D loss: 0.542810, acc: 73.44%] [G loss: 3.914659]\n",
      "epoch:35 step:27489 [D loss: 0.592095, acc: 66.41%] [G loss: 6.546755]\n",
      "epoch:35 step:27490 [D loss: 0.681672, acc: 60.16%] [G loss: 1.621190]\n",
      "epoch:35 step:27491 [D loss: 0.068116, acc: 100.00%] [G loss: 3.133575]\n",
      "epoch:35 step:27492 [D loss: 0.776977, acc: 53.12%] [G loss: 6.533642]\n",
      "epoch:35 step:27493 [D loss: 0.272815, acc: 89.06%] [G loss: 5.842584]\n",
      "epoch:35 step:27494 [D loss: 0.133058, acc: 98.44%] [G loss: 5.655779]\n",
      "epoch:35 step:27495 [D loss: 0.309499, acc: 84.38%] [G loss: 3.600086]\n",
      "epoch:35 step:27496 [D loss: 0.104037, acc: 100.00%] [G loss: 4.794957]\n",
      "epoch:35 step:27497 [D loss: 0.170968, acc: 100.00%] [G loss: 5.340410]\n",
      "epoch:35 step:27498 [D loss: 0.211099, acc: 97.66%] [G loss: 3.167510]\n",
      "epoch:35 step:27499 [D loss: 0.346041, acc: 89.06%] [G loss: 7.013039]\n",
      "epoch:35 step:27500 [D loss: 0.204111, acc: 98.44%] [G loss: 5.098082]\n",
      "epoch:35 step:27501 [D loss: 0.662790, acc: 64.84%] [G loss: 6.218579]\n",
      "epoch:35 step:27502 [D loss: 0.452212, acc: 75.00%] [G loss: 5.337960]\n",
      "epoch:35 step:27503 [D loss: 0.349154, acc: 85.94%] [G loss: 6.916855]\n",
      "epoch:35 step:27504 [D loss: 0.806244, acc: 53.91%] [G loss: 4.682589]\n",
      "epoch:35 step:27505 [D loss: 0.179478, acc: 99.22%] [G loss: 6.559849]\n",
      "epoch:35 step:27506 [D loss: 0.447080, acc: 68.75%] [G loss: 5.073246]\n",
      "epoch:35 step:27507 [D loss: 0.405714, acc: 79.69%] [G loss: 6.214389]\n",
      "epoch:35 step:27508 [D loss: 0.260314, acc: 92.19%] [G loss: 6.089441]\n",
      "epoch:35 step:27509 [D loss: 0.193663, acc: 96.88%] [G loss: 6.894217]\n",
      "epoch:35 step:27510 [D loss: 0.244953, acc: 91.41%] [G loss: 6.748950]\n",
      "epoch:35 step:27511 [D loss: 0.334244, acc: 93.75%] [G loss: 4.506098]\n",
      "epoch:35 step:27512 [D loss: 0.170936, acc: 98.44%] [G loss: 6.012939]\n",
      "epoch:35 step:27513 [D loss: 0.168317, acc: 100.00%] [G loss: 4.569258]\n",
      "epoch:35 step:27514 [D loss: 0.166692, acc: 97.66%] [G loss: 3.493897]\n",
      "epoch:35 step:27515 [D loss: 1.072797, acc: 22.66%] [G loss: 3.418869]\n",
      "epoch:35 step:27516 [D loss: 0.124025, acc: 98.44%] [G loss: 3.775771]\n",
      "epoch:35 step:27517 [D loss: 0.585877, acc: 63.28%] [G loss: 3.684179]\n",
      "epoch:35 step:27518 [D loss: 0.354988, acc: 92.97%] [G loss: 6.912842]\n",
      "epoch:35 step:27519 [D loss: 0.226181, acc: 92.19%] [G loss: 5.333067]\n",
      "epoch:35 step:27520 [D loss: 0.251643, acc: 95.31%] [G loss: 5.281910]\n",
      "epoch:35 step:27521 [D loss: 0.368499, acc: 80.47%] [G loss: 5.262171]\n",
      "epoch:35 step:27522 [D loss: 0.129052, acc: 100.00%] [G loss: 7.453422]\n",
      "epoch:35 step:27523 [D loss: 0.512639, acc: 68.75%] [G loss: 6.221019]\n",
      "epoch:35 step:27524 [D loss: 0.069542, acc: 99.22%] [G loss: 7.093817]\n",
      "epoch:35 step:27525 [D loss: 0.646674, acc: 61.72%] [G loss: 5.976405]\n",
      "epoch:35 step:27526 [D loss: 0.075655, acc: 100.00%] [G loss: 2.473249]\n",
      "epoch:35 step:27527 [D loss: 0.805474, acc: 46.09%] [G loss: 7.270564]\n",
      "epoch:35 step:27528 [D loss: 1.408007, acc: 12.50%] [G loss: 5.134357]\n",
      "epoch:35 step:27529 [D loss: 0.591799, acc: 74.22%] [G loss: 5.364467]\n",
      "epoch:35 step:27530 [D loss: 0.197115, acc: 96.88%] [G loss: 5.082814]\n",
      "epoch:35 step:27531 [D loss: 0.204782, acc: 96.09%] [G loss: 4.001065]\n",
      "epoch:35 step:27532 [D loss: 0.118855, acc: 99.22%] [G loss: 5.869630]\n",
      "epoch:35 step:27533 [D loss: 0.330227, acc: 82.03%] [G loss: 5.561005]\n",
      "epoch:35 step:27534 [D loss: 0.753052, acc: 56.25%] [G loss: 5.663677]\n",
      "epoch:35 step:27535 [D loss: 0.032983, acc: 100.00%] [G loss: 5.197141]\n",
      "epoch:35 step:27536 [D loss: 1.579053, acc: 50.00%] [G loss: 7.290096]\n",
      "epoch:35 step:27537 [D loss: 1.250320, acc: 46.09%] [G loss: 4.625697]\n",
      "epoch:35 step:27538 [D loss: 0.820229, acc: 50.78%] [G loss: 6.484593]\n",
      "epoch:35 step:27539 [D loss: 0.194464, acc: 95.31%] [G loss: 4.020384]\n",
      "epoch:35 step:27540 [D loss: 0.155529, acc: 99.22%] [G loss: 6.467802]\n",
      "epoch:35 step:27541 [D loss: 1.253927, acc: 36.72%] [G loss: 5.090413]\n",
      "epoch:35 step:27542 [D loss: 0.256359, acc: 96.88%] [G loss: 3.345021]\n",
      "epoch:35 step:27543 [D loss: 1.141019, acc: 21.09%] [G loss: 5.462032]\n",
      "epoch:35 step:27544 [D loss: 0.247804, acc: 98.44%] [G loss: 4.823003]\n",
      "epoch:35 step:27545 [D loss: 0.633103, acc: 60.16%] [G loss: 6.645782]\n",
      "epoch:35 step:27546 [D loss: 0.061254, acc: 100.00%] [G loss: 5.620156]\n",
      "epoch:35 step:27547 [D loss: 0.353646, acc: 79.69%] [G loss: 4.002605]\n",
      "epoch:35 step:27548 [D loss: 0.178074, acc: 99.22%] [G loss: 7.036506]\n",
      "epoch:35 step:27549 [D loss: 0.123298, acc: 99.22%] [G loss: 5.421250]\n",
      "epoch:35 step:27550 [D loss: 0.387732, acc: 85.16%] [G loss: 4.810273]\n",
      "epoch:35 step:27551 [D loss: 0.288520, acc: 92.19%] [G loss: 6.722316]\n",
      "epoch:35 step:27552 [D loss: 0.310873, acc: 93.75%] [G loss: 6.098189]\n",
      "epoch:35 step:27553 [D loss: 0.377150, acc: 86.72%] [G loss: 4.963052]\n",
      "epoch:35 step:27554 [D loss: 0.375155, acc: 86.72%] [G loss: 3.076918]\n",
      "epoch:35 step:27555 [D loss: 1.053574, acc: 30.47%] [G loss: 6.329484]\n",
      "epoch:35 step:27556 [D loss: 0.490921, acc: 68.75%] [G loss: 5.065041]\n",
      "epoch:35 step:27557 [D loss: 0.363673, acc: 80.47%] [G loss: 4.121090]\n",
      "epoch:35 step:27558 [D loss: 0.972546, acc: 32.03%] [G loss: 4.492095]\n",
      "epoch:35 step:27559 [D loss: 0.314200, acc: 84.38%] [G loss: 3.838284]\n",
      "epoch:35 step:27560 [D loss: 0.562822, acc: 72.66%] [G loss: 5.703033]\n",
      "epoch:35 step:27561 [D loss: 0.594463, acc: 57.81%] [G loss: 6.113855]\n",
      "epoch:35 step:27562 [D loss: 0.117326, acc: 100.00%] [G loss: 5.083143]\n",
      "epoch:35 step:27563 [D loss: 0.812545, acc: 50.78%] [G loss: 7.320482]\n",
      "epoch:35 step:27564 [D loss: 0.203600, acc: 97.66%] [G loss: 5.455666]\n",
      "epoch:35 step:27565 [D loss: 0.165871, acc: 97.66%] [G loss: 5.949681]\n",
      "epoch:35 step:27566 [D loss: 0.109902, acc: 99.22%] [G loss: 3.531712]\n",
      "epoch:35 step:27567 [D loss: 0.704068, acc: 56.25%] [G loss: 7.102573]\n",
      "epoch:35 step:27568 [D loss: 0.558473, acc: 60.16%] [G loss: 4.533205]\n",
      "epoch:35 step:27569 [D loss: 0.050975, acc: 100.00%] [G loss: 4.886349]\n",
      "epoch:35 step:27570 [D loss: 0.386546, acc: 85.94%] [G loss: 5.814787]\n",
      "epoch:35 step:27571 [D loss: 0.438960, acc: 71.09%] [G loss: 6.282806]\n",
      "epoch:35 step:27572 [D loss: 0.366059, acc: 76.56%] [G loss: 3.255825]\n",
      "epoch:35 step:27573 [D loss: 0.300233, acc: 93.75%] [G loss: 5.109318]\n",
      "epoch:35 step:27574 [D loss: 0.256312, acc: 93.75%] [G loss: 3.424355]\n",
      "epoch:35 step:27575 [D loss: 0.686850, acc: 57.81%] [G loss: 4.113796]\n",
      "epoch:35 step:27576 [D loss: 0.710174, acc: 59.38%] [G loss: 6.084423]\n",
      "epoch:35 step:27577 [D loss: 0.366298, acc: 76.56%] [G loss: 4.626885]\n",
      "epoch:35 step:27578 [D loss: 0.293964, acc: 95.31%] [G loss: 6.845026]\n",
      "epoch:35 step:27579 [D loss: 0.537806, acc: 65.62%] [G loss: 3.146522]\n",
      "epoch:35 step:27580 [D loss: 0.289833, acc: 84.38%] [G loss: 6.792716]\n",
      "epoch:35 step:27581 [D loss: 0.192269, acc: 98.44%] [G loss: 4.605365]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27582 [D loss: 0.295948, acc: 96.09%] [G loss: 5.752513]\n",
      "epoch:35 step:27583 [D loss: 0.897827, acc: 44.53%] [G loss: 4.859172]\n",
      "epoch:35 step:27584 [D loss: 0.093220, acc: 99.22%] [G loss: 3.721612]\n",
      "epoch:35 step:27585 [D loss: 0.204884, acc: 94.53%] [G loss: 3.909438]\n",
      "epoch:35 step:27586 [D loss: 0.093230, acc: 100.00%] [G loss: 5.498210]\n",
      "epoch:35 step:27587 [D loss: 0.121325, acc: 100.00%] [G loss: 2.681024]\n",
      "epoch:35 step:27588 [D loss: 0.659160, acc: 64.06%] [G loss: 5.348661]\n",
      "epoch:35 step:27589 [D loss: 0.272442, acc: 95.31%] [G loss: 4.540644]\n",
      "epoch:35 step:27590 [D loss: 0.040278, acc: 100.00%] [G loss: 4.542870]\n",
      "epoch:35 step:27591 [D loss: 0.429950, acc: 78.91%] [G loss: 5.356239]\n",
      "epoch:35 step:27592 [D loss: 0.417058, acc: 79.69%] [G loss: 6.257785]\n",
      "epoch:35 step:27593 [D loss: 0.811209, acc: 52.34%] [G loss: 2.877826]\n",
      "epoch:35 step:27594 [D loss: 0.723913, acc: 60.94%] [G loss: 4.676445]\n",
      "epoch:35 step:27595 [D loss: 0.182183, acc: 96.09%] [G loss: 2.745375]\n",
      "epoch:35 step:27596 [D loss: 0.172556, acc: 98.44%] [G loss: 4.145439]\n",
      "epoch:35 step:27597 [D loss: 0.117773, acc: 100.00%] [G loss: 6.820110]\n",
      "epoch:35 step:27598 [D loss: 0.158880, acc: 96.88%] [G loss: 4.572440]\n",
      "epoch:35 step:27599 [D loss: 0.378600, acc: 93.75%] [G loss: 7.034145]\n",
      "epoch:35 step:27600 [D loss: 0.372641, acc: 85.94%] [G loss: 4.521539]\n",
      "epoch:35 step:27601 [D loss: 0.391468, acc: 81.25%] [G loss: 6.156895]\n",
      "epoch:35 step:27602 [D loss: 0.069001, acc: 100.00%] [G loss: 6.566381]\n",
      "epoch:35 step:27603 [D loss: 0.304907, acc: 97.66%] [G loss: 3.173516]\n",
      "epoch:35 step:27604 [D loss: 0.821749, acc: 50.78%] [G loss: 2.341859]\n",
      "epoch:35 step:27605 [D loss: 0.243216, acc: 92.97%] [G loss: 2.316710]\n",
      "epoch:35 step:27606 [D loss: 0.160294, acc: 99.22%] [G loss: 6.011514]\n",
      "epoch:35 step:27607 [D loss: 0.660578, acc: 62.50%] [G loss: 4.989971]\n",
      "epoch:35 step:27608 [D loss: 0.651013, acc: 60.94%] [G loss: 6.074092]\n",
      "epoch:35 step:27609 [D loss: 0.628305, acc: 59.38%] [G loss: 5.017473]\n",
      "epoch:35 step:27610 [D loss: 0.210439, acc: 96.88%] [G loss: 4.105591]\n",
      "epoch:35 step:27611 [D loss: 0.321601, acc: 85.16%] [G loss: 7.611661]\n",
      "epoch:35 step:27612 [D loss: 1.018686, acc: 51.56%] [G loss: 5.738708]\n",
      "epoch:35 step:27613 [D loss: 0.440425, acc: 80.47%] [G loss: 5.508562]\n",
      "epoch:35 step:27614 [D loss: 0.268871, acc: 92.97%] [G loss: 6.107902]\n",
      "epoch:35 step:27615 [D loss: 0.113070, acc: 100.00%] [G loss: 4.778990]\n",
      "epoch:35 step:27616 [D loss: 0.282712, acc: 92.97%] [G loss: 3.351376]\n",
      "epoch:35 step:27617 [D loss: 0.360873, acc: 87.50%] [G loss: 4.647451]\n",
      "epoch:35 step:27618 [D loss: 0.417892, acc: 81.25%] [G loss: 4.260251]\n",
      "epoch:35 step:27619 [D loss: 0.078374, acc: 100.00%] [G loss: 5.533777]\n",
      "epoch:35 step:27620 [D loss: 0.317582, acc: 91.41%] [G loss: 5.269076]\n",
      "epoch:35 step:27621 [D loss: 0.339761, acc: 88.28%] [G loss: 5.326719]\n",
      "epoch:35 step:27622 [D loss: 0.322143, acc: 91.41%] [G loss: 2.942148]\n",
      "epoch:35 step:27623 [D loss: 0.113275, acc: 99.22%] [G loss: 3.030564]\n",
      "epoch:35 step:27624 [D loss: 0.112410, acc: 99.22%] [G loss: 2.858517]\n",
      "epoch:35 step:27625 [D loss: 0.219991, acc: 96.09%] [G loss: 4.554288]\n",
      "epoch:35 step:27626 [D loss: 0.250527, acc: 92.19%] [G loss: 3.147888]\n",
      "epoch:35 step:27627 [D loss: 0.175181, acc: 98.44%] [G loss: 6.494735]\n",
      "epoch:35 step:27628 [D loss: 0.220520, acc: 93.75%] [G loss: 7.257698]\n",
      "epoch:35 step:27629 [D loss: 0.330306, acc: 84.38%] [G loss: 4.052015]\n",
      "epoch:35 step:27630 [D loss: 0.382853, acc: 89.06%] [G loss: 5.435794]\n",
      "epoch:35 step:27631 [D loss: 0.140924, acc: 99.22%] [G loss: 5.423000]\n",
      "epoch:35 step:27632 [D loss: 1.445532, acc: 47.66%] [G loss: 6.152714]\n",
      "epoch:35 step:27633 [D loss: 0.962645, acc: 52.34%] [G loss: 4.683687]\n",
      "epoch:35 step:27634 [D loss: 0.106479, acc: 100.00%] [G loss: 6.762577]\n",
      "epoch:35 step:27635 [D loss: 0.648016, acc: 61.72%] [G loss: 5.525205]\n",
      "epoch:35 step:27636 [D loss: 0.328116, acc: 89.84%] [G loss: 5.611214]\n",
      "epoch:35 step:27637 [D loss: 0.091235, acc: 98.44%] [G loss: 4.700579]\n",
      "epoch:35 step:27638 [D loss: 0.508232, acc: 71.09%] [G loss: 7.290082]\n",
      "epoch:35 step:27639 [D loss: 0.370870, acc: 88.28%] [G loss: 3.366230]\n",
      "epoch:35 step:27640 [D loss: 0.185380, acc: 96.09%] [G loss: 5.080226]\n",
      "epoch:35 step:27641 [D loss: 0.324505, acc: 89.84%] [G loss: 4.601947]\n",
      "epoch:35 step:27642 [D loss: 0.193608, acc: 96.88%] [G loss: 6.505781]\n",
      "epoch:35 step:27643 [D loss: 0.480662, acc: 78.12%] [G loss: 5.452943]\n",
      "epoch:35 step:27644 [D loss: 0.093010, acc: 100.00%] [G loss: 5.767030]\n",
      "epoch:35 step:27645 [D loss: 0.238104, acc: 92.97%] [G loss: 4.106291]\n",
      "epoch:35 step:27646 [D loss: 0.082319, acc: 100.00%] [G loss: 5.745353]\n",
      "epoch:35 step:27647 [D loss: 0.267073, acc: 97.66%] [G loss: 4.947068]\n",
      "epoch:35 step:27648 [D loss: 0.683611, acc: 59.38%] [G loss: 3.452862]\n",
      "epoch:35 step:27649 [D loss: 0.143031, acc: 99.22%] [G loss: 4.453635]\n",
      "epoch:35 step:27650 [D loss: 0.067421, acc: 100.00%] [G loss: 5.016960]\n",
      "epoch:35 step:27651 [D loss: 0.541181, acc: 72.66%] [G loss: 7.021166]\n",
      "epoch:35 step:27652 [D loss: 0.941829, acc: 43.75%] [G loss: 5.851367]\n",
      "epoch:35 step:27653 [D loss: 0.295705, acc: 92.97%] [G loss: 4.277303]\n",
      "epoch:35 step:27654 [D loss: 0.587574, acc: 71.88%] [G loss: 4.332363]\n",
      "epoch:35 step:27655 [D loss: 1.385989, acc: 14.84%] [G loss: 5.109168]\n",
      "epoch:35 step:27656 [D loss: 0.164359, acc: 98.44%] [G loss: 6.067803]\n",
      "epoch:35 step:27657 [D loss: 0.165509, acc: 99.22%] [G loss: 2.868817]\n",
      "epoch:35 step:27658 [D loss: 0.129578, acc: 98.44%] [G loss: 3.354961]\n",
      "epoch:35 step:27659 [D loss: 0.667459, acc: 57.81%] [G loss: 6.265047]\n",
      "epoch:35 step:27660 [D loss: 0.749936, acc: 51.56%] [G loss: 4.566565]\n",
      "epoch:35 step:27661 [D loss: 0.065526, acc: 100.00%] [G loss: 4.151947]\n",
      "epoch:35 step:27662 [D loss: 0.970070, acc: 45.31%] [G loss: 4.231165]\n",
      "epoch:35 step:27663 [D loss: 0.361134, acc: 90.62%] [G loss: 4.276746]\n",
      "epoch:35 step:27664 [D loss: 0.029072, acc: 100.00%] [G loss: 6.294515]\n",
      "epoch:35 step:27665 [D loss: 0.765267, acc: 54.69%] [G loss: 5.086267]\n",
      "epoch:35 step:27666 [D loss: 0.077644, acc: 100.00%] [G loss: 4.617674]\n",
      "epoch:35 step:27667 [D loss: 0.357900, acc: 82.03%] [G loss: 3.574843]\n",
      "epoch:35 step:27668 [D loss: 0.094721, acc: 99.22%] [G loss: 5.215762]\n",
      "epoch:35 step:27669 [D loss: 0.611291, acc: 60.16%] [G loss: 4.354312]\n",
      "epoch:35 step:27670 [D loss: 0.095925, acc: 100.00%] [G loss: 6.687475]\n",
      "epoch:35 step:27671 [D loss: 0.462977, acc: 82.81%] [G loss: 5.752726]\n",
      "epoch:35 step:27672 [D loss: 0.170966, acc: 97.66%] [G loss: 4.900149]\n",
      "epoch:35 step:27673 [D loss: 0.276899, acc: 96.88%] [G loss: 5.471955]\n",
      "epoch:35 step:27674 [D loss: 1.012997, acc: 44.53%] [G loss: 5.907435]\n",
      "epoch:35 step:27675 [D loss: 0.096722, acc: 99.22%] [G loss: 4.208397]\n",
      "epoch:35 step:27676 [D loss: 0.658985, acc: 55.47%] [G loss: 4.559172]\n",
      "epoch:35 step:27677 [D loss: 0.770675, acc: 53.12%] [G loss: 4.578736]\n",
      "epoch:35 step:27678 [D loss: 0.189162, acc: 97.66%] [G loss: 4.115262]\n",
      "epoch:35 step:27679 [D loss: 0.657022, acc: 63.28%] [G loss: 4.340528]\n",
      "epoch:35 step:27680 [D loss: 0.503899, acc: 78.91%] [G loss: 4.878181]\n",
      "epoch:35 step:27681 [D loss: 0.435422, acc: 74.22%] [G loss: 5.539692]\n",
      "epoch:35 step:27682 [D loss: 0.973120, acc: 48.44%] [G loss: 4.672565]\n",
      "epoch:35 step:27683 [D loss: 1.029980, acc: 32.03%] [G loss: 4.216777]\n",
      "epoch:35 step:27684 [D loss: 0.353787, acc: 81.25%] [G loss: 5.903367]\n",
      "epoch:35 step:27685 [D loss: 0.590331, acc: 64.06%] [G loss: 2.368841]\n",
      "epoch:35 step:27686 [D loss: 0.983647, acc: 50.78%] [G loss: 3.737146]\n",
      "epoch:35 step:27687 [D loss: 0.132840, acc: 98.44%] [G loss: 7.938241]\n",
      "epoch:35 step:27688 [D loss: 0.451958, acc: 68.75%] [G loss: 6.994932]\n",
      "epoch:35 step:27689 [D loss: 1.453484, acc: 5.47%] [G loss: 8.175076]\n",
      "epoch:35 step:27690 [D loss: 0.100935, acc: 98.44%] [G loss: 4.051706]\n",
      "epoch:35 step:27691 [D loss: 0.507815, acc: 72.66%] [G loss: 5.129168]\n",
      "epoch:35 step:27692 [D loss: 0.285938, acc: 90.62%] [G loss: 4.702790]\n",
      "epoch:35 step:27693 [D loss: 0.553628, acc: 59.38%] [G loss: 5.753923]\n",
      "epoch:35 step:27694 [D loss: 0.440404, acc: 67.97%] [G loss: 6.662872]\n",
      "epoch:35 step:27695 [D loss: 0.524802, acc: 73.44%] [G loss: 4.745185]\n",
      "epoch:35 step:27696 [D loss: 0.371990, acc: 86.72%] [G loss: 5.688204]\n",
      "epoch:35 step:27697 [D loss: 0.185727, acc: 99.22%] [G loss: 4.011466]\n",
      "epoch:35 step:27698 [D loss: 0.501071, acc: 63.28%] [G loss: 4.218677]\n",
      "epoch:35 step:27699 [D loss: 0.748758, acc: 54.69%] [G loss: 4.292848]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27700 [D loss: 0.380548, acc: 74.22%] [G loss: 5.083024]\n",
      "epoch:35 step:27701 [D loss: 0.352504, acc: 80.47%] [G loss: 5.522614]\n",
      "epoch:35 step:27702 [D loss: 0.427343, acc: 82.03%] [G loss: 4.277292]\n",
      "epoch:35 step:27703 [D loss: 0.097448, acc: 98.44%] [G loss: 3.262105]\n",
      "epoch:35 step:27704 [D loss: 0.210812, acc: 93.75%] [G loss: 6.063764]\n",
      "epoch:35 step:27705 [D loss: 0.422406, acc: 79.69%] [G loss: 5.300156]\n",
      "epoch:35 step:27706 [D loss: 0.111972, acc: 100.00%] [G loss: 3.663407]\n",
      "epoch:35 step:27707 [D loss: 0.630687, acc: 66.41%] [G loss: 6.545640]\n",
      "epoch:35 step:27708 [D loss: 0.419606, acc: 77.34%] [G loss: 1.439425]\n",
      "epoch:35 step:27709 [D loss: 0.537860, acc: 64.84%] [G loss: 4.988418]\n",
      "epoch:35 step:27710 [D loss: 0.484622, acc: 69.53%] [G loss: 4.849051]\n",
      "epoch:35 step:27711 [D loss: 0.047139, acc: 99.22%] [G loss: 7.383824]\n",
      "epoch:35 step:27712 [D loss: 0.252506, acc: 90.62%] [G loss: 5.104014]\n",
      "epoch:35 step:27713 [D loss: 0.136123, acc: 99.22%] [G loss: 5.618305]\n",
      "epoch:35 step:27714 [D loss: 0.408453, acc: 71.88%] [G loss: 5.414485]\n",
      "epoch:35 step:27715 [D loss: 0.358962, acc: 91.41%] [G loss: 4.128780]\n",
      "epoch:35 step:27716 [D loss: 0.080450, acc: 100.00%] [G loss: 7.018064]\n",
      "epoch:35 step:27717 [D loss: 0.255912, acc: 92.19%] [G loss: 4.706335]\n",
      "epoch:35 step:27718 [D loss: 0.644760, acc: 57.81%] [G loss: 3.268807]\n",
      "epoch:35 step:27719 [D loss: 0.069941, acc: 100.00%] [G loss: 4.682793]\n",
      "epoch:35 step:27720 [D loss: 1.034128, acc: 48.44%] [G loss: 6.027657]\n",
      "epoch:35 step:27721 [D loss: 0.043159, acc: 100.00%] [G loss: 4.068459]\n",
      "epoch:35 step:27722 [D loss: 1.963856, acc: 33.59%] [G loss: 5.420435]\n",
      "epoch:35 step:27723 [D loss: 0.050241, acc: 100.00%] [G loss: 8.807338]\n",
      "epoch:35 step:27724 [D loss: 0.339415, acc: 84.38%] [G loss: 4.775639]\n",
      "epoch:35 step:27725 [D loss: 0.306052, acc: 90.62%] [G loss: 4.447294]\n",
      "epoch:35 step:27726 [D loss: 0.145486, acc: 99.22%] [G loss: 5.673801]\n",
      "epoch:35 step:27727 [D loss: 0.080686, acc: 100.00%] [G loss: 3.324790]\n",
      "epoch:35 step:27728 [D loss: 0.142677, acc: 100.00%] [G loss: 5.034875]\n",
      "epoch:35 step:27729 [D loss: 0.385448, acc: 82.81%] [G loss: 6.110164]\n",
      "epoch:35 step:27730 [D loss: 0.660150, acc: 64.84%] [G loss: 6.210054]\n",
      "epoch:35 step:27731 [D loss: 0.234730, acc: 95.31%] [G loss: 4.118481]\n",
      "epoch:35 step:27732 [D loss: 0.104892, acc: 100.00%] [G loss: 4.426868]\n",
      "epoch:35 step:27733 [D loss: 0.408174, acc: 85.16%] [G loss: 4.037650]\n",
      "epoch:35 step:27734 [D loss: 0.214614, acc: 96.09%] [G loss: 5.664877]\n",
      "epoch:35 step:27735 [D loss: 0.337644, acc: 96.09%] [G loss: 5.751864]\n",
      "epoch:35 step:27736 [D loss: 0.098802, acc: 99.22%] [G loss: 7.348879]\n",
      "epoch:35 step:27737 [D loss: 0.342978, acc: 82.03%] [G loss: 5.364143]\n",
      "epoch:35 step:27738 [D loss: 0.182524, acc: 99.22%] [G loss: 4.252791]\n",
      "epoch:35 step:27739 [D loss: 1.746732, acc: 37.50%] [G loss: 7.505404]\n",
      "epoch:35 step:27740 [D loss: 0.426867, acc: 88.28%] [G loss: 4.116498]\n",
      "epoch:35 step:27741 [D loss: 0.509148, acc: 75.78%] [G loss: 5.881280]\n",
      "epoch:35 step:27742 [D loss: 0.576916, acc: 60.16%] [G loss: 5.204722]\n",
      "epoch:35 step:27743 [D loss: 0.655039, acc: 56.25%] [G loss: 6.565650]\n",
      "epoch:35 step:27744 [D loss: 1.462235, acc: 48.44%] [G loss: 6.530206]\n",
      "epoch:35 step:27745 [D loss: 0.822508, acc: 52.34%] [G loss: 5.153763]\n",
      "epoch:35 step:27746 [D loss: 0.275829, acc: 92.19%] [G loss: 4.069745]\n",
      "epoch:35 step:27747 [D loss: 0.248642, acc: 96.09%] [G loss: 4.631708]\n",
      "epoch:35 step:27748 [D loss: 0.142903, acc: 99.22%] [G loss: 5.300714]\n",
      "epoch:35 step:27749 [D loss: 0.500837, acc: 70.31%] [G loss: 4.986783]\n",
      "epoch:35 step:27750 [D loss: 0.342461, acc: 90.62%] [G loss: 3.553282]\n",
      "epoch:35 step:27751 [D loss: 0.876022, acc: 52.34%] [G loss: 3.795223]\n",
      "epoch:35 step:27752 [D loss: 0.269315, acc: 92.97%] [G loss: 5.019020]\n",
      "epoch:35 step:27753 [D loss: 0.157844, acc: 99.22%] [G loss: 6.589793]\n",
      "epoch:35 step:27754 [D loss: 0.234085, acc: 92.19%] [G loss: 5.806709]\n",
      "epoch:35 step:27755 [D loss: 1.077511, acc: 40.62%] [G loss: 6.328839]\n",
      "epoch:35 step:27756 [D loss: 0.760720, acc: 56.25%] [G loss: 5.204270]\n",
      "epoch:35 step:27757 [D loss: 0.322738, acc: 95.31%] [G loss: 3.334388]\n",
      "epoch:35 step:27758 [D loss: 0.675400, acc: 60.16%] [G loss: 4.676497]\n",
      "epoch:35 step:27759 [D loss: 0.769156, acc: 57.03%] [G loss: 6.844860]\n",
      "epoch:35 step:27760 [D loss: 0.522642, acc: 68.75%] [G loss: 8.468353]\n",
      "epoch:35 step:27761 [D loss: 0.517108, acc: 69.53%] [G loss: 4.740189]\n",
      "epoch:35 step:27762 [D loss: 0.222034, acc: 96.88%] [G loss: 3.193212]\n",
      "epoch:35 step:27763 [D loss: 0.145222, acc: 98.44%] [G loss: 4.178923]\n",
      "epoch:35 step:27764 [D loss: 0.234936, acc: 92.97%] [G loss: 4.363276]\n",
      "epoch:35 step:27765 [D loss: 0.224989, acc: 96.09%] [G loss: 3.296534]\n",
      "epoch:35 step:27766 [D loss: 0.273152, acc: 96.88%] [G loss: 3.536711]\n",
      "epoch:35 step:27767 [D loss: 0.464609, acc: 81.25%] [G loss: 4.995060]\n",
      "epoch:35 step:27768 [D loss: 0.334153, acc: 78.91%] [G loss: 6.073660]\n",
      "epoch:35 step:27769 [D loss: 0.043544, acc: 100.00%] [G loss: 6.802959]\n",
      "epoch:35 step:27770 [D loss: 0.127272, acc: 100.00%] [G loss: 6.731751]\n",
      "epoch:35 step:27771 [D loss: 0.576664, acc: 69.53%] [G loss: 5.434634]\n",
      "epoch:35 step:27772 [D loss: 1.261310, acc: 42.19%] [G loss: 4.940758]\n",
      "epoch:35 step:27773 [D loss: 0.685443, acc: 60.94%] [G loss: 3.005402]\n",
      "epoch:35 step:27774 [D loss: 0.210806, acc: 97.66%] [G loss: 5.279696]\n",
      "epoch:35 step:27775 [D loss: 0.891682, acc: 47.66%] [G loss: 5.043578]\n",
      "epoch:35 step:27776 [D loss: 0.448824, acc: 78.91%] [G loss: 5.638541]\n",
      "epoch:35 step:27777 [D loss: 0.286372, acc: 92.19%] [G loss: 4.002241]\n",
      "epoch:35 step:27778 [D loss: 0.442460, acc: 73.44%] [G loss: 6.158670]\n",
      "epoch:35 step:27779 [D loss: 0.418351, acc: 78.12%] [G loss: 5.573241]\n",
      "epoch:35 step:27780 [D loss: 0.272416, acc: 96.09%] [G loss: 5.131508]\n",
      "epoch:35 step:27781 [D loss: 0.801721, acc: 48.44%] [G loss: 5.435092]\n",
      "epoch:35 step:27782 [D loss: 0.177181, acc: 99.22%] [G loss: 4.979779]\n",
      "epoch:35 step:27783 [D loss: 0.332676, acc: 93.75%] [G loss: 4.425903]\n",
      "epoch:35 step:27784 [D loss: 0.229650, acc: 93.75%] [G loss: 5.447950]\n",
      "epoch:35 step:27785 [D loss: 0.174514, acc: 98.44%] [G loss: 4.833054]\n",
      "epoch:35 step:27786 [D loss: 0.189792, acc: 99.22%] [G loss: 5.353784]\n",
      "epoch:35 step:27787 [D loss: 0.306396, acc: 86.72%] [G loss: 5.778045]\n",
      "epoch:35 step:27788 [D loss: 1.047268, acc: 49.22%] [G loss: 5.397827]\n",
      "epoch:35 step:27789 [D loss: 0.053789, acc: 100.00%] [G loss: 7.144428]\n",
      "epoch:35 step:27790 [D loss: 0.500478, acc: 77.34%] [G loss: 5.009913]\n",
      "epoch:35 step:27791 [D loss: 0.163857, acc: 99.22%] [G loss: 6.192358]\n",
      "epoch:35 step:27792 [D loss: 0.178022, acc: 93.75%] [G loss: 6.272064]\n",
      "epoch:35 step:27793 [D loss: 0.118324, acc: 99.22%] [G loss: 2.926876]\n",
      "epoch:35 step:27794 [D loss: 0.354114, acc: 84.38%] [G loss: 5.383245]\n",
      "epoch:35 step:27795 [D loss: 0.409369, acc: 83.59%] [G loss: 6.389044]\n",
      "epoch:35 step:27796 [D loss: 0.317907, acc: 88.28%] [G loss: 5.672860]\n",
      "epoch:35 step:27797 [D loss: 0.077142, acc: 100.00%] [G loss: 7.201875]\n",
      "epoch:35 step:27798 [D loss: 0.094709, acc: 99.22%] [G loss: 5.792639]\n",
      "epoch:35 step:27799 [D loss: 1.063945, acc: 43.75%] [G loss: 3.840591]\n",
      "epoch:35 step:27800 [D loss: 0.284960, acc: 91.41%] [G loss: 4.993176]\n",
      "epoch:35 step:27801 [D loss: 0.026095, acc: 100.00%] [G loss: 7.362119]\n",
      "epoch:35 step:27802 [D loss: 0.222430, acc: 100.00%] [G loss: 6.053650]\n",
      "epoch:35 step:27803 [D loss: 0.476419, acc: 62.50%] [G loss: 5.297870]\n",
      "epoch:35 step:27804 [D loss: 0.070872, acc: 100.00%] [G loss: 3.848182]\n",
      "epoch:35 step:27805 [D loss: 0.782063, acc: 57.03%] [G loss: 7.086195]\n",
      "epoch:35 step:27806 [D loss: 0.272542, acc: 92.19%] [G loss: 3.579089]\n",
      "epoch:35 step:27807 [D loss: 0.580384, acc: 62.50%] [G loss: 5.187734]\n",
      "epoch:35 step:27808 [D loss: 1.278612, acc: 16.41%] [G loss: 5.850023]\n",
      "epoch:35 step:27809 [D loss: 0.264354, acc: 90.62%] [G loss: 3.089246]\n",
      "epoch:35 step:27810 [D loss: 0.679210, acc: 56.25%] [G loss: 3.083485]\n",
      "epoch:35 step:27811 [D loss: 0.477194, acc: 68.75%] [G loss: 5.137735]\n",
      "epoch:35 step:27812 [D loss: 0.889838, acc: 50.78%] [G loss: 5.163494]\n",
      "epoch:35 step:27813 [D loss: 0.125758, acc: 100.00%] [G loss: 5.165174]\n",
      "epoch:35 step:27814 [D loss: 0.201983, acc: 96.09%] [G loss: 2.427112]\n",
      "epoch:35 step:27815 [D loss: 0.495831, acc: 75.00%] [G loss: 5.757346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27816 [D loss: 0.142484, acc: 99.22%] [G loss: 5.318274]\n",
      "epoch:35 step:27817 [D loss: 0.563918, acc: 64.84%] [G loss: 3.627665]\n",
      "epoch:35 step:27818 [D loss: 0.190462, acc: 98.44%] [G loss: 3.456079]\n",
      "epoch:35 step:27819 [D loss: 0.295816, acc: 96.88%] [G loss: 5.113493]\n",
      "epoch:35 step:27820 [D loss: 0.424804, acc: 84.38%] [G loss: 4.047307]\n",
      "epoch:35 step:27821 [D loss: 0.530401, acc: 62.50%] [G loss: 6.095068]\n",
      "epoch:35 step:27822 [D loss: 0.423344, acc: 82.03%] [G loss: 3.859706]\n",
      "epoch:35 step:27823 [D loss: 0.668825, acc: 54.69%] [G loss: 5.778514]\n",
      "epoch:35 step:27824 [D loss: 0.120804, acc: 100.00%] [G loss: 4.687962]\n",
      "epoch:35 step:27825 [D loss: 0.028160, acc: 100.00%] [G loss: 7.662059]\n",
      "epoch:35 step:27826 [D loss: 0.980548, acc: 52.34%] [G loss: 6.190782]\n",
      "epoch:35 step:27827 [D loss: 0.123400, acc: 99.22%] [G loss: 6.717109]\n",
      "epoch:35 step:27828 [D loss: 0.397232, acc: 85.16%] [G loss: 6.464142]\n",
      "epoch:35 step:27829 [D loss: 0.091366, acc: 99.22%] [G loss: 5.486551]\n",
      "epoch:35 step:27830 [D loss: 0.433200, acc: 73.44%] [G loss: 6.583776]\n",
      "epoch:35 step:27831 [D loss: 0.666039, acc: 54.69%] [G loss: 3.296252]\n",
      "epoch:35 step:27832 [D loss: 0.075089, acc: 99.22%] [G loss: 7.029787]\n",
      "epoch:35 step:27833 [D loss: 0.080769, acc: 100.00%] [G loss: 2.410355]\n",
      "epoch:35 step:27834 [D loss: 0.464424, acc: 82.81%] [G loss: 3.306189]\n",
      "epoch:35 step:27835 [D loss: 0.327732, acc: 87.50%] [G loss: 6.193258]\n",
      "epoch:35 step:27836 [D loss: 0.742493, acc: 57.03%] [G loss: 6.433779]\n",
      "epoch:35 step:27837 [D loss: 0.702245, acc: 57.03%] [G loss: 5.325043]\n",
      "epoch:35 step:27838 [D loss: 0.854543, acc: 54.69%] [G loss: 5.945111]\n",
      "epoch:35 step:27839 [D loss: 0.207464, acc: 96.88%] [G loss: 4.333858]\n",
      "epoch:35 step:27840 [D loss: 0.651160, acc: 57.03%] [G loss: 5.488924]\n",
      "epoch:35 step:27841 [D loss: 0.667225, acc: 57.81%] [G loss: 3.064546]\n",
      "epoch:35 step:27842 [D loss: 0.286781, acc: 91.41%] [G loss: 4.537738]\n",
      "epoch:35 step:27843 [D loss: 0.531530, acc: 66.41%] [G loss: 3.349976]\n",
      "epoch:35 step:27844 [D loss: 0.122383, acc: 99.22%] [G loss: 3.690832]\n",
      "epoch:35 step:27845 [D loss: 0.277224, acc: 95.31%] [G loss: 4.741191]\n",
      "epoch:35 step:27846 [D loss: 0.054196, acc: 100.00%] [G loss: 7.952355]\n",
      "epoch:35 step:27847 [D loss: 0.127942, acc: 99.22%] [G loss: 4.980380]\n",
      "epoch:35 step:27848 [D loss: 0.129957, acc: 100.00%] [G loss: 3.728765]\n",
      "epoch:35 step:27849 [D loss: 0.558039, acc: 69.53%] [G loss: 5.478998]\n",
      "epoch:35 step:27850 [D loss: 1.024640, acc: 50.78%] [G loss: 3.864967]\n",
      "epoch:35 step:27851 [D loss: 0.392784, acc: 85.16%] [G loss: 4.377778]\n",
      "epoch:35 step:27852 [D loss: 0.111607, acc: 99.22%] [G loss: 5.021997]\n",
      "epoch:35 step:27853 [D loss: 0.525386, acc: 64.84%] [G loss: 6.354131]\n",
      "epoch:35 step:27854 [D loss: 0.457321, acc: 75.00%] [G loss: 6.657477]\n",
      "epoch:35 step:27855 [D loss: 0.254309, acc: 90.62%] [G loss: 4.979596]\n",
      "epoch:35 step:27856 [D loss: 0.786438, acc: 53.12%] [G loss: 2.923562]\n",
      "epoch:35 step:27857 [D loss: 0.725299, acc: 57.03%] [G loss: 6.108719]\n",
      "epoch:35 step:27858 [D loss: 0.662994, acc: 57.81%] [G loss: 7.423193]\n",
      "epoch:35 step:27859 [D loss: 0.034697, acc: 100.00%] [G loss: 4.245276]\n",
      "epoch:35 step:27860 [D loss: 0.263154, acc: 96.88%] [G loss: 4.347039]\n",
      "epoch:35 step:27861 [D loss: 0.694127, acc: 62.50%] [G loss: 3.236563]\n",
      "epoch:35 step:27862 [D loss: 0.141433, acc: 100.00%] [G loss: 4.798176]\n",
      "epoch:35 step:27863 [D loss: 0.069878, acc: 100.00%] [G loss: 5.744792]\n",
      "epoch:35 step:27864 [D loss: 1.119022, acc: 50.00%] [G loss: 4.850086]\n",
      "epoch:35 step:27865 [D loss: 0.347040, acc: 83.59%] [G loss: 4.417041]\n",
      "epoch:35 step:27866 [D loss: 0.040914, acc: 100.00%] [G loss: 4.158751]\n",
      "epoch:35 step:27867 [D loss: 0.159800, acc: 99.22%] [G loss: 4.358398]\n",
      "epoch:35 step:27868 [D loss: 0.365509, acc: 85.94%] [G loss: 5.737474]\n",
      "epoch:35 step:27869 [D loss: 0.300984, acc: 96.09%] [G loss: 6.311425]\n",
      "epoch:35 step:27870 [D loss: 1.292120, acc: 8.59%] [G loss: 6.011993]\n",
      "epoch:35 step:27871 [D loss: 0.186015, acc: 97.66%] [G loss: 7.577877]\n",
      "epoch:35 step:27872 [D loss: 0.044648, acc: 100.00%] [G loss: 7.584551]\n",
      "epoch:35 step:27873 [D loss: 0.650932, acc: 64.06%] [G loss: 6.036558]\n",
      "epoch:35 step:27874 [D loss: 0.349727, acc: 76.56%] [G loss: 3.618388]\n",
      "epoch:35 step:27875 [D loss: 1.023176, acc: 47.66%] [G loss: 6.578544]\n",
      "epoch:35 step:27876 [D loss: 0.160954, acc: 98.44%] [G loss: 4.012306]\n",
      "epoch:35 step:27877 [D loss: 0.901962, acc: 52.34%] [G loss: 3.514111]\n",
      "epoch:35 step:27878 [D loss: 0.314038, acc: 82.03%] [G loss: 3.651021]\n",
      "epoch:35 step:27879 [D loss: 0.471540, acc: 82.81%] [G loss: 6.321409]\n",
      "epoch:35 step:27880 [D loss: 1.115345, acc: 50.00%] [G loss: 4.721923]\n",
      "epoch:35 step:27881 [D loss: 0.198355, acc: 96.09%] [G loss: 6.033296]\n",
      "epoch:35 step:27882 [D loss: 0.465970, acc: 73.44%] [G loss: 6.008116]\n",
      "epoch:35 step:27883 [D loss: 0.284897, acc: 99.22%] [G loss: 4.785871]\n",
      "epoch:35 step:27884 [D loss: 0.214584, acc: 97.66%] [G loss: 2.996738]\n",
      "epoch:35 step:27885 [D loss: 0.160961, acc: 97.66%] [G loss: 4.200170]\n",
      "epoch:35 step:27886 [D loss: 0.080240, acc: 99.22%] [G loss: 4.929781]\n",
      "epoch:35 step:27887 [D loss: 0.432913, acc: 78.91%] [G loss: 5.720523]\n",
      "epoch:35 step:27888 [D loss: 0.603883, acc: 60.94%] [G loss: 3.426409]\n",
      "epoch:35 step:27889 [D loss: 0.445778, acc: 78.12%] [G loss: 6.179217]\n",
      "epoch:35 step:27890 [D loss: 0.059057, acc: 100.00%] [G loss: 5.349563]\n",
      "epoch:35 step:27891 [D loss: 0.605538, acc: 62.50%] [G loss: 6.766960]\n",
      "epoch:35 step:27892 [D loss: 1.440971, acc: 18.75%] [G loss: 6.001036]\n",
      "epoch:35 step:27893 [D loss: 0.123223, acc: 97.66%] [G loss: 5.027133]\n",
      "epoch:35 step:27894 [D loss: 0.185837, acc: 99.22%] [G loss: 5.834382]\n",
      "epoch:35 step:27895 [D loss: 0.138708, acc: 99.22%] [G loss: 6.526194]\n",
      "epoch:35 step:27896 [D loss: 0.203057, acc: 98.44%] [G loss: 5.545108]\n",
      "epoch:35 step:27897 [D loss: 0.127267, acc: 100.00%] [G loss: 6.171738]\n",
      "epoch:35 step:27898 [D loss: 0.285874, acc: 96.88%] [G loss: 5.697749]\n",
      "epoch:35 step:27899 [D loss: 0.062720, acc: 100.00%] [G loss: 3.694232]\n",
      "epoch:35 step:27900 [D loss: 1.859449, acc: 7.03%] [G loss: 7.788073]\n",
      "epoch:35 step:27901 [D loss: 0.636110, acc: 59.38%] [G loss: 7.417494]\n",
      "epoch:35 step:27902 [D loss: 0.167962, acc: 98.44%] [G loss: 4.482152]\n",
      "epoch:35 step:27903 [D loss: 0.376686, acc: 78.12%] [G loss: 4.920583]\n",
      "epoch:35 step:27904 [D loss: 0.393478, acc: 75.00%] [G loss: 6.433325]\n",
      "epoch:35 step:27905 [D loss: 0.302236, acc: 87.50%] [G loss: 5.001143]\n",
      "epoch:35 step:27906 [D loss: 0.513409, acc: 62.50%] [G loss: 8.741961]\n",
      "epoch:35 step:27907 [D loss: 0.784096, acc: 53.91%] [G loss: 4.397417]\n",
      "epoch:35 step:27908 [D loss: 0.320035, acc: 85.16%] [G loss: 3.888046]\n",
      "epoch:35 step:27909 [D loss: 0.482430, acc: 81.25%] [G loss: 4.910215]\n",
      "epoch:35 step:27910 [D loss: 0.303807, acc: 86.72%] [G loss: 3.076572]\n",
      "epoch:35 step:27911 [D loss: 0.108210, acc: 98.44%] [G loss: 3.598505]\n",
      "epoch:35 step:27912 [D loss: 1.183556, acc: 24.22%] [G loss: 7.825482]\n",
      "epoch:35 step:27913 [D loss: 0.157753, acc: 99.22%] [G loss: 6.248003]\n",
      "epoch:35 step:27914 [D loss: 0.670431, acc: 59.38%] [G loss: 5.188085]\n",
      "epoch:35 step:27915 [D loss: 0.492768, acc: 65.62%] [G loss: 5.585063]\n",
      "epoch:35 step:27916 [D loss: 0.509774, acc: 68.75%] [G loss: 8.775658]\n",
      "epoch:35 step:27917 [D loss: 0.411648, acc: 85.94%] [G loss: 3.965445]\n",
      "epoch:35 step:27918 [D loss: 0.542890, acc: 64.84%] [G loss: 7.608612]\n",
      "epoch:35 step:27919 [D loss: 0.493830, acc: 83.59%] [G loss: 5.062612]\n",
      "epoch:35 step:27920 [D loss: 1.187122, acc: 50.00%] [G loss: 4.286856]\n",
      "epoch:35 step:27921 [D loss: 0.295185, acc: 96.88%] [G loss: 2.291160]\n",
      "epoch:35 step:27922 [D loss: 0.156867, acc: 97.66%] [G loss: 3.259460]\n",
      "epoch:35 step:27923 [D loss: 0.540363, acc: 66.41%] [G loss: 6.641171]\n",
      "epoch:35 step:27924 [D loss: 0.391580, acc: 78.12%] [G loss: 3.166340]\n",
      "epoch:35 step:27925 [D loss: 0.114143, acc: 99.22%] [G loss: 3.765744]\n",
      "epoch:35 step:27926 [D loss: 0.381974, acc: 86.72%] [G loss: 3.649854]\n",
      "epoch:35 step:27927 [D loss: 0.282166, acc: 91.41%] [G loss: 5.820297]\n",
      "epoch:35 step:27928 [D loss: 0.703975, acc: 53.12%] [G loss: 3.095892]\n",
      "epoch:35 step:27929 [D loss: 0.535201, acc: 66.41%] [G loss: 3.842955]\n",
      "epoch:35 step:27930 [D loss: 0.507056, acc: 71.09%] [G loss: 4.307218]\n",
      "epoch:35 step:27931 [D loss: 0.232882, acc: 93.75%] [G loss: 4.500897]\n",
      "epoch:35 step:27932 [D loss: 0.721846, acc: 53.91%] [G loss: 5.886971]\n",
      "epoch:35 step:27933 [D loss: 1.270125, acc: 25.78%] [G loss: 6.631033]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27934 [D loss: 0.327455, acc: 91.41%] [G loss: 3.025411]\n",
      "epoch:35 step:27935 [D loss: 2.012646, acc: 14.84%] [G loss: 3.098896]\n",
      "epoch:35 step:27936 [D loss: 0.255344, acc: 90.62%] [G loss: 3.701112]\n",
      "epoch:35 step:27937 [D loss: 0.216917, acc: 99.22%] [G loss: 4.349043]\n",
      "epoch:35 step:27938 [D loss: 0.089545, acc: 99.22%] [G loss: 3.712611]\n",
      "epoch:35 step:27939 [D loss: 0.614385, acc: 67.19%] [G loss: 2.674517]\n",
      "epoch:35 step:27940 [D loss: 0.144619, acc: 100.00%] [G loss: 5.350184]\n",
      "epoch:35 step:27941 [D loss: 0.546568, acc: 71.09%] [G loss: 4.617567]\n",
      "epoch:35 step:27942 [D loss: 0.721790, acc: 57.03%] [G loss: 4.410854]\n",
      "epoch:35 step:27943 [D loss: 0.541490, acc: 74.22%] [G loss: 3.454415]\n",
      "epoch:35 step:27944 [D loss: 0.585070, acc: 67.97%] [G loss: 7.980620]\n",
      "epoch:35 step:27945 [D loss: 0.248885, acc: 96.09%] [G loss: 3.483602]\n",
      "epoch:35 step:27946 [D loss: 0.156139, acc: 99.22%] [G loss: 4.638415]\n",
      "epoch:35 step:27947 [D loss: 0.245335, acc: 97.66%] [G loss: 3.283554]\n",
      "epoch:35 step:27948 [D loss: 0.497674, acc: 67.19%] [G loss: 4.419904]\n",
      "epoch:35 step:27949 [D loss: 0.681863, acc: 58.59%] [G loss: 7.082346]\n",
      "epoch:35 step:27950 [D loss: 0.528698, acc: 71.09%] [G loss: 4.043445]\n",
      "epoch:35 step:27951 [D loss: 1.092421, acc: 19.53%] [G loss: 4.321405]\n",
      "epoch:35 step:27952 [D loss: 0.277319, acc: 89.84%] [G loss: 3.261196]\n",
      "epoch:35 step:27953 [D loss: 0.407560, acc: 86.72%] [G loss: 3.601285]\n",
      "epoch:35 step:27954 [D loss: 0.117142, acc: 100.00%] [G loss: 3.247891]\n",
      "epoch:35 step:27955 [D loss: 0.331592, acc: 90.62%] [G loss: 5.264467]\n",
      "epoch:35 step:27956 [D loss: 0.256993, acc: 97.66%] [G loss: 3.806818]\n",
      "epoch:35 step:27957 [D loss: 0.317364, acc: 89.06%] [G loss: 4.845083]\n",
      "epoch:35 step:27958 [D loss: 0.572432, acc: 71.09%] [G loss: 5.246137]\n",
      "epoch:35 step:27959 [D loss: 0.196270, acc: 98.44%] [G loss: 4.563558]\n",
      "epoch:35 step:27960 [D loss: 0.606401, acc: 64.06%] [G loss: 6.185458]\n",
      "epoch:35 step:27961 [D loss: 0.148966, acc: 100.00%] [G loss: 4.319706]\n",
      "epoch:35 step:27962 [D loss: 0.760087, acc: 51.56%] [G loss: 4.709680]\n",
      "epoch:35 step:27963 [D loss: 0.166249, acc: 96.09%] [G loss: 4.288308]\n",
      "epoch:35 step:27964 [D loss: 0.057699, acc: 100.00%] [G loss: 2.318167]\n",
      "epoch:35 step:27965 [D loss: 0.152777, acc: 97.66%] [G loss: 4.586335]\n",
      "epoch:35 step:27966 [D loss: 0.198191, acc: 98.44%] [G loss: 4.068542]\n",
      "epoch:35 step:27967 [D loss: 0.261691, acc: 87.50%] [G loss: 6.081728]\n",
      "epoch:35 step:27968 [D loss: 0.273869, acc: 95.31%] [G loss: 5.726318]\n",
      "epoch:35 step:27969 [D loss: 0.200616, acc: 100.00%] [G loss: 2.348984]\n",
      "epoch:35 step:27970 [D loss: 0.589401, acc: 61.72%] [G loss: 3.476778]\n",
      "epoch:35 step:27971 [D loss: 0.312309, acc: 84.38%] [G loss: 6.883230]\n",
      "epoch:35 step:27972 [D loss: 0.426834, acc: 75.00%] [G loss: 4.194952]\n",
      "epoch:35 step:27973 [D loss: 0.566515, acc: 71.09%] [G loss: 5.504390]\n",
      "epoch:35 step:27974 [D loss: 0.919918, acc: 46.88%] [G loss: 6.088659]\n",
      "epoch:35 step:27975 [D loss: 0.301238, acc: 96.09%] [G loss: 5.145312]\n",
      "epoch:35 step:27976 [D loss: 0.246906, acc: 94.53%] [G loss: 5.940736]\n",
      "epoch:35 step:27977 [D loss: 0.282675, acc: 93.75%] [G loss: 4.053033]\n",
      "epoch:35 step:27978 [D loss: 0.137681, acc: 100.00%] [G loss: 4.533991]\n",
      "epoch:35 step:27979 [D loss: 0.452649, acc: 82.81%] [G loss: 3.325865]\n",
      "epoch:35 step:27980 [D loss: 0.162577, acc: 99.22%] [G loss: 6.238322]\n",
      "epoch:35 step:27981 [D loss: 0.554187, acc: 66.41%] [G loss: 5.827292]\n",
      "epoch:35 step:27982 [D loss: 0.290075, acc: 94.53%] [G loss: 4.685017]\n",
      "epoch:35 step:27983 [D loss: 0.239054, acc: 92.97%] [G loss: 4.469161]\n",
      "epoch:35 step:27984 [D loss: 0.650941, acc: 64.06%] [G loss: 5.685637]\n",
      "epoch:35 step:27985 [D loss: 0.837297, acc: 51.56%] [G loss: 7.248955]\n",
      "epoch:35 step:27986 [D loss: 0.176620, acc: 100.00%] [G loss: 3.808399]\n",
      "epoch:35 step:27987 [D loss: 0.237599, acc: 96.88%] [G loss: 4.675260]\n",
      "epoch:35 step:27988 [D loss: 0.058396, acc: 100.00%] [G loss: 5.020199]\n",
      "epoch:35 step:27989 [D loss: 0.720566, acc: 54.69%] [G loss: 4.163903]\n",
      "epoch:35 step:27990 [D loss: 0.064906, acc: 100.00%] [G loss: 6.069088]\n",
      "epoch:35 step:27991 [D loss: 1.132570, acc: 39.06%] [G loss: 11.229588]\n",
      "epoch:35 step:27992 [D loss: 1.377974, acc: 6.25%] [G loss: 6.982263]\n",
      "epoch:35 step:27993 [D loss: 0.302774, acc: 92.19%] [G loss: 4.548480]\n",
      "epoch:35 step:27994 [D loss: 0.062833, acc: 100.00%] [G loss: 4.934329]\n",
      "epoch:35 step:27995 [D loss: 0.452690, acc: 80.47%] [G loss: 4.084001]\n",
      "epoch:35 step:27996 [D loss: 0.098377, acc: 98.44%] [G loss: 3.102125]\n",
      "epoch:35 step:27997 [D loss: 1.787263, acc: 20.31%] [G loss: 6.924341]\n",
      "epoch:35 step:27998 [D loss: 0.212013, acc: 99.22%] [G loss: 5.527701]\n",
      "epoch:35 step:27999 [D loss: 0.120240, acc: 98.44%] [G loss: 6.948764]\n",
      "epoch:35 step:28000 [D loss: 0.109046, acc: 100.00%] [G loss: 4.265417]\n",
      "epoch:35 step:28001 [D loss: 0.290356, acc: 91.41%] [G loss: 8.610378]\n",
      "epoch:35 step:28002 [D loss: 0.162179, acc: 98.44%] [G loss: 6.778936]\n",
      "epoch:35 step:28003 [D loss: 1.190725, acc: 50.78%] [G loss: 4.822083]\n",
      "epoch:35 step:28004 [D loss: 0.392857, acc: 81.25%] [G loss: 4.727928]\n",
      "epoch:35 step:28005 [D loss: 0.285739, acc: 92.97%] [G loss: 2.485765]\n",
      "epoch:35 step:28006 [D loss: 0.816686, acc: 52.34%] [G loss: 8.109549]\n",
      "epoch:35 step:28007 [D loss: 0.581791, acc: 60.94%] [G loss: 4.754054]\n",
      "epoch:35 step:28008 [D loss: 0.226725, acc: 97.66%] [G loss: 5.243093]\n",
      "epoch:35 step:28009 [D loss: 1.101615, acc: 46.88%] [G loss: 3.661517]\n",
      "epoch:35 step:28010 [D loss: 0.554397, acc: 59.38%] [G loss: 4.283093]\n",
      "epoch:35 step:28011 [D loss: 0.042148, acc: 100.00%] [G loss: 9.035888]\n",
      "epoch:35 step:28012 [D loss: 1.000399, acc: 35.16%] [G loss: 4.142281]\n",
      "epoch:35 step:28013 [D loss: 0.452729, acc: 68.75%] [G loss: 7.296307]\n",
      "epoch:35 step:28014 [D loss: 0.665341, acc: 57.81%] [G loss: 6.796054]\n",
      "epoch:35 step:28015 [D loss: 0.344575, acc: 80.47%] [G loss: 5.846560]\n",
      "epoch:35 step:28016 [D loss: 0.124285, acc: 100.00%] [G loss: 6.127849]\n",
      "epoch:35 step:28017 [D loss: 0.297980, acc: 92.97%] [G loss: 5.751030]\n",
      "epoch:35 step:28018 [D loss: 0.278172, acc: 93.75%] [G loss: 4.055136]\n",
      "epoch:35 step:28019 [D loss: 0.228774, acc: 96.88%] [G loss: 2.277118]\n",
      "epoch:35 step:28020 [D loss: 0.920081, acc: 34.38%] [G loss: 1.605532]\n",
      "epoch:35 step:28021 [D loss: 0.435686, acc: 78.12%] [G loss: 5.287973]\n",
      "epoch:35 step:28022 [D loss: 0.838015, acc: 53.12%] [G loss: 6.519494]\n",
      "epoch:35 step:28023 [D loss: 0.252057, acc: 92.97%] [G loss: 4.748381]\n",
      "epoch:35 step:28024 [D loss: 0.268508, acc: 96.09%] [G loss: 3.727026]\n",
      "epoch:35 step:28025 [D loss: 0.160076, acc: 99.22%] [G loss: 5.607199]\n",
      "epoch:35 step:28026 [D loss: 0.160668, acc: 100.00%] [G loss: 3.330325]\n",
      "epoch:35 step:28027 [D loss: 0.856072, acc: 49.22%] [G loss: 7.779954]\n",
      "epoch:35 step:28028 [D loss: 0.577393, acc: 59.38%] [G loss: 4.526353]\n",
      "epoch:35 step:28029 [D loss: 0.712548, acc: 55.47%] [G loss: 6.091818]\n",
      "epoch:35 step:28030 [D loss: 0.459438, acc: 70.31%] [G loss: 7.784189]\n",
      "epoch:35 step:28031 [D loss: 0.057616, acc: 100.00%] [G loss: 7.158017]\n",
      "epoch:35 step:28032 [D loss: 0.059684, acc: 100.00%] [G loss: 5.319627]\n",
      "epoch:35 step:28033 [D loss: 0.357663, acc: 90.62%] [G loss: 3.672487]\n",
      "epoch:35 step:28034 [D loss: 0.257056, acc: 88.28%] [G loss: 3.842607]\n",
      "epoch:35 step:28035 [D loss: 0.131915, acc: 99.22%] [G loss: 5.737803]\n",
      "epoch:35 step:28036 [D loss: 0.296168, acc: 95.31%] [G loss: 2.291582]\n",
      "epoch:35 step:28037 [D loss: 0.346800, acc: 92.19%] [G loss: 4.199540]\n",
      "epoch:35 step:28038 [D loss: 0.278174, acc: 95.31%] [G loss: 2.400359]\n",
      "epoch:35 step:28039 [D loss: 0.190794, acc: 97.66%] [G loss: 4.184941]\n",
      "epoch:35 step:28040 [D loss: 1.814153, acc: 3.91%] [G loss: 7.063583]\n",
      "epoch:35 step:28041 [D loss: 0.138036, acc: 99.22%] [G loss: 4.755164]\n",
      "epoch:35 step:28042 [D loss: 0.053900, acc: 100.00%] [G loss: 4.835528]\n",
      "epoch:35 step:28043 [D loss: 0.071968, acc: 100.00%] [G loss: 5.066845]\n",
      "epoch:35 step:28044 [D loss: 0.170647, acc: 99.22%] [G loss: 3.284149]\n",
      "epoch:35 step:28045 [D loss: 0.484756, acc: 82.81%] [G loss: 4.617455]\n",
      "epoch:35 step:28046 [D loss: 0.387077, acc: 73.44%] [G loss: 7.205842]\n",
      "epoch:35 step:28047 [D loss: 0.484554, acc: 79.69%] [G loss: 3.693534]\n",
      "epoch:35 step:28048 [D loss: 0.051648, acc: 100.00%] [G loss: 9.546307]\n",
      "epoch:35 step:28049 [D loss: 1.012276, acc: 50.00%] [G loss: 4.684741]\n",
      "epoch:35 step:28050 [D loss: 0.499755, acc: 67.97%] [G loss: 5.047631]\n",
      "epoch:35 step:28051 [D loss: 0.377878, acc: 88.28%] [G loss: 2.890026]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:28052 [D loss: 0.107370, acc: 99.22%] [G loss: 4.254545]\n",
      "epoch:35 step:28053 [D loss: 0.245099, acc: 92.19%] [G loss: 2.844197]\n",
      "epoch:35 step:28054 [D loss: 1.048536, acc: 26.56%] [G loss: 4.999653]\n",
      "epoch:35 step:28055 [D loss: 0.732735, acc: 55.47%] [G loss: 4.441881]\n",
      "epoch:35 step:28056 [D loss: 0.563214, acc: 58.59%] [G loss: 7.051015]\n",
      "epoch:35 step:28057 [D loss: 0.476750, acc: 68.75%] [G loss: 5.968477]\n",
      "epoch:35 step:28058 [D loss: 0.062895, acc: 100.00%] [G loss: 4.782811]\n",
      "epoch:35 step:28059 [D loss: 0.292955, acc: 85.94%] [G loss: 5.402746]\n",
      "epoch:35 step:28060 [D loss: 0.573519, acc: 68.75%] [G loss: 7.079628]\n",
      "epoch:35 step:28061 [D loss: 0.111972, acc: 100.00%] [G loss: 5.148394]\n",
      "epoch:35 step:28062 [D loss: 0.104172, acc: 100.00%] [G loss: 4.763788]\n",
      "epoch:35 step:28063 [D loss: 0.296617, acc: 90.62%] [G loss: 2.850815]\n",
      "epoch:35 step:28064 [D loss: 0.477598, acc: 78.91%] [G loss: 4.711982]\n",
      "epoch:35 step:28065 [D loss: 0.166188, acc: 100.00%] [G loss: 3.576828]\n",
      "epoch:35 step:28066 [D loss: 0.190876, acc: 98.44%] [G loss: 6.023547]\n",
      "epoch:35 step:28067 [D loss: 0.596754, acc: 71.09%] [G loss: 3.437133]\n",
      "epoch:35 step:28068 [D loss: 0.630123, acc: 66.41%] [G loss: 6.240911]\n",
      "epoch:35 step:28069 [D loss: 0.342937, acc: 82.81%] [G loss: 4.591621]\n",
      "epoch:35 step:28070 [D loss: 0.150107, acc: 100.00%] [G loss: 5.137892]\n",
      "epoch:35 step:28071 [D loss: 0.684671, acc: 55.47%] [G loss: 4.695395]\n",
      "epoch:35 step:28072 [D loss: 0.154355, acc: 96.09%] [G loss: 5.882896]\n",
      "epoch:35 step:28073 [D loss: 0.398700, acc: 75.78%] [G loss: 5.956981]\n",
      "epoch:35 step:28074 [D loss: 0.695160, acc: 60.94%] [G loss: 4.994405]\n",
      "epoch:35 step:28075 [D loss: 0.480548, acc: 76.56%] [G loss: 6.181416]\n",
      "epoch:35 step:28076 [D loss: 0.179988, acc: 95.31%] [G loss: 4.564466]\n",
      "epoch:35 step:28077 [D loss: 0.095548, acc: 99.22%] [G loss: 3.792541]\n",
      "epoch:35 step:28078 [D loss: 0.800921, acc: 41.41%] [G loss: 4.923608]\n",
      "epoch:35 step:28079 [D loss: 0.623101, acc: 59.38%] [G loss: 5.392290]\n",
      "epoch:35 step:28080 [D loss: 0.105798, acc: 99.22%] [G loss: 2.506227]\n",
      "epoch:35 step:28081 [D loss: 1.077526, acc: 52.34%] [G loss: 6.651431]\n",
      "epoch:35 step:28082 [D loss: 1.162077, acc: 50.78%] [G loss: 5.124382]\n",
      "epoch:35 step:28083 [D loss: 0.088807, acc: 100.00%] [G loss: 4.725263]\n",
      "epoch:35 step:28084 [D loss: 0.389960, acc: 80.47%] [G loss: 5.412841]\n",
      "epoch:35 step:28085 [D loss: 0.664160, acc: 55.47%] [G loss: 4.059080]\n",
      "epoch:35 step:28086 [D loss: 1.842038, acc: 44.53%] [G loss: 3.714411]\n",
      "epoch:35 step:28087 [D loss: 0.035004, acc: 100.00%] [G loss: 2.536032]\n",
      "epoch:35 step:28088 [D loss: 0.039064, acc: 100.00%] [G loss: 4.965485]\n",
      "epoch:35 step:28089 [D loss: 0.966398, acc: 50.00%] [G loss: 5.136067]\n",
      "epoch:35 step:28090 [D loss: 0.470725, acc: 64.84%] [G loss: 6.643668]\n",
      "epoch:35 step:28091 [D loss: 0.669871, acc: 55.47%] [G loss: 5.636613]\n",
      "epoch:35 step:28092 [D loss: 1.973093, acc: 47.66%] [G loss: 4.148154]\n",
      "epoch:35 step:28093 [D loss: 0.135912, acc: 98.44%] [G loss: 4.423362]\n",
      "epoch:35 step:28094 [D loss: 0.210244, acc: 97.66%] [G loss: 3.382100]\n",
      "epoch:35 step:28095 [D loss: 0.018729, acc: 100.00%] [G loss: 6.831136]\n",
      "epoch:35 step:28096 [D loss: 1.098327, acc: 25.78%] [G loss: 7.328635]\n",
      "epoch:35 step:28097 [D loss: 0.116820, acc: 99.22%] [G loss: 5.151375]\n",
      "epoch:35 step:28098 [D loss: 0.303270, acc: 88.28%] [G loss: 4.112697]\n",
      "epoch:35 step:28099 [D loss: 0.166064, acc: 98.44%] [G loss: 5.613692]\n",
      "epoch:35 step:28100 [D loss: 0.050853, acc: 100.00%] [G loss: 5.363622]\n",
      "epoch:35 step:28101 [D loss: 0.465564, acc: 76.56%] [G loss: 3.561862]\n",
      "epoch:35 step:28102 [D loss: 0.379601, acc: 83.59%] [G loss: 6.267940]\n",
      "epoch:35 step:28103 [D loss: 0.515685, acc: 64.84%] [G loss: 7.040895]\n",
      "epoch:35 step:28104 [D loss: 0.411232, acc: 89.84%] [G loss: 4.200667]\n",
      "epoch:35 step:28105 [D loss: 0.264746, acc: 96.88%] [G loss: 4.830675]\n",
      "epoch:35 step:28106 [D loss: 0.521209, acc: 73.44%] [G loss: 4.383282]\n",
      "epoch:35 step:28107 [D loss: 0.230386, acc: 95.31%] [G loss: 5.749647]\n",
      "epoch:35 step:28108 [D loss: 0.060920, acc: 100.00%] [G loss: 6.567185]\n",
      "epoch:35 step:28109 [D loss: 0.329555, acc: 84.38%] [G loss: 6.946340]\n",
      "epoch:35 step:28110 [D loss: 0.069153, acc: 100.00%] [G loss: 4.560323]\n",
      "epoch:35 step:28111 [D loss: 0.179391, acc: 99.22%] [G loss: 1.732733]\n",
      "epoch:35 step:28112 [D loss: 0.474163, acc: 83.59%] [G loss: 5.824665]\n",
      "epoch:35 step:28113 [D loss: 0.176926, acc: 100.00%] [G loss: 3.490494]\n",
      "epoch:35 step:28114 [D loss: 0.171762, acc: 97.66%] [G loss: 7.207438]\n",
      "epoch:35 step:28115 [D loss: 0.261889, acc: 89.84%] [G loss: 5.691638]\n",
      "epoch:35 step:28116 [D loss: 0.163809, acc: 99.22%] [G loss: 3.509984]\n",
      "epoch:36 step:28117 [D loss: 0.278968, acc: 93.75%] [G loss: 4.973672]\n",
      "epoch:36 step:28118 [D loss: 0.276104, acc: 87.50%] [G loss: 6.120681]\n",
      "epoch:36 step:28119 [D loss: 1.365662, acc: 14.84%] [G loss: 5.416096]\n",
      "epoch:36 step:28120 [D loss: 0.096245, acc: 100.00%] [G loss: 5.749921]\n",
      "epoch:36 step:28121 [D loss: 0.199531, acc: 95.31%] [G loss: 4.198349]\n",
      "epoch:36 step:28122 [D loss: 0.460040, acc: 85.94%] [G loss: 4.214497]\n",
      "epoch:36 step:28123 [D loss: 0.216081, acc: 98.44%] [G loss: 3.688533]\n",
      "epoch:36 step:28124 [D loss: 0.215603, acc: 96.88%] [G loss: 3.507174]\n",
      "epoch:36 step:28125 [D loss: 0.150203, acc: 98.44%] [G loss: 7.739311]\n",
      "epoch:36 step:28126 [D loss: 0.632025, acc: 67.19%] [G loss: 4.707362]\n",
      "epoch:36 step:28127 [D loss: 0.242327, acc: 95.31%] [G loss: 4.354629]\n",
      "epoch:36 step:28128 [D loss: 0.334896, acc: 94.53%] [G loss: 4.086829]\n",
      "epoch:36 step:28129 [D loss: 0.443927, acc: 88.28%] [G loss: 4.314091]\n",
      "epoch:36 step:28130 [D loss: 0.786420, acc: 45.31%] [G loss: 5.727465]\n",
      "epoch:36 step:28131 [D loss: 0.471085, acc: 86.72%] [G loss: 2.777139]\n",
      "epoch:36 step:28132 [D loss: 1.310836, acc: 10.94%] [G loss: 4.261041]\n",
      "epoch:36 step:28133 [D loss: 0.161767, acc: 97.66%] [G loss: 8.423138]\n",
      "epoch:36 step:28134 [D loss: 0.238593, acc: 99.22%] [G loss: 3.953307]\n",
      "epoch:36 step:28135 [D loss: 0.370739, acc: 82.81%] [G loss: 4.160814]\n",
      "epoch:36 step:28136 [D loss: 0.157319, acc: 97.66%] [G loss: 4.198826]\n",
      "epoch:36 step:28137 [D loss: 0.895589, acc: 38.28%] [G loss: 4.008849]\n",
      "epoch:36 step:28138 [D loss: 0.905691, acc: 43.75%] [G loss: 6.203086]\n",
      "epoch:36 step:28139 [D loss: 0.256421, acc: 89.84%] [G loss: 5.724290]\n",
      "epoch:36 step:28140 [D loss: 0.125753, acc: 99.22%] [G loss: 5.720222]\n",
      "epoch:36 step:28141 [D loss: 0.730828, acc: 56.25%] [G loss: 3.884395]\n",
      "epoch:36 step:28142 [D loss: 0.420197, acc: 85.16%] [G loss: 7.072372]\n",
      "epoch:36 step:28143 [D loss: 0.183831, acc: 96.09%] [G loss: 5.636266]\n",
      "epoch:36 step:28144 [D loss: 0.450000, acc: 80.47%] [G loss: 3.453962]\n",
      "epoch:36 step:28145 [D loss: 0.228331, acc: 96.09%] [G loss: 5.146138]\n",
      "epoch:36 step:28146 [D loss: 0.270414, acc: 86.72%] [G loss: 5.977132]\n",
      "epoch:36 step:28147 [D loss: 0.417026, acc: 83.59%] [G loss: 3.704032]\n",
      "epoch:36 step:28148 [D loss: 0.150698, acc: 96.88%] [G loss: 7.480736]\n",
      "epoch:36 step:28149 [D loss: 0.385553, acc: 81.25%] [G loss: 5.928491]\n",
      "epoch:36 step:28150 [D loss: 0.311546, acc: 82.81%] [G loss: 2.906113]\n",
      "epoch:36 step:28151 [D loss: 0.254089, acc: 98.44%] [G loss: 1.705721]\n",
      "epoch:36 step:28152 [D loss: 0.441068, acc: 78.12%] [G loss: 5.265729]\n",
      "epoch:36 step:28153 [D loss: 0.580047, acc: 72.66%] [G loss: 5.230023]\n",
      "epoch:36 step:28154 [D loss: 0.545234, acc: 74.22%] [G loss: 5.732225]\n",
      "epoch:36 step:28155 [D loss: 0.352841, acc: 91.41%] [G loss: 7.644670]\n",
      "epoch:36 step:28156 [D loss: 0.233030, acc: 99.22%] [G loss: 3.300112]\n",
      "epoch:36 step:28157 [D loss: 0.544673, acc: 65.62%] [G loss: 3.584744]\n",
      "epoch:36 step:28158 [D loss: 1.319154, acc: 38.28%] [G loss: 6.278688]\n",
      "epoch:36 step:28159 [D loss: 0.114563, acc: 99.22%] [G loss: 3.954241]\n",
      "epoch:36 step:28160 [D loss: 0.530634, acc: 76.56%] [G loss: 7.896909]\n",
      "epoch:36 step:28161 [D loss: 0.307642, acc: 96.09%] [G loss: 5.539417]\n",
      "epoch:36 step:28162 [D loss: 0.124886, acc: 98.44%] [G loss: 6.110652]\n",
      "epoch:36 step:28163 [D loss: 0.234929, acc: 90.62%] [G loss: 4.869138]\n",
      "epoch:36 step:28164 [D loss: 0.060549, acc: 100.00%] [G loss: 3.424686]\n",
      "epoch:36 step:28165 [D loss: 0.866391, acc: 53.91%] [G loss: 6.960700]\n",
      "epoch:36 step:28166 [D loss: 0.298041, acc: 92.97%] [G loss: 5.223560]\n",
      "epoch:36 step:28167 [D loss: 0.949714, acc: 53.12%] [G loss: 8.226604]\n",
      "epoch:36 step:28168 [D loss: 0.483191, acc: 64.84%] [G loss: 4.651319]\n",
      "epoch:36 step:28169 [D loss: 0.340613, acc: 88.28%] [G loss: 4.130464]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28170 [D loss: 0.128455, acc: 100.00%] [G loss: 7.466259]\n",
      "epoch:36 step:28171 [D loss: 0.072137, acc: 100.00%] [G loss: 9.313366]\n",
      "epoch:36 step:28172 [D loss: 0.367309, acc: 89.06%] [G loss: 2.472475]\n",
      "epoch:36 step:28173 [D loss: 0.215728, acc: 92.19%] [G loss: 4.725460]\n",
      "epoch:36 step:28174 [D loss: 0.216420, acc: 96.88%] [G loss: 4.531312]\n",
      "epoch:36 step:28175 [D loss: 0.282696, acc: 92.19%] [G loss: 3.987521]\n",
      "epoch:36 step:28176 [D loss: 0.512631, acc: 76.56%] [G loss: 6.495619]\n",
      "epoch:36 step:28177 [D loss: 0.420485, acc: 76.56%] [G loss: 5.055390]\n",
      "epoch:36 step:28178 [D loss: 0.255568, acc: 93.75%] [G loss: 6.421918]\n",
      "epoch:36 step:28179 [D loss: 0.187110, acc: 98.44%] [G loss: 4.469330]\n",
      "epoch:36 step:28180 [D loss: 0.176329, acc: 96.88%] [G loss: 4.391770]\n",
      "epoch:36 step:28181 [D loss: 0.485385, acc: 68.75%] [G loss: 7.199553]\n",
      "epoch:36 step:28182 [D loss: 0.769549, acc: 53.91%] [G loss: 4.866545]\n",
      "epoch:36 step:28183 [D loss: 0.232075, acc: 98.44%] [G loss: 4.515195]\n",
      "epoch:36 step:28184 [D loss: 0.265810, acc: 89.06%] [G loss: 3.587196]\n",
      "epoch:36 step:28185 [D loss: 0.217971, acc: 92.19%] [G loss: 3.689111]\n",
      "epoch:36 step:28186 [D loss: 0.316146, acc: 90.62%] [G loss: 3.714484]\n",
      "epoch:36 step:28187 [D loss: 0.384210, acc: 83.59%] [G loss: 3.629169]\n",
      "epoch:36 step:28188 [D loss: 0.166226, acc: 98.44%] [G loss: 3.121250]\n",
      "epoch:36 step:28189 [D loss: 0.757788, acc: 53.12%] [G loss: 3.117165]\n",
      "epoch:36 step:28190 [D loss: 0.200833, acc: 96.88%] [G loss: 6.202516]\n",
      "epoch:36 step:28191 [D loss: 0.812655, acc: 50.78%] [G loss: 6.893754]\n",
      "epoch:36 step:28192 [D loss: 0.103959, acc: 99.22%] [G loss: 8.006442]\n",
      "epoch:36 step:28193 [D loss: 1.450616, acc: 51.56%] [G loss: 5.060236]\n",
      "epoch:36 step:28194 [D loss: 0.303027, acc: 84.38%] [G loss: 4.412074]\n",
      "epoch:36 step:28195 [D loss: 0.287629, acc: 85.16%] [G loss: 3.983365]\n",
      "epoch:36 step:28196 [D loss: 0.046446, acc: 100.00%] [G loss: 4.410778]\n",
      "epoch:36 step:28197 [D loss: 0.226285, acc: 96.09%] [G loss: 4.259185]\n",
      "epoch:36 step:28198 [D loss: 0.893612, acc: 51.56%] [G loss: 7.787700]\n",
      "epoch:36 step:28199 [D loss: 0.068619, acc: 99.22%] [G loss: 5.129057]\n",
      "epoch:36 step:28200 [D loss: 0.303386, acc: 92.19%] [G loss: 6.393198]\n",
      "epoch:36 step:28201 [D loss: 0.314295, acc: 96.88%] [G loss: 5.983380]\n",
      "epoch:36 step:28202 [D loss: 0.320124, acc: 91.41%] [G loss: 6.611578]\n",
      "epoch:36 step:28203 [D loss: 0.546024, acc: 71.88%] [G loss: 3.694419]\n",
      "epoch:36 step:28204 [D loss: 0.171463, acc: 98.44%] [G loss: 4.356263]\n",
      "epoch:36 step:28205 [D loss: 0.216566, acc: 95.31%] [G loss: 7.306948]\n",
      "epoch:36 step:28206 [D loss: 0.141058, acc: 97.66%] [G loss: 5.721307]\n",
      "epoch:36 step:28207 [D loss: 0.045899, acc: 100.00%] [G loss: 5.760359]\n",
      "epoch:36 step:28208 [D loss: 0.342456, acc: 85.16%] [G loss: 4.065155]\n",
      "epoch:36 step:28209 [D loss: 0.081171, acc: 100.00%] [G loss: 4.879547]\n",
      "epoch:36 step:28210 [D loss: 0.899409, acc: 50.00%] [G loss: 4.336047]\n",
      "epoch:36 step:28211 [D loss: 0.344728, acc: 85.94%] [G loss: 3.801163]\n",
      "epoch:36 step:28212 [D loss: 0.506353, acc: 78.12%] [G loss: 5.090749]\n",
      "epoch:36 step:28213 [D loss: 0.483649, acc: 68.75%] [G loss: 4.512826]\n",
      "epoch:36 step:28214 [D loss: 0.198285, acc: 98.44%] [G loss: 4.386960]\n",
      "epoch:36 step:28215 [D loss: 0.347260, acc: 83.59%] [G loss: 6.002705]\n",
      "epoch:36 step:28216 [D loss: 0.570244, acc: 72.66%] [G loss: 3.423596]\n",
      "epoch:36 step:28217 [D loss: 0.446466, acc: 77.34%] [G loss: 6.617535]\n",
      "epoch:36 step:28218 [D loss: 0.374939, acc: 85.94%] [G loss: 4.289711]\n",
      "epoch:36 step:28219 [D loss: 0.771801, acc: 50.78%] [G loss: 6.311035]\n",
      "epoch:36 step:28220 [D loss: 0.758203, acc: 54.69%] [G loss: 4.170588]\n",
      "epoch:36 step:28221 [D loss: 0.355566, acc: 84.38%] [G loss: 3.292915]\n",
      "epoch:36 step:28222 [D loss: 0.257224, acc: 92.97%] [G loss: 5.206387]\n",
      "epoch:36 step:28223 [D loss: 0.733674, acc: 53.12%] [G loss: 4.372021]\n",
      "epoch:36 step:28224 [D loss: 0.261185, acc: 91.41%] [G loss: 3.678707]\n",
      "epoch:36 step:28225 [D loss: 0.322424, acc: 89.84%] [G loss: 6.057763]\n",
      "epoch:36 step:28226 [D loss: 0.439498, acc: 81.25%] [G loss: 5.061099]\n",
      "epoch:36 step:28227 [D loss: 0.537998, acc: 64.06%] [G loss: 4.149298]\n",
      "epoch:36 step:28228 [D loss: 0.101426, acc: 99.22%] [G loss: 6.805029]\n",
      "epoch:36 step:28229 [D loss: 1.237077, acc: 10.94%] [G loss: 5.227618]\n",
      "epoch:36 step:28230 [D loss: 1.247816, acc: 42.97%] [G loss: 6.148113]\n",
      "epoch:36 step:28231 [D loss: 0.659710, acc: 63.28%] [G loss: 5.052754]\n",
      "epoch:36 step:28232 [D loss: 0.534895, acc: 71.09%] [G loss: 3.608301]\n",
      "epoch:36 step:28233 [D loss: 0.191084, acc: 95.31%] [G loss: 6.806581]\n",
      "epoch:36 step:28234 [D loss: 0.167747, acc: 99.22%] [G loss: 3.832359]\n",
      "epoch:36 step:28235 [D loss: 0.441853, acc: 79.69%] [G loss: 6.447619]\n",
      "epoch:36 step:28236 [D loss: 0.188848, acc: 100.00%] [G loss: 2.376045]\n",
      "epoch:36 step:28237 [D loss: 0.162982, acc: 96.88%] [G loss: 5.535137]\n",
      "epoch:36 step:28238 [D loss: 0.238457, acc: 91.41%] [G loss: 5.443143]\n",
      "epoch:36 step:28239 [D loss: 0.167162, acc: 98.44%] [G loss: 5.926098]\n",
      "epoch:36 step:28240 [D loss: 0.474846, acc: 66.41%] [G loss: 5.374581]\n",
      "epoch:36 step:28241 [D loss: 0.644485, acc: 60.94%] [G loss: 4.610779]\n",
      "epoch:36 step:28242 [D loss: 0.160560, acc: 100.00%] [G loss: 5.561354]\n",
      "epoch:36 step:28243 [D loss: 0.224072, acc: 92.97%] [G loss: 7.824004]\n",
      "epoch:36 step:28244 [D loss: 0.083570, acc: 100.00%] [G loss: 3.221162]\n",
      "epoch:36 step:28245 [D loss: 0.596177, acc: 66.41%] [G loss: 5.478692]\n",
      "epoch:36 step:28246 [D loss: 0.197165, acc: 95.31%] [G loss: 5.236248]\n",
      "epoch:36 step:28247 [D loss: 0.241305, acc: 89.06%] [G loss: 5.657910]\n",
      "epoch:36 step:28248 [D loss: 0.190408, acc: 99.22%] [G loss: 4.544529]\n",
      "epoch:36 step:28249 [D loss: 0.104632, acc: 100.00%] [G loss: 3.705106]\n",
      "epoch:36 step:28250 [D loss: 0.678925, acc: 53.91%] [G loss: 3.289145]\n",
      "epoch:36 step:28251 [D loss: 2.011855, acc: 39.84%] [G loss: 6.636607]\n",
      "epoch:36 step:28252 [D loss: 0.129048, acc: 98.44%] [G loss: 7.744190]\n",
      "epoch:36 step:28253 [D loss: 0.362663, acc: 94.53%] [G loss: 4.404243]\n",
      "epoch:36 step:28254 [D loss: 0.257282, acc: 96.09%] [G loss: 5.838475]\n",
      "epoch:36 step:28255 [D loss: 0.462452, acc: 76.56%] [G loss: 3.338818]\n",
      "epoch:36 step:28256 [D loss: 0.358148, acc: 88.28%] [G loss: 3.556524]\n",
      "epoch:36 step:28257 [D loss: 0.796654, acc: 50.78%] [G loss: 3.425491]\n",
      "epoch:36 step:28258 [D loss: 1.447965, acc: 50.78%] [G loss: 4.973596]\n",
      "epoch:36 step:28259 [D loss: 0.269946, acc: 96.88%] [G loss: 5.147414]\n",
      "epoch:36 step:28260 [D loss: 0.143033, acc: 96.88%] [G loss: 6.142891]\n",
      "epoch:36 step:28261 [D loss: 0.181549, acc: 96.09%] [G loss: 6.158239]\n",
      "epoch:36 step:28262 [D loss: 0.040817, acc: 100.00%] [G loss: 6.239958]\n",
      "epoch:36 step:28263 [D loss: 0.243410, acc: 96.88%] [G loss: 4.737200]\n",
      "epoch:36 step:28264 [D loss: 1.014636, acc: 22.66%] [G loss: 5.449250]\n",
      "epoch:36 step:28265 [D loss: 0.473329, acc: 82.81%] [G loss: 5.917944]\n",
      "epoch:36 step:28266 [D loss: 0.101117, acc: 100.00%] [G loss: 4.273867]\n",
      "epoch:36 step:28267 [D loss: 0.648580, acc: 63.28%] [G loss: 5.652256]\n",
      "epoch:36 step:28268 [D loss: 0.756886, acc: 42.19%] [G loss: 5.520917]\n",
      "epoch:36 step:28269 [D loss: 0.352580, acc: 83.59%] [G loss: 5.512650]\n",
      "epoch:36 step:28270 [D loss: 0.072046, acc: 100.00%] [G loss: 4.223081]\n",
      "epoch:36 step:28271 [D loss: 0.446061, acc: 78.12%] [G loss: 3.156565]\n",
      "epoch:36 step:28272 [D loss: 1.264871, acc: 27.34%] [G loss: 5.803030]\n",
      "epoch:36 step:28273 [D loss: 0.589634, acc: 58.59%] [G loss: 4.259497]\n",
      "epoch:36 step:28274 [D loss: 0.100766, acc: 100.00%] [G loss: 3.797273]\n",
      "epoch:36 step:28275 [D loss: 0.476392, acc: 76.56%] [G loss: 6.798840]\n",
      "epoch:36 step:28276 [D loss: 0.388572, acc: 74.22%] [G loss: 3.581516]\n",
      "epoch:36 step:28277 [D loss: 0.438709, acc: 75.78%] [G loss: 7.691536]\n",
      "epoch:36 step:28278 [D loss: 0.442664, acc: 78.12%] [G loss: 5.561815]\n",
      "epoch:36 step:28279 [D loss: 0.496852, acc: 79.69%] [G loss: 5.364424]\n",
      "epoch:36 step:28280 [D loss: 0.060551, acc: 100.00%] [G loss: 4.884066]\n",
      "epoch:36 step:28281 [D loss: 0.555236, acc: 64.06%] [G loss: 5.603504]\n",
      "epoch:36 step:28282 [D loss: 0.733474, acc: 52.34%] [G loss: 5.480090]\n",
      "epoch:36 step:28283 [D loss: 0.453552, acc: 77.34%] [G loss: 5.792099]\n",
      "epoch:36 step:28284 [D loss: 0.215218, acc: 93.75%] [G loss: 6.142470]\n",
      "epoch:36 step:28285 [D loss: 0.554877, acc: 64.06%] [G loss: 3.307087]\n",
      "epoch:36 step:28286 [D loss: 0.056194, acc: 100.00%] [G loss: 3.691710]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28287 [D loss: 0.303592, acc: 91.41%] [G loss: 5.967724]\n",
      "epoch:36 step:28288 [D loss: 0.257605, acc: 96.09%] [G loss: 4.945746]\n",
      "epoch:36 step:28289 [D loss: 0.140662, acc: 98.44%] [G loss: 2.917242]\n",
      "epoch:36 step:28290 [D loss: 0.017112, acc: 100.00%] [G loss: 8.017091]\n",
      "epoch:36 step:28291 [D loss: 0.284217, acc: 82.81%] [G loss: 7.337635]\n",
      "epoch:36 step:28292 [D loss: 0.478644, acc: 71.88%] [G loss: 4.466535]\n",
      "epoch:36 step:28293 [D loss: 0.252104, acc: 97.66%] [G loss: 4.780524]\n",
      "epoch:36 step:28294 [D loss: 0.196324, acc: 97.66%] [G loss: 3.413149]\n",
      "epoch:36 step:28295 [D loss: 0.233239, acc: 96.88%] [G loss: 5.214885]\n",
      "epoch:36 step:28296 [D loss: 0.261478, acc: 94.53%] [G loss: 1.612114]\n",
      "epoch:36 step:28297 [D loss: 0.086700, acc: 100.00%] [G loss: 7.125929]\n",
      "epoch:36 step:28298 [D loss: 0.266162, acc: 93.75%] [G loss: 3.169537]\n",
      "epoch:36 step:28299 [D loss: 0.168010, acc: 98.44%] [G loss: 4.574834]\n",
      "epoch:36 step:28300 [D loss: 0.204773, acc: 96.09%] [G loss: 6.262837]\n",
      "epoch:36 step:28301 [D loss: 0.202052, acc: 97.66%] [G loss: 6.476315]\n",
      "epoch:36 step:28302 [D loss: 0.140232, acc: 98.44%] [G loss: 4.062498]\n",
      "epoch:36 step:28303 [D loss: 0.055532, acc: 99.22%] [G loss: 4.370313]\n",
      "epoch:36 step:28304 [D loss: 0.039798, acc: 100.00%] [G loss: 5.877744]\n",
      "epoch:36 step:28305 [D loss: 0.345397, acc: 78.91%] [G loss: 5.534187]\n",
      "epoch:36 step:28306 [D loss: 0.603695, acc: 57.03%] [G loss: 3.346249]\n",
      "epoch:36 step:28307 [D loss: 0.779779, acc: 51.56%] [G loss: 5.476287]\n",
      "epoch:36 step:28308 [D loss: 0.055482, acc: 100.00%] [G loss: 5.414568]\n",
      "epoch:36 step:28309 [D loss: 0.095950, acc: 100.00%] [G loss: 4.736662]\n",
      "epoch:36 step:28310 [D loss: 0.570896, acc: 68.75%] [G loss: 8.019706]\n",
      "epoch:36 step:28311 [D loss: 0.057389, acc: 100.00%] [G loss: 4.458493]\n",
      "epoch:36 step:28312 [D loss: 0.721135, acc: 54.69%] [G loss: 6.710130]\n",
      "epoch:36 step:28313 [D loss: 0.109824, acc: 100.00%] [G loss: 4.831302]\n",
      "epoch:36 step:28314 [D loss: 0.199652, acc: 96.09%] [G loss: 6.386947]\n",
      "epoch:36 step:28315 [D loss: 0.208569, acc: 97.66%] [G loss: 7.636155]\n",
      "epoch:36 step:28316 [D loss: 0.267190, acc: 92.19%] [G loss: 6.152452]\n",
      "epoch:36 step:28317 [D loss: 0.097932, acc: 99.22%] [G loss: 4.817303]\n",
      "epoch:36 step:28318 [D loss: 0.695485, acc: 62.50%] [G loss: 5.298472]\n",
      "epoch:36 step:28319 [D loss: 0.422041, acc: 82.81%] [G loss: 3.249240]\n",
      "epoch:36 step:28320 [D loss: 0.881673, acc: 40.62%] [G loss: 3.835511]\n",
      "epoch:36 step:28321 [D loss: 0.050468, acc: 100.00%] [G loss: 4.984682]\n",
      "epoch:36 step:28322 [D loss: 0.095461, acc: 100.00%] [G loss: 5.488115]\n",
      "epoch:36 step:28323 [D loss: 0.429135, acc: 88.28%] [G loss: 6.298723]\n",
      "epoch:36 step:28324 [D loss: 0.379905, acc: 87.50%] [G loss: 5.057760]\n",
      "epoch:36 step:28325 [D loss: 0.401511, acc: 84.38%] [G loss: 3.461024]\n",
      "epoch:36 step:28326 [D loss: 0.298915, acc: 92.97%] [G loss: 2.865039]\n",
      "epoch:36 step:28327 [D loss: 0.277827, acc: 95.31%] [G loss: 3.921845]\n",
      "epoch:36 step:28328 [D loss: 0.295562, acc: 89.06%] [G loss: 9.333841]\n",
      "epoch:36 step:28329 [D loss: 0.648070, acc: 60.94%] [G loss: 6.333404]\n",
      "epoch:36 step:28330 [D loss: 0.034365, acc: 100.00%] [G loss: 3.361024]\n",
      "epoch:36 step:28331 [D loss: 0.747717, acc: 55.47%] [G loss: 5.424652]\n",
      "epoch:36 step:28332 [D loss: 0.166589, acc: 99.22%] [G loss: 5.677733]\n",
      "epoch:36 step:28333 [D loss: 0.477742, acc: 74.22%] [G loss: 4.406300]\n",
      "epoch:36 step:28334 [D loss: 0.091671, acc: 99.22%] [G loss: 5.250839]\n",
      "epoch:36 step:28335 [D loss: 0.841304, acc: 51.56%] [G loss: 5.209322]\n",
      "epoch:36 step:28336 [D loss: 0.258452, acc: 85.94%] [G loss: 6.747217]\n",
      "epoch:36 step:28337 [D loss: 0.056901, acc: 100.00%] [G loss: 3.126075]\n",
      "epoch:36 step:28338 [D loss: 0.869989, acc: 54.69%] [G loss: 5.640342]\n",
      "epoch:36 step:28339 [D loss: 0.812718, acc: 51.56%] [G loss: 3.592427]\n",
      "epoch:36 step:28340 [D loss: 0.222954, acc: 95.31%] [G loss: 4.373537]\n",
      "epoch:36 step:28341 [D loss: 0.056776, acc: 100.00%] [G loss: 3.097965]\n",
      "epoch:36 step:28342 [D loss: 0.167241, acc: 97.66%] [G loss: 6.507213]\n",
      "epoch:36 step:28343 [D loss: 0.008944, acc: 100.00%] [G loss: 7.187352]\n",
      "epoch:36 step:28344 [D loss: 0.094020, acc: 100.00%] [G loss: 5.466418]\n",
      "epoch:36 step:28345 [D loss: 0.551874, acc: 60.94%] [G loss: 7.650416]\n",
      "epoch:36 step:28346 [D loss: 0.321105, acc: 81.25%] [G loss: 6.069355]\n",
      "epoch:36 step:28347 [D loss: 0.334141, acc: 87.50%] [G loss: 3.579508]\n",
      "epoch:36 step:28348 [D loss: 0.182583, acc: 98.44%] [G loss: 4.875867]\n",
      "epoch:36 step:28349 [D loss: 0.759251, acc: 53.12%] [G loss: 6.045873]\n",
      "epoch:36 step:28350 [D loss: 0.507111, acc: 71.09%] [G loss: 4.795211]\n",
      "epoch:36 step:28351 [D loss: 0.203403, acc: 96.88%] [G loss: 4.223644]\n",
      "epoch:36 step:28352 [D loss: 0.212900, acc: 97.66%] [G loss: 8.934136]\n",
      "epoch:36 step:28353 [D loss: 0.167726, acc: 97.66%] [G loss: 5.809172]\n",
      "epoch:36 step:28354 [D loss: 1.181693, acc: 47.66%] [G loss: 3.026504]\n",
      "epoch:36 step:28355 [D loss: 0.244376, acc: 95.31%] [G loss: 3.596633]\n",
      "epoch:36 step:28356 [D loss: 0.545567, acc: 75.78%] [G loss: 4.918809]\n",
      "epoch:36 step:28357 [D loss: 0.274167, acc: 88.28%] [G loss: 5.776860]\n",
      "epoch:36 step:28358 [D loss: 0.102033, acc: 100.00%] [G loss: 4.104597]\n",
      "epoch:36 step:28359 [D loss: 0.225272, acc: 98.44%] [G loss: 5.168555]\n",
      "epoch:36 step:28360 [D loss: 0.024308, acc: 100.00%] [G loss: 4.421291]\n",
      "epoch:36 step:28361 [D loss: 0.494171, acc: 77.34%] [G loss: 6.592502]\n",
      "epoch:36 step:28362 [D loss: 0.450439, acc: 82.81%] [G loss: 4.411411]\n",
      "epoch:36 step:28363 [D loss: 0.946766, acc: 35.94%] [G loss: 6.744537]\n",
      "epoch:36 step:28364 [D loss: 0.114645, acc: 100.00%] [G loss: 4.260504]\n",
      "epoch:36 step:28365 [D loss: 0.015546, acc: 100.00%] [G loss: 5.982010]\n",
      "epoch:36 step:28366 [D loss: 0.407731, acc: 85.16%] [G loss: 5.132349]\n",
      "epoch:36 step:28367 [D loss: 0.224763, acc: 97.66%] [G loss: 4.106913]\n",
      "epoch:36 step:28368 [D loss: 0.472659, acc: 71.09%] [G loss: 7.035017]\n",
      "epoch:36 step:28369 [D loss: 0.372393, acc: 79.69%] [G loss: 5.889420]\n",
      "epoch:36 step:28370 [D loss: 0.732297, acc: 51.56%] [G loss: 5.629574]\n",
      "epoch:36 step:28371 [D loss: 0.176476, acc: 100.00%] [G loss: 4.609828]\n",
      "epoch:36 step:28372 [D loss: 0.135464, acc: 100.00%] [G loss: 7.178914]\n",
      "epoch:36 step:28373 [D loss: 0.290707, acc: 92.97%] [G loss: 5.449214]\n",
      "epoch:36 step:28374 [D loss: 1.434474, acc: 5.47%] [G loss: 7.533047]\n",
      "epoch:36 step:28375 [D loss: 0.108919, acc: 100.00%] [G loss: 4.048372]\n",
      "epoch:36 step:28376 [D loss: 0.035441, acc: 100.00%] [G loss: 6.047186]\n",
      "epoch:36 step:28377 [D loss: 0.540152, acc: 65.62%] [G loss: 3.983607]\n",
      "epoch:36 step:28378 [D loss: 0.076872, acc: 98.44%] [G loss: 6.304183]\n",
      "epoch:36 step:28379 [D loss: 0.481885, acc: 67.97%] [G loss: 5.768613]\n",
      "epoch:36 step:28380 [D loss: 0.233918, acc: 94.53%] [G loss: 5.537257]\n",
      "epoch:36 step:28381 [D loss: 0.093724, acc: 100.00%] [G loss: 5.008924]\n",
      "epoch:36 step:28382 [D loss: 0.475113, acc: 75.00%] [G loss: 4.562676]\n",
      "epoch:36 step:28383 [D loss: 0.526365, acc: 75.00%] [G loss: 2.231601]\n",
      "epoch:36 step:28384 [D loss: 0.944023, acc: 40.62%] [G loss: 5.867825]\n",
      "epoch:36 step:28385 [D loss: 0.889140, acc: 37.50%] [G loss: 4.146496]\n",
      "epoch:36 step:28386 [D loss: 0.413525, acc: 80.47%] [G loss: 5.350794]\n",
      "epoch:36 step:28387 [D loss: 0.818501, acc: 53.12%] [G loss: 4.104039]\n",
      "epoch:36 step:28388 [D loss: 0.867328, acc: 43.75%] [G loss: 4.803570]\n",
      "epoch:36 step:28389 [D loss: 0.178086, acc: 97.66%] [G loss: 6.231182]\n",
      "epoch:36 step:28390 [D loss: 0.767497, acc: 50.78%] [G loss: 5.510701]\n",
      "epoch:36 step:28391 [D loss: 0.106473, acc: 100.00%] [G loss: 4.758719]\n",
      "epoch:36 step:28392 [D loss: 0.295934, acc: 87.50%] [G loss: 3.708844]\n",
      "epoch:36 step:28393 [D loss: 0.337903, acc: 93.75%] [G loss: 4.471449]\n",
      "epoch:36 step:28394 [D loss: 0.456036, acc: 75.00%] [G loss: 6.862415]\n",
      "epoch:36 step:28395 [D loss: 1.368249, acc: 50.00%] [G loss: 5.632639]\n",
      "epoch:36 step:28396 [D loss: 0.222966, acc: 96.88%] [G loss: 5.746553]\n",
      "epoch:36 step:28397 [D loss: 0.469761, acc: 80.47%] [G loss: 4.067507]\n",
      "epoch:36 step:28398 [D loss: 0.834355, acc: 53.91%] [G loss: 7.685495]\n",
      "epoch:36 step:28399 [D loss: 0.987430, acc: 50.78%] [G loss: 7.406652]\n",
      "epoch:36 step:28400 [D loss: 0.237254, acc: 92.19%] [G loss: 4.781909]\n",
      "epoch:36 step:28401 [D loss: 1.217221, acc: 18.75%] [G loss: 6.345547]\n",
      "epoch:36 step:28402 [D loss: 0.271332, acc: 95.31%] [G loss: 6.343362]\n",
      "epoch:36 step:28403 [D loss: 0.297403, acc: 89.84%] [G loss: 7.009437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28404 [D loss: 0.338755, acc: 90.62%] [G loss: 4.189362]\n",
      "epoch:36 step:28405 [D loss: 0.161129, acc: 100.00%] [G loss: 5.564671]\n",
      "epoch:36 step:28406 [D loss: 0.140626, acc: 99.22%] [G loss: 3.470568]\n",
      "epoch:36 step:28407 [D loss: 0.656532, acc: 54.69%] [G loss: 6.058980]\n",
      "epoch:36 step:28408 [D loss: 0.325856, acc: 84.38%] [G loss: 4.987386]\n",
      "epoch:36 step:28409 [D loss: 0.376231, acc: 78.12%] [G loss: 4.721509]\n",
      "epoch:36 step:28410 [D loss: 0.149250, acc: 99.22%] [G loss: 3.699548]\n",
      "epoch:36 step:28411 [D loss: 0.434065, acc: 89.06%] [G loss: 3.237546]\n",
      "epoch:36 step:28412 [D loss: 0.170854, acc: 96.09%] [G loss: 6.157698]\n",
      "epoch:36 step:28413 [D loss: 0.890312, acc: 50.78%] [G loss: 3.443896]\n",
      "epoch:36 step:28414 [D loss: 0.206330, acc: 96.88%] [G loss: 6.882763]\n",
      "epoch:36 step:28415 [D loss: 1.125369, acc: 28.12%] [G loss: 6.129280]\n",
      "epoch:36 step:28416 [D loss: 0.269944, acc: 96.88%] [G loss: 5.118849]\n",
      "epoch:36 step:28417 [D loss: 0.346325, acc: 82.03%] [G loss: 3.721916]\n",
      "epoch:36 step:28418 [D loss: 0.062896, acc: 100.00%] [G loss: 4.813959]\n",
      "epoch:36 step:28419 [D loss: 0.352494, acc: 92.97%] [G loss: 5.202803]\n",
      "epoch:36 step:28420 [D loss: 0.780503, acc: 47.66%] [G loss: 4.471054]\n",
      "epoch:36 step:28421 [D loss: 0.434321, acc: 74.22%] [G loss: 3.707493]\n",
      "epoch:36 step:28422 [D loss: 0.156498, acc: 98.44%] [G loss: 6.259489]\n",
      "epoch:36 step:28423 [D loss: 0.407832, acc: 87.50%] [G loss: 3.643490]\n",
      "epoch:36 step:28424 [D loss: 0.475292, acc: 78.12%] [G loss: 5.547032]\n",
      "epoch:36 step:28425 [D loss: 0.522122, acc: 68.75%] [G loss: 5.281327]\n",
      "epoch:36 step:28426 [D loss: 0.153318, acc: 97.66%] [G loss: 7.035612]\n",
      "epoch:36 step:28427 [D loss: 0.286077, acc: 95.31%] [G loss: 5.055968]\n",
      "epoch:36 step:28428 [D loss: 0.468784, acc: 78.12%] [G loss: 4.132749]\n",
      "epoch:36 step:28429 [D loss: 0.216200, acc: 96.88%] [G loss: 3.715775]\n",
      "epoch:36 step:28430 [D loss: 0.025175, acc: 100.00%] [G loss: 3.919008]\n",
      "epoch:36 step:28431 [D loss: 0.467236, acc: 67.97%] [G loss: 8.338120]\n",
      "epoch:36 step:28432 [D loss: 0.281849, acc: 93.75%] [G loss: 6.491944]\n",
      "epoch:36 step:28433 [D loss: 0.357502, acc: 82.03%] [G loss: 3.925688]\n",
      "epoch:36 step:28434 [D loss: 0.089758, acc: 100.00%] [G loss: 4.648406]\n",
      "epoch:36 step:28435 [D loss: 0.299647, acc: 82.03%] [G loss: 7.675132]\n",
      "epoch:36 step:28436 [D loss: 0.398040, acc: 81.25%] [G loss: 5.032477]\n",
      "epoch:36 step:28437 [D loss: 0.260690, acc: 93.75%] [G loss: 3.064133]\n",
      "epoch:36 step:28438 [D loss: 0.445086, acc: 78.91%] [G loss: 7.152778]\n",
      "epoch:36 step:28439 [D loss: 0.157913, acc: 98.44%] [G loss: 3.895374]\n",
      "epoch:36 step:28440 [D loss: 0.349473, acc: 89.84%] [G loss: 3.768793]\n",
      "epoch:36 step:28441 [D loss: 0.826107, acc: 47.66%] [G loss: 4.406912]\n",
      "epoch:36 step:28442 [D loss: 0.599558, acc: 67.19%] [G loss: 5.993223]\n",
      "epoch:36 step:28443 [D loss: 0.181473, acc: 97.66%] [G loss: 4.149236]\n",
      "epoch:36 step:28444 [D loss: 0.540715, acc: 67.19%] [G loss: 4.313643]\n",
      "epoch:36 step:28445 [D loss: 1.390849, acc: 49.22%] [G loss: 5.351586]\n",
      "epoch:36 step:28446 [D loss: 0.090346, acc: 99.22%] [G loss: 3.315939]\n",
      "epoch:36 step:28447 [D loss: 1.672161, acc: 9.38%] [G loss: 5.090003]\n",
      "epoch:36 step:28448 [D loss: 0.792000, acc: 54.69%] [G loss: 5.744095]\n",
      "epoch:36 step:28449 [D loss: 0.119979, acc: 98.44%] [G loss: 7.395128]\n",
      "epoch:36 step:28450 [D loss: 0.401686, acc: 77.34%] [G loss: 4.936418]\n",
      "epoch:36 step:28451 [D loss: 0.481654, acc: 69.53%] [G loss: 6.356885]\n",
      "epoch:36 step:28452 [D loss: 0.755055, acc: 54.69%] [G loss: 6.859854]\n",
      "epoch:36 step:28453 [D loss: 0.169148, acc: 99.22%] [G loss: 4.437286]\n",
      "epoch:36 step:28454 [D loss: 0.377587, acc: 82.03%] [G loss: 4.264770]\n",
      "epoch:36 step:28455 [D loss: 0.158350, acc: 99.22%] [G loss: 5.349031]\n",
      "epoch:36 step:28456 [D loss: 0.639607, acc: 60.16%] [G loss: 6.586807]\n",
      "epoch:36 step:28457 [D loss: 0.159282, acc: 99.22%] [G loss: 6.506472]\n",
      "epoch:36 step:28458 [D loss: 1.000347, acc: 32.03%] [G loss: 4.998321]\n",
      "epoch:36 step:28459 [D loss: 0.077963, acc: 99.22%] [G loss: 5.798978]\n",
      "epoch:36 step:28460 [D loss: 0.161212, acc: 100.00%] [G loss: 3.541253]\n",
      "epoch:36 step:28461 [D loss: 0.341394, acc: 82.03%] [G loss: 4.267818]\n",
      "epoch:36 step:28462 [D loss: 0.256695, acc: 92.19%] [G loss: 5.966628]\n",
      "epoch:36 step:28463 [D loss: 1.072954, acc: 51.56%] [G loss: 5.201712]\n",
      "epoch:36 step:28464 [D loss: 0.442160, acc: 71.09%] [G loss: 5.062100]\n",
      "epoch:36 step:28465 [D loss: 0.368397, acc: 83.59%] [G loss: 4.520584]\n",
      "epoch:36 step:28466 [D loss: 0.224112, acc: 92.19%] [G loss: 4.650140]\n",
      "epoch:36 step:28467 [D loss: 0.534458, acc: 72.66%] [G loss: 3.840542]\n",
      "epoch:36 step:28468 [D loss: 1.008895, acc: 50.78%] [G loss: 6.386223]\n",
      "epoch:36 step:28469 [D loss: 0.178108, acc: 96.88%] [G loss: 8.360353]\n",
      "epoch:36 step:28470 [D loss: 0.583798, acc: 57.03%] [G loss: 3.713305]\n",
      "epoch:36 step:28471 [D loss: 0.445687, acc: 78.91%] [G loss: 4.658467]\n",
      "epoch:36 step:28472 [D loss: 0.657187, acc: 59.38%] [G loss: 7.423227]\n",
      "epoch:36 step:28473 [D loss: 0.523912, acc: 63.28%] [G loss: 3.232362]\n",
      "epoch:36 step:28474 [D loss: 0.197179, acc: 96.88%] [G loss: 3.780410]\n",
      "epoch:36 step:28475 [D loss: 0.824889, acc: 50.78%] [G loss: 8.536482]\n",
      "epoch:36 step:28476 [D loss: 0.193415, acc: 95.31%] [G loss: 6.322344]\n",
      "epoch:36 step:28477 [D loss: 0.408300, acc: 81.25%] [G loss: 2.076632]\n",
      "epoch:36 step:28478 [D loss: 0.087763, acc: 98.44%] [G loss: 6.433077]\n",
      "epoch:36 step:28479 [D loss: 0.599005, acc: 72.66%] [G loss: 4.207495]\n",
      "epoch:36 step:28480 [D loss: 0.459132, acc: 82.03%] [G loss: 4.112225]\n",
      "epoch:36 step:28481 [D loss: 0.282547, acc: 94.53%] [G loss: 4.988080]\n",
      "epoch:36 step:28482 [D loss: 0.193866, acc: 97.66%] [G loss: 4.705231]\n",
      "epoch:36 step:28483 [D loss: 0.268752, acc: 89.84%] [G loss: 4.667808]\n",
      "epoch:36 step:28484 [D loss: 0.029487, acc: 100.00%] [G loss: 5.116737]\n",
      "epoch:36 step:28485 [D loss: 0.104854, acc: 100.00%] [G loss: 5.954344]\n",
      "epoch:36 step:28486 [D loss: 0.458938, acc: 71.88%] [G loss: 4.526121]\n",
      "epoch:36 step:28487 [D loss: 0.455753, acc: 81.25%] [G loss: 6.089350]\n",
      "epoch:36 step:28488 [D loss: 0.427697, acc: 75.00%] [G loss: 6.319304]\n",
      "epoch:36 step:28489 [D loss: 0.119556, acc: 100.00%] [G loss: 6.580040]\n",
      "epoch:36 step:28490 [D loss: 0.082499, acc: 98.44%] [G loss: 4.456543]\n",
      "epoch:36 step:28491 [D loss: 0.364061, acc: 87.50%] [G loss: 2.855517]\n",
      "epoch:36 step:28492 [D loss: 0.101087, acc: 99.22%] [G loss: 4.390441]\n",
      "epoch:36 step:28493 [D loss: 0.137657, acc: 100.00%] [G loss: 3.856951]\n",
      "epoch:36 step:28494 [D loss: 0.196158, acc: 99.22%] [G loss: 6.242960]\n",
      "epoch:36 step:28495 [D loss: 0.257398, acc: 95.31%] [G loss: 6.776359]\n",
      "epoch:36 step:28496 [D loss: 0.363492, acc: 89.06%] [G loss: 7.971430]\n",
      "epoch:36 step:28497 [D loss: 0.190769, acc: 96.09%] [G loss: 4.654636]\n",
      "epoch:36 step:28498 [D loss: 0.072177, acc: 99.22%] [G loss: 5.263252]\n",
      "epoch:36 step:28499 [D loss: 0.268505, acc: 96.09%] [G loss: 5.186244]\n",
      "epoch:36 step:28500 [D loss: 0.258623, acc: 90.62%] [G loss: 5.072353]\n",
      "epoch:36 step:28501 [D loss: 0.847416, acc: 53.12%] [G loss: 6.105415]\n",
      "epoch:36 step:28502 [D loss: 0.190204, acc: 99.22%] [G loss: 4.120673]\n",
      "epoch:36 step:28503 [D loss: 1.290874, acc: 17.19%] [G loss: 6.432550]\n",
      "epoch:36 step:28504 [D loss: 0.219031, acc: 96.09%] [G loss: 5.584129]\n",
      "epoch:36 step:28505 [D loss: 0.179556, acc: 99.22%] [G loss: 6.710182]\n",
      "epoch:36 step:28506 [D loss: 0.245008, acc: 95.31%] [G loss: 5.516273]\n",
      "epoch:36 step:28507 [D loss: 0.914043, acc: 44.53%] [G loss: 5.876534]\n",
      "epoch:36 step:28508 [D loss: 0.173359, acc: 99.22%] [G loss: 4.583353]\n",
      "epoch:36 step:28509 [D loss: 0.560230, acc: 62.50%] [G loss: 3.943391]\n",
      "epoch:36 step:28510 [D loss: 0.078823, acc: 100.00%] [G loss: 7.462628]\n",
      "epoch:36 step:28511 [D loss: 0.659335, acc: 61.72%] [G loss: 6.495606]\n",
      "epoch:36 step:28512 [D loss: 0.212570, acc: 95.31%] [G loss: 4.679819]\n",
      "epoch:36 step:28513 [D loss: 0.310142, acc: 92.97%] [G loss: 5.599778]\n",
      "epoch:36 step:28514 [D loss: 0.748715, acc: 49.22%] [G loss: 6.075616]\n",
      "epoch:36 step:28515 [D loss: 0.247793, acc: 97.66%] [G loss: 4.226184]\n",
      "epoch:36 step:28516 [D loss: 0.442488, acc: 84.38%] [G loss: 4.505812]\n",
      "epoch:36 step:28517 [D loss: 0.859045, acc: 50.78%] [G loss: 5.099355]\n",
      "epoch:36 step:28518 [D loss: 0.248790, acc: 89.84%] [G loss: 6.258420]\n",
      "epoch:36 step:28519 [D loss: 0.533696, acc: 60.16%] [G loss: 5.841919]\n",
      "epoch:36 step:28520 [D loss: 0.113730, acc: 100.00%] [G loss: 6.537508]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28521 [D loss: 0.569525, acc: 60.16%] [G loss: 6.749066]\n",
      "epoch:36 step:28522 [D loss: 0.199485, acc: 94.53%] [G loss: 4.308389]\n",
      "epoch:36 step:28523 [D loss: 1.200470, acc: 50.00%] [G loss: 4.555984]\n",
      "epoch:36 step:28524 [D loss: 0.209819, acc: 97.66%] [G loss: 4.014802]\n",
      "epoch:36 step:28525 [D loss: 0.207873, acc: 93.75%] [G loss: 6.245012]\n",
      "epoch:36 step:28526 [D loss: 1.323153, acc: 50.00%] [G loss: 4.157392]\n",
      "epoch:36 step:28527 [D loss: 1.384382, acc: 46.88%] [G loss: 5.928869]\n",
      "epoch:36 step:28528 [D loss: 0.673270, acc: 57.03%] [G loss: 3.607537]\n",
      "epoch:36 step:28529 [D loss: 0.222974, acc: 95.31%] [G loss: 5.679529]\n",
      "epoch:36 step:28530 [D loss: 1.016845, acc: 41.41%] [G loss: 5.681443]\n",
      "epoch:36 step:28531 [D loss: 0.225289, acc: 97.66%] [G loss: 5.527698]\n",
      "epoch:36 step:28532 [D loss: 0.283810, acc: 94.53%] [G loss: 4.777731]\n",
      "epoch:36 step:28533 [D loss: 0.427228, acc: 82.81%] [G loss: 6.900352]\n",
      "epoch:36 step:28534 [D loss: 0.151919, acc: 97.66%] [G loss: 5.259004]\n",
      "epoch:36 step:28535 [D loss: 0.110159, acc: 100.00%] [G loss: 5.628540]\n",
      "epoch:36 step:28536 [D loss: 0.611865, acc: 64.06%] [G loss: 6.394698]\n",
      "epoch:36 step:28537 [D loss: 0.062324, acc: 100.00%] [G loss: 4.219515]\n",
      "epoch:36 step:28538 [D loss: 0.060626, acc: 100.00%] [G loss: 6.156997]\n",
      "epoch:36 step:28539 [D loss: 0.114608, acc: 100.00%] [G loss: 7.149646]\n",
      "epoch:36 step:28540 [D loss: 0.428928, acc: 78.12%] [G loss: 5.968505]\n",
      "epoch:36 step:28541 [D loss: 0.318433, acc: 82.03%] [G loss: 3.600534]\n",
      "epoch:36 step:28542 [D loss: 0.254574, acc: 96.88%] [G loss: 4.465805]\n",
      "epoch:36 step:28543 [D loss: 1.200189, acc: 31.25%] [G loss: 5.573781]\n",
      "epoch:36 step:28544 [D loss: 0.417242, acc: 74.22%] [G loss: 3.950237]\n",
      "epoch:36 step:28545 [D loss: 0.133962, acc: 100.00%] [G loss: 5.042557]\n",
      "epoch:36 step:28546 [D loss: 0.115471, acc: 100.00%] [G loss: 4.994110]\n",
      "epoch:36 step:28547 [D loss: 0.345019, acc: 91.41%] [G loss: 4.707690]\n",
      "epoch:36 step:28548 [D loss: 0.199235, acc: 96.88%] [G loss: 6.067719]\n",
      "epoch:36 step:28549 [D loss: 0.278099, acc: 94.53%] [G loss: 7.401970]\n",
      "epoch:36 step:28550 [D loss: 0.672876, acc: 55.47%] [G loss: 7.672184]\n",
      "epoch:36 step:28551 [D loss: 0.304706, acc: 84.38%] [G loss: 6.642735]\n",
      "epoch:36 step:28552 [D loss: 0.189330, acc: 92.97%] [G loss: 7.322583]\n",
      "epoch:36 step:28553 [D loss: 1.448114, acc: 42.97%] [G loss: 5.495307]\n",
      "epoch:36 step:28554 [D loss: 1.640771, acc: 50.00%] [G loss: 6.214615]\n",
      "epoch:36 step:28555 [D loss: 0.101004, acc: 100.00%] [G loss: 4.761747]\n",
      "epoch:36 step:28556 [D loss: 0.340531, acc: 79.69%] [G loss: 6.536835]\n",
      "epoch:36 step:28557 [D loss: 0.273676, acc: 89.84%] [G loss: 4.200961]\n",
      "epoch:36 step:28558 [D loss: 0.256407, acc: 91.41%] [G loss: 5.159782]\n",
      "epoch:36 step:28559 [D loss: 0.717633, acc: 54.69%] [G loss: 7.027812]\n",
      "epoch:36 step:28560 [D loss: 0.027322, acc: 100.00%] [G loss: 5.581603]\n",
      "epoch:36 step:28561 [D loss: 0.862111, acc: 53.91%] [G loss: 6.935287]\n",
      "epoch:36 step:28562 [D loss: 0.323742, acc: 82.81%] [G loss: 7.726145]\n",
      "epoch:36 step:28563 [D loss: 0.190202, acc: 97.66%] [G loss: 6.874182]\n",
      "epoch:36 step:28564 [D loss: 0.145816, acc: 99.22%] [G loss: 6.398076]\n",
      "epoch:36 step:28565 [D loss: 0.331841, acc: 88.28%] [G loss: 6.135354]\n",
      "epoch:36 step:28566 [D loss: 0.055625, acc: 100.00%] [G loss: 4.652026]\n",
      "epoch:36 step:28567 [D loss: 0.316919, acc: 89.84%] [G loss: 7.249610]\n",
      "epoch:36 step:28568 [D loss: 0.174651, acc: 97.66%] [G loss: 7.527363]\n",
      "epoch:36 step:28569 [D loss: 0.293282, acc: 90.62%] [G loss: 6.673338]\n",
      "epoch:36 step:28570 [D loss: 0.208547, acc: 96.88%] [G loss: 3.954880]\n",
      "epoch:36 step:28571 [D loss: 0.408995, acc: 73.44%] [G loss: 10.373991]\n",
      "epoch:36 step:28572 [D loss: 0.316384, acc: 85.94%] [G loss: 5.801528]\n",
      "epoch:36 step:28573 [D loss: 0.121641, acc: 99.22%] [G loss: 4.763113]\n",
      "epoch:36 step:28574 [D loss: 0.156658, acc: 98.44%] [G loss: 6.357616]\n",
      "epoch:36 step:28575 [D loss: 0.644323, acc: 62.50%] [G loss: 4.344753]\n",
      "epoch:36 step:28576 [D loss: 0.084227, acc: 100.00%] [G loss: 3.978703]\n",
      "epoch:36 step:28577 [D loss: 0.081184, acc: 100.00%] [G loss: 7.203236]\n",
      "epoch:36 step:28578 [D loss: 0.187863, acc: 96.09%] [G loss: 6.708364]\n",
      "epoch:36 step:28579 [D loss: 1.095740, acc: 42.19%] [G loss: 4.955493]\n",
      "epoch:36 step:28580 [D loss: 0.129652, acc: 100.00%] [G loss: 5.280209]\n",
      "epoch:36 step:28581 [D loss: 0.110626, acc: 98.44%] [G loss: 3.822764]\n",
      "epoch:36 step:28582 [D loss: 0.061859, acc: 100.00%] [G loss: 5.990285]\n",
      "epoch:36 step:28583 [D loss: 0.941074, acc: 33.59%] [G loss: 4.760095]\n",
      "epoch:36 step:28584 [D loss: 0.476232, acc: 78.12%] [G loss: 6.180606]\n",
      "epoch:36 step:28585 [D loss: 0.475655, acc: 68.75%] [G loss: 5.523966]\n",
      "epoch:36 step:28586 [D loss: 0.033374, acc: 100.00%] [G loss: 5.368604]\n",
      "epoch:36 step:28587 [D loss: 0.824952, acc: 42.97%] [G loss: 2.858835]\n",
      "epoch:36 step:28588 [D loss: 0.073662, acc: 98.44%] [G loss: 6.424070]\n",
      "epoch:36 step:28589 [D loss: 0.974732, acc: 44.53%] [G loss: 5.803255]\n",
      "epoch:36 step:28590 [D loss: 0.246466, acc: 96.09%] [G loss: 3.848324]\n",
      "epoch:36 step:28591 [D loss: 0.489540, acc: 67.19%] [G loss: 1.701540]\n",
      "epoch:36 step:28592 [D loss: 0.102458, acc: 98.44%] [G loss: 5.260669]\n",
      "epoch:36 step:28593 [D loss: 0.129716, acc: 100.00%] [G loss: 3.519442]\n",
      "epoch:36 step:28594 [D loss: 0.886705, acc: 50.78%] [G loss: 3.483495]\n",
      "epoch:36 step:28595 [D loss: 0.171605, acc: 96.09%] [G loss: 5.544763]\n",
      "epoch:36 step:28596 [D loss: 0.442031, acc: 72.66%] [G loss: 7.170240]\n",
      "epoch:36 step:28597 [D loss: 1.576969, acc: 46.88%] [G loss: 8.458550]\n",
      "epoch:36 step:28598 [D loss: 0.453084, acc: 71.88%] [G loss: 5.785182]\n",
      "epoch:36 step:28599 [D loss: 0.101475, acc: 100.00%] [G loss: 7.174970]\n",
      "epoch:36 step:28600 [D loss: 0.311748, acc: 85.94%] [G loss: 4.367692]\n",
      "epoch:36 step:28601 [D loss: 0.257369, acc: 96.88%] [G loss: 4.234227]\n",
      "epoch:36 step:28602 [D loss: 0.576803, acc: 64.06%] [G loss: 5.543207]\n",
      "epoch:36 step:28603 [D loss: 0.146214, acc: 96.88%] [G loss: 4.064741]\n",
      "epoch:36 step:28604 [D loss: 0.333479, acc: 82.03%] [G loss: 3.917701]\n",
      "epoch:36 step:28605 [D loss: 0.254856, acc: 96.88%] [G loss: 3.030968]\n",
      "epoch:36 step:28606 [D loss: 0.051061, acc: 100.00%] [G loss: 5.260442]\n",
      "epoch:36 step:28607 [D loss: 0.124268, acc: 99.22%] [G loss: 3.370967]\n",
      "epoch:36 step:28608 [D loss: 0.243834, acc: 92.97%] [G loss: 5.911121]\n",
      "epoch:36 step:28609 [D loss: 0.394512, acc: 82.03%] [G loss: 4.542774]\n",
      "epoch:36 step:28610 [D loss: 0.131312, acc: 100.00%] [G loss: 6.237901]\n",
      "epoch:36 step:28611 [D loss: 0.348572, acc: 92.19%] [G loss: 4.556838]\n",
      "epoch:36 step:28612 [D loss: 0.806566, acc: 53.12%] [G loss: 4.669569]\n",
      "epoch:36 step:28613 [D loss: 0.035757, acc: 100.00%] [G loss: 7.054065]\n",
      "epoch:36 step:28614 [D loss: 0.423485, acc: 75.00%] [G loss: 5.371076]\n",
      "epoch:36 step:28615 [D loss: 1.565645, acc: 28.91%] [G loss: 4.456263]\n",
      "epoch:36 step:28616 [D loss: 0.265820, acc: 93.75%] [G loss: 4.029096]\n",
      "epoch:36 step:28617 [D loss: 0.209958, acc: 96.88%] [G loss: 5.104918]\n",
      "epoch:36 step:28618 [D loss: 0.550200, acc: 68.75%] [G loss: 6.356545]\n",
      "epoch:36 step:28619 [D loss: 0.125784, acc: 99.22%] [G loss: 5.909345]\n",
      "epoch:36 step:28620 [D loss: 0.717754, acc: 57.03%] [G loss: 6.802252]\n",
      "epoch:36 step:28621 [D loss: 1.127122, acc: 46.09%] [G loss: 3.380102]\n",
      "epoch:36 step:28622 [D loss: 0.021739, acc: 100.00%] [G loss: 5.348907]\n",
      "epoch:36 step:28623 [D loss: 0.164328, acc: 99.22%] [G loss: 6.550631]\n",
      "epoch:36 step:28624 [D loss: 0.084830, acc: 100.00%] [G loss: 5.936574]\n",
      "epoch:36 step:28625 [D loss: 0.538712, acc: 65.62%] [G loss: 5.749015]\n",
      "epoch:36 step:28626 [D loss: 0.264608, acc: 88.28%] [G loss: 4.482571]\n",
      "epoch:36 step:28627 [D loss: 0.412195, acc: 71.88%] [G loss: 5.986650]\n",
      "epoch:36 step:28628 [D loss: 0.719963, acc: 57.03%] [G loss: 6.686627]\n",
      "epoch:36 step:28629 [D loss: 0.476261, acc: 69.53%] [G loss: 2.838417]\n",
      "epoch:36 step:28630 [D loss: 0.349689, acc: 82.03%] [G loss: 5.819142]\n",
      "epoch:36 step:28631 [D loss: 0.164740, acc: 99.22%] [G loss: 3.748665]\n",
      "epoch:36 step:28632 [D loss: 0.377700, acc: 82.81%] [G loss: 6.229907]\n",
      "epoch:36 step:28633 [D loss: 0.253892, acc: 92.19%] [G loss: 6.216110]\n",
      "epoch:36 step:28634 [D loss: 0.816225, acc: 52.34%] [G loss: 3.696939]\n",
      "epoch:36 step:28635 [D loss: 0.153452, acc: 99.22%] [G loss: 5.302526]\n",
      "epoch:36 step:28636 [D loss: 1.940553, acc: 50.00%] [G loss: 7.645706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28637 [D loss: 0.352825, acc: 80.47%] [G loss: 6.774184]\n",
      "epoch:36 step:28638 [D loss: 0.055612, acc: 100.00%] [G loss: 6.497805]\n",
      "epoch:36 step:28639 [D loss: 0.222940, acc: 96.09%] [G loss: 4.210510]\n",
      "epoch:36 step:28640 [D loss: 0.318849, acc: 91.41%] [G loss: 4.802258]\n",
      "epoch:36 step:28641 [D loss: 0.120572, acc: 99.22%] [G loss: 5.079172]\n",
      "epoch:36 step:28642 [D loss: 0.540698, acc: 76.56%] [G loss: 5.728763]\n",
      "epoch:36 step:28643 [D loss: 0.083058, acc: 100.00%] [G loss: 3.518275]\n",
      "epoch:36 step:28644 [D loss: 0.376151, acc: 88.28%] [G loss: 4.417886]\n",
      "epoch:36 step:28645 [D loss: 0.139758, acc: 98.44%] [G loss: 4.380079]\n",
      "epoch:36 step:28646 [D loss: 0.408730, acc: 84.38%] [G loss: 4.403638]\n",
      "epoch:36 step:28647 [D loss: 0.637653, acc: 57.81%] [G loss: 6.054449]\n",
      "epoch:36 step:28648 [D loss: 0.334137, acc: 83.59%] [G loss: 5.377873]\n",
      "epoch:36 step:28649 [D loss: 0.531779, acc: 73.44%] [G loss: 4.729070]\n",
      "epoch:36 step:28650 [D loss: 0.571075, acc: 62.50%] [G loss: 5.147795]\n",
      "epoch:36 step:28651 [D loss: 0.203402, acc: 99.22%] [G loss: 4.338642]\n",
      "epoch:36 step:28652 [D loss: 0.068590, acc: 100.00%] [G loss: 6.806013]\n",
      "epoch:36 step:28653 [D loss: 0.081610, acc: 99.22%] [G loss: 6.512531]\n",
      "epoch:36 step:28654 [D loss: 0.093121, acc: 99.22%] [G loss: 5.780100]\n",
      "epoch:36 step:28655 [D loss: 0.199056, acc: 95.31%] [G loss: 7.161108]\n",
      "epoch:36 step:28656 [D loss: 0.554985, acc: 68.75%] [G loss: 6.563826]\n",
      "epoch:36 step:28657 [D loss: 0.096648, acc: 98.44%] [G loss: 4.270847]\n",
      "epoch:36 step:28658 [D loss: 0.894567, acc: 36.72%] [G loss: 6.379608]\n",
      "epoch:36 step:28659 [D loss: 0.333130, acc: 94.53%] [G loss: 5.438121]\n",
      "epoch:36 step:28660 [D loss: 0.448665, acc: 83.59%] [G loss: 4.317831]\n",
      "epoch:36 step:28661 [D loss: 0.374316, acc: 77.34%] [G loss: 6.106327]\n",
      "epoch:36 step:28662 [D loss: 0.192297, acc: 100.00%] [G loss: 5.874424]\n",
      "epoch:36 step:28663 [D loss: 0.432560, acc: 70.31%] [G loss: 7.091686]\n",
      "epoch:36 step:28664 [D loss: 0.147390, acc: 98.44%] [G loss: 4.774003]\n",
      "epoch:36 step:28665 [D loss: 0.270924, acc: 95.31%] [G loss: 3.424349]\n",
      "epoch:36 step:28666 [D loss: 0.082293, acc: 100.00%] [G loss: 5.924495]\n",
      "epoch:36 step:28667 [D loss: 0.226000, acc: 97.66%] [G loss: 4.794335]\n",
      "epoch:36 step:28668 [D loss: 0.416262, acc: 85.16%] [G loss: 4.029023]\n",
      "epoch:36 step:28669 [D loss: 0.102457, acc: 100.00%] [G loss: 2.184225]\n",
      "epoch:36 step:28670 [D loss: 0.033766, acc: 100.00%] [G loss: 7.432442]\n",
      "epoch:36 step:28671 [D loss: 0.331506, acc: 80.47%] [G loss: 3.303726]\n",
      "epoch:36 step:28672 [D loss: 0.331455, acc: 91.41%] [G loss: 3.018263]\n",
      "epoch:36 step:28673 [D loss: 0.279816, acc: 96.09%] [G loss: 4.044158]\n",
      "epoch:36 step:28674 [D loss: 0.323281, acc: 92.97%] [G loss: 5.977226]\n",
      "epoch:36 step:28675 [D loss: 0.058436, acc: 100.00%] [G loss: 5.632598]\n",
      "epoch:36 step:28676 [D loss: 0.159082, acc: 99.22%] [G loss: 8.062427]\n",
      "epoch:36 step:28677 [D loss: 0.556841, acc: 67.19%] [G loss: 4.033624]\n",
      "epoch:36 step:28678 [D loss: 0.260423, acc: 92.19%] [G loss: 5.562768]\n",
      "epoch:36 step:28679 [D loss: 0.325886, acc: 91.41%] [G loss: 5.021649]\n",
      "epoch:36 step:28680 [D loss: 0.323772, acc: 91.41%] [G loss: 5.287330]\n",
      "epoch:36 step:28681 [D loss: 0.177177, acc: 99.22%] [G loss: 7.025762]\n",
      "epoch:36 step:28682 [D loss: 0.332798, acc: 84.38%] [G loss: 5.787143]\n",
      "epoch:36 step:28683 [D loss: 0.157899, acc: 98.44%] [G loss: 5.596018]\n",
      "epoch:36 step:28684 [D loss: 0.645367, acc: 58.59%] [G loss: 3.809851]\n",
      "epoch:36 step:28685 [D loss: 0.201084, acc: 96.09%] [G loss: 6.678239]\n",
      "epoch:36 step:28686 [D loss: 0.190929, acc: 97.66%] [G loss: 5.156816]\n",
      "epoch:36 step:28687 [D loss: 0.283102, acc: 90.62%] [G loss: 5.765612]\n",
      "epoch:36 step:28688 [D loss: 0.609191, acc: 57.03%] [G loss: 5.824837]\n",
      "epoch:36 step:28689 [D loss: 0.068617, acc: 100.00%] [G loss: 5.417302]\n",
      "epoch:36 step:28690 [D loss: 1.189047, acc: 50.78%] [G loss: 5.698061]\n",
      "epoch:36 step:28691 [D loss: 0.553136, acc: 76.56%] [G loss: 6.621537]\n",
      "epoch:36 step:28692 [D loss: 0.034433, acc: 100.00%] [G loss: 4.952779]\n",
      "epoch:36 step:28693 [D loss: 0.391796, acc: 76.56%] [G loss: 7.799341]\n",
      "epoch:36 step:28694 [D loss: 0.104031, acc: 99.22%] [G loss: 4.928157]\n",
      "epoch:36 step:28695 [D loss: 0.334718, acc: 89.06%] [G loss: 5.808543]\n",
      "epoch:36 step:28696 [D loss: 0.201350, acc: 95.31%] [G loss: 6.590356]\n",
      "epoch:36 step:28697 [D loss: 0.363962, acc: 78.12%] [G loss: 4.329141]\n",
      "epoch:36 step:28698 [D loss: 0.211351, acc: 99.22%] [G loss: 5.664837]\n",
      "epoch:36 step:28699 [D loss: 0.152193, acc: 98.44%] [G loss: 4.376612]\n",
      "epoch:36 step:28700 [D loss: 0.862024, acc: 55.47%] [G loss: 6.729587]\n",
      "epoch:36 step:28701 [D loss: 0.330137, acc: 88.28%] [G loss: 6.224537]\n",
      "epoch:36 step:28702 [D loss: 0.336656, acc: 84.38%] [G loss: 5.226274]\n",
      "epoch:36 step:28703 [D loss: 0.021313, acc: 100.00%] [G loss: 7.128645]\n",
      "epoch:36 step:28704 [D loss: 0.820418, acc: 53.12%] [G loss: 4.914965]\n",
      "epoch:36 step:28705 [D loss: 0.794883, acc: 44.53%] [G loss: 5.206244]\n",
      "epoch:36 step:28706 [D loss: 0.193819, acc: 95.31%] [G loss: 5.526261]\n",
      "epoch:36 step:28707 [D loss: 0.190422, acc: 96.09%] [G loss: 5.072422]\n",
      "epoch:36 step:28708 [D loss: 0.085568, acc: 100.00%] [G loss: 5.614896]\n",
      "epoch:36 step:28709 [D loss: 0.953796, acc: 50.00%] [G loss: 9.109604]\n",
      "epoch:36 step:28710 [D loss: 1.830515, acc: 49.22%] [G loss: 3.735732]\n",
      "epoch:36 step:28711 [D loss: 0.296045, acc: 92.97%] [G loss: 3.550459]\n",
      "epoch:36 step:28712 [D loss: 0.157826, acc: 99.22%] [G loss: 3.474366]\n",
      "epoch:36 step:28713 [D loss: 0.127589, acc: 98.44%] [G loss: 4.390968]\n",
      "epoch:36 step:28714 [D loss: 0.358370, acc: 79.69%] [G loss: 3.967616]\n",
      "epoch:36 step:28715 [D loss: 2.615220, acc: 46.09%] [G loss: 5.046473]\n",
      "epoch:36 step:28716 [D loss: 0.260438, acc: 97.66%] [G loss: 3.439921]\n",
      "epoch:36 step:28717 [D loss: 0.377920, acc: 91.41%] [G loss: 8.459167]\n",
      "epoch:36 step:28718 [D loss: 0.489128, acc: 80.47%] [G loss: 4.083526]\n",
      "epoch:36 step:28719 [D loss: 0.248240, acc: 89.84%] [G loss: 4.304139]\n",
      "epoch:36 step:28720 [D loss: 0.069359, acc: 100.00%] [G loss: 3.554184]\n",
      "epoch:36 step:28721 [D loss: 0.223100, acc: 95.31%] [G loss: 5.695411]\n",
      "epoch:36 step:28722 [D loss: 0.503365, acc: 77.34%] [G loss: 6.416910]\n",
      "epoch:36 step:28723 [D loss: 1.503930, acc: 48.44%] [G loss: 1.747876]\n",
      "epoch:36 step:28724 [D loss: 0.209606, acc: 96.09%] [G loss: 5.040337]\n",
      "epoch:36 step:28725 [D loss: 0.266862, acc: 88.28%] [G loss: 6.608033]\n",
      "epoch:36 step:28726 [D loss: 0.202771, acc: 96.09%] [G loss: 4.991586]\n",
      "epoch:36 step:28727 [D loss: 0.343403, acc: 89.84%] [G loss: 7.064087]\n",
      "epoch:36 step:28728 [D loss: 0.248357, acc: 89.84%] [G loss: 3.737339]\n",
      "epoch:36 step:28729 [D loss: 0.736549, acc: 58.59%] [G loss: 4.631312]\n",
      "epoch:36 step:28730 [D loss: 0.786183, acc: 52.34%] [G loss: 8.919829]\n",
      "epoch:36 step:28731 [D loss: 0.070896, acc: 100.00%] [G loss: 6.440128]\n",
      "epoch:36 step:28732 [D loss: 1.040682, acc: 33.59%] [G loss: 7.260333]\n",
      "epoch:36 step:28733 [D loss: 0.178261, acc: 96.88%] [G loss: 4.619554]\n",
      "epoch:36 step:28734 [D loss: 0.507209, acc: 74.22%] [G loss: 7.581237]\n",
      "epoch:36 step:28735 [D loss: 0.624503, acc: 66.41%] [G loss: 5.631879]\n",
      "epoch:36 step:28736 [D loss: 0.629840, acc: 58.59%] [G loss: 4.355259]\n",
      "epoch:36 step:28737 [D loss: 0.188815, acc: 97.66%] [G loss: 3.835684]\n",
      "epoch:36 step:28738 [D loss: 0.563784, acc: 76.56%] [G loss: 3.860249]\n",
      "epoch:36 step:28739 [D loss: 0.480336, acc: 76.56%] [G loss: 4.758936]\n",
      "epoch:36 step:28740 [D loss: 0.111967, acc: 100.00%] [G loss: 5.684613]\n",
      "epoch:36 step:28741 [D loss: 0.256200, acc: 97.66%] [G loss: 2.542798]\n",
      "epoch:36 step:28742 [D loss: 0.578172, acc: 68.75%] [G loss: 4.191448]\n",
      "epoch:36 step:28743 [D loss: 0.351753, acc: 94.53%] [G loss: 6.743044]\n",
      "epoch:36 step:28744 [D loss: 0.276235, acc: 90.62%] [G loss: 3.658306]\n",
      "epoch:36 step:28745 [D loss: 0.192730, acc: 99.22%] [G loss: 5.512784]\n",
      "epoch:36 step:28746 [D loss: 0.246828, acc: 92.97%] [G loss: 6.187986]\n",
      "epoch:36 step:28747 [D loss: 0.244388, acc: 92.97%] [G loss: 6.645171]\n",
      "epoch:36 step:28748 [D loss: 0.372132, acc: 86.72%] [G loss: 4.090384]\n",
      "epoch:36 step:28749 [D loss: 0.235834, acc: 96.09%] [G loss: 4.258859]\n",
      "epoch:36 step:28750 [D loss: 0.411303, acc: 77.34%] [G loss: 3.927327]\n",
      "epoch:36 step:28751 [D loss: 0.559491, acc: 74.22%] [G loss: 4.587632]\n",
      "epoch:36 step:28752 [D loss: 0.222783, acc: 96.09%] [G loss: 4.895958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28753 [D loss: 0.325419, acc: 81.25%] [G loss: 3.616889]\n",
      "epoch:36 step:28754 [D loss: 0.217239, acc: 94.53%] [G loss: 4.746806]\n",
      "epoch:36 step:28755 [D loss: 0.618973, acc: 61.72%] [G loss: 7.068261]\n",
      "epoch:36 step:28756 [D loss: 0.349785, acc: 82.81%] [G loss: 5.278716]\n",
      "epoch:36 step:28757 [D loss: 0.107530, acc: 100.00%] [G loss: 3.305269]\n",
      "epoch:36 step:28758 [D loss: 0.364466, acc: 85.94%] [G loss: 7.527545]\n",
      "epoch:36 step:28759 [D loss: 0.577958, acc: 70.31%] [G loss: 3.616143]\n",
      "epoch:36 step:28760 [D loss: 0.704340, acc: 58.59%] [G loss: 4.798616]\n",
      "epoch:36 step:28761 [D loss: 0.800606, acc: 54.69%] [G loss: 7.110681]\n",
      "epoch:36 step:28762 [D loss: 0.165562, acc: 96.09%] [G loss: 3.614380]\n",
      "epoch:36 step:28763 [D loss: 0.359138, acc: 79.69%] [G loss: 4.189673]\n",
      "epoch:36 step:28764 [D loss: 1.193801, acc: 38.28%] [G loss: 7.186538]\n",
      "epoch:36 step:28765 [D loss: 0.193632, acc: 96.88%] [G loss: 4.790463]\n",
      "epoch:36 step:28766 [D loss: 0.141875, acc: 98.44%] [G loss: 6.481704]\n",
      "epoch:36 step:28767 [D loss: 0.021538, acc: 100.00%] [G loss: 4.409173]\n",
      "epoch:36 step:28768 [D loss: 0.085778, acc: 100.00%] [G loss: 6.264677]\n",
      "epoch:36 step:28769 [D loss: 0.621865, acc: 59.38%] [G loss: 4.742396]\n",
      "epoch:36 step:28770 [D loss: 0.169035, acc: 99.22%] [G loss: 2.751529]\n",
      "epoch:36 step:28771 [D loss: 0.122707, acc: 99.22%] [G loss: 3.428452]\n",
      "epoch:36 step:28772 [D loss: 1.039573, acc: 50.00%] [G loss: 6.054716]\n",
      "epoch:36 step:28773 [D loss: 0.154200, acc: 96.09%] [G loss: 9.095230]\n",
      "epoch:36 step:28774 [D loss: 0.261354, acc: 92.19%] [G loss: 4.665989]\n",
      "epoch:36 step:28775 [D loss: 0.369677, acc: 89.84%] [G loss: 6.753602]\n",
      "epoch:36 step:28776 [D loss: 0.372160, acc: 75.00%] [G loss: 7.001286]\n",
      "epoch:36 step:28777 [D loss: 0.377918, acc: 79.69%] [G loss: 5.962376]\n",
      "epoch:36 step:28778 [D loss: 0.133887, acc: 99.22%] [G loss: 4.555302]\n",
      "epoch:36 step:28779 [D loss: 0.416689, acc: 86.72%] [G loss: 5.703878]\n",
      "epoch:36 step:28780 [D loss: 0.100459, acc: 99.22%] [G loss: 6.462755]\n",
      "epoch:36 step:28781 [D loss: 0.656053, acc: 57.03%] [G loss: 4.542706]\n",
      "epoch:36 step:28782 [D loss: 0.203201, acc: 96.88%] [G loss: 3.870409]\n",
      "epoch:36 step:28783 [D loss: 0.633003, acc: 58.59%] [G loss: 6.564539]\n",
      "epoch:36 step:28784 [D loss: 0.333048, acc: 89.06%] [G loss: 3.440325]\n",
      "epoch:36 step:28785 [D loss: 0.540508, acc: 75.78%] [G loss: 4.888358]\n",
      "epoch:36 step:28786 [D loss: 0.311980, acc: 91.41%] [G loss: 7.047520]\n",
      "epoch:36 step:28787 [D loss: 0.276176, acc: 89.06%] [G loss: 4.776245]\n",
      "epoch:36 step:28788 [D loss: 1.425880, acc: 45.31%] [G loss: 5.203140]\n",
      "epoch:36 step:28789 [D loss: 0.201561, acc: 98.44%] [G loss: 4.440023]\n",
      "epoch:36 step:28790 [D loss: 0.661911, acc: 60.16%] [G loss: 4.166542]\n",
      "epoch:36 step:28791 [D loss: 0.112047, acc: 99.22%] [G loss: 3.966216]\n",
      "epoch:36 step:28792 [D loss: 0.207169, acc: 97.66%] [G loss: 3.308565]\n",
      "epoch:36 step:28793 [D loss: 0.115867, acc: 98.44%] [G loss: 5.564276]\n",
      "epoch:36 step:28794 [D loss: 0.322957, acc: 94.53%] [G loss: 4.403209]\n",
      "epoch:36 step:28795 [D loss: 0.596096, acc: 64.84%] [G loss: 5.212753]\n",
      "epoch:36 step:28796 [D loss: 0.605437, acc: 67.97%] [G loss: 6.095433]\n",
      "epoch:36 step:28797 [D loss: 0.222171, acc: 94.53%] [G loss: 5.588783]\n",
      "epoch:36 step:28798 [D loss: 0.846137, acc: 55.47%] [G loss: 4.691231]\n",
      "epoch:36 step:28799 [D loss: 0.567712, acc: 61.72%] [G loss: 4.945253]\n",
      "epoch:36 step:28800 [D loss: 0.366252, acc: 91.41%] [G loss: 3.934313]\n",
      "epoch:36 step:28801 [D loss: 0.140935, acc: 99.22%] [G loss: 2.344668]\n",
      "epoch:36 step:28802 [D loss: 0.054538, acc: 100.00%] [G loss: 5.768973]\n",
      "epoch:36 step:28803 [D loss: 0.441368, acc: 72.66%] [G loss: 3.560721]\n",
      "epoch:36 step:28804 [D loss: 0.054279, acc: 100.00%] [G loss: 8.111901]\n",
      "epoch:36 step:28805 [D loss: 1.441988, acc: 11.72%] [G loss: 7.882721]\n",
      "epoch:36 step:28806 [D loss: 0.025089, acc: 100.00%] [G loss: 2.486648]\n",
      "epoch:36 step:28807 [D loss: 0.272241, acc: 92.19%] [G loss: 7.890686]\n",
      "epoch:36 step:28808 [D loss: 0.385628, acc: 79.69%] [G loss: 7.844537]\n",
      "epoch:36 step:28809 [D loss: 0.085816, acc: 100.00%] [G loss: 5.490014]\n",
      "epoch:36 step:28810 [D loss: 0.598144, acc: 54.69%] [G loss: 3.812126]\n",
      "epoch:36 step:28811 [D loss: 0.245495, acc: 93.75%] [G loss: 5.299254]\n",
      "epoch:36 step:28812 [D loss: 0.200407, acc: 98.44%] [G loss: 7.673132]\n",
      "epoch:36 step:28813 [D loss: 0.870403, acc: 51.56%] [G loss: 6.968273]\n",
      "epoch:36 step:28814 [D loss: 1.069233, acc: 33.59%] [G loss: 2.507996]\n",
      "epoch:36 step:28815 [D loss: 0.622188, acc: 66.41%] [G loss: 3.816459]\n",
      "epoch:36 step:28816 [D loss: 0.474922, acc: 74.22%] [G loss: 4.601757]\n",
      "epoch:36 step:28817 [D loss: 0.104287, acc: 98.44%] [G loss: 3.499331]\n",
      "epoch:36 step:28818 [D loss: 0.296137, acc: 92.97%] [G loss: 5.317496]\n",
      "epoch:36 step:28819 [D loss: 0.060594, acc: 100.00%] [G loss: 6.618145]\n",
      "epoch:36 step:28820 [D loss: 0.219540, acc: 94.53%] [G loss: 4.685219]\n",
      "epoch:36 step:28821 [D loss: 0.195976, acc: 96.88%] [G loss: 3.868987]\n",
      "epoch:36 step:28822 [D loss: 0.391240, acc: 84.38%] [G loss: 4.812335]\n",
      "epoch:36 step:28823 [D loss: 0.049836, acc: 100.00%] [G loss: 4.025986]\n",
      "epoch:36 step:28824 [D loss: 0.057512, acc: 100.00%] [G loss: 3.292917]\n",
      "epoch:36 step:28825 [D loss: 0.106842, acc: 100.00%] [G loss: 9.714832]\n",
      "epoch:36 step:28826 [D loss: 0.815293, acc: 51.56%] [G loss: 4.348029]\n",
      "epoch:36 step:28827 [D loss: 0.014032, acc: 100.00%] [G loss: 8.423064]\n",
      "epoch:36 step:28828 [D loss: 0.169196, acc: 97.66%] [G loss: 5.647899]\n",
      "epoch:36 step:28829 [D loss: 0.277499, acc: 96.09%] [G loss: 7.324200]\n",
      "epoch:36 step:28830 [D loss: 0.327897, acc: 92.19%] [G loss: 3.673285]\n",
      "epoch:36 step:28831 [D loss: 0.724552, acc: 56.25%] [G loss: 5.244116]\n",
      "epoch:36 step:28832 [D loss: 0.413197, acc: 74.22%] [G loss: 7.355645]\n",
      "epoch:36 step:28833 [D loss: 1.656016, acc: 50.00%] [G loss: 4.771016]\n",
      "epoch:36 step:28834 [D loss: 0.389390, acc: 89.06%] [G loss: 2.373711]\n",
      "epoch:36 step:28835 [D loss: 0.202187, acc: 96.88%] [G loss: 4.110515]\n",
      "epoch:36 step:28836 [D loss: 0.476502, acc: 79.69%] [G loss: 2.522632]\n",
      "epoch:36 step:28837 [D loss: 0.286553, acc: 87.50%] [G loss: 4.540219]\n",
      "epoch:36 step:28838 [D loss: 0.252393, acc: 97.66%] [G loss: 5.638771]\n",
      "epoch:36 step:28839 [D loss: 0.106254, acc: 99.22%] [G loss: 6.058166]\n",
      "epoch:36 step:28840 [D loss: 0.320867, acc: 89.84%] [G loss: 4.733211]\n",
      "epoch:36 step:28841 [D loss: 0.456578, acc: 77.34%] [G loss: 3.392445]\n",
      "epoch:36 step:28842 [D loss: 0.196537, acc: 94.53%] [G loss: 4.145195]\n",
      "epoch:36 step:28843 [D loss: 0.513328, acc: 68.75%] [G loss: 5.733802]\n",
      "epoch:36 step:28844 [D loss: 2.706204, acc: 1.56%] [G loss: 5.630905]\n",
      "epoch:36 step:28845 [D loss: 0.156596, acc: 96.88%] [G loss: 4.188927]\n",
      "epoch:36 step:28846 [D loss: 0.657615, acc: 59.38%] [G loss: 3.980183]\n",
      "epoch:36 step:28847 [D loss: 1.667295, acc: 49.22%] [G loss: 4.636920]\n",
      "epoch:36 step:28848 [D loss: 1.176587, acc: 47.66%] [G loss: 5.338892]\n",
      "epoch:36 step:28849 [D loss: 0.327683, acc: 88.28%] [G loss: 4.125517]\n",
      "epoch:36 step:28850 [D loss: 1.597618, acc: 10.94%] [G loss: 7.220111]\n",
      "epoch:36 step:28851 [D loss: 0.464643, acc: 67.19%] [G loss: 4.338786]\n",
      "epoch:36 step:28852 [D loss: 0.573390, acc: 57.81%] [G loss: 6.421502]\n",
      "epoch:36 step:28853 [D loss: 0.313534, acc: 82.81%] [G loss: 6.379954]\n",
      "epoch:36 step:28854 [D loss: 0.162088, acc: 99.22%] [G loss: 4.276339]\n",
      "epoch:36 step:28855 [D loss: 0.375027, acc: 86.72%] [G loss: 3.474007]\n",
      "epoch:36 step:28856 [D loss: 0.163445, acc: 96.88%] [G loss: 7.349781]\n",
      "epoch:36 step:28857 [D loss: 0.338362, acc: 84.38%] [G loss: 6.082725]\n",
      "epoch:36 step:28858 [D loss: 0.233162, acc: 97.66%] [G loss: 3.873330]\n",
      "epoch:36 step:28859 [D loss: 0.356195, acc: 92.19%] [G loss: 4.879406]\n",
      "epoch:36 step:28860 [D loss: 0.176829, acc: 98.44%] [G loss: 4.102415]\n",
      "epoch:36 step:28861 [D loss: 0.596379, acc: 67.19%] [G loss: 5.070066]\n",
      "epoch:36 step:28862 [D loss: 0.305964, acc: 90.62%] [G loss: 8.244980]\n",
      "epoch:36 step:28863 [D loss: 0.216970, acc: 95.31%] [G loss: 5.792101]\n",
      "epoch:36 step:28864 [D loss: 0.264900, acc: 92.97%] [G loss: 5.231956]\n",
      "epoch:36 step:28865 [D loss: 0.109329, acc: 99.22%] [G loss: 3.950383]\n",
      "epoch:36 step:28866 [D loss: 1.070443, acc: 23.44%] [G loss: 3.635909]\n",
      "epoch:36 step:28867 [D loss: 0.503346, acc: 81.25%] [G loss: 5.339060]\n",
      "epoch:36 step:28868 [D loss: 0.695435, acc: 53.91%] [G loss: 6.125536]\n",
      "epoch:36 step:28869 [D loss: 0.481701, acc: 74.22%] [G loss: 6.386209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28870 [D loss: 0.371585, acc: 82.03%] [G loss: 5.431084]\n",
      "epoch:36 step:28871 [D loss: 0.653481, acc: 59.38%] [G loss: 5.219692]\n",
      "epoch:36 step:28872 [D loss: 0.596495, acc: 64.06%] [G loss: 4.876523]\n",
      "epoch:36 step:28873 [D loss: 0.997651, acc: 50.78%] [G loss: 6.049312]\n",
      "epoch:36 step:28874 [D loss: 0.058705, acc: 100.00%] [G loss: 3.601120]\n",
      "epoch:36 step:28875 [D loss: 0.207846, acc: 95.31%] [G loss: 4.861358]\n",
      "epoch:36 step:28876 [D loss: 0.295137, acc: 86.72%] [G loss: 6.749784]\n",
      "epoch:36 step:28877 [D loss: 0.019508, acc: 100.00%] [G loss: 7.371501]\n",
      "epoch:36 step:28878 [D loss: 0.338977, acc: 85.94%] [G loss: 3.664802]\n",
      "epoch:36 step:28879 [D loss: 0.849960, acc: 48.44%] [G loss: 5.992752]\n",
      "epoch:36 step:28880 [D loss: 0.246093, acc: 89.06%] [G loss: 5.754625]\n",
      "epoch:36 step:28881 [D loss: 1.496349, acc: 46.88%] [G loss: 5.524550]\n",
      "epoch:36 step:28882 [D loss: 0.228508, acc: 92.19%] [G loss: 4.447126]\n",
      "epoch:36 step:28883 [D loss: 0.769953, acc: 53.91%] [G loss: 7.427937]\n",
      "epoch:36 step:28884 [D loss: 0.234987, acc: 97.66%] [G loss: 6.408081]\n",
      "epoch:36 step:28885 [D loss: 1.031748, acc: 53.12%] [G loss: 7.874837]\n",
      "epoch:36 step:28886 [D loss: 0.049810, acc: 100.00%] [G loss: 4.877062]\n",
      "epoch:36 step:28887 [D loss: 0.694352, acc: 56.25%] [G loss: 4.650415]\n",
      "epoch:36 step:28888 [D loss: 0.661732, acc: 64.06%] [G loss: 6.741474]\n",
      "epoch:36 step:28889 [D loss: 0.008845, acc: 100.00%] [G loss: 8.118843]\n",
      "epoch:36 step:28890 [D loss: 0.066991, acc: 100.00%] [G loss: 6.565572]\n",
      "epoch:36 step:28891 [D loss: 0.222254, acc: 96.88%] [G loss: 4.425069]\n",
      "epoch:36 step:28892 [D loss: 0.663926, acc: 60.94%] [G loss: 7.186345]\n",
      "epoch:36 step:28893 [D loss: 0.190566, acc: 97.66%] [G loss: 6.345667]\n",
      "epoch:36 step:28894 [D loss: 0.497765, acc: 71.09%] [G loss: 6.018165]\n",
      "epoch:36 step:28895 [D loss: 0.094882, acc: 100.00%] [G loss: 3.677276]\n",
      "epoch:36 step:28896 [D loss: 1.023957, acc: 41.41%] [G loss: 4.513605]\n",
      "epoch:36 step:28897 [D loss: 1.498520, acc: 5.47%] [G loss: 4.331741]\n",
      "epoch:37 step:28898 [D loss: 0.554013, acc: 59.38%] [G loss: 4.727350]\n",
      "epoch:37 step:28899 [D loss: 1.586245, acc: 5.47%] [G loss: 5.882476]\n",
      "epoch:37 step:28900 [D loss: 0.300558, acc: 92.19%] [G loss: 4.605284]\n",
      "epoch:37 step:28901 [D loss: 0.246540, acc: 91.41%] [G loss: 5.187463]\n",
      "epoch:37 step:28902 [D loss: 0.676129, acc: 58.59%] [G loss: 5.064209]\n",
      "epoch:37 step:28903 [D loss: 0.105438, acc: 100.00%] [G loss: 6.681379]\n",
      "epoch:37 step:28904 [D loss: 0.111136, acc: 100.00%] [G loss: 6.459604]\n",
      "epoch:37 step:28905 [D loss: 0.134910, acc: 98.44%] [G loss: 6.936887]\n",
      "epoch:37 step:28906 [D loss: 0.082056, acc: 100.00%] [G loss: 3.485925]\n",
      "epoch:37 step:28907 [D loss: 0.075148, acc: 100.00%] [G loss: 6.550192]\n",
      "epoch:37 step:28908 [D loss: 0.510264, acc: 68.75%] [G loss: 2.346587]\n",
      "epoch:37 step:28909 [D loss: 0.329225, acc: 83.59%] [G loss: 5.760700]\n",
      "epoch:37 step:28910 [D loss: 0.608638, acc: 58.59%] [G loss: 2.786754]\n",
      "epoch:37 step:28911 [D loss: 0.210571, acc: 91.41%] [G loss: 5.676036]\n",
      "epoch:37 step:28912 [D loss: 0.575273, acc: 67.97%] [G loss: 6.152369]\n",
      "epoch:37 step:28913 [D loss: 0.303505, acc: 88.28%] [G loss: 5.031947]\n",
      "epoch:37 step:28914 [D loss: 0.222928, acc: 94.53%] [G loss: 6.232711]\n",
      "epoch:37 step:28915 [D loss: 0.081629, acc: 100.00%] [G loss: 5.337543]\n",
      "epoch:37 step:28916 [D loss: 0.325130, acc: 95.31%] [G loss: 6.001425]\n",
      "epoch:37 step:28917 [D loss: 0.242951, acc: 95.31%] [G loss: 3.688223]\n",
      "epoch:37 step:28918 [D loss: 0.187047, acc: 96.09%] [G loss: 5.945460]\n",
      "epoch:37 step:28919 [D loss: 0.895934, acc: 51.56%] [G loss: 2.693672]\n",
      "epoch:37 step:28920 [D loss: 0.254140, acc: 92.19%] [G loss: 5.084458]\n",
      "epoch:37 step:28921 [D loss: 0.732756, acc: 57.03%] [G loss: 4.817227]\n",
      "epoch:37 step:28922 [D loss: 0.576738, acc: 65.62%] [G loss: 4.964306]\n",
      "epoch:37 step:28923 [D loss: 0.200176, acc: 99.22%] [G loss: 6.279779]\n",
      "epoch:37 step:28924 [D loss: 0.371838, acc: 92.97%] [G loss: 2.667556]\n",
      "epoch:37 step:28925 [D loss: 1.622095, acc: 26.56%] [G loss: 4.840656]\n",
      "epoch:37 step:28926 [D loss: 0.185702, acc: 97.66%] [G loss: 2.605619]\n",
      "epoch:37 step:28927 [D loss: 0.327721, acc: 89.06%] [G loss: 5.164828]\n",
      "epoch:37 step:28928 [D loss: 0.221260, acc: 94.53%] [G loss: 5.876043]\n",
      "epoch:37 step:28929 [D loss: 0.306413, acc: 92.97%] [G loss: 5.401028]\n",
      "epoch:37 step:28930 [D loss: 0.088886, acc: 99.22%] [G loss: 3.942519]\n",
      "epoch:37 step:28931 [D loss: 0.140689, acc: 99.22%] [G loss: 9.590271]\n",
      "epoch:37 step:28932 [D loss: 0.855095, acc: 53.12%] [G loss: 7.475708]\n",
      "epoch:37 step:28933 [D loss: 0.360399, acc: 79.69%] [G loss: 5.881016]\n",
      "epoch:37 step:28934 [D loss: 0.191379, acc: 94.53%] [G loss: 4.789863]\n",
      "epoch:37 step:28935 [D loss: 0.419496, acc: 78.91%] [G loss: 4.185283]\n",
      "epoch:37 step:28936 [D loss: 0.959869, acc: 39.84%] [G loss: 4.942552]\n",
      "epoch:37 step:28937 [D loss: 0.063962, acc: 100.00%] [G loss: 9.611809]\n",
      "epoch:37 step:28938 [D loss: 0.487023, acc: 67.97%] [G loss: 7.595038]\n",
      "epoch:37 step:28939 [D loss: 0.172499, acc: 96.88%] [G loss: 5.699792]\n",
      "epoch:37 step:28940 [D loss: 0.627376, acc: 58.59%] [G loss: 4.898513]\n",
      "epoch:37 step:28941 [D loss: 0.150491, acc: 97.66%] [G loss: 3.901794]\n",
      "epoch:37 step:28942 [D loss: 0.750834, acc: 52.34%] [G loss: 5.729091]\n",
      "epoch:37 step:28943 [D loss: 0.358051, acc: 82.81%] [G loss: 4.564590]\n",
      "epoch:37 step:28944 [D loss: 0.635120, acc: 60.94%] [G loss: 3.924301]\n",
      "epoch:37 step:28945 [D loss: 0.256676, acc: 87.50%] [G loss: 5.632092]\n",
      "epoch:37 step:28946 [D loss: 0.466733, acc: 84.38%] [G loss: 2.792587]\n",
      "epoch:37 step:28947 [D loss: 0.754586, acc: 54.69%] [G loss: 4.045711]\n",
      "epoch:37 step:28948 [D loss: 0.503313, acc: 64.84%] [G loss: 4.900662]\n",
      "epoch:37 step:28949 [D loss: 0.618430, acc: 62.50%] [G loss: 3.885767]\n",
      "epoch:37 step:28950 [D loss: 0.254488, acc: 96.09%] [G loss: 5.370676]\n",
      "epoch:37 step:28951 [D loss: 0.228730, acc: 97.66%] [G loss: 5.076603]\n",
      "epoch:37 step:28952 [D loss: 0.229067, acc: 96.09%] [G loss: 5.184610]\n",
      "epoch:37 step:28953 [D loss: 0.498352, acc: 72.66%] [G loss: 4.624997]\n",
      "epoch:37 step:28954 [D loss: 0.157549, acc: 96.88%] [G loss: 3.811539]\n",
      "epoch:37 step:28955 [D loss: 0.659635, acc: 56.25%] [G loss: 5.485812]\n",
      "epoch:37 step:28956 [D loss: 0.998414, acc: 50.78%] [G loss: 4.544067]\n",
      "epoch:37 step:28957 [D loss: 0.059853, acc: 100.00%] [G loss: 4.184691]\n",
      "epoch:37 step:28958 [D loss: 0.364153, acc: 89.84%] [G loss: 4.280318]\n",
      "epoch:37 step:28959 [D loss: 0.426354, acc: 76.56%] [G loss: 3.433344]\n",
      "epoch:37 step:28960 [D loss: 0.822922, acc: 51.56%] [G loss: 6.103015]\n",
      "epoch:37 step:28961 [D loss: 1.132928, acc: 25.00%] [G loss: 5.913074]\n",
      "epoch:37 step:28962 [D loss: 0.329985, acc: 82.81%] [G loss: 5.581462]\n",
      "epoch:37 step:28963 [D loss: 0.284838, acc: 95.31%] [G loss: 4.514779]\n",
      "epoch:37 step:28964 [D loss: 0.313940, acc: 89.06%] [G loss: 5.319283]\n",
      "epoch:37 step:28965 [D loss: 0.240737, acc: 96.09%] [G loss: 4.060732]\n",
      "epoch:37 step:28966 [D loss: 0.379951, acc: 85.16%] [G loss: 5.510672]\n",
      "epoch:37 step:28967 [D loss: 0.352567, acc: 85.16%] [G loss: 4.223958]\n",
      "epoch:37 step:28968 [D loss: 0.179109, acc: 96.88%] [G loss: 4.196312]\n",
      "epoch:37 step:28969 [D loss: 0.504705, acc: 72.66%] [G loss: 7.486133]\n",
      "epoch:37 step:28970 [D loss: 0.114721, acc: 100.00%] [G loss: 6.218581]\n",
      "epoch:37 step:28971 [D loss: 0.640883, acc: 68.75%] [G loss: 6.558931]\n",
      "epoch:37 step:28972 [D loss: 0.112523, acc: 98.44%] [G loss: 5.945705]\n",
      "epoch:37 step:28973 [D loss: 0.343271, acc: 86.72%] [G loss: 4.345751]\n",
      "epoch:37 step:28974 [D loss: 0.366952, acc: 87.50%] [G loss: 3.347290]\n",
      "epoch:37 step:28975 [D loss: 0.894629, acc: 50.78%] [G loss: 4.093219]\n",
      "epoch:37 step:28976 [D loss: 0.261597, acc: 94.53%] [G loss: 4.960929]\n",
      "epoch:37 step:28977 [D loss: 0.431103, acc: 89.06%] [G loss: 5.425882]\n",
      "epoch:37 step:28978 [D loss: 0.928383, acc: 42.97%] [G loss: 5.584782]\n",
      "epoch:37 step:28979 [D loss: 0.343486, acc: 92.19%] [G loss: 3.391097]\n",
      "epoch:37 step:28980 [D loss: 0.706909, acc: 57.81%] [G loss: 6.830387]\n",
      "epoch:37 step:28981 [D loss: 0.521755, acc: 71.88%] [G loss: 4.044468]\n",
      "epoch:37 step:28982 [D loss: 0.582263, acc: 67.19%] [G loss: 5.538632]\n",
      "epoch:37 step:28983 [D loss: 0.059223, acc: 100.00%] [G loss: 4.530954]\n",
      "epoch:37 step:28984 [D loss: 1.537304, acc: 37.50%] [G loss: 6.127224]\n",
      "epoch:37 step:28985 [D loss: 0.335728, acc: 87.50%] [G loss: 4.333615]\n",
      "epoch:37 step:28986 [D loss: 0.881678, acc: 50.78%] [G loss: 5.911943]\n",
      "epoch:37 step:28987 [D loss: 0.092518, acc: 99.22%] [G loss: 4.607275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:28988 [D loss: 0.068529, acc: 100.00%] [G loss: 3.785004]\n",
      "epoch:37 step:28989 [D loss: 0.133906, acc: 99.22%] [G loss: 2.777118]\n",
      "epoch:37 step:28990 [D loss: 0.802819, acc: 57.03%] [G loss: 3.087042]\n",
      "epoch:37 step:28991 [D loss: 0.289978, acc: 93.75%] [G loss: 4.280132]\n",
      "epoch:37 step:28992 [D loss: 0.410439, acc: 85.94%] [G loss: 5.228622]\n",
      "epoch:37 step:28993 [D loss: 0.432691, acc: 81.25%] [G loss: 4.835111]\n",
      "epoch:37 step:28994 [D loss: 1.192226, acc: 50.00%] [G loss: 6.399790]\n",
      "epoch:37 step:28995 [D loss: 0.392422, acc: 75.78%] [G loss: 4.601602]\n",
      "epoch:37 step:28996 [D loss: 0.963010, acc: 44.53%] [G loss: 6.528192]\n",
      "epoch:37 step:28997 [D loss: 0.509074, acc: 77.34%] [G loss: 3.469998]\n",
      "epoch:37 step:28998 [D loss: 0.678835, acc: 52.34%] [G loss: 7.436319]\n",
      "epoch:37 step:28999 [D loss: 0.292153, acc: 90.62%] [G loss: 3.565536]\n",
      "epoch:37 step:29000 [D loss: 0.458186, acc: 84.38%] [G loss: 4.496223]\n",
      "epoch:37 step:29001 [D loss: 0.158449, acc: 100.00%] [G loss: 4.268751]\n",
      "epoch:37 step:29002 [D loss: 1.519718, acc: 14.84%] [G loss: 5.261249]\n",
      "epoch:37 step:29003 [D loss: 0.306818, acc: 92.19%] [G loss: 4.343101]\n",
      "epoch:37 step:29004 [D loss: 0.225157, acc: 96.09%] [G loss: 5.848531]\n",
      "epoch:37 step:29005 [D loss: 0.713582, acc: 51.56%] [G loss: 6.030546]\n",
      "epoch:37 step:29006 [D loss: 0.064782, acc: 99.22%] [G loss: 4.901528]\n",
      "epoch:37 step:29007 [D loss: 0.539529, acc: 61.72%] [G loss: 5.208072]\n",
      "epoch:37 step:29008 [D loss: 0.818839, acc: 53.91%] [G loss: 6.745567]\n",
      "epoch:37 step:29009 [D loss: 0.552586, acc: 65.62%] [G loss: 6.122544]\n",
      "epoch:37 step:29010 [D loss: 0.111361, acc: 100.00%] [G loss: 3.123909]\n",
      "epoch:37 step:29011 [D loss: 0.607007, acc: 57.03%] [G loss: 5.269822]\n",
      "epoch:37 step:29012 [D loss: 0.163979, acc: 98.44%] [G loss: 4.387132]\n",
      "epoch:37 step:29013 [D loss: 0.455825, acc: 76.56%] [G loss: 5.425148]\n",
      "epoch:37 step:29014 [D loss: 0.064632, acc: 100.00%] [G loss: 5.142920]\n",
      "epoch:37 step:29015 [D loss: 0.063366, acc: 100.00%] [G loss: 5.092459]\n",
      "epoch:37 step:29016 [D loss: 0.275129, acc: 96.88%] [G loss: 4.983552]\n",
      "epoch:37 step:29017 [D loss: 0.484570, acc: 80.47%] [G loss: 4.665701]\n",
      "epoch:37 step:29018 [D loss: 0.240398, acc: 96.88%] [G loss: 3.336628]\n",
      "epoch:37 step:29019 [D loss: 0.086489, acc: 100.00%] [G loss: 6.471902]\n",
      "epoch:37 step:29020 [D loss: 0.134059, acc: 100.00%] [G loss: 3.696322]\n",
      "epoch:37 step:29021 [D loss: 0.312886, acc: 92.97%] [G loss: 5.751237]\n",
      "epoch:37 step:29022 [D loss: 0.365364, acc: 89.06%] [G loss: 2.403538]\n",
      "epoch:37 step:29023 [D loss: 0.877085, acc: 48.44%] [G loss: 6.467062]\n",
      "epoch:37 step:29024 [D loss: 0.210391, acc: 95.31%] [G loss: 6.593430]\n",
      "epoch:37 step:29025 [D loss: 0.066987, acc: 100.00%] [G loss: 5.743929]\n",
      "epoch:37 step:29026 [D loss: 0.215028, acc: 97.66%] [G loss: 6.718283]\n",
      "epoch:37 step:29027 [D loss: 0.559254, acc: 72.66%] [G loss: 3.944958]\n",
      "epoch:37 step:29028 [D loss: 0.201620, acc: 97.66%] [G loss: 3.867212]\n",
      "epoch:37 step:29029 [D loss: 0.342513, acc: 91.41%] [G loss: 4.252226]\n",
      "epoch:37 step:29030 [D loss: 0.494861, acc: 72.66%] [G loss: 4.841755]\n",
      "epoch:37 step:29031 [D loss: 0.408675, acc: 85.94%] [G loss: 4.071540]\n",
      "epoch:37 step:29032 [D loss: 0.039596, acc: 100.00%] [G loss: 3.315116]\n",
      "epoch:37 step:29033 [D loss: 0.255128, acc: 95.31%] [G loss: 4.875564]\n",
      "epoch:37 step:29034 [D loss: 0.111689, acc: 100.00%] [G loss: 5.419456]\n",
      "epoch:37 step:29035 [D loss: 0.604048, acc: 64.84%] [G loss: 6.020205]\n",
      "epoch:37 step:29036 [D loss: 0.322298, acc: 94.53%] [G loss: 3.488219]\n",
      "epoch:37 step:29037 [D loss: 0.096463, acc: 100.00%] [G loss: 3.909260]\n",
      "epoch:37 step:29038 [D loss: 0.251775, acc: 91.41%] [G loss: 5.729159]\n",
      "epoch:37 step:29039 [D loss: 0.441514, acc: 82.03%] [G loss: 6.623269]\n",
      "epoch:37 step:29040 [D loss: 0.286543, acc: 88.28%] [G loss: 3.195871]\n",
      "epoch:37 step:29041 [D loss: 0.903076, acc: 50.78%] [G loss: 5.301727]\n",
      "epoch:37 step:29042 [D loss: 0.425510, acc: 82.81%] [G loss: 6.051982]\n",
      "epoch:37 step:29043 [D loss: 0.090088, acc: 99.22%] [G loss: 4.922051]\n",
      "epoch:37 step:29044 [D loss: 0.551017, acc: 75.00%] [G loss: 6.135664]\n",
      "epoch:37 step:29045 [D loss: 0.273381, acc: 96.09%] [G loss: 4.609121]\n",
      "epoch:37 step:29046 [D loss: 0.335412, acc: 93.75%] [G loss: 3.621949]\n",
      "epoch:37 step:29047 [D loss: 1.153543, acc: 38.28%] [G loss: 5.071879]\n",
      "epoch:37 step:29048 [D loss: 0.535752, acc: 60.94%] [G loss: 5.185213]\n",
      "epoch:37 step:29049 [D loss: 0.410877, acc: 85.16%] [G loss: 3.671929]\n",
      "epoch:37 step:29050 [D loss: 0.357072, acc: 89.06%] [G loss: 2.408932]\n",
      "epoch:37 step:29051 [D loss: 0.208593, acc: 96.09%] [G loss: 6.057201]\n",
      "epoch:37 step:29052 [D loss: 0.276415, acc: 95.31%] [G loss: 3.453087]\n",
      "epoch:37 step:29053 [D loss: 0.687566, acc: 61.72%] [G loss: 6.717896]\n",
      "epoch:37 step:29054 [D loss: 0.365520, acc: 91.41%] [G loss: 3.987193]\n",
      "epoch:37 step:29055 [D loss: 0.119863, acc: 100.00%] [G loss: 3.972464]\n",
      "epoch:37 step:29056 [D loss: 0.464374, acc: 78.12%] [G loss: 5.931364]\n",
      "epoch:37 step:29057 [D loss: 0.289667, acc: 94.53%] [G loss: 5.023309]\n",
      "epoch:37 step:29058 [D loss: 0.465555, acc: 77.34%] [G loss: 5.671698]\n",
      "epoch:37 step:29059 [D loss: 0.272471, acc: 96.09%] [G loss: 3.586339]\n",
      "epoch:37 step:29060 [D loss: 0.329353, acc: 92.19%] [G loss: 5.991103]\n",
      "epoch:37 step:29061 [D loss: 0.436940, acc: 85.94%] [G loss: 4.376974]\n",
      "epoch:37 step:29062 [D loss: 0.156851, acc: 100.00%] [G loss: 6.986445]\n",
      "epoch:37 step:29063 [D loss: 0.233098, acc: 93.75%] [G loss: 3.902802]\n",
      "epoch:37 step:29064 [D loss: 0.528905, acc: 61.72%] [G loss: 4.822906]\n",
      "epoch:37 step:29065 [D loss: 0.932085, acc: 48.44%] [G loss: 5.833801]\n",
      "epoch:37 step:29066 [D loss: 1.058986, acc: 48.44%] [G loss: 8.201416]\n",
      "epoch:37 step:29067 [D loss: 1.459661, acc: 8.59%] [G loss: 4.096121]\n",
      "epoch:37 step:29068 [D loss: 0.312541, acc: 94.53%] [G loss: 3.581966]\n",
      "epoch:37 step:29069 [D loss: 0.166011, acc: 99.22%] [G loss: 3.786158]\n",
      "epoch:37 step:29070 [D loss: 0.847993, acc: 50.00%] [G loss: 7.014844]\n",
      "epoch:37 step:29071 [D loss: 0.100404, acc: 99.22%] [G loss: 5.599565]\n",
      "epoch:37 step:29072 [D loss: 0.137450, acc: 98.44%] [G loss: 6.243341]\n",
      "epoch:37 step:29073 [D loss: 0.203296, acc: 99.22%] [G loss: 5.552733]\n",
      "epoch:37 step:29074 [D loss: 0.404978, acc: 77.34%] [G loss: 6.520005]\n",
      "epoch:37 step:29075 [D loss: 0.274842, acc: 94.53%] [G loss: 3.569768]\n",
      "epoch:37 step:29076 [D loss: 0.428375, acc: 85.94%] [G loss: 3.819462]\n",
      "epoch:37 step:29077 [D loss: 0.397837, acc: 81.25%] [G loss: 6.879140]\n",
      "epoch:37 step:29078 [D loss: 0.073462, acc: 100.00%] [G loss: 5.051631]\n",
      "epoch:37 step:29079 [D loss: 0.517318, acc: 67.19%] [G loss: 5.599514]\n",
      "epoch:37 step:29080 [D loss: 0.017998, acc: 100.00%] [G loss: 6.514392]\n",
      "epoch:37 step:29081 [D loss: 0.066141, acc: 100.00%] [G loss: 2.314118]\n",
      "epoch:37 step:29082 [D loss: 0.500176, acc: 66.41%] [G loss: 5.250835]\n",
      "epoch:37 step:29083 [D loss: 0.170820, acc: 98.44%] [G loss: 3.873501]\n",
      "epoch:37 step:29084 [D loss: 0.441460, acc: 67.97%] [G loss: 4.198710]\n",
      "epoch:37 step:29085 [D loss: 0.095155, acc: 100.00%] [G loss: 2.701841]\n",
      "epoch:37 step:29086 [D loss: 0.232385, acc: 93.75%] [G loss: 6.305859]\n",
      "epoch:37 step:29087 [D loss: 1.101366, acc: 30.47%] [G loss: 7.207797]\n",
      "epoch:37 step:29088 [D loss: 0.507070, acc: 75.00%] [G loss: 5.314132]\n",
      "epoch:37 step:29089 [D loss: 0.191741, acc: 96.09%] [G loss: 2.662281]\n",
      "epoch:37 step:29090 [D loss: 0.391975, acc: 77.34%] [G loss: 5.382906]\n",
      "epoch:37 step:29091 [D loss: 0.246252, acc: 93.75%] [G loss: 7.556925]\n",
      "epoch:37 step:29092 [D loss: 0.071078, acc: 100.00%] [G loss: 7.052017]\n",
      "epoch:37 step:29093 [D loss: 0.381922, acc: 82.03%] [G loss: 4.274071]\n",
      "epoch:37 step:29094 [D loss: 0.167712, acc: 98.44%] [G loss: 5.744382]\n",
      "epoch:37 step:29095 [D loss: 0.093527, acc: 99.22%] [G loss: 5.555541]\n",
      "epoch:37 step:29096 [D loss: 0.905213, acc: 46.88%] [G loss: 9.337200]\n",
      "epoch:37 step:29097 [D loss: 0.354425, acc: 91.41%] [G loss: 4.680873]\n",
      "epoch:37 step:29098 [D loss: 0.642867, acc: 67.19%] [G loss: 6.175479]\n",
      "epoch:37 step:29099 [D loss: 0.633904, acc: 57.03%] [G loss: 5.895422]\n",
      "epoch:37 step:29100 [D loss: 0.321811, acc: 89.06%] [G loss: 5.647418]\n",
      "epoch:37 step:29101 [D loss: 0.178789, acc: 99.22%] [G loss: 4.755232]\n",
      "epoch:37 step:29102 [D loss: 0.243653, acc: 98.44%] [G loss: 5.220484]\n",
      "epoch:37 step:29103 [D loss: 0.050805, acc: 100.00%] [G loss: 4.305375]\n",
      "epoch:37 step:29104 [D loss: 0.538932, acc: 75.78%] [G loss: 3.212164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29105 [D loss: 0.050614, acc: 100.00%] [G loss: 6.332725]\n",
      "epoch:37 step:29106 [D loss: 0.534546, acc: 68.75%] [G loss: 5.091604]\n",
      "epoch:37 step:29107 [D loss: 0.119932, acc: 99.22%] [G loss: 2.337235]\n",
      "epoch:37 step:29108 [D loss: 0.299863, acc: 89.84%] [G loss: 5.086638]\n",
      "epoch:37 step:29109 [D loss: 0.605931, acc: 63.28%] [G loss: 6.964748]\n",
      "epoch:37 step:29110 [D loss: 0.416393, acc: 75.78%] [G loss: 4.827597]\n",
      "epoch:37 step:29111 [D loss: 0.277084, acc: 99.22%] [G loss: 8.082303]\n",
      "epoch:37 step:29112 [D loss: 0.213001, acc: 97.66%] [G loss: 4.950443]\n",
      "epoch:37 step:29113 [D loss: 0.476200, acc: 82.03%] [G loss: 5.987357]\n",
      "epoch:37 step:29114 [D loss: 0.187811, acc: 96.09%] [G loss: 4.777410]\n",
      "epoch:37 step:29115 [D loss: 0.253424, acc: 94.53%] [G loss: 4.969535]\n",
      "epoch:37 step:29116 [D loss: 0.111011, acc: 100.00%] [G loss: 2.210371]\n",
      "epoch:37 step:29117 [D loss: 0.065333, acc: 99.22%] [G loss: 4.245805]\n",
      "epoch:37 step:29118 [D loss: 0.472939, acc: 67.19%] [G loss: 3.565592]\n",
      "epoch:37 step:29119 [D loss: 0.650918, acc: 57.03%] [G loss: 6.164384]\n",
      "epoch:37 step:29120 [D loss: 0.308584, acc: 94.53%] [G loss: 5.461963]\n",
      "epoch:37 step:29121 [D loss: 0.522709, acc: 78.12%] [G loss: 3.844301]\n",
      "epoch:37 step:29122 [D loss: 0.284913, acc: 94.53%] [G loss: 5.337396]\n",
      "epoch:37 step:29123 [D loss: 0.977181, acc: 49.22%] [G loss: 5.806383]\n",
      "epoch:37 step:29124 [D loss: 0.299130, acc: 85.94%] [G loss: 11.040829]\n",
      "epoch:37 step:29125 [D loss: 0.468885, acc: 66.41%] [G loss: 4.612895]\n",
      "epoch:37 step:29126 [D loss: 0.173730, acc: 97.66%] [G loss: 5.722455]\n",
      "epoch:37 step:29127 [D loss: 0.875712, acc: 54.69%] [G loss: 7.587178]\n",
      "epoch:37 step:29128 [D loss: 0.116558, acc: 100.00%] [G loss: 4.654876]\n",
      "epoch:37 step:29129 [D loss: 0.293593, acc: 94.53%] [G loss: 5.141385]\n",
      "epoch:37 step:29130 [D loss: 0.160023, acc: 100.00%] [G loss: 4.003234]\n",
      "epoch:37 step:29131 [D loss: 0.141067, acc: 99.22%] [G loss: 2.820861]\n",
      "epoch:37 step:29132 [D loss: 0.344543, acc: 90.62%] [G loss: 6.239233]\n",
      "epoch:37 step:29133 [D loss: 0.822133, acc: 45.31%] [G loss: 3.313486]\n",
      "epoch:37 step:29134 [D loss: 0.209744, acc: 92.97%] [G loss: 3.514420]\n",
      "epoch:37 step:29135 [D loss: 0.411069, acc: 81.25%] [G loss: 2.637566]\n",
      "epoch:37 step:29136 [D loss: 0.300520, acc: 92.97%] [G loss: 3.876675]\n",
      "epoch:37 step:29137 [D loss: 0.400709, acc: 69.53%] [G loss: 6.180138]\n",
      "epoch:37 step:29138 [D loss: 0.374994, acc: 88.28%] [G loss: 2.206378]\n",
      "epoch:37 step:29139 [D loss: 0.051315, acc: 100.00%] [G loss: 6.539569]\n",
      "epoch:37 step:29140 [D loss: 0.711174, acc: 52.34%] [G loss: 6.875312]\n",
      "epoch:37 step:29141 [D loss: 0.115967, acc: 100.00%] [G loss: 5.493559]\n",
      "epoch:37 step:29142 [D loss: 0.743239, acc: 52.34%] [G loss: 5.786162]\n",
      "epoch:37 step:29143 [D loss: 2.277392, acc: 2.34%] [G loss: 4.928239]\n",
      "epoch:37 step:29144 [D loss: 0.587402, acc: 57.03%] [G loss: 3.364323]\n",
      "epoch:37 step:29145 [D loss: 0.210599, acc: 96.09%] [G loss: 5.945721]\n",
      "epoch:37 step:29146 [D loss: 0.035276, acc: 100.00%] [G loss: 6.760400]\n",
      "epoch:37 step:29147 [D loss: 0.063614, acc: 100.00%] [G loss: 5.940857]\n",
      "epoch:37 step:29148 [D loss: 0.459244, acc: 82.81%] [G loss: 7.668380]\n",
      "epoch:37 step:29149 [D loss: 0.063409, acc: 100.00%] [G loss: 3.034350]\n",
      "epoch:37 step:29150 [D loss: 0.426715, acc: 87.50%] [G loss: 5.116029]\n",
      "epoch:37 step:29151 [D loss: 0.441647, acc: 83.59%] [G loss: 4.696431]\n",
      "epoch:37 step:29152 [D loss: 0.052813, acc: 100.00%] [G loss: 5.024280]\n",
      "epoch:37 step:29153 [D loss: 0.074021, acc: 100.00%] [G loss: 6.146219]\n",
      "epoch:37 step:29154 [D loss: 0.106978, acc: 100.00%] [G loss: 6.473346]\n",
      "epoch:37 step:29155 [D loss: 0.163332, acc: 100.00%] [G loss: 5.633801]\n",
      "epoch:37 step:29156 [D loss: 0.339990, acc: 92.97%] [G loss: 5.331137]\n",
      "epoch:37 step:29157 [D loss: 0.350992, acc: 79.69%] [G loss: 5.692203]\n",
      "epoch:37 step:29158 [D loss: 0.222499, acc: 99.22%] [G loss: 5.201776]\n",
      "epoch:37 step:29159 [D loss: 0.326022, acc: 82.03%] [G loss: 5.144096]\n",
      "epoch:37 step:29160 [D loss: 0.362020, acc: 79.69%] [G loss: 5.877278]\n",
      "epoch:37 step:29161 [D loss: 0.605420, acc: 59.38%] [G loss: 4.596560]\n",
      "epoch:37 step:29162 [D loss: 0.595487, acc: 63.28%] [G loss: 4.465659]\n",
      "epoch:37 step:29163 [D loss: 0.681208, acc: 57.03%] [G loss: 5.469268]\n",
      "epoch:37 step:29164 [D loss: 0.272122, acc: 85.16%] [G loss: 6.296986]\n",
      "epoch:37 step:29165 [D loss: 0.400461, acc: 72.66%] [G loss: 7.392978]\n",
      "epoch:37 step:29166 [D loss: 0.454792, acc: 71.88%] [G loss: 3.542424]\n",
      "epoch:37 step:29167 [D loss: 0.312819, acc: 85.16%] [G loss: 7.162952]\n",
      "epoch:37 step:29168 [D loss: 0.153888, acc: 98.44%] [G loss: 4.749383]\n",
      "epoch:37 step:29169 [D loss: 0.333798, acc: 81.25%] [G loss: 5.267083]\n",
      "epoch:37 step:29170 [D loss: 0.323978, acc: 90.62%] [G loss: 5.319079]\n",
      "epoch:37 step:29171 [D loss: 0.593241, acc: 67.97%] [G loss: 6.719351]\n",
      "epoch:37 step:29172 [D loss: 0.250580, acc: 92.19%] [G loss: 5.397696]\n",
      "epoch:37 step:29173 [D loss: 0.032871, acc: 100.00%] [G loss: 3.508062]\n",
      "epoch:37 step:29174 [D loss: 0.312710, acc: 90.62%] [G loss: 5.836287]\n",
      "epoch:37 step:29175 [D loss: 0.912360, acc: 52.34%] [G loss: 6.950409]\n",
      "epoch:37 step:29176 [D loss: 0.263557, acc: 91.41%] [G loss: 5.411460]\n",
      "epoch:37 step:29177 [D loss: 0.258532, acc: 91.41%] [G loss: 3.794528]\n",
      "epoch:37 step:29178 [D loss: 1.104903, acc: 26.56%] [G loss: 6.402416]\n",
      "epoch:37 step:29179 [D loss: 0.032263, acc: 100.00%] [G loss: 7.332651]\n",
      "epoch:37 step:29180 [D loss: 0.634704, acc: 67.19%] [G loss: 4.014061]\n",
      "epoch:37 step:29181 [D loss: 0.093492, acc: 100.00%] [G loss: 4.548981]\n",
      "epoch:37 step:29182 [D loss: 0.398174, acc: 84.38%] [G loss: 5.011068]\n",
      "epoch:37 step:29183 [D loss: 0.433154, acc: 85.16%] [G loss: 6.515625]\n",
      "epoch:37 step:29184 [D loss: 0.035302, acc: 100.00%] [G loss: 3.990835]\n",
      "epoch:37 step:29185 [D loss: 0.306474, acc: 95.31%] [G loss: 4.311163]\n",
      "epoch:37 step:29186 [D loss: 0.778426, acc: 52.34%] [G loss: 7.039463]\n",
      "epoch:37 step:29187 [D loss: 0.348013, acc: 92.97%] [G loss: 3.548669]\n",
      "epoch:37 step:29188 [D loss: 0.605848, acc: 60.94%] [G loss: 3.988834]\n",
      "epoch:37 step:29189 [D loss: 0.045745, acc: 100.00%] [G loss: 4.716242]\n",
      "epoch:37 step:29190 [D loss: 0.319716, acc: 83.59%] [G loss: 6.970967]\n",
      "epoch:37 step:29191 [D loss: 0.146791, acc: 99.22%] [G loss: 7.976595]\n",
      "epoch:37 step:29192 [D loss: 0.402184, acc: 83.59%] [G loss: 4.811381]\n",
      "epoch:37 step:29193 [D loss: 0.289232, acc: 86.72%] [G loss: 7.929578]\n",
      "epoch:37 step:29194 [D loss: 0.790834, acc: 44.53%] [G loss: 6.094594]\n",
      "epoch:37 step:29195 [D loss: 0.083269, acc: 100.00%] [G loss: 8.011172]\n",
      "epoch:37 step:29196 [D loss: 0.427402, acc: 82.03%] [G loss: 7.558210]\n",
      "epoch:37 step:29197 [D loss: 0.310520, acc: 85.94%] [G loss: 6.226404]\n",
      "epoch:37 step:29198 [D loss: 0.874906, acc: 44.53%] [G loss: 7.967935]\n",
      "epoch:37 step:29199 [D loss: 0.642733, acc: 62.50%] [G loss: 5.592277]\n",
      "epoch:37 step:29200 [D loss: 0.043091, acc: 100.00%] [G loss: 3.759883]\n",
      "epoch:37 step:29201 [D loss: 0.030111, acc: 100.00%] [G loss: 6.379943]\n",
      "epoch:37 step:29202 [D loss: 0.975586, acc: 27.34%] [G loss: 7.310081]\n",
      "epoch:37 step:29203 [D loss: 0.366629, acc: 92.97%] [G loss: 4.901638]\n",
      "epoch:37 step:29204 [D loss: 0.125126, acc: 100.00%] [G loss: 6.255124]\n",
      "epoch:37 step:29205 [D loss: 0.981216, acc: 50.00%] [G loss: 7.688890]\n",
      "epoch:37 step:29206 [D loss: 0.309405, acc: 91.41%] [G loss: 3.721331]\n",
      "epoch:37 step:29207 [D loss: 0.791379, acc: 52.34%] [G loss: 6.847206]\n",
      "epoch:37 step:29208 [D loss: 0.044635, acc: 100.00%] [G loss: 5.028177]\n",
      "epoch:37 step:29209 [D loss: 1.758098, acc: 43.75%] [G loss: 8.571205]\n",
      "epoch:37 step:29210 [D loss: 0.772156, acc: 53.12%] [G loss: 6.197478]\n",
      "epoch:37 step:29211 [D loss: 0.727145, acc: 60.94%] [G loss: 5.540399]\n",
      "epoch:37 step:29212 [D loss: 0.452475, acc: 69.53%] [G loss: 5.550569]\n",
      "epoch:37 step:29213 [D loss: 1.180044, acc: 33.59%] [G loss: 4.746506]\n",
      "epoch:37 step:29214 [D loss: 0.245336, acc: 90.62%] [G loss: 3.813920]\n",
      "epoch:37 step:29215 [D loss: 0.090157, acc: 100.00%] [G loss: 4.189500]\n",
      "epoch:37 step:29216 [D loss: 0.216648, acc: 92.19%] [G loss: 6.608508]\n",
      "epoch:37 step:29217 [D loss: 0.803818, acc: 50.00%] [G loss: 5.601310]\n",
      "epoch:37 step:29218 [D loss: 0.269472, acc: 95.31%] [G loss: 6.757463]\n",
      "epoch:37 step:29219 [D loss: 0.080093, acc: 100.00%] [G loss: 5.454211]\n",
      "epoch:37 step:29220 [D loss: 1.070934, acc: 42.19%] [G loss: 4.403559]\n",
      "epoch:37 step:29221 [D loss: 0.530690, acc: 61.72%] [G loss: 5.277750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29222 [D loss: 0.496982, acc: 71.88%] [G loss: 5.465811]\n",
      "epoch:37 step:29223 [D loss: 0.067337, acc: 100.00%] [G loss: 6.052548]\n",
      "epoch:37 step:29224 [D loss: 0.378392, acc: 89.84%] [G loss: 3.984242]\n",
      "epoch:37 step:29225 [D loss: 0.113959, acc: 99.22%] [G loss: 5.749690]\n",
      "epoch:37 step:29226 [D loss: 0.067081, acc: 100.00%] [G loss: 4.638777]\n",
      "epoch:37 step:29227 [D loss: 0.521473, acc: 78.12%] [G loss: 5.105571]\n",
      "epoch:37 step:29228 [D loss: 0.339871, acc: 92.19%] [G loss: 5.382857]\n",
      "epoch:37 step:29229 [D loss: 0.153916, acc: 98.44%] [G loss: 4.666990]\n",
      "epoch:37 step:29230 [D loss: 0.244606, acc: 93.75%] [G loss: 6.341204]\n",
      "epoch:37 step:29231 [D loss: 0.269206, acc: 96.09%] [G loss: 2.602076]\n",
      "epoch:37 step:29232 [D loss: 0.119209, acc: 100.00%] [G loss: 7.754262]\n",
      "epoch:37 step:29233 [D loss: 0.101726, acc: 99.22%] [G loss: 7.793108]\n",
      "epoch:37 step:29234 [D loss: 1.069652, acc: 33.59%] [G loss: 5.237957]\n",
      "epoch:37 step:29235 [D loss: 0.482457, acc: 80.47%] [G loss: 4.888542]\n",
      "epoch:37 step:29236 [D loss: 0.298244, acc: 94.53%] [G loss: 10.476561]\n",
      "epoch:37 step:29237 [D loss: 0.056116, acc: 100.00%] [G loss: 5.598876]\n",
      "epoch:37 step:29238 [D loss: 0.515832, acc: 67.19%] [G loss: 5.105198]\n",
      "epoch:37 step:29239 [D loss: 0.911730, acc: 51.56%] [G loss: 7.166233]\n",
      "epoch:37 step:29240 [D loss: 0.016816, acc: 100.00%] [G loss: 5.493100]\n",
      "epoch:37 step:29241 [D loss: 0.985410, acc: 45.31%] [G loss: 4.524981]\n",
      "epoch:37 step:29242 [D loss: 0.155296, acc: 98.44%] [G loss: 5.795992]\n",
      "epoch:37 step:29243 [D loss: 0.498973, acc: 69.53%] [G loss: 4.419837]\n",
      "epoch:37 step:29244 [D loss: 0.177479, acc: 98.44%] [G loss: 5.966475]\n",
      "epoch:37 step:29245 [D loss: 0.141938, acc: 99.22%] [G loss: 5.512589]\n",
      "epoch:37 step:29246 [D loss: 0.595200, acc: 61.72%] [G loss: 6.492574]\n",
      "epoch:37 step:29247 [D loss: 0.191034, acc: 97.66%] [G loss: 3.361205]\n",
      "epoch:37 step:29248 [D loss: 0.188705, acc: 98.44%] [G loss: 2.950682]\n",
      "epoch:37 step:29249 [D loss: 0.212184, acc: 89.84%] [G loss: 8.814041]\n",
      "epoch:37 step:29250 [D loss: 0.522443, acc: 73.44%] [G loss: 5.161380]\n",
      "epoch:37 step:29251 [D loss: 0.265544, acc: 93.75%] [G loss: 3.741564]\n",
      "epoch:37 step:29252 [D loss: 0.847134, acc: 48.44%] [G loss: 6.253430]\n",
      "epoch:37 step:29253 [D loss: 0.131546, acc: 99.22%] [G loss: 6.590256]\n",
      "epoch:37 step:29254 [D loss: 0.357086, acc: 91.41%] [G loss: 5.571422]\n",
      "epoch:37 step:29255 [D loss: 0.174146, acc: 96.88%] [G loss: 4.797834]\n",
      "epoch:37 step:29256 [D loss: 0.062996, acc: 99.22%] [G loss: 5.551809]\n",
      "epoch:37 step:29257 [D loss: 0.481403, acc: 75.00%] [G loss: 5.824498]\n",
      "epoch:37 step:29258 [D loss: 0.742541, acc: 50.00%] [G loss: 3.408657]\n",
      "epoch:37 step:29259 [D loss: 0.078468, acc: 100.00%] [G loss: 5.420417]\n",
      "epoch:37 step:29260 [D loss: 0.069596, acc: 100.00%] [G loss: 4.120410]\n",
      "epoch:37 step:29261 [D loss: 0.272816, acc: 93.75%] [G loss: 6.493133]\n",
      "epoch:37 step:29262 [D loss: 0.243347, acc: 94.53%] [G loss: 5.378125]\n",
      "epoch:37 step:29263 [D loss: 0.264053, acc: 96.88%] [G loss: 3.933902]\n",
      "epoch:37 step:29264 [D loss: 0.216795, acc: 95.31%] [G loss: 3.744777]\n",
      "epoch:37 step:29265 [D loss: 0.250518, acc: 93.75%] [G loss: 5.004230]\n",
      "epoch:37 step:29266 [D loss: 0.253913, acc: 90.62%] [G loss: 7.045406]\n",
      "epoch:37 step:29267 [D loss: 0.243630, acc: 98.44%] [G loss: 5.531741]\n",
      "epoch:37 step:29268 [D loss: 0.151534, acc: 99.22%] [G loss: 3.266979]\n",
      "epoch:37 step:29269 [D loss: 0.606373, acc: 67.97%] [G loss: 6.131868]\n",
      "epoch:37 step:29270 [D loss: 0.193972, acc: 97.66%] [G loss: 5.177761]\n",
      "epoch:37 step:29271 [D loss: 0.169759, acc: 96.88%] [G loss: 4.994951]\n",
      "epoch:37 step:29272 [D loss: 0.051819, acc: 99.22%] [G loss: 8.473969]\n",
      "epoch:37 step:29273 [D loss: 0.207224, acc: 99.22%] [G loss: 5.351311]\n",
      "epoch:37 step:29274 [D loss: 0.629486, acc: 65.62%] [G loss: 6.135151]\n",
      "epoch:37 step:29275 [D loss: 0.463893, acc: 73.44%] [G loss: 6.545768]\n",
      "epoch:37 step:29276 [D loss: 0.099118, acc: 100.00%] [G loss: 7.353270]\n",
      "epoch:37 step:29277 [D loss: 0.056870, acc: 100.00%] [G loss: 7.903167]\n",
      "epoch:37 step:29278 [D loss: 0.187886, acc: 96.09%] [G loss: 5.070150]\n",
      "epoch:37 step:29279 [D loss: 0.960274, acc: 39.84%] [G loss: 6.404438]\n",
      "epoch:37 step:29280 [D loss: 0.166295, acc: 97.66%] [G loss: 4.937120]\n",
      "epoch:37 step:29281 [D loss: 0.188084, acc: 96.88%] [G loss: 3.114373]\n",
      "epoch:37 step:29282 [D loss: 0.444347, acc: 87.50%] [G loss: 5.583664]\n",
      "epoch:37 step:29283 [D loss: 0.375671, acc: 83.59%] [G loss: 8.301109]\n",
      "epoch:37 step:29284 [D loss: 0.155715, acc: 97.66%] [G loss: 5.156121]\n",
      "epoch:37 step:29285 [D loss: 0.287555, acc: 89.84%] [G loss: 3.873576]\n",
      "epoch:37 step:29286 [D loss: 0.118244, acc: 98.44%] [G loss: 2.262182]\n",
      "epoch:37 step:29287 [D loss: 1.591065, acc: 7.03%] [G loss: 7.230169]\n",
      "epoch:37 step:29288 [D loss: 0.523767, acc: 73.44%] [G loss: 2.249403]\n",
      "epoch:37 step:29289 [D loss: 0.159650, acc: 99.22%] [G loss: 3.103193]\n",
      "epoch:37 step:29290 [D loss: 0.396764, acc: 89.06%] [G loss: 3.193267]\n",
      "epoch:37 step:29291 [D loss: 0.157624, acc: 98.44%] [G loss: 2.952230]\n",
      "epoch:37 step:29292 [D loss: 0.095408, acc: 99.22%] [G loss: 4.000574]\n",
      "epoch:37 step:29293 [D loss: 0.557099, acc: 67.97%] [G loss: 4.349558]\n",
      "epoch:37 step:29294 [D loss: 1.103361, acc: 42.97%] [G loss: 4.182348]\n",
      "epoch:37 step:29295 [D loss: 0.149799, acc: 99.22%] [G loss: 6.437032]\n",
      "epoch:37 step:29296 [D loss: 0.679088, acc: 54.69%] [G loss: 8.124445]\n",
      "epoch:37 step:29297 [D loss: 0.188215, acc: 98.44%] [G loss: 6.667669]\n",
      "epoch:37 step:29298 [D loss: 0.043740, acc: 100.00%] [G loss: 8.948698]\n",
      "epoch:37 step:29299 [D loss: 0.246011, acc: 96.88%] [G loss: 4.138893]\n",
      "epoch:37 step:29300 [D loss: 0.519547, acc: 74.22%] [G loss: 6.634782]\n",
      "epoch:37 step:29301 [D loss: 0.105718, acc: 100.00%] [G loss: 3.748055]\n",
      "epoch:37 step:29302 [D loss: 0.489446, acc: 75.78%] [G loss: 5.783312]\n",
      "epoch:37 step:29303 [D loss: 0.548763, acc: 67.97%] [G loss: 4.428135]\n",
      "epoch:37 step:29304 [D loss: 0.093397, acc: 100.00%] [G loss: 4.015163]\n",
      "epoch:37 step:29305 [D loss: 0.251645, acc: 89.06%] [G loss: 7.650710]\n",
      "epoch:37 step:29306 [D loss: 0.134980, acc: 99.22%] [G loss: 3.434750]\n",
      "epoch:37 step:29307 [D loss: 0.212150, acc: 99.22%] [G loss: 3.377649]\n",
      "epoch:37 step:29308 [D loss: 0.282559, acc: 93.75%] [G loss: 4.059328]\n",
      "epoch:37 step:29309 [D loss: 0.265960, acc: 92.97%] [G loss: 5.029151]\n",
      "epoch:37 step:29310 [D loss: 1.152320, acc: 50.78%] [G loss: 6.758789]\n",
      "epoch:37 step:29311 [D loss: 0.871012, acc: 52.34%] [G loss: 7.217407]\n",
      "epoch:37 step:29312 [D loss: 0.557242, acc: 72.66%] [G loss: 10.652140]\n",
      "epoch:37 step:29313 [D loss: 0.461398, acc: 84.38%] [G loss: 4.643985]\n",
      "epoch:37 step:29314 [D loss: 0.533483, acc: 62.50%] [G loss: 4.908494]\n",
      "epoch:37 step:29315 [D loss: 0.036894, acc: 100.00%] [G loss: 7.864172]\n",
      "epoch:37 step:29316 [D loss: 0.215204, acc: 99.22%] [G loss: 5.603005]\n",
      "epoch:37 step:29317 [D loss: 0.207219, acc: 95.31%] [G loss: 4.470725]\n",
      "epoch:37 step:29318 [D loss: 0.075550, acc: 100.00%] [G loss: 4.228002]\n",
      "epoch:37 step:29319 [D loss: 0.069342, acc: 100.00%] [G loss: 6.247312]\n",
      "epoch:37 step:29320 [D loss: 0.676813, acc: 61.72%] [G loss: 5.274088]\n",
      "epoch:37 step:29321 [D loss: 0.727478, acc: 55.47%] [G loss: 4.301270]\n",
      "epoch:37 step:29322 [D loss: 0.906307, acc: 46.88%] [G loss: 6.429821]\n",
      "epoch:37 step:29323 [D loss: 0.747195, acc: 55.47%] [G loss: 4.740436]\n",
      "epoch:37 step:29324 [D loss: 0.226746, acc: 92.97%] [G loss: 6.445855]\n",
      "epoch:37 step:29325 [D loss: 0.228266, acc: 96.09%] [G loss: 6.740233]\n",
      "epoch:37 step:29326 [D loss: 0.155062, acc: 99.22%] [G loss: 7.538347]\n",
      "epoch:37 step:29327 [D loss: 0.582874, acc: 64.84%] [G loss: 6.254497]\n",
      "epoch:37 step:29328 [D loss: 0.313038, acc: 86.72%] [G loss: 7.338273]\n",
      "epoch:37 step:29329 [D loss: 0.127474, acc: 100.00%] [G loss: 4.582900]\n",
      "epoch:37 step:29330 [D loss: 0.725152, acc: 52.34%] [G loss: 5.810135]\n",
      "epoch:37 step:29331 [D loss: 0.102509, acc: 99.22%] [G loss: 7.312063]\n",
      "epoch:37 step:29332 [D loss: 0.488400, acc: 66.41%] [G loss: 8.718370]\n",
      "epoch:37 step:29333 [D loss: 0.446213, acc: 85.94%] [G loss: 5.630060]\n",
      "epoch:37 step:29334 [D loss: 0.157718, acc: 100.00%] [G loss: 3.851628]\n",
      "epoch:37 step:29335 [D loss: 1.692381, acc: 1.56%] [G loss: 8.149617]\n",
      "epoch:37 step:29336 [D loss: 0.619477, acc: 65.62%] [G loss: 3.964049]\n",
      "epoch:37 step:29337 [D loss: 0.308517, acc: 92.97%] [G loss: 2.851588]\n",
      "epoch:37 step:29338 [D loss: 1.069619, acc: 51.56%] [G loss: 8.663195]\n",
      "epoch:37 step:29339 [D loss: 0.232447, acc: 94.53%] [G loss: 4.123575]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29340 [D loss: 0.282121, acc: 91.41%] [G loss: 7.146509]\n",
      "epoch:37 step:29341 [D loss: 0.121642, acc: 99.22%] [G loss: 4.160582]\n",
      "epoch:37 step:29342 [D loss: 0.732315, acc: 53.12%] [G loss: 4.182465]\n",
      "epoch:37 step:29343 [D loss: 0.033149, acc: 100.00%] [G loss: 5.612500]\n",
      "epoch:37 step:29344 [D loss: 0.265935, acc: 87.50%] [G loss: 5.010476]\n",
      "epoch:37 step:29345 [D loss: 0.175084, acc: 94.53%] [G loss: 4.688375]\n",
      "epoch:37 step:29346 [D loss: 0.043181, acc: 100.00%] [G loss: 3.801153]\n",
      "epoch:37 step:29347 [D loss: 0.324946, acc: 89.84%] [G loss: 2.693779]\n",
      "epoch:37 step:29348 [D loss: 0.349100, acc: 81.25%] [G loss: 3.075300]\n",
      "epoch:37 step:29349 [D loss: 0.319576, acc: 86.72%] [G loss: 7.393845]\n",
      "epoch:37 step:29350 [D loss: 0.437771, acc: 82.81%] [G loss: 4.752399]\n",
      "epoch:37 step:29351 [D loss: 1.021619, acc: 28.12%] [G loss: 3.570584]\n",
      "epoch:37 step:29352 [D loss: 0.632569, acc: 65.62%] [G loss: 4.088581]\n",
      "epoch:37 step:29353 [D loss: 0.855002, acc: 40.62%] [G loss: 6.110024]\n",
      "epoch:37 step:29354 [D loss: 0.094938, acc: 100.00%] [G loss: 7.496961]\n",
      "epoch:37 step:29355 [D loss: 0.427426, acc: 79.69%] [G loss: 7.342945]\n",
      "epoch:37 step:29356 [D loss: 0.320406, acc: 92.19%] [G loss: 5.513382]\n",
      "epoch:37 step:29357 [D loss: 0.054690, acc: 100.00%] [G loss: 3.961968]\n",
      "epoch:37 step:29358 [D loss: 0.038986, acc: 100.00%] [G loss: 6.266499]\n",
      "epoch:37 step:29359 [D loss: 0.144581, acc: 98.44%] [G loss: 4.853530]\n",
      "epoch:37 step:29360 [D loss: 0.540666, acc: 73.44%] [G loss: 5.135402]\n",
      "epoch:37 step:29361 [D loss: 0.452674, acc: 81.25%] [G loss: 2.535530]\n",
      "epoch:37 step:29362 [D loss: 0.631663, acc: 60.16%] [G loss: 4.008207]\n",
      "epoch:37 step:29363 [D loss: 0.008233, acc: 100.00%] [G loss: 8.168758]\n",
      "epoch:37 step:29364 [D loss: 0.538825, acc: 64.06%] [G loss: 3.705822]\n",
      "epoch:37 step:29365 [D loss: 0.572289, acc: 77.34%] [G loss: 6.569496]\n",
      "epoch:37 step:29366 [D loss: 0.472916, acc: 82.03%] [G loss: 5.695697]\n",
      "epoch:37 step:29367 [D loss: 0.010251, acc: 100.00%] [G loss: 8.691309]\n",
      "epoch:37 step:29368 [D loss: 0.872163, acc: 42.19%] [G loss: 4.161336]\n",
      "epoch:37 step:29369 [D loss: 0.080195, acc: 100.00%] [G loss: 6.496973]\n",
      "epoch:37 step:29370 [D loss: 0.895522, acc: 53.12%] [G loss: 4.723482]\n",
      "epoch:37 step:29371 [D loss: 0.762015, acc: 54.69%] [G loss: 4.947391]\n",
      "epoch:37 step:29372 [D loss: 0.432489, acc: 82.03%] [G loss: 3.540738]\n",
      "epoch:37 step:29373 [D loss: 0.924740, acc: 50.78%] [G loss: 5.403649]\n",
      "epoch:37 step:29374 [D loss: 0.193113, acc: 96.09%] [G loss: 10.162419]\n",
      "epoch:37 step:29375 [D loss: 0.256606, acc: 94.53%] [G loss: 5.834995]\n",
      "epoch:37 step:29376 [D loss: 0.320667, acc: 82.81%] [G loss: 5.675686]\n",
      "epoch:37 step:29377 [D loss: 0.099076, acc: 98.44%] [G loss: 3.624311]\n",
      "epoch:37 step:29378 [D loss: 0.611885, acc: 64.84%] [G loss: 5.522626]\n",
      "epoch:37 step:29379 [D loss: 0.925907, acc: 38.28%] [G loss: 7.316220]\n",
      "epoch:37 step:29380 [D loss: 0.575663, acc: 71.88%] [G loss: 5.406672]\n",
      "epoch:37 step:29381 [D loss: 0.339113, acc: 90.62%] [G loss: 4.476139]\n",
      "epoch:37 step:29382 [D loss: 0.284229, acc: 87.50%] [G loss: 7.828725]\n",
      "epoch:37 step:29383 [D loss: 0.417056, acc: 80.47%] [G loss: 3.106517]\n",
      "epoch:37 step:29384 [D loss: 0.299459, acc: 91.41%] [G loss: 6.892513]\n",
      "epoch:37 step:29385 [D loss: 0.371873, acc: 89.84%] [G loss: 3.879712]\n",
      "epoch:37 step:29386 [D loss: 0.066644, acc: 100.00%] [G loss: 4.086341]\n",
      "epoch:37 step:29387 [D loss: 0.115605, acc: 100.00%] [G loss: 6.251197]\n",
      "epoch:37 step:29388 [D loss: 0.302624, acc: 88.28%] [G loss: 4.267334]\n",
      "epoch:37 step:29389 [D loss: 0.030899, acc: 100.00%] [G loss: 4.675809]\n",
      "epoch:37 step:29390 [D loss: 0.217307, acc: 97.66%] [G loss: 7.258627]\n",
      "epoch:37 step:29391 [D loss: 0.302859, acc: 91.41%] [G loss: 3.492062]\n",
      "epoch:37 step:29392 [D loss: 0.157967, acc: 98.44%] [G loss: 3.271568]\n",
      "epoch:37 step:29393 [D loss: 0.765773, acc: 56.25%] [G loss: 3.839349]\n",
      "epoch:37 step:29394 [D loss: 0.013263, acc: 100.00%] [G loss: 9.856431]\n",
      "epoch:37 step:29395 [D loss: 0.407061, acc: 74.22%] [G loss: 8.548801]\n",
      "epoch:37 step:29396 [D loss: 0.270954, acc: 97.66%] [G loss: 6.175165]\n",
      "epoch:37 step:29397 [D loss: 0.252642, acc: 95.31%] [G loss: 8.395523]\n",
      "epoch:37 step:29398 [D loss: 0.052774, acc: 100.00%] [G loss: 4.548732]\n",
      "epoch:37 step:29399 [D loss: 0.126249, acc: 100.00%] [G loss: 4.099405]\n",
      "epoch:37 step:29400 [D loss: 0.008865, acc: 100.00%] [G loss: 7.180406]\n",
      "epoch:37 step:29401 [D loss: 0.685254, acc: 57.81%] [G loss: 3.054320]\n",
      "epoch:37 step:29402 [D loss: 0.192306, acc: 96.09%] [G loss: 2.438923]\n",
      "epoch:37 step:29403 [D loss: 0.425974, acc: 82.81%] [G loss: 2.944422]\n",
      "epoch:37 step:29404 [D loss: 0.347602, acc: 81.25%] [G loss: 1.884060]\n",
      "epoch:37 step:29405 [D loss: 1.569354, acc: 25.00%] [G loss: 5.760703]\n",
      "epoch:37 step:29406 [D loss: 0.136454, acc: 100.00%] [G loss: 4.783476]\n",
      "epoch:37 step:29407 [D loss: 0.319108, acc: 81.25%] [G loss: 2.720026]\n",
      "epoch:37 step:29408 [D loss: 0.105350, acc: 98.44%] [G loss: 7.455007]\n",
      "epoch:37 step:29409 [D loss: 0.370396, acc: 88.28%] [G loss: 5.577400]\n",
      "epoch:37 step:29410 [D loss: 1.800926, acc: 6.25%] [G loss: 10.354252]\n",
      "epoch:37 step:29411 [D loss: 0.083762, acc: 100.00%] [G loss: 5.882322]\n",
      "epoch:37 step:29412 [D loss: 0.591020, acc: 61.72%] [G loss: 4.659163]\n",
      "epoch:37 step:29413 [D loss: 0.306654, acc: 93.75%] [G loss: 5.152073]\n",
      "epoch:37 step:29414 [D loss: 0.051440, acc: 100.00%] [G loss: 7.237167]\n",
      "epoch:37 step:29415 [D loss: 0.563077, acc: 71.09%] [G loss: 6.140534]\n",
      "epoch:37 step:29416 [D loss: 0.733131, acc: 57.81%] [G loss: 5.806225]\n",
      "epoch:37 step:29417 [D loss: 0.199932, acc: 94.53%] [G loss: 5.739192]\n",
      "epoch:37 step:29418 [D loss: 0.241825, acc: 92.19%] [G loss: 5.377159]\n",
      "epoch:37 step:29419 [D loss: 0.648320, acc: 60.16%] [G loss: 3.478868]\n",
      "epoch:37 step:29420 [D loss: 0.451149, acc: 77.34%] [G loss: 4.542965]\n",
      "epoch:37 step:29421 [D loss: 0.072302, acc: 99.22%] [G loss: 4.388698]\n",
      "epoch:37 step:29422 [D loss: 0.769271, acc: 50.78%] [G loss: 4.741793]\n",
      "epoch:37 step:29423 [D loss: 0.205691, acc: 97.66%] [G loss: 4.900163]\n",
      "epoch:37 step:29424 [D loss: 0.172683, acc: 96.88%] [G loss: 5.141104]\n",
      "epoch:37 step:29425 [D loss: 0.107629, acc: 100.00%] [G loss: 4.492244]\n",
      "epoch:37 step:29426 [D loss: 0.815194, acc: 50.78%] [G loss: 3.981252]\n",
      "epoch:37 step:29427 [D loss: 0.402445, acc: 88.28%] [G loss: 3.118685]\n",
      "epoch:37 step:29428 [D loss: 0.462721, acc: 84.38%] [G loss: 5.922614]\n",
      "epoch:37 step:29429 [D loss: 0.482011, acc: 77.34%] [G loss: 4.588603]\n",
      "epoch:37 step:29430 [D loss: 0.169913, acc: 96.88%] [G loss: 5.071177]\n",
      "epoch:37 step:29431 [D loss: 0.085667, acc: 100.00%] [G loss: 6.255669]\n",
      "epoch:37 step:29432 [D loss: 0.095847, acc: 98.44%] [G loss: 6.036420]\n",
      "epoch:37 step:29433 [D loss: 0.434306, acc: 74.22%] [G loss: 8.216522]\n",
      "epoch:37 step:29434 [D loss: 0.080891, acc: 100.00%] [G loss: 6.046429]\n",
      "epoch:37 step:29435 [D loss: 0.354577, acc: 91.41%] [G loss: 5.965540]\n",
      "epoch:37 step:29436 [D loss: 0.427018, acc: 77.34%] [G loss: 3.269874]\n",
      "epoch:37 step:29437 [D loss: 0.082756, acc: 100.00%] [G loss: 4.780042]\n",
      "epoch:37 step:29438 [D loss: 0.334077, acc: 89.06%] [G loss: 2.934981]\n",
      "epoch:37 step:29439 [D loss: 0.157140, acc: 100.00%] [G loss: 3.802517]\n",
      "epoch:37 step:29440 [D loss: 0.872131, acc: 53.91%] [G loss: 5.344410]\n",
      "epoch:37 step:29441 [D loss: 0.422750, acc: 71.88%] [G loss: 6.018647]\n",
      "epoch:37 step:29442 [D loss: 0.252337, acc: 96.88%] [G loss: 4.850498]\n",
      "epoch:37 step:29443 [D loss: 0.257325, acc: 95.31%] [G loss: 6.264465]\n",
      "epoch:37 step:29444 [D loss: 0.965305, acc: 51.56%] [G loss: 3.703953]\n",
      "epoch:37 step:29445 [D loss: 0.046424, acc: 100.00%] [G loss: 5.170259]\n",
      "epoch:37 step:29446 [D loss: 0.717448, acc: 55.47%] [G loss: 7.042166]\n",
      "epoch:37 step:29447 [D loss: 0.157497, acc: 99.22%] [G loss: 4.132775]\n",
      "epoch:37 step:29448 [D loss: 0.263985, acc: 95.31%] [G loss: 3.867070]\n",
      "epoch:37 step:29449 [D loss: 0.070753, acc: 100.00%] [G loss: 4.656388]\n",
      "epoch:37 step:29450 [D loss: 0.283184, acc: 97.66%] [G loss: 2.652808]\n",
      "epoch:37 step:29451 [D loss: 1.174630, acc: 50.00%] [G loss: 3.430853]\n",
      "epoch:37 step:29452 [D loss: 0.122511, acc: 96.88%] [G loss: 9.374109]\n",
      "epoch:37 step:29453 [D loss: 0.423364, acc: 69.53%] [G loss: 6.692116]\n",
      "epoch:37 step:29454 [D loss: 1.044161, acc: 49.22%] [G loss: 4.530988]\n",
      "epoch:37 step:29455 [D loss: 0.185233, acc: 96.09%] [G loss: 6.678888]\n",
      "epoch:37 step:29456 [D loss: 0.142038, acc: 99.22%] [G loss: 6.318240]\n",
      "epoch:37 step:29457 [D loss: 0.240225, acc: 96.09%] [G loss: 6.955636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29458 [D loss: 0.134066, acc: 99.22%] [G loss: 4.824528]\n",
      "epoch:37 step:29459 [D loss: 0.735461, acc: 59.38%] [G loss: 7.845430]\n",
      "epoch:37 step:29460 [D loss: 0.740383, acc: 54.69%] [G loss: 6.894706]\n",
      "epoch:37 step:29461 [D loss: 0.467469, acc: 71.88%] [G loss: 3.526561]\n",
      "epoch:37 step:29462 [D loss: 0.343620, acc: 79.69%] [G loss: 8.144623]\n",
      "epoch:37 step:29463 [D loss: 0.048868, acc: 100.00%] [G loss: 6.315460]\n",
      "epoch:37 step:29464 [D loss: 0.500845, acc: 73.44%] [G loss: 4.970681]\n",
      "epoch:37 step:29465 [D loss: 0.174195, acc: 97.66%] [G loss: 5.376615]\n",
      "epoch:37 step:29466 [D loss: 0.117657, acc: 99.22%] [G loss: 5.202065]\n",
      "epoch:37 step:29467 [D loss: 0.332880, acc: 92.19%] [G loss: 4.045650]\n",
      "epoch:37 step:29468 [D loss: 0.203555, acc: 96.88%] [G loss: 4.818281]\n",
      "epoch:37 step:29469 [D loss: 0.577729, acc: 62.50%] [G loss: 6.165421]\n",
      "epoch:37 step:29470 [D loss: 0.904172, acc: 51.56%] [G loss: 5.847745]\n",
      "epoch:37 step:29471 [D loss: 0.516073, acc: 63.28%] [G loss: 7.415475]\n",
      "epoch:37 step:29472 [D loss: 2.374867, acc: 50.00%] [G loss: 3.211846]\n",
      "epoch:37 step:29473 [D loss: 0.057387, acc: 100.00%] [G loss: 4.682216]\n",
      "epoch:37 step:29474 [D loss: 0.258626, acc: 96.09%] [G loss: 5.847707]\n",
      "epoch:37 step:29475 [D loss: 0.224632, acc: 92.19%] [G loss: 6.738843]\n",
      "epoch:37 step:29476 [D loss: 0.157284, acc: 96.09%] [G loss: 3.710060]\n",
      "epoch:37 step:29477 [D loss: 0.095443, acc: 100.00%] [G loss: 3.609996]\n",
      "epoch:37 step:29478 [D loss: 0.176143, acc: 99.22%] [G loss: 5.995305]\n",
      "epoch:37 step:29479 [D loss: 0.184253, acc: 98.44%] [G loss: 4.081352]\n",
      "epoch:37 step:29480 [D loss: 0.592700, acc: 71.09%] [G loss: 5.553793]\n",
      "epoch:37 step:29481 [D loss: 0.176374, acc: 96.88%] [G loss: 5.571004]\n",
      "epoch:37 step:29482 [D loss: 0.721488, acc: 54.69%] [G loss: 4.380748]\n",
      "epoch:37 step:29483 [D loss: 0.265406, acc: 93.75%] [G loss: 4.894724]\n",
      "epoch:37 step:29484 [D loss: 0.218701, acc: 95.31%] [G loss: 6.393354]\n",
      "epoch:37 step:29485 [D loss: 0.394006, acc: 78.91%] [G loss: 5.807668]\n",
      "epoch:37 step:29486 [D loss: 0.405715, acc: 75.00%] [G loss: 4.837803]\n",
      "epoch:37 step:29487 [D loss: 0.556104, acc: 67.97%] [G loss: 4.496669]\n",
      "epoch:37 step:29488 [D loss: 0.047204, acc: 100.00%] [G loss: 6.300767]\n",
      "epoch:37 step:29489 [D loss: 0.009550, acc: 100.00%] [G loss: 8.484058]\n",
      "epoch:37 step:29490 [D loss: 0.162878, acc: 99.22%] [G loss: 3.400696]\n",
      "epoch:37 step:29491 [D loss: 1.147414, acc: 42.19%] [G loss: 4.605202]\n",
      "epoch:37 step:29492 [D loss: 0.620754, acc: 56.25%] [G loss: 4.437880]\n",
      "epoch:37 step:29493 [D loss: 0.125115, acc: 100.00%] [G loss: 5.934144]\n",
      "epoch:37 step:29494 [D loss: 0.268596, acc: 93.75%] [G loss: 4.154813]\n",
      "epoch:37 step:29495 [D loss: 0.632861, acc: 62.50%] [G loss: 5.216445]\n",
      "epoch:37 step:29496 [D loss: 0.379665, acc: 78.12%] [G loss: 4.540367]\n",
      "epoch:37 step:29497 [D loss: 0.290009, acc: 93.75%] [G loss: 5.697133]\n",
      "epoch:37 step:29498 [D loss: 0.093568, acc: 100.00%] [G loss: 7.812115]\n",
      "epoch:37 step:29499 [D loss: 0.065567, acc: 100.00%] [G loss: 5.491840]\n",
      "epoch:37 step:29500 [D loss: 0.365607, acc: 85.16%] [G loss: 4.703966]\n",
      "epoch:37 step:29501 [D loss: 0.378241, acc: 82.81%] [G loss: 5.720112]\n",
      "epoch:37 step:29502 [D loss: 0.756691, acc: 55.47%] [G loss: 6.082036]\n",
      "epoch:37 step:29503 [D loss: 0.594779, acc: 63.28%] [G loss: 3.348954]\n",
      "epoch:37 step:29504 [D loss: 0.141961, acc: 97.66%] [G loss: 5.291382]\n",
      "epoch:37 step:29505 [D loss: 0.121671, acc: 99.22%] [G loss: 3.302575]\n",
      "epoch:37 step:29506 [D loss: 0.837352, acc: 52.34%] [G loss: 6.166862]\n",
      "epoch:37 step:29507 [D loss: 0.997274, acc: 42.97%] [G loss: 7.908994]\n",
      "epoch:37 step:29508 [D loss: 0.355855, acc: 86.72%] [G loss: 2.976465]\n",
      "epoch:37 step:29509 [D loss: 0.210298, acc: 93.75%] [G loss: 5.321964]\n",
      "epoch:37 step:29510 [D loss: 0.753503, acc: 50.00%] [G loss: 5.820340]\n",
      "epoch:37 step:29511 [D loss: 0.402193, acc: 82.81%] [G loss: 8.448427]\n",
      "epoch:37 step:29512 [D loss: 0.137488, acc: 99.22%] [G loss: 4.356108]\n",
      "epoch:37 step:29513 [D loss: 0.813242, acc: 50.78%] [G loss: 5.394960]\n",
      "epoch:37 step:29514 [D loss: 0.332502, acc: 90.62%] [G loss: 4.193463]\n",
      "epoch:37 step:29515 [D loss: 0.382903, acc: 83.59%] [G loss: 4.037647]\n",
      "epoch:37 step:29516 [D loss: 0.035038, acc: 100.00%] [G loss: 5.486330]\n",
      "epoch:37 step:29517 [D loss: 0.264089, acc: 95.31%] [G loss: 5.182449]\n",
      "epoch:37 step:29518 [D loss: 0.410733, acc: 80.47%] [G loss: 2.773426]\n",
      "epoch:37 step:29519 [D loss: 0.570651, acc: 75.00%] [G loss: 4.004023]\n",
      "epoch:37 step:29520 [D loss: 0.280486, acc: 98.44%] [G loss: 4.154073]\n",
      "epoch:37 step:29521 [D loss: 0.095093, acc: 100.00%] [G loss: 7.319435]\n",
      "epoch:37 step:29522 [D loss: 0.367805, acc: 89.84%] [G loss: 5.972121]\n",
      "epoch:37 step:29523 [D loss: 1.368315, acc: 50.00%] [G loss: 3.452093]\n",
      "epoch:37 step:29524 [D loss: 0.129480, acc: 97.66%] [G loss: 4.852753]\n",
      "epoch:37 step:29525 [D loss: 0.595125, acc: 67.19%] [G loss: 5.828197]\n",
      "epoch:37 step:29526 [D loss: 0.315291, acc: 91.41%] [G loss: 6.710570]\n",
      "epoch:37 step:29527 [D loss: 0.098650, acc: 100.00%] [G loss: 7.728434]\n",
      "epoch:37 step:29528 [D loss: 0.139974, acc: 100.00%] [G loss: 4.606632]\n",
      "epoch:37 step:29529 [D loss: 0.109939, acc: 100.00%] [G loss: 4.114294]\n",
      "epoch:37 step:29530 [D loss: 0.219946, acc: 97.66%] [G loss: 3.364964]\n",
      "epoch:37 step:29531 [D loss: 0.345720, acc: 82.81%] [G loss: 8.420153]\n",
      "epoch:37 step:29532 [D loss: 0.445964, acc: 76.56%] [G loss: 3.897888]\n",
      "epoch:37 step:29533 [D loss: 0.535238, acc: 75.78%] [G loss: 4.208221]\n",
      "epoch:37 step:29534 [D loss: 0.186776, acc: 97.66%] [G loss: 6.462582]\n",
      "epoch:37 step:29535 [D loss: 0.131088, acc: 98.44%] [G loss: 4.842426]\n",
      "epoch:37 step:29536 [D loss: 0.546948, acc: 68.75%] [G loss: 3.465960]\n",
      "epoch:37 step:29537 [D loss: 0.285423, acc: 91.41%] [G loss: 5.591865]\n",
      "epoch:37 step:29538 [D loss: 0.666158, acc: 58.59%] [G loss: 7.601282]\n",
      "epoch:37 step:29539 [D loss: 1.062411, acc: 50.78%] [G loss: 4.621256]\n",
      "epoch:37 step:29540 [D loss: 0.301984, acc: 84.38%] [G loss: 4.173617]\n",
      "epoch:37 step:29541 [D loss: 0.221602, acc: 100.00%] [G loss: 4.509443]\n",
      "epoch:37 step:29542 [D loss: 0.629326, acc: 59.38%] [G loss: 6.409106]\n",
      "epoch:37 step:29543 [D loss: 0.265589, acc: 90.62%] [G loss: 4.281018]\n",
      "epoch:37 step:29544 [D loss: 0.220730, acc: 97.66%] [G loss: 4.188450]\n",
      "epoch:37 step:29545 [D loss: 0.065502, acc: 100.00%] [G loss: 5.321987]\n",
      "epoch:37 step:29546 [D loss: 0.407306, acc: 86.72%] [G loss: 2.893411]\n",
      "epoch:37 step:29547 [D loss: 0.339080, acc: 91.41%] [G loss: 4.823438]\n",
      "epoch:37 step:29548 [D loss: 0.541249, acc: 71.09%] [G loss: 8.869157]\n",
      "epoch:37 step:29549 [D loss: 0.854885, acc: 50.00%] [G loss: 6.968966]\n",
      "epoch:37 step:29550 [D loss: 0.615794, acc: 58.59%] [G loss: 7.442537]\n",
      "epoch:37 step:29551 [D loss: 0.199393, acc: 94.53%] [G loss: 6.716154]\n",
      "epoch:37 step:29552 [D loss: 0.442964, acc: 72.66%] [G loss: 6.735006]\n",
      "epoch:37 step:29553 [D loss: 0.705252, acc: 61.72%] [G loss: 8.392070]\n",
      "epoch:37 step:29554 [D loss: 0.245004, acc: 95.31%] [G loss: 4.124537]\n",
      "epoch:37 step:29555 [D loss: 1.375302, acc: 32.03%] [G loss: 6.573585]\n",
      "epoch:37 step:29556 [D loss: 0.222531, acc: 96.09%] [G loss: 3.753814]\n",
      "epoch:37 step:29557 [D loss: 0.421298, acc: 82.81%] [G loss: 3.253471]\n",
      "epoch:37 step:29558 [D loss: 0.021436, acc: 100.00%] [G loss: 4.370590]\n",
      "epoch:37 step:29559 [D loss: 0.184069, acc: 95.31%] [G loss: 4.350564]\n",
      "epoch:37 step:29560 [D loss: 0.214186, acc: 92.97%] [G loss: 4.834663]\n",
      "epoch:37 step:29561 [D loss: 0.151838, acc: 99.22%] [G loss: 4.425256]\n",
      "epoch:37 step:29562 [D loss: 0.486618, acc: 75.00%] [G loss: 5.947430]\n",
      "epoch:37 step:29563 [D loss: 0.224609, acc: 99.22%] [G loss: 4.498361]\n",
      "epoch:37 step:29564 [D loss: 0.283760, acc: 85.16%] [G loss: 6.725817]\n",
      "epoch:37 step:29565 [D loss: 0.156084, acc: 99.22%] [G loss: 2.797606]\n",
      "epoch:37 step:29566 [D loss: 0.179090, acc: 96.88%] [G loss: 7.508508]\n",
      "epoch:37 step:29567 [D loss: 1.822934, acc: 4.69%] [G loss: 7.347844]\n",
      "epoch:37 step:29568 [D loss: 0.582305, acc: 63.28%] [G loss: 6.740438]\n",
      "epoch:37 step:29569 [D loss: 0.226704, acc: 95.31%] [G loss: 4.696290]\n",
      "epoch:37 step:29570 [D loss: 0.643470, acc: 63.28%] [G loss: 3.673847]\n",
      "epoch:37 step:29571 [D loss: 0.092471, acc: 100.00%] [G loss: 4.759579]\n",
      "epoch:37 step:29572 [D loss: 0.426980, acc: 81.25%] [G loss: 7.201593]\n",
      "epoch:37 step:29573 [D loss: 0.089678, acc: 100.00%] [G loss: 4.242827]\n",
      "epoch:37 step:29574 [D loss: 0.230907, acc: 96.88%] [G loss: 5.274155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29575 [D loss: 0.168328, acc: 98.44%] [G loss: 3.052148]\n",
      "epoch:37 step:29576 [D loss: 0.129511, acc: 100.00%] [G loss: 4.600234]\n",
      "epoch:37 step:29577 [D loss: 0.784681, acc: 52.34%] [G loss: 6.572374]\n",
      "epoch:37 step:29578 [D loss: 0.143559, acc: 98.44%] [G loss: 6.049451]\n",
      "epoch:37 step:29579 [D loss: 0.828449, acc: 52.34%] [G loss: 5.174768]\n",
      "epoch:37 step:29580 [D loss: 0.288648, acc: 95.31%] [G loss: 5.845400]\n",
      "epoch:37 step:29581 [D loss: 0.182053, acc: 98.44%] [G loss: 4.605927]\n",
      "epoch:37 step:29582 [D loss: 0.145185, acc: 98.44%] [G loss: 4.147782]\n",
      "epoch:37 step:29583 [D loss: 0.340785, acc: 81.25%] [G loss: 4.354554]\n",
      "epoch:37 step:29584 [D loss: 0.329859, acc: 90.62%] [G loss: 3.444640]\n",
      "epoch:37 step:29585 [D loss: 0.102862, acc: 99.22%] [G loss: 5.361535]\n",
      "epoch:37 step:29586 [D loss: 0.175530, acc: 97.66%] [G loss: 2.818239]\n",
      "epoch:37 step:29587 [D loss: 0.075104, acc: 99.22%] [G loss: 5.771296]\n",
      "epoch:37 step:29588 [D loss: 0.350061, acc: 82.81%] [G loss: 3.898605]\n",
      "epoch:37 step:29589 [D loss: 0.557335, acc: 67.19%] [G loss: 4.207553]\n",
      "epoch:37 step:29590 [D loss: 0.114459, acc: 100.00%] [G loss: 2.130717]\n",
      "epoch:37 step:29591 [D loss: 0.419670, acc: 86.72%] [G loss: 7.659798]\n",
      "epoch:37 step:29592 [D loss: 0.304296, acc: 82.81%] [G loss: 5.251618]\n",
      "epoch:37 step:29593 [D loss: 0.251000, acc: 95.31%] [G loss: 4.682099]\n",
      "epoch:37 step:29594 [D loss: 0.368828, acc: 76.56%] [G loss: 6.197369]\n",
      "epoch:37 step:29595 [D loss: 0.272248, acc: 94.53%] [G loss: 3.516318]\n",
      "epoch:37 step:29596 [D loss: 0.134701, acc: 99.22%] [G loss: 4.767439]\n",
      "epoch:37 step:29597 [D loss: 0.367622, acc: 92.19%] [G loss: 6.660402]\n",
      "epoch:37 step:29598 [D loss: 1.190271, acc: 19.53%] [G loss: 4.134139]\n",
      "epoch:37 step:29599 [D loss: 0.203031, acc: 96.09%] [G loss: 3.870151]\n",
      "epoch:37 step:29600 [D loss: 0.651999, acc: 59.38%] [G loss: 6.036016]\n",
      "epoch:37 step:29601 [D loss: 0.405332, acc: 71.88%] [G loss: 4.821382]\n",
      "epoch:37 step:29602 [D loss: 0.140706, acc: 99.22%] [G loss: 5.309176]\n",
      "epoch:37 step:29603 [D loss: 0.491091, acc: 69.53%] [G loss: 4.918186]\n",
      "epoch:37 step:29604 [D loss: 0.118171, acc: 99.22%] [G loss: 5.624829]\n",
      "epoch:37 step:29605 [D loss: 0.136651, acc: 98.44%] [G loss: 2.278970]\n",
      "epoch:37 step:29606 [D loss: 0.325535, acc: 89.84%] [G loss: 2.388178]\n",
      "epoch:37 step:29607 [D loss: 0.403215, acc: 91.41%] [G loss: 4.422108]\n",
      "epoch:37 step:29608 [D loss: 0.318897, acc: 93.75%] [G loss: 8.623035]\n",
      "epoch:37 step:29609 [D loss: 0.024258, acc: 100.00%] [G loss: 6.101885]\n",
      "epoch:37 step:29610 [D loss: 0.065857, acc: 100.00%] [G loss: 6.018826]\n",
      "epoch:37 step:29611 [D loss: 0.390367, acc: 78.12%] [G loss: 5.880848]\n",
      "epoch:37 step:29612 [D loss: 0.141798, acc: 97.66%] [G loss: 5.195601]\n",
      "epoch:37 step:29613 [D loss: 0.035190, acc: 100.00%] [G loss: 4.576287]\n",
      "epoch:37 step:29614 [D loss: 1.170697, acc: 15.62%] [G loss: 6.249587]\n",
      "epoch:37 step:29615 [D loss: 0.137324, acc: 98.44%] [G loss: 3.453158]\n",
      "epoch:37 step:29616 [D loss: 0.126054, acc: 99.22%] [G loss: 5.539360]\n",
      "epoch:37 step:29617 [D loss: 0.455169, acc: 82.03%] [G loss: 6.270334]\n",
      "epoch:37 step:29618 [D loss: 0.023892, acc: 100.00%] [G loss: 7.073953]\n",
      "epoch:37 step:29619 [D loss: 0.116848, acc: 100.00%] [G loss: 5.778892]\n",
      "epoch:37 step:29620 [D loss: 0.023460, acc: 100.00%] [G loss: 7.001430]\n",
      "epoch:37 step:29621 [D loss: 0.143245, acc: 99.22%] [G loss: 5.351271]\n",
      "epoch:37 step:29622 [D loss: 0.546887, acc: 71.88%] [G loss: 6.421422]\n",
      "epoch:37 step:29623 [D loss: 0.100787, acc: 100.00%] [G loss: 8.988279]\n",
      "epoch:37 step:29624 [D loss: 0.393030, acc: 80.47%] [G loss: 5.722093]\n",
      "epoch:37 step:29625 [D loss: 0.179772, acc: 97.66%] [G loss: 5.219929]\n",
      "epoch:37 step:29626 [D loss: 0.133228, acc: 100.00%] [G loss: 5.997311]\n",
      "epoch:37 step:29627 [D loss: 0.858147, acc: 53.91%] [G loss: 7.883421]\n",
      "epoch:37 step:29628 [D loss: 1.421954, acc: 50.00%] [G loss: 9.444319]\n",
      "epoch:37 step:29629 [D loss: 0.413531, acc: 85.16%] [G loss: 4.106795]\n",
      "epoch:37 step:29630 [D loss: 0.711804, acc: 53.91%] [G loss: 5.187126]\n",
      "epoch:37 step:29631 [D loss: 0.160551, acc: 98.44%] [G loss: 4.157208]\n",
      "epoch:37 step:29632 [D loss: 0.031256, acc: 100.00%] [G loss: 5.748952]\n",
      "epoch:37 step:29633 [D loss: 0.045925, acc: 100.00%] [G loss: 3.498491]\n",
      "epoch:37 step:29634 [D loss: 0.022753, acc: 100.00%] [G loss: 6.257136]\n",
      "epoch:37 step:29635 [D loss: 1.527584, acc: 50.00%] [G loss: 6.514114]\n",
      "epoch:37 step:29636 [D loss: 0.588935, acc: 57.81%] [G loss: 7.466023]\n",
      "epoch:37 step:29637 [D loss: 0.291690, acc: 96.09%] [G loss: 5.945154]\n",
      "epoch:37 step:29638 [D loss: 0.184094, acc: 97.66%] [G loss: 5.520329]\n",
      "epoch:37 step:29639 [D loss: 0.821606, acc: 43.75%] [G loss: 4.117696]\n",
      "epoch:37 step:29640 [D loss: 0.096594, acc: 100.00%] [G loss: 1.882208]\n",
      "epoch:37 step:29641 [D loss: 0.489767, acc: 64.84%] [G loss: 4.462728]\n",
      "epoch:37 step:29642 [D loss: 0.444240, acc: 77.34%] [G loss: 6.098073]\n",
      "epoch:37 step:29643 [D loss: 0.068163, acc: 100.00%] [G loss: 7.508917]\n",
      "epoch:37 step:29644 [D loss: 0.182286, acc: 94.53%] [G loss: 5.531573]\n",
      "epoch:37 step:29645 [D loss: 0.406901, acc: 85.94%] [G loss: 7.513086]\n",
      "epoch:37 step:29646 [D loss: 0.146935, acc: 98.44%] [G loss: 4.104386]\n",
      "epoch:37 step:29647 [D loss: 0.501821, acc: 80.47%] [G loss: 5.404188]\n",
      "epoch:37 step:29648 [D loss: 0.460299, acc: 82.03%] [G loss: 8.301123]\n",
      "epoch:37 step:29649 [D loss: 0.090378, acc: 100.00%] [G loss: 4.688177]\n",
      "epoch:37 step:29650 [D loss: 0.917836, acc: 52.34%] [G loss: 4.414265]\n",
      "epoch:37 step:29651 [D loss: 0.212602, acc: 92.19%] [G loss: 3.723624]\n",
      "epoch:37 step:29652 [D loss: 0.166715, acc: 96.09%] [G loss: 6.623739]\n",
      "epoch:37 step:29653 [D loss: 0.484048, acc: 73.44%] [G loss: 5.816908]\n",
      "epoch:37 step:29654 [D loss: 0.083689, acc: 99.22%] [G loss: 6.459360]\n",
      "epoch:37 step:29655 [D loss: 0.838707, acc: 46.09%] [G loss: 6.527453]\n",
      "epoch:37 step:29656 [D loss: 0.189510, acc: 93.75%] [G loss: 6.385465]\n",
      "epoch:37 step:29657 [D loss: 0.478031, acc: 68.75%] [G loss: 6.161958]\n",
      "epoch:37 step:29658 [D loss: 0.105959, acc: 100.00%] [G loss: 2.670177]\n",
      "epoch:37 step:29659 [D loss: 1.271672, acc: 8.59%] [G loss: 7.286489]\n",
      "epoch:37 step:29660 [D loss: 0.344208, acc: 81.25%] [G loss: 6.593453]\n",
      "epoch:37 step:29661 [D loss: 0.760271, acc: 53.91%] [G loss: 4.461982]\n",
      "epoch:37 step:29662 [D loss: 0.215812, acc: 98.44%] [G loss: 4.213580]\n",
      "epoch:37 step:29663 [D loss: 0.293837, acc: 92.97%] [G loss: 6.339746]\n",
      "epoch:37 step:29664 [D loss: 0.164148, acc: 98.44%] [G loss: 7.569769]\n",
      "epoch:37 step:29665 [D loss: 0.104878, acc: 99.22%] [G loss: 5.956564]\n",
      "epoch:37 step:29666 [D loss: 0.139782, acc: 100.00%] [G loss: 5.300196]\n",
      "epoch:37 step:29667 [D loss: 0.231791, acc: 95.31%] [G loss: 3.365282]\n",
      "epoch:37 step:29668 [D loss: 0.214625, acc: 97.66%] [G loss: 7.290313]\n",
      "epoch:37 step:29669 [D loss: 0.301931, acc: 96.09%] [G loss: 6.134927]\n",
      "epoch:37 step:29670 [D loss: 0.089385, acc: 100.00%] [G loss: 6.973849]\n",
      "epoch:37 step:29671 [D loss: 0.134514, acc: 98.44%] [G loss: 6.017596]\n",
      "epoch:37 step:29672 [D loss: 0.106129, acc: 98.44%] [G loss: 3.059122]\n",
      "epoch:37 step:29673 [D loss: 0.330354, acc: 80.47%] [G loss: 6.394027]\n",
      "epoch:37 step:29674 [D loss: 1.186452, acc: 50.00%] [G loss: 5.066026]\n",
      "epoch:37 step:29675 [D loss: 0.075095, acc: 100.00%] [G loss: 5.004572]\n",
      "epoch:37 step:29676 [D loss: 0.723947, acc: 56.25%] [G loss: 6.523774]\n",
      "epoch:37 step:29677 [D loss: 0.228327, acc: 93.75%] [G loss: 5.332134]\n",
      "epoch:37 step:29678 [D loss: 0.245085, acc: 93.75%] [G loss: 3.948965]\n",
      "epoch:38 step:29679 [D loss: 0.372337, acc: 80.47%] [G loss: 4.313837]\n",
      "epoch:38 step:29680 [D loss: 0.089455, acc: 99.22%] [G loss: 5.024334]\n",
      "epoch:38 step:29681 [D loss: 0.354978, acc: 82.03%] [G loss: 4.221735]\n",
      "epoch:38 step:29682 [D loss: 0.303829, acc: 95.31%] [G loss: 4.988522]\n",
      "epoch:38 step:29683 [D loss: 0.454844, acc: 67.97%] [G loss: 6.428497]\n",
      "epoch:38 step:29684 [D loss: 0.271744, acc: 89.06%] [G loss: 7.514128]\n",
      "epoch:38 step:29685 [D loss: 0.202649, acc: 96.88%] [G loss: 5.108171]\n",
      "epoch:38 step:29686 [D loss: 0.230439, acc: 91.41%] [G loss: 5.619410]\n",
      "epoch:38 step:29687 [D loss: 1.337942, acc: 11.72%] [G loss: 5.507800]\n",
      "epoch:38 step:29688 [D loss: 0.197619, acc: 95.31%] [G loss: 5.103881]\n",
      "epoch:38 step:29689 [D loss: 0.140639, acc: 99.22%] [G loss: 4.951715]\n",
      "epoch:38 step:29690 [D loss: 0.164073, acc: 99.22%] [G loss: 5.402411]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:29691 [D loss: 0.506381, acc: 71.09%] [G loss: 7.167744]\n",
      "epoch:38 step:29692 [D loss: 0.135822, acc: 98.44%] [G loss: 7.306067]\n",
      "epoch:38 step:29693 [D loss: 0.544055, acc: 64.84%] [G loss: 4.834229]\n",
      "epoch:38 step:29694 [D loss: 0.726957, acc: 56.25%] [G loss: 3.825050]\n",
      "epoch:38 step:29695 [D loss: 0.255898, acc: 90.62%] [G loss: 5.341994]\n",
      "epoch:38 step:29696 [D loss: 0.113572, acc: 97.66%] [G loss: 5.145503]\n",
      "epoch:38 step:29697 [D loss: 0.252104, acc: 92.19%] [G loss: 4.960868]\n",
      "epoch:38 step:29698 [D loss: 0.207860, acc: 97.66%] [G loss: 2.599562]\n",
      "epoch:38 step:29699 [D loss: 0.367039, acc: 88.28%] [G loss: 4.671363]\n",
      "epoch:38 step:29700 [D loss: 0.284640, acc: 92.97%] [G loss: 3.571638]\n",
      "epoch:38 step:29701 [D loss: 1.319630, acc: 10.94%] [G loss: 6.582389]\n",
      "epoch:38 step:29702 [D loss: 0.737821, acc: 51.56%] [G loss: 6.104784]\n",
      "epoch:38 step:29703 [D loss: 0.615554, acc: 64.06%] [G loss: 5.645525]\n",
      "epoch:38 step:29704 [D loss: 0.174331, acc: 96.09%] [G loss: 4.197476]\n",
      "epoch:38 step:29705 [D loss: 0.435619, acc: 87.50%] [G loss: 5.211724]\n",
      "epoch:38 step:29706 [D loss: 0.440605, acc: 86.72%] [G loss: 2.313038]\n",
      "epoch:38 step:29707 [D loss: 0.267017, acc: 96.09%] [G loss: 4.231819]\n",
      "epoch:38 step:29708 [D loss: 0.087151, acc: 100.00%] [G loss: 5.950274]\n",
      "epoch:38 step:29709 [D loss: 0.162998, acc: 99.22%] [G loss: 6.086945]\n",
      "epoch:38 step:29710 [D loss: 0.866706, acc: 37.50%] [G loss: 6.643496]\n",
      "epoch:38 step:29711 [D loss: 0.197543, acc: 97.66%] [G loss: 4.589632]\n",
      "epoch:38 step:29712 [D loss: 0.214693, acc: 97.66%] [G loss: 1.872532]\n",
      "epoch:38 step:29713 [D loss: 0.436664, acc: 79.69%] [G loss: 4.008538]\n",
      "epoch:38 step:29714 [D loss: 1.304860, acc: 50.78%] [G loss: 7.215182]\n",
      "epoch:38 step:29715 [D loss: 0.377899, acc: 78.12%] [G loss: 7.065269]\n",
      "epoch:38 step:29716 [D loss: 0.920738, acc: 49.22%] [G loss: 5.443783]\n",
      "epoch:38 step:29717 [D loss: 0.265296, acc: 87.50%] [G loss: 5.380379]\n",
      "epoch:38 step:29718 [D loss: 0.133389, acc: 99.22%] [G loss: 4.139020]\n",
      "epoch:38 step:29719 [D loss: 0.314052, acc: 86.72%] [G loss: 5.368944]\n",
      "epoch:38 step:29720 [D loss: 0.648902, acc: 58.59%] [G loss: 3.755690]\n",
      "epoch:38 step:29721 [D loss: 0.132488, acc: 99.22%] [G loss: 4.900899]\n",
      "epoch:38 step:29722 [D loss: 0.446874, acc: 75.00%] [G loss: 4.871766]\n",
      "epoch:38 step:29723 [D loss: 0.148637, acc: 96.88%] [G loss: 5.001018]\n",
      "epoch:38 step:29724 [D loss: 0.209638, acc: 95.31%] [G loss: 6.284150]\n",
      "epoch:38 step:29725 [D loss: 0.803213, acc: 50.78%] [G loss: 2.805117]\n",
      "epoch:38 step:29726 [D loss: 0.780675, acc: 53.91%] [G loss: 5.310538]\n",
      "epoch:38 step:29727 [D loss: 0.425703, acc: 86.72%] [G loss: 5.610289]\n",
      "epoch:38 step:29728 [D loss: 0.365025, acc: 80.47%] [G loss: 3.074261]\n",
      "epoch:38 step:29729 [D loss: 1.130599, acc: 50.00%] [G loss: 5.092480]\n",
      "epoch:38 step:29730 [D loss: 0.147547, acc: 98.44%] [G loss: 4.522929]\n",
      "epoch:38 step:29731 [D loss: 0.427322, acc: 85.94%] [G loss: 4.983149]\n",
      "epoch:38 step:29732 [D loss: 0.548293, acc: 71.88%] [G loss: 5.565485]\n",
      "epoch:38 step:29733 [D loss: 0.263801, acc: 89.84%] [G loss: 4.929360]\n",
      "epoch:38 step:29734 [D loss: 0.877901, acc: 42.97%] [G loss: 5.569476]\n",
      "epoch:38 step:29735 [D loss: 0.403840, acc: 87.50%] [G loss: 3.817954]\n",
      "epoch:38 step:29736 [D loss: 0.260100, acc: 92.19%] [G loss: 5.739922]\n",
      "epoch:38 step:29737 [D loss: 0.353106, acc: 92.97%] [G loss: 6.838990]\n",
      "epoch:38 step:29738 [D loss: 0.528608, acc: 64.84%] [G loss: 5.658099]\n",
      "epoch:38 step:29739 [D loss: 0.090121, acc: 99.22%] [G loss: 5.637393]\n",
      "epoch:38 step:29740 [D loss: 0.120311, acc: 99.22%] [G loss: 5.127935]\n",
      "epoch:38 step:29741 [D loss: 0.270625, acc: 90.62%] [G loss: 5.914064]\n",
      "epoch:38 step:29742 [D loss: 0.446416, acc: 82.03%] [G loss: 5.844329]\n",
      "epoch:38 step:29743 [D loss: 0.419085, acc: 77.34%] [G loss: 7.477760]\n",
      "epoch:38 step:29744 [D loss: 0.080942, acc: 100.00%] [G loss: 4.337824]\n",
      "epoch:38 step:29745 [D loss: 1.040393, acc: 50.78%] [G loss: 3.679083]\n",
      "epoch:38 step:29746 [D loss: 0.112555, acc: 99.22%] [G loss: 4.978990]\n",
      "epoch:38 step:29747 [D loss: 0.863323, acc: 42.97%] [G loss: 5.080638]\n",
      "epoch:38 step:29748 [D loss: 0.139072, acc: 99.22%] [G loss: 3.087090]\n",
      "epoch:38 step:29749 [D loss: 1.230190, acc: 49.22%] [G loss: 6.243079]\n",
      "epoch:38 step:29750 [D loss: 0.897296, acc: 52.34%] [G loss: 6.416136]\n",
      "epoch:38 step:29751 [D loss: 0.268701, acc: 96.09%] [G loss: 4.541498]\n",
      "epoch:38 step:29752 [D loss: 0.054074, acc: 98.44%] [G loss: 4.461838]\n",
      "epoch:38 step:29753 [D loss: 0.209251, acc: 95.31%] [G loss: 6.663202]\n",
      "epoch:38 step:29754 [D loss: 0.771603, acc: 57.03%] [G loss: 5.529493]\n",
      "epoch:38 step:29755 [D loss: 0.169546, acc: 96.88%] [G loss: 4.468148]\n",
      "epoch:38 step:29756 [D loss: 0.785360, acc: 53.91%] [G loss: 6.652963]\n",
      "epoch:38 step:29757 [D loss: 0.491873, acc: 72.66%] [G loss: 5.303257]\n",
      "epoch:38 step:29758 [D loss: 0.168908, acc: 97.66%] [G loss: 4.753757]\n",
      "epoch:38 step:29759 [D loss: 0.135210, acc: 98.44%] [G loss: 4.831146]\n",
      "epoch:38 step:29760 [D loss: 0.294911, acc: 86.72%] [G loss: 4.731695]\n",
      "epoch:38 step:29761 [D loss: 0.126499, acc: 98.44%] [G loss: 3.756814]\n",
      "epoch:38 step:29762 [D loss: 0.310285, acc: 89.84%] [G loss: 5.839664]\n",
      "epoch:38 step:29763 [D loss: 0.207074, acc: 95.31%] [G loss: 6.207129]\n",
      "epoch:38 step:29764 [D loss: 0.443661, acc: 80.47%] [G loss: 6.540212]\n",
      "epoch:38 step:29765 [D loss: 0.340866, acc: 77.34%] [G loss: 6.380451]\n",
      "epoch:38 step:29766 [D loss: 0.615083, acc: 67.19%] [G loss: 5.556472]\n",
      "epoch:38 step:29767 [D loss: 0.102443, acc: 100.00%] [G loss: 4.915537]\n",
      "epoch:38 step:29768 [D loss: 0.809496, acc: 50.00%] [G loss: 5.135951]\n",
      "epoch:38 step:29769 [D loss: 0.032317, acc: 100.00%] [G loss: 5.077994]\n",
      "epoch:38 step:29770 [D loss: 0.223658, acc: 94.53%] [G loss: 2.106397]\n",
      "epoch:38 step:29771 [D loss: 0.758333, acc: 53.12%] [G loss: 6.106174]\n",
      "epoch:38 step:29772 [D loss: 0.555289, acc: 60.94%] [G loss: 6.674562]\n",
      "epoch:38 step:29773 [D loss: 0.050633, acc: 100.00%] [G loss: 4.133943]\n",
      "epoch:38 step:29774 [D loss: 0.134570, acc: 99.22%] [G loss: 4.689103]\n",
      "epoch:38 step:29775 [D loss: 0.115262, acc: 100.00%] [G loss: 2.311939]\n",
      "epoch:38 step:29776 [D loss: 0.579662, acc: 67.19%] [G loss: 3.850291]\n",
      "epoch:38 step:29777 [D loss: 0.064089, acc: 100.00%] [G loss: 6.086562]\n",
      "epoch:38 step:29778 [D loss: 0.486037, acc: 69.53%] [G loss: 5.912161]\n",
      "epoch:38 step:29779 [D loss: 0.531549, acc: 78.91%] [G loss: 4.413191]\n",
      "epoch:38 step:29780 [D loss: 0.332707, acc: 86.72%] [G loss: 5.530231]\n",
      "epoch:38 step:29781 [D loss: 1.166053, acc: 31.25%] [G loss: 5.355603]\n",
      "epoch:38 step:29782 [D loss: 0.135492, acc: 98.44%] [G loss: 5.091122]\n",
      "epoch:38 step:29783 [D loss: 0.913857, acc: 44.53%] [G loss: 6.859595]\n",
      "epoch:38 step:29784 [D loss: 0.756522, acc: 51.56%] [G loss: 3.616325]\n",
      "epoch:38 step:29785 [D loss: 0.240332, acc: 93.75%] [G loss: 5.188324]\n",
      "epoch:38 step:29786 [D loss: 0.329903, acc: 85.94%] [G loss: 5.243297]\n",
      "epoch:38 step:29787 [D loss: 0.772935, acc: 55.47%] [G loss: 6.527321]\n",
      "epoch:38 step:29788 [D loss: 0.373398, acc: 85.94%] [G loss: 4.487361]\n",
      "epoch:38 step:29789 [D loss: 0.307422, acc: 92.97%] [G loss: 3.854857]\n",
      "epoch:38 step:29790 [D loss: 0.140345, acc: 99.22%] [G loss: 5.609004]\n",
      "epoch:38 step:29791 [D loss: 0.271191, acc: 95.31%] [G loss: 5.710148]\n",
      "epoch:38 step:29792 [D loss: 0.107936, acc: 99.22%] [G loss: 6.543293]\n",
      "epoch:38 step:29793 [D loss: 0.635787, acc: 60.16%] [G loss: 4.229259]\n",
      "epoch:38 step:29794 [D loss: 0.270485, acc: 94.53%] [G loss: 7.103597]\n",
      "epoch:38 step:29795 [D loss: 0.208372, acc: 96.88%] [G loss: 3.185966]\n",
      "epoch:38 step:29796 [D loss: 0.079381, acc: 100.00%] [G loss: 6.452892]\n",
      "epoch:38 step:29797 [D loss: 0.237510, acc: 96.88%] [G loss: 4.971273]\n",
      "epoch:38 step:29798 [D loss: 0.080932, acc: 100.00%] [G loss: 6.221817]\n",
      "epoch:38 step:29799 [D loss: 0.385929, acc: 89.06%] [G loss: 3.534194]\n",
      "epoch:38 step:29800 [D loss: 0.053966, acc: 100.00%] [G loss: 4.673905]\n",
      "epoch:38 step:29801 [D loss: 0.294094, acc: 91.41%] [G loss: 3.632270]\n",
      "epoch:38 step:29802 [D loss: 1.892711, acc: 7.03%] [G loss: 5.891951]\n",
      "epoch:38 step:29803 [D loss: 0.583649, acc: 62.50%] [G loss: 5.130094]\n",
      "epoch:38 step:29804 [D loss: 0.322376, acc: 83.59%] [G loss: 3.945902]\n",
      "epoch:38 step:29805 [D loss: 0.317265, acc: 87.50%] [G loss: 8.249793]\n",
      "epoch:38 step:29806 [D loss: 0.162837, acc: 96.09%] [G loss: 3.156884]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:29807 [D loss: 1.024512, acc: 39.06%] [G loss: 6.065199]\n",
      "epoch:38 step:29808 [D loss: 0.597103, acc: 61.72%] [G loss: 6.386613]\n",
      "epoch:38 step:29809 [D loss: 0.384393, acc: 89.84%] [G loss: 4.237798]\n",
      "epoch:38 step:29810 [D loss: 0.193370, acc: 97.66%] [G loss: 3.999947]\n",
      "epoch:38 step:29811 [D loss: 0.253695, acc: 97.66%] [G loss: 3.200235]\n",
      "epoch:38 step:29812 [D loss: 0.041340, acc: 100.00%] [G loss: 6.451334]\n",
      "epoch:38 step:29813 [D loss: 0.452405, acc: 74.22%] [G loss: 3.310802]\n",
      "epoch:38 step:29814 [D loss: 0.088774, acc: 100.00%] [G loss: 8.168592]\n",
      "epoch:38 step:29815 [D loss: 0.121129, acc: 99.22%] [G loss: 4.592505]\n",
      "epoch:38 step:29816 [D loss: 0.354387, acc: 79.69%] [G loss: 7.293612]\n",
      "epoch:38 step:29817 [D loss: 0.133751, acc: 100.00%] [G loss: 3.980102]\n",
      "epoch:38 step:29818 [D loss: 0.793084, acc: 52.34%] [G loss: 5.155102]\n",
      "epoch:38 step:29819 [D loss: 0.836663, acc: 50.00%] [G loss: 5.474705]\n",
      "epoch:38 step:29820 [D loss: 0.052482, acc: 100.00%] [G loss: 6.120640]\n",
      "epoch:38 step:29821 [D loss: 0.490898, acc: 64.06%] [G loss: 6.727768]\n",
      "epoch:38 step:29822 [D loss: 0.801927, acc: 50.00%] [G loss: 2.297384]\n",
      "epoch:38 step:29823 [D loss: 0.283567, acc: 91.41%] [G loss: 6.103361]\n",
      "epoch:38 step:29824 [D loss: 0.141789, acc: 98.44%] [G loss: 4.492841]\n",
      "epoch:38 step:29825 [D loss: 0.259993, acc: 92.97%] [G loss: 4.489740]\n",
      "epoch:38 step:29826 [D loss: 0.321237, acc: 93.75%] [G loss: 4.227706]\n",
      "epoch:38 step:29827 [D loss: 0.192156, acc: 98.44%] [G loss: 8.024607]\n",
      "epoch:38 step:29828 [D loss: 0.188884, acc: 98.44%] [G loss: 3.040259]\n",
      "epoch:38 step:29829 [D loss: 0.230107, acc: 98.44%] [G loss: 3.514470]\n",
      "epoch:38 step:29830 [D loss: 0.206518, acc: 97.66%] [G loss: 3.626362]\n",
      "epoch:38 step:29831 [D loss: 0.434731, acc: 83.59%] [G loss: 4.857767]\n",
      "epoch:38 step:29832 [D loss: 0.324135, acc: 90.62%] [G loss: 4.346022]\n",
      "epoch:38 step:29833 [D loss: 0.097666, acc: 100.00%] [G loss: 4.416236]\n",
      "epoch:38 step:29834 [D loss: 0.125590, acc: 99.22%] [G loss: 4.407371]\n",
      "epoch:38 step:29835 [D loss: 0.403867, acc: 74.22%] [G loss: 5.775434]\n",
      "epoch:38 step:29836 [D loss: 0.119152, acc: 98.44%] [G loss: 3.756330]\n",
      "epoch:38 step:29837 [D loss: 1.070945, acc: 35.94%] [G loss: 5.097041]\n",
      "epoch:38 step:29838 [D loss: 0.619251, acc: 60.94%] [G loss: 4.894855]\n",
      "epoch:38 step:29839 [D loss: 0.310766, acc: 92.19%] [G loss: 4.852767]\n",
      "epoch:38 step:29840 [D loss: 0.106640, acc: 100.00%] [G loss: 5.767591]\n",
      "epoch:38 step:29841 [D loss: 0.358202, acc: 89.06%] [G loss: 4.878055]\n",
      "epoch:38 step:29842 [D loss: 0.422326, acc: 82.03%] [G loss: 7.992019]\n",
      "epoch:38 step:29843 [D loss: 0.178399, acc: 96.88%] [G loss: 6.116397]\n",
      "epoch:38 step:29844 [D loss: 1.317578, acc: 26.56%] [G loss: 7.465217]\n",
      "epoch:38 step:29845 [D loss: 0.063964, acc: 100.00%] [G loss: 4.405120]\n",
      "epoch:38 step:29846 [D loss: 0.174843, acc: 97.66%] [G loss: 5.311441]\n",
      "epoch:38 step:29847 [D loss: 0.294895, acc: 86.72%] [G loss: 6.055171]\n",
      "epoch:38 step:29848 [D loss: 0.188100, acc: 97.66%] [G loss: 4.003736]\n",
      "epoch:38 step:29849 [D loss: 0.164851, acc: 99.22%] [G loss: 4.878788]\n",
      "epoch:38 step:29850 [D loss: 0.325603, acc: 93.75%] [G loss: 4.271304]\n",
      "epoch:38 step:29851 [D loss: 0.580153, acc: 60.94%] [G loss: 8.512838]\n",
      "epoch:38 step:29852 [D loss: 0.385014, acc: 81.25%] [G loss: 4.358568]\n",
      "epoch:38 step:29853 [D loss: 0.014300, acc: 100.00%] [G loss: 6.698748]\n",
      "epoch:38 step:29854 [D loss: 0.963008, acc: 43.75%] [G loss: 5.250050]\n",
      "epoch:38 step:29855 [D loss: 0.433072, acc: 80.47%] [G loss: 5.887486]\n",
      "epoch:38 step:29856 [D loss: 1.081295, acc: 43.75%] [G loss: 5.413172]\n",
      "epoch:38 step:29857 [D loss: 1.067589, acc: 52.34%] [G loss: 7.910375]\n",
      "epoch:38 step:29858 [D loss: 0.403237, acc: 85.16%] [G loss: 5.349591]\n",
      "epoch:38 step:29859 [D loss: 0.941874, acc: 50.78%] [G loss: 4.674708]\n",
      "epoch:38 step:29860 [D loss: 0.492203, acc: 72.66%] [G loss: 5.830172]\n",
      "epoch:38 step:29861 [D loss: 0.085719, acc: 100.00%] [G loss: 4.980343]\n",
      "epoch:38 step:29862 [D loss: 0.210180, acc: 94.53%] [G loss: 5.615164]\n",
      "epoch:38 step:29863 [D loss: 1.002624, acc: 29.69%] [G loss: 7.619227]\n",
      "epoch:38 step:29864 [D loss: 0.583466, acc: 72.66%] [G loss: 4.046303]\n",
      "epoch:38 step:29865 [D loss: 0.181985, acc: 98.44%] [G loss: 4.215280]\n",
      "epoch:38 step:29866 [D loss: 0.060622, acc: 100.00%] [G loss: 4.673320]\n",
      "epoch:38 step:29867 [D loss: 0.289841, acc: 95.31%] [G loss: 6.046731]\n",
      "epoch:38 step:29868 [D loss: 0.132084, acc: 98.44%] [G loss: 3.850716]\n",
      "epoch:38 step:29869 [D loss: 0.318056, acc: 85.16%] [G loss: 7.440778]\n",
      "epoch:38 step:29870 [D loss: 0.103506, acc: 99.22%] [G loss: 5.180977]\n",
      "epoch:38 step:29871 [D loss: 0.991385, acc: 48.44%] [G loss: 8.358642]\n",
      "epoch:38 step:29872 [D loss: 0.282155, acc: 91.41%] [G loss: 7.136611]\n",
      "epoch:38 step:29873 [D loss: 0.211007, acc: 92.19%] [G loss: 5.591146]\n",
      "epoch:38 step:29874 [D loss: 0.235606, acc: 96.88%] [G loss: 4.128598]\n",
      "epoch:38 step:29875 [D loss: 0.446390, acc: 78.91%] [G loss: 4.794099]\n",
      "epoch:38 step:29876 [D loss: 0.637161, acc: 58.59%] [G loss: 5.619160]\n",
      "epoch:38 step:29877 [D loss: 1.132821, acc: 17.19%] [G loss: 5.388359]\n",
      "epoch:38 step:29878 [D loss: 0.187843, acc: 98.44%] [G loss: 4.997309]\n",
      "epoch:38 step:29879 [D loss: 0.392951, acc: 85.16%] [G loss: 3.915811]\n",
      "epoch:38 step:29880 [D loss: 0.071888, acc: 99.22%] [G loss: 4.700804]\n",
      "epoch:38 step:29881 [D loss: 0.722946, acc: 56.25%] [G loss: 6.458952]\n",
      "epoch:38 step:29882 [D loss: 0.192620, acc: 99.22%] [G loss: 3.798866]\n",
      "epoch:38 step:29883 [D loss: 0.161073, acc: 99.22%] [G loss: 4.646950]\n",
      "epoch:38 step:29884 [D loss: 0.203279, acc: 96.09%] [G loss: 5.393820]\n",
      "epoch:38 step:29885 [D loss: 0.298766, acc: 95.31%] [G loss: 5.160887]\n",
      "epoch:38 step:29886 [D loss: 0.262521, acc: 96.88%] [G loss: 5.599741]\n",
      "epoch:38 step:29887 [D loss: 0.621019, acc: 61.72%] [G loss: 3.354490]\n",
      "epoch:38 step:29888 [D loss: 0.686101, acc: 61.72%] [G loss: 6.344830]\n",
      "epoch:38 step:29889 [D loss: 0.224198, acc: 97.66%] [G loss: 4.510730]\n",
      "epoch:38 step:29890 [D loss: 0.502728, acc: 73.44%] [G loss: 4.834254]\n",
      "epoch:38 step:29891 [D loss: 0.170321, acc: 98.44%] [G loss: 5.342153]\n",
      "epoch:38 step:29892 [D loss: 0.283670, acc: 95.31%] [G loss: 2.698757]\n",
      "epoch:38 step:29893 [D loss: 0.203042, acc: 97.66%] [G loss: 6.457172]\n",
      "epoch:38 step:29894 [D loss: 0.374733, acc: 84.38%] [G loss: 6.366254]\n",
      "epoch:38 step:29895 [D loss: 0.281205, acc: 89.84%] [G loss: 4.889318]\n",
      "epoch:38 step:29896 [D loss: 0.203622, acc: 97.66%] [G loss: 4.082476]\n",
      "epoch:38 step:29897 [D loss: 1.825529, acc: 25.78%] [G loss: 6.028283]\n",
      "epoch:38 step:29898 [D loss: 0.101449, acc: 98.44%] [G loss: 5.610971]\n",
      "epoch:38 step:29899 [D loss: 0.938415, acc: 51.56%] [G loss: 4.552964]\n",
      "epoch:38 step:29900 [D loss: 0.704768, acc: 53.12%] [G loss: 3.411054]\n",
      "epoch:38 step:29901 [D loss: 0.284068, acc: 97.66%] [G loss: 4.678489]\n",
      "epoch:38 step:29902 [D loss: 0.211481, acc: 97.66%] [G loss: 5.307223]\n",
      "epoch:38 step:29903 [D loss: 0.271779, acc: 98.44%] [G loss: 8.254000]\n",
      "epoch:38 step:29904 [D loss: 0.333770, acc: 89.06%] [G loss: 5.015958]\n",
      "epoch:38 step:29905 [D loss: 0.287693, acc: 92.19%] [G loss: 5.493298]\n",
      "epoch:38 step:29906 [D loss: 0.081450, acc: 100.00%] [G loss: 4.031760]\n",
      "epoch:38 step:29907 [D loss: 0.281332, acc: 96.09%] [G loss: 5.282859]\n",
      "epoch:38 step:29908 [D loss: 0.062896, acc: 100.00%] [G loss: 5.546119]\n",
      "epoch:38 step:29909 [D loss: 0.117023, acc: 98.44%] [G loss: 4.656299]\n",
      "epoch:38 step:29910 [D loss: 0.227659, acc: 98.44%] [G loss: 5.477663]\n",
      "epoch:38 step:29911 [D loss: 0.718041, acc: 57.81%] [G loss: 7.986965]\n",
      "epoch:38 step:29912 [D loss: 0.917012, acc: 51.56%] [G loss: 7.103572]\n",
      "epoch:38 step:29913 [D loss: 0.219897, acc: 95.31%] [G loss: 4.934099]\n",
      "epoch:38 step:29914 [D loss: 0.224589, acc: 94.53%] [G loss: 4.097149]\n",
      "epoch:38 step:29915 [D loss: 0.199514, acc: 96.88%] [G loss: 4.428000]\n",
      "epoch:38 step:29916 [D loss: 0.172843, acc: 99.22%] [G loss: 4.506057]\n",
      "epoch:38 step:29917 [D loss: 0.076080, acc: 100.00%] [G loss: 6.086907]\n",
      "epoch:38 step:29918 [D loss: 0.468820, acc: 72.66%] [G loss: 5.879353]\n",
      "epoch:38 step:29919 [D loss: 1.036436, acc: 50.78%] [G loss: 6.361355]\n",
      "epoch:38 step:29920 [D loss: 0.061025, acc: 100.00%] [G loss: 5.852601]\n",
      "epoch:38 step:29921 [D loss: 0.588830, acc: 60.16%] [G loss: 2.955673]\n",
      "epoch:38 step:29922 [D loss: 0.019236, acc: 100.00%] [G loss: 10.069284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:29923 [D loss: 0.844810, acc: 52.34%] [G loss: 5.495591]\n",
      "epoch:38 step:29924 [D loss: 2.147464, acc: 28.12%] [G loss: 4.462796]\n",
      "epoch:38 step:29925 [D loss: 0.210738, acc: 96.88%] [G loss: 2.500840]\n",
      "epoch:38 step:29926 [D loss: 2.094405, acc: 8.59%] [G loss: 5.441722]\n",
      "epoch:38 step:29927 [D loss: 0.162390, acc: 94.53%] [G loss: 6.818243]\n",
      "epoch:38 step:29928 [D loss: 0.497448, acc: 69.53%] [G loss: 9.261768]\n",
      "epoch:38 step:29929 [D loss: 0.027053, acc: 100.00%] [G loss: 10.256800]\n",
      "epoch:38 step:29930 [D loss: 0.110162, acc: 98.44%] [G loss: 5.322661]\n",
      "epoch:38 step:29931 [D loss: 0.464968, acc: 75.78%] [G loss: 4.674442]\n",
      "epoch:38 step:29932 [D loss: 0.773363, acc: 53.91%] [G loss: 3.248801]\n",
      "epoch:38 step:29933 [D loss: 0.967129, acc: 50.78%] [G loss: 4.586346]\n",
      "epoch:38 step:29934 [D loss: 0.098506, acc: 100.00%] [G loss: 7.378631]\n",
      "epoch:38 step:29935 [D loss: 0.401111, acc: 88.28%] [G loss: 5.341084]\n",
      "epoch:38 step:29936 [D loss: 0.264447, acc: 87.50%] [G loss: 7.097882]\n",
      "epoch:38 step:29937 [D loss: 0.563747, acc: 60.94%] [G loss: 3.358521]\n",
      "epoch:38 step:29938 [D loss: 0.251379, acc: 92.19%] [G loss: 5.757501]\n",
      "epoch:38 step:29939 [D loss: 0.378231, acc: 76.56%] [G loss: 5.369084]\n",
      "epoch:38 step:29940 [D loss: 0.526636, acc: 65.62%] [G loss: 6.711432]\n",
      "epoch:38 step:29941 [D loss: 0.242669, acc: 92.19%] [G loss: 5.183439]\n",
      "epoch:38 step:29942 [D loss: 0.171566, acc: 98.44%] [G loss: 3.160642]\n",
      "epoch:38 step:29943 [D loss: 0.299698, acc: 88.28%] [G loss: 5.345479]\n",
      "epoch:38 step:29944 [D loss: 0.869146, acc: 35.94%] [G loss: 6.307944]\n",
      "epoch:38 step:29945 [D loss: 0.096065, acc: 100.00%] [G loss: 2.094997]\n",
      "epoch:38 step:29946 [D loss: 0.297318, acc: 85.94%] [G loss: 6.587775]\n",
      "epoch:38 step:29947 [D loss: 0.714022, acc: 57.03%] [G loss: 6.501101]\n",
      "epoch:38 step:29948 [D loss: 0.328995, acc: 83.59%] [G loss: 6.061509]\n",
      "epoch:38 step:29949 [D loss: 0.056620, acc: 100.00%] [G loss: 3.689040]\n",
      "epoch:38 step:29950 [D loss: 0.352358, acc: 86.72%] [G loss: 2.153821]\n",
      "epoch:38 step:29951 [D loss: 0.143521, acc: 99.22%] [G loss: 3.537315]\n",
      "epoch:38 step:29952 [D loss: 0.230349, acc: 92.97%] [G loss: 5.162932]\n",
      "epoch:38 step:29953 [D loss: 0.264560, acc: 94.53%] [G loss: 4.445443]\n",
      "epoch:38 step:29954 [D loss: 0.024901, acc: 100.00%] [G loss: 4.834986]\n",
      "epoch:38 step:29955 [D loss: 0.555441, acc: 64.06%] [G loss: 3.715701]\n",
      "epoch:38 step:29956 [D loss: 0.108211, acc: 100.00%] [G loss: 6.027012]\n",
      "epoch:38 step:29957 [D loss: 0.711822, acc: 57.81%] [G loss: 7.287048]\n",
      "epoch:38 step:29958 [D loss: 0.068956, acc: 100.00%] [G loss: 3.909827]\n",
      "epoch:38 step:29959 [D loss: 0.545929, acc: 73.44%] [G loss: 8.141954]\n",
      "epoch:38 step:29960 [D loss: 0.314932, acc: 89.06%] [G loss: 5.224269]\n",
      "epoch:38 step:29961 [D loss: 0.215435, acc: 98.44%] [G loss: 2.820350]\n",
      "epoch:38 step:29962 [D loss: 0.967179, acc: 41.41%] [G loss: 9.090998]\n",
      "epoch:38 step:29963 [D loss: 0.199252, acc: 96.09%] [G loss: 4.966585]\n",
      "epoch:38 step:29964 [D loss: 0.087692, acc: 100.00%] [G loss: 5.265362]\n",
      "epoch:38 step:29965 [D loss: 0.086022, acc: 99.22%] [G loss: 5.325382]\n",
      "epoch:38 step:29966 [D loss: 0.212158, acc: 94.53%] [G loss: 5.508650]\n",
      "epoch:38 step:29967 [D loss: 0.273790, acc: 93.75%] [G loss: 4.982931]\n",
      "epoch:38 step:29968 [D loss: 0.442305, acc: 67.97%] [G loss: 5.557137]\n",
      "epoch:38 step:29969 [D loss: 0.359265, acc: 92.19%] [G loss: 6.186232]\n",
      "epoch:38 step:29970 [D loss: 0.126667, acc: 99.22%] [G loss: 7.002370]\n",
      "epoch:38 step:29971 [D loss: 0.817973, acc: 53.12%] [G loss: 8.808990]\n",
      "epoch:38 step:29972 [D loss: 0.835460, acc: 50.78%] [G loss: 4.685853]\n",
      "epoch:38 step:29973 [D loss: 0.119594, acc: 97.66%] [G loss: 6.611339]\n",
      "epoch:38 step:29974 [D loss: 0.110550, acc: 99.22%] [G loss: 4.853190]\n",
      "epoch:38 step:29975 [D loss: 0.115460, acc: 99.22%] [G loss: 7.778098]\n",
      "epoch:38 step:29976 [D loss: 0.689782, acc: 59.38%] [G loss: 3.294863]\n",
      "epoch:38 step:29977 [D loss: 0.187909, acc: 96.09%] [G loss: 4.328552]\n",
      "epoch:38 step:29978 [D loss: 0.156761, acc: 97.66%] [G loss: 5.321416]\n",
      "epoch:38 step:29979 [D loss: 0.814029, acc: 52.34%] [G loss: 6.678396]\n",
      "epoch:38 step:29980 [D loss: 0.365886, acc: 92.97%] [G loss: 5.005818]\n",
      "epoch:38 step:29981 [D loss: 0.572097, acc: 67.19%] [G loss: 7.363321]\n",
      "epoch:38 step:29982 [D loss: 0.456172, acc: 78.91%] [G loss: 5.507555]\n",
      "epoch:38 step:29983 [D loss: 0.249358, acc: 92.97%] [G loss: 4.488241]\n",
      "epoch:38 step:29984 [D loss: 0.180547, acc: 96.88%] [G loss: 4.381276]\n",
      "epoch:38 step:29985 [D loss: 0.079640, acc: 100.00%] [G loss: 3.879537]\n",
      "epoch:38 step:29986 [D loss: 0.195502, acc: 97.66%] [G loss: 5.011247]\n",
      "epoch:38 step:29987 [D loss: 0.359712, acc: 91.41%] [G loss: 4.949137]\n",
      "epoch:38 step:29988 [D loss: 0.186687, acc: 97.66%] [G loss: 5.197548]\n",
      "epoch:38 step:29989 [D loss: 0.257500, acc: 89.06%] [G loss: 4.197889]\n",
      "epoch:38 step:29990 [D loss: 0.141962, acc: 99.22%] [G loss: 3.165374]\n",
      "epoch:38 step:29991 [D loss: 0.067108, acc: 100.00%] [G loss: 6.634829]\n",
      "epoch:38 step:29992 [D loss: 0.080273, acc: 99.22%] [G loss: 6.466768]\n",
      "epoch:38 step:29993 [D loss: 0.189669, acc: 94.53%] [G loss: 6.066140]\n",
      "epoch:38 step:29994 [D loss: 0.239582, acc: 91.41%] [G loss: 7.663034]\n",
      "epoch:38 step:29995 [D loss: 2.174448, acc: 49.22%] [G loss: 3.269952]\n",
      "epoch:38 step:29996 [D loss: 0.059393, acc: 100.00%] [G loss: 5.066087]\n",
      "epoch:38 step:29997 [D loss: 0.565666, acc: 60.94%] [G loss: 5.936949]\n",
      "epoch:38 step:29998 [D loss: 0.466481, acc: 82.03%] [G loss: 11.436308]\n",
      "epoch:38 step:29999 [D loss: 0.351148, acc: 87.50%] [G loss: 5.872292]\n",
      "epoch:38 step:30000 [D loss: 0.253796, acc: 96.88%] [G loss: 5.373956]\n",
      "epoch:38 step:30001 [D loss: 0.862422, acc: 50.78%] [G loss: 3.856761]\n",
      "epoch:38 step:30002 [D loss: 0.403635, acc: 89.06%] [G loss: 4.176850]\n",
      "epoch:38 step:30003 [D loss: 0.065975, acc: 100.00%] [G loss: 3.853703]\n",
      "epoch:38 step:30004 [D loss: 0.146872, acc: 98.44%] [G loss: 6.402938]\n",
      "epoch:38 step:30005 [D loss: 0.341523, acc: 92.97%] [G loss: 5.692729]\n",
      "epoch:38 step:30006 [D loss: 0.210076, acc: 95.31%] [G loss: 5.948921]\n",
      "epoch:38 step:30007 [D loss: 0.581453, acc: 70.31%] [G loss: 5.499442]\n",
      "epoch:38 step:30008 [D loss: 0.513462, acc: 79.69%] [G loss: 4.584684]\n",
      "epoch:38 step:30009 [D loss: 0.091011, acc: 99.22%] [G loss: 4.526703]\n",
      "epoch:38 step:30010 [D loss: 0.778783, acc: 47.66%] [G loss: 6.776937]\n",
      "epoch:38 step:30011 [D loss: 0.098786, acc: 99.22%] [G loss: 5.782697]\n",
      "epoch:38 step:30012 [D loss: 0.214361, acc: 96.88%] [G loss: 7.387078]\n",
      "epoch:38 step:30013 [D loss: 0.058184, acc: 100.00%] [G loss: 7.710850]\n",
      "epoch:38 step:30014 [D loss: 0.377145, acc: 82.03%] [G loss: 5.308926]\n",
      "epoch:38 step:30015 [D loss: 0.164420, acc: 97.66%] [G loss: 5.886980]\n",
      "epoch:38 step:30016 [D loss: 0.676910, acc: 56.25%] [G loss: 4.413203]\n",
      "epoch:38 step:30017 [D loss: 0.240826, acc: 95.31%] [G loss: 5.914671]\n",
      "epoch:38 step:30018 [D loss: 0.403393, acc: 79.69%] [G loss: 6.377834]\n",
      "epoch:38 step:30019 [D loss: 0.138611, acc: 99.22%] [G loss: 5.454779]\n",
      "epoch:38 step:30020 [D loss: 0.176059, acc: 96.09%] [G loss: 5.809171]\n",
      "epoch:38 step:30021 [D loss: 0.455194, acc: 82.81%] [G loss: 6.315526]\n",
      "epoch:38 step:30022 [D loss: 1.386868, acc: 50.00%] [G loss: 5.500644]\n",
      "epoch:38 step:30023 [D loss: 0.458623, acc: 82.81%] [G loss: 4.759852]\n",
      "epoch:38 step:30024 [D loss: 0.740885, acc: 54.69%] [G loss: 6.705573]\n",
      "epoch:38 step:30025 [D loss: 0.544868, acc: 75.78%] [G loss: 3.843646]\n",
      "epoch:38 step:30026 [D loss: 0.265262, acc: 94.53%] [G loss: 6.272876]\n",
      "epoch:38 step:30027 [D loss: 0.895174, acc: 50.00%] [G loss: 5.018902]\n",
      "epoch:38 step:30028 [D loss: 0.089987, acc: 100.00%] [G loss: 5.392054]\n",
      "epoch:38 step:30029 [D loss: 0.302285, acc: 86.72%] [G loss: 4.871018]\n",
      "epoch:38 step:30030 [D loss: 0.069428, acc: 99.22%] [G loss: 6.114759]\n",
      "epoch:38 step:30031 [D loss: 0.075309, acc: 100.00%] [G loss: 5.058416]\n",
      "epoch:38 step:30032 [D loss: 0.293384, acc: 92.97%] [G loss: 3.917725]\n",
      "epoch:38 step:30033 [D loss: 0.976859, acc: 51.56%] [G loss: 7.330057]\n",
      "epoch:38 step:30034 [D loss: 0.244780, acc: 93.75%] [G loss: 7.645981]\n",
      "epoch:38 step:30035 [D loss: 0.347371, acc: 78.12%] [G loss: 8.210753]\n",
      "epoch:38 step:30036 [D loss: 0.456904, acc: 79.69%] [G loss: 7.385136]\n",
      "epoch:38 step:30037 [D loss: 0.510956, acc: 78.91%] [G loss: 7.672765]\n",
      "epoch:38 step:30038 [D loss: 0.534654, acc: 73.44%] [G loss: 4.351505]\n",
      "epoch:38 step:30039 [D loss: 0.987020, acc: 28.91%] [G loss: 3.408200]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:30040 [D loss: 0.351939, acc: 87.50%] [G loss: 6.202321]\n",
      "epoch:38 step:30041 [D loss: 0.906753, acc: 31.25%] [G loss: 7.443645]\n",
      "epoch:38 step:30042 [D loss: 0.186201, acc: 96.88%] [G loss: 6.970577]\n",
      "epoch:38 step:30043 [D loss: 0.391115, acc: 75.78%] [G loss: 5.354306]\n",
      "epoch:38 step:30044 [D loss: 0.101903, acc: 99.22%] [G loss: 3.353198]\n",
      "epoch:38 step:30045 [D loss: 0.342833, acc: 82.03%] [G loss: 4.467250]\n",
      "epoch:38 step:30046 [D loss: 0.044358, acc: 100.00%] [G loss: 6.275282]\n",
      "epoch:38 step:30047 [D loss: 0.574828, acc: 70.31%] [G loss: 4.412861]\n",
      "epoch:38 step:30048 [D loss: 0.206086, acc: 96.88%] [G loss: 5.466780]\n",
      "epoch:38 step:30049 [D loss: 0.074797, acc: 100.00%] [G loss: 5.709596]\n",
      "epoch:38 step:30050 [D loss: 0.290840, acc: 89.84%] [G loss: 7.121863]\n",
      "epoch:38 step:30051 [D loss: 0.644075, acc: 56.25%] [G loss: 8.075316]\n",
      "epoch:38 step:30052 [D loss: 0.095793, acc: 99.22%] [G loss: 7.242702]\n",
      "epoch:38 step:30053 [D loss: 0.125847, acc: 100.00%] [G loss: 4.821205]\n",
      "epoch:38 step:30054 [D loss: 0.529183, acc: 71.88%] [G loss: 3.106138]\n",
      "epoch:38 step:30055 [D loss: 0.136487, acc: 98.44%] [G loss: 4.400716]\n",
      "epoch:38 step:30056 [D loss: 0.258537, acc: 98.44%] [G loss: 5.198451]\n",
      "epoch:38 step:30057 [D loss: 0.153920, acc: 99.22%] [G loss: 5.331340]\n",
      "epoch:38 step:30058 [D loss: 0.149246, acc: 100.00%] [G loss: 5.946576]\n",
      "epoch:38 step:30059 [D loss: 0.646459, acc: 65.62%] [G loss: 5.128859]\n",
      "epoch:38 step:30060 [D loss: 0.783339, acc: 52.34%] [G loss: 6.468679]\n",
      "epoch:38 step:30061 [D loss: 0.179190, acc: 96.09%] [G loss: 4.431672]\n",
      "epoch:38 step:30062 [D loss: 0.412477, acc: 76.56%] [G loss: 7.228114]\n",
      "epoch:38 step:30063 [D loss: 0.311705, acc: 83.59%] [G loss: 4.077315]\n",
      "epoch:38 step:30064 [D loss: 0.048190, acc: 100.00%] [G loss: 5.656041]\n",
      "epoch:38 step:30065 [D loss: 0.644092, acc: 61.72%] [G loss: 5.829361]\n",
      "epoch:38 step:30066 [D loss: 0.387254, acc: 88.28%] [G loss: 8.592523]\n",
      "epoch:38 step:30067 [D loss: 0.205420, acc: 95.31%] [G loss: 6.003354]\n",
      "epoch:38 step:30068 [D loss: 0.367858, acc: 78.91%] [G loss: 7.984874]\n",
      "epoch:38 step:30069 [D loss: 0.382293, acc: 83.59%] [G loss: 3.738854]\n",
      "epoch:38 step:30070 [D loss: 0.587564, acc: 67.97%] [G loss: 3.005255]\n",
      "epoch:38 step:30071 [D loss: 0.202724, acc: 99.22%] [G loss: 2.278475]\n",
      "epoch:38 step:30072 [D loss: 0.917989, acc: 50.00%] [G loss: 3.818185]\n",
      "epoch:38 step:30073 [D loss: 0.467166, acc: 75.00%] [G loss: 7.182626]\n",
      "epoch:38 step:30074 [D loss: 0.187443, acc: 98.44%] [G loss: 7.647638]\n",
      "epoch:38 step:30075 [D loss: 0.500362, acc: 82.81%] [G loss: 3.916107]\n",
      "epoch:38 step:30076 [D loss: 0.622007, acc: 59.38%] [G loss: 3.056554]\n",
      "epoch:38 step:30077 [D loss: 0.090517, acc: 99.22%] [G loss: 7.246570]\n",
      "epoch:38 step:30078 [D loss: 1.879584, acc: 45.31%] [G loss: 7.237942]\n",
      "epoch:38 step:30079 [D loss: 0.113563, acc: 99.22%] [G loss: 6.557565]\n",
      "epoch:38 step:30080 [D loss: 0.426624, acc: 76.56%] [G loss: 5.612325]\n",
      "epoch:38 step:30081 [D loss: 0.566717, acc: 68.75%] [G loss: 9.161495]\n",
      "epoch:38 step:30082 [D loss: 1.233164, acc: 19.53%] [G loss: 5.891773]\n",
      "epoch:38 step:30083 [D loss: 0.189507, acc: 96.88%] [G loss: 4.565812]\n",
      "epoch:38 step:30084 [D loss: 0.572600, acc: 66.41%] [G loss: 3.900515]\n",
      "epoch:38 step:30085 [D loss: 0.927382, acc: 39.84%] [G loss: 4.597658]\n",
      "epoch:38 step:30086 [D loss: 0.052726, acc: 99.22%] [G loss: 4.457248]\n",
      "epoch:38 step:30087 [D loss: 0.351554, acc: 81.25%] [G loss: 4.708418]\n",
      "epoch:38 step:30088 [D loss: 0.164413, acc: 97.66%] [G loss: 4.725143]\n",
      "epoch:38 step:30089 [D loss: 0.652526, acc: 55.47%] [G loss: 6.948814]\n",
      "epoch:38 step:30090 [D loss: 0.073565, acc: 100.00%] [G loss: 5.561013]\n",
      "epoch:38 step:30091 [D loss: 0.359489, acc: 84.38%] [G loss: 8.294632]\n",
      "epoch:38 step:30092 [D loss: 0.097892, acc: 100.00%] [G loss: 4.265150]\n",
      "epoch:38 step:30093 [D loss: 0.124260, acc: 99.22%] [G loss: 3.466206]\n",
      "epoch:38 step:30094 [D loss: 0.101255, acc: 98.44%] [G loss: 4.719942]\n",
      "epoch:38 step:30095 [D loss: 0.131104, acc: 100.00%] [G loss: 2.933627]\n",
      "epoch:38 step:30096 [D loss: 0.013823, acc: 100.00%] [G loss: 5.047806]\n",
      "epoch:38 step:30097 [D loss: 0.082891, acc: 100.00%] [G loss: 5.242207]\n",
      "epoch:38 step:30098 [D loss: 0.424719, acc: 83.59%] [G loss: 4.866673]\n",
      "epoch:38 step:30099 [D loss: 0.458961, acc: 82.03%] [G loss: 4.925028]\n",
      "epoch:38 step:30100 [D loss: 0.152207, acc: 99.22%] [G loss: 4.624910]\n",
      "epoch:38 step:30101 [D loss: 0.761848, acc: 57.81%] [G loss: 4.492815]\n",
      "epoch:38 step:30102 [D loss: 0.644049, acc: 60.94%] [G loss: 6.143941]\n",
      "epoch:38 step:30103 [D loss: 0.047690, acc: 100.00%] [G loss: 4.040589]\n",
      "epoch:38 step:30104 [D loss: 0.058305, acc: 100.00%] [G loss: 5.881509]\n",
      "epoch:38 step:30105 [D loss: 0.929152, acc: 36.72%] [G loss: 6.268556]\n",
      "epoch:38 step:30106 [D loss: 1.134469, acc: 22.66%] [G loss: 6.166344]\n",
      "epoch:38 step:30107 [D loss: 0.178803, acc: 97.66%] [G loss: 8.102836]\n",
      "epoch:38 step:30108 [D loss: 0.508879, acc: 73.44%] [G loss: 6.844452]\n",
      "epoch:38 step:30109 [D loss: 0.194194, acc: 95.31%] [G loss: 5.074951]\n",
      "epoch:38 step:30110 [D loss: 0.775164, acc: 53.12%] [G loss: 5.060982]\n",
      "epoch:38 step:30111 [D loss: 0.479035, acc: 70.31%] [G loss: 3.668410]\n",
      "epoch:38 step:30112 [D loss: 0.090050, acc: 100.00%] [G loss: 7.381173]\n",
      "epoch:38 step:30113 [D loss: 0.060502, acc: 100.00%] [G loss: 8.275514]\n",
      "epoch:38 step:30114 [D loss: 0.276315, acc: 93.75%] [G loss: 4.822327]\n",
      "epoch:38 step:30115 [D loss: 0.528226, acc: 67.97%] [G loss: 3.048234]\n",
      "epoch:38 step:30116 [D loss: 0.137218, acc: 98.44%] [G loss: 5.989723]\n",
      "epoch:38 step:30117 [D loss: 1.126396, acc: 27.34%] [G loss: 6.785846]\n",
      "epoch:38 step:30118 [D loss: 1.035460, acc: 52.34%] [G loss: 4.221663]\n",
      "epoch:38 step:30119 [D loss: 0.339806, acc: 90.62%] [G loss: 4.928997]\n",
      "epoch:38 step:30120 [D loss: 0.865791, acc: 50.78%] [G loss: 6.343058]\n",
      "epoch:38 step:30121 [D loss: 0.756426, acc: 53.91%] [G loss: 3.813340]\n",
      "epoch:38 step:30122 [D loss: 0.053807, acc: 100.00%] [G loss: 5.466665]\n",
      "epoch:38 step:30123 [D loss: 1.060882, acc: 27.34%] [G loss: 6.773211]\n",
      "epoch:38 step:30124 [D loss: 0.166268, acc: 98.44%] [G loss: 4.011480]\n",
      "epoch:38 step:30125 [D loss: 0.121504, acc: 100.00%] [G loss: 4.344401]\n",
      "epoch:38 step:30126 [D loss: 1.099491, acc: 23.44%] [G loss: 6.171502]\n",
      "epoch:38 step:30127 [D loss: 0.049990, acc: 100.00%] [G loss: 5.659114]\n",
      "epoch:38 step:30128 [D loss: 0.598436, acc: 60.16%] [G loss: 5.506885]\n",
      "epoch:38 step:30129 [D loss: 0.585031, acc: 71.09%] [G loss: 3.838969]\n",
      "epoch:38 step:30130 [D loss: 0.754534, acc: 54.69%] [G loss: 5.373326]\n",
      "epoch:38 step:30131 [D loss: 0.234558, acc: 96.88%] [G loss: 5.757951]\n",
      "epoch:38 step:30132 [D loss: 0.484472, acc: 67.19%] [G loss: 5.518628]\n",
      "epoch:38 step:30133 [D loss: 0.463726, acc: 68.75%] [G loss: 3.803591]\n",
      "epoch:38 step:30134 [D loss: 0.461976, acc: 70.31%] [G loss: 5.079529]\n",
      "epoch:38 step:30135 [D loss: 0.169861, acc: 99.22%] [G loss: 4.120258]\n",
      "epoch:38 step:30136 [D loss: 0.174475, acc: 97.66%] [G loss: 7.356588]\n",
      "epoch:38 step:30137 [D loss: 0.411333, acc: 75.00%] [G loss: 6.421374]\n",
      "epoch:38 step:30138 [D loss: 0.620417, acc: 62.50%] [G loss: 5.462801]\n",
      "epoch:38 step:30139 [D loss: 0.038483, acc: 100.00%] [G loss: 7.019721]\n",
      "epoch:38 step:30140 [D loss: 0.346096, acc: 82.03%] [G loss: 4.247119]\n",
      "epoch:38 step:30141 [D loss: 0.325455, acc: 92.19%] [G loss: 3.975757]\n",
      "epoch:38 step:30142 [D loss: 0.038604, acc: 100.00%] [G loss: 5.674975]\n",
      "epoch:38 step:30143 [D loss: 0.738951, acc: 53.12%] [G loss: 8.016516]\n",
      "epoch:38 step:30144 [D loss: 0.041889, acc: 100.00%] [G loss: 8.734145]\n",
      "epoch:38 step:30145 [D loss: 0.241784, acc: 95.31%] [G loss: 2.738680]\n",
      "epoch:38 step:30146 [D loss: 0.125876, acc: 100.00%] [G loss: 3.093073]\n",
      "epoch:38 step:30147 [D loss: 0.248830, acc: 96.09%] [G loss: 2.995700]\n",
      "epoch:38 step:30148 [D loss: 0.226785, acc: 95.31%] [G loss: 4.988580]\n",
      "epoch:38 step:30149 [D loss: 0.540195, acc: 70.31%] [G loss: 4.898498]\n",
      "epoch:38 step:30150 [D loss: 0.845008, acc: 50.00%] [G loss: 5.364636]\n",
      "epoch:38 step:30151 [D loss: 0.904148, acc: 48.44%] [G loss: 6.447366]\n",
      "epoch:38 step:30152 [D loss: 0.713382, acc: 55.47%] [G loss: 6.344969]\n",
      "epoch:38 step:30153 [D loss: 0.428296, acc: 85.16%] [G loss: 4.824793]\n",
      "epoch:38 step:30154 [D loss: 0.918942, acc: 42.97%] [G loss: 3.509002]\n",
      "epoch:38 step:30155 [D loss: 0.204079, acc: 96.09%] [G loss: 4.615982]\n",
      "epoch:38 step:30156 [D loss: 0.308289, acc: 89.06%] [G loss: 9.233171]\n",
      "epoch:38 step:30157 [D loss: 0.331512, acc: 92.19%] [G loss: 5.917822]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:30158 [D loss: 0.297498, acc: 92.19%] [G loss: 3.340260]\n",
      "epoch:38 step:30159 [D loss: 0.887610, acc: 46.09%] [G loss: 4.223905]\n",
      "epoch:38 step:30160 [D loss: 0.340639, acc: 89.84%] [G loss: 3.017338]\n",
      "epoch:38 step:30161 [D loss: 0.518496, acc: 72.66%] [G loss: 5.651677]\n",
      "epoch:38 step:30162 [D loss: 0.208354, acc: 98.44%] [G loss: 3.825269]\n",
      "epoch:38 step:30163 [D loss: 0.540799, acc: 67.97%] [G loss: 5.008043]\n",
      "epoch:38 step:30164 [D loss: 0.204655, acc: 96.09%] [G loss: 3.639915]\n",
      "epoch:38 step:30165 [D loss: 0.132131, acc: 99.22%] [G loss: 5.034497]\n",
      "epoch:38 step:30166 [D loss: 1.380580, acc: 48.44%] [G loss: 7.210736]\n",
      "epoch:38 step:30167 [D loss: 0.765840, acc: 55.47%] [G loss: 5.125029]\n",
      "epoch:38 step:30168 [D loss: 0.068743, acc: 100.00%] [G loss: 5.997320]\n",
      "epoch:38 step:30169 [D loss: 0.405566, acc: 82.81%] [G loss: 7.516711]\n",
      "epoch:38 step:30170 [D loss: 0.541635, acc: 78.12%] [G loss: 7.529758]\n",
      "epoch:38 step:30171 [D loss: 0.138816, acc: 100.00%] [G loss: 6.930302]\n",
      "epoch:38 step:30172 [D loss: 0.348241, acc: 88.28%] [G loss: 4.002326]\n",
      "epoch:38 step:30173 [D loss: 0.182119, acc: 96.88%] [G loss: 6.337511]\n",
      "epoch:38 step:30174 [D loss: 0.774023, acc: 54.69%] [G loss: 7.321658]\n",
      "epoch:38 step:30175 [D loss: 0.412333, acc: 71.88%] [G loss: 6.256097]\n",
      "epoch:38 step:30176 [D loss: 0.092707, acc: 100.00%] [G loss: 4.669264]\n",
      "epoch:38 step:30177 [D loss: 0.512733, acc: 63.28%] [G loss: 8.695702]\n",
      "epoch:38 step:30178 [D loss: 2.253867, acc: 1.56%] [G loss: 7.590265]\n",
      "epoch:38 step:30179 [D loss: 0.093147, acc: 99.22%] [G loss: 4.197010]\n",
      "epoch:38 step:30180 [D loss: 0.862695, acc: 42.19%] [G loss: 6.337236]\n",
      "epoch:38 step:30181 [D loss: 0.383096, acc: 87.50%] [G loss: 6.368474]\n",
      "epoch:38 step:30182 [D loss: 0.706556, acc: 57.03%] [G loss: 6.020857]\n",
      "epoch:38 step:30183 [D loss: 0.396540, acc: 85.16%] [G loss: 5.280346]\n",
      "epoch:38 step:30184 [D loss: 0.263265, acc: 96.88%] [G loss: 4.231547]\n",
      "epoch:38 step:30185 [D loss: 0.077644, acc: 100.00%] [G loss: 5.952432]\n",
      "epoch:38 step:30186 [D loss: 0.064624, acc: 100.00%] [G loss: 5.166732]\n",
      "epoch:38 step:30187 [D loss: 0.495435, acc: 76.56%] [G loss: 4.437275]\n",
      "epoch:38 step:30188 [D loss: 0.221123, acc: 95.31%] [G loss: 6.577065]\n",
      "epoch:38 step:30189 [D loss: 0.010883, acc: 100.00%] [G loss: 4.259212]\n",
      "epoch:38 step:30190 [D loss: 0.138083, acc: 100.00%] [G loss: 4.985641]\n",
      "epoch:38 step:30191 [D loss: 0.083904, acc: 100.00%] [G loss: 4.615454]\n",
      "epoch:38 step:30192 [D loss: 0.430095, acc: 84.38%] [G loss: 4.500619]\n",
      "epoch:38 step:30193 [D loss: 0.826619, acc: 53.91%] [G loss: 5.146064]\n",
      "epoch:38 step:30194 [D loss: 0.921271, acc: 40.62%] [G loss: 5.842643]\n",
      "epoch:38 step:30195 [D loss: 0.083800, acc: 99.22%] [G loss: 5.476004]\n",
      "epoch:38 step:30196 [D loss: 0.250927, acc: 93.75%] [G loss: 6.410666]\n",
      "epoch:38 step:30197 [D loss: 0.736206, acc: 62.50%] [G loss: 5.385752]\n",
      "epoch:38 step:30198 [D loss: 0.309366, acc: 90.62%] [G loss: 5.464357]\n",
      "epoch:38 step:30199 [D loss: 1.265372, acc: 39.84%] [G loss: 5.044043]\n",
      "epoch:38 step:30200 [D loss: 0.485142, acc: 78.91%] [G loss: 4.457401]\n",
      "epoch:38 step:30201 [D loss: 0.412660, acc: 76.56%] [G loss: 5.311202]\n",
      "epoch:38 step:30202 [D loss: 0.192168, acc: 96.09%] [G loss: 5.141093]\n",
      "epoch:38 step:30203 [D loss: 0.487030, acc: 79.69%] [G loss: 5.799922]\n",
      "epoch:38 step:30204 [D loss: 0.223179, acc: 97.66%] [G loss: 5.899684]\n",
      "epoch:38 step:30205 [D loss: 0.245235, acc: 91.41%] [G loss: 4.830638]\n",
      "epoch:38 step:30206 [D loss: 0.238061, acc: 94.53%] [G loss: 4.446845]\n",
      "epoch:38 step:30207 [D loss: 0.167516, acc: 100.00%] [G loss: 3.626327]\n",
      "epoch:38 step:30208 [D loss: 0.206950, acc: 96.88%] [G loss: 4.779457]\n",
      "epoch:38 step:30209 [D loss: 0.171029, acc: 98.44%] [G loss: 4.736004]\n",
      "epoch:38 step:30210 [D loss: 0.714480, acc: 56.25%] [G loss: 6.580093]\n",
      "epoch:38 step:30211 [D loss: 0.873213, acc: 51.56%] [G loss: 3.340576]\n",
      "epoch:38 step:30212 [D loss: 0.513591, acc: 70.31%] [G loss: 5.912089]\n",
      "epoch:38 step:30213 [D loss: 0.376385, acc: 81.25%] [G loss: 4.616842]\n",
      "epoch:38 step:30214 [D loss: 0.097114, acc: 99.22%] [G loss: 4.983509]\n",
      "epoch:38 step:30215 [D loss: 0.095124, acc: 99.22%] [G loss: 7.398039]\n",
      "epoch:38 step:30216 [D loss: 0.160399, acc: 99.22%] [G loss: 5.152781]\n",
      "epoch:38 step:30217 [D loss: 0.640364, acc: 63.28%] [G loss: 6.372077]\n",
      "epoch:38 step:30218 [D loss: 0.748967, acc: 52.34%] [G loss: 2.081439]\n",
      "epoch:38 step:30219 [D loss: 0.235120, acc: 95.31%] [G loss: 6.009155]\n",
      "epoch:38 step:30220 [D loss: 0.340727, acc: 85.94%] [G loss: 6.267333]\n",
      "epoch:38 step:30221 [D loss: 0.542818, acc: 75.78%] [G loss: 4.853079]\n",
      "epoch:38 step:30222 [D loss: 0.209343, acc: 96.88%] [G loss: 3.483249]\n",
      "epoch:38 step:30223 [D loss: 0.200240, acc: 94.53%] [G loss: 7.604963]\n",
      "epoch:38 step:30224 [D loss: 0.207773, acc: 95.31%] [G loss: 6.580950]\n",
      "epoch:38 step:30225 [D loss: 0.756153, acc: 56.25%] [G loss: 5.097685]\n",
      "epoch:38 step:30226 [D loss: 0.866076, acc: 51.56%] [G loss: 3.834356]\n",
      "epoch:38 step:30227 [D loss: 0.352124, acc: 90.62%] [G loss: 2.169189]\n",
      "epoch:38 step:30228 [D loss: 0.422172, acc: 80.47%] [G loss: 4.975151]\n",
      "epoch:38 step:30229 [D loss: 0.052155, acc: 100.00%] [G loss: 4.696749]\n",
      "epoch:38 step:30230 [D loss: 0.860958, acc: 47.66%] [G loss: 5.594511]\n",
      "epoch:38 step:30231 [D loss: 0.663346, acc: 55.47%] [G loss: 4.200500]\n",
      "epoch:38 step:30232 [D loss: 0.319854, acc: 92.97%] [G loss: 5.414260]\n",
      "epoch:38 step:30233 [D loss: 0.349258, acc: 79.69%] [G loss: 4.001301]\n",
      "epoch:38 step:30234 [D loss: 0.246244, acc: 93.75%] [G loss: 3.923015]\n",
      "epoch:38 step:30235 [D loss: 0.613662, acc: 58.59%] [G loss: 6.461078]\n",
      "epoch:38 step:30236 [D loss: 0.329248, acc: 91.41%] [G loss: 6.111093]\n",
      "epoch:38 step:30237 [D loss: 0.047120, acc: 100.00%] [G loss: 4.739604]\n",
      "epoch:38 step:30238 [D loss: 0.567053, acc: 66.41%] [G loss: 4.291069]\n",
      "epoch:38 step:30239 [D loss: 0.080176, acc: 98.44%] [G loss: 5.069955]\n",
      "epoch:38 step:30240 [D loss: 0.570484, acc: 63.28%] [G loss: 6.264152]\n",
      "epoch:38 step:30241 [D loss: 0.944926, acc: 46.88%] [G loss: 6.974973]\n",
      "epoch:38 step:30242 [D loss: 0.680811, acc: 56.25%] [G loss: 4.296541]\n",
      "epoch:38 step:30243 [D loss: 0.043946, acc: 100.00%] [G loss: 6.970784]\n",
      "epoch:38 step:30244 [D loss: 0.724375, acc: 54.69%] [G loss: 7.346941]\n",
      "epoch:38 step:30245 [D loss: 0.315678, acc: 89.06%] [G loss: 6.703154]\n",
      "epoch:38 step:30246 [D loss: 0.382660, acc: 88.28%] [G loss: 5.530108]\n",
      "epoch:38 step:30247 [D loss: 0.019466, acc: 100.00%] [G loss: 5.170891]\n",
      "epoch:38 step:30248 [D loss: 0.285792, acc: 92.19%] [G loss: 4.561826]\n",
      "epoch:38 step:30249 [D loss: 0.099799, acc: 100.00%] [G loss: 4.553796]\n",
      "epoch:38 step:30250 [D loss: 0.027887, acc: 100.00%] [G loss: 8.133669]\n",
      "epoch:38 step:30251 [D loss: 0.186115, acc: 96.88%] [G loss: 3.487436]\n",
      "epoch:38 step:30252 [D loss: 0.106278, acc: 99.22%] [G loss: 5.838057]\n",
      "epoch:38 step:30253 [D loss: 0.603353, acc: 66.41%] [G loss: 3.609682]\n",
      "epoch:38 step:30254 [D loss: 0.081168, acc: 99.22%] [G loss: 5.049851]\n",
      "epoch:38 step:30255 [D loss: 0.072896, acc: 100.00%] [G loss: 7.636256]\n",
      "epoch:38 step:30256 [D loss: 0.561506, acc: 69.53%] [G loss: 6.962119]\n",
      "epoch:38 step:30257 [D loss: 1.134293, acc: 33.59%] [G loss: 3.124192]\n",
      "epoch:38 step:30258 [D loss: 0.212054, acc: 96.88%] [G loss: 4.222644]\n",
      "epoch:38 step:30259 [D loss: 0.407639, acc: 76.56%] [G loss: 3.372046]\n",
      "epoch:38 step:30260 [D loss: 0.467217, acc: 81.25%] [G loss: 4.742892]\n",
      "epoch:38 step:30261 [D loss: 0.896091, acc: 40.62%] [G loss: 4.779270]\n",
      "epoch:38 step:30262 [D loss: 0.328323, acc: 82.03%] [G loss: 3.881133]\n",
      "epoch:38 step:30263 [D loss: 0.353013, acc: 82.03%] [G loss: 5.104539]\n",
      "epoch:38 step:30264 [D loss: 0.036616, acc: 100.00%] [G loss: 7.427583]\n",
      "epoch:38 step:30265 [D loss: 0.116167, acc: 98.44%] [G loss: 3.417024]\n",
      "epoch:38 step:30266 [D loss: 0.303375, acc: 88.28%] [G loss: 4.572516]\n",
      "epoch:38 step:30267 [D loss: 0.081242, acc: 99.22%] [G loss: 4.968329]\n",
      "epoch:38 step:30268 [D loss: 0.199957, acc: 95.31%] [G loss: 5.382184]\n",
      "epoch:38 step:30269 [D loss: 0.033526, acc: 100.00%] [G loss: 4.512004]\n",
      "epoch:38 step:30270 [D loss: 0.546306, acc: 63.28%] [G loss: 3.281489]\n",
      "epoch:38 step:30271 [D loss: 0.617795, acc: 63.28%] [G loss: 4.203353]\n",
      "epoch:38 step:30272 [D loss: 0.224159, acc: 93.75%] [G loss: 7.327687]\n",
      "epoch:38 step:30273 [D loss: 0.183678, acc: 95.31%] [G loss: 5.897530]\n",
      "epoch:38 step:30274 [D loss: 0.152606, acc: 100.00%] [G loss: 5.128957]\n",
      "epoch:38 step:30275 [D loss: 0.067505, acc: 100.00%] [G loss: 4.451457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:30276 [D loss: 0.243442, acc: 97.66%] [G loss: 6.357785]\n",
      "epoch:38 step:30277 [D loss: 0.559319, acc: 71.88%] [G loss: 4.492875]\n",
      "epoch:38 step:30278 [D loss: 0.467297, acc: 69.53%] [G loss: 3.309918]\n",
      "epoch:38 step:30279 [D loss: 0.916287, acc: 50.78%] [G loss: 6.892426]\n",
      "epoch:38 step:30280 [D loss: 0.248785, acc: 92.97%] [G loss: 6.136954]\n",
      "epoch:38 step:30281 [D loss: 0.130537, acc: 100.00%] [G loss: 5.978464]\n",
      "epoch:38 step:30282 [D loss: 0.588835, acc: 58.59%] [G loss: 3.244806]\n",
      "epoch:38 step:30283 [D loss: 0.169241, acc: 96.09%] [G loss: 7.005041]\n",
      "epoch:38 step:30284 [D loss: 0.624502, acc: 58.59%] [G loss: 6.958275]\n",
      "epoch:38 step:30285 [D loss: 0.335495, acc: 88.28%] [G loss: 2.217862]\n",
      "epoch:38 step:30286 [D loss: 0.569948, acc: 64.06%] [G loss: 5.631851]\n",
      "epoch:38 step:30287 [D loss: 0.415536, acc: 86.72%] [G loss: 5.635848]\n",
      "epoch:38 step:30288 [D loss: 0.294342, acc: 91.41%] [G loss: 5.300008]\n",
      "epoch:38 step:30289 [D loss: 0.095694, acc: 99.22%] [G loss: 3.899594]\n",
      "epoch:38 step:30290 [D loss: 0.350798, acc: 91.41%] [G loss: 2.890187]\n",
      "epoch:38 step:30291 [D loss: 0.047624, acc: 100.00%] [G loss: 5.111029]\n",
      "epoch:38 step:30292 [D loss: 0.116880, acc: 99.22%] [G loss: 6.257040]\n",
      "epoch:38 step:30293 [D loss: 0.058710, acc: 99.22%] [G loss: 9.423893]\n",
      "epoch:38 step:30294 [D loss: 0.092444, acc: 98.44%] [G loss: 5.390360]\n",
      "epoch:38 step:30295 [D loss: 0.214018, acc: 96.88%] [G loss: 4.578659]\n",
      "epoch:38 step:30296 [D loss: 1.273369, acc: 50.00%] [G loss: 5.359822]\n",
      "epoch:38 step:30297 [D loss: 0.330022, acc: 90.62%] [G loss: 6.946360]\n",
      "epoch:38 step:30298 [D loss: 0.201522, acc: 95.31%] [G loss: 3.359117]\n",
      "epoch:38 step:30299 [D loss: 0.939587, acc: 35.94%] [G loss: 4.799294]\n",
      "epoch:38 step:30300 [D loss: 0.209003, acc: 95.31%] [G loss: 2.973444]\n",
      "epoch:38 step:30301 [D loss: 0.270440, acc: 98.44%] [G loss: 6.897592]\n",
      "epoch:38 step:30302 [D loss: 0.229527, acc: 90.62%] [G loss: 6.156766]\n",
      "epoch:38 step:30303 [D loss: 0.070662, acc: 100.00%] [G loss: 4.491992]\n",
      "epoch:38 step:30304 [D loss: 0.503063, acc: 83.59%] [G loss: 3.192694]\n",
      "epoch:38 step:30305 [D loss: 0.200891, acc: 96.88%] [G loss: 7.245569]\n",
      "epoch:38 step:30306 [D loss: 0.475519, acc: 76.56%] [G loss: 5.447347]\n",
      "epoch:38 step:30307 [D loss: 0.066807, acc: 100.00%] [G loss: 3.771152]\n",
      "epoch:38 step:30308 [D loss: 0.269413, acc: 89.84%] [G loss: 6.710134]\n",
      "epoch:38 step:30309 [D loss: 0.372447, acc: 86.72%] [G loss: 3.876782]\n",
      "epoch:38 step:30310 [D loss: 0.158320, acc: 100.00%] [G loss: 4.926224]\n",
      "epoch:38 step:30311 [D loss: 0.075543, acc: 100.00%] [G loss: 6.730771]\n",
      "epoch:38 step:30312 [D loss: 1.351235, acc: 26.56%] [G loss: 4.816149]\n",
      "epoch:38 step:30313 [D loss: 0.637685, acc: 59.38%] [G loss: 3.252720]\n",
      "epoch:38 step:30314 [D loss: 0.135829, acc: 98.44%] [G loss: 4.076466]\n",
      "epoch:38 step:30315 [D loss: 0.359091, acc: 92.97%] [G loss: 3.357902]\n",
      "epoch:38 step:30316 [D loss: 0.161306, acc: 98.44%] [G loss: 4.851793]\n",
      "epoch:38 step:30317 [D loss: 0.539895, acc: 74.22%] [G loss: 4.757423]\n",
      "epoch:38 step:30318 [D loss: 0.254897, acc: 89.84%] [G loss: 5.434066]\n",
      "epoch:38 step:30319 [D loss: 0.213043, acc: 96.09%] [G loss: 5.210868]\n",
      "epoch:38 step:30320 [D loss: 0.938774, acc: 31.25%] [G loss: 7.278582]\n",
      "epoch:38 step:30321 [D loss: 0.076589, acc: 100.00%] [G loss: 4.939520]\n",
      "epoch:38 step:30322 [D loss: 0.571460, acc: 71.09%] [G loss: 7.728487]\n",
      "epoch:38 step:30323 [D loss: 0.511225, acc: 67.19%] [G loss: 6.714774]\n",
      "epoch:38 step:30324 [D loss: 0.633859, acc: 60.16%] [G loss: 7.114794]\n",
      "epoch:38 step:30325 [D loss: 0.141802, acc: 98.44%] [G loss: 4.600503]\n",
      "epoch:38 step:30326 [D loss: 0.411760, acc: 72.66%] [G loss: 6.415025]\n",
      "epoch:38 step:30327 [D loss: 0.930556, acc: 29.69%] [G loss: 4.595496]\n",
      "epoch:38 step:30328 [D loss: 0.157985, acc: 99.22%] [G loss: 6.804906]\n",
      "epoch:38 step:30329 [D loss: 0.337513, acc: 85.94%] [G loss: 5.856623]\n",
      "epoch:38 step:30330 [D loss: 0.480022, acc: 74.22%] [G loss: 9.012114]\n",
      "epoch:38 step:30331 [D loss: 0.131124, acc: 99.22%] [G loss: 6.123263]\n",
      "epoch:38 step:30332 [D loss: 0.267386, acc: 87.50%] [G loss: 4.381487]\n",
      "epoch:38 step:30333 [D loss: 0.358723, acc: 88.28%] [G loss: 5.097876]\n",
      "epoch:38 step:30334 [D loss: 0.583101, acc: 61.72%] [G loss: 4.109563]\n",
      "epoch:38 step:30335 [D loss: 0.450284, acc: 66.41%] [G loss: 2.962535]\n",
      "epoch:38 step:30336 [D loss: 0.092403, acc: 99.22%] [G loss: 5.885510]\n",
      "epoch:38 step:30337 [D loss: 0.150562, acc: 99.22%] [G loss: 4.801762]\n",
      "epoch:38 step:30338 [D loss: 0.792328, acc: 52.34%] [G loss: 6.142902]\n",
      "epoch:38 step:30339 [D loss: 0.443330, acc: 71.88%] [G loss: 5.546036]\n",
      "epoch:38 step:30340 [D loss: 0.413581, acc: 80.47%] [G loss: 4.560585]\n",
      "epoch:38 step:30341 [D loss: 0.050556, acc: 100.00%] [G loss: 10.140073]\n",
      "epoch:38 step:30342 [D loss: 0.147625, acc: 98.44%] [G loss: 3.501080]\n",
      "epoch:38 step:30343 [D loss: 0.207726, acc: 97.66%] [G loss: 4.094423]\n",
      "epoch:38 step:30344 [D loss: 0.276652, acc: 90.62%] [G loss: 5.205424]\n",
      "epoch:38 step:30345 [D loss: 0.170332, acc: 99.22%] [G loss: 3.416815]\n",
      "epoch:38 step:30346 [D loss: 0.883750, acc: 50.78%] [G loss: 7.143637]\n",
      "epoch:38 step:30347 [D loss: 0.428336, acc: 86.72%] [G loss: 8.394184]\n",
      "epoch:38 step:30348 [D loss: 0.252976, acc: 92.97%] [G loss: 4.095413]\n",
      "epoch:38 step:30349 [D loss: 0.247761, acc: 89.84%] [G loss: 6.210626]\n",
      "epoch:38 step:30350 [D loss: 0.116847, acc: 99.22%] [G loss: 4.740552]\n",
      "epoch:38 step:30351 [D loss: 0.098176, acc: 100.00%] [G loss: 3.406512]\n",
      "epoch:38 step:30352 [D loss: 0.350543, acc: 82.81%] [G loss: 4.727705]\n",
      "epoch:38 step:30353 [D loss: 0.524395, acc: 60.16%] [G loss: 5.222336]\n",
      "epoch:38 step:30354 [D loss: 0.073145, acc: 100.00%] [G loss: 4.629109]\n",
      "epoch:38 step:30355 [D loss: 0.057351, acc: 100.00%] [G loss: 6.016866]\n",
      "epoch:38 step:30356 [D loss: 0.120299, acc: 100.00%] [G loss: 5.287963]\n",
      "epoch:38 step:30357 [D loss: 0.382646, acc: 81.25%] [G loss: 4.406296]\n",
      "epoch:38 step:30358 [D loss: 0.145442, acc: 97.66%] [G loss: 6.968491]\n",
      "epoch:38 step:30359 [D loss: 0.572724, acc: 64.06%] [G loss: 6.250889]\n",
      "epoch:38 step:30360 [D loss: 0.418539, acc: 79.69%] [G loss: 2.778517]\n",
      "epoch:38 step:30361 [D loss: 0.224030, acc: 92.97%] [G loss: 5.264813]\n",
      "epoch:38 step:30362 [D loss: 0.739711, acc: 61.72%] [G loss: 4.099485]\n",
      "epoch:38 step:30363 [D loss: 0.095990, acc: 100.00%] [G loss: 5.023189]\n",
      "epoch:38 step:30364 [D loss: 0.337465, acc: 92.97%] [G loss: 2.648297]\n",
      "epoch:38 step:30365 [D loss: 0.328770, acc: 86.72%] [G loss: 5.837512]\n",
      "epoch:38 step:30366 [D loss: 0.586137, acc: 58.59%] [G loss: 6.042511]\n",
      "epoch:38 step:30367 [D loss: 0.069703, acc: 99.22%] [G loss: 6.127410]\n",
      "epoch:38 step:30368 [D loss: 0.159523, acc: 98.44%] [G loss: 6.362487]\n",
      "epoch:38 step:30369 [D loss: 1.890919, acc: 14.06%] [G loss: 5.958891]\n",
      "epoch:38 step:30370 [D loss: 0.392751, acc: 82.03%] [G loss: 1.927012]\n",
      "epoch:38 step:30371 [D loss: 0.465091, acc: 71.88%] [G loss: 7.148363]\n",
      "epoch:38 step:30372 [D loss: 0.545368, acc: 72.66%] [G loss: 4.494943]\n",
      "epoch:38 step:30373 [D loss: 0.026350, acc: 100.00%] [G loss: 6.300075]\n",
      "epoch:38 step:30374 [D loss: 0.033741, acc: 100.00%] [G loss: 6.557827]\n",
      "epoch:38 step:30375 [D loss: 0.136213, acc: 97.66%] [G loss: 8.817474]\n",
      "epoch:38 step:30376 [D loss: 0.168701, acc: 100.00%] [G loss: 5.631468]\n",
      "epoch:38 step:30377 [D loss: 0.160428, acc: 97.66%] [G loss: 5.729187]\n",
      "epoch:38 step:30378 [D loss: 0.037327, acc: 100.00%] [G loss: 5.910257]\n",
      "epoch:38 step:30379 [D loss: 0.405641, acc: 83.59%] [G loss: 5.381339]\n",
      "epoch:38 step:30380 [D loss: 0.159820, acc: 96.88%] [G loss: 5.319042]\n",
      "epoch:38 step:30381 [D loss: 0.209973, acc: 99.22%] [G loss: 6.780312]\n",
      "epoch:38 step:30382 [D loss: 0.239399, acc: 93.75%] [G loss: 3.225127]\n",
      "epoch:38 step:30383 [D loss: 1.173572, acc: 18.75%] [G loss: 7.341379]\n",
      "epoch:38 step:30384 [D loss: 0.370808, acc: 90.62%] [G loss: 5.264994]\n",
      "epoch:38 step:30385 [D loss: 0.165491, acc: 96.09%] [G loss: 5.566828]\n",
      "epoch:38 step:30386 [D loss: 0.796510, acc: 54.69%] [G loss: 8.905521]\n",
      "epoch:38 step:30387 [D loss: 0.204983, acc: 93.75%] [G loss: 5.043093]\n",
      "epoch:38 step:30388 [D loss: 0.294588, acc: 90.62%] [G loss: 5.537595]\n",
      "epoch:38 step:30389 [D loss: 0.042946, acc: 100.00%] [G loss: 8.078387]\n",
      "epoch:38 step:30390 [D loss: 0.084489, acc: 100.00%] [G loss: 5.229328]\n",
      "epoch:38 step:30391 [D loss: 0.956600, acc: 24.22%] [G loss: 4.883502]\n",
      "epoch:38 step:30392 [D loss: 0.431648, acc: 84.38%] [G loss: 4.149577]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:30393 [D loss: 0.167399, acc: 99.22%] [G loss: 3.233118]\n",
      "epoch:38 step:30394 [D loss: 0.150078, acc: 99.22%] [G loss: 4.629457]\n",
      "epoch:38 step:30395 [D loss: 0.742303, acc: 53.91%] [G loss: 6.511403]\n",
      "epoch:38 step:30396 [D loss: 0.482440, acc: 70.31%] [G loss: 4.787576]\n",
      "epoch:38 step:30397 [D loss: 0.423873, acc: 81.25%] [G loss: 4.222198]\n",
      "epoch:38 step:30398 [D loss: 0.705770, acc: 53.91%] [G loss: 5.893136]\n",
      "epoch:38 step:30399 [D loss: 0.260973, acc: 86.72%] [G loss: 4.657913]\n",
      "epoch:38 step:30400 [D loss: 0.535886, acc: 74.22%] [G loss: 4.924698]\n",
      "epoch:38 step:30401 [D loss: 0.078632, acc: 100.00%] [G loss: 7.170338]\n",
      "epoch:38 step:30402 [D loss: 1.301512, acc: 42.19%] [G loss: 7.896519]\n",
      "epoch:38 step:30403 [D loss: 0.247971, acc: 96.09%] [G loss: 4.306764]\n",
      "epoch:38 step:30404 [D loss: 0.301322, acc: 88.28%] [G loss: 7.121244]\n",
      "epoch:38 step:30405 [D loss: 0.072418, acc: 100.00%] [G loss: 3.610848]\n",
      "epoch:38 step:30406 [D loss: 0.898703, acc: 50.78%] [G loss: 9.186483]\n",
      "epoch:38 step:30407 [D loss: 0.419073, acc: 74.22%] [G loss: 3.478629]\n",
      "epoch:38 step:30408 [D loss: 0.350727, acc: 84.38%] [G loss: 4.042881]\n",
      "epoch:38 step:30409 [D loss: 0.372085, acc: 75.78%] [G loss: 6.662733]\n",
      "epoch:38 step:30410 [D loss: 0.183903, acc: 96.09%] [G loss: 4.900082]\n",
      "epoch:38 step:30411 [D loss: 0.050780, acc: 100.00%] [G loss: 5.979463]\n",
      "epoch:38 step:30412 [D loss: 0.627868, acc: 57.03%] [G loss: 4.741677]\n",
      "epoch:38 step:30413 [D loss: 0.076509, acc: 100.00%] [G loss: 10.734253]\n",
      "epoch:38 step:30414 [D loss: 0.142972, acc: 100.00%] [G loss: 8.601601]\n",
      "epoch:38 step:30415 [D loss: 0.082658, acc: 100.00%] [G loss: 8.827521]\n",
      "epoch:38 step:30416 [D loss: 0.310232, acc: 89.06%] [G loss: 3.638888]\n",
      "epoch:38 step:30417 [D loss: 0.213869, acc: 95.31%] [G loss: 4.732131]\n",
      "epoch:38 step:30418 [D loss: 0.146230, acc: 99.22%] [G loss: 5.354569]\n",
      "epoch:38 step:30419 [D loss: 0.514937, acc: 78.91%] [G loss: 5.074848]\n",
      "epoch:38 step:30420 [D loss: 0.771186, acc: 45.31%] [G loss: 7.442819]\n",
      "epoch:38 step:30421 [D loss: 0.174157, acc: 97.66%] [G loss: 5.303950]\n",
      "epoch:38 step:30422 [D loss: 0.569194, acc: 75.00%] [G loss: 6.387400]\n",
      "epoch:38 step:30423 [D loss: 0.128827, acc: 99.22%] [G loss: 5.922539]\n",
      "epoch:38 step:30424 [D loss: 0.031299, acc: 100.00%] [G loss: 6.088883]\n",
      "epoch:38 step:30425 [D loss: 0.434625, acc: 72.66%] [G loss: 4.620867]\n",
      "epoch:38 step:30426 [D loss: 0.031099, acc: 100.00%] [G loss: 8.400551]\n",
      "epoch:38 step:30427 [D loss: 0.267469, acc: 92.19%] [G loss: 8.064122]\n",
      "epoch:38 step:30428 [D loss: 0.845615, acc: 47.66%] [G loss: 10.612350]\n",
      "epoch:38 step:30429 [D loss: 0.384486, acc: 77.34%] [G loss: 4.428057]\n",
      "epoch:38 step:30430 [D loss: 0.275062, acc: 88.28%] [G loss: 5.290461]\n",
      "epoch:38 step:30431 [D loss: 1.002872, acc: 38.28%] [G loss: 6.208015]\n",
      "epoch:38 step:30432 [D loss: 0.113818, acc: 100.00%] [G loss: 6.042307]\n",
      "epoch:38 step:30433 [D loss: 0.103090, acc: 99.22%] [G loss: 6.217322]\n",
      "epoch:38 step:30434 [D loss: 0.060075, acc: 100.00%] [G loss: 2.762527]\n",
      "epoch:38 step:30435 [D loss: 0.067994, acc: 100.00%] [G loss: 3.254824]\n",
      "epoch:38 step:30436 [D loss: 0.274344, acc: 91.41%] [G loss: 3.602769]\n",
      "epoch:38 step:30437 [D loss: 0.161387, acc: 96.88%] [G loss: 4.724889]\n",
      "epoch:38 step:30438 [D loss: 0.564989, acc: 63.28%] [G loss: 9.119545]\n",
      "epoch:38 step:30439 [D loss: 0.107987, acc: 99.22%] [G loss: 6.264171]\n",
      "epoch:38 step:30440 [D loss: 0.832692, acc: 52.34%] [G loss: 5.629011]\n",
      "epoch:38 step:30441 [D loss: 0.463021, acc: 76.56%] [G loss: 4.444662]\n",
      "epoch:38 step:30442 [D loss: 0.465202, acc: 71.88%] [G loss: 5.458454]\n",
      "epoch:38 step:30443 [D loss: 0.468948, acc: 71.88%] [G loss: 3.532773]\n",
      "epoch:38 step:30444 [D loss: 0.132729, acc: 99.22%] [G loss: 3.196838]\n",
      "epoch:38 step:30445 [D loss: 0.116822, acc: 100.00%] [G loss: 7.986548]\n",
      "epoch:38 step:30446 [D loss: 0.091222, acc: 100.00%] [G loss: 5.448636]\n",
      "epoch:38 step:30447 [D loss: 0.226630, acc: 99.22%] [G loss: 2.344054]\n",
      "epoch:38 step:30448 [D loss: 0.134193, acc: 96.88%] [G loss: 4.592739]\n",
      "epoch:38 step:30449 [D loss: 1.875639, acc: 32.81%] [G loss: 3.009554]\n",
      "epoch:38 step:30450 [D loss: 0.559803, acc: 67.19%] [G loss: 5.958549]\n",
      "epoch:38 step:30451 [D loss: 0.010633, acc: 100.00%] [G loss: 9.299088]\n",
      "epoch:38 step:30452 [D loss: 0.127319, acc: 98.44%] [G loss: 7.697545]\n",
      "epoch:38 step:30453 [D loss: 0.362639, acc: 92.19%] [G loss: 3.752472]\n",
      "epoch:38 step:30454 [D loss: 0.801070, acc: 44.53%] [G loss: 5.701081]\n",
      "epoch:38 step:30455 [D loss: 0.153952, acc: 100.00%] [G loss: 5.910653]\n",
      "epoch:38 step:30456 [D loss: 0.579862, acc: 68.75%] [G loss: 2.598465]\n",
      "epoch:38 step:30457 [D loss: 0.223148, acc: 96.88%] [G loss: 5.965429]\n",
      "epoch:38 step:30458 [D loss: 0.318645, acc: 86.72%] [G loss: 3.512077]\n",
      "epoch:38 step:30459 [D loss: 0.229267, acc: 97.66%] [G loss: 5.803220]\n",
      "epoch:39 step:30460 [D loss: 0.242048, acc: 96.09%] [G loss: 6.601851]\n",
      "epoch:39 step:30461 [D loss: 0.040856, acc: 100.00%] [G loss: 4.233314]\n",
      "epoch:39 step:30462 [D loss: 0.138090, acc: 100.00%] [G loss: 4.402900]\n",
      "epoch:39 step:30463 [D loss: 0.726919, acc: 59.38%] [G loss: 5.847646]\n",
      "epoch:39 step:30464 [D loss: 0.839945, acc: 52.34%] [G loss: 6.184467]\n",
      "epoch:39 step:30465 [D loss: 0.494126, acc: 70.31%] [G loss: 5.623245]\n",
      "epoch:39 step:30466 [D loss: 0.321655, acc: 93.75%] [G loss: 6.383242]\n",
      "epoch:39 step:30467 [D loss: 1.160853, acc: 30.47%] [G loss: 5.287250]\n",
      "epoch:39 step:30468 [D loss: 0.442375, acc: 74.22%] [G loss: 3.427651]\n",
      "epoch:39 step:30469 [D loss: 0.231319, acc: 93.75%] [G loss: 6.096455]\n",
      "epoch:39 step:30470 [D loss: 0.127551, acc: 97.66%] [G loss: 5.924026]\n",
      "epoch:39 step:30471 [D loss: 0.092804, acc: 98.44%] [G loss: 5.901803]\n",
      "epoch:39 step:30472 [D loss: 0.449090, acc: 71.88%] [G loss: 6.051147]\n",
      "epoch:39 step:30473 [D loss: 0.120803, acc: 100.00%] [G loss: 5.720539]\n",
      "epoch:39 step:30474 [D loss: 0.929467, acc: 46.09%] [G loss: 6.469718]\n",
      "epoch:39 step:30475 [D loss: 0.240233, acc: 90.62%] [G loss: 9.260613]\n",
      "epoch:39 step:30476 [D loss: 0.072550, acc: 99.22%] [G loss: 4.287656]\n",
      "epoch:39 step:30477 [D loss: 0.216989, acc: 97.66%] [G loss: 5.086180]\n",
      "epoch:39 step:30478 [D loss: 0.839020, acc: 50.00%] [G loss: 5.627690]\n",
      "epoch:39 step:30479 [D loss: 1.408484, acc: 49.22%] [G loss: 6.309595]\n",
      "epoch:39 step:30480 [D loss: 0.084233, acc: 100.00%] [G loss: 7.544613]\n",
      "epoch:39 step:30481 [D loss: 0.480538, acc: 66.41%] [G loss: 5.563366]\n",
      "epoch:39 step:30482 [D loss: 0.509461, acc: 70.31%] [G loss: 4.793755]\n",
      "epoch:39 step:30483 [D loss: 0.379473, acc: 77.34%] [G loss: 5.555289]\n",
      "epoch:39 step:30484 [D loss: 0.287084, acc: 95.31%] [G loss: 2.699715]\n",
      "epoch:39 step:30485 [D loss: 0.473308, acc: 82.03%] [G loss: 4.443272]\n",
      "epoch:39 step:30486 [D loss: 0.165098, acc: 97.66%] [G loss: 7.380819]\n",
      "epoch:39 step:30487 [D loss: 0.736843, acc: 57.03%] [G loss: 4.731050]\n",
      "epoch:39 step:30488 [D loss: 0.303864, acc: 93.75%] [G loss: 2.834774]\n",
      "epoch:39 step:30489 [D loss: 0.073217, acc: 99.22%] [G loss: 3.972439]\n",
      "epoch:39 step:30490 [D loss: 0.374040, acc: 78.12%] [G loss: 6.994080]\n",
      "epoch:39 step:30491 [D loss: 0.144827, acc: 99.22%] [G loss: 3.550196]\n",
      "epoch:39 step:30492 [D loss: 0.786498, acc: 53.91%] [G loss: 2.871850]\n",
      "epoch:39 step:30493 [D loss: 0.067686, acc: 100.00%] [G loss: 6.494232]\n",
      "epoch:39 step:30494 [D loss: 0.639589, acc: 59.38%] [G loss: 6.815804]\n",
      "epoch:39 step:30495 [D loss: 0.136229, acc: 100.00%] [G loss: 6.807462]\n",
      "epoch:39 step:30496 [D loss: 0.343723, acc: 82.81%] [G loss: 5.926815]\n",
      "epoch:39 step:30497 [D loss: 0.279731, acc: 89.06%] [G loss: 6.193939]\n",
      "epoch:39 step:30498 [D loss: 0.715086, acc: 55.47%] [G loss: 4.391764]\n",
      "epoch:39 step:30499 [D loss: 0.296599, acc: 92.19%] [G loss: 5.598009]\n",
      "epoch:39 step:30500 [D loss: 0.043152, acc: 100.00%] [G loss: 4.103146]\n",
      "epoch:39 step:30501 [D loss: 0.696136, acc: 56.25%] [G loss: 5.192622]\n",
      "epoch:39 step:30502 [D loss: 0.307893, acc: 89.84%] [G loss: 3.779608]\n",
      "epoch:39 step:30503 [D loss: 1.442423, acc: 50.00%] [G loss: 4.153394]\n",
      "epoch:39 step:30504 [D loss: 0.354461, acc: 79.69%] [G loss: 5.460796]\n",
      "epoch:39 step:30505 [D loss: 1.724459, acc: 50.78%] [G loss: 7.642166]\n",
      "epoch:39 step:30506 [D loss: 0.877832, acc: 40.62%] [G loss: 5.602086]\n",
      "epoch:39 step:30507 [D loss: 1.009122, acc: 47.66%] [G loss: 8.268099]\n",
      "epoch:39 step:30508 [D loss: 0.382099, acc: 90.62%] [G loss: 2.985815]\n",
      "epoch:39 step:30509 [D loss: 0.140937, acc: 99.22%] [G loss: 4.759459]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30510 [D loss: 0.518463, acc: 71.09%] [G loss: 6.310192]\n",
      "epoch:39 step:30511 [D loss: 0.112573, acc: 100.00%] [G loss: 5.982193]\n",
      "epoch:39 step:30512 [D loss: 0.317149, acc: 89.84%] [G loss: 6.238554]\n",
      "epoch:39 step:30513 [D loss: 0.102830, acc: 100.00%] [G loss: 5.719597]\n",
      "epoch:39 step:30514 [D loss: 0.487902, acc: 74.22%] [G loss: 4.029199]\n",
      "epoch:39 step:30515 [D loss: 0.046503, acc: 100.00%] [G loss: 3.164941]\n",
      "epoch:39 step:30516 [D loss: 0.131354, acc: 99.22%] [G loss: 4.024986]\n",
      "epoch:39 step:30517 [D loss: 0.337868, acc: 80.47%] [G loss: 5.338573]\n",
      "epoch:39 step:30518 [D loss: 0.092978, acc: 98.44%] [G loss: 4.679350]\n",
      "epoch:39 step:30519 [D loss: 0.095561, acc: 100.00%] [G loss: 5.452256]\n",
      "epoch:39 step:30520 [D loss: 0.112358, acc: 100.00%] [G loss: 4.563310]\n",
      "epoch:39 step:30521 [D loss: 0.304399, acc: 94.53%] [G loss: 4.587101]\n",
      "epoch:39 step:30522 [D loss: 0.338106, acc: 91.41%] [G loss: 3.074064]\n",
      "epoch:39 step:30523 [D loss: 0.796938, acc: 53.12%] [G loss: 5.280440]\n",
      "epoch:39 step:30524 [D loss: 1.443618, acc: 50.00%] [G loss: 5.225564]\n",
      "epoch:39 step:30525 [D loss: 0.170593, acc: 96.88%] [G loss: 4.236882]\n",
      "epoch:39 step:30526 [D loss: 1.191845, acc: 39.84%] [G loss: 4.929683]\n",
      "epoch:39 step:30527 [D loss: 0.982819, acc: 51.56%] [G loss: 2.280344]\n",
      "epoch:39 step:30528 [D loss: 0.782148, acc: 53.12%] [G loss: 6.557140]\n",
      "epoch:39 step:30529 [D loss: 0.502795, acc: 64.06%] [G loss: 7.174798]\n",
      "epoch:39 step:30530 [D loss: 1.136410, acc: 24.22%] [G loss: 7.301331]\n",
      "epoch:39 step:30531 [D loss: 0.314685, acc: 82.81%] [G loss: 4.593180]\n",
      "epoch:39 step:30532 [D loss: 0.504596, acc: 82.03%] [G loss: 4.961594]\n",
      "epoch:39 step:30533 [D loss: 0.137863, acc: 99.22%] [G loss: 3.578144]\n",
      "epoch:39 step:30534 [D loss: 0.065474, acc: 100.00%] [G loss: 4.534960]\n",
      "epoch:39 step:30535 [D loss: 0.306373, acc: 92.19%] [G loss: 5.834168]\n",
      "epoch:39 step:30536 [D loss: 0.113021, acc: 100.00%] [G loss: 5.960630]\n",
      "epoch:39 step:30537 [D loss: 0.147928, acc: 97.66%] [G loss: 7.707799]\n",
      "epoch:39 step:30538 [D loss: 0.101405, acc: 100.00%] [G loss: 4.450342]\n",
      "epoch:39 step:30539 [D loss: 0.351257, acc: 92.97%] [G loss: 6.040987]\n",
      "epoch:39 step:30540 [D loss: 0.420043, acc: 75.00%] [G loss: 7.107903]\n",
      "epoch:39 step:30541 [D loss: 0.072886, acc: 100.00%] [G loss: 3.893748]\n",
      "epoch:39 step:30542 [D loss: 0.168130, acc: 96.88%] [G loss: 7.300632]\n",
      "epoch:39 step:30543 [D loss: 0.476809, acc: 72.66%] [G loss: 7.176473]\n",
      "epoch:39 step:30544 [D loss: 0.120457, acc: 100.00%] [G loss: 3.870523]\n",
      "epoch:39 step:30545 [D loss: 0.703480, acc: 57.81%] [G loss: 6.107557]\n",
      "epoch:39 step:30546 [D loss: 0.063553, acc: 100.00%] [G loss: 8.658705]\n",
      "epoch:39 step:30547 [D loss: 0.246653, acc: 96.09%] [G loss: 7.347303]\n",
      "epoch:39 step:30548 [D loss: 0.128699, acc: 99.22%] [G loss: 4.748333]\n",
      "epoch:39 step:30549 [D loss: 0.050553, acc: 100.00%] [G loss: 4.581255]\n",
      "epoch:39 step:30550 [D loss: 0.321231, acc: 84.38%] [G loss: 5.435415]\n",
      "epoch:39 step:30551 [D loss: 0.444618, acc: 75.00%] [G loss: 2.640134]\n",
      "epoch:39 step:30552 [D loss: 0.448238, acc: 78.91%] [G loss: 4.619345]\n",
      "epoch:39 step:30553 [D loss: 0.504087, acc: 71.09%] [G loss: 3.204369]\n",
      "epoch:39 step:30554 [D loss: 0.157227, acc: 99.22%] [G loss: 3.779174]\n",
      "epoch:39 step:30555 [D loss: 0.346827, acc: 83.59%] [G loss: 5.148870]\n",
      "epoch:39 step:30556 [D loss: 0.052474, acc: 100.00%] [G loss: 5.334270]\n",
      "epoch:39 step:30557 [D loss: 0.056694, acc: 100.00%] [G loss: 5.742356]\n",
      "epoch:39 step:30558 [D loss: 0.151839, acc: 100.00%] [G loss: 5.218670]\n",
      "epoch:39 step:30559 [D loss: 0.128549, acc: 98.44%] [G loss: 5.976206]\n",
      "epoch:39 step:30560 [D loss: 0.619925, acc: 63.28%] [G loss: 6.121515]\n",
      "epoch:39 step:30561 [D loss: 0.058315, acc: 100.00%] [G loss: 5.493912]\n",
      "epoch:39 step:30562 [D loss: 0.349008, acc: 84.38%] [G loss: 5.716411]\n",
      "epoch:39 step:30563 [D loss: 0.061380, acc: 100.00%] [G loss: 7.706680]\n",
      "epoch:39 step:30564 [D loss: 0.886892, acc: 49.22%] [G loss: 6.632687]\n",
      "epoch:39 step:30565 [D loss: 0.153061, acc: 99.22%] [G loss: 4.173995]\n",
      "epoch:39 step:30566 [D loss: 1.446652, acc: 13.28%] [G loss: 5.256401]\n",
      "epoch:39 step:30567 [D loss: 0.748509, acc: 57.81%] [G loss: 5.230055]\n",
      "epoch:39 step:30568 [D loss: 0.848929, acc: 51.56%] [G loss: 5.741741]\n",
      "epoch:39 step:30569 [D loss: 0.138435, acc: 100.00%] [G loss: 4.693280]\n",
      "epoch:39 step:30570 [D loss: 1.238965, acc: 48.44%] [G loss: 6.945278]\n",
      "epoch:39 step:30571 [D loss: 0.102271, acc: 99.22%] [G loss: 5.572814]\n",
      "epoch:39 step:30572 [D loss: 0.474356, acc: 69.53%] [G loss: 6.368203]\n",
      "epoch:39 step:30573 [D loss: 0.188119, acc: 96.88%] [G loss: 5.722482]\n",
      "epoch:39 step:30574 [D loss: 0.198088, acc: 97.66%] [G loss: 5.111904]\n",
      "epoch:39 step:30575 [D loss: 0.150593, acc: 98.44%] [G loss: 3.485638]\n",
      "epoch:39 step:30576 [D loss: 0.652577, acc: 64.84%] [G loss: 7.947765]\n",
      "epoch:39 step:30577 [D loss: 0.311748, acc: 81.25%] [G loss: 4.950828]\n",
      "epoch:39 step:30578 [D loss: 0.351843, acc: 88.28%] [G loss: 7.067610]\n",
      "epoch:39 step:30579 [D loss: 0.219831, acc: 99.22%] [G loss: 5.275338]\n",
      "epoch:39 step:30580 [D loss: 0.242405, acc: 96.88%] [G loss: 7.556574]\n",
      "epoch:39 step:30581 [D loss: 0.315588, acc: 93.75%] [G loss: 5.719900]\n",
      "epoch:39 step:30582 [D loss: 0.207983, acc: 99.22%] [G loss: 3.538304]\n",
      "epoch:39 step:30583 [D loss: 0.323470, acc: 89.84%] [G loss: 6.508594]\n",
      "epoch:39 step:30584 [D loss: 0.637886, acc: 57.81%] [G loss: 6.419227]\n",
      "epoch:39 step:30585 [D loss: 0.652157, acc: 58.59%] [G loss: 2.769365]\n",
      "epoch:39 step:30586 [D loss: 0.052143, acc: 100.00%] [G loss: 5.628691]\n",
      "epoch:39 step:30587 [D loss: 0.514504, acc: 67.19%] [G loss: 4.550212]\n",
      "epoch:39 step:30588 [D loss: 0.203400, acc: 99.22%] [G loss: 3.637244]\n",
      "epoch:39 step:30589 [D loss: 0.409600, acc: 75.78%] [G loss: 6.238178]\n",
      "epoch:39 step:30590 [D loss: 0.160498, acc: 96.88%] [G loss: 4.954037]\n",
      "epoch:39 step:30591 [D loss: 0.213900, acc: 97.66%] [G loss: 4.263294]\n",
      "epoch:39 step:30592 [D loss: 0.898293, acc: 38.28%] [G loss: 5.112865]\n",
      "epoch:39 step:30593 [D loss: 0.435639, acc: 78.91%] [G loss: 4.161220]\n",
      "epoch:39 step:30594 [D loss: 0.767714, acc: 53.91%] [G loss: 5.157579]\n",
      "epoch:39 step:30595 [D loss: 0.229780, acc: 98.44%] [G loss: 6.820054]\n",
      "epoch:39 step:30596 [D loss: 0.035642, acc: 100.00%] [G loss: 6.896703]\n",
      "epoch:39 step:30597 [D loss: 0.219146, acc: 95.31%] [G loss: 6.337982]\n",
      "epoch:39 step:30598 [D loss: 0.370294, acc: 85.16%] [G loss: 6.092065]\n",
      "epoch:39 step:30599 [D loss: 0.819697, acc: 50.78%] [G loss: 7.257542]\n",
      "epoch:39 step:30600 [D loss: 0.489729, acc: 76.56%] [G loss: 4.972495]\n",
      "epoch:39 step:30601 [D loss: 0.062741, acc: 100.00%] [G loss: 4.303636]\n",
      "epoch:39 step:30602 [D loss: 1.265646, acc: 19.53%] [G loss: 3.670490]\n",
      "epoch:39 step:30603 [D loss: 0.781913, acc: 50.78%] [G loss: 4.685989]\n",
      "epoch:39 step:30604 [D loss: 0.528952, acc: 64.06%] [G loss: 6.747480]\n",
      "epoch:39 step:30605 [D loss: 0.160524, acc: 99.22%] [G loss: 4.960497]\n",
      "epoch:39 step:30606 [D loss: 1.436976, acc: 24.22%] [G loss: 5.875247]\n",
      "epoch:39 step:30607 [D loss: 0.033384, acc: 100.00%] [G loss: 4.649858]\n",
      "epoch:39 step:30608 [D loss: 0.361745, acc: 89.06%] [G loss: 6.157911]\n",
      "epoch:39 step:30609 [D loss: 0.130519, acc: 99.22%] [G loss: 5.141469]\n",
      "epoch:39 step:30610 [D loss: 0.103672, acc: 100.00%] [G loss: 5.641747]\n",
      "epoch:39 step:30611 [D loss: 0.369163, acc: 90.62%] [G loss: 4.854810]\n",
      "epoch:39 step:30612 [D loss: 0.087489, acc: 99.22%] [G loss: 5.220119]\n",
      "epoch:39 step:30613 [D loss: 0.202382, acc: 96.88%] [G loss: 6.136703]\n",
      "epoch:39 step:30614 [D loss: 0.432956, acc: 85.16%] [G loss: 3.620372]\n",
      "epoch:39 step:30615 [D loss: 0.269268, acc: 94.53%] [G loss: 4.932185]\n",
      "epoch:39 step:30616 [D loss: 0.733697, acc: 55.47%] [G loss: 7.549794]\n",
      "epoch:39 step:30617 [D loss: 0.541206, acc: 64.84%] [G loss: 5.548119]\n",
      "epoch:39 step:30618 [D loss: 0.262598, acc: 92.97%] [G loss: 4.596472]\n",
      "epoch:39 step:30619 [D loss: 0.326241, acc: 92.19%] [G loss: 7.160467]\n",
      "epoch:39 step:30620 [D loss: 0.474537, acc: 75.78%] [G loss: 5.359050]\n",
      "epoch:39 step:30621 [D loss: 0.369199, acc: 89.06%] [G loss: 4.116127]\n",
      "epoch:39 step:30622 [D loss: 0.259872, acc: 96.09%] [G loss: 4.018951]\n",
      "epoch:39 step:30623 [D loss: 0.175479, acc: 98.44%] [G loss: 7.308105]\n",
      "epoch:39 step:30624 [D loss: 0.505068, acc: 75.00%] [G loss: 5.051646]\n",
      "epoch:39 step:30625 [D loss: 0.136906, acc: 98.44%] [G loss: 4.563188]\n",
      "epoch:39 step:30626 [D loss: 0.387477, acc: 89.06%] [G loss: 6.693339]\n",
      "epoch:39 step:30627 [D loss: 0.315948, acc: 91.41%] [G loss: 5.973857]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30628 [D loss: 0.218010, acc: 98.44%] [G loss: 4.760846]\n",
      "epoch:39 step:30629 [D loss: 0.178956, acc: 96.09%] [G loss: 7.204170]\n",
      "epoch:39 step:30630 [D loss: 0.210721, acc: 96.88%] [G loss: 7.195473]\n",
      "epoch:39 step:30631 [D loss: 0.059472, acc: 100.00%] [G loss: 5.099418]\n",
      "epoch:39 step:30632 [D loss: 1.019789, acc: 29.69%] [G loss: 2.073432]\n",
      "epoch:39 step:30633 [D loss: 0.306970, acc: 92.97%] [G loss: 4.233068]\n",
      "epoch:39 step:30634 [D loss: 0.071154, acc: 99.22%] [G loss: 7.889802]\n",
      "epoch:39 step:30635 [D loss: 0.341081, acc: 89.06%] [G loss: 3.833673]\n",
      "epoch:39 step:30636 [D loss: 0.067104, acc: 99.22%] [G loss: 3.848156]\n",
      "epoch:39 step:30637 [D loss: 1.763204, acc: 49.22%] [G loss: 5.972226]\n",
      "epoch:39 step:30638 [D loss: 0.607329, acc: 59.38%] [G loss: 6.435789]\n",
      "epoch:39 step:30639 [D loss: 0.709502, acc: 59.38%] [G loss: 3.679245]\n",
      "epoch:39 step:30640 [D loss: 0.273129, acc: 91.41%] [G loss: 3.704696]\n",
      "epoch:39 step:30641 [D loss: 0.631434, acc: 58.59%] [G loss: 7.228430]\n",
      "epoch:39 step:30642 [D loss: 0.700043, acc: 54.69%] [G loss: 7.348551]\n",
      "epoch:39 step:30643 [D loss: 0.152655, acc: 97.66%] [G loss: 7.168905]\n",
      "epoch:39 step:30644 [D loss: 0.271143, acc: 92.19%] [G loss: 4.961054]\n",
      "epoch:39 step:30645 [D loss: 0.528587, acc: 64.06%] [G loss: 6.605441]\n",
      "epoch:39 step:30646 [D loss: 0.313807, acc: 92.19%] [G loss: 5.730557]\n",
      "epoch:39 step:30647 [D loss: 0.186730, acc: 95.31%] [G loss: 6.271649]\n",
      "epoch:39 step:30648 [D loss: 0.563732, acc: 55.47%] [G loss: 8.361545]\n",
      "epoch:39 step:30649 [D loss: 0.391291, acc: 74.22%] [G loss: 7.348771]\n",
      "epoch:39 step:30650 [D loss: 0.136437, acc: 98.44%] [G loss: 3.997523]\n",
      "epoch:39 step:30651 [D loss: 0.942399, acc: 52.34%] [G loss: 5.766244]\n",
      "epoch:39 step:30652 [D loss: 0.813107, acc: 50.78%] [G loss: 5.522439]\n",
      "epoch:39 step:30653 [D loss: 0.222639, acc: 95.31%] [G loss: 6.882845]\n",
      "epoch:39 step:30654 [D loss: 0.642136, acc: 60.94%] [G loss: 4.176530]\n",
      "epoch:39 step:30655 [D loss: 0.846987, acc: 38.28%] [G loss: 5.406104]\n",
      "epoch:39 step:30656 [D loss: 0.092868, acc: 99.22%] [G loss: 5.201296]\n",
      "epoch:39 step:30657 [D loss: 0.453121, acc: 79.69%] [G loss: 4.079427]\n",
      "epoch:39 step:30658 [D loss: 0.145057, acc: 99.22%] [G loss: 3.256413]\n",
      "epoch:39 step:30659 [D loss: 0.275046, acc: 97.66%] [G loss: 8.386497]\n",
      "epoch:39 step:30660 [D loss: 0.326509, acc: 94.53%] [G loss: 3.594958]\n",
      "epoch:39 step:30661 [D loss: 0.130800, acc: 99.22%] [G loss: 5.883258]\n",
      "epoch:39 step:30662 [D loss: 0.108268, acc: 99.22%] [G loss: 4.115943]\n",
      "epoch:39 step:30663 [D loss: 0.257389, acc: 94.53%] [G loss: 3.445257]\n",
      "epoch:39 step:30664 [D loss: 0.479403, acc: 67.19%] [G loss: 5.078637]\n",
      "epoch:39 step:30665 [D loss: 0.040974, acc: 100.00%] [G loss: 4.267367]\n",
      "epoch:39 step:30666 [D loss: 0.714658, acc: 61.72%] [G loss: 4.848593]\n",
      "epoch:39 step:30667 [D loss: 0.439226, acc: 71.09%] [G loss: 5.657607]\n",
      "epoch:39 step:30668 [D loss: 1.002824, acc: 50.78%] [G loss: 7.784237]\n",
      "epoch:39 step:30669 [D loss: 0.732091, acc: 59.38%] [G loss: 4.887497]\n",
      "epoch:39 step:30670 [D loss: 0.343956, acc: 93.75%] [G loss: 3.522432]\n",
      "epoch:39 step:30671 [D loss: 0.064191, acc: 100.00%] [G loss: 7.412058]\n",
      "epoch:39 step:30672 [D loss: 0.176932, acc: 95.31%] [G loss: 6.960491]\n",
      "epoch:39 step:30673 [D loss: 0.125730, acc: 99.22%] [G loss: 4.036342]\n",
      "epoch:39 step:30674 [D loss: 0.276915, acc: 95.31%] [G loss: 6.020122]\n",
      "epoch:39 step:30675 [D loss: 0.411292, acc: 83.59%] [G loss: 6.301004]\n",
      "epoch:39 step:30676 [D loss: 0.258270, acc: 94.53%] [G loss: 6.218173]\n",
      "epoch:39 step:30677 [D loss: 0.118063, acc: 99.22%] [G loss: 4.894606]\n",
      "epoch:39 step:30678 [D loss: 0.243509, acc: 96.88%] [G loss: 5.190009]\n",
      "epoch:39 step:30679 [D loss: 0.113361, acc: 99.22%] [G loss: 5.780118]\n",
      "epoch:39 step:30680 [D loss: 0.858804, acc: 48.44%] [G loss: 4.836616]\n",
      "epoch:39 step:30681 [D loss: 0.815895, acc: 50.78%] [G loss: 4.620593]\n",
      "epoch:39 step:30682 [D loss: 0.433837, acc: 83.59%] [G loss: 3.315669]\n",
      "epoch:39 step:30683 [D loss: 0.337659, acc: 91.41%] [G loss: 7.210450]\n",
      "epoch:39 step:30684 [D loss: 0.180763, acc: 98.44%] [G loss: 3.654518]\n",
      "epoch:39 step:30685 [D loss: 0.106038, acc: 98.44%] [G loss: 3.864906]\n",
      "epoch:39 step:30686 [D loss: 0.087553, acc: 100.00%] [G loss: 4.593001]\n",
      "epoch:39 step:30687 [D loss: 0.226821, acc: 97.66%] [G loss: 4.594965]\n",
      "epoch:39 step:30688 [D loss: 0.136961, acc: 99.22%] [G loss: 6.934060]\n",
      "epoch:39 step:30689 [D loss: 1.067719, acc: 22.66%] [G loss: 5.632093]\n",
      "epoch:39 step:30690 [D loss: 0.104036, acc: 100.00%] [G loss: 5.120430]\n",
      "epoch:39 step:30691 [D loss: 0.085306, acc: 100.00%] [G loss: 3.492586]\n",
      "epoch:39 step:30692 [D loss: 0.104744, acc: 99.22%] [G loss: 6.357941]\n",
      "epoch:39 step:30693 [D loss: 0.346219, acc: 80.47%] [G loss: 5.194270]\n",
      "epoch:39 step:30694 [D loss: 0.486796, acc: 66.41%] [G loss: 5.071402]\n",
      "epoch:39 step:30695 [D loss: 0.552258, acc: 74.22%] [G loss: 2.875498]\n",
      "epoch:39 step:30696 [D loss: 0.208246, acc: 98.44%] [G loss: 4.776114]\n",
      "epoch:39 step:30697 [D loss: 0.380971, acc: 89.84%] [G loss: 4.399698]\n",
      "epoch:39 step:30698 [D loss: 0.401299, acc: 87.50%] [G loss: 6.720758]\n",
      "epoch:39 step:30699 [D loss: 0.106659, acc: 99.22%] [G loss: 4.027123]\n",
      "epoch:39 step:30700 [D loss: 0.373025, acc: 89.06%] [G loss: 4.428743]\n",
      "epoch:39 step:30701 [D loss: 0.034535, acc: 100.00%] [G loss: 5.946282]\n",
      "epoch:39 step:30702 [D loss: 0.952457, acc: 41.41%] [G loss: 4.695499]\n",
      "epoch:39 step:30703 [D loss: 0.102161, acc: 99.22%] [G loss: 11.431755]\n",
      "epoch:39 step:30704 [D loss: 0.246624, acc: 94.53%] [G loss: 3.063173]\n",
      "epoch:39 step:30705 [D loss: 0.270648, acc: 93.75%] [G loss: 6.741111]\n",
      "epoch:39 step:30706 [D loss: 0.278747, acc: 96.09%] [G loss: 4.519232]\n",
      "epoch:39 step:30707 [D loss: 1.400119, acc: 49.22%] [G loss: 2.629256]\n",
      "epoch:39 step:30708 [D loss: 0.495514, acc: 67.19%] [G loss: 5.751254]\n",
      "epoch:39 step:30709 [D loss: 0.132785, acc: 97.66%] [G loss: 7.960955]\n",
      "epoch:39 step:30710 [D loss: 0.211785, acc: 92.97%] [G loss: 8.325808]\n",
      "epoch:39 step:30711 [D loss: 0.902678, acc: 49.22%] [G loss: 6.614856]\n",
      "epoch:39 step:30712 [D loss: 0.886265, acc: 35.16%] [G loss: 6.249767]\n",
      "epoch:39 step:30713 [D loss: 1.075955, acc: 50.00%] [G loss: 5.338154]\n",
      "epoch:39 step:30714 [D loss: 0.182304, acc: 100.00%] [G loss: 5.137226]\n",
      "epoch:39 step:30715 [D loss: 0.245643, acc: 90.62%] [G loss: 4.726965]\n",
      "epoch:39 step:30716 [D loss: 0.472284, acc: 65.62%] [G loss: 6.214985]\n",
      "epoch:39 step:30717 [D loss: 0.492179, acc: 65.62%] [G loss: 4.995656]\n",
      "epoch:39 step:30718 [D loss: 0.268098, acc: 98.44%] [G loss: 4.381907]\n",
      "epoch:39 step:30719 [D loss: 0.174631, acc: 97.66%] [G loss: 5.673102]\n",
      "epoch:39 step:30720 [D loss: 0.127079, acc: 100.00%] [G loss: 7.580382]\n",
      "epoch:39 step:30721 [D loss: 0.269952, acc: 93.75%] [G loss: 10.396885]\n",
      "epoch:39 step:30722 [D loss: 0.365757, acc: 78.12%] [G loss: 4.792049]\n",
      "epoch:39 step:30723 [D loss: 1.132958, acc: 50.00%] [G loss: 3.184668]\n",
      "epoch:39 step:30724 [D loss: 0.259202, acc: 98.44%] [G loss: 4.412565]\n",
      "epoch:39 step:30725 [D loss: 1.819487, acc: 47.66%] [G loss: 7.259584]\n",
      "epoch:39 step:30726 [D loss: 0.496260, acc: 74.22%] [G loss: 4.966337]\n",
      "epoch:39 step:30727 [D loss: 0.786939, acc: 57.03%] [G loss: 6.019685]\n",
      "epoch:39 step:30728 [D loss: 0.258907, acc: 89.84%] [G loss: 7.106272]\n",
      "epoch:39 step:30729 [D loss: 0.827645, acc: 50.78%] [G loss: 6.009874]\n",
      "epoch:39 step:30730 [D loss: 0.417423, acc: 72.66%] [G loss: 8.606510]\n",
      "epoch:39 step:30731 [D loss: 0.205826, acc: 99.22%] [G loss: 5.726120]\n",
      "epoch:39 step:30732 [D loss: 0.270261, acc: 92.19%] [G loss: 3.911700]\n",
      "epoch:39 step:30733 [D loss: 0.108462, acc: 100.00%] [G loss: 5.147108]\n",
      "epoch:39 step:30734 [D loss: 0.337249, acc: 81.25%] [G loss: 4.685063]\n",
      "epoch:39 step:30735 [D loss: 0.335705, acc: 81.25%] [G loss: 7.072073]\n",
      "epoch:39 step:30736 [D loss: 1.372213, acc: 29.69%] [G loss: 7.549642]\n",
      "epoch:39 step:30737 [D loss: 0.051420, acc: 100.00%] [G loss: 3.292465]\n",
      "epoch:39 step:30738 [D loss: 0.132318, acc: 96.88%] [G loss: 5.275514]\n",
      "epoch:39 step:30739 [D loss: 0.136327, acc: 99.22%] [G loss: 5.842027]\n",
      "epoch:39 step:30740 [D loss: 0.170256, acc: 98.44%] [G loss: 6.660385]\n",
      "epoch:39 step:30741 [D loss: 0.064085, acc: 100.00%] [G loss: 2.860547]\n",
      "epoch:39 step:30742 [D loss: 0.310821, acc: 84.38%] [G loss: 5.278650]\n",
      "epoch:39 step:30743 [D loss: 0.625230, acc: 69.53%] [G loss: 6.635292]\n",
      "epoch:39 step:30744 [D loss: 0.677793, acc: 64.84%] [G loss: 4.707316]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30745 [D loss: 0.286451, acc: 96.88%] [G loss: 6.339949]\n",
      "epoch:39 step:30746 [D loss: 0.159141, acc: 99.22%] [G loss: 4.957187]\n",
      "epoch:39 step:30747 [D loss: 0.120215, acc: 100.00%] [G loss: 7.142949]\n",
      "epoch:39 step:30748 [D loss: 0.600140, acc: 68.75%] [G loss: 4.357476]\n",
      "epoch:39 step:30749 [D loss: 0.904002, acc: 51.56%] [G loss: 6.392320]\n",
      "epoch:39 step:30750 [D loss: 0.099254, acc: 99.22%] [G loss: 9.442384]\n",
      "epoch:39 step:30751 [D loss: 0.741546, acc: 56.25%] [G loss: 7.427208]\n",
      "epoch:39 step:30752 [D loss: 0.923673, acc: 42.19%] [G loss: 6.677318]\n",
      "epoch:39 step:30753 [D loss: 0.336109, acc: 89.84%] [G loss: 4.439521]\n",
      "epoch:39 step:30754 [D loss: 1.489138, acc: 27.34%] [G loss: 4.305846]\n",
      "epoch:39 step:30755 [D loss: 0.022486, acc: 100.00%] [G loss: 5.748449]\n",
      "epoch:39 step:30756 [D loss: 0.446038, acc: 71.09%] [G loss: 5.635416]\n",
      "epoch:39 step:30757 [D loss: 0.859825, acc: 36.72%] [G loss: 3.346644]\n",
      "epoch:39 step:30758 [D loss: 0.123177, acc: 100.00%] [G loss: 6.116781]\n",
      "epoch:39 step:30759 [D loss: 0.670287, acc: 57.03%] [G loss: 5.622918]\n",
      "epoch:39 step:30760 [D loss: 0.570978, acc: 59.38%] [G loss: 6.899990]\n",
      "epoch:39 step:30761 [D loss: 0.851470, acc: 52.34%] [G loss: 5.938846]\n",
      "epoch:39 step:30762 [D loss: 0.307770, acc: 89.84%] [G loss: 4.281576]\n",
      "epoch:39 step:30763 [D loss: 0.675592, acc: 67.97%] [G loss: 5.173749]\n",
      "epoch:39 step:30764 [D loss: 0.206508, acc: 100.00%] [G loss: 6.558175]\n",
      "epoch:39 step:30765 [D loss: 0.395757, acc: 68.75%] [G loss: 4.811279]\n",
      "epoch:39 step:30766 [D loss: 0.092074, acc: 100.00%] [G loss: 5.349300]\n",
      "epoch:39 step:30767 [D loss: 0.247512, acc: 94.53%] [G loss: 3.676161]\n",
      "epoch:39 step:30768 [D loss: 0.258697, acc: 96.09%] [G loss: 3.266017]\n",
      "epoch:39 step:30769 [D loss: 0.287133, acc: 92.19%] [G loss: 8.641122]\n",
      "epoch:39 step:30770 [D loss: 0.658031, acc: 56.25%] [G loss: 2.182047]\n",
      "epoch:39 step:30771 [D loss: 0.281557, acc: 94.53%] [G loss: 4.635043]\n",
      "epoch:39 step:30772 [D loss: 0.100441, acc: 100.00%] [G loss: 2.967114]\n",
      "epoch:39 step:30773 [D loss: 0.104134, acc: 100.00%] [G loss: 4.249375]\n",
      "epoch:39 step:30774 [D loss: 0.148435, acc: 99.22%] [G loss: 4.994314]\n",
      "epoch:39 step:30775 [D loss: 0.665300, acc: 64.84%] [G loss: 5.861989]\n",
      "epoch:39 step:30776 [D loss: 0.090593, acc: 100.00%] [G loss: 3.187619]\n",
      "epoch:39 step:30777 [D loss: 0.878406, acc: 50.78%] [G loss: 5.635991]\n",
      "epoch:39 step:30778 [D loss: 0.092195, acc: 99.22%] [G loss: 6.677141]\n",
      "epoch:39 step:30779 [D loss: 1.077548, acc: 48.44%] [G loss: 8.578304]\n",
      "epoch:39 step:30780 [D loss: 0.374227, acc: 85.94%] [G loss: 1.893156]\n",
      "epoch:39 step:30781 [D loss: 0.128890, acc: 100.00%] [G loss: 2.643849]\n",
      "epoch:39 step:30782 [D loss: 0.159929, acc: 99.22%] [G loss: 5.873478]\n",
      "epoch:39 step:30783 [D loss: 0.146302, acc: 99.22%] [G loss: 6.357175]\n",
      "epoch:39 step:30784 [D loss: 0.340540, acc: 93.75%] [G loss: 4.631724]\n",
      "epoch:39 step:30785 [D loss: 0.583554, acc: 66.41%] [G loss: 7.073071]\n",
      "epoch:39 step:30786 [D loss: 0.109786, acc: 99.22%] [G loss: 4.175254]\n",
      "epoch:39 step:30787 [D loss: 0.212101, acc: 96.09%] [G loss: 3.657333]\n",
      "epoch:39 step:30788 [D loss: 0.062585, acc: 100.00%] [G loss: 3.969389]\n",
      "epoch:39 step:30789 [D loss: 0.439655, acc: 83.59%] [G loss: 7.372193]\n",
      "epoch:39 step:30790 [D loss: 0.243828, acc: 97.66%] [G loss: 1.905881]\n",
      "epoch:39 step:30791 [D loss: 0.447112, acc: 78.91%] [G loss: 6.979163]\n",
      "epoch:39 step:30792 [D loss: 0.086050, acc: 100.00%] [G loss: 5.729023]\n",
      "epoch:39 step:30793 [D loss: 0.661392, acc: 60.16%] [G loss: 6.271994]\n",
      "epoch:39 step:30794 [D loss: 0.028651, acc: 100.00%] [G loss: 6.562802]\n",
      "epoch:39 step:30795 [D loss: 0.034629, acc: 100.00%] [G loss: 6.829678]\n",
      "epoch:39 step:30796 [D loss: 1.286107, acc: 11.72%] [G loss: 7.855484]\n",
      "epoch:39 step:30797 [D loss: 0.157267, acc: 99.22%] [G loss: 5.109573]\n",
      "epoch:39 step:30798 [D loss: 0.419775, acc: 78.12%] [G loss: 4.297545]\n",
      "epoch:39 step:30799 [D loss: 0.293018, acc: 92.97%] [G loss: 6.075222]\n",
      "epoch:39 step:30800 [D loss: 0.151049, acc: 99.22%] [G loss: 3.436458]\n",
      "epoch:39 step:30801 [D loss: 0.795127, acc: 53.12%] [G loss: 4.674040]\n",
      "epoch:39 step:30802 [D loss: 0.509924, acc: 68.75%] [G loss: 5.167572]\n",
      "epoch:39 step:30803 [D loss: 0.171137, acc: 98.44%] [G loss: 3.215157]\n",
      "epoch:39 step:30804 [D loss: 0.413052, acc: 78.91%] [G loss: 6.485050]\n",
      "epoch:39 step:30805 [D loss: 1.032907, acc: 50.00%] [G loss: 6.375211]\n",
      "epoch:39 step:30806 [D loss: 0.087126, acc: 98.44%] [G loss: 6.299788]\n",
      "epoch:39 step:30807 [D loss: 0.249396, acc: 97.66%] [G loss: 5.288078]\n",
      "epoch:39 step:30808 [D loss: 0.127727, acc: 99.22%] [G loss: 5.137955]\n",
      "epoch:39 step:30809 [D loss: 1.564862, acc: 28.91%] [G loss: 7.408948]\n",
      "epoch:39 step:30810 [D loss: 2.233503, acc: 6.25%] [G loss: 5.079143]\n",
      "epoch:39 step:30811 [D loss: 0.240345, acc: 94.53%] [G loss: 4.369160]\n",
      "epoch:39 step:30812 [D loss: 0.473454, acc: 71.88%] [G loss: 4.440291]\n",
      "epoch:39 step:30813 [D loss: 0.447465, acc: 73.44%] [G loss: 3.687481]\n",
      "epoch:39 step:30814 [D loss: 0.092321, acc: 100.00%] [G loss: 7.292476]\n",
      "epoch:39 step:30815 [D loss: 0.118934, acc: 97.66%] [G loss: 3.607837]\n",
      "epoch:39 step:30816 [D loss: 0.379616, acc: 90.62%] [G loss: 2.812706]\n",
      "epoch:39 step:30817 [D loss: 0.649671, acc: 62.50%] [G loss: 6.592121]\n",
      "epoch:39 step:30818 [D loss: 0.769698, acc: 51.56%] [G loss: 7.983362]\n",
      "epoch:39 step:30819 [D loss: 0.479056, acc: 67.97%] [G loss: 4.113232]\n",
      "epoch:39 step:30820 [D loss: 0.250641, acc: 92.97%] [G loss: 3.606210]\n",
      "epoch:39 step:30821 [D loss: 0.132532, acc: 98.44%] [G loss: 6.309089]\n",
      "epoch:39 step:30822 [D loss: 0.222001, acc: 96.09%] [G loss: 5.123189]\n",
      "epoch:39 step:30823 [D loss: 0.227879, acc: 97.66%] [G loss: 5.768326]\n",
      "epoch:39 step:30824 [D loss: 0.203928, acc: 96.88%] [G loss: 4.866474]\n",
      "epoch:39 step:30825 [D loss: 0.127849, acc: 99.22%] [G loss: 2.931447]\n",
      "epoch:39 step:30826 [D loss: 0.420448, acc: 78.91%] [G loss: 6.439108]\n",
      "epoch:39 step:30827 [D loss: 0.064667, acc: 100.00%] [G loss: 5.648927]\n",
      "epoch:39 step:30828 [D loss: 0.456089, acc: 69.53%] [G loss: 5.363147]\n",
      "epoch:39 step:30829 [D loss: 0.168316, acc: 98.44%] [G loss: 3.288673]\n",
      "epoch:39 step:30830 [D loss: 0.052509, acc: 100.00%] [G loss: 6.108947]\n",
      "epoch:39 step:30831 [D loss: 0.081132, acc: 100.00%] [G loss: 4.205969]\n",
      "epoch:39 step:30832 [D loss: 0.770945, acc: 53.91%] [G loss: 2.565140]\n",
      "epoch:39 step:30833 [D loss: 0.084183, acc: 99.22%] [G loss: 6.838101]\n",
      "epoch:39 step:30834 [D loss: 0.296819, acc: 84.38%] [G loss: 6.308205]\n",
      "epoch:39 step:30835 [D loss: 0.477489, acc: 71.09%] [G loss: 3.387030]\n",
      "epoch:39 step:30836 [D loss: 0.295280, acc: 88.28%] [G loss: 6.036771]\n",
      "epoch:39 step:30837 [D loss: 0.184662, acc: 98.44%] [G loss: 3.583388]\n",
      "epoch:39 step:30838 [D loss: 0.092183, acc: 100.00%] [G loss: 3.172192]\n",
      "epoch:39 step:30839 [D loss: 0.027936, acc: 100.00%] [G loss: 6.239992]\n",
      "epoch:39 step:30840 [D loss: 0.188583, acc: 96.09%] [G loss: 5.182938]\n",
      "epoch:39 step:30841 [D loss: 0.091637, acc: 99.22%] [G loss: 5.464075]\n",
      "epoch:39 step:30842 [D loss: 0.281939, acc: 92.97%] [G loss: 3.601592]\n",
      "epoch:39 step:30843 [D loss: 0.099243, acc: 100.00%] [G loss: 2.540479]\n",
      "epoch:39 step:30844 [D loss: 0.211092, acc: 97.66%] [G loss: 4.462491]\n",
      "epoch:39 step:30845 [D loss: 0.463745, acc: 71.88%] [G loss: 5.221023]\n",
      "epoch:39 step:30846 [D loss: 0.582583, acc: 59.38%] [G loss: 6.138966]\n",
      "epoch:39 step:30847 [D loss: 0.388644, acc: 81.25%] [G loss: 6.281920]\n",
      "epoch:39 step:30848 [D loss: 0.558555, acc: 60.16%] [G loss: 3.133371]\n",
      "epoch:39 step:30849 [D loss: 0.310783, acc: 86.72%] [G loss: 6.304645]\n",
      "epoch:39 step:30850 [D loss: 0.209356, acc: 96.88%] [G loss: 4.503841]\n",
      "epoch:39 step:30851 [D loss: 0.220866, acc: 93.75%] [G loss: 5.892818]\n",
      "epoch:39 step:30852 [D loss: 0.331757, acc: 87.50%] [G loss: 2.367602]\n",
      "epoch:39 step:30853 [D loss: 0.760954, acc: 52.34%] [G loss: 6.910837]\n",
      "epoch:39 step:30854 [D loss: 0.296441, acc: 92.97%] [G loss: 4.259020]\n",
      "epoch:39 step:30855 [D loss: 0.036859, acc: 100.00%] [G loss: 6.494333]\n",
      "epoch:39 step:30856 [D loss: 0.695902, acc: 56.25%] [G loss: 4.032979]\n",
      "epoch:39 step:30857 [D loss: 0.438040, acc: 82.81%] [G loss: 4.111161]\n",
      "epoch:39 step:30858 [D loss: 0.149630, acc: 100.00%] [G loss: 3.150683]\n",
      "epoch:39 step:30859 [D loss: 0.147222, acc: 98.44%] [G loss: 5.199818]\n",
      "epoch:39 step:30860 [D loss: 0.066021, acc: 100.00%] [G loss: 6.919663]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30861 [D loss: 0.206831, acc: 98.44%] [G loss: 4.984581]\n",
      "epoch:39 step:30862 [D loss: 0.124224, acc: 99.22%] [G loss: 5.945458]\n",
      "epoch:39 step:30863 [D loss: 0.430106, acc: 74.22%] [G loss: 5.979531]\n",
      "epoch:39 step:30864 [D loss: 1.249903, acc: 17.19%] [G loss: 6.305821]\n",
      "epoch:39 step:30865 [D loss: 0.854296, acc: 50.00%] [G loss: 4.395508]\n",
      "epoch:39 step:30866 [D loss: 0.211926, acc: 96.09%] [G loss: 6.614322]\n",
      "epoch:39 step:30867 [D loss: 0.076905, acc: 100.00%] [G loss: 3.985580]\n",
      "epoch:39 step:30868 [D loss: 0.041501, acc: 100.00%] [G loss: 8.451592]\n",
      "epoch:39 step:30869 [D loss: 0.229860, acc: 93.75%] [G loss: 6.427144]\n",
      "epoch:39 step:30870 [D loss: 0.419433, acc: 74.22%] [G loss: 7.084567]\n",
      "epoch:39 step:30871 [D loss: 0.148364, acc: 100.00%] [G loss: 6.349873]\n",
      "epoch:39 step:30872 [D loss: 0.128120, acc: 100.00%] [G loss: 4.396208]\n",
      "epoch:39 step:30873 [D loss: 0.415995, acc: 85.94%] [G loss: 5.620094]\n",
      "epoch:39 step:30874 [D loss: 0.430661, acc: 72.66%] [G loss: 4.505632]\n",
      "epoch:39 step:30875 [D loss: 0.435703, acc: 67.97%] [G loss: 3.867357]\n",
      "epoch:39 step:30876 [D loss: 0.493472, acc: 85.16%] [G loss: 5.002462]\n",
      "epoch:39 step:30877 [D loss: 0.064819, acc: 100.00%] [G loss: 6.469567]\n",
      "epoch:39 step:30878 [D loss: 0.118821, acc: 99.22%] [G loss: 4.874545]\n",
      "epoch:39 step:30879 [D loss: 0.357929, acc: 91.41%] [G loss: 3.100767]\n",
      "epoch:39 step:30880 [D loss: 0.217394, acc: 94.53%] [G loss: 5.728191]\n",
      "epoch:39 step:30881 [D loss: 0.294990, acc: 90.62%] [G loss: 6.142609]\n",
      "epoch:39 step:30882 [D loss: 0.527284, acc: 66.41%] [G loss: 7.003606]\n",
      "epoch:39 step:30883 [D loss: 0.092296, acc: 100.00%] [G loss: 4.450904]\n",
      "epoch:39 step:30884 [D loss: 0.375513, acc: 83.59%] [G loss: 7.146216]\n",
      "epoch:39 step:30885 [D loss: 0.684761, acc: 61.72%] [G loss: 5.573442]\n",
      "epoch:39 step:30886 [D loss: 0.997334, acc: 30.47%] [G loss: 8.777513]\n",
      "epoch:39 step:30887 [D loss: 0.280849, acc: 86.72%] [G loss: 6.202776]\n",
      "epoch:39 step:30888 [D loss: 0.161557, acc: 96.88%] [G loss: 6.608071]\n",
      "epoch:39 step:30889 [D loss: 0.144005, acc: 98.44%] [G loss: 6.230230]\n",
      "epoch:39 step:30890 [D loss: 0.618644, acc: 63.28%] [G loss: 5.565724]\n",
      "epoch:39 step:30891 [D loss: 0.153252, acc: 100.00%] [G loss: 4.838058]\n",
      "epoch:39 step:30892 [D loss: 0.562611, acc: 67.19%] [G loss: 2.942711]\n",
      "epoch:39 step:30893 [D loss: 0.121219, acc: 98.44%] [G loss: 3.981994]\n",
      "epoch:39 step:30894 [D loss: 0.106484, acc: 98.44%] [G loss: 7.442203]\n",
      "epoch:39 step:30895 [D loss: 0.321525, acc: 81.25%] [G loss: 6.684632]\n",
      "epoch:39 step:30896 [D loss: 0.214238, acc: 96.09%] [G loss: 3.055357]\n",
      "epoch:39 step:30897 [D loss: 0.292266, acc: 86.72%] [G loss: 7.024377]\n",
      "epoch:39 step:30898 [D loss: 0.106005, acc: 99.22%] [G loss: 5.588959]\n",
      "epoch:39 step:30899 [D loss: 1.140028, acc: 18.75%] [G loss: 5.128396]\n",
      "epoch:39 step:30900 [D loss: 0.414609, acc: 85.94%] [G loss: 6.799257]\n",
      "epoch:39 step:30901 [D loss: 0.337501, acc: 91.41%] [G loss: 6.256806]\n",
      "epoch:39 step:30902 [D loss: 0.291781, acc: 85.16%] [G loss: 3.789435]\n",
      "epoch:39 step:30903 [D loss: 0.311839, acc: 85.94%] [G loss: 4.369287]\n",
      "epoch:39 step:30904 [D loss: 0.172093, acc: 98.44%] [G loss: 4.803737]\n",
      "epoch:39 step:30905 [D loss: 0.237570, acc: 96.88%] [G loss: 5.354255]\n",
      "epoch:39 step:30906 [D loss: 0.073037, acc: 100.00%] [G loss: 6.676655]\n",
      "epoch:39 step:30907 [D loss: 0.142694, acc: 98.44%] [G loss: 6.644783]\n",
      "epoch:39 step:30908 [D loss: 0.129745, acc: 96.88%] [G loss: 5.691639]\n",
      "epoch:39 step:30909 [D loss: 0.695062, acc: 54.69%] [G loss: 6.052287]\n",
      "epoch:39 step:30910 [D loss: 0.622660, acc: 64.84%] [G loss: 8.111380]\n",
      "epoch:39 step:30911 [D loss: 0.308910, acc: 93.75%] [G loss: 3.813989]\n",
      "epoch:39 step:30912 [D loss: 0.543324, acc: 69.53%] [G loss: 5.363198]\n",
      "epoch:39 step:30913 [D loss: 0.427200, acc: 78.91%] [G loss: 4.880081]\n",
      "epoch:39 step:30914 [D loss: 0.092685, acc: 100.00%] [G loss: 5.393237]\n",
      "epoch:39 step:30915 [D loss: 0.426911, acc: 74.22%] [G loss: 2.390269]\n",
      "epoch:39 step:30916 [D loss: 0.556029, acc: 61.72%] [G loss: 7.596445]\n",
      "epoch:39 step:30917 [D loss: 0.533677, acc: 75.00%] [G loss: 5.406570]\n",
      "epoch:39 step:30918 [D loss: 0.042866, acc: 100.00%] [G loss: 5.230558]\n",
      "epoch:39 step:30919 [D loss: 0.134220, acc: 97.66%] [G loss: 8.883269]\n",
      "epoch:39 step:30920 [D loss: 0.054171, acc: 100.00%] [G loss: 5.302416]\n",
      "epoch:39 step:30921 [D loss: 0.052225, acc: 100.00%] [G loss: 6.316622]\n",
      "epoch:39 step:30922 [D loss: 0.067452, acc: 100.00%] [G loss: 5.205970]\n",
      "epoch:39 step:30923 [D loss: 0.583220, acc: 58.59%] [G loss: 7.200772]\n",
      "epoch:39 step:30924 [D loss: 0.304939, acc: 85.94%] [G loss: 7.471542]\n",
      "epoch:39 step:30925 [D loss: 0.036688, acc: 100.00%] [G loss: 4.734713]\n",
      "epoch:39 step:30926 [D loss: 0.487636, acc: 78.91%] [G loss: 6.395515]\n",
      "epoch:39 step:30927 [D loss: 0.660461, acc: 57.03%] [G loss: 3.763410]\n",
      "epoch:39 step:30928 [D loss: 0.490014, acc: 65.62%] [G loss: 8.210281]\n",
      "epoch:39 step:30929 [D loss: 0.124271, acc: 100.00%] [G loss: 6.494712]\n",
      "epoch:39 step:30930 [D loss: 0.222404, acc: 96.09%] [G loss: 3.993101]\n",
      "epoch:39 step:30931 [D loss: 0.044979, acc: 100.00%] [G loss: 3.971681]\n",
      "epoch:39 step:30932 [D loss: 0.651645, acc: 60.94%] [G loss: 6.382575]\n",
      "epoch:39 step:30933 [D loss: 0.292094, acc: 91.41%] [G loss: 7.605660]\n",
      "epoch:39 step:30934 [D loss: 0.080135, acc: 100.00%] [G loss: 3.639946]\n",
      "epoch:39 step:30935 [D loss: 0.105718, acc: 99.22%] [G loss: 6.843666]\n",
      "epoch:39 step:30936 [D loss: 0.159043, acc: 98.44%] [G loss: 4.710085]\n",
      "epoch:39 step:30937 [D loss: 0.048471, acc: 100.00%] [G loss: 5.261197]\n",
      "epoch:39 step:30938 [D loss: 0.029395, acc: 100.00%] [G loss: 6.303649]\n",
      "epoch:39 step:30939 [D loss: 0.225916, acc: 96.88%] [G loss: 6.860858]\n",
      "epoch:39 step:30940 [D loss: 0.117929, acc: 97.66%] [G loss: 3.415579]\n",
      "epoch:39 step:30941 [D loss: 0.906773, acc: 42.19%] [G loss: 3.781320]\n",
      "epoch:39 step:30942 [D loss: 0.181169, acc: 99.22%] [G loss: 3.800794]\n",
      "epoch:39 step:30943 [D loss: 0.289409, acc: 87.50%] [G loss: 4.662652]\n",
      "epoch:39 step:30944 [D loss: 0.099005, acc: 99.22%] [G loss: 8.868282]\n",
      "epoch:39 step:30945 [D loss: 0.317033, acc: 79.69%] [G loss: 5.320624]\n",
      "epoch:39 step:30946 [D loss: 0.392474, acc: 78.91%] [G loss: 6.819854]\n",
      "epoch:39 step:30947 [D loss: 0.114304, acc: 98.44%] [G loss: 7.647972]\n",
      "epoch:39 step:30948 [D loss: 0.460673, acc: 81.25%] [G loss: 6.290202]\n",
      "epoch:39 step:30949 [D loss: 0.007879, acc: 100.00%] [G loss: 6.771725]\n",
      "epoch:39 step:30950 [D loss: 1.050933, acc: 21.88%] [G loss: 5.353395]\n",
      "epoch:39 step:30951 [D loss: 0.234574, acc: 94.53%] [G loss: 6.669489]\n",
      "epoch:39 step:30952 [D loss: 0.074152, acc: 100.00%] [G loss: 4.668217]\n",
      "epoch:39 step:30953 [D loss: 0.470096, acc: 79.69%] [G loss: 4.195740]\n",
      "epoch:39 step:30954 [D loss: 0.406702, acc: 74.22%] [G loss: 5.369761]\n",
      "epoch:39 step:30955 [D loss: 0.466324, acc: 70.31%] [G loss: 6.599525]\n",
      "epoch:39 step:30956 [D loss: 0.962815, acc: 50.78%] [G loss: 5.377019]\n",
      "epoch:39 step:30957 [D loss: 0.219463, acc: 96.09%] [G loss: 7.528093]\n",
      "epoch:39 step:30958 [D loss: 0.141473, acc: 99.22%] [G loss: 9.445631]\n",
      "epoch:39 step:30959 [D loss: 0.915268, acc: 53.12%] [G loss: 5.964820]\n",
      "epoch:39 step:30960 [D loss: 0.214748, acc: 95.31%] [G loss: 4.864614]\n",
      "epoch:39 step:30961 [D loss: 0.188720, acc: 95.31%] [G loss: 4.875440]\n",
      "epoch:39 step:30962 [D loss: 0.112813, acc: 99.22%] [G loss: 5.917868]\n",
      "epoch:39 step:30963 [D loss: 0.236395, acc: 96.09%] [G loss: 5.467981]\n",
      "epoch:39 step:30964 [D loss: 0.927718, acc: 41.41%] [G loss: 6.463524]\n",
      "epoch:39 step:30965 [D loss: 0.460277, acc: 85.16%] [G loss: 3.391325]\n",
      "epoch:39 step:30966 [D loss: 0.078779, acc: 100.00%] [G loss: 4.438662]\n",
      "epoch:39 step:30967 [D loss: 0.204270, acc: 97.66%] [G loss: 4.440219]\n",
      "epoch:39 step:30968 [D loss: 0.408849, acc: 85.16%] [G loss: 5.291590]\n",
      "epoch:39 step:30969 [D loss: 0.353917, acc: 86.72%] [G loss: 5.814494]\n",
      "epoch:39 step:30970 [D loss: 0.077686, acc: 100.00%] [G loss: 8.249487]\n",
      "epoch:39 step:30971 [D loss: 0.270511, acc: 93.75%] [G loss: 7.060632]\n",
      "epoch:39 step:30972 [D loss: 0.166825, acc: 99.22%] [G loss: 4.739719]\n",
      "epoch:39 step:30973 [D loss: 0.585241, acc: 68.75%] [G loss: 5.370963]\n",
      "epoch:39 step:30974 [D loss: 0.167129, acc: 100.00%] [G loss: 5.694830]\n",
      "epoch:39 step:30975 [D loss: 0.683377, acc: 60.16%] [G loss: 5.929880]\n",
      "epoch:39 step:30976 [D loss: 0.383432, acc: 76.56%] [G loss: 8.564905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30977 [D loss: 0.767282, acc: 52.34%] [G loss: 9.815386]\n",
      "epoch:39 step:30978 [D loss: 0.226909, acc: 91.41%] [G loss: 6.272695]\n",
      "epoch:39 step:30979 [D loss: 0.864151, acc: 53.91%] [G loss: 6.090575]\n",
      "epoch:39 step:30980 [D loss: 0.272487, acc: 94.53%] [G loss: 3.225143]\n",
      "epoch:39 step:30981 [D loss: 0.488936, acc: 69.53%] [G loss: 5.678961]\n",
      "epoch:39 step:30982 [D loss: 0.334278, acc: 87.50%] [G loss: 4.710984]\n",
      "epoch:39 step:30983 [D loss: 0.866829, acc: 43.75%] [G loss: 4.610271]\n",
      "epoch:39 step:30984 [D loss: 0.386622, acc: 78.91%] [G loss: 3.905304]\n",
      "epoch:39 step:30985 [D loss: 0.346748, acc: 81.25%] [G loss: 6.076121]\n",
      "epoch:39 step:30986 [D loss: 0.298559, acc: 90.62%] [G loss: 2.932070]\n",
      "epoch:39 step:30987 [D loss: 0.346890, acc: 81.25%] [G loss: 5.394369]\n",
      "epoch:39 step:30988 [D loss: 0.747114, acc: 54.69%] [G loss: 5.209179]\n",
      "epoch:39 step:30989 [D loss: 0.288440, acc: 89.06%] [G loss: 3.748536]\n",
      "epoch:39 step:30990 [D loss: 0.861226, acc: 53.91%] [G loss: 7.428319]\n",
      "epoch:39 step:30991 [D loss: 0.325483, acc: 84.38%] [G loss: 7.946949]\n",
      "epoch:39 step:30992 [D loss: 1.984976, acc: 7.03%] [G loss: 7.504919]\n",
      "epoch:39 step:30993 [D loss: 0.149118, acc: 98.44%] [G loss: 7.415787]\n",
      "epoch:39 step:30994 [D loss: 0.579926, acc: 63.28%] [G loss: 7.547563]\n",
      "epoch:39 step:30995 [D loss: 0.359127, acc: 92.19%] [G loss: 7.792763]\n",
      "epoch:39 step:30996 [D loss: 0.025099, acc: 100.00%] [G loss: 6.363254]\n",
      "epoch:39 step:30997 [D loss: 0.605511, acc: 61.72%] [G loss: 7.028005]\n",
      "epoch:39 step:30998 [D loss: 0.665453, acc: 59.38%] [G loss: 5.740228]\n",
      "epoch:39 step:30999 [D loss: 0.224661, acc: 96.09%] [G loss: 4.907952]\n",
      "epoch:39 step:31000 [D loss: 0.023857, acc: 100.00%] [G loss: 6.702364]\n",
      "epoch:39 step:31001 [D loss: 0.086483, acc: 99.22%] [G loss: 6.127628]\n",
      "epoch:39 step:31002 [D loss: 0.158518, acc: 98.44%] [G loss: 4.804749]\n",
      "epoch:39 step:31003 [D loss: 0.145834, acc: 99.22%] [G loss: 3.269116]\n",
      "epoch:39 step:31004 [D loss: 0.215578, acc: 98.44%] [G loss: 4.652555]\n",
      "epoch:39 step:31005 [D loss: 0.176979, acc: 98.44%] [G loss: 6.174325]\n",
      "epoch:39 step:31006 [D loss: 0.199042, acc: 99.22%] [G loss: 6.184040]\n",
      "epoch:39 step:31007 [D loss: 0.074463, acc: 99.22%] [G loss: 3.286837]\n",
      "epoch:39 step:31008 [D loss: 0.210376, acc: 98.44%] [G loss: 3.562013]\n",
      "epoch:39 step:31009 [D loss: 0.046130, acc: 100.00%] [G loss: 5.084818]\n",
      "epoch:39 step:31010 [D loss: 0.129935, acc: 100.00%] [G loss: 6.401708]\n",
      "epoch:39 step:31011 [D loss: 0.818704, acc: 46.09%] [G loss: 5.740638]\n",
      "epoch:39 step:31012 [D loss: 0.438566, acc: 71.88%] [G loss: 4.058633]\n",
      "epoch:39 step:31013 [D loss: 0.325143, acc: 90.62%] [G loss: 5.509412]\n",
      "epoch:39 step:31014 [D loss: 0.060462, acc: 99.22%] [G loss: 5.086995]\n",
      "epoch:39 step:31015 [D loss: 0.198679, acc: 98.44%] [G loss: 4.901724]\n",
      "epoch:39 step:31016 [D loss: 0.326810, acc: 86.72%] [G loss: 7.591932]\n",
      "epoch:39 step:31017 [D loss: 0.682806, acc: 57.03%] [G loss: 6.503659]\n",
      "epoch:39 step:31018 [D loss: 0.079504, acc: 100.00%] [G loss: 8.736931]\n",
      "epoch:39 step:31019 [D loss: 0.413170, acc: 75.00%] [G loss: 10.316481]\n",
      "epoch:39 step:31020 [D loss: 1.195346, acc: 49.22%] [G loss: 6.670428]\n",
      "epoch:39 step:31021 [D loss: 0.322970, acc: 82.03%] [G loss: 8.045377]\n",
      "epoch:39 step:31022 [D loss: 1.196438, acc: 44.53%] [G loss: 7.090033]\n",
      "epoch:39 step:31023 [D loss: 0.897619, acc: 53.12%] [G loss: 6.022407]\n",
      "epoch:39 step:31024 [D loss: 0.027477, acc: 100.00%] [G loss: 5.095811]\n",
      "epoch:39 step:31025 [D loss: 0.159247, acc: 96.88%] [G loss: 8.519854]\n",
      "epoch:39 step:31026 [D loss: 0.172407, acc: 97.66%] [G loss: 5.715388]\n",
      "epoch:39 step:31027 [D loss: 0.182041, acc: 97.66%] [G loss: 5.029008]\n",
      "epoch:39 step:31028 [D loss: 0.109834, acc: 99.22%] [G loss: 3.507115]\n",
      "epoch:39 step:31029 [D loss: 0.206712, acc: 96.88%] [G loss: 6.945347]\n",
      "epoch:39 step:31030 [D loss: 0.142008, acc: 100.00%] [G loss: 2.644304]\n",
      "epoch:39 step:31031 [D loss: 0.029155, acc: 100.00%] [G loss: 7.836539]\n",
      "epoch:39 step:31032 [D loss: 0.439477, acc: 86.72%] [G loss: 3.687884]\n",
      "epoch:39 step:31033 [D loss: 0.322360, acc: 90.62%] [G loss: 6.469325]\n",
      "epoch:39 step:31034 [D loss: 0.227838, acc: 96.09%] [G loss: 6.631803]\n",
      "epoch:39 step:31035 [D loss: 0.887483, acc: 33.59%] [G loss: 5.075527]\n",
      "epoch:39 step:31036 [D loss: 0.116780, acc: 99.22%] [G loss: 4.240725]\n",
      "epoch:39 step:31037 [D loss: 0.032672, acc: 99.22%] [G loss: 7.801817]\n",
      "epoch:39 step:31038 [D loss: 0.304730, acc: 95.31%] [G loss: 6.330655]\n",
      "epoch:39 step:31039 [D loss: 0.213453, acc: 97.66%] [G loss: 3.369837]\n",
      "epoch:39 step:31040 [D loss: 0.211981, acc: 96.09%] [G loss: 10.115900]\n",
      "epoch:39 step:31041 [D loss: 0.671856, acc: 56.25%] [G loss: 5.764712]\n",
      "epoch:39 step:31042 [D loss: 0.656221, acc: 57.03%] [G loss: 6.090257]\n",
      "epoch:39 step:31043 [D loss: 0.243559, acc: 95.31%] [G loss: 4.236226]\n",
      "epoch:39 step:31044 [D loss: 0.199434, acc: 99.22%] [G loss: 5.705453]\n",
      "epoch:39 step:31045 [D loss: 0.363824, acc: 90.62%] [G loss: 4.934074]\n",
      "epoch:39 step:31046 [D loss: 0.186863, acc: 97.66%] [G loss: 5.966018]\n",
      "epoch:39 step:31047 [D loss: 0.257459, acc: 91.41%] [G loss: 5.734807]\n",
      "epoch:39 step:31048 [D loss: 1.307126, acc: 50.78%] [G loss: 5.364317]\n",
      "epoch:39 step:31049 [D loss: 0.222171, acc: 96.88%] [G loss: 7.902351]\n",
      "epoch:39 step:31050 [D loss: 0.184594, acc: 98.44%] [G loss: 3.196087]\n",
      "epoch:39 step:31051 [D loss: 0.233872, acc: 95.31%] [G loss: 6.401193]\n",
      "epoch:39 step:31052 [D loss: 0.069358, acc: 100.00%] [G loss: 4.367802]\n",
      "epoch:39 step:31053 [D loss: 0.138147, acc: 98.44%] [G loss: 5.224653]\n",
      "epoch:39 step:31054 [D loss: 0.186229, acc: 97.66%] [G loss: 4.266150]\n",
      "epoch:39 step:31055 [D loss: 0.078638, acc: 100.00%] [G loss: 5.509637]\n",
      "epoch:39 step:31056 [D loss: 0.112264, acc: 100.00%] [G loss: 2.160806]\n",
      "epoch:39 step:31057 [D loss: 0.100132, acc: 99.22%] [G loss: 8.758121]\n",
      "epoch:39 step:31058 [D loss: 0.539589, acc: 69.53%] [G loss: 3.936639]\n",
      "epoch:39 step:31059 [D loss: 0.574242, acc: 72.66%] [G loss: 3.973438]\n",
      "epoch:39 step:31060 [D loss: 0.314901, acc: 84.38%] [G loss: 7.293262]\n",
      "epoch:39 step:31061 [D loss: 0.825338, acc: 52.34%] [G loss: 4.511970]\n",
      "epoch:39 step:31062 [D loss: 0.117876, acc: 98.44%] [G loss: 4.358817]\n",
      "epoch:39 step:31063 [D loss: 0.191833, acc: 97.66%] [G loss: 1.963090]\n",
      "epoch:39 step:31064 [D loss: 0.134948, acc: 99.22%] [G loss: 4.730227]\n",
      "epoch:39 step:31065 [D loss: 0.355467, acc: 91.41%] [G loss: 6.408245]\n",
      "epoch:39 step:31066 [D loss: 0.979442, acc: 32.03%] [G loss: 5.557748]\n",
      "epoch:39 step:31067 [D loss: 2.213326, acc: 30.47%] [G loss: 5.709226]\n",
      "epoch:39 step:31068 [D loss: 0.228578, acc: 93.75%] [G loss: 3.881319]\n",
      "epoch:39 step:31069 [D loss: 0.131846, acc: 97.66%] [G loss: 4.752986]\n",
      "epoch:39 step:31070 [D loss: 1.196988, acc: 49.22%] [G loss: 5.525561]\n",
      "epoch:39 step:31071 [D loss: 0.350049, acc: 83.59%] [G loss: 2.862056]\n",
      "epoch:39 step:31072 [D loss: 0.562817, acc: 63.28%] [G loss: 6.708713]\n",
      "epoch:39 step:31073 [D loss: 0.147661, acc: 98.44%] [G loss: 3.764874]\n",
      "epoch:39 step:31074 [D loss: 0.607446, acc: 61.72%] [G loss: 5.941074]\n",
      "epoch:39 step:31075 [D loss: 0.542277, acc: 63.28%] [G loss: 2.757121]\n",
      "epoch:39 step:31076 [D loss: 1.225908, acc: 19.53%] [G loss: 6.187127]\n",
      "epoch:39 step:31077 [D loss: 0.491648, acc: 76.56%] [G loss: 3.927937]\n",
      "epoch:39 step:31078 [D loss: 0.150107, acc: 97.66%] [G loss: 6.994441]\n",
      "epoch:39 step:31079 [D loss: 0.403057, acc: 85.94%] [G loss: 6.334225]\n",
      "epoch:39 step:31080 [D loss: 0.191643, acc: 99.22%] [G loss: 4.848279]\n",
      "epoch:39 step:31081 [D loss: 1.004705, acc: 52.34%] [G loss: 4.939712]\n",
      "epoch:39 step:31082 [D loss: 0.810269, acc: 52.34%] [G loss: 5.516231]\n",
      "epoch:39 step:31083 [D loss: 0.178699, acc: 98.44%] [G loss: 5.164318]\n",
      "epoch:39 step:31084 [D loss: 0.085655, acc: 100.00%] [G loss: 3.758840]\n",
      "epoch:39 step:31085 [D loss: 0.541469, acc: 68.75%] [G loss: 6.376271]\n",
      "epoch:39 step:31086 [D loss: 0.224903, acc: 92.97%] [G loss: 3.815517]\n",
      "epoch:39 step:31087 [D loss: 0.304578, acc: 90.62%] [G loss: 5.713226]\n",
      "epoch:39 step:31088 [D loss: 0.043368, acc: 100.00%] [G loss: 6.699893]\n",
      "epoch:39 step:31089 [D loss: 0.175977, acc: 99.22%] [G loss: 7.324548]\n",
      "epoch:39 step:31090 [D loss: 1.317767, acc: 49.22%] [G loss: 4.076795]\n",
      "epoch:39 step:31091 [D loss: 0.267000, acc: 86.72%] [G loss: 7.292978]\n",
      "epoch:39 step:31092 [D loss: 1.354940, acc: 13.28%] [G loss: 5.265116]\n",
      "epoch:39 step:31093 [D loss: 0.152092, acc: 97.66%] [G loss: 7.934536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:31094 [D loss: 0.176504, acc: 98.44%] [G loss: 6.410490]\n",
      "epoch:39 step:31095 [D loss: 0.142284, acc: 99.22%] [G loss: 5.478708]\n",
      "epoch:39 step:31096 [D loss: 0.319685, acc: 85.94%] [G loss: 6.138051]\n",
      "epoch:39 step:31097 [D loss: 0.086883, acc: 99.22%] [G loss: 4.761594]\n",
      "epoch:39 step:31098 [D loss: 0.485514, acc: 75.00%] [G loss: 4.928958]\n",
      "epoch:39 step:31099 [D loss: 0.926286, acc: 50.78%] [G loss: 6.951075]\n",
      "epoch:39 step:31100 [D loss: 0.104388, acc: 99.22%] [G loss: 5.979712]\n",
      "epoch:39 step:31101 [D loss: 0.611642, acc: 61.72%] [G loss: 4.566425]\n",
      "epoch:39 step:31102 [D loss: 0.170262, acc: 99.22%] [G loss: 3.013662]\n",
      "epoch:39 step:31103 [D loss: 0.284808, acc: 87.50%] [G loss: 2.995849]\n",
      "epoch:39 step:31104 [D loss: 0.171672, acc: 100.00%] [G loss: 5.490758]\n",
      "epoch:39 step:31105 [D loss: 0.121255, acc: 100.00%] [G loss: 7.165091]\n",
      "epoch:39 step:31106 [D loss: 0.307587, acc: 85.16%] [G loss: 6.463847]\n",
      "epoch:39 step:31107 [D loss: 0.030283, acc: 100.00%] [G loss: 6.178843]\n",
      "epoch:39 step:31108 [D loss: 0.362651, acc: 85.16%] [G loss: 5.553180]\n",
      "epoch:39 step:31109 [D loss: 0.314907, acc: 85.16%] [G loss: 4.971609]\n",
      "epoch:39 step:31110 [D loss: 0.103055, acc: 98.44%] [G loss: 5.320484]\n",
      "epoch:39 step:31111 [D loss: 0.291849, acc: 92.97%] [G loss: 7.140388]\n",
      "epoch:39 step:31112 [D loss: 0.332762, acc: 82.81%] [G loss: 6.886423]\n",
      "epoch:39 step:31113 [D loss: 0.186853, acc: 96.88%] [G loss: 5.043935]\n",
      "epoch:39 step:31114 [D loss: 0.065673, acc: 100.00%] [G loss: 7.397438]\n",
      "epoch:39 step:31115 [D loss: 0.414244, acc: 82.81%] [G loss: 7.711058]\n",
      "epoch:39 step:31116 [D loss: 0.547181, acc: 75.78%] [G loss: 5.082901]\n",
      "epoch:39 step:31117 [D loss: 0.201262, acc: 98.44%] [G loss: 5.540814]\n",
      "epoch:39 step:31118 [D loss: 0.707872, acc: 58.59%] [G loss: 7.261399]\n",
      "epoch:39 step:31119 [D loss: 0.036100, acc: 100.00%] [G loss: 7.297905]\n",
      "epoch:39 step:31120 [D loss: 0.153961, acc: 99.22%] [G loss: 3.979631]\n",
      "epoch:39 step:31121 [D loss: 0.204220, acc: 96.88%] [G loss: 5.464595]\n",
      "epoch:39 step:31122 [D loss: 0.211783, acc: 97.66%] [G loss: 5.506358]\n",
      "epoch:39 step:31123 [D loss: 0.422266, acc: 86.72%] [G loss: 4.461911]\n",
      "epoch:39 step:31124 [D loss: 0.098428, acc: 100.00%] [G loss: 5.839699]\n",
      "epoch:39 step:31125 [D loss: 0.222569, acc: 96.88%] [G loss: 4.590042]\n",
      "epoch:39 step:31126 [D loss: 0.146340, acc: 99.22%] [G loss: 5.213932]\n",
      "epoch:39 step:31127 [D loss: 0.464671, acc: 82.03%] [G loss: 6.632181]\n",
      "epoch:39 step:31128 [D loss: 0.239485, acc: 92.97%] [G loss: 6.272067]\n",
      "epoch:39 step:31129 [D loss: 0.189684, acc: 96.88%] [G loss: 5.040723]\n",
      "epoch:39 step:31130 [D loss: 0.309296, acc: 88.28%] [G loss: 4.978118]\n",
      "epoch:39 step:31131 [D loss: 0.111279, acc: 100.00%] [G loss: 4.157979]\n",
      "epoch:39 step:31132 [D loss: 0.059487, acc: 100.00%] [G loss: 6.849683]\n",
      "epoch:39 step:31133 [D loss: 0.463017, acc: 67.97%] [G loss: 5.004862]\n",
      "epoch:39 step:31134 [D loss: 0.930385, acc: 32.03%] [G loss: 6.652071]\n",
      "epoch:39 step:31135 [D loss: 0.165352, acc: 96.88%] [G loss: 6.220790]\n",
      "epoch:39 step:31136 [D loss: 0.128381, acc: 100.00%] [G loss: 3.886816]\n",
      "epoch:39 step:31137 [D loss: 0.162065, acc: 96.09%] [G loss: 5.346479]\n",
      "epoch:39 step:31138 [D loss: 0.124339, acc: 99.22%] [G loss: 5.409239]\n",
      "epoch:39 step:31139 [D loss: 0.177706, acc: 96.09%] [G loss: 2.300584]\n",
      "epoch:39 step:31140 [D loss: 0.051515, acc: 100.00%] [G loss: 6.040635]\n",
      "epoch:39 step:31141 [D loss: 0.256113, acc: 93.75%] [G loss: 3.384170]\n",
      "epoch:39 step:31142 [D loss: 0.341653, acc: 90.62%] [G loss: 3.946572]\n",
      "epoch:39 step:31143 [D loss: 0.127445, acc: 99.22%] [G loss: 6.492305]\n",
      "epoch:39 step:31144 [D loss: 0.063889, acc: 100.00%] [G loss: 2.768166]\n",
      "epoch:39 step:31145 [D loss: 0.083811, acc: 99.22%] [G loss: 3.473931]\n",
      "epoch:39 step:31146 [D loss: 0.162591, acc: 97.66%] [G loss: 5.633840]\n",
      "epoch:39 step:31147 [D loss: 0.097763, acc: 100.00%] [G loss: 6.708654]\n",
      "epoch:39 step:31148 [D loss: 0.442042, acc: 64.84%] [G loss: 4.971561]\n",
      "epoch:39 step:31149 [D loss: 0.057164, acc: 100.00%] [G loss: 4.938096]\n",
      "epoch:39 step:31150 [D loss: 0.204174, acc: 98.44%] [G loss: 5.730687]\n",
      "epoch:39 step:31151 [D loss: 0.339405, acc: 87.50%] [G loss: 4.390766]\n",
      "epoch:39 step:31152 [D loss: 0.051551, acc: 100.00%] [G loss: 6.533923]\n",
      "epoch:39 step:31153 [D loss: 0.247898, acc: 90.62%] [G loss: 5.745127]\n",
      "epoch:39 step:31154 [D loss: 0.192385, acc: 99.22%] [G loss: 4.916616]\n",
      "epoch:39 step:31155 [D loss: 0.167281, acc: 99.22%] [G loss: 9.575689]\n",
      "epoch:39 step:31156 [D loss: 0.806035, acc: 53.91%] [G loss: 7.266638]\n",
      "epoch:39 step:31157 [D loss: 0.135896, acc: 100.00%] [G loss: 3.235557]\n",
      "epoch:39 step:31158 [D loss: 1.140019, acc: 50.78%] [G loss: 4.361222]\n",
      "epoch:39 step:31159 [D loss: 0.287894, acc: 95.31%] [G loss: 2.618449]\n",
      "epoch:39 step:31160 [D loss: 0.375409, acc: 92.19%] [G loss: 3.369050]\n",
      "epoch:39 step:31161 [D loss: 0.319688, acc: 93.75%] [G loss: 4.793803]\n",
      "epoch:39 step:31162 [D loss: 0.234351, acc: 93.75%] [G loss: 5.765891]\n",
      "epoch:39 step:31163 [D loss: 0.744631, acc: 60.16%] [G loss: 5.280427]\n",
      "epoch:39 step:31164 [D loss: 0.847944, acc: 42.19%] [G loss: 9.528193]\n",
      "epoch:39 step:31165 [D loss: 0.197474, acc: 99.22%] [G loss: 4.672762]\n",
      "epoch:39 step:31166 [D loss: 0.706185, acc: 53.91%] [G loss: 5.445651]\n",
      "epoch:39 step:31167 [D loss: 0.224329, acc: 92.97%] [G loss: 4.536842]\n",
      "epoch:39 step:31168 [D loss: 0.285391, acc: 88.28%] [G loss: 5.234224]\n",
      "epoch:39 step:31169 [D loss: 0.330038, acc: 93.75%] [G loss: 7.187407]\n",
      "epoch:39 step:31170 [D loss: 0.145326, acc: 98.44%] [G loss: 7.011524]\n",
      "epoch:39 step:31171 [D loss: 0.035843, acc: 100.00%] [G loss: 5.625627]\n",
      "epoch:39 step:31172 [D loss: 0.058930, acc: 100.00%] [G loss: 7.369118]\n",
      "epoch:39 step:31173 [D loss: 0.363135, acc: 86.72%] [G loss: 5.491714]\n",
      "epoch:39 step:31174 [D loss: 0.318054, acc: 93.75%] [G loss: 5.306090]\n",
      "epoch:39 step:31175 [D loss: 0.183486, acc: 98.44%] [G loss: 5.932067]\n",
      "epoch:39 step:31176 [D loss: 0.093629, acc: 100.00%] [G loss: 6.097892]\n",
      "epoch:39 step:31177 [D loss: 0.096286, acc: 100.00%] [G loss: 3.924147]\n",
      "epoch:39 step:31178 [D loss: 0.505390, acc: 72.66%] [G loss: 7.048428]\n",
      "epoch:39 step:31179 [D loss: 0.421370, acc: 86.72%] [G loss: 3.834156]\n",
      "epoch:39 step:31180 [D loss: 0.576320, acc: 66.41%] [G loss: 7.832170]\n",
      "epoch:39 step:31181 [D loss: 0.237550, acc: 92.97%] [G loss: 5.476517]\n",
      "epoch:39 step:31182 [D loss: 0.021287, acc: 100.00%] [G loss: 4.275722]\n",
      "epoch:39 step:31183 [D loss: 0.203317, acc: 97.66%] [G loss: 6.223600]\n",
      "epoch:39 step:31184 [D loss: 0.750611, acc: 46.09%] [G loss: 7.992433]\n",
      "epoch:39 step:31185 [D loss: 0.018706, acc: 100.00%] [G loss: 7.260742]\n",
      "epoch:39 step:31186 [D loss: 0.065246, acc: 100.00%] [G loss: 5.489077]\n",
      "epoch:39 step:31187 [D loss: 0.087598, acc: 100.00%] [G loss: 4.797688]\n",
      "epoch:39 step:31188 [D loss: 0.056116, acc: 100.00%] [G loss: 5.948641]\n",
      "epoch:39 step:31189 [D loss: 0.976820, acc: 49.22%] [G loss: 3.633247]\n",
      "epoch:39 step:31190 [D loss: 0.407946, acc: 84.38%] [G loss: 3.630021]\n",
      "epoch:39 step:31191 [D loss: 0.116329, acc: 99.22%] [G loss: 7.472576]\n",
      "epoch:39 step:31192 [D loss: 0.642906, acc: 60.16%] [G loss: 6.676487]\n",
      "epoch:39 step:31193 [D loss: 0.271500, acc: 90.62%] [G loss: 3.614671]\n",
      "epoch:39 step:31194 [D loss: 0.955291, acc: 53.12%] [G loss: 4.745155]\n",
      "epoch:39 step:31195 [D loss: 0.678209, acc: 64.06%] [G loss: 4.891186]\n",
      "epoch:39 step:31196 [D loss: 0.276868, acc: 87.50%] [G loss: 5.669203]\n",
      "epoch:39 step:31197 [D loss: 0.587811, acc: 64.06%] [G loss: 7.259770]\n",
      "epoch:39 step:31198 [D loss: 1.895132, acc: 5.47%] [G loss: 4.447664]\n",
      "epoch:39 step:31199 [D loss: 0.280759, acc: 85.16%] [G loss: 4.703387]\n",
      "epoch:39 step:31200 [D loss: 0.046612, acc: 100.00%] [G loss: 6.369931]\n",
      "epoch:39 step:31201 [D loss: 0.957417, acc: 41.41%] [G loss: 7.190895]\n",
      "epoch:39 step:31202 [D loss: 0.204634, acc: 99.22%] [G loss: 3.638489]\n",
      "epoch:39 step:31203 [D loss: 0.335333, acc: 85.16%] [G loss: 6.945011]\n",
      "epoch:39 step:31204 [D loss: 0.207997, acc: 96.09%] [G loss: 5.830585]\n",
      "epoch:39 step:31205 [D loss: 0.347911, acc: 91.41%] [G loss: 5.443455]\n",
      "epoch:39 step:31206 [D loss: 0.099929, acc: 100.00%] [G loss: 5.618275]\n",
      "epoch:39 step:31207 [D loss: 0.493026, acc: 78.91%] [G loss: 6.381829]\n",
      "epoch:39 step:31208 [D loss: 0.048093, acc: 100.00%] [G loss: 6.887147]\n",
      "epoch:39 step:31209 [D loss: 0.029946, acc: 100.00%] [G loss: 10.003391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:31210 [D loss: 0.143951, acc: 98.44%] [G loss: 3.987711]\n",
      "epoch:39 step:31211 [D loss: 0.146249, acc: 97.66%] [G loss: 4.989756]\n",
      "epoch:39 step:31212 [D loss: 0.508282, acc: 70.31%] [G loss: 5.619161]\n",
      "epoch:39 step:31213 [D loss: 0.197847, acc: 96.09%] [G loss: 4.598279]\n",
      "epoch:39 step:31214 [D loss: 0.897082, acc: 46.88%] [G loss: 6.238473]\n",
      "epoch:39 step:31215 [D loss: 0.167662, acc: 99.22%] [G loss: 3.475764]\n",
      "epoch:39 step:31216 [D loss: 0.568676, acc: 64.06%] [G loss: 4.977476]\n",
      "epoch:39 step:31217 [D loss: 0.201305, acc: 96.88%] [G loss: 5.852257]\n",
      "epoch:39 step:31218 [D loss: 0.607102, acc: 56.25%] [G loss: 8.388706]\n",
      "epoch:39 step:31219 [D loss: 0.219298, acc: 89.06%] [G loss: 5.956189]\n",
      "epoch:39 step:31220 [D loss: 0.126584, acc: 98.44%] [G loss: 5.048159]\n",
      "epoch:39 step:31221 [D loss: 0.278956, acc: 93.75%] [G loss: 6.934376]\n",
      "epoch:39 step:31222 [D loss: 0.206939, acc: 95.31%] [G loss: 5.039580]\n",
      "epoch:39 step:31223 [D loss: 0.240075, acc: 92.19%] [G loss: 5.201370]\n",
      "epoch:39 step:31224 [D loss: 0.521711, acc: 76.56%] [G loss: 6.646305]\n",
      "epoch:39 step:31225 [D loss: 0.239302, acc: 94.53%] [G loss: 5.419937]\n",
      "epoch:39 step:31226 [D loss: 0.050794, acc: 100.00%] [G loss: 4.244943]\n",
      "epoch:39 step:31227 [D loss: 0.044264, acc: 100.00%] [G loss: 5.725898]\n",
      "epoch:39 step:31228 [D loss: 0.381434, acc: 78.12%] [G loss: 4.336502]\n",
      "epoch:39 step:31229 [D loss: 0.448474, acc: 74.22%] [G loss: 3.782919]\n",
      "epoch:39 step:31230 [D loss: 0.863694, acc: 44.53%] [G loss: 5.567031]\n",
      "epoch:39 step:31231 [D loss: 0.658861, acc: 59.38%] [G loss: 5.898302]\n",
      "epoch:39 step:31232 [D loss: 0.032485, acc: 100.00%] [G loss: 3.229048]\n",
      "epoch:39 step:31233 [D loss: 0.068506, acc: 100.00%] [G loss: 5.374148]\n",
      "epoch:39 step:31234 [D loss: 0.765639, acc: 50.78%] [G loss: 4.733884]\n",
      "epoch:39 step:31235 [D loss: 0.057475, acc: 100.00%] [G loss: 6.923515]\n",
      "epoch:39 step:31236 [D loss: 1.106192, acc: 31.25%] [G loss: 5.909676]\n",
      "epoch:39 step:31237 [D loss: 0.117875, acc: 100.00%] [G loss: 7.039730]\n",
      "epoch:39 step:31238 [D loss: 0.373925, acc: 87.50%] [G loss: 5.721812]\n",
      "epoch:39 step:31239 [D loss: 0.288585, acc: 93.75%] [G loss: 5.137309]\n",
      "epoch:39 step:31240 [D loss: 0.739729, acc: 55.47%] [G loss: 3.762326]\n",
      "epoch:40 step:31241 [D loss: 0.454843, acc: 75.00%] [G loss: 5.224430]\n",
      "epoch:40 step:31242 [D loss: 0.306668, acc: 93.75%] [G loss: 7.574481]\n",
      "epoch:40 step:31243 [D loss: 1.019103, acc: 29.69%] [G loss: 8.072857]\n",
      "epoch:40 step:31244 [D loss: 0.290084, acc: 96.09%] [G loss: 3.985106]\n",
      "epoch:40 step:31245 [D loss: 0.364077, acc: 82.03%] [G loss: 4.905435]\n",
      "epoch:40 step:31246 [D loss: 0.042088, acc: 100.00%] [G loss: 4.824795]\n",
      "epoch:40 step:31247 [D loss: 0.260714, acc: 95.31%] [G loss: 6.000315]\n",
      "epoch:40 step:31248 [D loss: 0.329121, acc: 90.62%] [G loss: 5.406385]\n",
      "epoch:40 step:31249 [D loss: 0.330259, acc: 81.25%] [G loss: 9.617178]\n",
      "epoch:40 step:31250 [D loss: 0.176430, acc: 98.44%] [G loss: 5.057937]\n",
      "epoch:40 step:31251 [D loss: 0.268155, acc: 95.31%] [G loss: 3.723689]\n",
      "epoch:40 step:31252 [D loss: 0.183610, acc: 98.44%] [G loss: 4.436009]\n",
      "epoch:40 step:31253 [D loss: 0.580744, acc: 72.66%] [G loss: 6.210583]\n",
      "epoch:40 step:31254 [D loss: 0.182660, acc: 100.00%] [G loss: 7.560502]\n",
      "epoch:40 step:31255 [D loss: 0.089423, acc: 99.22%] [G loss: 3.639601]\n",
      "epoch:40 step:31256 [D loss: 0.225258, acc: 96.88%] [G loss: 6.639136]\n",
      "epoch:40 step:31257 [D loss: 0.424909, acc: 85.94%] [G loss: 4.422008]\n",
      "epoch:40 step:31258 [D loss: 0.081405, acc: 100.00%] [G loss: 5.584725]\n",
      "epoch:40 step:31259 [D loss: 0.210569, acc: 96.09%] [G loss: 6.664575]\n",
      "epoch:40 step:31260 [D loss: 0.447029, acc: 71.09%] [G loss: 7.288248]\n",
      "epoch:40 step:31261 [D loss: 0.919403, acc: 37.50%] [G loss: 6.438640]\n",
      "epoch:40 step:31262 [D loss: 0.110223, acc: 100.00%] [G loss: 2.957861]\n",
      "epoch:40 step:31263 [D loss: 0.301966, acc: 88.28%] [G loss: 5.195558]\n",
      "epoch:40 step:31264 [D loss: 0.244222, acc: 88.28%] [G loss: 8.080327]\n",
      "epoch:40 step:31265 [D loss: 0.611560, acc: 64.84%] [G loss: 8.865192]\n",
      "epoch:40 step:31266 [D loss: 0.254581, acc: 92.19%] [G loss: 4.407499]\n",
      "epoch:40 step:31267 [D loss: 0.256480, acc: 92.97%] [G loss: 7.211685]\n",
      "epoch:40 step:31268 [D loss: 0.447929, acc: 82.81%] [G loss: 5.143610]\n",
      "epoch:40 step:31269 [D loss: 0.200745, acc: 96.09%] [G loss: 5.733622]\n",
      "epoch:40 step:31270 [D loss: 0.337937, acc: 80.47%] [G loss: 4.924985]\n",
      "epoch:40 step:31271 [D loss: 0.218449, acc: 99.22%] [G loss: 3.110308]\n",
      "epoch:40 step:31272 [D loss: 0.400143, acc: 75.00%] [G loss: 6.292037]\n",
      "epoch:40 step:31273 [D loss: 0.190691, acc: 95.31%] [G loss: 3.473692]\n",
      "epoch:40 step:31274 [D loss: 0.460245, acc: 82.03%] [G loss: 5.555447]\n",
      "epoch:40 step:31275 [D loss: 0.239175, acc: 95.31%] [G loss: 5.646076]\n",
      "epoch:40 step:31276 [D loss: 0.224482, acc: 95.31%] [G loss: 4.610114]\n",
      "epoch:40 step:31277 [D loss: 0.155145, acc: 99.22%] [G loss: 5.033221]\n",
      "epoch:40 step:31278 [D loss: 0.172419, acc: 100.00%] [G loss: 3.143925]\n",
      "epoch:40 step:31279 [D loss: 0.352859, acc: 92.97%] [G loss: 4.835344]\n",
      "epoch:40 step:31280 [D loss: 0.409238, acc: 80.47%] [G loss: 4.572599]\n",
      "epoch:40 step:31281 [D loss: 0.384227, acc: 77.34%] [G loss: 4.087136]\n",
      "epoch:40 step:31282 [D loss: 0.321972, acc: 93.75%] [G loss: 6.961430]\n",
      "epoch:40 step:31283 [D loss: 1.605760, acc: 17.19%] [G loss: 6.686477]\n",
      "epoch:40 step:31284 [D loss: 0.107098, acc: 99.22%] [G loss: 6.327080]\n",
      "epoch:40 step:31285 [D loss: 0.187679, acc: 98.44%] [G loss: 5.318946]\n",
      "epoch:40 step:31286 [D loss: 0.044086, acc: 100.00%] [G loss: 5.684580]\n",
      "epoch:40 step:31287 [D loss: 0.584663, acc: 67.19%] [G loss: 4.344467]\n",
      "epoch:40 step:31288 [D loss: 0.197937, acc: 96.88%] [G loss: 5.581843]\n",
      "epoch:40 step:31289 [D loss: 0.140906, acc: 98.44%] [G loss: 7.323806]\n",
      "epoch:40 step:31290 [D loss: 0.283607, acc: 95.31%] [G loss: 5.642807]\n",
      "epoch:40 step:31291 [D loss: 0.041293, acc: 100.00%] [G loss: 7.164397]\n",
      "epoch:40 step:31292 [D loss: 0.120778, acc: 99.22%] [G loss: 6.866265]\n",
      "epoch:40 step:31293 [D loss: 0.532123, acc: 62.50%] [G loss: 1.697507]\n",
      "epoch:40 step:31294 [D loss: 0.223500, acc: 96.09%] [G loss: 4.695338]\n",
      "epoch:40 step:31295 [D loss: 1.181266, acc: 50.00%] [G loss: 9.008129]\n",
      "epoch:40 step:31296 [D loss: 0.220455, acc: 97.66%] [G loss: 2.475470]\n",
      "epoch:40 step:31297 [D loss: 0.367745, acc: 77.34%] [G loss: 5.326362]\n",
      "epoch:40 step:31298 [D loss: 0.113418, acc: 100.00%] [G loss: 3.554143]\n",
      "epoch:40 step:31299 [D loss: 1.164592, acc: 47.66%] [G loss: 7.261992]\n",
      "epoch:40 step:31300 [D loss: 0.320327, acc: 83.59%] [G loss: 4.301831]\n",
      "epoch:40 step:31301 [D loss: 0.202971, acc: 96.88%] [G loss: 5.311310]\n",
      "epoch:40 step:31302 [D loss: 0.561595, acc: 71.09%] [G loss: 7.127445]\n",
      "epoch:40 step:31303 [D loss: 0.198640, acc: 94.53%] [G loss: 6.768386]\n",
      "epoch:40 step:31304 [D loss: 0.425479, acc: 71.09%] [G loss: 7.908720]\n",
      "epoch:40 step:31305 [D loss: 0.317583, acc: 92.19%] [G loss: 5.739530]\n",
      "epoch:40 step:31306 [D loss: 0.053173, acc: 100.00%] [G loss: 3.992182]\n",
      "epoch:40 step:31307 [D loss: 0.404357, acc: 88.28%] [G loss: 4.625544]\n",
      "epoch:40 step:31308 [D loss: 0.421044, acc: 81.25%] [G loss: 4.718066]\n",
      "epoch:40 step:31309 [D loss: 0.120510, acc: 99.22%] [G loss: 1.938513]\n",
      "epoch:40 step:31310 [D loss: 0.039857, acc: 100.00%] [G loss: 4.240393]\n",
      "epoch:40 step:31311 [D loss: 0.549617, acc: 64.84%] [G loss: 3.610777]\n",
      "epoch:40 step:31312 [D loss: 0.888360, acc: 50.00%] [G loss: 6.969585]\n",
      "epoch:40 step:31313 [D loss: 0.111919, acc: 98.44%] [G loss: 6.821446]\n",
      "epoch:40 step:31314 [D loss: 0.098707, acc: 99.22%] [G loss: 4.386429]\n",
      "epoch:40 step:31315 [D loss: 0.417727, acc: 73.44%] [G loss: 4.875296]\n",
      "epoch:40 step:31316 [D loss: 0.049224, acc: 100.00%] [G loss: 4.251448]\n",
      "epoch:40 step:31317 [D loss: 0.433103, acc: 75.78%] [G loss: 6.930191]\n",
      "epoch:40 step:31318 [D loss: 0.690501, acc: 57.81%] [G loss: 8.619972]\n",
      "epoch:40 step:31319 [D loss: 0.196528, acc: 94.53%] [G loss: 6.707471]\n",
      "epoch:40 step:31320 [D loss: 0.374283, acc: 90.62%] [G loss: 7.287057]\n",
      "epoch:40 step:31321 [D loss: 0.293703, acc: 92.19%] [G loss: 7.003666]\n",
      "epoch:40 step:31322 [D loss: 0.189198, acc: 99.22%] [G loss: 5.514993]\n",
      "epoch:40 step:31323 [D loss: 0.155419, acc: 98.44%] [G loss: 2.723284]\n",
      "epoch:40 step:31324 [D loss: 0.188715, acc: 96.88%] [G loss: 4.426312]\n",
      "epoch:40 step:31325 [D loss: 0.666968, acc: 60.16%] [G loss: 4.621126]\n",
      "epoch:40 step:31326 [D loss: 0.190386, acc: 96.88%] [G loss: 3.359713]\n",
      "epoch:40 step:31327 [D loss: 1.060526, acc: 28.91%] [G loss: 7.538645]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31328 [D loss: 0.147684, acc: 99.22%] [G loss: 7.037484]\n",
      "epoch:40 step:31329 [D loss: 0.109268, acc: 98.44%] [G loss: 5.515311]\n",
      "epoch:40 step:31330 [D loss: 0.890799, acc: 42.19%] [G loss: 8.077541]\n",
      "epoch:40 step:31331 [D loss: 0.274302, acc: 86.72%] [G loss: 4.692071]\n",
      "epoch:40 step:31332 [D loss: 0.231619, acc: 91.41%] [G loss: 4.252468]\n",
      "epoch:40 step:31333 [D loss: 0.394752, acc: 86.72%] [G loss: 4.375355]\n",
      "epoch:40 step:31334 [D loss: 0.147707, acc: 99.22%] [G loss: 4.414951]\n",
      "epoch:40 step:31335 [D loss: 0.025854, acc: 100.00%] [G loss: 5.422188]\n",
      "epoch:40 step:31336 [D loss: 0.170112, acc: 96.88%] [G loss: 7.973927]\n",
      "epoch:40 step:31337 [D loss: 0.069175, acc: 99.22%] [G loss: 3.017466]\n",
      "epoch:40 step:31338 [D loss: 0.104153, acc: 100.00%] [G loss: 7.438470]\n",
      "epoch:40 step:31339 [D loss: 2.397485, acc: 50.00%] [G loss: 4.777523]\n",
      "epoch:40 step:31340 [D loss: 0.636093, acc: 61.72%] [G loss: 6.871186]\n",
      "epoch:40 step:31341 [D loss: 0.260507, acc: 89.84%] [G loss: 4.421251]\n",
      "epoch:40 step:31342 [D loss: 1.501223, acc: 39.06%] [G loss: 3.889632]\n",
      "epoch:40 step:31343 [D loss: 0.226214, acc: 92.97%] [G loss: 6.807919]\n",
      "epoch:40 step:31344 [D loss: 0.314184, acc: 86.72%] [G loss: 3.623257]\n",
      "epoch:40 step:31345 [D loss: 0.120830, acc: 98.44%] [G loss: 4.918545]\n",
      "epoch:40 step:31346 [D loss: 0.227679, acc: 94.53%] [G loss: 5.678461]\n",
      "epoch:40 step:31347 [D loss: 0.154269, acc: 98.44%] [G loss: 2.927112]\n",
      "epoch:40 step:31348 [D loss: 0.071232, acc: 100.00%] [G loss: 5.593281]\n",
      "epoch:40 step:31349 [D loss: 0.172959, acc: 99.22%] [G loss: 3.404575]\n",
      "epoch:40 step:31350 [D loss: 0.337659, acc: 85.16%] [G loss: 8.855490]\n",
      "epoch:40 step:31351 [D loss: 0.237451, acc: 95.31%] [G loss: 6.002932]\n",
      "epoch:40 step:31352 [D loss: 0.238456, acc: 93.75%] [G loss: 7.208597]\n",
      "epoch:40 step:31353 [D loss: 0.342745, acc: 89.06%] [G loss: 5.555826]\n",
      "epoch:40 step:31354 [D loss: 0.017777, acc: 100.00%] [G loss: 3.908961]\n",
      "epoch:40 step:31355 [D loss: 0.457214, acc: 83.59%] [G loss: 4.795659]\n",
      "epoch:40 step:31356 [D loss: 0.156116, acc: 100.00%] [G loss: 6.490209]\n",
      "epoch:40 step:31357 [D loss: 0.239330, acc: 96.88%] [G loss: 3.481465]\n",
      "epoch:40 step:31358 [D loss: 0.106778, acc: 100.00%] [G loss: 6.948774]\n",
      "epoch:40 step:31359 [D loss: 0.035090, acc: 100.00%] [G loss: 5.766252]\n",
      "epoch:40 step:31360 [D loss: 0.418605, acc: 85.94%] [G loss: 6.322435]\n",
      "epoch:40 step:31361 [D loss: 0.309484, acc: 91.41%] [G loss: 7.008327]\n",
      "epoch:40 step:31362 [D loss: 0.066633, acc: 100.00%] [G loss: 4.219563]\n",
      "epoch:40 step:31363 [D loss: 0.084179, acc: 98.44%] [G loss: 7.024795]\n",
      "epoch:40 step:31364 [D loss: 0.471467, acc: 80.47%] [G loss: 6.722414]\n",
      "epoch:40 step:31365 [D loss: 0.452189, acc: 69.53%] [G loss: 2.302748]\n",
      "epoch:40 step:31366 [D loss: 0.295076, acc: 91.41%] [G loss: 5.455910]\n",
      "epoch:40 step:31367 [D loss: 0.317253, acc: 82.81%] [G loss: 8.196558]\n",
      "epoch:40 step:31368 [D loss: 0.542915, acc: 65.62%] [G loss: 6.896826]\n",
      "epoch:40 step:31369 [D loss: 1.048251, acc: 50.78%] [G loss: 6.643102]\n",
      "epoch:40 step:31370 [D loss: 0.195323, acc: 97.66%] [G loss: 7.784936]\n",
      "epoch:40 step:31371 [D loss: 0.653474, acc: 64.06%] [G loss: 6.922007]\n",
      "epoch:40 step:31372 [D loss: 0.139199, acc: 98.44%] [G loss: 3.625453]\n",
      "epoch:40 step:31373 [D loss: 0.169265, acc: 97.66%] [G loss: 5.386015]\n",
      "epoch:40 step:31374 [D loss: 0.111514, acc: 99.22%] [G loss: 5.823424]\n",
      "epoch:40 step:31375 [D loss: 0.333404, acc: 96.09%] [G loss: 3.327501]\n",
      "epoch:40 step:31376 [D loss: 0.381030, acc: 75.78%] [G loss: 4.526543]\n",
      "epoch:40 step:31377 [D loss: 0.891293, acc: 46.88%] [G loss: 7.148822]\n",
      "epoch:40 step:31378 [D loss: 0.873877, acc: 53.12%] [G loss: 8.516094]\n",
      "epoch:40 step:31379 [D loss: 0.724051, acc: 55.47%] [G loss: 8.968762]\n",
      "epoch:40 step:31380 [D loss: 0.448665, acc: 74.22%] [G loss: 3.388063]\n",
      "epoch:40 step:31381 [D loss: 1.688679, acc: 50.00%] [G loss: 3.680445]\n",
      "epoch:40 step:31382 [D loss: 0.802865, acc: 49.22%] [G loss: 4.839607]\n",
      "epoch:40 step:31383 [D loss: 0.776391, acc: 53.12%] [G loss: 6.974531]\n",
      "epoch:40 step:31384 [D loss: 0.504745, acc: 77.34%] [G loss: 6.758845]\n",
      "epoch:40 step:31385 [D loss: 0.039764, acc: 100.00%] [G loss: 5.864142]\n",
      "epoch:40 step:31386 [D loss: 0.455071, acc: 84.38%] [G loss: 10.181637]\n",
      "epoch:40 step:31387 [D loss: 0.233435, acc: 98.44%] [G loss: 5.484149]\n",
      "epoch:40 step:31388 [D loss: 0.143972, acc: 100.00%] [G loss: 7.756845]\n",
      "epoch:40 step:31389 [D loss: 0.254851, acc: 97.66%] [G loss: 4.509632]\n",
      "epoch:40 step:31390 [D loss: 0.643215, acc: 56.25%] [G loss: 7.253876]\n",
      "epoch:40 step:31391 [D loss: 0.121662, acc: 99.22%] [G loss: 6.133182]\n",
      "epoch:40 step:31392 [D loss: 0.114586, acc: 99.22%] [G loss: 6.147966]\n",
      "epoch:40 step:31393 [D loss: 0.481969, acc: 75.78%] [G loss: 6.158803]\n",
      "epoch:40 step:31394 [D loss: 0.161244, acc: 97.66%] [G loss: 3.574990]\n",
      "epoch:40 step:31395 [D loss: 0.192161, acc: 98.44%] [G loss: 6.754893]\n",
      "epoch:40 step:31396 [D loss: 1.760974, acc: 23.44%] [G loss: 6.825119]\n",
      "epoch:40 step:31397 [D loss: 0.679103, acc: 57.03%] [G loss: 6.188717]\n",
      "epoch:40 step:31398 [D loss: 0.125278, acc: 100.00%] [G loss: 2.782908]\n",
      "epoch:40 step:31399 [D loss: 0.184222, acc: 96.88%] [G loss: 7.648470]\n",
      "epoch:40 step:31400 [D loss: 0.307632, acc: 96.09%] [G loss: 7.770375]\n",
      "epoch:40 step:31401 [D loss: 0.058309, acc: 100.00%] [G loss: 6.041242]\n",
      "epoch:40 step:31402 [D loss: 1.217959, acc: 18.75%] [G loss: 5.461745]\n",
      "epoch:40 step:31403 [D loss: 0.332868, acc: 91.41%] [G loss: 6.176641]\n",
      "epoch:40 step:31404 [D loss: 0.240448, acc: 96.88%] [G loss: 5.354049]\n",
      "epoch:40 step:31405 [D loss: 0.080203, acc: 100.00%] [G loss: 4.078182]\n",
      "epoch:40 step:31406 [D loss: 0.411132, acc: 77.34%] [G loss: 3.890974]\n",
      "epoch:40 step:31407 [D loss: 0.066371, acc: 100.00%] [G loss: 6.659703]\n",
      "epoch:40 step:31408 [D loss: 0.146324, acc: 99.22%] [G loss: 4.901718]\n",
      "epoch:40 step:31409 [D loss: 1.008847, acc: 31.25%] [G loss: 7.407470]\n",
      "epoch:40 step:31410 [D loss: 0.208981, acc: 98.44%] [G loss: 6.062912]\n",
      "epoch:40 step:31411 [D loss: 1.049193, acc: 49.22%] [G loss: 5.315092]\n",
      "epoch:40 step:31412 [D loss: 0.112999, acc: 100.00%] [G loss: 5.898475]\n",
      "epoch:40 step:31413 [D loss: 0.552225, acc: 73.44%] [G loss: 3.168549]\n",
      "epoch:40 step:31414 [D loss: 0.509567, acc: 62.50%] [G loss: 5.628309]\n",
      "epoch:40 step:31415 [D loss: 0.165556, acc: 96.88%] [G loss: 8.555237]\n",
      "epoch:40 step:31416 [D loss: 0.904428, acc: 51.56%] [G loss: 8.472786]\n",
      "epoch:40 step:31417 [D loss: 1.366056, acc: 50.00%] [G loss: 6.315775]\n",
      "epoch:40 step:31418 [D loss: 0.121794, acc: 99.22%] [G loss: 5.945477]\n",
      "epoch:40 step:31419 [D loss: 0.195679, acc: 96.88%] [G loss: 6.735872]\n",
      "epoch:40 step:31420 [D loss: 0.381298, acc: 87.50%] [G loss: 5.981557]\n",
      "epoch:40 step:31421 [D loss: 0.531991, acc: 67.19%] [G loss: 6.471238]\n",
      "epoch:40 step:31422 [D loss: 0.394743, acc: 77.34%] [G loss: 4.733886]\n",
      "epoch:40 step:31423 [D loss: 0.325465, acc: 82.81%] [G loss: 6.041834]\n",
      "epoch:40 step:31424 [D loss: 0.734945, acc: 53.12%] [G loss: 7.647857]\n",
      "epoch:40 step:31425 [D loss: 0.073789, acc: 100.00%] [G loss: 4.715760]\n",
      "epoch:40 step:31426 [D loss: 0.254820, acc: 92.19%] [G loss: 7.921363]\n",
      "epoch:40 step:31427 [D loss: 0.360518, acc: 79.69%] [G loss: 6.383451]\n",
      "epoch:40 step:31428 [D loss: 0.381813, acc: 77.34%] [G loss: 5.859706]\n",
      "epoch:40 step:31429 [D loss: 0.017074, acc: 100.00%] [G loss: 7.904978]\n",
      "epoch:40 step:31430 [D loss: 0.248820, acc: 97.66%] [G loss: 2.665675]\n",
      "epoch:40 step:31431 [D loss: 0.329364, acc: 92.97%] [G loss: 3.394768]\n",
      "epoch:40 step:31432 [D loss: 0.179436, acc: 100.00%] [G loss: 5.634171]\n",
      "epoch:40 step:31433 [D loss: 1.243832, acc: 29.69%] [G loss: 7.981048]\n",
      "epoch:40 step:31434 [D loss: 0.052339, acc: 100.00%] [G loss: 4.391033]\n",
      "epoch:40 step:31435 [D loss: 0.357146, acc: 92.19%] [G loss: 4.323171]\n",
      "epoch:40 step:31436 [D loss: 0.012986, acc: 100.00%] [G loss: 6.404227]\n",
      "epoch:40 step:31437 [D loss: 0.879948, acc: 40.62%] [G loss: 5.928249]\n",
      "epoch:40 step:31438 [D loss: 0.131890, acc: 98.44%] [G loss: 2.951665]\n",
      "epoch:40 step:31439 [D loss: 0.652892, acc: 55.47%] [G loss: 7.930282]\n",
      "epoch:40 step:31440 [D loss: 0.183766, acc: 97.66%] [G loss: 5.763889]\n",
      "epoch:40 step:31441 [D loss: 0.153575, acc: 98.44%] [G loss: 5.139471]\n",
      "epoch:40 step:31442 [D loss: 1.101802, acc: 49.22%] [G loss: 2.523025]\n",
      "epoch:40 step:31443 [D loss: 0.367039, acc: 80.47%] [G loss: 5.467807]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31444 [D loss: 0.076507, acc: 100.00%] [G loss: 2.527974]\n",
      "epoch:40 step:31445 [D loss: 0.341761, acc: 90.62%] [G loss: 6.258522]\n",
      "epoch:40 step:31446 [D loss: 1.440622, acc: 50.00%] [G loss: 4.584438]\n",
      "epoch:40 step:31447 [D loss: 0.595415, acc: 68.75%] [G loss: 3.951662]\n",
      "epoch:40 step:31448 [D loss: 1.266955, acc: 50.78%] [G loss: 9.864031]\n",
      "epoch:40 step:31449 [D loss: 0.787435, acc: 53.12%] [G loss: 5.369290]\n",
      "epoch:40 step:31450 [D loss: 0.228878, acc: 94.53%] [G loss: 7.734479]\n",
      "epoch:40 step:31451 [D loss: 0.274858, acc: 87.50%] [G loss: 6.404742]\n",
      "epoch:40 step:31452 [D loss: 0.290882, acc: 85.16%] [G loss: 8.447655]\n",
      "epoch:40 step:31453 [D loss: 0.153230, acc: 98.44%] [G loss: 3.918491]\n",
      "epoch:40 step:31454 [D loss: 0.331018, acc: 80.47%] [G loss: 8.224718]\n",
      "epoch:40 step:31455 [D loss: 0.219100, acc: 96.09%] [G loss: 4.266628]\n",
      "epoch:40 step:31456 [D loss: 0.338256, acc: 87.50%] [G loss: 5.235920]\n",
      "epoch:40 step:31457 [D loss: 0.096130, acc: 100.00%] [G loss: 4.520570]\n",
      "epoch:40 step:31458 [D loss: 0.173372, acc: 97.66%] [G loss: 9.582092]\n",
      "epoch:40 step:31459 [D loss: 1.127021, acc: 50.78%] [G loss: 6.776643]\n",
      "epoch:40 step:31460 [D loss: 0.192798, acc: 92.97%] [G loss: 4.415193]\n",
      "epoch:40 step:31461 [D loss: 0.070662, acc: 99.22%] [G loss: 4.169351]\n",
      "epoch:40 step:31462 [D loss: 0.223580, acc: 90.62%] [G loss: 5.666866]\n",
      "epoch:40 step:31463 [D loss: 0.367038, acc: 88.28%] [G loss: 7.395951]\n",
      "epoch:40 step:31464 [D loss: 0.375665, acc: 88.28%] [G loss: 5.168183]\n",
      "epoch:40 step:31465 [D loss: 0.221274, acc: 94.53%] [G loss: 9.253850]\n",
      "epoch:40 step:31466 [D loss: 0.251327, acc: 96.09%] [G loss: 6.391500]\n",
      "epoch:40 step:31467 [D loss: 0.205008, acc: 98.44%] [G loss: 7.960830]\n",
      "epoch:40 step:31468 [D loss: 0.245582, acc: 96.88%] [G loss: 5.804832]\n",
      "epoch:40 step:31469 [D loss: 0.122477, acc: 98.44%] [G loss: 6.768198]\n",
      "epoch:40 step:31470 [D loss: 0.595579, acc: 57.03%] [G loss: 6.231121]\n",
      "epoch:40 step:31471 [D loss: 0.419818, acc: 83.59%] [G loss: 6.669928]\n",
      "epoch:40 step:31472 [D loss: 1.350366, acc: 50.00%] [G loss: 6.580365]\n",
      "epoch:40 step:31473 [D loss: 0.420691, acc: 80.47%] [G loss: 7.713992]\n",
      "epoch:40 step:31474 [D loss: 0.054969, acc: 100.00%] [G loss: 3.852313]\n",
      "epoch:40 step:31475 [D loss: 0.730117, acc: 54.69%] [G loss: 10.100501]\n",
      "epoch:40 step:31476 [D loss: 0.732564, acc: 56.25%] [G loss: 5.492128]\n",
      "epoch:40 step:31477 [D loss: 0.016492, acc: 100.00%] [G loss: 5.062938]\n",
      "epoch:40 step:31478 [D loss: 2.177182, acc: 15.62%] [G loss: 5.061582]\n",
      "epoch:40 step:31479 [D loss: 0.101341, acc: 100.00%] [G loss: 6.415441]\n",
      "epoch:40 step:31480 [D loss: 0.278424, acc: 96.09%] [G loss: 7.049355]\n",
      "epoch:40 step:31481 [D loss: 1.902669, acc: 25.78%] [G loss: 8.800316]\n",
      "epoch:40 step:31482 [D loss: 0.489636, acc: 74.22%] [G loss: 5.938062]\n",
      "epoch:40 step:31483 [D loss: 1.277649, acc: 51.56%] [G loss: 1.519817]\n",
      "epoch:40 step:31484 [D loss: 0.016742, acc: 100.00%] [G loss: 6.601135]\n",
      "epoch:40 step:31485 [D loss: 0.262599, acc: 93.75%] [G loss: 5.338266]\n",
      "epoch:40 step:31486 [D loss: 0.534749, acc: 72.66%] [G loss: 3.015308]\n",
      "epoch:40 step:31487 [D loss: 0.339233, acc: 92.19%] [G loss: 4.697489]\n",
      "epoch:40 step:31488 [D loss: 0.227755, acc: 93.75%] [G loss: 5.615382]\n",
      "epoch:40 step:31489 [D loss: 0.076975, acc: 99.22%] [G loss: 3.712985]\n",
      "epoch:40 step:31490 [D loss: 0.152948, acc: 99.22%] [G loss: 6.569860]\n",
      "epoch:40 step:31491 [D loss: 0.412057, acc: 83.59%] [G loss: 5.800304]\n",
      "epoch:40 step:31492 [D loss: 0.093249, acc: 100.00%] [G loss: 7.060807]\n",
      "epoch:40 step:31493 [D loss: 0.687265, acc: 57.81%] [G loss: 4.836336]\n",
      "epoch:40 step:31494 [D loss: 0.332043, acc: 78.91%] [G loss: 5.577877]\n",
      "epoch:40 step:31495 [D loss: 0.102490, acc: 99.22%] [G loss: 4.640962]\n",
      "epoch:40 step:31496 [D loss: 0.164336, acc: 98.44%] [G loss: 4.736173]\n",
      "epoch:40 step:31497 [D loss: 0.456631, acc: 71.09%] [G loss: 6.632250]\n",
      "epoch:40 step:31498 [D loss: 0.414794, acc: 73.44%] [G loss: 6.721636]\n",
      "epoch:40 step:31499 [D loss: 0.524369, acc: 78.91%] [G loss: 6.638386]\n",
      "epoch:40 step:31500 [D loss: 0.357766, acc: 77.34%] [G loss: 5.261449]\n",
      "epoch:40 step:31501 [D loss: 0.299674, acc: 93.75%] [G loss: 5.525229]\n",
      "epoch:40 step:31502 [D loss: 0.073078, acc: 100.00%] [G loss: 3.824884]\n",
      "epoch:40 step:31503 [D loss: 1.235411, acc: 35.94%] [G loss: 7.123136]\n",
      "epoch:40 step:31504 [D loss: 0.262096, acc: 95.31%] [G loss: 4.027249]\n",
      "epoch:40 step:31505 [D loss: 0.190219, acc: 97.66%] [G loss: 2.454693]\n",
      "epoch:40 step:31506 [D loss: 0.335758, acc: 88.28%] [G loss: 8.120778]\n",
      "epoch:40 step:31507 [D loss: 0.497470, acc: 79.69%] [G loss: 4.882955]\n",
      "epoch:40 step:31508 [D loss: 0.173406, acc: 98.44%] [G loss: 2.178326]\n",
      "epoch:40 step:31509 [D loss: 0.332787, acc: 82.81%] [G loss: 4.161266]\n",
      "epoch:40 step:31510 [D loss: 0.409788, acc: 86.72%] [G loss: 4.266450]\n",
      "epoch:40 step:31511 [D loss: 0.444934, acc: 68.75%] [G loss: 4.888258]\n",
      "epoch:40 step:31512 [D loss: 0.343963, acc: 82.81%] [G loss: 5.527634]\n",
      "epoch:40 step:31513 [D loss: 0.718603, acc: 58.59%] [G loss: 6.764358]\n",
      "epoch:40 step:31514 [D loss: 0.420430, acc: 83.59%] [G loss: 7.259356]\n",
      "epoch:40 step:31515 [D loss: 0.466087, acc: 75.78%] [G loss: 6.626872]\n",
      "epoch:40 step:31516 [D loss: 0.159029, acc: 100.00%] [G loss: 5.634838]\n",
      "epoch:40 step:31517 [D loss: 0.109733, acc: 98.44%] [G loss: 3.216061]\n",
      "epoch:40 step:31518 [D loss: 0.069618, acc: 100.00%] [G loss: 4.011919]\n",
      "epoch:40 step:31519 [D loss: 0.130600, acc: 98.44%] [G loss: 6.868941]\n",
      "epoch:40 step:31520 [D loss: 0.460015, acc: 75.78%] [G loss: 4.500485]\n",
      "epoch:40 step:31521 [D loss: 0.051936, acc: 100.00%] [G loss: 5.990092]\n",
      "epoch:40 step:31522 [D loss: 0.793900, acc: 52.34%] [G loss: 7.236950]\n",
      "epoch:40 step:31523 [D loss: 1.384439, acc: 34.38%] [G loss: 3.995311]\n",
      "epoch:40 step:31524 [D loss: 0.569227, acc: 60.94%] [G loss: 3.902717]\n",
      "epoch:40 step:31525 [D loss: 0.294678, acc: 94.53%] [G loss: 5.560855]\n",
      "epoch:40 step:31526 [D loss: 0.078738, acc: 100.00%] [G loss: 1.970954]\n",
      "epoch:40 step:31527 [D loss: 1.371607, acc: 48.44%] [G loss: 6.966531]\n",
      "epoch:40 step:31528 [D loss: 0.530083, acc: 62.50%] [G loss: 5.152472]\n",
      "epoch:40 step:31529 [D loss: 0.097317, acc: 100.00%] [G loss: 5.200089]\n",
      "epoch:40 step:31530 [D loss: 0.144712, acc: 99.22%] [G loss: 4.065721]\n",
      "epoch:40 step:31531 [D loss: 0.285302, acc: 96.09%] [G loss: 4.796990]\n",
      "epoch:40 step:31532 [D loss: 0.229940, acc: 97.66%] [G loss: 4.612518]\n",
      "epoch:40 step:31533 [D loss: 0.013755, acc: 100.00%] [G loss: 6.220456]\n",
      "epoch:40 step:31534 [D loss: 1.034951, acc: 32.81%] [G loss: 6.512299]\n",
      "epoch:40 step:31535 [D loss: 0.404299, acc: 78.12%] [G loss: 4.524014]\n",
      "epoch:40 step:31536 [D loss: 0.081416, acc: 99.22%] [G loss: 4.753439]\n",
      "epoch:40 step:31537 [D loss: 0.164180, acc: 97.66%] [G loss: 4.199422]\n",
      "epoch:40 step:31538 [D loss: 0.512264, acc: 68.75%] [G loss: 4.094717]\n",
      "epoch:40 step:31539 [D loss: 1.463626, acc: 49.22%] [G loss: 4.695046]\n",
      "epoch:40 step:31540 [D loss: 0.179432, acc: 95.31%] [G loss: 4.072718]\n",
      "epoch:40 step:31541 [D loss: 0.047097, acc: 100.00%] [G loss: 9.604469]\n",
      "epoch:40 step:31542 [D loss: 1.052673, acc: 32.81%] [G loss: 6.125436]\n",
      "epoch:40 step:31543 [D loss: 0.497231, acc: 75.00%] [G loss: 4.066141]\n",
      "epoch:40 step:31544 [D loss: 0.098847, acc: 98.44%] [G loss: 10.414783]\n",
      "epoch:40 step:31545 [D loss: 0.255460, acc: 96.09%] [G loss: 4.004681]\n",
      "epoch:40 step:31546 [D loss: 0.718176, acc: 57.03%] [G loss: 5.535415]\n",
      "epoch:40 step:31547 [D loss: 0.339453, acc: 85.16%] [G loss: 7.580114]\n",
      "epoch:40 step:31548 [D loss: 1.358866, acc: 46.88%] [G loss: 4.655704]\n",
      "epoch:40 step:31549 [D loss: 0.168528, acc: 99.22%] [G loss: 4.484303]\n",
      "epoch:40 step:31550 [D loss: 0.108664, acc: 99.22%] [G loss: 3.276522]\n",
      "epoch:40 step:31551 [D loss: 0.207765, acc: 98.44%] [G loss: 4.610227]\n",
      "epoch:40 step:31552 [D loss: 0.139504, acc: 100.00%] [G loss: 4.100618]\n",
      "epoch:40 step:31553 [D loss: 0.031933, acc: 100.00%] [G loss: 4.447824]\n",
      "epoch:40 step:31554 [D loss: 0.121768, acc: 100.00%] [G loss: 6.492052]\n",
      "epoch:40 step:31555 [D loss: 0.794467, acc: 42.97%] [G loss: 8.413856]\n",
      "epoch:40 step:31556 [D loss: 0.199809, acc: 95.31%] [G loss: 4.908679]\n",
      "epoch:40 step:31557 [D loss: 0.185402, acc: 100.00%] [G loss: 1.856336]\n",
      "epoch:40 step:31558 [D loss: 0.623325, acc: 64.06%] [G loss: 5.171725]\n",
      "epoch:40 step:31559 [D loss: 0.373479, acc: 80.47%] [G loss: 5.948070]\n",
      "epoch:40 step:31560 [D loss: 0.057473, acc: 100.00%] [G loss: 8.268139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31561 [D loss: 1.930390, acc: 42.19%] [G loss: 6.089661]\n",
      "epoch:40 step:31562 [D loss: 0.531859, acc: 63.28%] [G loss: 6.605414]\n",
      "epoch:40 step:31563 [D loss: 0.206835, acc: 97.66%] [G loss: 6.300042]\n",
      "epoch:40 step:31564 [D loss: 0.406126, acc: 75.78%] [G loss: 6.864919]\n",
      "epoch:40 step:31565 [D loss: 0.191588, acc: 98.44%] [G loss: 8.008045]\n",
      "epoch:40 step:31566 [D loss: 0.330251, acc: 93.75%] [G loss: 5.715341]\n",
      "epoch:40 step:31567 [D loss: 0.539386, acc: 75.78%] [G loss: 5.313105]\n",
      "epoch:40 step:31568 [D loss: 0.602117, acc: 61.72%] [G loss: 6.946083]\n",
      "epoch:40 step:31569 [D loss: 0.531598, acc: 76.56%] [G loss: 10.273600]\n",
      "epoch:40 step:31570 [D loss: 0.296286, acc: 93.75%] [G loss: 5.455378]\n",
      "epoch:40 step:31571 [D loss: 0.219830, acc: 98.44%] [G loss: 7.558772]\n",
      "epoch:40 step:31572 [D loss: 0.175025, acc: 98.44%] [G loss: 4.501864]\n",
      "epoch:40 step:31573 [D loss: 0.084288, acc: 100.00%] [G loss: 7.682421]\n",
      "epoch:40 step:31574 [D loss: 0.421378, acc: 84.38%] [G loss: 7.105737]\n",
      "epoch:40 step:31575 [D loss: 0.027328, acc: 100.00%] [G loss: 10.889475]\n",
      "epoch:40 step:31576 [D loss: 0.192179, acc: 98.44%] [G loss: 8.311289]\n",
      "epoch:40 step:31577 [D loss: 0.929637, acc: 52.34%] [G loss: 6.954208]\n",
      "epoch:40 step:31578 [D loss: 0.159968, acc: 96.88%] [G loss: 7.647537]\n",
      "epoch:40 step:31579 [D loss: 0.294996, acc: 85.16%] [G loss: 7.665230]\n",
      "epoch:40 step:31580 [D loss: 0.121409, acc: 99.22%] [G loss: 5.795061]\n",
      "epoch:40 step:31581 [D loss: 0.159752, acc: 98.44%] [G loss: 3.164002]\n",
      "epoch:40 step:31582 [D loss: 0.120893, acc: 99.22%] [G loss: 3.209431]\n",
      "epoch:40 step:31583 [D loss: 0.673502, acc: 60.94%] [G loss: 3.408566]\n",
      "epoch:40 step:31584 [D loss: 0.293644, acc: 96.88%] [G loss: 6.915844]\n",
      "epoch:40 step:31585 [D loss: 0.173939, acc: 96.09%] [G loss: 4.390131]\n",
      "epoch:40 step:31586 [D loss: 0.154498, acc: 96.88%] [G loss: 6.339637]\n",
      "epoch:40 step:31587 [D loss: 0.269127, acc: 92.19%] [G loss: 5.364130]\n",
      "epoch:40 step:31588 [D loss: 0.133431, acc: 100.00%] [G loss: 3.344743]\n",
      "epoch:40 step:31589 [D loss: 1.331958, acc: 32.03%] [G loss: 7.249465]\n",
      "epoch:40 step:31590 [D loss: 0.536950, acc: 67.97%] [G loss: 5.587065]\n",
      "epoch:40 step:31591 [D loss: 0.315984, acc: 93.75%] [G loss: 5.988163]\n",
      "epoch:40 step:31592 [D loss: 0.172551, acc: 100.00%] [G loss: 6.769412]\n",
      "epoch:40 step:31593 [D loss: 0.074722, acc: 100.00%] [G loss: 4.016630]\n",
      "epoch:40 step:31594 [D loss: 0.678158, acc: 62.50%] [G loss: 4.335096]\n",
      "epoch:40 step:31595 [D loss: 0.534243, acc: 72.66%] [G loss: 7.162930]\n",
      "epoch:40 step:31596 [D loss: 0.351501, acc: 78.91%] [G loss: 4.951388]\n",
      "epoch:40 step:31597 [D loss: 1.362226, acc: 32.03%] [G loss: 5.250186]\n",
      "epoch:40 step:31598 [D loss: 0.159156, acc: 100.00%] [G loss: 6.751889]\n",
      "epoch:40 step:31599 [D loss: 0.537393, acc: 68.75%] [G loss: 7.199335]\n",
      "epoch:40 step:31600 [D loss: 0.080852, acc: 100.00%] [G loss: 6.562217]\n",
      "epoch:40 step:31601 [D loss: 0.283507, acc: 97.66%] [G loss: 6.015624]\n",
      "epoch:40 step:31602 [D loss: 0.129026, acc: 100.00%] [G loss: 4.937706]\n",
      "epoch:40 step:31603 [D loss: 0.273406, acc: 95.31%] [G loss: 5.594622]\n",
      "epoch:40 step:31604 [D loss: 0.634284, acc: 64.06%] [G loss: 6.924803]\n",
      "epoch:40 step:31605 [D loss: 0.086609, acc: 100.00%] [G loss: 2.800369]\n",
      "epoch:40 step:31606 [D loss: 0.168202, acc: 100.00%] [G loss: 4.538611]\n",
      "epoch:40 step:31607 [D loss: 0.294680, acc: 87.50%] [G loss: 5.118409]\n",
      "epoch:40 step:31608 [D loss: 0.534516, acc: 64.06%] [G loss: 4.496433]\n",
      "epoch:40 step:31609 [D loss: 0.219530, acc: 91.41%] [G loss: 5.080635]\n",
      "epoch:40 step:31610 [D loss: 0.150121, acc: 98.44%] [G loss: 4.014117]\n",
      "epoch:40 step:31611 [D loss: 1.219743, acc: 45.31%] [G loss: 5.574210]\n",
      "epoch:40 step:31612 [D loss: 0.696459, acc: 52.34%] [G loss: 4.102262]\n",
      "epoch:40 step:31613 [D loss: 0.518661, acc: 64.84%] [G loss: 5.963122]\n",
      "epoch:40 step:31614 [D loss: 0.220982, acc: 92.19%] [G loss: 4.888414]\n",
      "epoch:40 step:31615 [D loss: 0.041511, acc: 100.00%] [G loss: 3.384596]\n",
      "epoch:40 step:31616 [D loss: 0.057450, acc: 100.00%] [G loss: 6.539061]\n",
      "epoch:40 step:31617 [D loss: 0.348496, acc: 91.41%] [G loss: 6.652725]\n",
      "epoch:40 step:31618 [D loss: 0.049844, acc: 99.22%] [G loss: 7.350712]\n",
      "epoch:40 step:31619 [D loss: 0.061357, acc: 100.00%] [G loss: 6.254102]\n",
      "epoch:40 step:31620 [D loss: 0.218748, acc: 96.88%] [G loss: 7.029925]\n",
      "epoch:40 step:31621 [D loss: 0.134699, acc: 98.44%] [G loss: 5.835945]\n",
      "epoch:40 step:31622 [D loss: 0.591614, acc: 63.28%] [G loss: 7.744750]\n",
      "epoch:40 step:31623 [D loss: 1.148881, acc: 49.22%] [G loss: 1.653673]\n",
      "epoch:40 step:31624 [D loss: 1.540886, acc: 3.12%] [G loss: 5.245737]\n",
      "epoch:40 step:31625 [D loss: 0.446977, acc: 70.31%] [G loss: 6.298732]\n",
      "epoch:40 step:31626 [D loss: 0.076425, acc: 100.00%] [G loss: 5.101619]\n",
      "epoch:40 step:31627 [D loss: 0.179333, acc: 96.09%] [G loss: 7.427669]\n",
      "epoch:40 step:31628 [D loss: 0.409809, acc: 75.00%] [G loss: 6.844804]\n",
      "epoch:40 step:31629 [D loss: 0.071974, acc: 100.00%] [G loss: 5.685617]\n",
      "epoch:40 step:31630 [D loss: 0.074711, acc: 100.00%] [G loss: 4.903603]\n",
      "epoch:40 step:31631 [D loss: 1.077524, acc: 32.81%] [G loss: 6.773184]\n",
      "epoch:40 step:31632 [D loss: 0.135149, acc: 99.22%] [G loss: 5.300062]\n",
      "epoch:40 step:31633 [D loss: 0.162347, acc: 100.00%] [G loss: 3.880310]\n",
      "epoch:40 step:31634 [D loss: 0.085187, acc: 99.22%] [G loss: 5.492514]\n",
      "epoch:40 step:31635 [D loss: 0.136772, acc: 98.44%] [G loss: 5.031594]\n",
      "epoch:40 step:31636 [D loss: 1.120794, acc: 50.00%] [G loss: 7.102917]\n",
      "epoch:40 step:31637 [D loss: 0.441349, acc: 68.75%] [G loss: 7.856822]\n",
      "epoch:40 step:31638 [D loss: 1.244606, acc: 30.47%] [G loss: 8.327546]\n",
      "epoch:40 step:31639 [D loss: 0.653163, acc: 60.16%] [G loss: 4.746114]\n",
      "epoch:40 step:31640 [D loss: 0.043519, acc: 99.22%] [G loss: 7.306802]\n",
      "epoch:40 step:31641 [D loss: 0.047650, acc: 100.00%] [G loss: 4.606897]\n",
      "epoch:40 step:31642 [D loss: 0.498365, acc: 71.09%] [G loss: 8.578211]\n",
      "epoch:40 step:31643 [D loss: 0.217865, acc: 96.88%] [G loss: 5.828535]\n",
      "epoch:40 step:31644 [D loss: 0.198466, acc: 97.66%] [G loss: 4.789235]\n",
      "epoch:40 step:31645 [D loss: 0.252389, acc: 93.75%] [G loss: 5.412646]\n",
      "epoch:40 step:31646 [D loss: 0.164863, acc: 97.66%] [G loss: 3.879677]\n",
      "epoch:40 step:31647 [D loss: 0.120588, acc: 100.00%] [G loss: 4.896322]\n",
      "epoch:40 step:31648 [D loss: 0.110720, acc: 99.22%] [G loss: 6.996990]\n",
      "epoch:40 step:31649 [D loss: 0.314663, acc: 96.09%] [G loss: 5.972076]\n",
      "epoch:40 step:31650 [D loss: 0.518749, acc: 72.66%] [G loss: 6.283385]\n",
      "epoch:40 step:31651 [D loss: 0.177879, acc: 98.44%] [G loss: 4.691883]\n",
      "epoch:40 step:31652 [D loss: 0.286137, acc: 94.53%] [G loss: 6.629635]\n",
      "epoch:40 step:31653 [D loss: 0.445424, acc: 72.66%] [G loss: 3.999828]\n",
      "epoch:40 step:31654 [D loss: 0.194524, acc: 95.31%] [G loss: 4.824593]\n",
      "epoch:40 step:31655 [D loss: 0.192374, acc: 97.66%] [G loss: 4.072805]\n",
      "epoch:40 step:31656 [D loss: 0.974068, acc: 35.94%] [G loss: 6.909437]\n",
      "epoch:40 step:31657 [D loss: 0.112470, acc: 100.00%] [G loss: 3.240688]\n",
      "epoch:40 step:31658 [D loss: 0.058493, acc: 100.00%] [G loss: 7.655025]\n",
      "epoch:40 step:31659 [D loss: 0.810503, acc: 53.12%] [G loss: 3.286770]\n",
      "epoch:40 step:31660 [D loss: 0.384525, acc: 84.38%] [G loss: 5.153391]\n",
      "epoch:40 step:31661 [D loss: 0.589946, acc: 59.38%] [G loss: 4.828934]\n",
      "epoch:40 step:31662 [D loss: 0.577161, acc: 59.38%] [G loss: 6.868606]\n",
      "epoch:40 step:31663 [D loss: 0.315408, acc: 94.53%] [G loss: 2.532716]\n",
      "epoch:40 step:31664 [D loss: 0.666988, acc: 61.72%] [G loss: 5.812035]\n",
      "epoch:40 step:31665 [D loss: 0.151770, acc: 99.22%] [G loss: 3.152570]\n",
      "epoch:40 step:31666 [D loss: 0.247033, acc: 96.09%] [G loss: 4.870000]\n",
      "epoch:40 step:31667 [D loss: 0.798627, acc: 52.34%] [G loss: 3.008491]\n",
      "epoch:40 step:31668 [D loss: 0.567143, acc: 61.72%] [G loss: 6.407405]\n",
      "epoch:40 step:31669 [D loss: 0.560925, acc: 67.19%] [G loss: 4.747029]\n",
      "epoch:40 step:31670 [D loss: 0.365382, acc: 82.03%] [G loss: 5.861935]\n",
      "epoch:40 step:31671 [D loss: 0.377719, acc: 75.78%] [G loss: 4.620352]\n",
      "epoch:40 step:31672 [D loss: 0.330650, acc: 78.12%] [G loss: 3.405197]\n",
      "epoch:40 step:31673 [D loss: 0.206384, acc: 100.00%] [G loss: 5.507939]\n",
      "epoch:40 step:31674 [D loss: 0.203914, acc: 96.09%] [G loss: 3.811240]\n",
      "epoch:40 step:31675 [D loss: 0.092052, acc: 98.44%] [G loss: 6.839474]\n",
      "epoch:40 step:31676 [D loss: 0.319268, acc: 89.06%] [G loss: 4.004605]\n",
      "epoch:40 step:31677 [D loss: 0.229633, acc: 96.09%] [G loss: 3.268517]\n",
      "epoch:40 step:31678 [D loss: 0.679738, acc: 61.72%] [G loss: 5.056148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31679 [D loss: 0.369635, acc: 85.94%] [G loss: 5.014304]\n",
      "epoch:40 step:31680 [D loss: 0.251871, acc: 97.66%] [G loss: 4.004133]\n",
      "epoch:40 step:31681 [D loss: 0.126816, acc: 100.00%] [G loss: 6.125019]\n",
      "epoch:40 step:31682 [D loss: 0.220991, acc: 96.88%] [G loss: 6.413033]\n",
      "epoch:40 step:31683 [D loss: 0.362312, acc: 89.06%] [G loss: 3.316852]\n",
      "epoch:40 step:31684 [D loss: 0.105301, acc: 99.22%] [G loss: 2.222926]\n",
      "epoch:40 step:31685 [D loss: 0.369419, acc: 81.25%] [G loss: 5.005203]\n",
      "epoch:40 step:31686 [D loss: 0.342040, acc: 81.25%] [G loss: 5.656772]\n",
      "epoch:40 step:31687 [D loss: 0.481886, acc: 75.78%] [G loss: 6.057816]\n",
      "epoch:40 step:31688 [D loss: 0.375702, acc: 82.03%] [G loss: 3.386293]\n",
      "epoch:40 step:31689 [D loss: 0.557476, acc: 65.62%] [G loss: 2.710004]\n",
      "epoch:40 step:31690 [D loss: 0.168687, acc: 99.22%] [G loss: 6.202807]\n",
      "epoch:40 step:31691 [D loss: 0.060710, acc: 100.00%] [G loss: 5.805828]\n",
      "epoch:40 step:31692 [D loss: 0.703090, acc: 56.25%] [G loss: 6.282372]\n",
      "epoch:40 step:31693 [D loss: 0.859366, acc: 52.34%] [G loss: 6.147514]\n",
      "epoch:40 step:31694 [D loss: 0.016386, acc: 100.00%] [G loss: 4.090466]\n",
      "epoch:40 step:31695 [D loss: 0.162063, acc: 96.88%] [G loss: 7.333900]\n",
      "epoch:40 step:31696 [D loss: 0.207169, acc: 92.19%] [G loss: 7.969844]\n",
      "epoch:40 step:31697 [D loss: 0.313327, acc: 92.97%] [G loss: 7.603968]\n",
      "epoch:40 step:31698 [D loss: 0.221512, acc: 95.31%] [G loss: 3.164081]\n",
      "epoch:40 step:31699 [D loss: 0.304093, acc: 85.94%] [G loss: 5.237911]\n",
      "epoch:40 step:31700 [D loss: 0.146040, acc: 100.00%] [G loss: 5.278405]\n",
      "epoch:40 step:31701 [D loss: 0.189632, acc: 99.22%] [G loss: 4.034227]\n",
      "epoch:40 step:31702 [D loss: 0.099699, acc: 99.22%] [G loss: 8.228142]\n",
      "epoch:40 step:31703 [D loss: 0.291569, acc: 86.72%] [G loss: 6.453760]\n",
      "epoch:40 step:31704 [D loss: 0.412299, acc: 82.81%] [G loss: 5.756715]\n",
      "epoch:40 step:31705 [D loss: 0.398852, acc: 78.12%] [G loss: 6.223133]\n",
      "epoch:40 step:31706 [D loss: 0.034913, acc: 100.00%] [G loss: 6.946519]\n",
      "epoch:40 step:31707 [D loss: 0.059853, acc: 100.00%] [G loss: 4.130353]\n",
      "epoch:40 step:31708 [D loss: 0.314182, acc: 89.84%] [G loss: 4.965789]\n",
      "epoch:40 step:31709 [D loss: 0.337960, acc: 83.59%] [G loss: 7.935601]\n",
      "epoch:40 step:31710 [D loss: 0.046769, acc: 100.00%] [G loss: 8.650095]\n",
      "epoch:40 step:31711 [D loss: 0.438224, acc: 74.22%] [G loss: 5.627883]\n",
      "epoch:40 step:31712 [D loss: 0.399691, acc: 73.44%] [G loss: 5.228250]\n",
      "epoch:40 step:31713 [D loss: 0.728158, acc: 56.25%] [G loss: 7.210745]\n",
      "epoch:40 step:31714 [D loss: 0.113375, acc: 99.22%] [G loss: 6.885418]\n",
      "epoch:40 step:31715 [D loss: 0.449334, acc: 85.16%] [G loss: 6.364188]\n",
      "epoch:40 step:31716 [D loss: 0.138613, acc: 98.44%] [G loss: 2.991014]\n",
      "epoch:40 step:31717 [D loss: 0.156607, acc: 97.66%] [G loss: 4.239154]\n",
      "epoch:40 step:31718 [D loss: 0.188133, acc: 97.66%] [G loss: 5.563469]\n",
      "epoch:40 step:31719 [D loss: 0.074062, acc: 100.00%] [G loss: 6.284295]\n",
      "epoch:40 step:31720 [D loss: 0.554074, acc: 72.66%] [G loss: 4.293080]\n",
      "epoch:40 step:31721 [D loss: 0.745569, acc: 52.34%] [G loss: 6.257432]\n",
      "epoch:40 step:31722 [D loss: 0.612225, acc: 66.41%] [G loss: 5.022272]\n",
      "epoch:40 step:31723 [D loss: 0.049431, acc: 100.00%] [G loss: 4.524380]\n",
      "epoch:40 step:31724 [D loss: 0.159667, acc: 95.31%] [G loss: 3.716756]\n",
      "epoch:40 step:31725 [D loss: 0.097378, acc: 99.22%] [G loss: 6.352437]\n",
      "epoch:40 step:31726 [D loss: 0.194148, acc: 94.53%] [G loss: 5.054358]\n",
      "epoch:40 step:31727 [D loss: 0.343724, acc: 83.59%] [G loss: 3.036455]\n",
      "epoch:40 step:31728 [D loss: 0.385325, acc: 83.59%] [G loss: 4.561133]\n",
      "epoch:40 step:31729 [D loss: 0.352382, acc: 82.81%] [G loss: 7.189266]\n",
      "epoch:40 step:31730 [D loss: 0.043099, acc: 100.00%] [G loss: 7.731043]\n",
      "epoch:40 step:31731 [D loss: 0.326883, acc: 91.41%] [G loss: 5.314210]\n",
      "epoch:40 step:31732 [D loss: 1.469111, acc: 7.03%] [G loss: 9.066277]\n",
      "epoch:40 step:31733 [D loss: 0.177970, acc: 99.22%] [G loss: 5.428537]\n",
      "epoch:40 step:31734 [D loss: 0.108432, acc: 100.00%] [G loss: 4.066226]\n",
      "epoch:40 step:31735 [D loss: 0.551512, acc: 64.84%] [G loss: 9.105383]\n",
      "epoch:40 step:31736 [D loss: 0.141132, acc: 96.88%] [G loss: 8.810683]\n",
      "epoch:40 step:31737 [D loss: 0.041080, acc: 100.00%] [G loss: 5.167421]\n",
      "epoch:40 step:31738 [D loss: 0.017049, acc: 100.00%] [G loss: 7.112451]\n",
      "epoch:40 step:31739 [D loss: 0.363635, acc: 82.03%] [G loss: 6.989780]\n",
      "epoch:40 step:31740 [D loss: 0.280804, acc: 90.62%] [G loss: 5.416441]\n",
      "epoch:40 step:31741 [D loss: 0.720523, acc: 57.03%] [G loss: 7.858270]\n",
      "epoch:40 step:31742 [D loss: 0.495491, acc: 65.62%] [G loss: 6.939553]\n",
      "epoch:40 step:31743 [D loss: 0.102527, acc: 99.22%] [G loss: 7.738742]\n",
      "epoch:40 step:31744 [D loss: 0.634680, acc: 64.84%] [G loss: 4.183203]\n",
      "epoch:40 step:31745 [D loss: 0.219946, acc: 96.09%] [G loss: 5.041586]\n",
      "epoch:40 step:31746 [D loss: 0.184742, acc: 99.22%] [G loss: 6.710443]\n",
      "epoch:40 step:31747 [D loss: 0.791460, acc: 52.34%] [G loss: 6.204314]\n",
      "epoch:40 step:31748 [D loss: 0.056547, acc: 100.00%] [G loss: 8.361536]\n",
      "epoch:40 step:31749 [D loss: 0.420630, acc: 74.22%] [G loss: 7.990621]\n",
      "epoch:40 step:31750 [D loss: 0.077515, acc: 100.00%] [G loss: 6.153172]\n",
      "epoch:40 step:31751 [D loss: 0.359557, acc: 79.69%] [G loss: 10.414572]\n",
      "epoch:40 step:31752 [D loss: 0.062263, acc: 99.22%] [G loss: 4.004091]\n",
      "epoch:40 step:31753 [D loss: 0.687801, acc: 59.38%] [G loss: 8.102158]\n",
      "epoch:40 step:31754 [D loss: 0.569161, acc: 63.28%] [G loss: 3.410053]\n",
      "epoch:40 step:31755 [D loss: 0.185314, acc: 96.88%] [G loss: 5.182503]\n",
      "epoch:40 step:31756 [D loss: 0.301961, acc: 89.84%] [G loss: 4.893445]\n",
      "epoch:40 step:31757 [D loss: 0.048012, acc: 100.00%] [G loss: 6.369020]\n",
      "epoch:40 step:31758 [D loss: 0.150487, acc: 97.66%] [G loss: 7.220786]\n",
      "epoch:40 step:31759 [D loss: 1.220940, acc: 12.50%] [G loss: 5.698166]\n",
      "epoch:40 step:31760 [D loss: 1.721095, acc: 48.44%] [G loss: 4.384735]\n",
      "epoch:40 step:31761 [D loss: 0.337981, acc: 85.16%] [G loss: 5.184697]\n",
      "epoch:40 step:31762 [D loss: 0.970720, acc: 35.94%] [G loss: 6.376731]\n",
      "epoch:40 step:31763 [D loss: 0.147240, acc: 99.22%] [G loss: 4.207650]\n",
      "epoch:40 step:31764 [D loss: 0.285518, acc: 92.19%] [G loss: 4.174177]\n",
      "epoch:40 step:31765 [D loss: 0.104328, acc: 100.00%] [G loss: 6.100109]\n",
      "epoch:40 step:31766 [D loss: 1.073962, acc: 49.22%] [G loss: 5.582575]\n",
      "epoch:40 step:31767 [D loss: 0.501800, acc: 74.22%] [G loss: 3.127920]\n",
      "epoch:40 step:31768 [D loss: 0.288200, acc: 94.53%] [G loss: 4.233929]\n",
      "epoch:40 step:31769 [D loss: 0.253333, acc: 88.28%] [G loss: 3.614287]\n",
      "epoch:40 step:31770 [D loss: 0.529758, acc: 61.72%] [G loss: 6.168670]\n",
      "epoch:40 step:31771 [D loss: 0.253688, acc: 96.88%] [G loss: 3.377362]\n",
      "epoch:40 step:31772 [D loss: 0.084113, acc: 100.00%] [G loss: 6.868318]\n",
      "epoch:40 step:31773 [D loss: 0.147126, acc: 100.00%] [G loss: 8.210151]\n",
      "epoch:40 step:31774 [D loss: 0.017367, acc: 100.00%] [G loss: 5.739885]\n",
      "epoch:40 step:31775 [D loss: 0.139395, acc: 97.66%] [G loss: 2.151999]\n",
      "epoch:40 step:31776 [D loss: 0.507877, acc: 82.03%] [G loss: 6.590280]\n",
      "epoch:40 step:31777 [D loss: 0.045047, acc: 100.00%] [G loss: 7.198614]\n",
      "epoch:40 step:31778 [D loss: 0.057332, acc: 100.00%] [G loss: 6.456363]\n",
      "epoch:40 step:31779 [D loss: 0.260473, acc: 90.62%] [G loss: 6.542763]\n",
      "epoch:40 step:31780 [D loss: 0.231046, acc: 92.97%] [G loss: 5.271485]\n",
      "epoch:40 step:31781 [D loss: 0.176500, acc: 98.44%] [G loss: 1.613457]\n",
      "epoch:40 step:31782 [D loss: 0.413126, acc: 81.25%] [G loss: 5.973358]\n",
      "epoch:40 step:31783 [D loss: 0.029180, acc: 100.00%] [G loss: 4.673661]\n",
      "epoch:40 step:31784 [D loss: 0.233169, acc: 96.09%] [G loss: 4.571236]\n",
      "epoch:40 step:31785 [D loss: 0.139392, acc: 96.09%] [G loss: 4.079359]\n",
      "epoch:40 step:31786 [D loss: 0.060917, acc: 100.00%] [G loss: 5.082768]\n",
      "epoch:40 step:31787 [D loss: 0.897445, acc: 53.12%] [G loss: 5.632042]\n",
      "epoch:40 step:31788 [D loss: 0.294878, acc: 87.50%] [G loss: 5.233269]\n",
      "epoch:40 step:31789 [D loss: 0.518087, acc: 60.94%] [G loss: 7.118153]\n",
      "epoch:40 step:31790 [D loss: 0.286750, acc: 84.38%] [G loss: 7.283198]\n",
      "epoch:40 step:31791 [D loss: 1.346623, acc: 50.00%] [G loss: 4.192321]\n",
      "epoch:40 step:31792 [D loss: 0.281975, acc: 90.62%] [G loss: 5.805762]\n",
      "epoch:40 step:31793 [D loss: 0.261480, acc: 89.84%] [G loss: 6.761627]\n",
      "epoch:40 step:31794 [D loss: 0.459649, acc: 73.44%] [G loss: 7.698112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31795 [D loss: 0.216032, acc: 91.41%] [G loss: 4.255239]\n",
      "epoch:40 step:31796 [D loss: 0.172971, acc: 98.44%] [G loss: 6.274731]\n",
      "epoch:40 step:31797 [D loss: 0.280861, acc: 93.75%] [G loss: 6.732589]\n",
      "epoch:40 step:31798 [D loss: 0.339596, acc: 86.72%] [G loss: 4.124291]\n",
      "epoch:40 step:31799 [D loss: 0.126319, acc: 98.44%] [G loss: 8.170536]\n",
      "epoch:40 step:31800 [D loss: 0.649470, acc: 61.72%] [G loss: 7.567485]\n",
      "epoch:40 step:31801 [D loss: 0.454694, acc: 78.12%] [G loss: 4.510383]\n",
      "epoch:40 step:31802 [D loss: 0.820678, acc: 45.31%] [G loss: 6.514381]\n",
      "epoch:40 step:31803 [D loss: 0.235762, acc: 92.19%] [G loss: 3.073004]\n",
      "epoch:40 step:31804 [D loss: 1.228205, acc: 18.75%] [G loss: 5.800442]\n",
      "epoch:40 step:31805 [D loss: 0.246145, acc: 92.19%] [G loss: 4.357856]\n",
      "epoch:40 step:31806 [D loss: 0.439614, acc: 75.78%] [G loss: 3.749048]\n",
      "epoch:40 step:31807 [D loss: 0.414853, acc: 84.38%] [G loss: 3.021968]\n",
      "epoch:40 step:31808 [D loss: 0.282018, acc: 92.97%] [G loss: 5.908931]\n",
      "epoch:40 step:31809 [D loss: 0.070671, acc: 100.00%] [G loss: 3.271859]\n",
      "epoch:40 step:31810 [D loss: 0.115389, acc: 100.00%] [G loss: 2.950086]\n",
      "epoch:40 step:31811 [D loss: 0.516883, acc: 77.34%] [G loss: 6.603872]\n",
      "epoch:40 step:31812 [D loss: 0.684957, acc: 59.38%] [G loss: 5.083600]\n",
      "epoch:40 step:31813 [D loss: 0.458591, acc: 75.00%] [G loss: 5.638511]\n",
      "epoch:40 step:31814 [D loss: 0.446966, acc: 71.88%] [G loss: 7.621504]\n",
      "epoch:40 step:31815 [D loss: 0.150576, acc: 99.22%] [G loss: 5.194462]\n",
      "epoch:40 step:31816 [D loss: 1.074070, acc: 50.00%] [G loss: 3.243158]\n",
      "epoch:40 step:31817 [D loss: 0.241229, acc: 91.41%] [G loss: 6.198741]\n",
      "epoch:40 step:31818 [D loss: 0.424095, acc: 75.00%] [G loss: 7.826105]\n",
      "epoch:40 step:31819 [D loss: 0.081306, acc: 100.00%] [G loss: 5.794917]\n",
      "epoch:40 step:31820 [D loss: 0.213147, acc: 96.88%] [G loss: 5.975805]\n",
      "epoch:40 step:31821 [D loss: 0.173348, acc: 98.44%] [G loss: 5.757608]\n",
      "epoch:40 step:31822 [D loss: 1.033010, acc: 52.34%] [G loss: 7.421289]\n",
      "epoch:40 step:31823 [D loss: 0.220619, acc: 95.31%] [G loss: 2.941864]\n",
      "epoch:40 step:31824 [D loss: 0.143452, acc: 99.22%] [G loss: 6.358059]\n",
      "epoch:40 step:31825 [D loss: 0.454659, acc: 73.44%] [G loss: 5.044358]\n",
      "epoch:40 step:31826 [D loss: 0.322701, acc: 89.06%] [G loss: 6.136504]\n",
      "epoch:40 step:31827 [D loss: 0.068868, acc: 100.00%] [G loss: 4.994954]\n",
      "epoch:40 step:31828 [D loss: 0.346822, acc: 94.53%] [G loss: 5.452552]\n",
      "epoch:40 step:31829 [D loss: 0.214787, acc: 94.53%] [G loss: 4.871982]\n",
      "epoch:40 step:31830 [D loss: 0.530175, acc: 65.62%] [G loss: 5.497310]\n",
      "epoch:40 step:31831 [D loss: 0.754727, acc: 53.91%] [G loss: 5.631571]\n",
      "epoch:40 step:31832 [D loss: 0.185742, acc: 97.66%] [G loss: 4.969635]\n",
      "epoch:40 step:31833 [D loss: 0.109500, acc: 99.22%] [G loss: 5.166042]\n",
      "epoch:40 step:31834 [D loss: 0.301754, acc: 92.19%] [G loss: 6.933332]\n",
      "epoch:40 step:31835 [D loss: 0.418507, acc: 75.00%] [G loss: 3.737174]\n",
      "epoch:40 step:31836 [D loss: 0.277064, acc: 91.41%] [G loss: 3.864425]\n",
      "epoch:40 step:31837 [D loss: 0.567895, acc: 57.81%] [G loss: 8.779593]\n",
      "epoch:40 step:31838 [D loss: 0.192000, acc: 97.66%] [G loss: 7.027586]\n",
      "epoch:40 step:31839 [D loss: 0.386564, acc: 75.78%] [G loss: 6.351017]\n",
      "epoch:40 step:31840 [D loss: 0.081383, acc: 100.00%] [G loss: 4.331365]\n",
      "epoch:40 step:31841 [D loss: 2.090195, acc: 50.78%] [G loss: 4.819031]\n",
      "epoch:40 step:31842 [D loss: 0.239016, acc: 93.75%] [G loss: 5.744013]\n",
      "epoch:40 step:31843 [D loss: 0.633679, acc: 66.41%] [G loss: 6.813413]\n",
      "epoch:40 step:31844 [D loss: 0.125181, acc: 98.44%] [G loss: 2.485498]\n",
      "epoch:40 step:31845 [D loss: 2.072106, acc: 3.12%] [G loss: 7.112959]\n",
      "epoch:40 step:31846 [D loss: 0.045358, acc: 100.00%] [G loss: 6.735391]\n",
      "epoch:40 step:31847 [D loss: 0.316662, acc: 88.28%] [G loss: 5.055268]\n",
      "epoch:40 step:31848 [D loss: 0.114531, acc: 100.00%] [G loss: 3.917330]\n",
      "epoch:40 step:31849 [D loss: 0.479107, acc: 83.59%] [G loss: 3.587013]\n",
      "epoch:40 step:31850 [D loss: 0.058852, acc: 100.00%] [G loss: 4.085782]\n",
      "epoch:40 step:31851 [D loss: 0.669375, acc: 55.47%] [G loss: 8.956489]\n",
      "epoch:40 step:31852 [D loss: 0.142537, acc: 99.22%] [G loss: 4.374950]\n",
      "epoch:40 step:31853 [D loss: 0.070433, acc: 100.00%] [G loss: 6.102671]\n",
      "epoch:40 step:31854 [D loss: 0.392812, acc: 82.03%] [G loss: 7.423402]\n",
      "epoch:40 step:31855 [D loss: 0.505905, acc: 66.41%] [G loss: 5.659004]\n",
      "epoch:40 step:31856 [D loss: 0.565081, acc: 62.50%] [G loss: 4.451030]\n",
      "epoch:40 step:31857 [D loss: 0.308251, acc: 85.94%] [G loss: 9.691013]\n",
      "epoch:40 step:31858 [D loss: 0.170648, acc: 97.66%] [G loss: 3.532552]\n",
      "epoch:40 step:31859 [D loss: 0.046376, acc: 100.00%] [G loss: 3.964516]\n",
      "epoch:40 step:31860 [D loss: 0.391610, acc: 77.34%] [G loss: 4.201218]\n",
      "epoch:40 step:31861 [D loss: 0.536772, acc: 69.53%] [G loss: 3.163811]\n",
      "epoch:40 step:31862 [D loss: 1.057675, acc: 53.12%] [G loss: 8.303078]\n",
      "epoch:40 step:31863 [D loss: 1.012911, acc: 45.31%] [G loss: 6.925084]\n",
      "epoch:40 step:31864 [D loss: 0.182313, acc: 95.31%] [G loss: 7.208158]\n",
      "epoch:40 step:31865 [D loss: 0.193304, acc: 99.22%] [G loss: 3.651711]\n",
      "epoch:40 step:31866 [D loss: 0.207195, acc: 94.53%] [G loss: 3.146858]\n",
      "epoch:40 step:31867 [D loss: 0.176335, acc: 95.31%] [G loss: 6.010053]\n",
      "epoch:40 step:31868 [D loss: 0.289091, acc: 87.50%] [G loss: 6.940642]\n",
      "epoch:40 step:31869 [D loss: 0.069958, acc: 100.00%] [G loss: 5.101913]\n",
      "epoch:40 step:31870 [D loss: 0.616552, acc: 57.81%] [G loss: 6.199124]\n",
      "epoch:40 step:31871 [D loss: 0.269076, acc: 87.50%] [G loss: 8.308052]\n",
      "epoch:40 step:31872 [D loss: 0.427373, acc: 71.09%] [G loss: 4.888128]\n",
      "epoch:40 step:31873 [D loss: 0.276974, acc: 96.09%] [G loss: 5.940879]\n",
      "epoch:40 step:31874 [D loss: 0.196583, acc: 96.09%] [G loss: 5.270325]\n",
      "epoch:40 step:31875 [D loss: 0.109274, acc: 100.00%] [G loss: 3.741264]\n",
      "epoch:40 step:31876 [D loss: 0.233251, acc: 96.88%] [G loss: 6.194818]\n",
      "epoch:40 step:31877 [D loss: 0.652481, acc: 56.25%] [G loss: 3.442940]\n",
      "epoch:40 step:31878 [D loss: 0.373237, acc: 89.06%] [G loss: 1.904765]\n",
      "epoch:40 step:31879 [D loss: 0.194872, acc: 98.44%] [G loss: 5.389414]\n",
      "epoch:40 step:31880 [D loss: 0.773528, acc: 57.03%] [G loss: 4.716539]\n",
      "epoch:40 step:31881 [D loss: 0.020363, acc: 100.00%] [G loss: 5.947569]\n",
      "epoch:40 step:31882 [D loss: 1.549973, acc: 50.00%] [G loss: 4.261980]\n",
      "epoch:40 step:31883 [D loss: 0.180475, acc: 95.31%] [G loss: 6.835035]\n",
      "epoch:40 step:31884 [D loss: 0.806872, acc: 45.31%] [G loss: 4.955190]\n",
      "epoch:40 step:31885 [D loss: 0.140755, acc: 97.66%] [G loss: 5.132663]\n",
      "epoch:40 step:31886 [D loss: 0.260263, acc: 95.31%] [G loss: 4.805974]\n",
      "epoch:40 step:31887 [D loss: 0.712361, acc: 57.81%] [G loss: 7.773443]\n",
      "epoch:40 step:31888 [D loss: 0.571748, acc: 58.59%] [G loss: 4.227721]\n",
      "epoch:40 step:31889 [D loss: 0.290977, acc: 89.06%] [G loss: 6.370484]\n",
      "epoch:40 step:31890 [D loss: 0.891321, acc: 50.00%] [G loss: 5.944602]\n",
      "epoch:40 step:31891 [D loss: 0.247704, acc: 89.84%] [G loss: 7.862737]\n",
      "epoch:40 step:31892 [D loss: 0.249780, acc: 91.41%] [G loss: 5.680370]\n",
      "epoch:40 step:31893 [D loss: 0.031709, acc: 100.00%] [G loss: 6.577640]\n",
      "epoch:40 step:31894 [D loss: 0.194978, acc: 99.22%] [G loss: 8.223793]\n",
      "epoch:40 step:31895 [D loss: 0.031311, acc: 100.00%] [G loss: 8.863404]\n",
      "epoch:40 step:31896 [D loss: 0.597963, acc: 65.62%] [G loss: 4.732980]\n",
      "epoch:40 step:31897 [D loss: 0.347719, acc: 91.41%] [G loss: 5.768195]\n",
      "epoch:40 step:31898 [D loss: 0.082762, acc: 100.00%] [G loss: 5.672568]\n",
      "epoch:40 step:31899 [D loss: 0.236550, acc: 92.97%] [G loss: 7.340339]\n",
      "epoch:40 step:31900 [D loss: 0.354182, acc: 90.62%] [G loss: 4.736803]\n",
      "epoch:40 step:31901 [D loss: 0.390282, acc: 87.50%] [G loss: 6.750075]\n",
      "epoch:40 step:31902 [D loss: 0.186284, acc: 96.88%] [G loss: 6.928026]\n",
      "epoch:40 step:31903 [D loss: 0.416615, acc: 75.00%] [G loss: 6.633008]\n",
      "epoch:40 step:31904 [D loss: 0.129613, acc: 99.22%] [G loss: 5.721948]\n",
      "epoch:40 step:31905 [D loss: 0.503580, acc: 72.66%] [G loss: 3.602212]\n",
      "epoch:40 step:31906 [D loss: 0.417638, acc: 79.69%] [G loss: 8.589691]\n",
      "epoch:40 step:31907 [D loss: 0.124562, acc: 100.00%] [G loss: 5.281003]\n",
      "epoch:40 step:31908 [D loss: 0.054816, acc: 100.00%] [G loss: 5.484538]\n",
      "epoch:40 step:31909 [D loss: 0.144830, acc: 99.22%] [G loss: 5.963561]\n",
      "epoch:40 step:31910 [D loss: 0.149292, acc: 100.00%] [G loss: 7.657118]\n",
      "epoch:40 step:31911 [D loss: 0.058820, acc: 100.00%] [G loss: 4.024993]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31912 [D loss: 0.279386, acc: 90.62%] [G loss: 5.947335]\n",
      "epoch:40 step:31913 [D loss: 0.065471, acc: 100.00%] [G loss: 3.784560]\n",
      "epoch:40 step:31914 [D loss: 0.231482, acc: 94.53%] [G loss: 7.533196]\n",
      "epoch:40 step:31915 [D loss: 0.050587, acc: 100.00%] [G loss: 6.517579]\n",
      "epoch:40 step:31916 [D loss: 0.336428, acc: 87.50%] [G loss: 4.345853]\n",
      "epoch:40 step:31917 [D loss: 0.261271, acc: 91.41%] [G loss: 4.375543]\n",
      "epoch:40 step:31918 [D loss: 0.556716, acc: 74.22%] [G loss: 6.301241]\n",
      "epoch:40 step:31919 [D loss: 0.327983, acc: 83.59%] [G loss: 5.644745]\n",
      "epoch:40 step:31920 [D loss: 0.493570, acc: 63.28%] [G loss: 5.204061]\n",
      "epoch:40 step:31921 [D loss: 0.123514, acc: 99.22%] [G loss: 4.441649]\n",
      "epoch:40 step:31922 [D loss: 0.044704, acc: 100.00%] [G loss: 4.280972]\n",
      "epoch:40 step:31923 [D loss: 0.221731, acc: 98.44%] [G loss: 4.052100]\n",
      "epoch:40 step:31924 [D loss: 0.554360, acc: 70.31%] [G loss: 5.901597]\n",
      "epoch:40 step:31925 [D loss: 0.340461, acc: 82.81%] [G loss: 3.976938]\n",
      "epoch:40 step:31926 [D loss: 0.742678, acc: 57.81%] [G loss: 6.631540]\n",
      "epoch:40 step:31927 [D loss: 0.598491, acc: 69.53%] [G loss: 3.796881]\n",
      "epoch:40 step:31928 [D loss: 0.431374, acc: 87.50%] [G loss: 5.868433]\n",
      "epoch:40 step:31929 [D loss: 0.407912, acc: 71.88%] [G loss: 5.618639]\n",
      "epoch:40 step:31930 [D loss: 1.621757, acc: 50.00%] [G loss: 6.522506]\n",
      "epoch:40 step:31931 [D loss: 0.047106, acc: 100.00%] [G loss: 5.113456]\n",
      "epoch:40 step:31932 [D loss: 1.503377, acc: 50.00%] [G loss: 5.783286]\n",
      "epoch:40 step:31933 [D loss: 0.114645, acc: 100.00%] [G loss: 3.016014]\n",
      "epoch:40 step:31934 [D loss: 0.310363, acc: 91.41%] [G loss: 6.010278]\n",
      "epoch:40 step:31935 [D loss: 0.748518, acc: 52.34%] [G loss: 5.183914]\n",
      "epoch:40 step:31936 [D loss: 0.416674, acc: 69.53%] [G loss: 7.865328]\n",
      "epoch:40 step:31937 [D loss: 0.817184, acc: 50.78%] [G loss: 6.927414]\n",
      "epoch:40 step:31938 [D loss: 0.262081, acc: 97.66%] [G loss: 5.836084]\n",
      "epoch:40 step:31939 [D loss: 0.608513, acc: 62.50%] [G loss: 6.119607]\n",
      "epoch:40 step:31940 [D loss: 1.023495, acc: 51.56%] [G loss: 7.369450]\n",
      "epoch:40 step:31941 [D loss: 0.490270, acc: 78.12%] [G loss: 5.311856]\n",
      "epoch:40 step:31942 [D loss: 0.855447, acc: 49.22%] [G loss: 6.198254]\n",
      "epoch:40 step:31943 [D loss: 0.121727, acc: 96.88%] [G loss: 3.353180]\n",
      "epoch:40 step:31944 [D loss: 0.388494, acc: 87.50%] [G loss: 5.575837]\n",
      "epoch:40 step:31945 [D loss: 0.343852, acc: 88.28%] [G loss: 4.518731]\n",
      "epoch:40 step:31946 [D loss: 0.037885, acc: 100.00%] [G loss: 6.106320]\n",
      "epoch:40 step:31947 [D loss: 0.419453, acc: 77.34%] [G loss: 8.253423]\n",
      "epoch:40 step:31948 [D loss: 0.237815, acc: 95.31%] [G loss: 3.542922]\n",
      "epoch:40 step:31949 [D loss: 0.639224, acc: 56.25%] [G loss: 5.887099]\n",
      "epoch:40 step:31950 [D loss: 0.506118, acc: 74.22%] [G loss: 5.410292]\n",
      "epoch:40 step:31951 [D loss: 0.331584, acc: 86.72%] [G loss: 9.470528]\n",
      "epoch:40 step:31952 [D loss: 0.593918, acc: 60.16%] [G loss: 6.777152]\n",
      "epoch:40 step:31953 [D loss: 0.168072, acc: 96.88%] [G loss: 5.081232]\n",
      "epoch:40 step:31954 [D loss: 0.421546, acc: 82.81%] [G loss: 5.136158]\n",
      "epoch:40 step:31955 [D loss: 0.386945, acc: 74.22%] [G loss: 3.828757]\n",
      "epoch:40 step:31956 [D loss: 0.307573, acc: 92.97%] [G loss: 6.161919]\n",
      "epoch:40 step:31957 [D loss: 0.085106, acc: 100.00%] [G loss: 5.567735]\n",
      "epoch:40 step:31958 [D loss: 0.038846, acc: 99.22%] [G loss: 7.592875]\n",
      "epoch:40 step:31959 [D loss: 0.062529, acc: 99.22%] [G loss: 4.568673]\n",
      "epoch:40 step:31960 [D loss: 0.209391, acc: 94.53%] [G loss: 6.579865]\n",
      "epoch:40 step:31961 [D loss: 0.120788, acc: 98.44%] [G loss: 7.640646]\n",
      "epoch:40 step:31962 [D loss: 0.314877, acc: 92.97%] [G loss: 6.368750]\n",
      "epoch:40 step:31963 [D loss: 0.145531, acc: 100.00%] [G loss: 5.449456]\n",
      "epoch:40 step:31964 [D loss: 0.401600, acc: 86.72%] [G loss: 8.729045]\n",
      "epoch:40 step:31965 [D loss: 0.063570, acc: 100.00%] [G loss: 7.085017]\n",
      "epoch:40 step:31966 [D loss: 0.313542, acc: 82.81%] [G loss: 8.059001]\n",
      "epoch:40 step:31967 [D loss: 0.159221, acc: 96.88%] [G loss: 5.378832]\n",
      "epoch:40 step:31968 [D loss: 1.046828, acc: 50.78%] [G loss: 5.422833]\n",
      "epoch:40 step:31969 [D loss: 0.743872, acc: 54.69%] [G loss: 7.678884]\n",
      "epoch:40 step:31970 [D loss: 0.739149, acc: 58.59%] [G loss: 8.534317]\n",
      "epoch:40 step:31971 [D loss: 0.081034, acc: 100.00%] [G loss: 4.841383]\n",
      "epoch:40 step:31972 [D loss: 0.537787, acc: 64.06%] [G loss: 6.475471]\n",
      "epoch:40 step:31973 [D loss: 0.120528, acc: 98.44%] [G loss: 3.263851]\n",
      "epoch:40 step:31974 [D loss: 1.170998, acc: 46.88%] [G loss: 9.722298]\n",
      "epoch:40 step:31975 [D loss: 0.145685, acc: 100.00%] [G loss: 7.687497]\n",
      "epoch:40 step:31976 [D loss: 0.066506, acc: 99.22%] [G loss: 7.044606]\n",
      "epoch:40 step:31977 [D loss: 0.133250, acc: 100.00%] [G loss: 5.749928]\n",
      "epoch:40 step:31978 [D loss: 0.136374, acc: 99.22%] [G loss: 4.892794]\n",
      "epoch:40 step:31979 [D loss: 0.257707, acc: 97.66%] [G loss: 6.858391]\n",
      "epoch:40 step:31980 [D loss: 0.971782, acc: 50.00%] [G loss: 6.902719]\n",
      "epoch:40 step:31981 [D loss: 0.081825, acc: 100.00%] [G loss: 5.903418]\n",
      "epoch:40 step:31982 [D loss: 0.842767, acc: 51.56%] [G loss: 4.775173]\n",
      "epoch:40 step:31983 [D loss: 0.055694, acc: 100.00%] [G loss: 5.887670]\n",
      "epoch:40 step:31984 [D loss: 0.214315, acc: 96.09%] [G loss: 5.412959]\n",
      "epoch:40 step:31985 [D loss: 0.494764, acc: 67.97%] [G loss: 6.636528]\n",
      "epoch:40 step:31986 [D loss: 0.576556, acc: 67.97%] [G loss: 6.100647]\n",
      "epoch:40 step:31987 [D loss: 0.193296, acc: 97.66%] [G loss: 6.383374]\n",
      "epoch:40 step:31988 [D loss: 0.037746, acc: 100.00%] [G loss: 5.011771]\n",
      "epoch:40 step:31989 [D loss: 0.471060, acc: 64.84%] [G loss: 8.415247]\n",
      "epoch:40 step:31990 [D loss: 0.145063, acc: 100.00%] [G loss: 3.637225]\n",
      "epoch:40 step:31991 [D loss: 2.133161, acc: 50.00%] [G loss: 6.315927]\n",
      "epoch:40 step:31992 [D loss: 0.111579, acc: 98.44%] [G loss: 4.354032]\n",
      "epoch:40 step:31993 [D loss: 0.383916, acc: 78.91%] [G loss: 4.731803]\n",
      "epoch:40 step:31994 [D loss: 0.057993, acc: 100.00%] [G loss: 3.112251]\n",
      "epoch:40 step:31995 [D loss: 0.057709, acc: 100.00%] [G loss: 7.702227]\n",
      "epoch:40 step:31996 [D loss: 0.066907, acc: 100.00%] [G loss: 4.452088]\n",
      "epoch:40 step:31997 [D loss: 0.765646, acc: 51.56%] [G loss: 3.749082]\n",
      "epoch:40 step:31998 [D loss: 1.097453, acc: 31.25%] [G loss: 3.355102]\n",
      "epoch:40 step:31999 [D loss: 0.462199, acc: 78.91%] [G loss: 5.031413]\n",
      "epoch:40 step:32000 [D loss: 0.159301, acc: 96.88%] [G loss: 8.752796]\n",
      "epoch:40 step:32001 [D loss: 0.036985, acc: 100.00%] [G loss: 7.030200]\n",
      "epoch:40 step:32002 [D loss: 0.711277, acc: 53.91%] [G loss: 7.528619]\n",
      "epoch:40 step:32003 [D loss: 0.651705, acc: 53.91%] [G loss: 7.100933]\n",
      "epoch:40 step:32004 [D loss: 1.744728, acc: 46.88%] [G loss: 6.038884]\n",
      "epoch:40 step:32005 [D loss: 0.088673, acc: 100.00%] [G loss: 5.461866]\n",
      "epoch:40 step:32006 [D loss: 0.126855, acc: 99.22%] [G loss: 5.618604]\n",
      "epoch:40 step:32007 [D loss: 0.045743, acc: 100.00%] [G loss: 6.098208]\n",
      "epoch:40 step:32008 [D loss: 0.013329, acc: 100.00%] [G loss: 7.800303]\n",
      "epoch:40 step:32009 [D loss: 0.065451, acc: 100.00%] [G loss: 4.270877]\n",
      "epoch:40 step:32010 [D loss: 0.268698, acc: 92.97%] [G loss: 3.455348]\n",
      "epoch:40 step:32011 [D loss: 0.215612, acc: 95.31%] [G loss: 4.383485]\n",
      "epoch:40 step:32012 [D loss: 0.220679, acc: 94.53%] [G loss: 3.218002]\n",
      "epoch:40 step:32013 [D loss: 0.479817, acc: 68.75%] [G loss: 5.253358]\n",
      "epoch:40 step:32014 [D loss: 0.267637, acc: 86.72%] [G loss: 10.119576]\n",
      "epoch:40 step:32015 [D loss: 0.545363, acc: 67.19%] [G loss: 6.451017]\n",
      "epoch:40 step:32016 [D loss: 0.388677, acc: 76.56%] [G loss: 6.964850]\n",
      "epoch:40 step:32017 [D loss: 0.146876, acc: 96.88%] [G loss: 5.211184]\n",
      "epoch:40 step:32018 [D loss: 0.089661, acc: 99.22%] [G loss: 5.268805]\n",
      "epoch:40 step:32019 [D loss: 0.578116, acc: 59.38%] [G loss: 5.311215]\n",
      "epoch:40 step:32020 [D loss: 0.832735, acc: 45.31%] [G loss: 2.208909]\n",
      "epoch:40 step:32021 [D loss: 0.203160, acc: 95.31%] [G loss: 6.526918]\n",
      "epoch:41 step:32022 [D loss: 0.064285, acc: 100.00%] [G loss: 6.767519]\n",
      "epoch:41 step:32023 [D loss: 0.019642, acc: 100.00%] [G loss: 7.197068]\n",
      "epoch:41 step:32024 [D loss: 0.294347, acc: 91.41%] [G loss: 6.300009]\n",
      "epoch:41 step:32025 [D loss: 0.398258, acc: 76.56%] [G loss: 3.954603]\n",
      "epoch:41 step:32026 [D loss: 0.591322, acc: 62.50%] [G loss: 4.241389]\n",
      "epoch:41 step:32027 [D loss: 0.863319, acc: 50.78%] [G loss: 4.493414]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32028 [D loss: 1.138580, acc: 50.00%] [G loss: 7.184792]\n",
      "epoch:41 step:32029 [D loss: 0.303770, acc: 87.50%] [G loss: 10.145927]\n",
      "epoch:41 step:32030 [D loss: 0.390561, acc: 76.56%] [G loss: 8.284374]\n",
      "epoch:41 step:32031 [D loss: 0.616206, acc: 67.19%] [G loss: 5.230933]\n",
      "epoch:41 step:32032 [D loss: 0.375456, acc: 85.16%] [G loss: 4.280536]\n",
      "epoch:41 step:32033 [D loss: 0.237032, acc: 95.31%] [G loss: 5.980247]\n",
      "epoch:41 step:32034 [D loss: 0.457086, acc: 79.69%] [G loss: 6.705080]\n",
      "epoch:41 step:32035 [D loss: 0.859889, acc: 54.69%] [G loss: 6.825082]\n",
      "epoch:41 step:32036 [D loss: 0.248250, acc: 96.09%] [G loss: 4.147837]\n",
      "epoch:41 step:32037 [D loss: 0.096766, acc: 100.00%] [G loss: 5.730387]\n",
      "epoch:41 step:32038 [D loss: 0.658208, acc: 57.03%] [G loss: 6.028064]\n",
      "epoch:41 step:32039 [D loss: 0.235684, acc: 96.09%] [G loss: 6.100727]\n",
      "epoch:41 step:32040 [D loss: 0.648242, acc: 66.41%] [G loss: 6.045252]\n",
      "epoch:41 step:32041 [D loss: 0.136233, acc: 98.44%] [G loss: 3.818986]\n",
      "epoch:41 step:32042 [D loss: 0.152881, acc: 99.22%] [G loss: 1.886458]\n",
      "epoch:41 step:32043 [D loss: 0.163781, acc: 99.22%] [G loss: 9.173212]\n",
      "epoch:41 step:32044 [D loss: 0.064374, acc: 99.22%] [G loss: 4.056694]\n",
      "epoch:41 step:32045 [D loss: 0.182803, acc: 96.88%] [G loss: 5.080526]\n",
      "epoch:41 step:32046 [D loss: 0.294490, acc: 89.06%] [G loss: 3.434205]\n",
      "epoch:41 step:32047 [D loss: 0.424617, acc: 85.16%] [G loss: 4.298973]\n",
      "epoch:41 step:32048 [D loss: 0.328673, acc: 92.19%] [G loss: 4.506663]\n",
      "epoch:41 step:32049 [D loss: 0.945973, acc: 52.34%] [G loss: 5.716053]\n",
      "epoch:41 step:32050 [D loss: 0.619575, acc: 66.41%] [G loss: 7.518012]\n",
      "epoch:41 step:32051 [D loss: 0.367405, acc: 85.94%] [G loss: 8.323231]\n",
      "epoch:41 step:32052 [D loss: 0.170996, acc: 95.31%] [G loss: 7.146657]\n",
      "epoch:41 step:32053 [D loss: 0.211224, acc: 95.31%] [G loss: 1.592168]\n",
      "epoch:41 step:32054 [D loss: 0.220900, acc: 98.44%] [G loss: 8.528719]\n",
      "epoch:41 step:32055 [D loss: 0.562182, acc: 71.09%] [G loss: 6.238458]\n",
      "epoch:41 step:32056 [D loss: 0.698477, acc: 55.47%] [G loss: 8.281121]\n",
      "epoch:41 step:32057 [D loss: 0.102267, acc: 99.22%] [G loss: 6.452546]\n",
      "epoch:41 step:32058 [D loss: 0.492328, acc: 72.66%] [G loss: 3.040498]\n",
      "epoch:41 step:32059 [D loss: 0.646955, acc: 66.41%] [G loss: 7.883542]\n",
      "epoch:41 step:32060 [D loss: 0.384179, acc: 79.69%] [G loss: 7.244293]\n",
      "epoch:41 step:32061 [D loss: 0.644442, acc: 62.50%] [G loss: 6.504849]\n",
      "epoch:41 step:32062 [D loss: 0.114548, acc: 99.22%] [G loss: 7.443183]\n",
      "epoch:41 step:32063 [D loss: 0.369776, acc: 76.56%] [G loss: 4.536133]\n",
      "epoch:41 step:32064 [D loss: 0.019273, acc: 100.00%] [G loss: 5.364397]\n",
      "epoch:41 step:32065 [D loss: 0.504492, acc: 64.06%] [G loss: 6.683794]\n",
      "epoch:41 step:32066 [D loss: 0.151079, acc: 99.22%] [G loss: 5.453402]\n",
      "epoch:41 step:32067 [D loss: 0.928863, acc: 51.56%] [G loss: 5.779034]\n",
      "epoch:41 step:32068 [D loss: 0.225446, acc: 93.75%] [G loss: 3.158733]\n",
      "epoch:41 step:32069 [D loss: 0.058941, acc: 100.00%] [G loss: 3.149013]\n",
      "epoch:41 step:32070 [D loss: 0.460327, acc: 65.62%] [G loss: 8.648759]\n",
      "epoch:41 step:32071 [D loss: 0.599919, acc: 62.50%] [G loss: 6.580980]\n",
      "epoch:41 step:32072 [D loss: 0.068774, acc: 100.00%] [G loss: 4.125083]\n",
      "epoch:41 step:32073 [D loss: 0.095520, acc: 100.00%] [G loss: 6.977877]\n",
      "epoch:41 step:32074 [D loss: 0.100228, acc: 100.00%] [G loss: 6.568421]\n",
      "epoch:41 step:32075 [D loss: 0.056237, acc: 100.00%] [G loss: 9.082167]\n",
      "epoch:41 step:32076 [D loss: 0.045025, acc: 100.00%] [G loss: 6.952127]\n",
      "epoch:41 step:32077 [D loss: 2.111265, acc: 0.00%] [G loss: 5.667601]\n",
      "epoch:41 step:32078 [D loss: 1.109206, acc: 35.16%] [G loss: 2.523695]\n",
      "epoch:41 step:32079 [D loss: 0.071264, acc: 100.00%] [G loss: 3.918463]\n",
      "epoch:41 step:32080 [D loss: 0.418829, acc: 78.12%] [G loss: 6.154469]\n",
      "epoch:41 step:32081 [D loss: 0.269649, acc: 92.97%] [G loss: 5.443391]\n",
      "epoch:41 step:32082 [D loss: 1.024888, acc: 48.44%] [G loss: 8.079137]\n",
      "epoch:41 step:32083 [D loss: 0.030780, acc: 100.00%] [G loss: 4.670947]\n",
      "epoch:41 step:32084 [D loss: 0.723847, acc: 54.69%] [G loss: 5.431256]\n",
      "epoch:41 step:32085 [D loss: 0.186800, acc: 97.66%] [G loss: 8.846613]\n",
      "epoch:41 step:32086 [D loss: 0.214067, acc: 93.75%] [G loss: 6.150737]\n",
      "epoch:41 step:32087 [D loss: 0.153971, acc: 98.44%] [G loss: 3.500053]\n",
      "epoch:41 step:32088 [D loss: 0.670881, acc: 57.03%] [G loss: 2.973847]\n",
      "epoch:41 step:32089 [D loss: 0.515370, acc: 71.88%] [G loss: 5.041882]\n",
      "epoch:41 step:32090 [D loss: 0.177812, acc: 99.22%] [G loss: 3.200534]\n",
      "epoch:41 step:32091 [D loss: 0.555335, acc: 63.28%] [G loss: 3.989698]\n",
      "epoch:41 step:32092 [D loss: 0.472535, acc: 64.06%] [G loss: 7.066594]\n",
      "epoch:41 step:32093 [D loss: 0.776922, acc: 53.91%] [G loss: 4.621543]\n",
      "epoch:41 step:32094 [D loss: 0.152598, acc: 96.88%] [G loss: 5.363887]\n",
      "epoch:41 step:32095 [D loss: 0.185419, acc: 96.88%] [G loss: 5.380992]\n",
      "epoch:41 step:32096 [D loss: 0.062450, acc: 100.00%] [G loss: 5.016607]\n",
      "epoch:41 step:32097 [D loss: 0.224017, acc: 96.88%] [G loss: 3.727669]\n",
      "epoch:41 step:32098 [D loss: 0.219591, acc: 97.66%] [G loss: 5.073728]\n",
      "epoch:41 step:32099 [D loss: 0.183818, acc: 99.22%] [G loss: 3.458242]\n",
      "epoch:41 step:32100 [D loss: 0.147791, acc: 97.66%] [G loss: 5.947339]\n",
      "epoch:41 step:32101 [D loss: 0.560588, acc: 67.97%] [G loss: 5.130637]\n",
      "epoch:41 step:32102 [D loss: 0.107867, acc: 100.00%] [G loss: 6.056658]\n",
      "epoch:41 step:32103 [D loss: 0.908195, acc: 50.00%] [G loss: 4.045076]\n",
      "epoch:41 step:32104 [D loss: 0.599835, acc: 60.16%] [G loss: 8.031349]\n",
      "epoch:41 step:32105 [D loss: 0.080960, acc: 100.00%] [G loss: 3.958103]\n",
      "epoch:41 step:32106 [D loss: 0.186051, acc: 99.22%] [G loss: 5.923519]\n",
      "epoch:41 step:32107 [D loss: 0.222167, acc: 96.88%] [G loss: 2.877071]\n",
      "epoch:41 step:32108 [D loss: 0.470743, acc: 71.88%] [G loss: 7.238312]\n",
      "epoch:41 step:32109 [D loss: 0.404370, acc: 75.00%] [G loss: 6.034995]\n",
      "epoch:41 step:32110 [D loss: 0.292559, acc: 92.97%] [G loss: 6.847143]\n",
      "epoch:41 step:32111 [D loss: 0.160667, acc: 98.44%] [G loss: 4.744842]\n",
      "epoch:41 step:32112 [D loss: 0.462234, acc: 73.44%] [G loss: 5.272078]\n",
      "epoch:41 step:32113 [D loss: 0.132248, acc: 97.66%] [G loss: 1.967048]\n",
      "epoch:41 step:32114 [D loss: 0.529063, acc: 61.72%] [G loss: 7.338553]\n",
      "epoch:41 step:32115 [D loss: 0.248355, acc: 95.31%] [G loss: 3.889643]\n",
      "epoch:41 step:32116 [D loss: 0.549467, acc: 71.88%] [G loss: 4.295292]\n",
      "epoch:41 step:32117 [D loss: 0.078416, acc: 100.00%] [G loss: 7.190429]\n",
      "epoch:41 step:32118 [D loss: 0.902102, acc: 33.59%] [G loss: 5.474514]\n",
      "epoch:41 step:32119 [D loss: 0.423900, acc: 82.81%] [G loss: 3.932700]\n",
      "epoch:41 step:32120 [D loss: 0.257281, acc: 88.28%] [G loss: 9.057962]\n",
      "epoch:41 step:32121 [D loss: 0.054352, acc: 100.00%] [G loss: 4.814335]\n",
      "epoch:41 step:32122 [D loss: 0.041969, acc: 100.00%] [G loss: 5.545377]\n",
      "epoch:41 step:32123 [D loss: 0.397055, acc: 82.03%] [G loss: 2.841607]\n",
      "epoch:41 step:32124 [D loss: 0.242077, acc: 96.09%] [G loss: 4.313324]\n",
      "epoch:41 step:32125 [D loss: 0.805242, acc: 50.00%] [G loss: 3.706329]\n",
      "epoch:41 step:32126 [D loss: 0.158436, acc: 96.88%] [G loss: 5.007998]\n",
      "epoch:41 step:32127 [D loss: 0.338028, acc: 83.59%] [G loss: 4.956649]\n",
      "epoch:41 step:32128 [D loss: 0.287401, acc: 86.72%] [G loss: 4.908165]\n",
      "epoch:41 step:32129 [D loss: 0.286723, acc: 84.38%] [G loss: 4.820033]\n",
      "epoch:41 step:32130 [D loss: 0.803438, acc: 50.78%] [G loss: 4.244257]\n",
      "epoch:41 step:32131 [D loss: 0.670534, acc: 59.38%] [G loss: 9.091142]\n",
      "epoch:41 step:32132 [D loss: 0.454056, acc: 85.16%] [G loss: 4.041206]\n",
      "epoch:41 step:32133 [D loss: 0.622738, acc: 63.28%] [G loss: 6.265106]\n",
      "epoch:41 step:32134 [D loss: 0.374102, acc: 89.84%] [G loss: 6.306313]\n",
      "epoch:41 step:32135 [D loss: 0.051286, acc: 100.00%] [G loss: 7.785256]\n",
      "epoch:41 step:32136 [D loss: 0.446172, acc: 79.69%] [G loss: 4.064471]\n",
      "epoch:41 step:32137 [D loss: 0.777381, acc: 52.34%] [G loss: 6.070597]\n",
      "epoch:41 step:32138 [D loss: 0.095879, acc: 100.00%] [G loss: 8.697607]\n",
      "epoch:41 step:32139 [D loss: 0.287244, acc: 92.19%] [G loss: 7.457475]\n",
      "epoch:41 step:32140 [D loss: 0.454008, acc: 80.47%] [G loss: 5.352832]\n",
      "epoch:41 step:32141 [D loss: 1.321180, acc: 31.25%] [G loss: 6.808802]\n",
      "epoch:41 step:32142 [D loss: 0.562412, acc: 59.38%] [G loss: 6.322219]\n",
      "epoch:41 step:32143 [D loss: 0.014492, acc: 100.00%] [G loss: 8.019678]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32144 [D loss: 0.665581, acc: 64.06%] [G loss: 4.980883]\n",
      "epoch:41 step:32145 [D loss: 0.023377, acc: 100.00%] [G loss: 9.416438]\n",
      "epoch:41 step:32146 [D loss: 0.771912, acc: 57.03%] [G loss: 6.323071]\n",
      "epoch:41 step:32147 [D loss: 0.118137, acc: 100.00%] [G loss: 6.540737]\n",
      "epoch:41 step:32148 [D loss: 0.374409, acc: 81.25%] [G loss: 8.340823]\n",
      "epoch:41 step:32149 [D loss: 0.051367, acc: 100.00%] [G loss: 5.744003]\n",
      "epoch:41 step:32150 [D loss: 0.031729, acc: 100.00%] [G loss: 6.963542]\n",
      "epoch:41 step:32151 [D loss: 0.599709, acc: 61.72%] [G loss: 5.869201]\n",
      "epoch:41 step:32152 [D loss: 0.020363, acc: 100.00%] [G loss: 5.818760]\n",
      "epoch:41 step:32153 [D loss: 0.953464, acc: 42.97%] [G loss: 5.177301]\n",
      "epoch:41 step:32154 [D loss: 1.402420, acc: 36.72%] [G loss: 4.578983]\n",
      "epoch:41 step:32155 [D loss: 0.234846, acc: 93.75%] [G loss: 4.667504]\n",
      "epoch:41 step:32156 [D loss: 0.186784, acc: 98.44%] [G loss: 8.138231]\n",
      "epoch:41 step:32157 [D loss: 0.316261, acc: 84.38%] [G loss: 5.733443]\n",
      "epoch:41 step:32158 [D loss: 1.054493, acc: 30.47%] [G loss: 7.451591]\n",
      "epoch:41 step:32159 [D loss: 0.112360, acc: 98.44%] [G loss: 8.723845]\n",
      "epoch:41 step:32160 [D loss: 0.810649, acc: 52.34%] [G loss: 7.859723]\n",
      "epoch:41 step:32161 [D loss: 0.386511, acc: 83.59%] [G loss: 3.041362]\n",
      "epoch:41 step:32162 [D loss: 0.310511, acc: 89.84%] [G loss: 5.618245]\n",
      "epoch:41 step:32163 [D loss: 0.346956, acc: 78.91%] [G loss: 3.864211]\n",
      "epoch:41 step:32164 [D loss: 0.085079, acc: 100.00%] [G loss: 3.238665]\n",
      "epoch:41 step:32165 [D loss: 0.164188, acc: 97.66%] [G loss: 7.464029]\n",
      "epoch:41 step:32166 [D loss: 0.118403, acc: 100.00%] [G loss: 4.277742]\n",
      "epoch:41 step:32167 [D loss: 0.264146, acc: 95.31%] [G loss: 8.160760]\n",
      "epoch:41 step:32168 [D loss: 0.385212, acc: 89.06%] [G loss: 3.059426]\n",
      "epoch:41 step:32169 [D loss: 0.086777, acc: 100.00%] [G loss: 5.910665]\n",
      "epoch:41 step:32170 [D loss: 0.616993, acc: 62.50%] [G loss: 8.033552]\n",
      "epoch:41 step:32171 [D loss: 0.139272, acc: 97.66%] [G loss: 6.319656]\n",
      "epoch:41 step:32172 [D loss: 0.487839, acc: 64.84%] [G loss: 6.983341]\n",
      "epoch:41 step:32173 [D loss: 0.510716, acc: 64.06%] [G loss: 8.415689]\n",
      "epoch:41 step:32174 [D loss: 0.069016, acc: 100.00%] [G loss: 3.318044]\n",
      "epoch:41 step:32175 [D loss: 0.478487, acc: 77.34%] [G loss: 4.211453]\n",
      "epoch:41 step:32176 [D loss: 0.192980, acc: 96.09%] [G loss: 7.401048]\n",
      "epoch:41 step:32177 [D loss: 0.121721, acc: 97.66%] [G loss: 4.605087]\n",
      "epoch:41 step:32178 [D loss: 0.452164, acc: 73.44%] [G loss: 5.261650]\n",
      "epoch:41 step:32179 [D loss: 0.271509, acc: 89.84%] [G loss: 5.600637]\n",
      "epoch:41 step:32180 [D loss: 0.068400, acc: 100.00%] [G loss: 3.220940]\n",
      "epoch:41 step:32181 [D loss: 0.573131, acc: 61.72%] [G loss: 5.565510]\n",
      "epoch:41 step:32182 [D loss: 0.107387, acc: 99.22%] [G loss: 6.261135]\n",
      "epoch:41 step:32183 [D loss: 0.339653, acc: 86.72%] [G loss: 2.740148]\n",
      "epoch:41 step:32184 [D loss: 0.433559, acc: 82.03%] [G loss: 4.999635]\n",
      "epoch:41 step:32185 [D loss: 0.114066, acc: 98.44%] [G loss: 3.999918]\n",
      "epoch:41 step:32186 [D loss: 0.013411, acc: 100.00%] [G loss: 9.340153]\n",
      "epoch:41 step:32187 [D loss: 0.321340, acc: 92.19%] [G loss: 6.308601]\n",
      "epoch:41 step:32188 [D loss: 0.126619, acc: 99.22%] [G loss: 4.972470]\n",
      "epoch:41 step:32189 [D loss: 0.564156, acc: 69.53%] [G loss: 6.110987]\n",
      "epoch:41 step:32190 [D loss: 0.395610, acc: 74.22%] [G loss: 6.787257]\n",
      "epoch:41 step:32191 [D loss: 0.355256, acc: 91.41%] [G loss: 6.387528]\n",
      "epoch:41 step:32192 [D loss: 0.232329, acc: 92.19%] [G loss: 4.000836]\n",
      "epoch:41 step:32193 [D loss: 0.045783, acc: 100.00%] [G loss: 7.666237]\n",
      "epoch:41 step:32194 [D loss: 0.387719, acc: 80.47%] [G loss: 4.986653]\n",
      "epoch:41 step:32195 [D loss: 0.075668, acc: 100.00%] [G loss: 7.553887]\n",
      "epoch:41 step:32196 [D loss: 0.233169, acc: 91.41%] [G loss: 7.029926]\n",
      "epoch:41 step:32197 [D loss: 0.088836, acc: 100.00%] [G loss: 4.617695]\n",
      "epoch:41 step:32198 [D loss: 0.445709, acc: 83.59%] [G loss: 7.855187]\n",
      "epoch:41 step:32199 [D loss: 0.186608, acc: 97.66%] [G loss: 3.126770]\n",
      "epoch:41 step:32200 [D loss: 0.443383, acc: 77.34%] [G loss: 6.412835]\n",
      "epoch:41 step:32201 [D loss: 0.172503, acc: 100.00%] [G loss: 5.669371]\n",
      "epoch:41 step:32202 [D loss: 1.438189, acc: 50.00%] [G loss: 6.944545]\n",
      "epoch:41 step:32203 [D loss: 0.140649, acc: 96.88%] [G loss: 4.665016]\n",
      "epoch:41 step:32204 [D loss: 1.804450, acc: 48.44%] [G loss: 9.931682]\n",
      "epoch:41 step:32205 [D loss: 0.153212, acc: 97.66%] [G loss: 4.830567]\n",
      "epoch:41 step:32206 [D loss: 0.108540, acc: 99.22%] [G loss: 7.677931]\n",
      "epoch:41 step:32207 [D loss: 0.360498, acc: 87.50%] [G loss: 4.990163]\n",
      "epoch:41 step:32208 [D loss: 0.355029, acc: 91.41%] [G loss: 7.802189]\n",
      "epoch:41 step:32209 [D loss: 0.026426, acc: 100.00%] [G loss: 5.442364]\n",
      "epoch:41 step:32210 [D loss: 0.026701, acc: 100.00%] [G loss: 5.626280]\n",
      "epoch:41 step:32211 [D loss: 0.103520, acc: 99.22%] [G loss: 6.019391]\n",
      "epoch:41 step:32212 [D loss: 0.919404, acc: 41.41%] [G loss: 7.645551]\n",
      "epoch:41 step:32213 [D loss: 0.188400, acc: 96.09%] [G loss: 6.146801]\n",
      "epoch:41 step:32214 [D loss: 0.121486, acc: 98.44%] [G loss: 3.044157]\n",
      "epoch:41 step:32215 [D loss: 0.793780, acc: 52.34%] [G loss: 6.431357]\n",
      "epoch:41 step:32216 [D loss: 0.043349, acc: 100.00%] [G loss: 5.336563]\n",
      "epoch:41 step:32217 [D loss: 0.441006, acc: 81.25%] [G loss: 3.827606]\n",
      "epoch:41 step:32218 [D loss: 0.039022, acc: 100.00%] [G loss: 5.166072]\n",
      "epoch:41 step:32219 [D loss: 0.116867, acc: 98.44%] [G loss: 5.861799]\n",
      "epoch:41 step:32220 [D loss: 0.171164, acc: 100.00%] [G loss: 9.962257]\n",
      "epoch:41 step:32221 [D loss: 0.107306, acc: 100.00%] [G loss: 6.286555]\n",
      "epoch:41 step:32222 [D loss: 0.343710, acc: 88.28%] [G loss: 3.714275]\n",
      "epoch:41 step:32223 [D loss: 0.657362, acc: 59.38%] [G loss: 6.809698]\n",
      "epoch:41 step:32224 [D loss: 0.570174, acc: 61.72%] [G loss: 6.084802]\n",
      "epoch:41 step:32225 [D loss: 0.477160, acc: 75.00%] [G loss: 7.123564]\n",
      "epoch:41 step:32226 [D loss: 0.501589, acc: 65.62%] [G loss: 7.570529]\n",
      "epoch:41 step:32227 [D loss: 0.224301, acc: 96.09%] [G loss: 5.671577]\n",
      "epoch:41 step:32228 [D loss: 0.374176, acc: 78.12%] [G loss: 4.544513]\n",
      "epoch:41 step:32229 [D loss: 0.227263, acc: 94.53%] [G loss: 6.781765]\n",
      "epoch:41 step:32230 [D loss: 0.120418, acc: 99.22%] [G loss: 4.485852]\n",
      "epoch:41 step:32231 [D loss: 0.258538, acc: 89.84%] [G loss: 6.856102]\n",
      "epoch:41 step:32232 [D loss: 0.328593, acc: 89.06%] [G loss: 4.050983]\n",
      "epoch:41 step:32233 [D loss: 0.189992, acc: 95.31%] [G loss: 5.720887]\n",
      "epoch:41 step:32234 [D loss: 0.420995, acc: 83.59%] [G loss: 7.031455]\n",
      "epoch:41 step:32235 [D loss: 0.112328, acc: 99.22%] [G loss: 9.763433]\n",
      "epoch:41 step:32236 [D loss: 0.388368, acc: 87.50%] [G loss: 5.613448]\n",
      "epoch:41 step:32237 [D loss: 0.112629, acc: 99.22%] [G loss: 5.922598]\n",
      "epoch:41 step:32238 [D loss: 0.300831, acc: 88.28%] [G loss: 3.568293]\n",
      "epoch:41 step:32239 [D loss: 0.124024, acc: 96.88%] [G loss: 5.548424]\n",
      "epoch:41 step:32240 [D loss: 0.301351, acc: 83.59%] [G loss: 6.236874]\n",
      "epoch:41 step:32241 [D loss: 0.578049, acc: 66.41%] [G loss: 4.681545]\n",
      "epoch:41 step:32242 [D loss: 0.666461, acc: 60.16%] [G loss: 3.752901]\n",
      "epoch:41 step:32243 [D loss: 0.241915, acc: 89.06%] [G loss: 4.673191]\n",
      "epoch:41 step:32244 [D loss: 0.749798, acc: 54.69%] [G loss: 3.202442]\n",
      "epoch:41 step:32245 [D loss: 0.993560, acc: 36.72%] [G loss: 3.026474]\n",
      "epoch:41 step:32246 [D loss: 0.086590, acc: 100.00%] [G loss: 5.345902]\n",
      "epoch:41 step:32247 [D loss: 0.278989, acc: 87.50%] [G loss: 11.916494]\n",
      "epoch:41 step:32248 [D loss: 0.055258, acc: 99.22%] [G loss: 6.741968]\n",
      "epoch:41 step:32249 [D loss: 0.059075, acc: 100.00%] [G loss: 3.976563]\n",
      "epoch:41 step:32250 [D loss: 0.361036, acc: 84.38%] [G loss: 5.378253]\n",
      "epoch:41 step:32251 [D loss: 0.088143, acc: 100.00%] [G loss: 3.802737]\n",
      "epoch:41 step:32252 [D loss: 0.594155, acc: 70.31%] [G loss: 6.071805]\n",
      "epoch:41 step:32253 [D loss: 0.036305, acc: 100.00%] [G loss: 7.908552]\n",
      "epoch:41 step:32254 [D loss: 0.859005, acc: 39.84%] [G loss: 5.587149]\n",
      "epoch:41 step:32255 [D loss: 0.545433, acc: 79.69%] [G loss: 8.141136]\n",
      "epoch:41 step:32256 [D loss: 0.183337, acc: 99.22%] [G loss: 6.072945]\n",
      "epoch:41 step:32257 [D loss: 0.539480, acc: 72.66%] [G loss: 7.638689]\n",
      "epoch:41 step:32258 [D loss: 0.180174, acc: 97.66%] [G loss: 4.454640]\n",
      "epoch:41 step:32259 [D loss: 0.910464, acc: 35.94%] [G loss: 5.358543]\n",
      "epoch:41 step:32260 [D loss: 0.260727, acc: 91.41%] [G loss: 4.603313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32261 [D loss: 0.397468, acc: 72.66%] [G loss: 6.743933]\n",
      "epoch:41 step:32262 [D loss: 0.253038, acc: 90.62%] [G loss: 7.557079]\n",
      "epoch:41 step:32263 [D loss: 0.088740, acc: 99.22%] [G loss: 8.105919]\n",
      "epoch:41 step:32264 [D loss: 0.303782, acc: 85.16%] [G loss: 5.254437]\n",
      "epoch:41 step:32265 [D loss: 0.201351, acc: 97.66%] [G loss: 5.775557]\n",
      "epoch:41 step:32266 [D loss: 0.074854, acc: 100.00%] [G loss: 5.100327]\n",
      "epoch:41 step:32267 [D loss: 0.457514, acc: 79.69%] [G loss: 4.461757]\n",
      "epoch:41 step:32268 [D loss: 0.121591, acc: 100.00%] [G loss: 5.512331]\n",
      "epoch:41 step:32269 [D loss: 0.973985, acc: 49.22%] [G loss: 5.046219]\n",
      "epoch:41 step:32270 [D loss: 0.091247, acc: 99.22%] [G loss: 5.251738]\n",
      "epoch:41 step:32271 [D loss: 0.385466, acc: 78.91%] [G loss: 7.497872]\n",
      "epoch:41 step:32272 [D loss: 0.122626, acc: 99.22%] [G loss: 7.102778]\n",
      "epoch:41 step:32273 [D loss: 0.416466, acc: 78.12%] [G loss: 6.382813]\n",
      "epoch:41 step:32274 [D loss: 0.716833, acc: 56.25%] [G loss: 5.483675]\n",
      "epoch:41 step:32275 [D loss: 0.420608, acc: 83.59%] [G loss: 6.926553]\n",
      "epoch:41 step:32276 [D loss: 0.691754, acc: 57.03%] [G loss: 8.029708]\n",
      "epoch:41 step:32277 [D loss: 0.040115, acc: 100.00%] [G loss: 4.173368]\n",
      "epoch:41 step:32278 [D loss: 1.344682, acc: 50.78%] [G loss: 6.054717]\n",
      "epoch:41 step:32279 [D loss: 0.775941, acc: 49.22%] [G loss: 5.700675]\n",
      "epoch:41 step:32280 [D loss: 0.070463, acc: 99.22%] [G loss: 7.602571]\n",
      "epoch:41 step:32281 [D loss: 0.304712, acc: 84.38%] [G loss: 7.220419]\n",
      "epoch:41 step:32282 [D loss: 0.501908, acc: 67.19%] [G loss: 4.945884]\n",
      "epoch:41 step:32283 [D loss: 0.176984, acc: 97.66%] [G loss: 9.700073]\n",
      "epoch:41 step:32284 [D loss: 0.068408, acc: 100.00%] [G loss: 5.437070]\n",
      "epoch:41 step:32285 [D loss: 0.066139, acc: 100.00%] [G loss: 7.535929]\n",
      "epoch:41 step:32286 [D loss: 0.523238, acc: 73.44%] [G loss: 4.700616]\n",
      "epoch:41 step:32287 [D loss: 0.467022, acc: 61.72%] [G loss: 9.070370]\n",
      "epoch:41 step:32288 [D loss: 0.402583, acc: 84.38%] [G loss: 7.618891]\n",
      "epoch:41 step:32289 [D loss: 0.201963, acc: 96.88%] [G loss: 3.773734]\n",
      "epoch:41 step:32290 [D loss: 0.756444, acc: 52.34%] [G loss: 5.876545]\n",
      "epoch:41 step:32291 [D loss: 0.270416, acc: 88.28%] [G loss: 6.123010]\n",
      "epoch:41 step:32292 [D loss: 0.465062, acc: 75.78%] [G loss: 3.838840]\n",
      "epoch:41 step:32293 [D loss: 0.189425, acc: 93.75%] [G loss: 6.159583]\n",
      "epoch:41 step:32294 [D loss: 0.130727, acc: 98.44%] [G loss: 2.431774]\n",
      "epoch:41 step:32295 [D loss: 0.143937, acc: 100.00%] [G loss: 4.238466]\n",
      "epoch:41 step:32296 [D loss: 0.313242, acc: 91.41%] [G loss: 4.759852]\n",
      "epoch:41 step:32297 [D loss: 0.211846, acc: 96.88%] [G loss: 6.825084]\n",
      "epoch:41 step:32298 [D loss: 0.292056, acc: 88.28%] [G loss: 3.709996]\n",
      "epoch:41 step:32299 [D loss: 0.028895, acc: 100.00%] [G loss: 5.098470]\n",
      "epoch:41 step:32300 [D loss: 0.305718, acc: 86.72%] [G loss: 4.119651]\n",
      "epoch:41 step:32301 [D loss: 0.665717, acc: 60.16%] [G loss: 5.584680]\n",
      "epoch:41 step:32302 [D loss: 0.252483, acc: 89.84%] [G loss: 4.702818]\n",
      "epoch:41 step:32303 [D loss: 0.659001, acc: 62.50%] [G loss: 5.891349]\n",
      "epoch:41 step:32304 [D loss: 0.178029, acc: 96.09%] [G loss: 8.891151]\n",
      "epoch:41 step:32305 [D loss: 1.004284, acc: 50.00%] [G loss: 4.986094]\n",
      "epoch:41 step:32306 [D loss: 0.283517, acc: 86.72%] [G loss: 9.531472]\n",
      "epoch:41 step:32307 [D loss: 0.901750, acc: 43.75%] [G loss: 2.292225]\n",
      "epoch:41 step:32308 [D loss: 0.589774, acc: 67.97%] [G loss: 6.091022]\n",
      "epoch:41 step:32309 [D loss: 0.409244, acc: 80.47%] [G loss: 4.713766]\n",
      "epoch:41 step:32310 [D loss: 0.117728, acc: 100.00%] [G loss: 6.832997]\n",
      "epoch:41 step:32311 [D loss: 0.287123, acc: 90.62%] [G loss: 5.915932]\n",
      "epoch:41 step:32312 [D loss: 0.491391, acc: 70.31%] [G loss: 5.368973]\n",
      "epoch:41 step:32313 [D loss: 0.105671, acc: 97.66%] [G loss: 8.754583]\n",
      "epoch:41 step:32314 [D loss: 0.263179, acc: 94.53%] [G loss: 7.403048]\n",
      "epoch:41 step:32315 [D loss: 0.982244, acc: 44.53%] [G loss: 6.625058]\n",
      "epoch:41 step:32316 [D loss: 0.545611, acc: 73.44%] [G loss: 3.826607]\n",
      "epoch:41 step:32317 [D loss: 0.256589, acc: 89.84%] [G loss: 4.693656]\n",
      "epoch:41 step:32318 [D loss: 0.386822, acc: 74.22%] [G loss: 6.111491]\n",
      "epoch:41 step:32319 [D loss: 0.126587, acc: 99.22%] [G loss: 4.310658]\n",
      "epoch:41 step:32320 [D loss: 0.342942, acc: 86.72%] [G loss: 4.861773]\n",
      "epoch:41 step:32321 [D loss: 0.335873, acc: 90.62%] [G loss: 7.281110]\n",
      "epoch:41 step:32322 [D loss: 1.163185, acc: 50.78%] [G loss: 3.634533]\n",
      "epoch:41 step:32323 [D loss: 0.435187, acc: 71.09%] [G loss: 6.750009]\n",
      "epoch:41 step:32324 [D loss: 0.111646, acc: 100.00%] [G loss: 7.720720]\n",
      "epoch:41 step:32325 [D loss: 1.103158, acc: 21.09%] [G loss: 7.862024]\n",
      "epoch:41 step:32326 [D loss: 0.098891, acc: 99.22%] [G loss: 5.217638]\n",
      "epoch:41 step:32327 [D loss: 0.173152, acc: 100.00%] [G loss: 4.172680]\n",
      "epoch:41 step:32328 [D loss: 0.280703, acc: 82.03%] [G loss: 6.543461]\n",
      "epoch:41 step:32329 [D loss: 0.452016, acc: 81.25%] [G loss: 8.022635]\n",
      "epoch:41 step:32330 [D loss: 0.258308, acc: 88.28%] [G loss: 6.699474]\n",
      "epoch:41 step:32331 [D loss: 0.326052, acc: 89.06%] [G loss: 7.439572]\n",
      "epoch:41 step:32332 [D loss: 0.907481, acc: 49.22%] [G loss: 7.761640]\n",
      "epoch:41 step:32333 [D loss: 0.067237, acc: 99.22%] [G loss: 7.451371]\n",
      "epoch:41 step:32334 [D loss: 0.016447, acc: 100.00%] [G loss: 8.845357]\n",
      "epoch:41 step:32335 [D loss: 0.258235, acc: 96.09%] [G loss: 6.376313]\n",
      "epoch:41 step:32336 [D loss: 0.041854, acc: 100.00%] [G loss: 5.107514]\n",
      "epoch:41 step:32337 [D loss: 0.270537, acc: 92.97%] [G loss: 4.939526]\n",
      "epoch:41 step:32338 [D loss: 0.771320, acc: 46.88%] [G loss: 7.761048]\n",
      "epoch:41 step:32339 [D loss: 0.466185, acc: 68.75%] [G loss: 3.484316]\n",
      "epoch:41 step:32340 [D loss: 0.198680, acc: 97.66%] [G loss: 5.656928]\n",
      "epoch:41 step:32341 [D loss: 0.281719, acc: 89.06%] [G loss: 5.943688]\n",
      "epoch:41 step:32342 [D loss: 0.180789, acc: 96.88%] [G loss: 5.767305]\n",
      "epoch:41 step:32343 [D loss: 0.150328, acc: 100.00%] [G loss: 6.622726]\n",
      "epoch:41 step:32344 [D loss: 0.108236, acc: 100.00%] [G loss: 9.704556]\n",
      "epoch:41 step:32345 [D loss: 0.059499, acc: 98.44%] [G loss: 5.512849]\n",
      "epoch:41 step:32346 [D loss: 0.242278, acc: 87.50%] [G loss: 5.312594]\n",
      "epoch:41 step:32347 [D loss: 1.182526, acc: 47.66%] [G loss: 5.741304]\n",
      "epoch:41 step:32348 [D loss: 0.312569, acc: 85.94%] [G loss: 5.139343]\n",
      "epoch:41 step:32349 [D loss: 0.142674, acc: 100.00%] [G loss: 5.237349]\n",
      "epoch:41 step:32350 [D loss: 0.124750, acc: 98.44%] [G loss: 5.973378]\n",
      "epoch:41 step:32351 [D loss: 0.302676, acc: 86.72%] [G loss: 5.531599]\n",
      "epoch:41 step:32352 [D loss: 0.304896, acc: 94.53%] [G loss: 6.968499]\n",
      "epoch:41 step:32353 [D loss: 0.243027, acc: 97.66%] [G loss: 5.365411]\n",
      "epoch:41 step:32354 [D loss: 0.031310, acc: 100.00%] [G loss: 9.349588]\n",
      "epoch:41 step:32355 [D loss: 0.496698, acc: 71.09%] [G loss: 6.699430]\n",
      "epoch:41 step:32356 [D loss: 0.286171, acc: 84.38%] [G loss: 6.738481]\n",
      "epoch:41 step:32357 [D loss: 0.043774, acc: 100.00%] [G loss: 5.986320]\n",
      "epoch:41 step:32358 [D loss: 0.241612, acc: 98.44%] [G loss: 5.462395]\n",
      "epoch:41 step:32359 [D loss: 0.049269, acc: 100.00%] [G loss: 7.084413]\n",
      "epoch:41 step:32360 [D loss: 0.094672, acc: 99.22%] [G loss: 6.654983]\n",
      "epoch:41 step:32361 [D loss: 0.386579, acc: 71.09%] [G loss: 6.658664]\n",
      "epoch:41 step:32362 [D loss: 0.533963, acc: 68.75%] [G loss: 7.254814]\n",
      "epoch:41 step:32363 [D loss: 0.436357, acc: 82.03%] [G loss: 4.355514]\n",
      "epoch:41 step:32364 [D loss: 0.392381, acc: 77.34%] [G loss: 6.512173]\n",
      "epoch:41 step:32365 [D loss: 0.263383, acc: 89.84%] [G loss: 7.273356]\n",
      "epoch:41 step:32366 [D loss: 0.375649, acc: 82.03%] [G loss: 2.871727]\n",
      "epoch:41 step:32367 [D loss: 0.209199, acc: 97.66%] [G loss: 5.395694]\n",
      "epoch:41 step:32368 [D loss: 0.073565, acc: 100.00%] [G loss: 4.527977]\n",
      "epoch:41 step:32369 [D loss: 0.440783, acc: 71.09%] [G loss: 3.612112]\n",
      "epoch:41 step:32370 [D loss: 0.216265, acc: 98.44%] [G loss: 2.498971]\n",
      "epoch:41 step:32371 [D loss: 0.193109, acc: 96.09%] [G loss: 5.561606]\n",
      "epoch:41 step:32372 [D loss: 0.134142, acc: 99.22%] [G loss: 7.953835]\n",
      "epoch:41 step:32373 [D loss: 0.370757, acc: 78.12%] [G loss: 4.698789]\n",
      "epoch:41 step:32374 [D loss: 0.714369, acc: 57.81%] [G loss: 4.921857]\n",
      "epoch:41 step:32375 [D loss: 0.076711, acc: 100.00%] [G loss: 6.500832]\n",
      "epoch:41 step:32376 [D loss: 0.556428, acc: 69.53%] [G loss: 5.393368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32377 [D loss: 1.245594, acc: 46.09%] [G loss: 6.611854]\n",
      "epoch:41 step:32378 [D loss: 1.618054, acc: 50.00%] [G loss: 4.266039]\n",
      "epoch:41 step:32379 [D loss: 0.223301, acc: 94.53%] [G loss: 4.606805]\n",
      "epoch:41 step:32380 [D loss: 0.077053, acc: 99.22%] [G loss: 6.811547]\n",
      "epoch:41 step:32381 [D loss: 0.271485, acc: 89.84%] [G loss: 8.019926]\n",
      "epoch:41 step:32382 [D loss: 1.162617, acc: 50.00%] [G loss: 7.719261]\n",
      "epoch:41 step:32383 [D loss: 0.082314, acc: 100.00%] [G loss: 5.554855]\n",
      "epoch:41 step:32384 [D loss: 0.363832, acc: 82.03%] [G loss: 3.867461]\n",
      "epoch:41 step:32385 [D loss: 0.214919, acc: 96.09%] [G loss: 4.135940]\n",
      "epoch:41 step:32386 [D loss: 0.380196, acc: 82.81%] [G loss: 5.500747]\n",
      "epoch:41 step:32387 [D loss: 0.323040, acc: 82.03%] [G loss: 4.942851]\n",
      "epoch:41 step:32388 [D loss: 0.286878, acc: 92.97%] [G loss: 3.643321]\n",
      "epoch:41 step:32389 [D loss: 0.031671, acc: 100.00%] [G loss: 6.708666]\n",
      "epoch:41 step:32390 [D loss: 0.082854, acc: 100.00%] [G loss: 5.368742]\n",
      "epoch:41 step:32391 [D loss: 0.381808, acc: 87.50%] [G loss: 4.663167]\n",
      "epoch:41 step:32392 [D loss: 0.254032, acc: 95.31%] [G loss: 5.773409]\n",
      "epoch:41 step:32393 [D loss: 0.154161, acc: 99.22%] [G loss: 4.693474]\n",
      "epoch:41 step:32394 [D loss: 0.356438, acc: 79.69%] [G loss: 3.921675]\n",
      "epoch:41 step:32395 [D loss: 0.200023, acc: 96.09%] [G loss: 7.402378]\n",
      "epoch:41 step:32396 [D loss: 0.561860, acc: 57.03%] [G loss: 5.804976]\n",
      "epoch:41 step:32397 [D loss: 0.052284, acc: 100.00%] [G loss: 5.234344]\n",
      "epoch:41 step:32398 [D loss: 0.030115, acc: 100.00%] [G loss: 6.031233]\n",
      "epoch:41 step:32399 [D loss: 0.697315, acc: 57.03%] [G loss: 5.649526]\n",
      "epoch:41 step:32400 [D loss: 0.070496, acc: 99.22%] [G loss: 8.246868]\n",
      "epoch:41 step:32401 [D loss: 0.895283, acc: 52.34%] [G loss: 7.220808]\n",
      "epoch:41 step:32402 [D loss: 0.119046, acc: 98.44%] [G loss: 7.368228]\n",
      "epoch:41 step:32403 [D loss: 0.009046, acc: 100.00%] [G loss: 8.786317]\n",
      "epoch:41 step:32404 [D loss: 0.248053, acc: 96.09%] [G loss: 5.281587]\n",
      "epoch:41 step:32405 [D loss: 0.380551, acc: 85.94%] [G loss: 6.020316]\n",
      "epoch:41 step:32406 [D loss: 0.475887, acc: 70.31%] [G loss: 4.540640]\n",
      "epoch:41 step:32407 [D loss: 0.111200, acc: 100.00%] [G loss: 5.614660]\n",
      "epoch:41 step:32408 [D loss: 0.160059, acc: 96.88%] [G loss: 4.769307]\n",
      "epoch:41 step:32409 [D loss: 0.843426, acc: 43.75%] [G loss: 7.938713]\n",
      "epoch:41 step:32410 [D loss: 0.123118, acc: 98.44%] [G loss: 6.247465]\n",
      "epoch:41 step:32411 [D loss: 0.459818, acc: 75.00%] [G loss: 5.557680]\n",
      "epoch:41 step:32412 [D loss: 0.514987, acc: 71.88%] [G loss: 6.072416]\n",
      "epoch:41 step:32413 [D loss: 0.717668, acc: 57.03%] [G loss: 4.219857]\n",
      "epoch:41 step:32414 [D loss: 0.264080, acc: 93.75%] [G loss: 6.933741]\n",
      "epoch:41 step:32415 [D loss: 0.751938, acc: 52.34%] [G loss: 8.466841]\n",
      "epoch:41 step:32416 [D loss: 0.473439, acc: 71.88%] [G loss: 5.597369]\n",
      "epoch:41 step:32417 [D loss: 0.318712, acc: 89.06%] [G loss: 3.906232]\n",
      "epoch:41 step:32418 [D loss: 0.289276, acc: 89.84%] [G loss: 3.290529]\n",
      "epoch:41 step:32419 [D loss: 0.134166, acc: 98.44%] [G loss: 4.598397]\n",
      "epoch:41 step:32420 [D loss: 0.038381, acc: 100.00%] [G loss: 7.808025]\n",
      "epoch:41 step:32421 [D loss: 0.602383, acc: 58.59%] [G loss: 4.687096]\n",
      "epoch:41 step:32422 [D loss: 0.108878, acc: 100.00%] [G loss: 2.460009]\n",
      "epoch:41 step:32423 [D loss: 0.239996, acc: 90.62%] [G loss: 7.839059]\n",
      "epoch:41 step:32424 [D loss: 0.613397, acc: 64.06%] [G loss: 6.112218]\n",
      "epoch:41 step:32425 [D loss: 1.960557, acc: 7.81%] [G loss: 6.352563]\n",
      "epoch:41 step:32426 [D loss: 0.471199, acc: 75.78%] [G loss: 6.943581]\n",
      "epoch:41 step:32427 [D loss: 0.676317, acc: 54.69%] [G loss: 6.366129]\n",
      "epoch:41 step:32428 [D loss: 0.049107, acc: 100.00%] [G loss: 9.036440]\n",
      "epoch:41 step:32429 [D loss: 0.156417, acc: 98.44%] [G loss: 6.319989]\n",
      "epoch:41 step:32430 [D loss: 0.091897, acc: 99.22%] [G loss: 6.635742]\n",
      "epoch:41 step:32431 [D loss: 0.094981, acc: 99.22%] [G loss: 8.365994]\n",
      "epoch:41 step:32432 [D loss: 0.149249, acc: 98.44%] [G loss: 6.663169]\n",
      "epoch:41 step:32433 [D loss: 0.032236, acc: 100.00%] [G loss: 7.700169]\n",
      "epoch:41 step:32434 [D loss: 0.057264, acc: 100.00%] [G loss: 5.669424]\n",
      "epoch:41 step:32435 [D loss: 0.154803, acc: 97.66%] [G loss: 6.275833]\n",
      "epoch:41 step:32436 [D loss: 0.366395, acc: 75.00%] [G loss: 3.915796]\n",
      "epoch:41 step:32437 [D loss: 0.828321, acc: 53.12%] [G loss: 8.349359]\n",
      "epoch:41 step:32438 [D loss: 0.489041, acc: 72.66%] [G loss: 4.759912]\n",
      "epoch:41 step:32439 [D loss: 0.021878, acc: 100.00%] [G loss: 5.417476]\n",
      "epoch:41 step:32440 [D loss: 0.329005, acc: 93.75%] [G loss: 10.591122]\n",
      "epoch:41 step:32441 [D loss: 0.102054, acc: 99.22%] [G loss: 3.950021]\n",
      "epoch:41 step:32442 [D loss: 0.021420, acc: 100.00%] [G loss: 5.923323]\n",
      "epoch:41 step:32443 [D loss: 0.135992, acc: 98.44%] [G loss: 9.085447]\n",
      "epoch:41 step:32444 [D loss: 0.527933, acc: 68.75%] [G loss: 6.593933]\n",
      "epoch:41 step:32445 [D loss: 1.003482, acc: 51.56%] [G loss: 7.685432]\n",
      "epoch:41 step:32446 [D loss: 0.249013, acc: 95.31%] [G loss: 3.642190]\n",
      "epoch:41 step:32447 [D loss: 0.321454, acc: 94.53%] [G loss: 4.153075]\n",
      "epoch:41 step:32448 [D loss: 0.448158, acc: 71.88%] [G loss: 8.620300]\n",
      "epoch:41 step:32449 [D loss: 0.125095, acc: 97.66%] [G loss: 10.508060]\n",
      "epoch:41 step:32450 [D loss: 0.120730, acc: 98.44%] [G loss: 8.282860]\n",
      "epoch:41 step:32451 [D loss: 0.762289, acc: 54.69%] [G loss: 5.711168]\n",
      "epoch:41 step:32452 [D loss: 0.088776, acc: 100.00%] [G loss: 5.430247]\n",
      "epoch:41 step:32453 [D loss: 1.129389, acc: 51.56%] [G loss: 5.251765]\n",
      "epoch:41 step:32454 [D loss: 0.556782, acc: 63.28%] [G loss: 7.594283]\n",
      "epoch:41 step:32455 [D loss: 0.080726, acc: 100.00%] [G loss: 5.668785]\n",
      "epoch:41 step:32456 [D loss: 0.007300, acc: 100.00%] [G loss: 7.846755]\n",
      "epoch:41 step:32457 [D loss: 0.182431, acc: 97.66%] [G loss: 3.887639]\n",
      "epoch:41 step:32458 [D loss: 0.237378, acc: 94.53%] [G loss: 5.750664]\n",
      "epoch:41 step:32459 [D loss: 0.066995, acc: 99.22%] [G loss: 5.048017]\n",
      "epoch:41 step:32460 [D loss: 0.668559, acc: 60.94%] [G loss: 3.971327]\n",
      "epoch:41 step:32461 [D loss: 0.415363, acc: 85.16%] [G loss: 7.946565]\n",
      "epoch:41 step:32462 [D loss: 0.059126, acc: 100.00%] [G loss: 5.118297]\n",
      "epoch:41 step:32463 [D loss: 0.193044, acc: 93.75%] [G loss: 5.362350]\n",
      "epoch:41 step:32464 [D loss: 0.948732, acc: 42.19%] [G loss: 6.452297]\n",
      "epoch:41 step:32465 [D loss: 0.123397, acc: 99.22%] [G loss: 8.410708]\n",
      "epoch:41 step:32466 [D loss: 0.291306, acc: 89.84%] [G loss: 5.111388]\n",
      "epoch:41 step:32467 [D loss: 0.131543, acc: 99.22%] [G loss: 5.762660]\n",
      "epoch:41 step:32468 [D loss: 0.136794, acc: 99.22%] [G loss: 6.546610]\n",
      "epoch:41 step:32469 [D loss: 0.038865, acc: 100.00%] [G loss: 5.997515]\n",
      "epoch:41 step:32470 [D loss: 0.992890, acc: 50.00%] [G loss: 7.543951]\n",
      "epoch:41 step:32471 [D loss: 1.068327, acc: 50.00%] [G loss: 6.399960]\n",
      "epoch:41 step:32472 [D loss: 0.104276, acc: 100.00%] [G loss: 7.901466]\n",
      "epoch:41 step:32473 [D loss: 0.103481, acc: 100.00%] [G loss: 6.147058]\n",
      "epoch:41 step:32474 [D loss: 0.542125, acc: 68.75%] [G loss: 6.121090]\n",
      "epoch:41 step:32475 [D loss: 0.657248, acc: 64.06%] [G loss: 7.852660]\n",
      "epoch:41 step:32476 [D loss: 0.137849, acc: 98.44%] [G loss: 6.006935]\n",
      "epoch:41 step:32477 [D loss: 0.387879, acc: 82.81%] [G loss: 3.329985]\n",
      "epoch:41 step:32478 [D loss: 0.091331, acc: 100.00%] [G loss: 4.536498]\n",
      "epoch:41 step:32479 [D loss: 0.080310, acc: 98.44%] [G loss: 4.876416]\n",
      "epoch:41 step:32480 [D loss: 0.603685, acc: 65.62%] [G loss: 4.822317]\n",
      "epoch:41 step:32481 [D loss: 0.064832, acc: 100.00%] [G loss: 6.358958]\n",
      "epoch:41 step:32482 [D loss: 0.068919, acc: 99.22%] [G loss: 9.376240]\n",
      "epoch:41 step:32483 [D loss: 0.044684, acc: 100.00%] [G loss: 9.127550]\n",
      "epoch:41 step:32484 [D loss: 0.139413, acc: 99.22%] [G loss: 5.028677]\n",
      "epoch:41 step:32485 [D loss: 0.080306, acc: 100.00%] [G loss: 4.165304]\n",
      "epoch:41 step:32486 [D loss: 1.067220, acc: 47.66%] [G loss: 5.380937]\n",
      "epoch:41 step:32487 [D loss: 0.010153, acc: 100.00%] [G loss: 8.174912]\n",
      "epoch:41 step:32488 [D loss: 0.152632, acc: 96.88%] [G loss: 4.985133]\n",
      "epoch:41 step:32489 [D loss: 0.368288, acc: 89.84%] [G loss: 4.089930]\n",
      "epoch:41 step:32490 [D loss: 0.236204, acc: 97.66%] [G loss: 8.853618]\n",
      "epoch:41 step:32491 [D loss: 0.090878, acc: 99.22%] [G loss: 10.306410]\n",
      "epoch:41 step:32492 [D loss: 0.905384, acc: 52.34%] [G loss: 7.294014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32493 [D loss: 0.127398, acc: 100.00%] [G loss: 6.855299]\n",
      "epoch:41 step:32494 [D loss: 0.178306, acc: 98.44%] [G loss: 6.014210]\n",
      "epoch:41 step:32495 [D loss: 0.795397, acc: 53.91%] [G loss: 3.691484]\n",
      "epoch:41 step:32496 [D loss: 0.331427, acc: 91.41%] [G loss: 5.650790]\n",
      "epoch:41 step:32497 [D loss: 0.544863, acc: 65.62%] [G loss: 7.235527]\n",
      "epoch:41 step:32498 [D loss: 0.216316, acc: 96.09%] [G loss: 4.749613]\n",
      "epoch:41 step:32499 [D loss: 0.304004, acc: 82.81%] [G loss: 6.794387]\n",
      "epoch:41 step:32500 [D loss: 0.166834, acc: 96.88%] [G loss: 5.998215]\n",
      "epoch:41 step:32501 [D loss: 1.194187, acc: 35.94%] [G loss: 5.908971]\n",
      "epoch:41 step:32502 [D loss: 0.671061, acc: 58.59%] [G loss: 4.484325]\n",
      "epoch:41 step:32503 [D loss: 1.201570, acc: 46.09%] [G loss: 9.567484]\n",
      "epoch:41 step:32504 [D loss: 0.168670, acc: 98.44%] [G loss: 4.229172]\n",
      "epoch:41 step:32505 [D loss: 0.645231, acc: 58.59%] [G loss: 6.156489]\n",
      "epoch:41 step:32506 [D loss: 0.391982, acc: 75.00%] [G loss: 5.990214]\n",
      "epoch:41 step:32507 [D loss: 0.165514, acc: 97.66%] [G loss: 7.633636]\n",
      "epoch:41 step:32508 [D loss: 1.180686, acc: 43.75%] [G loss: 4.337956]\n",
      "epoch:41 step:32509 [D loss: 0.052875, acc: 100.00%] [G loss: 8.459609]\n",
      "epoch:41 step:32510 [D loss: 0.184332, acc: 99.22%] [G loss: 7.429508]\n",
      "epoch:41 step:32511 [D loss: 0.143027, acc: 100.00%] [G loss: 4.539676]\n",
      "epoch:41 step:32512 [D loss: 0.153262, acc: 98.44%] [G loss: 3.173613]\n",
      "epoch:41 step:32513 [D loss: 0.094449, acc: 100.00%] [G loss: 5.387575]\n",
      "epoch:41 step:32514 [D loss: 0.179817, acc: 97.66%] [G loss: 5.943736]\n",
      "epoch:41 step:32515 [D loss: 0.345134, acc: 85.16%] [G loss: 2.724515]\n",
      "epoch:41 step:32516 [D loss: 0.144329, acc: 97.66%] [G loss: 8.822722]\n",
      "epoch:41 step:32517 [D loss: 0.083321, acc: 99.22%] [G loss: 6.390450]\n",
      "epoch:41 step:32518 [D loss: 0.031230, acc: 100.00%] [G loss: 7.909363]\n",
      "epoch:41 step:32519 [D loss: 0.408900, acc: 84.38%] [G loss: 7.876590]\n",
      "epoch:41 step:32520 [D loss: 0.029390, acc: 100.00%] [G loss: 3.928395]\n",
      "epoch:41 step:32521 [D loss: 0.071682, acc: 100.00%] [G loss: 5.466097]\n",
      "epoch:41 step:32522 [D loss: 0.097519, acc: 99.22%] [G loss: 8.154299]\n",
      "epoch:41 step:32523 [D loss: 0.193957, acc: 95.31%] [G loss: 5.527628]\n",
      "epoch:41 step:32524 [D loss: 0.136390, acc: 98.44%] [G loss: 8.403918]\n",
      "epoch:41 step:32525 [D loss: 0.061219, acc: 100.00%] [G loss: 3.325561]\n",
      "epoch:41 step:32526 [D loss: 0.232835, acc: 95.31%] [G loss: 5.187970]\n",
      "epoch:41 step:32527 [D loss: 0.502114, acc: 78.12%] [G loss: 7.260389]\n",
      "epoch:41 step:32528 [D loss: 0.241045, acc: 95.31%] [G loss: 6.009963]\n",
      "epoch:41 step:32529 [D loss: 0.178639, acc: 97.66%] [G loss: 3.632366]\n",
      "epoch:41 step:32530 [D loss: 0.313981, acc: 91.41%] [G loss: 5.855716]\n",
      "epoch:41 step:32531 [D loss: 0.038858, acc: 100.00%] [G loss: 9.993589]\n",
      "epoch:41 step:32532 [D loss: 0.148221, acc: 97.66%] [G loss: 8.918914]\n",
      "epoch:41 step:32533 [D loss: 0.507422, acc: 67.19%] [G loss: 4.514389]\n",
      "epoch:41 step:32534 [D loss: 0.070726, acc: 100.00%] [G loss: 6.058506]\n",
      "epoch:41 step:32535 [D loss: 0.494604, acc: 78.91%] [G loss: 3.211580]\n",
      "epoch:41 step:32536 [D loss: 0.449071, acc: 79.69%] [G loss: 4.329319]\n",
      "epoch:41 step:32537 [D loss: 0.906785, acc: 52.34%] [G loss: 7.111748]\n",
      "epoch:41 step:32538 [D loss: 0.049664, acc: 100.00%] [G loss: 5.872953]\n",
      "epoch:41 step:32539 [D loss: 0.393892, acc: 75.00%] [G loss: 6.747233]\n",
      "epoch:41 step:32540 [D loss: 0.233265, acc: 90.62%] [G loss: 6.921978]\n",
      "epoch:41 step:32541 [D loss: 0.554890, acc: 74.22%] [G loss: 6.321525]\n",
      "epoch:41 step:32542 [D loss: 0.022431, acc: 100.00%] [G loss: 3.696050]\n",
      "epoch:41 step:32543 [D loss: 0.236921, acc: 91.41%] [G loss: 4.536866]\n",
      "epoch:41 step:32544 [D loss: 0.062356, acc: 100.00%] [G loss: 4.348177]\n",
      "epoch:41 step:32545 [D loss: 0.186336, acc: 96.88%] [G loss: 5.620418]\n",
      "epoch:41 step:32546 [D loss: 0.105107, acc: 99.22%] [G loss: 3.612044]\n",
      "epoch:41 step:32547 [D loss: 0.189623, acc: 97.66%] [G loss: 8.322075]\n",
      "epoch:41 step:32548 [D loss: 0.171469, acc: 96.88%] [G loss: 4.418279]\n",
      "epoch:41 step:32549 [D loss: 0.152496, acc: 98.44%] [G loss: 7.738417]\n",
      "epoch:41 step:32550 [D loss: 1.530827, acc: 50.00%] [G loss: 4.443460]\n",
      "epoch:41 step:32551 [D loss: 0.228939, acc: 96.09%] [G loss: 4.197740]\n",
      "epoch:41 step:32552 [D loss: 0.161880, acc: 97.66%] [G loss: 5.453083]\n",
      "epoch:41 step:32553 [D loss: 1.025907, acc: 50.78%] [G loss: 5.853716]\n",
      "epoch:41 step:32554 [D loss: 0.805199, acc: 55.47%] [G loss: 6.172541]\n",
      "epoch:41 step:32555 [D loss: 0.237810, acc: 97.66%] [G loss: 5.350538]\n",
      "epoch:41 step:32556 [D loss: 1.020695, acc: 39.84%] [G loss: 3.578395]\n",
      "epoch:41 step:32557 [D loss: 1.125095, acc: 49.22%] [G loss: 3.419582]\n",
      "epoch:41 step:32558 [D loss: 0.591419, acc: 57.03%] [G loss: 8.453203]\n",
      "epoch:41 step:32559 [D loss: 0.111338, acc: 99.22%] [G loss: 5.139865]\n",
      "epoch:41 step:32560 [D loss: 0.661331, acc: 65.62%] [G loss: 7.616014]\n",
      "epoch:41 step:32561 [D loss: 1.193729, acc: 28.12%] [G loss: 6.527638]\n",
      "epoch:41 step:32562 [D loss: 0.345990, acc: 89.84%] [G loss: 4.892241]\n",
      "epoch:41 step:32563 [D loss: 0.347331, acc: 78.12%] [G loss: 8.491716]\n",
      "epoch:41 step:32564 [D loss: 0.665434, acc: 63.28%] [G loss: 8.437428]\n",
      "epoch:41 step:32565 [D loss: 0.193758, acc: 98.44%] [G loss: 5.407349]\n",
      "epoch:41 step:32566 [D loss: 0.495033, acc: 67.19%] [G loss: 5.969201]\n",
      "epoch:41 step:32567 [D loss: 0.040470, acc: 100.00%] [G loss: 2.722326]\n",
      "epoch:41 step:32568 [D loss: 0.073086, acc: 99.22%] [G loss: 3.208065]\n",
      "epoch:41 step:32569 [D loss: 0.368471, acc: 86.72%] [G loss: 6.498722]\n",
      "epoch:41 step:32570 [D loss: 0.066273, acc: 100.00%] [G loss: 6.941226]\n",
      "epoch:41 step:32571 [D loss: 0.743717, acc: 54.69%] [G loss: 9.308987]\n",
      "epoch:41 step:32572 [D loss: 0.370129, acc: 78.91%] [G loss: 8.262282]\n",
      "epoch:41 step:32573 [D loss: 0.623872, acc: 62.50%] [G loss: 4.739929]\n",
      "epoch:41 step:32574 [D loss: 0.472559, acc: 69.53%] [G loss: 6.235246]\n",
      "epoch:41 step:32575 [D loss: 0.095591, acc: 100.00%] [G loss: 3.953657]\n",
      "epoch:41 step:32576 [D loss: 0.176058, acc: 96.09%] [G loss: 7.055404]\n",
      "epoch:41 step:32577 [D loss: 0.127204, acc: 97.66%] [G loss: 5.833985]\n",
      "epoch:41 step:32578 [D loss: 0.207556, acc: 97.66%] [G loss: 4.248489]\n",
      "epoch:41 step:32579 [D loss: 0.221900, acc: 96.09%] [G loss: 4.640501]\n",
      "epoch:41 step:32580 [D loss: 0.042382, acc: 100.00%] [G loss: 8.435028]\n",
      "epoch:41 step:32581 [D loss: 0.143565, acc: 97.66%] [G loss: 9.610537]\n",
      "epoch:41 step:32582 [D loss: 0.113233, acc: 100.00%] [G loss: 7.619456]\n",
      "epoch:41 step:32583 [D loss: 0.249663, acc: 96.09%] [G loss: 5.999571]\n",
      "epoch:41 step:32584 [D loss: 0.078144, acc: 99.22%] [G loss: 5.525499]\n",
      "epoch:41 step:32585 [D loss: 0.182952, acc: 99.22%] [G loss: 8.591119]\n",
      "epoch:41 step:32586 [D loss: 0.220985, acc: 96.09%] [G loss: 4.854291]\n",
      "epoch:41 step:32587 [D loss: 0.109326, acc: 99.22%] [G loss: 5.505130]\n",
      "epoch:41 step:32588 [D loss: 0.407917, acc: 89.84%] [G loss: 7.066614]\n",
      "epoch:41 step:32589 [D loss: 0.176254, acc: 96.09%] [G loss: 7.541933]\n",
      "epoch:41 step:32590 [D loss: 0.325123, acc: 90.62%] [G loss: 5.231738]\n",
      "epoch:41 step:32591 [D loss: 0.059609, acc: 100.00%] [G loss: 3.278359]\n",
      "epoch:41 step:32592 [D loss: 0.403370, acc: 71.09%] [G loss: 3.307555]\n",
      "epoch:41 step:32593 [D loss: 0.276434, acc: 90.62%] [G loss: 4.783967]\n",
      "epoch:41 step:32594 [D loss: 1.363870, acc: 50.00%] [G loss: 5.825436]\n",
      "epoch:41 step:32595 [D loss: 0.030369, acc: 100.00%] [G loss: 6.192592]\n",
      "epoch:41 step:32596 [D loss: 0.514275, acc: 74.22%] [G loss: 4.820483]\n",
      "epoch:41 step:32597 [D loss: 0.353105, acc: 81.25%] [G loss: 6.720331]\n",
      "epoch:41 step:32598 [D loss: 0.403849, acc: 85.16%] [G loss: 7.237423]\n",
      "epoch:41 step:32599 [D loss: 0.077244, acc: 99.22%] [G loss: 10.110536]\n",
      "epoch:41 step:32600 [D loss: 1.236078, acc: 16.41%] [G loss: 9.695147]\n",
      "epoch:41 step:32601 [D loss: 0.233626, acc: 91.41%] [G loss: 6.603295]\n",
      "epoch:41 step:32602 [D loss: 0.148545, acc: 100.00%] [G loss: 4.143136]\n",
      "epoch:41 step:32603 [D loss: 0.036198, acc: 100.00%] [G loss: 6.630078]\n",
      "epoch:41 step:32604 [D loss: 0.332081, acc: 90.62%] [G loss: 4.407982]\n",
      "epoch:41 step:32605 [D loss: 0.229266, acc: 93.75%] [G loss: 4.948582]\n",
      "epoch:41 step:32606 [D loss: 0.206995, acc: 100.00%] [G loss: 4.730483]\n",
      "epoch:41 step:32607 [D loss: 0.239077, acc: 96.09%] [G loss: 4.868207]\n",
      "epoch:41 step:32608 [D loss: 0.186617, acc: 95.31%] [G loss: 4.555654]\n",
      "epoch:41 step:32609 [D loss: 0.112927, acc: 99.22%] [G loss: 4.572746]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32610 [D loss: 0.118502, acc: 99.22%] [G loss: 5.296777]\n",
      "epoch:41 step:32611 [D loss: 0.291885, acc: 93.75%] [G loss: 8.533002]\n",
      "epoch:41 step:32612 [D loss: 0.211587, acc: 97.66%] [G loss: 7.419580]\n",
      "epoch:41 step:32613 [D loss: 1.773916, acc: 23.44%] [G loss: 5.676271]\n",
      "epoch:41 step:32614 [D loss: 0.106431, acc: 99.22%] [G loss: 3.126865]\n",
      "epoch:41 step:32615 [D loss: 0.749331, acc: 56.25%] [G loss: 5.967345]\n",
      "epoch:41 step:32616 [D loss: 0.639361, acc: 58.59%] [G loss: 6.158519]\n",
      "epoch:41 step:32617 [D loss: 0.693727, acc: 61.72%] [G loss: 4.979941]\n",
      "epoch:41 step:32618 [D loss: 0.174109, acc: 97.66%] [G loss: 5.524516]\n",
      "epoch:41 step:32619 [D loss: 0.432550, acc: 78.91%] [G loss: 8.153332]\n",
      "epoch:41 step:32620 [D loss: 0.798036, acc: 51.56%] [G loss: 3.156228]\n",
      "epoch:41 step:32621 [D loss: 0.496909, acc: 69.53%] [G loss: 6.673436]\n",
      "epoch:41 step:32622 [D loss: 0.137329, acc: 98.44%] [G loss: 7.289669]\n",
      "epoch:41 step:32623 [D loss: 0.215114, acc: 96.09%] [G loss: 4.431397]\n",
      "epoch:41 step:32624 [D loss: 0.102104, acc: 98.44%] [G loss: 5.891489]\n",
      "epoch:41 step:32625 [D loss: 0.877823, acc: 39.84%] [G loss: 5.644322]\n",
      "epoch:41 step:32626 [D loss: 0.468057, acc: 69.53%] [G loss: 4.643014]\n",
      "epoch:41 step:32627 [D loss: 0.664711, acc: 61.72%] [G loss: 8.437999]\n",
      "epoch:41 step:32628 [D loss: 0.155727, acc: 99.22%] [G loss: 4.488788]\n",
      "epoch:41 step:32629 [D loss: 1.240921, acc: 20.31%] [G loss: 6.841109]\n",
      "epoch:41 step:32630 [D loss: 0.285949, acc: 88.28%] [G loss: 5.442348]\n",
      "epoch:41 step:32631 [D loss: 0.091614, acc: 100.00%] [G loss: 4.616961]\n",
      "epoch:41 step:32632 [D loss: 0.183148, acc: 94.53%] [G loss: 4.813461]\n",
      "epoch:41 step:32633 [D loss: 0.254471, acc: 95.31%] [G loss: 5.135205]\n",
      "epoch:41 step:32634 [D loss: 0.315678, acc: 92.97%] [G loss: 4.785203]\n",
      "epoch:41 step:32635 [D loss: 0.089561, acc: 99.22%] [G loss: 4.000003]\n",
      "epoch:41 step:32636 [D loss: 0.226862, acc: 92.19%] [G loss: 7.743019]\n",
      "epoch:41 step:32637 [D loss: 0.525010, acc: 61.72%] [G loss: 6.633136]\n",
      "epoch:41 step:32638 [D loss: 0.371441, acc: 83.59%] [G loss: 5.800507]\n",
      "epoch:41 step:32639 [D loss: 0.077766, acc: 99.22%] [G loss: 7.559520]\n",
      "epoch:41 step:32640 [D loss: 0.639037, acc: 65.62%] [G loss: 5.738056]\n",
      "epoch:41 step:32641 [D loss: 0.339987, acc: 91.41%] [G loss: 5.981298]\n",
      "epoch:41 step:32642 [D loss: 0.453723, acc: 84.38%] [G loss: 6.086380]\n",
      "epoch:41 step:32643 [D loss: 0.140220, acc: 100.00%] [G loss: 6.586464]\n",
      "epoch:41 step:32644 [D loss: 0.321956, acc: 92.97%] [G loss: 4.732219]\n",
      "epoch:41 step:32645 [D loss: 0.121005, acc: 99.22%] [G loss: 5.865386]\n",
      "epoch:41 step:32646 [D loss: 0.473749, acc: 74.22%] [G loss: 5.018691]\n",
      "epoch:41 step:32647 [D loss: 1.252923, acc: 25.00%] [G loss: 4.331901]\n",
      "epoch:41 step:32648 [D loss: 0.140426, acc: 100.00%] [G loss: 3.492715]\n",
      "epoch:41 step:32649 [D loss: 0.482439, acc: 67.97%] [G loss: 6.969868]\n",
      "epoch:41 step:32650 [D loss: 0.167856, acc: 96.88%] [G loss: 7.547542]\n",
      "epoch:41 step:32651 [D loss: 0.035658, acc: 100.00%] [G loss: 9.272387]\n",
      "epoch:41 step:32652 [D loss: 0.274696, acc: 96.09%] [G loss: 5.730394]\n",
      "epoch:41 step:32653 [D loss: 0.174829, acc: 96.09%] [G loss: 6.883319]\n",
      "epoch:41 step:32654 [D loss: 0.648602, acc: 56.25%] [G loss: 5.149643]\n",
      "epoch:41 step:32655 [D loss: 0.931161, acc: 51.56%] [G loss: 4.909478]\n",
      "epoch:41 step:32656 [D loss: 0.148631, acc: 97.66%] [G loss: 4.341766]\n",
      "epoch:41 step:32657 [D loss: 0.372110, acc: 74.22%] [G loss: 7.214547]\n",
      "epoch:41 step:32658 [D loss: 1.062286, acc: 28.91%] [G loss: 6.215132]\n",
      "epoch:41 step:32659 [D loss: 0.852570, acc: 46.88%] [G loss: 6.532109]\n",
      "epoch:41 step:32660 [D loss: 0.539143, acc: 73.44%] [G loss: 6.912008]\n",
      "epoch:41 step:32661 [D loss: 0.063326, acc: 100.00%] [G loss: 7.387859]\n",
      "epoch:41 step:32662 [D loss: 0.309082, acc: 95.31%] [G loss: 4.949479]\n",
      "epoch:41 step:32663 [D loss: 0.103992, acc: 99.22%] [G loss: 6.823780]\n",
      "epoch:41 step:32664 [D loss: 1.477468, acc: 9.38%] [G loss: 6.462666]\n",
      "epoch:41 step:32665 [D loss: 0.300982, acc: 95.31%] [G loss: 5.354767]\n",
      "epoch:41 step:32666 [D loss: 0.186979, acc: 98.44%] [G loss: 6.160822]\n",
      "epoch:41 step:32667 [D loss: 0.022932, acc: 100.00%] [G loss: 6.201601]\n",
      "epoch:41 step:32668 [D loss: 0.222489, acc: 97.66%] [G loss: 4.920409]\n",
      "epoch:41 step:32669 [D loss: 0.114860, acc: 99.22%] [G loss: 3.023905]\n",
      "epoch:41 step:32670 [D loss: 0.204005, acc: 98.44%] [G loss: 4.594414]\n",
      "epoch:41 step:32671 [D loss: 0.324662, acc: 92.19%] [G loss: 7.388997]\n",
      "epoch:41 step:32672 [D loss: 0.818051, acc: 42.19%] [G loss: 4.930071]\n",
      "epoch:41 step:32673 [D loss: 0.691259, acc: 59.38%] [G loss: 5.553272]\n",
      "epoch:41 step:32674 [D loss: 0.048860, acc: 100.00%] [G loss: 7.510230]\n",
      "epoch:41 step:32675 [D loss: 0.766297, acc: 55.47%] [G loss: 6.458145]\n",
      "epoch:41 step:32676 [D loss: 0.131859, acc: 99.22%] [G loss: 6.038951]\n",
      "epoch:41 step:32677 [D loss: 0.277028, acc: 96.88%] [G loss: 4.986879]\n",
      "epoch:41 step:32678 [D loss: 0.559168, acc: 61.72%] [G loss: 5.517127]\n",
      "epoch:41 step:32679 [D loss: 0.029272, acc: 100.00%] [G loss: 4.723165]\n",
      "epoch:41 step:32680 [D loss: 0.162496, acc: 99.22%] [G loss: 6.225109]\n",
      "epoch:41 step:32681 [D loss: 0.643727, acc: 59.38%] [G loss: 8.593263]\n",
      "epoch:41 step:32682 [D loss: 0.131659, acc: 99.22%] [G loss: 6.237568]\n",
      "epoch:41 step:32683 [D loss: 0.607653, acc: 57.03%] [G loss: 3.258482]\n",
      "epoch:41 step:32684 [D loss: 0.142490, acc: 99.22%] [G loss: 4.252112]\n",
      "epoch:41 step:32685 [D loss: 0.497028, acc: 64.84%] [G loss: 9.125959]\n",
      "epoch:41 step:32686 [D loss: 1.113120, acc: 30.47%] [G loss: 4.997502]\n",
      "epoch:41 step:32687 [D loss: 0.331961, acc: 90.62%] [G loss: 6.499995]\n",
      "epoch:41 step:32688 [D loss: 0.288540, acc: 86.72%] [G loss: 6.778824]\n",
      "epoch:41 step:32689 [D loss: 0.100640, acc: 99.22%] [G loss: 2.546526]\n",
      "epoch:41 step:32690 [D loss: 0.211254, acc: 95.31%] [G loss: 5.246112]\n",
      "epoch:41 step:32691 [D loss: 0.650125, acc: 64.84%] [G loss: 4.120247]\n",
      "epoch:41 step:32692 [D loss: 0.351682, acc: 90.62%] [G loss: 5.575170]\n",
      "epoch:41 step:32693 [D loss: 0.110798, acc: 100.00%] [G loss: 7.054665]\n",
      "epoch:41 step:32694 [D loss: 0.102241, acc: 100.00%] [G loss: 6.334671]\n",
      "epoch:41 step:32695 [D loss: 0.196440, acc: 96.88%] [G loss: 5.923437]\n",
      "epoch:41 step:32696 [D loss: 0.301745, acc: 87.50%] [G loss: 4.878819]\n",
      "epoch:41 step:32697 [D loss: 0.513196, acc: 64.84%] [G loss: 3.297238]\n",
      "epoch:41 step:32698 [D loss: 0.075236, acc: 100.00%] [G loss: 5.729759]\n",
      "epoch:41 step:32699 [D loss: 0.248431, acc: 94.53%] [G loss: 2.827133]\n",
      "epoch:41 step:32700 [D loss: 0.065375, acc: 100.00%] [G loss: 6.201293]\n",
      "epoch:41 step:32701 [D loss: 0.076747, acc: 100.00%] [G loss: 4.667458]\n",
      "epoch:41 step:32702 [D loss: 0.277134, acc: 89.06%] [G loss: 7.805928]\n",
      "epoch:41 step:32703 [D loss: 0.384367, acc: 80.47%] [G loss: 5.637700]\n",
      "epoch:41 step:32704 [D loss: 0.668200, acc: 59.38%] [G loss: 5.004385]\n",
      "epoch:41 step:32705 [D loss: 0.063065, acc: 100.00%] [G loss: 5.617039]\n",
      "epoch:41 step:32706 [D loss: 0.585870, acc: 68.75%] [G loss: 5.516699]\n",
      "epoch:41 step:32707 [D loss: 0.048854, acc: 100.00%] [G loss: 3.987757]\n",
      "epoch:41 step:32708 [D loss: 1.008748, acc: 28.91%] [G loss: 7.637426]\n",
      "epoch:41 step:32709 [D loss: 0.135869, acc: 97.66%] [G loss: 5.110497]\n",
      "epoch:41 step:32710 [D loss: 0.062261, acc: 100.00%] [G loss: 4.830427]\n",
      "epoch:41 step:32711 [D loss: 0.201736, acc: 95.31%] [G loss: 6.300331]\n",
      "epoch:41 step:32712 [D loss: 0.097145, acc: 98.44%] [G loss: 6.725489]\n",
      "epoch:41 step:32713 [D loss: 0.273475, acc: 92.97%] [G loss: 7.136161]\n",
      "epoch:41 step:32714 [D loss: 0.215688, acc: 94.53%] [G loss: 8.543616]\n",
      "epoch:41 step:32715 [D loss: 0.378096, acc: 78.12%] [G loss: 4.400937]\n",
      "epoch:41 step:32716 [D loss: 0.723135, acc: 53.12%] [G loss: 8.575291]\n",
      "epoch:41 step:32717 [D loss: 0.079761, acc: 100.00%] [G loss: 4.426622]\n",
      "epoch:41 step:32718 [D loss: 0.205410, acc: 96.88%] [G loss: 4.637921]\n",
      "epoch:41 step:32719 [D loss: 0.212415, acc: 98.44%] [G loss: 6.401330]\n",
      "epoch:41 step:32720 [D loss: 0.368171, acc: 86.72%] [G loss: 5.832828]\n",
      "epoch:41 step:32721 [D loss: 0.051300, acc: 100.00%] [G loss: 5.621000]\n",
      "epoch:41 step:32722 [D loss: 0.147686, acc: 97.66%] [G loss: 5.241356]\n",
      "epoch:41 step:32723 [D loss: 0.587361, acc: 60.94%] [G loss: 5.639286]\n",
      "epoch:41 step:32724 [D loss: 0.185836, acc: 98.44%] [G loss: 4.343069]\n",
      "epoch:41 step:32725 [D loss: 0.316423, acc: 87.50%] [G loss: 4.543112]\n",
      "epoch:41 step:32726 [D loss: 0.270742, acc: 95.31%] [G loss: 6.825543]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32727 [D loss: 0.676900, acc: 53.12%] [G loss: 5.553930]\n",
      "epoch:41 step:32728 [D loss: 1.417147, acc: 48.44%] [G loss: 6.146945]\n",
      "epoch:41 step:32729 [D loss: 0.035726, acc: 100.00%] [G loss: 6.228869]\n",
      "epoch:41 step:32730 [D loss: 0.306293, acc: 84.38%] [G loss: 5.283855]\n",
      "epoch:41 step:32731 [D loss: 0.165948, acc: 98.44%] [G loss: 4.784179]\n",
      "epoch:41 step:32732 [D loss: 0.791425, acc: 53.12%] [G loss: 7.374980]\n",
      "epoch:41 step:32733 [D loss: 0.440204, acc: 76.56%] [G loss: 7.273954]\n",
      "epoch:41 step:32734 [D loss: 0.026610, acc: 100.00%] [G loss: 6.910903]\n",
      "epoch:41 step:32735 [D loss: 0.117961, acc: 98.44%] [G loss: 5.864382]\n",
      "epoch:41 step:32736 [D loss: 0.058918, acc: 100.00%] [G loss: 4.871878]\n",
      "epoch:41 step:32737 [D loss: 0.362926, acc: 85.16%] [G loss: 4.579019]\n",
      "epoch:41 step:32738 [D loss: 0.523776, acc: 68.75%] [G loss: 4.363644]\n",
      "epoch:41 step:32739 [D loss: 0.355662, acc: 85.94%] [G loss: 7.450070]\n",
      "epoch:41 step:32740 [D loss: 0.597846, acc: 55.47%] [G loss: 5.752572]\n",
      "epoch:41 step:32741 [D loss: 0.268133, acc: 95.31%] [G loss: 5.390774]\n",
      "epoch:41 step:32742 [D loss: 0.351018, acc: 79.69%] [G loss: 3.472510]\n",
      "epoch:41 step:32743 [D loss: 0.340554, acc: 85.16%] [G loss: 5.324321]\n",
      "epoch:41 step:32744 [D loss: 0.048743, acc: 100.00%] [G loss: 7.870699]\n",
      "epoch:41 step:32745 [D loss: 0.074656, acc: 100.00%] [G loss: 9.132532]\n",
      "epoch:41 step:32746 [D loss: 0.413323, acc: 75.00%] [G loss: 5.140287]\n",
      "epoch:41 step:32747 [D loss: 0.034735, acc: 100.00%] [G loss: 9.465827]\n",
      "epoch:41 step:32748 [D loss: 0.549361, acc: 73.44%] [G loss: 5.630959]\n",
      "epoch:41 step:32749 [D loss: 1.273817, acc: 50.00%] [G loss: 8.005634]\n",
      "epoch:41 step:32750 [D loss: 0.114040, acc: 99.22%] [G loss: 7.233350]\n",
      "epoch:41 step:32751 [D loss: 0.770994, acc: 53.91%] [G loss: 4.419627]\n",
      "epoch:41 step:32752 [D loss: 0.542293, acc: 71.09%] [G loss: 4.739488]\n",
      "epoch:41 step:32753 [D loss: 0.452430, acc: 69.53%] [G loss: 8.338164]\n",
      "epoch:41 step:32754 [D loss: 0.311329, acc: 82.81%] [G loss: 5.247513]\n",
      "epoch:41 step:32755 [D loss: 0.150930, acc: 99.22%] [G loss: 5.216616]\n",
      "epoch:41 step:32756 [D loss: 0.058618, acc: 100.00%] [G loss: 5.762150]\n",
      "epoch:41 step:32757 [D loss: 0.216862, acc: 96.88%] [G loss: 5.529072]\n",
      "epoch:41 step:32758 [D loss: 0.236446, acc: 95.31%] [G loss: 7.332097]\n",
      "epoch:41 step:32759 [D loss: 0.110841, acc: 98.44%] [G loss: 2.337451]\n",
      "epoch:41 step:32760 [D loss: 0.488701, acc: 72.66%] [G loss: 4.590708]\n",
      "epoch:41 step:32761 [D loss: 0.193891, acc: 100.00%] [G loss: 2.448984]\n",
      "epoch:41 step:32762 [D loss: 0.281211, acc: 96.88%] [G loss: 8.177732]\n",
      "epoch:41 step:32763 [D loss: 0.792706, acc: 53.12%] [G loss: 7.072687]\n",
      "epoch:41 step:32764 [D loss: 0.566916, acc: 63.28%] [G loss: 3.482268]\n",
      "epoch:41 step:32765 [D loss: 0.066022, acc: 99.22%] [G loss: 5.446945]\n",
      "epoch:41 step:32766 [D loss: 0.671699, acc: 59.38%] [G loss: 4.524667]\n",
      "epoch:41 step:32767 [D loss: 0.105675, acc: 100.00%] [G loss: 4.256359]\n",
      "epoch:41 step:32768 [D loss: 0.595966, acc: 64.84%] [G loss: 11.560844]\n",
      "epoch:41 step:32769 [D loss: 0.154710, acc: 99.22%] [G loss: 5.466076]\n",
      "epoch:41 step:32770 [D loss: 0.155357, acc: 97.66%] [G loss: 6.555225]\n",
      "epoch:41 step:32771 [D loss: 0.451922, acc: 67.19%] [G loss: 5.835844]\n",
      "epoch:41 step:32772 [D loss: 0.322436, acc: 89.06%] [G loss: 9.840711]\n",
      "epoch:41 step:32773 [D loss: 0.270860, acc: 94.53%] [G loss: 4.730316]\n",
      "epoch:41 step:32774 [D loss: 0.091206, acc: 100.00%] [G loss: 4.378747]\n",
      "epoch:41 step:32775 [D loss: 0.094016, acc: 99.22%] [G loss: 3.175147]\n",
      "epoch:41 step:32776 [D loss: 0.397997, acc: 74.22%] [G loss: 7.186074]\n",
      "epoch:41 step:32777 [D loss: 0.954929, acc: 51.56%] [G loss: 4.732860]\n",
      "epoch:41 step:32778 [D loss: 0.120718, acc: 98.44%] [G loss: 5.810562]\n",
      "epoch:41 step:32779 [D loss: 0.481731, acc: 71.88%] [G loss: 7.837701]\n",
      "epoch:41 step:32780 [D loss: 0.241072, acc: 90.62%] [G loss: 6.170862]\n",
      "epoch:41 step:32781 [D loss: 0.065008, acc: 99.22%] [G loss: 7.429782]\n",
      "epoch:41 step:32782 [D loss: 0.699588, acc: 62.50%] [G loss: 5.351515]\n",
      "epoch:41 step:32783 [D loss: 0.147237, acc: 98.44%] [G loss: 4.059054]\n",
      "epoch:41 step:32784 [D loss: 0.073647, acc: 99.22%] [G loss: 4.961468]\n",
      "epoch:41 step:32785 [D loss: 0.914008, acc: 41.41%] [G loss: 7.347262]\n",
      "epoch:41 step:32786 [D loss: 0.437377, acc: 78.91%] [G loss: 5.001365]\n",
      "epoch:41 step:32787 [D loss: 0.265073, acc: 89.84%] [G loss: 7.255851]\n",
      "epoch:41 step:32788 [D loss: 0.120689, acc: 99.22%] [G loss: 6.088192]\n",
      "epoch:41 step:32789 [D loss: 0.748444, acc: 48.44%] [G loss: 6.982679]\n",
      "epoch:41 step:32790 [D loss: 0.276903, acc: 89.06%] [G loss: 11.017781]\n",
      "epoch:41 step:32791 [D loss: 0.064797, acc: 100.00%] [G loss: 4.242287]\n",
      "epoch:41 step:32792 [D loss: 0.559956, acc: 63.28%] [G loss: 5.212214]\n",
      "epoch:41 step:32793 [D loss: 0.128474, acc: 99.22%] [G loss: 5.336587]\n",
      "epoch:41 step:32794 [D loss: 0.245900, acc: 90.62%] [G loss: 8.581448]\n",
      "epoch:41 step:32795 [D loss: 0.108550, acc: 100.00%] [G loss: 4.070856]\n",
      "epoch:41 step:32796 [D loss: 0.204421, acc: 97.66%] [G loss: 7.251279]\n",
      "epoch:41 step:32797 [D loss: 0.424502, acc: 82.03%] [G loss: 6.468158]\n",
      "epoch:41 step:32798 [D loss: 0.381298, acc: 80.47%] [G loss: 6.100763]\n",
      "epoch:41 step:32799 [D loss: 0.412305, acc: 83.59%] [G loss: 8.022228]\n",
      "epoch:41 step:32800 [D loss: 0.070400, acc: 99.22%] [G loss: 3.594604]\n",
      "epoch:41 step:32801 [D loss: 0.375334, acc: 78.91%] [G loss: 6.534280]\n",
      "epoch:41 step:32802 [D loss: 1.446183, acc: 46.09%] [G loss: 7.685841]\n",
      "epoch:42 step:32803 [D loss: 0.752896, acc: 54.69%] [G loss: 7.522242]\n",
      "epoch:42 step:32804 [D loss: 0.283753, acc: 92.19%] [G loss: 5.989443]\n",
      "epoch:42 step:32805 [D loss: 0.273705, acc: 92.19%] [G loss: 4.346144]\n",
      "epoch:42 step:32806 [D loss: 0.412124, acc: 71.09%] [G loss: 9.186060]\n",
      "epoch:42 step:32807 [D loss: 0.259079, acc: 94.53%] [G loss: 4.248531]\n",
      "epoch:42 step:32808 [D loss: 0.227778, acc: 95.31%] [G loss: 6.118488]\n",
      "epoch:42 step:32809 [D loss: 0.019945, acc: 100.00%] [G loss: 6.235105]\n",
      "epoch:42 step:32810 [D loss: 0.131967, acc: 99.22%] [G loss: 4.105605]\n",
      "epoch:42 step:32811 [D loss: 0.188916, acc: 99.22%] [G loss: 5.578741]\n",
      "epoch:42 step:32812 [D loss: 0.338800, acc: 89.84%] [G loss: 7.944335]\n",
      "epoch:42 step:32813 [D loss: 0.124179, acc: 100.00%] [G loss: 6.717684]\n",
      "epoch:42 step:32814 [D loss: 0.105832, acc: 98.44%] [G loss: 3.378719]\n",
      "epoch:42 step:32815 [D loss: 0.300823, acc: 85.94%] [G loss: 6.830025]\n",
      "epoch:42 step:32816 [D loss: 0.141397, acc: 97.66%] [G loss: 7.892198]\n",
      "epoch:42 step:32817 [D loss: 1.406132, acc: 10.94%] [G loss: 10.593126]\n",
      "epoch:42 step:32818 [D loss: 0.121070, acc: 100.00%] [G loss: 3.858006]\n",
      "epoch:42 step:32819 [D loss: 0.988522, acc: 21.88%] [G loss: 5.241179]\n",
      "epoch:42 step:32820 [D loss: 0.600090, acc: 64.06%] [G loss: 3.307397]\n",
      "epoch:42 step:32821 [D loss: 0.055450, acc: 100.00%] [G loss: 6.868064]\n",
      "epoch:42 step:32822 [D loss: 0.689794, acc: 64.84%] [G loss: 5.735355]\n",
      "epoch:42 step:32823 [D loss: 0.397585, acc: 75.78%] [G loss: 5.448082]\n",
      "epoch:42 step:32824 [D loss: 0.576906, acc: 69.53%] [G loss: 6.825792]\n",
      "epoch:42 step:32825 [D loss: 0.105988, acc: 100.00%] [G loss: 6.548092]\n",
      "epoch:42 step:32826 [D loss: 1.115995, acc: 40.62%] [G loss: 8.714941]\n",
      "epoch:42 step:32827 [D loss: 0.062229, acc: 99.22%] [G loss: 3.273787]\n",
      "epoch:42 step:32828 [D loss: 0.084049, acc: 100.00%] [G loss: 7.575392]\n",
      "epoch:42 step:32829 [D loss: 0.651228, acc: 56.25%] [G loss: 8.288859]\n",
      "epoch:42 step:32830 [D loss: 0.265041, acc: 85.94%] [G loss: 8.304577]\n",
      "epoch:42 step:32831 [D loss: 0.556459, acc: 68.75%] [G loss: 6.379467]\n",
      "epoch:42 step:32832 [D loss: 0.281471, acc: 85.94%] [G loss: 7.984449]\n",
      "epoch:42 step:32833 [D loss: 0.308251, acc: 93.75%] [G loss: 7.951102]\n",
      "epoch:42 step:32834 [D loss: 0.603395, acc: 66.41%] [G loss: 6.318886]\n",
      "epoch:42 step:32835 [D loss: 0.092885, acc: 99.22%] [G loss: 3.886872]\n",
      "epoch:42 step:32836 [D loss: 0.267677, acc: 97.66%] [G loss: 3.357170]\n",
      "epoch:42 step:32837 [D loss: 0.479072, acc: 65.62%] [G loss: 6.425602]\n",
      "epoch:42 step:32838 [D loss: 0.037428, acc: 100.00%] [G loss: 8.812962]\n",
      "epoch:42 step:32839 [D loss: 1.630319, acc: 50.00%] [G loss: 4.532864]\n",
      "epoch:42 step:32840 [D loss: 0.506279, acc: 72.66%] [G loss: 6.295766]\n",
      "epoch:42 step:32841 [D loss: 0.324186, acc: 85.94%] [G loss: 5.193158]\n",
      "epoch:42 step:32842 [D loss: 0.201888, acc: 99.22%] [G loss: 4.914384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:32843 [D loss: 0.235797, acc: 96.09%] [G loss: 4.514269]\n",
      "epoch:42 step:32844 [D loss: 0.112044, acc: 100.00%] [G loss: 2.548373]\n",
      "epoch:42 step:32845 [D loss: 0.425246, acc: 75.78%] [G loss: 5.158437]\n",
      "epoch:42 step:32846 [D loss: 1.346995, acc: 50.00%] [G loss: 8.057421]\n",
      "epoch:42 step:32847 [D loss: 0.270917, acc: 89.06%] [G loss: 8.142128]\n",
      "epoch:42 step:32848 [D loss: 0.156011, acc: 98.44%] [G loss: 5.808666]\n",
      "epoch:42 step:32849 [D loss: 0.048172, acc: 100.00%] [G loss: 5.978637]\n",
      "epoch:42 step:32850 [D loss: 0.137370, acc: 99.22%] [G loss: 3.959425]\n",
      "epoch:42 step:32851 [D loss: 0.219986, acc: 94.53%] [G loss: 3.160547]\n",
      "epoch:42 step:32852 [D loss: 0.824386, acc: 42.19%] [G loss: 6.689214]\n",
      "epoch:42 step:32853 [D loss: 0.130176, acc: 100.00%] [G loss: 4.237892]\n",
      "epoch:42 step:32854 [D loss: 0.201663, acc: 96.88%] [G loss: 6.298868]\n",
      "epoch:42 step:32855 [D loss: 0.211936, acc: 97.66%] [G loss: 6.337057]\n",
      "epoch:42 step:32856 [D loss: 0.341506, acc: 86.72%] [G loss: 4.026660]\n",
      "epoch:42 step:32857 [D loss: 0.049457, acc: 100.00%] [G loss: 5.180765]\n",
      "epoch:42 step:32858 [D loss: 0.348479, acc: 91.41%] [G loss: 7.507254]\n",
      "epoch:42 step:32859 [D loss: 0.214073, acc: 97.66%] [G loss: 5.901748]\n",
      "epoch:42 step:32860 [D loss: 0.145429, acc: 99.22%] [G loss: 6.558442]\n",
      "epoch:42 step:32861 [D loss: 0.316343, acc: 92.19%] [G loss: 5.751237]\n",
      "epoch:42 step:32862 [D loss: 0.274012, acc: 88.28%] [G loss: 2.020027]\n",
      "epoch:42 step:32863 [D loss: 0.333868, acc: 84.38%] [G loss: 4.344731]\n",
      "epoch:42 step:32864 [D loss: 0.173375, acc: 98.44%] [G loss: 4.794044]\n",
      "epoch:42 step:32865 [D loss: 0.517797, acc: 70.31%] [G loss: 7.759698]\n",
      "epoch:42 step:32866 [D loss: 0.684015, acc: 56.25%] [G loss: 6.386790]\n",
      "epoch:42 step:32867 [D loss: 0.385378, acc: 77.34%] [G loss: 5.229306]\n",
      "epoch:42 step:32868 [D loss: 0.277466, acc: 95.31%] [G loss: 5.792281]\n",
      "epoch:42 step:32869 [D loss: 0.204045, acc: 94.53%] [G loss: 4.424038]\n",
      "epoch:42 step:32870 [D loss: 0.321780, acc: 89.84%] [G loss: 8.994139]\n",
      "epoch:42 step:32871 [D loss: 0.119089, acc: 100.00%] [G loss: 5.573899]\n",
      "epoch:42 step:32872 [D loss: 0.148845, acc: 96.09%] [G loss: 8.037147]\n",
      "epoch:42 step:32873 [D loss: 0.482971, acc: 65.62%] [G loss: 7.225447]\n",
      "epoch:42 step:32874 [D loss: 0.029863, acc: 100.00%] [G loss: 5.387424]\n",
      "epoch:42 step:32875 [D loss: 0.886336, acc: 50.78%] [G loss: 7.508633]\n",
      "epoch:42 step:32876 [D loss: 0.328684, acc: 80.47%] [G loss: 3.978683]\n",
      "epoch:42 step:32877 [D loss: 0.020956, acc: 100.00%] [G loss: 5.652110]\n",
      "epoch:42 step:32878 [D loss: 0.309583, acc: 85.94%] [G loss: 1.464525]\n",
      "epoch:42 step:32879 [D loss: 0.987377, acc: 37.50%] [G loss: 6.549860]\n",
      "epoch:42 step:32880 [D loss: 0.886124, acc: 53.12%] [G loss: 7.000988]\n",
      "epoch:42 step:32881 [D loss: 0.378210, acc: 85.16%] [G loss: 5.859341]\n",
      "epoch:42 step:32882 [D loss: 0.524480, acc: 64.06%] [G loss: 3.930890]\n",
      "epoch:42 step:32883 [D loss: 0.294064, acc: 89.84%] [G loss: 8.422094]\n",
      "epoch:42 step:32884 [D loss: 0.109760, acc: 100.00%] [G loss: 5.863410]\n",
      "epoch:42 step:32885 [D loss: 0.120023, acc: 99.22%] [G loss: 5.030911]\n",
      "epoch:42 step:32886 [D loss: 0.439213, acc: 69.53%] [G loss: 4.943470]\n",
      "epoch:42 step:32887 [D loss: 0.087795, acc: 99.22%] [G loss: 5.436061]\n",
      "epoch:42 step:32888 [D loss: 0.603218, acc: 65.62%] [G loss: 7.804790]\n",
      "epoch:42 step:32889 [D loss: 0.299826, acc: 82.03%] [G loss: 4.450422]\n",
      "epoch:42 step:32890 [D loss: 1.199052, acc: 25.78%] [G loss: 3.709520]\n",
      "epoch:42 step:32891 [D loss: 0.986015, acc: 50.78%] [G loss: 10.096576]\n",
      "epoch:42 step:32892 [D loss: 0.606428, acc: 60.16%] [G loss: 7.823194]\n",
      "epoch:42 step:32893 [D loss: 0.045658, acc: 99.22%] [G loss: 8.673859]\n",
      "epoch:42 step:32894 [D loss: 0.070302, acc: 99.22%] [G loss: 7.229647]\n",
      "epoch:42 step:32895 [D loss: 0.165379, acc: 98.44%] [G loss: 5.733820]\n",
      "epoch:42 step:32896 [D loss: 1.051875, acc: 46.88%] [G loss: 5.415378]\n",
      "epoch:42 step:32897 [D loss: 1.443659, acc: 26.56%] [G loss: 5.914745]\n",
      "epoch:42 step:32898 [D loss: 0.567698, acc: 61.72%] [G loss: 5.921405]\n",
      "epoch:42 step:32899 [D loss: 1.363053, acc: 50.00%] [G loss: 7.262552]\n",
      "epoch:42 step:32900 [D loss: 0.112726, acc: 100.00%] [G loss: 4.355106]\n",
      "epoch:42 step:32901 [D loss: 0.202899, acc: 96.88%] [G loss: 4.357806]\n",
      "epoch:42 step:32902 [D loss: 0.279742, acc: 90.62%] [G loss: 5.582460]\n",
      "epoch:42 step:32903 [D loss: 0.160177, acc: 99.22%] [G loss: 4.242148]\n",
      "epoch:42 step:32904 [D loss: 0.148920, acc: 99.22%] [G loss: 8.110493]\n",
      "epoch:42 step:32905 [D loss: 0.141195, acc: 99.22%] [G loss: 4.683697]\n",
      "epoch:42 step:32906 [D loss: 0.105786, acc: 100.00%] [G loss: 7.003608]\n",
      "epoch:42 step:32907 [D loss: 0.126144, acc: 99.22%] [G loss: 5.192873]\n",
      "epoch:42 step:32908 [D loss: 0.071816, acc: 99.22%] [G loss: 5.928954]\n",
      "epoch:42 step:32909 [D loss: 0.032676, acc: 100.00%] [G loss: 5.089966]\n",
      "epoch:42 step:32910 [D loss: 0.605904, acc: 58.59%] [G loss: 7.503727]\n",
      "epoch:42 step:32911 [D loss: 0.968136, acc: 43.75%] [G loss: 2.803864]\n",
      "epoch:42 step:32912 [D loss: 0.262841, acc: 88.28%] [G loss: 4.020034]\n",
      "epoch:42 step:32913 [D loss: 0.008893, acc: 100.00%] [G loss: 6.970892]\n",
      "epoch:42 step:32914 [D loss: 0.383589, acc: 78.12%] [G loss: 5.939518]\n",
      "epoch:42 step:32915 [D loss: 0.388512, acc: 89.84%] [G loss: 6.016809]\n",
      "epoch:42 step:32916 [D loss: 0.217115, acc: 96.09%] [G loss: 5.484480]\n",
      "epoch:42 step:32917 [D loss: 0.202594, acc: 100.00%] [G loss: 3.533385]\n",
      "epoch:42 step:32918 [D loss: 0.479253, acc: 79.69%] [G loss: 6.006460]\n",
      "epoch:42 step:32919 [D loss: 0.106021, acc: 99.22%] [G loss: 2.971004]\n",
      "epoch:42 step:32920 [D loss: 0.114273, acc: 100.00%] [G loss: 5.963398]\n",
      "epoch:42 step:32921 [D loss: 0.033359, acc: 100.00%] [G loss: 4.663188]\n",
      "epoch:42 step:32922 [D loss: 0.532683, acc: 60.94%] [G loss: 4.349352]\n",
      "epoch:42 step:32923 [D loss: 0.349107, acc: 89.84%] [G loss: 3.509131]\n",
      "epoch:42 step:32924 [D loss: 0.461528, acc: 83.59%] [G loss: 7.399316]\n",
      "epoch:42 step:32925 [D loss: 0.162726, acc: 96.88%] [G loss: 3.530618]\n",
      "epoch:42 step:32926 [D loss: 0.174608, acc: 98.44%] [G loss: 7.707442]\n",
      "epoch:42 step:32927 [D loss: 0.583103, acc: 58.59%] [G loss: 6.899364]\n",
      "epoch:42 step:32928 [D loss: 0.926640, acc: 50.78%] [G loss: 4.590086]\n",
      "epoch:42 step:32929 [D loss: 0.124363, acc: 99.22%] [G loss: 2.730093]\n",
      "epoch:42 step:32930 [D loss: 0.327558, acc: 91.41%] [G loss: 5.331952]\n",
      "epoch:42 step:32931 [D loss: 0.198624, acc: 97.66%] [G loss: 6.701082]\n",
      "epoch:42 step:32932 [D loss: 0.202034, acc: 94.53%] [G loss: 6.826986]\n",
      "epoch:42 step:32933 [D loss: 1.026700, acc: 51.56%] [G loss: 8.296698]\n",
      "epoch:42 step:32934 [D loss: 0.681661, acc: 62.50%] [G loss: 6.338810]\n",
      "epoch:42 step:32935 [D loss: 0.527590, acc: 69.53%] [G loss: 6.271896]\n",
      "epoch:42 step:32936 [D loss: 0.092783, acc: 100.00%] [G loss: 6.350948]\n",
      "epoch:42 step:32937 [D loss: 0.067823, acc: 100.00%] [G loss: 8.697237]\n",
      "epoch:42 step:32938 [D loss: 0.439412, acc: 80.47%] [G loss: 4.442449]\n",
      "epoch:42 step:32939 [D loss: 0.207692, acc: 95.31%] [G loss: 7.120654]\n",
      "epoch:42 step:32940 [D loss: 1.236036, acc: 42.97%] [G loss: 9.465046]\n",
      "epoch:42 step:32941 [D loss: 0.136437, acc: 99.22%] [G loss: 6.483411]\n",
      "epoch:42 step:32942 [D loss: 0.205412, acc: 95.31%] [G loss: 3.932810]\n",
      "epoch:42 step:32943 [D loss: 0.664035, acc: 55.47%] [G loss: 5.861227]\n",
      "epoch:42 step:32944 [D loss: 0.799720, acc: 53.12%] [G loss: 6.051152]\n",
      "epoch:42 step:32945 [D loss: 1.121916, acc: 50.00%] [G loss: 5.601115]\n",
      "epoch:42 step:32946 [D loss: 0.723383, acc: 58.59%] [G loss: 5.262658]\n",
      "epoch:42 step:32947 [D loss: 0.039414, acc: 100.00%] [G loss: 6.709849]\n",
      "epoch:42 step:32948 [D loss: 0.153785, acc: 97.66%] [G loss: 5.798331]\n",
      "epoch:42 step:32949 [D loss: 0.137063, acc: 99.22%] [G loss: 5.617552]\n",
      "epoch:42 step:32950 [D loss: 0.402976, acc: 88.28%] [G loss: 5.560234]\n",
      "epoch:42 step:32951 [D loss: 0.267634, acc: 92.19%] [G loss: 5.744321]\n",
      "epoch:42 step:32952 [D loss: 0.875351, acc: 51.56%] [G loss: 3.547499]\n",
      "epoch:42 step:32953 [D loss: 0.294773, acc: 86.72%] [G loss: 4.705403]\n",
      "epoch:42 step:32954 [D loss: 1.131950, acc: 51.56%] [G loss: 7.371690]\n",
      "epoch:42 step:32955 [D loss: 0.323626, acc: 84.38%] [G loss: 5.889174]\n",
      "epoch:42 step:32956 [D loss: 0.403597, acc: 77.34%] [G loss: 4.581446]\n",
      "epoch:42 step:32957 [D loss: 0.113124, acc: 99.22%] [G loss: 6.086149]\n",
      "epoch:42 step:32958 [D loss: 0.810907, acc: 52.34%] [G loss: 6.025648]\n",
      "epoch:42 step:32959 [D loss: 0.740039, acc: 57.03%] [G loss: 8.133947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:32960 [D loss: 0.735108, acc: 57.81%] [G loss: 7.039581]\n",
      "epoch:42 step:32961 [D loss: 0.089638, acc: 100.00%] [G loss: 7.365903]\n",
      "epoch:42 step:32962 [D loss: 0.770613, acc: 53.12%] [G loss: 6.207430]\n",
      "epoch:42 step:32963 [D loss: 0.261458, acc: 92.97%] [G loss: 4.619783]\n",
      "epoch:42 step:32964 [D loss: 0.652216, acc: 58.59%] [G loss: 3.679267]\n",
      "epoch:42 step:32965 [D loss: 0.585776, acc: 74.22%] [G loss: 7.561456]\n",
      "epoch:42 step:32966 [D loss: 0.174192, acc: 97.66%] [G loss: 5.229936]\n",
      "epoch:42 step:32967 [D loss: 0.188893, acc: 99.22%] [G loss: 7.739229]\n",
      "epoch:42 step:32968 [D loss: 0.399649, acc: 82.03%] [G loss: 6.215343]\n",
      "epoch:42 step:32969 [D loss: 0.405701, acc: 74.22%] [G loss: 5.805833]\n",
      "epoch:42 step:32970 [D loss: 0.166356, acc: 96.88%] [G loss: 4.296773]\n",
      "epoch:42 step:32971 [D loss: 0.635832, acc: 64.84%] [G loss: 5.949602]\n",
      "epoch:42 step:32972 [D loss: 0.283812, acc: 94.53%] [G loss: 4.615665]\n",
      "epoch:42 step:32973 [D loss: 0.258687, acc: 96.88%] [G loss: 5.494723]\n",
      "epoch:42 step:32974 [D loss: 0.702963, acc: 58.59%] [G loss: 8.172415]\n",
      "epoch:42 step:32975 [D loss: 0.296640, acc: 89.84%] [G loss: 3.999215]\n",
      "epoch:42 step:32976 [D loss: 0.120043, acc: 99.22%] [G loss: 3.819076]\n",
      "epoch:42 step:32977 [D loss: 0.122915, acc: 99.22%] [G loss: 8.634784]\n",
      "epoch:42 step:32978 [D loss: 1.199203, acc: 28.12%] [G loss: 9.209762]\n",
      "epoch:42 step:32979 [D loss: 0.116266, acc: 99.22%] [G loss: 3.666001]\n",
      "epoch:42 step:32980 [D loss: 0.687914, acc: 60.16%] [G loss: 5.825057]\n",
      "epoch:42 step:32981 [D loss: 0.311336, acc: 92.97%] [G loss: 5.727454]\n",
      "epoch:42 step:32982 [D loss: 0.254085, acc: 93.75%] [G loss: 3.528948]\n",
      "epoch:42 step:32983 [D loss: 1.395132, acc: 19.53%] [G loss: 3.941113]\n",
      "epoch:42 step:32984 [D loss: 0.533446, acc: 65.62%] [G loss: 5.437306]\n",
      "epoch:42 step:32985 [D loss: 0.209085, acc: 94.53%] [G loss: 9.488169]\n",
      "epoch:42 step:32986 [D loss: 0.903967, acc: 51.56%] [G loss: 10.865628]\n",
      "epoch:42 step:32987 [D loss: 0.464047, acc: 65.62%] [G loss: 6.844997]\n",
      "epoch:42 step:32988 [D loss: 0.188630, acc: 97.66%] [G loss: 4.106085]\n",
      "epoch:42 step:32989 [D loss: 1.488717, acc: 5.47%] [G loss: 6.155651]\n",
      "epoch:42 step:32990 [D loss: 0.105587, acc: 99.22%] [G loss: 4.576071]\n",
      "epoch:42 step:32991 [D loss: 0.141774, acc: 97.66%] [G loss: 8.783615]\n",
      "epoch:42 step:32992 [D loss: 0.171702, acc: 95.31%] [G loss: 7.740239]\n",
      "epoch:42 step:32993 [D loss: 1.608527, acc: 14.06%] [G loss: 7.169271]\n",
      "epoch:42 step:32994 [D loss: 0.686704, acc: 60.16%] [G loss: 5.487222]\n",
      "epoch:42 step:32995 [D loss: 0.505737, acc: 76.56%] [G loss: 4.203884]\n",
      "epoch:42 step:32996 [D loss: 0.106575, acc: 98.44%] [G loss: 4.826643]\n",
      "epoch:42 step:32997 [D loss: 0.227976, acc: 95.31%] [G loss: 6.247646]\n",
      "epoch:42 step:32998 [D loss: 0.331310, acc: 86.72%] [G loss: 4.744869]\n",
      "epoch:42 step:32999 [D loss: 0.202580, acc: 97.66%] [G loss: 5.815043]\n",
      "epoch:42 step:33000 [D loss: 1.290017, acc: 43.75%] [G loss: 9.993811]\n",
      "epoch:42 step:33001 [D loss: 0.154281, acc: 97.66%] [G loss: 4.285126]\n",
      "epoch:42 step:33002 [D loss: 0.009353, acc: 100.00%] [G loss: 7.941189]\n",
      "epoch:42 step:33003 [D loss: 0.238987, acc: 95.31%] [G loss: 6.708391]\n",
      "epoch:42 step:33004 [D loss: 0.034230, acc: 100.00%] [G loss: 3.707332]\n",
      "epoch:42 step:33005 [D loss: 0.535231, acc: 67.97%] [G loss: 8.441381]\n",
      "epoch:42 step:33006 [D loss: 0.464562, acc: 74.22%] [G loss: 5.824515]\n",
      "epoch:42 step:33007 [D loss: 0.110486, acc: 99.22%] [G loss: 9.606516]\n",
      "epoch:42 step:33008 [D loss: 0.116411, acc: 99.22%] [G loss: 3.397058]\n",
      "epoch:42 step:33009 [D loss: 0.425589, acc: 85.16%] [G loss: 7.358113]\n",
      "epoch:42 step:33010 [D loss: 0.102713, acc: 99.22%] [G loss: 9.538585]\n",
      "epoch:42 step:33011 [D loss: 1.116396, acc: 14.84%] [G loss: 7.260601]\n",
      "epoch:42 step:33012 [D loss: 0.332494, acc: 87.50%] [G loss: 2.662457]\n",
      "epoch:42 step:33013 [D loss: 0.360999, acc: 89.06%] [G loss: 4.085906]\n",
      "epoch:42 step:33014 [D loss: 0.084922, acc: 100.00%] [G loss: 3.212243]\n",
      "epoch:42 step:33015 [D loss: 0.453601, acc: 71.09%] [G loss: 7.595311]\n",
      "epoch:42 step:33016 [D loss: 0.905250, acc: 51.56%] [G loss: 4.966838]\n",
      "epoch:42 step:33017 [D loss: 0.068419, acc: 100.00%] [G loss: 7.070614]\n",
      "epoch:42 step:33018 [D loss: 0.829875, acc: 37.50%] [G loss: 6.133606]\n",
      "epoch:42 step:33019 [D loss: 0.627749, acc: 61.72%] [G loss: 4.768612]\n",
      "epoch:42 step:33020 [D loss: 0.083217, acc: 100.00%] [G loss: 5.283732]\n",
      "epoch:42 step:33021 [D loss: 0.225673, acc: 92.19%] [G loss: 5.982428]\n",
      "epoch:42 step:33022 [D loss: 0.703622, acc: 60.94%] [G loss: 4.499996]\n",
      "epoch:42 step:33023 [D loss: 0.194841, acc: 96.88%] [G loss: 6.526539]\n",
      "epoch:42 step:33024 [D loss: 0.076290, acc: 100.00%] [G loss: 4.779865]\n",
      "epoch:42 step:33025 [D loss: 0.099814, acc: 99.22%] [G loss: 2.761863]\n",
      "epoch:42 step:33026 [D loss: 0.266614, acc: 89.84%] [G loss: 4.953512]\n",
      "epoch:42 step:33027 [D loss: 0.392324, acc: 80.47%] [G loss: 3.730144]\n",
      "epoch:42 step:33028 [D loss: 0.245333, acc: 92.97%] [G loss: 6.852036]\n",
      "epoch:42 step:33029 [D loss: 0.119804, acc: 96.88%] [G loss: 4.278654]\n",
      "epoch:42 step:33030 [D loss: 0.128026, acc: 98.44%] [G loss: 5.472487]\n",
      "epoch:42 step:33031 [D loss: 0.175571, acc: 98.44%] [G loss: 4.774855]\n",
      "epoch:42 step:33032 [D loss: 0.492814, acc: 64.06%] [G loss: 7.673623]\n",
      "epoch:42 step:33033 [D loss: 0.433132, acc: 84.38%] [G loss: 5.597868]\n",
      "epoch:42 step:33034 [D loss: 0.093052, acc: 100.00%] [G loss: 5.050580]\n",
      "epoch:42 step:33035 [D loss: 0.187132, acc: 95.31%] [G loss: 5.322724]\n",
      "epoch:42 step:33036 [D loss: 0.118207, acc: 98.44%] [G loss: 6.230485]\n",
      "epoch:42 step:33037 [D loss: 0.890933, acc: 42.19%] [G loss: 5.746201]\n",
      "epoch:42 step:33038 [D loss: 0.402412, acc: 75.00%] [G loss: 5.990247]\n",
      "epoch:42 step:33039 [D loss: 0.767823, acc: 53.12%] [G loss: 5.829905]\n",
      "epoch:42 step:33040 [D loss: 1.135878, acc: 50.78%] [G loss: 6.325919]\n",
      "epoch:42 step:33041 [D loss: 1.466548, acc: 50.00%] [G loss: 6.834611]\n",
      "epoch:42 step:33042 [D loss: 0.334002, acc: 85.94%] [G loss: 2.765494]\n",
      "epoch:42 step:33043 [D loss: 1.514017, acc: 50.00%] [G loss: 5.826589]\n",
      "epoch:42 step:33044 [D loss: 0.053624, acc: 99.22%] [G loss: 4.536088]\n",
      "epoch:42 step:33045 [D loss: 0.903388, acc: 56.25%] [G loss: 9.682076]\n",
      "epoch:42 step:33046 [D loss: 0.197871, acc: 98.44%] [G loss: 4.848850]\n",
      "epoch:42 step:33047 [D loss: 0.152115, acc: 96.88%] [G loss: 5.278992]\n",
      "epoch:42 step:33048 [D loss: 0.350313, acc: 89.06%] [G loss: 6.811825]\n",
      "epoch:42 step:33049 [D loss: 0.333149, acc: 92.19%] [G loss: 4.928586]\n",
      "epoch:42 step:33050 [D loss: 0.515405, acc: 62.50%] [G loss: 3.934944]\n",
      "epoch:42 step:33051 [D loss: 0.160709, acc: 97.66%] [G loss: 5.761340]\n",
      "epoch:42 step:33052 [D loss: 0.023155, acc: 99.22%] [G loss: 7.757350]\n",
      "epoch:42 step:33053 [D loss: 0.110806, acc: 100.00%] [G loss: 8.347792]\n",
      "epoch:42 step:33054 [D loss: 0.320798, acc: 83.59%] [G loss: 5.566118]\n",
      "epoch:42 step:33055 [D loss: 0.141811, acc: 97.66%] [G loss: 3.317988]\n",
      "epoch:42 step:33056 [D loss: 0.452079, acc: 70.31%] [G loss: 4.010113]\n",
      "epoch:42 step:33057 [D loss: 0.021246, acc: 100.00%] [G loss: 4.981298]\n",
      "epoch:42 step:33058 [D loss: 0.136098, acc: 99.22%] [G loss: 3.108849]\n",
      "epoch:42 step:33059 [D loss: 0.338762, acc: 82.03%] [G loss: 6.752954]\n",
      "epoch:42 step:33060 [D loss: 0.597293, acc: 64.06%] [G loss: 6.093000]\n",
      "epoch:42 step:33061 [D loss: 0.109604, acc: 99.22%] [G loss: 5.015944]\n",
      "epoch:42 step:33062 [D loss: 0.246496, acc: 96.88%] [G loss: 5.285705]\n",
      "epoch:42 step:33063 [D loss: 0.221867, acc: 96.88%] [G loss: 2.435932]\n",
      "epoch:42 step:33064 [D loss: 0.219955, acc: 93.75%] [G loss: 2.499387]\n",
      "epoch:42 step:33065 [D loss: 1.002448, acc: 46.09%] [G loss: 5.242527]\n",
      "epoch:42 step:33066 [D loss: 0.225050, acc: 96.09%] [G loss: 6.276529]\n",
      "epoch:42 step:33067 [D loss: 0.652736, acc: 54.69%] [G loss: 7.147466]\n",
      "epoch:42 step:33068 [D loss: 0.253918, acc: 96.09%] [G loss: 8.206203]\n",
      "epoch:42 step:33069 [D loss: 0.487553, acc: 67.19%] [G loss: 4.786752]\n",
      "epoch:42 step:33070 [D loss: 0.083477, acc: 100.00%] [G loss: 3.026346]\n",
      "epoch:42 step:33071 [D loss: 0.095804, acc: 99.22%] [G loss: 5.345590]\n",
      "epoch:42 step:33072 [D loss: 0.104954, acc: 100.00%] [G loss: 3.629816]\n",
      "epoch:42 step:33073 [D loss: 1.545862, acc: 7.81%] [G loss: 6.797788]\n",
      "epoch:42 step:33074 [D loss: 0.318703, acc: 88.28%] [G loss: 4.805807]\n",
      "epoch:42 step:33075 [D loss: 0.077454, acc: 100.00%] [G loss: 6.497245]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33076 [D loss: 1.186822, acc: 24.22%] [G loss: 5.146069]\n",
      "epoch:42 step:33077 [D loss: 0.066887, acc: 99.22%] [G loss: 4.416983]\n",
      "epoch:42 step:33078 [D loss: 0.299806, acc: 89.84%] [G loss: 4.987611]\n",
      "epoch:42 step:33079 [D loss: 0.359979, acc: 90.62%] [G loss: 7.081756]\n",
      "epoch:42 step:33080 [D loss: 0.125100, acc: 99.22%] [G loss: 6.669832]\n",
      "epoch:42 step:33081 [D loss: 0.025521, acc: 100.00%] [G loss: 5.858813]\n",
      "epoch:42 step:33082 [D loss: 0.111322, acc: 100.00%] [G loss: 3.681400]\n",
      "epoch:42 step:33083 [D loss: 0.473053, acc: 78.91%] [G loss: 8.571739]\n",
      "epoch:42 step:33084 [D loss: 0.329352, acc: 87.50%] [G loss: 7.317143]\n",
      "epoch:42 step:33085 [D loss: 0.314529, acc: 93.75%] [G loss: 4.782459]\n",
      "epoch:42 step:33086 [D loss: 0.074053, acc: 100.00%] [G loss: 7.765518]\n",
      "epoch:42 step:33087 [D loss: 0.203482, acc: 96.09%] [G loss: 6.647489]\n",
      "epoch:42 step:33088 [D loss: 0.410364, acc: 87.50%] [G loss: 2.654378]\n",
      "epoch:42 step:33089 [D loss: 0.319091, acc: 80.47%] [G loss: 8.076267]\n",
      "epoch:42 step:33090 [D loss: 0.074178, acc: 99.22%] [G loss: 5.968762]\n",
      "epoch:42 step:33091 [D loss: 0.191038, acc: 96.09%] [G loss: 8.009977]\n",
      "epoch:42 step:33092 [D loss: 0.176298, acc: 97.66%] [G loss: 5.048401]\n",
      "epoch:42 step:33093 [D loss: 0.099928, acc: 100.00%] [G loss: 6.502400]\n",
      "epoch:42 step:33094 [D loss: 0.143850, acc: 100.00%] [G loss: 6.105748]\n",
      "epoch:42 step:33095 [D loss: 0.093493, acc: 99.22%] [G loss: 8.154348]\n",
      "epoch:42 step:33096 [D loss: 1.697783, acc: 50.00%] [G loss: 6.025983]\n",
      "epoch:42 step:33097 [D loss: 0.964181, acc: 52.34%] [G loss: 5.750890]\n",
      "epoch:42 step:33098 [D loss: 0.042453, acc: 100.00%] [G loss: 9.934505]\n",
      "epoch:42 step:33099 [D loss: 0.722055, acc: 54.69%] [G loss: 5.072549]\n",
      "epoch:42 step:33100 [D loss: 0.179024, acc: 96.88%] [G loss: 4.364991]\n",
      "epoch:42 step:33101 [D loss: 0.713002, acc: 59.38%] [G loss: 3.827536]\n",
      "epoch:42 step:33102 [D loss: 0.604493, acc: 64.84%] [G loss: 7.106816]\n",
      "epoch:42 step:33103 [D loss: 0.777744, acc: 53.12%] [G loss: 4.924359]\n",
      "epoch:42 step:33104 [D loss: 0.068908, acc: 100.00%] [G loss: 5.055202]\n",
      "epoch:42 step:33105 [D loss: 0.848100, acc: 53.12%] [G loss: 7.316990]\n",
      "epoch:42 step:33106 [D loss: 0.133445, acc: 100.00%] [G loss: 7.239404]\n",
      "epoch:42 step:33107 [D loss: 1.066536, acc: 49.22%] [G loss: 7.228182]\n",
      "epoch:42 step:33108 [D loss: 0.137134, acc: 99.22%] [G loss: 6.906342]\n",
      "epoch:42 step:33109 [D loss: 0.932796, acc: 45.31%] [G loss: 5.495650]\n",
      "epoch:42 step:33110 [D loss: 0.085650, acc: 99.22%] [G loss: 8.031089]\n",
      "epoch:42 step:33111 [D loss: 0.026033, acc: 100.00%] [G loss: 3.150561]\n",
      "epoch:42 step:33112 [D loss: 0.186736, acc: 96.09%] [G loss: 7.741490]\n",
      "epoch:42 step:33113 [D loss: 0.057954, acc: 100.00%] [G loss: 5.559726]\n",
      "epoch:42 step:33114 [D loss: 0.679109, acc: 59.38%] [G loss: 5.488183]\n",
      "epoch:42 step:33115 [D loss: 0.597404, acc: 60.94%] [G loss: 8.034394]\n",
      "epoch:42 step:33116 [D loss: 0.100774, acc: 100.00%] [G loss: 9.783939]\n",
      "epoch:42 step:33117 [D loss: 0.424602, acc: 81.25%] [G loss: 6.779876]\n",
      "epoch:42 step:33118 [D loss: 0.033224, acc: 100.00%] [G loss: 4.884262]\n",
      "epoch:42 step:33119 [D loss: 0.833755, acc: 42.97%] [G loss: 5.215286]\n",
      "epoch:42 step:33120 [D loss: 0.307739, acc: 90.62%] [G loss: 5.758507]\n",
      "epoch:42 step:33121 [D loss: 0.424130, acc: 74.22%] [G loss: 5.291461]\n",
      "epoch:42 step:33122 [D loss: 0.031127, acc: 100.00%] [G loss: 5.064855]\n",
      "epoch:42 step:33123 [D loss: 0.616314, acc: 62.50%] [G loss: 5.720660]\n",
      "epoch:42 step:33124 [D loss: 0.444862, acc: 70.31%] [G loss: 4.726531]\n",
      "epoch:42 step:33125 [D loss: 0.553967, acc: 69.53%] [G loss: 5.149605]\n",
      "epoch:42 step:33126 [D loss: 0.203863, acc: 96.09%] [G loss: 2.927341]\n",
      "epoch:42 step:33127 [D loss: 0.028622, acc: 100.00%] [G loss: 5.666091]\n",
      "epoch:42 step:33128 [D loss: 0.153232, acc: 96.88%] [G loss: 3.195905]\n",
      "epoch:42 step:33129 [D loss: 0.179376, acc: 97.66%] [G loss: 6.750949]\n",
      "epoch:42 step:33130 [D loss: 0.154105, acc: 99.22%] [G loss: 9.069758]\n",
      "epoch:42 step:33131 [D loss: 0.049797, acc: 100.00%] [G loss: 5.528859]\n",
      "epoch:42 step:33132 [D loss: 0.260594, acc: 96.09%] [G loss: 7.227399]\n",
      "epoch:42 step:33133 [D loss: 0.096398, acc: 98.44%] [G loss: 9.869439]\n",
      "epoch:42 step:33134 [D loss: 1.115693, acc: 50.00%] [G loss: 7.040691]\n",
      "epoch:42 step:33135 [D loss: 0.058138, acc: 100.00%] [G loss: 8.915444]\n",
      "epoch:42 step:33136 [D loss: 0.827765, acc: 37.50%] [G loss: 7.971123]\n",
      "epoch:42 step:33137 [D loss: 0.021353, acc: 100.00%] [G loss: 7.153244]\n",
      "epoch:42 step:33138 [D loss: 0.086025, acc: 100.00%] [G loss: 6.158133]\n",
      "epoch:42 step:33139 [D loss: 0.449816, acc: 78.12%] [G loss: 7.334600]\n",
      "epoch:42 step:33140 [D loss: 0.291706, acc: 94.53%] [G loss: 3.846718]\n",
      "epoch:42 step:33141 [D loss: 0.317207, acc: 88.28%] [G loss: 6.243360]\n",
      "epoch:42 step:33142 [D loss: 0.072652, acc: 99.22%] [G loss: 4.757257]\n",
      "epoch:42 step:33143 [D loss: 1.449218, acc: 50.78%] [G loss: 6.226489]\n",
      "epoch:42 step:33144 [D loss: 0.408388, acc: 73.44%] [G loss: 2.791547]\n",
      "epoch:42 step:33145 [D loss: 0.156265, acc: 98.44%] [G loss: 4.423957]\n",
      "epoch:42 step:33146 [D loss: 0.158505, acc: 98.44%] [G loss: 4.537384]\n",
      "epoch:42 step:33147 [D loss: 0.152405, acc: 96.88%] [G loss: 6.191444]\n",
      "epoch:42 step:33148 [D loss: 0.281095, acc: 93.75%] [G loss: 2.712820]\n",
      "epoch:42 step:33149 [D loss: 0.150340, acc: 97.66%] [G loss: 5.258121]\n",
      "epoch:42 step:33150 [D loss: 0.190075, acc: 94.53%] [G loss: 5.790868]\n",
      "epoch:42 step:33151 [D loss: 0.199011, acc: 97.66%] [G loss: 3.257981]\n",
      "epoch:42 step:33152 [D loss: 0.598235, acc: 61.72%] [G loss: 4.776707]\n",
      "epoch:42 step:33153 [D loss: 0.358075, acc: 74.22%] [G loss: 2.670451]\n",
      "epoch:42 step:33154 [D loss: 0.065640, acc: 100.00%] [G loss: 4.590225]\n",
      "epoch:42 step:33155 [D loss: 0.344766, acc: 81.25%] [G loss: 6.522891]\n",
      "epoch:42 step:33156 [D loss: 0.160115, acc: 98.44%] [G loss: 3.742019]\n",
      "epoch:42 step:33157 [D loss: 2.461116, acc: 7.03%] [G loss: 7.949581]\n",
      "epoch:42 step:33158 [D loss: 0.177283, acc: 99.22%] [G loss: 5.223537]\n",
      "epoch:42 step:33159 [D loss: 0.097709, acc: 100.00%] [G loss: 6.513090]\n",
      "epoch:42 step:33160 [D loss: 0.054094, acc: 100.00%] [G loss: 4.361288]\n",
      "epoch:42 step:33161 [D loss: 0.130020, acc: 98.44%] [G loss: 7.006454]\n",
      "epoch:42 step:33162 [D loss: 0.522136, acc: 64.84%] [G loss: 5.992150]\n",
      "epoch:42 step:33163 [D loss: 0.388649, acc: 78.12%] [G loss: 3.823191]\n",
      "epoch:42 step:33164 [D loss: 0.060771, acc: 99.22%] [G loss: 5.750602]\n",
      "epoch:42 step:33165 [D loss: 0.141688, acc: 100.00%] [G loss: 4.267482]\n",
      "epoch:42 step:33166 [D loss: 0.255149, acc: 97.66%] [G loss: 6.004678]\n",
      "epoch:42 step:33167 [D loss: 0.452906, acc: 80.47%] [G loss: 4.768591]\n",
      "epoch:42 step:33168 [D loss: 0.106979, acc: 100.00%] [G loss: 7.091550]\n",
      "epoch:42 step:33169 [D loss: 0.245247, acc: 97.66%] [G loss: 5.148704]\n",
      "epoch:42 step:33170 [D loss: 0.522189, acc: 68.75%] [G loss: 5.022953]\n",
      "epoch:42 step:33171 [D loss: 0.230010, acc: 92.97%] [G loss: 3.631539]\n",
      "epoch:42 step:33172 [D loss: 0.235703, acc: 94.53%] [G loss: 5.729179]\n",
      "epoch:42 step:33173 [D loss: 0.132745, acc: 100.00%] [G loss: 4.015425]\n",
      "epoch:42 step:33174 [D loss: 0.601591, acc: 65.62%] [G loss: 3.885091]\n",
      "epoch:42 step:33175 [D loss: 0.592145, acc: 64.84%] [G loss: 5.918086]\n",
      "epoch:42 step:33176 [D loss: 0.308914, acc: 89.06%] [G loss: 8.892609]\n",
      "epoch:42 step:33177 [D loss: 0.598177, acc: 58.59%] [G loss: 5.643970]\n",
      "epoch:42 step:33178 [D loss: 0.033156, acc: 100.00%] [G loss: 5.927299]\n",
      "epoch:42 step:33179 [D loss: 0.050437, acc: 100.00%] [G loss: 1.257545]\n",
      "epoch:42 step:33180 [D loss: 0.223077, acc: 97.66%] [G loss: 4.774496]\n",
      "epoch:42 step:33181 [D loss: 0.167089, acc: 99.22%] [G loss: 5.644189]\n",
      "epoch:42 step:33182 [D loss: 0.145180, acc: 100.00%] [G loss: 5.823541]\n",
      "epoch:42 step:33183 [D loss: 0.410346, acc: 89.06%] [G loss: 6.213661]\n",
      "epoch:42 step:33184 [D loss: 0.664517, acc: 58.59%] [G loss: 3.133507]\n",
      "epoch:42 step:33185 [D loss: 0.757292, acc: 54.69%] [G loss: 6.544271]\n",
      "epoch:42 step:33186 [D loss: 0.062423, acc: 99.22%] [G loss: 4.088749]\n",
      "epoch:42 step:33187 [D loss: 0.271808, acc: 94.53%] [G loss: 8.809631]\n",
      "epoch:42 step:33188 [D loss: 0.514991, acc: 72.66%] [G loss: 2.420099]\n",
      "epoch:42 step:33189 [D loss: 0.599746, acc: 64.84%] [G loss: 7.801690]\n",
      "epoch:42 step:33190 [D loss: 0.231641, acc: 96.88%] [G loss: 3.090153]\n",
      "epoch:42 step:33191 [D loss: 0.294798, acc: 94.53%] [G loss: 5.314160]\n",
      "epoch:42 step:33192 [D loss: 0.319604, acc: 92.97%] [G loss: 5.332648]\n",
      "epoch:42 step:33193 [D loss: 0.943411, acc: 51.56%] [G loss: 8.733627]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33194 [D loss: 0.583926, acc: 58.59%] [G loss: 2.775562]\n",
      "epoch:42 step:33195 [D loss: 0.116636, acc: 98.44%] [G loss: 3.168307]\n",
      "epoch:42 step:33196 [D loss: 0.065372, acc: 100.00%] [G loss: 4.593441]\n",
      "epoch:42 step:33197 [D loss: 0.579651, acc: 71.88%] [G loss: 7.057279]\n",
      "epoch:42 step:33198 [D loss: 0.027742, acc: 100.00%] [G loss: 2.915438]\n",
      "epoch:42 step:33199 [D loss: 0.411225, acc: 86.72%] [G loss: 3.550704]\n",
      "epoch:42 step:33200 [D loss: 0.028897, acc: 100.00%] [G loss: 4.147952]\n",
      "epoch:42 step:33201 [D loss: 0.339401, acc: 91.41%] [G loss: 3.206767]\n",
      "epoch:42 step:33202 [D loss: 0.120698, acc: 99.22%] [G loss: 5.451024]\n",
      "epoch:42 step:33203 [D loss: 0.100197, acc: 100.00%] [G loss: 8.298396]\n",
      "epoch:42 step:33204 [D loss: 0.242072, acc: 96.88%] [G loss: 6.372113]\n",
      "epoch:42 step:33205 [D loss: 0.196201, acc: 95.31%] [G loss: 7.762033]\n",
      "epoch:42 step:33206 [D loss: 0.457575, acc: 82.03%] [G loss: 6.537707]\n",
      "epoch:42 step:33207 [D loss: 0.202037, acc: 99.22%] [G loss: 4.770428]\n",
      "epoch:42 step:33208 [D loss: 0.251203, acc: 92.19%] [G loss: 8.591761]\n",
      "epoch:42 step:33209 [D loss: 0.832156, acc: 41.41%] [G loss: 6.094744]\n",
      "epoch:42 step:33210 [D loss: 0.047722, acc: 100.00%] [G loss: 6.205157]\n",
      "epoch:42 step:33211 [D loss: 0.127252, acc: 99.22%] [G loss: 6.523117]\n",
      "epoch:42 step:33212 [D loss: 0.069901, acc: 100.00%] [G loss: 5.858009]\n",
      "epoch:42 step:33213 [D loss: 0.108444, acc: 100.00%] [G loss: 5.763117]\n",
      "epoch:42 step:33214 [D loss: 0.409373, acc: 77.34%] [G loss: 6.082239]\n",
      "epoch:42 step:33215 [D loss: 0.128317, acc: 98.44%] [G loss: 4.735016]\n",
      "epoch:42 step:33216 [D loss: 0.302093, acc: 96.09%] [G loss: 6.705243]\n",
      "epoch:42 step:33217 [D loss: 0.094121, acc: 99.22%] [G loss: 8.710272]\n",
      "epoch:42 step:33218 [D loss: 0.134816, acc: 96.88%] [G loss: 6.214513]\n",
      "epoch:42 step:33219 [D loss: 0.554181, acc: 75.78%] [G loss: 2.730699]\n",
      "epoch:42 step:33220 [D loss: 0.131806, acc: 98.44%] [G loss: 5.425107]\n",
      "epoch:42 step:33221 [D loss: 0.057592, acc: 100.00%] [G loss: 6.793876]\n",
      "epoch:42 step:33222 [D loss: 0.022863, acc: 100.00%] [G loss: 7.053573]\n",
      "epoch:42 step:33223 [D loss: 1.082792, acc: 35.94%] [G loss: 5.226619]\n",
      "epoch:42 step:33224 [D loss: 0.020583, acc: 100.00%] [G loss: 5.368445]\n",
      "epoch:42 step:33225 [D loss: 0.578666, acc: 60.94%] [G loss: 4.264042]\n",
      "epoch:42 step:33226 [D loss: 0.131889, acc: 98.44%] [G loss: 6.948788]\n",
      "epoch:42 step:33227 [D loss: 0.222623, acc: 93.75%] [G loss: 3.123673]\n",
      "epoch:42 step:33228 [D loss: 0.431424, acc: 76.56%] [G loss: 5.806152]\n",
      "epoch:42 step:33229 [D loss: 0.355262, acc: 90.62%] [G loss: 8.039782]\n",
      "epoch:42 step:33230 [D loss: 0.124294, acc: 100.00%] [G loss: 5.804106]\n",
      "epoch:42 step:33231 [D loss: 0.509509, acc: 78.91%] [G loss: 7.728197]\n",
      "epoch:42 step:33232 [D loss: 0.714478, acc: 57.03%] [G loss: 5.776957]\n",
      "epoch:42 step:33233 [D loss: 0.048471, acc: 100.00%] [G loss: 9.059505]\n",
      "epoch:42 step:33234 [D loss: 0.399447, acc: 77.34%] [G loss: 7.658756]\n",
      "epoch:42 step:33235 [D loss: 0.208241, acc: 96.09%] [G loss: 6.592286]\n",
      "epoch:42 step:33236 [D loss: 0.569885, acc: 61.72%] [G loss: 3.425677]\n",
      "epoch:42 step:33237 [D loss: 0.085226, acc: 100.00%] [G loss: 4.150933]\n",
      "epoch:42 step:33238 [D loss: 1.588108, acc: 49.22%] [G loss: 6.740184]\n",
      "epoch:42 step:33239 [D loss: 0.277858, acc: 90.62%] [G loss: 6.745442]\n",
      "epoch:42 step:33240 [D loss: 0.151906, acc: 96.88%] [G loss: 6.942102]\n",
      "epoch:42 step:33241 [D loss: 1.230268, acc: 49.22%] [G loss: 3.695778]\n",
      "epoch:42 step:33242 [D loss: 0.267123, acc: 85.94%] [G loss: 5.350423]\n",
      "epoch:42 step:33243 [D loss: 0.176666, acc: 96.88%] [G loss: 4.971052]\n",
      "epoch:42 step:33244 [D loss: 0.038234, acc: 100.00%] [G loss: 8.172050]\n",
      "epoch:42 step:33245 [D loss: 0.071372, acc: 100.00%] [G loss: 5.343110]\n",
      "epoch:42 step:33246 [D loss: 0.263386, acc: 92.19%] [G loss: 5.163384]\n",
      "epoch:42 step:33247 [D loss: 0.204782, acc: 95.31%] [G loss: 6.071650]\n",
      "epoch:42 step:33248 [D loss: 0.108786, acc: 100.00%] [G loss: 5.482894]\n",
      "epoch:42 step:33249 [D loss: 0.069116, acc: 100.00%] [G loss: 5.643077]\n",
      "epoch:42 step:33250 [D loss: 0.191308, acc: 98.44%] [G loss: 6.224746]\n",
      "epoch:42 step:33251 [D loss: 0.866684, acc: 46.09%] [G loss: 7.830555]\n",
      "epoch:42 step:33252 [D loss: 0.818792, acc: 49.22%] [G loss: 2.505300]\n",
      "epoch:42 step:33253 [D loss: 0.332384, acc: 86.72%] [G loss: 6.701824]\n",
      "epoch:42 step:33254 [D loss: 0.612222, acc: 55.47%] [G loss: 7.974911]\n",
      "epoch:42 step:33255 [D loss: 0.097328, acc: 99.22%] [G loss: 8.552111]\n",
      "epoch:42 step:33256 [D loss: 0.176999, acc: 96.88%] [G loss: 8.892178]\n",
      "epoch:42 step:33257 [D loss: 0.192003, acc: 99.22%] [G loss: 4.037107]\n",
      "epoch:42 step:33258 [D loss: 0.293272, acc: 92.97%] [G loss: 4.663659]\n",
      "epoch:42 step:33259 [D loss: 0.146061, acc: 98.44%] [G loss: 2.811034]\n",
      "epoch:42 step:33260 [D loss: 0.589125, acc: 69.53%] [G loss: 6.339450]\n",
      "epoch:42 step:33261 [D loss: 0.110054, acc: 98.44%] [G loss: 5.375822]\n",
      "epoch:42 step:33262 [D loss: 0.356279, acc: 85.16%] [G loss: 7.426417]\n",
      "epoch:42 step:33263 [D loss: 0.018271, acc: 100.00%] [G loss: 4.144147]\n",
      "epoch:42 step:33264 [D loss: 0.158715, acc: 98.44%] [G loss: 3.252941]\n",
      "epoch:42 step:33265 [D loss: 0.462202, acc: 65.62%] [G loss: 5.753176]\n",
      "epoch:42 step:33266 [D loss: 0.940036, acc: 52.34%] [G loss: 5.885170]\n",
      "epoch:42 step:33267 [D loss: 0.447688, acc: 69.53%] [G loss: 7.028792]\n",
      "epoch:42 step:33268 [D loss: 0.023988, acc: 100.00%] [G loss: 6.945718]\n",
      "epoch:42 step:33269 [D loss: 0.154136, acc: 100.00%] [G loss: 4.727393]\n",
      "epoch:42 step:33270 [D loss: 0.190442, acc: 98.44%] [G loss: 5.015379]\n",
      "epoch:42 step:33271 [D loss: 0.144687, acc: 99.22%] [G loss: 6.412971]\n",
      "epoch:42 step:33272 [D loss: 1.193282, acc: 50.00%] [G loss: 9.756456]\n",
      "epoch:42 step:33273 [D loss: 0.110644, acc: 100.00%] [G loss: 4.594382]\n",
      "epoch:42 step:33274 [D loss: 0.413981, acc: 84.38%] [G loss: 6.751731]\n",
      "epoch:42 step:33275 [D loss: 0.822912, acc: 52.34%] [G loss: 8.020349]\n",
      "epoch:42 step:33276 [D loss: 0.864680, acc: 50.78%] [G loss: 8.710404]\n",
      "epoch:42 step:33277 [D loss: 0.342430, acc: 78.12%] [G loss: 5.983082]\n",
      "epoch:42 step:33278 [D loss: 0.381705, acc: 78.12%] [G loss: 7.666423]\n",
      "epoch:42 step:33279 [D loss: 0.259614, acc: 92.19%] [G loss: 5.305824]\n",
      "epoch:42 step:33280 [D loss: 0.207291, acc: 98.44%] [G loss: 3.621642]\n",
      "epoch:42 step:33281 [D loss: 0.490822, acc: 70.31%] [G loss: 7.091663]\n",
      "epoch:42 step:33282 [D loss: 0.373670, acc: 80.47%] [G loss: 7.893019]\n",
      "epoch:42 step:33283 [D loss: 0.084318, acc: 100.00%] [G loss: 5.058297]\n",
      "epoch:42 step:33284 [D loss: 0.210914, acc: 94.53%] [G loss: 8.925960]\n",
      "epoch:42 step:33285 [D loss: 0.204965, acc: 97.66%] [G loss: 4.442100]\n",
      "epoch:42 step:33286 [D loss: 0.544386, acc: 68.75%] [G loss: 4.170841]\n",
      "epoch:42 step:33287 [D loss: 0.310399, acc: 84.38%] [G loss: 3.005354]\n",
      "epoch:42 step:33288 [D loss: 0.391788, acc: 84.38%] [G loss: 5.841028]\n",
      "epoch:42 step:33289 [D loss: 0.234161, acc: 93.75%] [G loss: 7.790325]\n",
      "epoch:42 step:33290 [D loss: 0.064008, acc: 100.00%] [G loss: 6.739303]\n",
      "epoch:42 step:33291 [D loss: 0.040438, acc: 100.00%] [G loss: 6.141931]\n",
      "epoch:42 step:33292 [D loss: 0.062502, acc: 100.00%] [G loss: 5.817024]\n",
      "epoch:42 step:33293 [D loss: 0.112464, acc: 99.22%] [G loss: 9.525858]\n",
      "epoch:42 step:33294 [D loss: 0.463923, acc: 64.84%] [G loss: 9.004264]\n",
      "epoch:42 step:33295 [D loss: 1.667853, acc: 11.72%] [G loss: 4.834243]\n",
      "epoch:42 step:33296 [D loss: 0.151802, acc: 99.22%] [G loss: 8.165514]\n",
      "epoch:42 step:33297 [D loss: 0.215080, acc: 94.53%] [G loss: 3.135401]\n",
      "epoch:42 step:33298 [D loss: 0.883331, acc: 44.53%] [G loss: 4.238206]\n",
      "epoch:42 step:33299 [D loss: 0.096040, acc: 100.00%] [G loss: 7.038079]\n",
      "epoch:42 step:33300 [D loss: 0.076355, acc: 100.00%] [G loss: 4.321452]\n",
      "epoch:42 step:33301 [D loss: 0.294018, acc: 95.31%] [G loss: 4.746099]\n",
      "epoch:42 step:33302 [D loss: 0.188383, acc: 97.66%] [G loss: 5.422019]\n",
      "epoch:42 step:33303 [D loss: 0.465328, acc: 75.00%] [G loss: 5.275785]\n",
      "epoch:42 step:33304 [D loss: 0.073231, acc: 100.00%] [G loss: 8.213168]\n",
      "epoch:42 step:33305 [D loss: 0.185425, acc: 97.66%] [G loss: 5.541647]\n",
      "epoch:42 step:33306 [D loss: 0.604082, acc: 66.41%] [G loss: 3.888866]\n",
      "epoch:42 step:33307 [D loss: 0.342538, acc: 92.19%] [G loss: 2.560535]\n",
      "epoch:42 step:33308 [D loss: 0.597575, acc: 64.84%] [G loss: 5.826280]\n",
      "epoch:42 step:33309 [D loss: 1.756163, acc: 47.66%] [G loss: 2.852243]\n",
      "epoch:42 step:33310 [D loss: 0.072559, acc: 100.00%] [G loss: 7.548679]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33311 [D loss: 0.178900, acc: 98.44%] [G loss: 5.116222]\n",
      "epoch:42 step:33312 [D loss: 1.818466, acc: 39.84%] [G loss: 8.868480]\n",
      "epoch:42 step:33313 [D loss: 1.010114, acc: 50.78%] [G loss: 7.472594]\n",
      "epoch:42 step:33314 [D loss: 0.236722, acc: 92.97%] [G loss: 8.346659]\n",
      "epoch:42 step:33315 [D loss: 0.215498, acc: 92.19%] [G loss: 8.244325]\n",
      "epoch:42 step:33316 [D loss: 0.183596, acc: 98.44%] [G loss: 7.329499]\n",
      "epoch:42 step:33317 [D loss: 0.577235, acc: 61.72%] [G loss: 3.759305]\n",
      "epoch:42 step:33318 [D loss: 0.117117, acc: 99.22%] [G loss: 3.740205]\n",
      "epoch:42 step:33319 [D loss: 0.635745, acc: 63.28%] [G loss: 5.595425]\n",
      "epoch:42 step:33320 [D loss: 0.187196, acc: 97.66%] [G loss: 4.662517]\n",
      "epoch:42 step:33321 [D loss: 0.815427, acc: 52.34%] [G loss: 12.562040]\n",
      "epoch:42 step:33322 [D loss: 0.478969, acc: 74.22%] [G loss: 5.542490]\n",
      "epoch:42 step:33323 [D loss: 0.370576, acc: 88.28%] [G loss: 6.005245]\n",
      "epoch:42 step:33324 [D loss: 0.942640, acc: 46.09%] [G loss: 5.578692]\n",
      "epoch:42 step:33325 [D loss: 0.073707, acc: 99.22%] [G loss: 7.626789]\n",
      "epoch:42 step:33326 [D loss: 0.257996, acc: 93.75%] [G loss: 4.804671]\n",
      "epoch:42 step:33327 [D loss: 1.187548, acc: 29.69%] [G loss: 6.070845]\n",
      "epoch:42 step:33328 [D loss: 0.071341, acc: 100.00%] [G loss: 4.922707]\n",
      "epoch:42 step:33329 [D loss: 0.503613, acc: 73.44%] [G loss: 6.627645]\n",
      "epoch:42 step:33330 [D loss: 1.307755, acc: 26.56%] [G loss: 6.362790]\n",
      "epoch:42 step:33331 [D loss: 0.128336, acc: 99.22%] [G loss: 7.061047]\n",
      "epoch:42 step:33332 [D loss: 0.145295, acc: 99.22%] [G loss: 5.874718]\n",
      "epoch:42 step:33333 [D loss: 0.356273, acc: 73.44%] [G loss: 9.713770]\n",
      "epoch:42 step:33334 [D loss: 0.093967, acc: 99.22%] [G loss: 5.082587]\n",
      "epoch:42 step:33335 [D loss: 0.555500, acc: 65.62%] [G loss: 7.640233]\n",
      "epoch:42 step:33336 [D loss: 0.324578, acc: 88.28%] [G loss: 6.697057]\n",
      "epoch:42 step:33337 [D loss: 1.168382, acc: 25.00%] [G loss: 7.721928]\n",
      "epoch:42 step:33338 [D loss: 0.384244, acc: 86.72%] [G loss: 7.828480]\n",
      "epoch:42 step:33339 [D loss: 0.301465, acc: 84.38%] [G loss: 2.409595]\n",
      "epoch:42 step:33340 [D loss: 0.173617, acc: 96.88%] [G loss: 8.189806]\n",
      "epoch:42 step:33341 [D loss: 0.135537, acc: 99.22%] [G loss: 7.741338]\n",
      "epoch:42 step:33342 [D loss: 0.235615, acc: 92.97%] [G loss: 5.983906]\n",
      "epoch:42 step:33343 [D loss: 0.642476, acc: 63.28%] [G loss: 3.811752]\n",
      "epoch:42 step:33344 [D loss: 0.130159, acc: 99.22%] [G loss: 4.130424]\n",
      "epoch:42 step:33345 [D loss: 1.110785, acc: 17.97%] [G loss: 7.183502]\n",
      "epoch:42 step:33346 [D loss: 0.328545, acc: 92.19%] [G loss: 4.935715]\n",
      "epoch:42 step:33347 [D loss: 0.028266, acc: 100.00%] [G loss: 6.512550]\n",
      "epoch:42 step:33348 [D loss: 0.605442, acc: 64.06%] [G loss: 4.497235]\n",
      "epoch:42 step:33349 [D loss: 0.372792, acc: 82.03%] [G loss: 3.228477]\n",
      "epoch:42 step:33350 [D loss: 0.261135, acc: 91.41%] [G loss: 3.754337]\n",
      "epoch:42 step:33351 [D loss: 1.186060, acc: 50.00%] [G loss: 7.862889]\n",
      "epoch:42 step:33352 [D loss: 0.895244, acc: 54.69%] [G loss: 7.378314]\n",
      "epoch:42 step:33353 [D loss: 0.195510, acc: 99.22%] [G loss: 5.709624]\n",
      "epoch:42 step:33354 [D loss: 0.711220, acc: 52.34%] [G loss: 5.672534]\n",
      "epoch:42 step:33355 [D loss: 0.061120, acc: 100.00%] [G loss: 6.187682]\n",
      "epoch:42 step:33356 [D loss: 2.346105, acc: 44.53%] [G loss: 2.821439]\n",
      "epoch:42 step:33357 [D loss: 0.023376, acc: 100.00%] [G loss: 4.484386]\n",
      "epoch:42 step:33358 [D loss: 1.215259, acc: 46.09%] [G loss: 5.743126]\n",
      "epoch:42 step:33359 [D loss: 0.077053, acc: 100.00%] [G loss: 6.663822]\n",
      "epoch:42 step:33360 [D loss: 0.103997, acc: 100.00%] [G loss: 6.707589]\n",
      "epoch:42 step:33361 [D loss: 0.495404, acc: 71.09%] [G loss: 6.715219]\n",
      "epoch:42 step:33362 [D loss: 0.040980, acc: 100.00%] [G loss: 6.573844]\n",
      "epoch:42 step:33363 [D loss: 0.050353, acc: 100.00%] [G loss: 4.484736]\n",
      "epoch:42 step:33364 [D loss: 0.084822, acc: 98.44%] [G loss: 7.502759]\n",
      "epoch:42 step:33365 [D loss: 0.114441, acc: 99.22%] [G loss: 4.259244]\n",
      "epoch:42 step:33366 [D loss: 0.027663, acc: 100.00%] [G loss: 6.387093]\n",
      "epoch:42 step:33367 [D loss: 0.158589, acc: 99.22%] [G loss: 6.344764]\n",
      "epoch:42 step:33368 [D loss: 0.085034, acc: 100.00%] [G loss: 9.257448]\n",
      "epoch:42 step:33369 [D loss: 0.155181, acc: 100.00%] [G loss: 4.711706]\n",
      "epoch:42 step:33370 [D loss: 0.191633, acc: 95.31%] [G loss: 1.884319]\n",
      "epoch:42 step:33371 [D loss: 0.385174, acc: 91.41%] [G loss: 6.755567]\n",
      "epoch:42 step:33372 [D loss: 0.316630, acc: 91.41%] [G loss: 6.704761]\n",
      "epoch:42 step:33373 [D loss: 0.284510, acc: 95.31%] [G loss: 8.310145]\n",
      "epoch:42 step:33374 [D loss: 0.232715, acc: 92.97%] [G loss: 8.930642]\n",
      "epoch:42 step:33375 [D loss: 0.203565, acc: 94.53%] [G loss: 7.476444]\n",
      "epoch:42 step:33376 [D loss: 0.379315, acc: 86.72%] [G loss: 5.450852]\n",
      "epoch:42 step:33377 [D loss: 0.146054, acc: 100.00%] [G loss: 5.979902]\n",
      "epoch:42 step:33378 [D loss: 0.092237, acc: 100.00%] [G loss: 5.283404]\n",
      "epoch:42 step:33379 [D loss: 0.029405, acc: 100.00%] [G loss: 6.531090]\n",
      "epoch:42 step:33380 [D loss: 0.024983, acc: 100.00%] [G loss: 4.140924]\n",
      "epoch:42 step:33381 [D loss: 0.197672, acc: 97.66%] [G loss: 6.055767]\n",
      "epoch:42 step:33382 [D loss: 0.096371, acc: 100.00%] [G loss: 4.985181]\n",
      "epoch:42 step:33383 [D loss: 0.418434, acc: 75.78%] [G loss: 3.739121]\n",
      "epoch:42 step:33384 [D loss: 0.073671, acc: 100.00%] [G loss: 5.256263]\n",
      "epoch:42 step:33385 [D loss: 0.529659, acc: 64.06%] [G loss: 3.219480]\n",
      "epoch:42 step:33386 [D loss: 0.162874, acc: 98.44%] [G loss: 2.735542]\n",
      "epoch:42 step:33387 [D loss: 0.337272, acc: 81.25%] [G loss: 6.191281]\n",
      "epoch:42 step:33388 [D loss: 0.157209, acc: 100.00%] [G loss: 4.373513]\n",
      "epoch:42 step:33389 [D loss: 1.805280, acc: 7.81%] [G loss: 11.433731]\n",
      "epoch:42 step:33390 [D loss: 0.673881, acc: 58.59%] [G loss: 5.044099]\n",
      "epoch:42 step:33391 [D loss: 1.480907, acc: 23.44%] [G loss: 9.178195]\n",
      "epoch:42 step:33392 [D loss: 0.227359, acc: 97.66%] [G loss: 4.855102]\n",
      "epoch:42 step:33393 [D loss: 0.188034, acc: 98.44%] [G loss: 3.440905]\n",
      "epoch:42 step:33394 [D loss: 0.043363, acc: 100.00%] [G loss: 7.793278]\n",
      "epoch:42 step:33395 [D loss: 0.541695, acc: 77.34%] [G loss: 3.072203]\n",
      "epoch:42 step:33396 [D loss: 0.050135, acc: 100.00%] [G loss: 4.686903]\n",
      "epoch:42 step:33397 [D loss: 0.402654, acc: 73.44%] [G loss: 2.057438]\n",
      "epoch:42 step:33398 [D loss: 0.118274, acc: 99.22%] [G loss: 4.751508]\n",
      "epoch:42 step:33399 [D loss: 0.648561, acc: 55.47%] [G loss: 6.423516]\n",
      "epoch:42 step:33400 [D loss: 0.405310, acc: 87.50%] [G loss: 6.945266]\n",
      "epoch:42 step:33401 [D loss: 0.190354, acc: 94.53%] [G loss: 5.220485]\n",
      "epoch:42 step:33402 [D loss: 0.468283, acc: 79.69%] [G loss: 5.527262]\n",
      "epoch:42 step:33403 [D loss: 1.297062, acc: 17.97%] [G loss: 3.386797]\n",
      "epoch:42 step:33404 [D loss: 0.069198, acc: 98.44%] [G loss: 5.446777]\n",
      "epoch:42 step:33405 [D loss: 0.233677, acc: 94.53%] [G loss: 5.009809]\n",
      "epoch:42 step:33406 [D loss: 0.265127, acc: 93.75%] [G loss: 3.725450]\n",
      "epoch:42 step:33407 [D loss: 0.061761, acc: 100.00%] [G loss: 3.438722]\n",
      "epoch:42 step:33408 [D loss: 0.591816, acc: 60.94%] [G loss: 3.667225]\n",
      "epoch:42 step:33409 [D loss: 0.306267, acc: 94.53%] [G loss: 3.342850]\n",
      "epoch:42 step:33410 [D loss: 0.942650, acc: 51.56%] [G loss: 6.744330]\n",
      "epoch:42 step:33411 [D loss: 0.470353, acc: 81.25%] [G loss: 4.166935]\n",
      "epoch:42 step:33412 [D loss: 0.131148, acc: 97.66%] [G loss: 8.470607]\n",
      "epoch:42 step:33413 [D loss: 0.117681, acc: 100.00%] [G loss: 7.268184]\n",
      "epoch:42 step:33414 [D loss: 0.257086, acc: 87.50%] [G loss: 4.816704]\n",
      "epoch:42 step:33415 [D loss: 0.115209, acc: 99.22%] [G loss: 4.619555]\n",
      "epoch:42 step:33416 [D loss: 1.195452, acc: 50.78%] [G loss: 4.495368]\n",
      "epoch:42 step:33417 [D loss: 0.191801, acc: 96.88%] [G loss: 7.642624]\n",
      "epoch:42 step:33418 [D loss: 0.304162, acc: 85.94%] [G loss: 6.423903]\n",
      "epoch:42 step:33419 [D loss: 0.266751, acc: 94.53%] [G loss: 3.340448]\n",
      "epoch:42 step:33420 [D loss: 0.123510, acc: 99.22%] [G loss: 4.930863]\n",
      "epoch:42 step:33421 [D loss: 0.840517, acc: 41.41%] [G loss: 3.798571]\n",
      "epoch:42 step:33422 [D loss: 0.678670, acc: 63.28%] [G loss: 6.004936]\n",
      "epoch:42 step:33423 [D loss: 0.273091, acc: 95.31%] [G loss: 4.344919]\n",
      "epoch:42 step:33424 [D loss: 0.828976, acc: 51.56%] [G loss: 7.933646]\n",
      "epoch:42 step:33425 [D loss: 0.263424, acc: 89.06%] [G loss: 6.526767]\n",
      "epoch:42 step:33426 [D loss: 0.120298, acc: 99.22%] [G loss: 5.133089]\n",
      "epoch:42 step:33427 [D loss: 0.296993, acc: 93.75%] [G loss: 7.954025]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33428 [D loss: 0.330186, acc: 95.31%] [G loss: 7.246938]\n",
      "epoch:42 step:33429 [D loss: 0.677828, acc: 62.50%] [G loss: 6.702502]\n",
      "epoch:42 step:33430 [D loss: 0.377920, acc: 85.94%] [G loss: 4.578672]\n",
      "epoch:42 step:33431 [D loss: 0.565403, acc: 64.06%] [G loss: 8.232229]\n",
      "epoch:42 step:33432 [D loss: 0.148191, acc: 99.22%] [G loss: 4.965937]\n",
      "epoch:42 step:33433 [D loss: 0.079067, acc: 100.00%] [G loss: 4.490945]\n",
      "epoch:42 step:33434 [D loss: 0.116785, acc: 99.22%] [G loss: 4.366889]\n",
      "epoch:42 step:33435 [D loss: 0.156825, acc: 100.00%] [G loss: 4.925968]\n",
      "epoch:42 step:33436 [D loss: 0.089264, acc: 100.00%] [G loss: 4.211621]\n",
      "epoch:42 step:33437 [D loss: 0.886618, acc: 51.56%] [G loss: 4.946443]\n",
      "epoch:42 step:33438 [D loss: 0.594420, acc: 60.94%] [G loss: 7.331194]\n",
      "epoch:42 step:33439 [D loss: 0.239503, acc: 96.09%] [G loss: 7.517714]\n",
      "epoch:42 step:33440 [D loss: 0.504345, acc: 75.00%] [G loss: 5.513115]\n",
      "epoch:42 step:33441 [D loss: 0.234751, acc: 95.31%] [G loss: 3.175014]\n",
      "epoch:42 step:33442 [D loss: 0.569964, acc: 67.19%] [G loss: 7.262360]\n",
      "epoch:42 step:33443 [D loss: 0.212371, acc: 99.22%] [G loss: 5.836938]\n",
      "epoch:42 step:33444 [D loss: 0.379413, acc: 95.31%] [G loss: 6.153532]\n",
      "epoch:42 step:33445 [D loss: 0.361434, acc: 78.91%] [G loss: 6.826871]\n",
      "epoch:42 step:33446 [D loss: 0.284736, acc: 86.72%] [G loss: 4.583883]\n",
      "epoch:42 step:33447 [D loss: 0.375382, acc: 85.94%] [G loss: 5.117024]\n",
      "epoch:42 step:33448 [D loss: 0.336999, acc: 91.41%] [G loss: 4.681700]\n",
      "epoch:42 step:33449 [D loss: 0.299563, acc: 86.72%] [G loss: 3.880217]\n",
      "epoch:42 step:33450 [D loss: 0.252233, acc: 91.41%] [G loss: 7.010113]\n",
      "epoch:42 step:33451 [D loss: 0.133176, acc: 100.00%] [G loss: 4.131441]\n",
      "epoch:42 step:33452 [D loss: 0.654735, acc: 53.91%] [G loss: 3.330640]\n",
      "epoch:42 step:33453 [D loss: 0.116887, acc: 100.00%] [G loss: 3.026020]\n",
      "epoch:42 step:33454 [D loss: 0.491962, acc: 65.62%] [G loss: 6.471340]\n",
      "epoch:42 step:33455 [D loss: 0.020730, acc: 100.00%] [G loss: 7.474395]\n",
      "epoch:42 step:33456 [D loss: 0.241324, acc: 91.41%] [G loss: 5.120329]\n",
      "epoch:42 step:33457 [D loss: 0.020427, acc: 100.00%] [G loss: 7.543629]\n",
      "epoch:42 step:33458 [D loss: 1.095219, acc: 22.66%] [G loss: 7.534403]\n",
      "epoch:42 step:33459 [D loss: 0.186069, acc: 98.44%] [G loss: 7.771044]\n",
      "epoch:42 step:33460 [D loss: 0.483595, acc: 72.66%] [G loss: 7.990786]\n",
      "epoch:42 step:33461 [D loss: 0.554253, acc: 71.09%] [G loss: 4.955555]\n",
      "epoch:42 step:33462 [D loss: 0.165452, acc: 100.00%] [G loss: 5.473893]\n",
      "epoch:42 step:33463 [D loss: 0.721817, acc: 57.03%] [G loss: 6.961378]\n",
      "epoch:42 step:33464 [D loss: 0.450075, acc: 82.81%] [G loss: 5.920994]\n",
      "epoch:42 step:33465 [D loss: 0.096269, acc: 99.22%] [G loss: 4.550907]\n",
      "epoch:42 step:33466 [D loss: 0.123692, acc: 99.22%] [G loss: 5.695464]\n",
      "epoch:42 step:33467 [D loss: 0.105462, acc: 99.22%] [G loss: 3.633038]\n",
      "epoch:42 step:33468 [D loss: 0.098380, acc: 100.00%] [G loss: 3.996572]\n",
      "epoch:42 step:33469 [D loss: 0.096177, acc: 100.00%] [G loss: 7.234091]\n",
      "epoch:42 step:33470 [D loss: 0.520349, acc: 65.62%] [G loss: 5.977646]\n",
      "epoch:42 step:33471 [D loss: 0.078307, acc: 100.00%] [G loss: 3.619524]\n",
      "epoch:42 step:33472 [D loss: 0.036509, acc: 100.00%] [G loss: 3.651704]\n",
      "epoch:42 step:33473 [D loss: 1.148938, acc: 50.00%] [G loss: 5.750322]\n",
      "epoch:42 step:33474 [D loss: 0.076581, acc: 100.00%] [G loss: 6.053094]\n",
      "epoch:42 step:33475 [D loss: 0.509150, acc: 78.12%] [G loss: 5.772400]\n",
      "epoch:42 step:33476 [D loss: 0.095464, acc: 99.22%] [G loss: 6.317414]\n",
      "epoch:42 step:33477 [D loss: 0.329989, acc: 96.09%] [G loss: 5.865638]\n",
      "epoch:42 step:33478 [D loss: 0.302257, acc: 88.28%] [G loss: 5.513881]\n",
      "epoch:42 step:33479 [D loss: 0.036912, acc: 100.00%] [G loss: 6.896131]\n",
      "epoch:42 step:33480 [D loss: 0.368539, acc: 82.81%] [G loss: 5.340665]\n",
      "epoch:42 step:33481 [D loss: 0.875271, acc: 53.12%] [G loss: 6.002461]\n",
      "epoch:42 step:33482 [D loss: 0.499718, acc: 77.34%] [G loss: 5.777306]\n",
      "epoch:42 step:33483 [D loss: 0.930207, acc: 30.47%] [G loss: 5.756088]\n",
      "epoch:42 step:33484 [D loss: 0.257930, acc: 89.84%] [G loss: 3.494436]\n",
      "epoch:42 step:33485 [D loss: 0.336560, acc: 92.19%] [G loss: 4.947553]\n",
      "epoch:42 step:33486 [D loss: 0.719835, acc: 56.25%] [G loss: 4.227942]\n",
      "epoch:42 step:33487 [D loss: 0.256416, acc: 94.53%] [G loss: 3.793651]\n",
      "epoch:42 step:33488 [D loss: 0.383572, acc: 79.69%] [G loss: 5.888483]\n",
      "epoch:42 step:33489 [D loss: 0.048024, acc: 100.00%] [G loss: 4.208571]\n",
      "epoch:42 step:33490 [D loss: 0.057299, acc: 99.22%] [G loss: 5.405066]\n",
      "epoch:42 step:33491 [D loss: 0.097465, acc: 99.22%] [G loss: 6.385918]\n",
      "epoch:42 step:33492 [D loss: 0.271818, acc: 97.66%] [G loss: 5.451504]\n",
      "epoch:42 step:33493 [D loss: 0.198009, acc: 96.88%] [G loss: 5.633841]\n",
      "epoch:42 step:33494 [D loss: 0.100473, acc: 99.22%] [G loss: 6.745279]\n",
      "epoch:42 step:33495 [D loss: 0.338737, acc: 79.69%] [G loss: 5.983663]\n",
      "epoch:42 step:33496 [D loss: 0.164741, acc: 97.66%] [G loss: 6.061176]\n",
      "epoch:42 step:33497 [D loss: 0.087489, acc: 100.00%] [G loss: 3.100543]\n",
      "epoch:42 step:33498 [D loss: 0.043653, acc: 99.22%] [G loss: 5.507996]\n",
      "epoch:42 step:33499 [D loss: 0.217696, acc: 96.09%] [G loss: 4.456137]\n",
      "epoch:42 step:33500 [D loss: 0.345022, acc: 87.50%] [G loss: 8.670149]\n",
      "epoch:42 step:33501 [D loss: 0.277159, acc: 95.31%] [G loss: 6.231579]\n",
      "epoch:42 step:33502 [D loss: 0.155319, acc: 97.66%] [G loss: 3.383902]\n",
      "epoch:42 step:33503 [D loss: 1.178688, acc: 20.31%] [G loss: 6.344975]\n",
      "epoch:42 step:33504 [D loss: 0.162031, acc: 96.09%] [G loss: 6.085783]\n",
      "epoch:42 step:33505 [D loss: 0.194617, acc: 96.09%] [G loss: 6.349193]\n",
      "epoch:42 step:33506 [D loss: 0.254150, acc: 92.97%] [G loss: 6.689248]\n",
      "epoch:42 step:33507 [D loss: 0.476911, acc: 82.03%] [G loss: 6.779956]\n",
      "epoch:42 step:33508 [D loss: 0.294561, acc: 96.09%] [G loss: 5.958471]\n",
      "epoch:42 step:33509 [D loss: 0.872301, acc: 51.56%] [G loss: 4.119429]\n",
      "epoch:42 step:33510 [D loss: 0.036918, acc: 100.00%] [G loss: 6.618384]\n",
      "epoch:42 step:33511 [D loss: 1.100661, acc: 50.00%] [G loss: 6.862150]\n",
      "epoch:42 step:33512 [D loss: 0.706636, acc: 55.47%] [G loss: 3.410870]\n",
      "epoch:42 step:33513 [D loss: 0.188726, acc: 96.88%] [G loss: 4.961577]\n",
      "epoch:42 step:33514 [D loss: 0.115126, acc: 100.00%] [G loss: 5.552857]\n",
      "epoch:42 step:33515 [D loss: 0.221970, acc: 96.88%] [G loss: 5.520298]\n",
      "epoch:42 step:33516 [D loss: 0.242546, acc: 93.75%] [G loss: 6.098389]\n",
      "epoch:42 step:33517 [D loss: 0.177922, acc: 98.44%] [G loss: 4.371812]\n",
      "epoch:42 step:33518 [D loss: 0.337441, acc: 84.38%] [G loss: 5.382119]\n",
      "epoch:42 step:33519 [D loss: 0.337330, acc: 82.03%] [G loss: 5.509086]\n",
      "epoch:42 step:33520 [D loss: 0.141902, acc: 98.44%] [G loss: 5.044179]\n",
      "epoch:42 step:33521 [D loss: 0.224389, acc: 98.44%] [G loss: 5.149389]\n",
      "epoch:42 step:33522 [D loss: 0.606508, acc: 60.16%] [G loss: 8.609934]\n",
      "epoch:42 step:33523 [D loss: 0.165991, acc: 98.44%] [G loss: 4.960666]\n",
      "epoch:42 step:33524 [D loss: 0.528779, acc: 62.50%] [G loss: 6.501171]\n",
      "epoch:42 step:33525 [D loss: 0.036922, acc: 100.00%] [G loss: 9.319767]\n",
      "epoch:42 step:33526 [D loss: 0.135425, acc: 99.22%] [G loss: 7.290207]\n",
      "epoch:42 step:33527 [D loss: 0.078377, acc: 100.00%] [G loss: 7.163250]\n",
      "epoch:42 step:33528 [D loss: 0.206664, acc: 92.97%] [G loss: 6.103944]\n",
      "epoch:42 step:33529 [D loss: 0.321492, acc: 86.72%] [G loss: 5.724751]\n",
      "epoch:42 step:33530 [D loss: 0.095105, acc: 99.22%] [G loss: 8.694343]\n",
      "epoch:42 step:33531 [D loss: 0.181073, acc: 98.44%] [G loss: 4.478714]\n",
      "epoch:42 step:33532 [D loss: 0.157455, acc: 98.44%] [G loss: 6.500979]\n",
      "epoch:42 step:33533 [D loss: 0.509427, acc: 70.31%] [G loss: 8.342103]\n",
      "epoch:42 step:33534 [D loss: 0.386804, acc: 88.28%] [G loss: 2.391294]\n",
      "epoch:42 step:33535 [D loss: 0.138391, acc: 99.22%] [G loss: 3.627866]\n",
      "epoch:42 step:33536 [D loss: 2.021498, acc: 2.34%] [G loss: 4.164574]\n",
      "epoch:42 step:33537 [D loss: 0.133187, acc: 97.66%] [G loss: 8.656663]\n",
      "epoch:42 step:33538 [D loss: 0.428045, acc: 82.03%] [G loss: 6.591002]\n",
      "epoch:42 step:33539 [D loss: 0.055643, acc: 100.00%] [G loss: 10.271105]\n",
      "epoch:42 step:33540 [D loss: 0.207631, acc: 95.31%] [G loss: 4.669975]\n",
      "epoch:42 step:33541 [D loss: 0.872381, acc: 50.78%] [G loss: 5.570207]\n",
      "epoch:42 step:33542 [D loss: 1.131113, acc: 50.78%] [G loss: 5.255373]\n",
      "epoch:42 step:33543 [D loss: 0.704827, acc: 57.81%] [G loss: 6.163611]\n",
      "epoch:42 step:33544 [D loss: 0.573295, acc: 64.06%] [G loss: 6.649973]\n",
      "epoch:42 step:33545 [D loss: 0.647524, acc: 60.16%] [G loss: 7.056372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33546 [D loss: 1.101826, acc: 33.59%] [G loss: 5.892870]\n",
      "epoch:42 step:33547 [D loss: 0.067791, acc: 99.22%] [G loss: 6.471682]\n",
      "epoch:42 step:33548 [D loss: 0.713093, acc: 53.12%] [G loss: 6.912161]\n",
      "epoch:42 step:33549 [D loss: 0.220310, acc: 94.53%] [G loss: 3.696786]\n",
      "epoch:42 step:33550 [D loss: 1.906667, acc: 49.22%] [G loss: 6.388047]\n",
      "epoch:42 step:33551 [D loss: 0.613212, acc: 62.50%] [G loss: 4.417974]\n",
      "epoch:42 step:33552 [D loss: 0.070871, acc: 100.00%] [G loss: 5.754299]\n",
      "epoch:42 step:33553 [D loss: 0.083416, acc: 98.44%] [G loss: 3.753285]\n",
      "epoch:42 step:33554 [D loss: 0.246051, acc: 96.09%] [G loss: 4.501117]\n",
      "epoch:42 step:33555 [D loss: 0.715012, acc: 54.69%] [G loss: 7.614362]\n",
      "epoch:42 step:33556 [D loss: 1.294682, acc: 50.78%] [G loss: 6.797887]\n",
      "epoch:42 step:33557 [D loss: 0.187472, acc: 98.44%] [G loss: 7.391706]\n",
      "epoch:42 step:33558 [D loss: 0.030332, acc: 100.00%] [G loss: 5.009822]\n",
      "epoch:42 step:33559 [D loss: 0.139621, acc: 98.44%] [G loss: 6.271031]\n",
      "epoch:42 step:33560 [D loss: 0.808913, acc: 55.47%] [G loss: 4.163144]\n",
      "epoch:42 step:33561 [D loss: 0.052576, acc: 100.00%] [G loss: 6.611775]\n",
      "epoch:42 step:33562 [D loss: 0.041248, acc: 100.00%] [G loss: 5.425926]\n",
      "epoch:42 step:33563 [D loss: 0.108836, acc: 100.00%] [G loss: 8.637890]\n",
      "epoch:42 step:33564 [D loss: 0.523891, acc: 75.00%] [G loss: 8.238861]\n",
      "epoch:42 step:33565 [D loss: 1.057374, acc: 48.44%] [G loss: 8.811613]\n",
      "epoch:42 step:33566 [D loss: 0.086994, acc: 100.00%] [G loss: 5.531447]\n",
      "epoch:42 step:33567 [D loss: 0.174566, acc: 96.88%] [G loss: 6.445397]\n",
      "epoch:42 step:33568 [D loss: 0.294755, acc: 92.19%] [G loss: 5.338311]\n",
      "epoch:42 step:33569 [D loss: 0.679440, acc: 57.03%] [G loss: 5.357510]\n",
      "epoch:42 step:33570 [D loss: 0.018439, acc: 100.00%] [G loss: 9.451855]\n",
      "epoch:42 step:33571 [D loss: 0.937809, acc: 52.34%] [G loss: 6.537715]\n",
      "epoch:42 step:33572 [D loss: 0.092038, acc: 99.22%] [G loss: 1.691545]\n",
      "epoch:42 step:33573 [D loss: 0.743586, acc: 58.59%] [G loss: 3.403950]\n",
      "epoch:42 step:33574 [D loss: 0.127160, acc: 99.22%] [G loss: 3.473354]\n",
      "epoch:42 step:33575 [D loss: 0.117699, acc: 100.00%] [G loss: 5.969844]\n",
      "epoch:42 step:33576 [D loss: 0.213131, acc: 97.66%] [G loss: 6.753432]\n",
      "epoch:42 step:33577 [D loss: 0.084229, acc: 100.00%] [G loss: 5.727718]\n",
      "epoch:42 step:33578 [D loss: 0.203499, acc: 99.22%] [G loss: 3.324698]\n",
      "epoch:42 step:33579 [D loss: 0.171643, acc: 99.22%] [G loss: 5.379371]\n",
      "epoch:42 step:33580 [D loss: 0.826847, acc: 47.66%] [G loss: 4.145242]\n",
      "epoch:42 step:33581 [D loss: 0.441796, acc: 78.91%] [G loss: 4.976072]\n",
      "epoch:42 step:33582 [D loss: 0.489126, acc: 71.09%] [G loss: 4.992460]\n",
      "epoch:42 step:33583 [D loss: 0.187967, acc: 94.53%] [G loss: 7.328232]\n",
      "epoch:43 step:33584 [D loss: 0.363265, acc: 79.69%] [G loss: 6.299888]\n",
      "epoch:43 step:33585 [D loss: 0.214650, acc: 96.09%] [G loss: 4.540498]\n",
      "epoch:43 step:33586 [D loss: 1.173059, acc: 17.19%] [G loss: 6.794393]\n",
      "epoch:43 step:33587 [D loss: 0.074913, acc: 100.00%] [G loss: 3.261343]\n",
      "epoch:43 step:33588 [D loss: 0.150076, acc: 99.22%] [G loss: 5.496904]\n",
      "epoch:43 step:33589 [D loss: 0.449510, acc: 82.81%] [G loss: 6.749980]\n",
      "epoch:43 step:33590 [D loss: 0.141180, acc: 99.22%] [G loss: 4.315755]\n",
      "epoch:43 step:33591 [D loss: 0.334337, acc: 93.75%] [G loss: 3.349152]\n",
      "epoch:43 step:33592 [D loss: 1.459200, acc: 50.00%] [G loss: 6.670327]\n",
      "epoch:43 step:33593 [D loss: 0.282435, acc: 85.94%] [G loss: 4.481392]\n",
      "epoch:43 step:33594 [D loss: 0.659459, acc: 57.03%] [G loss: 5.985658]\n",
      "epoch:43 step:33595 [D loss: 0.598176, acc: 64.84%] [G loss: 5.686668]\n",
      "epoch:43 step:33596 [D loss: 0.117890, acc: 100.00%] [G loss: 6.095187]\n",
      "epoch:43 step:33597 [D loss: 0.188566, acc: 98.44%] [G loss: 7.138243]\n",
      "epoch:43 step:33598 [D loss: 0.018281, acc: 100.00%] [G loss: 10.517937]\n",
      "epoch:43 step:33599 [D loss: 0.896253, acc: 38.28%] [G loss: 4.879106]\n",
      "epoch:43 step:33600 [D loss: 0.350005, acc: 85.16%] [G loss: 5.702660]\n",
      "epoch:43 step:33601 [D loss: 0.113681, acc: 99.22%] [G loss: 6.746077]\n",
      "epoch:43 step:33602 [D loss: 0.385273, acc: 89.06%] [G loss: 4.961834]\n",
      "epoch:43 step:33603 [D loss: 0.080741, acc: 99.22%] [G loss: 6.583789]\n",
      "epoch:43 step:33604 [D loss: 0.042988, acc: 100.00%] [G loss: 7.800460]\n",
      "epoch:43 step:33605 [D loss: 0.078124, acc: 99.22%] [G loss: 3.489358]\n",
      "epoch:43 step:33606 [D loss: 0.182746, acc: 96.09%] [G loss: 7.099558]\n",
      "epoch:43 step:33607 [D loss: 0.436901, acc: 72.66%] [G loss: 5.094917]\n",
      "epoch:43 step:33608 [D loss: 0.112040, acc: 100.00%] [G loss: 7.130190]\n",
      "epoch:43 step:33609 [D loss: 0.468636, acc: 79.69%] [G loss: 3.239184]\n",
      "epoch:43 step:33610 [D loss: 0.451311, acc: 71.09%] [G loss: 5.086839]\n",
      "epoch:43 step:33611 [D loss: 0.256550, acc: 92.19%] [G loss: 6.218074]\n",
      "epoch:43 step:33612 [D loss: 0.498909, acc: 73.44%] [G loss: 7.626402]\n",
      "epoch:43 step:33613 [D loss: 0.666156, acc: 53.91%] [G loss: 6.991342]\n",
      "epoch:43 step:33614 [D loss: 0.089405, acc: 99.22%] [G loss: 5.873108]\n",
      "epoch:43 step:33615 [D loss: 0.421245, acc: 81.25%] [G loss: 3.947829]\n",
      "epoch:43 step:33616 [D loss: 1.328182, acc: 46.88%] [G loss: 11.016548]\n",
      "epoch:43 step:33617 [D loss: 0.270947, acc: 97.66%] [G loss: 6.859216]\n",
      "epoch:43 step:33618 [D loss: 1.170013, acc: 46.88%] [G loss: 6.475218]\n",
      "epoch:43 step:33619 [D loss: 0.129516, acc: 100.00%] [G loss: 5.064948]\n",
      "epoch:43 step:33620 [D loss: 0.671970, acc: 62.50%] [G loss: 6.684276]\n",
      "epoch:43 step:33621 [D loss: 1.850352, acc: 26.56%] [G loss: 7.208688]\n",
      "epoch:43 step:33622 [D loss: 0.113607, acc: 100.00%] [G loss: 4.809457]\n",
      "epoch:43 step:33623 [D loss: 0.271463, acc: 86.72%] [G loss: 8.756912]\n",
      "epoch:43 step:33624 [D loss: 0.180815, acc: 96.09%] [G loss: 8.203586]\n",
      "epoch:43 step:33625 [D loss: 0.204639, acc: 94.53%] [G loss: 5.621713]\n",
      "epoch:43 step:33626 [D loss: 0.086992, acc: 100.00%] [G loss: 4.822788]\n",
      "epoch:43 step:33627 [D loss: 0.055336, acc: 100.00%] [G loss: 4.809757]\n",
      "epoch:43 step:33628 [D loss: 1.027838, acc: 50.78%] [G loss: 5.212642]\n",
      "epoch:43 step:33629 [D loss: 0.085683, acc: 99.22%] [G loss: 6.018591]\n",
      "epoch:43 step:33630 [D loss: 0.374001, acc: 76.56%] [G loss: 5.742090]\n",
      "epoch:43 step:33631 [D loss: 0.757300, acc: 57.81%] [G loss: 4.703653]\n",
      "epoch:43 step:33632 [D loss: 0.085759, acc: 100.00%] [G loss: 4.006487]\n",
      "epoch:43 step:33633 [D loss: 0.048511, acc: 100.00%] [G loss: 4.897700]\n",
      "epoch:43 step:33634 [D loss: 0.420411, acc: 75.78%] [G loss: 5.392132]\n",
      "epoch:43 step:33635 [D loss: 0.169950, acc: 98.44%] [G loss: 3.586179]\n",
      "epoch:43 step:33636 [D loss: 1.233489, acc: 40.62%] [G loss: 4.383296]\n",
      "epoch:43 step:33637 [D loss: 0.189444, acc: 93.75%] [G loss: 4.398268]\n",
      "epoch:43 step:33638 [D loss: 0.081458, acc: 99.22%] [G loss: 5.434743]\n",
      "epoch:43 step:33639 [D loss: 0.177443, acc: 96.09%] [G loss: 4.880053]\n",
      "epoch:43 step:33640 [D loss: 0.706942, acc: 55.47%] [G loss: 7.562730]\n",
      "epoch:43 step:33641 [D loss: 0.383661, acc: 78.91%] [G loss: 4.201710]\n",
      "epoch:43 step:33642 [D loss: 0.036096, acc: 100.00%] [G loss: 6.335922]\n",
      "epoch:43 step:33643 [D loss: 0.541716, acc: 75.00%] [G loss: 8.875618]\n",
      "epoch:43 step:33644 [D loss: 0.303426, acc: 87.50%] [G loss: 8.056520]\n",
      "epoch:43 step:33645 [D loss: 0.454697, acc: 79.69%] [G loss: 6.978785]\n",
      "epoch:43 step:33646 [D loss: 0.016960, acc: 100.00%] [G loss: 6.461386]\n",
      "epoch:43 step:33647 [D loss: 0.096260, acc: 99.22%] [G loss: 6.155519]\n",
      "epoch:43 step:33648 [D loss: 0.488479, acc: 79.69%] [G loss: 6.211957]\n",
      "epoch:43 step:33649 [D loss: 0.454727, acc: 79.69%] [G loss: 4.945827]\n",
      "epoch:43 step:33650 [D loss: 0.425655, acc: 78.12%] [G loss: 7.366217]\n",
      "epoch:43 step:33651 [D loss: 0.051054, acc: 100.00%] [G loss: 3.707018]\n",
      "epoch:43 step:33652 [D loss: 0.029555, acc: 100.00%] [G loss: 7.795835]\n",
      "epoch:43 step:33653 [D loss: 0.162192, acc: 96.88%] [G loss: 5.730585]\n",
      "epoch:43 step:33654 [D loss: 0.271505, acc: 96.88%] [G loss: 4.156331]\n",
      "epoch:43 step:33655 [D loss: 0.338981, acc: 88.28%] [G loss: 4.847237]\n",
      "epoch:43 step:33656 [D loss: 0.045423, acc: 100.00%] [G loss: 3.159956]\n",
      "epoch:43 step:33657 [D loss: 0.279063, acc: 94.53%] [G loss: 6.994861]\n",
      "epoch:43 step:33658 [D loss: 0.520014, acc: 63.28%] [G loss: 4.461323]\n",
      "epoch:43 step:33659 [D loss: 0.250176, acc: 96.88%] [G loss: 7.072137]\n",
      "epoch:43 step:33660 [D loss: 0.195954, acc: 97.66%] [G loss: 3.344865]\n",
      "epoch:43 step:33661 [D loss: 0.643567, acc: 58.59%] [G loss: 4.105343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:33662 [D loss: 0.106109, acc: 100.00%] [G loss: 7.312871]\n",
      "epoch:43 step:33663 [D loss: 0.454469, acc: 75.00%] [G loss: 6.071799]\n",
      "epoch:43 step:33664 [D loss: 0.633984, acc: 58.59%] [G loss: 4.806310]\n",
      "epoch:43 step:33665 [D loss: 0.106140, acc: 98.44%] [G loss: 5.869063]\n",
      "epoch:43 step:33666 [D loss: 0.143588, acc: 100.00%] [G loss: 4.154973]\n",
      "epoch:43 step:33667 [D loss: 0.679156, acc: 59.38%] [G loss: 1.720386]\n",
      "epoch:43 step:33668 [D loss: 0.138097, acc: 99.22%] [G loss: 7.602942]\n",
      "epoch:43 step:33669 [D loss: 0.303777, acc: 89.84%] [G loss: 6.176461]\n",
      "epoch:43 step:33670 [D loss: 0.608375, acc: 66.41%] [G loss: 3.528093]\n",
      "epoch:43 step:33671 [D loss: 0.037932, acc: 100.00%] [G loss: 4.987563]\n",
      "epoch:43 step:33672 [D loss: 0.427480, acc: 82.81%] [G loss: 8.998539]\n",
      "epoch:43 step:33673 [D loss: 0.017162, acc: 100.00%] [G loss: 7.349998]\n",
      "epoch:43 step:33674 [D loss: 1.308910, acc: 50.00%] [G loss: 7.113334]\n",
      "epoch:43 step:33675 [D loss: 0.388764, acc: 90.62%] [G loss: 5.236487]\n",
      "epoch:43 step:33676 [D loss: 0.128266, acc: 99.22%] [G loss: 6.463055]\n",
      "epoch:43 step:33677 [D loss: 0.287857, acc: 92.19%] [G loss: 4.003164]\n",
      "epoch:43 step:33678 [D loss: 0.446868, acc: 79.69%] [G loss: 4.719568]\n",
      "epoch:43 step:33679 [D loss: 0.333006, acc: 89.84%] [G loss: 2.240513]\n",
      "epoch:43 step:33680 [D loss: 0.040494, acc: 100.00%] [G loss: 3.803031]\n",
      "epoch:43 step:33681 [D loss: 0.116361, acc: 100.00%] [G loss: 4.221878]\n",
      "epoch:43 step:33682 [D loss: 0.165243, acc: 98.44%] [G loss: 6.871637]\n",
      "epoch:43 step:33683 [D loss: 1.005009, acc: 50.00%] [G loss: 9.263519]\n",
      "epoch:43 step:33684 [D loss: 0.382517, acc: 77.34%] [G loss: 5.978457]\n",
      "epoch:43 step:33685 [D loss: 0.185209, acc: 95.31%] [G loss: 5.164675]\n",
      "epoch:43 step:33686 [D loss: 0.603570, acc: 66.41%] [G loss: 4.502122]\n",
      "epoch:43 step:33687 [D loss: 0.056153, acc: 100.00%] [G loss: 3.926490]\n",
      "epoch:43 step:33688 [D loss: 0.247811, acc: 90.62%] [G loss: 7.026320]\n",
      "epoch:43 step:33689 [D loss: 0.312170, acc: 89.84%] [G loss: 4.403922]\n",
      "epoch:43 step:33690 [D loss: 0.228725, acc: 96.88%] [G loss: 5.943426]\n",
      "epoch:43 step:33691 [D loss: 0.590002, acc: 67.19%] [G loss: 5.301633]\n",
      "epoch:43 step:33692 [D loss: 0.897125, acc: 34.38%] [G loss: 6.891057]\n",
      "epoch:43 step:33693 [D loss: 0.103405, acc: 100.00%] [G loss: 3.766565]\n",
      "epoch:43 step:33694 [D loss: 0.238156, acc: 96.88%] [G loss: 4.895169]\n",
      "epoch:43 step:33695 [D loss: 1.025394, acc: 50.78%] [G loss: 4.275059]\n",
      "epoch:43 step:33696 [D loss: 0.128024, acc: 99.22%] [G loss: 7.973201]\n",
      "epoch:43 step:33697 [D loss: 0.326285, acc: 79.69%] [G loss: 5.482373]\n",
      "epoch:43 step:33698 [D loss: 0.861807, acc: 45.31%] [G loss: 5.800654]\n",
      "epoch:43 step:33699 [D loss: 0.197330, acc: 96.88%] [G loss: 4.343689]\n",
      "epoch:43 step:33700 [D loss: 0.808043, acc: 42.19%] [G loss: 5.482704]\n",
      "epoch:43 step:33701 [D loss: 0.117044, acc: 100.00%] [G loss: 6.253691]\n",
      "epoch:43 step:33702 [D loss: 0.254718, acc: 92.97%] [G loss: 4.705561]\n",
      "epoch:43 step:33703 [D loss: 0.043793, acc: 100.00%] [G loss: 4.156415]\n",
      "epoch:43 step:33704 [D loss: 0.244276, acc: 93.75%] [G loss: 5.060991]\n",
      "epoch:43 step:33705 [D loss: 0.040448, acc: 100.00%] [G loss: 5.896148]\n",
      "epoch:43 step:33706 [D loss: 0.268181, acc: 90.62%] [G loss: 7.654743]\n",
      "epoch:43 step:33707 [D loss: 0.466727, acc: 75.00%] [G loss: 3.349129]\n",
      "epoch:43 step:33708 [D loss: 0.182174, acc: 96.88%] [G loss: 8.065674]\n",
      "epoch:43 step:33709 [D loss: 0.206423, acc: 94.53%] [G loss: 6.971172]\n",
      "epoch:43 step:33710 [D loss: 1.048043, acc: 50.00%] [G loss: 5.566938]\n",
      "epoch:43 step:33711 [D loss: 0.559564, acc: 63.28%] [G loss: 7.113041]\n",
      "epoch:43 step:33712 [D loss: 0.058466, acc: 100.00%] [G loss: 4.300092]\n",
      "epoch:43 step:33713 [D loss: 0.627421, acc: 62.50%] [G loss: 8.098048]\n",
      "epoch:43 step:33714 [D loss: 0.532024, acc: 75.00%] [G loss: 6.304399]\n",
      "epoch:43 step:33715 [D loss: 0.123977, acc: 100.00%] [G loss: 5.566543]\n",
      "epoch:43 step:33716 [D loss: 0.218831, acc: 94.53%] [G loss: 3.987215]\n",
      "epoch:43 step:33717 [D loss: 0.281622, acc: 85.94%] [G loss: 5.548231]\n",
      "epoch:43 step:33718 [D loss: 0.404879, acc: 75.00%] [G loss: 5.456752]\n",
      "epoch:43 step:33719 [D loss: 0.011340, acc: 100.00%] [G loss: 6.985313]\n",
      "epoch:43 step:33720 [D loss: 0.035618, acc: 100.00%] [G loss: 4.991436]\n",
      "epoch:43 step:33721 [D loss: 0.050991, acc: 100.00%] [G loss: 3.180281]\n",
      "epoch:43 step:33722 [D loss: 0.110115, acc: 100.00%] [G loss: 3.244197]\n",
      "epoch:43 step:33723 [D loss: 0.516759, acc: 70.31%] [G loss: 4.968760]\n",
      "epoch:43 step:33724 [D loss: 0.094050, acc: 100.00%] [G loss: 6.507511]\n",
      "epoch:43 step:33725 [D loss: 0.223294, acc: 95.31%] [G loss: 3.347867]\n",
      "epoch:43 step:33726 [D loss: 0.396080, acc: 90.62%] [G loss: 6.269221]\n",
      "epoch:43 step:33727 [D loss: 0.044671, acc: 99.22%] [G loss: 4.246908]\n",
      "epoch:43 step:33728 [D loss: 0.251929, acc: 96.88%] [G loss: 3.889474]\n",
      "epoch:43 step:33729 [D loss: 0.197335, acc: 95.31%] [G loss: 7.500919]\n",
      "epoch:43 step:33730 [D loss: 1.065807, acc: 50.00%] [G loss: 5.768221]\n",
      "epoch:43 step:33731 [D loss: 0.088699, acc: 99.22%] [G loss: 3.610976]\n",
      "epoch:43 step:33732 [D loss: 1.226708, acc: 42.97%] [G loss: 8.939225]\n",
      "epoch:43 step:33733 [D loss: 0.095950, acc: 100.00%] [G loss: 2.024477]\n",
      "epoch:43 step:33734 [D loss: 0.450488, acc: 70.31%] [G loss: 7.699337]\n",
      "epoch:43 step:33735 [D loss: 0.646343, acc: 57.81%] [G loss: 6.671312]\n",
      "epoch:43 step:33736 [D loss: 0.505764, acc: 71.88%] [G loss: 6.288622]\n",
      "epoch:43 step:33737 [D loss: 0.492179, acc: 68.75%] [G loss: 4.269157]\n",
      "epoch:43 step:33738 [D loss: 0.357010, acc: 83.59%] [G loss: 4.054297]\n",
      "epoch:43 step:33739 [D loss: 0.196091, acc: 98.44%] [G loss: 6.816243]\n",
      "epoch:43 step:33740 [D loss: 0.022362, acc: 100.00%] [G loss: 5.201463]\n",
      "epoch:43 step:33741 [D loss: 0.051662, acc: 100.00%] [G loss: 7.154498]\n",
      "epoch:43 step:33742 [D loss: 0.390669, acc: 85.94%] [G loss: 7.799221]\n",
      "epoch:43 step:33743 [D loss: 0.093037, acc: 100.00%] [G loss: 2.754101]\n",
      "epoch:43 step:33744 [D loss: 0.479314, acc: 74.22%] [G loss: 4.977143]\n",
      "epoch:43 step:33745 [D loss: 1.196282, acc: 35.16%] [G loss: 6.517036]\n",
      "epoch:43 step:33746 [D loss: 0.214696, acc: 92.19%] [G loss: 6.895143]\n",
      "epoch:43 step:33747 [D loss: 1.418662, acc: 26.56%] [G loss: 6.730971]\n",
      "epoch:43 step:33748 [D loss: 0.564608, acc: 73.44%] [G loss: 5.657211]\n",
      "epoch:43 step:33749 [D loss: 0.463612, acc: 67.97%] [G loss: 3.510899]\n",
      "epoch:43 step:33750 [D loss: 0.092921, acc: 100.00%] [G loss: 6.419579]\n",
      "epoch:43 step:33751 [D loss: 0.180814, acc: 95.31%] [G loss: 6.482981]\n",
      "epoch:43 step:33752 [D loss: 0.076879, acc: 100.00%] [G loss: 4.179205]\n",
      "epoch:43 step:33753 [D loss: 0.308876, acc: 85.94%] [G loss: 3.918879]\n",
      "epoch:43 step:33754 [D loss: 0.102401, acc: 99.22%] [G loss: 5.314191]\n",
      "epoch:43 step:33755 [D loss: 0.330379, acc: 92.19%] [G loss: 6.014681]\n",
      "epoch:43 step:33756 [D loss: 0.999825, acc: 32.81%] [G loss: 6.251166]\n",
      "epoch:43 step:33757 [D loss: 0.092328, acc: 100.00%] [G loss: 6.479029]\n",
      "epoch:43 step:33758 [D loss: 0.020490, acc: 100.00%] [G loss: 6.274511]\n",
      "epoch:43 step:33759 [D loss: 0.035664, acc: 100.00%] [G loss: 7.688101]\n",
      "epoch:43 step:33760 [D loss: 0.090293, acc: 100.00%] [G loss: 5.549768]\n",
      "epoch:43 step:33761 [D loss: 0.128408, acc: 99.22%] [G loss: 5.623303]\n",
      "epoch:43 step:33762 [D loss: 0.146398, acc: 98.44%] [G loss: 5.340635]\n",
      "epoch:43 step:33763 [D loss: 0.508429, acc: 64.84%] [G loss: 5.525687]\n",
      "epoch:43 step:33764 [D loss: 0.254083, acc: 96.09%] [G loss: 4.272244]\n",
      "epoch:43 step:33765 [D loss: 0.322714, acc: 85.94%] [G loss: 5.537979]\n",
      "epoch:43 step:33766 [D loss: 0.096879, acc: 97.66%] [G loss: 1.719689]\n",
      "epoch:43 step:33767 [D loss: 0.657778, acc: 56.25%] [G loss: 7.460402]\n",
      "epoch:43 step:33768 [D loss: 0.091772, acc: 100.00%] [G loss: 7.468199]\n",
      "epoch:43 step:33769 [D loss: 0.161075, acc: 98.44%] [G loss: 2.622954]\n",
      "epoch:43 step:33770 [D loss: 0.063739, acc: 100.00%] [G loss: 5.816740]\n",
      "epoch:43 step:33771 [D loss: 0.676619, acc: 57.81%] [G loss: 6.730771]\n",
      "epoch:43 step:33772 [D loss: 0.349983, acc: 77.34%] [G loss: 7.929368]\n",
      "epoch:43 step:33773 [D loss: 0.054145, acc: 100.00%] [G loss: 3.992517]\n",
      "epoch:43 step:33774 [D loss: 0.220476, acc: 94.53%] [G loss: 4.373624]\n",
      "epoch:43 step:33775 [D loss: 0.135643, acc: 100.00%] [G loss: 6.497670]\n",
      "epoch:43 step:33776 [D loss: 0.138760, acc: 100.00%] [G loss: 4.406648]\n",
      "epoch:43 step:33777 [D loss: 0.037906, acc: 100.00%] [G loss: 4.567540]\n",
      "epoch:43 step:33778 [D loss: 0.258872, acc: 97.66%] [G loss: 4.768458]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:33779 [D loss: 0.058813, acc: 100.00%] [G loss: 8.964579]\n",
      "epoch:43 step:33780 [D loss: 0.041591, acc: 100.00%] [G loss: 7.550757]\n",
      "epoch:43 step:33781 [D loss: 0.172180, acc: 97.66%] [G loss: 4.557492]\n",
      "epoch:43 step:33782 [D loss: 0.404318, acc: 89.84%] [G loss: 5.197776]\n",
      "epoch:43 step:33783 [D loss: 0.146756, acc: 99.22%] [G loss: 5.563487]\n",
      "epoch:43 step:33784 [D loss: 0.066400, acc: 100.00%] [G loss: 4.280149]\n",
      "epoch:43 step:33785 [D loss: 0.498591, acc: 66.41%] [G loss: 6.932749]\n",
      "epoch:43 step:33786 [D loss: 0.731242, acc: 56.25%] [G loss: 4.307177]\n",
      "epoch:43 step:33787 [D loss: 0.259962, acc: 96.09%] [G loss: 5.133021]\n",
      "epoch:43 step:33788 [D loss: 0.357824, acc: 87.50%] [G loss: 2.051306]\n",
      "epoch:43 step:33789 [D loss: 0.369259, acc: 89.06%] [G loss: 6.703687]\n",
      "epoch:43 step:33790 [D loss: 0.229558, acc: 93.75%] [G loss: 6.690006]\n",
      "epoch:43 step:33791 [D loss: 0.743036, acc: 54.69%] [G loss: 4.490389]\n",
      "epoch:43 step:33792 [D loss: 1.059107, acc: 50.00%] [G loss: 7.941088]\n",
      "epoch:43 step:33793 [D loss: 0.210118, acc: 97.66%] [G loss: 5.179264]\n",
      "epoch:43 step:33794 [D loss: 0.326905, acc: 91.41%] [G loss: 4.020998]\n",
      "epoch:43 step:33795 [D loss: 0.109629, acc: 99.22%] [G loss: 7.675335]\n",
      "epoch:43 step:33796 [D loss: 0.311687, acc: 82.81%] [G loss: 6.551691]\n",
      "epoch:43 step:33797 [D loss: 0.020851, acc: 100.00%] [G loss: 5.802053]\n",
      "epoch:43 step:33798 [D loss: 0.253164, acc: 94.53%] [G loss: 5.717539]\n",
      "epoch:43 step:33799 [D loss: 0.372218, acc: 78.12%] [G loss: 6.086231]\n",
      "epoch:43 step:33800 [D loss: 0.122513, acc: 100.00%] [G loss: 5.753457]\n",
      "epoch:43 step:33801 [D loss: 0.216869, acc: 94.53%] [G loss: 5.074024]\n",
      "epoch:43 step:33802 [D loss: 0.084205, acc: 100.00%] [G loss: 5.087403]\n",
      "epoch:43 step:33803 [D loss: 0.278051, acc: 92.19%] [G loss: 5.494431]\n",
      "epoch:43 step:33804 [D loss: 0.492000, acc: 78.91%] [G loss: 6.878168]\n",
      "epoch:43 step:33805 [D loss: 0.912688, acc: 50.00%] [G loss: 4.547527]\n",
      "epoch:43 step:33806 [D loss: 0.188372, acc: 95.31%] [G loss: 6.194623]\n",
      "epoch:43 step:33807 [D loss: 0.195890, acc: 96.09%] [G loss: 4.201137]\n",
      "epoch:43 step:33808 [D loss: 0.131645, acc: 99.22%] [G loss: 6.277314]\n",
      "epoch:43 step:33809 [D loss: 0.109072, acc: 99.22%] [G loss: 3.479378]\n",
      "epoch:43 step:33810 [D loss: 0.041297, acc: 100.00%] [G loss: 5.408115]\n",
      "epoch:43 step:33811 [D loss: 0.110401, acc: 99.22%] [G loss: 2.830608]\n",
      "epoch:43 step:33812 [D loss: 0.077882, acc: 100.00%] [G loss: 6.259791]\n",
      "epoch:43 step:33813 [D loss: 0.219142, acc: 96.09%] [G loss: 3.083616]\n",
      "epoch:43 step:33814 [D loss: 0.331661, acc: 85.16%] [G loss: 3.655533]\n",
      "epoch:43 step:33815 [D loss: 0.217565, acc: 94.53%] [G loss: 6.378603]\n",
      "epoch:43 step:33816 [D loss: 0.523930, acc: 65.62%] [G loss: 6.936182]\n",
      "epoch:43 step:33817 [D loss: 0.070917, acc: 100.00%] [G loss: 4.559196]\n",
      "epoch:43 step:33818 [D loss: 0.111841, acc: 99.22%] [G loss: 3.544920]\n",
      "epoch:43 step:33819 [D loss: 0.601388, acc: 61.72%] [G loss: 8.484248]\n",
      "epoch:43 step:33820 [D loss: 0.258612, acc: 87.50%] [G loss: 3.384013]\n",
      "epoch:43 step:33821 [D loss: 0.149584, acc: 96.88%] [G loss: 6.464908]\n",
      "epoch:43 step:33822 [D loss: 0.083419, acc: 100.00%] [G loss: 5.091359]\n",
      "epoch:43 step:33823 [D loss: 0.142390, acc: 97.66%] [G loss: 7.334113]\n",
      "epoch:43 step:33824 [D loss: 0.138787, acc: 100.00%] [G loss: 5.856815]\n",
      "epoch:43 step:33825 [D loss: 1.410935, acc: 50.00%] [G loss: 4.868268]\n",
      "epoch:43 step:33826 [D loss: 0.187461, acc: 99.22%] [G loss: 5.046527]\n",
      "epoch:43 step:33827 [D loss: 0.093301, acc: 100.00%] [G loss: 5.662844]\n",
      "epoch:43 step:33828 [D loss: 1.146340, acc: 18.75%] [G loss: 8.527336]\n",
      "epoch:43 step:33829 [D loss: 0.427529, acc: 82.81%] [G loss: 4.607649]\n",
      "epoch:43 step:33830 [D loss: 0.603952, acc: 68.75%] [G loss: 7.586668]\n",
      "epoch:43 step:33831 [D loss: 0.666204, acc: 56.25%] [G loss: 7.578627]\n",
      "epoch:43 step:33832 [D loss: 0.759511, acc: 53.12%] [G loss: 8.266120]\n",
      "epoch:43 step:33833 [D loss: 0.303350, acc: 86.72%] [G loss: 4.099966]\n",
      "epoch:43 step:33834 [D loss: 0.149685, acc: 98.44%] [G loss: 5.829710]\n",
      "epoch:43 step:33835 [D loss: 0.478321, acc: 66.41%] [G loss: 8.455876]\n",
      "epoch:43 step:33836 [D loss: 0.559321, acc: 67.97%] [G loss: 5.688906]\n",
      "epoch:43 step:33837 [D loss: 0.382756, acc: 88.28%] [G loss: 4.198497]\n",
      "epoch:43 step:33838 [D loss: 2.016844, acc: 2.34%] [G loss: 6.036258]\n",
      "epoch:43 step:33839 [D loss: 0.257350, acc: 95.31%] [G loss: 7.309842]\n",
      "epoch:43 step:33840 [D loss: 0.221508, acc: 96.09%] [G loss: 6.389702]\n",
      "epoch:43 step:33841 [D loss: 0.101678, acc: 98.44%] [G loss: 4.335709]\n",
      "epoch:43 step:33842 [D loss: 1.077775, acc: 39.06%] [G loss: 7.318542]\n",
      "epoch:43 step:33843 [D loss: 0.290159, acc: 86.72%] [G loss: 7.022376]\n",
      "epoch:43 step:33844 [D loss: 0.327274, acc: 89.84%] [G loss: 6.328647]\n",
      "epoch:43 step:33845 [D loss: 0.199679, acc: 99.22%] [G loss: 9.869276]\n",
      "epoch:43 step:33846 [D loss: 0.144488, acc: 99.22%] [G loss: 7.509446]\n",
      "epoch:43 step:33847 [D loss: 0.059377, acc: 100.00%] [G loss: 7.550912]\n",
      "epoch:43 step:33848 [D loss: 0.138710, acc: 100.00%] [G loss: 10.300478]\n",
      "epoch:43 step:33849 [D loss: 0.148840, acc: 99.22%] [G loss: 6.897456]\n",
      "epoch:43 step:33850 [D loss: 0.056103, acc: 100.00%] [G loss: 8.608221]\n",
      "epoch:43 step:33851 [D loss: 1.128939, acc: 50.00%] [G loss: 9.069470]\n",
      "epoch:43 step:33852 [D loss: 0.150182, acc: 98.44%] [G loss: 7.423584]\n",
      "epoch:43 step:33853 [D loss: 0.870747, acc: 51.56%] [G loss: 5.455197]\n",
      "epoch:43 step:33854 [D loss: 0.225999, acc: 90.62%] [G loss: 6.104396]\n",
      "epoch:43 step:33855 [D loss: 0.596470, acc: 73.44%] [G loss: 6.079929]\n",
      "epoch:43 step:33856 [D loss: 0.891655, acc: 46.09%] [G loss: 5.701969]\n",
      "epoch:43 step:33857 [D loss: 0.400238, acc: 82.81%] [G loss: 5.649640]\n",
      "epoch:43 step:33858 [D loss: 0.834771, acc: 52.34%] [G loss: 3.420466]\n",
      "epoch:43 step:33859 [D loss: 0.299451, acc: 90.62%] [G loss: 6.683401]\n",
      "epoch:43 step:33860 [D loss: 0.052421, acc: 100.00%] [G loss: 3.274517]\n",
      "epoch:43 step:33861 [D loss: 0.019773, acc: 100.00%] [G loss: 9.250410]\n",
      "epoch:43 step:33862 [D loss: 0.554120, acc: 72.66%] [G loss: 5.129776]\n",
      "epoch:43 step:33863 [D loss: 0.405345, acc: 81.25%] [G loss: 3.172352]\n",
      "epoch:43 step:33864 [D loss: 0.037950, acc: 100.00%] [G loss: 4.438174]\n",
      "epoch:43 step:33865 [D loss: 0.078819, acc: 99.22%] [G loss: 4.945574]\n",
      "epoch:43 step:33866 [D loss: 1.206463, acc: 51.56%] [G loss: 7.674226]\n",
      "epoch:43 step:33867 [D loss: 0.441896, acc: 73.44%] [G loss: 4.656020]\n",
      "epoch:43 step:33868 [D loss: 0.636209, acc: 57.81%] [G loss: 5.868385]\n",
      "epoch:43 step:33869 [D loss: 0.425425, acc: 71.88%] [G loss: 7.505167]\n",
      "epoch:43 step:33870 [D loss: 1.746108, acc: 15.62%] [G loss: 7.641226]\n",
      "epoch:43 step:33871 [D loss: 0.370541, acc: 83.59%] [G loss: 7.437457]\n",
      "epoch:43 step:33872 [D loss: 0.536459, acc: 71.09%] [G loss: 5.739903]\n",
      "epoch:43 step:33873 [D loss: 0.158346, acc: 99.22%] [G loss: 4.197165]\n",
      "epoch:43 step:33874 [D loss: 0.104216, acc: 100.00%] [G loss: 6.361478]\n",
      "epoch:43 step:33875 [D loss: 0.109679, acc: 100.00%] [G loss: 5.253188]\n",
      "epoch:43 step:33876 [D loss: 0.051797, acc: 100.00%] [G loss: 3.853776]\n",
      "epoch:43 step:33877 [D loss: 0.442618, acc: 89.84%] [G loss: 6.914312]\n",
      "epoch:43 step:33878 [D loss: 0.049135, acc: 100.00%] [G loss: 4.644186]\n",
      "epoch:43 step:33879 [D loss: 0.166940, acc: 96.88%] [G loss: 4.907848]\n",
      "epoch:43 step:33880 [D loss: 0.203264, acc: 96.09%] [G loss: 4.928741]\n",
      "epoch:43 step:33881 [D loss: 0.380727, acc: 90.62%] [G loss: 6.842638]\n",
      "epoch:43 step:33882 [D loss: 0.615516, acc: 60.16%] [G loss: 7.734873]\n",
      "epoch:43 step:33883 [D loss: 0.179251, acc: 95.31%] [G loss: 9.503942]\n",
      "epoch:43 step:33884 [D loss: 0.228274, acc: 93.75%] [G loss: 7.577055]\n",
      "epoch:43 step:33885 [D loss: 0.056062, acc: 100.00%] [G loss: 3.581767]\n",
      "epoch:43 step:33886 [D loss: 0.073803, acc: 100.00%] [G loss: 5.448460]\n",
      "epoch:43 step:33887 [D loss: 0.131066, acc: 98.44%] [G loss: 5.088243]\n",
      "epoch:43 step:33888 [D loss: 0.324646, acc: 88.28%] [G loss: 3.002934]\n",
      "epoch:43 step:33889 [D loss: 0.498380, acc: 85.16%] [G loss: 7.427909]\n",
      "epoch:43 step:33890 [D loss: 0.127152, acc: 100.00%] [G loss: 8.163603]\n",
      "epoch:43 step:33891 [D loss: 1.169088, acc: 50.78%] [G loss: 5.241948]\n",
      "epoch:43 step:33892 [D loss: 1.433017, acc: 44.53%] [G loss: 5.079998]\n",
      "epoch:43 step:33893 [D loss: 0.018091, acc: 100.00%] [G loss: 7.864179]\n",
      "epoch:43 step:33894 [D loss: 0.171840, acc: 96.88%] [G loss: 3.044484]\n",
      "epoch:43 step:33895 [D loss: 0.385650, acc: 84.38%] [G loss: 4.344031]\n",
      "epoch:43 step:33896 [D loss: 0.237988, acc: 95.31%] [G loss: 6.740284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:33897 [D loss: 0.242104, acc: 97.66%] [G loss: 5.571522]\n",
      "epoch:43 step:33898 [D loss: 0.831301, acc: 52.34%] [G loss: 5.019114]\n",
      "epoch:43 step:33899 [D loss: 0.033541, acc: 100.00%] [G loss: 7.543613]\n",
      "epoch:43 step:33900 [D loss: 1.011855, acc: 50.00%] [G loss: 4.344619]\n",
      "epoch:43 step:33901 [D loss: 0.046168, acc: 100.00%] [G loss: 4.491096]\n",
      "epoch:43 step:33902 [D loss: 0.283878, acc: 95.31%] [G loss: 6.169787]\n",
      "epoch:43 step:33903 [D loss: 0.408532, acc: 74.22%] [G loss: 6.372559]\n",
      "epoch:43 step:33904 [D loss: 0.524451, acc: 67.19%] [G loss: 8.843376]\n",
      "epoch:43 step:33905 [D loss: 0.091433, acc: 100.00%] [G loss: 3.926064]\n",
      "epoch:43 step:33906 [D loss: 0.462034, acc: 78.12%] [G loss: 5.805234]\n",
      "epoch:43 step:33907 [D loss: 0.364400, acc: 91.41%] [G loss: 6.390776]\n",
      "epoch:43 step:33908 [D loss: 0.131620, acc: 99.22%] [G loss: 3.026396]\n",
      "epoch:43 step:33909 [D loss: 0.127173, acc: 100.00%] [G loss: 4.331284]\n",
      "epoch:43 step:33910 [D loss: 0.064260, acc: 100.00%] [G loss: 4.396641]\n",
      "epoch:43 step:33911 [D loss: 0.187878, acc: 96.09%] [G loss: 7.532280]\n",
      "epoch:43 step:33912 [D loss: 0.226089, acc: 91.41%] [G loss: 4.942012]\n",
      "epoch:43 step:33913 [D loss: 0.229018, acc: 96.09%] [G loss: 7.420571]\n",
      "epoch:43 step:33914 [D loss: 0.271849, acc: 85.94%] [G loss: 7.914134]\n",
      "epoch:43 step:33915 [D loss: 0.585623, acc: 64.84%] [G loss: 4.281791]\n",
      "epoch:43 step:33916 [D loss: 0.027324, acc: 100.00%] [G loss: 7.692310]\n",
      "epoch:43 step:33917 [D loss: 0.358134, acc: 81.25%] [G loss: 6.672037]\n",
      "epoch:43 step:33918 [D loss: 0.034614, acc: 98.44%] [G loss: 6.472980]\n",
      "epoch:43 step:33919 [D loss: 0.162690, acc: 98.44%] [G loss: 5.728312]\n",
      "epoch:43 step:33920 [D loss: 0.396053, acc: 79.69%] [G loss: 6.739084]\n",
      "epoch:43 step:33921 [D loss: 1.281519, acc: 50.00%] [G loss: 7.351258]\n",
      "epoch:43 step:33922 [D loss: 0.686670, acc: 56.25%] [G loss: 2.528593]\n",
      "epoch:43 step:33923 [D loss: 0.024525, acc: 100.00%] [G loss: 6.469696]\n",
      "epoch:43 step:33924 [D loss: 1.352339, acc: 46.09%] [G loss: 4.230347]\n",
      "epoch:43 step:33925 [D loss: 0.973176, acc: 53.91%] [G loss: 5.848992]\n",
      "epoch:43 step:33926 [D loss: 0.545836, acc: 63.28%] [G loss: 7.697577]\n",
      "epoch:43 step:33927 [D loss: 0.337786, acc: 80.47%] [G loss: 5.183007]\n",
      "epoch:43 step:33928 [D loss: 0.801858, acc: 56.25%] [G loss: 3.283548]\n",
      "epoch:43 step:33929 [D loss: 0.089884, acc: 99.22%] [G loss: 4.322328]\n",
      "epoch:43 step:33930 [D loss: 0.594969, acc: 55.47%] [G loss: 6.351338]\n",
      "epoch:43 step:33931 [D loss: 0.085740, acc: 98.44%] [G loss: 4.881244]\n",
      "epoch:43 step:33932 [D loss: 0.248795, acc: 92.97%] [G loss: 5.796902]\n",
      "epoch:43 step:33933 [D loss: 0.385126, acc: 73.44%] [G loss: 5.435082]\n",
      "epoch:43 step:33934 [D loss: 0.422651, acc: 85.94%] [G loss: 3.209522]\n",
      "epoch:43 step:33935 [D loss: 0.555755, acc: 70.31%] [G loss: 5.697947]\n",
      "epoch:43 step:33936 [D loss: 0.192872, acc: 98.44%] [G loss: 4.774797]\n",
      "epoch:43 step:33937 [D loss: 0.243254, acc: 96.09%] [G loss: 2.950110]\n",
      "epoch:43 step:33938 [D loss: 0.474364, acc: 74.22%] [G loss: 6.929070]\n",
      "epoch:43 step:33939 [D loss: 0.049993, acc: 100.00%] [G loss: 5.607090]\n",
      "epoch:43 step:33940 [D loss: 0.136500, acc: 100.00%] [G loss: 8.008219]\n",
      "epoch:43 step:33941 [D loss: 0.192548, acc: 92.97%] [G loss: 5.328325]\n",
      "epoch:43 step:33942 [D loss: 0.141983, acc: 97.66%] [G loss: 4.016981]\n",
      "epoch:43 step:33943 [D loss: 0.237094, acc: 91.41%] [G loss: 9.203983]\n",
      "epoch:43 step:33944 [D loss: 1.272026, acc: 17.19%] [G loss: 7.324360]\n",
      "epoch:43 step:33945 [D loss: 0.260963, acc: 96.09%] [G loss: 7.152041]\n",
      "epoch:43 step:33946 [D loss: 0.134875, acc: 98.44%] [G loss: 6.333154]\n",
      "epoch:43 step:33947 [D loss: 0.813586, acc: 48.44%] [G loss: 6.641324]\n",
      "epoch:43 step:33948 [D loss: 0.025919, acc: 100.00%] [G loss: 3.968167]\n",
      "epoch:43 step:33949 [D loss: 0.154714, acc: 97.66%] [G loss: 2.843071]\n",
      "epoch:43 step:33950 [D loss: 0.744982, acc: 56.25%] [G loss: 4.621781]\n",
      "epoch:43 step:33951 [D loss: 0.685215, acc: 56.25%] [G loss: 8.901543]\n",
      "epoch:43 step:33952 [D loss: 0.100750, acc: 100.00%] [G loss: 9.973230]\n",
      "epoch:43 step:33953 [D loss: 0.161143, acc: 99.22%] [G loss: 4.187435]\n",
      "epoch:43 step:33954 [D loss: 0.557473, acc: 68.75%] [G loss: 8.911828]\n",
      "epoch:43 step:33955 [D loss: 0.081603, acc: 100.00%] [G loss: 7.027532]\n",
      "epoch:43 step:33956 [D loss: 0.221198, acc: 96.09%] [G loss: 6.409682]\n",
      "epoch:43 step:33957 [D loss: 0.177860, acc: 94.53%] [G loss: 4.991761]\n",
      "epoch:43 step:33958 [D loss: 0.286230, acc: 92.97%] [G loss: 3.584892]\n",
      "epoch:43 step:33959 [D loss: 1.109056, acc: 33.59%] [G loss: 5.723785]\n",
      "epoch:43 step:33960 [D loss: 0.687790, acc: 60.16%] [G loss: 6.992663]\n",
      "epoch:43 step:33961 [D loss: 0.029141, acc: 100.00%] [G loss: 6.916092]\n",
      "epoch:43 step:33962 [D loss: 0.470371, acc: 67.19%] [G loss: 9.889261]\n",
      "epoch:43 step:33963 [D loss: 0.009680, acc: 100.00%] [G loss: 6.304119]\n",
      "epoch:43 step:33964 [D loss: 0.145285, acc: 98.44%] [G loss: 9.067589]\n",
      "epoch:43 step:33965 [D loss: 0.136263, acc: 98.44%] [G loss: 5.773703]\n",
      "epoch:43 step:33966 [D loss: 0.249384, acc: 89.06%] [G loss: 7.562543]\n",
      "epoch:43 step:33967 [D loss: 1.115741, acc: 50.00%] [G loss: 4.435856]\n",
      "epoch:43 step:33968 [D loss: 0.202940, acc: 96.09%] [G loss: 4.258273]\n",
      "epoch:43 step:33969 [D loss: 0.113416, acc: 100.00%] [G loss: 4.907217]\n",
      "epoch:43 step:33970 [D loss: 1.008821, acc: 51.56%] [G loss: 6.779535]\n",
      "epoch:43 step:33971 [D loss: 0.783615, acc: 50.78%] [G loss: 7.513042]\n",
      "epoch:43 step:33972 [D loss: 0.788939, acc: 47.66%] [G loss: 5.965199]\n",
      "epoch:43 step:33973 [D loss: 0.109505, acc: 100.00%] [G loss: 4.108962]\n",
      "epoch:43 step:33974 [D loss: 0.260070, acc: 86.72%] [G loss: 4.289211]\n",
      "epoch:43 step:33975 [D loss: 0.055945, acc: 100.00%] [G loss: 7.130248]\n",
      "epoch:43 step:33976 [D loss: 0.509176, acc: 80.47%] [G loss: 4.405668]\n",
      "epoch:43 step:33977 [D loss: 0.269268, acc: 92.19%] [G loss: 4.726338]\n",
      "epoch:43 step:33978 [D loss: 0.260604, acc: 92.97%] [G loss: 2.518775]\n",
      "epoch:43 step:33979 [D loss: 0.572818, acc: 69.53%] [G loss: 5.569851]\n",
      "epoch:43 step:33980 [D loss: 0.591422, acc: 68.75%] [G loss: 4.070449]\n",
      "epoch:43 step:33981 [D loss: 0.190617, acc: 96.09%] [G loss: 5.195066]\n",
      "epoch:43 step:33982 [D loss: 0.206754, acc: 98.44%] [G loss: 6.873162]\n",
      "epoch:43 step:33983 [D loss: 0.422986, acc: 75.78%] [G loss: 3.508114]\n",
      "epoch:43 step:33984 [D loss: 0.349742, acc: 91.41%] [G loss: 7.481863]\n",
      "epoch:43 step:33985 [D loss: 0.260430, acc: 88.28%] [G loss: 6.613728]\n",
      "epoch:43 step:33986 [D loss: 0.155379, acc: 98.44%] [G loss: 2.092905]\n",
      "epoch:43 step:33987 [D loss: 0.485050, acc: 80.47%] [G loss: 3.526819]\n",
      "epoch:43 step:33988 [D loss: 0.349018, acc: 90.62%] [G loss: 6.011486]\n",
      "epoch:43 step:33989 [D loss: 0.770387, acc: 53.91%] [G loss: 8.280317]\n",
      "epoch:43 step:33990 [D loss: 0.402319, acc: 72.66%] [G loss: 6.612625]\n",
      "epoch:43 step:33991 [D loss: 0.191948, acc: 100.00%] [G loss: 5.304093]\n",
      "epoch:43 step:33992 [D loss: 0.211697, acc: 98.44%] [G loss: 5.728814]\n",
      "epoch:43 step:33993 [D loss: 0.174246, acc: 96.09%] [G loss: 4.903958]\n",
      "epoch:43 step:33994 [D loss: 0.274616, acc: 93.75%] [G loss: 2.431344]\n",
      "epoch:43 step:33995 [D loss: 0.039057, acc: 100.00%] [G loss: 5.411875]\n",
      "epoch:43 step:33996 [D loss: 0.088203, acc: 100.00%] [G loss: 7.190810]\n",
      "epoch:43 step:33997 [D loss: 0.250671, acc: 96.09%] [G loss: 3.537005]\n",
      "epoch:43 step:33998 [D loss: 0.430073, acc: 78.91%] [G loss: 4.548674]\n",
      "epoch:43 step:33999 [D loss: 0.399966, acc: 81.25%] [G loss: 5.004088]\n",
      "epoch:43 step:34000 [D loss: 0.837257, acc: 49.22%] [G loss: 5.453591]\n",
      "epoch:43 step:34001 [D loss: 0.457261, acc: 67.97%] [G loss: 5.962383]\n",
      "epoch:43 step:34002 [D loss: 0.675492, acc: 61.72%] [G loss: 5.083766]\n",
      "epoch:43 step:34003 [D loss: 0.266191, acc: 89.06%] [G loss: 4.541752]\n",
      "epoch:43 step:34004 [D loss: 0.061716, acc: 100.00%] [G loss: 6.812193]\n",
      "epoch:43 step:34005 [D loss: 0.203236, acc: 96.09%] [G loss: 7.649333]\n",
      "epoch:43 step:34006 [D loss: 0.155614, acc: 98.44%] [G loss: 8.220192]\n",
      "epoch:43 step:34007 [D loss: 0.832887, acc: 38.28%] [G loss: 4.638560]\n",
      "epoch:43 step:34008 [D loss: 0.826014, acc: 48.44%] [G loss: 5.651542]\n",
      "epoch:43 step:34009 [D loss: 0.137593, acc: 100.00%] [G loss: 4.198637]\n",
      "epoch:43 step:34010 [D loss: 0.299377, acc: 89.84%] [G loss: 6.041789]\n",
      "epoch:43 step:34011 [D loss: 0.408665, acc: 82.03%] [G loss: 4.090413]\n",
      "epoch:43 step:34012 [D loss: 0.036116, acc: 100.00%] [G loss: 6.763664]\n",
      "epoch:43 step:34013 [D loss: 0.113458, acc: 100.00%] [G loss: 7.151637]\n",
      "epoch:43 step:34014 [D loss: 0.236712, acc: 92.97%] [G loss: 6.468426]\n",
      "epoch:43 step:34015 [D loss: 0.079610, acc: 99.22%] [G loss: 6.055641]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:34016 [D loss: 0.011393, acc: 100.00%] [G loss: 9.309731]\n",
      "epoch:43 step:34017 [D loss: 0.103723, acc: 99.22%] [G loss: 5.163103]\n",
      "epoch:43 step:34018 [D loss: 0.013915, acc: 100.00%] [G loss: 7.170322]\n",
      "epoch:43 step:34019 [D loss: 0.105655, acc: 100.00%] [G loss: 6.074275]\n",
      "epoch:43 step:34020 [D loss: 0.895799, acc: 40.62%] [G loss: 6.277477]\n",
      "epoch:43 step:34021 [D loss: 0.081039, acc: 99.22%] [G loss: 7.134516]\n",
      "epoch:43 step:34022 [D loss: 0.354135, acc: 84.38%] [G loss: 5.232412]\n",
      "epoch:43 step:34023 [D loss: 0.162478, acc: 99.22%] [G loss: 3.252771]\n",
      "epoch:43 step:34024 [D loss: 0.262146, acc: 88.28%] [G loss: 5.733421]\n",
      "epoch:43 step:34025 [D loss: 0.330957, acc: 88.28%] [G loss: 6.698174]\n",
      "epoch:43 step:34026 [D loss: 0.185872, acc: 97.66%] [G loss: 2.235729]\n",
      "epoch:43 step:34027 [D loss: 0.104562, acc: 100.00%] [G loss: 4.551057]\n",
      "epoch:43 step:34028 [D loss: 0.480712, acc: 73.44%] [G loss: 7.898379]\n",
      "epoch:43 step:34029 [D loss: 0.525541, acc: 63.28%] [G loss: 6.685213]\n",
      "epoch:43 step:34030 [D loss: 0.768258, acc: 53.12%] [G loss: 9.483784]\n",
      "epoch:43 step:34031 [D loss: 0.491599, acc: 80.47%] [G loss: 9.392910]\n",
      "epoch:43 step:34032 [D loss: 0.247153, acc: 91.41%] [G loss: 7.110196]\n",
      "epoch:43 step:34033 [D loss: 0.375982, acc: 80.47%] [G loss: 7.518430]\n",
      "epoch:43 step:34034 [D loss: 0.101520, acc: 99.22%] [G loss: 6.323565]\n",
      "epoch:43 step:34035 [D loss: 0.376791, acc: 79.69%] [G loss: 4.858482]\n",
      "epoch:43 step:34036 [D loss: 0.078657, acc: 100.00%] [G loss: 4.569724]\n",
      "epoch:43 step:34037 [D loss: 0.258611, acc: 93.75%] [G loss: 5.719067]\n",
      "epoch:43 step:34038 [D loss: 0.499603, acc: 68.75%] [G loss: 6.901992]\n",
      "epoch:43 step:34039 [D loss: 0.512261, acc: 75.00%] [G loss: 5.387921]\n",
      "epoch:43 step:34040 [D loss: 0.152132, acc: 98.44%] [G loss: 6.566753]\n",
      "epoch:43 step:34041 [D loss: 0.292907, acc: 84.38%] [G loss: 6.673987]\n",
      "epoch:43 step:34042 [D loss: 0.492744, acc: 75.00%] [G loss: 6.252918]\n",
      "epoch:43 step:34043 [D loss: 0.975017, acc: 53.12%] [G loss: 6.234876]\n",
      "epoch:43 step:34044 [D loss: 0.113065, acc: 100.00%] [G loss: 8.057915]\n",
      "epoch:43 step:34045 [D loss: 0.050530, acc: 100.00%] [G loss: 11.355579]\n",
      "epoch:43 step:34046 [D loss: 0.205634, acc: 94.53%] [G loss: 2.843584]\n",
      "epoch:43 step:34047 [D loss: 0.397129, acc: 75.78%] [G loss: 5.245722]\n",
      "epoch:43 step:34048 [D loss: 0.199576, acc: 98.44%] [G loss: 6.607719]\n",
      "epoch:43 step:34049 [D loss: 0.108395, acc: 98.44%] [G loss: 5.318495]\n",
      "epoch:43 step:34050 [D loss: 0.393145, acc: 85.94%] [G loss: 7.560486]\n",
      "epoch:43 step:34051 [D loss: 0.154324, acc: 98.44%] [G loss: 6.180756]\n",
      "epoch:43 step:34052 [D loss: 0.290037, acc: 92.19%] [G loss: 8.558207]\n",
      "epoch:43 step:34053 [D loss: 0.010780, acc: 100.00%] [G loss: 5.373966]\n",
      "epoch:43 step:34054 [D loss: 0.163688, acc: 96.88%] [G loss: 2.931291]\n",
      "epoch:43 step:34055 [D loss: 0.053213, acc: 99.22%] [G loss: 9.228729]\n",
      "epoch:43 step:34056 [D loss: 0.092142, acc: 100.00%] [G loss: 5.022813]\n",
      "epoch:43 step:34057 [D loss: 0.106671, acc: 98.44%] [G loss: 6.649212]\n",
      "epoch:43 step:34058 [D loss: 0.165840, acc: 98.44%] [G loss: 4.889037]\n",
      "epoch:43 step:34059 [D loss: 0.497090, acc: 66.41%] [G loss: 7.128143]\n",
      "epoch:43 step:34060 [D loss: 0.963540, acc: 52.34%] [G loss: 5.705349]\n",
      "epoch:43 step:34061 [D loss: 0.234984, acc: 91.41%] [G loss: 7.836976]\n",
      "epoch:43 step:34062 [D loss: 0.045269, acc: 99.22%] [G loss: 4.684679]\n",
      "epoch:43 step:34063 [D loss: 0.686341, acc: 53.12%] [G loss: 3.760238]\n",
      "epoch:43 step:34064 [D loss: 0.512575, acc: 63.28%] [G loss: 7.226127]\n",
      "epoch:43 step:34065 [D loss: 0.343493, acc: 80.47%] [G loss: 7.234823]\n",
      "epoch:43 step:34066 [D loss: 1.797503, acc: 48.44%] [G loss: 3.302176]\n",
      "epoch:43 step:34067 [D loss: 0.098769, acc: 99.22%] [G loss: 3.623603]\n",
      "epoch:43 step:34068 [D loss: 0.261534, acc: 93.75%] [G loss: 5.282736]\n",
      "epoch:43 step:34069 [D loss: 0.677809, acc: 57.81%] [G loss: 6.125446]\n",
      "epoch:43 step:34070 [D loss: 0.460860, acc: 73.44%] [G loss: 7.887642]\n",
      "epoch:43 step:34071 [D loss: 0.173403, acc: 96.88%] [G loss: 6.656902]\n",
      "epoch:43 step:34072 [D loss: 0.172883, acc: 96.88%] [G loss: 5.579568]\n",
      "epoch:43 step:34073 [D loss: 0.063951, acc: 100.00%] [G loss: 7.543192]\n",
      "epoch:43 step:34074 [D loss: 1.007169, acc: 39.84%] [G loss: 3.321016]\n",
      "epoch:43 step:34075 [D loss: 0.171783, acc: 96.88%] [G loss: 7.322817]\n",
      "epoch:43 step:34076 [D loss: 0.302798, acc: 85.16%] [G loss: 10.736993]\n",
      "epoch:43 step:34077 [D loss: 0.477660, acc: 80.47%] [G loss: 4.985883]\n",
      "epoch:43 step:34078 [D loss: 0.060198, acc: 99.22%] [G loss: 9.805010]\n",
      "epoch:43 step:34079 [D loss: 0.132053, acc: 99.22%] [G loss: 6.110685]\n",
      "epoch:43 step:34080 [D loss: 0.486373, acc: 75.00%] [G loss: 11.187920]\n",
      "epoch:43 step:34081 [D loss: 0.565096, acc: 62.50%] [G loss: 4.774300]\n",
      "epoch:43 step:34082 [D loss: 0.823982, acc: 49.22%] [G loss: 7.176112]\n",
      "epoch:43 step:34083 [D loss: 0.354090, acc: 82.81%] [G loss: 8.393721]\n",
      "epoch:43 step:34084 [D loss: 0.209120, acc: 95.31%] [G loss: 3.492032]\n",
      "epoch:43 step:34085 [D loss: 0.113964, acc: 99.22%] [G loss: 4.686066]\n",
      "epoch:43 step:34086 [D loss: 0.027948, acc: 100.00%] [G loss: 4.283190]\n",
      "epoch:43 step:34087 [D loss: 0.495244, acc: 77.34%] [G loss: 5.760194]\n",
      "epoch:43 step:34088 [D loss: 0.134361, acc: 98.44%] [G loss: 6.833402]\n",
      "epoch:43 step:34089 [D loss: 0.517969, acc: 74.22%] [G loss: 5.747108]\n",
      "epoch:43 step:34090 [D loss: 0.155514, acc: 98.44%] [G loss: 6.731845]\n",
      "epoch:43 step:34091 [D loss: 0.110873, acc: 100.00%] [G loss: 4.269154]\n",
      "epoch:43 step:34092 [D loss: 0.493010, acc: 75.78%] [G loss: 4.018607]\n",
      "epoch:43 step:34093 [D loss: 0.050715, acc: 100.00%] [G loss: 4.881320]\n",
      "epoch:43 step:34094 [D loss: 0.023058, acc: 100.00%] [G loss: 7.729046]\n",
      "epoch:43 step:34095 [D loss: 0.294753, acc: 92.19%] [G loss: 6.759482]\n",
      "epoch:43 step:34096 [D loss: 0.355707, acc: 79.69%] [G loss: 6.036870]\n",
      "epoch:43 step:34097 [D loss: 0.206065, acc: 96.09%] [G loss: 4.653545]\n",
      "epoch:43 step:34098 [D loss: 0.313653, acc: 88.28%] [G loss: 8.429785]\n",
      "epoch:43 step:34099 [D loss: 0.591857, acc: 60.94%] [G loss: 5.232247]\n",
      "epoch:43 step:34100 [D loss: 0.411292, acc: 76.56%] [G loss: 9.894735]\n",
      "epoch:43 step:34101 [D loss: 0.039241, acc: 100.00%] [G loss: 6.105281]\n",
      "epoch:43 step:34102 [D loss: 1.098205, acc: 42.19%] [G loss: 5.585787]\n",
      "epoch:43 step:34103 [D loss: 0.925084, acc: 52.34%] [G loss: 11.173262]\n",
      "epoch:43 step:34104 [D loss: 0.809339, acc: 53.12%] [G loss: 10.486715]\n",
      "epoch:43 step:34105 [D loss: 0.010394, acc: 100.00%] [G loss: 10.680716]\n",
      "epoch:43 step:34106 [D loss: 0.901068, acc: 48.44%] [G loss: 5.358987]\n",
      "epoch:43 step:34107 [D loss: 0.597391, acc: 62.50%] [G loss: 7.149090]\n",
      "epoch:43 step:34108 [D loss: 0.130990, acc: 99.22%] [G loss: 4.756623]\n",
      "epoch:43 step:34109 [D loss: 0.595049, acc: 61.72%] [G loss: 9.466744]\n",
      "epoch:43 step:34110 [D loss: 0.039794, acc: 100.00%] [G loss: 4.093693]\n",
      "epoch:43 step:34111 [D loss: 0.301907, acc: 92.19%] [G loss: 5.267446]\n",
      "epoch:43 step:34112 [D loss: 0.375403, acc: 78.91%] [G loss: 6.574851]\n",
      "epoch:43 step:34113 [D loss: 0.134567, acc: 96.88%] [G loss: 5.739874]\n",
      "epoch:43 step:34114 [D loss: 0.087017, acc: 100.00%] [G loss: 4.009125]\n",
      "epoch:43 step:34115 [D loss: 0.233532, acc: 95.31%] [G loss: 5.107146]\n",
      "epoch:43 step:34116 [D loss: 0.479888, acc: 72.66%] [G loss: 3.963665]\n",
      "epoch:43 step:34117 [D loss: 0.154332, acc: 98.44%] [G loss: 3.670865]\n",
      "epoch:43 step:34118 [D loss: 0.212344, acc: 98.44%] [G loss: 8.560899]\n",
      "epoch:43 step:34119 [D loss: 0.047921, acc: 100.00%] [G loss: 5.438968]\n",
      "epoch:43 step:34120 [D loss: 0.022474, acc: 100.00%] [G loss: 4.970591]\n",
      "epoch:43 step:34121 [D loss: 0.106482, acc: 100.00%] [G loss: 5.203912]\n",
      "epoch:43 step:34122 [D loss: 0.360424, acc: 88.28%] [G loss: 4.569149]\n",
      "epoch:43 step:34123 [D loss: 0.425144, acc: 86.72%] [G loss: 3.065569]\n",
      "epoch:43 step:34124 [D loss: 0.042241, acc: 100.00%] [G loss: 3.712662]\n",
      "epoch:43 step:34125 [D loss: 0.130525, acc: 99.22%] [G loss: 3.650330]\n",
      "epoch:43 step:34126 [D loss: 0.147793, acc: 100.00%] [G loss: 3.449573]\n",
      "epoch:43 step:34127 [D loss: 0.294897, acc: 86.72%] [G loss: 4.954749]\n",
      "epoch:43 step:34128 [D loss: 0.235346, acc: 98.44%] [G loss: 6.446648]\n",
      "epoch:43 step:34129 [D loss: 0.233021, acc: 96.09%] [G loss: 2.227316]\n",
      "epoch:43 step:34130 [D loss: 0.280369, acc: 94.53%] [G loss: 3.218977]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:34131 [D loss: 0.623534, acc: 68.75%] [G loss: 6.539535]\n",
      "epoch:43 step:34132 [D loss: 0.095591, acc: 100.00%] [G loss: 8.369794]\n",
      "epoch:43 step:34133 [D loss: 0.458319, acc: 71.88%] [G loss: 8.639799]\n",
      "epoch:43 step:34134 [D loss: 0.412745, acc: 76.56%] [G loss: 3.109369]\n",
      "epoch:43 step:34135 [D loss: 0.792051, acc: 53.91%] [G loss: 4.845333]\n",
      "epoch:43 step:34136 [D loss: 0.149105, acc: 96.88%] [G loss: 2.432419]\n",
      "epoch:43 step:34137 [D loss: 1.019909, acc: 30.47%] [G loss: 7.625744]\n",
      "epoch:43 step:34138 [D loss: 0.247038, acc: 90.62%] [G loss: 8.742542]\n",
      "epoch:43 step:34139 [D loss: 0.115532, acc: 99.22%] [G loss: 5.373415]\n",
      "epoch:43 step:34140 [D loss: 0.863332, acc: 46.09%] [G loss: 4.974616]\n",
      "epoch:43 step:34141 [D loss: 0.149389, acc: 97.66%] [G loss: 5.488039]\n",
      "epoch:43 step:34142 [D loss: 0.062554, acc: 100.00%] [G loss: 4.201457]\n",
      "epoch:43 step:34143 [D loss: 0.024624, acc: 100.00%] [G loss: 8.484337]\n",
      "epoch:43 step:34144 [D loss: 0.206162, acc: 98.44%] [G loss: 4.937559]\n",
      "epoch:43 step:34145 [D loss: 0.212600, acc: 96.88%] [G loss: 6.244541]\n",
      "epoch:43 step:34146 [D loss: 0.298199, acc: 89.06%] [G loss: 4.341620]\n",
      "epoch:43 step:34147 [D loss: 0.409829, acc: 68.75%] [G loss: 5.607233]\n",
      "epoch:43 step:34148 [D loss: 0.270879, acc: 89.84%] [G loss: 7.102339]\n",
      "epoch:43 step:34149 [D loss: 0.084627, acc: 100.00%] [G loss: 9.199101]\n",
      "epoch:43 step:34150 [D loss: 0.160628, acc: 96.88%] [G loss: 6.508437]\n",
      "epoch:43 step:34151 [D loss: 0.187562, acc: 98.44%] [G loss: 5.630607]\n",
      "epoch:43 step:34152 [D loss: 0.103139, acc: 100.00%] [G loss: 5.662663]\n",
      "epoch:43 step:34153 [D loss: 0.081786, acc: 100.00%] [G loss: 5.197886]\n",
      "epoch:43 step:34154 [D loss: 0.112119, acc: 100.00%] [G loss: 3.285344]\n",
      "epoch:43 step:34155 [D loss: 0.135700, acc: 99.22%] [G loss: 4.311309]\n",
      "epoch:43 step:34156 [D loss: 0.268665, acc: 93.75%] [G loss: 4.500998]\n",
      "epoch:43 step:34157 [D loss: 0.185755, acc: 97.66%] [G loss: 4.916522]\n",
      "epoch:43 step:34158 [D loss: 0.206763, acc: 94.53%] [G loss: 7.602429]\n",
      "epoch:43 step:34159 [D loss: 0.119330, acc: 100.00%] [G loss: 6.067648]\n",
      "epoch:43 step:34160 [D loss: 0.537484, acc: 73.44%] [G loss: 7.719701]\n",
      "epoch:43 step:34161 [D loss: 0.054290, acc: 100.00%] [G loss: 6.222990]\n",
      "epoch:43 step:34162 [D loss: 0.109918, acc: 99.22%] [G loss: 5.534069]\n",
      "epoch:43 step:34163 [D loss: 1.348972, acc: 14.06%] [G loss: 8.608604]\n",
      "epoch:43 step:34164 [D loss: 0.022058, acc: 100.00%] [G loss: 5.468115]\n",
      "epoch:43 step:34165 [D loss: 0.274382, acc: 85.16%] [G loss: 5.299694]\n",
      "epoch:43 step:34166 [D loss: 0.472483, acc: 83.59%] [G loss: 5.115600]\n",
      "epoch:43 step:34167 [D loss: 0.215050, acc: 96.09%] [G loss: 5.672168]\n",
      "epoch:43 step:34168 [D loss: 0.034128, acc: 100.00%] [G loss: 4.122333]\n",
      "epoch:43 step:34169 [D loss: 0.126338, acc: 99.22%] [G loss: 6.574941]\n",
      "epoch:43 step:34170 [D loss: 0.793805, acc: 56.25%] [G loss: 6.680398]\n",
      "epoch:43 step:34171 [D loss: 0.242169, acc: 94.53%] [G loss: 3.434447]\n",
      "epoch:43 step:34172 [D loss: 0.236258, acc: 94.53%] [G loss: 5.484171]\n",
      "epoch:43 step:34173 [D loss: 0.894054, acc: 50.78%] [G loss: 8.311010]\n",
      "epoch:43 step:34174 [D loss: 0.374590, acc: 83.59%] [G loss: 5.935679]\n",
      "epoch:43 step:34175 [D loss: 0.703177, acc: 54.69%] [G loss: 4.950685]\n",
      "epoch:43 step:34176 [D loss: 0.085671, acc: 100.00%] [G loss: 5.482399]\n",
      "epoch:43 step:34177 [D loss: 0.398046, acc: 79.69%] [G loss: 7.707328]\n",
      "epoch:43 step:34178 [D loss: 1.099778, acc: 40.62%] [G loss: 6.342804]\n",
      "epoch:43 step:34179 [D loss: 0.746821, acc: 55.47%] [G loss: 4.116229]\n",
      "epoch:43 step:34180 [D loss: 0.151414, acc: 97.66%] [G loss: 7.061661]\n",
      "epoch:43 step:34181 [D loss: 0.371797, acc: 80.47%] [G loss: 4.834268]\n",
      "epoch:43 step:34182 [D loss: 0.184790, acc: 97.66%] [G loss: 6.213733]\n",
      "epoch:43 step:34183 [D loss: 0.672484, acc: 57.81%] [G loss: 8.582139]\n",
      "epoch:43 step:34184 [D loss: 0.109040, acc: 99.22%] [G loss: 7.446169]\n",
      "epoch:43 step:34185 [D loss: 0.411821, acc: 86.72%] [G loss: 4.883657]\n",
      "epoch:43 step:34186 [D loss: 0.141307, acc: 98.44%] [G loss: 6.582567]\n",
      "epoch:43 step:34187 [D loss: 0.752614, acc: 50.78%] [G loss: 6.509171]\n",
      "epoch:43 step:34188 [D loss: 0.905134, acc: 53.12%] [G loss: 5.204351]\n",
      "epoch:43 step:34189 [D loss: 0.420956, acc: 83.59%] [G loss: 3.833562]\n",
      "epoch:43 step:34190 [D loss: 0.261056, acc: 89.84%] [G loss: 4.271115]\n",
      "epoch:43 step:34191 [D loss: 0.229247, acc: 97.66%] [G loss: 4.857601]\n",
      "epoch:43 step:34192 [D loss: 0.230732, acc: 96.09%] [G loss: 4.636591]\n",
      "epoch:43 step:34193 [D loss: 0.364756, acc: 81.25%] [G loss: 5.117107]\n",
      "epoch:43 step:34194 [D loss: 0.064524, acc: 100.00%] [G loss: 6.762813]\n",
      "epoch:43 step:34195 [D loss: 0.150875, acc: 98.44%] [G loss: 6.424685]\n",
      "epoch:43 step:34196 [D loss: 0.600776, acc: 61.72%] [G loss: 3.768258]\n",
      "epoch:43 step:34197 [D loss: 0.195870, acc: 97.66%] [G loss: 6.304064]\n",
      "epoch:43 step:34198 [D loss: 0.403954, acc: 74.22%] [G loss: 10.647204]\n",
      "epoch:43 step:34199 [D loss: 0.144258, acc: 98.44%] [G loss: 5.470247]\n",
      "epoch:43 step:34200 [D loss: 0.109132, acc: 99.22%] [G loss: 4.396562]\n",
      "epoch:43 step:34201 [D loss: 0.381075, acc: 78.12%] [G loss: 4.695485]\n",
      "epoch:43 step:34202 [D loss: 0.141076, acc: 99.22%] [G loss: 6.678566]\n",
      "epoch:43 step:34203 [D loss: 0.237309, acc: 92.19%] [G loss: 6.084064]\n",
      "epoch:43 step:34204 [D loss: 0.194740, acc: 97.66%] [G loss: 5.936690]\n",
      "epoch:43 step:34205 [D loss: 0.174309, acc: 94.53%] [G loss: 6.279296]\n",
      "epoch:43 step:34206 [D loss: 0.552124, acc: 78.91%] [G loss: 5.131026]\n",
      "epoch:43 step:34207 [D loss: 0.181894, acc: 97.66%] [G loss: 4.655348]\n",
      "epoch:43 step:34208 [D loss: 0.250903, acc: 90.62%] [G loss: 6.594702]\n",
      "epoch:43 step:34209 [D loss: 0.320408, acc: 86.72%] [G loss: 6.857330]\n",
      "epoch:43 step:34210 [D loss: 1.160054, acc: 31.25%] [G loss: 4.443271]\n",
      "epoch:43 step:34211 [D loss: 0.016733, acc: 100.00%] [G loss: 7.547983]\n",
      "epoch:43 step:34212 [D loss: 0.213404, acc: 95.31%] [G loss: 5.948722]\n",
      "epoch:43 step:34213 [D loss: 0.373251, acc: 86.72%] [G loss: 7.409156]\n",
      "epoch:43 step:34214 [D loss: 0.175675, acc: 99.22%] [G loss: 6.042028]\n",
      "epoch:43 step:34215 [D loss: 0.548135, acc: 66.41%] [G loss: 10.040892]\n",
      "epoch:43 step:34216 [D loss: 0.294464, acc: 93.75%] [G loss: 2.738054]\n",
      "epoch:43 step:34217 [D loss: 0.469290, acc: 65.62%] [G loss: 8.176366]\n",
      "epoch:43 step:34218 [D loss: 0.113327, acc: 100.00%] [G loss: 6.122840]\n",
      "epoch:43 step:34219 [D loss: 0.149235, acc: 98.44%] [G loss: 7.317917]\n",
      "epoch:43 step:34220 [D loss: 0.279837, acc: 92.97%] [G loss: 3.382941]\n",
      "epoch:43 step:34221 [D loss: 0.332718, acc: 90.62%] [G loss: 4.592589]\n",
      "epoch:43 step:34222 [D loss: 0.961136, acc: 42.19%] [G loss: 7.622996]\n",
      "epoch:43 step:34223 [D loss: 0.464392, acc: 66.41%] [G loss: 7.800893]\n",
      "epoch:43 step:34224 [D loss: 0.062970, acc: 99.22%] [G loss: 2.843509]\n",
      "epoch:43 step:34225 [D loss: 0.584473, acc: 60.94%] [G loss: 7.234560]\n",
      "epoch:43 step:34226 [D loss: 1.141522, acc: 47.66%] [G loss: 6.407043]\n",
      "epoch:43 step:34227 [D loss: 0.062537, acc: 100.00%] [G loss: 4.024360]\n",
      "epoch:43 step:34228 [D loss: 0.142990, acc: 98.44%] [G loss: 7.432037]\n",
      "epoch:43 step:34229 [D loss: 0.555105, acc: 64.06%] [G loss: 7.827884]\n",
      "epoch:43 step:34230 [D loss: 0.508087, acc: 65.62%] [G loss: 8.128214]\n",
      "epoch:43 step:34231 [D loss: 0.338560, acc: 84.38%] [G loss: 5.894652]\n",
      "epoch:43 step:34232 [D loss: 1.157613, acc: 50.00%] [G loss: 3.796103]\n",
      "epoch:43 step:34233 [D loss: 0.108062, acc: 100.00%] [G loss: 10.267979]\n",
      "epoch:43 step:34234 [D loss: 0.467271, acc: 78.91%] [G loss: 6.877892]\n",
      "epoch:43 step:34235 [D loss: 0.127046, acc: 99.22%] [G loss: 4.934425]\n",
      "epoch:43 step:34236 [D loss: 0.141015, acc: 96.88%] [G loss: 5.062861]\n",
      "epoch:43 step:34237 [D loss: 0.091633, acc: 100.00%] [G loss: 6.881875]\n",
      "epoch:43 step:34238 [D loss: 0.866702, acc: 43.75%] [G loss: 7.693835]\n",
      "epoch:43 step:34239 [D loss: 0.225179, acc: 95.31%] [G loss: 3.863904]\n",
      "epoch:43 step:34240 [D loss: 0.083472, acc: 100.00%] [G loss: 5.819533]\n",
      "epoch:43 step:34241 [D loss: 0.264993, acc: 92.97%] [G loss: 4.455419]\n",
      "epoch:43 step:34242 [D loss: 0.384981, acc: 80.47%] [G loss: 3.561493]\n",
      "epoch:43 step:34243 [D loss: 0.118996, acc: 98.44%] [G loss: 6.623163]\n",
      "epoch:43 step:34244 [D loss: 0.429419, acc: 71.88%] [G loss: 5.834136]\n",
      "epoch:43 step:34245 [D loss: 0.203523, acc: 89.84%] [G loss: 8.735107]\n",
      "epoch:43 step:34246 [D loss: 0.451847, acc: 79.69%] [G loss: 4.854797]\n",
      "epoch:43 step:34247 [D loss: 0.726493, acc: 59.38%] [G loss: 5.168366]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:34248 [D loss: 0.338488, acc: 83.59%] [G loss: 4.678392]\n",
      "epoch:43 step:34249 [D loss: 0.551311, acc: 60.16%] [G loss: 5.561444]\n",
      "epoch:43 step:34250 [D loss: 0.026140, acc: 100.00%] [G loss: 8.960414]\n",
      "epoch:43 step:34251 [D loss: 0.774562, acc: 55.47%] [G loss: 3.511743]\n",
      "epoch:43 step:34252 [D loss: 0.215355, acc: 98.44%] [G loss: 6.291624]\n",
      "epoch:43 step:34253 [D loss: 0.185574, acc: 96.88%] [G loss: 5.790586]\n",
      "epoch:43 step:34254 [D loss: 0.048007, acc: 100.00%] [G loss: 6.523018]\n",
      "epoch:43 step:34255 [D loss: 0.366289, acc: 77.34%] [G loss: 8.570064]\n",
      "epoch:43 step:34256 [D loss: 0.076513, acc: 100.00%] [G loss: 7.915774]\n",
      "epoch:43 step:34257 [D loss: 0.139306, acc: 99.22%] [G loss: 5.330760]\n",
      "epoch:43 step:34258 [D loss: 0.237882, acc: 96.88%] [G loss: 7.602757]\n",
      "epoch:43 step:34259 [D loss: 0.012517, acc: 100.00%] [G loss: 5.428734]\n",
      "epoch:43 step:34260 [D loss: 0.056534, acc: 100.00%] [G loss: 7.192479]\n",
      "epoch:43 step:34261 [D loss: 0.238495, acc: 94.53%] [G loss: 3.467478]\n",
      "epoch:43 step:34262 [D loss: 0.351947, acc: 89.06%] [G loss: 6.334589]\n",
      "epoch:43 step:34263 [D loss: 0.444975, acc: 81.25%] [G loss: 3.324733]\n",
      "epoch:43 step:34264 [D loss: 0.064295, acc: 99.22%] [G loss: 4.218524]\n",
      "epoch:43 step:34265 [D loss: 0.366219, acc: 87.50%] [G loss: 5.299669]\n",
      "epoch:43 step:34266 [D loss: 0.672709, acc: 65.62%] [G loss: 6.698501]\n",
      "epoch:43 step:34267 [D loss: 0.443086, acc: 78.12%] [G loss: 7.079382]\n",
      "epoch:43 step:34268 [D loss: 0.346525, acc: 91.41%] [G loss: 4.451115]\n",
      "epoch:43 step:34269 [D loss: 0.285501, acc: 89.84%] [G loss: 3.079857]\n",
      "epoch:43 step:34270 [D loss: 0.052458, acc: 100.00%] [G loss: 5.632581]\n",
      "epoch:43 step:34271 [D loss: 0.185286, acc: 96.09%] [G loss: 8.246233]\n",
      "epoch:43 step:34272 [D loss: 0.093887, acc: 100.00%] [G loss: 4.626504]\n",
      "epoch:43 step:34273 [D loss: 0.528119, acc: 63.28%] [G loss: 6.028766]\n",
      "epoch:43 step:34274 [D loss: 0.142381, acc: 98.44%] [G loss: 6.879649]\n",
      "epoch:43 step:34275 [D loss: 0.338143, acc: 80.47%] [G loss: 5.428108]\n",
      "epoch:43 step:34276 [D loss: 0.332070, acc: 88.28%] [G loss: 7.680841]\n",
      "epoch:43 step:34277 [D loss: 0.189175, acc: 97.66%] [G loss: 4.087960]\n",
      "epoch:43 step:34278 [D loss: 0.039420, acc: 100.00%] [G loss: 4.424397]\n",
      "epoch:43 step:34279 [D loss: 0.060096, acc: 100.00%] [G loss: 6.833126]\n",
      "epoch:43 step:34280 [D loss: 0.086169, acc: 100.00%] [G loss: 3.886648]\n",
      "epoch:43 step:34281 [D loss: 0.447906, acc: 73.44%] [G loss: 5.036511]\n",
      "epoch:43 step:34282 [D loss: 0.331828, acc: 86.72%] [G loss: 3.854805]\n",
      "epoch:43 step:34283 [D loss: 0.259166, acc: 94.53%] [G loss: 6.239393]\n",
      "epoch:43 step:34284 [D loss: 0.297636, acc: 92.97%] [G loss: 7.613473]\n",
      "epoch:43 step:34285 [D loss: 0.377019, acc: 81.25%] [G loss: 5.261478]\n",
      "epoch:43 step:34286 [D loss: 0.174220, acc: 97.66%] [G loss: 7.556330]\n",
      "epoch:43 step:34287 [D loss: 0.101767, acc: 100.00%] [G loss: 6.426047]\n",
      "epoch:43 step:34288 [D loss: 0.631914, acc: 65.62%] [G loss: 4.514874]\n",
      "epoch:43 step:34289 [D loss: 0.116426, acc: 99.22%] [G loss: 3.215443]\n",
      "epoch:43 step:34290 [D loss: 0.130574, acc: 100.00%] [G loss: 6.341736]\n",
      "epoch:43 step:34291 [D loss: 0.122214, acc: 98.44%] [G loss: 6.695711]\n",
      "epoch:43 step:34292 [D loss: 1.169377, acc: 46.88%] [G loss: 8.567609]\n",
      "epoch:43 step:34293 [D loss: 0.700083, acc: 58.59%] [G loss: 5.413643]\n",
      "epoch:43 step:34294 [D loss: 0.209697, acc: 96.88%] [G loss: 4.790925]\n",
      "epoch:43 step:34295 [D loss: 0.234743, acc: 96.09%] [G loss: 5.399282]\n",
      "epoch:43 step:34296 [D loss: 0.048006, acc: 100.00%] [G loss: 9.092477]\n",
      "epoch:43 step:34297 [D loss: 0.055231, acc: 99.22%] [G loss: 4.494601]\n",
      "epoch:43 step:34298 [D loss: 0.085664, acc: 99.22%] [G loss: 6.991347]\n",
      "epoch:43 step:34299 [D loss: 0.212212, acc: 98.44%] [G loss: 6.905698]\n",
      "epoch:43 step:34300 [D loss: 0.212025, acc: 96.09%] [G loss: 5.506734]\n",
      "epoch:43 step:34301 [D loss: 0.178550, acc: 97.66%] [G loss: 2.979166]\n",
      "epoch:43 step:34302 [D loss: 0.198167, acc: 96.88%] [G loss: 8.062098]\n",
      "epoch:43 step:34303 [D loss: 0.176550, acc: 98.44%] [G loss: 6.056254]\n",
      "epoch:43 step:34304 [D loss: 0.086320, acc: 99.22%] [G loss: 7.213554]\n",
      "epoch:43 step:34305 [D loss: 0.205070, acc: 96.88%] [G loss: 7.679964]\n",
      "epoch:43 step:34306 [D loss: 0.058242, acc: 99.22%] [G loss: 6.370358]\n",
      "epoch:43 step:34307 [D loss: 0.672784, acc: 60.16%] [G loss: 6.678600]\n",
      "epoch:43 step:34308 [D loss: 0.113744, acc: 100.00%] [G loss: 3.571281]\n",
      "epoch:43 step:34309 [D loss: 0.007626, acc: 100.00%] [G loss: 10.905220]\n",
      "epoch:43 step:34310 [D loss: 1.389757, acc: 50.00%] [G loss: 9.082272]\n",
      "epoch:43 step:34311 [D loss: 0.220105, acc: 95.31%] [G loss: 4.040124]\n",
      "epoch:43 step:34312 [D loss: 0.086956, acc: 100.00%] [G loss: 9.108894]\n",
      "epoch:43 step:34313 [D loss: 0.103071, acc: 100.00%] [G loss: 6.654346]\n",
      "epoch:43 step:34314 [D loss: 0.580738, acc: 67.97%] [G loss: 6.641228]\n",
      "epoch:43 step:34315 [D loss: 0.328438, acc: 84.38%] [G loss: 8.546963]\n",
      "epoch:43 step:34316 [D loss: 0.273699, acc: 96.09%] [G loss: 5.703278]\n",
      "epoch:43 step:34317 [D loss: 0.137519, acc: 98.44%] [G loss: 4.852774]\n",
      "epoch:43 step:34318 [D loss: 0.585699, acc: 57.81%] [G loss: 7.622994]\n",
      "epoch:43 step:34319 [D loss: 0.381553, acc: 88.28%] [G loss: 4.900768]\n",
      "epoch:43 step:34320 [D loss: 0.073555, acc: 100.00%] [G loss: 8.174875]\n",
      "epoch:43 step:34321 [D loss: 1.166848, acc: 50.78%] [G loss: 7.563557]\n",
      "epoch:43 step:34322 [D loss: 0.308054, acc: 82.03%] [G loss: 8.655635]\n",
      "epoch:43 step:34323 [D loss: 0.385116, acc: 83.59%] [G loss: 3.788136]\n",
      "epoch:43 step:34324 [D loss: 0.034221, acc: 100.00%] [G loss: 8.593557]\n",
      "epoch:43 step:34325 [D loss: 0.488446, acc: 67.19%] [G loss: 6.153980]\n",
      "epoch:43 step:34326 [D loss: 0.173478, acc: 96.88%] [G loss: 3.200116]\n",
      "epoch:43 step:34327 [D loss: 0.230925, acc: 92.97%] [G loss: 7.647601]\n",
      "epoch:43 step:34328 [D loss: 0.627775, acc: 64.06%] [G loss: 5.319263]\n",
      "epoch:43 step:34329 [D loss: 0.018799, acc: 100.00%] [G loss: 7.711688]\n",
      "epoch:43 step:34330 [D loss: 0.182334, acc: 98.44%] [G loss: 5.101900]\n",
      "epoch:43 step:34331 [D loss: 0.117870, acc: 98.44%] [G loss: 2.651459]\n",
      "epoch:43 step:34332 [D loss: 0.241466, acc: 92.97%] [G loss: 7.945342]\n",
      "epoch:43 step:34333 [D loss: 0.196045, acc: 93.75%] [G loss: 6.110273]\n",
      "epoch:43 step:34334 [D loss: 0.563642, acc: 67.19%] [G loss: 6.448822]\n",
      "epoch:43 step:34335 [D loss: 1.071779, acc: 49.22%] [G loss: 3.488834]\n",
      "epoch:43 step:34336 [D loss: 0.078221, acc: 100.00%] [G loss: 4.027722]\n",
      "epoch:43 step:34337 [D loss: 0.163700, acc: 97.66%] [G loss: 6.379910]\n",
      "epoch:43 step:34338 [D loss: 0.133743, acc: 97.66%] [G loss: 6.514935]\n",
      "epoch:43 step:34339 [D loss: 0.272192, acc: 95.31%] [G loss: 6.621537]\n",
      "epoch:43 step:34340 [D loss: 0.015507, acc: 100.00%] [G loss: 6.600569]\n",
      "epoch:43 step:34341 [D loss: 0.238760, acc: 94.53%] [G loss: 2.846853]\n",
      "epoch:43 step:34342 [D loss: 0.046140, acc: 100.00%] [G loss: 6.364034]\n",
      "epoch:43 step:34343 [D loss: 0.190386, acc: 94.53%] [G loss: 9.590541]\n",
      "epoch:43 step:34344 [D loss: 0.252707, acc: 91.41%] [G loss: 5.682167]\n",
      "epoch:43 step:34345 [D loss: 0.087634, acc: 98.44%] [G loss: 4.339742]\n",
      "epoch:43 step:34346 [D loss: 0.288782, acc: 92.19%] [G loss: 7.412662]\n",
      "epoch:43 step:34347 [D loss: 0.144509, acc: 98.44%] [G loss: 3.938807]\n",
      "epoch:43 step:34348 [D loss: 0.278195, acc: 91.41%] [G loss: 7.614058]\n",
      "epoch:43 step:34349 [D loss: 0.102127, acc: 100.00%] [G loss: 5.030262]\n",
      "epoch:43 step:34350 [D loss: 0.533715, acc: 72.66%] [G loss: 7.882936]\n",
      "epoch:43 step:34351 [D loss: 0.078667, acc: 99.22%] [G loss: 7.164406]\n",
      "epoch:43 step:34352 [D loss: 0.261569, acc: 90.62%] [G loss: 2.270246]\n",
      "epoch:43 step:34353 [D loss: 0.534891, acc: 75.78%] [G loss: 5.835772]\n",
      "epoch:43 step:34354 [D loss: 0.459567, acc: 79.69%] [G loss: 3.418550]\n",
      "epoch:43 step:34355 [D loss: 0.247265, acc: 92.19%] [G loss: 6.970099]\n",
      "epoch:43 step:34356 [D loss: 0.608381, acc: 57.81%] [G loss: 10.259001]\n",
      "epoch:43 step:34357 [D loss: 0.035313, acc: 100.00%] [G loss: 5.813745]\n",
      "epoch:43 step:34358 [D loss: 0.496586, acc: 68.75%] [G loss: 5.855094]\n",
      "epoch:43 step:34359 [D loss: 0.286370, acc: 91.41%] [G loss: 7.121259]\n",
      "epoch:43 step:34360 [D loss: 0.650751, acc: 57.81%] [G loss: 4.908379]\n",
      "epoch:43 step:34361 [D loss: 0.158621, acc: 97.66%] [G loss: 2.133941]\n",
      "epoch:43 step:34362 [D loss: 0.496355, acc: 67.19%] [G loss: 7.108894]\n",
      "epoch:43 step:34363 [D loss: 0.082161, acc: 100.00%] [G loss: 5.610232]\n",
      "epoch:43 step:34364 [D loss: 1.082810, acc: 51.56%] [G loss: 3.696989]\n",
      "epoch:44 step:34365 [D loss: 0.861887, acc: 43.75%] [G loss: 6.292531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34366 [D loss: 0.054064, acc: 100.00%] [G loss: 7.675330]\n",
      "epoch:44 step:34367 [D loss: 0.181698, acc: 93.75%] [G loss: 6.013361]\n",
      "epoch:44 step:34368 [D loss: 0.145628, acc: 97.66%] [G loss: 7.446546]\n",
      "epoch:44 step:34369 [D loss: 0.021551, acc: 100.00%] [G loss: 4.851943]\n",
      "epoch:44 step:34370 [D loss: 0.042775, acc: 100.00%] [G loss: 3.740208]\n",
      "epoch:44 step:34371 [D loss: 0.216537, acc: 95.31%] [G loss: 6.259428]\n",
      "epoch:44 step:34372 [D loss: 0.491976, acc: 71.88%] [G loss: 6.944333]\n",
      "epoch:44 step:34373 [D loss: 0.271573, acc: 90.62%] [G loss: 6.743091]\n",
      "epoch:44 step:34374 [D loss: 0.038155, acc: 100.00%] [G loss: 7.231176]\n",
      "epoch:44 step:34375 [D loss: 0.305275, acc: 89.84%] [G loss: 6.931500]\n",
      "epoch:44 step:34376 [D loss: 0.215477, acc: 92.97%] [G loss: 6.638780]\n",
      "epoch:44 step:34377 [D loss: 0.626835, acc: 64.84%] [G loss: 6.159463]\n",
      "epoch:44 step:34378 [D loss: 0.110914, acc: 100.00%] [G loss: 2.244467]\n",
      "epoch:44 step:34379 [D loss: 0.309187, acc: 88.28%] [G loss: 5.314993]\n",
      "epoch:44 step:34380 [D loss: 1.915607, acc: 49.22%] [G loss: 9.629799]\n",
      "epoch:44 step:34381 [D loss: 0.123752, acc: 99.22%] [G loss: 7.417564]\n",
      "epoch:44 step:34382 [D loss: 0.361125, acc: 79.69%] [G loss: 6.263219]\n",
      "epoch:44 step:34383 [D loss: 0.358980, acc: 89.06%] [G loss: 3.531375]\n",
      "epoch:44 step:34384 [D loss: 0.060618, acc: 100.00%] [G loss: 4.708344]\n",
      "epoch:44 step:34385 [D loss: 0.530829, acc: 69.53%] [G loss: 8.076255]\n",
      "epoch:44 step:34386 [D loss: 0.685592, acc: 54.69%] [G loss: 4.644589]\n",
      "epoch:44 step:34387 [D loss: 0.034073, acc: 100.00%] [G loss: 3.038441]\n",
      "epoch:44 step:34388 [D loss: 0.153521, acc: 100.00%] [G loss: 6.808682]\n",
      "epoch:44 step:34389 [D loss: 0.639750, acc: 62.50%] [G loss: 3.579149]\n",
      "epoch:44 step:34390 [D loss: 0.401503, acc: 75.78%] [G loss: 7.581062]\n",
      "epoch:44 step:34391 [D loss: 0.388243, acc: 77.34%] [G loss: 5.583191]\n",
      "epoch:44 step:34392 [D loss: 0.382611, acc: 85.94%] [G loss: 4.082153]\n",
      "epoch:44 step:34393 [D loss: 0.292206, acc: 92.97%] [G loss: 7.158406]\n",
      "epoch:44 step:34394 [D loss: 0.183200, acc: 96.09%] [G loss: 9.488219]\n",
      "epoch:44 step:34395 [D loss: 0.219919, acc: 95.31%] [G loss: 6.650610]\n",
      "epoch:44 step:34396 [D loss: 0.119062, acc: 99.22%] [G loss: 6.378910]\n",
      "epoch:44 step:34397 [D loss: 0.521145, acc: 63.28%] [G loss: 5.390386]\n",
      "epoch:44 step:34398 [D loss: 0.096347, acc: 99.22%] [G loss: 5.408731]\n",
      "epoch:44 step:34399 [D loss: 0.314729, acc: 84.38%] [G loss: 7.722281]\n",
      "epoch:44 step:34400 [D loss: 0.038580, acc: 100.00%] [G loss: 5.267598]\n",
      "epoch:44 step:34401 [D loss: 0.056199, acc: 100.00%] [G loss: 4.966309]\n",
      "epoch:44 step:34402 [D loss: 0.272973, acc: 86.72%] [G loss: 2.705553]\n",
      "epoch:44 step:34403 [D loss: 0.110474, acc: 99.22%] [G loss: 4.976990]\n",
      "epoch:44 step:34404 [D loss: 0.203068, acc: 99.22%] [G loss: 7.013573]\n",
      "epoch:44 step:34405 [D loss: 0.104029, acc: 100.00%] [G loss: 8.354156]\n",
      "epoch:44 step:34406 [D loss: 0.233422, acc: 95.31%] [G loss: 4.567738]\n",
      "epoch:44 step:34407 [D loss: 1.450309, acc: 32.81%] [G loss: 9.973594]\n",
      "epoch:44 step:34408 [D loss: 0.573807, acc: 65.62%] [G loss: 6.833239]\n",
      "epoch:44 step:34409 [D loss: 0.050702, acc: 100.00%] [G loss: 7.854890]\n",
      "epoch:44 step:34410 [D loss: 0.486857, acc: 77.34%] [G loss: 7.346619]\n",
      "epoch:44 step:34411 [D loss: 0.027292, acc: 100.00%] [G loss: 8.150884]\n",
      "epoch:44 step:34412 [D loss: 0.243429, acc: 94.53%] [G loss: 5.136284]\n",
      "epoch:44 step:34413 [D loss: 0.122073, acc: 98.44%] [G loss: 4.119265]\n",
      "epoch:44 step:34414 [D loss: 0.095341, acc: 100.00%] [G loss: 7.173909]\n",
      "epoch:44 step:34415 [D loss: 0.766423, acc: 56.25%] [G loss: 5.454760]\n",
      "epoch:44 step:34416 [D loss: 0.320543, acc: 89.84%] [G loss: 5.087466]\n",
      "epoch:44 step:34417 [D loss: 0.052567, acc: 100.00%] [G loss: 10.632008]\n",
      "epoch:44 step:34418 [D loss: 0.037594, acc: 100.00%] [G loss: 7.896338]\n",
      "epoch:44 step:34419 [D loss: 0.022951, acc: 100.00%] [G loss: 6.293275]\n",
      "epoch:44 step:34420 [D loss: 0.256197, acc: 96.09%] [G loss: 3.825842]\n",
      "epoch:44 step:34421 [D loss: 0.341276, acc: 85.94%] [G loss: 5.790838]\n",
      "epoch:44 step:34422 [D loss: 0.436587, acc: 71.09%] [G loss: 4.153522]\n",
      "epoch:44 step:34423 [D loss: 0.179274, acc: 98.44%] [G loss: 6.060349]\n",
      "epoch:44 step:34424 [D loss: 0.330343, acc: 84.38%] [G loss: 5.839860]\n",
      "epoch:44 step:34425 [D loss: 0.542953, acc: 63.28%] [G loss: 5.627737]\n",
      "epoch:44 step:34426 [D loss: 0.156121, acc: 97.66%] [G loss: 7.357810]\n",
      "epoch:44 step:34427 [D loss: 0.350295, acc: 85.16%] [G loss: 6.406553]\n",
      "epoch:44 step:34428 [D loss: 0.749498, acc: 51.56%] [G loss: 3.084849]\n",
      "epoch:44 step:34429 [D loss: 0.070723, acc: 99.22%] [G loss: 4.962973]\n",
      "epoch:44 step:34430 [D loss: 1.324841, acc: 33.59%] [G loss: 8.516109]\n",
      "epoch:44 step:34431 [D loss: 0.682304, acc: 57.03%] [G loss: 6.525732]\n",
      "epoch:44 step:34432 [D loss: 0.058707, acc: 100.00%] [G loss: 2.373594]\n",
      "epoch:44 step:34433 [D loss: 0.555029, acc: 69.53%] [G loss: 8.960732]\n",
      "epoch:44 step:34434 [D loss: 2.247063, acc: 36.72%] [G loss: 5.835495]\n",
      "epoch:44 step:34435 [D loss: 0.187763, acc: 96.09%] [G loss: 6.644825]\n",
      "epoch:44 step:34436 [D loss: 0.081810, acc: 99.22%] [G loss: 3.756599]\n",
      "epoch:44 step:34437 [D loss: 0.893307, acc: 51.56%] [G loss: 11.879131]\n",
      "epoch:44 step:34438 [D loss: 0.156407, acc: 97.66%] [G loss: 5.002524]\n",
      "epoch:44 step:34439 [D loss: 0.195417, acc: 96.88%] [G loss: 4.275597]\n",
      "epoch:44 step:34440 [D loss: 0.176107, acc: 99.22%] [G loss: 5.650240]\n",
      "epoch:44 step:34441 [D loss: 0.301009, acc: 88.28%] [G loss: 3.527884]\n",
      "epoch:44 step:34442 [D loss: 0.377101, acc: 75.00%] [G loss: 6.675906]\n",
      "epoch:44 step:34443 [D loss: 0.221502, acc: 94.53%] [G loss: 6.192099]\n",
      "epoch:44 step:34444 [D loss: 0.109257, acc: 98.44%] [G loss: 6.006233]\n",
      "epoch:44 step:34445 [D loss: 0.691356, acc: 57.03%] [G loss: 5.549919]\n",
      "epoch:44 step:34446 [D loss: 0.620945, acc: 55.47%] [G loss: 8.684576]\n",
      "epoch:44 step:34447 [D loss: 0.087269, acc: 99.22%] [G loss: 5.313371]\n",
      "epoch:44 step:34448 [D loss: 0.097174, acc: 98.44%] [G loss: 5.830819]\n",
      "epoch:44 step:34449 [D loss: 0.336340, acc: 82.81%] [G loss: 10.710464]\n",
      "epoch:44 step:34450 [D loss: 1.219447, acc: 49.22%] [G loss: 6.590148]\n",
      "epoch:44 step:34451 [D loss: 0.140369, acc: 99.22%] [G loss: 4.880596]\n",
      "epoch:44 step:34452 [D loss: 0.928068, acc: 52.34%] [G loss: 7.624412]\n",
      "epoch:44 step:34453 [D loss: 0.227904, acc: 88.28%] [G loss: 9.672827]\n",
      "epoch:44 step:34454 [D loss: 0.489486, acc: 63.28%] [G loss: 3.251570]\n",
      "epoch:44 step:34455 [D loss: 0.200945, acc: 96.09%] [G loss: 7.490697]\n",
      "epoch:44 step:34456 [D loss: 0.096805, acc: 100.00%] [G loss: 8.692202]\n",
      "epoch:44 step:34457 [D loss: 0.387672, acc: 75.78%] [G loss: 5.809106]\n",
      "epoch:44 step:34458 [D loss: 0.305979, acc: 92.97%] [G loss: 6.231655]\n",
      "epoch:44 step:34459 [D loss: 0.077917, acc: 99.22%] [G loss: 6.238951]\n",
      "epoch:44 step:34460 [D loss: 0.810908, acc: 52.34%] [G loss: 5.862938]\n",
      "epoch:44 step:34461 [D loss: 0.232672, acc: 97.66%] [G loss: 2.465806]\n",
      "epoch:44 step:34462 [D loss: 0.202866, acc: 96.09%] [G loss: 4.286009]\n",
      "epoch:44 step:34463 [D loss: 0.154904, acc: 98.44%] [G loss: 3.960834]\n",
      "epoch:44 step:34464 [D loss: 0.396132, acc: 81.25%] [G loss: 4.381084]\n",
      "epoch:44 step:34465 [D loss: 0.573843, acc: 57.81%] [G loss: 8.346452]\n",
      "epoch:44 step:34466 [D loss: 0.074687, acc: 100.00%] [G loss: 3.061711]\n",
      "epoch:44 step:34467 [D loss: 0.330817, acc: 75.78%] [G loss: 4.863177]\n",
      "epoch:44 step:34468 [D loss: 0.009274, acc: 100.00%] [G loss: 6.270592]\n",
      "epoch:44 step:34469 [D loss: 0.053629, acc: 100.00%] [G loss: 9.484872]\n",
      "epoch:44 step:34470 [D loss: 0.187290, acc: 96.09%] [G loss: 4.459600]\n",
      "epoch:44 step:34471 [D loss: 0.610264, acc: 57.81%] [G loss: 4.745825]\n",
      "epoch:44 step:34472 [D loss: 1.291444, acc: 28.91%] [G loss: 6.406525]\n",
      "epoch:44 step:34473 [D loss: 0.149577, acc: 97.66%] [G loss: 4.664992]\n",
      "epoch:44 step:34474 [D loss: 0.387456, acc: 87.50%] [G loss: 6.820895]\n",
      "epoch:44 step:34475 [D loss: 0.130465, acc: 99.22%] [G loss: 6.903335]\n",
      "epoch:44 step:34476 [D loss: 0.375020, acc: 80.47%] [G loss: 5.557413]\n",
      "epoch:44 step:34477 [D loss: 0.555483, acc: 71.09%] [G loss: 6.808465]\n",
      "epoch:44 step:34478 [D loss: 0.524773, acc: 65.62%] [G loss: 4.342010]\n",
      "epoch:44 step:34479 [D loss: 0.058274, acc: 100.00%] [G loss: 3.534748]\n",
      "epoch:44 step:34480 [D loss: 1.124041, acc: 51.56%] [G loss: 9.648499]\n",
      "epoch:44 step:34481 [D loss: 0.803842, acc: 53.91%] [G loss: 8.152568]\n",
      "epoch:44 step:34482 [D loss: 0.617342, acc: 64.06%] [G loss: 5.579547]\n",
      "epoch:44 step:34483 [D loss: 0.109454, acc: 99.22%] [G loss: 8.047791]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34484 [D loss: 2.241467, acc: 50.00%] [G loss: 11.451398]\n",
      "epoch:44 step:34485 [D loss: 0.924927, acc: 50.78%] [G loss: 7.081759]\n",
      "epoch:44 step:34486 [D loss: 0.150194, acc: 97.66%] [G loss: 6.175157]\n",
      "epoch:44 step:34487 [D loss: 0.235616, acc: 92.97%] [G loss: 8.510109]\n",
      "epoch:44 step:34488 [D loss: 0.122741, acc: 99.22%] [G loss: 6.147040]\n",
      "epoch:44 step:34489 [D loss: 0.084549, acc: 99.22%] [G loss: 6.478732]\n",
      "epoch:44 step:34490 [D loss: 0.637053, acc: 55.47%] [G loss: 5.986098]\n",
      "epoch:44 step:34491 [D loss: 0.850658, acc: 51.56%] [G loss: 12.217655]\n",
      "epoch:44 step:34492 [D loss: 0.036683, acc: 100.00%] [G loss: 5.695409]\n",
      "epoch:44 step:34493 [D loss: 0.460207, acc: 67.97%] [G loss: 6.029929]\n",
      "epoch:44 step:34494 [D loss: 0.277852, acc: 90.62%] [G loss: 5.277234]\n",
      "epoch:44 step:34495 [D loss: 0.390235, acc: 78.12%] [G loss: 5.565213]\n",
      "epoch:44 step:34496 [D loss: 0.226904, acc: 96.09%] [G loss: 8.378438]\n",
      "epoch:44 step:34497 [D loss: 0.576603, acc: 58.59%] [G loss: 5.223683]\n",
      "epoch:44 step:34498 [D loss: 0.130586, acc: 97.66%] [G loss: 5.969254]\n",
      "epoch:44 step:34499 [D loss: 0.571006, acc: 61.72%] [G loss: 7.216221]\n",
      "epoch:44 step:34500 [D loss: 0.223269, acc: 91.41%] [G loss: 5.903988]\n",
      "epoch:44 step:34501 [D loss: 0.638237, acc: 66.41%] [G loss: 8.149395]\n",
      "epoch:44 step:34502 [D loss: 0.227821, acc: 91.41%] [G loss: 5.568418]\n",
      "epoch:44 step:34503 [D loss: 0.358324, acc: 87.50%] [G loss: 5.721526]\n",
      "epoch:44 step:34504 [D loss: 1.009244, acc: 52.34%] [G loss: 4.052239]\n",
      "epoch:44 step:34505 [D loss: 0.584438, acc: 69.53%] [G loss: 7.923389]\n",
      "epoch:44 step:34506 [D loss: 0.660129, acc: 57.81%] [G loss: 3.464902]\n",
      "epoch:44 step:34507 [D loss: 0.369925, acc: 79.69%] [G loss: 7.418301]\n",
      "epoch:44 step:34508 [D loss: 0.508448, acc: 81.25%] [G loss: 5.845152]\n",
      "epoch:44 step:34509 [D loss: 0.257085, acc: 89.84%] [G loss: 5.908363]\n",
      "epoch:44 step:34510 [D loss: 0.087968, acc: 100.00%] [G loss: 5.484310]\n",
      "epoch:44 step:34511 [D loss: 0.480315, acc: 73.44%] [G loss: 5.407102]\n",
      "epoch:44 step:34512 [D loss: 0.359261, acc: 78.91%] [G loss: 5.442175]\n",
      "epoch:44 step:34513 [D loss: 0.410463, acc: 75.78%] [G loss: 8.012994]\n",
      "epoch:44 step:34514 [D loss: 0.468827, acc: 65.62%] [G loss: 7.519970]\n",
      "epoch:44 step:34515 [D loss: 1.324407, acc: 25.00%] [G loss: 7.240422]\n",
      "epoch:44 step:34516 [D loss: 0.069843, acc: 100.00%] [G loss: 4.070712]\n",
      "epoch:44 step:34517 [D loss: 0.038689, acc: 100.00%] [G loss: 8.494732]\n",
      "epoch:44 step:34518 [D loss: 0.277340, acc: 91.41%] [G loss: 6.405870]\n",
      "epoch:44 step:34519 [D loss: 0.405857, acc: 89.84%] [G loss: 4.237572]\n",
      "epoch:44 step:34520 [D loss: 0.069961, acc: 99.22%] [G loss: 5.802026]\n",
      "epoch:44 step:34521 [D loss: 0.835010, acc: 56.25%] [G loss: 6.219278]\n",
      "epoch:44 step:34522 [D loss: 0.350505, acc: 89.84%] [G loss: 6.314110]\n",
      "epoch:44 step:34523 [D loss: 0.044862, acc: 100.00%] [G loss: 7.767625]\n",
      "epoch:44 step:34524 [D loss: 0.640707, acc: 60.94%] [G loss: 10.627378]\n",
      "epoch:44 step:34525 [D loss: 0.169627, acc: 97.66%] [G loss: 5.954570]\n",
      "epoch:44 step:34526 [D loss: 0.453186, acc: 71.88%] [G loss: 6.907807]\n",
      "epoch:44 step:34527 [D loss: 0.210544, acc: 99.22%] [G loss: 5.953593]\n",
      "epoch:44 step:34528 [D loss: 0.456971, acc: 67.97%] [G loss: 5.143646]\n",
      "epoch:44 step:34529 [D loss: 0.315440, acc: 85.16%] [G loss: 7.538119]\n",
      "epoch:44 step:34530 [D loss: 0.199037, acc: 95.31%] [G loss: 8.123689]\n",
      "epoch:44 step:34531 [D loss: 0.332717, acc: 89.84%] [G loss: 6.855245]\n",
      "epoch:44 step:34532 [D loss: 0.029566, acc: 100.00%] [G loss: 5.808537]\n",
      "epoch:44 step:34533 [D loss: 0.202835, acc: 96.88%] [G loss: 7.534571]\n",
      "epoch:44 step:34534 [D loss: 0.627250, acc: 64.84%] [G loss: 4.412306]\n",
      "epoch:44 step:34535 [D loss: 0.577995, acc: 67.97%] [G loss: 6.579142]\n",
      "epoch:44 step:34536 [D loss: 0.862064, acc: 48.44%] [G loss: 5.878031]\n",
      "epoch:44 step:34537 [D loss: 0.530614, acc: 75.00%] [G loss: 6.008911]\n",
      "epoch:44 step:34538 [D loss: 0.341187, acc: 86.72%] [G loss: 5.792255]\n",
      "epoch:44 step:34539 [D loss: 0.005365, acc: 100.00%] [G loss: 6.816273]\n",
      "epoch:44 step:34540 [D loss: 0.623725, acc: 67.97%] [G loss: 6.062386]\n",
      "epoch:44 step:34541 [D loss: 0.044811, acc: 100.00%] [G loss: 6.230111]\n",
      "epoch:44 step:34542 [D loss: 0.202713, acc: 95.31%] [G loss: 4.810943]\n",
      "epoch:44 step:34543 [D loss: 0.436977, acc: 86.72%] [G loss: 4.488975]\n",
      "epoch:44 step:34544 [D loss: 0.769194, acc: 52.34%] [G loss: 7.402849]\n",
      "epoch:44 step:34545 [D loss: 0.499140, acc: 76.56%] [G loss: 5.587136]\n",
      "epoch:44 step:34546 [D loss: 0.210897, acc: 92.97%] [G loss: 6.206890]\n",
      "epoch:44 step:34547 [D loss: 0.075839, acc: 100.00%] [G loss: 4.099172]\n",
      "epoch:44 step:34548 [D loss: 0.113207, acc: 100.00%] [G loss: 5.935020]\n",
      "epoch:44 step:34549 [D loss: 0.440551, acc: 75.00%] [G loss: 8.796165]\n",
      "epoch:44 step:34550 [D loss: 0.820649, acc: 56.25%] [G loss: 5.225510]\n",
      "epoch:44 step:34551 [D loss: 0.044671, acc: 100.00%] [G loss: 6.797791]\n",
      "epoch:44 step:34552 [D loss: 0.471014, acc: 73.44%] [G loss: 6.637125]\n",
      "epoch:44 step:34553 [D loss: 0.021019, acc: 100.00%] [G loss: 7.774749]\n",
      "epoch:44 step:34554 [D loss: 0.954088, acc: 43.75%] [G loss: 6.128293]\n",
      "epoch:44 step:34555 [D loss: 0.107554, acc: 98.44%] [G loss: 5.265504]\n",
      "epoch:44 step:34556 [D loss: 0.280802, acc: 94.53%] [G loss: 6.333477]\n",
      "epoch:44 step:34557 [D loss: 0.112301, acc: 99.22%] [G loss: 4.636914]\n",
      "epoch:44 step:34558 [D loss: 0.192224, acc: 96.88%] [G loss: 9.503335]\n",
      "epoch:44 step:34559 [D loss: 0.432482, acc: 77.34%] [G loss: 6.118948]\n",
      "epoch:44 step:34560 [D loss: 0.312112, acc: 85.94%] [G loss: 3.430991]\n",
      "epoch:44 step:34561 [D loss: 0.276949, acc: 92.19%] [G loss: 3.866217]\n",
      "epoch:44 step:34562 [D loss: 0.049473, acc: 98.44%] [G loss: 5.315108]\n",
      "epoch:44 step:34563 [D loss: 0.880159, acc: 46.09%] [G loss: 4.593680]\n",
      "epoch:44 step:34564 [D loss: 0.058421, acc: 100.00%] [G loss: 6.850686]\n",
      "epoch:44 step:34565 [D loss: 0.365114, acc: 92.19%] [G loss: 6.130043]\n",
      "epoch:44 step:34566 [D loss: 0.131201, acc: 100.00%] [G loss: 3.951467]\n",
      "epoch:44 step:34567 [D loss: 0.747026, acc: 55.47%] [G loss: 6.904390]\n",
      "epoch:44 step:34568 [D loss: 0.185303, acc: 96.09%] [G loss: 6.977114]\n",
      "epoch:44 step:34569 [D loss: 0.729381, acc: 52.34%] [G loss: 4.860152]\n",
      "epoch:44 step:34570 [D loss: 0.409000, acc: 82.03%] [G loss: 4.050450]\n",
      "epoch:44 step:34571 [D loss: 0.496137, acc: 81.25%] [G loss: 5.096805]\n",
      "epoch:44 step:34572 [D loss: 0.075336, acc: 100.00%] [G loss: 7.147470]\n",
      "epoch:44 step:34573 [D loss: 0.108355, acc: 99.22%] [G loss: 5.034602]\n",
      "epoch:44 step:34574 [D loss: 1.548545, acc: 15.62%] [G loss: 7.771561]\n",
      "epoch:44 step:34575 [D loss: 0.169465, acc: 96.88%] [G loss: 9.717709]\n",
      "epoch:44 step:34576 [D loss: 0.026416, acc: 100.00%] [G loss: 7.196073]\n",
      "epoch:44 step:34577 [D loss: 0.514039, acc: 63.28%] [G loss: 5.802999]\n",
      "epoch:44 step:34578 [D loss: 0.340969, acc: 84.38%] [G loss: 4.031823]\n",
      "epoch:44 step:34579 [D loss: 0.183048, acc: 96.09%] [G loss: 4.964775]\n",
      "epoch:44 step:34580 [D loss: 0.054699, acc: 100.00%] [G loss: 6.493044]\n",
      "epoch:44 step:34581 [D loss: 0.257870, acc: 92.97%] [G loss: 5.936265]\n",
      "epoch:44 step:34582 [D loss: 0.926980, acc: 50.78%] [G loss: 5.706702]\n",
      "epoch:44 step:34583 [D loss: 0.048650, acc: 100.00%] [G loss: 6.022161]\n",
      "epoch:44 step:34584 [D loss: 0.648665, acc: 57.03%] [G loss: 6.047621]\n",
      "epoch:44 step:34585 [D loss: 1.018288, acc: 45.31%] [G loss: 5.526569]\n",
      "epoch:44 step:34586 [D loss: 0.716727, acc: 59.38%] [G loss: 5.711908]\n",
      "epoch:44 step:34587 [D loss: 0.121927, acc: 99.22%] [G loss: 4.720027]\n",
      "epoch:44 step:34588 [D loss: 0.128846, acc: 100.00%] [G loss: 2.148739]\n",
      "epoch:44 step:34589 [D loss: 0.293754, acc: 85.16%] [G loss: 8.258289]\n",
      "epoch:44 step:34590 [D loss: 0.142890, acc: 100.00%] [G loss: 5.533412]\n",
      "epoch:44 step:34591 [D loss: 0.108467, acc: 99.22%] [G loss: 8.301342]\n",
      "epoch:44 step:34592 [D loss: 0.092089, acc: 100.00%] [G loss: 5.128684]\n",
      "epoch:44 step:34593 [D loss: 0.554982, acc: 60.94%] [G loss: 8.633444]\n",
      "epoch:44 step:34594 [D loss: 0.906044, acc: 53.12%] [G loss: 7.040399]\n",
      "epoch:44 step:34595 [D loss: 0.038377, acc: 100.00%] [G loss: 5.415334]\n",
      "epoch:44 step:34596 [D loss: 0.139646, acc: 99.22%] [G loss: 4.772946]\n",
      "epoch:44 step:34597 [D loss: 0.236669, acc: 96.88%] [G loss: 5.941183]\n",
      "epoch:44 step:34598 [D loss: 1.108264, acc: 42.97%] [G loss: 3.575839]\n",
      "epoch:44 step:34599 [D loss: 0.047744, acc: 100.00%] [G loss: 5.369104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34600 [D loss: 0.429448, acc: 71.09%] [G loss: 6.361895]\n",
      "epoch:44 step:34601 [D loss: 0.212476, acc: 92.97%] [G loss: 3.803692]\n",
      "epoch:44 step:34602 [D loss: 0.187068, acc: 95.31%] [G loss: 2.827528]\n",
      "epoch:44 step:34603 [D loss: 0.140026, acc: 99.22%] [G loss: 5.979959]\n",
      "epoch:44 step:34604 [D loss: 1.308382, acc: 50.00%] [G loss: 4.626370]\n",
      "epoch:44 step:34605 [D loss: 0.075847, acc: 100.00%] [G loss: 1.653208]\n",
      "epoch:44 step:34606 [D loss: 0.170434, acc: 98.44%] [G loss: 5.424275]\n",
      "epoch:44 step:34607 [D loss: 0.277350, acc: 95.31%] [G loss: 9.378119]\n",
      "epoch:44 step:34608 [D loss: 0.009404, acc: 100.00%] [G loss: 10.456339]\n",
      "epoch:44 step:34609 [D loss: 0.804221, acc: 51.56%] [G loss: 5.334715]\n",
      "epoch:44 step:34610 [D loss: 0.241050, acc: 94.53%] [G loss: 4.161300]\n",
      "epoch:44 step:34611 [D loss: 0.655852, acc: 61.72%] [G loss: 5.844870]\n",
      "epoch:44 step:34612 [D loss: 0.257074, acc: 89.84%] [G loss: 5.208470]\n",
      "epoch:44 step:34613 [D loss: 0.079118, acc: 100.00%] [G loss: 4.717026]\n",
      "epoch:44 step:34614 [D loss: 0.360327, acc: 79.69%] [G loss: 5.066477]\n",
      "epoch:44 step:34615 [D loss: 0.006091, acc: 100.00%] [G loss: 7.616292]\n",
      "epoch:44 step:34616 [D loss: 0.074924, acc: 100.00%] [G loss: 5.422529]\n",
      "epoch:44 step:34617 [D loss: 0.348929, acc: 89.06%] [G loss: 6.406663]\n",
      "epoch:44 step:34618 [D loss: 0.144073, acc: 99.22%] [G loss: 6.025785]\n",
      "epoch:44 step:34619 [D loss: 0.688258, acc: 55.47%] [G loss: 8.336672]\n",
      "epoch:44 step:34620 [D loss: 0.366069, acc: 75.78%] [G loss: 5.392602]\n",
      "epoch:44 step:34621 [D loss: 0.087011, acc: 100.00%] [G loss: 2.814833]\n",
      "epoch:44 step:34622 [D loss: 0.935299, acc: 35.16%] [G loss: 9.170626]\n",
      "epoch:44 step:34623 [D loss: 0.140551, acc: 99.22%] [G loss: 4.132732]\n",
      "epoch:44 step:34624 [D loss: 0.158172, acc: 99.22%] [G loss: 2.884642]\n",
      "epoch:44 step:34625 [D loss: 0.434160, acc: 71.88%] [G loss: 6.593732]\n",
      "epoch:44 step:34626 [D loss: 0.255607, acc: 89.06%] [G loss: 8.078355]\n",
      "epoch:44 step:34627 [D loss: 1.395529, acc: 7.81%] [G loss: 5.551685]\n",
      "epoch:44 step:34628 [D loss: 0.339159, acc: 78.91%] [G loss: 3.971587]\n",
      "epoch:44 step:34629 [D loss: 0.175657, acc: 97.66%] [G loss: 5.505803]\n",
      "epoch:44 step:34630 [D loss: 0.339055, acc: 85.94%] [G loss: 6.442116]\n",
      "epoch:44 step:34631 [D loss: 0.184541, acc: 97.66%] [G loss: 5.068858]\n",
      "epoch:44 step:34632 [D loss: 0.443195, acc: 70.31%] [G loss: 1.885708]\n",
      "epoch:44 step:34633 [D loss: 0.106847, acc: 100.00%] [G loss: 5.393730]\n",
      "epoch:44 step:34634 [D loss: 0.153508, acc: 100.00%] [G loss: 6.927838]\n",
      "epoch:44 step:34635 [D loss: 0.194204, acc: 98.44%] [G loss: 6.465236]\n",
      "epoch:44 step:34636 [D loss: 0.228398, acc: 90.62%] [G loss: 8.149759]\n",
      "epoch:44 step:34637 [D loss: 0.757243, acc: 54.69%] [G loss: 5.613132]\n",
      "epoch:44 step:34638 [D loss: 0.605477, acc: 64.84%] [G loss: 8.350820]\n",
      "epoch:44 step:34639 [D loss: 0.267439, acc: 96.09%] [G loss: 4.498599]\n",
      "epoch:44 step:34640 [D loss: 0.206649, acc: 91.41%] [G loss: 6.324630]\n",
      "epoch:44 step:34641 [D loss: 0.098830, acc: 100.00%] [G loss: 4.243695]\n",
      "epoch:44 step:34642 [D loss: 0.969867, acc: 52.34%] [G loss: 7.448553]\n",
      "epoch:44 step:34643 [D loss: 0.212627, acc: 96.09%] [G loss: 5.930522]\n",
      "epoch:44 step:34644 [D loss: 0.615886, acc: 61.72%] [G loss: 7.012216]\n",
      "epoch:44 step:34645 [D loss: 0.371916, acc: 82.03%] [G loss: 5.130791]\n",
      "epoch:44 step:34646 [D loss: 0.295539, acc: 93.75%] [G loss: 6.631505]\n",
      "epoch:44 step:34647 [D loss: 0.418910, acc: 73.44%] [G loss: 6.834109]\n",
      "epoch:44 step:34648 [D loss: 0.053738, acc: 100.00%] [G loss: 3.286818]\n",
      "epoch:44 step:34649 [D loss: 0.443694, acc: 75.78%] [G loss: 7.543036]\n",
      "epoch:44 step:34650 [D loss: 0.075227, acc: 100.00%] [G loss: 2.898924]\n",
      "epoch:44 step:34651 [D loss: 0.041248, acc: 100.00%] [G loss: 4.225448]\n",
      "epoch:44 step:34652 [D loss: 0.451266, acc: 81.25%] [G loss: 6.990773]\n",
      "epoch:44 step:34653 [D loss: 0.469536, acc: 70.31%] [G loss: 4.307224]\n",
      "epoch:44 step:34654 [D loss: 0.041681, acc: 100.00%] [G loss: 5.213455]\n",
      "epoch:44 step:34655 [D loss: 0.334794, acc: 78.91%] [G loss: 5.566333]\n",
      "epoch:44 step:34656 [D loss: 0.116087, acc: 100.00%] [G loss: 7.195024]\n",
      "epoch:44 step:34657 [D loss: 0.142406, acc: 98.44%] [G loss: 5.757066]\n",
      "epoch:44 step:34658 [D loss: 0.026395, acc: 100.00%] [G loss: 2.684285]\n",
      "epoch:44 step:34659 [D loss: 0.435414, acc: 79.69%] [G loss: 3.319950]\n",
      "epoch:44 step:34660 [D loss: 0.069893, acc: 100.00%] [G loss: 7.385749]\n",
      "epoch:44 step:34661 [D loss: 0.130360, acc: 99.22%] [G loss: 4.972409]\n",
      "epoch:44 step:34662 [D loss: 0.548900, acc: 66.41%] [G loss: 6.921340]\n",
      "epoch:44 step:34663 [D loss: 0.200576, acc: 95.31%] [G loss: 8.535099]\n",
      "epoch:44 step:34664 [D loss: 0.328461, acc: 90.62%] [G loss: 5.165149]\n",
      "epoch:44 step:34665 [D loss: 0.145577, acc: 97.66%] [G loss: 5.491741]\n",
      "epoch:44 step:34666 [D loss: 0.367139, acc: 85.16%] [G loss: 5.364177]\n",
      "epoch:44 step:34667 [D loss: 0.352062, acc: 84.38%] [G loss: 4.951406]\n",
      "epoch:44 step:34668 [D loss: 0.189306, acc: 99.22%] [G loss: 5.581656]\n",
      "epoch:44 step:34669 [D loss: 0.116757, acc: 100.00%] [G loss: 4.911661]\n",
      "epoch:44 step:34670 [D loss: 0.447525, acc: 73.44%] [G loss: 2.809966]\n",
      "epoch:44 step:34671 [D loss: 0.015086, acc: 100.00%] [G loss: 5.614564]\n",
      "epoch:44 step:34672 [D loss: 0.588503, acc: 64.84%] [G loss: 5.652111]\n",
      "epoch:44 step:34673 [D loss: 1.059207, acc: 50.78%] [G loss: 8.274093]\n",
      "epoch:44 step:34674 [D loss: 0.620344, acc: 61.72%] [G loss: 6.148619]\n",
      "epoch:44 step:34675 [D loss: 0.446142, acc: 73.44%] [G loss: 6.682638]\n",
      "epoch:44 step:34676 [D loss: 0.056980, acc: 100.00%] [G loss: 4.392756]\n",
      "epoch:44 step:34677 [D loss: 0.080071, acc: 100.00%] [G loss: 7.153079]\n",
      "epoch:44 step:34678 [D loss: 0.183465, acc: 96.09%] [G loss: 9.335083]\n",
      "epoch:44 step:34679 [D loss: 0.436530, acc: 79.69%] [G loss: 7.890690]\n",
      "epoch:44 step:34680 [D loss: 0.521439, acc: 70.31%] [G loss: 6.747161]\n",
      "epoch:44 step:34681 [D loss: 0.278361, acc: 93.75%] [G loss: 5.463218]\n",
      "epoch:44 step:34682 [D loss: 0.195861, acc: 96.88%] [G loss: 5.983431]\n",
      "epoch:44 step:34683 [D loss: 0.508099, acc: 72.66%] [G loss: 5.383112]\n",
      "epoch:44 step:34684 [D loss: 0.143321, acc: 99.22%] [G loss: 3.287798]\n",
      "epoch:44 step:34685 [D loss: 1.082158, acc: 35.94%] [G loss: 7.965921]\n",
      "epoch:44 step:34686 [D loss: 0.585343, acc: 66.41%] [G loss: 6.738443]\n",
      "epoch:44 step:34687 [D loss: 0.744648, acc: 54.69%] [G loss: 3.700812]\n",
      "epoch:44 step:34688 [D loss: 0.271955, acc: 89.84%] [G loss: 2.065978]\n",
      "epoch:44 step:34689 [D loss: 0.818848, acc: 52.34%] [G loss: 9.163784]\n",
      "epoch:44 step:34690 [D loss: 0.426567, acc: 82.81%] [G loss: 6.778631]\n",
      "epoch:44 step:34691 [D loss: 0.980548, acc: 50.78%] [G loss: 9.125855]\n",
      "epoch:44 step:34692 [D loss: 0.036238, acc: 100.00%] [G loss: 8.270965]\n",
      "epoch:44 step:34693 [D loss: 0.340895, acc: 78.91%] [G loss: 8.937531]\n",
      "epoch:44 step:34694 [D loss: 0.027756, acc: 100.00%] [G loss: 8.900367]\n",
      "epoch:44 step:34695 [D loss: 0.538272, acc: 67.97%] [G loss: 4.147458]\n",
      "epoch:44 step:34696 [D loss: 0.803770, acc: 53.91%] [G loss: 6.133754]\n",
      "epoch:44 step:34697 [D loss: 0.956190, acc: 50.78%] [G loss: 7.270097]\n",
      "epoch:44 step:34698 [D loss: 0.022442, acc: 100.00%] [G loss: 7.567315]\n",
      "epoch:44 step:34699 [D loss: 0.127235, acc: 98.44%] [G loss: 11.089439]\n",
      "epoch:44 step:34700 [D loss: 0.502304, acc: 65.62%] [G loss: 9.281505]\n",
      "epoch:44 step:34701 [D loss: 0.197709, acc: 93.75%] [G loss: 6.328281]\n",
      "epoch:44 step:34702 [D loss: 0.076737, acc: 100.00%] [G loss: 7.440544]\n",
      "epoch:44 step:34703 [D loss: 0.666158, acc: 58.59%] [G loss: 8.536890]\n",
      "epoch:44 step:34704 [D loss: 1.421332, acc: 32.81%] [G loss: 3.662798]\n",
      "epoch:44 step:34705 [D loss: 0.046091, acc: 100.00%] [G loss: 5.445517]\n",
      "epoch:44 step:34706 [D loss: 1.193953, acc: 44.53%] [G loss: 5.683631]\n",
      "epoch:44 step:34707 [D loss: 0.180331, acc: 95.31%] [G loss: 5.633394]\n",
      "epoch:44 step:34708 [D loss: 0.143223, acc: 99.22%] [G loss: 6.906649]\n",
      "epoch:44 step:34709 [D loss: 0.159088, acc: 96.09%] [G loss: 4.562245]\n",
      "epoch:44 step:34710 [D loss: 0.149765, acc: 97.66%] [G loss: 2.367279]\n",
      "epoch:44 step:34711 [D loss: 0.306082, acc: 89.84%] [G loss: 6.059561]\n",
      "epoch:44 step:34712 [D loss: 0.579082, acc: 70.31%] [G loss: 9.619509]\n",
      "epoch:44 step:34713 [D loss: 0.221575, acc: 96.88%] [G loss: 8.076192]\n",
      "epoch:44 step:34714 [D loss: 0.260250, acc: 96.88%] [G loss: 5.728536]\n",
      "epoch:44 step:34715 [D loss: 0.849560, acc: 43.75%] [G loss: 5.706812]\n",
      "epoch:44 step:34716 [D loss: 0.167800, acc: 99.22%] [G loss: 5.417560]\n",
      "epoch:44 step:34717 [D loss: 0.314562, acc: 86.72%] [G loss: 3.430244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34718 [D loss: 0.162024, acc: 99.22%] [G loss: 3.970553]\n",
      "epoch:44 step:34719 [D loss: 0.104931, acc: 100.00%] [G loss: 4.425719]\n",
      "epoch:44 step:34720 [D loss: 0.233334, acc: 97.66%] [G loss: 4.911645]\n",
      "epoch:44 step:34721 [D loss: 0.712885, acc: 58.59%] [G loss: 3.336541]\n",
      "epoch:44 step:34722 [D loss: 0.270267, acc: 91.41%] [G loss: 5.855386]\n",
      "epoch:44 step:34723 [D loss: 0.283187, acc: 94.53%] [G loss: 5.888639]\n",
      "epoch:44 step:34724 [D loss: 0.295050, acc: 90.62%] [G loss: 4.786300]\n",
      "epoch:44 step:34725 [D loss: 0.590350, acc: 63.28%] [G loss: 7.473362]\n",
      "epoch:44 step:34726 [D loss: 0.606835, acc: 55.47%] [G loss: 5.429170]\n",
      "epoch:44 step:34727 [D loss: 0.078434, acc: 100.00%] [G loss: 7.942416]\n",
      "epoch:44 step:34728 [D loss: 0.348856, acc: 83.59%] [G loss: 7.095098]\n",
      "epoch:44 step:34729 [D loss: 0.170838, acc: 99.22%] [G loss: 6.969828]\n",
      "epoch:44 step:34730 [D loss: 0.290771, acc: 85.94%] [G loss: 6.820646]\n",
      "epoch:44 step:34731 [D loss: 0.110126, acc: 98.44%] [G loss: 4.370206]\n",
      "epoch:44 step:34732 [D loss: 0.282660, acc: 88.28%] [G loss: 5.834477]\n",
      "epoch:44 step:34733 [D loss: 1.151685, acc: 31.25%] [G loss: 7.356194]\n",
      "epoch:44 step:34734 [D loss: 0.287697, acc: 94.53%] [G loss: 5.320161]\n",
      "epoch:44 step:34735 [D loss: 0.224882, acc: 95.31%] [G loss: 5.831497]\n",
      "epoch:44 step:34736 [D loss: 0.120290, acc: 99.22%] [G loss: 5.005485]\n",
      "epoch:44 step:34737 [D loss: 1.165094, acc: 17.19%] [G loss: 6.028358]\n",
      "epoch:44 step:34738 [D loss: 0.284510, acc: 87.50%] [G loss: 5.079070]\n",
      "epoch:44 step:34739 [D loss: 0.096258, acc: 99.22%] [G loss: 6.434211]\n",
      "epoch:44 step:34740 [D loss: 0.047579, acc: 100.00%] [G loss: 5.166678]\n",
      "epoch:44 step:34741 [D loss: 1.011248, acc: 33.59%] [G loss: 8.173973]\n",
      "epoch:44 step:34742 [D loss: 0.070544, acc: 99.22%] [G loss: 4.087434]\n",
      "epoch:44 step:34743 [D loss: 0.169052, acc: 97.66%] [G loss: 8.132493]\n",
      "epoch:44 step:34744 [D loss: 0.504895, acc: 65.62%] [G loss: 4.968863]\n",
      "epoch:44 step:34745 [D loss: 0.089354, acc: 99.22%] [G loss: 8.235319]\n",
      "epoch:44 step:34746 [D loss: 0.407118, acc: 78.12%] [G loss: 9.814222]\n",
      "epoch:44 step:34747 [D loss: 0.214317, acc: 95.31%] [G loss: 4.537477]\n",
      "epoch:44 step:34748 [D loss: 0.142456, acc: 98.44%] [G loss: 2.366466]\n",
      "epoch:44 step:34749 [D loss: 0.071652, acc: 100.00%] [G loss: 6.457250]\n",
      "epoch:44 step:34750 [D loss: 0.620591, acc: 59.38%] [G loss: 7.186175]\n",
      "epoch:44 step:34751 [D loss: 0.728923, acc: 51.56%] [G loss: 7.390702]\n",
      "epoch:44 step:34752 [D loss: 0.094463, acc: 99.22%] [G loss: 7.392427]\n",
      "epoch:44 step:34753 [D loss: 0.476003, acc: 76.56%] [G loss: 8.248446]\n",
      "epoch:44 step:34754 [D loss: 0.169068, acc: 100.00%] [G loss: 3.881253]\n",
      "epoch:44 step:34755 [D loss: 0.367004, acc: 89.06%] [G loss: 4.008934]\n",
      "epoch:44 step:34756 [D loss: 0.479517, acc: 79.69%] [G loss: 5.542839]\n",
      "epoch:44 step:34757 [D loss: 0.221559, acc: 96.88%] [G loss: 5.495411]\n",
      "epoch:44 step:34758 [D loss: 1.017598, acc: 34.38%] [G loss: 5.332211]\n",
      "epoch:44 step:34759 [D loss: 0.141469, acc: 99.22%] [G loss: 4.809503]\n",
      "epoch:44 step:34760 [D loss: 0.097727, acc: 99.22%] [G loss: 8.316562]\n",
      "epoch:44 step:34761 [D loss: 0.249572, acc: 88.28%] [G loss: 6.118924]\n",
      "epoch:44 step:34762 [D loss: 0.035677, acc: 100.00%] [G loss: 6.346004]\n",
      "epoch:44 step:34763 [D loss: 0.214198, acc: 95.31%] [G loss: 5.957573]\n",
      "epoch:44 step:34764 [D loss: 0.136191, acc: 96.09%] [G loss: 4.658063]\n",
      "epoch:44 step:34765 [D loss: 0.160248, acc: 100.00%] [G loss: 7.087545]\n",
      "epoch:44 step:34766 [D loss: 0.094835, acc: 99.22%] [G loss: 3.167660]\n",
      "epoch:44 step:34767 [D loss: 1.186857, acc: 26.56%] [G loss: 8.081923]\n",
      "epoch:44 step:34768 [D loss: 0.528566, acc: 71.09%] [G loss: 5.238878]\n",
      "epoch:44 step:34769 [D loss: 0.177373, acc: 99.22%] [G loss: 8.037661]\n",
      "epoch:44 step:34770 [D loss: 0.289743, acc: 92.97%] [G loss: 4.284251]\n",
      "epoch:44 step:34771 [D loss: 1.520435, acc: 50.00%] [G loss: 6.459375]\n",
      "epoch:44 step:34772 [D loss: 0.724358, acc: 56.25%] [G loss: 2.766889]\n",
      "epoch:44 step:34773 [D loss: 0.046757, acc: 100.00%] [G loss: 4.568342]\n",
      "epoch:44 step:34774 [D loss: 0.360034, acc: 92.97%] [G loss: 4.247282]\n",
      "epoch:44 step:34775 [D loss: 0.135890, acc: 99.22%] [G loss: 7.763880]\n",
      "epoch:44 step:34776 [D loss: 0.634672, acc: 63.28%] [G loss: 3.750045]\n",
      "epoch:44 step:34777 [D loss: 0.150338, acc: 99.22%] [G loss: 5.218802]\n",
      "epoch:44 step:34778 [D loss: 1.514620, acc: 11.72%] [G loss: 7.151552]\n",
      "epoch:44 step:34779 [D loss: 0.252591, acc: 92.97%] [G loss: 5.985495]\n",
      "epoch:44 step:34780 [D loss: 0.290664, acc: 89.84%] [G loss: 7.610531]\n",
      "epoch:44 step:34781 [D loss: 0.117983, acc: 99.22%] [G loss: 6.245358]\n",
      "epoch:44 step:34782 [D loss: 0.210382, acc: 98.44%] [G loss: 6.125628]\n",
      "epoch:44 step:34783 [D loss: 0.436358, acc: 85.94%] [G loss: 4.922739]\n",
      "epoch:44 step:34784 [D loss: 0.301362, acc: 89.84%] [G loss: 6.315848]\n",
      "epoch:44 step:34785 [D loss: 0.646911, acc: 60.16%] [G loss: 7.022051]\n",
      "epoch:44 step:34786 [D loss: 0.142848, acc: 99.22%] [G loss: 5.671037]\n",
      "epoch:44 step:34787 [D loss: 0.138912, acc: 99.22%] [G loss: 7.177339]\n",
      "epoch:44 step:34788 [D loss: 0.513455, acc: 75.00%] [G loss: 5.130111]\n",
      "epoch:44 step:34789 [D loss: 0.561476, acc: 65.62%] [G loss: 7.141430]\n",
      "epoch:44 step:34790 [D loss: 0.333065, acc: 78.91%] [G loss: 6.078359]\n",
      "epoch:44 step:34791 [D loss: 1.006891, acc: 43.75%] [G loss: 8.960052]\n",
      "epoch:44 step:34792 [D loss: 0.024982, acc: 100.00%] [G loss: 7.743065]\n",
      "epoch:44 step:34793 [D loss: 0.665332, acc: 58.59%] [G loss: 8.115811]\n",
      "epoch:44 step:34794 [D loss: 0.135243, acc: 99.22%] [G loss: 6.709632]\n",
      "epoch:44 step:34795 [D loss: 0.611523, acc: 64.84%] [G loss: 9.248742]\n",
      "epoch:44 step:34796 [D loss: 0.308475, acc: 92.97%] [G loss: 4.302739]\n",
      "epoch:44 step:34797 [D loss: 1.046501, acc: 50.78%] [G loss: 8.150958]\n",
      "epoch:44 step:34798 [D loss: 0.034947, acc: 99.22%] [G loss: 7.832074]\n",
      "epoch:44 step:34799 [D loss: 0.182234, acc: 96.09%] [G loss: 8.560785]\n",
      "epoch:44 step:34800 [D loss: 0.648018, acc: 59.38%] [G loss: 7.578710]\n",
      "epoch:44 step:34801 [D loss: 0.164666, acc: 97.66%] [G loss: 7.202021]\n",
      "epoch:44 step:34802 [D loss: 0.057435, acc: 99.22%] [G loss: 5.735353]\n",
      "epoch:44 step:34803 [D loss: 0.155452, acc: 99.22%] [G loss: 5.895833]\n",
      "epoch:44 step:34804 [D loss: 0.400872, acc: 89.06%] [G loss: 7.900372]\n",
      "epoch:44 step:34805 [D loss: 0.141755, acc: 97.66%] [G loss: 7.171509]\n",
      "epoch:44 step:34806 [D loss: 0.104277, acc: 100.00%] [G loss: 4.839466]\n",
      "epoch:44 step:34807 [D loss: 0.784883, acc: 53.91%] [G loss: 6.396574]\n",
      "epoch:44 step:34808 [D loss: 2.073067, acc: 39.06%] [G loss: 7.389967]\n",
      "epoch:44 step:34809 [D loss: 0.215173, acc: 97.66%] [G loss: 5.446670]\n",
      "epoch:44 step:34810 [D loss: 0.289098, acc: 83.59%] [G loss: 6.471144]\n",
      "epoch:44 step:34811 [D loss: 0.492933, acc: 75.78%] [G loss: 5.980114]\n",
      "epoch:44 step:34812 [D loss: 0.043888, acc: 100.00%] [G loss: 6.142931]\n",
      "epoch:44 step:34813 [D loss: 0.100344, acc: 99.22%] [G loss: 5.163300]\n",
      "epoch:44 step:34814 [D loss: 0.280632, acc: 90.62%] [G loss: 6.903329]\n",
      "epoch:44 step:34815 [D loss: 0.232120, acc: 92.97%] [G loss: 6.392604]\n",
      "epoch:44 step:34816 [D loss: 0.614123, acc: 69.53%] [G loss: 7.271954]\n",
      "epoch:44 step:34817 [D loss: 0.307567, acc: 86.72%] [G loss: 7.873993]\n",
      "epoch:44 step:34818 [D loss: 0.306044, acc: 87.50%] [G loss: 5.255223]\n",
      "epoch:44 step:34819 [D loss: 0.264865, acc: 93.75%] [G loss: 7.738511]\n",
      "epoch:44 step:34820 [D loss: 0.435272, acc: 82.03%] [G loss: 5.140126]\n",
      "epoch:44 step:34821 [D loss: 0.187294, acc: 98.44%] [G loss: 8.114913]\n",
      "epoch:44 step:34822 [D loss: 1.369091, acc: 23.44%] [G loss: 6.758146]\n",
      "epoch:44 step:34823 [D loss: 0.355193, acc: 76.56%] [G loss: 6.503938]\n",
      "epoch:44 step:34824 [D loss: 0.197912, acc: 96.88%] [G loss: 5.933405]\n",
      "epoch:44 step:34825 [D loss: 0.045272, acc: 100.00%] [G loss: 7.095687]\n",
      "epoch:44 step:34826 [D loss: 0.012455, acc: 100.00%] [G loss: 4.466805]\n",
      "epoch:44 step:34827 [D loss: 1.976620, acc: 43.75%] [G loss: 5.636307]\n",
      "epoch:44 step:34828 [D loss: 1.030622, acc: 50.00%] [G loss: 5.054091]\n",
      "epoch:44 step:34829 [D loss: 0.331605, acc: 91.41%] [G loss: 4.850477]\n",
      "epoch:44 step:34830 [D loss: 0.026592, acc: 100.00%] [G loss: 8.232304]\n",
      "epoch:44 step:34831 [D loss: 0.300891, acc: 90.62%] [G loss: 4.738475]\n",
      "epoch:44 step:34832 [D loss: 0.306336, acc: 90.62%] [G loss: 3.920805]\n",
      "epoch:44 step:34833 [D loss: 0.096931, acc: 100.00%] [G loss: 6.416794]\n",
      "epoch:44 step:34834 [D loss: 0.083500, acc: 100.00%] [G loss: 6.597510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34835 [D loss: 0.192642, acc: 96.88%] [G loss: 1.995629]\n",
      "epoch:44 step:34836 [D loss: 0.571383, acc: 75.00%] [G loss: 7.477790]\n",
      "epoch:44 step:34837 [D loss: 0.046064, acc: 100.00%] [G loss: 5.712942]\n",
      "epoch:44 step:34838 [D loss: 0.051823, acc: 99.22%] [G loss: 6.622006]\n",
      "epoch:44 step:34839 [D loss: 0.342395, acc: 83.59%] [G loss: 4.180237]\n",
      "epoch:44 step:34840 [D loss: 0.117595, acc: 99.22%] [G loss: 3.789530]\n",
      "epoch:44 step:34841 [D loss: 0.083035, acc: 100.00%] [G loss: 2.915411]\n",
      "epoch:44 step:34842 [D loss: 0.096062, acc: 100.00%] [G loss: 6.606497]\n",
      "epoch:44 step:34843 [D loss: 0.098151, acc: 99.22%] [G loss: 3.451403]\n",
      "epoch:44 step:34844 [D loss: 0.092131, acc: 100.00%] [G loss: 5.142580]\n",
      "epoch:44 step:34845 [D loss: 0.115286, acc: 100.00%] [G loss: 2.317395]\n",
      "epoch:44 step:34846 [D loss: 0.079594, acc: 100.00%] [G loss: 5.164993]\n",
      "epoch:44 step:34847 [D loss: 0.310331, acc: 93.75%] [G loss: 10.655230]\n",
      "epoch:44 step:34848 [D loss: 0.404014, acc: 89.06%] [G loss: 4.718856]\n",
      "epoch:44 step:34849 [D loss: 0.204786, acc: 97.66%] [G loss: 5.789761]\n",
      "epoch:44 step:34850 [D loss: 0.264742, acc: 89.06%] [G loss: 7.676326]\n",
      "epoch:44 step:34851 [D loss: 0.612929, acc: 62.50%] [G loss: 7.346180]\n",
      "epoch:44 step:34852 [D loss: 0.196231, acc: 98.44%] [G loss: 5.779489]\n",
      "epoch:44 step:34853 [D loss: 0.410122, acc: 70.31%] [G loss: 4.936289]\n",
      "epoch:44 step:34854 [D loss: 0.673453, acc: 57.81%] [G loss: 5.402723]\n",
      "epoch:44 step:34855 [D loss: 0.038292, acc: 100.00%] [G loss: 4.365005]\n",
      "epoch:44 step:34856 [D loss: 1.192445, acc: 50.00%] [G loss: 9.145176]\n",
      "epoch:44 step:34857 [D loss: 0.218147, acc: 97.66%] [G loss: 5.429636]\n",
      "epoch:44 step:34858 [D loss: 0.934426, acc: 52.34%] [G loss: 7.600006]\n",
      "epoch:44 step:34859 [D loss: 0.214202, acc: 92.19%] [G loss: 6.539276]\n",
      "epoch:44 step:34860 [D loss: 0.157670, acc: 98.44%] [G loss: 6.665985]\n",
      "epoch:44 step:34861 [D loss: 0.012970, acc: 100.00%] [G loss: 8.471759]\n",
      "epoch:44 step:34862 [D loss: 0.168704, acc: 98.44%] [G loss: 5.116539]\n",
      "epoch:44 step:34863 [D loss: 0.236746, acc: 96.88%] [G loss: 7.934695]\n",
      "epoch:44 step:34864 [D loss: 0.155597, acc: 96.09%] [G loss: 9.811449]\n",
      "epoch:44 step:34865 [D loss: 0.552997, acc: 60.16%] [G loss: 7.146082]\n",
      "epoch:44 step:34866 [D loss: 0.630514, acc: 57.81%] [G loss: 5.056237]\n",
      "epoch:44 step:34867 [D loss: 0.328181, acc: 85.94%] [G loss: 4.933374]\n",
      "epoch:44 step:34868 [D loss: 0.836889, acc: 53.12%] [G loss: 7.762711]\n",
      "epoch:44 step:34869 [D loss: 0.283838, acc: 89.84%] [G loss: 5.545035]\n",
      "epoch:44 step:34870 [D loss: 0.977435, acc: 52.34%] [G loss: 6.542257]\n",
      "epoch:44 step:34871 [D loss: 0.077746, acc: 100.00%] [G loss: 5.422384]\n",
      "epoch:44 step:34872 [D loss: 0.179362, acc: 99.22%] [G loss: 8.140506]\n",
      "epoch:44 step:34873 [D loss: 0.176575, acc: 94.53%] [G loss: 5.979074]\n",
      "epoch:44 step:34874 [D loss: 0.509040, acc: 65.62%] [G loss: 8.066872]\n",
      "epoch:44 step:34875 [D loss: 0.332984, acc: 78.91%] [G loss: 10.666024]\n",
      "epoch:44 step:34876 [D loss: 0.014697, acc: 100.00%] [G loss: 7.163262]\n",
      "epoch:44 step:34877 [D loss: 0.506877, acc: 78.12%] [G loss: 6.783103]\n",
      "epoch:44 step:34878 [D loss: 0.498746, acc: 78.12%] [G loss: 4.832413]\n",
      "epoch:44 step:34879 [D loss: 0.224969, acc: 96.88%] [G loss: 4.884647]\n",
      "epoch:44 step:34880 [D loss: 0.213139, acc: 96.88%] [G loss: 5.161929]\n",
      "epoch:44 step:34881 [D loss: 0.134779, acc: 99.22%] [G loss: 10.949085]\n",
      "epoch:44 step:34882 [D loss: 0.258305, acc: 96.09%] [G loss: 4.566279]\n",
      "epoch:44 step:34883 [D loss: 0.018339, acc: 100.00%] [G loss: 4.082728]\n",
      "epoch:44 step:34884 [D loss: 0.160955, acc: 97.66%] [G loss: 6.597534]\n",
      "epoch:44 step:34885 [D loss: 0.593525, acc: 57.81%] [G loss: 6.495224]\n",
      "epoch:44 step:34886 [D loss: 0.308296, acc: 86.72%] [G loss: 10.873326]\n",
      "epoch:44 step:34887 [D loss: 0.150279, acc: 98.44%] [G loss: 6.934734]\n",
      "epoch:44 step:34888 [D loss: 0.337829, acc: 89.06%] [G loss: 8.749202]\n",
      "epoch:44 step:34889 [D loss: 0.480432, acc: 79.69%] [G loss: 5.145936]\n",
      "epoch:44 step:34890 [D loss: 0.036956, acc: 99.22%] [G loss: 7.160582]\n",
      "epoch:44 step:34891 [D loss: 0.192920, acc: 93.75%] [G loss: 5.200806]\n",
      "epoch:44 step:34892 [D loss: 0.533351, acc: 73.44%] [G loss: 4.372409]\n",
      "epoch:44 step:34893 [D loss: 0.195854, acc: 95.31%] [G loss: 4.197995]\n",
      "epoch:44 step:34894 [D loss: 0.495513, acc: 64.84%] [G loss: 7.724358]\n",
      "epoch:44 step:34895 [D loss: 0.306586, acc: 93.75%] [G loss: 4.011089]\n",
      "epoch:44 step:34896 [D loss: 0.348363, acc: 85.94%] [G loss: 4.254712]\n",
      "epoch:44 step:34897 [D loss: 0.124971, acc: 99.22%] [G loss: 8.057153]\n",
      "epoch:44 step:34898 [D loss: 0.090913, acc: 100.00%] [G loss: 8.323866]\n",
      "epoch:44 step:34899 [D loss: 0.208150, acc: 95.31%] [G loss: 7.230292]\n",
      "epoch:44 step:34900 [D loss: 0.443016, acc: 73.44%] [G loss: 8.203375]\n",
      "epoch:44 step:34901 [D loss: 0.327928, acc: 87.50%] [G loss: 4.928442]\n",
      "epoch:44 step:34902 [D loss: 0.062884, acc: 100.00%] [G loss: 8.109214]\n",
      "epoch:44 step:34903 [D loss: 1.142384, acc: 50.78%] [G loss: 12.759007]\n",
      "epoch:44 step:34904 [D loss: 0.809601, acc: 55.47%] [G loss: 7.251384]\n",
      "epoch:44 step:34905 [D loss: 0.189669, acc: 95.31%] [G loss: 5.476337]\n",
      "epoch:44 step:34906 [D loss: 0.658537, acc: 60.16%] [G loss: 6.612538]\n",
      "epoch:44 step:34907 [D loss: 0.251413, acc: 89.84%] [G loss: 7.617844]\n",
      "epoch:44 step:34908 [D loss: 0.342201, acc: 86.72%] [G loss: 8.892147]\n",
      "epoch:44 step:34909 [D loss: 0.810732, acc: 53.91%] [G loss: 2.129368]\n",
      "epoch:44 step:34910 [D loss: 0.046939, acc: 100.00%] [G loss: 4.858203]\n",
      "epoch:44 step:34911 [D loss: 0.726703, acc: 55.47%] [G loss: 8.155689]\n",
      "epoch:44 step:34912 [D loss: 0.066285, acc: 100.00%] [G loss: 6.694632]\n",
      "epoch:44 step:34913 [D loss: 0.273357, acc: 87.50%] [G loss: 10.721723]\n",
      "epoch:44 step:34914 [D loss: 0.109635, acc: 100.00%] [G loss: 10.939960]\n",
      "epoch:44 step:34915 [D loss: 1.049510, acc: 52.34%] [G loss: 4.620653]\n",
      "epoch:44 step:34916 [D loss: 0.230265, acc: 96.09%] [G loss: 5.796707]\n",
      "epoch:44 step:34917 [D loss: 0.194328, acc: 96.88%] [G loss: 5.374964]\n",
      "epoch:44 step:34918 [D loss: 0.352525, acc: 89.84%] [G loss: 4.065097]\n",
      "epoch:44 step:34919 [D loss: 0.179158, acc: 96.09%] [G loss: 6.035677]\n",
      "epoch:44 step:34920 [D loss: 0.065197, acc: 99.22%] [G loss: 8.714455]\n",
      "epoch:44 step:34921 [D loss: 0.135755, acc: 98.44%] [G loss: 4.723979]\n",
      "epoch:44 step:34922 [D loss: 0.313613, acc: 89.84%] [G loss: 5.864503]\n",
      "epoch:44 step:34923 [D loss: 0.127317, acc: 99.22%] [G loss: 3.210921]\n",
      "epoch:44 step:34924 [D loss: 0.059238, acc: 100.00%] [G loss: 4.112919]\n",
      "epoch:44 step:34925 [D loss: 0.037017, acc: 100.00%] [G loss: 7.430490]\n",
      "epoch:44 step:34926 [D loss: 0.518761, acc: 66.41%] [G loss: 4.931027]\n",
      "epoch:44 step:34927 [D loss: 0.206933, acc: 94.53%] [G loss: 5.838327]\n",
      "epoch:44 step:34928 [D loss: 0.523278, acc: 81.25%] [G loss: 3.393013]\n",
      "epoch:44 step:34929 [D loss: 0.507817, acc: 78.12%] [G loss: 8.117932]\n",
      "epoch:44 step:34930 [D loss: 0.141655, acc: 99.22%] [G loss: 6.783499]\n",
      "epoch:44 step:34931 [D loss: 0.232284, acc: 93.75%] [G loss: 6.227730]\n",
      "epoch:44 step:34932 [D loss: 0.251601, acc: 92.19%] [G loss: 8.124215]\n",
      "epoch:44 step:34933 [D loss: 0.158758, acc: 98.44%] [G loss: 8.304948]\n",
      "epoch:44 step:34934 [D loss: 0.241862, acc: 95.31%] [G loss: 9.256914]\n",
      "epoch:44 step:34935 [D loss: 0.242747, acc: 92.97%] [G loss: 2.545579]\n",
      "epoch:44 step:34936 [D loss: 0.064047, acc: 99.22%] [G loss: 5.149450]\n",
      "epoch:44 step:34937 [D loss: 0.211972, acc: 97.66%] [G loss: 3.430666]\n",
      "epoch:44 step:34938 [D loss: 0.658571, acc: 60.16%] [G loss: 9.056283]\n",
      "epoch:44 step:34939 [D loss: 0.113337, acc: 100.00%] [G loss: 2.559378]\n",
      "epoch:44 step:34940 [D loss: 0.303166, acc: 94.53%] [G loss: 4.942939]\n",
      "epoch:44 step:34941 [D loss: 0.224598, acc: 96.88%] [G loss: 7.820674]\n",
      "epoch:44 step:34942 [D loss: 0.102901, acc: 99.22%] [G loss: 2.402304]\n",
      "epoch:44 step:34943 [D loss: 0.471698, acc: 82.81%] [G loss: 6.769721]\n",
      "epoch:44 step:34944 [D loss: 0.050407, acc: 100.00%] [G loss: 4.282260]\n",
      "epoch:44 step:34945 [D loss: 0.092820, acc: 100.00%] [G loss: 9.111921]\n",
      "epoch:44 step:34946 [D loss: 0.159744, acc: 96.09%] [G loss: 5.594813]\n",
      "epoch:44 step:34947 [D loss: 0.574008, acc: 69.53%] [G loss: 5.766295]\n",
      "epoch:44 step:34948 [D loss: 0.304261, acc: 92.97%] [G loss: 5.515924]\n",
      "epoch:44 step:34949 [D loss: 0.102433, acc: 100.00%] [G loss: 5.099904]\n",
      "epoch:44 step:34950 [D loss: 0.356008, acc: 85.94%] [G loss: 6.339826]\n",
      "epoch:44 step:34951 [D loss: 0.125884, acc: 98.44%] [G loss: 5.327296]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34952 [D loss: 1.041420, acc: 27.34%] [G loss: 7.457002]\n",
      "epoch:44 step:34953 [D loss: 0.123853, acc: 99.22%] [G loss: 5.954594]\n",
      "epoch:44 step:34954 [D loss: 0.415697, acc: 81.25%] [G loss: 6.145744]\n",
      "epoch:44 step:34955 [D loss: 0.339028, acc: 86.72%] [G loss: 5.241760]\n",
      "epoch:44 step:34956 [D loss: 0.816337, acc: 47.66%] [G loss: 5.968559]\n",
      "epoch:44 step:34957 [D loss: 0.219040, acc: 99.22%] [G loss: 4.602811]\n",
      "epoch:44 step:34958 [D loss: 0.090402, acc: 100.00%] [G loss: 6.477913]\n",
      "epoch:44 step:34959 [D loss: 0.089716, acc: 97.66%] [G loss: 6.831634]\n",
      "epoch:44 step:34960 [D loss: 0.331256, acc: 85.16%] [G loss: 6.446690]\n",
      "epoch:44 step:34961 [D loss: 0.431891, acc: 83.59%] [G loss: 7.212082]\n",
      "epoch:44 step:34962 [D loss: 0.812177, acc: 51.56%] [G loss: 4.459148]\n",
      "epoch:44 step:34963 [D loss: 1.186444, acc: 40.62%] [G loss: 8.594871]\n",
      "epoch:44 step:34964 [D loss: 0.574174, acc: 63.28%] [G loss: 8.865838]\n",
      "epoch:44 step:34965 [D loss: 0.137313, acc: 97.66%] [G loss: 6.742000]\n",
      "epoch:44 step:34966 [D loss: 0.476061, acc: 67.19%] [G loss: 7.168692]\n",
      "epoch:44 step:34967 [D loss: 0.087533, acc: 99.22%] [G loss: 5.117038]\n",
      "epoch:44 step:34968 [D loss: 0.272192, acc: 92.97%] [G loss: 5.392742]\n",
      "epoch:44 step:34969 [D loss: 0.065523, acc: 100.00%] [G loss: 7.556110]\n",
      "epoch:44 step:34970 [D loss: 0.066854, acc: 99.22%] [G loss: 4.269048]\n",
      "epoch:44 step:34971 [D loss: 0.160871, acc: 98.44%] [G loss: 2.629457]\n",
      "epoch:44 step:34972 [D loss: 0.399451, acc: 84.38%] [G loss: 6.161975]\n",
      "epoch:44 step:34973 [D loss: 0.091974, acc: 100.00%] [G loss: 4.779462]\n",
      "epoch:44 step:34974 [D loss: 0.328951, acc: 89.84%] [G loss: 4.130223]\n",
      "epoch:44 step:34975 [D loss: 0.179891, acc: 95.31%] [G loss: 6.244835]\n",
      "epoch:44 step:34976 [D loss: 0.183006, acc: 95.31%] [G loss: 5.881853]\n",
      "epoch:44 step:34977 [D loss: 0.264244, acc: 90.62%] [G loss: 9.405646]\n",
      "epoch:44 step:34978 [D loss: 0.145694, acc: 99.22%] [G loss: 4.721128]\n",
      "epoch:44 step:34979 [D loss: 0.088205, acc: 100.00%] [G loss: 4.972544]\n",
      "epoch:44 step:34980 [D loss: 0.039100, acc: 100.00%] [G loss: 7.685629]\n",
      "epoch:44 step:34981 [D loss: 0.349146, acc: 88.28%] [G loss: 8.126948]\n",
      "epoch:44 step:34982 [D loss: 0.514875, acc: 72.66%] [G loss: 7.688205]\n",
      "epoch:44 step:34983 [D loss: 0.147336, acc: 99.22%] [G loss: 7.173073]\n",
      "epoch:44 step:34984 [D loss: 0.702676, acc: 56.25%] [G loss: 5.940372]\n",
      "epoch:44 step:34985 [D loss: 1.183586, acc: 46.88%] [G loss: 4.443866]\n",
      "epoch:44 step:34986 [D loss: 0.049452, acc: 100.00%] [G loss: 6.141797]\n",
      "epoch:44 step:34987 [D loss: 0.226847, acc: 99.22%] [G loss: 2.733432]\n",
      "epoch:44 step:34988 [D loss: 0.455967, acc: 77.34%] [G loss: 6.451107]\n",
      "epoch:44 step:34989 [D loss: 0.082258, acc: 100.00%] [G loss: 6.568182]\n",
      "epoch:44 step:34990 [D loss: 0.040171, acc: 100.00%] [G loss: 4.741674]\n",
      "epoch:44 step:34991 [D loss: 1.743009, acc: 12.50%] [G loss: 9.797253]\n",
      "epoch:44 step:34992 [D loss: 0.440868, acc: 85.16%] [G loss: 11.362950]\n",
      "epoch:44 step:34993 [D loss: 0.085113, acc: 100.00%] [G loss: 5.674219]\n",
      "epoch:44 step:34994 [D loss: 0.415090, acc: 76.56%] [G loss: 4.193328]\n",
      "epoch:44 step:34995 [D loss: 0.471606, acc: 70.31%] [G loss: 8.918818]\n",
      "epoch:44 step:34996 [D loss: 0.181661, acc: 97.66%] [G loss: 7.014071]\n",
      "epoch:44 step:34997 [D loss: 0.115621, acc: 99.22%] [G loss: 7.326340]\n",
      "epoch:44 step:34998 [D loss: 0.671791, acc: 53.91%] [G loss: 4.781261]\n",
      "epoch:44 step:34999 [D loss: 0.605744, acc: 62.50%] [G loss: 6.078579]\n",
      "epoch:44 step:35000 [D loss: 0.055980, acc: 100.00%] [G loss: 9.770422]\n",
      "epoch:44 step:35001 [D loss: 0.460723, acc: 70.31%] [G loss: 7.167588]\n",
      "epoch:44 step:35002 [D loss: 0.648391, acc: 58.59%] [G loss: 4.670665]\n",
      "epoch:44 step:35003 [D loss: 0.153629, acc: 96.09%] [G loss: 6.964958]\n",
      "epoch:44 step:35004 [D loss: 0.067252, acc: 100.00%] [G loss: 7.653802]\n",
      "epoch:44 step:35005 [D loss: 0.973573, acc: 37.50%] [G loss: 7.226052]\n",
      "epoch:44 step:35006 [D loss: 0.014930, acc: 100.00%] [G loss: 5.157761]\n",
      "epoch:44 step:35007 [D loss: 0.434531, acc: 75.00%] [G loss: 2.980458]\n",
      "epoch:44 step:35008 [D loss: 0.465842, acc: 71.09%] [G loss: 5.012823]\n",
      "epoch:44 step:35009 [D loss: 0.164907, acc: 98.44%] [G loss: 3.789661]\n",
      "epoch:44 step:35010 [D loss: 0.007894, acc: 100.00%] [G loss: 5.242949]\n",
      "epoch:44 step:35011 [D loss: 0.069546, acc: 100.00%] [G loss: 5.276312]\n",
      "epoch:44 step:35012 [D loss: 0.139113, acc: 97.66%] [G loss: 10.103515]\n",
      "epoch:44 step:35013 [D loss: 0.161012, acc: 95.31%] [G loss: 5.069388]\n",
      "epoch:44 step:35014 [D loss: 0.270221, acc: 91.41%] [G loss: 5.691333]\n",
      "epoch:44 step:35015 [D loss: 0.288761, acc: 92.19%] [G loss: 5.631718]\n",
      "epoch:44 step:35016 [D loss: 0.242718, acc: 95.31%] [G loss: 6.676659]\n",
      "epoch:44 step:35017 [D loss: 0.139161, acc: 98.44%] [G loss: 5.205616]\n",
      "epoch:44 step:35018 [D loss: 0.112977, acc: 100.00%] [G loss: 5.115764]\n",
      "epoch:44 step:35019 [D loss: 0.223897, acc: 95.31%] [G loss: 6.010722]\n",
      "epoch:44 step:35020 [D loss: 0.652651, acc: 60.94%] [G loss: 4.374010]\n",
      "epoch:44 step:35021 [D loss: 0.083575, acc: 99.22%] [G loss: 4.592431]\n",
      "epoch:44 step:35022 [D loss: 0.238184, acc: 94.53%] [G loss: 7.943654]\n",
      "epoch:44 step:35023 [D loss: 0.089264, acc: 99.22%] [G loss: 5.903312]\n",
      "epoch:44 step:35024 [D loss: 0.042638, acc: 100.00%] [G loss: 7.772910]\n",
      "epoch:44 step:35025 [D loss: 0.296628, acc: 92.97%] [G loss: 7.219765]\n",
      "epoch:44 step:35026 [D loss: 0.083519, acc: 100.00%] [G loss: 6.104944]\n",
      "epoch:44 step:35027 [D loss: 0.300559, acc: 85.94%] [G loss: 6.512123]\n",
      "epoch:44 step:35028 [D loss: 0.320827, acc: 81.25%] [G loss: 7.330607]\n",
      "epoch:44 step:35029 [D loss: 0.997636, acc: 35.94%] [G loss: 7.829276]\n",
      "epoch:44 step:35030 [D loss: 0.050014, acc: 99.22%] [G loss: 2.891316]\n",
      "epoch:44 step:35031 [D loss: 0.860425, acc: 53.91%] [G loss: 6.574697]\n",
      "epoch:44 step:35032 [D loss: 0.954729, acc: 53.91%] [G loss: 7.819520]\n",
      "epoch:44 step:35033 [D loss: 1.044645, acc: 49.22%] [G loss: 7.278172]\n",
      "epoch:44 step:35034 [D loss: 0.119871, acc: 99.22%] [G loss: 4.941006]\n",
      "epoch:44 step:35035 [D loss: 0.092395, acc: 100.00%] [G loss: 6.905139]\n",
      "epoch:44 step:35036 [D loss: 0.166911, acc: 99.22%] [G loss: 9.452131]\n",
      "epoch:44 step:35037 [D loss: 0.345142, acc: 85.16%] [G loss: 10.904676]\n",
      "epoch:44 step:35038 [D loss: 0.230818, acc: 94.53%] [G loss: 2.626576]\n",
      "epoch:44 step:35039 [D loss: 0.089969, acc: 99.22%] [G loss: 3.599658]\n",
      "epoch:44 step:35040 [D loss: 1.738374, acc: 6.25%] [G loss: 6.339462]\n",
      "epoch:44 step:35041 [D loss: 0.317481, acc: 94.53%] [G loss: 9.487651]\n",
      "epoch:44 step:35042 [D loss: 0.245889, acc: 95.31%] [G loss: 5.573613]\n",
      "epoch:44 step:35043 [D loss: 0.475891, acc: 74.22%] [G loss: 4.011199]\n",
      "epoch:44 step:35044 [D loss: 0.151509, acc: 98.44%] [G loss: 8.351294]\n",
      "epoch:44 step:35045 [D loss: 0.152527, acc: 100.00%] [G loss: 5.132541]\n",
      "epoch:44 step:35046 [D loss: 0.435080, acc: 87.50%] [G loss: 4.897767]\n",
      "epoch:44 step:35047 [D loss: 0.180334, acc: 96.88%] [G loss: 7.906781]\n",
      "epoch:44 step:35048 [D loss: 0.973949, acc: 51.56%] [G loss: 8.657800]\n",
      "epoch:44 step:35049 [D loss: 1.010107, acc: 50.78%] [G loss: 8.070320]\n",
      "epoch:44 step:35050 [D loss: 0.123173, acc: 100.00%] [G loss: 5.439863]\n",
      "epoch:44 step:35051 [D loss: 0.077565, acc: 100.00%] [G loss: 7.854278]\n",
      "epoch:44 step:35052 [D loss: 0.416213, acc: 74.22%] [G loss: 9.695311]\n",
      "epoch:44 step:35053 [D loss: 0.451841, acc: 67.97%] [G loss: 5.329475]\n",
      "epoch:44 step:35054 [D loss: 0.206762, acc: 99.22%] [G loss: 8.943344]\n",
      "epoch:44 step:35055 [D loss: 0.714904, acc: 59.38%] [G loss: 9.449738]\n",
      "epoch:44 step:35056 [D loss: 0.948862, acc: 52.34%] [G loss: 7.168688]\n",
      "epoch:44 step:35057 [D loss: 0.455599, acc: 85.94%] [G loss: 9.517665]\n",
      "epoch:44 step:35058 [D loss: 0.063251, acc: 99.22%] [G loss: 5.186495]\n",
      "epoch:44 step:35059 [D loss: 0.072610, acc: 100.00%] [G loss: 3.539351]\n",
      "epoch:44 step:35060 [D loss: 0.649981, acc: 62.50%] [G loss: 4.471563]\n",
      "epoch:44 step:35061 [D loss: 0.167715, acc: 99.22%] [G loss: 3.717043]\n",
      "epoch:44 step:35062 [D loss: 0.342119, acc: 82.81%] [G loss: 6.006149]\n",
      "epoch:44 step:35063 [D loss: 0.030056, acc: 100.00%] [G loss: 6.778077]\n",
      "epoch:44 step:35064 [D loss: 0.126933, acc: 99.22%] [G loss: 6.252132]\n",
      "epoch:44 step:35065 [D loss: 0.217241, acc: 97.66%] [G loss: 6.754406]\n",
      "epoch:44 step:35066 [D loss: 0.298818, acc: 92.19%] [G loss: 7.884088]\n",
      "epoch:44 step:35067 [D loss: 0.162246, acc: 98.44%] [G loss: 9.263008]\n",
      "epoch:44 step:35068 [D loss: 0.173911, acc: 96.88%] [G loss: 8.296151]\n",
      "epoch:44 step:35069 [D loss: 0.116452, acc: 99.22%] [G loss: 5.062755]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:35070 [D loss: 0.132257, acc: 98.44%] [G loss: 2.578055]\n",
      "epoch:44 step:35071 [D loss: 0.534190, acc: 71.09%] [G loss: 7.825360]\n",
      "epoch:44 step:35072 [D loss: 0.133271, acc: 99.22%] [G loss: 4.107248]\n",
      "epoch:44 step:35073 [D loss: 0.242583, acc: 91.41%] [G loss: 5.805225]\n",
      "epoch:44 step:35074 [D loss: 0.510165, acc: 62.50%] [G loss: 9.360569]\n",
      "epoch:44 step:35075 [D loss: 0.808978, acc: 53.91%] [G loss: 8.268679]\n",
      "epoch:44 step:35076 [D loss: 0.130288, acc: 96.88%] [G loss: 4.582916]\n",
      "epoch:44 step:35077 [D loss: 0.082602, acc: 99.22%] [G loss: 5.855492]\n",
      "epoch:44 step:35078 [D loss: 0.154794, acc: 98.44%] [G loss: 3.635284]\n",
      "epoch:44 step:35079 [D loss: 0.134543, acc: 98.44%] [G loss: 7.697023]\n",
      "epoch:44 step:35080 [D loss: 1.013920, acc: 49.22%] [G loss: 9.633300]\n",
      "epoch:44 step:35081 [D loss: 0.032978, acc: 100.00%] [G loss: 6.915163]\n",
      "epoch:44 step:35082 [D loss: 0.653184, acc: 53.91%] [G loss: 3.867680]\n",
      "epoch:44 step:35083 [D loss: 0.386721, acc: 77.34%] [G loss: 6.083897]\n",
      "epoch:44 step:35084 [D loss: 0.795816, acc: 53.12%] [G loss: 6.882817]\n",
      "epoch:44 step:35085 [D loss: 0.273530, acc: 91.41%] [G loss: 7.972463]\n",
      "epoch:44 step:35086 [D loss: 0.411982, acc: 86.72%] [G loss: 4.000912]\n",
      "epoch:44 step:35087 [D loss: 0.025669, acc: 100.00%] [G loss: 7.241728]\n",
      "epoch:44 step:35088 [D loss: 0.168771, acc: 98.44%] [G loss: 4.631059]\n",
      "epoch:44 step:35089 [D loss: 0.428783, acc: 76.56%] [G loss: 5.596793]\n",
      "epoch:44 step:35090 [D loss: 0.546423, acc: 60.94%] [G loss: 8.089460]\n",
      "epoch:44 step:35091 [D loss: 0.089034, acc: 100.00%] [G loss: 5.635843]\n",
      "epoch:44 step:35092 [D loss: 0.651141, acc: 64.06%] [G loss: 7.592305]\n",
      "epoch:44 step:35093 [D loss: 0.117194, acc: 98.44%] [G loss: 3.784644]\n",
      "epoch:44 step:35094 [D loss: 1.109044, acc: 34.38%] [G loss: 5.548023]\n",
      "epoch:44 step:35095 [D loss: 1.096138, acc: 27.34%] [G loss: 9.604950]\n",
      "epoch:44 step:35096 [D loss: 0.109971, acc: 99.22%] [G loss: 3.942976]\n",
      "epoch:44 step:35097 [D loss: 0.335070, acc: 83.59%] [G loss: 7.568423]\n",
      "epoch:44 step:35098 [D loss: 0.899338, acc: 53.12%] [G loss: 5.899546]\n",
      "epoch:44 step:35099 [D loss: 0.044833, acc: 100.00%] [G loss: 4.722022]\n",
      "epoch:44 step:35100 [D loss: 0.111515, acc: 100.00%] [G loss: 5.090027]\n",
      "epoch:44 step:35101 [D loss: 0.044653, acc: 100.00%] [G loss: 3.894381]\n",
      "epoch:44 step:35102 [D loss: 0.124084, acc: 99.22%] [G loss: 4.356929]\n",
      "epoch:44 step:35103 [D loss: 1.044635, acc: 51.56%] [G loss: 8.632144]\n",
      "epoch:44 step:35104 [D loss: 0.189232, acc: 96.88%] [G loss: 5.246810]\n",
      "epoch:44 step:35105 [D loss: 0.368935, acc: 78.12%] [G loss: 7.299236]\n",
      "epoch:44 step:35106 [D loss: 0.215610, acc: 94.53%] [G loss: 5.914486]\n",
      "epoch:44 step:35107 [D loss: 0.293437, acc: 86.72%] [G loss: 4.990389]\n",
      "epoch:44 step:35108 [D loss: 0.063224, acc: 100.00%] [G loss: 5.180560]\n",
      "epoch:44 step:35109 [D loss: 0.219623, acc: 96.09%] [G loss: 5.257567]\n",
      "epoch:44 step:35110 [D loss: 0.214380, acc: 97.66%] [G loss: 4.597481]\n",
      "epoch:44 step:35111 [D loss: 0.181049, acc: 95.31%] [G loss: 6.819553]\n",
      "epoch:44 step:35112 [D loss: 0.375437, acc: 90.62%] [G loss: 3.698192]\n",
      "epoch:44 step:35113 [D loss: 0.235657, acc: 96.09%] [G loss: 5.630277]\n",
      "epoch:44 step:35114 [D loss: 0.333449, acc: 89.06%] [G loss: 5.289454]\n",
      "epoch:44 step:35115 [D loss: 0.430646, acc: 85.16%] [G loss: 5.478759]\n",
      "epoch:44 step:35116 [D loss: 0.379223, acc: 89.06%] [G loss: 7.563594]\n",
      "epoch:44 step:35117 [D loss: 0.336095, acc: 90.62%] [G loss: 7.336777]\n",
      "epoch:44 step:35118 [D loss: 0.136846, acc: 98.44%] [G loss: 4.042976]\n",
      "epoch:44 step:35119 [D loss: 0.021633, acc: 100.00%] [G loss: 4.059349]\n",
      "epoch:44 step:35120 [D loss: 0.169081, acc: 97.66%] [G loss: 5.954723]\n",
      "epoch:44 step:35121 [D loss: 0.628131, acc: 64.06%] [G loss: 4.735945]\n",
      "epoch:44 step:35122 [D loss: 0.064595, acc: 100.00%] [G loss: 6.393110]\n",
      "epoch:44 step:35123 [D loss: 0.118313, acc: 98.44%] [G loss: 4.450858]\n",
      "epoch:44 step:35124 [D loss: 0.029669, acc: 100.00%] [G loss: 11.284153]\n",
      "epoch:44 step:35125 [D loss: 0.037543, acc: 100.00%] [G loss: 8.894555]\n",
      "epoch:44 step:35126 [D loss: 0.051308, acc: 100.00%] [G loss: 6.077291]\n",
      "epoch:44 step:35127 [D loss: 0.086207, acc: 99.22%] [G loss: 5.916985]\n",
      "epoch:44 step:35128 [D loss: 0.040832, acc: 100.00%] [G loss: 7.913465]\n",
      "epoch:44 step:35129 [D loss: 0.698695, acc: 60.16%] [G loss: 9.104019]\n",
      "epoch:44 step:35130 [D loss: 0.166290, acc: 95.31%] [G loss: 5.981006]\n",
      "epoch:44 step:35131 [D loss: 0.100485, acc: 100.00%] [G loss: 4.378281]\n",
      "epoch:44 step:35132 [D loss: 0.727974, acc: 61.72%] [G loss: 7.809536]\n",
      "epoch:44 step:35133 [D loss: 0.096360, acc: 100.00%] [G loss: 3.493826]\n",
      "epoch:44 step:35134 [D loss: 0.292317, acc: 89.84%] [G loss: 4.939795]\n",
      "epoch:44 step:35135 [D loss: 0.280063, acc: 90.62%] [G loss: 6.512990]\n",
      "epoch:44 step:35136 [D loss: 0.356978, acc: 87.50%] [G loss: 6.882297]\n",
      "epoch:44 step:35137 [D loss: 0.017685, acc: 100.00%] [G loss: 7.972097]\n",
      "epoch:44 step:35138 [D loss: 0.736166, acc: 50.78%] [G loss: 9.147825]\n",
      "epoch:44 step:35139 [D loss: 0.047132, acc: 100.00%] [G loss: 7.783972]\n",
      "epoch:44 step:35140 [D loss: 0.762808, acc: 54.69%] [G loss: 8.912900]\n",
      "epoch:44 step:35141 [D loss: 0.162229, acc: 94.53%] [G loss: 6.084778]\n",
      "epoch:44 step:35142 [D loss: 0.536077, acc: 64.06%] [G loss: 6.219355]\n",
      "epoch:44 step:35143 [D loss: 0.538736, acc: 67.19%] [G loss: 6.442118]\n",
      "epoch:44 step:35144 [D loss: 0.330683, acc: 86.72%] [G loss: 4.605518]\n",
      "epoch:44 step:35145 [D loss: 0.266471, acc: 89.06%] [G loss: 3.372097]\n",
      "epoch:45 step:35146 [D loss: 0.212566, acc: 98.44%] [G loss: 7.091754]\n",
      "epoch:45 step:35147 [D loss: 0.095130, acc: 99.22%] [G loss: 7.852602]\n",
      "epoch:45 step:35148 [D loss: 0.864922, acc: 53.91%] [G loss: 9.396749]\n",
      "epoch:45 step:35149 [D loss: 1.958795, acc: 15.62%] [G loss: 7.107815]\n",
      "epoch:45 step:35150 [D loss: 0.214660, acc: 93.75%] [G loss: 5.289392]\n",
      "epoch:45 step:35151 [D loss: 0.105835, acc: 100.00%] [G loss: 7.216741]\n",
      "epoch:45 step:35152 [D loss: 0.104322, acc: 98.44%] [G loss: 6.529366]\n",
      "epoch:45 step:35153 [D loss: 0.611384, acc: 57.03%] [G loss: 8.048838]\n",
      "epoch:45 step:35154 [D loss: 1.222726, acc: 50.78%] [G loss: 3.560778]\n",
      "epoch:45 step:35155 [D loss: 0.390974, acc: 77.34%] [G loss: 6.410110]\n",
      "epoch:45 step:35156 [D loss: 0.162446, acc: 96.88%] [G loss: 8.064140]\n",
      "epoch:45 step:35157 [D loss: 0.223990, acc: 96.09%] [G loss: 6.769388]\n",
      "epoch:45 step:35158 [D loss: 0.085041, acc: 100.00%] [G loss: 6.570340]\n",
      "epoch:45 step:35159 [D loss: 0.406436, acc: 79.69%] [G loss: 6.130804]\n",
      "epoch:45 step:35160 [D loss: 0.139657, acc: 99.22%] [G loss: 5.309282]\n",
      "epoch:45 step:35161 [D loss: 0.723629, acc: 56.25%] [G loss: 8.215453]\n",
      "epoch:45 step:35162 [D loss: 0.200080, acc: 93.75%] [G loss: 4.048322]\n",
      "epoch:45 step:35163 [D loss: 0.087292, acc: 99.22%] [G loss: 5.811429]\n",
      "epoch:45 step:35164 [D loss: 0.125876, acc: 97.66%] [G loss: 7.039658]\n",
      "epoch:45 step:35165 [D loss: 0.067050, acc: 100.00%] [G loss: 4.976006]\n",
      "epoch:45 step:35166 [D loss: 0.339575, acc: 88.28%] [G loss: 7.261769]\n",
      "epoch:45 step:35167 [D loss: 0.109067, acc: 98.44%] [G loss: 4.280507]\n",
      "epoch:45 step:35168 [D loss: 0.648268, acc: 64.84%] [G loss: 6.129557]\n",
      "epoch:45 step:35169 [D loss: 0.183521, acc: 95.31%] [G loss: 7.166428]\n",
      "epoch:45 step:35170 [D loss: 1.060451, acc: 48.44%] [G loss: 3.461517]\n",
      "epoch:45 step:35171 [D loss: 0.192308, acc: 95.31%] [G loss: 7.333168]\n",
      "epoch:45 step:35172 [D loss: 0.786976, acc: 51.56%] [G loss: 8.058725]\n",
      "epoch:45 step:35173 [D loss: 1.136369, acc: 25.00%] [G loss: 6.463258]\n",
      "epoch:45 step:35174 [D loss: 0.404246, acc: 79.69%] [G loss: 4.975780]\n",
      "epoch:45 step:35175 [D loss: 0.074991, acc: 100.00%] [G loss: 8.154351]\n",
      "epoch:45 step:35176 [D loss: 0.166161, acc: 97.66%] [G loss: 6.885809]\n",
      "epoch:45 step:35177 [D loss: 0.058576, acc: 100.00%] [G loss: 6.029732]\n",
      "epoch:45 step:35178 [D loss: 0.306818, acc: 84.38%] [G loss: 5.741043]\n",
      "epoch:45 step:35179 [D loss: 0.128354, acc: 96.88%] [G loss: 6.187695]\n",
      "epoch:45 step:35180 [D loss: 0.223007, acc: 96.09%] [G loss: 1.720267]\n",
      "epoch:45 step:35181 [D loss: 0.109487, acc: 98.44%] [G loss: 7.959756]\n",
      "epoch:45 step:35182 [D loss: 0.062073, acc: 100.00%] [G loss: 6.841372]\n",
      "epoch:45 step:35183 [D loss: 0.131601, acc: 97.66%] [G loss: 6.013007]\n",
      "epoch:45 step:35184 [D loss: 0.778793, acc: 53.91%] [G loss: 4.617138]\n",
      "epoch:45 step:35185 [D loss: 0.540899, acc: 78.91%] [G loss: 7.311443]\n",
      "epoch:45 step:35186 [D loss: 0.279111, acc: 89.06%] [G loss: 3.952662]\n",
      "epoch:45 step:35187 [D loss: 0.331390, acc: 87.50%] [G loss: 5.370418]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35188 [D loss: 0.763792, acc: 53.12%] [G loss: 6.303966]\n",
      "epoch:45 step:35189 [D loss: 0.523942, acc: 66.41%] [G loss: 6.546042]\n",
      "epoch:45 step:35190 [D loss: 0.376902, acc: 89.06%] [G loss: 4.756927]\n",
      "epoch:45 step:35191 [D loss: 0.418085, acc: 77.34%] [G loss: 6.548911]\n",
      "epoch:45 step:35192 [D loss: 0.236781, acc: 95.31%] [G loss: 6.215629]\n",
      "epoch:45 step:35193 [D loss: 0.713209, acc: 60.94%] [G loss: 6.884961]\n",
      "epoch:45 step:35194 [D loss: 0.213622, acc: 95.31%] [G loss: 3.200258]\n",
      "epoch:45 step:35195 [D loss: 1.085176, acc: 24.22%] [G loss: 5.803329]\n",
      "epoch:45 step:35196 [D loss: 0.200241, acc: 96.88%] [G loss: 6.561865]\n",
      "epoch:45 step:35197 [D loss: 0.222419, acc: 95.31%] [G loss: 5.222184]\n",
      "epoch:45 step:35198 [D loss: 0.266957, acc: 90.62%] [G loss: 9.826851]\n",
      "epoch:45 step:35199 [D loss: 0.453090, acc: 80.47%] [G loss: 4.342707]\n",
      "epoch:45 step:35200 [D loss: 0.660323, acc: 59.38%] [G loss: 6.672375]\n",
      "epoch:45 step:35201 [D loss: 0.031413, acc: 100.00%] [G loss: 6.229581]\n",
      "epoch:45 step:35202 [D loss: 0.472734, acc: 78.91%] [G loss: 8.954100]\n",
      "epoch:45 step:35203 [D loss: 0.074849, acc: 100.00%] [G loss: 2.233353]\n",
      "epoch:45 step:35204 [D loss: 0.499045, acc: 70.31%] [G loss: 7.454542]\n",
      "epoch:45 step:35205 [D loss: 0.079870, acc: 99.22%] [G loss: 5.757839]\n",
      "epoch:45 step:35206 [D loss: 0.106377, acc: 100.00%] [G loss: 4.798290]\n",
      "epoch:45 step:35207 [D loss: 0.269045, acc: 94.53%] [G loss: 4.806273]\n",
      "epoch:45 step:35208 [D loss: 0.329999, acc: 82.03%] [G loss: 5.152681]\n",
      "epoch:45 step:35209 [D loss: 1.136243, acc: 34.38%] [G loss: 7.626924]\n",
      "epoch:45 step:35210 [D loss: 0.178724, acc: 96.88%] [G loss: 4.290066]\n",
      "epoch:45 step:35211 [D loss: 0.081176, acc: 100.00%] [G loss: 3.382754]\n",
      "epoch:45 step:35212 [D loss: 0.269074, acc: 88.28%] [G loss: 9.733013]\n",
      "epoch:45 step:35213 [D loss: 0.404741, acc: 83.59%] [G loss: 7.084367]\n",
      "epoch:45 step:35214 [D loss: 0.294451, acc: 92.97%] [G loss: 8.787727]\n",
      "epoch:45 step:35215 [D loss: 0.049942, acc: 100.00%] [G loss: 7.162980]\n",
      "epoch:45 step:35216 [D loss: 0.206236, acc: 97.66%] [G loss: 2.381582]\n",
      "epoch:45 step:35217 [D loss: 0.053907, acc: 100.00%] [G loss: 4.340667]\n",
      "epoch:45 step:35218 [D loss: 0.288811, acc: 84.38%] [G loss: 7.746970]\n",
      "epoch:45 step:35219 [D loss: 1.447544, acc: 32.03%] [G loss: 6.730048]\n",
      "epoch:45 step:35220 [D loss: 0.284298, acc: 96.09%] [G loss: 4.974239]\n",
      "epoch:45 step:35221 [D loss: 0.141677, acc: 97.66%] [G loss: 6.361640]\n",
      "epoch:45 step:35222 [D loss: 0.343089, acc: 84.38%] [G loss: 3.732327]\n",
      "epoch:45 step:35223 [D loss: 0.350151, acc: 89.06%] [G loss: 5.652997]\n",
      "epoch:45 step:35224 [D loss: 0.070672, acc: 100.00%] [G loss: 7.198824]\n",
      "epoch:45 step:35225 [D loss: 0.548859, acc: 63.28%] [G loss: 5.036669]\n",
      "epoch:45 step:35226 [D loss: 0.119690, acc: 99.22%] [G loss: 5.663052]\n",
      "epoch:45 step:35227 [D loss: 0.107884, acc: 97.66%] [G loss: 7.537233]\n",
      "epoch:45 step:35228 [D loss: 1.078690, acc: 50.78%] [G loss: 7.067561]\n",
      "epoch:45 step:35229 [D loss: 0.296828, acc: 83.59%] [G loss: 5.851278]\n",
      "epoch:45 step:35230 [D loss: 0.171833, acc: 97.66%] [G loss: 4.947790]\n",
      "epoch:45 step:35231 [D loss: 0.366026, acc: 75.00%] [G loss: 5.911655]\n",
      "epoch:45 step:35232 [D loss: 1.508737, acc: 35.16%] [G loss: 6.171070]\n",
      "epoch:45 step:35233 [D loss: 0.019860, acc: 100.00%] [G loss: 9.871121]\n",
      "epoch:45 step:35234 [D loss: 0.002954, acc: 100.00%] [G loss: 7.930800]\n",
      "epoch:45 step:35235 [D loss: 0.121050, acc: 99.22%] [G loss: 6.553475]\n",
      "epoch:45 step:35236 [D loss: 0.176750, acc: 95.31%] [G loss: 3.460544]\n",
      "epoch:45 step:35237 [D loss: 0.325253, acc: 86.72%] [G loss: 9.128622]\n",
      "epoch:45 step:35238 [D loss: 0.831492, acc: 42.97%] [G loss: 5.137006]\n",
      "epoch:45 step:35239 [D loss: 1.273230, acc: 50.78%] [G loss: 6.817321]\n",
      "epoch:45 step:35240 [D loss: 1.419450, acc: 34.38%] [G loss: 8.187119]\n",
      "epoch:45 step:35241 [D loss: 0.038582, acc: 100.00%] [G loss: 8.434317]\n",
      "epoch:45 step:35242 [D loss: 0.544108, acc: 72.66%] [G loss: 6.004675]\n",
      "epoch:45 step:35243 [D loss: 0.033754, acc: 100.00%] [G loss: 6.081605]\n",
      "epoch:45 step:35244 [D loss: 0.120192, acc: 100.00%] [G loss: 4.702738]\n",
      "epoch:45 step:35245 [D loss: 0.126996, acc: 97.66%] [G loss: 5.857147]\n",
      "epoch:45 step:35246 [D loss: 1.773988, acc: 5.47%] [G loss: 5.808031]\n",
      "epoch:45 step:35247 [D loss: 0.033694, acc: 100.00%] [G loss: 5.656118]\n",
      "epoch:45 step:35248 [D loss: 0.097284, acc: 99.22%] [G loss: 4.205063]\n",
      "epoch:45 step:35249 [D loss: 0.112952, acc: 99.22%] [G loss: 5.288571]\n",
      "epoch:45 step:35250 [D loss: 0.386124, acc: 83.59%] [G loss: 8.730768]\n",
      "epoch:45 step:35251 [D loss: 0.098255, acc: 99.22%] [G loss: 3.444125]\n",
      "epoch:45 step:35252 [D loss: 0.080526, acc: 99.22%] [G loss: 3.553362]\n",
      "epoch:45 step:35253 [D loss: 0.540166, acc: 65.62%] [G loss: 7.653026]\n",
      "epoch:45 step:35254 [D loss: 0.291984, acc: 91.41%] [G loss: 4.679497]\n",
      "epoch:45 step:35255 [D loss: 1.058865, acc: 29.69%] [G loss: 6.559580]\n",
      "epoch:45 step:35256 [D loss: 0.319510, acc: 82.03%] [G loss: 4.403750]\n",
      "epoch:45 step:35257 [D loss: 0.434130, acc: 83.59%] [G loss: 4.821934]\n",
      "epoch:45 step:35258 [D loss: 0.210339, acc: 97.66%] [G loss: 5.959668]\n",
      "epoch:45 step:35259 [D loss: 0.056202, acc: 100.00%] [G loss: 6.172646]\n",
      "epoch:45 step:35260 [D loss: 0.326326, acc: 82.03%] [G loss: 4.970347]\n",
      "epoch:45 step:35261 [D loss: 0.033702, acc: 100.00%] [G loss: 8.286661]\n",
      "epoch:45 step:35262 [D loss: 0.104345, acc: 100.00%] [G loss: 5.881702]\n",
      "epoch:45 step:35263 [D loss: 0.580622, acc: 60.94%] [G loss: 7.523212]\n",
      "epoch:45 step:35264 [D loss: 0.139928, acc: 97.66%] [G loss: 5.745222]\n",
      "epoch:45 step:35265 [D loss: 0.784236, acc: 59.38%] [G loss: 8.386780]\n",
      "epoch:45 step:35266 [D loss: 0.462113, acc: 70.31%] [G loss: 8.752221]\n",
      "epoch:45 step:35267 [D loss: 0.062826, acc: 100.00%] [G loss: 8.333238]\n",
      "epoch:45 step:35268 [D loss: 0.317330, acc: 87.50%] [G loss: 6.976712]\n",
      "epoch:45 step:35269 [D loss: 0.473240, acc: 79.69%] [G loss: 6.483604]\n",
      "epoch:45 step:35270 [D loss: 0.353193, acc: 91.41%] [G loss: 5.014063]\n",
      "epoch:45 step:35271 [D loss: 0.414574, acc: 73.44%] [G loss: 4.234160]\n",
      "epoch:45 step:35272 [D loss: 0.363256, acc: 85.16%] [G loss: 5.580681]\n",
      "epoch:45 step:35273 [D loss: 0.090128, acc: 100.00%] [G loss: 7.635305]\n",
      "epoch:45 step:35274 [D loss: 0.621343, acc: 62.50%] [G loss: 2.989130]\n",
      "epoch:45 step:35275 [D loss: 0.937184, acc: 39.06%] [G loss: 7.096823]\n",
      "epoch:45 step:35276 [D loss: 0.113475, acc: 99.22%] [G loss: 4.220914]\n",
      "epoch:45 step:35277 [D loss: 0.022653, acc: 100.00%] [G loss: 8.300142]\n",
      "epoch:45 step:35278 [D loss: 0.894288, acc: 51.56%] [G loss: 5.291903]\n",
      "epoch:45 step:35279 [D loss: 0.507454, acc: 63.28%] [G loss: 8.428218]\n",
      "epoch:45 step:35280 [D loss: 0.135097, acc: 98.44%] [G loss: 8.610631]\n",
      "epoch:45 step:35281 [D loss: 0.124995, acc: 99.22%] [G loss: 3.678410]\n",
      "epoch:45 step:35282 [D loss: 0.175450, acc: 98.44%] [G loss: 4.235925]\n",
      "epoch:45 step:35283 [D loss: 0.029657, acc: 100.00%] [G loss: 8.331384]\n",
      "epoch:45 step:35284 [D loss: 0.114504, acc: 100.00%] [G loss: 4.966352]\n",
      "epoch:45 step:35285 [D loss: 0.012611, acc: 100.00%] [G loss: 4.571325]\n",
      "epoch:45 step:35286 [D loss: 0.430427, acc: 78.91%] [G loss: 4.933768]\n",
      "epoch:45 step:35287 [D loss: 0.060400, acc: 100.00%] [G loss: 5.618047]\n",
      "epoch:45 step:35288 [D loss: 0.686285, acc: 57.03%] [G loss: 7.188493]\n",
      "epoch:45 step:35289 [D loss: 0.622716, acc: 59.38%] [G loss: 6.579093]\n",
      "epoch:45 step:35290 [D loss: 0.095452, acc: 100.00%] [G loss: 6.138587]\n",
      "epoch:45 step:35291 [D loss: 0.087120, acc: 99.22%] [G loss: 2.739590]\n",
      "epoch:45 step:35292 [D loss: 0.368656, acc: 83.59%] [G loss: 5.372047]\n",
      "epoch:45 step:35293 [D loss: 0.875561, acc: 50.78%] [G loss: 6.547528]\n",
      "epoch:45 step:35294 [D loss: 0.177326, acc: 97.66%] [G loss: 5.873874]\n",
      "epoch:45 step:35295 [D loss: 0.570082, acc: 61.72%] [G loss: 5.495685]\n",
      "epoch:45 step:35296 [D loss: 0.057830, acc: 99.22%] [G loss: 5.130951]\n",
      "epoch:45 step:35297 [D loss: 0.711571, acc: 54.69%] [G loss: 6.687570]\n",
      "epoch:45 step:35298 [D loss: 0.367285, acc: 81.25%] [G loss: 7.341104]\n",
      "epoch:45 step:35299 [D loss: 0.821348, acc: 49.22%] [G loss: 6.166438]\n",
      "epoch:45 step:35300 [D loss: 0.482110, acc: 79.69%] [G loss: 5.240683]\n",
      "epoch:45 step:35301 [D loss: 0.149456, acc: 100.00%] [G loss: 3.383132]\n",
      "epoch:45 step:35302 [D loss: 0.222504, acc: 97.66%] [G loss: 7.282949]\n",
      "epoch:45 step:35303 [D loss: 0.121094, acc: 100.00%] [G loss: 4.982901]\n",
      "epoch:45 step:35304 [D loss: 0.843759, acc: 51.56%] [G loss: 7.347434]\n",
      "epoch:45 step:35305 [D loss: 0.359836, acc: 81.25%] [G loss: 4.759188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35306 [D loss: 0.079021, acc: 100.00%] [G loss: 8.139378]\n",
      "epoch:45 step:35307 [D loss: 0.174265, acc: 97.66%] [G loss: 3.101078]\n",
      "epoch:45 step:35308 [D loss: 0.077614, acc: 100.00%] [G loss: 4.343412]\n",
      "epoch:45 step:35309 [D loss: 0.181839, acc: 97.66%] [G loss: 5.807749]\n",
      "epoch:45 step:35310 [D loss: 0.142832, acc: 99.22%] [G loss: 3.160478]\n",
      "epoch:45 step:35311 [D loss: 0.705265, acc: 54.69%] [G loss: 7.972569]\n",
      "epoch:45 step:35312 [D loss: 0.801229, acc: 53.91%] [G loss: 6.948816]\n",
      "epoch:45 step:35313 [D loss: 0.233062, acc: 94.53%] [G loss: 6.234844]\n",
      "epoch:45 step:35314 [D loss: 1.009826, acc: 50.78%] [G loss: 12.158608]\n",
      "epoch:45 step:35315 [D loss: 0.078397, acc: 100.00%] [G loss: 4.783534]\n",
      "epoch:45 step:35316 [D loss: 0.969925, acc: 51.56%] [G loss: 8.210564]\n",
      "epoch:45 step:35317 [D loss: 0.187707, acc: 96.88%] [G loss: 4.709369]\n",
      "epoch:45 step:35318 [D loss: 2.271574, acc: 50.00%] [G loss: 8.104485]\n",
      "epoch:45 step:35319 [D loss: 0.144651, acc: 99.22%] [G loss: 5.069178]\n",
      "epoch:45 step:35320 [D loss: 0.091451, acc: 100.00%] [G loss: 6.357001]\n",
      "epoch:45 step:35321 [D loss: 0.676336, acc: 57.03%] [G loss: 8.131176]\n",
      "epoch:45 step:35322 [D loss: 0.158030, acc: 97.66%] [G loss: 4.691742]\n",
      "epoch:45 step:35323 [D loss: 0.400507, acc: 84.38%] [G loss: 7.421165]\n",
      "epoch:45 step:35324 [D loss: 0.084385, acc: 99.22%] [G loss: 7.008403]\n",
      "epoch:45 step:35325 [D loss: 0.287474, acc: 97.66%] [G loss: 5.204135]\n",
      "epoch:45 step:35326 [D loss: 0.200878, acc: 93.75%] [G loss: 7.160748]\n",
      "epoch:45 step:35327 [D loss: 0.296657, acc: 93.75%] [G loss: 5.781723]\n",
      "epoch:45 step:35328 [D loss: 0.171384, acc: 97.66%] [G loss: 6.164321]\n",
      "epoch:45 step:35329 [D loss: 1.302178, acc: 39.84%] [G loss: 3.348763]\n",
      "epoch:45 step:35330 [D loss: 0.084179, acc: 100.00%] [G loss: 6.790394]\n",
      "epoch:45 step:35331 [D loss: 0.094709, acc: 100.00%] [G loss: 5.590859]\n",
      "epoch:45 step:35332 [D loss: 1.009687, acc: 42.19%] [G loss: 8.728418]\n",
      "epoch:45 step:35333 [D loss: 0.089533, acc: 99.22%] [G loss: 8.356153]\n",
      "epoch:45 step:35334 [D loss: 0.147028, acc: 98.44%] [G loss: 7.217482]\n",
      "epoch:45 step:35335 [D loss: 0.154833, acc: 99.22%] [G loss: 4.344630]\n",
      "epoch:45 step:35336 [D loss: 0.146869, acc: 100.00%] [G loss: 5.992741]\n",
      "epoch:45 step:35337 [D loss: 0.813871, acc: 48.44%] [G loss: 5.566780]\n",
      "epoch:45 step:35338 [D loss: 0.766415, acc: 56.25%] [G loss: 6.344685]\n",
      "epoch:45 step:35339 [D loss: 0.044321, acc: 100.00%] [G loss: 5.999545]\n",
      "epoch:45 step:35340 [D loss: 0.364714, acc: 81.25%] [G loss: 7.997235]\n",
      "epoch:45 step:35341 [D loss: 0.072991, acc: 99.22%] [G loss: 6.034852]\n",
      "epoch:45 step:35342 [D loss: 0.651267, acc: 53.12%] [G loss: 7.857533]\n",
      "epoch:45 step:35343 [D loss: 0.030970, acc: 100.00%] [G loss: 7.152265]\n",
      "epoch:45 step:35344 [D loss: 0.229735, acc: 95.31%] [G loss: 4.461983]\n",
      "epoch:45 step:35345 [D loss: 1.042155, acc: 50.00%] [G loss: 5.351418]\n",
      "epoch:45 step:35346 [D loss: 0.340769, acc: 82.81%] [G loss: 5.106020]\n",
      "epoch:45 step:35347 [D loss: 0.396551, acc: 81.25%] [G loss: 6.223572]\n",
      "epoch:45 step:35348 [D loss: 0.429702, acc: 79.69%] [G loss: 3.951645]\n",
      "epoch:45 step:35349 [D loss: 0.154462, acc: 99.22%] [G loss: 6.667993]\n",
      "epoch:45 step:35350 [D loss: 0.094396, acc: 100.00%] [G loss: 4.668464]\n",
      "epoch:45 step:35351 [D loss: 0.670635, acc: 60.94%] [G loss: 6.379785]\n",
      "epoch:45 step:35352 [D loss: 0.150327, acc: 99.22%] [G loss: 4.225341]\n",
      "epoch:45 step:35353 [D loss: 0.324991, acc: 82.03%] [G loss: 5.095281]\n",
      "epoch:45 step:35354 [D loss: 0.148173, acc: 99.22%] [G loss: 6.452284]\n",
      "epoch:45 step:35355 [D loss: 1.225168, acc: 17.97%] [G loss: 7.215244]\n",
      "epoch:45 step:35356 [D loss: 0.280571, acc: 88.28%] [G loss: 5.189675]\n",
      "epoch:45 step:35357 [D loss: 0.321457, acc: 93.75%] [G loss: 6.694366]\n",
      "epoch:45 step:35358 [D loss: 0.034337, acc: 100.00%] [G loss: 7.902983]\n",
      "epoch:45 step:35359 [D loss: 0.108130, acc: 100.00%] [G loss: 7.395267]\n",
      "epoch:45 step:35360 [D loss: 0.316008, acc: 92.19%] [G loss: 5.897647]\n",
      "epoch:45 step:35361 [D loss: 0.283572, acc: 85.94%] [G loss: 11.167422]\n",
      "epoch:45 step:35362 [D loss: 0.154523, acc: 97.66%] [G loss: 5.071748]\n",
      "epoch:45 step:35363 [D loss: 0.084038, acc: 100.00%] [G loss: 6.936846]\n",
      "epoch:45 step:35364 [D loss: 0.073570, acc: 100.00%] [G loss: 7.917439]\n",
      "epoch:45 step:35365 [D loss: 0.698023, acc: 53.12%] [G loss: 5.693973]\n",
      "epoch:45 step:35366 [D loss: 0.402043, acc: 78.12%] [G loss: 7.590882]\n",
      "epoch:45 step:35367 [D loss: 0.845970, acc: 52.34%] [G loss: 6.374164]\n",
      "epoch:45 step:35368 [D loss: 0.214211, acc: 96.09%] [G loss: 4.618373]\n",
      "epoch:45 step:35369 [D loss: 0.697041, acc: 58.59%] [G loss: 5.935443]\n",
      "epoch:45 step:35370 [D loss: 0.143004, acc: 99.22%] [G loss: 4.040248]\n",
      "epoch:45 step:35371 [D loss: 0.710221, acc: 55.47%] [G loss: 2.849350]\n",
      "epoch:45 step:35372 [D loss: 0.045759, acc: 100.00%] [G loss: 5.842833]\n",
      "epoch:45 step:35373 [D loss: 0.835743, acc: 53.91%] [G loss: 6.672438]\n",
      "epoch:45 step:35374 [D loss: 0.461304, acc: 65.62%] [G loss: 2.556118]\n",
      "epoch:45 step:35375 [D loss: 0.088710, acc: 100.00%] [G loss: 4.418395]\n",
      "epoch:45 step:35376 [D loss: 0.247635, acc: 98.44%] [G loss: 5.958451]\n",
      "epoch:45 step:35377 [D loss: 0.106364, acc: 99.22%] [G loss: 4.255425]\n",
      "epoch:45 step:35378 [D loss: 0.408057, acc: 71.88%] [G loss: 3.508928]\n",
      "epoch:45 step:35379 [D loss: 0.329808, acc: 89.06%] [G loss: 4.710361]\n",
      "epoch:45 step:35380 [D loss: 0.811332, acc: 52.34%] [G loss: 7.386228]\n",
      "epoch:45 step:35381 [D loss: 0.647263, acc: 60.16%] [G loss: 4.529640]\n",
      "epoch:45 step:35382 [D loss: 0.274489, acc: 92.97%] [G loss: 2.228488]\n",
      "epoch:45 step:35383 [D loss: 0.929487, acc: 46.09%] [G loss: 7.637933]\n",
      "epoch:45 step:35384 [D loss: 0.899136, acc: 50.00%] [G loss: 4.333992]\n",
      "epoch:45 step:35385 [D loss: 0.319813, acc: 78.12%] [G loss: 5.989395]\n",
      "epoch:45 step:35386 [D loss: 0.362013, acc: 91.41%] [G loss: 5.372497]\n",
      "epoch:45 step:35387 [D loss: 0.061459, acc: 100.00%] [G loss: 9.015675]\n",
      "epoch:45 step:35388 [D loss: 0.044668, acc: 100.00%] [G loss: 8.252611]\n",
      "epoch:45 step:35389 [D loss: 0.062591, acc: 100.00%] [G loss: 7.805127]\n",
      "epoch:45 step:35390 [D loss: 0.021458, acc: 100.00%] [G loss: 7.300882]\n",
      "epoch:45 step:35391 [D loss: 0.355247, acc: 89.84%] [G loss: 3.148168]\n",
      "epoch:45 step:35392 [D loss: 0.168893, acc: 95.31%] [G loss: 7.006331]\n",
      "epoch:45 step:35393 [D loss: 0.614956, acc: 64.84%] [G loss: 6.693142]\n",
      "epoch:45 step:35394 [D loss: 1.477535, acc: 50.00%] [G loss: 9.230392]\n",
      "epoch:45 step:35395 [D loss: 0.041886, acc: 100.00%] [G loss: 7.520195]\n",
      "epoch:45 step:35396 [D loss: 0.045279, acc: 100.00%] [G loss: 7.065893]\n",
      "epoch:45 step:35397 [D loss: 0.677362, acc: 58.59%] [G loss: 10.055759]\n",
      "epoch:45 step:35398 [D loss: 0.442844, acc: 75.00%] [G loss: 5.005700]\n",
      "epoch:45 step:35399 [D loss: 1.333215, acc: 51.56%] [G loss: 3.264035]\n",
      "epoch:45 step:35400 [D loss: 0.038033, acc: 100.00%] [G loss: 4.029389]\n",
      "epoch:45 step:35401 [D loss: 0.162231, acc: 98.44%] [G loss: 4.667907]\n",
      "epoch:45 step:35402 [D loss: 0.233713, acc: 93.75%] [G loss: 5.221791]\n",
      "epoch:45 step:35403 [D loss: 0.137426, acc: 99.22%] [G loss: 6.083085]\n",
      "epoch:45 step:35404 [D loss: 0.236684, acc: 93.75%] [G loss: 5.328071]\n",
      "epoch:45 step:35405 [D loss: 0.097435, acc: 99.22%] [G loss: 4.648945]\n",
      "epoch:45 step:35406 [D loss: 1.122534, acc: 42.19%] [G loss: 6.568718]\n",
      "epoch:45 step:35407 [D loss: 0.304584, acc: 87.50%] [G loss: 3.658744]\n",
      "epoch:45 step:35408 [D loss: 0.737734, acc: 57.03%] [G loss: 5.623876]\n",
      "epoch:45 step:35409 [D loss: 0.228669, acc: 92.19%] [G loss: 9.461630]\n",
      "epoch:45 step:35410 [D loss: 0.100216, acc: 98.44%] [G loss: 6.996243]\n",
      "epoch:45 step:35411 [D loss: 0.436992, acc: 84.38%] [G loss: 7.316942]\n",
      "epoch:45 step:35412 [D loss: 0.121020, acc: 99.22%] [G loss: 3.912560]\n",
      "epoch:45 step:35413 [D loss: 0.259754, acc: 93.75%] [G loss: 5.581573]\n",
      "epoch:45 step:35414 [D loss: 0.719930, acc: 55.47%] [G loss: 5.797003]\n",
      "epoch:45 step:35415 [D loss: 1.162100, acc: 39.06%] [G loss: 9.401660]\n",
      "epoch:45 step:35416 [D loss: 1.477861, acc: 48.44%] [G loss: 6.986188]\n",
      "epoch:45 step:35417 [D loss: 0.214731, acc: 89.84%] [G loss: 6.552054]\n",
      "epoch:45 step:35418 [D loss: 0.031518, acc: 100.00%] [G loss: 6.670537]\n",
      "epoch:45 step:35419 [D loss: 1.877266, acc: 6.25%] [G loss: 5.187100]\n",
      "epoch:45 step:35420 [D loss: 0.445994, acc: 82.03%] [G loss: 6.158809]\n",
      "epoch:45 step:35421 [D loss: 0.286201, acc: 92.97%] [G loss: 8.140591]\n",
      "epoch:45 step:35422 [D loss: 0.733562, acc: 54.69%] [G loss: 9.370271]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35423 [D loss: 0.834443, acc: 54.69%] [G loss: 10.238614]\n",
      "epoch:45 step:35424 [D loss: 0.033601, acc: 100.00%] [G loss: 5.413936]\n",
      "epoch:45 step:35425 [D loss: 0.557887, acc: 61.72%] [G loss: 6.991408]\n",
      "epoch:45 step:35426 [D loss: 0.060565, acc: 100.00%] [G loss: 4.606756]\n",
      "epoch:45 step:35427 [D loss: 0.645374, acc: 62.50%] [G loss: 7.308675]\n",
      "epoch:45 step:35428 [D loss: 0.666124, acc: 66.41%] [G loss: 5.760571]\n",
      "epoch:45 step:35429 [D loss: 0.228160, acc: 92.19%] [G loss: 8.516358]\n",
      "epoch:45 step:35430 [D loss: 0.161162, acc: 96.09%] [G loss: 4.912955]\n",
      "epoch:45 step:35431 [D loss: 0.121496, acc: 98.44%] [G loss: 8.024280]\n",
      "epoch:45 step:35432 [D loss: 0.094663, acc: 98.44%] [G loss: 7.083455]\n",
      "epoch:45 step:35433 [D loss: 0.274319, acc: 92.19%] [G loss: 2.843336]\n",
      "epoch:45 step:35434 [D loss: 0.501705, acc: 73.44%] [G loss: 4.647719]\n",
      "epoch:45 step:35435 [D loss: 0.080006, acc: 100.00%] [G loss: 2.979138]\n",
      "epoch:45 step:35436 [D loss: 0.557675, acc: 64.84%] [G loss: 6.795624]\n",
      "epoch:45 step:35437 [D loss: 0.115267, acc: 100.00%] [G loss: 5.526696]\n",
      "epoch:45 step:35438 [D loss: 0.035471, acc: 100.00%] [G loss: 7.629946]\n",
      "epoch:45 step:35439 [D loss: 1.066351, acc: 50.78%] [G loss: 7.950908]\n",
      "epoch:45 step:35440 [D loss: 0.979864, acc: 50.78%] [G loss: 5.700681]\n",
      "epoch:45 step:35441 [D loss: 0.146015, acc: 99.22%] [G loss: 7.337024]\n",
      "epoch:45 step:35442 [D loss: 0.267751, acc: 96.88%] [G loss: 4.385882]\n",
      "epoch:45 step:35443 [D loss: 0.237770, acc: 94.53%] [G loss: 7.491959]\n",
      "epoch:45 step:35444 [D loss: 0.554132, acc: 75.00%] [G loss: 6.777838]\n",
      "epoch:45 step:35445 [D loss: 0.961214, acc: 34.38%] [G loss: 5.202097]\n",
      "epoch:45 step:35446 [D loss: 0.301159, acc: 92.19%] [G loss: 5.684228]\n",
      "epoch:45 step:35447 [D loss: 0.324074, acc: 94.53%] [G loss: 7.781877]\n",
      "epoch:45 step:35448 [D loss: 0.364084, acc: 89.06%] [G loss: 5.591829]\n",
      "epoch:45 step:35449 [D loss: 0.106827, acc: 99.22%] [G loss: 4.375240]\n",
      "epoch:45 step:35450 [D loss: 0.098331, acc: 99.22%] [G loss: 3.832946]\n",
      "epoch:45 step:35451 [D loss: 0.491993, acc: 79.69%] [G loss: 6.356300]\n",
      "epoch:45 step:35452 [D loss: 0.117882, acc: 100.00%] [G loss: 6.969714]\n",
      "epoch:45 step:35453 [D loss: 0.215865, acc: 95.31%] [G loss: 3.739249]\n",
      "epoch:45 step:35454 [D loss: 0.488476, acc: 75.78%] [G loss: 5.970001]\n",
      "epoch:45 step:35455 [D loss: 0.359211, acc: 90.62%] [G loss: 6.546421]\n",
      "epoch:45 step:35456 [D loss: 0.256631, acc: 89.06%] [G loss: 8.713036]\n",
      "epoch:45 step:35457 [D loss: 0.315583, acc: 92.97%] [G loss: 7.709636]\n",
      "epoch:45 step:35458 [D loss: 0.093844, acc: 100.00%] [G loss: 5.414779]\n",
      "epoch:45 step:35459 [D loss: 0.128881, acc: 98.44%] [G loss: 8.820627]\n",
      "epoch:45 step:35460 [D loss: 0.075245, acc: 99.22%] [G loss: 4.277463]\n",
      "epoch:45 step:35461 [D loss: 1.463002, acc: 46.09%] [G loss: 8.401915]\n",
      "epoch:45 step:35462 [D loss: 0.356508, acc: 77.34%] [G loss: 8.854122]\n",
      "epoch:45 step:35463 [D loss: 0.375204, acc: 83.59%] [G loss: 6.848061]\n",
      "epoch:45 step:35464 [D loss: 0.084390, acc: 99.22%] [G loss: 4.207635]\n",
      "epoch:45 step:35465 [D loss: 0.066434, acc: 100.00%] [G loss: 8.662736]\n",
      "epoch:45 step:35466 [D loss: 1.134246, acc: 42.19%] [G loss: 7.634592]\n",
      "epoch:45 step:35467 [D loss: 0.664605, acc: 59.38%] [G loss: 6.751418]\n",
      "epoch:45 step:35468 [D loss: 0.793966, acc: 52.34%] [G loss: 6.064926]\n",
      "epoch:45 step:35469 [D loss: 0.317986, acc: 90.62%] [G loss: 6.391009]\n",
      "epoch:45 step:35470 [D loss: 0.113744, acc: 100.00%] [G loss: 4.923271]\n",
      "epoch:45 step:35471 [D loss: 0.546971, acc: 66.41%] [G loss: 7.377635]\n",
      "epoch:45 step:35472 [D loss: 0.177483, acc: 99.22%] [G loss: 7.550807]\n",
      "epoch:45 step:35473 [D loss: 0.022070, acc: 100.00%] [G loss: 4.784075]\n",
      "epoch:45 step:35474 [D loss: 0.126393, acc: 100.00%] [G loss: 6.115635]\n",
      "epoch:45 step:35475 [D loss: 0.064653, acc: 100.00%] [G loss: 5.699597]\n",
      "epoch:45 step:35476 [D loss: 0.128842, acc: 100.00%] [G loss: 5.975022]\n",
      "epoch:45 step:35477 [D loss: 0.324690, acc: 86.72%] [G loss: 5.547170]\n",
      "epoch:45 step:35478 [D loss: 0.056207, acc: 100.00%] [G loss: 9.635427]\n",
      "epoch:45 step:35479 [D loss: 0.142070, acc: 96.09%] [G loss: 3.676207]\n",
      "epoch:45 step:35480 [D loss: 0.122319, acc: 100.00%] [G loss: 8.380877]\n",
      "epoch:45 step:35481 [D loss: 0.073530, acc: 100.00%] [G loss: 6.275711]\n",
      "epoch:45 step:35482 [D loss: 0.556840, acc: 69.53%] [G loss: 7.403539]\n",
      "epoch:45 step:35483 [D loss: 0.100868, acc: 98.44%] [G loss: 7.088134]\n",
      "epoch:45 step:35484 [D loss: 0.277203, acc: 92.19%] [G loss: 5.371781]\n",
      "epoch:45 step:35485 [D loss: 0.972579, acc: 50.00%] [G loss: 9.874190]\n",
      "epoch:45 step:35486 [D loss: 0.141968, acc: 99.22%] [G loss: 9.597166]\n",
      "epoch:45 step:35487 [D loss: 0.189105, acc: 94.53%] [G loss: 6.384724]\n",
      "epoch:45 step:35488 [D loss: 1.819983, acc: 17.97%] [G loss: 9.248386]\n",
      "epoch:45 step:35489 [D loss: 0.184823, acc: 98.44%] [G loss: 4.746438]\n",
      "epoch:45 step:35490 [D loss: 0.391359, acc: 71.88%] [G loss: 4.700489]\n",
      "epoch:45 step:35491 [D loss: 0.177353, acc: 97.66%] [G loss: 8.475862]\n",
      "epoch:45 step:35492 [D loss: 0.110376, acc: 98.44%] [G loss: 5.511560]\n",
      "epoch:45 step:35493 [D loss: 0.127891, acc: 97.66%] [G loss: 5.019816]\n",
      "epoch:45 step:35494 [D loss: 1.253949, acc: 30.47%] [G loss: 5.221367]\n",
      "epoch:45 step:35495 [D loss: 0.240991, acc: 95.31%] [G loss: 6.209076]\n",
      "epoch:45 step:35496 [D loss: 0.048555, acc: 100.00%] [G loss: 3.928924]\n",
      "epoch:45 step:35497 [D loss: 0.205012, acc: 95.31%] [G loss: 6.293234]\n",
      "epoch:45 step:35498 [D loss: 0.447223, acc: 78.12%] [G loss: 3.510839]\n",
      "epoch:45 step:35499 [D loss: 0.375674, acc: 88.28%] [G loss: 5.849871]\n",
      "epoch:45 step:35500 [D loss: 1.231444, acc: 48.44%] [G loss: 5.852349]\n",
      "epoch:45 step:35501 [D loss: 1.182065, acc: 50.00%] [G loss: 6.003402]\n",
      "epoch:45 step:35502 [D loss: 0.967712, acc: 35.16%] [G loss: 6.228445]\n",
      "epoch:45 step:35503 [D loss: 0.544330, acc: 76.56%] [G loss: 6.717494]\n",
      "epoch:45 step:35504 [D loss: 0.318944, acc: 89.84%] [G loss: 6.024640]\n",
      "epoch:45 step:35505 [D loss: 0.200288, acc: 93.75%] [G loss: 5.417828]\n",
      "epoch:45 step:35506 [D loss: 0.356801, acc: 82.81%] [G loss: 6.908461]\n",
      "epoch:45 step:35507 [D loss: 0.034875, acc: 100.00%] [G loss: 7.484703]\n",
      "epoch:45 step:35508 [D loss: 1.033585, acc: 43.75%] [G loss: 8.422261]\n",
      "epoch:45 step:35509 [D loss: 0.043813, acc: 100.00%] [G loss: 8.117263]\n",
      "epoch:45 step:35510 [D loss: 0.091218, acc: 100.00%] [G loss: 8.480503]\n",
      "epoch:45 step:35511 [D loss: 0.589742, acc: 64.84%] [G loss: 4.704328]\n",
      "epoch:45 step:35512 [D loss: 0.180743, acc: 96.88%] [G loss: 5.408987]\n",
      "epoch:45 step:35513 [D loss: 0.399792, acc: 71.09%] [G loss: 3.713032]\n",
      "epoch:45 step:35514 [D loss: 0.131062, acc: 99.22%] [G loss: 5.083265]\n",
      "epoch:45 step:35515 [D loss: 0.180829, acc: 98.44%] [G loss: 8.050406]\n",
      "epoch:45 step:35516 [D loss: 0.751640, acc: 53.12%] [G loss: 4.886601]\n",
      "epoch:45 step:35517 [D loss: 0.628864, acc: 65.62%] [G loss: 4.532233]\n",
      "epoch:45 step:35518 [D loss: 0.279394, acc: 88.28%] [G loss: 4.215945]\n",
      "epoch:45 step:35519 [D loss: 0.273826, acc: 93.75%] [G loss: 5.553345]\n",
      "epoch:45 step:35520 [D loss: 0.201870, acc: 97.66%] [G loss: 2.783676]\n",
      "epoch:45 step:35521 [D loss: 0.116645, acc: 99.22%] [G loss: 4.877084]\n",
      "epoch:45 step:35522 [D loss: 0.063443, acc: 100.00%] [G loss: 6.275837]\n",
      "epoch:45 step:35523 [D loss: 0.130002, acc: 100.00%] [G loss: 3.579704]\n",
      "epoch:45 step:35524 [D loss: 0.072113, acc: 100.00%] [G loss: 5.932781]\n",
      "epoch:45 step:35525 [D loss: 1.042999, acc: 50.78%] [G loss: 3.982181]\n",
      "epoch:45 step:35526 [D loss: 0.275640, acc: 89.06%] [G loss: 7.484933]\n",
      "epoch:45 step:35527 [D loss: 1.830706, acc: 5.47%] [G loss: 10.207377]\n",
      "epoch:45 step:35528 [D loss: 0.832729, acc: 44.53%] [G loss: 5.675898]\n",
      "epoch:45 step:35529 [D loss: 0.637245, acc: 64.06%] [G loss: 6.349910]\n",
      "epoch:45 step:35530 [D loss: 1.800755, acc: 6.25%] [G loss: 8.536820]\n",
      "epoch:45 step:35531 [D loss: 0.040052, acc: 99.22%] [G loss: 9.351947]\n",
      "epoch:45 step:35532 [D loss: 0.063214, acc: 99.22%] [G loss: 4.196831]\n",
      "epoch:45 step:35533 [D loss: 0.291908, acc: 93.75%] [G loss: 5.056557]\n",
      "epoch:45 step:35534 [D loss: 0.240172, acc: 94.53%] [G loss: 7.633195]\n",
      "epoch:45 step:35535 [D loss: 0.187284, acc: 96.88%] [G loss: 8.416771]\n",
      "epoch:45 step:35536 [D loss: 0.214723, acc: 96.09%] [G loss: 5.618801]\n",
      "epoch:45 step:35537 [D loss: 0.684925, acc: 59.38%] [G loss: 8.173471]\n",
      "epoch:45 step:35538 [D loss: 0.160834, acc: 96.88%] [G loss: 6.782405]\n",
      "epoch:45 step:35539 [D loss: 0.070788, acc: 100.00%] [G loss: 6.032013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35540 [D loss: 0.383319, acc: 85.16%] [G loss: 4.677444]\n",
      "epoch:45 step:35541 [D loss: 0.724499, acc: 56.25%] [G loss: 4.377293]\n",
      "epoch:45 step:35542 [D loss: 0.316017, acc: 85.94%] [G loss: 10.637218]\n",
      "epoch:45 step:35543 [D loss: 0.408249, acc: 75.78%] [G loss: 8.821096]\n",
      "epoch:45 step:35544 [D loss: 0.813400, acc: 52.34%] [G loss: 4.905846]\n",
      "epoch:45 step:35545 [D loss: 0.099373, acc: 100.00%] [G loss: 6.927524]\n",
      "epoch:45 step:35546 [D loss: 0.068743, acc: 100.00%] [G loss: 5.336658]\n",
      "epoch:45 step:35547 [D loss: 0.164397, acc: 97.66%] [G loss: 7.217827]\n",
      "epoch:45 step:35548 [D loss: 0.049047, acc: 100.00%] [G loss: 6.170460]\n",
      "epoch:45 step:35549 [D loss: 0.601070, acc: 71.09%] [G loss: 6.587293]\n",
      "epoch:45 step:35550 [D loss: 0.140138, acc: 97.66%] [G loss: 9.765866]\n",
      "epoch:45 step:35551 [D loss: 0.158857, acc: 98.44%] [G loss: 4.214531]\n",
      "epoch:45 step:35552 [D loss: 0.191274, acc: 98.44%] [G loss: 8.543859]\n",
      "epoch:45 step:35553 [D loss: 0.080167, acc: 100.00%] [G loss: 4.326066]\n",
      "epoch:45 step:35554 [D loss: 0.102730, acc: 100.00%] [G loss: 4.611728]\n",
      "epoch:45 step:35555 [D loss: 0.199696, acc: 96.09%] [G loss: 3.663326]\n",
      "epoch:45 step:35556 [D loss: 0.326424, acc: 83.59%] [G loss: 8.690622]\n",
      "epoch:45 step:35557 [D loss: 0.442482, acc: 71.88%] [G loss: 5.916072]\n",
      "epoch:45 step:35558 [D loss: 0.224354, acc: 97.66%] [G loss: 4.688138]\n",
      "epoch:45 step:35559 [D loss: 0.098592, acc: 100.00%] [G loss: 3.505109]\n",
      "epoch:45 step:35560 [D loss: 0.420814, acc: 85.16%] [G loss: 4.099186]\n",
      "epoch:45 step:35561 [D loss: 0.527638, acc: 75.00%] [G loss: 4.306761]\n",
      "epoch:45 step:35562 [D loss: 0.119241, acc: 100.00%] [G loss: 4.219758]\n",
      "epoch:45 step:35563 [D loss: 0.581019, acc: 67.19%] [G loss: 3.840211]\n",
      "epoch:45 step:35564 [D loss: 0.377075, acc: 77.34%] [G loss: 5.226971]\n",
      "epoch:45 step:35565 [D loss: 0.291792, acc: 96.09%] [G loss: 9.550779]\n",
      "epoch:45 step:35566 [D loss: 0.114730, acc: 99.22%] [G loss: 3.887417]\n",
      "epoch:45 step:35567 [D loss: 0.225779, acc: 92.19%] [G loss: 4.598228]\n",
      "epoch:45 step:35568 [D loss: 0.208834, acc: 98.44%] [G loss: 7.056208]\n",
      "epoch:45 step:35569 [D loss: 0.191284, acc: 97.66%] [G loss: 4.595209]\n",
      "epoch:45 step:35570 [D loss: 1.743077, acc: 22.66%] [G loss: 7.805398]\n",
      "epoch:45 step:35571 [D loss: 0.460687, acc: 70.31%] [G loss: 8.166933]\n",
      "epoch:45 step:35572 [D loss: 0.333048, acc: 91.41%] [G loss: 6.567142]\n",
      "epoch:45 step:35573 [D loss: 0.012665, acc: 100.00%] [G loss: 9.991373]\n",
      "epoch:45 step:35574 [D loss: 0.232600, acc: 93.75%] [G loss: 5.938170]\n",
      "epoch:45 step:35575 [D loss: 1.596224, acc: 7.81%] [G loss: 8.677016]\n",
      "epoch:45 step:35576 [D loss: 0.052249, acc: 100.00%] [G loss: 4.543113]\n",
      "epoch:45 step:35577 [D loss: 0.065949, acc: 100.00%] [G loss: 6.818482]\n",
      "epoch:45 step:35578 [D loss: 0.554639, acc: 64.06%] [G loss: 7.109221]\n",
      "epoch:45 step:35579 [D loss: 1.248090, acc: 50.00%] [G loss: 5.350164]\n",
      "epoch:45 step:35580 [D loss: 0.004802, acc: 100.00%] [G loss: 5.928781]\n",
      "epoch:45 step:35581 [D loss: 0.816238, acc: 53.12%] [G loss: 8.073256]\n",
      "epoch:45 step:35582 [D loss: 0.225628, acc: 92.97%] [G loss: 5.840101]\n",
      "epoch:45 step:35583 [D loss: 0.284364, acc: 94.53%] [G loss: 4.297154]\n",
      "epoch:45 step:35584 [D loss: 1.575948, acc: 2.34%] [G loss: 11.258686]\n",
      "epoch:45 step:35585 [D loss: 0.146108, acc: 97.66%] [G loss: 3.611827]\n",
      "epoch:45 step:35586 [D loss: 0.247743, acc: 94.53%] [G loss: 5.205710]\n",
      "epoch:45 step:35587 [D loss: 0.277720, acc: 88.28%] [G loss: 4.233326]\n",
      "epoch:45 step:35588 [D loss: 0.377850, acc: 79.69%] [G loss: 5.096469]\n",
      "epoch:45 step:35589 [D loss: 0.908105, acc: 50.78%] [G loss: 7.164372]\n",
      "epoch:45 step:35590 [D loss: 0.751055, acc: 55.47%] [G loss: 7.515713]\n",
      "epoch:45 step:35591 [D loss: 0.192397, acc: 97.66%] [G loss: 5.030125]\n",
      "epoch:45 step:35592 [D loss: 0.109978, acc: 100.00%] [G loss: 3.883994]\n",
      "epoch:45 step:35593 [D loss: 0.498020, acc: 75.00%] [G loss: 5.377913]\n",
      "epoch:45 step:35594 [D loss: 0.457556, acc: 77.34%] [G loss: 5.906568]\n",
      "epoch:45 step:35595 [D loss: 0.091291, acc: 100.00%] [G loss: 4.851712]\n",
      "epoch:45 step:35596 [D loss: 0.516170, acc: 77.34%] [G loss: 7.948018]\n",
      "epoch:45 step:35597 [D loss: 0.306371, acc: 93.75%] [G loss: 6.325238]\n",
      "epoch:45 step:35598 [D loss: 0.081901, acc: 100.00%] [G loss: 7.339282]\n",
      "epoch:45 step:35599 [D loss: 0.102142, acc: 99.22%] [G loss: 7.002913]\n",
      "epoch:45 step:35600 [D loss: 0.120559, acc: 98.44%] [G loss: 5.577281]\n",
      "epoch:45 step:35601 [D loss: 0.248308, acc: 96.88%] [G loss: 3.535568]\n",
      "epoch:45 step:35602 [D loss: 0.611275, acc: 57.81%] [G loss: 3.376850]\n",
      "epoch:45 step:35603 [D loss: 0.094847, acc: 100.00%] [G loss: 5.739121]\n",
      "epoch:45 step:35604 [D loss: 2.330313, acc: 50.00%] [G loss: 6.203562]\n",
      "epoch:45 step:35605 [D loss: 0.133516, acc: 97.66%] [G loss: 5.437009]\n",
      "epoch:45 step:35606 [D loss: 0.451967, acc: 66.41%] [G loss: 7.761272]\n",
      "epoch:45 step:35607 [D loss: 0.049047, acc: 100.00%] [G loss: 5.613393]\n",
      "epoch:45 step:35608 [D loss: 0.466127, acc: 68.75%] [G loss: 5.332891]\n",
      "epoch:45 step:35609 [D loss: 0.092468, acc: 100.00%] [G loss: 6.311741]\n",
      "epoch:45 step:35610 [D loss: 0.254188, acc: 89.84%] [G loss: 6.777442]\n",
      "epoch:45 step:35611 [D loss: 0.066157, acc: 100.00%] [G loss: 7.638225]\n",
      "epoch:45 step:35612 [D loss: 0.088497, acc: 100.00%] [G loss: 8.440645]\n",
      "epoch:45 step:35613 [D loss: 0.096411, acc: 98.44%] [G loss: 3.258407]\n",
      "epoch:45 step:35614 [D loss: 0.138400, acc: 99.22%] [G loss: 4.841706]\n",
      "epoch:45 step:35615 [D loss: 0.814197, acc: 51.56%] [G loss: 7.917756]\n",
      "epoch:45 step:35616 [D loss: 0.353329, acc: 81.25%] [G loss: 5.256916]\n",
      "epoch:45 step:35617 [D loss: 0.423894, acc: 78.91%] [G loss: 8.801936]\n",
      "epoch:45 step:35618 [D loss: 0.340468, acc: 93.75%] [G loss: 5.401395]\n",
      "epoch:45 step:35619 [D loss: 0.216572, acc: 94.53%] [G loss: 7.393133]\n",
      "epoch:45 step:35620 [D loss: 0.141722, acc: 97.66%] [G loss: 6.280697]\n",
      "epoch:45 step:35621 [D loss: 0.534403, acc: 60.16%] [G loss: 4.938829]\n",
      "epoch:45 step:35622 [D loss: 0.155332, acc: 98.44%] [G loss: 6.855531]\n",
      "epoch:45 step:35623 [D loss: 0.246681, acc: 96.09%] [G loss: 4.966355]\n",
      "epoch:45 step:35624 [D loss: 0.353406, acc: 85.16%] [G loss: 4.011172]\n",
      "epoch:45 step:35625 [D loss: 0.309551, acc: 93.75%] [G loss: 5.461149]\n",
      "epoch:45 step:35626 [D loss: 0.866495, acc: 57.03%] [G loss: 7.311687]\n",
      "epoch:45 step:35627 [D loss: 0.117608, acc: 97.66%] [G loss: 6.661416]\n",
      "epoch:45 step:35628 [D loss: 0.162433, acc: 99.22%] [G loss: 6.268568]\n",
      "epoch:45 step:35629 [D loss: 0.102212, acc: 100.00%] [G loss: 6.462433]\n",
      "epoch:45 step:35630 [D loss: 0.488393, acc: 71.09%] [G loss: 6.794150]\n",
      "epoch:45 step:35631 [D loss: 0.056096, acc: 100.00%] [G loss: 4.345053]\n",
      "epoch:45 step:35632 [D loss: 1.112808, acc: 20.31%] [G loss: 5.100793]\n",
      "epoch:45 step:35633 [D loss: 0.710005, acc: 59.38%] [G loss: 4.917428]\n",
      "epoch:45 step:35634 [D loss: 0.269106, acc: 91.41%] [G loss: 6.611424]\n",
      "epoch:45 step:35635 [D loss: 0.035290, acc: 100.00%] [G loss: 7.014600]\n",
      "epoch:45 step:35636 [D loss: 0.816382, acc: 53.12%] [G loss: 5.704520]\n",
      "epoch:45 step:35637 [D loss: 0.051737, acc: 100.00%] [G loss: 8.596863]\n",
      "epoch:45 step:35638 [D loss: 0.129474, acc: 100.00%] [G loss: 3.783536]\n",
      "epoch:45 step:35639 [D loss: 1.108582, acc: 52.34%] [G loss: 4.280925]\n",
      "epoch:45 step:35640 [D loss: 0.374775, acc: 79.69%] [G loss: 8.236406]\n",
      "epoch:45 step:35641 [D loss: 0.152748, acc: 97.66%] [G loss: 9.720820]\n",
      "epoch:45 step:35642 [D loss: 0.157689, acc: 99.22%] [G loss: 6.280120]\n",
      "epoch:45 step:35643 [D loss: 0.041686, acc: 100.00%] [G loss: 7.480079]\n",
      "epoch:45 step:35644 [D loss: 0.106310, acc: 99.22%] [G loss: 7.268693]\n",
      "epoch:45 step:35645 [D loss: 0.404301, acc: 87.50%] [G loss: 5.218441]\n",
      "epoch:45 step:35646 [D loss: 0.043236, acc: 100.00%] [G loss: 3.999657]\n",
      "epoch:45 step:35647 [D loss: 0.189987, acc: 98.44%] [G loss: 4.974049]\n",
      "epoch:45 step:35648 [D loss: 0.219742, acc: 100.00%] [G loss: 4.135798]\n",
      "epoch:45 step:35649 [D loss: 0.036709, acc: 100.00%] [G loss: 7.756450]\n",
      "epoch:45 step:35650 [D loss: 1.310018, acc: 48.44%] [G loss: 1.978369]\n",
      "epoch:45 step:35651 [D loss: 0.617741, acc: 60.94%] [G loss: 8.093725]\n",
      "epoch:45 step:35652 [D loss: 0.652715, acc: 64.06%] [G loss: 4.024380]\n",
      "epoch:45 step:35653 [D loss: 0.114827, acc: 100.00%] [G loss: 7.137957]\n",
      "epoch:45 step:35654 [D loss: 2.019613, acc: 7.81%] [G loss: 6.200962]\n",
      "epoch:45 step:35655 [D loss: 0.155257, acc: 96.88%] [G loss: 5.687510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35656 [D loss: 0.178374, acc: 96.88%] [G loss: 8.553087]\n",
      "epoch:45 step:35657 [D loss: 0.508195, acc: 67.19%] [G loss: 7.169453]\n",
      "epoch:45 step:35658 [D loss: 0.378441, acc: 92.97%] [G loss: 6.768233]\n",
      "epoch:45 step:35659 [D loss: 0.386862, acc: 76.56%] [G loss: 6.166837]\n",
      "epoch:45 step:35660 [D loss: 0.081666, acc: 100.00%] [G loss: 8.917263]\n",
      "epoch:45 step:35661 [D loss: 0.046172, acc: 99.22%] [G loss: 7.101836]\n",
      "epoch:45 step:35662 [D loss: 0.128136, acc: 97.66%] [G loss: 8.364635]\n",
      "epoch:45 step:35663 [D loss: 0.401186, acc: 73.44%] [G loss: 6.358806]\n",
      "epoch:45 step:35664 [D loss: 0.305919, acc: 90.62%] [G loss: 6.245378]\n",
      "epoch:45 step:35665 [D loss: 0.901672, acc: 51.56%] [G loss: 12.429956]\n",
      "epoch:45 step:35666 [D loss: 0.133285, acc: 98.44%] [G loss: 6.717132]\n",
      "epoch:45 step:35667 [D loss: 1.613136, acc: 44.53%] [G loss: 4.973680]\n",
      "epoch:45 step:35668 [D loss: 0.357293, acc: 83.59%] [G loss: 2.731444]\n",
      "epoch:45 step:35669 [D loss: 0.538091, acc: 64.06%] [G loss: 6.754575]\n",
      "epoch:45 step:35670 [D loss: 2.320279, acc: 50.00%] [G loss: 8.721106]\n",
      "epoch:45 step:35671 [D loss: 0.301450, acc: 92.97%] [G loss: 7.181220]\n",
      "epoch:45 step:35672 [D loss: 0.469705, acc: 66.41%] [G loss: 8.395973]\n",
      "epoch:45 step:35673 [D loss: 0.522570, acc: 66.41%] [G loss: 4.628746]\n",
      "epoch:45 step:35674 [D loss: 0.052509, acc: 100.00%] [G loss: 6.651541]\n",
      "epoch:45 step:35675 [D loss: 0.407359, acc: 70.31%] [G loss: 5.176147]\n",
      "epoch:45 step:35676 [D loss: 0.226810, acc: 93.75%] [G loss: 6.359322]\n",
      "epoch:45 step:35677 [D loss: 1.955135, acc: 2.34%] [G loss: 7.044941]\n",
      "epoch:45 step:35678 [D loss: 0.147838, acc: 99.22%] [G loss: 3.421349]\n",
      "epoch:45 step:35679 [D loss: 0.384927, acc: 88.28%] [G loss: 6.949263]\n",
      "epoch:45 step:35680 [D loss: 0.041413, acc: 100.00%] [G loss: 4.192451]\n",
      "epoch:45 step:35681 [D loss: 0.404290, acc: 78.12%] [G loss: 5.981402]\n",
      "epoch:45 step:35682 [D loss: 0.473019, acc: 72.66%] [G loss: 5.282654]\n",
      "epoch:45 step:35683 [D loss: 0.187560, acc: 99.22%] [G loss: 7.924596]\n",
      "epoch:45 step:35684 [D loss: 0.058548, acc: 99.22%] [G loss: 6.747905]\n",
      "epoch:45 step:35685 [D loss: 0.356982, acc: 82.03%] [G loss: 6.217449]\n",
      "epoch:45 step:35686 [D loss: 0.487691, acc: 65.62%] [G loss: 3.431038]\n",
      "epoch:45 step:35687 [D loss: 0.340939, acc: 80.47%] [G loss: 5.631743]\n",
      "epoch:45 step:35688 [D loss: 0.136286, acc: 98.44%] [G loss: 7.256375]\n",
      "epoch:45 step:35689 [D loss: 0.285276, acc: 89.06%] [G loss: 5.486776]\n",
      "epoch:45 step:35690 [D loss: 0.195333, acc: 94.53%] [G loss: 4.269350]\n",
      "epoch:45 step:35691 [D loss: 0.426520, acc: 85.16%] [G loss: 4.924957]\n",
      "epoch:45 step:35692 [D loss: 0.683281, acc: 60.16%] [G loss: 7.046208]\n",
      "epoch:45 step:35693 [D loss: 1.120410, acc: 50.78%] [G loss: 3.229645]\n",
      "epoch:45 step:35694 [D loss: 0.128976, acc: 99.22%] [G loss: 6.307836]\n",
      "epoch:45 step:35695 [D loss: 0.165760, acc: 97.66%] [G loss: 8.002291]\n",
      "epoch:45 step:35696 [D loss: 0.476330, acc: 71.09%] [G loss: 6.324363]\n",
      "epoch:45 step:35697 [D loss: 0.187429, acc: 96.09%] [G loss: 7.118158]\n",
      "epoch:45 step:35698 [D loss: 0.076745, acc: 100.00%] [G loss: 3.797802]\n",
      "epoch:45 step:35699 [D loss: 0.237674, acc: 96.88%] [G loss: 6.298230]\n",
      "epoch:45 step:35700 [D loss: 0.121491, acc: 98.44%] [G loss: 5.459151]\n",
      "epoch:45 step:35701 [D loss: 0.714484, acc: 60.94%] [G loss: 5.716423]\n",
      "epoch:45 step:35702 [D loss: 0.228665, acc: 92.97%] [G loss: 6.523973]\n",
      "epoch:45 step:35703 [D loss: 0.343198, acc: 89.84%] [G loss: 4.328287]\n",
      "epoch:45 step:35704 [D loss: 0.031924, acc: 100.00%] [G loss: 8.187674]\n",
      "epoch:45 step:35705 [D loss: 0.374727, acc: 80.47%] [G loss: 6.448815]\n",
      "epoch:45 step:35706 [D loss: 0.751502, acc: 55.47%] [G loss: 4.395927]\n",
      "epoch:45 step:35707 [D loss: 0.347766, acc: 91.41%] [G loss: 6.836457]\n",
      "epoch:45 step:35708 [D loss: 0.052054, acc: 100.00%] [G loss: 4.455637]\n",
      "epoch:45 step:35709 [D loss: 0.307764, acc: 87.50%] [G loss: 7.532726]\n",
      "epoch:45 step:35710 [D loss: 0.101881, acc: 100.00%] [G loss: 6.917416]\n",
      "epoch:45 step:35711 [D loss: 0.105256, acc: 99.22%] [G loss: 8.038984]\n",
      "epoch:45 step:35712 [D loss: 0.100601, acc: 100.00%] [G loss: 4.240664]\n",
      "epoch:45 step:35713 [D loss: 0.360970, acc: 85.94%] [G loss: 6.281232]\n",
      "epoch:45 step:35714 [D loss: 0.010967, acc: 100.00%] [G loss: 9.404149]\n",
      "epoch:45 step:35715 [D loss: 1.579196, acc: 46.09%] [G loss: 7.461904]\n",
      "epoch:45 step:35716 [D loss: 1.193891, acc: 50.78%] [G loss: 4.123703]\n",
      "epoch:45 step:35717 [D loss: 0.324916, acc: 92.19%] [G loss: 3.792178]\n",
      "epoch:45 step:35718 [D loss: 0.392590, acc: 82.03%] [G loss: 4.521414]\n",
      "epoch:45 step:35719 [D loss: 1.046253, acc: 49.22%] [G loss: 8.510383]\n",
      "epoch:45 step:35720 [D loss: 0.191227, acc: 97.66%] [G loss: 7.160751]\n",
      "epoch:45 step:35721 [D loss: 0.449103, acc: 71.88%] [G loss: 3.692626]\n",
      "epoch:45 step:35722 [D loss: 0.342694, acc: 82.81%] [G loss: 9.644710]\n",
      "epoch:45 step:35723 [D loss: 0.208012, acc: 96.09%] [G loss: 5.181771]\n",
      "epoch:45 step:35724 [D loss: 0.167986, acc: 98.44%] [G loss: 6.242237]\n",
      "epoch:45 step:35725 [D loss: 0.164028, acc: 97.66%] [G loss: 5.195197]\n",
      "epoch:45 step:35726 [D loss: 0.317747, acc: 87.50%] [G loss: 7.736098]\n",
      "epoch:45 step:35727 [D loss: 1.013167, acc: 44.53%] [G loss: 8.334514]\n",
      "epoch:45 step:35728 [D loss: 0.201677, acc: 98.44%] [G loss: 4.945867]\n",
      "epoch:45 step:35729 [D loss: 0.127482, acc: 100.00%] [G loss: 2.743373]\n",
      "epoch:45 step:35730 [D loss: 0.635477, acc: 58.59%] [G loss: 6.235887]\n",
      "epoch:45 step:35731 [D loss: 0.134243, acc: 97.66%] [G loss: 5.820662]\n",
      "epoch:45 step:35732 [D loss: 0.231141, acc: 97.66%] [G loss: 6.290622]\n",
      "epoch:45 step:35733 [D loss: 0.181682, acc: 98.44%] [G loss: 6.332399]\n",
      "epoch:45 step:35734 [D loss: 0.129755, acc: 99.22%] [G loss: 5.633537]\n",
      "epoch:45 step:35735 [D loss: 0.055738, acc: 100.00%] [G loss: 4.585566]\n",
      "epoch:45 step:35736 [D loss: 0.630199, acc: 71.09%] [G loss: 6.802335]\n",
      "epoch:45 step:35737 [D loss: 0.971437, acc: 47.66%] [G loss: 5.421901]\n",
      "epoch:45 step:35738 [D loss: 0.404117, acc: 75.00%] [G loss: 6.460894]\n",
      "epoch:45 step:35739 [D loss: 0.375356, acc: 89.84%] [G loss: 5.362606]\n",
      "epoch:45 step:35740 [D loss: 0.834432, acc: 50.78%] [G loss: 4.377920]\n",
      "epoch:45 step:35741 [D loss: 1.156656, acc: 45.31%] [G loss: 6.667120]\n",
      "epoch:45 step:35742 [D loss: 0.234848, acc: 94.53%] [G loss: 4.943746]\n",
      "epoch:45 step:35743 [D loss: 0.702878, acc: 55.47%] [G loss: 9.226451]\n",
      "epoch:45 step:35744 [D loss: 0.306598, acc: 89.84%] [G loss: 4.749664]\n",
      "epoch:45 step:35745 [D loss: 0.254689, acc: 94.53%] [G loss: 5.732309]\n",
      "epoch:45 step:35746 [D loss: 0.806433, acc: 53.91%] [G loss: 6.184036]\n",
      "epoch:45 step:35747 [D loss: 0.658726, acc: 62.50%] [G loss: 6.282324]\n",
      "epoch:45 step:35748 [D loss: 0.618793, acc: 64.06%] [G loss: 5.951147]\n",
      "epoch:45 step:35749 [D loss: 0.032614, acc: 100.00%] [G loss: 6.145260]\n",
      "epoch:45 step:35750 [D loss: 0.191842, acc: 98.44%] [G loss: 6.300878]\n",
      "epoch:45 step:35751 [D loss: 0.757314, acc: 57.03%] [G loss: 5.772802]\n",
      "epoch:45 step:35752 [D loss: 0.377054, acc: 92.19%] [G loss: 5.108945]\n",
      "epoch:45 step:35753 [D loss: 0.444086, acc: 84.38%] [G loss: 8.192160]\n",
      "epoch:45 step:35754 [D loss: 0.395696, acc: 76.56%] [G loss: 5.812140]\n",
      "epoch:45 step:35755 [D loss: 0.170794, acc: 97.66%] [G loss: 4.587700]\n",
      "epoch:45 step:35756 [D loss: 0.785478, acc: 49.22%] [G loss: 8.914812]\n",
      "epoch:45 step:35757 [D loss: 0.388812, acc: 85.94%] [G loss: 8.162110]\n",
      "epoch:45 step:35758 [D loss: 0.108406, acc: 99.22%] [G loss: 2.702100]\n",
      "epoch:45 step:35759 [D loss: 0.043905, acc: 100.00%] [G loss: 7.800641]\n",
      "epoch:45 step:35760 [D loss: 0.092478, acc: 99.22%] [G loss: 7.817068]\n",
      "epoch:45 step:35761 [D loss: 0.123704, acc: 100.00%] [G loss: 4.861813]\n",
      "epoch:45 step:35762 [D loss: 0.200236, acc: 96.09%] [G loss: 6.375690]\n",
      "epoch:45 step:35763 [D loss: 0.179445, acc: 94.53%] [G loss: 6.949779]\n",
      "epoch:45 step:35764 [D loss: 0.667649, acc: 59.38%] [G loss: 6.632698]\n",
      "epoch:45 step:35765 [D loss: 0.660714, acc: 59.38%] [G loss: 4.500620]\n",
      "epoch:45 step:35766 [D loss: 0.052879, acc: 100.00%] [G loss: 6.955644]\n",
      "epoch:45 step:35767 [D loss: 0.550250, acc: 59.38%] [G loss: 7.523453]\n",
      "epoch:45 step:35768 [D loss: 0.531578, acc: 76.56%] [G loss: 5.672677]\n",
      "epoch:45 step:35769 [D loss: 0.177997, acc: 96.88%] [G loss: 7.724554]\n",
      "epoch:45 step:35770 [D loss: 0.931630, acc: 42.97%] [G loss: 4.812462]\n",
      "epoch:45 step:35771 [D loss: 0.052781, acc: 100.00%] [G loss: 3.410878]\n",
      "epoch:45 step:35772 [D loss: 0.203433, acc: 99.22%] [G loss: 6.712821]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35773 [D loss: 0.039281, acc: 100.00%] [G loss: 5.315177]\n",
      "epoch:45 step:35774 [D loss: 0.179021, acc: 98.44%] [G loss: 8.303708]\n",
      "epoch:45 step:35775 [D loss: 0.167810, acc: 98.44%] [G loss: 4.446609]\n",
      "epoch:45 step:35776 [D loss: 0.166282, acc: 99.22%] [G loss: 5.158319]\n",
      "epoch:45 step:35777 [D loss: 0.154899, acc: 97.66%] [G loss: 7.946648]\n",
      "epoch:45 step:35778 [D loss: 1.294786, acc: 50.78%] [G loss: 4.678233]\n",
      "epoch:45 step:35779 [D loss: 0.186484, acc: 98.44%] [G loss: 7.436099]\n",
      "epoch:45 step:35780 [D loss: 0.350339, acc: 82.81%] [G loss: 5.887924]\n",
      "epoch:45 step:35781 [D loss: 0.948709, acc: 46.09%] [G loss: 8.108212]\n",
      "epoch:45 step:35782 [D loss: 0.100157, acc: 100.00%] [G loss: 2.294690]\n",
      "epoch:45 step:35783 [D loss: 0.128570, acc: 100.00%] [G loss: 2.589151]\n",
      "epoch:45 step:35784 [D loss: 0.368278, acc: 83.59%] [G loss: 9.507554]\n",
      "epoch:45 step:35785 [D loss: 0.198548, acc: 97.66%] [G loss: 6.714779]\n",
      "epoch:45 step:35786 [D loss: 0.175789, acc: 100.00%] [G loss: 9.149282]\n",
      "epoch:45 step:35787 [D loss: 0.247187, acc: 89.84%] [G loss: 9.286349]\n",
      "epoch:45 step:35788 [D loss: 0.399943, acc: 75.00%] [G loss: 5.526553]\n",
      "epoch:45 step:35789 [D loss: 0.299105, acc: 85.16%] [G loss: 6.290558]\n",
      "epoch:45 step:35790 [D loss: 0.439131, acc: 82.81%] [G loss: 6.311942]\n",
      "epoch:45 step:35791 [D loss: 0.344773, acc: 92.19%] [G loss: 3.610659]\n",
      "epoch:45 step:35792 [D loss: 0.502335, acc: 75.00%] [G loss: 6.412316]\n",
      "epoch:45 step:35793 [D loss: 0.036293, acc: 100.00%] [G loss: 8.025214]\n",
      "epoch:45 step:35794 [D loss: 1.355106, acc: 9.38%] [G loss: 5.206935]\n",
      "epoch:45 step:35795 [D loss: 0.280123, acc: 86.72%] [G loss: 3.186405]\n",
      "epoch:45 step:35796 [D loss: 0.175503, acc: 98.44%] [G loss: 7.832787]\n",
      "epoch:45 step:35797 [D loss: 0.113376, acc: 99.22%] [G loss: 2.296226]\n",
      "epoch:45 step:35798 [D loss: 0.056505, acc: 100.00%] [G loss: 5.788456]\n",
      "epoch:45 step:35799 [D loss: 0.354186, acc: 89.06%] [G loss: 2.811151]\n",
      "epoch:45 step:35800 [D loss: 0.289088, acc: 85.16%] [G loss: 4.183178]\n",
      "epoch:45 step:35801 [D loss: 0.016067, acc: 100.00%] [G loss: 8.698087]\n",
      "epoch:45 step:35802 [D loss: 0.612964, acc: 64.84%] [G loss: 7.601404]\n",
      "epoch:45 step:35803 [D loss: 0.176569, acc: 98.44%] [G loss: 5.017309]\n",
      "epoch:45 step:35804 [D loss: 0.036865, acc: 100.00%] [G loss: 4.973632]\n",
      "epoch:45 step:35805 [D loss: 0.439871, acc: 86.72%] [G loss: 6.016909]\n",
      "epoch:45 step:35806 [D loss: 0.073943, acc: 100.00%] [G loss: 7.783156]\n",
      "epoch:45 step:35807 [D loss: 0.053530, acc: 100.00%] [G loss: 2.827952]\n",
      "epoch:45 step:35808 [D loss: 0.277422, acc: 92.19%] [G loss: 5.461376]\n",
      "epoch:45 step:35809 [D loss: 0.925606, acc: 45.31%] [G loss: 7.932769]\n",
      "epoch:45 step:35810 [D loss: 0.194050, acc: 99.22%] [G loss: 7.032924]\n",
      "epoch:45 step:35811 [D loss: 0.062639, acc: 99.22%] [G loss: 3.871083]\n",
      "epoch:45 step:35812 [D loss: 0.039599, acc: 100.00%] [G loss: 6.595468]\n",
      "epoch:45 step:35813 [D loss: 0.342074, acc: 80.47%] [G loss: 7.721313]\n",
      "epoch:45 step:35814 [D loss: 0.199947, acc: 96.88%] [G loss: 6.557440]\n",
      "epoch:45 step:35815 [D loss: 0.619129, acc: 57.03%] [G loss: 6.698084]\n",
      "epoch:45 step:35816 [D loss: 0.273288, acc: 87.50%] [G loss: 10.739075]\n",
      "epoch:45 step:35817 [D loss: 0.207724, acc: 93.75%] [G loss: 4.028285]\n",
      "epoch:45 step:35818 [D loss: 0.207814, acc: 98.44%] [G loss: 5.333860]\n",
      "epoch:45 step:35819 [D loss: 1.080083, acc: 52.34%] [G loss: 8.086829]\n",
      "epoch:45 step:35820 [D loss: 0.417865, acc: 76.56%] [G loss: 5.210086]\n",
      "epoch:45 step:35821 [D loss: 0.036953, acc: 100.00%] [G loss: 3.720346]\n",
      "epoch:45 step:35822 [D loss: 0.054081, acc: 100.00%] [G loss: 5.760772]\n",
      "epoch:45 step:35823 [D loss: 1.044503, acc: 49.22%] [G loss: 8.000832]\n",
      "epoch:45 step:35824 [D loss: 0.877956, acc: 50.78%] [G loss: 5.894104]\n",
      "epoch:45 step:35825 [D loss: 0.721486, acc: 55.47%] [G loss: 7.601005]\n",
      "epoch:45 step:35826 [D loss: 0.071620, acc: 100.00%] [G loss: 3.618142]\n",
      "epoch:45 step:35827 [D loss: 0.164604, acc: 97.66%] [G loss: 5.156112]\n",
      "epoch:45 step:35828 [D loss: 0.521843, acc: 64.06%] [G loss: 7.701190]\n",
      "epoch:45 step:35829 [D loss: 0.329971, acc: 88.28%] [G loss: 5.910532]\n",
      "epoch:45 step:35830 [D loss: 0.316202, acc: 92.19%] [G loss: 3.983493]\n",
      "epoch:45 step:35831 [D loss: 0.118207, acc: 98.44%] [G loss: 3.484240]\n",
      "epoch:45 step:35832 [D loss: 0.202169, acc: 100.00%] [G loss: 5.628696]\n",
      "epoch:45 step:35833 [D loss: 0.019468, acc: 100.00%] [G loss: 6.260719]\n",
      "epoch:45 step:35834 [D loss: 0.139728, acc: 99.22%] [G loss: 5.573182]\n",
      "epoch:45 step:35835 [D loss: 0.181564, acc: 98.44%] [G loss: 7.668238]\n",
      "epoch:45 step:35836 [D loss: 0.047194, acc: 100.00%] [G loss: 4.239487]\n",
      "epoch:45 step:35837 [D loss: 0.546230, acc: 69.53%] [G loss: 6.400103]\n",
      "epoch:45 step:35838 [D loss: 0.108275, acc: 97.66%] [G loss: 6.879701]\n",
      "epoch:45 step:35839 [D loss: 0.291492, acc: 85.16%] [G loss: 6.173502]\n",
      "epoch:45 step:35840 [D loss: 0.388313, acc: 90.62%] [G loss: 3.616968]\n",
      "epoch:45 step:35841 [D loss: 0.195510, acc: 94.53%] [G loss: 4.589056]\n",
      "epoch:45 step:35842 [D loss: 0.340960, acc: 86.72%] [G loss: 4.252745]\n",
      "epoch:45 step:35843 [D loss: 0.295235, acc: 86.72%] [G loss: 5.785493]\n",
      "epoch:45 step:35844 [D loss: 0.083415, acc: 100.00%] [G loss: 4.166293]\n",
      "epoch:45 step:35845 [D loss: 0.293370, acc: 89.06%] [G loss: 4.684879]\n",
      "epoch:45 step:35846 [D loss: 0.401690, acc: 74.22%] [G loss: 5.702232]\n",
      "epoch:45 step:35847 [D loss: 0.441141, acc: 75.00%] [G loss: 4.878344]\n",
      "epoch:45 step:35848 [D loss: 0.188553, acc: 96.09%] [G loss: 3.695118]\n",
      "epoch:45 step:35849 [D loss: 0.404682, acc: 90.62%] [G loss: 4.491889]\n",
      "epoch:45 step:35850 [D loss: 0.817382, acc: 53.91%] [G loss: 9.709202]\n",
      "epoch:45 step:35851 [D loss: 0.408170, acc: 79.69%] [G loss: 7.346018]\n",
      "epoch:45 step:35852 [D loss: 0.808830, acc: 50.78%] [G loss: 8.712435]\n",
      "epoch:45 step:35853 [D loss: 0.116436, acc: 99.22%] [G loss: 5.591644]\n",
      "epoch:45 step:35854 [D loss: 0.111680, acc: 99.22%] [G loss: 3.142385]\n",
      "epoch:45 step:35855 [D loss: 2.021437, acc: 11.72%] [G loss: 8.641279]\n",
      "epoch:45 step:35856 [D loss: 0.038857, acc: 100.00%] [G loss: 4.751407]\n",
      "epoch:45 step:35857 [D loss: 0.040797, acc: 100.00%] [G loss: 6.128989]\n",
      "epoch:45 step:35858 [D loss: 0.359616, acc: 87.50%] [G loss: 5.872004]\n",
      "epoch:45 step:35859 [D loss: 0.090256, acc: 100.00%] [G loss: 6.125123]\n",
      "epoch:45 step:35860 [D loss: 0.079607, acc: 97.66%] [G loss: 5.799326]\n",
      "epoch:45 step:35861 [D loss: 0.175620, acc: 98.44%] [G loss: 10.617153]\n",
      "epoch:45 step:35862 [D loss: 0.121687, acc: 99.22%] [G loss: 3.949346]\n",
      "epoch:45 step:35863 [D loss: 0.191875, acc: 98.44%] [G loss: 3.660895]\n",
      "epoch:45 step:35864 [D loss: 0.071447, acc: 100.00%] [G loss: 6.211568]\n",
      "epoch:45 step:35865 [D loss: 1.072978, acc: 42.19%] [G loss: 5.925849]\n",
      "epoch:45 step:35866 [D loss: 0.357744, acc: 81.25%] [G loss: 4.397550]\n",
      "epoch:45 step:35867 [D loss: 0.054096, acc: 100.00%] [G loss: 7.100879]\n",
      "epoch:45 step:35868 [D loss: 0.108222, acc: 99.22%] [G loss: 6.433914]\n",
      "epoch:45 step:35869 [D loss: 0.126090, acc: 100.00%] [G loss: 6.969592]\n",
      "epoch:45 step:35870 [D loss: 0.096463, acc: 100.00%] [G loss: 3.167071]\n",
      "epoch:45 step:35871 [D loss: 0.132250, acc: 98.44%] [G loss: 6.320266]\n",
      "epoch:45 step:35872 [D loss: 0.561597, acc: 64.84%] [G loss: 7.814010]\n",
      "epoch:45 step:35873 [D loss: 0.475579, acc: 76.56%] [G loss: 6.442327]\n",
      "epoch:45 step:35874 [D loss: 0.421361, acc: 71.09%] [G loss: 4.570762]\n",
      "epoch:45 step:35875 [D loss: 0.973550, acc: 50.78%] [G loss: 4.374796]\n",
      "epoch:45 step:35876 [D loss: 0.363015, acc: 76.56%] [G loss: 5.158418]\n",
      "epoch:45 step:35877 [D loss: 0.086980, acc: 100.00%] [G loss: 3.284286]\n",
      "epoch:45 step:35878 [D loss: 0.130232, acc: 100.00%] [G loss: 7.477995]\n",
      "epoch:45 step:35879 [D loss: 1.311883, acc: 44.53%] [G loss: 3.500957]\n",
      "epoch:45 step:35880 [D loss: 0.154104, acc: 99.22%] [G loss: 6.044565]\n",
      "epoch:45 step:35881 [D loss: 0.109092, acc: 100.00%] [G loss: 6.978034]\n",
      "epoch:45 step:35882 [D loss: 0.125973, acc: 98.44%] [G loss: 6.026447]\n",
      "epoch:45 step:35883 [D loss: 0.604820, acc: 64.84%] [G loss: 4.828265]\n",
      "epoch:45 step:35884 [D loss: 0.254608, acc: 93.75%] [G loss: 6.530951]\n",
      "epoch:45 step:35885 [D loss: 0.428996, acc: 88.28%] [G loss: 7.589165]\n",
      "epoch:45 step:35886 [D loss: 0.192119, acc: 92.97%] [G loss: 4.554180]\n",
      "epoch:45 step:35887 [D loss: 0.122447, acc: 98.44%] [G loss: 5.708011]\n",
      "epoch:45 step:35888 [D loss: 0.173043, acc: 98.44%] [G loss: 3.064941]\n",
      "epoch:45 step:35889 [D loss: 0.986526, acc: 50.00%] [G loss: 7.186609]\n",
      "epoch:45 step:35890 [D loss: 0.128170, acc: 98.44%] [G loss: 10.706823]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35891 [D loss: 0.281671, acc: 85.94%] [G loss: 7.660855]\n",
      "epoch:45 step:35892 [D loss: 0.425243, acc: 78.91%] [G loss: 5.994034]\n",
      "epoch:45 step:35893 [D loss: 1.703841, acc: 50.00%] [G loss: 4.623147]\n",
      "epoch:45 step:35894 [D loss: 0.082088, acc: 100.00%] [G loss: 6.241776]\n",
      "epoch:45 step:35895 [D loss: 0.960371, acc: 50.00%] [G loss: 8.800220]\n",
      "epoch:45 step:35896 [D loss: 0.685566, acc: 57.03%] [G loss: 6.473421]\n",
      "epoch:45 step:35897 [D loss: 0.793541, acc: 54.69%] [G loss: 5.735658]\n",
      "epoch:45 step:35898 [D loss: 0.113410, acc: 99.22%] [G loss: 5.868036]\n",
      "epoch:45 step:35899 [D loss: 0.190531, acc: 97.66%] [G loss: 5.821754]\n",
      "epoch:45 step:35900 [D loss: 0.228541, acc: 97.66%] [G loss: 6.547783]\n",
      "epoch:45 step:35901 [D loss: 0.495622, acc: 67.97%] [G loss: 5.079216]\n",
      "epoch:45 step:35902 [D loss: 0.261994, acc: 90.62%] [G loss: 4.955096]\n",
      "epoch:45 step:35903 [D loss: 0.515149, acc: 69.53%] [G loss: 4.337224]\n",
      "epoch:45 step:35904 [D loss: 0.479936, acc: 78.12%] [G loss: 7.565393]\n",
      "epoch:45 step:35905 [D loss: 0.176348, acc: 97.66%] [G loss: 9.420236]\n",
      "epoch:45 step:35906 [D loss: 0.049467, acc: 99.22%] [G loss: 4.155050]\n",
      "epoch:45 step:35907 [D loss: 0.220590, acc: 92.97%] [G loss: 5.096401]\n",
      "epoch:45 step:35908 [D loss: 0.134942, acc: 100.00%] [G loss: 3.946610]\n",
      "epoch:45 step:35909 [D loss: 0.088442, acc: 99.22%] [G loss: 6.691730]\n",
      "epoch:45 step:35910 [D loss: 0.162047, acc: 96.88%] [G loss: 4.076444]\n",
      "epoch:45 step:35911 [D loss: 0.090057, acc: 99.22%] [G loss: 5.974921]\n",
      "epoch:45 step:35912 [D loss: 0.825715, acc: 51.56%] [G loss: 5.223329]\n",
      "epoch:45 step:35913 [D loss: 0.022786, acc: 100.00%] [G loss: 7.386135]\n",
      "epoch:45 step:35914 [D loss: 0.240738, acc: 92.97%] [G loss: 4.568073]\n",
      "epoch:45 step:35915 [D loss: 0.403339, acc: 82.03%] [G loss: 8.769953]\n",
      "epoch:45 step:35916 [D loss: 0.300411, acc: 86.72%] [G loss: 9.141456]\n",
      "epoch:45 step:35917 [D loss: 0.290889, acc: 85.94%] [G loss: 7.214898]\n",
      "epoch:45 step:35918 [D loss: 0.020930, acc: 100.00%] [G loss: 5.960989]\n",
      "epoch:45 step:35919 [D loss: 0.223438, acc: 92.97%] [G loss: 7.485635]\n",
      "epoch:45 step:35920 [D loss: 0.093975, acc: 99.22%] [G loss: 7.721927]\n",
      "epoch:45 step:35921 [D loss: 0.158184, acc: 98.44%] [G loss: 4.430520]\n",
      "epoch:45 step:35922 [D loss: 0.052341, acc: 100.00%] [G loss: 4.964558]\n",
      "epoch:45 step:35923 [D loss: 0.330696, acc: 96.09%] [G loss: 5.562241]\n",
      "epoch:45 step:35924 [D loss: 0.573404, acc: 58.59%] [G loss: 6.541789]\n",
      "epoch:45 step:35925 [D loss: 0.278083, acc: 88.28%] [G loss: 5.445582]\n",
      "epoch:45 step:35926 [D loss: 0.126926, acc: 100.00%] [G loss: 6.400641]\n",
      "epoch:46 step:35927 [D loss: 0.070650, acc: 100.00%] [G loss: 6.356840]\n",
      "epoch:46 step:35928 [D loss: 0.419701, acc: 86.72%] [G loss: 5.874498]\n",
      "epoch:46 step:35929 [D loss: 0.475537, acc: 82.03%] [G loss: 5.129282]\n",
      "epoch:46 step:35930 [D loss: 0.173516, acc: 98.44%] [G loss: 4.429250]\n",
      "epoch:46 step:35931 [D loss: 0.113174, acc: 100.00%] [G loss: 6.200991]\n",
      "epoch:46 step:35932 [D loss: 0.447580, acc: 73.44%] [G loss: 6.048401]\n",
      "epoch:46 step:35933 [D loss: 0.587430, acc: 61.72%] [G loss: 5.133798]\n",
      "epoch:46 step:35934 [D loss: 0.100795, acc: 99.22%] [G loss: 6.261392]\n",
      "epoch:46 step:35935 [D loss: 0.406136, acc: 85.94%] [G loss: 6.798899]\n",
      "epoch:46 step:35936 [D loss: 0.063374, acc: 100.00%] [G loss: 5.490335]\n",
      "epoch:46 step:35937 [D loss: 0.162535, acc: 98.44%] [G loss: 3.566236]\n",
      "epoch:46 step:35938 [D loss: 0.141751, acc: 98.44%] [G loss: 7.055765]\n",
      "epoch:46 step:35939 [D loss: 0.132497, acc: 99.22%] [G loss: 4.693036]\n",
      "epoch:46 step:35940 [D loss: 0.262080, acc: 94.53%] [G loss: 6.351660]\n",
      "epoch:46 step:35941 [D loss: 0.176428, acc: 98.44%] [G loss: 2.845618]\n",
      "epoch:46 step:35942 [D loss: 0.084477, acc: 100.00%] [G loss: 5.308423]\n",
      "epoch:46 step:35943 [D loss: 0.305784, acc: 85.94%] [G loss: 7.367167]\n",
      "epoch:46 step:35944 [D loss: 0.451121, acc: 83.59%] [G loss: 4.480705]\n",
      "epoch:46 step:35945 [D loss: 0.653015, acc: 57.03%] [G loss: 3.891135]\n",
      "epoch:46 step:35946 [D loss: 0.025035, acc: 100.00%] [G loss: 5.573519]\n",
      "epoch:46 step:35947 [D loss: 0.098436, acc: 100.00%] [G loss: 2.535997]\n",
      "epoch:46 step:35948 [D loss: 0.063473, acc: 99.22%] [G loss: 4.046519]\n",
      "epoch:46 step:35949 [D loss: 0.077003, acc: 100.00%] [G loss: 3.620342]\n",
      "epoch:46 step:35950 [D loss: 0.313015, acc: 92.19%] [G loss: 3.145117]\n",
      "epoch:46 step:35951 [D loss: 0.183243, acc: 99.22%] [G loss: 4.233068]\n",
      "epoch:46 step:35952 [D loss: 0.035659, acc: 100.00%] [G loss: 6.636524]\n",
      "epoch:46 step:35953 [D loss: 0.531557, acc: 67.97%] [G loss: 4.596581]\n",
      "epoch:46 step:35954 [D loss: 0.520484, acc: 64.84%] [G loss: 5.679602]\n",
      "epoch:46 step:35955 [D loss: 0.975520, acc: 50.78%] [G loss: 5.756588]\n",
      "epoch:46 step:35956 [D loss: 0.545495, acc: 60.94%] [G loss: 6.188163]\n",
      "epoch:46 step:35957 [D loss: 0.380497, acc: 76.56%] [G loss: 5.985085]\n",
      "epoch:46 step:35958 [D loss: 0.432935, acc: 71.09%] [G loss: 9.637934]\n",
      "epoch:46 step:35959 [D loss: 0.288949, acc: 92.19%] [G loss: 6.242434]\n",
      "epoch:46 step:35960 [D loss: 0.410776, acc: 80.47%] [G loss: 7.402103]\n",
      "epoch:46 step:35961 [D loss: 0.448352, acc: 75.78%] [G loss: 3.826290]\n",
      "epoch:46 step:35962 [D loss: 0.216428, acc: 94.53%] [G loss: 3.970922]\n",
      "epoch:46 step:35963 [D loss: 0.272487, acc: 92.97%] [G loss: 6.228457]\n",
      "epoch:46 step:35964 [D loss: 0.070885, acc: 99.22%] [G loss: 5.987373]\n",
      "epoch:46 step:35965 [D loss: 1.714503, acc: 9.38%] [G loss: 8.992305]\n",
      "epoch:46 step:35966 [D loss: 0.109538, acc: 99.22%] [G loss: 6.199697]\n",
      "epoch:46 step:35967 [D loss: 0.076907, acc: 100.00%] [G loss: 7.736035]\n",
      "epoch:46 step:35968 [D loss: 0.365319, acc: 88.28%] [G loss: 5.536898]\n",
      "epoch:46 step:35969 [D loss: 0.211040, acc: 98.44%] [G loss: 5.870334]\n",
      "epoch:46 step:35970 [D loss: 0.405971, acc: 85.94%] [G loss: 5.700812]\n",
      "epoch:46 step:35971 [D loss: 0.336925, acc: 87.50%] [G loss: 6.860969]\n",
      "epoch:46 step:35972 [D loss: 0.167682, acc: 97.66%] [G loss: 5.044464]\n",
      "epoch:46 step:35973 [D loss: 0.019901, acc: 100.00%] [G loss: 6.244113]\n",
      "epoch:46 step:35974 [D loss: 0.368221, acc: 78.91%] [G loss: 5.839829]\n",
      "epoch:46 step:35975 [D loss: 0.135010, acc: 97.66%] [G loss: 6.836570]\n",
      "epoch:46 step:35976 [D loss: 1.057181, acc: 43.75%] [G loss: 5.866069]\n",
      "epoch:46 step:35977 [D loss: 0.646198, acc: 64.84%] [G loss: 4.223635]\n",
      "epoch:46 step:35978 [D loss: 0.258174, acc: 96.88%] [G loss: 7.033067]\n",
      "epoch:46 step:35979 [D loss: 0.750617, acc: 54.69%] [G loss: 5.439100]\n",
      "epoch:46 step:35980 [D loss: 0.135392, acc: 96.88%] [G loss: 6.405412]\n",
      "epoch:46 step:35981 [D loss: 0.262422, acc: 89.06%] [G loss: 7.258034]\n",
      "epoch:46 step:35982 [D loss: 1.084883, acc: 28.91%] [G loss: 6.571759]\n",
      "epoch:46 step:35983 [D loss: 0.549610, acc: 71.09%] [G loss: 6.327069]\n",
      "epoch:46 step:35984 [D loss: 0.120303, acc: 99.22%] [G loss: 5.855919]\n",
      "epoch:46 step:35985 [D loss: 0.091101, acc: 99.22%] [G loss: 5.729235]\n",
      "epoch:46 step:35986 [D loss: 0.040219, acc: 100.00%] [G loss: 4.461305]\n",
      "epoch:46 step:35987 [D loss: 0.313102, acc: 87.50%] [G loss: 3.388063]\n",
      "epoch:46 step:35988 [D loss: 0.061586, acc: 100.00%] [G loss: 4.283160]\n",
      "epoch:46 step:35989 [D loss: 0.145704, acc: 97.66%] [G loss: 10.897497]\n",
      "epoch:46 step:35990 [D loss: 1.380626, acc: 17.97%] [G loss: 6.605984]\n",
      "epoch:46 step:35991 [D loss: 0.244121, acc: 91.41%] [G loss: 5.857234]\n",
      "epoch:46 step:35992 [D loss: 0.025506, acc: 100.00%] [G loss: 7.247432]\n",
      "epoch:46 step:35993 [D loss: 0.185431, acc: 97.66%] [G loss: 4.211464]\n",
      "epoch:46 step:35994 [D loss: 0.281712, acc: 94.53%] [G loss: 6.178638]\n",
      "epoch:46 step:35995 [D loss: 0.031456, acc: 100.00%] [G loss: 5.768456]\n",
      "epoch:46 step:35996 [D loss: 0.783163, acc: 50.78%] [G loss: 5.401073]\n",
      "epoch:46 step:35997 [D loss: 0.183134, acc: 95.31%] [G loss: 4.262205]\n",
      "epoch:46 step:35998 [D loss: 1.585860, acc: 49.22%] [G loss: 6.597955]\n",
      "epoch:46 step:35999 [D loss: 0.134268, acc: 98.44%] [G loss: 6.922701]\n",
      "epoch:46 step:36000 [D loss: 0.843736, acc: 53.91%] [G loss: 6.165299]\n",
      "epoch:46 step:36001 [D loss: 0.052579, acc: 100.00%] [G loss: 7.442507]\n",
      "epoch:46 step:36002 [D loss: 0.311459, acc: 85.16%] [G loss: 7.084292]\n",
      "epoch:46 step:36003 [D loss: 0.608171, acc: 71.88%] [G loss: 5.054618]\n",
      "epoch:46 step:36004 [D loss: 0.049991, acc: 100.00%] [G loss: 6.910810]\n",
      "epoch:46 step:36005 [D loss: 0.589636, acc: 64.06%] [G loss: 7.344070]\n",
      "epoch:46 step:36006 [D loss: 0.334150, acc: 82.81%] [G loss: 6.517221]\n",
      "epoch:46 step:36007 [D loss: 0.246818, acc: 95.31%] [G loss: 9.851892]\n",
      "epoch:46 step:36008 [D loss: 0.044201, acc: 99.22%] [G loss: 4.476123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36009 [D loss: 0.059257, acc: 99.22%] [G loss: 4.861402]\n",
      "epoch:46 step:36010 [D loss: 0.161117, acc: 98.44%] [G loss: 3.744067]\n",
      "epoch:46 step:36011 [D loss: 0.272958, acc: 96.88%] [G loss: 3.483907]\n",
      "epoch:46 step:36012 [D loss: 0.574966, acc: 63.28%] [G loss: 5.576329]\n",
      "epoch:46 step:36013 [D loss: 0.106935, acc: 100.00%] [G loss: 6.018907]\n",
      "epoch:46 step:36014 [D loss: 0.330911, acc: 84.38%] [G loss: 6.221879]\n",
      "epoch:46 step:36015 [D loss: 0.008727, acc: 100.00%] [G loss: 11.223299]\n",
      "epoch:46 step:36016 [D loss: 0.147549, acc: 99.22%] [G loss: 6.119634]\n",
      "epoch:46 step:36017 [D loss: 0.069661, acc: 99.22%] [G loss: 4.666131]\n",
      "epoch:46 step:36018 [D loss: 0.443584, acc: 72.66%] [G loss: 5.280052]\n",
      "epoch:46 step:36019 [D loss: 0.040853, acc: 100.00%] [G loss: 5.387806]\n",
      "epoch:46 step:36020 [D loss: 0.826199, acc: 51.56%] [G loss: 8.526132]\n",
      "epoch:46 step:36021 [D loss: 1.076484, acc: 51.56%] [G loss: 6.460648]\n",
      "epoch:46 step:36022 [D loss: 0.063825, acc: 100.00%] [G loss: 3.553135]\n",
      "epoch:46 step:36023 [D loss: 0.723969, acc: 56.25%] [G loss: 7.103035]\n",
      "epoch:46 step:36024 [D loss: 0.597353, acc: 62.50%] [G loss: 8.186178]\n",
      "epoch:46 step:36025 [D loss: 0.886053, acc: 36.72%] [G loss: 7.630558]\n",
      "epoch:46 step:36026 [D loss: 0.193734, acc: 96.09%] [G loss: 4.920043]\n",
      "epoch:46 step:36027 [D loss: 0.273652, acc: 89.06%] [G loss: 8.927372]\n",
      "epoch:46 step:36028 [D loss: 0.546613, acc: 65.62%] [G loss: 5.905468]\n",
      "epoch:46 step:36029 [D loss: 0.953408, acc: 53.91%] [G loss: 2.221319]\n",
      "epoch:46 step:36030 [D loss: 0.234164, acc: 89.06%] [G loss: 2.385267]\n",
      "epoch:46 step:36031 [D loss: 0.190329, acc: 97.66%] [G loss: 6.335297]\n",
      "epoch:46 step:36032 [D loss: 0.130611, acc: 98.44%] [G loss: 3.841583]\n",
      "epoch:46 step:36033 [D loss: 0.133398, acc: 99.22%] [G loss: 5.724893]\n",
      "epoch:46 step:36034 [D loss: 0.065870, acc: 100.00%] [G loss: 4.302672]\n",
      "epoch:46 step:36035 [D loss: 0.285920, acc: 92.19%] [G loss: 4.530933]\n",
      "epoch:46 step:36036 [D loss: 0.167884, acc: 99.22%] [G loss: 4.702568]\n",
      "epoch:46 step:36037 [D loss: 0.437878, acc: 83.59%] [G loss: 4.217547]\n",
      "epoch:46 step:36038 [D loss: 0.106071, acc: 100.00%] [G loss: 5.113965]\n",
      "epoch:46 step:36039 [D loss: 0.267155, acc: 96.09%] [G loss: 4.261415]\n",
      "epoch:46 step:36040 [D loss: 0.067719, acc: 100.00%] [G loss: 2.800328]\n",
      "epoch:46 step:36041 [D loss: 0.317141, acc: 80.47%] [G loss: 6.102143]\n",
      "epoch:46 step:36042 [D loss: 0.700839, acc: 61.72%] [G loss: 7.986234]\n",
      "epoch:46 step:36043 [D loss: 0.111406, acc: 98.44%] [G loss: 5.118189]\n",
      "epoch:46 step:36044 [D loss: 0.373447, acc: 78.12%] [G loss: 6.061593]\n",
      "epoch:46 step:36045 [D loss: 0.130524, acc: 97.66%] [G loss: 7.352477]\n",
      "epoch:46 step:36046 [D loss: 0.165325, acc: 98.44%] [G loss: 9.120935]\n",
      "epoch:46 step:36047 [D loss: 0.432840, acc: 89.06%] [G loss: 4.135472]\n",
      "epoch:46 step:36048 [D loss: 0.028307, acc: 100.00%] [G loss: 7.095746]\n",
      "epoch:46 step:36049 [D loss: 0.210594, acc: 97.66%] [G loss: 3.331138]\n",
      "epoch:46 step:36050 [D loss: 0.101315, acc: 99.22%] [G loss: 7.882922]\n",
      "epoch:46 step:36051 [D loss: 0.190910, acc: 96.09%] [G loss: 4.838955]\n",
      "epoch:46 step:36052 [D loss: 0.540938, acc: 73.44%] [G loss: 6.388258]\n",
      "epoch:46 step:36053 [D loss: 0.288377, acc: 87.50%] [G loss: 3.455045]\n",
      "epoch:46 step:36054 [D loss: 0.080693, acc: 100.00%] [G loss: 7.982606]\n",
      "epoch:46 step:36055 [D loss: 1.483755, acc: 46.09%] [G loss: 8.125900]\n",
      "epoch:46 step:36056 [D loss: 0.100068, acc: 99.22%] [G loss: 6.521981]\n",
      "epoch:46 step:36057 [D loss: 0.866839, acc: 52.34%] [G loss: 6.215460]\n",
      "epoch:46 step:36058 [D loss: 0.274700, acc: 92.19%] [G loss: 6.968760]\n",
      "epoch:46 step:36059 [D loss: 0.326649, acc: 90.62%] [G loss: 7.527951]\n",
      "epoch:46 step:36060 [D loss: 0.053006, acc: 100.00%] [G loss: 7.207099]\n",
      "epoch:46 step:36061 [D loss: 0.110894, acc: 99.22%] [G loss: 3.108239]\n",
      "epoch:46 step:36062 [D loss: 0.110840, acc: 99.22%] [G loss: 4.968873]\n",
      "epoch:46 step:36063 [D loss: 0.124741, acc: 99.22%] [G loss: 5.216153]\n",
      "epoch:46 step:36064 [D loss: 0.256544, acc: 87.50%] [G loss: 3.561269]\n",
      "epoch:46 step:36065 [D loss: 0.356371, acc: 79.69%] [G loss: 4.294674]\n",
      "epoch:46 step:36066 [D loss: 0.158849, acc: 99.22%] [G loss: 2.879341]\n",
      "epoch:46 step:36067 [D loss: 0.134750, acc: 97.66%] [G loss: 4.453892]\n",
      "epoch:46 step:36068 [D loss: 0.349463, acc: 85.16%] [G loss: 5.592463]\n",
      "epoch:46 step:36069 [D loss: 0.513603, acc: 71.09%] [G loss: 6.272960]\n",
      "epoch:46 step:36070 [D loss: 0.315160, acc: 89.84%] [G loss: 3.978216]\n",
      "epoch:46 step:36071 [D loss: 0.188898, acc: 100.00%] [G loss: 5.121920]\n",
      "epoch:46 step:36072 [D loss: 0.138088, acc: 99.22%] [G loss: 3.728984]\n",
      "epoch:46 step:36073 [D loss: 0.082281, acc: 100.00%] [G loss: 5.376830]\n",
      "epoch:46 step:36074 [D loss: 0.166714, acc: 96.88%] [G loss: 6.009881]\n",
      "epoch:46 step:36075 [D loss: 0.381951, acc: 91.41%] [G loss: 5.917111]\n",
      "epoch:46 step:36076 [D loss: 0.033762, acc: 100.00%] [G loss: 5.415837]\n",
      "epoch:46 step:36077 [D loss: 1.038735, acc: 29.69%] [G loss: 9.364208]\n",
      "epoch:46 step:36078 [D loss: 0.097787, acc: 100.00%] [G loss: 8.542385]\n",
      "epoch:46 step:36079 [D loss: 0.132001, acc: 97.66%] [G loss: 6.079744]\n",
      "epoch:46 step:36080 [D loss: 0.862526, acc: 53.12%] [G loss: 7.159699]\n",
      "epoch:46 step:36081 [D loss: 0.495177, acc: 69.53%] [G loss: 8.402391]\n",
      "epoch:46 step:36082 [D loss: 0.202784, acc: 96.88%] [G loss: 5.371438]\n",
      "epoch:46 step:36083 [D loss: 0.096408, acc: 98.44%] [G loss: 3.856690]\n",
      "epoch:46 step:36084 [D loss: 0.171378, acc: 97.66%] [G loss: 4.958489]\n",
      "epoch:46 step:36085 [D loss: 0.640017, acc: 60.94%] [G loss: 8.107639]\n",
      "epoch:46 step:36086 [D loss: 0.279481, acc: 89.06%] [G loss: 7.129520]\n",
      "epoch:46 step:36087 [D loss: 0.500406, acc: 75.00%] [G loss: 7.320144]\n",
      "epoch:46 step:36088 [D loss: 0.742855, acc: 54.69%] [G loss: 5.940329]\n",
      "epoch:46 step:36089 [D loss: 0.058185, acc: 100.00%] [G loss: 5.668142]\n",
      "epoch:46 step:36090 [D loss: 0.632337, acc: 60.94%] [G loss: 7.040353]\n",
      "epoch:46 step:36091 [D loss: 0.430093, acc: 88.28%] [G loss: 5.530470]\n",
      "epoch:46 step:36092 [D loss: 0.507789, acc: 74.22%] [G loss: 5.016492]\n",
      "epoch:46 step:36093 [D loss: 0.205765, acc: 92.19%] [G loss: 7.992211]\n",
      "epoch:46 step:36094 [D loss: 0.707032, acc: 57.81%] [G loss: 7.397912]\n",
      "epoch:46 step:36095 [D loss: 0.017708, acc: 100.00%] [G loss: 6.406309]\n",
      "epoch:46 step:36096 [D loss: 0.013907, acc: 100.00%] [G loss: 4.977115]\n",
      "epoch:46 step:36097 [D loss: 0.238582, acc: 93.75%] [G loss: 6.677001]\n",
      "epoch:46 step:36098 [D loss: 0.215967, acc: 93.75%] [G loss: 7.436808]\n",
      "epoch:46 step:36099 [D loss: 0.105416, acc: 100.00%] [G loss: 5.217580]\n",
      "epoch:46 step:36100 [D loss: 0.089781, acc: 100.00%] [G loss: 4.559685]\n",
      "epoch:46 step:36101 [D loss: 0.254791, acc: 94.53%] [G loss: 7.598114]\n",
      "epoch:46 step:36102 [D loss: 0.065848, acc: 100.00%] [G loss: 4.515865]\n",
      "epoch:46 step:36103 [D loss: 0.622539, acc: 63.28%] [G loss: 3.414149]\n",
      "epoch:46 step:36104 [D loss: 0.546051, acc: 69.53%] [G loss: 8.579189]\n",
      "epoch:46 step:36105 [D loss: 0.409281, acc: 79.69%] [G loss: 5.038120]\n",
      "epoch:46 step:36106 [D loss: 0.480563, acc: 75.78%] [G loss: 5.070609]\n",
      "epoch:46 step:36107 [D loss: 0.719396, acc: 57.03%] [G loss: 5.694116]\n",
      "epoch:46 step:36108 [D loss: 0.431722, acc: 78.91%] [G loss: 6.016764]\n",
      "epoch:46 step:36109 [D loss: 0.196219, acc: 96.09%] [G loss: 8.001856]\n",
      "epoch:46 step:36110 [D loss: 0.295136, acc: 87.50%] [G loss: 11.604402]\n",
      "epoch:46 step:36111 [D loss: 0.367720, acc: 83.59%] [G loss: 6.461560]\n",
      "epoch:46 step:36112 [D loss: 0.277252, acc: 88.28%] [G loss: 6.944677]\n",
      "epoch:46 step:36113 [D loss: 0.032137, acc: 100.00%] [G loss: 6.903163]\n",
      "epoch:46 step:36114 [D loss: 0.299181, acc: 85.16%] [G loss: 4.735988]\n",
      "epoch:46 step:36115 [D loss: 0.050883, acc: 100.00%] [G loss: 9.436273]\n",
      "epoch:46 step:36116 [D loss: 0.105752, acc: 98.44%] [G loss: 5.437627]\n",
      "epoch:46 step:36117 [D loss: 0.575599, acc: 70.31%] [G loss: 5.533581]\n",
      "epoch:46 step:36118 [D loss: 0.047010, acc: 100.00%] [G loss: 7.743524]\n",
      "epoch:46 step:36119 [D loss: 0.053528, acc: 99.22%] [G loss: 5.150763]\n",
      "epoch:46 step:36120 [D loss: 0.105072, acc: 100.00%] [G loss: 6.448481]\n",
      "epoch:46 step:36121 [D loss: 0.349775, acc: 78.91%] [G loss: 3.346396]\n",
      "epoch:46 step:36122 [D loss: 0.952533, acc: 50.00%] [G loss: 7.617485]\n",
      "epoch:46 step:36123 [D loss: 0.082057, acc: 100.00%] [G loss: 7.364871]\n",
      "epoch:46 step:36124 [D loss: 0.189701, acc: 97.66%] [G loss: 5.462462]\n",
      "epoch:46 step:36125 [D loss: 0.022979, acc: 100.00%] [G loss: 5.981379]\n",
      "epoch:46 step:36126 [D loss: 0.226946, acc: 92.19%] [G loss: 6.727382]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36127 [D loss: 0.596692, acc: 63.28%] [G loss: 6.611331]\n",
      "epoch:46 step:36128 [D loss: 0.248585, acc: 93.75%] [G loss: 5.277168]\n",
      "epoch:46 step:36129 [D loss: 0.354972, acc: 80.47%] [G loss: 5.915303]\n",
      "epoch:46 step:36130 [D loss: 0.658696, acc: 62.50%] [G loss: 2.328025]\n",
      "epoch:46 step:36131 [D loss: 0.081104, acc: 100.00%] [G loss: 3.780209]\n",
      "epoch:46 step:36132 [D loss: 0.099362, acc: 100.00%] [G loss: 5.260276]\n",
      "epoch:46 step:36133 [D loss: 0.413226, acc: 85.16%] [G loss: 5.422117]\n",
      "epoch:46 step:36134 [D loss: 0.062104, acc: 99.22%] [G loss: 5.923707]\n",
      "epoch:46 step:36135 [D loss: 0.176118, acc: 99.22%] [G loss: 6.781370]\n",
      "epoch:46 step:36136 [D loss: 0.032845, acc: 100.00%] [G loss: 6.321184]\n",
      "epoch:46 step:36137 [D loss: 2.374119, acc: 0.78%] [G loss: 9.828897]\n",
      "epoch:46 step:36138 [D loss: 0.041566, acc: 100.00%] [G loss: 4.170836]\n",
      "epoch:46 step:36139 [D loss: 0.029131, acc: 100.00%] [G loss: 6.314516]\n",
      "epoch:46 step:36140 [D loss: 0.618214, acc: 59.38%] [G loss: 4.684144]\n",
      "epoch:46 step:36141 [D loss: 0.475545, acc: 75.00%] [G loss: 5.111437]\n",
      "epoch:46 step:36142 [D loss: 0.478480, acc: 78.12%] [G loss: 9.307995]\n",
      "epoch:46 step:36143 [D loss: 0.438333, acc: 68.75%] [G loss: 7.795553]\n",
      "epoch:46 step:36144 [D loss: 0.192421, acc: 95.31%] [G loss: 6.760609]\n",
      "epoch:46 step:36145 [D loss: 0.398255, acc: 74.22%] [G loss: 5.296965]\n",
      "epoch:46 step:36146 [D loss: 0.021457, acc: 100.00%] [G loss: 4.602277]\n",
      "epoch:46 step:36147 [D loss: 0.273866, acc: 90.62%] [G loss: 9.062050]\n",
      "epoch:46 step:36148 [D loss: 0.386879, acc: 83.59%] [G loss: 6.532880]\n",
      "epoch:46 step:36149 [D loss: 0.176789, acc: 96.88%] [G loss: 4.681643]\n",
      "epoch:46 step:36150 [D loss: 1.658596, acc: 50.00%] [G loss: 7.155942]\n",
      "epoch:46 step:36151 [D loss: 0.352627, acc: 89.84%] [G loss: 4.590884]\n",
      "epoch:46 step:36152 [D loss: 0.206406, acc: 93.75%] [G loss: 6.462762]\n",
      "epoch:46 step:36153 [D loss: 0.357023, acc: 80.47%] [G loss: 7.851810]\n",
      "epoch:46 step:36154 [D loss: 0.010642, acc: 100.00%] [G loss: 8.505199]\n",
      "epoch:46 step:36155 [D loss: 0.125847, acc: 99.22%] [G loss: 6.325115]\n",
      "epoch:46 step:36156 [D loss: 0.175679, acc: 97.66%] [G loss: 3.020248]\n",
      "epoch:46 step:36157 [D loss: 0.023969, acc: 100.00%] [G loss: 7.768248]\n",
      "epoch:46 step:36158 [D loss: 0.529499, acc: 67.97%] [G loss: 7.666248]\n",
      "epoch:46 step:36159 [D loss: 0.086012, acc: 99.22%] [G loss: 6.788810]\n",
      "epoch:46 step:36160 [D loss: 0.370503, acc: 80.47%] [G loss: 8.340834]\n",
      "epoch:46 step:36161 [D loss: 0.708496, acc: 55.47%] [G loss: 3.662741]\n",
      "epoch:46 step:36162 [D loss: 0.009297, acc: 100.00%] [G loss: 8.501774]\n",
      "epoch:46 step:36163 [D loss: 0.634305, acc: 63.28%] [G loss: 4.358588]\n",
      "epoch:46 step:36164 [D loss: 0.531286, acc: 71.88%] [G loss: 5.341319]\n",
      "epoch:46 step:36165 [D loss: 0.336459, acc: 95.31%] [G loss: 4.121495]\n",
      "epoch:46 step:36166 [D loss: 0.142404, acc: 98.44%] [G loss: 6.129105]\n",
      "epoch:46 step:36167 [D loss: 0.298276, acc: 85.94%] [G loss: 6.338267]\n",
      "epoch:46 step:36168 [D loss: 0.237698, acc: 95.31%] [G loss: 7.322056]\n",
      "epoch:46 step:36169 [D loss: 0.074909, acc: 100.00%] [G loss: 7.928592]\n",
      "epoch:46 step:36170 [D loss: 0.238969, acc: 98.44%] [G loss: 7.116602]\n",
      "epoch:46 step:36171 [D loss: 0.156841, acc: 98.44%] [G loss: 5.518961]\n",
      "epoch:46 step:36172 [D loss: 0.797698, acc: 54.69%] [G loss: 5.354206]\n",
      "epoch:46 step:36173 [D loss: 0.075992, acc: 100.00%] [G loss: 3.192295]\n",
      "epoch:46 step:36174 [D loss: 0.432236, acc: 81.25%] [G loss: 7.350242]\n",
      "epoch:46 step:36175 [D loss: 0.042140, acc: 100.00%] [G loss: 6.179843]\n",
      "epoch:46 step:36176 [D loss: 0.109484, acc: 100.00%] [G loss: 7.341601]\n",
      "epoch:46 step:36177 [D loss: 0.483405, acc: 71.88%] [G loss: 6.044786]\n",
      "epoch:46 step:36178 [D loss: 0.554384, acc: 65.62%] [G loss: 6.939785]\n",
      "epoch:46 step:36179 [D loss: 0.439927, acc: 80.47%] [G loss: 4.451439]\n",
      "epoch:46 step:36180 [D loss: 0.324163, acc: 92.97%] [G loss: 7.822543]\n",
      "epoch:46 step:36181 [D loss: 0.048849, acc: 100.00%] [G loss: 7.492838]\n",
      "epoch:46 step:36182 [D loss: 0.419399, acc: 69.53%] [G loss: 7.556808]\n",
      "epoch:46 step:36183 [D loss: 0.369927, acc: 90.62%] [G loss: 4.876356]\n",
      "epoch:46 step:36184 [D loss: 0.159936, acc: 97.66%] [G loss: 6.014708]\n",
      "epoch:46 step:36185 [D loss: 0.339030, acc: 84.38%] [G loss: 6.441542]\n",
      "epoch:46 step:36186 [D loss: 0.027026, acc: 100.00%] [G loss: 5.464153]\n",
      "epoch:46 step:36187 [D loss: 0.186380, acc: 96.88%] [G loss: 5.348367]\n",
      "epoch:46 step:36188 [D loss: 0.028472, acc: 100.00%] [G loss: 7.654307]\n",
      "epoch:46 step:36189 [D loss: 0.140357, acc: 99.22%] [G loss: 8.323142]\n",
      "epoch:46 step:36190 [D loss: 0.190363, acc: 94.53%] [G loss: 4.767003]\n",
      "epoch:46 step:36191 [D loss: 0.973064, acc: 50.78%] [G loss: 5.134204]\n",
      "epoch:46 step:36192 [D loss: 0.721140, acc: 56.25%] [G loss: 6.844203]\n",
      "epoch:46 step:36193 [D loss: 0.191778, acc: 96.88%] [G loss: 4.283466]\n",
      "epoch:46 step:36194 [D loss: 0.875118, acc: 42.97%] [G loss: 6.293248]\n",
      "epoch:46 step:36195 [D loss: 0.188129, acc: 99.22%] [G loss: 6.199154]\n",
      "epoch:46 step:36196 [D loss: 0.239298, acc: 89.06%] [G loss: 5.347545]\n",
      "epoch:46 step:36197 [D loss: 0.154438, acc: 98.44%] [G loss: 4.617659]\n",
      "epoch:46 step:36198 [D loss: 0.338982, acc: 89.84%] [G loss: 8.243972]\n",
      "epoch:46 step:36199 [D loss: 0.068488, acc: 100.00%] [G loss: 6.970955]\n",
      "epoch:46 step:36200 [D loss: 0.090197, acc: 100.00%] [G loss: 7.830646]\n",
      "epoch:46 step:36201 [D loss: 0.191371, acc: 96.88%] [G loss: 4.939268]\n",
      "epoch:46 step:36202 [D loss: 0.132503, acc: 100.00%] [G loss: 5.875529]\n",
      "epoch:46 step:36203 [D loss: 0.071068, acc: 99.22%] [G loss: 6.701034]\n",
      "epoch:46 step:36204 [D loss: 0.049690, acc: 100.00%] [G loss: 4.924422]\n",
      "epoch:46 step:36205 [D loss: 0.183697, acc: 92.97%] [G loss: 6.665783]\n",
      "epoch:46 step:36206 [D loss: 0.104546, acc: 100.00%] [G loss: 2.768152]\n",
      "epoch:46 step:36207 [D loss: 0.078954, acc: 100.00%] [G loss: 7.638044]\n",
      "epoch:46 step:36208 [D loss: 0.224915, acc: 98.44%] [G loss: 4.691757]\n",
      "epoch:46 step:36209 [D loss: 0.034648, acc: 100.00%] [G loss: 5.026675]\n",
      "epoch:46 step:36210 [D loss: 0.399924, acc: 84.38%] [G loss: 4.251365]\n",
      "epoch:46 step:36211 [D loss: 0.463339, acc: 67.97%] [G loss: 9.528769]\n",
      "epoch:46 step:36212 [D loss: 0.724361, acc: 57.81%] [G loss: 7.632006]\n",
      "epoch:46 step:36213 [D loss: 0.503541, acc: 66.41%] [G loss: 6.390789]\n",
      "epoch:46 step:36214 [D loss: 0.283045, acc: 85.94%] [G loss: 6.479493]\n",
      "epoch:46 step:36215 [D loss: 0.123676, acc: 99.22%] [G loss: 4.907295]\n",
      "epoch:46 step:36216 [D loss: 0.372128, acc: 88.28%] [G loss: 5.162266]\n",
      "epoch:46 step:36217 [D loss: 0.348393, acc: 82.03%] [G loss: 7.683587]\n",
      "epoch:46 step:36218 [D loss: 0.187039, acc: 98.44%] [G loss: 5.306429]\n",
      "epoch:46 step:36219 [D loss: 0.158319, acc: 97.66%] [G loss: 2.568799]\n",
      "epoch:46 step:36220 [D loss: 1.313773, acc: 17.19%] [G loss: 8.134647]\n",
      "epoch:46 step:36221 [D loss: 0.157866, acc: 100.00%] [G loss: 7.107488]\n",
      "epoch:46 step:36222 [D loss: 0.397808, acc: 82.81%] [G loss: 6.575993]\n",
      "epoch:46 step:36223 [D loss: 1.422459, acc: 14.84%] [G loss: 7.047241]\n",
      "epoch:46 step:36224 [D loss: 0.095866, acc: 100.00%] [G loss: 6.057835]\n",
      "epoch:46 step:36225 [D loss: 0.059374, acc: 100.00%] [G loss: 7.107761]\n",
      "epoch:46 step:36226 [D loss: 0.075788, acc: 100.00%] [G loss: 6.305974]\n",
      "epoch:46 step:36227 [D loss: 0.041846, acc: 100.00%] [G loss: 2.421110]\n",
      "epoch:46 step:36228 [D loss: 0.156547, acc: 97.66%] [G loss: 2.058450]\n",
      "epoch:46 step:36229 [D loss: 0.299197, acc: 89.84%] [G loss: 2.675409]\n",
      "epoch:46 step:36230 [D loss: 0.730641, acc: 55.47%] [G loss: 5.976375]\n",
      "epoch:46 step:36231 [D loss: 0.183199, acc: 97.66%] [G loss: 4.718625]\n",
      "epoch:46 step:36232 [D loss: 0.159446, acc: 96.09%] [G loss: 8.103318]\n",
      "epoch:46 step:36233 [D loss: 0.110238, acc: 100.00%] [G loss: 8.046665]\n",
      "epoch:46 step:36234 [D loss: 0.554943, acc: 71.88%] [G loss: 6.210398]\n",
      "epoch:46 step:36235 [D loss: 0.387363, acc: 87.50%] [G loss: 8.062274]\n",
      "epoch:46 step:36236 [D loss: 0.020075, acc: 99.22%] [G loss: 8.803369]\n",
      "epoch:46 step:36237 [D loss: 0.611874, acc: 58.59%] [G loss: 6.642387]\n",
      "epoch:46 step:36238 [D loss: 0.163502, acc: 98.44%] [G loss: 5.946806]\n",
      "epoch:46 step:36239 [D loss: 0.020210, acc: 100.00%] [G loss: 5.524546]\n",
      "epoch:46 step:36240 [D loss: 0.335437, acc: 83.59%] [G loss: 6.508496]\n",
      "epoch:46 step:36241 [D loss: 0.360616, acc: 84.38%] [G loss: 3.809456]\n",
      "epoch:46 step:36242 [D loss: 0.028084, acc: 100.00%] [G loss: 4.166493]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36243 [D loss: 0.037403, acc: 100.00%] [G loss: 6.088822]\n",
      "epoch:46 step:36244 [D loss: 0.509058, acc: 78.91%] [G loss: 4.697674]\n",
      "epoch:46 step:36245 [D loss: 0.110387, acc: 99.22%] [G loss: 5.944230]\n",
      "epoch:46 step:36246 [D loss: 0.190828, acc: 95.31%] [G loss: 7.891524]\n",
      "epoch:46 step:36247 [D loss: 0.237118, acc: 91.41%] [G loss: 7.403563]\n",
      "epoch:46 step:36248 [D loss: 0.044672, acc: 100.00%] [G loss: 5.771302]\n",
      "epoch:46 step:36249 [D loss: 0.227999, acc: 94.53%] [G loss: 6.904587]\n",
      "epoch:46 step:36250 [D loss: 0.671432, acc: 58.59%] [G loss: 8.502932]\n",
      "epoch:46 step:36251 [D loss: 0.313233, acc: 83.59%] [G loss: 9.623442]\n",
      "epoch:46 step:36252 [D loss: 0.662471, acc: 60.16%] [G loss: 6.828278]\n",
      "epoch:46 step:36253 [D loss: 0.122330, acc: 99.22%] [G loss: 7.596404]\n",
      "epoch:46 step:36254 [D loss: 0.606457, acc: 60.94%] [G loss: 8.813416]\n",
      "epoch:46 step:36255 [D loss: 0.016982, acc: 100.00%] [G loss: 9.826509]\n",
      "epoch:46 step:36256 [D loss: 0.264336, acc: 96.09%] [G loss: 5.195010]\n",
      "epoch:46 step:36257 [D loss: 0.023525, acc: 100.00%] [G loss: 8.950918]\n",
      "epoch:46 step:36258 [D loss: 0.194869, acc: 96.09%] [G loss: 7.586729]\n",
      "epoch:46 step:36259 [D loss: 0.029504, acc: 100.00%] [G loss: 10.799817]\n",
      "epoch:46 step:36260 [D loss: 0.043644, acc: 100.00%] [G loss: 8.461053]\n",
      "epoch:46 step:36261 [D loss: 0.018073, acc: 100.00%] [G loss: 10.456120]\n",
      "epoch:46 step:36262 [D loss: 0.405302, acc: 76.56%] [G loss: 5.944619]\n",
      "epoch:46 step:36263 [D loss: 0.225672, acc: 95.31%] [G loss: 7.425117]\n",
      "epoch:46 step:36264 [D loss: 0.295875, acc: 94.53%] [G loss: 3.282091]\n",
      "epoch:46 step:36265 [D loss: 0.125504, acc: 100.00%] [G loss: 3.056439]\n",
      "epoch:46 step:36266 [D loss: 0.087320, acc: 99.22%] [G loss: 4.877541]\n",
      "epoch:46 step:36267 [D loss: 0.200370, acc: 97.66%] [G loss: 7.092688]\n",
      "epoch:46 step:36268 [D loss: 0.134422, acc: 100.00%] [G loss: 7.013096]\n",
      "epoch:46 step:36269 [D loss: 0.403490, acc: 78.91%] [G loss: 6.858107]\n",
      "epoch:46 step:36270 [D loss: 0.313703, acc: 93.75%] [G loss: 7.428678]\n",
      "epoch:46 step:36271 [D loss: 0.077023, acc: 99.22%] [G loss: 4.237195]\n",
      "epoch:46 step:36272 [D loss: 0.085020, acc: 99.22%] [G loss: 4.099667]\n",
      "epoch:46 step:36273 [D loss: 0.055849, acc: 100.00%] [G loss: 7.307132]\n",
      "epoch:46 step:36274 [D loss: 0.568358, acc: 58.59%] [G loss: 8.149573]\n",
      "epoch:46 step:36275 [D loss: 0.424706, acc: 85.16%] [G loss: 6.073125]\n",
      "epoch:46 step:36276 [D loss: 0.160442, acc: 98.44%] [G loss: 6.983325]\n",
      "epoch:46 step:36277 [D loss: 0.484073, acc: 67.19%] [G loss: 8.464254]\n",
      "epoch:46 step:36278 [D loss: 0.088291, acc: 100.00%] [G loss: 8.866630]\n",
      "epoch:46 step:36279 [D loss: 0.138965, acc: 100.00%] [G loss: 4.786111]\n",
      "epoch:46 step:36280 [D loss: 0.588504, acc: 63.28%] [G loss: 8.370806]\n",
      "epoch:46 step:36281 [D loss: 0.444282, acc: 78.12%] [G loss: 6.376211]\n",
      "epoch:46 step:36282 [D loss: 0.287463, acc: 85.94%] [G loss: 8.123789]\n",
      "epoch:46 step:36283 [D loss: 0.035332, acc: 100.00%] [G loss: 7.469165]\n",
      "epoch:46 step:36284 [D loss: 0.080457, acc: 99.22%] [G loss: 7.178195]\n",
      "epoch:46 step:36285 [D loss: 0.098381, acc: 98.44%] [G loss: 6.634640]\n",
      "epoch:46 step:36286 [D loss: 0.765976, acc: 50.78%] [G loss: 8.829557]\n",
      "epoch:46 step:36287 [D loss: 0.189969, acc: 97.66%] [G loss: 3.468592]\n",
      "epoch:46 step:36288 [D loss: 0.184827, acc: 97.66%] [G loss: 5.823681]\n",
      "epoch:46 step:36289 [D loss: 0.065597, acc: 100.00%] [G loss: 6.783704]\n",
      "epoch:46 step:36290 [D loss: 0.520654, acc: 78.91%] [G loss: 9.142558]\n",
      "epoch:46 step:36291 [D loss: 0.251570, acc: 91.41%] [G loss: 5.379892]\n",
      "epoch:46 step:36292 [D loss: 0.490584, acc: 74.22%] [G loss: 6.721903]\n",
      "epoch:46 step:36293 [D loss: 0.513911, acc: 67.19%] [G loss: 7.532847]\n",
      "epoch:46 step:36294 [D loss: 0.016828, acc: 100.00%] [G loss: 4.808750]\n",
      "epoch:46 step:36295 [D loss: 0.126485, acc: 100.00%] [G loss: 7.207826]\n",
      "epoch:46 step:36296 [D loss: 0.540688, acc: 75.00%] [G loss: 6.039907]\n",
      "epoch:46 step:36297 [D loss: 0.154107, acc: 99.22%] [G loss: 6.081405]\n",
      "epoch:46 step:36298 [D loss: 0.647813, acc: 65.62%] [G loss: 4.513558]\n",
      "epoch:46 step:36299 [D loss: 0.899764, acc: 39.84%] [G loss: 8.740668]\n",
      "epoch:46 step:36300 [D loss: 0.340747, acc: 78.91%] [G loss: 6.099866]\n",
      "epoch:46 step:36301 [D loss: 0.049486, acc: 100.00%] [G loss: 6.324729]\n",
      "epoch:46 step:36302 [D loss: 0.161473, acc: 98.44%] [G loss: 4.743348]\n",
      "epoch:46 step:36303 [D loss: 0.855989, acc: 53.91%] [G loss: 6.599807]\n",
      "epoch:46 step:36304 [D loss: 0.135403, acc: 99.22%] [G loss: 7.813902]\n",
      "epoch:46 step:36305 [D loss: 0.084091, acc: 99.22%] [G loss: 8.089746]\n",
      "epoch:46 step:36306 [D loss: 0.509185, acc: 66.41%] [G loss: 5.247356]\n",
      "epoch:46 step:36307 [D loss: 1.032304, acc: 49.22%] [G loss: 6.115895]\n",
      "epoch:46 step:36308 [D loss: 0.147813, acc: 96.09%] [G loss: 4.919778]\n",
      "epoch:46 step:36309 [D loss: 0.421636, acc: 71.88%] [G loss: 8.062719]\n",
      "epoch:46 step:36310 [D loss: 0.631217, acc: 62.50%] [G loss: 6.127143]\n",
      "epoch:46 step:36311 [D loss: 0.262622, acc: 89.84%] [G loss: 6.601906]\n",
      "epoch:46 step:36312 [D loss: 1.352263, acc: 14.06%] [G loss: 11.603028]\n",
      "epoch:46 step:36313 [D loss: 0.199982, acc: 98.44%] [G loss: 4.478573]\n",
      "epoch:46 step:36314 [D loss: 0.582726, acc: 64.84%] [G loss: 4.427089]\n",
      "epoch:46 step:36315 [D loss: 0.188013, acc: 96.88%] [G loss: 6.153275]\n",
      "epoch:46 step:36316 [D loss: 1.258201, acc: 42.19%] [G loss: 7.069548]\n",
      "epoch:46 step:36317 [D loss: 0.066166, acc: 100.00%] [G loss: 7.119270]\n",
      "epoch:46 step:36318 [D loss: 0.487446, acc: 67.97%] [G loss: 6.715707]\n",
      "epoch:46 step:36319 [D loss: 0.369875, acc: 80.47%] [G loss: 6.924772]\n",
      "epoch:46 step:36320 [D loss: 0.353731, acc: 75.00%] [G loss: 7.734833]\n",
      "epoch:46 step:36321 [D loss: 1.498561, acc: 50.78%] [G loss: 6.720558]\n",
      "epoch:46 step:36322 [D loss: 0.033081, acc: 100.00%] [G loss: 3.340651]\n",
      "epoch:46 step:36323 [D loss: 0.205387, acc: 98.44%] [G loss: 5.148340]\n",
      "epoch:46 step:36324 [D loss: 0.881303, acc: 53.12%] [G loss: 10.946753]\n",
      "epoch:46 step:36325 [D loss: 0.033177, acc: 100.00%] [G loss: 6.527453]\n",
      "epoch:46 step:36326 [D loss: 0.372276, acc: 75.00%] [G loss: 4.958973]\n",
      "epoch:46 step:36327 [D loss: 0.125646, acc: 98.44%] [G loss: 9.314552]\n",
      "epoch:46 step:36328 [D loss: 0.899138, acc: 48.44%] [G loss: 7.139511]\n",
      "epoch:46 step:36329 [D loss: 0.352784, acc: 80.47%] [G loss: 8.205875]\n",
      "epoch:46 step:36330 [D loss: 0.976235, acc: 50.78%] [G loss: 10.780203]\n",
      "epoch:46 step:36331 [D loss: 1.055382, acc: 51.56%] [G loss: 4.912865]\n",
      "epoch:46 step:36332 [D loss: 0.455831, acc: 67.19%] [G loss: 4.343831]\n",
      "epoch:46 step:36333 [D loss: 0.053399, acc: 100.00%] [G loss: 7.771375]\n",
      "epoch:46 step:36334 [D loss: 0.171335, acc: 99.22%] [G loss: 2.492831]\n",
      "epoch:46 step:36335 [D loss: 0.088809, acc: 100.00%] [G loss: 2.656540]\n",
      "epoch:46 step:36336 [D loss: 0.468847, acc: 73.44%] [G loss: 5.225438]\n",
      "epoch:46 step:36337 [D loss: 0.190917, acc: 96.88%] [G loss: 7.982224]\n",
      "epoch:46 step:36338 [D loss: 0.392102, acc: 84.38%] [G loss: 4.208325]\n",
      "epoch:46 step:36339 [D loss: 0.165374, acc: 95.31%] [G loss: 9.255289]\n",
      "epoch:46 step:36340 [D loss: 0.027253, acc: 100.00%] [G loss: 3.894954]\n",
      "epoch:46 step:36341 [D loss: 0.074319, acc: 100.00%] [G loss: 8.454971]\n",
      "epoch:46 step:36342 [D loss: 0.562075, acc: 71.88%] [G loss: 4.067222]\n",
      "epoch:46 step:36343 [D loss: 0.119670, acc: 99.22%] [G loss: 9.056896]\n",
      "epoch:46 step:36344 [D loss: 0.183421, acc: 96.09%] [G loss: 4.361249]\n",
      "epoch:46 step:36345 [D loss: 0.052150, acc: 100.00%] [G loss: 7.184787]\n",
      "epoch:46 step:36346 [D loss: 0.290835, acc: 93.75%] [G loss: 5.501951]\n",
      "epoch:46 step:36347 [D loss: 0.544997, acc: 62.50%] [G loss: 10.425483]\n",
      "epoch:46 step:36348 [D loss: 0.350962, acc: 81.25%] [G loss: 4.196728]\n",
      "epoch:46 step:36349 [D loss: 0.089024, acc: 99.22%] [G loss: 8.216996]\n",
      "epoch:46 step:36350 [D loss: 0.890156, acc: 50.00%] [G loss: 5.051641]\n",
      "epoch:46 step:36351 [D loss: 0.373911, acc: 92.97%] [G loss: 6.029421]\n",
      "epoch:46 step:36352 [D loss: 0.378985, acc: 74.22%] [G loss: 6.345079]\n",
      "epoch:46 step:36353 [D loss: 0.109909, acc: 100.00%] [G loss: 4.559604]\n",
      "epoch:46 step:36354 [D loss: 0.101529, acc: 99.22%] [G loss: 5.190365]\n",
      "epoch:46 step:36355 [D loss: 0.110204, acc: 98.44%] [G loss: 4.756157]\n",
      "epoch:46 step:36356 [D loss: 0.245480, acc: 92.97%] [G loss: 6.615741]\n",
      "epoch:46 step:36357 [D loss: 0.084671, acc: 99.22%] [G loss: 5.974993]\n",
      "epoch:46 step:36358 [D loss: 0.397368, acc: 74.22%] [G loss: 8.922319]\n",
      "epoch:46 step:36359 [D loss: 0.029213, acc: 100.00%] [G loss: 6.178212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36360 [D loss: 1.414679, acc: 50.00%] [G loss: 5.094447]\n",
      "epoch:46 step:36361 [D loss: 0.057922, acc: 99.22%] [G loss: 8.578230]\n",
      "epoch:46 step:36362 [D loss: 0.449414, acc: 70.31%] [G loss: 7.766320]\n",
      "epoch:46 step:36363 [D loss: 0.282005, acc: 94.53%] [G loss: 4.267301]\n",
      "epoch:46 step:36364 [D loss: 0.239490, acc: 94.53%] [G loss: 6.466301]\n",
      "epoch:46 step:36365 [D loss: 0.015638, acc: 100.00%] [G loss: 3.093141]\n",
      "epoch:46 step:36366 [D loss: 0.166352, acc: 98.44%] [G loss: 4.153678]\n",
      "epoch:46 step:36367 [D loss: 0.025567, acc: 100.00%] [G loss: 6.191168]\n",
      "epoch:46 step:36368 [D loss: 0.177726, acc: 95.31%] [G loss: 4.527519]\n",
      "epoch:46 step:36369 [D loss: 0.060391, acc: 100.00%] [G loss: 5.418668]\n",
      "epoch:46 step:36370 [D loss: 0.132338, acc: 99.22%] [G loss: 7.541380]\n",
      "epoch:46 step:36371 [D loss: 0.083631, acc: 100.00%] [G loss: 3.458773]\n",
      "epoch:46 step:36372 [D loss: 0.182891, acc: 98.44%] [G loss: 6.666603]\n",
      "epoch:46 step:36373 [D loss: 0.054228, acc: 100.00%] [G loss: 6.228138]\n",
      "epoch:46 step:36374 [D loss: 1.630661, acc: 7.81%] [G loss: 8.626432]\n",
      "epoch:46 step:36375 [D loss: 0.792971, acc: 46.88%] [G loss: 5.762555]\n",
      "epoch:46 step:36376 [D loss: 0.266818, acc: 85.94%] [G loss: 7.263717]\n",
      "epoch:46 step:36377 [D loss: 0.060613, acc: 100.00%] [G loss: 5.518606]\n",
      "epoch:46 step:36378 [D loss: 0.275501, acc: 91.41%] [G loss: 4.599887]\n",
      "epoch:46 step:36379 [D loss: 0.692719, acc: 59.38%] [G loss: 6.405350]\n",
      "epoch:46 step:36380 [D loss: 0.091706, acc: 100.00%] [G loss: 5.265836]\n",
      "epoch:46 step:36381 [D loss: 0.507527, acc: 64.84%] [G loss: 10.247154]\n",
      "epoch:46 step:36382 [D loss: 0.162178, acc: 98.44%] [G loss: 4.295732]\n",
      "epoch:46 step:36383 [D loss: 0.832044, acc: 50.00%] [G loss: 6.997455]\n",
      "epoch:46 step:36384 [D loss: 0.102249, acc: 100.00%] [G loss: 4.368296]\n",
      "epoch:46 step:36385 [D loss: 0.194837, acc: 95.31%] [G loss: 6.818246]\n",
      "epoch:46 step:36386 [D loss: 1.113795, acc: 42.97%] [G loss: 7.111281]\n",
      "epoch:46 step:36387 [D loss: 0.299505, acc: 84.38%] [G loss: 6.469198]\n",
      "epoch:46 step:36388 [D loss: 0.228655, acc: 98.44%] [G loss: 5.384746]\n",
      "epoch:46 step:36389 [D loss: 0.009568, acc: 100.00%] [G loss: 9.491786]\n",
      "epoch:46 step:36390 [D loss: 0.394056, acc: 90.62%] [G loss: 6.784909]\n",
      "epoch:46 step:36391 [D loss: 0.056430, acc: 100.00%] [G loss: 9.713175]\n",
      "epoch:46 step:36392 [D loss: 0.093175, acc: 100.00%] [G loss: 5.663780]\n",
      "epoch:46 step:36393 [D loss: 0.532084, acc: 70.31%] [G loss: 6.116374]\n",
      "epoch:46 step:36394 [D loss: 0.373697, acc: 76.56%] [G loss: 7.794767]\n",
      "epoch:46 step:36395 [D loss: 0.338758, acc: 83.59%] [G loss: 3.414136]\n",
      "epoch:46 step:36396 [D loss: 0.041383, acc: 100.00%] [G loss: 4.397153]\n",
      "epoch:46 step:36397 [D loss: 0.564331, acc: 67.97%] [G loss: 4.052531]\n",
      "epoch:46 step:36398 [D loss: 0.029532, acc: 100.00%] [G loss: 6.781809]\n",
      "epoch:46 step:36399 [D loss: 0.643762, acc: 63.28%] [G loss: 8.405323]\n",
      "epoch:46 step:36400 [D loss: 0.340582, acc: 78.12%] [G loss: 7.105995]\n",
      "epoch:46 step:36401 [D loss: 0.151520, acc: 96.88%] [G loss: 4.126346]\n",
      "epoch:46 step:36402 [D loss: 0.142640, acc: 97.66%] [G loss: 5.127645]\n",
      "epoch:46 step:36403 [D loss: 0.086453, acc: 100.00%] [G loss: 4.053540]\n",
      "epoch:46 step:36404 [D loss: 0.104544, acc: 100.00%] [G loss: 6.671214]\n",
      "epoch:46 step:36405 [D loss: 0.159963, acc: 98.44%] [G loss: 7.246752]\n",
      "epoch:46 step:36406 [D loss: 0.758254, acc: 55.47%] [G loss: 5.066535]\n",
      "epoch:46 step:36407 [D loss: 0.092953, acc: 100.00%] [G loss: 6.681310]\n",
      "epoch:46 step:36408 [D loss: 0.011304, acc: 100.00%] [G loss: 7.296188]\n",
      "epoch:46 step:36409 [D loss: 0.500650, acc: 77.34%] [G loss: 6.224642]\n",
      "epoch:46 step:36410 [D loss: 0.067502, acc: 100.00%] [G loss: 7.026699]\n",
      "epoch:46 step:36411 [D loss: 0.321863, acc: 92.19%] [G loss: 1.888363]\n",
      "epoch:46 step:36412 [D loss: 0.145557, acc: 96.09%] [G loss: 8.373760]\n",
      "epoch:46 step:36413 [D loss: 0.154747, acc: 99.22%] [G loss: 5.569039]\n",
      "epoch:46 step:36414 [D loss: 0.140823, acc: 98.44%] [G loss: 5.592359]\n",
      "epoch:46 step:36415 [D loss: 0.212637, acc: 96.88%] [G loss: 4.706581]\n",
      "epoch:46 step:36416 [D loss: 0.540670, acc: 67.97%] [G loss: 9.706152]\n",
      "epoch:46 step:36417 [D loss: 0.100628, acc: 100.00%] [G loss: 7.883436]\n",
      "epoch:46 step:36418 [D loss: 0.019672, acc: 100.00%] [G loss: 3.730403]\n",
      "epoch:46 step:36419 [D loss: 0.115891, acc: 97.66%] [G loss: 6.003533]\n",
      "epoch:46 step:36420 [D loss: 0.158448, acc: 95.31%] [G loss: 4.772108]\n",
      "epoch:46 step:36421 [D loss: 0.405696, acc: 72.66%] [G loss: 6.209978]\n",
      "epoch:46 step:36422 [D loss: 0.030820, acc: 100.00%] [G loss: 4.576607]\n",
      "epoch:46 step:36423 [D loss: 0.187243, acc: 95.31%] [G loss: 9.410933]\n",
      "epoch:46 step:36424 [D loss: 0.808741, acc: 53.12%] [G loss: 11.351310]\n",
      "epoch:46 step:36425 [D loss: 0.376482, acc: 86.72%] [G loss: 4.086800]\n",
      "epoch:46 step:36426 [D loss: 0.216224, acc: 93.75%] [G loss: 10.302471]\n",
      "epoch:46 step:36427 [D loss: 1.190152, acc: 50.78%] [G loss: 4.788296]\n",
      "epoch:46 step:36428 [D loss: 0.049270, acc: 100.00%] [G loss: 5.085227]\n",
      "epoch:46 step:36429 [D loss: 0.756603, acc: 56.25%] [G loss: 11.182521]\n",
      "epoch:46 step:36430 [D loss: 0.108572, acc: 100.00%] [G loss: 5.640480]\n",
      "epoch:46 step:36431 [D loss: 0.199052, acc: 98.44%] [G loss: 5.941358]\n",
      "epoch:46 step:36432 [D loss: 0.713954, acc: 54.69%] [G loss: 8.849686]\n",
      "epoch:46 step:36433 [D loss: 0.670422, acc: 61.72%] [G loss: 6.324412]\n",
      "epoch:46 step:36434 [D loss: 0.410186, acc: 71.09%] [G loss: 7.182415]\n",
      "epoch:46 step:36435 [D loss: 0.347128, acc: 80.47%] [G loss: 11.942935]\n",
      "epoch:46 step:36436 [D loss: 0.028781, acc: 100.00%] [G loss: 7.169415]\n",
      "epoch:46 step:36437 [D loss: 0.491063, acc: 69.53%] [G loss: 8.953342]\n",
      "epoch:46 step:36438 [D loss: 0.334314, acc: 85.16%] [G loss: 6.445679]\n",
      "epoch:46 step:36439 [D loss: 0.333082, acc: 78.12%] [G loss: 5.230197]\n",
      "epoch:46 step:36440 [D loss: 0.561792, acc: 71.09%] [G loss: 6.979621]\n",
      "epoch:46 step:36441 [D loss: 1.102226, acc: 42.19%] [G loss: 6.931126]\n",
      "epoch:46 step:36442 [D loss: 0.468907, acc: 79.69%] [G loss: 7.768495]\n",
      "epoch:46 step:36443 [D loss: 0.047415, acc: 100.00%] [G loss: 7.855915]\n",
      "epoch:46 step:36444 [D loss: 0.273073, acc: 89.06%] [G loss: 7.264480]\n",
      "epoch:46 step:36445 [D loss: 0.081151, acc: 100.00%] [G loss: 3.875959]\n",
      "epoch:46 step:36446 [D loss: 0.020280, acc: 100.00%] [G loss: 6.981534]\n",
      "epoch:46 step:36447 [D loss: 0.192231, acc: 95.31%] [G loss: 4.748774]\n",
      "epoch:46 step:36448 [D loss: 0.272045, acc: 93.75%] [G loss: 10.604806]\n",
      "epoch:46 step:36449 [D loss: 0.066634, acc: 100.00%] [G loss: 4.678280]\n",
      "epoch:46 step:36450 [D loss: 0.253620, acc: 95.31%] [G loss: 5.363933]\n",
      "epoch:46 step:36451 [D loss: 0.711886, acc: 55.47%] [G loss: 8.240420]\n",
      "epoch:46 step:36452 [D loss: 0.083638, acc: 100.00%] [G loss: 7.705950]\n",
      "epoch:46 step:36453 [D loss: 2.023999, acc: 50.78%] [G loss: 10.082863]\n",
      "epoch:46 step:36454 [D loss: 0.141388, acc: 100.00%] [G loss: 6.134262]\n",
      "epoch:46 step:36455 [D loss: 0.450611, acc: 71.88%] [G loss: 5.917301]\n",
      "epoch:46 step:36456 [D loss: 0.171919, acc: 97.66%] [G loss: 3.478956]\n",
      "epoch:46 step:36457 [D loss: 0.092792, acc: 99.22%] [G loss: 4.339677]\n",
      "epoch:46 step:36458 [D loss: 0.352663, acc: 90.62%] [G loss: 5.176106]\n",
      "epoch:46 step:36459 [D loss: 0.147859, acc: 99.22%] [G loss: 5.748278]\n",
      "epoch:46 step:36460 [D loss: 0.445998, acc: 72.66%] [G loss: 5.802732]\n",
      "epoch:46 step:36461 [D loss: 0.304986, acc: 89.06%] [G loss: 4.716349]\n",
      "epoch:46 step:36462 [D loss: 0.535212, acc: 77.34%] [G loss: 8.992111]\n",
      "epoch:46 step:36463 [D loss: 0.852026, acc: 51.56%] [G loss: 4.980047]\n",
      "epoch:46 step:36464 [D loss: 0.419766, acc: 75.00%] [G loss: 10.798565]\n",
      "epoch:46 step:36465 [D loss: 0.082938, acc: 100.00%] [G loss: 5.230770]\n",
      "epoch:46 step:36466 [D loss: 0.098745, acc: 99.22%] [G loss: 4.961656]\n",
      "epoch:46 step:36467 [D loss: 0.136086, acc: 96.88%] [G loss: 6.443134]\n",
      "epoch:46 step:36468 [D loss: 0.095772, acc: 98.44%] [G loss: 6.099986]\n",
      "epoch:46 step:36469 [D loss: 0.151460, acc: 99.22%] [G loss: 3.866316]\n",
      "epoch:46 step:36470 [D loss: 0.232857, acc: 94.53%] [G loss: 5.552409]\n",
      "epoch:46 step:36471 [D loss: 0.338026, acc: 91.41%] [G loss: 4.779466]\n",
      "epoch:46 step:36472 [D loss: 0.710818, acc: 60.16%] [G loss: 8.310612]\n",
      "epoch:46 step:36473 [D loss: 0.060908, acc: 100.00%] [G loss: 6.005358]\n",
      "epoch:46 step:36474 [D loss: 0.294162, acc: 92.19%] [G loss: 5.781796]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36475 [D loss: 0.322667, acc: 84.38%] [G loss: 10.227730]\n",
      "epoch:46 step:36476 [D loss: 0.429767, acc: 70.31%] [G loss: 4.932686]\n",
      "epoch:46 step:36477 [D loss: 0.248780, acc: 96.88%] [G loss: 5.447970]\n",
      "epoch:46 step:36478 [D loss: 0.066806, acc: 100.00%] [G loss: 5.566043]\n",
      "epoch:46 step:36479 [D loss: 0.366975, acc: 80.47%] [G loss: 7.759346]\n",
      "epoch:46 step:36480 [D loss: 0.402721, acc: 87.50%] [G loss: 6.664670]\n",
      "epoch:46 step:36481 [D loss: 0.097627, acc: 100.00%] [G loss: 6.491417]\n",
      "epoch:46 step:36482 [D loss: 0.499777, acc: 65.62%] [G loss: 6.079124]\n",
      "epoch:46 step:36483 [D loss: 0.447551, acc: 65.62%] [G loss: 5.230339]\n",
      "epoch:46 step:36484 [D loss: 0.088590, acc: 99.22%] [G loss: 11.748405]\n",
      "epoch:46 step:36485 [D loss: 0.468210, acc: 75.78%] [G loss: 8.731765]\n",
      "epoch:46 step:36486 [D loss: 0.378739, acc: 87.50%] [G loss: 6.409502]\n",
      "epoch:46 step:36487 [D loss: 0.307671, acc: 89.06%] [G loss: 9.581224]\n",
      "epoch:46 step:36488 [D loss: 0.328363, acc: 84.38%] [G loss: 5.960984]\n",
      "epoch:46 step:36489 [D loss: 0.586345, acc: 66.41%] [G loss: 4.511453]\n",
      "epoch:46 step:36490 [D loss: 0.219687, acc: 98.44%] [G loss: 2.848023]\n",
      "epoch:46 step:36491 [D loss: 0.445512, acc: 71.09%] [G loss: 11.588086]\n",
      "epoch:46 step:36492 [D loss: 0.317917, acc: 93.75%] [G loss: 6.289174]\n",
      "epoch:46 step:36493 [D loss: 0.130690, acc: 100.00%] [G loss: 7.423972]\n",
      "epoch:46 step:36494 [D loss: 0.298095, acc: 91.41%] [G loss: 3.826236]\n",
      "epoch:46 step:36495 [D loss: 0.363003, acc: 79.69%] [G loss: 10.451427]\n",
      "epoch:46 step:36496 [D loss: 0.688324, acc: 59.38%] [G loss: 7.004419]\n",
      "epoch:46 step:36497 [D loss: 0.218791, acc: 91.41%] [G loss: 9.903730]\n",
      "epoch:46 step:36498 [D loss: 0.085074, acc: 100.00%] [G loss: 5.530066]\n",
      "epoch:46 step:36499 [D loss: 0.703443, acc: 54.69%] [G loss: 7.549752]\n",
      "epoch:46 step:36500 [D loss: 0.268397, acc: 89.84%] [G loss: 3.699481]\n",
      "epoch:46 step:36501 [D loss: 0.027987, acc: 100.00%] [G loss: 7.415565]\n",
      "epoch:46 step:36502 [D loss: 0.240110, acc: 92.97%] [G loss: 6.545929]\n",
      "epoch:46 step:36503 [D loss: 0.058173, acc: 99.22%] [G loss: 5.948040]\n",
      "epoch:46 step:36504 [D loss: 0.470655, acc: 73.44%] [G loss: 10.868645]\n",
      "epoch:46 step:36505 [D loss: 0.157486, acc: 96.88%] [G loss: 7.230280]\n",
      "epoch:46 step:36506 [D loss: 0.276690, acc: 88.28%] [G loss: 4.383224]\n",
      "epoch:46 step:36507 [D loss: 0.031356, acc: 100.00%] [G loss: 5.737162]\n",
      "epoch:46 step:36508 [D loss: 0.194055, acc: 92.19%] [G loss: 8.486033]\n",
      "epoch:46 step:36509 [D loss: 0.126155, acc: 99.22%] [G loss: 3.847395]\n",
      "epoch:46 step:36510 [D loss: 0.059468, acc: 99.22%] [G loss: 6.898163]\n",
      "epoch:46 step:36511 [D loss: 0.116589, acc: 99.22%] [G loss: 6.293146]\n",
      "epoch:46 step:36512 [D loss: 0.239849, acc: 90.62%] [G loss: 8.050798]\n",
      "epoch:46 step:36513 [D loss: 0.563404, acc: 69.53%] [G loss: 8.813259]\n",
      "epoch:46 step:36514 [D loss: 0.349364, acc: 80.47%] [G loss: 5.626956]\n",
      "epoch:46 step:36515 [D loss: 0.168566, acc: 96.09%] [G loss: 4.649867]\n",
      "epoch:46 step:36516 [D loss: 0.347508, acc: 85.16%] [G loss: 7.460400]\n",
      "epoch:46 step:36517 [D loss: 0.411526, acc: 82.03%] [G loss: 9.124960]\n",
      "epoch:46 step:36518 [D loss: 0.161995, acc: 97.66%] [G loss: 8.995390]\n",
      "epoch:46 step:36519 [D loss: 0.137243, acc: 100.00%] [G loss: 1.796456]\n",
      "epoch:46 step:36520 [D loss: 0.041632, acc: 100.00%] [G loss: 6.763588]\n",
      "epoch:46 step:36521 [D loss: 0.332625, acc: 85.94%] [G loss: 5.179107]\n",
      "epoch:46 step:36522 [D loss: 0.106649, acc: 99.22%] [G loss: 8.379859]\n",
      "epoch:46 step:36523 [D loss: 0.012169, acc: 100.00%] [G loss: 6.697391]\n",
      "epoch:46 step:36524 [D loss: 0.068564, acc: 100.00%] [G loss: 6.055610]\n",
      "epoch:46 step:36525 [D loss: 0.349156, acc: 90.62%] [G loss: 5.582073]\n",
      "epoch:46 step:36526 [D loss: 0.235381, acc: 97.66%] [G loss: 7.598952]\n",
      "epoch:46 step:36527 [D loss: 0.457076, acc: 67.97%] [G loss: 8.053843]\n",
      "epoch:46 step:36528 [D loss: 0.042825, acc: 100.00%] [G loss: 6.317762]\n",
      "epoch:46 step:36529 [D loss: 1.841873, acc: 48.44%] [G loss: 6.130830]\n",
      "epoch:46 step:36530 [D loss: 0.120879, acc: 99.22%] [G loss: 3.906872]\n",
      "epoch:46 step:36531 [D loss: 0.108817, acc: 100.00%] [G loss: 2.982881]\n",
      "epoch:46 step:36532 [D loss: 0.598975, acc: 66.41%] [G loss: 4.004138]\n",
      "epoch:46 step:36533 [D loss: 0.806043, acc: 55.47%] [G loss: 9.729877]\n",
      "epoch:46 step:36534 [D loss: 0.432241, acc: 80.47%] [G loss: 2.476183]\n",
      "epoch:46 step:36535 [D loss: 0.030592, acc: 99.22%] [G loss: 7.600828]\n",
      "epoch:46 step:36536 [D loss: 0.975866, acc: 33.59%] [G loss: 6.003690]\n",
      "epoch:46 step:36537 [D loss: 0.158712, acc: 99.22%] [G loss: 3.559608]\n",
      "epoch:46 step:36538 [D loss: 0.187285, acc: 97.66%] [G loss: 5.717038]\n",
      "epoch:46 step:36539 [D loss: 0.662193, acc: 57.03%] [G loss: 6.429962]\n",
      "epoch:46 step:36540 [D loss: 0.064061, acc: 99.22%] [G loss: 8.622281]\n",
      "epoch:46 step:36541 [D loss: 0.455788, acc: 71.88%] [G loss: 9.397098]\n",
      "epoch:46 step:36542 [D loss: 0.114150, acc: 100.00%] [G loss: 5.104506]\n",
      "epoch:46 step:36543 [D loss: 1.058335, acc: 44.53%] [G loss: 6.060014]\n",
      "epoch:46 step:36544 [D loss: 0.162667, acc: 97.66%] [G loss: 4.865878]\n",
      "epoch:46 step:36545 [D loss: 0.276690, acc: 93.75%] [G loss: 4.689047]\n",
      "epoch:46 step:36546 [D loss: 1.369164, acc: 28.91%] [G loss: 10.137876]\n",
      "epoch:46 step:36547 [D loss: 0.672459, acc: 59.38%] [G loss: 7.632557]\n",
      "epoch:46 step:36548 [D loss: 0.064009, acc: 100.00%] [G loss: 5.854937]\n",
      "epoch:46 step:36549 [D loss: 0.180448, acc: 96.88%] [G loss: 5.327581]\n",
      "epoch:46 step:36550 [D loss: 0.103054, acc: 99.22%] [G loss: 8.923869]\n",
      "epoch:46 step:36551 [D loss: 0.036816, acc: 100.00%] [G loss: 7.036522]\n",
      "epoch:46 step:36552 [D loss: 0.475061, acc: 71.88%] [G loss: 6.572678]\n",
      "epoch:46 step:36553 [D loss: 0.190639, acc: 99.22%] [G loss: 8.095420]\n",
      "epoch:46 step:36554 [D loss: 0.114402, acc: 98.44%] [G loss: 7.239676]\n",
      "epoch:46 step:36555 [D loss: 0.090453, acc: 100.00%] [G loss: 6.590581]\n",
      "epoch:46 step:36556 [D loss: 0.050476, acc: 100.00%] [G loss: 8.309322]\n",
      "epoch:46 step:36557 [D loss: 0.070651, acc: 100.00%] [G loss: 5.117912]\n",
      "epoch:46 step:36558 [D loss: 0.131032, acc: 99.22%] [G loss: 6.542420]\n",
      "epoch:46 step:36559 [D loss: 0.014157, acc: 100.00%] [G loss: 9.415169]\n",
      "epoch:46 step:36560 [D loss: 0.564587, acc: 70.31%] [G loss: 5.756324]\n",
      "epoch:46 step:36561 [D loss: 0.095254, acc: 99.22%] [G loss: 3.402026]\n",
      "epoch:46 step:36562 [D loss: 0.075785, acc: 98.44%] [G loss: 4.775159]\n",
      "epoch:46 step:36563 [D loss: 0.059269, acc: 100.00%] [G loss: 6.056566]\n",
      "epoch:46 step:36564 [D loss: 0.656601, acc: 60.16%] [G loss: 6.401740]\n",
      "epoch:46 step:36565 [D loss: 2.314791, acc: 10.94%] [G loss: 7.477584]\n",
      "epoch:46 step:36566 [D loss: 0.115175, acc: 98.44%] [G loss: 8.126925]\n",
      "epoch:46 step:36567 [D loss: 0.175061, acc: 99.22%] [G loss: 2.885009]\n",
      "epoch:46 step:36568 [D loss: 0.163010, acc: 95.31%] [G loss: 4.581969]\n",
      "epoch:46 step:36569 [D loss: 0.207953, acc: 99.22%] [G loss: 8.548534]\n",
      "epoch:46 step:36570 [D loss: 0.373983, acc: 89.06%] [G loss: 3.366163]\n",
      "epoch:46 step:36571 [D loss: 0.514936, acc: 64.84%] [G loss: 5.961034]\n",
      "epoch:46 step:36572 [D loss: 0.247960, acc: 89.06%] [G loss: 7.054554]\n",
      "epoch:46 step:36573 [D loss: 0.258908, acc: 92.97%] [G loss: 6.009941]\n",
      "epoch:46 step:36574 [D loss: 0.486105, acc: 80.47%] [G loss: 4.641021]\n",
      "epoch:46 step:36575 [D loss: 0.251528, acc: 94.53%] [G loss: 6.885919]\n",
      "epoch:46 step:36576 [D loss: 0.495036, acc: 68.75%] [G loss: 5.586839]\n",
      "epoch:46 step:36577 [D loss: 0.507733, acc: 66.41%] [G loss: 10.043420]\n",
      "epoch:46 step:36578 [D loss: 0.249446, acc: 94.53%] [G loss: 6.273455]\n",
      "epoch:46 step:36579 [D loss: 0.043781, acc: 100.00%] [G loss: 5.986107]\n",
      "epoch:46 step:36580 [D loss: 0.103510, acc: 99.22%] [G loss: 5.699686]\n",
      "epoch:46 step:36581 [D loss: 0.063361, acc: 100.00%] [G loss: 7.664005]\n",
      "epoch:46 step:36582 [D loss: 0.324013, acc: 89.84%] [G loss: 2.194807]\n",
      "epoch:46 step:36583 [D loss: 0.178724, acc: 98.44%] [G loss: 9.140162]\n",
      "epoch:46 step:36584 [D loss: 0.196073, acc: 93.75%] [G loss: 7.693542]\n",
      "epoch:46 step:36585 [D loss: 0.404093, acc: 76.56%] [G loss: 3.371201]\n",
      "epoch:46 step:36586 [D loss: 0.174761, acc: 96.88%] [G loss: 7.466701]\n",
      "epoch:46 step:36587 [D loss: 0.495719, acc: 69.53%] [G loss: 4.780239]\n",
      "epoch:46 step:36588 [D loss: 0.531161, acc: 75.00%] [G loss: 6.813001]\n",
      "epoch:46 step:36589 [D loss: 0.737306, acc: 54.69%] [G loss: 6.968162]\n",
      "epoch:46 step:36590 [D loss: 0.749769, acc: 55.47%] [G loss: 8.217498]\n",
      "epoch:46 step:36591 [D loss: 0.399488, acc: 82.81%] [G loss: 7.213898]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36592 [D loss: 0.053357, acc: 100.00%] [G loss: 4.096080]\n",
      "epoch:46 step:36593 [D loss: 0.190081, acc: 93.75%] [G loss: 6.262458]\n",
      "epoch:46 step:36594 [D loss: 0.041793, acc: 100.00%] [G loss: 8.111894]\n",
      "epoch:46 step:36595 [D loss: 0.099595, acc: 100.00%] [G loss: 7.067835]\n",
      "epoch:46 step:36596 [D loss: 0.740581, acc: 53.12%] [G loss: 5.141782]\n",
      "epoch:46 step:36597 [D loss: 0.113476, acc: 100.00%] [G loss: 12.773003]\n",
      "epoch:46 step:36598 [D loss: 0.109984, acc: 100.00%] [G loss: 7.958532]\n",
      "epoch:46 step:36599 [D loss: 0.678217, acc: 55.47%] [G loss: 10.953362]\n",
      "epoch:46 step:36600 [D loss: 0.101613, acc: 99.22%] [G loss: 4.970975]\n",
      "epoch:46 step:36601 [D loss: 0.121037, acc: 99.22%] [G loss: 7.585388]\n",
      "epoch:46 step:36602 [D loss: 0.135457, acc: 99.22%] [G loss: 5.145518]\n",
      "epoch:46 step:36603 [D loss: 0.146137, acc: 96.88%] [G loss: 6.391581]\n",
      "epoch:46 step:36604 [D loss: 0.220041, acc: 95.31%] [G loss: 3.663541]\n",
      "epoch:46 step:36605 [D loss: 0.161817, acc: 100.00%] [G loss: 6.952536]\n",
      "epoch:46 step:36606 [D loss: 0.141443, acc: 99.22%] [G loss: 6.038699]\n",
      "epoch:46 step:36607 [D loss: 0.175259, acc: 93.75%] [G loss: 6.517122]\n",
      "epoch:46 step:36608 [D loss: 0.397056, acc: 75.78%] [G loss: 7.886863]\n",
      "epoch:46 step:36609 [D loss: 0.514441, acc: 76.56%] [G loss: 4.150663]\n",
      "epoch:46 step:36610 [D loss: 0.142943, acc: 98.44%] [G loss: 4.400805]\n",
      "epoch:46 step:36611 [D loss: 0.497661, acc: 70.31%] [G loss: 4.263368]\n",
      "epoch:46 step:36612 [D loss: 0.872353, acc: 45.31%] [G loss: 7.968469]\n",
      "epoch:46 step:36613 [D loss: 0.664886, acc: 63.28%] [G loss: 6.994452]\n",
      "epoch:46 step:36614 [D loss: 0.144424, acc: 97.66%] [G loss: 8.510186]\n",
      "epoch:46 step:36615 [D loss: 0.092204, acc: 100.00%] [G loss: 5.436171]\n",
      "epoch:46 step:36616 [D loss: 1.071424, acc: 50.00%] [G loss: 9.465908]\n",
      "epoch:46 step:36617 [D loss: 0.771412, acc: 54.69%] [G loss: 9.542035]\n",
      "epoch:46 step:36618 [D loss: 0.859032, acc: 53.91%] [G loss: 9.399870]\n",
      "epoch:46 step:36619 [D loss: 2.463698, acc: 50.78%] [G loss: 4.452282]\n",
      "epoch:46 step:36620 [D loss: 0.067174, acc: 100.00%] [G loss: 2.738646]\n",
      "epoch:46 step:36621 [D loss: 0.087620, acc: 99.22%] [G loss: 5.257639]\n",
      "epoch:46 step:36622 [D loss: 0.659689, acc: 59.38%] [G loss: 3.500566]\n",
      "epoch:46 step:36623 [D loss: 0.596095, acc: 59.38%] [G loss: 8.132051]\n",
      "epoch:46 step:36624 [D loss: 0.948999, acc: 30.47%] [G loss: 9.808872]\n",
      "epoch:46 step:36625 [D loss: 0.034339, acc: 100.00%] [G loss: 5.995535]\n",
      "epoch:46 step:36626 [D loss: 0.507491, acc: 65.62%] [G loss: 6.530217]\n",
      "epoch:46 step:36627 [D loss: 0.108686, acc: 100.00%] [G loss: 8.225818]\n",
      "epoch:46 step:36628 [D loss: 0.730272, acc: 56.25%] [G loss: 9.090810]\n",
      "epoch:46 step:36629 [D loss: 0.335408, acc: 81.25%] [G loss: 8.887646]\n",
      "epoch:46 step:36630 [D loss: 0.375648, acc: 82.03%] [G loss: 5.162754]\n",
      "epoch:46 step:36631 [D loss: 0.065581, acc: 100.00%] [G loss: 5.624129]\n",
      "epoch:46 step:36632 [D loss: 0.059228, acc: 99.22%] [G loss: 7.667754]\n",
      "epoch:46 step:36633 [D loss: 0.082514, acc: 99.22%] [G loss: 4.294400]\n",
      "epoch:46 step:36634 [D loss: 0.078796, acc: 99.22%] [G loss: 5.862082]\n",
      "epoch:46 step:36635 [D loss: 0.211286, acc: 99.22%] [G loss: 8.748932]\n",
      "epoch:46 step:36636 [D loss: 0.130665, acc: 97.66%] [G loss: 5.861543]\n",
      "epoch:46 step:36637 [D loss: 0.009966, acc: 100.00%] [G loss: 4.652751]\n",
      "epoch:46 step:36638 [D loss: 0.278158, acc: 92.19%] [G loss: 7.500180]\n",
      "epoch:46 step:36639 [D loss: 1.174613, acc: 26.56%] [G loss: 7.123467]\n",
      "epoch:46 step:36640 [D loss: 0.147783, acc: 96.88%] [G loss: 9.610970]\n",
      "epoch:46 step:36641 [D loss: 0.061652, acc: 100.00%] [G loss: 3.773785]\n",
      "epoch:46 step:36642 [D loss: 1.803631, acc: 46.09%] [G loss: 6.397731]\n",
      "epoch:46 step:36643 [D loss: 0.249097, acc: 98.44%] [G loss: 8.537023]\n",
      "epoch:46 step:36644 [D loss: 0.832401, acc: 51.56%] [G loss: 6.273326]\n",
      "epoch:46 step:36645 [D loss: 0.661642, acc: 62.50%] [G loss: 8.018175]\n",
      "epoch:46 step:36646 [D loss: 0.055984, acc: 100.00%] [G loss: 6.299152]\n",
      "epoch:46 step:36647 [D loss: 0.374275, acc: 78.12%] [G loss: 8.134647]\n",
      "epoch:46 step:36648 [D loss: 0.265829, acc: 90.62%] [G loss: 8.299885]\n",
      "epoch:46 step:36649 [D loss: 0.318801, acc: 85.16%] [G loss: 8.972301]\n",
      "epoch:46 step:36650 [D loss: 0.031273, acc: 100.00%] [G loss: 8.749904]\n",
      "epoch:46 step:36651 [D loss: 0.192879, acc: 95.31%] [G loss: 3.152212]\n",
      "epoch:46 step:36652 [D loss: 0.050820, acc: 100.00%] [G loss: 7.478781]\n",
      "epoch:46 step:36653 [D loss: 0.053971, acc: 100.00%] [G loss: 5.651656]\n",
      "epoch:46 step:36654 [D loss: 0.332877, acc: 91.41%] [G loss: 8.355282]\n",
      "epoch:46 step:36655 [D loss: 0.414837, acc: 84.38%] [G loss: 4.225304]\n",
      "epoch:46 step:36656 [D loss: 0.117636, acc: 99.22%] [G loss: 7.329403]\n",
      "epoch:46 step:36657 [D loss: 0.359881, acc: 77.34%] [G loss: 9.539219]\n",
      "epoch:46 step:36658 [D loss: 0.262571, acc: 88.28%] [G loss: 5.493607]\n",
      "epoch:46 step:36659 [D loss: 0.264196, acc: 95.31%] [G loss: 2.490252]\n",
      "epoch:46 step:36660 [D loss: 0.844388, acc: 53.12%] [G loss: 6.795326]\n",
      "epoch:46 step:36661 [D loss: 0.163126, acc: 100.00%] [G loss: 6.928399]\n",
      "epoch:46 step:36662 [D loss: 0.233665, acc: 93.75%] [G loss: 3.695804]\n",
      "epoch:46 step:36663 [D loss: 0.236500, acc: 89.84%] [G loss: 7.535250]\n",
      "epoch:46 step:36664 [D loss: 0.089271, acc: 97.66%] [G loss: 5.410872]\n",
      "epoch:46 step:36665 [D loss: 0.194655, acc: 96.88%] [G loss: 5.931030]\n",
      "epoch:46 step:36666 [D loss: 0.235058, acc: 97.66%] [G loss: 6.293475]\n",
      "epoch:46 step:36667 [D loss: 0.284279, acc: 88.28%] [G loss: 5.758110]\n",
      "epoch:46 step:36668 [D loss: 0.204786, acc: 96.09%] [G loss: 5.510245]\n",
      "epoch:46 step:36669 [D loss: 1.158926, acc: 21.09%] [G loss: 6.849223]\n",
      "epoch:46 step:36670 [D loss: 0.116073, acc: 95.31%] [G loss: 9.483564]\n",
      "epoch:46 step:36671 [D loss: 0.859488, acc: 53.91%] [G loss: 6.782061]\n",
      "epoch:46 step:36672 [D loss: 0.197659, acc: 94.53%] [G loss: 10.534695]\n",
      "epoch:46 step:36673 [D loss: 0.543803, acc: 67.19%] [G loss: 10.690954]\n",
      "epoch:46 step:36674 [D loss: 0.061382, acc: 100.00%] [G loss: 8.035017]\n",
      "epoch:46 step:36675 [D loss: 0.570903, acc: 60.94%] [G loss: 7.032018]\n",
      "epoch:46 step:36676 [D loss: 0.184589, acc: 96.88%] [G loss: 7.465460]\n",
      "epoch:46 step:36677 [D loss: 0.258415, acc: 95.31%] [G loss: 5.433908]\n",
      "epoch:46 step:36678 [D loss: 0.197475, acc: 96.88%] [G loss: 5.366022]\n",
      "epoch:46 step:36679 [D loss: 0.655635, acc: 57.81%] [G loss: 5.009951]\n",
      "epoch:46 step:36680 [D loss: 0.283937, acc: 89.06%] [G loss: 4.978343]\n",
      "epoch:46 step:36681 [D loss: 1.340866, acc: 16.41%] [G loss: 5.752916]\n",
      "epoch:46 step:36682 [D loss: 0.146313, acc: 97.66%] [G loss: 5.011553]\n",
      "epoch:46 step:36683 [D loss: 0.079331, acc: 100.00%] [G loss: 5.484759]\n",
      "epoch:46 step:36684 [D loss: 1.141745, acc: 38.28%] [G loss: 7.959892]\n",
      "epoch:46 step:36685 [D loss: 0.235144, acc: 96.88%] [G loss: 6.050212]\n",
      "epoch:46 step:36686 [D loss: 0.016233, acc: 100.00%] [G loss: 9.623315]\n",
      "epoch:46 step:36687 [D loss: 0.477800, acc: 79.69%] [G loss: 4.143548]\n",
      "epoch:46 step:36688 [D loss: 1.156904, acc: 48.44%] [G loss: 4.345907]\n",
      "epoch:46 step:36689 [D loss: 0.190052, acc: 98.44%] [G loss: 4.820086]\n",
      "epoch:46 step:36690 [D loss: 0.150115, acc: 95.31%] [G loss: 10.601484]\n",
      "epoch:46 step:36691 [D loss: 0.084824, acc: 100.00%] [G loss: 6.019584]\n",
      "epoch:46 step:36692 [D loss: 0.438270, acc: 75.78%] [G loss: 5.127816]\n",
      "epoch:46 step:36693 [D loss: 0.276285, acc: 91.41%] [G loss: 5.296377]\n",
      "epoch:46 step:36694 [D loss: 0.406110, acc: 88.28%] [G loss: 7.099313]\n",
      "epoch:46 step:36695 [D loss: 0.336880, acc: 85.94%] [G loss: 4.816231]\n",
      "epoch:46 step:36696 [D loss: 0.142169, acc: 97.66%] [G loss: 4.864331]\n",
      "epoch:46 step:36697 [D loss: 1.268107, acc: 35.94%] [G loss: 5.519027]\n",
      "epoch:46 step:36698 [D loss: 0.185472, acc: 96.09%] [G loss: 2.763831]\n",
      "epoch:46 step:36699 [D loss: 0.029557, acc: 100.00%] [G loss: 12.264703]\n",
      "epoch:46 step:36700 [D loss: 0.216414, acc: 97.66%] [G loss: 8.149614]\n",
      "epoch:46 step:36701 [D loss: 0.175388, acc: 98.44%] [G loss: 6.403392]\n",
      "epoch:46 step:36702 [D loss: 0.830213, acc: 53.12%] [G loss: 8.984860]\n",
      "epoch:46 step:36703 [D loss: 0.108912, acc: 100.00%] [G loss: 5.124974]\n",
      "epoch:46 step:36704 [D loss: 0.858644, acc: 53.91%] [G loss: 8.144967]\n",
      "epoch:46 step:36705 [D loss: 0.039917, acc: 99.22%] [G loss: 8.815002]\n",
      "epoch:46 step:36706 [D loss: 0.401352, acc: 75.78%] [G loss: 4.781939]\n",
      "epoch:46 step:36707 [D loss: 0.402175, acc: 80.47%] [G loss: 6.120275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:36708 [D loss: 0.179274, acc: 96.88%] [G loss: 3.268922]\n",
      "epoch:47 step:36709 [D loss: 0.216802, acc: 92.97%] [G loss: 5.539825]\n",
      "epoch:47 step:36710 [D loss: 0.130441, acc: 97.66%] [G loss: 6.383585]\n",
      "epoch:47 step:36711 [D loss: 0.048659, acc: 100.00%] [G loss: 3.038783]\n",
      "epoch:47 step:36712 [D loss: 1.148275, acc: 28.91%] [G loss: 8.966479]\n",
      "epoch:47 step:36713 [D loss: 0.214980, acc: 94.53%] [G loss: 6.822766]\n",
      "epoch:47 step:36714 [D loss: 0.005863, acc: 100.00%] [G loss: 7.482072]\n",
      "epoch:47 step:36715 [D loss: 0.775100, acc: 55.47%] [G loss: 8.799980]\n",
      "epoch:47 step:36716 [D loss: 0.138480, acc: 97.66%] [G loss: 6.982783]\n",
      "epoch:47 step:36717 [D loss: 0.303176, acc: 84.38%] [G loss: 4.119838]\n",
      "epoch:47 step:36718 [D loss: 0.171039, acc: 96.09%] [G loss: 6.366986]\n",
      "epoch:47 step:36719 [D loss: 0.363253, acc: 86.72%] [G loss: 5.085352]\n",
      "epoch:47 step:36720 [D loss: 0.025029, acc: 100.00%] [G loss: 5.202385]\n",
      "epoch:47 step:36721 [D loss: 0.276537, acc: 92.19%] [G loss: 4.230545]\n",
      "epoch:47 step:36722 [D loss: 0.948203, acc: 28.91%] [G loss: 8.560437]\n",
      "epoch:47 step:36723 [D loss: 0.149195, acc: 98.44%] [G loss: 7.691998]\n",
      "epoch:47 step:36724 [D loss: 0.389667, acc: 72.66%] [G loss: 6.193330]\n",
      "epoch:47 step:36725 [D loss: 0.860842, acc: 45.31%] [G loss: 4.484370]\n",
      "epoch:47 step:36726 [D loss: 0.143968, acc: 99.22%] [G loss: 2.253195]\n",
      "epoch:47 step:36727 [D loss: 0.626856, acc: 59.38%] [G loss: 6.167797]\n",
      "epoch:47 step:36728 [D loss: 0.571446, acc: 53.91%] [G loss: 6.447824]\n",
      "epoch:47 step:36729 [D loss: 0.369574, acc: 85.16%] [G loss: 6.554843]\n",
      "epoch:47 step:36730 [D loss: 0.260907, acc: 87.50%] [G loss: 6.317167]\n",
      "epoch:47 step:36731 [D loss: 0.596573, acc: 68.75%] [G loss: 4.933871]\n",
      "epoch:47 step:36732 [D loss: 0.061318, acc: 100.00%] [G loss: 5.491876]\n",
      "epoch:47 step:36733 [D loss: 0.224742, acc: 93.75%] [G loss: 4.548221]\n",
      "epoch:47 step:36734 [D loss: 0.049105, acc: 99.22%] [G loss: 4.356523]\n",
      "epoch:47 step:36735 [D loss: 0.187419, acc: 98.44%] [G loss: 4.352760]\n",
      "epoch:47 step:36736 [D loss: 0.666685, acc: 57.81%] [G loss: 5.226824]\n",
      "epoch:47 step:36737 [D loss: 0.632320, acc: 60.16%] [G loss: 5.270770]\n",
      "epoch:47 step:36738 [D loss: 0.027006, acc: 100.00%] [G loss: 4.381091]\n",
      "epoch:47 step:36739 [D loss: 0.696210, acc: 56.25%] [G loss: 5.955453]\n",
      "epoch:47 step:36740 [D loss: 0.434124, acc: 71.09%] [G loss: 6.232420]\n",
      "epoch:47 step:36741 [D loss: 0.155234, acc: 99.22%] [G loss: 8.794466]\n",
      "epoch:47 step:36742 [D loss: 0.163900, acc: 100.00%] [G loss: 4.122643]\n",
      "epoch:47 step:36743 [D loss: 0.176530, acc: 96.88%] [G loss: 5.630446]\n",
      "epoch:47 step:36744 [D loss: 0.067556, acc: 100.00%] [G loss: 9.030533]\n",
      "epoch:47 step:36745 [D loss: 0.254093, acc: 89.84%] [G loss: 8.964545]\n",
      "epoch:47 step:36746 [D loss: 0.574514, acc: 71.88%] [G loss: 5.233238]\n",
      "epoch:47 step:36747 [D loss: 0.069199, acc: 100.00%] [G loss: 5.817365]\n",
      "epoch:47 step:36748 [D loss: 0.171493, acc: 96.09%] [G loss: 5.206634]\n",
      "epoch:47 step:36749 [D loss: 0.114934, acc: 98.44%] [G loss: 3.802775]\n",
      "epoch:47 step:36750 [D loss: 0.580869, acc: 59.38%] [G loss: 5.058597]\n",
      "epoch:47 step:36751 [D loss: 0.349938, acc: 78.91%] [G loss: 4.733387]\n",
      "epoch:47 step:36752 [D loss: 0.081947, acc: 99.22%] [G loss: 3.452285]\n",
      "epoch:47 step:36753 [D loss: 0.442786, acc: 72.66%] [G loss: 2.495012]\n",
      "epoch:47 step:36754 [D loss: 0.385145, acc: 84.38%] [G loss: 8.321720]\n",
      "epoch:47 step:36755 [D loss: 1.291931, acc: 49.22%] [G loss: 9.158298]\n",
      "epoch:47 step:36756 [D loss: 0.813068, acc: 52.34%] [G loss: 6.850215]\n",
      "epoch:47 step:36757 [D loss: 0.106149, acc: 99.22%] [G loss: 3.876912]\n",
      "epoch:47 step:36758 [D loss: 0.345537, acc: 92.19%] [G loss: 5.792391]\n",
      "epoch:47 step:36759 [D loss: 0.081893, acc: 100.00%] [G loss: 2.841962]\n",
      "epoch:47 step:36760 [D loss: 0.771586, acc: 58.59%] [G loss: 6.621158]\n",
      "epoch:47 step:36761 [D loss: 0.109869, acc: 100.00%] [G loss: 7.377754]\n",
      "epoch:47 step:36762 [D loss: 0.891376, acc: 52.34%] [G loss: 6.417473]\n",
      "epoch:47 step:36763 [D loss: 0.366988, acc: 86.72%] [G loss: 6.258534]\n",
      "epoch:47 step:36764 [D loss: 0.522068, acc: 63.28%] [G loss: 7.101208]\n",
      "epoch:47 step:36765 [D loss: 0.459770, acc: 67.97%] [G loss: 8.168734]\n",
      "epoch:47 step:36766 [D loss: 0.149664, acc: 100.00%] [G loss: 6.209683]\n",
      "epoch:47 step:36767 [D loss: 0.194345, acc: 98.44%] [G loss: 5.433738]\n",
      "epoch:47 step:36768 [D loss: 0.030230, acc: 100.00%] [G loss: 5.742707]\n",
      "epoch:47 step:36769 [D loss: 0.079534, acc: 100.00%] [G loss: 6.441314]\n",
      "epoch:47 step:36770 [D loss: 0.099623, acc: 99.22%] [G loss: 7.259648]\n",
      "epoch:47 step:36771 [D loss: 0.250324, acc: 94.53%] [G loss: 5.226797]\n",
      "epoch:47 step:36772 [D loss: 0.377633, acc: 85.94%] [G loss: 4.200845]\n",
      "epoch:47 step:36773 [D loss: 0.873227, acc: 47.66%] [G loss: 6.874609]\n",
      "epoch:47 step:36774 [D loss: 0.271018, acc: 95.31%] [G loss: 5.423244]\n",
      "epoch:47 step:36775 [D loss: 1.018266, acc: 35.16%] [G loss: 6.235237]\n",
      "epoch:47 step:36776 [D loss: 0.070878, acc: 99.22%] [G loss: 6.746008]\n",
      "epoch:47 step:36777 [D loss: 0.632797, acc: 61.72%] [G loss: 4.761042]\n",
      "epoch:47 step:36778 [D loss: 0.847205, acc: 50.00%] [G loss: 10.096866]\n",
      "epoch:47 step:36779 [D loss: 0.098195, acc: 99.22%] [G loss: 7.242567]\n",
      "epoch:47 step:36780 [D loss: 0.035672, acc: 100.00%] [G loss: 6.630042]\n",
      "epoch:47 step:36781 [D loss: 0.124566, acc: 97.66%] [G loss: 4.125536]\n",
      "epoch:47 step:36782 [D loss: 0.440870, acc: 78.91%] [G loss: 4.507892]\n",
      "epoch:47 step:36783 [D loss: 0.516072, acc: 69.53%] [G loss: 6.523988]\n",
      "epoch:47 step:36784 [D loss: 0.162343, acc: 96.09%] [G loss: 6.764277]\n",
      "epoch:47 step:36785 [D loss: 0.105695, acc: 99.22%] [G loss: 11.496286]\n",
      "epoch:47 step:36786 [D loss: 0.164992, acc: 97.66%] [G loss: 7.068330]\n",
      "epoch:47 step:36787 [D loss: 0.157150, acc: 96.88%] [G loss: 7.205263]\n",
      "epoch:47 step:36788 [D loss: 0.057173, acc: 100.00%] [G loss: 8.494007]\n",
      "epoch:47 step:36789 [D loss: 0.322715, acc: 83.59%] [G loss: 6.096096]\n",
      "epoch:47 step:36790 [D loss: 0.269054, acc: 92.97%] [G loss: 5.620843]\n",
      "epoch:47 step:36791 [D loss: 0.093564, acc: 98.44%] [G loss: 6.643663]\n",
      "epoch:47 step:36792 [D loss: 0.421656, acc: 72.66%] [G loss: 3.728207]\n",
      "epoch:47 step:36793 [D loss: 0.171888, acc: 98.44%] [G loss: 4.791648]\n",
      "epoch:47 step:36794 [D loss: 0.065544, acc: 99.22%] [G loss: 7.972552]\n",
      "epoch:47 step:36795 [D loss: 0.100707, acc: 100.00%] [G loss: 5.270651]\n",
      "epoch:47 step:36796 [D loss: 0.047493, acc: 100.00%] [G loss: 6.090487]\n",
      "epoch:47 step:36797 [D loss: 0.553181, acc: 61.72%] [G loss: 5.762927]\n",
      "epoch:47 step:36798 [D loss: 0.082002, acc: 100.00%] [G loss: 4.985303]\n",
      "epoch:47 step:36799 [D loss: 0.287394, acc: 87.50%] [G loss: 6.935549]\n",
      "epoch:47 step:36800 [D loss: 0.367068, acc: 86.72%] [G loss: 4.689398]\n",
      "epoch:47 step:36801 [D loss: 0.123495, acc: 100.00%] [G loss: 2.827580]\n",
      "epoch:47 step:36802 [D loss: 0.705752, acc: 60.16%] [G loss: 4.307724]\n",
      "epoch:47 step:36803 [D loss: 0.181349, acc: 95.31%] [G loss: 4.851054]\n",
      "epoch:47 step:36804 [D loss: 0.166227, acc: 97.66%] [G loss: 6.708165]\n",
      "epoch:47 step:36805 [D loss: 0.447229, acc: 69.53%] [G loss: 8.650657]\n",
      "epoch:47 step:36806 [D loss: 0.123414, acc: 99.22%] [G loss: 5.841141]\n",
      "epoch:47 step:36807 [D loss: 2.071492, acc: 50.00%] [G loss: 9.383856]\n",
      "epoch:47 step:36808 [D loss: 0.886894, acc: 54.69%] [G loss: 4.130671]\n",
      "epoch:47 step:36809 [D loss: 0.075442, acc: 99.22%] [G loss: 2.581291]\n",
      "epoch:47 step:36810 [D loss: 0.420556, acc: 77.34%] [G loss: 5.142403]\n",
      "epoch:47 step:36811 [D loss: 0.052614, acc: 100.00%] [G loss: 6.115970]\n",
      "epoch:47 step:36812 [D loss: 0.084784, acc: 97.66%] [G loss: 5.105141]\n",
      "epoch:47 step:36813 [D loss: 0.091693, acc: 99.22%] [G loss: 7.441069]\n",
      "epoch:47 step:36814 [D loss: 0.455127, acc: 78.91%] [G loss: 7.353646]\n",
      "epoch:47 step:36815 [D loss: 0.227685, acc: 94.53%] [G loss: 6.101477]\n",
      "epoch:47 step:36816 [D loss: 0.116048, acc: 99.22%] [G loss: 3.710966]\n",
      "epoch:47 step:36817 [D loss: 0.391019, acc: 85.94%] [G loss: 6.878985]\n",
      "epoch:47 step:36818 [D loss: 0.291857, acc: 89.06%] [G loss: 6.626350]\n",
      "epoch:47 step:36819 [D loss: 0.083522, acc: 100.00%] [G loss: 5.482160]\n",
      "epoch:47 step:36820 [D loss: 0.363069, acc: 81.25%] [G loss: 8.167140]\n",
      "epoch:47 step:36821 [D loss: 0.053123, acc: 98.44%] [G loss: 5.957279]\n",
      "epoch:47 step:36822 [D loss: 0.125507, acc: 99.22%] [G loss: 4.904412]\n",
      "epoch:47 step:36823 [D loss: 0.208474, acc: 94.53%] [G loss: 5.985885]\n",
      "epoch:47 step:36824 [D loss: 0.832370, acc: 49.22%] [G loss: 2.898904]\n",
      "epoch:47 step:36825 [D loss: 0.103665, acc: 99.22%] [G loss: 6.639282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:36826 [D loss: 0.247769, acc: 87.50%] [G loss: 2.680557]\n",
      "epoch:47 step:36827 [D loss: 0.192923, acc: 96.09%] [G loss: 4.201700]\n",
      "epoch:47 step:36828 [D loss: 0.631597, acc: 62.50%] [G loss: 5.556950]\n",
      "epoch:47 step:36829 [D loss: 0.050173, acc: 100.00%] [G loss: 6.967468]\n",
      "epoch:47 step:36830 [D loss: 0.339253, acc: 88.28%] [G loss: 6.543962]\n",
      "epoch:47 step:36831 [D loss: 1.356206, acc: 11.72%] [G loss: 6.185243]\n",
      "epoch:47 step:36832 [D loss: 0.018687, acc: 100.00%] [G loss: 7.107162]\n",
      "epoch:47 step:36833 [D loss: 0.115332, acc: 99.22%] [G loss: 6.751487]\n",
      "epoch:47 step:36834 [D loss: 0.225607, acc: 97.66%] [G loss: 5.970145]\n",
      "epoch:47 step:36835 [D loss: 0.175751, acc: 95.31%] [G loss: 5.813212]\n",
      "epoch:47 step:36836 [D loss: 0.246915, acc: 94.53%] [G loss: 7.928038]\n",
      "epoch:47 step:36837 [D loss: 2.494816, acc: 5.47%] [G loss: 9.287571]\n",
      "epoch:47 step:36838 [D loss: 0.085715, acc: 100.00%] [G loss: 1.773481]\n",
      "epoch:47 step:36839 [D loss: 0.316610, acc: 82.81%] [G loss: 8.050529]\n",
      "epoch:47 step:36840 [D loss: 0.560074, acc: 60.94%] [G loss: 4.938295]\n",
      "epoch:47 step:36841 [D loss: 1.156839, acc: 51.56%] [G loss: 7.817557]\n",
      "epoch:47 step:36842 [D loss: 0.233878, acc: 92.97%] [G loss: 5.988717]\n",
      "epoch:47 step:36843 [D loss: 0.122178, acc: 98.44%] [G loss: 10.411217]\n",
      "epoch:47 step:36844 [D loss: 0.307607, acc: 82.03%] [G loss: 6.693757]\n",
      "epoch:47 step:36845 [D loss: 0.264112, acc: 96.09%] [G loss: 6.761890]\n",
      "epoch:47 step:36846 [D loss: 0.019580, acc: 100.00%] [G loss: 6.535788]\n",
      "epoch:47 step:36847 [D loss: 0.116053, acc: 98.44%] [G loss: 10.493695]\n",
      "epoch:47 step:36848 [D loss: 0.607135, acc: 58.59%] [G loss: 4.091040]\n",
      "epoch:47 step:36849 [D loss: 0.303594, acc: 87.50%] [G loss: 5.326180]\n",
      "epoch:47 step:36850 [D loss: 0.314717, acc: 84.38%] [G loss: 5.332941]\n",
      "epoch:47 step:36851 [D loss: 0.211961, acc: 96.88%] [G loss: 7.440145]\n",
      "epoch:47 step:36852 [D loss: 0.321012, acc: 83.59%] [G loss: 4.275125]\n",
      "epoch:47 step:36853 [D loss: 0.095429, acc: 99.22%] [G loss: 7.567000]\n",
      "epoch:47 step:36854 [D loss: 0.578353, acc: 63.28%] [G loss: 7.632499]\n",
      "epoch:47 step:36855 [D loss: 0.099940, acc: 100.00%] [G loss: 7.192338]\n",
      "epoch:47 step:36856 [D loss: 0.448037, acc: 74.22%] [G loss: 8.363285]\n",
      "epoch:47 step:36857 [D loss: 0.025424, acc: 100.00%] [G loss: 6.184756]\n",
      "epoch:47 step:36858 [D loss: 0.055927, acc: 100.00%] [G loss: 8.818297]\n",
      "epoch:47 step:36859 [D loss: 0.411095, acc: 85.16%] [G loss: 1.966277]\n",
      "epoch:47 step:36860 [D loss: 0.385747, acc: 82.81%] [G loss: 5.376033]\n",
      "epoch:47 step:36861 [D loss: 0.089505, acc: 99.22%] [G loss: 8.043208]\n",
      "epoch:47 step:36862 [D loss: 0.949631, acc: 51.56%] [G loss: 7.419439]\n",
      "epoch:47 step:36863 [D loss: 0.290773, acc: 89.06%] [G loss: 6.039198]\n",
      "epoch:47 step:36864 [D loss: 0.368946, acc: 76.56%] [G loss: 3.298190]\n",
      "epoch:47 step:36865 [D loss: 0.120464, acc: 97.66%] [G loss: 7.959219]\n",
      "epoch:47 step:36866 [D loss: 0.123218, acc: 98.44%] [G loss: 6.731317]\n",
      "epoch:47 step:36867 [D loss: 0.177560, acc: 97.66%] [G loss: 5.816358]\n",
      "epoch:47 step:36868 [D loss: 0.275557, acc: 90.62%] [G loss: 6.646554]\n",
      "epoch:47 step:36869 [D loss: 0.306883, acc: 83.59%] [G loss: 10.397303]\n",
      "epoch:47 step:36870 [D loss: 0.312418, acc: 86.72%] [G loss: 4.947846]\n",
      "epoch:47 step:36871 [D loss: 0.027533, acc: 100.00%] [G loss: 4.790566]\n",
      "epoch:47 step:36872 [D loss: 0.220323, acc: 94.53%] [G loss: 6.486555]\n",
      "epoch:47 step:36873 [D loss: 0.118854, acc: 100.00%] [G loss: 7.472044]\n",
      "epoch:47 step:36874 [D loss: 0.226757, acc: 93.75%] [G loss: 12.427030]\n",
      "epoch:47 step:36875 [D loss: 0.197444, acc: 97.66%] [G loss: 6.003011]\n",
      "epoch:47 step:36876 [D loss: 0.317029, acc: 78.12%] [G loss: 5.064670]\n",
      "epoch:47 step:36877 [D loss: 0.938193, acc: 50.00%] [G loss: 5.624990]\n",
      "epoch:47 step:36878 [D loss: 0.564071, acc: 63.28%] [G loss: 3.761135]\n",
      "epoch:47 step:36879 [D loss: 0.069943, acc: 100.00%] [G loss: 8.792685]\n",
      "epoch:47 step:36880 [D loss: 1.460481, acc: 22.66%] [G loss: 8.290583]\n",
      "epoch:47 step:36881 [D loss: 0.677738, acc: 56.25%] [G loss: 5.447863]\n",
      "epoch:47 step:36882 [D loss: 0.010765, acc: 100.00%] [G loss: 8.160804]\n",
      "epoch:47 step:36883 [D loss: 0.490875, acc: 73.44%] [G loss: 4.188371]\n",
      "epoch:47 step:36884 [D loss: 0.049104, acc: 100.00%] [G loss: 3.214932]\n",
      "epoch:47 step:36885 [D loss: 0.160448, acc: 96.88%] [G loss: 6.329229]\n",
      "epoch:47 step:36886 [D loss: 0.213525, acc: 96.09%] [G loss: 5.042791]\n",
      "epoch:47 step:36887 [D loss: 0.349008, acc: 91.41%] [G loss: 7.133488]\n",
      "epoch:47 step:36888 [D loss: 0.038818, acc: 100.00%] [G loss: 5.046372]\n",
      "epoch:47 step:36889 [D loss: 0.030856, acc: 100.00%] [G loss: 10.826017]\n",
      "epoch:47 step:36890 [D loss: 1.068250, acc: 28.91%] [G loss: 6.237581]\n",
      "epoch:47 step:36891 [D loss: 0.279498, acc: 92.19%] [G loss: 7.290936]\n",
      "epoch:47 step:36892 [D loss: 0.376731, acc: 87.50%] [G loss: 4.011582]\n",
      "epoch:47 step:36893 [D loss: 0.126498, acc: 98.44%] [G loss: 6.865803]\n",
      "epoch:47 step:36894 [D loss: 0.080784, acc: 100.00%] [G loss: 5.987054]\n",
      "epoch:47 step:36895 [D loss: 0.167658, acc: 97.66%] [G loss: 7.956115]\n",
      "epoch:47 step:36896 [D loss: 0.026349, acc: 100.00%] [G loss: 10.540579]\n",
      "epoch:47 step:36897 [D loss: 0.366262, acc: 75.00%] [G loss: 7.676099]\n",
      "epoch:47 step:36898 [D loss: 0.332376, acc: 88.28%] [G loss: 7.578859]\n",
      "epoch:47 step:36899 [D loss: 0.183399, acc: 93.75%] [G loss: 5.864302]\n",
      "epoch:47 step:36900 [D loss: 0.123779, acc: 98.44%] [G loss: 5.229511]\n",
      "epoch:47 step:36901 [D loss: 0.094154, acc: 100.00%] [G loss: 5.488667]\n",
      "epoch:47 step:36902 [D loss: 0.289854, acc: 89.84%] [G loss: 5.958917]\n",
      "epoch:47 step:36903 [D loss: 0.329891, acc: 80.47%] [G loss: 4.154666]\n",
      "epoch:47 step:36904 [D loss: 0.076250, acc: 99.22%] [G loss: 7.964398]\n",
      "epoch:47 step:36905 [D loss: 0.015508, acc: 100.00%] [G loss: 6.574976]\n",
      "epoch:47 step:36906 [D loss: 0.192860, acc: 99.22%] [G loss: 6.464474]\n",
      "epoch:47 step:36907 [D loss: 0.158996, acc: 99.22%] [G loss: 4.136579]\n",
      "epoch:47 step:36908 [D loss: 0.171496, acc: 98.44%] [G loss: 3.592014]\n",
      "epoch:47 step:36909 [D loss: 1.041770, acc: 51.56%] [G loss: 6.218486]\n",
      "epoch:47 step:36910 [D loss: 0.489748, acc: 74.22%] [G loss: 5.716874]\n",
      "epoch:47 step:36911 [D loss: 0.141706, acc: 98.44%] [G loss: 6.849662]\n",
      "epoch:47 step:36912 [D loss: 0.100931, acc: 100.00%] [G loss: 6.455880]\n",
      "epoch:47 step:36913 [D loss: 0.253168, acc: 95.31%] [G loss: 6.487446]\n",
      "epoch:47 step:36914 [D loss: 0.054351, acc: 99.22%] [G loss: 5.192992]\n",
      "epoch:47 step:36915 [D loss: 0.041611, acc: 100.00%] [G loss: 4.892581]\n",
      "epoch:47 step:36916 [D loss: 0.318507, acc: 93.75%] [G loss: 4.013642]\n",
      "epoch:47 step:36917 [D loss: 0.174825, acc: 99.22%] [G loss: 5.577182]\n",
      "epoch:47 step:36918 [D loss: 1.447564, acc: 30.47%] [G loss: 5.938169]\n",
      "epoch:47 step:36919 [D loss: 0.117557, acc: 100.00%] [G loss: 5.586747]\n",
      "epoch:47 step:36920 [D loss: 0.197282, acc: 94.53%] [G loss: 6.756032]\n",
      "epoch:47 step:36921 [D loss: 0.046986, acc: 100.00%] [G loss: 5.966968]\n",
      "epoch:47 step:36922 [D loss: 0.015664, acc: 100.00%] [G loss: 7.498792]\n",
      "epoch:47 step:36923 [D loss: 0.393618, acc: 75.78%] [G loss: 8.176041]\n",
      "epoch:47 step:36924 [D loss: 0.292016, acc: 89.06%] [G loss: 7.264802]\n",
      "epoch:47 step:36925 [D loss: 0.238953, acc: 92.97%] [G loss: 5.861342]\n",
      "epoch:47 step:36926 [D loss: 0.295769, acc: 89.84%] [G loss: 4.465874]\n",
      "epoch:47 step:36927 [D loss: 0.203295, acc: 96.88%] [G loss: 8.143000]\n",
      "epoch:47 step:36928 [D loss: 1.452644, acc: 46.09%] [G loss: 8.940277]\n",
      "epoch:47 step:36929 [D loss: 0.980814, acc: 36.72%] [G loss: 6.618365]\n",
      "epoch:47 step:36930 [D loss: 0.357020, acc: 91.41%] [G loss: 4.500705]\n",
      "epoch:47 step:36931 [D loss: 1.357625, acc: 10.16%] [G loss: 8.442474]\n",
      "epoch:47 step:36932 [D loss: 1.056865, acc: 50.00%] [G loss: 10.227272]\n",
      "epoch:47 step:36933 [D loss: 0.071434, acc: 100.00%] [G loss: 8.842788]\n",
      "epoch:47 step:36934 [D loss: 0.288721, acc: 83.59%] [G loss: 7.130408]\n",
      "epoch:47 step:36935 [D loss: 0.051693, acc: 100.00%] [G loss: 5.787472]\n",
      "epoch:47 step:36936 [D loss: 0.340144, acc: 85.16%] [G loss: 5.774035]\n",
      "epoch:47 step:36937 [D loss: 1.503245, acc: 35.94%] [G loss: 5.122328]\n",
      "epoch:47 step:36938 [D loss: 0.187739, acc: 95.31%] [G loss: 8.155294]\n",
      "epoch:47 step:36939 [D loss: 0.164357, acc: 96.09%] [G loss: 3.131501]\n",
      "epoch:47 step:36940 [D loss: 0.806535, acc: 54.69%] [G loss: 7.847302]\n",
      "epoch:47 step:36941 [D loss: 0.082311, acc: 98.44%] [G loss: 3.352004]\n",
      "epoch:47 step:36942 [D loss: 0.079855, acc: 100.00%] [G loss: 7.248211]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:36943 [D loss: 0.086159, acc: 99.22%] [G loss: 7.644933]\n",
      "epoch:47 step:36944 [D loss: 0.047840, acc: 100.00%] [G loss: 2.922091]\n",
      "epoch:47 step:36945 [D loss: 0.396268, acc: 76.56%] [G loss: 6.209929]\n",
      "epoch:47 step:36946 [D loss: 0.101739, acc: 99.22%] [G loss: 6.927664]\n",
      "epoch:47 step:36947 [D loss: 0.162617, acc: 98.44%] [G loss: 4.831872]\n",
      "epoch:47 step:36948 [D loss: 0.045225, acc: 100.00%] [G loss: 4.965494]\n",
      "epoch:47 step:36949 [D loss: 0.060730, acc: 99.22%] [G loss: 9.812204]\n",
      "epoch:47 step:36950 [D loss: 0.098839, acc: 99.22%] [G loss: 5.226534]\n",
      "epoch:47 step:36951 [D loss: 0.040266, acc: 100.00%] [G loss: 4.009093]\n",
      "epoch:47 step:36952 [D loss: 0.444183, acc: 74.22%] [G loss: 7.467119]\n",
      "epoch:47 step:36953 [D loss: 1.398939, acc: 48.44%] [G loss: 4.206773]\n",
      "epoch:47 step:36954 [D loss: 0.262748, acc: 95.31%] [G loss: 6.134824]\n",
      "epoch:47 step:36955 [D loss: 0.496982, acc: 77.34%] [G loss: 8.382751]\n",
      "epoch:47 step:36956 [D loss: 1.491159, acc: 46.88%] [G loss: 6.576146]\n",
      "epoch:47 step:36957 [D loss: 1.229009, acc: 53.12%] [G loss: 9.834878]\n",
      "epoch:47 step:36958 [D loss: 0.143834, acc: 99.22%] [G loss: 11.455037]\n",
      "epoch:47 step:36959 [D loss: 0.107596, acc: 99.22%] [G loss: 4.413394]\n",
      "epoch:47 step:36960 [D loss: 0.888541, acc: 52.34%] [G loss: 4.320675]\n",
      "epoch:47 step:36961 [D loss: 0.095572, acc: 100.00%] [G loss: 5.136926]\n",
      "epoch:47 step:36962 [D loss: 0.139654, acc: 98.44%] [G loss: 4.425475]\n",
      "epoch:47 step:36963 [D loss: 0.122902, acc: 98.44%] [G loss: 6.577847]\n",
      "epoch:47 step:36964 [D loss: 0.439709, acc: 69.53%] [G loss: 5.322290]\n",
      "epoch:47 step:36965 [D loss: 0.034942, acc: 100.00%] [G loss: 3.293236]\n",
      "epoch:47 step:36966 [D loss: 0.083061, acc: 99.22%] [G loss: 6.786597]\n",
      "epoch:47 step:36967 [D loss: 0.182801, acc: 97.66%] [G loss: 5.853478]\n",
      "epoch:47 step:36968 [D loss: 0.091478, acc: 100.00%] [G loss: 4.809450]\n",
      "epoch:47 step:36969 [D loss: 0.267456, acc: 89.06%] [G loss: 7.160064]\n",
      "epoch:47 step:36970 [D loss: 0.079690, acc: 100.00%] [G loss: 8.046320]\n",
      "epoch:47 step:36971 [D loss: 1.140152, acc: 21.09%] [G loss: 7.272691]\n",
      "epoch:47 step:36972 [D loss: 1.883802, acc: 11.72%] [G loss: 7.561266]\n",
      "epoch:47 step:36973 [D loss: 0.113997, acc: 100.00%] [G loss: 3.934441]\n",
      "epoch:47 step:36974 [D loss: 0.974172, acc: 43.75%] [G loss: 3.747066]\n",
      "epoch:47 step:36975 [D loss: 0.794305, acc: 47.66%] [G loss: 7.302873]\n",
      "epoch:47 step:36976 [D loss: 0.135224, acc: 98.44%] [G loss: 3.849375]\n",
      "epoch:47 step:36977 [D loss: 0.211668, acc: 94.53%] [G loss: 4.059585]\n",
      "epoch:47 step:36978 [D loss: 0.130134, acc: 97.66%] [G loss: 4.663795]\n",
      "epoch:47 step:36979 [D loss: 0.201313, acc: 95.31%] [G loss: 9.623795]\n",
      "epoch:47 step:36980 [D loss: 0.653860, acc: 59.38%] [G loss: 7.072555]\n",
      "epoch:47 step:36981 [D loss: 0.235758, acc: 96.88%] [G loss: 5.664699]\n",
      "epoch:47 step:36982 [D loss: 0.234689, acc: 96.09%] [G loss: 4.168720]\n",
      "epoch:47 step:36983 [D loss: 0.040106, acc: 100.00%] [G loss: 5.117990]\n",
      "epoch:47 step:36984 [D loss: 0.504994, acc: 64.84%] [G loss: 6.393355]\n",
      "epoch:47 step:36985 [D loss: 0.061825, acc: 99.22%] [G loss: 9.084587]\n",
      "epoch:47 step:36986 [D loss: 0.638333, acc: 56.25%] [G loss: 8.412284]\n",
      "epoch:47 step:36987 [D loss: 0.234751, acc: 96.88%] [G loss: 5.212302]\n",
      "epoch:47 step:36988 [D loss: 0.130259, acc: 99.22%] [G loss: 6.025379]\n",
      "epoch:47 step:36989 [D loss: 0.070380, acc: 99.22%] [G loss: 4.110787]\n",
      "epoch:47 step:36990 [D loss: 0.562786, acc: 64.06%] [G loss: 4.167671]\n",
      "epoch:47 step:36991 [D loss: 0.638547, acc: 56.25%] [G loss: 6.581590]\n",
      "epoch:47 step:36992 [D loss: 0.450348, acc: 80.47%] [G loss: 7.665160]\n",
      "epoch:47 step:36993 [D loss: 0.259479, acc: 96.88%] [G loss: 4.915139]\n",
      "epoch:47 step:36994 [D loss: 0.654265, acc: 61.72%] [G loss: 6.832086]\n",
      "epoch:47 step:36995 [D loss: 0.125651, acc: 99.22%] [G loss: 5.860291]\n",
      "epoch:47 step:36996 [D loss: 0.060087, acc: 100.00%] [G loss: 3.627000]\n",
      "epoch:47 step:36997 [D loss: 0.035675, acc: 100.00%] [G loss: 6.047799]\n",
      "epoch:47 step:36998 [D loss: 0.125517, acc: 98.44%] [G loss: 2.934591]\n",
      "epoch:47 step:36999 [D loss: 0.067393, acc: 100.00%] [G loss: 4.997848]\n",
      "epoch:47 step:37000 [D loss: 0.140964, acc: 99.22%] [G loss: 8.723793]\n",
      "epoch:47 step:37001 [D loss: 0.375580, acc: 82.03%] [G loss: 4.623881]\n",
      "epoch:47 step:37002 [D loss: 1.066342, acc: 39.84%] [G loss: 6.557846]\n",
      "epoch:47 step:37003 [D loss: 0.071063, acc: 100.00%] [G loss: 9.664716]\n",
      "epoch:47 step:37004 [D loss: 0.263543, acc: 86.72%] [G loss: 7.127164]\n",
      "epoch:47 step:37005 [D loss: 1.439526, acc: 11.72%] [G loss: 10.143504]\n",
      "epoch:47 step:37006 [D loss: 0.045484, acc: 100.00%] [G loss: 3.889200]\n",
      "epoch:47 step:37007 [D loss: 0.038537, acc: 100.00%] [G loss: 4.095089]\n",
      "epoch:47 step:37008 [D loss: 0.645151, acc: 58.59%] [G loss: 10.674971]\n",
      "epoch:47 step:37009 [D loss: 0.081968, acc: 99.22%] [G loss: 5.345253]\n",
      "epoch:47 step:37010 [D loss: 0.944174, acc: 51.56%] [G loss: 7.658761]\n",
      "epoch:47 step:37011 [D loss: 0.139266, acc: 97.66%] [G loss: 6.317462]\n",
      "epoch:47 step:37012 [D loss: 0.114279, acc: 100.00%] [G loss: 6.166224]\n",
      "epoch:47 step:37013 [D loss: 0.055776, acc: 99.22%] [G loss: 8.136050]\n",
      "epoch:47 step:37014 [D loss: 0.537467, acc: 72.66%] [G loss: 5.604695]\n",
      "epoch:47 step:37015 [D loss: 0.058600, acc: 100.00%] [G loss: 6.105949]\n",
      "epoch:47 step:37016 [D loss: 0.264668, acc: 87.50%] [G loss: 5.535293]\n",
      "epoch:47 step:37017 [D loss: 0.109295, acc: 98.44%] [G loss: 6.232741]\n",
      "epoch:47 step:37018 [D loss: 0.121542, acc: 100.00%] [G loss: 6.414071]\n",
      "epoch:47 step:37019 [D loss: 0.309268, acc: 86.72%] [G loss: 8.976343]\n",
      "epoch:47 step:37020 [D loss: 0.269836, acc: 89.06%] [G loss: 5.080333]\n",
      "epoch:47 step:37021 [D loss: 0.057555, acc: 100.00%] [G loss: 6.784115]\n",
      "epoch:47 step:37022 [D loss: 0.975442, acc: 51.56%] [G loss: 7.748678]\n",
      "epoch:47 step:37023 [D loss: 0.100737, acc: 100.00%] [G loss: 4.531573]\n",
      "epoch:47 step:37024 [D loss: 0.363072, acc: 78.91%] [G loss: 8.042793]\n",
      "epoch:47 step:37025 [D loss: 0.168931, acc: 98.44%] [G loss: 5.572367]\n",
      "epoch:47 step:37026 [D loss: 0.926156, acc: 53.12%] [G loss: 4.234344]\n",
      "epoch:47 step:37027 [D loss: 0.124013, acc: 99.22%] [G loss: 5.822073]\n",
      "epoch:47 step:37028 [D loss: 0.289024, acc: 93.75%] [G loss: 5.715183]\n",
      "epoch:47 step:37029 [D loss: 0.052821, acc: 100.00%] [G loss: 6.901053]\n",
      "epoch:47 step:37030 [D loss: 0.356874, acc: 80.47%] [G loss: 5.235873]\n",
      "epoch:47 step:37031 [D loss: 0.174974, acc: 97.66%] [G loss: 2.147059]\n",
      "epoch:47 step:37032 [D loss: 0.274048, acc: 94.53%] [G loss: 6.268900]\n",
      "epoch:47 step:37033 [D loss: 0.628788, acc: 57.81%] [G loss: 6.541893]\n",
      "epoch:47 step:37034 [D loss: 0.141932, acc: 99.22%] [G loss: 6.392837]\n",
      "epoch:47 step:37035 [D loss: 0.142052, acc: 97.66%] [G loss: 9.811539]\n",
      "epoch:47 step:37036 [D loss: 0.090711, acc: 100.00%] [G loss: 7.400598]\n",
      "epoch:47 step:37037 [D loss: 0.270490, acc: 85.94%] [G loss: 5.698536]\n",
      "epoch:47 step:37038 [D loss: 0.066492, acc: 99.22%] [G loss: 4.285144]\n",
      "epoch:47 step:37039 [D loss: 0.210764, acc: 92.97%] [G loss: 5.281141]\n",
      "epoch:47 step:37040 [D loss: 0.033522, acc: 100.00%] [G loss: 6.952613]\n",
      "epoch:47 step:37041 [D loss: 0.032974, acc: 100.00%] [G loss: 6.514045]\n",
      "epoch:47 step:37042 [D loss: 0.102257, acc: 99.22%] [G loss: 11.473057]\n",
      "epoch:47 step:37043 [D loss: 0.213887, acc: 99.22%] [G loss: 4.985786]\n",
      "epoch:47 step:37044 [D loss: 0.104301, acc: 98.44%] [G loss: 5.058062]\n",
      "epoch:47 step:37045 [D loss: 0.109730, acc: 100.00%] [G loss: 3.297463]\n",
      "epoch:47 step:37046 [D loss: 0.636740, acc: 56.25%] [G loss: 4.970400]\n",
      "epoch:47 step:37047 [D loss: 0.282195, acc: 95.31%] [G loss: 4.143213]\n",
      "epoch:47 step:37048 [D loss: 0.708736, acc: 55.47%] [G loss: 6.717565]\n",
      "epoch:47 step:37049 [D loss: 1.025996, acc: 39.06%] [G loss: 7.540987]\n",
      "epoch:47 step:37050 [D loss: 0.218704, acc: 92.19%] [G loss: 4.966375]\n",
      "epoch:47 step:37051 [D loss: 0.136597, acc: 99.22%] [G loss: 3.119512]\n",
      "epoch:47 step:37052 [D loss: 0.504794, acc: 78.12%] [G loss: 7.694949]\n",
      "epoch:47 step:37053 [D loss: 0.230601, acc: 98.44%] [G loss: 4.069761]\n",
      "epoch:47 step:37054 [D loss: 0.080132, acc: 99.22%] [G loss: 8.299145]\n",
      "epoch:47 step:37055 [D loss: 0.237365, acc: 96.09%] [G loss: 7.647377]\n",
      "epoch:47 step:37056 [D loss: 0.245791, acc: 92.97%] [G loss: 5.491399]\n",
      "epoch:47 step:37057 [D loss: 0.028813, acc: 100.00%] [G loss: 7.450680]\n",
      "epoch:47 step:37058 [D loss: 0.079663, acc: 99.22%] [G loss: 5.029948]\n",
      "epoch:47 step:37059 [D loss: 0.112052, acc: 99.22%] [G loss: 5.308794]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:37060 [D loss: 0.315090, acc: 82.03%] [G loss: 4.635393]\n",
      "epoch:47 step:37061 [D loss: 0.821695, acc: 54.69%] [G loss: 4.058213]\n",
      "epoch:47 step:37062 [D loss: 0.268465, acc: 95.31%] [G loss: 3.724111]\n",
      "epoch:47 step:37063 [D loss: 0.054239, acc: 100.00%] [G loss: 4.525917]\n",
      "epoch:47 step:37064 [D loss: 0.262685, acc: 89.06%] [G loss: 8.607437]\n",
      "epoch:47 step:37065 [D loss: 0.380416, acc: 92.19%] [G loss: 5.645420]\n",
      "epoch:47 step:37066 [D loss: 0.054963, acc: 100.00%] [G loss: 8.226821]\n",
      "epoch:47 step:37067 [D loss: 0.063145, acc: 100.00%] [G loss: 6.603584]\n",
      "epoch:47 step:37068 [D loss: 0.430311, acc: 82.03%] [G loss: 4.895631]\n",
      "epoch:47 step:37069 [D loss: 0.224748, acc: 98.44%] [G loss: 4.749783]\n",
      "epoch:47 step:37070 [D loss: 0.049497, acc: 100.00%] [G loss: 5.075575]\n",
      "epoch:47 step:37071 [D loss: 0.729103, acc: 53.91%] [G loss: 7.440954]\n",
      "epoch:47 step:37072 [D loss: 0.280095, acc: 88.28%] [G loss: 6.447007]\n",
      "epoch:47 step:37073 [D loss: 2.002372, acc: 49.22%] [G loss: 4.617727]\n",
      "epoch:47 step:37074 [D loss: 0.302674, acc: 86.72%] [G loss: 4.841275]\n",
      "epoch:47 step:37075 [D loss: 0.358398, acc: 89.84%] [G loss: 4.329691]\n",
      "epoch:47 step:37076 [D loss: 0.023857, acc: 100.00%] [G loss: 5.971142]\n",
      "epoch:47 step:37077 [D loss: 0.175535, acc: 96.88%] [G loss: 6.290736]\n",
      "epoch:47 step:37078 [D loss: 0.185674, acc: 96.09%] [G loss: 6.884119]\n",
      "epoch:47 step:37079 [D loss: 0.381717, acc: 86.72%] [G loss: 10.021481]\n",
      "epoch:47 step:37080 [D loss: 0.111748, acc: 97.66%] [G loss: 4.683656]\n",
      "epoch:47 step:37081 [D loss: 0.396275, acc: 86.72%] [G loss: 3.524777]\n",
      "epoch:47 step:37082 [D loss: 0.039034, acc: 100.00%] [G loss: 5.983973]\n",
      "epoch:47 step:37083 [D loss: 0.110496, acc: 97.66%] [G loss: 5.436874]\n",
      "epoch:47 step:37084 [D loss: 0.713587, acc: 53.12%] [G loss: 9.484522]\n",
      "epoch:47 step:37085 [D loss: 0.165146, acc: 97.66%] [G loss: 4.884161]\n",
      "epoch:47 step:37086 [D loss: 0.439562, acc: 71.09%] [G loss: 9.830210]\n",
      "epoch:47 step:37087 [D loss: 0.314866, acc: 90.62%] [G loss: 8.916285]\n",
      "epoch:47 step:37088 [D loss: 0.219870, acc: 93.75%] [G loss: 6.069548]\n",
      "epoch:47 step:37089 [D loss: 0.497550, acc: 70.31%] [G loss: 6.811131]\n",
      "epoch:47 step:37090 [D loss: 0.255432, acc: 89.06%] [G loss: 5.734878]\n",
      "epoch:47 step:37091 [D loss: 0.730970, acc: 52.34%] [G loss: 8.002697]\n",
      "epoch:47 step:37092 [D loss: 0.102821, acc: 98.44%] [G loss: 5.433423]\n",
      "epoch:47 step:37093 [D loss: 1.046039, acc: 52.34%] [G loss: 8.080652]\n",
      "epoch:47 step:37094 [D loss: 0.193810, acc: 94.53%] [G loss: 4.730997]\n",
      "epoch:47 step:37095 [D loss: 0.640675, acc: 60.94%] [G loss: 7.260469]\n",
      "epoch:47 step:37096 [D loss: 0.155077, acc: 96.88%] [G loss: 6.101840]\n",
      "epoch:47 step:37097 [D loss: 1.358081, acc: 39.06%] [G loss: 8.164638]\n",
      "epoch:47 step:37098 [D loss: 1.023646, acc: 50.00%] [G loss: 4.074430]\n",
      "epoch:47 step:37099 [D loss: 0.802472, acc: 52.34%] [G loss: 7.981159]\n",
      "epoch:47 step:37100 [D loss: 0.346145, acc: 78.91%] [G loss: 8.830931]\n",
      "epoch:47 step:37101 [D loss: 0.189352, acc: 96.88%] [G loss: 5.444401]\n",
      "epoch:47 step:37102 [D loss: 1.352601, acc: 19.53%] [G loss: 8.810715]\n",
      "epoch:47 step:37103 [D loss: 0.457678, acc: 77.34%] [G loss: 4.346713]\n",
      "epoch:47 step:37104 [D loss: 0.279556, acc: 93.75%] [G loss: 6.527881]\n",
      "epoch:47 step:37105 [D loss: 0.063286, acc: 100.00%] [G loss: 6.011701]\n",
      "epoch:47 step:37106 [D loss: 2.276259, acc: 10.94%] [G loss: 7.002576]\n",
      "epoch:47 step:37107 [D loss: 0.140075, acc: 96.88%] [G loss: 6.009623]\n",
      "epoch:47 step:37108 [D loss: 0.193655, acc: 96.09%] [G loss: 8.032001]\n",
      "epoch:47 step:37109 [D loss: 1.150534, acc: 50.78%] [G loss: 7.701973]\n",
      "epoch:47 step:37110 [D loss: 0.078664, acc: 98.44%] [G loss: 5.398179]\n",
      "epoch:47 step:37111 [D loss: 0.156559, acc: 99.22%] [G loss: 5.286897]\n",
      "epoch:47 step:37112 [D loss: 0.084093, acc: 99.22%] [G loss: 4.085456]\n",
      "epoch:47 step:37113 [D loss: 0.079728, acc: 100.00%] [G loss: 5.677315]\n",
      "epoch:47 step:37114 [D loss: 0.282467, acc: 92.19%] [G loss: 5.887854]\n",
      "epoch:47 step:37115 [D loss: 0.083526, acc: 100.00%] [G loss: 6.070045]\n",
      "epoch:47 step:37116 [D loss: 0.108411, acc: 99.22%] [G loss: 8.210318]\n",
      "epoch:47 step:37117 [D loss: 0.111520, acc: 100.00%] [G loss: 5.128884]\n",
      "epoch:47 step:37118 [D loss: 0.797661, acc: 42.19%] [G loss: 8.038267]\n",
      "epoch:47 step:37119 [D loss: 0.804048, acc: 53.91%] [G loss: 5.554960]\n",
      "epoch:47 step:37120 [D loss: 0.143743, acc: 99.22%] [G loss: 2.098582]\n",
      "epoch:47 step:37121 [D loss: 0.113906, acc: 99.22%] [G loss: 5.376076]\n",
      "epoch:47 step:37122 [D loss: 1.143954, acc: 50.78%] [G loss: 9.506814]\n",
      "epoch:47 step:37123 [D loss: 1.376111, acc: 50.78%] [G loss: 8.046787]\n",
      "epoch:47 step:37124 [D loss: 0.077725, acc: 100.00%] [G loss: 4.858294]\n",
      "epoch:47 step:37125 [D loss: 0.053313, acc: 100.00%] [G loss: 7.255802]\n",
      "epoch:47 step:37126 [D loss: 0.637748, acc: 60.16%] [G loss: 5.883383]\n",
      "epoch:47 step:37127 [D loss: 0.656282, acc: 63.28%] [G loss: 4.395794]\n",
      "epoch:47 step:37128 [D loss: 0.334043, acc: 82.81%] [G loss: 7.680228]\n",
      "epoch:47 step:37129 [D loss: 0.524569, acc: 61.72%] [G loss: 10.229397]\n",
      "epoch:47 step:37130 [D loss: 0.136694, acc: 99.22%] [G loss: 6.907011]\n",
      "epoch:47 step:37131 [D loss: 0.249778, acc: 96.88%] [G loss: 6.774298]\n",
      "epoch:47 step:37132 [D loss: 0.073281, acc: 100.00%] [G loss: 5.845536]\n",
      "epoch:47 step:37133 [D loss: 0.180727, acc: 95.31%] [G loss: 3.876495]\n",
      "epoch:47 step:37134 [D loss: 0.265981, acc: 94.53%] [G loss: 4.644186]\n",
      "epoch:47 step:37135 [D loss: 0.232406, acc: 97.66%] [G loss: 3.497901]\n",
      "epoch:47 step:37136 [D loss: 0.699207, acc: 53.91%] [G loss: 6.228249]\n",
      "epoch:47 step:37137 [D loss: 0.367962, acc: 76.56%] [G loss: 7.153990]\n",
      "epoch:47 step:37138 [D loss: 0.020473, acc: 100.00%] [G loss: 7.554871]\n",
      "epoch:47 step:37139 [D loss: 0.247624, acc: 97.66%] [G loss: 8.035627]\n",
      "epoch:47 step:37140 [D loss: 0.766685, acc: 53.12%] [G loss: 5.631706]\n",
      "epoch:47 step:37141 [D loss: 0.220407, acc: 92.19%] [G loss: 8.716505]\n",
      "epoch:47 step:37142 [D loss: 0.154407, acc: 96.88%] [G loss: 7.522779]\n",
      "epoch:47 step:37143 [D loss: 0.821159, acc: 56.25%] [G loss: 7.339866]\n",
      "epoch:47 step:37144 [D loss: 0.069214, acc: 100.00%] [G loss: 3.081920]\n",
      "epoch:47 step:37145 [D loss: 0.664086, acc: 61.72%] [G loss: 4.894989]\n",
      "epoch:47 step:37146 [D loss: 2.616012, acc: 8.59%] [G loss: 4.522342]\n",
      "epoch:47 step:37147 [D loss: 0.126869, acc: 99.22%] [G loss: 6.038228]\n",
      "epoch:47 step:37148 [D loss: 0.507959, acc: 67.19%] [G loss: 6.634027]\n",
      "epoch:47 step:37149 [D loss: 0.250583, acc: 94.53%] [G loss: 4.773211]\n",
      "epoch:47 step:37150 [D loss: 0.229667, acc: 97.66%] [G loss: 5.721934]\n",
      "epoch:47 step:37151 [D loss: 0.752204, acc: 53.91%] [G loss: 10.397170]\n",
      "epoch:47 step:37152 [D loss: 0.172369, acc: 97.66%] [G loss: 6.074209]\n",
      "epoch:47 step:37153 [D loss: 0.203698, acc: 96.09%] [G loss: 6.899776]\n",
      "epoch:47 step:37154 [D loss: 1.281943, acc: 50.00%] [G loss: 10.142004]\n",
      "epoch:47 step:37155 [D loss: 0.333702, acc: 83.59%] [G loss: 7.157160]\n",
      "epoch:47 step:37156 [D loss: 0.193432, acc: 96.09%] [G loss: 4.639095]\n",
      "epoch:47 step:37157 [D loss: 0.237117, acc: 92.97%] [G loss: 3.870776]\n",
      "epoch:47 step:37158 [D loss: 0.809571, acc: 55.47%] [G loss: 4.479506]\n",
      "epoch:47 step:37159 [D loss: 0.365579, acc: 78.12%] [G loss: 6.513451]\n",
      "epoch:47 step:37160 [D loss: 0.216679, acc: 95.31%] [G loss: 5.100474]\n",
      "epoch:47 step:37161 [D loss: 0.048861, acc: 100.00%] [G loss: 3.712684]\n",
      "epoch:47 step:37162 [D loss: 0.268073, acc: 90.62%] [G loss: 8.700138]\n",
      "epoch:47 step:37163 [D loss: 0.538246, acc: 66.41%] [G loss: 3.931163]\n",
      "epoch:47 step:37164 [D loss: 1.023732, acc: 53.12%] [G loss: 6.359796]\n",
      "epoch:47 step:37165 [D loss: 0.070945, acc: 99.22%] [G loss: 2.560890]\n",
      "epoch:47 step:37166 [D loss: 0.340282, acc: 88.28%] [G loss: 5.752759]\n",
      "epoch:47 step:37167 [D loss: 0.208483, acc: 92.97%] [G loss: 7.360529]\n",
      "epoch:47 step:37168 [D loss: 0.129001, acc: 99.22%] [G loss: 7.090812]\n",
      "epoch:47 step:37169 [D loss: 0.131648, acc: 99.22%] [G loss: 5.309275]\n",
      "epoch:47 step:37170 [D loss: 0.285231, acc: 92.19%] [G loss: 3.902702]\n",
      "epoch:47 step:37171 [D loss: 0.473897, acc: 78.91%] [G loss: 3.571373]\n",
      "epoch:47 step:37172 [D loss: 0.128828, acc: 100.00%] [G loss: 6.422859]\n",
      "epoch:47 step:37173 [D loss: 0.054703, acc: 100.00%] [G loss: 7.338236]\n",
      "epoch:47 step:37174 [D loss: 0.089854, acc: 100.00%] [G loss: 5.286243]\n",
      "epoch:47 step:37175 [D loss: 0.124751, acc: 100.00%] [G loss: 5.066430]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:37176 [D loss: 1.304429, acc: 25.78%] [G loss: 4.821902]\n",
      "epoch:47 step:37177 [D loss: 0.050866, acc: 100.00%] [G loss: 8.819633]\n",
      "epoch:47 step:37178 [D loss: 0.105990, acc: 98.44%] [G loss: 5.350014]\n",
      "epoch:47 step:37179 [D loss: 0.685347, acc: 57.81%] [G loss: 4.863382]\n",
      "epoch:47 step:37180 [D loss: 0.469142, acc: 75.00%] [G loss: 5.690168]\n",
      "epoch:47 step:37181 [D loss: 0.077967, acc: 100.00%] [G loss: 4.801248]\n",
      "epoch:47 step:37182 [D loss: 0.262315, acc: 98.44%] [G loss: 4.029820]\n",
      "epoch:47 step:37183 [D loss: 0.694707, acc: 60.94%] [G loss: 10.144169]\n",
      "epoch:47 step:37184 [D loss: 0.279795, acc: 87.50%] [G loss: 5.401541]\n",
      "epoch:47 step:37185 [D loss: 0.260062, acc: 89.06%] [G loss: 5.790748]\n",
      "epoch:47 step:37186 [D loss: 0.104291, acc: 98.44%] [G loss: 5.335974]\n",
      "epoch:47 step:37187 [D loss: 0.103237, acc: 99.22%] [G loss: 3.881185]\n",
      "epoch:47 step:37188 [D loss: 0.118638, acc: 99.22%] [G loss: 6.031128]\n",
      "epoch:47 step:37189 [D loss: 0.131048, acc: 98.44%] [G loss: 2.777847]\n",
      "epoch:47 step:37190 [D loss: 0.181148, acc: 98.44%] [G loss: 4.309753]\n",
      "epoch:47 step:37191 [D loss: 0.080122, acc: 99.22%] [G loss: 2.730155]\n",
      "epoch:47 step:37192 [D loss: 0.279691, acc: 93.75%] [G loss: 4.343835]\n",
      "epoch:47 step:37193 [D loss: 0.461464, acc: 77.34%] [G loss: 6.864452]\n",
      "epoch:47 step:37194 [D loss: 0.060752, acc: 100.00%] [G loss: 8.953476]\n",
      "epoch:47 step:37195 [D loss: 0.439934, acc: 78.12%] [G loss: 7.974289]\n",
      "epoch:47 step:37196 [D loss: 0.484936, acc: 79.69%] [G loss: 6.033654]\n",
      "epoch:47 step:37197 [D loss: 0.127304, acc: 97.66%] [G loss: 6.529939]\n",
      "epoch:47 step:37198 [D loss: 0.049635, acc: 100.00%] [G loss: 5.812691]\n",
      "epoch:47 step:37199 [D loss: 0.110400, acc: 99.22%] [G loss: 6.263858]\n",
      "epoch:47 step:37200 [D loss: 0.120113, acc: 99.22%] [G loss: 3.247129]\n",
      "epoch:47 step:37201 [D loss: 0.027460, acc: 100.00%] [G loss: 4.831088]\n",
      "epoch:47 step:37202 [D loss: 0.186121, acc: 98.44%] [G loss: 5.906713]\n",
      "epoch:47 step:37203 [D loss: 0.081056, acc: 100.00%] [G loss: 6.343671]\n",
      "epoch:47 step:37204 [D loss: 0.080248, acc: 98.44%] [G loss: 9.334493]\n",
      "epoch:47 step:37205 [D loss: 0.113623, acc: 98.44%] [G loss: 5.719791]\n",
      "epoch:47 step:37206 [D loss: 0.263103, acc: 95.31%] [G loss: 4.684164]\n",
      "epoch:47 step:37207 [D loss: 0.114875, acc: 98.44%] [G loss: 6.899524]\n",
      "epoch:47 step:37208 [D loss: 0.571158, acc: 68.75%] [G loss: 4.841002]\n",
      "epoch:47 step:37209 [D loss: 0.134219, acc: 99.22%] [G loss: 6.084786]\n",
      "epoch:47 step:37210 [D loss: 0.313593, acc: 82.81%] [G loss: 5.769554]\n",
      "epoch:47 step:37211 [D loss: 0.298399, acc: 90.62%] [G loss: 4.410844]\n",
      "epoch:47 step:37212 [D loss: 0.382043, acc: 84.38%] [G loss: 6.725333]\n",
      "epoch:47 step:37213 [D loss: 0.024054, acc: 100.00%] [G loss: 7.533309]\n",
      "epoch:47 step:37214 [D loss: 0.566567, acc: 67.19%] [G loss: 6.463519]\n",
      "epoch:47 step:37215 [D loss: 0.415663, acc: 71.09%] [G loss: 7.337385]\n",
      "epoch:47 step:37216 [D loss: 0.559657, acc: 64.06%] [G loss: 5.501483]\n",
      "epoch:47 step:37217 [D loss: 0.106401, acc: 98.44%] [G loss: 6.824854]\n",
      "epoch:47 step:37218 [D loss: 0.054974, acc: 100.00%] [G loss: 10.333687]\n",
      "epoch:47 step:37219 [D loss: 0.251439, acc: 93.75%] [G loss: 7.764057]\n",
      "epoch:47 step:37220 [D loss: 0.081335, acc: 99.22%] [G loss: 7.003113]\n",
      "epoch:47 step:37221 [D loss: 0.256881, acc: 95.31%] [G loss: 7.181314]\n",
      "epoch:47 step:37222 [D loss: 0.194045, acc: 98.44%] [G loss: 4.479649]\n",
      "epoch:47 step:37223 [D loss: 0.367914, acc: 79.69%] [G loss: 4.910214]\n",
      "epoch:47 step:37224 [D loss: 0.339262, acc: 78.91%] [G loss: 9.666037]\n",
      "epoch:47 step:37225 [D loss: 0.632699, acc: 58.59%] [G loss: 7.424947]\n",
      "epoch:47 step:37226 [D loss: 0.169642, acc: 98.44%] [G loss: 3.468419]\n",
      "epoch:47 step:37227 [D loss: 0.550366, acc: 63.28%] [G loss: 9.072199]\n",
      "epoch:47 step:37228 [D loss: 0.141380, acc: 100.00%] [G loss: 7.005532]\n",
      "epoch:47 step:37229 [D loss: 1.757169, acc: 50.00%] [G loss: 3.594433]\n",
      "epoch:47 step:37230 [D loss: 0.125722, acc: 99.22%] [G loss: 4.069867]\n",
      "epoch:47 step:37231 [D loss: 0.074334, acc: 100.00%] [G loss: 4.552529]\n",
      "epoch:47 step:37232 [D loss: 0.171867, acc: 96.09%] [G loss: 4.439922]\n",
      "epoch:47 step:37233 [D loss: 0.247118, acc: 92.19%] [G loss: 5.266927]\n",
      "epoch:47 step:37234 [D loss: 0.053751, acc: 99.22%] [G loss: 5.962844]\n",
      "epoch:47 step:37235 [D loss: 0.815840, acc: 54.69%] [G loss: 9.181244]\n",
      "epoch:47 step:37236 [D loss: 0.127990, acc: 98.44%] [G loss: 4.914295]\n",
      "epoch:47 step:37237 [D loss: 0.669131, acc: 57.03%] [G loss: 7.349443]\n",
      "epoch:47 step:37238 [D loss: 0.652102, acc: 59.38%] [G loss: 9.782963]\n",
      "epoch:47 step:37239 [D loss: 0.653684, acc: 60.94%] [G loss: 3.230232]\n",
      "epoch:47 step:37240 [D loss: 0.339476, acc: 89.84%] [G loss: 5.241522]\n",
      "epoch:47 step:37241 [D loss: 0.113275, acc: 100.00%] [G loss: 10.220699]\n",
      "epoch:47 step:37242 [D loss: 0.626034, acc: 66.41%] [G loss: 5.106178]\n",
      "epoch:47 step:37243 [D loss: 0.250982, acc: 90.62%] [G loss: 9.544290]\n",
      "epoch:47 step:37244 [D loss: 0.661362, acc: 56.25%] [G loss: 6.621877]\n",
      "epoch:47 step:37245 [D loss: 0.166773, acc: 98.44%] [G loss: 7.069414]\n",
      "epoch:47 step:37246 [D loss: 0.202500, acc: 96.09%] [G loss: 4.131696]\n",
      "epoch:47 step:37247 [D loss: 0.862575, acc: 53.12%] [G loss: 7.368933]\n",
      "epoch:47 step:37248 [D loss: 0.837866, acc: 52.34%] [G loss: 5.298450]\n",
      "epoch:47 step:37249 [D loss: 0.040313, acc: 100.00%] [G loss: 8.617955]\n",
      "epoch:47 step:37250 [D loss: 0.019923, acc: 100.00%] [G loss: 5.302116]\n",
      "epoch:47 step:37251 [D loss: 0.127385, acc: 98.44%] [G loss: 5.655029]\n",
      "epoch:47 step:37252 [D loss: 0.168912, acc: 97.66%] [G loss: 5.976635]\n",
      "epoch:47 step:37253 [D loss: 0.172745, acc: 97.66%] [G loss: 3.519425]\n",
      "epoch:47 step:37254 [D loss: 0.233337, acc: 91.41%] [G loss: 6.774656]\n",
      "epoch:47 step:37255 [D loss: 0.058280, acc: 100.00%] [G loss: 5.848332]\n",
      "epoch:47 step:37256 [D loss: 0.465507, acc: 74.22%] [G loss: 7.181338]\n",
      "epoch:47 step:37257 [D loss: 0.122020, acc: 96.88%] [G loss: 5.262461]\n",
      "epoch:47 step:37258 [D loss: 0.295758, acc: 90.62%] [G loss: 10.979866]\n",
      "epoch:47 step:37259 [D loss: 0.017890, acc: 100.00%] [G loss: 3.440376]\n",
      "epoch:47 step:37260 [D loss: 0.447544, acc: 71.09%] [G loss: 5.745881]\n",
      "epoch:47 step:37261 [D loss: 0.041221, acc: 100.00%] [G loss: 5.769053]\n",
      "epoch:47 step:37262 [D loss: 0.323598, acc: 83.59%] [G loss: 7.569047]\n",
      "epoch:47 step:37263 [D loss: 0.049201, acc: 100.00%] [G loss: 5.332093]\n",
      "epoch:47 step:37264 [D loss: 0.837458, acc: 50.00%] [G loss: 7.473729]\n",
      "epoch:47 step:37265 [D loss: 0.261009, acc: 96.09%] [G loss: 8.589794]\n",
      "epoch:47 step:37266 [D loss: 0.129090, acc: 99.22%] [G loss: 4.768978]\n",
      "epoch:47 step:37267 [D loss: 0.337515, acc: 78.91%] [G loss: 8.730978]\n",
      "epoch:47 step:37268 [D loss: 0.442652, acc: 69.53%] [G loss: 12.075411]\n",
      "epoch:47 step:37269 [D loss: 0.043564, acc: 100.00%] [G loss: 6.020351]\n",
      "epoch:47 step:37270 [D loss: 0.236293, acc: 92.19%] [G loss: 6.950362]\n",
      "epoch:47 step:37271 [D loss: 0.109075, acc: 99.22%] [G loss: 4.872668]\n",
      "epoch:47 step:37272 [D loss: 0.137297, acc: 98.44%] [G loss: 4.818349]\n",
      "epoch:47 step:37273 [D loss: 0.139527, acc: 98.44%] [G loss: 6.489313]\n",
      "epoch:47 step:37274 [D loss: 0.201891, acc: 96.88%] [G loss: 7.112703]\n",
      "epoch:47 step:37275 [D loss: 0.212607, acc: 96.09%] [G loss: 5.661881]\n",
      "epoch:47 step:37276 [D loss: 0.652896, acc: 52.34%] [G loss: 9.836723]\n",
      "epoch:47 step:37277 [D loss: 0.202820, acc: 95.31%] [G loss: 7.844870]\n",
      "epoch:47 step:37278 [D loss: 0.355920, acc: 85.94%] [G loss: 8.506023]\n",
      "epoch:47 step:37279 [D loss: 0.437332, acc: 71.09%] [G loss: 6.653622]\n",
      "epoch:47 step:37280 [D loss: 1.211523, acc: 24.22%] [G loss: 7.625566]\n",
      "epoch:47 step:37281 [D loss: 0.710559, acc: 58.59%] [G loss: 4.794065]\n",
      "epoch:47 step:37282 [D loss: 0.255264, acc: 93.75%] [G loss: 3.226158]\n",
      "epoch:47 step:37283 [D loss: 0.014225, acc: 100.00%] [G loss: 9.760344]\n",
      "epoch:47 step:37284 [D loss: 0.297842, acc: 90.62%] [G loss: 5.274439]\n",
      "epoch:47 step:37285 [D loss: 0.060775, acc: 100.00%] [G loss: 6.195726]\n",
      "epoch:47 step:37286 [D loss: 0.082043, acc: 100.00%] [G loss: 5.403819]\n",
      "epoch:47 step:37287 [D loss: 0.483334, acc: 82.81%] [G loss: 7.709232]\n",
      "epoch:47 step:37288 [D loss: 0.064088, acc: 100.00%] [G loss: 6.418737]\n",
      "epoch:47 step:37289 [D loss: 0.196388, acc: 94.53%] [G loss: 8.235902]\n",
      "epoch:47 step:37290 [D loss: 0.050640, acc: 100.00%] [G loss: 8.711931]\n",
      "epoch:47 step:37291 [D loss: 1.491758, acc: 10.16%] [G loss: 10.157933]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:37292 [D loss: 0.297338, acc: 89.06%] [G loss: 8.109673]\n",
      "epoch:47 step:37293 [D loss: 0.094448, acc: 100.00%] [G loss: 4.976328]\n",
      "epoch:47 step:37294 [D loss: 0.056281, acc: 100.00%] [G loss: 6.139180]\n",
      "epoch:47 step:37295 [D loss: 0.127169, acc: 99.22%] [G loss: 5.190011]\n",
      "epoch:47 step:37296 [D loss: 0.567268, acc: 66.41%] [G loss: 7.700400]\n",
      "epoch:47 step:37297 [D loss: 0.378191, acc: 76.56%] [G loss: 6.899110]\n",
      "epoch:47 step:37298 [D loss: 1.317615, acc: 45.31%] [G loss: 7.033164]\n",
      "epoch:47 step:37299 [D loss: 0.148663, acc: 96.88%] [G loss: 9.618715]\n",
      "epoch:47 step:37300 [D loss: 0.619853, acc: 60.94%] [G loss: 7.117836]\n",
      "epoch:47 step:37301 [D loss: 0.120766, acc: 100.00%] [G loss: 8.208538]\n",
      "epoch:47 step:37302 [D loss: 0.040325, acc: 99.22%] [G loss: 7.571416]\n",
      "epoch:47 step:37303 [D loss: 0.763669, acc: 51.56%] [G loss: 5.135162]\n",
      "epoch:47 step:37304 [D loss: 0.171797, acc: 96.88%] [G loss: 6.403842]\n",
      "epoch:47 step:37305 [D loss: 0.121225, acc: 98.44%] [G loss: 8.267525]\n",
      "epoch:47 step:37306 [D loss: 0.861975, acc: 47.66%] [G loss: 5.971826]\n",
      "epoch:47 step:37307 [D loss: 0.187938, acc: 96.09%] [G loss: 4.412541]\n",
      "epoch:47 step:37308 [D loss: 0.175183, acc: 99.22%] [G loss: 9.469479]\n",
      "epoch:47 step:37309 [D loss: 0.164875, acc: 96.88%] [G loss: 5.731728]\n",
      "epoch:47 step:37310 [D loss: 1.090223, acc: 50.78%] [G loss: 6.965182]\n",
      "epoch:47 step:37311 [D loss: 0.744332, acc: 58.59%] [G loss: 9.706554]\n",
      "epoch:47 step:37312 [D loss: 0.190871, acc: 97.66%] [G loss: 4.757709]\n",
      "epoch:47 step:37313 [D loss: 0.061717, acc: 99.22%] [G loss: 6.128035]\n",
      "epoch:47 step:37314 [D loss: 0.319436, acc: 94.53%] [G loss: 3.835114]\n",
      "epoch:47 step:37315 [D loss: 0.180426, acc: 97.66%] [G loss: 5.889647]\n",
      "epoch:47 step:37316 [D loss: 0.964189, acc: 51.56%] [G loss: 10.105866]\n",
      "epoch:47 step:37317 [D loss: 0.016656, acc: 100.00%] [G loss: 6.359754]\n",
      "epoch:47 step:37318 [D loss: 0.117085, acc: 98.44%] [G loss: 4.077367]\n",
      "epoch:47 step:37319 [D loss: 0.535410, acc: 64.84%] [G loss: 4.881960]\n",
      "epoch:47 step:37320 [D loss: 0.108014, acc: 100.00%] [G loss: 4.863107]\n",
      "epoch:47 step:37321 [D loss: 0.140238, acc: 100.00%] [G loss: 3.576259]\n",
      "epoch:47 step:37322 [D loss: 0.136345, acc: 99.22%] [G loss: 8.342152]\n",
      "epoch:47 step:37323 [D loss: 0.023127, acc: 100.00%] [G loss: 7.486712]\n",
      "epoch:47 step:37324 [D loss: 0.238892, acc: 96.88%] [G loss: 7.241421]\n",
      "epoch:47 step:37325 [D loss: 0.048934, acc: 100.00%] [G loss: 6.834102]\n",
      "epoch:47 step:37326 [D loss: 0.223413, acc: 90.62%] [G loss: 5.856788]\n",
      "epoch:47 step:37327 [D loss: 0.529809, acc: 63.28%] [G loss: 5.676164]\n",
      "epoch:47 step:37328 [D loss: 0.243486, acc: 96.09%] [G loss: 7.659911]\n",
      "epoch:47 step:37329 [D loss: 0.541233, acc: 66.41%] [G loss: 8.451878]\n",
      "epoch:47 step:37330 [D loss: 0.445845, acc: 67.97%] [G loss: 4.833784]\n",
      "epoch:47 step:37331 [D loss: 0.016920, acc: 100.00%] [G loss: 4.860013]\n",
      "epoch:47 step:37332 [D loss: 0.284143, acc: 89.84%] [G loss: 2.346014]\n",
      "epoch:47 step:37333 [D loss: 0.685764, acc: 56.25%] [G loss: 7.586791]\n",
      "epoch:47 step:37334 [D loss: 0.226792, acc: 95.31%] [G loss: 5.630053]\n",
      "epoch:47 step:37335 [D loss: 0.075388, acc: 100.00%] [G loss: 4.625020]\n",
      "epoch:47 step:37336 [D loss: 0.607945, acc: 54.69%] [G loss: 9.271498]\n",
      "epoch:47 step:37337 [D loss: 0.072896, acc: 100.00%] [G loss: 8.631562]\n",
      "epoch:47 step:37338 [D loss: 0.093622, acc: 100.00%] [G loss: 4.620470]\n",
      "epoch:47 step:37339 [D loss: 0.534316, acc: 81.25%] [G loss: 8.724510]\n",
      "epoch:47 step:37340 [D loss: 0.141046, acc: 97.66%] [G loss: 1.931660]\n",
      "epoch:47 step:37341 [D loss: 1.125767, acc: 23.44%] [G loss: 5.849381]\n",
      "epoch:47 step:37342 [D loss: 0.411301, acc: 84.38%] [G loss: 4.443261]\n",
      "epoch:47 step:37343 [D loss: 0.514474, acc: 71.09%] [G loss: 5.078308]\n",
      "epoch:47 step:37344 [D loss: 0.131944, acc: 98.44%] [G loss: 2.753174]\n",
      "epoch:47 step:37345 [D loss: 0.148139, acc: 97.66%] [G loss: 5.845942]\n",
      "epoch:47 step:37346 [D loss: 0.494048, acc: 69.53%] [G loss: 8.605780]\n",
      "epoch:47 step:37347 [D loss: 0.184356, acc: 96.88%] [G loss: 7.907078]\n",
      "epoch:47 step:37348 [D loss: 0.175211, acc: 97.66%] [G loss: 7.906242]\n",
      "epoch:47 step:37349 [D loss: 0.682118, acc: 57.03%] [G loss: 6.260770]\n",
      "epoch:47 step:37350 [D loss: 0.461114, acc: 67.19%] [G loss: 5.193176]\n",
      "epoch:47 step:37351 [D loss: 0.261591, acc: 93.75%] [G loss: 3.047172]\n",
      "epoch:47 step:37352 [D loss: 0.704662, acc: 57.03%] [G loss: 5.082982]\n",
      "epoch:47 step:37353 [D loss: 0.503973, acc: 75.00%] [G loss: 3.364043]\n",
      "epoch:47 step:37354 [D loss: 0.084487, acc: 98.44%] [G loss: 5.774035]\n",
      "epoch:47 step:37355 [D loss: 0.544530, acc: 60.94%] [G loss: 7.551381]\n",
      "epoch:47 step:37356 [D loss: 0.200969, acc: 96.09%] [G loss: 6.868464]\n",
      "epoch:47 step:37357 [D loss: 0.376132, acc: 77.34%] [G loss: 7.762047]\n",
      "epoch:47 step:37358 [D loss: 0.328527, acc: 89.84%] [G loss: 6.478983]\n",
      "epoch:47 step:37359 [D loss: 0.322851, acc: 94.53%] [G loss: 7.801102]\n",
      "epoch:47 step:37360 [D loss: 0.261305, acc: 92.19%] [G loss: 6.438249]\n",
      "epoch:47 step:37361 [D loss: 0.293122, acc: 88.28%] [G loss: 9.640749]\n",
      "epoch:47 step:37362 [D loss: 0.465036, acc: 68.75%] [G loss: 6.852748]\n",
      "epoch:47 step:37363 [D loss: 0.115523, acc: 100.00%] [G loss: 5.507087]\n",
      "epoch:47 step:37364 [D loss: 0.085779, acc: 98.44%] [G loss: 6.181774]\n",
      "epoch:47 step:37365 [D loss: 0.671080, acc: 59.38%] [G loss: 4.113191]\n",
      "epoch:47 step:37366 [D loss: 0.161529, acc: 95.31%] [G loss: 5.863298]\n",
      "epoch:47 step:37367 [D loss: 0.030520, acc: 100.00%] [G loss: 8.052774]\n",
      "epoch:47 step:37368 [D loss: 0.218651, acc: 96.09%] [G loss: 7.206220]\n",
      "epoch:47 step:37369 [D loss: 0.515587, acc: 66.41%] [G loss: 6.562796]\n",
      "epoch:47 step:37370 [D loss: 0.163194, acc: 97.66%] [G loss: 5.324696]\n",
      "epoch:47 step:37371 [D loss: 0.070975, acc: 100.00%] [G loss: 4.336215]\n",
      "epoch:47 step:37372 [D loss: 0.239037, acc: 93.75%] [G loss: 5.549637]\n",
      "epoch:47 step:37373 [D loss: 0.269177, acc: 89.06%] [G loss: 3.323730]\n",
      "epoch:47 step:37374 [D loss: 0.019174, acc: 100.00%] [G loss: 8.077805]\n",
      "epoch:47 step:37375 [D loss: 0.642359, acc: 64.06%] [G loss: 8.607322]\n",
      "epoch:47 step:37376 [D loss: 0.126138, acc: 100.00%] [G loss: 8.154360]\n",
      "epoch:47 step:37377 [D loss: 0.506999, acc: 67.19%] [G loss: 5.223231]\n",
      "epoch:47 step:37378 [D loss: 0.714959, acc: 58.59%] [G loss: 10.025105]\n",
      "epoch:47 step:37379 [D loss: 0.063071, acc: 100.00%] [G loss: 7.126087]\n",
      "epoch:47 step:37380 [D loss: 0.493715, acc: 64.06%] [G loss: 8.147371]\n",
      "epoch:47 step:37381 [D loss: 0.086845, acc: 100.00%] [G loss: 5.949225]\n",
      "epoch:47 step:37382 [D loss: 1.142212, acc: 48.44%] [G loss: 4.538842]\n",
      "epoch:47 step:37383 [D loss: 0.080343, acc: 100.00%] [G loss: 5.487494]\n",
      "epoch:47 step:37384 [D loss: 0.028169, acc: 100.00%] [G loss: 3.298833]\n",
      "epoch:47 step:37385 [D loss: 0.309941, acc: 89.84%] [G loss: 8.118385]\n",
      "epoch:47 step:37386 [D loss: 0.099080, acc: 98.44%] [G loss: 2.879761]\n",
      "epoch:47 step:37387 [D loss: 0.193073, acc: 97.66%] [G loss: 3.566234]\n",
      "epoch:47 step:37388 [D loss: 0.225597, acc: 94.53%] [G loss: 10.411077]\n",
      "epoch:47 step:37389 [D loss: 0.382380, acc: 90.62%] [G loss: 6.067804]\n",
      "epoch:47 step:37390 [D loss: 0.495820, acc: 66.41%] [G loss: 7.301363]\n",
      "epoch:47 step:37391 [D loss: 0.138238, acc: 96.88%] [G loss: 9.836249]\n",
      "epoch:47 step:37392 [D loss: 0.607378, acc: 68.75%] [G loss: 6.863324]\n",
      "epoch:47 step:37393 [D loss: 0.122422, acc: 96.88%] [G loss: 2.334764]\n",
      "epoch:47 step:37394 [D loss: 0.040180, acc: 100.00%] [G loss: 7.301699]\n",
      "epoch:47 step:37395 [D loss: 0.336682, acc: 81.25%] [G loss: 7.417859]\n",
      "epoch:47 step:37396 [D loss: 0.268574, acc: 91.41%] [G loss: 5.127018]\n",
      "epoch:47 step:37397 [D loss: 0.140661, acc: 96.09%] [G loss: 5.938189]\n",
      "epoch:47 step:37398 [D loss: 0.083372, acc: 100.00%] [G loss: 10.326470]\n",
      "epoch:47 step:37399 [D loss: 0.087968, acc: 99.22%] [G loss: 7.217958]\n",
      "epoch:47 step:37400 [D loss: 0.438716, acc: 87.50%] [G loss: 4.059174]\n",
      "epoch:47 step:37401 [D loss: 0.145615, acc: 99.22%] [G loss: 5.504008]\n",
      "epoch:47 step:37402 [D loss: 0.564720, acc: 67.97%] [G loss: 3.359525]\n",
      "epoch:47 step:37403 [D loss: 0.384345, acc: 87.50%] [G loss: 5.510643]\n",
      "epoch:47 step:37404 [D loss: 1.176892, acc: 35.94%] [G loss: 11.353097]\n",
      "epoch:47 step:37405 [D loss: 0.186296, acc: 96.88%] [G loss: 5.620018]\n",
      "epoch:47 step:37406 [D loss: 0.237132, acc: 96.09%] [G loss: 3.577847]\n",
      "epoch:47 step:37407 [D loss: 0.065058, acc: 100.00%] [G loss: 6.758587]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:37408 [D loss: 0.323083, acc: 89.84%] [G loss: 7.987420]\n",
      "epoch:47 step:37409 [D loss: 0.324889, acc: 91.41%] [G loss: 5.631965]\n",
      "epoch:47 step:37410 [D loss: 0.058239, acc: 100.00%] [G loss: 6.657042]\n",
      "epoch:47 step:37411 [D loss: 0.216175, acc: 100.00%] [G loss: 5.605368]\n",
      "epoch:47 step:37412 [D loss: 0.185917, acc: 95.31%] [G loss: 7.156425]\n",
      "epoch:47 step:37413 [D loss: 0.414373, acc: 82.03%] [G loss: 5.652741]\n",
      "epoch:47 step:37414 [D loss: 0.232290, acc: 96.88%] [G loss: 6.206976]\n",
      "epoch:47 step:37415 [D loss: 0.105002, acc: 99.22%] [G loss: 9.569916]\n",
      "epoch:47 step:37416 [D loss: 0.270420, acc: 95.31%] [G loss: 5.307780]\n",
      "epoch:47 step:37417 [D loss: 0.175711, acc: 97.66%] [G loss: 4.890121]\n",
      "epoch:47 step:37418 [D loss: 1.456113, acc: 50.00%] [G loss: 10.016298]\n",
      "epoch:47 step:37419 [D loss: 0.225470, acc: 92.97%] [G loss: 5.299201]\n",
      "epoch:47 step:37420 [D loss: 0.438861, acc: 71.88%] [G loss: 8.895053]\n",
      "epoch:47 step:37421 [D loss: 0.128240, acc: 99.22%] [G loss: 4.558642]\n",
      "epoch:47 step:37422 [D loss: 1.094971, acc: 33.59%] [G loss: 6.760099]\n",
      "epoch:47 step:37423 [D loss: 0.008409, acc: 100.00%] [G loss: 8.116259]\n",
      "epoch:47 step:37424 [D loss: 0.306941, acc: 83.59%] [G loss: 6.999516]\n",
      "epoch:47 step:37425 [D loss: 0.517279, acc: 75.00%] [G loss: 4.422256]\n",
      "epoch:47 step:37426 [D loss: 0.122760, acc: 100.00%] [G loss: 4.029468]\n",
      "epoch:47 step:37427 [D loss: 0.306088, acc: 96.09%] [G loss: 6.213295]\n",
      "epoch:47 step:37428 [D loss: 0.707036, acc: 59.38%] [G loss: 8.363050]\n",
      "epoch:47 step:37429 [D loss: 0.428418, acc: 75.00%] [G loss: 4.814113]\n",
      "epoch:47 step:37430 [D loss: 0.316617, acc: 80.47%] [G loss: 11.912453]\n",
      "epoch:47 step:37431 [D loss: 0.032636, acc: 100.00%] [G loss: 4.520691]\n",
      "epoch:47 step:37432 [D loss: 0.677084, acc: 60.94%] [G loss: 5.380688]\n",
      "epoch:47 step:37433 [D loss: 0.257471, acc: 92.19%] [G loss: 7.632811]\n",
      "epoch:47 step:37434 [D loss: 0.054048, acc: 100.00%] [G loss: 4.449709]\n",
      "epoch:47 step:37435 [D loss: 0.665049, acc: 61.72%] [G loss: 4.374803]\n",
      "epoch:47 step:37436 [D loss: 0.101950, acc: 100.00%] [G loss: 5.209456]\n",
      "epoch:47 step:37437 [D loss: 0.099971, acc: 99.22%] [G loss: 3.371981]\n",
      "epoch:47 step:37438 [D loss: 0.061935, acc: 99.22%] [G loss: 4.504476]\n",
      "epoch:47 step:37439 [D loss: 0.362927, acc: 79.69%] [G loss: 4.753519]\n",
      "epoch:47 step:37440 [D loss: 1.188177, acc: 50.00%] [G loss: 5.523693]\n",
      "epoch:47 step:37441 [D loss: 0.013141, acc: 100.00%] [G loss: 6.361961]\n",
      "epoch:47 step:37442 [D loss: 0.013954, acc: 100.00%] [G loss: 9.581160]\n",
      "epoch:47 step:37443 [D loss: 0.075290, acc: 100.00%] [G loss: 5.470329]\n",
      "epoch:47 step:37444 [D loss: 0.407893, acc: 75.00%] [G loss: 9.463902]\n",
      "epoch:47 step:37445 [D loss: 0.140780, acc: 100.00%] [G loss: 4.053448]\n",
      "epoch:47 step:37446 [D loss: 0.235680, acc: 93.75%] [G loss: 4.264009]\n",
      "epoch:47 step:37447 [D loss: 0.288800, acc: 92.19%] [G loss: 5.903032]\n",
      "epoch:47 step:37448 [D loss: 0.190810, acc: 98.44%] [G loss: 6.671815]\n",
      "epoch:47 step:37449 [D loss: 0.111157, acc: 99.22%] [G loss: 3.626096]\n",
      "epoch:47 step:37450 [D loss: 0.370964, acc: 78.12%] [G loss: 5.815483]\n",
      "epoch:47 step:37451 [D loss: 0.086135, acc: 100.00%] [G loss: 4.811110]\n",
      "epoch:47 step:37452 [D loss: 0.107385, acc: 100.00%] [G loss: 5.728338]\n",
      "epoch:47 step:37453 [D loss: 0.218946, acc: 92.97%] [G loss: 5.865375]\n",
      "epoch:47 step:37454 [D loss: 0.263904, acc: 95.31%] [G loss: 9.282363]\n",
      "epoch:47 step:37455 [D loss: 0.054147, acc: 100.00%] [G loss: 3.343677]\n",
      "epoch:47 step:37456 [D loss: 0.517359, acc: 67.97%] [G loss: 5.609404]\n",
      "epoch:47 step:37457 [D loss: 0.041356, acc: 100.00%] [G loss: 4.356905]\n",
      "epoch:47 step:37458 [D loss: 0.064753, acc: 99.22%] [G loss: 8.080247]\n",
      "epoch:47 step:37459 [D loss: 0.261898, acc: 87.50%] [G loss: 8.273832]\n",
      "epoch:47 step:37460 [D loss: 0.207327, acc: 95.31%] [G loss: 4.690116]\n",
      "epoch:47 step:37461 [D loss: 1.080173, acc: 37.50%] [G loss: 12.398642]\n",
      "epoch:47 step:37462 [D loss: 0.097103, acc: 100.00%] [G loss: 6.678841]\n",
      "epoch:47 step:37463 [D loss: 0.225275, acc: 92.97%] [G loss: 5.541490]\n",
      "epoch:47 step:37464 [D loss: 0.377788, acc: 81.25%] [G loss: 8.202330]\n",
      "epoch:47 step:37465 [D loss: 0.051574, acc: 100.00%] [G loss: 4.454211]\n",
      "epoch:47 step:37466 [D loss: 0.565576, acc: 64.06%] [G loss: 6.801171]\n",
      "epoch:47 step:37467 [D loss: 0.059199, acc: 99.22%] [G loss: 12.620731]\n",
      "epoch:47 step:37468 [D loss: 0.120076, acc: 99.22%] [G loss: 7.482737]\n",
      "epoch:47 step:37469 [D loss: 1.205350, acc: 49.22%] [G loss: 6.315775]\n",
      "epoch:47 step:37470 [D loss: 0.374690, acc: 80.47%] [G loss: 5.834376]\n",
      "epoch:47 step:37471 [D loss: 0.150215, acc: 96.88%] [G loss: 5.677926]\n",
      "epoch:47 step:37472 [D loss: 0.047133, acc: 100.00%] [G loss: 4.537865]\n",
      "epoch:47 step:37473 [D loss: 0.140710, acc: 98.44%] [G loss: 5.245039]\n",
      "epoch:47 step:37474 [D loss: 0.147530, acc: 99.22%] [G loss: 5.471485]\n",
      "epoch:47 step:37475 [D loss: 0.079452, acc: 99.22%] [G loss: 7.845469]\n",
      "epoch:47 step:37476 [D loss: 0.646868, acc: 61.72%] [G loss: 6.096260]\n",
      "epoch:47 step:37477 [D loss: 0.579983, acc: 61.72%] [G loss: 6.989331]\n",
      "epoch:47 step:37478 [D loss: 0.323958, acc: 91.41%] [G loss: 6.321804]\n",
      "epoch:47 step:37479 [D loss: 0.183161, acc: 96.88%] [G loss: 5.558221]\n",
      "epoch:47 step:37480 [D loss: 0.131508, acc: 98.44%] [G loss: 7.944275]\n",
      "epoch:47 step:37481 [D loss: 0.089574, acc: 100.00%] [G loss: 8.358414]\n",
      "epoch:47 step:37482 [D loss: 0.120231, acc: 99.22%] [G loss: 8.016943]\n",
      "epoch:47 step:37483 [D loss: 0.112945, acc: 99.22%] [G loss: 6.100685]\n",
      "epoch:47 step:37484 [D loss: 0.389155, acc: 88.28%] [G loss: 6.391773]\n",
      "epoch:47 step:37485 [D loss: 0.138980, acc: 96.88%] [G loss: 5.664582]\n",
      "epoch:47 step:37486 [D loss: 0.896388, acc: 53.91%] [G loss: 7.856882]\n",
      "epoch:47 step:37487 [D loss: 0.856571, acc: 53.91%] [G loss: 8.639047]\n",
      "epoch:47 step:37488 [D loss: 0.191410, acc: 99.22%] [G loss: 4.917508]\n",
      "epoch:48 step:37489 [D loss: 0.071500, acc: 100.00%] [G loss: 7.201713]\n",
      "epoch:48 step:37490 [D loss: 0.023968, acc: 100.00%] [G loss: 5.116315]\n",
      "epoch:48 step:37491 [D loss: 0.149702, acc: 98.44%] [G loss: 7.007269]\n",
      "epoch:48 step:37492 [D loss: 0.565662, acc: 70.31%] [G loss: 6.310097]\n",
      "epoch:48 step:37493 [D loss: 0.059024, acc: 100.00%] [G loss: 5.063258]\n",
      "epoch:48 step:37494 [D loss: 0.222958, acc: 94.53%] [G loss: 4.794843]\n",
      "epoch:48 step:37495 [D loss: 0.232124, acc: 96.88%] [G loss: 2.881332]\n",
      "epoch:48 step:37496 [D loss: 0.044606, acc: 100.00%] [G loss: 6.268766]\n",
      "epoch:48 step:37497 [D loss: 0.129572, acc: 100.00%] [G loss: 6.167387]\n",
      "epoch:48 step:37498 [D loss: 0.024708, acc: 100.00%] [G loss: 6.257843]\n",
      "epoch:48 step:37499 [D loss: 0.083225, acc: 100.00%] [G loss: 4.657065]\n",
      "epoch:48 step:37500 [D loss: 1.089123, acc: 30.47%] [G loss: 6.837720]\n",
      "epoch:48 step:37501 [D loss: 0.037166, acc: 100.00%] [G loss: 8.330266]\n",
      "epoch:48 step:37502 [D loss: 1.097814, acc: 45.31%] [G loss: 7.879163]\n",
      "epoch:48 step:37503 [D loss: 0.097811, acc: 100.00%] [G loss: 4.706824]\n",
      "epoch:48 step:37504 [D loss: 0.945395, acc: 48.44%] [G loss: 5.666045]\n",
      "epoch:48 step:37505 [D loss: 0.034078, acc: 100.00%] [G loss: 4.850267]\n",
      "epoch:48 step:37506 [D loss: 0.507336, acc: 65.62%] [G loss: 11.785077]\n",
      "epoch:48 step:37507 [D loss: 0.494748, acc: 70.31%] [G loss: 7.172005]\n",
      "epoch:48 step:37508 [D loss: 0.118780, acc: 100.00%] [G loss: 8.209493]\n",
      "epoch:48 step:37509 [D loss: 0.112023, acc: 100.00%] [G loss: 7.173172]\n",
      "epoch:48 step:37510 [D loss: 0.427925, acc: 87.50%] [G loss: 5.099643]\n",
      "epoch:48 step:37511 [D loss: 0.085257, acc: 100.00%] [G loss: 5.934898]\n",
      "epoch:48 step:37512 [D loss: 0.582592, acc: 70.31%] [G loss: 5.181420]\n",
      "epoch:48 step:37513 [D loss: 0.152732, acc: 98.44%] [G loss: 7.530563]\n",
      "epoch:48 step:37514 [D loss: 0.392060, acc: 80.47%] [G loss: 4.825770]\n",
      "epoch:48 step:37515 [D loss: 0.053364, acc: 100.00%] [G loss: 7.973358]\n",
      "epoch:48 step:37516 [D loss: 0.273946, acc: 89.06%] [G loss: 5.397068]\n",
      "epoch:48 step:37517 [D loss: 0.558747, acc: 64.06%] [G loss: 8.680809]\n",
      "epoch:48 step:37518 [D loss: 0.090109, acc: 99.22%] [G loss: 7.170336]\n",
      "epoch:48 step:37519 [D loss: 0.511932, acc: 76.56%] [G loss: 7.318653]\n",
      "epoch:48 step:37520 [D loss: 0.288517, acc: 85.16%] [G loss: 3.386741]\n",
      "epoch:48 step:37521 [D loss: 0.256102, acc: 91.41%] [G loss: 6.091743]\n",
      "epoch:48 step:37522 [D loss: 0.111942, acc: 100.00%] [G loss: 5.305876]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37523 [D loss: 0.277248, acc: 96.88%] [G loss: 5.427564]\n",
      "epoch:48 step:37524 [D loss: 0.239735, acc: 96.88%] [G loss: 5.535254]\n",
      "epoch:48 step:37525 [D loss: 0.388057, acc: 77.34%] [G loss: 8.865236]\n",
      "epoch:48 step:37526 [D loss: 0.339475, acc: 86.72%] [G loss: 8.756866]\n",
      "epoch:48 step:37527 [D loss: 0.017589, acc: 100.00%] [G loss: 10.623874]\n",
      "epoch:48 step:37528 [D loss: 0.089937, acc: 99.22%] [G loss: 4.252155]\n",
      "epoch:48 step:37529 [D loss: 0.115146, acc: 99.22%] [G loss: 5.092059]\n",
      "epoch:48 step:37530 [D loss: 0.202406, acc: 95.31%] [G loss: 5.429965]\n",
      "epoch:48 step:37531 [D loss: 1.053022, acc: 43.75%] [G loss: 5.532870]\n",
      "epoch:48 step:37532 [D loss: 2.875181, acc: 0.00%] [G loss: 10.933510]\n",
      "epoch:48 step:37533 [D loss: 0.110085, acc: 98.44%] [G loss: 8.309842]\n",
      "epoch:48 step:37534 [D loss: 0.303352, acc: 92.19%] [G loss: 6.353160]\n",
      "epoch:48 step:37535 [D loss: 0.277164, acc: 94.53%] [G loss: 4.804851]\n",
      "epoch:48 step:37536 [D loss: 0.118218, acc: 100.00%] [G loss: 4.807403]\n",
      "epoch:48 step:37537 [D loss: 0.710538, acc: 57.03%] [G loss: 5.591687]\n",
      "epoch:48 step:37538 [D loss: 0.111226, acc: 97.66%] [G loss: 10.267169]\n",
      "epoch:48 step:37539 [D loss: 0.302053, acc: 82.03%] [G loss: 4.646604]\n",
      "epoch:48 step:37540 [D loss: 0.073671, acc: 100.00%] [G loss: 3.540585]\n",
      "epoch:48 step:37541 [D loss: 0.404643, acc: 85.16%] [G loss: 5.525658]\n",
      "epoch:48 step:37542 [D loss: 0.075473, acc: 100.00%] [G loss: 4.812078]\n",
      "epoch:48 step:37543 [D loss: 0.213832, acc: 92.97%] [G loss: 5.907040]\n",
      "epoch:48 step:37544 [D loss: 0.296219, acc: 87.50%] [G loss: 5.303579]\n",
      "epoch:48 step:37545 [D loss: 0.698493, acc: 54.69%] [G loss: 4.728471]\n",
      "epoch:48 step:37546 [D loss: 0.187570, acc: 98.44%] [G loss: 5.949341]\n",
      "epoch:48 step:37547 [D loss: 0.359116, acc: 82.81%] [G loss: 6.893525]\n",
      "epoch:48 step:37548 [D loss: 0.068570, acc: 100.00%] [G loss: 4.420707]\n",
      "epoch:48 step:37549 [D loss: 0.532256, acc: 64.06%] [G loss: 9.401927]\n",
      "epoch:48 step:37550 [D loss: 0.021929, acc: 100.00%] [G loss: 7.434619]\n",
      "epoch:48 step:37551 [D loss: 0.175792, acc: 96.09%] [G loss: 6.569712]\n",
      "epoch:48 step:37552 [D loss: 0.076291, acc: 100.00%] [G loss: 5.364965]\n",
      "epoch:48 step:37553 [D loss: 0.334965, acc: 89.06%] [G loss: 6.786685]\n",
      "epoch:48 step:37554 [D loss: 0.110669, acc: 97.66%] [G loss: 7.452566]\n",
      "epoch:48 step:37555 [D loss: 0.458621, acc: 76.56%] [G loss: 5.856077]\n",
      "epoch:48 step:37556 [D loss: 0.081798, acc: 99.22%] [G loss: 4.190547]\n",
      "epoch:48 step:37557 [D loss: 0.086027, acc: 100.00%] [G loss: 5.551411]\n",
      "epoch:48 step:37558 [D loss: 0.324606, acc: 82.81%] [G loss: 9.659721]\n",
      "epoch:48 step:37559 [D loss: 0.197823, acc: 97.66%] [G loss: 8.081591]\n",
      "epoch:48 step:37560 [D loss: 0.102867, acc: 100.00%] [G loss: 8.484163]\n",
      "epoch:48 step:37561 [D loss: 0.176848, acc: 99.22%] [G loss: 7.363518]\n",
      "epoch:48 step:37562 [D loss: 0.150515, acc: 96.88%] [G loss: 5.524222]\n",
      "epoch:48 step:37563 [D loss: 0.156563, acc: 97.66%] [G loss: 8.201956]\n",
      "epoch:48 step:37564 [D loss: 0.303766, acc: 86.72%] [G loss: 6.223548]\n",
      "epoch:48 step:37565 [D loss: 0.151609, acc: 97.66%] [G loss: 4.523837]\n",
      "epoch:48 step:37566 [D loss: 0.134348, acc: 99.22%] [G loss: 9.392982]\n",
      "epoch:48 step:37567 [D loss: 0.303179, acc: 92.19%] [G loss: 5.404427]\n",
      "epoch:48 step:37568 [D loss: 0.084386, acc: 99.22%] [G loss: 4.308567]\n",
      "epoch:48 step:37569 [D loss: 0.095122, acc: 98.44%] [G loss: 7.272768]\n",
      "epoch:48 step:37570 [D loss: 0.254466, acc: 93.75%] [G loss: 4.948323]\n",
      "epoch:48 step:37571 [D loss: 0.300981, acc: 85.94%] [G loss: 3.844955]\n",
      "epoch:48 step:37572 [D loss: 0.303397, acc: 96.09%] [G loss: 8.442571]\n",
      "epoch:48 step:37573 [D loss: 0.109250, acc: 99.22%] [G loss: 7.112158]\n",
      "epoch:48 step:37574 [D loss: 0.947793, acc: 46.09%] [G loss: 4.265432]\n",
      "epoch:48 step:37575 [D loss: 0.134008, acc: 99.22%] [G loss: 2.508518]\n",
      "epoch:48 step:37576 [D loss: 0.440236, acc: 70.31%] [G loss: 6.350672]\n",
      "epoch:48 step:37577 [D loss: 0.214810, acc: 96.09%] [G loss: 9.531823]\n",
      "epoch:48 step:37578 [D loss: 0.114877, acc: 97.66%] [G loss: 3.026577]\n",
      "epoch:48 step:37579 [D loss: 0.060580, acc: 100.00%] [G loss: 5.273655]\n",
      "epoch:48 step:37580 [D loss: 0.062809, acc: 100.00%] [G loss: 7.723499]\n",
      "epoch:48 step:37581 [D loss: 0.163552, acc: 96.88%] [G loss: 5.356893]\n",
      "epoch:48 step:37582 [D loss: 0.081271, acc: 99.22%] [G loss: 3.345385]\n",
      "epoch:48 step:37583 [D loss: 0.405834, acc: 85.16%] [G loss: 4.831009]\n",
      "epoch:48 step:37584 [D loss: 0.054250, acc: 100.00%] [G loss: 2.661898]\n",
      "epoch:48 step:37585 [D loss: 0.274291, acc: 88.28%] [G loss: 6.704794]\n",
      "epoch:48 step:37586 [D loss: 0.210157, acc: 96.09%] [G loss: 7.133270]\n",
      "epoch:48 step:37587 [D loss: 1.463325, acc: 36.72%] [G loss: 4.283527]\n",
      "epoch:48 step:37588 [D loss: 0.093429, acc: 99.22%] [G loss: 5.499692]\n",
      "epoch:48 step:37589 [D loss: 0.239110, acc: 92.19%] [G loss: 5.373816]\n",
      "epoch:48 step:37590 [D loss: 0.575883, acc: 64.84%] [G loss: 6.280466]\n",
      "epoch:48 step:37591 [D loss: 0.381824, acc: 73.44%] [G loss: 4.481972]\n",
      "epoch:48 step:37592 [D loss: 0.073526, acc: 98.44%] [G loss: 4.821393]\n",
      "epoch:48 step:37593 [D loss: 0.166558, acc: 100.00%] [G loss: 6.604785]\n",
      "epoch:48 step:37594 [D loss: 0.350964, acc: 83.59%] [G loss: 8.656076]\n",
      "epoch:48 step:37595 [D loss: 0.612153, acc: 66.41%] [G loss: 7.452456]\n",
      "epoch:48 step:37596 [D loss: 0.216641, acc: 97.66%] [G loss: 6.993242]\n",
      "epoch:48 step:37597 [D loss: 0.704417, acc: 62.50%] [G loss: 8.932338]\n",
      "epoch:48 step:37598 [D loss: 0.134145, acc: 97.66%] [G loss: 9.644834]\n",
      "epoch:48 step:37599 [D loss: 0.188954, acc: 95.31%] [G loss: 7.585700]\n",
      "epoch:48 step:37600 [D loss: 0.226894, acc: 93.75%] [G loss: 3.919109]\n",
      "epoch:48 step:37601 [D loss: 0.034713, acc: 100.00%] [G loss: 6.501876]\n",
      "epoch:48 step:37602 [D loss: 0.107057, acc: 99.22%] [G loss: 5.653831]\n",
      "epoch:48 step:37603 [D loss: 0.297364, acc: 94.53%] [G loss: 3.150274]\n",
      "epoch:48 step:37604 [D loss: 0.131739, acc: 98.44%] [G loss: 6.052771]\n",
      "epoch:48 step:37605 [D loss: 0.755440, acc: 53.91%] [G loss: 7.765318]\n",
      "epoch:48 step:37606 [D loss: 1.249023, acc: 50.00%] [G loss: 5.812780]\n",
      "epoch:48 step:37607 [D loss: 0.075281, acc: 100.00%] [G loss: 4.293020]\n",
      "epoch:48 step:37608 [D loss: 0.221003, acc: 90.62%] [G loss: 8.483286]\n",
      "epoch:48 step:37609 [D loss: 0.362700, acc: 91.41%] [G loss: 5.181733]\n",
      "epoch:48 step:37610 [D loss: 0.052661, acc: 100.00%] [G loss: 11.869732]\n",
      "epoch:48 step:37611 [D loss: 0.041115, acc: 100.00%] [G loss: 7.331851]\n",
      "epoch:48 step:37612 [D loss: 0.380508, acc: 85.16%] [G loss: 7.423017]\n",
      "epoch:48 step:37613 [D loss: 0.177120, acc: 100.00%] [G loss: 6.244671]\n",
      "epoch:48 step:37614 [D loss: 0.727069, acc: 53.91%] [G loss: 7.131791]\n",
      "epoch:48 step:37615 [D loss: 0.050258, acc: 100.00%] [G loss: 6.776093]\n",
      "epoch:48 step:37616 [D loss: 0.154477, acc: 97.66%] [G loss: 6.628160]\n",
      "epoch:48 step:37617 [D loss: 0.026430, acc: 100.00%] [G loss: 6.099847]\n",
      "epoch:48 step:37618 [D loss: 0.085242, acc: 100.00%] [G loss: 6.906933]\n",
      "epoch:48 step:37619 [D loss: 0.594372, acc: 61.72%] [G loss: 3.582867]\n",
      "epoch:48 step:37620 [D loss: 0.979842, acc: 45.31%] [G loss: 8.043983]\n",
      "epoch:48 step:37621 [D loss: 0.299008, acc: 84.38%] [G loss: 6.105499]\n",
      "epoch:48 step:37622 [D loss: 0.380676, acc: 84.38%] [G loss: 7.258981]\n",
      "epoch:48 step:37623 [D loss: 0.179481, acc: 96.88%] [G loss: 3.624039]\n",
      "epoch:48 step:37624 [D loss: 0.238482, acc: 97.66%] [G loss: 4.353757]\n",
      "epoch:48 step:37625 [D loss: 0.227877, acc: 94.53%] [G loss: 6.579663]\n",
      "epoch:48 step:37626 [D loss: 0.352102, acc: 78.91%] [G loss: 7.860167]\n",
      "epoch:48 step:37627 [D loss: 0.110089, acc: 100.00%] [G loss: 6.085782]\n",
      "epoch:48 step:37628 [D loss: 0.169769, acc: 100.00%] [G loss: 5.382746]\n",
      "epoch:48 step:37629 [D loss: 0.417670, acc: 71.09%] [G loss: 5.638767]\n",
      "epoch:48 step:37630 [D loss: 0.068094, acc: 100.00%] [G loss: 4.735055]\n",
      "epoch:48 step:37631 [D loss: 0.458731, acc: 74.22%] [G loss: 8.819700]\n",
      "epoch:48 step:37632 [D loss: 0.756306, acc: 57.03%] [G loss: 6.839030]\n",
      "epoch:48 step:37633 [D loss: 0.082175, acc: 100.00%] [G loss: 5.953548]\n",
      "epoch:48 step:37634 [D loss: 0.189026, acc: 98.44%] [G loss: 5.802693]\n",
      "epoch:48 step:37635 [D loss: 0.325630, acc: 92.97%] [G loss: 5.928584]\n",
      "epoch:48 step:37636 [D loss: 0.082857, acc: 99.22%] [G loss: 5.859192]\n",
      "epoch:48 step:37637 [D loss: 0.159104, acc: 97.66%] [G loss: 4.660780]\n",
      "epoch:48 step:37638 [D loss: 0.042486, acc: 100.00%] [G loss: 4.323190]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37639 [D loss: 0.570295, acc: 66.41%] [G loss: 7.179135]\n",
      "epoch:48 step:37640 [D loss: 0.397942, acc: 91.41%] [G loss: 5.701651]\n",
      "epoch:48 step:37641 [D loss: 0.150296, acc: 96.88%] [G loss: 5.191101]\n",
      "epoch:48 step:37642 [D loss: 0.043446, acc: 100.00%] [G loss: 6.643961]\n",
      "epoch:48 step:37643 [D loss: 0.204366, acc: 96.09%] [G loss: 7.239989]\n",
      "epoch:48 step:37644 [D loss: 1.463719, acc: 34.38%] [G loss: 8.431730]\n",
      "epoch:48 step:37645 [D loss: 0.164674, acc: 98.44%] [G loss: 5.981383]\n",
      "epoch:48 step:37646 [D loss: 0.128750, acc: 100.00%] [G loss: 6.016333]\n",
      "epoch:48 step:37647 [D loss: 0.114078, acc: 100.00%] [G loss: 4.913276]\n",
      "epoch:48 step:37648 [D loss: 0.042165, acc: 100.00%] [G loss: 3.306937]\n",
      "epoch:48 step:37649 [D loss: 0.046455, acc: 99.22%] [G loss: 5.866131]\n",
      "epoch:48 step:37650 [D loss: 0.094505, acc: 100.00%] [G loss: 8.607871]\n",
      "epoch:48 step:37651 [D loss: 0.805387, acc: 50.78%] [G loss: 7.383439]\n",
      "epoch:48 step:37652 [D loss: 0.310997, acc: 92.19%] [G loss: 7.376595]\n",
      "epoch:48 step:37653 [D loss: 0.221814, acc: 94.53%] [G loss: 5.449249]\n",
      "epoch:48 step:37654 [D loss: 0.418962, acc: 84.38%] [G loss: 6.718402]\n",
      "epoch:48 step:37655 [D loss: 0.434582, acc: 70.31%] [G loss: 6.217043]\n",
      "epoch:48 step:37656 [D loss: 0.044999, acc: 100.00%] [G loss: 4.908918]\n",
      "epoch:48 step:37657 [D loss: 0.274212, acc: 85.16%] [G loss: 12.041332]\n",
      "epoch:48 step:37658 [D loss: 0.249619, acc: 93.75%] [G loss: 4.095902]\n",
      "epoch:48 step:37659 [D loss: 0.135766, acc: 99.22%] [G loss: 4.091065]\n",
      "epoch:48 step:37660 [D loss: 0.308300, acc: 83.59%] [G loss: 7.842675]\n",
      "epoch:48 step:37661 [D loss: 1.027789, acc: 50.00%] [G loss: 8.439112]\n",
      "epoch:48 step:37662 [D loss: 0.159275, acc: 96.88%] [G loss: 3.769304]\n",
      "epoch:48 step:37663 [D loss: 0.147126, acc: 97.66%] [G loss: 5.983602]\n",
      "epoch:48 step:37664 [D loss: 1.480725, acc: 46.09%] [G loss: 9.610794]\n",
      "epoch:48 step:37665 [D loss: 0.605360, acc: 62.50%] [G loss: 6.606164]\n",
      "epoch:48 step:37666 [D loss: 0.672511, acc: 61.72%] [G loss: 5.733476]\n",
      "epoch:48 step:37667 [D loss: 0.050507, acc: 100.00%] [G loss: 5.309470]\n",
      "epoch:48 step:37668 [D loss: 1.679341, acc: 4.69%] [G loss: 8.331751]\n",
      "epoch:48 step:37669 [D loss: 0.166816, acc: 96.88%] [G loss: 5.890050]\n",
      "epoch:48 step:37670 [D loss: 0.190693, acc: 96.09%] [G loss: 6.694478]\n",
      "epoch:48 step:37671 [D loss: 0.380460, acc: 75.00%] [G loss: 12.670297]\n",
      "epoch:48 step:37672 [D loss: 0.096114, acc: 100.00%] [G loss: 5.724031]\n",
      "epoch:48 step:37673 [D loss: 0.384121, acc: 74.22%] [G loss: 6.685628]\n",
      "epoch:48 step:37674 [D loss: 0.212847, acc: 96.09%] [G loss: 7.951368]\n",
      "epoch:48 step:37675 [D loss: 0.221490, acc: 92.97%] [G loss: 4.008284]\n",
      "epoch:48 step:37676 [D loss: 0.736790, acc: 54.69%] [G loss: 7.944498]\n",
      "epoch:48 step:37677 [D loss: 0.250460, acc: 88.28%] [G loss: 6.711440]\n",
      "epoch:48 step:37678 [D loss: 0.328488, acc: 88.28%] [G loss: 10.741470]\n",
      "epoch:48 step:37679 [D loss: 0.036047, acc: 100.00%] [G loss: 6.376846]\n",
      "epoch:48 step:37680 [D loss: 0.390482, acc: 82.81%] [G loss: 9.161152]\n",
      "epoch:48 step:37681 [D loss: 1.152856, acc: 41.41%] [G loss: 4.814873]\n",
      "epoch:48 step:37682 [D loss: 0.013617, acc: 100.00%] [G loss: 5.468163]\n",
      "epoch:48 step:37683 [D loss: 1.210117, acc: 32.81%] [G loss: 10.828808]\n",
      "epoch:48 step:37684 [D loss: 0.190148, acc: 99.22%] [G loss: 4.324901]\n",
      "epoch:48 step:37685 [D loss: 0.084411, acc: 100.00%] [G loss: 3.149055]\n",
      "epoch:48 step:37686 [D loss: 0.145178, acc: 97.66%] [G loss: 5.357730]\n",
      "epoch:48 step:37687 [D loss: 0.704239, acc: 55.47%] [G loss: 6.860727]\n",
      "epoch:48 step:37688 [D loss: 0.308836, acc: 81.25%] [G loss: 3.893672]\n",
      "epoch:48 step:37689 [D loss: 0.083326, acc: 100.00%] [G loss: 5.741991]\n",
      "epoch:48 step:37690 [D loss: 0.115040, acc: 100.00%] [G loss: 6.681212]\n",
      "epoch:48 step:37691 [D loss: 0.315988, acc: 87.50%] [G loss: 5.846459]\n",
      "epoch:48 step:37692 [D loss: 0.439398, acc: 68.75%] [G loss: 8.045366]\n",
      "epoch:48 step:37693 [D loss: 0.900619, acc: 42.19%] [G loss: 7.573323]\n",
      "epoch:48 step:37694 [D loss: 0.087702, acc: 100.00%] [G loss: 5.110090]\n",
      "epoch:48 step:37695 [D loss: 0.451941, acc: 83.59%] [G loss: 3.281804]\n",
      "epoch:48 step:37696 [D loss: 0.066644, acc: 100.00%] [G loss: 8.574371]\n",
      "epoch:48 step:37697 [D loss: 0.425129, acc: 67.19%] [G loss: 5.135882]\n",
      "epoch:48 step:37698 [D loss: 0.525911, acc: 65.62%] [G loss: 6.010946]\n",
      "epoch:48 step:37699 [D loss: 0.291154, acc: 92.97%] [G loss: 6.863697]\n",
      "epoch:48 step:37700 [D loss: 0.047735, acc: 100.00%] [G loss: 7.714480]\n",
      "epoch:48 step:37701 [D loss: 0.524491, acc: 64.06%] [G loss: 6.445719]\n",
      "epoch:48 step:37702 [D loss: 0.263668, acc: 89.84%] [G loss: 6.061590]\n",
      "epoch:48 step:37703 [D loss: 0.074614, acc: 100.00%] [G loss: 6.136296]\n",
      "epoch:48 step:37704 [D loss: 0.385469, acc: 82.81%] [G loss: 3.625257]\n",
      "epoch:48 step:37705 [D loss: 0.235917, acc: 92.97%] [G loss: 7.431247]\n",
      "epoch:48 step:37706 [D loss: 0.183341, acc: 97.66%] [G loss: 3.020334]\n",
      "epoch:48 step:37707 [D loss: 0.139867, acc: 98.44%] [G loss: 6.862992]\n",
      "epoch:48 step:37708 [D loss: 0.139823, acc: 100.00%] [G loss: 7.145850]\n",
      "epoch:48 step:37709 [D loss: 0.138030, acc: 98.44%] [G loss: 7.122220]\n",
      "epoch:48 step:37710 [D loss: 0.739052, acc: 58.59%] [G loss: 4.828260]\n",
      "epoch:48 step:37711 [D loss: 0.078282, acc: 100.00%] [G loss: 7.038961]\n",
      "epoch:48 step:37712 [D loss: 0.160401, acc: 98.44%] [G loss: 7.250394]\n",
      "epoch:48 step:37713 [D loss: 0.314080, acc: 84.38%] [G loss: 8.942390]\n",
      "epoch:48 step:37714 [D loss: 0.830598, acc: 50.00%] [G loss: 8.984413]\n",
      "epoch:48 step:37715 [D loss: 0.207775, acc: 96.09%] [G loss: 4.437985]\n",
      "epoch:48 step:37716 [D loss: 0.242314, acc: 95.31%] [G loss: 5.962542]\n",
      "epoch:48 step:37717 [D loss: 0.616600, acc: 57.81%] [G loss: 8.650028]\n",
      "epoch:48 step:37718 [D loss: 0.264637, acc: 95.31%] [G loss: 9.278416]\n",
      "epoch:48 step:37719 [D loss: 0.026720, acc: 100.00%] [G loss: 10.459440]\n",
      "epoch:48 step:37720 [D loss: 0.068115, acc: 100.00%] [G loss: 6.708040]\n",
      "epoch:48 step:37721 [D loss: 0.266251, acc: 94.53%] [G loss: 6.394017]\n",
      "epoch:48 step:37722 [D loss: 0.375104, acc: 82.03%] [G loss: 1.357136]\n",
      "epoch:48 step:37723 [D loss: 0.096148, acc: 100.00%] [G loss: 5.345019]\n",
      "epoch:48 step:37724 [D loss: 0.301762, acc: 86.72%] [G loss: 5.773175]\n",
      "epoch:48 step:37725 [D loss: 0.579095, acc: 60.94%] [G loss: 8.600033]\n",
      "epoch:48 step:37726 [D loss: 0.434515, acc: 80.47%] [G loss: 6.903523]\n",
      "epoch:48 step:37727 [D loss: 0.204654, acc: 92.97%] [G loss: 7.416225]\n",
      "epoch:48 step:37728 [D loss: 0.037014, acc: 100.00%] [G loss: 6.361323]\n",
      "epoch:48 step:37729 [D loss: 0.578232, acc: 64.84%] [G loss: 6.620703]\n",
      "epoch:48 step:37730 [D loss: 0.569849, acc: 62.50%] [G loss: 9.787990]\n",
      "epoch:48 step:37731 [D loss: 0.304965, acc: 85.16%] [G loss: 3.745011]\n",
      "epoch:48 step:37732 [D loss: 0.053300, acc: 100.00%] [G loss: 4.489223]\n",
      "epoch:48 step:37733 [D loss: 0.633275, acc: 63.28%] [G loss: 7.217479]\n",
      "epoch:48 step:37734 [D loss: 0.089491, acc: 99.22%] [G loss: 4.567970]\n",
      "epoch:48 step:37735 [D loss: 0.235031, acc: 93.75%] [G loss: 6.080433]\n",
      "epoch:48 step:37736 [D loss: 0.512119, acc: 63.28%] [G loss: 6.059924]\n",
      "epoch:48 step:37737 [D loss: 0.015034, acc: 100.00%] [G loss: 6.955058]\n",
      "epoch:48 step:37738 [D loss: 0.025224, acc: 100.00%] [G loss: 8.901162]\n",
      "epoch:48 step:37739 [D loss: 0.103908, acc: 97.66%] [G loss: 5.611537]\n",
      "epoch:48 step:37740 [D loss: 0.268912, acc: 87.50%] [G loss: 7.576810]\n",
      "epoch:48 step:37741 [D loss: 0.095009, acc: 99.22%] [G loss: 4.918160]\n",
      "epoch:48 step:37742 [D loss: 0.032966, acc: 100.00%] [G loss: 6.328416]\n",
      "epoch:48 step:37743 [D loss: 0.299290, acc: 89.06%] [G loss: 9.016979]\n",
      "epoch:48 step:37744 [D loss: 0.543737, acc: 65.62%] [G loss: 8.352982]\n",
      "epoch:48 step:37745 [D loss: 0.020448, acc: 100.00%] [G loss: 6.940235]\n",
      "epoch:48 step:37746 [D loss: 1.272458, acc: 28.91%] [G loss: 8.635408]\n",
      "epoch:48 step:37747 [D loss: 0.155261, acc: 100.00%] [G loss: 7.306340]\n",
      "epoch:48 step:37748 [D loss: 0.195961, acc: 96.88%] [G loss: 6.579350]\n",
      "epoch:48 step:37749 [D loss: 0.221818, acc: 93.75%] [G loss: 8.099545]\n",
      "epoch:48 step:37750 [D loss: 0.056095, acc: 100.00%] [G loss: 5.948746]\n",
      "epoch:48 step:37751 [D loss: 1.232068, acc: 50.00%] [G loss: 8.367180]\n",
      "epoch:48 step:37752 [D loss: 0.156982, acc: 97.66%] [G loss: 11.208887]\n",
      "epoch:48 step:37753 [D loss: 0.547114, acc: 64.06%] [G loss: 7.802233]\n",
      "epoch:48 step:37754 [D loss: 0.100709, acc: 100.00%] [G loss: 6.386025]\n",
      "epoch:48 step:37755 [D loss: 1.080635, acc: 29.69%] [G loss: 4.267012]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37756 [D loss: 0.214495, acc: 95.31%] [G loss: 6.929216]\n",
      "epoch:48 step:37757 [D loss: 0.468430, acc: 75.78%] [G loss: 6.165148]\n",
      "epoch:48 step:37758 [D loss: 0.558362, acc: 63.28%] [G loss: 10.102191]\n",
      "epoch:48 step:37759 [D loss: 1.238121, acc: 45.31%] [G loss: 6.305593]\n",
      "epoch:48 step:37760 [D loss: 0.514827, acc: 75.78%] [G loss: 7.637831]\n",
      "epoch:48 step:37761 [D loss: 1.401639, acc: 28.91%] [G loss: 6.861819]\n",
      "epoch:48 step:37762 [D loss: 0.654593, acc: 57.81%] [G loss: 7.214024]\n",
      "epoch:48 step:37763 [D loss: 0.030798, acc: 100.00%] [G loss: 6.838296]\n",
      "epoch:48 step:37764 [D loss: 0.493053, acc: 78.91%] [G loss: 4.560722]\n",
      "epoch:48 step:37765 [D loss: 0.445325, acc: 79.69%] [G loss: 5.962732]\n",
      "epoch:48 step:37766 [D loss: 0.120505, acc: 100.00%] [G loss: 3.078444]\n",
      "epoch:48 step:37767 [D loss: 0.090107, acc: 100.00%] [G loss: 5.252639]\n",
      "epoch:48 step:37768 [D loss: 1.356941, acc: 13.28%] [G loss: 9.780986]\n",
      "epoch:48 step:37769 [D loss: 0.399441, acc: 82.81%] [G loss: 4.996111]\n",
      "epoch:48 step:37770 [D loss: 0.355030, acc: 80.47%] [G loss: 5.540523]\n",
      "epoch:48 step:37771 [D loss: 0.587094, acc: 64.84%] [G loss: 6.628739]\n",
      "epoch:48 step:37772 [D loss: 0.050722, acc: 100.00%] [G loss: 8.333782]\n",
      "epoch:48 step:37773 [D loss: 0.306443, acc: 85.16%] [G loss: 8.976853]\n",
      "epoch:48 step:37774 [D loss: 0.251044, acc: 94.53%] [G loss: 4.270550]\n",
      "epoch:48 step:37775 [D loss: 0.106888, acc: 99.22%] [G loss: 5.972993]\n",
      "epoch:48 step:37776 [D loss: 1.115766, acc: 35.16%] [G loss: 6.314381]\n",
      "epoch:48 step:37777 [D loss: 0.059045, acc: 100.00%] [G loss: 5.534774]\n",
      "epoch:48 step:37778 [D loss: 0.608438, acc: 61.72%] [G loss: 6.678441]\n",
      "epoch:48 step:37779 [D loss: 0.107656, acc: 99.22%] [G loss: 6.739636]\n",
      "epoch:48 step:37780 [D loss: 0.015163, acc: 100.00%] [G loss: 4.650938]\n",
      "epoch:48 step:37781 [D loss: 0.017449, acc: 100.00%] [G loss: 2.835449]\n",
      "epoch:48 step:37782 [D loss: 0.549911, acc: 64.84%] [G loss: 8.984289]\n",
      "epoch:48 step:37783 [D loss: 0.151311, acc: 99.22%] [G loss: 4.431155]\n",
      "epoch:48 step:37784 [D loss: 0.900341, acc: 44.53%] [G loss: 8.588541]\n",
      "epoch:48 step:37785 [D loss: 0.088026, acc: 100.00%] [G loss: 4.316213]\n",
      "epoch:48 step:37786 [D loss: 0.191713, acc: 98.44%] [G loss: 9.492461]\n",
      "epoch:48 step:37787 [D loss: 0.177407, acc: 96.09%] [G loss: 5.801609]\n",
      "epoch:48 step:37788 [D loss: 0.362053, acc: 88.28%] [G loss: 4.257502]\n",
      "epoch:48 step:37789 [D loss: 0.295670, acc: 85.94%] [G loss: 3.103281]\n",
      "epoch:48 step:37790 [D loss: 0.094028, acc: 99.22%] [G loss: 5.163438]\n",
      "epoch:48 step:37791 [D loss: 0.242104, acc: 94.53%] [G loss: 6.693349]\n",
      "epoch:48 step:37792 [D loss: 0.182948, acc: 99.22%] [G loss: 5.441483]\n",
      "epoch:48 step:37793 [D loss: 0.119991, acc: 100.00%] [G loss: 8.940056]\n",
      "epoch:48 step:37794 [D loss: 0.915834, acc: 42.19%] [G loss: 8.407902]\n",
      "epoch:48 step:37795 [D loss: 0.196916, acc: 98.44%] [G loss: 8.275393]\n",
      "epoch:48 step:37796 [D loss: 0.855711, acc: 50.78%] [G loss: 7.744758]\n",
      "epoch:48 step:37797 [D loss: 0.680321, acc: 57.81%] [G loss: 7.329900]\n",
      "epoch:48 step:37798 [D loss: 0.086974, acc: 100.00%] [G loss: 6.890874]\n",
      "epoch:48 step:37799 [D loss: 0.561565, acc: 60.16%] [G loss: 4.130712]\n",
      "epoch:48 step:37800 [D loss: 0.499357, acc: 75.78%] [G loss: 8.629362]\n",
      "epoch:48 step:37801 [D loss: 0.083482, acc: 100.00%] [G loss: 5.371760]\n",
      "epoch:48 step:37802 [D loss: 0.104393, acc: 100.00%] [G loss: 9.063735]\n",
      "epoch:48 step:37803 [D loss: 0.956128, acc: 51.56%] [G loss: 7.990889]\n",
      "epoch:48 step:37804 [D loss: 0.109710, acc: 99.22%] [G loss: 5.821056]\n",
      "epoch:48 step:37805 [D loss: 0.042514, acc: 100.00%] [G loss: 8.824889]\n",
      "epoch:48 step:37806 [D loss: 0.036934, acc: 100.00%] [G loss: 6.719947]\n",
      "epoch:48 step:37807 [D loss: 0.529539, acc: 67.97%] [G loss: 5.583458]\n",
      "epoch:48 step:37808 [D loss: 0.512184, acc: 65.62%] [G loss: 6.889794]\n",
      "epoch:48 step:37809 [D loss: 0.342687, acc: 84.38%] [G loss: 4.928268]\n",
      "epoch:48 step:37810 [D loss: 0.034897, acc: 100.00%] [G loss: 2.713646]\n",
      "epoch:48 step:37811 [D loss: 0.392672, acc: 81.25%] [G loss: 2.700858]\n",
      "epoch:48 step:37812 [D loss: 0.423222, acc: 77.34%] [G loss: 5.198301]\n",
      "epoch:48 step:37813 [D loss: 0.141672, acc: 100.00%] [G loss: 5.161607]\n",
      "epoch:48 step:37814 [D loss: 0.414756, acc: 78.91%] [G loss: 3.746811]\n",
      "epoch:48 step:37815 [D loss: 0.078708, acc: 100.00%] [G loss: 4.125687]\n",
      "epoch:48 step:37816 [D loss: 0.205713, acc: 91.41%] [G loss: 5.670266]\n",
      "epoch:48 step:37817 [D loss: 0.091402, acc: 100.00%] [G loss: 4.301546]\n",
      "epoch:48 step:37818 [D loss: 0.236794, acc: 92.19%] [G loss: 7.420886]\n",
      "epoch:48 step:37819 [D loss: 1.371704, acc: 10.94%] [G loss: 7.118365]\n",
      "epoch:48 step:37820 [D loss: 0.241254, acc: 89.84%] [G loss: 6.118707]\n",
      "epoch:48 step:37821 [D loss: 0.042784, acc: 100.00%] [G loss: 10.197362]\n",
      "epoch:48 step:37822 [D loss: 0.363512, acc: 79.69%] [G loss: 5.337229]\n",
      "epoch:48 step:37823 [D loss: 0.157286, acc: 100.00%] [G loss: 8.431574]\n",
      "epoch:48 step:37824 [D loss: 0.019250, acc: 100.00%] [G loss: 5.884390]\n",
      "epoch:48 step:37825 [D loss: 0.391578, acc: 82.81%] [G loss: 4.317188]\n",
      "epoch:48 step:37826 [D loss: 0.082514, acc: 100.00%] [G loss: 5.905178]\n",
      "epoch:48 step:37827 [D loss: 0.175910, acc: 95.31%] [G loss: 9.719507]\n",
      "epoch:48 step:37828 [D loss: 0.039092, acc: 100.00%] [G loss: 4.373633]\n",
      "epoch:48 step:37829 [D loss: 0.075082, acc: 100.00%] [G loss: 5.327103]\n",
      "epoch:48 step:37830 [D loss: 0.317265, acc: 93.75%] [G loss: 5.051248]\n",
      "epoch:48 step:37831 [D loss: 0.148530, acc: 99.22%] [G loss: 4.156113]\n",
      "epoch:48 step:37832 [D loss: 0.037447, acc: 100.00%] [G loss: 5.362102]\n",
      "epoch:48 step:37833 [D loss: 0.133225, acc: 97.66%] [G loss: 8.346338]\n",
      "epoch:48 step:37834 [D loss: 0.115007, acc: 99.22%] [G loss: 4.386511]\n",
      "epoch:48 step:37835 [D loss: 0.886742, acc: 51.56%] [G loss: 5.427439]\n",
      "epoch:48 step:37836 [D loss: 0.069085, acc: 100.00%] [G loss: 4.908504]\n",
      "epoch:48 step:37837 [D loss: 1.498014, acc: 50.00%] [G loss: 9.010654]\n",
      "epoch:48 step:37838 [D loss: 1.470565, acc: 45.31%] [G loss: 9.057850]\n",
      "epoch:48 step:37839 [D loss: 0.727126, acc: 56.25%] [G loss: 10.518903]\n",
      "epoch:48 step:37840 [D loss: 0.030188, acc: 99.22%] [G loss: 11.846622]\n",
      "epoch:48 step:37841 [D loss: 0.436658, acc: 69.53%] [G loss: 7.560013]\n",
      "epoch:48 step:37842 [D loss: 0.424550, acc: 76.56%] [G loss: 6.015681]\n",
      "epoch:48 step:37843 [D loss: 0.525974, acc: 70.31%] [G loss: 4.477724]\n",
      "epoch:48 step:37844 [D loss: 0.855250, acc: 46.88%] [G loss: 4.381982]\n",
      "epoch:48 step:37845 [D loss: 0.495033, acc: 72.66%] [G loss: 6.775781]\n",
      "epoch:48 step:37846 [D loss: 0.206765, acc: 92.97%] [G loss: 3.528734]\n",
      "epoch:48 step:37847 [D loss: 0.481042, acc: 77.34%] [G loss: 5.769919]\n",
      "epoch:48 step:37848 [D loss: 0.283786, acc: 87.50%] [G loss: 6.385807]\n",
      "epoch:48 step:37849 [D loss: 0.121117, acc: 100.00%] [G loss: 6.004138]\n",
      "epoch:48 step:37850 [D loss: 0.166011, acc: 96.09%] [G loss: 4.620273]\n",
      "epoch:48 step:37851 [D loss: 2.640131, acc: 2.34%] [G loss: 11.202356]\n",
      "epoch:48 step:37852 [D loss: 0.041101, acc: 100.00%] [G loss: 4.576028]\n",
      "epoch:48 step:37853 [D loss: 0.248452, acc: 95.31%] [G loss: 3.544325]\n",
      "epoch:48 step:37854 [D loss: 1.081587, acc: 35.16%] [G loss: 8.229267]\n",
      "epoch:48 step:37855 [D loss: 0.433092, acc: 72.66%] [G loss: 7.517664]\n",
      "epoch:48 step:37856 [D loss: 0.277813, acc: 89.06%] [G loss: 5.228412]\n",
      "epoch:48 step:37857 [D loss: 0.037149, acc: 100.00%] [G loss: 4.251505]\n",
      "epoch:48 step:37858 [D loss: 0.096929, acc: 98.44%] [G loss: 9.175366]\n",
      "epoch:48 step:37859 [D loss: 0.141634, acc: 97.66%] [G loss: 6.233502]\n",
      "epoch:48 step:37860 [D loss: 0.198177, acc: 94.53%] [G loss: 8.271738]\n",
      "epoch:48 step:37861 [D loss: 0.085333, acc: 100.00%] [G loss: 5.049496]\n",
      "epoch:48 step:37862 [D loss: 0.132518, acc: 99.22%] [G loss: 6.676377]\n",
      "epoch:48 step:37863 [D loss: 0.075812, acc: 100.00%] [G loss: 3.158517]\n",
      "epoch:48 step:37864 [D loss: 0.736881, acc: 55.47%] [G loss: 5.882180]\n",
      "epoch:48 step:37865 [D loss: 0.118084, acc: 99.22%] [G loss: 4.714256]\n",
      "epoch:48 step:37866 [D loss: 0.259695, acc: 90.62%] [G loss: 8.056883]\n",
      "epoch:48 step:37867 [D loss: 0.049403, acc: 100.00%] [G loss: 7.595596]\n",
      "epoch:48 step:37868 [D loss: 0.171551, acc: 96.09%] [G loss: 8.392295]\n",
      "epoch:48 step:37869 [D loss: 0.010776, acc: 100.00%] [G loss: 7.037017]\n",
      "epoch:48 step:37870 [D loss: 0.100199, acc: 99.22%] [G loss: 4.516343]\n",
      "epoch:48 step:37871 [D loss: 0.053934, acc: 100.00%] [G loss: 5.609440]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37872 [D loss: 0.204314, acc: 98.44%] [G loss: 4.135754]\n",
      "epoch:48 step:37873 [D loss: 0.144774, acc: 97.66%] [G loss: 4.719419]\n",
      "epoch:48 step:37874 [D loss: 0.643475, acc: 63.28%] [G loss: 6.548732]\n",
      "epoch:48 step:37875 [D loss: 0.189113, acc: 96.88%] [G loss: 1.899086]\n",
      "epoch:48 step:37876 [D loss: 0.336843, acc: 86.72%] [G loss: 9.084864]\n",
      "epoch:48 step:37877 [D loss: 0.037344, acc: 100.00%] [G loss: 7.152813]\n",
      "epoch:48 step:37878 [D loss: 0.194665, acc: 93.75%] [G loss: 6.073102]\n",
      "epoch:48 step:37879 [D loss: 0.910594, acc: 34.38%] [G loss: 6.203111]\n",
      "epoch:48 step:37880 [D loss: 0.093070, acc: 99.22%] [G loss: 5.849109]\n",
      "epoch:48 step:37881 [D loss: 0.287921, acc: 85.16%] [G loss: 7.451797]\n",
      "epoch:48 step:37882 [D loss: 0.292836, acc: 92.97%] [G loss: 2.989131]\n",
      "epoch:48 step:37883 [D loss: 0.067646, acc: 100.00%] [G loss: 2.848267]\n",
      "epoch:48 step:37884 [D loss: 0.827623, acc: 53.91%] [G loss: 4.048281]\n",
      "epoch:48 step:37885 [D loss: 1.244793, acc: 40.62%] [G loss: 8.293192]\n",
      "epoch:48 step:37886 [D loss: 0.052438, acc: 100.00%] [G loss: 4.992048]\n",
      "epoch:48 step:37887 [D loss: 0.377815, acc: 78.91%] [G loss: 7.411427]\n",
      "epoch:48 step:37888 [D loss: 0.088361, acc: 100.00%] [G loss: 4.167165]\n",
      "epoch:48 step:37889 [D loss: 0.014774, acc: 100.00%] [G loss: 5.009275]\n",
      "epoch:48 step:37890 [D loss: 0.040738, acc: 100.00%] [G loss: 7.757018]\n",
      "epoch:48 step:37891 [D loss: 1.148805, acc: 39.84%] [G loss: 5.721469]\n",
      "epoch:48 step:37892 [D loss: 0.395149, acc: 79.69%] [G loss: 8.923009]\n",
      "epoch:48 step:37893 [D loss: 0.320691, acc: 92.97%] [G loss: 5.359206]\n",
      "epoch:48 step:37894 [D loss: 0.037111, acc: 100.00%] [G loss: 3.669026]\n",
      "epoch:48 step:37895 [D loss: 0.248030, acc: 91.41%] [G loss: 6.048884]\n",
      "epoch:48 step:37896 [D loss: 0.109282, acc: 97.66%] [G loss: 6.454327]\n",
      "epoch:48 step:37897 [D loss: 0.475050, acc: 69.53%] [G loss: 5.129138]\n",
      "epoch:48 step:37898 [D loss: 0.362517, acc: 83.59%] [G loss: 5.124348]\n",
      "epoch:48 step:37899 [D loss: 0.516723, acc: 60.94%] [G loss: 5.151590]\n",
      "epoch:48 step:37900 [D loss: 0.172793, acc: 95.31%] [G loss: 9.552086]\n",
      "epoch:48 step:37901 [D loss: 0.115593, acc: 100.00%] [G loss: 5.741931]\n",
      "epoch:48 step:37902 [D loss: 0.030952, acc: 100.00%] [G loss: 6.340247]\n",
      "epoch:48 step:37903 [D loss: 0.162215, acc: 98.44%] [G loss: 4.637469]\n",
      "epoch:48 step:37904 [D loss: 0.316009, acc: 88.28%] [G loss: 5.965670]\n",
      "epoch:48 step:37905 [D loss: 0.431320, acc: 78.91%] [G loss: 6.831223]\n",
      "epoch:48 step:37906 [D loss: 0.086130, acc: 99.22%] [G loss: 3.777920]\n",
      "epoch:48 step:37907 [D loss: 0.055240, acc: 100.00%] [G loss: 5.635896]\n",
      "epoch:48 step:37908 [D loss: 0.032965, acc: 100.00%] [G loss: 9.242435]\n",
      "epoch:48 step:37909 [D loss: 0.223914, acc: 94.53%] [G loss: 5.144815]\n",
      "epoch:48 step:37910 [D loss: 0.416238, acc: 82.81%] [G loss: 8.562840]\n",
      "epoch:48 step:37911 [D loss: 0.079649, acc: 100.00%] [G loss: 5.387082]\n",
      "epoch:48 step:37912 [D loss: 0.285387, acc: 91.41%] [G loss: 6.065577]\n",
      "epoch:48 step:37913 [D loss: 0.044939, acc: 100.00%] [G loss: 6.917921]\n",
      "epoch:48 step:37914 [D loss: 0.055471, acc: 100.00%] [G loss: 6.625980]\n",
      "epoch:48 step:37915 [D loss: 0.135495, acc: 99.22%] [G loss: 3.713662]\n",
      "epoch:48 step:37916 [D loss: 0.403726, acc: 70.31%] [G loss: 5.307883]\n",
      "epoch:48 step:37917 [D loss: 0.426798, acc: 72.66%] [G loss: 10.449573]\n",
      "epoch:48 step:37918 [D loss: 0.140643, acc: 99.22%] [G loss: 6.783936]\n",
      "epoch:48 step:37919 [D loss: 0.139879, acc: 98.44%] [G loss: 8.441076]\n",
      "epoch:48 step:37920 [D loss: 0.098381, acc: 100.00%] [G loss: 5.116980]\n",
      "epoch:48 step:37921 [D loss: 0.052827, acc: 100.00%] [G loss: 5.867522]\n",
      "epoch:48 step:37922 [D loss: 0.045134, acc: 100.00%] [G loss: 11.645926]\n",
      "epoch:48 step:37923 [D loss: 0.110469, acc: 100.00%] [G loss: 6.850368]\n",
      "epoch:48 step:37924 [D loss: 0.049693, acc: 100.00%] [G loss: 5.185664]\n",
      "epoch:48 step:37925 [D loss: 0.200223, acc: 94.53%] [G loss: 4.990268]\n",
      "epoch:48 step:37926 [D loss: 0.306670, acc: 87.50%] [G loss: 6.803443]\n",
      "epoch:48 step:37927 [D loss: 0.172065, acc: 97.66%] [G loss: 4.299079]\n",
      "epoch:48 step:37928 [D loss: 0.634769, acc: 62.50%] [G loss: 7.891175]\n",
      "epoch:48 step:37929 [D loss: 0.185951, acc: 96.09%] [G loss: 5.398774]\n",
      "epoch:48 step:37930 [D loss: 0.113275, acc: 98.44%] [G loss: 4.587652]\n",
      "epoch:48 step:37931 [D loss: 0.267980, acc: 96.88%] [G loss: 5.290604]\n",
      "epoch:48 step:37932 [D loss: 0.388918, acc: 79.69%] [G loss: 3.889544]\n",
      "epoch:48 step:37933 [D loss: 0.207596, acc: 94.53%] [G loss: 7.185353]\n",
      "epoch:48 step:37934 [D loss: 0.210936, acc: 100.00%] [G loss: 7.707764]\n",
      "epoch:48 step:37935 [D loss: 0.188994, acc: 94.53%] [G loss: 5.164208]\n",
      "epoch:48 step:37936 [D loss: 0.989664, acc: 51.56%] [G loss: 9.804935]\n",
      "epoch:48 step:37937 [D loss: 0.638731, acc: 57.81%] [G loss: 8.082676]\n",
      "epoch:48 step:37938 [D loss: 0.614978, acc: 60.16%] [G loss: 7.952873]\n",
      "epoch:48 step:37939 [D loss: 0.041997, acc: 100.00%] [G loss: 7.335783]\n",
      "epoch:48 step:37940 [D loss: 0.264962, acc: 93.75%] [G loss: 7.607600]\n",
      "epoch:48 step:37941 [D loss: 0.168993, acc: 96.88%] [G loss: 7.010418]\n",
      "epoch:48 step:37942 [D loss: 1.045069, acc: 50.00%] [G loss: 9.049241]\n",
      "epoch:48 step:37943 [D loss: 0.116804, acc: 98.44%] [G loss: 7.232524]\n",
      "epoch:48 step:37944 [D loss: 0.260909, acc: 89.84%] [G loss: 7.085060]\n",
      "epoch:48 step:37945 [D loss: 0.112243, acc: 98.44%] [G loss: 6.846754]\n",
      "epoch:48 step:37946 [D loss: 0.216157, acc: 92.97%] [G loss: 6.849610]\n",
      "epoch:48 step:37947 [D loss: 0.073457, acc: 99.22%] [G loss: 6.254768]\n",
      "epoch:48 step:37948 [D loss: 0.188710, acc: 96.09%] [G loss: 5.635979]\n",
      "epoch:48 step:37949 [D loss: 0.154354, acc: 98.44%] [G loss: 5.688153]\n",
      "epoch:48 step:37950 [D loss: 0.069143, acc: 100.00%] [G loss: 8.676147]\n",
      "epoch:48 step:37951 [D loss: 1.117841, acc: 50.00%] [G loss: 7.957664]\n",
      "epoch:48 step:37952 [D loss: 0.364411, acc: 85.16%] [G loss: 3.386981]\n",
      "epoch:48 step:37953 [D loss: 0.241206, acc: 96.09%] [G loss: 6.483252]\n",
      "epoch:48 step:37954 [D loss: 0.146253, acc: 96.09%] [G loss: 5.488146]\n",
      "epoch:48 step:37955 [D loss: 0.102236, acc: 100.00%] [G loss: 4.569084]\n",
      "epoch:48 step:37956 [D loss: 0.215161, acc: 95.31%] [G loss: 4.309990]\n",
      "epoch:48 step:37957 [D loss: 0.122375, acc: 99.22%] [G loss: 3.747083]\n",
      "epoch:48 step:37958 [D loss: 0.032463, acc: 100.00%] [G loss: 8.216908]\n",
      "epoch:48 step:37959 [D loss: 0.171113, acc: 98.44%] [G loss: 5.463019]\n",
      "epoch:48 step:37960 [D loss: 0.074404, acc: 99.22%] [G loss: 7.771318]\n",
      "epoch:48 step:37961 [D loss: 0.633755, acc: 64.06%] [G loss: 6.530597]\n",
      "epoch:48 step:37962 [D loss: 0.093755, acc: 100.00%] [G loss: 4.573366]\n",
      "epoch:48 step:37963 [D loss: 0.268685, acc: 94.53%] [G loss: 6.217150]\n",
      "epoch:48 step:37964 [D loss: 0.465369, acc: 71.09%] [G loss: 8.840214]\n",
      "epoch:48 step:37965 [D loss: 0.056701, acc: 100.00%] [G loss: 6.185699]\n",
      "epoch:48 step:37966 [D loss: 0.077900, acc: 100.00%] [G loss: 6.558585]\n",
      "epoch:48 step:37967 [D loss: 0.827500, acc: 54.69%] [G loss: 8.203935]\n",
      "epoch:48 step:37968 [D loss: 0.063313, acc: 100.00%] [G loss: 5.506741]\n",
      "epoch:48 step:37969 [D loss: 0.113430, acc: 99.22%] [G loss: 4.747105]\n",
      "epoch:48 step:37970 [D loss: 0.085725, acc: 100.00%] [G loss: 6.554088]\n",
      "epoch:48 step:37971 [D loss: 0.155861, acc: 98.44%] [G loss: 6.291842]\n",
      "epoch:48 step:37972 [D loss: 1.142333, acc: 23.44%] [G loss: 4.895137]\n",
      "epoch:48 step:37973 [D loss: 0.102171, acc: 100.00%] [G loss: 7.807921]\n",
      "epoch:48 step:37974 [D loss: 0.419259, acc: 74.22%] [G loss: 5.458686]\n",
      "epoch:48 step:37975 [D loss: 0.151547, acc: 97.66%] [G loss: 6.216629]\n",
      "epoch:48 step:37976 [D loss: 0.237229, acc: 90.62%] [G loss: 2.149571]\n",
      "epoch:48 step:37977 [D loss: 0.022261, acc: 100.00%] [G loss: 6.598536]\n",
      "epoch:48 step:37978 [D loss: 0.110530, acc: 99.22%] [G loss: 10.351897]\n",
      "epoch:48 step:37979 [D loss: 0.208873, acc: 96.88%] [G loss: 5.999338]\n",
      "epoch:48 step:37980 [D loss: 0.143719, acc: 100.00%] [G loss: 7.082033]\n",
      "epoch:48 step:37981 [D loss: 0.404899, acc: 88.28%] [G loss: 6.181285]\n",
      "epoch:48 step:37982 [D loss: 0.190953, acc: 99.22%] [G loss: 7.872511]\n",
      "epoch:48 step:37983 [D loss: 0.070474, acc: 100.00%] [G loss: 2.464111]\n",
      "epoch:48 step:37984 [D loss: 0.012940, acc: 100.00%] [G loss: 10.150066]\n",
      "epoch:48 step:37985 [D loss: 0.364526, acc: 86.72%] [G loss: 5.883552]\n",
      "epoch:48 step:37986 [D loss: 0.064113, acc: 100.00%] [G loss: 5.215668]\n",
      "epoch:48 step:37987 [D loss: 0.194036, acc: 98.44%] [G loss: 7.914980]\n",
      "epoch:48 step:37988 [D loss: 0.170183, acc: 96.09%] [G loss: 8.239589]\n",
      "epoch:48 step:37989 [D loss: 0.252216, acc: 89.84%] [G loss: 6.234053]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37990 [D loss: 0.271694, acc: 87.50%] [G loss: 6.426544]\n",
      "epoch:48 step:37991 [D loss: 0.191289, acc: 95.31%] [G loss: 6.503695]\n",
      "epoch:48 step:37992 [D loss: 0.158569, acc: 99.22%] [G loss: 4.660719]\n",
      "epoch:48 step:37993 [D loss: 0.072059, acc: 100.00%] [G loss: 8.245466]\n",
      "epoch:48 step:37994 [D loss: 0.398272, acc: 88.28%] [G loss: 6.341541]\n",
      "epoch:48 step:37995 [D loss: 0.491277, acc: 64.84%] [G loss: 7.094630]\n",
      "epoch:48 step:37996 [D loss: 0.043508, acc: 100.00%] [G loss: 4.556784]\n",
      "epoch:48 step:37997 [D loss: 0.266325, acc: 92.97%] [G loss: 8.903378]\n",
      "epoch:48 step:37998 [D loss: 0.206670, acc: 92.19%] [G loss: 6.097079]\n",
      "epoch:48 step:37999 [D loss: 0.011832, acc: 100.00%] [G loss: 8.101402]\n",
      "epoch:48 step:38000 [D loss: 0.097859, acc: 100.00%] [G loss: 6.571377]\n",
      "epoch:48 step:38001 [D loss: 0.093298, acc: 99.22%] [G loss: 7.636850]\n",
      "epoch:48 step:38002 [D loss: 0.117415, acc: 100.00%] [G loss: 4.551696]\n",
      "epoch:48 step:38003 [D loss: 0.512173, acc: 67.19%] [G loss: 4.059445]\n",
      "epoch:48 step:38004 [D loss: 0.207681, acc: 93.75%] [G loss: 6.071596]\n",
      "epoch:48 step:38005 [D loss: 0.125300, acc: 98.44%] [G loss: 9.737170]\n",
      "epoch:48 step:38006 [D loss: 0.101852, acc: 99.22%] [G loss: 6.417317]\n",
      "epoch:48 step:38007 [D loss: 0.050515, acc: 99.22%] [G loss: 5.051931]\n",
      "epoch:48 step:38008 [D loss: 0.282566, acc: 90.62%] [G loss: 7.196248]\n",
      "epoch:48 step:38009 [D loss: 0.186262, acc: 98.44%] [G loss: 6.969485]\n",
      "epoch:48 step:38010 [D loss: 0.732500, acc: 53.91%] [G loss: 6.433964]\n",
      "epoch:48 step:38011 [D loss: 0.262786, acc: 96.88%] [G loss: 4.615778]\n",
      "epoch:48 step:38012 [D loss: 0.263458, acc: 90.62%] [G loss: 8.849780]\n",
      "epoch:48 step:38013 [D loss: 0.770774, acc: 53.12%] [G loss: 9.506987]\n",
      "epoch:48 step:38014 [D loss: 0.404437, acc: 71.88%] [G loss: 8.500511]\n",
      "epoch:48 step:38015 [D loss: 1.319865, acc: 50.00%] [G loss: 5.590317]\n",
      "epoch:48 step:38016 [D loss: 0.209100, acc: 93.75%] [G loss: 8.672127]\n",
      "epoch:48 step:38017 [D loss: 0.097064, acc: 98.44%] [G loss: 11.016555]\n",
      "epoch:48 step:38018 [D loss: 0.524853, acc: 72.66%] [G loss: 11.855184]\n",
      "epoch:48 step:38019 [D loss: 0.050735, acc: 100.00%] [G loss: 5.893943]\n",
      "epoch:48 step:38020 [D loss: 0.270976, acc: 93.75%] [G loss: 4.385166]\n",
      "epoch:48 step:38021 [D loss: 0.486746, acc: 84.38%] [G loss: 6.810524]\n",
      "epoch:48 step:38022 [D loss: 0.525152, acc: 73.44%] [G loss: 9.584882]\n",
      "epoch:48 step:38023 [D loss: 0.060983, acc: 100.00%] [G loss: 1.970725]\n",
      "epoch:48 step:38024 [D loss: 0.073963, acc: 100.00%] [G loss: 7.013677]\n",
      "epoch:48 step:38025 [D loss: 0.132172, acc: 97.66%] [G loss: 7.091323]\n",
      "epoch:48 step:38026 [D loss: 0.064804, acc: 100.00%] [G loss: 5.591671]\n",
      "epoch:48 step:38027 [D loss: 0.368430, acc: 89.84%] [G loss: 5.604583]\n",
      "epoch:48 step:38028 [D loss: 0.584501, acc: 71.09%] [G loss: 7.374190]\n",
      "epoch:48 step:38029 [D loss: 0.146223, acc: 95.31%] [G loss: 5.701249]\n",
      "epoch:48 step:38030 [D loss: 1.001698, acc: 50.00%] [G loss: 5.421702]\n",
      "epoch:48 step:38031 [D loss: 0.339536, acc: 81.25%] [G loss: 8.392383]\n",
      "epoch:48 step:38032 [D loss: 1.157539, acc: 28.91%] [G loss: 8.729307]\n",
      "epoch:48 step:38033 [D loss: 0.253175, acc: 92.19%] [G loss: 10.109006]\n",
      "epoch:48 step:38034 [D loss: 0.803395, acc: 53.12%] [G loss: 8.997702]\n",
      "epoch:48 step:38035 [D loss: 0.345521, acc: 84.38%] [G loss: 7.879318]\n",
      "epoch:48 step:38036 [D loss: 0.038902, acc: 99.22%] [G loss: 5.972206]\n",
      "epoch:48 step:38037 [D loss: 0.059955, acc: 100.00%] [G loss: 7.053557]\n",
      "epoch:48 step:38038 [D loss: 0.486112, acc: 71.09%] [G loss: 4.353680]\n",
      "epoch:48 step:38039 [D loss: 0.525719, acc: 67.19%] [G loss: 6.759491]\n",
      "epoch:48 step:38040 [D loss: 0.355230, acc: 83.59%] [G loss: 8.627098]\n",
      "epoch:48 step:38041 [D loss: 0.182149, acc: 96.09%] [G loss: 8.776793]\n",
      "epoch:48 step:38042 [D loss: 0.086823, acc: 99.22%] [G loss: 3.398050]\n",
      "epoch:48 step:38043 [D loss: 0.015912, acc: 100.00%] [G loss: 6.179989]\n",
      "epoch:48 step:38044 [D loss: 0.192699, acc: 93.75%] [G loss: 6.735919]\n",
      "epoch:48 step:38045 [D loss: 0.108218, acc: 98.44%] [G loss: 6.672324]\n",
      "epoch:48 step:38046 [D loss: 0.280666, acc: 96.09%] [G loss: 9.657845]\n",
      "epoch:48 step:38047 [D loss: 0.400667, acc: 72.66%] [G loss: 7.828230]\n",
      "epoch:48 step:38048 [D loss: 0.099411, acc: 100.00%] [G loss: 9.772162]\n",
      "epoch:48 step:38049 [D loss: 0.137219, acc: 98.44%] [G loss: 6.255499]\n",
      "epoch:48 step:38050 [D loss: 0.732104, acc: 57.03%] [G loss: 9.907656]\n",
      "epoch:48 step:38051 [D loss: 0.264715, acc: 96.09%] [G loss: 2.211208]\n",
      "epoch:48 step:38052 [D loss: 0.197187, acc: 95.31%] [G loss: 7.477256]\n",
      "epoch:48 step:38053 [D loss: 0.013519, acc: 100.00%] [G loss: 7.443472]\n",
      "epoch:48 step:38054 [D loss: 0.325637, acc: 89.84%] [G loss: 7.664442]\n",
      "epoch:48 step:38055 [D loss: 0.306858, acc: 89.84%] [G loss: 5.913736]\n",
      "epoch:48 step:38056 [D loss: 0.079841, acc: 99.22%] [G loss: 4.778448]\n",
      "epoch:48 step:38057 [D loss: 0.169551, acc: 97.66%] [G loss: 8.354058]\n",
      "epoch:48 step:38058 [D loss: 0.164555, acc: 99.22%] [G loss: 5.801017]\n",
      "epoch:48 step:38059 [D loss: 0.665214, acc: 54.69%] [G loss: 5.650102]\n",
      "epoch:48 step:38060 [D loss: 0.085714, acc: 100.00%] [G loss: 7.251885]\n",
      "epoch:48 step:38061 [D loss: 0.356216, acc: 78.12%] [G loss: 9.243482]\n",
      "epoch:48 step:38062 [D loss: 0.182461, acc: 97.66%] [G loss: 6.339869]\n",
      "epoch:48 step:38063 [D loss: 0.066021, acc: 99.22%] [G loss: 7.812110]\n",
      "epoch:48 step:38064 [D loss: 0.015354, acc: 100.00%] [G loss: 8.049635]\n",
      "epoch:48 step:38065 [D loss: 0.573114, acc: 64.06%] [G loss: 6.535398]\n",
      "epoch:48 step:38066 [D loss: 0.114172, acc: 99.22%] [G loss: 7.469692]\n",
      "epoch:48 step:38067 [D loss: 0.629403, acc: 62.50%] [G loss: 8.767534]\n",
      "epoch:48 step:38068 [D loss: 0.131951, acc: 100.00%] [G loss: 8.033450]\n",
      "epoch:48 step:38069 [D loss: 0.130320, acc: 99.22%] [G loss: 4.362999]\n",
      "epoch:48 step:38070 [D loss: 0.086013, acc: 99.22%] [G loss: 2.751412]\n",
      "epoch:48 step:38071 [D loss: 0.535716, acc: 62.50%] [G loss: 7.165611]\n",
      "epoch:48 step:38072 [D loss: 0.251833, acc: 97.66%] [G loss: 4.323887]\n",
      "epoch:48 step:38073 [D loss: 1.030344, acc: 35.94%] [G loss: 10.288294]\n",
      "epoch:48 step:38074 [D loss: 0.281511, acc: 93.75%] [G loss: 2.830689]\n",
      "epoch:48 step:38075 [D loss: 0.054625, acc: 100.00%] [G loss: 5.772737]\n",
      "epoch:48 step:38076 [D loss: 0.438636, acc: 73.44%] [G loss: 11.357882]\n",
      "epoch:48 step:38077 [D loss: 0.575220, acc: 64.06%] [G loss: 7.160378]\n",
      "epoch:48 step:38078 [D loss: 0.063732, acc: 100.00%] [G loss: 5.027962]\n",
      "epoch:48 step:38079 [D loss: 0.190616, acc: 97.66%] [G loss: 9.376205]\n",
      "epoch:48 step:38080 [D loss: 0.365084, acc: 90.62%] [G loss: 3.680934]\n",
      "epoch:48 step:38081 [D loss: 0.041610, acc: 100.00%] [G loss: 4.026783]\n",
      "epoch:48 step:38082 [D loss: 0.233223, acc: 92.19%] [G loss: 5.403038]\n",
      "epoch:48 step:38083 [D loss: 0.932816, acc: 50.00%] [G loss: 7.562601]\n",
      "epoch:48 step:38084 [D loss: 0.223837, acc: 92.19%] [G loss: 7.314452]\n",
      "epoch:48 step:38085 [D loss: 0.133924, acc: 99.22%] [G loss: 5.057677]\n",
      "epoch:48 step:38086 [D loss: 0.179643, acc: 95.31%] [G loss: 4.666822]\n",
      "epoch:48 step:38087 [D loss: 0.116284, acc: 98.44%] [G loss: 6.944680]\n",
      "epoch:48 step:38088 [D loss: 0.536510, acc: 75.78%] [G loss: 5.761885]\n",
      "epoch:48 step:38089 [D loss: 0.335647, acc: 83.59%] [G loss: 4.668796]\n",
      "epoch:48 step:38090 [D loss: 0.431557, acc: 68.75%] [G loss: 6.350715]\n",
      "epoch:48 step:38091 [D loss: 0.752246, acc: 53.12%] [G loss: 7.614441]\n",
      "epoch:48 step:38092 [D loss: 0.130503, acc: 97.66%] [G loss: 8.747435]\n",
      "epoch:48 step:38093 [D loss: 0.050478, acc: 100.00%] [G loss: 6.655192]\n",
      "epoch:48 step:38094 [D loss: 0.308237, acc: 84.38%] [G loss: 8.402413]\n",
      "epoch:48 step:38095 [D loss: 0.048451, acc: 100.00%] [G loss: 5.552730]\n",
      "epoch:48 step:38096 [D loss: 1.075631, acc: 26.56%] [G loss: 8.808580]\n",
      "epoch:48 step:38097 [D loss: 0.355895, acc: 88.28%] [G loss: 5.274315]\n",
      "epoch:48 step:38098 [D loss: 3.002143, acc: 0.78%] [G loss: 9.467480]\n",
      "epoch:48 step:38099 [D loss: 0.283866, acc: 87.50%] [G loss: 5.913091]\n",
      "epoch:48 step:38100 [D loss: 0.499893, acc: 75.78%] [G loss: 8.123414]\n",
      "epoch:48 step:38101 [D loss: 0.366381, acc: 90.62%] [G loss: 7.237881]\n",
      "epoch:48 step:38102 [D loss: 0.235832, acc: 96.88%] [G loss: 8.437002]\n",
      "epoch:48 step:38103 [D loss: 0.097973, acc: 100.00%] [G loss: 5.407530]\n",
      "epoch:48 step:38104 [D loss: 0.032217, acc: 100.00%] [G loss: 10.048691]\n",
      "epoch:48 step:38105 [D loss: 0.054263, acc: 100.00%] [G loss: 6.311283]\n",
      "epoch:48 step:38106 [D loss: 0.183148, acc: 96.09%] [G loss: 8.324952]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:38107 [D loss: 0.389840, acc: 83.59%] [G loss: 4.998134]\n",
      "epoch:48 step:38108 [D loss: 0.062138, acc: 100.00%] [G loss: 2.503476]\n",
      "epoch:48 step:38109 [D loss: 0.312455, acc: 84.38%] [G loss: 7.233808]\n",
      "epoch:48 step:38110 [D loss: 0.787834, acc: 53.12%] [G loss: 5.924776]\n",
      "epoch:48 step:38111 [D loss: 0.730043, acc: 57.03%] [G loss: 8.223245]\n",
      "epoch:48 step:38112 [D loss: 0.053630, acc: 100.00%] [G loss: 5.417625]\n",
      "epoch:48 step:38113 [D loss: 0.177962, acc: 100.00%] [G loss: 5.422010]\n",
      "epoch:48 step:38114 [D loss: 0.332412, acc: 86.72%] [G loss: 8.312634]\n",
      "epoch:48 step:38115 [D loss: 0.032354, acc: 100.00%] [G loss: 6.048568]\n",
      "epoch:48 step:38116 [D loss: 0.158774, acc: 97.66%] [G loss: 6.337437]\n",
      "epoch:48 step:38117 [D loss: 0.011767, acc: 100.00%] [G loss: 6.440455]\n",
      "epoch:48 step:38118 [D loss: 0.002462, acc: 100.00%] [G loss: 8.000606]\n",
      "epoch:48 step:38119 [D loss: 0.022353, acc: 100.00%] [G loss: 5.835237]\n",
      "epoch:48 step:38120 [D loss: 0.319813, acc: 89.06%] [G loss: 8.650205]\n",
      "epoch:48 step:38121 [D loss: 0.536752, acc: 69.53%] [G loss: 7.400100]\n",
      "epoch:48 step:38122 [D loss: 0.177811, acc: 97.66%] [G loss: 8.195727]\n",
      "epoch:48 step:38123 [D loss: 0.318210, acc: 87.50%] [G loss: 4.189723]\n",
      "epoch:48 step:38124 [D loss: 0.178245, acc: 97.66%] [G loss: 7.037781]\n",
      "epoch:48 step:38125 [D loss: 0.263276, acc: 92.97%] [G loss: 4.569100]\n",
      "epoch:48 step:38126 [D loss: 0.366412, acc: 86.72%] [G loss: 5.396109]\n",
      "epoch:48 step:38127 [D loss: 0.045107, acc: 100.00%] [G loss: 5.681406]\n",
      "epoch:48 step:38128 [D loss: 0.115349, acc: 100.00%] [G loss: 7.532601]\n",
      "epoch:48 step:38129 [D loss: 0.929105, acc: 37.50%] [G loss: 6.702159]\n",
      "epoch:48 step:38130 [D loss: 0.176373, acc: 96.09%] [G loss: 6.760787]\n",
      "epoch:48 step:38131 [D loss: 0.083132, acc: 99.22%] [G loss: 7.220721]\n",
      "epoch:48 step:38132 [D loss: 0.028507, acc: 100.00%] [G loss: 9.447678]\n",
      "epoch:48 step:38133 [D loss: 1.025442, acc: 22.66%] [G loss: 7.255595]\n",
      "epoch:48 step:38134 [D loss: 0.706544, acc: 55.47%] [G loss: 8.357391]\n",
      "epoch:48 step:38135 [D loss: 0.141225, acc: 96.88%] [G loss: 6.242886]\n",
      "epoch:48 step:38136 [D loss: 0.063305, acc: 100.00%] [G loss: 5.450243]\n",
      "epoch:48 step:38137 [D loss: 0.530594, acc: 61.72%] [G loss: 6.563882]\n",
      "epoch:48 step:38138 [D loss: 0.465179, acc: 74.22%] [G loss: 8.594452]\n",
      "epoch:48 step:38139 [D loss: 0.101254, acc: 99.22%] [G loss: 5.361186]\n",
      "epoch:48 step:38140 [D loss: 0.172952, acc: 98.44%] [G loss: 7.050527]\n",
      "epoch:48 step:38141 [D loss: 0.372842, acc: 85.94%] [G loss: 5.417147]\n",
      "epoch:48 step:38142 [D loss: 0.392506, acc: 85.16%] [G loss: 6.001971]\n",
      "epoch:48 step:38143 [D loss: 0.017914, acc: 100.00%] [G loss: 8.516226]\n",
      "epoch:48 step:38144 [D loss: 0.188137, acc: 95.31%] [G loss: 9.769209]\n",
      "epoch:48 step:38145 [D loss: 0.518101, acc: 72.66%] [G loss: 9.847967]\n",
      "epoch:48 step:38146 [D loss: 0.184484, acc: 97.66%] [G loss: 4.688009]\n",
      "epoch:48 step:38147 [D loss: 0.154141, acc: 99.22%] [G loss: 6.292854]\n",
      "epoch:48 step:38148 [D loss: 0.709890, acc: 57.03%] [G loss: 5.669408]\n",
      "epoch:48 step:38149 [D loss: 0.109740, acc: 100.00%] [G loss: 5.909523]\n",
      "epoch:48 step:38150 [D loss: 0.102968, acc: 100.00%] [G loss: 6.365615]\n",
      "epoch:48 step:38151 [D loss: 0.129442, acc: 99.22%] [G loss: 4.444934]\n",
      "epoch:48 step:38152 [D loss: 0.178620, acc: 96.88%] [G loss: 8.446639]\n",
      "epoch:48 step:38153 [D loss: 0.729831, acc: 53.91%] [G loss: 7.789629]\n",
      "epoch:48 step:38154 [D loss: 0.246685, acc: 96.88%] [G loss: 4.711318]\n",
      "epoch:48 step:38155 [D loss: 0.272772, acc: 89.84%] [G loss: 7.427494]\n",
      "epoch:48 step:38156 [D loss: 0.447996, acc: 77.34%] [G loss: 5.298197]\n",
      "epoch:48 step:38157 [D loss: 0.111043, acc: 100.00%] [G loss: 5.250532]\n",
      "epoch:48 step:38158 [D loss: 0.340446, acc: 82.81%] [G loss: 11.903900]\n",
      "epoch:48 step:38159 [D loss: 0.132946, acc: 100.00%] [G loss: 6.829353]\n",
      "epoch:48 step:38160 [D loss: 0.037109, acc: 100.00%] [G loss: 4.718120]\n",
      "epoch:48 step:38161 [D loss: 0.028664, acc: 100.00%] [G loss: 4.024078]\n",
      "epoch:48 step:38162 [D loss: 0.358076, acc: 84.38%] [G loss: 7.581935]\n",
      "epoch:48 step:38163 [D loss: 0.287453, acc: 93.75%] [G loss: 6.179993]\n",
      "epoch:48 step:38164 [D loss: 0.052156, acc: 100.00%] [G loss: 8.236548]\n",
      "epoch:48 step:38165 [D loss: 0.028697, acc: 100.00%] [G loss: 7.149453]\n",
      "epoch:48 step:38166 [D loss: 1.235904, acc: 19.53%] [G loss: 4.194656]\n",
      "epoch:48 step:38167 [D loss: 0.020827, acc: 100.00%] [G loss: 6.748143]\n",
      "epoch:48 step:38168 [D loss: 1.210442, acc: 50.00%] [G loss: 6.474173]\n",
      "epoch:48 step:38169 [D loss: 0.159589, acc: 98.44%] [G loss: 6.238273]\n",
      "epoch:48 step:38170 [D loss: 1.094141, acc: 50.78%] [G loss: 10.462999]\n",
      "epoch:48 step:38171 [D loss: 0.133654, acc: 99.22%] [G loss: 7.733335]\n",
      "epoch:48 step:38172 [D loss: 0.581250, acc: 66.41%] [G loss: 5.822218]\n",
      "epoch:48 step:38173 [D loss: 0.139822, acc: 98.44%] [G loss: 5.759590]\n",
      "epoch:48 step:38174 [D loss: 0.136156, acc: 99.22%] [G loss: 6.996922]\n",
      "epoch:48 step:38175 [D loss: 1.371446, acc: 46.09%] [G loss: 7.764252]\n",
      "epoch:48 step:38176 [D loss: 0.013162, acc: 100.00%] [G loss: 9.342447]\n",
      "epoch:48 step:38177 [D loss: 0.495417, acc: 68.75%] [G loss: 9.583637]\n",
      "epoch:48 step:38178 [D loss: 0.060217, acc: 100.00%] [G loss: 11.824409]\n",
      "epoch:48 step:38179 [D loss: 0.232287, acc: 90.62%] [G loss: 7.988560]\n",
      "epoch:48 step:38180 [D loss: 0.038199, acc: 100.00%] [G loss: 6.850181]\n",
      "epoch:48 step:38181 [D loss: 0.028915, acc: 99.22%] [G loss: 7.006495]\n",
      "epoch:48 step:38182 [D loss: 1.955812, acc: 50.00%] [G loss: 5.895972]\n",
      "epoch:48 step:38183 [D loss: 0.141360, acc: 98.44%] [G loss: 6.824914]\n",
      "epoch:48 step:38184 [D loss: 0.250398, acc: 89.84%] [G loss: 7.054000]\n",
      "epoch:48 step:38185 [D loss: 0.219635, acc: 96.88%] [G loss: 8.795979]\n",
      "epoch:48 step:38186 [D loss: 0.306411, acc: 96.88%] [G loss: 6.938546]\n",
      "epoch:48 step:38187 [D loss: 0.149912, acc: 99.22%] [G loss: 4.935535]\n",
      "epoch:48 step:38188 [D loss: 0.331802, acc: 86.72%] [G loss: 7.151238]\n",
      "epoch:48 step:38189 [D loss: 0.188339, acc: 96.88%] [G loss: 3.455053]\n",
      "epoch:48 step:38190 [D loss: 0.031493, acc: 100.00%] [G loss: 8.732908]\n",
      "epoch:48 step:38191 [D loss: 0.110457, acc: 99.22%] [G loss: 5.818711]\n",
      "epoch:48 step:38192 [D loss: 1.031625, acc: 51.56%] [G loss: 7.142097]\n",
      "epoch:48 step:38193 [D loss: 0.363109, acc: 78.91%] [G loss: 8.894096]\n",
      "epoch:48 step:38194 [D loss: 0.671447, acc: 61.72%] [G loss: 7.871116]\n",
      "epoch:48 step:38195 [D loss: 0.241671, acc: 91.41%] [G loss: 7.560567]\n",
      "epoch:48 step:38196 [D loss: 0.303980, acc: 93.75%] [G loss: 6.534380]\n",
      "epoch:48 step:38197 [D loss: 0.130095, acc: 99.22%] [G loss: 11.043606]\n",
      "epoch:48 step:38198 [D loss: 0.431761, acc: 77.34%] [G loss: 6.883714]\n",
      "epoch:48 step:38199 [D loss: 0.120559, acc: 99.22%] [G loss: 7.113453]\n",
      "epoch:48 step:38200 [D loss: 0.020056, acc: 100.00%] [G loss: 6.420966]\n",
      "epoch:48 step:38201 [D loss: 0.330120, acc: 92.19%] [G loss: 7.147860]\n",
      "epoch:48 step:38202 [D loss: 0.315682, acc: 91.41%] [G loss: 5.236452]\n",
      "epoch:48 step:38203 [D loss: 0.036410, acc: 100.00%] [G loss: 7.211304]\n",
      "epoch:48 step:38204 [D loss: 0.131243, acc: 100.00%] [G loss: 5.524083]\n",
      "epoch:48 step:38205 [D loss: 0.044371, acc: 100.00%] [G loss: 11.111343]\n",
      "epoch:48 step:38206 [D loss: 0.112184, acc: 99.22%] [G loss: 3.985509]\n",
      "epoch:48 step:38207 [D loss: 0.521641, acc: 74.22%] [G loss: 7.060365]\n",
      "epoch:48 step:38208 [D loss: 0.152349, acc: 99.22%] [G loss: 5.578741]\n",
      "epoch:48 step:38209 [D loss: 0.165030, acc: 96.09%] [G loss: 9.051991]\n",
      "epoch:48 step:38210 [D loss: 0.332293, acc: 90.62%] [G loss: 4.646114]\n",
      "epoch:48 step:38211 [D loss: 0.021520, acc: 100.00%] [G loss: 10.363235]\n",
      "epoch:48 step:38212 [D loss: 0.334367, acc: 92.19%] [G loss: 7.648930]\n",
      "epoch:48 step:38213 [D loss: 0.067008, acc: 100.00%] [G loss: 6.346877]\n",
      "epoch:48 step:38214 [D loss: 0.004767, acc: 100.00%] [G loss: 11.678875]\n",
      "epoch:48 step:38215 [D loss: 0.088677, acc: 100.00%] [G loss: 6.956722]\n",
      "epoch:48 step:38216 [D loss: 0.137169, acc: 98.44%] [G loss: 8.171965]\n",
      "epoch:48 step:38217 [D loss: 0.391542, acc: 87.50%] [G loss: 3.553586]\n",
      "epoch:48 step:38218 [D loss: 0.198290, acc: 96.09%] [G loss: 8.675020]\n",
      "epoch:48 step:38219 [D loss: 0.401136, acc: 75.00%] [G loss: 9.972911]\n",
      "epoch:48 step:38220 [D loss: 1.525235, acc: 49.22%] [G loss: 7.335782]\n",
      "epoch:48 step:38221 [D loss: 0.269050, acc: 89.06%] [G loss: 2.466116]\n",
      "epoch:48 step:38222 [D loss: 0.441973, acc: 81.25%] [G loss: 6.429162]\n",
      "epoch:48 step:38223 [D loss: 0.341689, acc: 76.56%] [G loss: 8.891109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:38224 [D loss: 0.619592, acc: 61.72%] [G loss: 4.876551]\n",
      "epoch:48 step:38225 [D loss: 0.047858, acc: 100.00%] [G loss: 4.627993]\n",
      "epoch:48 step:38226 [D loss: 0.356278, acc: 78.12%] [G loss: 7.598953]\n",
      "epoch:48 step:38227 [D loss: 1.001503, acc: 33.59%] [G loss: 9.048993]\n",
      "epoch:48 step:38228 [D loss: 0.767130, acc: 51.56%] [G loss: 6.704373]\n",
      "epoch:48 step:38229 [D loss: 0.009736, acc: 100.00%] [G loss: 8.126603]\n",
      "epoch:48 step:38230 [D loss: 0.403288, acc: 75.78%] [G loss: 6.807156]\n",
      "epoch:48 step:38231 [D loss: 0.355597, acc: 92.97%] [G loss: 5.290246]\n",
      "epoch:48 step:38232 [D loss: 0.237798, acc: 90.62%] [G loss: 4.930186]\n",
      "epoch:48 step:38233 [D loss: 0.122504, acc: 99.22%] [G loss: 2.157570]\n",
      "epoch:48 step:38234 [D loss: 0.040064, acc: 100.00%] [G loss: 3.318020]\n",
      "epoch:48 step:38235 [D loss: 0.199341, acc: 97.66%] [G loss: 4.848289]\n",
      "epoch:48 step:38236 [D loss: 0.429294, acc: 83.59%] [G loss: 6.194869]\n",
      "epoch:48 step:38237 [D loss: 0.344370, acc: 90.62%] [G loss: 6.649788]\n",
      "epoch:48 step:38238 [D loss: 0.101811, acc: 100.00%] [G loss: 5.912518]\n",
      "epoch:48 step:38239 [D loss: 0.719812, acc: 60.94%] [G loss: 6.743612]\n",
      "epoch:48 step:38240 [D loss: 0.082860, acc: 99.22%] [G loss: 7.084153]\n",
      "epoch:48 step:38241 [D loss: 0.266695, acc: 94.53%] [G loss: 5.462394]\n",
      "epoch:48 step:38242 [D loss: 0.371990, acc: 81.25%] [G loss: 7.187055]\n",
      "epoch:48 step:38243 [D loss: 0.075975, acc: 99.22%] [G loss: 6.831538]\n",
      "epoch:48 step:38244 [D loss: 0.035068, acc: 100.00%] [G loss: 7.520108]\n",
      "epoch:48 step:38245 [D loss: 0.485218, acc: 72.66%] [G loss: 2.981278]\n",
      "epoch:48 step:38246 [D loss: 0.571506, acc: 61.72%] [G loss: 4.741595]\n",
      "epoch:48 step:38247 [D loss: 0.228327, acc: 91.41%] [G loss: 6.417317]\n",
      "epoch:48 step:38248 [D loss: 0.014384, acc: 100.00%] [G loss: 13.597717]\n",
      "epoch:48 step:38249 [D loss: 0.398607, acc: 73.44%] [G loss: 9.442039]\n",
      "epoch:48 step:38250 [D loss: 0.257768, acc: 92.19%] [G loss: 6.641397]\n",
      "epoch:48 step:38251 [D loss: 0.032163, acc: 100.00%] [G loss: 6.226417]\n",
      "epoch:48 step:38252 [D loss: 0.270233, acc: 91.41%] [G loss: 7.901484]\n",
      "epoch:48 step:38253 [D loss: 0.041572, acc: 100.00%] [G loss: 4.686586]\n",
      "epoch:48 step:38254 [D loss: 0.420277, acc: 76.56%] [G loss: 8.496489]\n",
      "epoch:48 step:38255 [D loss: 0.304911, acc: 88.28%] [G loss: 5.999775]\n",
      "epoch:48 step:38256 [D loss: 0.105259, acc: 100.00%] [G loss: 6.002968]\n",
      "epoch:48 step:38257 [D loss: 0.560804, acc: 56.25%] [G loss: 7.470648]\n",
      "epoch:48 step:38258 [D loss: 0.043259, acc: 100.00%] [G loss: 8.016759]\n",
      "epoch:48 step:38259 [D loss: 0.105035, acc: 99.22%] [G loss: 4.441089]\n",
      "epoch:48 step:38260 [D loss: 0.355378, acc: 86.72%] [G loss: 9.164815]\n",
      "epoch:48 step:38261 [D loss: 0.116607, acc: 99.22%] [G loss: 8.250963]\n",
      "epoch:48 step:38262 [D loss: 0.010778, acc: 100.00%] [G loss: 10.013713]\n",
      "epoch:48 step:38263 [D loss: 0.374302, acc: 86.72%] [G loss: 8.459286]\n",
      "epoch:48 step:38264 [D loss: 0.442256, acc: 78.12%] [G loss: 8.229331]\n",
      "epoch:48 step:38265 [D loss: 1.807228, acc: 5.47%] [G loss: 10.114809]\n",
      "epoch:48 step:38266 [D loss: 0.081579, acc: 100.00%] [G loss: 6.963726]\n",
      "epoch:48 step:38267 [D loss: 0.148727, acc: 98.44%] [G loss: 5.140301]\n",
      "epoch:48 step:38268 [D loss: 0.148318, acc: 99.22%] [G loss: 6.081450]\n",
      "epoch:48 step:38269 [D loss: 0.371488, acc: 75.00%] [G loss: 6.652848]\n",
      "epoch:49 step:38270 [D loss: 0.027207, acc: 100.00%] [G loss: 10.714727]\n",
      "epoch:49 step:38271 [D loss: 0.223455, acc: 96.09%] [G loss: 8.102640]\n",
      "epoch:49 step:38272 [D loss: 0.840415, acc: 52.34%] [G loss: 5.610177]\n",
      "epoch:49 step:38273 [D loss: 0.038658, acc: 100.00%] [G loss: 3.467176]\n",
      "epoch:49 step:38274 [D loss: 0.322656, acc: 82.81%] [G loss: 7.400359]\n",
      "epoch:49 step:38275 [D loss: 0.508746, acc: 76.56%] [G loss: 6.399129]\n",
      "epoch:49 step:38276 [D loss: 0.197326, acc: 96.09%] [G loss: 5.184629]\n",
      "epoch:49 step:38277 [D loss: 0.152195, acc: 97.66%] [G loss: 7.727363]\n",
      "epoch:49 step:38278 [D loss: 0.558388, acc: 59.38%] [G loss: 5.585313]\n",
      "epoch:49 step:38279 [D loss: 0.561358, acc: 65.62%] [G loss: 4.909192]\n",
      "epoch:49 step:38280 [D loss: 0.338557, acc: 92.97%] [G loss: 4.634433]\n",
      "epoch:49 step:38281 [D loss: 0.020937, acc: 100.00%] [G loss: 6.780720]\n",
      "epoch:49 step:38282 [D loss: 0.142376, acc: 96.88%] [G loss: 3.616554]\n",
      "epoch:49 step:38283 [D loss: 0.102076, acc: 100.00%] [G loss: 6.284382]\n",
      "epoch:49 step:38284 [D loss: 0.228371, acc: 94.53%] [G loss: 4.764788]\n",
      "epoch:49 step:38285 [D loss: 1.003794, acc: 42.97%] [G loss: 6.791415]\n",
      "epoch:49 step:38286 [D loss: 0.148541, acc: 95.31%] [G loss: 7.554964]\n",
      "epoch:49 step:38287 [D loss: 0.074945, acc: 100.00%] [G loss: 5.839015]\n",
      "epoch:49 step:38288 [D loss: 0.833865, acc: 47.66%] [G loss: 8.629211]\n",
      "epoch:49 step:38289 [D loss: 0.047253, acc: 100.00%] [G loss: 6.532059]\n",
      "epoch:49 step:38290 [D loss: 0.042951, acc: 100.00%] [G loss: 7.235725]\n",
      "epoch:49 step:38291 [D loss: 0.028234, acc: 100.00%] [G loss: 5.249869]\n",
      "epoch:49 step:38292 [D loss: 0.103282, acc: 99.22%] [G loss: 7.445124]\n",
      "epoch:49 step:38293 [D loss: 0.377245, acc: 78.12%] [G loss: 6.580877]\n",
      "epoch:49 step:38294 [D loss: 0.132030, acc: 99.22%] [G loss: 5.973393]\n",
      "epoch:49 step:38295 [D loss: 0.021460, acc: 100.00%] [G loss: 4.281828]\n",
      "epoch:49 step:38296 [D loss: 0.855678, acc: 52.34%] [G loss: 8.460961]\n",
      "epoch:49 step:38297 [D loss: 1.215662, acc: 47.66%] [G loss: 5.994905]\n",
      "epoch:49 step:38298 [D loss: 0.049158, acc: 99.22%] [G loss: 5.712615]\n",
      "epoch:49 step:38299 [D loss: 0.604008, acc: 58.59%] [G loss: 8.053681]\n",
      "epoch:49 step:38300 [D loss: 0.194503, acc: 95.31%] [G loss: 6.241446]\n",
      "epoch:49 step:38301 [D loss: 0.959900, acc: 52.34%] [G loss: 10.520320]\n",
      "epoch:49 step:38302 [D loss: 1.266264, acc: 50.00%] [G loss: 3.798620]\n",
      "epoch:49 step:38303 [D loss: 0.278555, acc: 90.62%] [G loss: 7.727990]\n",
      "epoch:49 step:38304 [D loss: 0.905020, acc: 39.84%] [G loss: 8.409993]\n",
      "epoch:49 step:38305 [D loss: 0.078613, acc: 100.00%] [G loss: 7.529310]\n",
      "epoch:49 step:38306 [D loss: 0.190919, acc: 95.31%] [G loss: 4.777483]\n",
      "epoch:49 step:38307 [D loss: 0.459720, acc: 82.81%] [G loss: 7.752259]\n",
      "epoch:49 step:38308 [D loss: 0.171083, acc: 97.66%] [G loss: 4.157444]\n",
      "epoch:49 step:38309 [D loss: 0.205310, acc: 96.09%] [G loss: 5.813947]\n",
      "epoch:49 step:38310 [D loss: 0.085807, acc: 100.00%] [G loss: 4.861872]\n",
      "epoch:49 step:38311 [D loss: 0.161172, acc: 96.88%] [G loss: 5.046360]\n",
      "epoch:49 step:38312 [D loss: 0.252303, acc: 96.09%] [G loss: 5.288269]\n",
      "epoch:49 step:38313 [D loss: 0.017544, acc: 100.00%] [G loss: 5.949492]\n",
      "epoch:49 step:38314 [D loss: 0.489646, acc: 74.22%] [G loss: 2.095013]\n",
      "epoch:49 step:38315 [D loss: 0.274837, acc: 87.50%] [G loss: 6.942632]\n",
      "epoch:49 step:38316 [D loss: 0.998337, acc: 48.44%] [G loss: 4.790901]\n",
      "epoch:49 step:38317 [D loss: 0.375100, acc: 86.72%] [G loss: 5.304145]\n",
      "epoch:49 step:38318 [D loss: 0.203999, acc: 91.41%] [G loss: 7.525128]\n",
      "epoch:49 step:38319 [D loss: 0.108515, acc: 100.00%] [G loss: 5.452261]\n",
      "epoch:49 step:38320 [D loss: 0.144914, acc: 98.44%] [G loss: 8.077403]\n",
      "epoch:49 step:38321 [D loss: 0.197163, acc: 99.22%] [G loss: 4.821430]\n",
      "epoch:49 step:38322 [D loss: 0.027442, acc: 100.00%] [G loss: 9.666653]\n",
      "epoch:49 step:38323 [D loss: 0.983582, acc: 48.44%] [G loss: 4.608307]\n",
      "epoch:49 step:38324 [D loss: 0.018556, acc: 100.00%] [G loss: 5.536084]\n",
      "epoch:49 step:38325 [D loss: 0.057312, acc: 100.00%] [G loss: 6.330148]\n",
      "epoch:49 step:38326 [D loss: 0.026556, acc: 100.00%] [G loss: 8.057276]\n",
      "epoch:49 step:38327 [D loss: 0.407781, acc: 87.50%] [G loss: 7.466677]\n",
      "epoch:49 step:38328 [D loss: 0.421135, acc: 73.44%] [G loss: 10.157484]\n",
      "epoch:49 step:38329 [D loss: 0.577638, acc: 60.16%] [G loss: 5.548903]\n",
      "epoch:49 step:38330 [D loss: 0.085422, acc: 98.44%] [G loss: 9.354498]\n",
      "epoch:49 step:38331 [D loss: 0.060312, acc: 100.00%] [G loss: 7.041361]\n",
      "epoch:49 step:38332 [D loss: 0.128035, acc: 99.22%] [G loss: 4.885844]\n",
      "epoch:49 step:38333 [D loss: 0.665408, acc: 58.59%] [G loss: 8.372652]\n",
      "epoch:49 step:38334 [D loss: 0.614331, acc: 69.53%] [G loss: 9.156841]\n",
      "epoch:49 step:38335 [D loss: 0.597880, acc: 59.38%] [G loss: 6.496067]\n",
      "epoch:49 step:38336 [D loss: 0.269243, acc: 93.75%] [G loss: 4.937899]\n",
      "epoch:49 step:38337 [D loss: 0.223079, acc: 96.88%] [G loss: 6.066978]\n",
      "epoch:49 step:38338 [D loss: 0.207277, acc: 92.97%] [G loss: 4.627028]\n",
      "epoch:49 step:38339 [D loss: 0.478634, acc: 67.97%] [G loss: 5.972723]\n",
      "epoch:49 step:38340 [D loss: 0.482030, acc: 83.59%] [G loss: 6.789694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38341 [D loss: 0.187763, acc: 93.75%] [G loss: 10.175661]\n",
      "epoch:49 step:38342 [D loss: 1.271162, acc: 23.44%] [G loss: 12.992399]\n",
      "epoch:49 step:38343 [D loss: 0.137306, acc: 96.09%] [G loss: 7.782877]\n",
      "epoch:49 step:38344 [D loss: 0.438023, acc: 74.22%] [G loss: 6.149182]\n",
      "epoch:49 step:38345 [D loss: 0.090002, acc: 100.00%] [G loss: 4.513121]\n",
      "epoch:49 step:38346 [D loss: 0.330829, acc: 83.59%] [G loss: 7.404095]\n",
      "epoch:49 step:38347 [D loss: 0.292327, acc: 86.72%] [G loss: 4.883715]\n",
      "epoch:49 step:38348 [D loss: 0.166402, acc: 96.88%] [G loss: 10.766378]\n",
      "epoch:49 step:38349 [D loss: 0.066974, acc: 100.00%] [G loss: 7.972413]\n",
      "epoch:49 step:38350 [D loss: 0.222323, acc: 92.19%] [G loss: 6.823915]\n",
      "epoch:49 step:38351 [D loss: 0.018066, acc: 100.00%] [G loss: 7.961197]\n",
      "epoch:49 step:38352 [D loss: 0.089248, acc: 99.22%] [G loss: 6.144322]\n",
      "epoch:49 step:38353 [D loss: 1.000165, acc: 50.00%] [G loss: 6.116107]\n",
      "epoch:49 step:38354 [D loss: 0.252636, acc: 91.41%] [G loss: 9.253260]\n",
      "epoch:49 step:38355 [D loss: 0.099907, acc: 98.44%] [G loss: 7.486652]\n",
      "epoch:49 step:38356 [D loss: 0.366305, acc: 85.94%] [G loss: 4.949668]\n",
      "epoch:49 step:38357 [D loss: 0.219453, acc: 96.09%] [G loss: 8.143948]\n",
      "epoch:49 step:38358 [D loss: 0.404779, acc: 73.44%] [G loss: 6.243077]\n",
      "epoch:49 step:38359 [D loss: 0.100813, acc: 100.00%] [G loss: 3.822809]\n",
      "epoch:49 step:38360 [D loss: 0.088938, acc: 100.00%] [G loss: 4.614223]\n",
      "epoch:49 step:38361 [D loss: 0.460245, acc: 83.59%] [G loss: 5.827043]\n",
      "epoch:49 step:38362 [D loss: 0.021149, acc: 100.00%] [G loss: 4.891784]\n",
      "epoch:49 step:38363 [D loss: 0.197861, acc: 96.09%] [G loss: 6.799688]\n",
      "epoch:49 step:38364 [D loss: 0.308802, acc: 87.50%] [G loss: 5.146893]\n",
      "epoch:49 step:38365 [D loss: 0.988301, acc: 32.03%] [G loss: 5.105081]\n",
      "epoch:49 step:38366 [D loss: 0.136116, acc: 99.22%] [G loss: 3.808445]\n",
      "epoch:49 step:38367 [D loss: 0.517534, acc: 68.75%] [G loss: 9.006115]\n",
      "epoch:49 step:38368 [D loss: 0.334016, acc: 86.72%] [G loss: 6.001148]\n",
      "epoch:49 step:38369 [D loss: 0.170642, acc: 96.88%] [G loss: 5.909370]\n",
      "epoch:49 step:38370 [D loss: 0.210756, acc: 97.66%] [G loss: 7.883982]\n",
      "epoch:49 step:38371 [D loss: 0.219060, acc: 95.31%] [G loss: 5.381596]\n",
      "epoch:49 step:38372 [D loss: 0.077264, acc: 100.00%] [G loss: 6.414355]\n",
      "epoch:49 step:38373 [D loss: 0.085869, acc: 100.00%] [G loss: 6.180847]\n",
      "epoch:49 step:38374 [D loss: 1.449556, acc: 49.22%] [G loss: 8.008689]\n",
      "epoch:49 step:38375 [D loss: 0.429597, acc: 65.62%] [G loss: 5.016518]\n",
      "epoch:49 step:38376 [D loss: 0.279700, acc: 87.50%] [G loss: 6.330537]\n",
      "epoch:49 step:38377 [D loss: 0.243578, acc: 92.19%] [G loss: 7.571835]\n",
      "epoch:49 step:38378 [D loss: 0.476034, acc: 70.31%] [G loss: 3.210506]\n",
      "epoch:49 step:38379 [D loss: 0.579042, acc: 71.88%] [G loss: 11.020281]\n",
      "epoch:49 step:38380 [D loss: 0.044570, acc: 100.00%] [G loss: 4.777663]\n",
      "epoch:49 step:38381 [D loss: 0.438555, acc: 73.44%] [G loss: 8.420177]\n",
      "epoch:49 step:38382 [D loss: 0.186716, acc: 96.09%] [G loss: 8.154496]\n",
      "epoch:49 step:38383 [D loss: 0.165026, acc: 96.09%] [G loss: 7.178135]\n",
      "epoch:49 step:38384 [D loss: 0.118426, acc: 99.22%] [G loss: 5.816386]\n",
      "epoch:49 step:38385 [D loss: 0.053484, acc: 100.00%] [G loss: 6.007400]\n",
      "epoch:49 step:38386 [D loss: 0.081454, acc: 100.00%] [G loss: 7.648561]\n",
      "epoch:49 step:38387 [D loss: 0.307148, acc: 89.84%] [G loss: 6.167395]\n",
      "epoch:49 step:38388 [D loss: 0.099815, acc: 99.22%] [G loss: 5.055302]\n",
      "epoch:49 step:38389 [D loss: 0.149391, acc: 97.66%] [G loss: 3.349463]\n",
      "epoch:49 step:38390 [D loss: 0.163647, acc: 93.75%] [G loss: 6.798851]\n",
      "epoch:49 step:38391 [D loss: 0.147764, acc: 98.44%] [G loss: 9.941235]\n",
      "epoch:49 step:38392 [D loss: 0.107126, acc: 100.00%] [G loss: 7.111899]\n",
      "epoch:49 step:38393 [D loss: 0.068207, acc: 100.00%] [G loss: 5.510253]\n",
      "epoch:49 step:38394 [D loss: 0.423208, acc: 84.38%] [G loss: 6.698831]\n",
      "epoch:49 step:38395 [D loss: 0.179610, acc: 96.09%] [G loss: 6.432831]\n",
      "epoch:49 step:38396 [D loss: 0.229913, acc: 96.88%] [G loss: 8.107046]\n",
      "epoch:49 step:38397 [D loss: 0.156416, acc: 96.09%] [G loss: 10.210682]\n",
      "epoch:49 step:38398 [D loss: 0.541359, acc: 78.91%] [G loss: 6.123750]\n",
      "epoch:49 step:38399 [D loss: 0.499375, acc: 67.19%] [G loss: 7.869413]\n",
      "epoch:49 step:38400 [D loss: 1.310158, acc: 50.00%] [G loss: 9.984457]\n",
      "epoch:49 step:38401 [D loss: 0.497471, acc: 71.09%] [G loss: 6.746279]\n",
      "epoch:49 step:38402 [D loss: 0.169320, acc: 97.66%] [G loss: 5.138853]\n",
      "epoch:49 step:38403 [D loss: 1.434382, acc: 25.00%] [G loss: 7.669673]\n",
      "epoch:49 step:38404 [D loss: 0.438265, acc: 69.53%] [G loss: 5.638928]\n",
      "epoch:49 step:38405 [D loss: 0.278149, acc: 93.75%] [G loss: 9.623798]\n",
      "epoch:49 step:38406 [D loss: 0.470471, acc: 67.19%] [G loss: 5.336111]\n",
      "epoch:49 step:38407 [D loss: 0.163176, acc: 96.88%] [G loss: 8.524978]\n",
      "epoch:49 step:38408 [D loss: 1.701576, acc: 50.00%] [G loss: 8.301920]\n",
      "epoch:49 step:38409 [D loss: 0.329341, acc: 89.84%] [G loss: 6.503691]\n",
      "epoch:49 step:38410 [D loss: 0.204126, acc: 96.09%] [G loss: 8.291600]\n",
      "epoch:49 step:38411 [D loss: 0.435637, acc: 80.47%] [G loss: 5.360880]\n",
      "epoch:49 step:38412 [D loss: 0.103250, acc: 99.22%] [G loss: 6.203447]\n",
      "epoch:49 step:38413 [D loss: 1.161841, acc: 18.75%] [G loss: 7.594500]\n",
      "epoch:49 step:38414 [D loss: 0.039720, acc: 100.00%] [G loss: 5.401863]\n",
      "epoch:49 step:38415 [D loss: 0.954810, acc: 51.56%] [G loss: 7.043711]\n",
      "epoch:49 step:38416 [D loss: 0.489753, acc: 71.88%] [G loss: 9.510897]\n",
      "epoch:49 step:38417 [D loss: 0.198556, acc: 95.31%] [G loss: 7.758041]\n",
      "epoch:49 step:38418 [D loss: 0.102058, acc: 99.22%] [G loss: 7.814396]\n",
      "epoch:49 step:38419 [D loss: 0.232026, acc: 90.62%] [G loss: 7.553611]\n",
      "epoch:49 step:38420 [D loss: 0.602424, acc: 58.59%] [G loss: 7.351989]\n",
      "epoch:49 step:38421 [D loss: 0.240215, acc: 97.66%] [G loss: 5.246335]\n",
      "epoch:49 step:38422 [D loss: 0.322565, acc: 91.41%] [G loss: 4.000735]\n",
      "epoch:49 step:38423 [D loss: 0.180661, acc: 96.88%] [G loss: 3.929790]\n",
      "epoch:49 step:38424 [D loss: 0.117114, acc: 99.22%] [G loss: 5.766939]\n",
      "epoch:49 step:38425 [D loss: 0.142966, acc: 99.22%] [G loss: 5.481895]\n",
      "epoch:49 step:38426 [D loss: 0.114537, acc: 100.00%] [G loss: 5.181663]\n",
      "epoch:49 step:38427 [D loss: 0.492282, acc: 75.78%] [G loss: 9.437006]\n",
      "epoch:49 step:38428 [D loss: 0.022909, acc: 100.00%] [G loss: 4.500873]\n",
      "epoch:49 step:38429 [D loss: 0.718307, acc: 56.25%] [G loss: 5.849432]\n",
      "epoch:49 step:38430 [D loss: 0.060244, acc: 99.22%] [G loss: 4.696088]\n",
      "epoch:49 step:38431 [D loss: 0.840696, acc: 48.44%] [G loss: 9.286173]\n",
      "epoch:49 step:38432 [D loss: 0.256256, acc: 89.84%] [G loss: 4.666829]\n",
      "epoch:49 step:38433 [D loss: 0.476384, acc: 80.47%] [G loss: 4.923910]\n",
      "epoch:49 step:38434 [D loss: 0.274450, acc: 95.31%] [G loss: 3.693410]\n",
      "epoch:49 step:38435 [D loss: 0.293316, acc: 84.38%] [G loss: 8.941639]\n",
      "epoch:49 step:38436 [D loss: 0.181760, acc: 96.09%] [G loss: 10.748512]\n",
      "epoch:49 step:38437 [D loss: 0.036593, acc: 100.00%] [G loss: 4.953575]\n",
      "epoch:49 step:38438 [D loss: 0.250283, acc: 88.28%] [G loss: 6.151207]\n",
      "epoch:49 step:38439 [D loss: 1.134764, acc: 49.22%] [G loss: 8.247773]\n",
      "epoch:49 step:38440 [D loss: 0.478517, acc: 68.75%] [G loss: 5.097264]\n",
      "epoch:49 step:38441 [D loss: 0.637154, acc: 65.62%] [G loss: 6.634327]\n",
      "epoch:49 step:38442 [D loss: 0.369347, acc: 85.94%] [G loss: 6.269096]\n",
      "epoch:49 step:38443 [D loss: 0.300407, acc: 84.38%] [G loss: 5.445035]\n",
      "epoch:49 step:38444 [D loss: 0.068120, acc: 100.00%] [G loss: 7.632506]\n",
      "epoch:49 step:38445 [D loss: 0.032619, acc: 100.00%] [G loss: 7.148179]\n",
      "epoch:49 step:38446 [D loss: 0.702383, acc: 57.03%] [G loss: 8.799114]\n",
      "epoch:49 step:38447 [D loss: 0.184957, acc: 99.22%] [G loss: 9.544307]\n",
      "epoch:49 step:38448 [D loss: 0.926101, acc: 50.78%] [G loss: 3.780631]\n",
      "epoch:49 step:38449 [D loss: 0.101349, acc: 99.22%] [G loss: 9.885304]\n",
      "epoch:49 step:38450 [D loss: 0.362750, acc: 83.59%] [G loss: 6.141087]\n",
      "epoch:49 step:38451 [D loss: 0.183703, acc: 96.88%] [G loss: 8.274595]\n",
      "epoch:49 step:38452 [D loss: 0.040544, acc: 100.00%] [G loss: 6.169619]\n",
      "epoch:49 step:38453 [D loss: 0.822364, acc: 53.12%] [G loss: 3.485788]\n",
      "epoch:49 step:38454 [D loss: 0.119677, acc: 99.22%] [G loss: 5.471807]\n",
      "epoch:49 step:38455 [D loss: 0.317019, acc: 82.03%] [G loss: 10.377851]\n",
      "epoch:49 step:38456 [D loss: 0.355312, acc: 92.19%] [G loss: 6.157138]\n",
      "epoch:49 step:38457 [D loss: 0.098399, acc: 100.00%] [G loss: 5.911798]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38458 [D loss: 0.100804, acc: 99.22%] [G loss: 9.292719]\n",
      "epoch:49 step:38459 [D loss: 0.443951, acc: 70.31%] [G loss: 5.556016]\n",
      "epoch:49 step:38460 [D loss: 0.585296, acc: 60.94%] [G loss: 6.605375]\n",
      "epoch:49 step:38461 [D loss: 1.012489, acc: 42.19%] [G loss: 10.591772]\n",
      "epoch:49 step:38462 [D loss: 0.047420, acc: 100.00%] [G loss: 6.023610]\n",
      "epoch:49 step:38463 [D loss: 0.091384, acc: 99.22%] [G loss: 9.039526]\n",
      "epoch:49 step:38464 [D loss: 0.134678, acc: 98.44%] [G loss: 5.692238]\n",
      "epoch:49 step:38465 [D loss: 0.088057, acc: 100.00%] [G loss: 7.587319]\n",
      "epoch:49 step:38466 [D loss: 0.124751, acc: 100.00%] [G loss: 3.829248]\n",
      "epoch:49 step:38467 [D loss: 0.173235, acc: 96.09%] [G loss: 7.828172]\n",
      "epoch:49 step:38468 [D loss: 0.615631, acc: 60.16%] [G loss: 6.700033]\n",
      "epoch:49 step:38469 [D loss: 0.191406, acc: 98.44%] [G loss: 6.419146]\n",
      "epoch:49 step:38470 [D loss: 0.146745, acc: 96.09%] [G loss: 3.329422]\n",
      "epoch:49 step:38471 [D loss: 0.512202, acc: 74.22%] [G loss: 5.021872]\n",
      "epoch:49 step:38472 [D loss: 0.257487, acc: 91.41%] [G loss: 7.640659]\n",
      "epoch:49 step:38473 [D loss: 1.250556, acc: 45.31%] [G loss: 5.629261]\n",
      "epoch:49 step:38474 [D loss: 0.043275, acc: 100.00%] [G loss: 8.039904]\n",
      "epoch:49 step:38475 [D loss: 1.132898, acc: 21.88%] [G loss: 9.742649]\n",
      "epoch:49 step:38476 [D loss: 0.506798, acc: 68.75%] [G loss: 5.715282]\n",
      "epoch:49 step:38477 [D loss: 0.189893, acc: 92.19%] [G loss: 2.860467]\n",
      "epoch:49 step:38478 [D loss: 0.036024, acc: 99.22%] [G loss: 6.184008]\n",
      "epoch:49 step:38479 [D loss: 0.660500, acc: 57.03%] [G loss: 5.226364]\n",
      "epoch:49 step:38480 [D loss: 0.287077, acc: 85.16%] [G loss: 7.903955]\n",
      "epoch:49 step:38481 [D loss: 0.401351, acc: 82.81%] [G loss: 8.715387]\n",
      "epoch:49 step:38482 [D loss: 0.611211, acc: 58.59%] [G loss: 6.423320]\n",
      "epoch:49 step:38483 [D loss: 0.034235, acc: 100.00%] [G loss: 6.869598]\n",
      "epoch:49 step:38484 [D loss: 0.866914, acc: 51.56%] [G loss: 6.833027]\n",
      "epoch:49 step:38485 [D loss: 0.233909, acc: 97.66%] [G loss: 5.971444]\n",
      "epoch:49 step:38486 [D loss: 0.648788, acc: 59.38%] [G loss: 7.565632]\n",
      "epoch:49 step:38487 [D loss: 0.159888, acc: 96.88%] [G loss: 8.260595]\n",
      "epoch:49 step:38488 [D loss: 0.953722, acc: 53.12%] [G loss: 9.222240]\n",
      "epoch:49 step:38489 [D loss: 0.625151, acc: 57.81%] [G loss: 5.683977]\n",
      "epoch:49 step:38490 [D loss: 0.124623, acc: 99.22%] [G loss: 6.376042]\n",
      "epoch:49 step:38491 [D loss: 0.153983, acc: 96.88%] [G loss: 7.821320]\n",
      "epoch:49 step:38492 [D loss: 0.073875, acc: 99.22%] [G loss: 4.167504]\n",
      "epoch:49 step:38493 [D loss: 0.173838, acc: 97.66%] [G loss: 3.392799]\n",
      "epoch:49 step:38494 [D loss: 0.043557, acc: 100.00%] [G loss: 5.173072]\n",
      "epoch:49 step:38495 [D loss: 0.767174, acc: 50.78%] [G loss: 6.583967]\n",
      "epoch:49 step:38496 [D loss: 0.196451, acc: 99.22%] [G loss: 6.450737]\n",
      "epoch:49 step:38497 [D loss: 0.423282, acc: 70.31%] [G loss: 8.776783]\n",
      "epoch:49 step:38498 [D loss: 0.041464, acc: 100.00%] [G loss: 5.573913]\n",
      "epoch:49 step:38499 [D loss: 1.636781, acc: 50.00%] [G loss: 7.238987]\n",
      "epoch:49 step:38500 [D loss: 0.346853, acc: 82.03%] [G loss: 5.314948]\n",
      "epoch:49 step:38501 [D loss: 1.470488, acc: 50.00%] [G loss: 7.755208]\n",
      "epoch:49 step:38502 [D loss: 0.313333, acc: 83.59%] [G loss: 4.752203]\n",
      "epoch:49 step:38503 [D loss: 0.322944, acc: 87.50%] [G loss: 8.887320]\n",
      "epoch:49 step:38504 [D loss: 0.111001, acc: 99.22%] [G loss: 7.412709]\n",
      "epoch:49 step:38505 [D loss: 0.196091, acc: 95.31%] [G loss: 5.974788]\n",
      "epoch:49 step:38506 [D loss: 0.065047, acc: 100.00%] [G loss: 5.259322]\n",
      "epoch:49 step:38507 [D loss: 1.595767, acc: 13.28%] [G loss: 6.403956]\n",
      "epoch:49 step:38508 [D loss: 0.222983, acc: 94.53%] [G loss: 6.413193]\n",
      "epoch:49 step:38509 [D loss: 0.372571, acc: 88.28%] [G loss: 4.951209]\n",
      "epoch:49 step:38510 [D loss: 0.043510, acc: 99.22%] [G loss: 8.732689]\n",
      "epoch:49 step:38511 [D loss: 0.059971, acc: 100.00%] [G loss: 5.357901]\n",
      "epoch:49 step:38512 [D loss: 0.114855, acc: 99.22%] [G loss: 7.854554]\n",
      "epoch:49 step:38513 [D loss: 0.411518, acc: 76.56%] [G loss: 8.546133]\n",
      "epoch:49 step:38514 [D loss: 0.053721, acc: 100.00%] [G loss: 8.815237]\n",
      "epoch:49 step:38515 [D loss: 0.642947, acc: 60.16%] [G loss: 9.135092]\n",
      "epoch:49 step:38516 [D loss: 0.546495, acc: 74.22%] [G loss: 7.772104]\n",
      "epoch:49 step:38517 [D loss: 0.333958, acc: 90.62%] [G loss: 4.414309]\n",
      "epoch:49 step:38518 [D loss: 0.250142, acc: 90.62%] [G loss: 6.497079]\n",
      "epoch:49 step:38519 [D loss: 0.545125, acc: 68.75%] [G loss: 8.647903]\n",
      "epoch:49 step:38520 [D loss: 0.474250, acc: 70.31%] [G loss: 4.534760]\n",
      "epoch:49 step:38521 [D loss: 0.334941, acc: 79.69%] [G loss: 7.457021]\n",
      "epoch:49 step:38522 [D loss: 0.332835, acc: 82.81%] [G loss: 6.349441]\n",
      "epoch:49 step:38523 [D loss: 0.174294, acc: 97.66%] [G loss: 4.017729]\n",
      "epoch:49 step:38524 [D loss: 0.817941, acc: 52.34%] [G loss: 9.406907]\n",
      "epoch:49 step:38525 [D loss: 0.060596, acc: 100.00%] [G loss: 5.414094]\n",
      "epoch:49 step:38526 [D loss: 1.013960, acc: 50.00%] [G loss: 5.679822]\n",
      "epoch:49 step:38527 [D loss: 0.033979, acc: 100.00%] [G loss: 7.364291]\n",
      "epoch:49 step:38528 [D loss: 0.525053, acc: 63.28%] [G loss: 6.175395]\n",
      "epoch:49 step:38529 [D loss: 0.063650, acc: 99.22%] [G loss: 10.363975]\n",
      "epoch:49 step:38530 [D loss: 0.377163, acc: 77.34%] [G loss: 3.845971]\n",
      "epoch:49 step:38531 [D loss: 0.120920, acc: 100.00%] [G loss: 5.623649]\n",
      "epoch:49 step:38532 [D loss: 0.078443, acc: 100.00%] [G loss: 6.811679]\n",
      "epoch:49 step:38533 [D loss: 0.025165, acc: 100.00%] [G loss: 8.443130]\n",
      "epoch:49 step:38534 [D loss: 0.108496, acc: 100.00%] [G loss: 7.623986]\n",
      "epoch:49 step:38535 [D loss: 1.146680, acc: 50.00%] [G loss: 10.511527]\n",
      "epoch:49 step:38536 [D loss: 0.515950, acc: 66.41%] [G loss: 6.650635]\n",
      "epoch:49 step:38537 [D loss: 0.362151, acc: 79.69%] [G loss: 3.746943]\n",
      "epoch:49 step:38538 [D loss: 0.544805, acc: 62.50%] [G loss: 8.860615]\n",
      "epoch:49 step:38539 [D loss: 0.050432, acc: 99.22%] [G loss: 5.836558]\n",
      "epoch:49 step:38540 [D loss: 0.029034, acc: 100.00%] [G loss: 8.549928]\n",
      "epoch:49 step:38541 [D loss: 0.396999, acc: 86.72%] [G loss: 4.616203]\n",
      "epoch:49 step:38542 [D loss: 0.458834, acc: 71.88%] [G loss: 4.441034]\n",
      "epoch:49 step:38543 [D loss: 0.524097, acc: 67.19%] [G loss: 5.018085]\n",
      "epoch:49 step:38544 [D loss: 0.202104, acc: 96.88%] [G loss: 7.431228]\n",
      "epoch:49 step:38545 [D loss: 0.273532, acc: 89.84%] [G loss: 7.751421]\n",
      "epoch:49 step:38546 [D loss: 0.580700, acc: 62.50%] [G loss: 6.140833]\n",
      "epoch:49 step:38547 [D loss: 0.024332, acc: 100.00%] [G loss: 3.031595]\n",
      "epoch:49 step:38548 [D loss: 0.389034, acc: 81.25%] [G loss: 10.686289]\n",
      "epoch:49 step:38549 [D loss: 0.022915, acc: 100.00%] [G loss: 10.199415]\n",
      "epoch:49 step:38550 [D loss: 0.110723, acc: 99.22%] [G loss: 3.491964]\n",
      "epoch:49 step:38551 [D loss: 0.284209, acc: 91.41%] [G loss: 5.301433]\n",
      "epoch:49 step:38552 [D loss: 0.149247, acc: 100.00%] [G loss: 2.935842]\n",
      "epoch:49 step:38553 [D loss: 0.195033, acc: 96.09%] [G loss: 5.752800]\n",
      "epoch:49 step:38554 [D loss: 1.495959, acc: 10.94%] [G loss: 10.842703]\n",
      "epoch:49 step:38555 [D loss: 0.489523, acc: 70.31%] [G loss: 8.175342]\n",
      "epoch:49 step:38556 [D loss: 0.694475, acc: 59.38%] [G loss: 8.077846]\n",
      "epoch:49 step:38557 [D loss: 0.710050, acc: 59.38%] [G loss: 7.541123]\n",
      "epoch:49 step:38558 [D loss: 0.050262, acc: 99.22%] [G loss: 7.335238]\n",
      "epoch:49 step:38559 [D loss: 0.231800, acc: 95.31%] [G loss: 6.514415]\n",
      "epoch:49 step:38560 [D loss: 0.466491, acc: 79.69%] [G loss: 3.359981]\n",
      "epoch:49 step:38561 [D loss: 0.038229, acc: 100.00%] [G loss: 3.299592]\n",
      "epoch:49 step:38562 [D loss: 0.329712, acc: 90.62%] [G loss: 5.995528]\n",
      "epoch:49 step:38563 [D loss: 0.836439, acc: 54.69%] [G loss: 6.708555]\n",
      "epoch:49 step:38564 [D loss: 0.154059, acc: 98.44%] [G loss: 6.615775]\n",
      "epoch:49 step:38565 [D loss: 0.059921, acc: 100.00%] [G loss: 7.813500]\n",
      "epoch:49 step:38566 [D loss: 0.191781, acc: 92.97%] [G loss: 8.115889]\n",
      "epoch:49 step:38567 [D loss: 0.199846, acc: 98.44%] [G loss: 6.831583]\n",
      "epoch:49 step:38568 [D loss: 0.060006, acc: 99.22%] [G loss: 4.476132]\n",
      "epoch:49 step:38569 [D loss: 0.190738, acc: 96.09%] [G loss: 6.589119]\n",
      "epoch:49 step:38570 [D loss: 0.147732, acc: 99.22%] [G loss: 6.975282]\n",
      "epoch:49 step:38571 [D loss: 0.400187, acc: 86.72%] [G loss: 7.295154]\n",
      "epoch:49 step:38572 [D loss: 0.216723, acc: 96.88%] [G loss: 5.837133]\n",
      "epoch:49 step:38573 [D loss: 0.902521, acc: 51.56%] [G loss: 4.631831]\n",
      "epoch:49 step:38574 [D loss: 2.016365, acc: 50.00%] [G loss: 7.527028]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38575 [D loss: 0.025884, acc: 100.00%] [G loss: 5.194890]\n",
      "epoch:49 step:38576 [D loss: 0.191215, acc: 91.41%] [G loss: 9.608160]\n",
      "epoch:49 step:38577 [D loss: 0.239392, acc: 95.31%] [G loss: 6.318770]\n",
      "epoch:49 step:38578 [D loss: 0.657505, acc: 59.38%] [G loss: 7.425192]\n",
      "epoch:49 step:38579 [D loss: 0.577597, acc: 59.38%] [G loss: 7.012256]\n",
      "epoch:49 step:38580 [D loss: 0.133444, acc: 98.44%] [G loss: 2.119492]\n",
      "epoch:49 step:38581 [D loss: 0.074942, acc: 99.22%] [G loss: 6.730690]\n",
      "epoch:49 step:38582 [D loss: 0.230523, acc: 97.66%] [G loss: 5.256300]\n",
      "epoch:49 step:38583 [D loss: 0.049135, acc: 100.00%] [G loss: 9.436772]\n",
      "epoch:49 step:38584 [D loss: 0.026430, acc: 100.00%] [G loss: 10.490608]\n",
      "epoch:49 step:38585 [D loss: 0.066667, acc: 100.00%] [G loss: 6.424169]\n",
      "epoch:49 step:38586 [D loss: 0.017244, acc: 100.00%] [G loss: 5.904021]\n",
      "epoch:49 step:38587 [D loss: 0.136035, acc: 96.88%] [G loss: 5.236854]\n",
      "epoch:49 step:38588 [D loss: 0.093387, acc: 99.22%] [G loss: 4.354608]\n",
      "epoch:49 step:38589 [D loss: 0.439619, acc: 75.78%] [G loss: 8.560122]\n",
      "epoch:49 step:38590 [D loss: 0.112206, acc: 99.22%] [G loss: 3.913836]\n",
      "epoch:49 step:38591 [D loss: 0.465297, acc: 71.09%] [G loss: 3.396790]\n",
      "epoch:49 step:38592 [D loss: 0.104426, acc: 100.00%] [G loss: 8.090475]\n",
      "epoch:49 step:38593 [D loss: 0.088297, acc: 100.00%] [G loss: 5.790261]\n",
      "epoch:49 step:38594 [D loss: 0.104254, acc: 99.22%] [G loss: 8.049829]\n",
      "epoch:49 step:38595 [D loss: 0.464357, acc: 77.34%] [G loss: 5.562944]\n",
      "epoch:49 step:38596 [D loss: 0.553367, acc: 68.75%] [G loss: 6.313516]\n",
      "epoch:49 step:38597 [D loss: 0.963305, acc: 52.34%] [G loss: 7.018641]\n",
      "epoch:49 step:38598 [D loss: 0.019514, acc: 100.00%] [G loss: 8.765114]\n",
      "epoch:49 step:38599 [D loss: 0.650052, acc: 58.59%] [G loss: 6.051908]\n",
      "epoch:49 step:38600 [D loss: 0.292123, acc: 87.50%] [G loss: 6.012988]\n",
      "epoch:49 step:38601 [D loss: 0.612493, acc: 59.38%] [G loss: 5.574988]\n",
      "epoch:49 step:38602 [D loss: 0.075392, acc: 100.00%] [G loss: 9.357043]\n",
      "epoch:49 step:38603 [D loss: 0.244819, acc: 93.75%] [G loss: 5.179613]\n",
      "epoch:49 step:38604 [D loss: 0.031078, acc: 100.00%] [G loss: 5.734578]\n",
      "epoch:49 step:38605 [D loss: 0.149952, acc: 96.88%] [G loss: 8.022435]\n",
      "epoch:49 step:38606 [D loss: 0.176174, acc: 95.31%] [G loss: 7.818966]\n",
      "epoch:49 step:38607 [D loss: 0.061699, acc: 100.00%] [G loss: 4.867214]\n",
      "epoch:49 step:38608 [D loss: 0.164330, acc: 96.09%] [G loss: 6.487611]\n",
      "epoch:49 step:38609 [D loss: 0.019540, acc: 100.00%] [G loss: 7.540262]\n",
      "epoch:49 step:38610 [D loss: 0.777331, acc: 53.91%] [G loss: 5.891277]\n",
      "epoch:49 step:38611 [D loss: 0.115937, acc: 98.44%] [G loss: 8.462198]\n",
      "epoch:49 step:38612 [D loss: 0.751489, acc: 56.25%] [G loss: 6.845424]\n",
      "epoch:49 step:38613 [D loss: 0.334519, acc: 78.12%] [G loss: 6.279911]\n",
      "epoch:49 step:38614 [D loss: 0.066062, acc: 100.00%] [G loss: 4.717108]\n",
      "epoch:49 step:38615 [D loss: 0.378290, acc: 82.81%] [G loss: 3.943867]\n",
      "epoch:49 step:38616 [D loss: 0.063752, acc: 100.00%] [G loss: 6.613712]\n",
      "epoch:49 step:38617 [D loss: 0.319037, acc: 92.97%] [G loss: 6.486704]\n",
      "epoch:49 step:38618 [D loss: 0.201938, acc: 98.44%] [G loss: 3.330213]\n",
      "epoch:49 step:38619 [D loss: 0.146791, acc: 98.44%] [G loss: 6.600801]\n",
      "epoch:49 step:38620 [D loss: 0.471378, acc: 69.53%] [G loss: 3.687703]\n",
      "epoch:49 step:38621 [D loss: 0.125273, acc: 98.44%] [G loss: 5.459503]\n",
      "epoch:49 step:38622 [D loss: 0.431645, acc: 70.31%] [G loss: 6.978191]\n",
      "epoch:49 step:38623 [D loss: 0.116317, acc: 100.00%] [G loss: 3.704706]\n",
      "epoch:49 step:38624 [D loss: 0.528069, acc: 64.06%] [G loss: 5.155121]\n",
      "epoch:49 step:38625 [D loss: 0.065139, acc: 100.00%] [G loss: 6.966178]\n",
      "epoch:49 step:38626 [D loss: 0.420594, acc: 71.88%] [G loss: 8.504126]\n",
      "epoch:49 step:38627 [D loss: 0.035382, acc: 99.22%] [G loss: 5.365012]\n",
      "epoch:49 step:38628 [D loss: 0.441534, acc: 71.09%] [G loss: 6.567882]\n",
      "epoch:49 step:38629 [D loss: 0.455097, acc: 66.41%] [G loss: 9.064161]\n",
      "epoch:49 step:38630 [D loss: 0.167289, acc: 98.44%] [G loss: 4.458506]\n",
      "epoch:49 step:38631 [D loss: 0.123521, acc: 99.22%] [G loss: 4.901722]\n",
      "epoch:49 step:38632 [D loss: 0.133806, acc: 99.22%] [G loss: 7.380762]\n",
      "epoch:49 step:38633 [D loss: 0.064928, acc: 100.00%] [G loss: 3.267144]\n",
      "epoch:49 step:38634 [D loss: 0.333585, acc: 80.47%] [G loss: 6.159668]\n",
      "epoch:49 step:38635 [D loss: 0.080016, acc: 99.22%] [G loss: 5.513552]\n",
      "epoch:49 step:38636 [D loss: 0.251287, acc: 92.19%] [G loss: 6.983664]\n",
      "epoch:49 step:38637 [D loss: 0.054105, acc: 100.00%] [G loss: 4.233689]\n",
      "epoch:49 step:38638 [D loss: 0.530620, acc: 64.06%] [G loss: 4.142683]\n",
      "epoch:49 step:38639 [D loss: 0.431359, acc: 84.38%] [G loss: 6.813540]\n",
      "epoch:49 step:38640 [D loss: 0.568875, acc: 71.88%] [G loss: 4.659777]\n",
      "epoch:49 step:38641 [D loss: 0.670737, acc: 57.03%] [G loss: 6.465764]\n",
      "epoch:49 step:38642 [D loss: 0.661167, acc: 60.16%] [G loss: 6.103366]\n",
      "epoch:49 step:38643 [D loss: 0.196002, acc: 96.88%] [G loss: 9.727064]\n",
      "epoch:49 step:38644 [D loss: 0.105789, acc: 100.00%] [G loss: 6.158005]\n",
      "epoch:49 step:38645 [D loss: 0.185589, acc: 95.31%] [G loss: 5.789829]\n",
      "epoch:49 step:38646 [D loss: 0.036092, acc: 100.00%] [G loss: 7.165322]\n",
      "epoch:49 step:38647 [D loss: 0.136347, acc: 99.22%] [G loss: 8.782295]\n",
      "epoch:49 step:38648 [D loss: 0.224312, acc: 92.19%] [G loss: 8.633763]\n",
      "epoch:49 step:38649 [D loss: 0.007054, acc: 100.00%] [G loss: 7.975955]\n",
      "epoch:49 step:38650 [D loss: 0.290911, acc: 94.53%] [G loss: 5.003666]\n",
      "epoch:49 step:38651 [D loss: 0.183546, acc: 94.53%] [G loss: 5.987586]\n",
      "epoch:49 step:38652 [D loss: 0.310334, acc: 94.53%] [G loss: 3.041072]\n",
      "epoch:49 step:38653 [D loss: 0.182782, acc: 99.22%] [G loss: 6.448129]\n",
      "epoch:49 step:38654 [D loss: 0.210962, acc: 96.88%] [G loss: 8.755167]\n",
      "epoch:49 step:38655 [D loss: 0.031540, acc: 100.00%] [G loss: 6.550622]\n",
      "epoch:49 step:38656 [D loss: 0.041957, acc: 100.00%] [G loss: 4.871301]\n",
      "epoch:49 step:38657 [D loss: 0.237144, acc: 96.88%] [G loss: 3.331891]\n",
      "epoch:49 step:38658 [D loss: 0.444313, acc: 85.16%] [G loss: 4.230197]\n",
      "epoch:49 step:38659 [D loss: 0.016174, acc: 100.00%] [G loss: 9.146645]\n",
      "epoch:49 step:38660 [D loss: 0.110362, acc: 99.22%] [G loss: 5.090464]\n",
      "epoch:49 step:38661 [D loss: 0.044963, acc: 100.00%] [G loss: 4.422567]\n",
      "epoch:49 step:38662 [D loss: 0.023862, acc: 100.00%] [G loss: 6.765739]\n",
      "epoch:49 step:38663 [D loss: 0.352039, acc: 77.34%] [G loss: 7.662152]\n",
      "epoch:49 step:38664 [D loss: 0.498505, acc: 79.69%] [G loss: 6.143723]\n",
      "epoch:49 step:38665 [D loss: 0.343528, acc: 93.75%] [G loss: 5.875118]\n",
      "epoch:49 step:38666 [D loss: 0.044686, acc: 100.00%] [G loss: 5.211969]\n",
      "epoch:49 step:38667 [D loss: 0.019467, acc: 100.00%] [G loss: 12.316443]\n",
      "epoch:49 step:38668 [D loss: 0.197587, acc: 93.75%] [G loss: 6.754772]\n",
      "epoch:49 step:38669 [D loss: 0.044441, acc: 99.22%] [G loss: 8.166418]\n",
      "epoch:49 step:38670 [D loss: 0.153508, acc: 97.66%] [G loss: 9.498125]\n",
      "epoch:49 step:38671 [D loss: 0.133936, acc: 99.22%] [G loss: 5.132312]\n",
      "epoch:49 step:38672 [D loss: 0.067657, acc: 99.22%] [G loss: 3.322810]\n",
      "epoch:49 step:38673 [D loss: 0.188419, acc: 98.44%] [G loss: 5.720800]\n",
      "epoch:49 step:38674 [D loss: 0.905129, acc: 50.78%] [G loss: 7.230283]\n",
      "epoch:49 step:38675 [D loss: 0.193877, acc: 98.44%] [G loss: 1.897488]\n",
      "epoch:49 step:38676 [D loss: 0.022774, acc: 100.00%] [G loss: 5.477818]\n",
      "epoch:49 step:38677 [D loss: 0.647881, acc: 63.28%] [G loss: 9.047687]\n",
      "epoch:49 step:38678 [D loss: 0.081804, acc: 99.22%] [G loss: 4.514537]\n",
      "epoch:49 step:38679 [D loss: 0.252887, acc: 91.41%] [G loss: 4.706993]\n",
      "epoch:49 step:38680 [D loss: 0.169485, acc: 96.09%] [G loss: 4.740846]\n",
      "epoch:49 step:38681 [D loss: 0.087326, acc: 100.00%] [G loss: 4.696218]\n",
      "epoch:49 step:38682 [D loss: 0.037797, acc: 100.00%] [G loss: 7.364973]\n",
      "epoch:49 step:38683 [D loss: 0.227374, acc: 92.19%] [G loss: 8.313379]\n",
      "epoch:49 step:38684 [D loss: 0.120728, acc: 100.00%] [G loss: 8.081818]\n",
      "epoch:49 step:38685 [D loss: 0.321352, acc: 84.38%] [G loss: 5.017480]\n",
      "epoch:49 step:38686 [D loss: 0.779386, acc: 54.69%] [G loss: 4.971001]\n",
      "epoch:49 step:38687 [D loss: 0.184497, acc: 96.09%] [G loss: 6.371943]\n",
      "epoch:49 step:38688 [D loss: 0.210025, acc: 98.44%] [G loss: 7.940017]\n",
      "epoch:49 step:38689 [D loss: 0.273453, acc: 89.06%] [G loss: 6.862096]\n",
      "epoch:49 step:38690 [D loss: 0.269802, acc: 90.62%] [G loss: 6.111425]\n",
      "epoch:49 step:38691 [D loss: 0.033679, acc: 100.00%] [G loss: 7.961530]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38692 [D loss: 0.343118, acc: 78.91%] [G loss: 7.580604]\n",
      "epoch:49 step:38693 [D loss: 0.252813, acc: 95.31%] [G loss: 6.377961]\n",
      "epoch:49 step:38694 [D loss: 0.483327, acc: 65.62%] [G loss: 5.415696]\n",
      "epoch:49 step:38695 [D loss: 0.145349, acc: 99.22%] [G loss: 7.394864]\n",
      "epoch:49 step:38696 [D loss: 0.369601, acc: 80.47%] [G loss: 7.502138]\n",
      "epoch:49 step:38697 [D loss: 0.223315, acc: 99.22%] [G loss: 5.546886]\n",
      "epoch:49 step:38698 [D loss: 0.046620, acc: 100.00%] [G loss: 8.641668]\n",
      "epoch:49 step:38699 [D loss: 0.125207, acc: 97.66%] [G loss: 7.010818]\n",
      "epoch:49 step:38700 [D loss: 0.199984, acc: 95.31%] [G loss: 6.430087]\n",
      "epoch:49 step:38701 [D loss: 0.204497, acc: 96.88%] [G loss: 3.743399]\n",
      "epoch:49 step:38702 [D loss: 0.048427, acc: 100.00%] [G loss: 6.744344]\n",
      "epoch:49 step:38703 [D loss: 0.128434, acc: 99.22%] [G loss: 12.118643]\n",
      "epoch:49 step:38704 [D loss: 0.032855, acc: 100.00%] [G loss: 8.645916]\n",
      "epoch:49 step:38705 [D loss: 0.135494, acc: 97.66%] [G loss: 6.320517]\n",
      "epoch:49 step:38706 [D loss: 0.102953, acc: 99.22%] [G loss: 2.777672]\n",
      "epoch:49 step:38707 [D loss: 1.869579, acc: 50.00%] [G loss: 7.192297]\n",
      "epoch:49 step:38708 [D loss: 0.130500, acc: 99.22%] [G loss: 3.983101]\n",
      "epoch:49 step:38709 [D loss: 0.534187, acc: 69.53%] [G loss: 7.634497]\n",
      "epoch:49 step:38710 [D loss: 1.084033, acc: 36.72%] [G loss: 6.283807]\n",
      "epoch:49 step:38711 [D loss: 0.626657, acc: 61.72%] [G loss: 7.496381]\n",
      "epoch:49 step:38712 [D loss: 0.196156, acc: 94.53%] [G loss: 4.055810]\n",
      "epoch:49 step:38713 [D loss: 0.202355, acc: 94.53%] [G loss: 6.298906]\n",
      "epoch:49 step:38714 [D loss: 0.139464, acc: 100.00%] [G loss: 6.733464]\n",
      "epoch:49 step:38715 [D loss: 0.239234, acc: 92.19%] [G loss: 9.084698]\n",
      "epoch:49 step:38716 [D loss: 0.328755, acc: 85.16%] [G loss: 6.336265]\n",
      "epoch:49 step:38717 [D loss: 0.042301, acc: 100.00%] [G loss: 8.197105]\n",
      "epoch:49 step:38718 [D loss: 0.152162, acc: 98.44%] [G loss: 3.473524]\n",
      "epoch:49 step:38719 [D loss: 0.112618, acc: 100.00%] [G loss: 6.641973]\n",
      "epoch:49 step:38720 [D loss: 0.154573, acc: 95.31%] [G loss: 10.709406]\n",
      "epoch:49 step:38721 [D loss: 0.055503, acc: 100.00%] [G loss: 5.963990]\n",
      "epoch:49 step:38722 [D loss: 0.086638, acc: 98.44%] [G loss: 5.425118]\n",
      "epoch:49 step:38723 [D loss: 0.294802, acc: 90.62%] [G loss: 5.486586]\n",
      "epoch:49 step:38724 [D loss: 0.368722, acc: 78.12%] [G loss: 6.474321]\n",
      "epoch:49 step:38725 [D loss: 0.024005, acc: 100.00%] [G loss: 6.968577]\n",
      "epoch:49 step:38726 [D loss: 0.018493, acc: 100.00%] [G loss: 5.139299]\n",
      "epoch:49 step:38727 [D loss: 0.778588, acc: 51.56%] [G loss: 8.782029]\n",
      "epoch:49 step:38728 [D loss: 0.035913, acc: 100.00%] [G loss: 5.894506]\n",
      "epoch:49 step:38729 [D loss: 0.088208, acc: 99.22%] [G loss: 8.978387]\n",
      "epoch:49 step:38730 [D loss: 0.015627, acc: 100.00%] [G loss: 7.448667]\n",
      "epoch:49 step:38731 [D loss: 0.360543, acc: 76.56%] [G loss: 5.254241]\n",
      "epoch:49 step:38732 [D loss: 0.360811, acc: 78.12%] [G loss: 8.373149]\n",
      "epoch:49 step:38733 [D loss: 0.375146, acc: 77.34%] [G loss: 4.387937]\n",
      "epoch:49 step:38734 [D loss: 0.117981, acc: 100.00%] [G loss: 4.788663]\n",
      "epoch:49 step:38735 [D loss: 0.046279, acc: 99.22%] [G loss: 9.358595]\n",
      "epoch:49 step:38736 [D loss: 0.486148, acc: 78.12%] [G loss: 7.249989]\n",
      "epoch:49 step:38737 [D loss: 0.288133, acc: 89.84%] [G loss: 5.871922]\n",
      "epoch:49 step:38738 [D loss: 0.662090, acc: 60.16%] [G loss: 5.542332]\n",
      "epoch:49 step:38739 [D loss: 0.077035, acc: 100.00%] [G loss: 12.185904]\n",
      "epoch:49 step:38740 [D loss: 0.210849, acc: 96.88%] [G loss: 3.538360]\n",
      "epoch:49 step:38741 [D loss: 0.443096, acc: 69.53%] [G loss: 8.491748]\n",
      "epoch:49 step:38742 [D loss: 0.236945, acc: 92.19%] [G loss: 4.112053]\n",
      "epoch:49 step:38743 [D loss: 0.289123, acc: 84.38%] [G loss: 10.241627]\n",
      "epoch:49 step:38744 [D loss: 0.329910, acc: 85.16%] [G loss: 4.124867]\n",
      "epoch:49 step:38745 [D loss: 0.090882, acc: 99.22%] [G loss: 6.041271]\n",
      "epoch:49 step:38746 [D loss: 0.073144, acc: 100.00%] [G loss: 5.640870]\n",
      "epoch:49 step:38747 [D loss: 0.323055, acc: 81.25%] [G loss: 4.507396]\n",
      "epoch:49 step:38748 [D loss: 0.108302, acc: 99.22%] [G loss: 7.710308]\n",
      "epoch:49 step:38749 [D loss: 0.214631, acc: 96.88%] [G loss: 5.058944]\n",
      "epoch:49 step:38750 [D loss: 0.341482, acc: 87.50%] [G loss: 5.796089]\n",
      "epoch:49 step:38751 [D loss: 0.149849, acc: 99.22%] [G loss: 5.692740]\n",
      "epoch:49 step:38752 [D loss: 0.672569, acc: 63.28%] [G loss: 8.835398]\n",
      "epoch:49 step:38753 [D loss: 0.335607, acc: 81.25%] [G loss: 2.402195]\n",
      "epoch:49 step:38754 [D loss: 1.033284, acc: 37.50%] [G loss: 5.787302]\n",
      "epoch:49 step:38755 [D loss: 0.292182, acc: 89.06%] [G loss: 5.359291]\n",
      "epoch:49 step:38756 [D loss: 0.287340, acc: 92.97%] [G loss: 6.577424]\n",
      "epoch:49 step:38757 [D loss: 0.941747, acc: 51.56%] [G loss: 7.175580]\n",
      "epoch:49 step:38758 [D loss: 0.117638, acc: 99.22%] [G loss: 6.477479]\n",
      "epoch:49 step:38759 [D loss: 0.004335, acc: 100.00%] [G loss: 10.533585]\n",
      "epoch:49 step:38760 [D loss: 0.063877, acc: 99.22%] [G loss: 7.176140]\n",
      "epoch:49 step:38761 [D loss: 0.459293, acc: 71.88%] [G loss: 7.051522]\n",
      "epoch:49 step:38762 [D loss: 0.139534, acc: 99.22%] [G loss: 5.372948]\n",
      "epoch:49 step:38763 [D loss: 0.024259, acc: 100.00%] [G loss: 4.863277]\n",
      "epoch:49 step:38764 [D loss: 0.075588, acc: 100.00%] [G loss: 6.506120]\n",
      "epoch:49 step:38765 [D loss: 0.154382, acc: 95.31%] [G loss: 9.695379]\n",
      "epoch:49 step:38766 [D loss: 0.489066, acc: 68.75%] [G loss: 16.473417]\n",
      "epoch:49 step:38767 [D loss: 0.099186, acc: 100.00%] [G loss: 8.173576]\n",
      "epoch:49 step:38768 [D loss: 0.065979, acc: 99.22%] [G loss: 3.472396]\n",
      "epoch:49 step:38769 [D loss: 0.061629, acc: 100.00%] [G loss: 5.301819]\n",
      "epoch:49 step:38770 [D loss: 0.094319, acc: 99.22%] [G loss: 7.983473]\n",
      "epoch:49 step:38771 [D loss: 0.302100, acc: 85.94%] [G loss: 7.614101]\n",
      "epoch:49 step:38772 [D loss: 0.198429, acc: 96.09%] [G loss: 4.047023]\n",
      "epoch:49 step:38773 [D loss: 0.218030, acc: 94.53%] [G loss: 7.035266]\n",
      "epoch:49 step:38774 [D loss: 0.088203, acc: 100.00%] [G loss: 6.784982]\n",
      "epoch:49 step:38775 [D loss: 0.140340, acc: 96.88%] [G loss: 9.311739]\n",
      "epoch:49 step:38776 [D loss: 0.116680, acc: 99.22%] [G loss: 6.614826]\n",
      "epoch:49 step:38777 [D loss: 0.003894, acc: 100.00%] [G loss: 6.617138]\n",
      "epoch:49 step:38778 [D loss: 0.054681, acc: 100.00%] [G loss: 4.484128]\n",
      "epoch:49 step:38779 [D loss: 1.097241, acc: 35.16%] [G loss: 8.884802]\n",
      "epoch:49 step:38780 [D loss: 0.106384, acc: 98.44%] [G loss: 10.490988]\n",
      "epoch:49 step:38781 [D loss: 0.046462, acc: 100.00%] [G loss: 7.588643]\n",
      "epoch:49 step:38782 [D loss: 0.072130, acc: 100.00%] [G loss: 3.456149]\n",
      "epoch:49 step:38783 [D loss: 2.312335, acc: 0.78%] [G loss: 7.822937]\n",
      "epoch:49 step:38784 [D loss: 0.108473, acc: 100.00%] [G loss: 6.085259]\n",
      "epoch:49 step:38785 [D loss: 0.076759, acc: 98.44%] [G loss: 4.345140]\n",
      "epoch:49 step:38786 [D loss: 0.018982, acc: 100.00%] [G loss: 5.435137]\n",
      "epoch:49 step:38787 [D loss: 0.147134, acc: 96.09%] [G loss: 7.237917]\n",
      "epoch:49 step:38788 [D loss: 0.165674, acc: 100.00%] [G loss: 8.421679]\n",
      "epoch:49 step:38789 [D loss: 0.027659, acc: 100.00%] [G loss: 8.619431]\n",
      "epoch:49 step:38790 [D loss: 0.113463, acc: 96.88%] [G loss: 5.597150]\n",
      "epoch:49 step:38791 [D loss: 0.074229, acc: 100.00%] [G loss: 3.916051]\n",
      "epoch:49 step:38792 [D loss: 0.972466, acc: 46.09%] [G loss: 11.549793]\n",
      "epoch:49 step:38793 [D loss: 0.225065, acc: 92.19%] [G loss: 6.753329]\n",
      "epoch:49 step:38794 [D loss: 0.064163, acc: 100.00%] [G loss: 7.485978]\n",
      "epoch:49 step:38795 [D loss: 0.157652, acc: 96.88%] [G loss: 3.518426]\n",
      "epoch:49 step:38796 [D loss: 0.632862, acc: 62.50%] [G loss: 10.800038]\n",
      "epoch:49 step:38797 [D loss: 0.912354, acc: 53.12%] [G loss: 9.222607]\n",
      "epoch:49 step:38798 [D loss: 0.053799, acc: 100.00%] [G loss: 4.700669]\n",
      "epoch:49 step:38799 [D loss: 0.139772, acc: 99.22%] [G loss: 7.057357]\n",
      "epoch:49 step:38800 [D loss: 0.079829, acc: 100.00%] [G loss: 13.204831]\n",
      "epoch:49 step:38801 [D loss: 1.738035, acc: 35.94%] [G loss: 10.234868]\n",
      "epoch:49 step:38802 [D loss: 0.024436, acc: 100.00%] [G loss: 3.608321]\n",
      "epoch:49 step:38803 [D loss: 2.308090, acc: 49.22%] [G loss: 9.253320]\n",
      "epoch:49 step:38804 [D loss: 0.091771, acc: 98.44%] [G loss: 6.915831]\n",
      "epoch:49 step:38805 [D loss: 0.293620, acc: 87.50%] [G loss: 8.699486]\n",
      "epoch:49 step:38806 [D loss: 2.668341, acc: 43.75%] [G loss: 12.474104]\n",
      "epoch:49 step:38807 [D loss: 0.008877, acc: 100.00%] [G loss: 10.340768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38808 [D loss: 0.670615, acc: 53.91%] [G loss: 8.384217]\n",
      "epoch:49 step:38809 [D loss: 0.017148, acc: 100.00%] [G loss: 8.949610]\n",
      "epoch:49 step:38810 [D loss: 0.264538, acc: 96.09%] [G loss: 5.280114]\n",
      "epoch:49 step:38811 [D loss: 0.084229, acc: 100.00%] [G loss: 9.455040]\n",
      "epoch:49 step:38812 [D loss: 0.205056, acc: 94.53%] [G loss: 6.403120]\n",
      "epoch:49 step:38813 [D loss: 0.107993, acc: 99.22%] [G loss: 8.787320]\n",
      "epoch:49 step:38814 [D loss: 0.053095, acc: 100.00%] [G loss: 9.230204]\n",
      "epoch:49 step:38815 [D loss: 0.293014, acc: 88.28%] [G loss: 8.225316]\n",
      "epoch:49 step:38816 [D loss: 0.152877, acc: 99.22%] [G loss: 4.497293]\n",
      "epoch:49 step:38817 [D loss: 0.099332, acc: 99.22%] [G loss: 5.722535]\n",
      "epoch:49 step:38818 [D loss: 0.161037, acc: 97.66%] [G loss: 5.880548]\n",
      "epoch:49 step:38819 [D loss: 0.270448, acc: 90.62%] [G loss: 3.789473]\n",
      "epoch:49 step:38820 [D loss: 0.494071, acc: 71.09%] [G loss: 6.251849]\n",
      "epoch:49 step:38821 [D loss: 0.240785, acc: 92.97%] [G loss: 5.904859]\n",
      "epoch:49 step:38822 [D loss: 0.188542, acc: 94.53%] [G loss: 6.997781]\n",
      "epoch:49 step:38823 [D loss: 0.079928, acc: 100.00%] [G loss: 4.683662]\n",
      "epoch:49 step:38824 [D loss: 0.545223, acc: 75.78%] [G loss: 7.513806]\n",
      "epoch:49 step:38825 [D loss: 0.482589, acc: 68.75%] [G loss: 8.970956]\n",
      "epoch:49 step:38826 [D loss: 0.348780, acc: 85.16%] [G loss: 7.874147]\n",
      "epoch:49 step:38827 [D loss: 0.026484, acc: 99.22%] [G loss: 7.681989]\n",
      "epoch:49 step:38828 [D loss: 0.009774, acc: 100.00%] [G loss: 7.716804]\n",
      "epoch:49 step:38829 [D loss: 0.239993, acc: 90.62%] [G loss: 6.324862]\n",
      "epoch:49 step:38830 [D loss: 0.089595, acc: 99.22%] [G loss: 4.353691]\n",
      "epoch:49 step:38831 [D loss: 0.081724, acc: 99.22%] [G loss: 7.845403]\n",
      "epoch:49 step:38832 [D loss: 0.254531, acc: 90.62%] [G loss: 3.714684]\n",
      "epoch:49 step:38833 [D loss: 0.064961, acc: 100.00%] [G loss: 3.143787]\n",
      "epoch:49 step:38834 [D loss: 0.135667, acc: 99.22%] [G loss: 6.643581]\n",
      "epoch:49 step:38835 [D loss: 0.035173, acc: 100.00%] [G loss: 8.669352]\n",
      "epoch:49 step:38836 [D loss: 0.033443, acc: 100.00%] [G loss: 6.037305]\n",
      "epoch:49 step:38837 [D loss: 0.155466, acc: 98.44%] [G loss: 7.753747]\n",
      "epoch:49 step:38838 [D loss: 0.073686, acc: 100.00%] [G loss: 4.503971]\n",
      "epoch:49 step:38839 [D loss: 0.011186, acc: 100.00%] [G loss: 7.529172]\n",
      "epoch:49 step:38840 [D loss: 0.759924, acc: 50.78%] [G loss: 6.629108]\n",
      "epoch:49 step:38841 [D loss: 0.083194, acc: 100.00%] [G loss: 6.429523]\n",
      "epoch:49 step:38842 [D loss: 0.292591, acc: 86.72%] [G loss: 8.426824]\n",
      "epoch:49 step:38843 [D loss: 0.194067, acc: 95.31%] [G loss: 2.830989]\n",
      "epoch:49 step:38844 [D loss: 0.450733, acc: 71.09%] [G loss: 7.466224]\n",
      "epoch:49 step:38845 [D loss: 0.509127, acc: 61.72%] [G loss: 6.591251]\n",
      "epoch:49 step:38846 [D loss: 0.230855, acc: 92.19%] [G loss: 5.071663]\n",
      "epoch:49 step:38847 [D loss: 0.022626, acc: 100.00%] [G loss: 8.081305]\n",
      "epoch:49 step:38848 [D loss: 0.415368, acc: 77.34%] [G loss: 8.045809]\n",
      "epoch:49 step:38849 [D loss: 0.851223, acc: 54.69%] [G loss: 10.254421]\n",
      "epoch:49 step:38850 [D loss: 0.071665, acc: 99.22%] [G loss: 11.829058]\n",
      "epoch:49 step:38851 [D loss: 0.153072, acc: 99.22%] [G loss: 5.089528]\n",
      "epoch:49 step:38852 [D loss: 0.247706, acc: 93.75%] [G loss: 5.200877]\n",
      "epoch:49 step:38853 [D loss: 0.945640, acc: 36.72%] [G loss: 8.665147]\n",
      "epoch:49 step:38854 [D loss: 0.060665, acc: 100.00%] [G loss: 8.130775]\n",
      "epoch:49 step:38855 [D loss: 0.397060, acc: 75.78%] [G loss: 4.265596]\n",
      "epoch:49 step:38856 [D loss: 0.411791, acc: 76.56%] [G loss: 7.300261]\n",
      "epoch:49 step:38857 [D loss: 0.152562, acc: 98.44%] [G loss: 6.786180]\n",
      "epoch:49 step:38858 [D loss: 0.157158, acc: 97.66%] [G loss: 4.015357]\n",
      "epoch:49 step:38859 [D loss: 0.224138, acc: 93.75%] [G loss: 6.259995]\n",
      "epoch:49 step:38860 [D loss: 1.866281, acc: 48.44%] [G loss: 5.414409]\n",
      "epoch:49 step:38861 [D loss: 1.337277, acc: 51.56%] [G loss: 9.198462]\n",
      "epoch:49 step:38862 [D loss: 0.134920, acc: 100.00%] [G loss: 5.692168]\n",
      "epoch:49 step:38863 [D loss: 0.460182, acc: 84.38%] [G loss: 7.182493]\n",
      "epoch:49 step:38864 [D loss: 0.496996, acc: 64.06%] [G loss: 5.180510]\n",
      "epoch:49 step:38865 [D loss: 0.184344, acc: 95.31%] [G loss: 8.258552]\n",
      "epoch:49 step:38866 [D loss: 0.135655, acc: 99.22%] [G loss: 7.511747]\n",
      "epoch:49 step:38867 [D loss: 0.237485, acc: 92.19%] [G loss: 6.539237]\n",
      "epoch:49 step:38868 [D loss: 0.012789, acc: 100.00%] [G loss: 4.426274]\n",
      "epoch:49 step:38869 [D loss: 0.201733, acc: 98.44%] [G loss: 4.893640]\n",
      "epoch:49 step:38870 [D loss: 0.713526, acc: 59.38%] [G loss: 7.262987]\n",
      "epoch:49 step:38871 [D loss: 0.329900, acc: 82.81%] [G loss: 5.586936]\n",
      "epoch:49 step:38872 [D loss: 0.252036, acc: 90.62%] [G loss: 5.771018]\n",
      "epoch:49 step:38873 [D loss: 0.857707, acc: 40.62%] [G loss: 6.451634]\n",
      "epoch:49 step:38874 [D loss: 0.635257, acc: 62.50%] [G loss: 6.890182]\n",
      "epoch:49 step:38875 [D loss: 1.078911, acc: 50.78%] [G loss: 3.915611]\n",
      "epoch:49 step:38876 [D loss: 0.201100, acc: 96.09%] [G loss: 5.603477]\n",
      "epoch:49 step:38877 [D loss: 0.689748, acc: 60.94%] [G loss: 5.994163]\n",
      "epoch:49 step:38878 [D loss: 0.504699, acc: 68.75%] [G loss: 4.733820]\n",
      "epoch:49 step:38879 [D loss: 0.334734, acc: 89.84%] [G loss: 7.716613]\n",
      "epoch:49 step:38880 [D loss: 0.210059, acc: 96.09%] [G loss: 5.361478]\n",
      "epoch:49 step:38881 [D loss: 0.423923, acc: 75.00%] [G loss: 7.705755]\n",
      "epoch:49 step:38882 [D loss: 0.235766, acc: 94.53%] [G loss: 5.732874]\n",
      "epoch:49 step:38883 [D loss: 0.017007, acc: 100.00%] [G loss: 10.830333]\n",
      "epoch:49 step:38884 [D loss: 0.009848, acc: 100.00%] [G loss: 9.597458]\n",
      "epoch:49 step:38885 [D loss: 0.109190, acc: 98.44%] [G loss: 6.570160]\n",
      "epoch:49 step:38886 [D loss: 0.181351, acc: 96.88%] [G loss: 4.681736]\n",
      "epoch:49 step:38887 [D loss: 0.307740, acc: 85.16%] [G loss: 4.796217]\n",
      "epoch:49 step:38888 [D loss: 0.110645, acc: 100.00%] [G loss: 9.420828]\n",
      "epoch:49 step:38889 [D loss: 1.320891, acc: 50.00%] [G loss: 7.089205]\n",
      "epoch:49 step:38890 [D loss: 0.102084, acc: 100.00%] [G loss: 5.994771]\n",
      "epoch:49 step:38891 [D loss: 0.354209, acc: 85.16%] [G loss: 7.866790]\n",
      "epoch:49 step:38892 [D loss: 0.198639, acc: 95.31%] [G loss: 5.986672]\n",
      "epoch:49 step:38893 [D loss: 0.064256, acc: 100.00%] [G loss: 3.667122]\n",
      "epoch:49 step:38894 [D loss: 0.779060, acc: 54.69%] [G loss: 4.220816]\n",
      "epoch:49 step:38895 [D loss: 0.320845, acc: 88.28%] [G loss: 7.444151]\n",
      "epoch:49 step:38896 [D loss: 0.154764, acc: 98.44%] [G loss: 6.860290]\n",
      "epoch:49 step:38897 [D loss: 0.079848, acc: 99.22%] [G loss: 6.241465]\n",
      "epoch:49 step:38898 [D loss: 0.085943, acc: 99.22%] [G loss: 4.461517]\n",
      "epoch:49 step:38899 [D loss: 0.211564, acc: 93.75%] [G loss: 5.592800]\n",
      "epoch:49 step:38900 [D loss: 0.292225, acc: 92.19%] [G loss: 3.285196]\n",
      "epoch:49 step:38901 [D loss: 0.606896, acc: 67.19%] [G loss: 9.233807]\n",
      "epoch:49 step:38902 [D loss: 0.805419, acc: 51.56%] [G loss: 13.079330]\n",
      "epoch:49 step:38903 [D loss: 0.411150, acc: 71.88%] [G loss: 6.368325]\n",
      "epoch:49 step:38904 [D loss: 0.341768, acc: 82.03%] [G loss: 7.061182]\n",
      "epoch:49 step:38905 [D loss: 0.038415, acc: 100.00%] [G loss: 5.339842]\n",
      "epoch:49 step:38906 [D loss: 1.162830, acc: 26.56%] [G loss: 6.142210]\n",
      "epoch:49 step:38907 [D loss: 0.428150, acc: 78.91%] [G loss: 7.159123]\n",
      "epoch:49 step:38908 [D loss: 0.121946, acc: 99.22%] [G loss: 6.406094]\n",
      "epoch:49 step:38909 [D loss: 0.218884, acc: 92.19%] [G loss: 4.821929]\n",
      "epoch:49 step:38910 [D loss: 0.077617, acc: 99.22%] [G loss: 5.959530]\n",
      "epoch:49 step:38911 [D loss: 0.380817, acc: 82.03%] [G loss: 5.839735]\n",
      "epoch:49 step:38912 [D loss: 0.006672, acc: 100.00%] [G loss: 8.331261]\n",
      "epoch:49 step:38913 [D loss: 0.301128, acc: 85.94%] [G loss: 8.397970]\n",
      "epoch:49 step:38914 [D loss: 0.354412, acc: 84.38%] [G loss: 7.112856]\n",
      "epoch:49 step:38915 [D loss: 0.140613, acc: 100.00%] [G loss: 7.776444]\n",
      "epoch:49 step:38916 [D loss: 0.494983, acc: 67.97%] [G loss: 6.355647]\n",
      "epoch:49 step:38917 [D loss: 0.066726, acc: 100.00%] [G loss: 4.331931]\n",
      "epoch:49 step:38918 [D loss: 0.151678, acc: 100.00%] [G loss: 3.496819]\n",
      "epoch:49 step:38919 [D loss: 0.217086, acc: 92.97%] [G loss: 3.788424]\n",
      "epoch:49 step:38920 [D loss: 0.739893, acc: 57.81%] [G loss: 5.960515]\n",
      "epoch:49 step:38921 [D loss: 0.177918, acc: 96.09%] [G loss: 6.473382]\n",
      "epoch:49 step:38922 [D loss: 0.271185, acc: 91.41%] [G loss: 5.467330]\n",
      "epoch:49 step:38923 [D loss: 0.449447, acc: 70.31%] [G loss: 9.589988]\n",
      "epoch:49 step:38924 [D loss: 0.060982, acc: 100.00%] [G loss: 6.499560]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38925 [D loss: 0.303494, acc: 90.62%] [G loss: 4.952621]\n",
      "epoch:49 step:38926 [D loss: 0.127383, acc: 98.44%] [G loss: 9.160003]\n",
      "epoch:49 step:38927 [D loss: 0.936235, acc: 50.00%] [G loss: 9.354731]\n",
      "epoch:49 step:38928 [D loss: 0.771654, acc: 55.47%] [G loss: 4.544422]\n",
      "epoch:49 step:38929 [D loss: 0.027309, acc: 100.00%] [G loss: 2.632430]\n",
      "epoch:49 step:38930 [D loss: 0.420621, acc: 83.59%] [G loss: 6.801983]\n",
      "epoch:49 step:38931 [D loss: 0.214916, acc: 93.75%] [G loss: 5.513331]\n",
      "epoch:49 step:38932 [D loss: 0.248527, acc: 92.97%] [G loss: 8.068051]\n",
      "epoch:49 step:38933 [D loss: 0.018493, acc: 100.00%] [G loss: 8.807262]\n",
      "epoch:49 step:38934 [D loss: 0.148823, acc: 96.09%] [G loss: 8.185399]\n",
      "epoch:49 step:38935 [D loss: 0.265561, acc: 91.41%] [G loss: 5.257712]\n",
      "epoch:49 step:38936 [D loss: 0.076732, acc: 100.00%] [G loss: 7.524589]\n",
      "epoch:49 step:38937 [D loss: 0.523497, acc: 67.97%] [G loss: 5.425125]\n",
      "epoch:49 step:38938 [D loss: 0.122027, acc: 98.44%] [G loss: 8.406659]\n",
      "epoch:49 step:38939 [D loss: 0.227807, acc: 96.88%] [G loss: 6.463090]\n",
      "epoch:49 step:38940 [D loss: 0.384234, acc: 76.56%] [G loss: 8.775904]\n",
      "epoch:49 step:38941 [D loss: 0.094710, acc: 99.22%] [G loss: 10.759289]\n",
      "epoch:49 step:38942 [D loss: 0.047314, acc: 100.00%] [G loss: 6.898787]\n",
      "epoch:49 step:38943 [D loss: 0.590486, acc: 66.41%] [G loss: 10.090210]\n",
      "epoch:49 step:38944 [D loss: 0.777120, acc: 54.69%] [G loss: 10.503354]\n",
      "epoch:49 step:38945 [D loss: 0.691314, acc: 56.25%] [G loss: 10.568062]\n",
      "epoch:49 step:38946 [D loss: 0.097335, acc: 96.88%] [G loss: 4.850856]\n",
      "epoch:49 step:38947 [D loss: 0.111488, acc: 100.00%] [G loss: 5.819424]\n",
      "epoch:49 step:38948 [D loss: 1.354988, acc: 23.44%] [G loss: 8.486093]\n",
      "epoch:49 step:38949 [D loss: 0.103418, acc: 100.00%] [G loss: 6.631729]\n",
      "epoch:49 step:38950 [D loss: 0.025130, acc: 100.00%] [G loss: 5.120746]\n",
      "epoch:49 step:38951 [D loss: 0.232352, acc: 94.53%] [G loss: 5.855789]\n",
      "epoch:49 step:38952 [D loss: 0.144598, acc: 99.22%] [G loss: 3.692722]\n",
      "epoch:49 step:38953 [D loss: 0.293880, acc: 86.72%] [G loss: 5.435627]\n",
      "epoch:49 step:38954 [D loss: 0.361755, acc: 92.97%] [G loss: 5.769541]\n",
      "epoch:49 step:38955 [D loss: 0.525154, acc: 71.88%] [G loss: 9.250637]\n",
      "epoch:49 step:38956 [D loss: 0.031035, acc: 100.00%] [G loss: 4.653388]\n",
      "epoch:49 step:38957 [D loss: 0.026087, acc: 99.22%] [G loss: 6.603879]\n",
      "epoch:49 step:38958 [D loss: 0.211591, acc: 95.31%] [G loss: 5.201428]\n",
      "epoch:49 step:38959 [D loss: 0.072363, acc: 99.22%] [G loss: 8.326575]\n",
      "epoch:49 step:38960 [D loss: 0.262724, acc: 92.19%] [G loss: 7.849210]\n",
      "epoch:49 step:38961 [D loss: 0.352782, acc: 84.38%] [G loss: 5.857816]\n",
      "epoch:49 step:38962 [D loss: 0.092907, acc: 100.00%] [G loss: 10.670472]\n",
      "epoch:49 step:38963 [D loss: 0.675281, acc: 61.72%] [G loss: 10.657139]\n",
      "epoch:49 step:38964 [D loss: 0.045019, acc: 100.00%] [G loss: 6.538567]\n",
      "epoch:49 step:38965 [D loss: 0.647292, acc: 60.16%] [G loss: 9.468298]\n",
      "epoch:49 step:38966 [D loss: 0.452895, acc: 75.78%] [G loss: 9.021269]\n",
      "epoch:49 step:38967 [D loss: 0.056482, acc: 100.00%] [G loss: 8.700818]\n",
      "epoch:49 step:38968 [D loss: 0.014849, acc: 100.00%] [G loss: 7.662176]\n",
      "epoch:49 step:38969 [D loss: 0.045995, acc: 100.00%] [G loss: 4.794086]\n",
      "epoch:49 step:38970 [D loss: 0.772997, acc: 55.47%] [G loss: 8.975602]\n",
      "epoch:49 step:38971 [D loss: 0.723095, acc: 52.34%] [G loss: 10.482763]\n",
      "epoch:49 step:38972 [D loss: 0.030935, acc: 100.00%] [G loss: 9.039217]\n",
      "epoch:49 step:38973 [D loss: 0.283074, acc: 89.06%] [G loss: 4.425544]\n",
      "epoch:49 step:38974 [D loss: 0.176403, acc: 95.31%] [G loss: 5.277741]\n",
      "epoch:49 step:38975 [D loss: 0.069141, acc: 99.22%] [G loss: 4.632784]\n",
      "epoch:49 step:38976 [D loss: 0.085214, acc: 99.22%] [G loss: 4.902118]\n",
      "epoch:49 step:38977 [D loss: 0.416514, acc: 76.56%] [G loss: 11.742325]\n",
      "epoch:49 step:38978 [D loss: 0.091375, acc: 100.00%] [G loss: 8.794203]\n",
      "epoch:49 step:38979 [D loss: 0.450509, acc: 78.91%] [G loss: 10.393619]\n",
      "epoch:49 step:38980 [D loss: 0.015044, acc: 100.00%] [G loss: 6.076332]\n",
      "epoch:49 step:38981 [D loss: 0.081114, acc: 98.44%] [G loss: 6.439775]\n",
      "epoch:49 step:38982 [D loss: 0.064017, acc: 100.00%] [G loss: 9.975052]\n",
      "epoch:49 step:38983 [D loss: 0.180452, acc: 96.88%] [G loss: 6.404335]\n",
      "epoch:49 step:38984 [D loss: 0.103331, acc: 100.00%] [G loss: 7.932552]\n",
      "epoch:49 step:38985 [D loss: 0.061063, acc: 100.00%] [G loss: 6.361024]\n",
      "epoch:49 step:38986 [D loss: 0.450214, acc: 70.31%] [G loss: 7.288161]\n",
      "epoch:49 step:38987 [D loss: 0.986249, acc: 51.56%] [G loss: 6.813315]\n",
      "epoch:49 step:38988 [D loss: 0.308931, acc: 96.09%] [G loss: 5.952316]\n",
      "epoch:49 step:38989 [D loss: 0.081325, acc: 100.00%] [G loss: 6.766528]\n",
      "epoch:49 step:38990 [D loss: 0.113452, acc: 99.22%] [G loss: 5.383633]\n",
      "epoch:49 step:38991 [D loss: 0.156864, acc: 99.22%] [G loss: 7.042317]\n",
      "epoch:49 step:38992 [D loss: 0.349517, acc: 84.38%] [G loss: 10.608454]\n",
      "epoch:49 step:38993 [D loss: 0.103169, acc: 100.00%] [G loss: 5.218516]\n",
      "epoch:49 step:38994 [D loss: 0.303281, acc: 87.50%] [G loss: 9.364195]\n",
      "epoch:49 step:38995 [D loss: 1.218739, acc: 50.00%] [G loss: 5.787105]\n",
      "epoch:49 step:38996 [D loss: 0.298280, acc: 89.06%] [G loss: 9.021595]\n",
      "epoch:49 step:38997 [D loss: 0.018514, acc: 100.00%] [G loss: 8.794603]\n",
      "epoch:49 step:38998 [D loss: 0.090183, acc: 99.22%] [G loss: 6.557237]\n",
      "epoch:49 step:38999 [D loss: 0.302725, acc: 85.94%] [G loss: 9.961829]\n",
      "epoch:49 step:39000 [D loss: 0.804309, acc: 51.56%] [G loss: 8.379940]\n",
      "epoch:49 step:39001 [D loss: 0.678271, acc: 59.38%] [G loss: 9.044783]\n",
      "epoch:49 step:39002 [D loss: 0.969152, acc: 51.56%] [G loss: 9.090297]\n",
      "epoch:49 step:39003 [D loss: 0.528915, acc: 65.62%] [G loss: 7.685852]\n",
      "epoch:49 step:39004 [D loss: 0.861968, acc: 53.91%] [G loss: 3.893322]\n",
      "epoch:49 step:39005 [D loss: 0.757890, acc: 54.69%] [G loss: 6.456771]\n",
      "epoch:49 step:39006 [D loss: 0.236650, acc: 92.19%] [G loss: 4.652512]\n",
      "epoch:49 step:39007 [D loss: 0.317987, acc: 87.50%] [G loss: 6.918909]\n",
      "epoch:49 step:39008 [D loss: 0.503370, acc: 63.28%] [G loss: 8.322523]\n",
      "epoch:49 step:39009 [D loss: 0.671641, acc: 53.91%] [G loss: 5.599953]\n",
      "epoch:49 step:39010 [D loss: 0.508949, acc: 77.34%] [G loss: 5.461801]\n",
      "epoch:49 step:39011 [D loss: 0.085828, acc: 100.00%] [G loss: 4.911340]\n",
      "epoch:49 step:39012 [D loss: 0.353018, acc: 83.59%] [G loss: 5.174740]\n",
      "epoch:49 step:39013 [D loss: 0.313842, acc: 87.50%] [G loss: 6.760541]\n",
      "epoch:49 step:39014 [D loss: 0.242827, acc: 96.09%] [G loss: 9.009822]\n",
      "epoch:49 step:39015 [D loss: 0.063674, acc: 99.22%] [G loss: 8.513126]\n",
      "epoch:49 step:39016 [D loss: 0.223857, acc: 94.53%] [G loss: 5.633616]\n",
      "epoch:49 step:39017 [D loss: 0.263699, acc: 95.31%] [G loss: 4.635727]\n",
      "epoch:49 step:39018 [D loss: 0.124085, acc: 99.22%] [G loss: 4.600459]\n",
      "epoch:49 step:39019 [D loss: 0.422524, acc: 75.00%] [G loss: 4.557302]\n",
      "epoch:49 step:39020 [D loss: 0.192112, acc: 93.75%] [G loss: 6.236044]\n",
      "epoch:49 step:39021 [D loss: 0.149838, acc: 97.66%] [G loss: 3.416312]\n",
      "epoch:49 step:39022 [D loss: 1.016691, acc: 49.22%] [G loss: 6.635929]\n",
      "epoch:49 step:39023 [D loss: 0.094744, acc: 99.22%] [G loss: 3.700629]\n",
      "epoch:49 step:39024 [D loss: 1.566883, acc: 51.56%] [G loss: 10.782164]\n",
      "epoch:49 step:39025 [D loss: 0.811035, acc: 47.66%] [G loss: 7.976768]\n",
      "epoch:49 step:39026 [D loss: 0.506659, acc: 65.62%] [G loss: 8.042709]\n",
      "epoch:49 step:39027 [D loss: 0.606062, acc: 60.94%] [G loss: 4.090519]\n",
      "epoch:49 step:39028 [D loss: 0.271707, acc: 90.62%] [G loss: 8.081712]\n",
      "epoch:49 step:39029 [D loss: 0.074769, acc: 98.44%] [G loss: 6.589901]\n",
      "epoch:49 step:39030 [D loss: 0.353972, acc: 82.81%] [G loss: 7.405770]\n",
      "epoch:49 step:39031 [D loss: 0.329028, acc: 79.69%] [G loss: 9.563570]\n",
      "epoch:49 step:39032 [D loss: 0.413279, acc: 73.44%] [G loss: 5.836498]\n",
      "epoch:49 step:39033 [D loss: 0.225549, acc: 92.19%] [G loss: 5.052106]\n",
      "epoch:49 step:39034 [D loss: 1.298257, acc: 42.19%] [G loss: 6.487288]\n",
      "epoch:49 step:39035 [D loss: 0.441034, acc: 82.81%] [G loss: 5.394109]\n",
      "epoch:49 step:39036 [D loss: 0.102638, acc: 99.22%] [G loss: 6.605426]\n",
      "epoch:49 step:39037 [D loss: 0.077709, acc: 100.00%] [G loss: 6.736005]\n",
      "epoch:49 step:39038 [D loss: 0.199746, acc: 96.09%] [G loss: 7.867668]\n",
      "epoch:49 step:39039 [D loss: 0.049948, acc: 99.22%] [G loss: 9.788977]\n",
      "epoch:49 step:39040 [D loss: 0.145117, acc: 100.00%] [G loss: 7.023788]\n",
      "epoch:49 step:39041 [D loss: 0.439501, acc: 79.69%] [G loss: 3.515817]\n",
      "epoch:49 step:39042 [D loss: 0.137939, acc: 96.88%] [G loss: 8.240325]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:39043 [D loss: 0.110067, acc: 99.22%] [G loss: 7.953777]\n",
      "epoch:49 step:39044 [D loss: 0.405203, acc: 82.03%] [G loss: 8.449113]\n",
      "epoch:49 step:39045 [D loss: 0.173005, acc: 96.88%] [G loss: 9.083858]\n",
      "epoch:49 step:39046 [D loss: 0.366549, acc: 92.19%] [G loss: 6.602138]\n",
      "epoch:49 step:39047 [D loss: 0.859794, acc: 50.78%] [G loss: 6.354909]\n",
      "epoch:49 step:39048 [D loss: 0.139893, acc: 100.00%] [G loss: 7.053217]\n",
      "epoch:49 step:39049 [D loss: 0.334944, acc: 80.47%] [G loss: 7.338583]\n",
      "epoch:49 step:39050 [D loss: 0.507283, acc: 73.44%] [G loss: 5.112873]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.data as Data\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, imgs, transform=None):\n",
    "        # super().__init__()\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.imgs[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = torch.from_numpy(img)\n",
    "        img=img.reshape([3,32,32])\n",
    "        return img\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import model\n",
    "import torch.nn.functional as F\n",
    "model = model.cifar10(128)\n",
    "model.load_state_dict(torch.load('./log/default/best-85.pth'))\n",
    "model.cuda()\n",
    "def get_mean_var(y_logit):\n",
    "    y_logit=np.abs(y_logit-0.1)\n",
    "    return np.mean(y_logit,axis=1)\n",
    "\n",
    "def get_possibility(images):\n",
    "    x_dataset = MyDataset(images)\n",
    "    # print(x_dataset[0].shape)\n",
    "    x_real_loader = Data.DataLoader(dataset=x_dataset, batch_size=100, shuffle=True)\n",
    "    y_logits = []\n",
    "    for i, data in enumerate(x_real_loader):\n",
    "        # indx_target = target.clone()\n",
    "        data = data.cuda()\n",
    "        data = Variable(data, volatile=True)\n",
    "        output = model(data)\n",
    "        pred = F.softmax(output).cpu().detach().numpy()\n",
    "        y_logits += [i for i in pred]\n",
    "        y_logits=np.array(y_logits)\n",
    "    return y_logits\n",
    "import os\n",
    "if not os.path.isdir('saved_models_{}'.format('bigan')):\n",
    "    os.mkdir('saved_models_{}'.format('bigan'))\n",
    "f = open('saved_models_{}/log_collapse1.txt'.format('bigan'), mode='w')\n",
    "import torch.utils.data as Data\n",
    "import cv2\n",
    "\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GaussianNoise\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers import MaxPooling2D, concatenate\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import losses\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class BIGAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 32\n",
    "        self.img_cols = 32\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "        self.x = []\n",
    "        self.y = np.zeros((31, 1), dtype=np.int)\n",
    "        self.y = list(self.y)\n",
    "        for i in range(31):\n",
    "            self.y[i] = []\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss=['binary_crossentropy'],\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # Build the encoder\n",
    "        self.encoder = self.build_encoder()\n",
    "\n",
    "        # The part of the bigan that trains the discriminator and encoder\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # Generate image from sampled noise\n",
    "        z = Input(shape=(self.latent_dim, ))\n",
    "        img_ = self.generator(z)\n",
    "\n",
    "        # Encode image\n",
    "        img = Input(shape=self.img_shape)\n",
    "        z_ = self.encoder(img)\n",
    "\n",
    "        # Latent -> img is fake, and img -> latent is valid\n",
    "        fake = self.discriminator([z, img_])\n",
    "        valid = self.discriminator([z_, img])\n",
    "\n",
    "        # Set up and compile the combined model\n",
    "        # Trains generator to fool the discriminator\n",
    "        self.bigan_generator = Model([z, img], [fake, valid])\n",
    "        self.bigan_generator.compile(loss=['binary_crossentropy', 'binary_crossentropy'],\n",
    "            optimizer=optimizer)\n",
    "\n",
    "    def build_encoder(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        # model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(self.latent_dim))\n",
    "\n",
    "        model.summary()\n",
    "        img = Input(shape=self.img_shape)\n",
    "        z = model(img)\n",
    "\n",
    "        return Model(img, z)\n",
    "\n",
    "    def build_generator(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 8 * 8, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((8, 8, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        gen_img = model(z)\n",
    "\n",
    "        return Model(z, gen_img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = Input(shape=self.img_shape)\n",
    "        d_in = concatenate([z, Flatten()(img)])\n",
    "\n",
    "        model = Dense(32 * 32 * 3)(d_in)\n",
    "        model = Reshape((32, 32, 3))(model)\n",
    "        model = Conv2D(32, kernel_size=3, strides=2, padding=\"same\")(model)\n",
    "        model = LeakyReLU(alpha=0.2)(model)\n",
    "        model = Dropout(0.25)(model)\n",
    "        model = Conv2D(64, kernel_size=3, strides=2, padding=\"same\")(model)\n",
    "        model = ZeroPadding2D(padding=((0, 1), (0, 1)))(model)\n",
    "        model = BatchNormalization(momentum=0.8)(model)\n",
    "        model = LeakyReLU(alpha=0.2)(model)\n",
    "        model = Dropout(0.25)(model)\n",
    "        model = Conv2D(128, kernel_size=3, strides=2, padding=\"same\")(model)\n",
    "        model = BatchNormalization(momentum=0.8)(model)\n",
    "        model = LeakyReLU(alpha=0.2)(model)\n",
    "        model = Dropout(0.25)(model)\n",
    "        model = Conv2D(256, kernel_size=3, strides=1, padding=\"same\")(model)\n",
    "        model = BatchNormalization(momentum=0.8)(model)\n",
    "        model = LeakyReLU(alpha=0.2)(model)\n",
    "        model = Dropout(0.25)(model)\n",
    "        model = Flatten()(model)\n",
    "        validity = Dense(1, activation=\"sigmoid\")(model)\n",
    "\n",
    "        return Model([z, img], validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (X_test, _) = cifar10.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "        steps = []\n",
    "        values = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random batch of images\n",
    "            # idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            for index in range(nb_batches):\n",
    "                global_step += 1\n",
    "                # progress_bar.update(index)\n",
    "\n",
    "                # get a batch of real images\n",
    "                image_batch = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                z = np.random.normal(size=(batch_size, self.latent_dim))\n",
    "                imgs_ = self.generator.predict(z)\n",
    "\n",
    "                # Select a random batch of images and encode\n",
    "                # idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "                # imgs = X_train[idx]\n",
    "                z_ = self.encoder.predict(image_batch)\n",
    "\n",
    "                # Train the discriminator (img -> z is valid, z -> img is fake)\n",
    "                d_loss_real = self.discriminator.train_on_batch([z_, image_batch], valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch([z, imgs_], fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Generator\n",
    "                # ---------------------\n",
    "\n",
    "                # Train the generator (z -> img is valid and img -> z is is invalid)\n",
    "                g_loss = self.bigan_generator.train_on_batch([z, image_batch], [valid, fake])\n",
    "\n",
    "                # Plot the progress\n",
    "                print(\"epoch:%d step:%d [D loss: %f, acc: %.2f%%] [G loss: %f]\" % (epoch, global_step, d_loss[0],\n",
    "                                                                                   100 * d_loss[1], g_loss[0]))\n",
    "\n",
    "                if global_step % sample_interval == 0:\n",
    "                    self.mode_drop(epoch, global_step)\n",
    "                    \n",
    "\n",
    "    def mode_drop(self, epoch, global_step):\n",
    "        r, c = 10, 1000\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "        # sampled_labels = np.array([num for _ in range(r) for num in range(c)])\n",
    "        gen_imgs = self.generator.predict([noise])\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        y_logits = get_possibility(gen_imgs)\n",
    "        metrics = get_mean_var(y_logits)\n",
    "\n",
    "\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('global_step:' + str(global_step))\n",
    "        f.writelines('\\n')\n",
    "        f.writelines(' %.8f ' % (i) for i in metrics)\n",
    "        f.writelines('\\n')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    bigan = BIGAN()\n",
    "    bigan.train(epochs=50, batch_size=64, sample_interval=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
