{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 64)        131136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 1)         1025      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,028,673\n",
      "Trainable params: 1,028,289\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 16)        160       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 100,097\n",
      "Trainable params: 99,649\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 step5 [D loss: 25.709017] [G loss: 0.489364]\n",
      "epoch0 step10 [D loss: 20.434769] [G loss: 0.687690]\n",
      "epoch0 step15 [D loss: 16.067001] [G loss: 0.661247]\n",
      "epoch0 step20 [D loss: 15.188581] [G loss: 0.252649]\n",
      "epoch0 step25 [D loss: 13.174104] [G loss: 0.790517]\n",
      "epoch0 step30 [D loss: 13.136195] [G loss: 0.718208]\n",
      "epoch0 step35 [D loss: 12.561382] [G loss: 0.537489]\n",
      "epoch0 step40 [D loss: 10.408094] [G loss: 0.609619]\n",
      "epoch0 step45 [D loss: 7.457113] [G loss: 0.305061]\n",
      "epoch0 step50 [D loss: 7.674180] [G loss: 0.539063]\n",
      "epoch0 step55 [D loss: 5.903104] [G loss: 0.494653]\n",
      "epoch0 step60 [D loss: 5.427229] [G loss: 0.640098]\n",
      "epoch0 step65 [D loss: 4.207169] [G loss: 0.554053]\n",
      "epoch0 step70 [D loss: 2.854095] [G loss: 0.523936]\n",
      "epoch0 step75 [D loss: 4.238759] [G loss: 0.600417]\n",
      "epoch0 step80 [D loss: 3.771777] [G loss: 0.418592]\n",
      "epoch0 step85 [D loss: 2.309586] [G loss: 0.627311]\n",
      "epoch0 step90 [D loss: 2.630761] [G loss: 0.360038]\n",
      "epoch0 step95 [D loss: 2.475827] [G loss: 0.383673]\n",
      "epoch0 step100 [D loss: 1.117287] [G loss: 0.380382]\n",
      "epoch0 step105 [D loss: 0.933831] [G loss: 0.308301]\n",
      "epoch0 step110 [D loss: 0.270942] [G loss: 0.339181]\n",
      "epoch0 step115 [D loss: 0.464589] [G loss: 0.391010]\n",
      "epoch0 step120 [D loss: -0.155522] [G loss: 0.555584]\n",
      "epoch0 step125 [D loss: -0.270709] [G loss: 0.392484]\n",
      "epoch0 step130 [D loss: -0.651772] [G loss: 0.424509]\n",
      "epoch0 step135 [D loss: -0.232545] [G loss: 0.248142]\n",
      "epoch0 step140 [D loss: -0.122833] [G loss: 0.183832]\n",
      "epoch0 step145 [D loss: -0.383751] [G loss: 0.255612]\n",
      "epoch0 step150 [D loss: -0.536429] [G loss: 0.373916]\n",
      "epoch0 step155 [D loss: -0.601368] [G loss: 0.364759]\n",
      "epoch0 step160 [D loss: -0.907559] [G loss: 0.519643]\n",
      "epoch0 step165 [D loss: -1.000533] [G loss: 0.325619]\n",
      "epoch0 step170 [D loss: -1.152250] [G loss: 0.402213]\n",
      "epoch0 step175 [D loss: -0.990514] [G loss: -0.051795]\n",
      "epoch0 step180 [D loss: -0.930083] [G loss: 0.230866]\n",
      "epoch0 step185 [D loss: -0.957630] [G loss: 0.032852]\n",
      "epoch0 step190 [D loss: -1.181901] [G loss: 0.152823]\n",
      "epoch0 step195 [D loss: -1.560587] [G loss: -0.076115]\n",
      "epoch0 step200 [D loss: -1.192326] [G loss: -0.378654]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "WARNING:tensorflow:From /home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/contrib/gan/python/eval/python/classifier_metrics_impl.py:185: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute score in space: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/ot/lp/__init__.py:211: UserWarning: numItermax reached before optimality. Try to increase numItermax.\n",
      "  check_result(result_code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute score in space: 1\n",
      "IS socre: 2.009512\n",
      "FID: 210.409546\n",
      "0 = 20.89258436851495\n",
      "1 = 0.48888012590405766\n",
      "2 = 1.0\n",
      "3 = 1.0\n",
      "4 = 1.0\n",
      "5 = 1.0\n",
      "6 = 1.0\n",
      "7 = 14.767103867006218\n",
      "8 = 0.26366170227772145\n",
      "9 = 0.9930999875068665\n",
      "10 = 0.9873999953269958\n",
      "11 = 0.9987999796867371\n",
      "12 = 0.9987861514091492\n",
      "13 = 0.9873999953269958\n",
      "14 = 2.0095126628875732\n",
      "15 = 7.454661846160889\n",
      "16 = 0.5907220244407654\n",
      "17 = 2.009511709213257\n",
      "18 = 210.4095458984375\n",
      "epoch0 step205 [D loss: -1.370411] [G loss: -0.482285]\n",
      "epoch0 step210 [D loss: -1.483072] [G loss: -0.381834]\n",
      "epoch0 step215 [D loss: -1.264601] [G loss: -0.473883]\n",
      "epoch0 step220 [D loss: -1.669289] [G loss: -0.240244]\n",
      "epoch0 step225 [D loss: -1.460519] [G loss: -0.125705]\n",
      "epoch0 step230 [D loss: -1.012411] [G loss: -0.369609]\n",
      "epoch0 step235 [D loss: -0.828847] [G loss: -0.522462]\n",
      "epoch0 step240 [D loss: -1.034721] [G loss: -0.540817]\n",
      "epoch0 step245 [D loss: -0.921811] [G loss: -0.326179]\n",
      "epoch0 step250 [D loss: -1.119400] [G loss: -0.453796]\n",
      "epoch0 step255 [D loss: -1.134869] [G loss: -0.469112]\n",
      "epoch0 step260 [D loss: -1.055700] [G loss: -0.647963]\n",
      "epoch0 step265 [D loss: -1.702876] [G loss: -0.278239]\n",
      "epoch0 step270 [D loss: -1.141591] [G loss: -0.974623]\n",
      "epoch0 step275 [D loss: -1.234845] [G loss: -0.609939]\n",
      "epoch0 step280 [D loss: -1.363963] [G loss: -0.627243]\n",
      "epoch0 step285 [D loss: -0.843337] [G loss: -0.746537]\n",
      "epoch0 step290 [D loss: -1.222255] [G loss: -0.959031]\n",
      "epoch0 step295 [D loss: -1.303565] [G loss: -0.666057]\n",
      "epoch0 step300 [D loss: -1.510934] [G loss: -1.122503]\n",
      "epoch0 step305 [D loss: -1.231264] [G loss: -1.011808]\n",
      "epoch0 step310 [D loss: -1.467420] [G loss: -1.058197]\n",
      "epoch0 step315 [D loss: -1.360851] [G loss: -1.046526]\n",
      "epoch0 step320 [D loss: -1.381734] [G loss: -1.487000]\n",
      "epoch0 step325 [D loss: -1.203791] [G loss: -1.216743]\n",
      "epoch0 step330 [D loss: -1.400039] [G loss: -1.445003]\n",
      "epoch0 step335 [D loss: -0.967574] [G loss: -1.388818]\n",
      "epoch0 step340 [D loss: -0.960192] [G loss: -1.605525]\n",
      "epoch0 step345 [D loss: -1.418154] [G loss: -1.327679]\n",
      "epoch0 step350 [D loss: -1.206924] [G loss: -1.434991]\n",
      "epoch0 step355 [D loss: -0.652343] [G loss: -1.571089]\n",
      "epoch0 step360 [D loss: -1.060661] [G loss: -1.653287]\n",
      "epoch0 step365 [D loss: -0.944152] [G loss: -1.817074]\n",
      "epoch0 step370 [D loss: -0.123738] [G loss: -1.738258]\n",
      "epoch0 step375 [D loss: -0.677802] [G loss: -1.502086]\n",
      "epoch0 step380 [D loss: -0.843356] [G loss: -1.701590]\n",
      "epoch0 step385 [D loss: -1.227320] [G loss: -1.989100]\n",
      "epoch0 step390 [D loss: -1.323170] [G loss: -1.610350]\n",
      "epoch0 step395 [D loss: -1.103973] [G loss: -1.678823]\n",
      "epoch0 step400 [D loss: -0.814076] [G loss: -1.887650]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 2.199970\n",
      "FID: 193.405975\n",
      "0 = 16.858465189933806\n",
      "1 = 0.3018210138102405\n",
      "2 = 0.9991999864578247\n",
      "3 = 0.9983999729156494\n",
      "4 = 1.0\n",
      "5 = 1.0\n",
      "6 = 0.9983999729156494\n",
      "7 = 14.308448190784457\n",
      "8 = 0.2534889900781103\n",
      "9 = 0.9901999831199646\n",
      "10 = 0.9832000136375427\n",
      "11 = 0.9972000122070312\n",
      "12 = 0.9971602559089661\n",
      "13 = 0.9832000136375427\n",
      "14 = 2.19996976852417\n",
      "15 = 7.312464714050293\n",
      "16 = 0.5758768320083618\n",
      "17 = 2.199970006942749\n",
      "18 = 193.40597534179688\n",
      "epoch0 step405 [D loss: -0.925805] [G loss: -1.978101]\n",
      "epoch0 step410 [D loss: -0.431691] [G loss: -2.171673]\n",
      "epoch0 step415 [D loss: -0.757317] [G loss: -1.958408]\n",
      "epoch0 step420 [D loss: -0.831081] [G loss: -1.931190]\n",
      "epoch0 step425 [D loss: -0.801737] [G loss: -1.988591]\n",
      "epoch0 step430 [D loss: -0.131076] [G loss: -2.168214]\n",
      "epoch0 step435 [D loss: -0.581803] [G loss: -1.601568]\n",
      "epoch0 step440 [D loss: -0.768123] [G loss: -1.780983]\n",
      "epoch0 step445 [D loss: -0.560736] [G loss: -1.994295]\n",
      "epoch0 step450 [D loss: -0.959440] [G loss: -1.818008]\n",
      "epoch0 step455 [D loss: -0.521220] [G loss: -1.730208]\n",
      "epoch0 step460 [D loss: -1.360376] [G loss: -1.773775]\n",
      "epoch0 step465 [D loss: -0.702157] [G loss: -1.882982]\n",
      "epoch0 step470 [D loss: -0.683271] [G loss: -2.094531]\n",
      "epoch0 step475 [D loss: -0.691148] [G loss: -1.791564]\n",
      "epoch0 step480 [D loss: -0.961732] [G loss: -1.888783]\n",
      "epoch0 step485 [D loss: -1.049264] [G loss: -1.588883]\n",
      "epoch0 step490 [D loss: -0.678578] [G loss: -1.773394]\n",
      "epoch0 step495 [D loss: -0.729822] [G loss: -1.546758]\n",
      "epoch0 step500 [D loss: -0.552398] [G loss: -1.733257]\n",
      "epoch0 step505 [D loss: -0.424464] [G loss: -1.811136]\n",
      "epoch0 step510 [D loss: -0.766567] [G loss: -1.672369]\n",
      "epoch0 step515 [D loss: -0.579105] [G loss: -2.204563]\n",
      "epoch0 step520 [D loss: -0.546823] [G loss: -1.902254]\n",
      "epoch0 step525 [D loss: -0.517098] [G loss: -1.783602]\n",
      "epoch0 step530 [D loss: -0.355095] [G loss: -1.549544]\n",
      "epoch0 step535 [D loss: -0.499614] [G loss: -1.661786]\n",
      "epoch0 step540 [D loss: -0.480390] [G loss: -1.801468]\n",
      "epoch0 step545 [D loss: -1.058231] [G loss: -1.509410]\n",
      "epoch0 step550 [D loss: -0.500833] [G loss: -2.063956]\n",
      "epoch0 step555 [D loss: -0.727334] [G loss: -1.771404]\n",
      "epoch0 step560 [D loss: 0.028131] [G loss: -1.739489]\n",
      "epoch0 step565 [D loss: -0.682598] [G loss: -1.497008]\n",
      "epoch0 step570 [D loss: -0.817780] [G loss: -1.359063]\n",
      "epoch0 step575 [D loss: -0.793218] [G loss: -1.417838]\n",
      "epoch0 step580 [D loss: -0.990906] [G loss: -1.028822]\n",
      "epoch0 step585 [D loss: -0.198794] [G loss: -1.002324]\n",
      "epoch0 step590 [D loss: -0.718937] [G loss: -1.001272]\n",
      "epoch0 step595 [D loss: -1.104342] [G loss: -0.943247]\n",
      "epoch0 step600 [D loss: -0.511755] [G loss: -1.148560]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 2.490647\n",
      "FID: 170.765015\n",
      "0 = 15.402149584960954\n",
      "1 = 0.22813814726268422\n",
      "2 = 0.9945999979972839\n",
      "3 = 0.9891999959945679\n",
      "4 = 1.0\n",
      "5 = 1.0\n",
      "6 = 0.9891999959945679\n",
      "7 = 13.670300985002566\n",
      "8 = 0.23784384682542722\n",
      "9 = 0.984000027179718\n",
      "10 = 0.9742000102996826\n",
      "11 = 0.9937999844551086\n",
      "12 = 0.9936760663986206\n",
      "13 = 0.9742000102996826\n",
      "14 = 2.490645408630371\n",
      "15 = 7.497479438781738\n",
      "16 = 0.5487262606620789\n",
      "17 = 2.490647315979004\n",
      "18 = 170.7650146484375\n",
      "epoch0 step605 [D loss: -0.446177] [G loss: -0.893726]\n",
      "epoch0 step610 [D loss: -0.295611] [G loss: -1.036181]\n",
      "epoch0 step615 [D loss: -0.832612] [G loss: -0.934000]\n",
      "epoch0 step620 [D loss: -0.911221] [G loss: -0.779645]\n",
      "epoch0 step625 [D loss: -0.783965] [G loss: -0.777210]\n",
      "epoch0 step630 [D loss: -0.913040] [G loss: -0.915237]\n",
      "epoch0 step635 [D loss: -0.370121] [G loss: -1.094552]\n",
      "epoch0 step640 [D loss: -0.385890] [G loss: -1.058722]\n",
      "epoch0 step645 [D loss: -0.805798] [G loss: -0.777924]\n",
      "epoch0 step650 [D loss: -0.437672] [G loss: -0.718775]\n",
      "epoch0 step655 [D loss: -0.877209] [G loss: -0.707498]\n",
      "epoch0 step660 [D loss: -0.871206] [G loss: -0.537900]\n",
      "epoch0 step665 [D loss: -0.401521] [G loss: -0.750532]\n",
      "epoch0 step670 [D loss: -0.393558] [G loss: -1.011208]\n",
      "epoch0 step675 [D loss: -0.976131] [G loss: -0.521985]\n",
      "epoch0 step680 [D loss: -0.821196] [G loss: -0.954795]\n",
      "epoch0 step685 [D loss: -0.977548] [G loss: -0.587859]\n",
      "epoch0 step690 [D loss: -0.783678] [G loss: -0.302215]\n",
      "epoch0 step695 [D loss: -0.776257] [G loss: -0.726097]\n",
      "epoch0 step700 [D loss: -0.718185] [G loss: -0.962707]\n",
      "epoch0 step705 [D loss: -0.507698] [G loss: -0.644816]\n",
      "epoch0 step710 [D loss: -0.528021] [G loss: -0.509618]\n",
      "epoch0 step715 [D loss: -0.787375] [G loss: -0.074318]\n",
      "epoch0 step720 [D loss: -0.782864] [G loss: -0.224954]\n",
      "epoch0 step725 [D loss: -0.497412] [G loss: -0.537382]\n",
      "epoch0 step730 [D loss: -0.243537] [G loss: -0.379822]\n",
      "epoch0 step735 [D loss: -0.353441] [G loss: -0.503286]\n",
      "epoch0 step740 [D loss: -0.149062] [G loss: -0.330094]\n",
      "epoch0 step745 [D loss: -0.877208] [G loss: -0.680143]\n",
      "epoch0 step750 [D loss: -1.180111] [G loss: 0.196633]\n",
      "epoch0 step755 [D loss: -0.824009] [G loss: 0.160407]\n",
      "epoch0 step760 [D loss: -0.907132] [G loss: 0.172984]\n",
      "epoch0 step765 [D loss: -1.546011] [G loss: 0.329805]\n",
      "epoch0 step770 [D loss: -0.478595] [G loss: 0.210329]\n",
      "epoch0 step775 [D loss: -0.591771] [G loss: 0.245779]\n",
      "epoch0 step780 [D loss: -0.481751] [G loss: 0.229255]\n",
      "epoch0 step785 [D loss: -0.724334] [G loss: 0.060792]\n",
      "epoch0 step790 [D loss: -0.338403] [G loss: 0.254156]\n",
      "epoch0 step795 [D loss: -0.547020] [G loss: 0.325168]\n",
      "epoch0 step800 [D loss: -0.559665] [G loss: 0.290926]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 2.704966\n",
      "FID: 159.179977\n",
      "0 = 14.029395435714667\n",
      "1 = 0.16530069233310313\n",
      "2 = 0.984000027179718\n",
      "3 = 0.968999981880188\n",
      "4 = 0.9990000128746033\n",
      "5 = 0.9989690780639648\n",
      "6 = 0.968999981880188\n",
      "7 = 13.508779186964023\n",
      "8 = 0.23177394793414338\n",
      "9 = 0.9797999858856201\n",
      "10 = 0.9688000082969666\n",
      "11 = 0.9908000230789185\n",
      "12 = 0.9905930757522583\n",
      "13 = 0.9688000082969666\n",
      "14 = 2.704967737197876\n",
      "15 = 8.299628257751465\n",
      "16 = 0.46969303488731384\n",
      "17 = 2.7049660682678223\n",
      "18 = 159.1799774169922\n",
      "epoch0 step805 [D loss: -0.759918] [G loss: 0.074304]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 step810 [D loss: -0.047976] [G loss: 0.151021]\n",
      "epoch0 step815 [D loss: -0.693353] [G loss: 0.095671]\n",
      "epoch0 step820 [D loss: -0.081403] [G loss: 0.192759]\n",
      "epoch0 step825 [D loss: -0.950784] [G loss: 0.407046]\n",
      "epoch0 step830 [D loss: -0.346226] [G loss: 0.233415]\n",
      "epoch0 step835 [D loss: -0.849224] [G loss: 0.168695]\n",
      "epoch0 step840 [D loss: -0.680571] [G loss: 0.070228]\n",
      "epoch0 step845 [D loss: -0.629984] [G loss: 0.319429]\n",
      "epoch0 step850 [D loss: -0.345160] [G loss: -0.023929]\n",
      "epoch0 step855 [D loss: -0.608772] [G loss: 0.238881]\n",
      "epoch0 step860 [D loss: -0.930457] [G loss: 0.229580]\n",
      "epoch0 step865 [D loss: -1.000885] [G loss: -0.244419]\n",
      "epoch0 step870 [D loss: -0.579095] [G loss: -0.249293]\n",
      "epoch0 step875 [D loss: -0.802146] [G loss: -0.063040]\n",
      "epoch0 step880 [D loss: -0.581586] [G loss: -0.122455]\n",
      "epoch0 step885 [D loss: -0.687049] [G loss: -0.212984]\n",
      "epoch0 step890 [D loss: -0.590504] [G loss: -0.324577]\n",
      "epoch0 step895 [D loss: -0.413006] [G loss: -0.474036]\n",
      "epoch0 step900 [D loss: -1.145171] [G loss: -0.380542]\n",
      "epoch0 step905 [D loss: -1.031139] [G loss: 0.225113]\n",
      "epoch0 step910 [D loss: -0.496081] [G loss: -0.424312]\n",
      "epoch0 step915 [D loss: -1.059899] [G loss: 0.088337]\n",
      "epoch0 step920 [D loss: -0.838055] [G loss: -0.459408]\n",
      "epoch0 step925 [D loss: -0.994794] [G loss: -0.423068]\n",
      "epoch0 step930 [D loss: -0.916335] [G loss: -0.289880]\n",
      "epoch0 step935 [D loss: -0.461376] [G loss: -0.408763]\n",
      "epoch0 step940 [D loss: -0.511101] [G loss: -0.650589]\n",
      "epoch0 step945 [D loss: -0.117278] [G loss: -0.399801]\n",
      "epoch0 step950 [D loss: -1.064102] [G loss: -0.498335]\n",
      "epoch0 step955 [D loss: -0.048944] [G loss: -0.494037]\n",
      "epoch0 step960 [D loss: -0.656937] [G loss: -0.581900]\n",
      "epoch0 step965 [D loss: -0.210929] [G loss: -0.624025]\n",
      "epoch0 step970 [D loss: -0.594593] [G loss: -0.655828]\n",
      "epoch0 step975 [D loss: -0.291884] [G loss: -0.684209]\n",
      "epoch0 step980 [D loss: -0.864444] [G loss: -0.310287]\n",
      "epoch0 step985 [D loss: -0.826105] [G loss: -0.813741]\n",
      "epoch0 step990 [D loss: -0.372432] [G loss: -0.601018]\n",
      "epoch0 step995 [D loss: -0.594306] [G loss: -0.752509]\n",
      "epoch0 step1000 [D loss: -0.538624] [G loss: -0.758501]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 3.569156\n",
      "FID: 115.062477\n",
      "0 = 16.37761141090394\n",
      "1 = 0.2619284174297221\n",
      "2 = 0.9930999875068665\n",
      "3 = 0.9905999898910522\n",
      "4 = 0.9955999851226807\n",
      "5 = 0.995577871799469\n",
      "6 = 0.9905999898910522\n",
      "7 = 12.110024289846445\n",
      "8 = 0.20608650431935915\n",
      "9 = 0.9639999866485596\n",
      "10 = 0.953000009059906\n",
      "11 = 0.9750000238418579\n",
      "12 = 0.9744376540184021\n",
      "13 = 0.953000009059906\n",
      "14 = 3.569157600402832\n",
      "15 = 8.365118026733398\n",
      "16 = 0.3936731517314911\n",
      "17 = 3.5691561698913574\n",
      "18 = 115.0624771118164\n",
      "epoch0 step1005 [D loss: -0.654729] [G loss: -0.780507]\n",
      "epoch0 step1010 [D loss: -0.273715] [G loss: -0.855444]\n",
      "epoch0 step1015 [D loss: -0.829120] [G loss: -0.574514]\n",
      "epoch0 step1020 [D loss: -0.605167] [G loss: -0.605187]\n",
      "epoch0 step1025 [D loss: -0.894021] [G loss: -1.004491]\n",
      "epoch0 step1030 [D loss: -0.585992] [G loss: -0.432803]\n",
      "epoch0 step1035 [D loss: -0.342460] [G loss: -0.434616]\n",
      "epoch0 step1040 [D loss: -0.925309] [G loss: -0.328193]\n",
      "epoch0 step1045 [D loss: -0.704047] [G loss: -0.576076]\n",
      "epoch0 step1050 [D loss: -0.835269] [G loss: -0.535368]\n",
      "epoch0 step1055 [D loss: -0.523057] [G loss: -1.038029]\n",
      "epoch0 step1060 [D loss: -0.517448] [G loss: -0.749092]\n",
      "epoch0 step1065 [D loss: -0.733032] [G loss: -0.805544]\n",
      "epoch0 step1070 [D loss: -0.974028] [G loss: -0.913615]\n",
      "epoch0 step1075 [D loss: -0.531109] [G loss: -0.960729]\n",
      "epoch0 step1080 [D loss: -0.487668] [G loss: -1.026377]\n",
      "epoch0 step1085 [D loss: -0.368197] [G loss: -0.829794]\n",
      "epoch0 step1090 [D loss: -0.564931] [G loss: -0.757951]\n",
      "epoch0 step1095 [D loss: -1.057665] [G loss: -0.681450]\n",
      "epoch0 step1100 [D loss: -0.762679] [G loss: -0.750596]\n",
      "epoch0 step1105 [D loss: -0.722880] [G loss: -0.940933]\n",
      "epoch0 step1110 [D loss: -0.579209] [G loss: -0.598428]\n",
      "epoch0 step1115 [D loss: -0.629093] [G loss: -1.016731]\n",
      "epoch0 step1120 [D loss: -0.393698] [G loss: -0.799593]\n",
      "epoch0 step1125 [D loss: -0.588661] [G loss: -0.612135]\n",
      "epoch0 step1130 [D loss: -0.689801] [G loss: -0.440711]\n",
      "epoch0 step1135 [D loss: -0.510248] [G loss: -0.842493]\n",
      "epoch0 step1140 [D loss: -0.182998] [G loss: -0.624179]\n",
      "epoch0 step1145 [D loss: -0.356173] [G loss: -0.818374]\n",
      "epoch0 step1150 [D loss: -0.306502] [G loss: -0.511481]\n",
      "epoch0 step1155 [D loss: -0.176951] [G loss: -0.528084]\n",
      "epoch0 step1160 [D loss: -0.444421] [G loss: -0.602587]\n",
      "epoch0 step1165 [D loss: -0.485537] [G loss: -0.861101]\n",
      "epoch0 step1170 [D loss: -0.833090] [G loss: -0.201107]\n",
      "epoch0 step1175 [D loss: -0.666136] [G loss: -0.686789]\n",
      "epoch0 step1180 [D loss: -0.852105] [G loss: -0.599259]\n",
      "epoch0 step1185 [D loss: -0.620252] [G loss: -0.675729]\n",
      "epoch0 step1190 [D loss: -0.558926] [G loss: -0.643382]\n",
      "epoch0 step1195 [D loss: -0.694785] [G loss: -0.618729]\n",
      "epoch0 step1200 [D loss: -0.546795] [G loss: -0.584274]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 3.738516\n",
      "FID: 111.624886\n",
      "0 = 14.260689744567841\n",
      "1 = 0.1286479790183008\n",
      "2 = 0.9801999926567078\n",
      "3 = 0.9692000150680542\n",
      "4 = 0.9911999702453613\n",
      "5 = 0.9910020232200623\n",
      "6 = 0.9692000150680542\n",
      "7 = 12.128520826244333\n",
      "8 = 0.20254933874681008\n",
      "9 = 0.9617000222206116\n",
      "10 = 0.951200008392334\n",
      "11 = 0.9721999764442444\n",
      "12 = 0.9716036915779114\n",
      "13 = 0.951200008392334\n",
      "14 = 3.7385172843933105\n",
      "15 = 8.646785736083984\n",
      "16 = 0.3583495318889618\n",
      "17 = 3.738515853881836\n",
      "18 = 111.62488555908203\n",
      "epoch0 step1205 [D loss: -0.374145] [G loss: -0.569443]\n",
      "epoch0 step1210 [D loss: -0.496134] [G loss: -0.286496]\n",
      "epoch0 step1215 [D loss: -0.729492] [G loss: -0.649944]\n",
      "epoch0 step1220 [D loss: -0.416077] [G loss: -0.243426]\n",
      "epoch0 step1225 [D loss: -0.715752] [G loss: -0.226061]\n",
      "epoch0 step1230 [D loss: -0.333209] [G loss: -0.449106]\n",
      "epoch0 step1235 [D loss: -0.066069] [G loss: -0.054882]\n",
      "epoch0 step1240 [D loss: -0.690867] [G loss: -0.570773]\n",
      "epoch0 step1245 [D loss: -0.397570] [G loss: -0.063730]\n",
      "epoch0 step1250 [D loss: -0.558951] [G loss: -0.413350]\n",
      "epoch0 step1255 [D loss: -0.737733] [G loss: -0.339973]\n",
      "epoch0 step1260 [D loss: -0.366983] [G loss: -0.440874]\n",
      "epoch0 step1265 [D loss: -0.330504] [G loss: -0.388891]\n",
      "epoch0 step1270 [D loss: -0.558926] [G loss: -0.317203]\n",
      "epoch0 step1275 [D loss: -0.619660] [G loss: -0.093629]\n",
      "epoch0 step1280 [D loss: -0.324127] [G loss: -0.245723]\n",
      "epoch0 step1285 [D loss: -0.618638] [G loss: -0.257791]\n",
      "epoch0 step1290 [D loss: -0.751874] [G loss: -0.691029]\n",
      "epoch0 step1295 [D loss: -0.449246] [G loss: -0.016625]\n",
      "epoch0 step1300 [D loss: -0.331669] [G loss: -0.499237]\n",
      "epoch0 step1305 [D loss: -0.510010] [G loss: -0.381026]\n",
      "epoch0 step1310 [D loss: -0.378555] [G loss: -0.712694]\n",
      "epoch0 step1315 [D loss: -0.850078] [G loss: -0.449186]\n",
      "epoch0 step1320 [D loss: -0.729874] [G loss: -0.623432]\n",
      "epoch0 step1325 [D loss: -0.363989] [G loss: -0.653919]\n",
      "epoch0 step1330 [D loss: 0.038929] [G loss: -0.687881]\n",
      "epoch0 step1335 [D loss: -0.499591] [G loss: -0.925108]\n",
      "epoch0 step1340 [D loss: -0.408752] [G loss: -0.992366]\n",
      "epoch0 step1345 [D loss: -0.473052] [G loss: -0.802759]\n",
      "epoch0 step1350 [D loss: 0.145768] [G loss: -1.397978]\n",
      "epoch0 step1355 [D loss: -0.159977] [G loss: -1.161804]\n",
      "epoch0 step1360 [D loss: -0.633748] [G loss: -1.057035]\n",
      "epoch0 step1365 [D loss: -0.343021] [G loss: -1.380141]\n",
      "epoch0 step1370 [D loss: -0.465247] [G loss: -1.200480]\n",
      "epoch0 step1375 [D loss: -0.335862] [G loss: -0.976930]\n",
      "epoch0 step1380 [D loss: -0.455657] [G loss: -1.211272]\n",
      "epoch0 step1385 [D loss: -0.636308] [G loss: -1.058196]\n",
      "epoch0 step1390 [D loss: -0.175866] [G loss: -1.403520]\n",
      "epoch0 step1395 [D loss: -0.471111] [G loss: -1.031108]\n",
      "epoch0 step1400 [D loss: -0.388999] [G loss: -1.199557]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 3.960906\n",
      "FID: 97.088669\n",
      "0 = 14.612174255847911\n",
      "1 = 0.1341201139130693\n",
      "2 = 0.9775999784469604\n",
      "3 = 0.9702000021934509\n",
      "4 = 0.9850000143051147\n",
      "5 = 0.984774649143219\n",
      "6 = 0.9702000021934509\n",
      "7 = 11.705384196925216\n",
      "8 = 0.19020137304779147\n",
      "9 = 0.9514999985694885\n",
      "10 = 0.9459999799728394\n",
      "11 = 0.9570000171661377\n",
      "12 = 0.95652174949646\n",
      "13 = 0.9459999799728394\n",
      "14 = 3.960911750793457\n",
      "15 = 8.509407997131348\n",
      "16 = 0.3649572730064392\n",
      "17 = 3.9609060287475586\n",
      "18 = 97.08866882324219\n",
      "epoch0 step1405 [D loss: -0.563484] [G loss: -0.878006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 step1410 [D loss: -0.465714] [G loss: -1.283562]\n",
      "epoch0 step1415 [D loss: -0.310550] [G loss: -1.165498]\n",
      "epoch0 step1420 [D loss: -0.273928] [G loss: -0.974549]\n",
      "epoch0 step1425 [D loss: -0.661412] [G loss: -1.385921]\n",
      "epoch0 step1430 [D loss: -0.424219] [G loss: -1.334279]\n",
      "epoch0 step1435 [D loss: -0.344391] [G loss: -1.130371]\n",
      "epoch0 step1440 [D loss: -0.798385] [G loss: -0.957174]\n",
      "epoch0 step1445 [D loss: -0.829195] [G loss: -1.087317]\n",
      "epoch0 step1450 [D loss: -0.757093] [G loss: -0.903661]\n",
      "epoch0 step1455 [D loss: -0.487769] [G loss: -0.946820]\n",
      "epoch0 step1460 [D loss: -0.552816] [G loss: -1.082402]\n",
      "epoch0 step1465 [D loss: -0.584791] [G loss: -1.144234]\n",
      "epoch0 step1470 [D loss: -0.490917] [G loss: -0.918075]\n",
      "epoch0 step1475 [D loss: -0.430213] [G loss: -0.779956]\n",
      "epoch0 step1480 [D loss: -0.847761] [G loss: -0.542688]\n",
      "epoch0 step1485 [D loss: -0.488879] [G loss: -0.842749]\n",
      "epoch0 step1490 [D loss: -0.247949] [G loss: -0.527153]\n",
      "epoch0 step1495 [D loss: -0.478262] [G loss: -0.863151]\n",
      "epoch0 step1500 [D loss: -0.541830] [G loss: -0.383628]\n",
      "epoch0 step1505 [D loss: -0.490133] [G loss: -0.796097]\n",
      "epoch0 step1510 [D loss: -0.349525] [G loss: -0.638559]\n",
      "epoch0 step1515 [D loss: -0.563612] [G loss: -0.565446]\n",
      "epoch0 step1520 [D loss: -0.953138] [G loss: -0.800553]\n",
      "epoch0 step1525 [D loss: -0.651021] [G loss: -0.377223]\n",
      "epoch0 step1530 [D loss: -0.322054] [G loss: -0.384803]\n",
      "epoch0 step1535 [D loss: -0.244502] [G loss: -0.633521]\n",
      "epoch0 step1540 [D loss: -0.567514] [G loss: -0.310951]\n",
      "epoch0 step1545 [D loss: -0.472416] [G loss: -0.465264]\n",
      "epoch0 step1550 [D loss: -1.066718] [G loss: -0.259099]\n",
      "epoch0 step1555 [D loss: -0.244699] [G loss: -0.626035]\n",
      "epoch0 step1560 [D loss: -0.468036] [G loss: -0.075046]\n",
      "epoch0 step1565 [D loss: -0.667348] [G loss: -0.387914]\n",
      "epoch0 step1570 [D loss: 0.075876] [G loss: -0.488235]\n",
      "epoch0 step1575 [D loss: -1.238121] [G loss: -0.314692]\n",
      "epoch0 step1580 [D loss: -0.257528] [G loss: -0.507596]\n",
      "epoch0 step1585 [D loss: -0.846329] [G loss: -0.358930]\n",
      "epoch0 step1590 [D loss: -0.153914] [G loss: -0.726476]\n",
      "epoch0 step1595 [D loss: -0.304395] [G loss: -0.656840]\n",
      "epoch0 step1600 [D loss: -0.322122] [G loss: -0.742370]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 3.927664\n",
      "FID: 101.248123\n",
      "0 = 14.725083661937722\n",
      "1 = 0.12104156354067026\n",
      "2 = 0.9775999784469604\n",
      "3 = 0.9789999723434448\n",
      "4 = 0.9761999845504761\n",
      "5 = 0.9762664437294006\n",
      "6 = 0.9789999723434448\n",
      "7 = 11.82546096704003\n",
      "8 = 0.19688090966452798\n",
      "9 = 0.9495000243186951\n",
      "10 = 0.9441999793052673\n",
      "11 = 0.954800009727478\n",
      "12 = 0.954315721988678\n",
      "13 = 0.9441999793052673\n",
      "14 = 3.9276700019836426\n",
      "15 = 8.273444175720215\n",
      "16 = 0.38519909977912903\n",
      "17 = 3.927664279937744\n",
      "18 = 101.24812316894531\n",
      "epoch0 step1605 [D loss: -0.415199] [G loss: -0.565814]\n",
      "epoch0 step1610 [D loss: -0.316531] [G loss: -0.365618]\n",
      "epoch0 step1615 [D loss: -0.322429] [G loss: -0.702294]\n",
      "epoch0 step1620 [D loss: -0.525201] [G loss: -0.730293]\n",
      "epoch0 step1625 [D loss: -0.478496] [G loss: -0.562520]\n",
      "epoch0 step1630 [D loss: -0.474008] [G loss: -0.652671]\n",
      "epoch0 step1635 [D loss: -0.481965] [G loss: -0.483739]\n",
      "epoch0 step1640 [D loss: -0.606848] [G loss: -0.692512]\n",
      "epoch0 step1645 [D loss: -0.626707] [G loss: -0.712719]\n",
      "epoch0 step1650 [D loss: -0.400476] [G loss: -0.429201]\n",
      "epoch0 step1655 [D loss: -0.401192] [G loss: -0.494102]\n",
      "epoch0 step1660 [D loss: -0.343686] [G loss: -0.917082]\n",
      "epoch0 step1665 [D loss: -0.988505] [G loss: -1.061978]\n",
      "epoch0 step1670 [D loss: -0.987163] [G loss: -0.667084]\n",
      "epoch0 step1675 [D loss: -0.269914] [G loss: -1.021706]\n",
      "epoch0 step1680 [D loss: -0.345462] [G loss: -1.093209]\n",
      "epoch0 step1685 [D loss: -0.534845] [G loss: -0.972703]\n",
      "epoch0 step1690 [D loss: -0.466219] [G loss: -0.916662]\n",
      "epoch0 step1695 [D loss: -0.533526] [G loss: -1.374322]\n",
      "epoch0 step1700 [D loss: -0.591678] [G loss: -1.402268]\n",
      "epoch0 step1705 [D loss: -0.673408] [G loss: -1.397490]\n",
      "epoch0 step1710 [D loss: -0.362544] [G loss: -1.441454]\n",
      "epoch0 step1715 [D loss: -0.880463] [G loss: -1.496434]\n",
      "epoch0 step1720 [D loss: -0.273135] [G loss: -1.773156]\n",
      "epoch0 step1725 [D loss: -0.212052] [G loss: -1.659660]\n",
      "epoch0 step1730 [D loss: -0.838712] [G loss: -1.178499]\n",
      "epoch0 step1735 [D loss: -0.357644] [G loss: -1.549372]\n",
      "epoch0 step1740 [D loss: -0.668964] [G loss: -1.266410]\n",
      "epoch0 step1745 [D loss: -0.574565] [G loss: -1.390871]\n",
      "epoch0 step1750 [D loss: -0.137531] [G loss: -1.508378]\n",
      "epoch0 step1755 [D loss: -0.315198] [G loss: -1.246241]\n",
      "epoch0 step1760 [D loss: -0.850518] [G loss: -1.174557]\n",
      "epoch0 step1765 [D loss: -0.410478] [G loss: -1.062864]\n",
      "epoch0 step1770 [D loss: -0.088337] [G loss: -1.273560]\n",
      "epoch0 step1775 [D loss: -0.543398] [G loss: -0.959040]\n",
      "epoch0 step1780 [D loss: -0.486555] [G loss: -1.220465]\n",
      "epoch0 step1785 [D loss: -0.517064] [G loss: -1.244507]\n",
      "epoch0 step1790 [D loss: -0.330355] [G loss: -1.086775]\n",
      "epoch0 step1795 [D loss: -0.505549] [G loss: -1.256648]\n",
      "epoch0 step1800 [D loss: -0.789507] [G loss: -1.245298]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 3.999680\n",
      "FID: 96.861275\n",
      "0 = 14.028932930564862\n",
      "1 = 0.09856813028397274\n",
      "2 = 0.9679999947547913\n",
      "3 = 0.9588000178337097\n",
      "4 = 0.9771999716758728\n",
      "5 = 0.9767726063728333\n",
      "6 = 0.9588000178337097\n",
      "7 = 11.683683466291425\n",
      "8 = 0.1893631239588482\n",
      "9 = 0.9473000168800354\n",
      "10 = 0.9430000185966492\n",
      "11 = 0.9516000151634216\n",
      "12 = 0.9511801600456238\n",
      "13 = 0.9430000185966492\n",
      "14 = 3.9996843338012695\n",
      "15 = 8.394436836242676\n",
      "16 = 0.3762202560901642\n",
      "17 = 3.9996800422668457\n",
      "18 = 96.86127471923828\n",
      "epoch0 step1805 [D loss: -0.458812] [G loss: -1.314076]\n",
      "epoch0 step1810 [D loss: -0.909083] [G loss: -0.660255]\n",
      "epoch0 step1815 [D loss: -0.356056] [G loss: -0.797428]\n",
      "epoch0 step1820 [D loss: -0.365226] [G loss: -1.039673]\n",
      "epoch0 step1825 [D loss: -0.288043] [G loss: -0.334559]\n",
      "epoch0 step1830 [D loss: -0.161145] [G loss: -0.579557]\n",
      "epoch0 step1835 [D loss: -0.458921] [G loss: -0.620278]\n",
      "epoch0 step1840 [D loss: -0.658845] [G loss: -0.784476]\n",
      "epoch0 step1845 [D loss: -0.222510] [G loss: -0.848713]\n",
      "epoch0 step1850 [D loss: -0.523729] [G loss: -0.942322]\n",
      "epoch0 step1855 [D loss: -0.807550] [G loss: -0.620347]\n",
      "epoch0 step1860 [D loss: -0.578792] [G loss: -0.819236]\n",
      "epoch0 step1865 [D loss: -0.639682] [G loss: -0.701215]\n",
      "epoch0 step1870 [D loss: 0.118109] [G loss: -1.074708]\n",
      "epoch0 step1875 [D loss: 0.315482] [G loss: -0.917583]\n",
      "epoch0 step1880 [D loss: -0.294748] [G loss: -0.841422]\n",
      "epoch0 step1885 [D loss: -0.488258] [G loss: -0.663113]\n",
      "epoch0 step1890 [D loss: -0.779057] [G loss: -0.664839]\n",
      "epoch0 step1895 [D loss: -0.802054] [G loss: -0.499845]\n",
      "epoch0 step1900 [D loss: -0.191133] [G loss: -0.749842]\n",
      "epoch0 step1905 [D loss: -0.383770] [G loss: -0.309943]\n",
      "epoch0 step1910 [D loss: -0.617341] [G loss: -0.268805]\n",
      "epoch0 step1915 [D loss: -0.637218] [G loss: -0.295189]\n",
      "epoch0 step1920 [D loss: -0.684986] [G loss: -0.764315]\n",
      "epoch0 step1925 [D loss: -0.439109] [G loss: -0.191313]\n",
      "epoch0 step1930 [D loss: -0.079501] [G loss: -0.645814]\n",
      "epoch0 step1935 [D loss: -0.456564] [G loss: -0.137836]\n",
      "epoch0 step1940 [D loss: -0.346317] [G loss: -0.040864]\n",
      "epoch0 step1945 [D loss: -0.910343] [G loss: -0.197668]\n",
      "epoch0 step1950 [D loss: -0.818027] [G loss: 0.009008]\n",
      "epoch0 step1955 [D loss: -0.562735] [G loss: 0.321950]\n",
      "epoch0 step1960 [D loss: -0.234855] [G loss: 0.132028]\n",
      "epoch0 step1965 [D loss: -0.382834] [G loss: -0.141278]\n",
      "epoch0 step1970 [D loss: -0.597465] [G loss: 0.188586]\n",
      "epoch0 step1975 [D loss: -0.792889] [G loss: 0.152792]\n",
      "epoch0 step1980 [D loss: -0.317378] [G loss: 0.107805]\n",
      "epoch0 step1985 [D loss: -0.645548] [G loss: 0.274430]\n",
      "epoch0 step1990 [D loss: -0.824944] [G loss: 0.208975]\n",
      "epoch0 step1995 [D loss: -0.623910] [G loss: 0.547814]\n",
      "epoch0 step2000 [D loss: -0.015752] [G loss: -0.073360]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.037580\n",
      "FID: 97.599739\n",
      "0 = 14.281809815692935\n",
      "1 = 0.12842261012287315\n",
      "2 = 0.9725000262260437\n",
      "3 = 0.9611999988555908\n",
      "4 = 0.9837999939918518\n",
      "5 = 0.9834254384040833\n",
      "6 = 0.9611999988555908\n",
      "7 = 11.809691718959815\n",
      "8 = 0.19352052697020458\n",
      "9 = 0.9488999843597412\n",
      "10 = 0.944599986076355\n",
      "11 = 0.9531999826431274\n",
      "12 = 0.9527940154075623\n",
      "13 = 0.944599986076355\n",
      "14 = 4.037583351135254\n",
      "15 = 8.470505714416504\n",
      "16 = 0.36243870854377747\n",
      "17 = 4.0375800132751465\n",
      "18 = 97.59973907470703\n",
      "epoch0 step2005 [D loss: -0.864021] [G loss: 0.591234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 step2010 [D loss: -0.282721] [G loss: -0.204190]\n",
      "epoch0 step2015 [D loss: -0.591126] [G loss: 0.179190]\n",
      "epoch0 step2020 [D loss: -0.166222] [G loss: 0.239271]\n",
      "epoch0 step2025 [D loss: 0.394918] [G loss: 0.085497]\n",
      "epoch0 step2030 [D loss: 0.063247] [G loss: -0.104298]\n",
      "epoch0 step2035 [D loss: -0.286743] [G loss: -0.246512]\n",
      "epoch0 step2040 [D loss: -0.605959] [G loss: -0.061973]\n",
      "epoch0 step2045 [D loss: -0.823528] [G loss: -0.071987]\n",
      "epoch0 step2050 [D loss: -0.596568] [G loss: -0.237297]\n",
      "epoch0 step2055 [D loss: -0.408020] [G loss: -0.318417]\n",
      "epoch0 step2060 [D loss: -0.369097] [G loss: -0.329333]\n",
      "epoch0 step2065 [D loss: -0.186886] [G loss: -0.121474]\n",
      "epoch0 step2070 [D loss: -0.121133] [G loss: -0.557834]\n",
      "epoch0 step2075 [D loss: 0.009945] [G loss: -0.327242]\n",
      "epoch0 step2080 [D loss: 0.068555] [G loss: -0.696419]\n",
      "epoch0 step2085 [D loss: -0.308713] [G loss: -0.295815]\n",
      "epoch0 step2090 [D loss: 0.006519] [G loss: -0.264301]\n",
      "epoch0 step2095 [D loss: -0.669130] [G loss: -0.282640]\n",
      "epoch0 step2100 [D loss: -0.631213] [G loss: -0.384600]\n",
      "epoch0 step2105 [D loss: -0.017247] [G loss: -0.884132]\n",
      "epoch0 step2110 [D loss: -0.270739] [G loss: -0.839143]\n",
      "epoch0 step2115 [D loss: -0.171688] [G loss: -0.933027]\n",
      "epoch0 step2120 [D loss: -0.498025] [G loss: -0.954737]\n",
      "epoch0 step2125 [D loss: -0.036613] [G loss: -1.112339]\n",
      "epoch0 step2130 [D loss: -0.265465] [G loss: -0.723269]\n",
      "epoch0 step2135 [D loss: -0.271351] [G loss: -0.410479]\n",
      "epoch0 step2140 [D loss: -0.261066] [G loss: -0.595876]\n",
      "epoch0 step2145 [D loss: -0.676492] [G loss: -0.555059]\n",
      "epoch0 step2150 [D loss: -0.780923] [G loss: -1.008142]\n",
      "epoch0 step2155 [D loss: -0.508488] [G loss: -0.731928]\n",
      "epoch0 step2160 [D loss: -0.091556] [G loss: -0.404296]\n",
      "epoch0 step2165 [D loss: -0.364405] [G loss: -0.783172]\n",
      "epoch0 step2170 [D loss: -1.104978] [G loss: -0.724717]\n",
      "epoch0 step2175 [D loss: -0.529262] [G loss: -0.793864]\n",
      "epoch0 step2180 [D loss: -0.306857] [G loss: -0.788643]\n",
      "epoch0 step2185 [D loss: -0.117240] [G loss: -0.632177]\n",
      "epoch0 step2190 [D loss: -0.836986] [G loss: -1.011586]\n",
      "epoch0 step2195 [D loss: -0.201923] [G loss: -0.674300]\n",
      "epoch0 step2200 [D loss: -0.753506] [G loss: -0.933955]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 3.382255\n",
      "FID: 120.672562\n",
      "0 = 14.106872222614243\n",
      "1 = 0.17031429184837218\n",
      "2 = 0.9772999882698059\n",
      "3 = 0.9646000266075134\n",
      "4 = 0.9900000095367432\n",
      "5 = 0.9897393584251404\n",
      "6 = 0.9646000266075134\n",
      "7 = 12.568850035333632\n",
      "8 = 0.21465529065564054\n",
      "9 = 0.9605000019073486\n",
      "10 = 0.9527999758720398\n",
      "11 = 0.9682000279426575\n",
      "12 = 0.9677026271820068\n",
      "13 = 0.9527999758720398\n",
      "14 = 3.3822576999664307\n",
      "15 = 7.551697731018066\n",
      "16 = 0.472391813993454\n",
      "17 = 3.3822550773620605\n",
      "18 = 120.67256164550781\n",
      "epoch0 step2205 [D loss: -1.511407] [G loss: -0.662304]\n",
      "epoch0 step2210 [D loss: -0.885748] [G loss: -0.926971]\n",
      "epoch0 step2215 [D loss: -0.459196] [G loss: -0.994021]\n",
      "epoch0 step2220 [D loss: -0.380957] [G loss: -1.052412]\n",
      "epoch0 step2225 [D loss: -1.113579] [G loss: -0.574368]\n",
      "epoch0 step2230 [D loss: -1.115002] [G loss: -0.895357]\n",
      "epoch0 step2235 [D loss: -0.335904] [G loss: -1.010286]\n",
      "epoch0 step2240 [D loss: 0.025812] [G loss: -1.534857]\n",
      "epoch0 step2245 [D loss: 0.129759] [G loss: -1.093499]\n",
      "epoch0 step2250 [D loss: 0.137041] [G loss: -0.924480]\n",
      "epoch0 step2255 [D loss: -0.293267] [G loss: -0.687121]\n",
      "epoch0 step2260 [D loss: -1.110530] [G loss: -1.198279]\n",
      "epoch0 step2265 [D loss: -0.275647] [G loss: -0.720610]\n",
      "epoch0 step2270 [D loss: 0.009508] [G loss: -1.146374]\n",
      "epoch0 step2275 [D loss: -0.659358] [G loss: -1.269626]\n",
      "epoch0 step2280 [D loss: -0.542209] [G loss: -1.353141]\n",
      "epoch0 step2285 [D loss: -0.404834] [G loss: -0.763313]\n",
      "epoch0 step2290 [D loss: -1.154352] [G loss: -1.119962]\n",
      "epoch0 step2295 [D loss: -0.949644] [G loss: -0.719457]\n",
      "epoch0 step2300 [D loss: -1.132000] [G loss: -0.974333]\n",
      "epoch0 step2305 [D loss: -1.166862] [G loss: -0.975668]\n",
      "epoch0 step2310 [D loss: -0.853081] [G loss: -0.885352]\n",
      "epoch0 step2315 [D loss: -1.481756] [G loss: -0.830772]\n",
      "epoch0 step2320 [D loss: -1.299681] [G loss: -0.590849]\n",
      "epoch0 step2325 [D loss: -0.562658] [G loss: -0.616722]\n",
      "epoch0 step2330 [D loss: -0.336102] [G loss: -0.546159]\n",
      "epoch0 step2335 [D loss: -0.373361] [G loss: -0.471820]\n",
      "epoch0 step2340 [D loss: -0.226285] [G loss: -0.698172]\n",
      "epoch0 step2345 [D loss: -0.140810] [G loss: -0.901146]\n",
      "epoch0 step2350 [D loss: 0.325695] [G loss: -0.955990]\n",
      "epoch0 step2355 [D loss: -0.361412] [G loss: -0.701050]\n",
      "epoch0 step2360 [D loss: 0.527431] [G loss: -1.358108]\n",
      "epoch0 step2365 [D loss: 0.026285] [G loss: -0.877577]\n",
      "epoch0 step2370 [D loss: -0.546649] [G loss: -0.808474]\n",
      "epoch0 step2375 [D loss: 0.004120] [G loss: -1.192364]\n",
      "epoch0 step2380 [D loss: -0.389292] [G loss: -0.984513]\n",
      "epoch0 step2385 [D loss: -0.194455] [G loss: -1.024988]\n",
      "epoch0 step2390 [D loss: -0.612486] [G loss: -0.838774]\n",
      "epoch0 step2395 [D loss: -0.617469] [G loss: -1.252998]\n",
      "epoch0 step2400 [D loss: -0.220856] [G loss: -1.391907]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 3.769615\n",
      "FID: 102.043739\n",
      "0 = 14.016625995922098\n",
      "1 = 0.07288405279395736\n",
      "2 = 0.9707000255584717\n",
      "3 = 0.9666000008583069\n",
      "4 = 0.9747999906539917\n",
      "5 = 0.9745916724205017\n",
      "6 = 0.9666000008583069\n",
      "7 = 11.907803945374463\n",
      "8 = 0.20033757807105967\n",
      "9 = 0.9402999877929688\n",
      "10 = 0.9413999915122986\n",
      "11 = 0.9391999840736389\n",
      "12 = 0.939333438873291\n",
      "13 = 0.9413999915122986\n",
      "14 = 3.769620180130005\n",
      "15 = 7.555245399475098\n",
      "16 = 0.4548787474632263\n",
      "17 = 3.769615411758423\n",
      "18 = 102.04373931884766\n",
      "epoch0 step2405 [D loss: -0.038882] [G loss: -1.421913]\n",
      "epoch0 step2410 [D loss: -0.166060] [G loss: -0.864291]\n",
      "epoch0 step2415 [D loss: -0.281771] [G loss: -1.493970]\n",
      "epoch0 step2420 [D loss: -0.099530] [G loss: -1.488044]\n",
      "epoch0 step2425 [D loss: -0.466832] [G loss: -1.436667]\n",
      "epoch0 step2430 [D loss: -0.252174] [G loss: -1.051786]\n",
      "epoch0 step2435 [D loss: -0.232683] [G loss: -1.179392]\n",
      "epoch0 step2440 [D loss: -0.989798] [G loss: -0.903509]\n",
      "epoch0 step2445 [D loss: -0.369236] [G loss: -1.427163]\n",
      "epoch0 step2450 [D loss: -0.481559] [G loss: -1.299771]\n",
      "epoch0 step2455 [D loss: -0.390941] [G loss: -1.161920]\n",
      "epoch0 step2460 [D loss: -0.432363] [G loss: -1.282142]\n",
      "epoch0 step2465 [D loss: -0.952005] [G loss: -0.758141]\n",
      "epoch0 step2470 [D loss: -0.495726] [G loss: -1.130318]\n",
      "epoch0 step2475 [D loss: -0.432549] [G loss: -0.877086]\n",
      "epoch0 step2480 [D loss: -0.218396] [G loss: -1.154352]\n",
      "epoch0 step2485 [D loss: -0.032198] [G loss: -1.426634]\n",
      "epoch0 step2490 [D loss: -0.547569] [G loss: -1.139227]\n",
      "epoch0 step2495 [D loss: -0.401190] [G loss: -1.071074]\n",
      "epoch0 step2500 [D loss: -1.140178] [G loss: -0.888321]\n",
      "epoch0 step2505 [D loss: -0.084515] [G loss: -1.508386]\n",
      "epoch0 step2510 [D loss: -0.505364] [G loss: -1.540406]\n",
      "epoch0 step2515 [D loss: -0.955476] [G loss: -1.184862]\n",
      "epoch0 step2520 [D loss: -0.560099] [G loss: -1.330118]\n",
      "epoch0 step2525 [D loss: -0.316830] [G loss: -1.994368]\n",
      "epoch0 step2530 [D loss: -0.622542] [G loss: -1.516569]\n",
      "epoch0 step2535 [D loss: -0.177304] [G loss: -1.365951]\n",
      "epoch0 step2540 [D loss: -0.381210] [G loss: -1.435907]\n",
      "epoch0 step2545 [D loss: -0.840369] [G loss: -1.713934]\n",
      "epoch0 step2550 [D loss: -0.515743] [G loss: -1.509789]\n",
      "epoch0 step2555 [D loss: -0.580383] [G loss: -1.772314]\n",
      "epoch0 step2560 [D loss: -0.070778] [G loss: -1.787199]\n",
      "epoch0 step2565 [D loss: -0.687968] [G loss: -1.685530]\n",
      "epoch0 step2570 [D loss: -0.759217] [G loss: -2.047853]\n",
      "epoch0 step2575 [D loss: -0.387948] [G loss: -1.179123]\n",
      "epoch0 step2580 [D loss: -0.839496] [G loss: -1.928322]\n",
      "epoch0 step2585 [D loss: -0.798433] [G loss: -1.791690]\n",
      "epoch0 step2590 [D loss: -0.126957] [G loss: -1.707744]\n",
      "epoch0 step2595 [D loss: -0.632265] [G loss: -1.673471]\n",
      "epoch0 step2600 [D loss: -0.470523] [G loss: -2.039528]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.111097\n",
      "FID: 87.855202\n",
      "0 = 14.327683418846116\n",
      "1 = 0.09615050089959068\n",
      "2 = 0.9642999768257141\n",
      "3 = 0.973800003528595\n",
      "4 = 0.954800009727478\n",
      "5 = 0.9556427597999573\n",
      "6 = 0.973800003528595\n",
      "7 = 11.41193917906287\n",
      "8 = 0.1845638536402961\n",
      "9 = 0.9323999881744385\n",
      "10 = 0.9297999739646912\n",
      "11 = 0.9350000023841858\n",
      "12 = 0.9346602559089661\n",
      "13 = 0.9297999739646912\n",
      "14 = 4.111104488372803\n",
      "15 = 7.810150146484375\n",
      "16 = 0.41240593791007996\n",
      "17 = 4.1110968589782715\n",
      "18 = 87.8552017211914\n",
      "epoch0 step2605 [D loss: -0.509024] [G loss: -1.968374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 step2610 [D loss: -0.844105] [G loss: -1.961184]\n",
      "epoch0 step2615 [D loss: -0.198937] [G loss: -1.642418]\n",
      "epoch0 step2620 [D loss: -0.060203] [G loss: -2.226908]\n",
      "epoch0 step2625 [D loss: -0.454661] [G loss: -1.719127]\n",
      "epoch0 step2630 [D loss: -1.012418] [G loss: -1.749717]\n",
      "epoch0 step2635 [D loss: -0.648602] [G loss: -1.563096]\n",
      "epoch0 step2640 [D loss: -0.864950] [G loss: -1.848117]\n",
      "epoch0 step2645 [D loss: -0.286519] [G loss: -1.869347]\n",
      "epoch0 step2650 [D loss: 0.206637] [G loss: -1.912305]\n",
      "epoch0 step2655 [D loss: -0.652979] [G loss: -1.394679]\n",
      "epoch0 step2660 [D loss: -0.237732] [G loss: -1.763617]\n",
      "epoch0 step2665 [D loss: -0.321033] [G loss: -2.181756]\n",
      "epoch0 step2670 [D loss: -0.255168] [G loss: -1.766015]\n",
      "epoch0 step2675 [D loss: -0.094252] [G loss: -1.848352]\n",
      "epoch0 step2680 [D loss: 0.399284] [G loss: -1.961957]\n",
      "epoch0 step2685 [D loss: -0.355976] [G loss: -1.984473]\n",
      "epoch0 step2690 [D loss: -0.266450] [G loss: -1.771107]\n",
      "epoch0 step2695 [D loss: -0.828660] [G loss: -1.438461]\n",
      "epoch0 step2700 [D loss: -0.194197] [G loss: -1.817912]\n",
      "epoch0 step2705 [D loss: -0.482183] [G loss: -2.242423]\n",
      "epoch0 step2710 [D loss: -0.882269] [G loss: -1.544272]\n",
      "epoch0 step2715 [D loss: -0.301127] [G loss: -1.831436]\n",
      "epoch0 step2720 [D loss: -0.602004] [G loss: -1.602646]\n",
      "epoch0 step2725 [D loss: -0.304867] [G loss: -1.757354]\n",
      "epoch0 step2730 [D loss: -0.577857] [G loss: -1.769301]\n",
      "epoch0 step2735 [D loss: -0.262619] [G loss: -1.676337]\n",
      "epoch0 step2740 [D loss: -0.682696] [G loss: -1.982495]\n",
      "epoch0 step2745 [D loss: 0.132806] [G loss: -1.844140]\n",
      "epoch0 step2750 [D loss: -0.514066] [G loss: -1.957092]\n",
      "epoch0 step2755 [D loss: -0.193753] [G loss: -1.741254]\n",
      "epoch0 step2760 [D loss: 0.203992] [G loss: -1.340284]\n",
      "epoch0 step2765 [D loss: -0.498324] [G loss: -1.116012]\n",
      "epoch0 step2770 [D loss: -0.683119] [G loss: -1.541613]\n",
      "epoch0 step2775 [D loss: -0.256334] [G loss: -1.074325]\n",
      "epoch0 step2780 [D loss: -0.180678] [G loss: -1.275937]\n",
      "epoch0 step2785 [D loss: -0.747037] [G loss: -1.334176]\n",
      "epoch0 step2790 [D loss: -0.782011] [G loss: -1.271152]\n",
      "epoch0 step2795 [D loss: -0.282068] [G loss: -1.317408]\n",
      "epoch0 step2800 [D loss: -0.604793] [G loss: -1.192783]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 3.920766\n",
      "FID: 94.209061\n",
      "0 = 13.861011288070644\n",
      "1 = 0.10671989652540004\n",
      "2 = 0.9688000082969666\n",
      "3 = 0.9621999859809875\n",
      "4 = 0.9753999710083008\n",
      "5 = 0.9750709533691406\n",
      "6 = 0.9621999859809875\n",
      "7 = 11.67424879746436\n",
      "8 = 0.18851387563779862\n",
      "9 = 0.9408000111579895\n",
      "10 = 0.9366000294685364\n",
      "11 = 0.9449999928474426\n",
      "12 = 0.9445340633392334\n",
      "13 = 0.9366000294685364\n",
      "14 = 3.92077374458313\n",
      "15 = 7.993536949157715\n",
      "16 = 0.40717267990112305\n",
      "17 = 3.9207661151885986\n",
      "18 = 94.20906066894531\n",
      "epoch0 step2805 [D loss: -0.644310] [G loss: -1.307382]\n",
      "epoch0 step2810 [D loss: -0.282121] [G loss: -1.619637]\n",
      "epoch0 step2815 [D loss: -0.329738] [G loss: -1.489991]\n",
      "epoch0 step2820 [D loss: -0.371133] [G loss: -1.751774]\n",
      "epoch0 step2825 [D loss: -1.011133] [G loss: -1.636700]\n",
      "epoch0 step2830 [D loss: -0.423683] [G loss: -1.859910]\n",
      "epoch0 step2835 [D loss: -0.868968] [G loss: -1.356911]\n",
      "epoch0 step2840 [D loss: -0.959811] [G loss: -1.787944]\n",
      "epoch0 step2845 [D loss: -0.915863] [G loss: -1.594921]\n",
      "epoch0 step2850 [D loss: -0.484106] [G loss: -1.470553]\n",
      "epoch0 step2855 [D loss: -0.713484] [G loss: -1.288835]\n",
      "epoch0 step2860 [D loss: -0.829650] [G loss: -1.756132]\n",
      "epoch0 step2865 [D loss: -0.753119] [G loss: -1.895758]\n",
      "epoch0 step2870 [D loss: -0.569290] [G loss: -1.860184]\n",
      "epoch0 step2875 [D loss: -0.787338] [G loss: -2.281648]\n",
      "epoch0 step2880 [D loss: -0.162895] [G loss: -1.783831]\n",
      "epoch0 step2885 [D loss: -0.809352] [G loss: -1.594553]\n",
      "epoch0 step2890 [D loss: -1.010682] [G loss: -1.467107]\n",
      "epoch0 step2895 [D loss: -0.236501] [G loss: -2.256904]\n",
      "epoch0 step2900 [D loss: -0.484045] [G loss: -1.498413]\n",
      "epoch0 step2905 [D loss: -0.319673] [G loss: -1.640046]\n",
      "epoch0 step2910 [D loss: -0.056964] [G loss: -1.700805]\n",
      "epoch0 step2915 [D loss: -0.135030] [G loss: -1.220369]\n",
      "epoch0 step2920 [D loss: -0.769022] [G loss: -1.202646]\n",
      "epoch0 step2925 [D loss: -0.535098] [G loss: -1.320857]\n",
      "epoch0 step2930 [D loss: -0.802276] [G loss: -1.206318]\n",
      "epoch0 step2935 [D loss: -0.435117] [G loss: -1.301618]\n",
      "epoch0 step2940 [D loss: -0.806128] [G loss: -0.799527]\n",
      "epoch0 step2945 [D loss: -0.204654] [G loss: -1.058292]\n",
      "epoch0 step2950 [D loss: 0.544347] [G loss: -0.854429]\n",
      "epoch0 step2955 [D loss: -0.822705] [G loss: -1.108240]\n",
      "epoch0 step2960 [D loss: -0.699496] [G loss: -0.805330]\n",
      "epoch0 step2965 [D loss: -0.099743] [G loss: -0.739106]\n",
      "epoch0 step2970 [D loss: -0.034699] [G loss: -0.799144]\n",
      "epoch0 step2975 [D loss: -0.424967] [G loss: -0.625782]\n",
      "epoch0 step2980 [D loss: -0.514356] [G loss: -0.428154]\n",
      "epoch0 step2985 [D loss: -0.631783] [G loss: -0.098616]\n",
      "epoch0 step2990 [D loss: -0.990282] [G loss: -0.382953]\n",
      "epoch0 step2995 [D loss: -1.188175] [G loss: -0.680558]\n",
      "epoch0 step3000 [D loss: -0.933348] [G loss: -0.318901]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 3.804458\n",
      "FID: 95.577347\n",
      "0 = 13.758373279190025\n",
      "1 = 0.09498105813968633\n",
      "2 = 0.965399980545044\n",
      "3 = 0.9656000137329102\n",
      "4 = 0.9652000069618225\n",
      "5 = 0.9652138948440552\n",
      "6 = 0.9656000137329102\n",
      "7 = 11.676318515062354\n",
      "8 = 0.19062302385150132\n",
      "9 = 0.9372000098228455\n",
      "10 = 0.9327999949455261\n",
      "11 = 0.9416000247001648\n",
      "12 = 0.9410815238952637\n",
      "13 = 0.9327999949455261\n",
      "14 = 3.8044629096984863\n",
      "15 = 7.990164279937744\n",
      "16 = 0.4109019339084625\n",
      "17 = 3.8044581413269043\n",
      "18 = 95.57734680175781\n",
      "epoch0 step3005 [D loss: -0.621743] [G loss: 0.202049]\n",
      "epoch0 step3010 [D loss: -0.404386] [G loss: -0.637052]\n",
      "epoch0 step3015 [D loss: -0.803553] [G loss: -0.214310]\n",
      "epoch0 step3020 [D loss: -0.319295] [G loss: -0.500266]\n",
      "epoch0 step3025 [D loss: -0.882110] [G loss: 0.159793]\n",
      "epoch0 step3030 [D loss: -0.889379] [G loss: -0.066102]\n",
      "epoch0 step3035 [D loss: -1.231575] [G loss: -0.088272]\n",
      "epoch0 step3040 [D loss: -0.786755] [G loss: 0.044771]\n",
      "epoch0 step3045 [D loss: -0.871015] [G loss: -0.019165]\n",
      "epoch0 step3050 [D loss: -0.781148] [G loss: -0.447629]\n",
      "epoch0 step3055 [D loss: -0.434098] [G loss: -0.152473]\n",
      "epoch0 step3060 [D loss: -0.509242] [G loss: -0.203995]\n",
      "epoch0 step3065 [D loss: -0.419034] [G loss: -0.601060]\n",
      "epoch0 step3070 [D loss: -0.611572] [G loss: -0.214141]\n",
      "epoch0 step3075 [D loss: -0.322337] [G loss: -0.782568]\n",
      "epoch0 step3080 [D loss: -0.602711] [G loss: -0.578214]\n",
      "epoch0 step3085 [D loss: -0.427046] [G loss: -0.822250]\n",
      "epoch0 step3090 [D loss: -0.248624] [G loss: -0.591025]\n",
      "epoch0 step3095 [D loss: -0.449659] [G loss: -0.738451]\n",
      "epoch0 step3100 [D loss: -0.398533] [G loss: -0.207357]\n",
      "epoch0 step3105 [D loss: -0.840244] [G loss: -0.542637]\n",
      "epoch0 step3110 [D loss: -0.183385] [G loss: -0.566684]\n",
      "epoch0 step3115 [D loss: -1.054591] [G loss: -0.257913]\n",
      "epoch0 step3120 [D loss: -0.934834] [G loss: 0.310170]\n",
      "epoch0 step3125 [D loss: -0.852727] [G loss: -0.015434]\n",
      "epoch0 step3130 [D loss: -1.324361] [G loss: 0.084338]\n",
      "epoch0 step3135 [D loss: -0.551199] [G loss: 0.557502]\n",
      "epoch0 step3140 [D loss: -1.076078] [G loss: 0.574081]\n",
      "epoch0 step3145 [D loss: -1.445558] [G loss: 0.074591]\n",
      "epoch0 step3150 [D loss: -0.539329] [G loss: 0.716887]\n",
      "epoch0 step3155 [D loss: -0.315740] [G loss: 0.367308]\n",
      "epoch0 step3160 [D loss: -0.138056] [G loss: 0.294357]\n",
      "epoch0 step3165 [D loss: -0.729728] [G loss: 0.121049]\n",
      "epoch0 step3170 [D loss: -1.172897] [G loss: 0.157437]\n",
      "epoch0 step3175 [D loss: -0.220361] [G loss: -0.596068]\n",
      "epoch0 step3180 [D loss: -0.551177] [G loss: -0.255842]\n",
      "epoch0 step3185 [D loss: -0.728097] [G loss: -0.039903]\n",
      "epoch0 step3190 [D loss: -0.616211] [G loss: -0.666043]\n",
      "epoch0 step3195 [D loss: -0.321644] [G loss: -0.684471]\n",
      "epoch0 step3200 [D loss: -1.033615] [G loss: -1.207515]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 3.951380\n",
      "FID: 89.738815\n",
      "0 = 14.105760183906545\n",
      "1 = 0.09198692614499086\n",
      "2 = 0.9629999995231628\n",
      "3 = 0.9746000170707703\n",
      "4 = 0.9513999819755554\n",
      "5 = 0.9525019526481628\n",
      "6 = 0.9746000170707703\n",
      "7 = 11.519197222423566\n",
      "8 = 0.18432180639491114\n",
      "9 = 0.9376999735832214\n",
      "10 = 0.9336000084877014\n",
      "11 = 0.9417999982833862\n",
      "12 = 0.9413188099861145\n",
      "13 = 0.9336000084877014\n",
      "14 = 3.9513885974884033\n",
      "15 = 7.93726110458374\n",
      "16 = 0.40591034293174744\n",
      "17 = 3.9513795375823975\n",
      "18 = 89.73881530761719\n",
      "epoch0 step3205 [D loss: -1.056141] [G loss: -1.216066]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 step3210 [D loss: -1.149368] [G loss: -1.283164]\n",
      "epoch0 step3215 [D loss: -0.322808] [G loss: -1.505106]\n",
      "epoch0 step3220 [D loss: -1.256150] [G loss: -1.465406]\n",
      "epoch0 step3225 [D loss: -0.903989] [G loss: -1.374872]\n",
      "epoch0 step3230 [D loss: -0.130987] [G loss: -1.886298]\n",
      "epoch0 step3235 [D loss: -1.114407] [G loss: -1.288350]\n",
      "epoch0 step3240 [D loss: -0.632636] [G loss: -1.769303]\n",
      "epoch0 step3245 [D loss: -0.852608] [G loss: -1.817445]\n",
      "epoch0 step3250 [D loss: -0.817398] [G loss: -2.158550]\n",
      "epoch0 step3255 [D loss: -0.547575] [G loss: -1.798521]\n",
      "epoch0 step3260 [D loss: -0.958225] [G loss: -1.881314]\n",
      "epoch0 step3265 [D loss: -0.328548] [G loss: -2.369484]\n",
      "epoch0 step3270 [D loss: -0.610558] [G loss: -2.513603]\n",
      "epoch0 step3275 [D loss: -0.591295] [G loss: -2.412993]\n",
      "epoch0 step3280 [D loss: -1.060766] [G loss: -1.533234]\n",
      "epoch0 step3285 [D loss: -0.655815] [G loss: -1.947153]\n",
      "epoch0 step3290 [D loss: -0.321680] [G loss: -2.226055]\n",
      "epoch0 step3295 [D loss: -0.512300] [G loss: -2.062369]\n",
      "epoch0 step3300 [D loss: -0.024374] [G loss: -2.785874]\n",
      "epoch0 step3305 [D loss: -0.813318] [G loss: -2.500294]\n",
      "epoch0 step3310 [D loss: -0.919811] [G loss: -2.030579]\n",
      "epoch0 step3315 [D loss: -0.366438] [G loss: -1.754626]\n",
      "epoch0 step3320 [D loss: -0.211407] [G loss: -1.933859]\n",
      "epoch0 step3325 [D loss: -0.703982] [G loss: -1.578560]\n",
      "epoch0 step3330 [D loss: -0.376863] [G loss: -2.272432]\n",
      "epoch0 step3335 [D loss: -0.502584] [G loss: -1.630441]\n",
      "epoch0 step3340 [D loss: -0.137289] [G loss: -1.424336]\n",
      "epoch0 step3345 [D loss: -0.959612] [G loss: -0.972631]\n",
      "epoch0 step3350 [D loss: -0.386776] [G loss: -1.370559]\n",
      "epoch0 step3355 [D loss: -0.086395] [G loss: -1.210867]\n",
      "epoch0 step3360 [D loss: -0.680768] [G loss: -0.967568]\n",
      "epoch0 step3365 [D loss: -1.252263] [G loss: -0.735606]\n",
      "epoch0 step3370 [D loss: -0.749256] [G loss: -1.186354]\n",
      "epoch0 step3375 [D loss: -0.859210] [G loss: -1.261209]\n",
      "epoch0 step3380 [D loss: -0.423965] [G loss: -0.962872]\n",
      "epoch0 step3385 [D loss: -0.718119] [G loss: -0.722599]\n",
      "epoch0 step3390 [D loss: -0.291025] [G loss: -1.291869]\n",
      "epoch0 step3395 [D loss: -0.418574] [G loss: -1.363393]\n",
      "epoch0 step3400 [D loss: -1.153628] [G loss: -0.864657]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 3.738034\n",
      "FID: 100.517830\n",
      "0 = 13.997232443428032\n",
      "1 = 0.09913552465763979\n",
      "2 = 0.957099974155426\n",
      "3 = 0.97079998254776\n",
      "4 = 0.9434000253677368\n",
      "5 = 0.9449094533920288\n",
      "6 = 0.97079998254776\n",
      "7 = 11.827416797995618\n",
      "8 = 0.21000379967657984\n",
      "9 = 0.9276999831199646\n",
      "10 = 0.9312000274658203\n",
      "11 = 0.9241999983787537\n",
      "12 = 0.9247269034385681\n",
      "13 = 0.9312000274658203\n",
      "14 = 3.738036870956421\n",
      "15 = 7.088494300842285\n",
      "16 = 0.4784705340862274\n",
      "17 = 3.7380340099334717\n",
      "18 = 100.51782989501953\n",
      "epoch0 step3405 [D loss: -0.919095] [G loss: -0.829181]\n",
      "epoch0 step3410 [D loss: -0.722733] [G loss: -1.030932]\n",
      "epoch0 step3415 [D loss: -1.060619] [G loss: -0.728217]\n",
      "epoch0 step3420 [D loss: -0.718725] [G loss: -1.335291]\n",
      "epoch0 step3425 [D loss: -0.943165] [G loss: -0.972629]\n",
      "epoch0 step3430 [D loss: -0.820610] [G loss: -0.799734]\n",
      "epoch0 step3435 [D loss: -1.097746] [G loss: -0.674328]\n",
      "epoch0 step3440 [D loss: -1.252207] [G loss: -0.752755]\n",
      "epoch0 step3445 [D loss: -0.979534] [G loss: -0.824483]\n",
      "epoch0 step3450 [D loss: -1.047075] [G loss: -1.191675]\n",
      "epoch0 step3455 [D loss: -1.375816] [G loss: -0.995362]\n",
      "epoch0 step3460 [D loss: -0.933372] [G loss: -0.685817]\n",
      "epoch0 step3465 [D loss: -1.637461] [G loss: -0.750350]\n",
      "epoch0 step3470 [D loss: -0.906213] [G loss: -0.565207]\n",
      "epoch0 step3475 [D loss: -1.389413] [G loss: 0.113643]\n",
      "epoch0 step3480 [D loss: -0.162257] [G loss: -0.692096]\n",
      "epoch0 step3485 [D loss: 0.534313] [G loss: -0.984501]\n",
      "epoch0 step3490 [D loss: -0.251747] [G loss: -0.772448]\n",
      "epoch0 step3495 [D loss: -0.600350] [G loss: -0.771942]\n",
      "epoch0 step3500 [D loss: -0.390005] [G loss: -1.263871]\n",
      "epoch0 step3505 [D loss: -0.570480] [G loss: -1.198040]\n",
      "epoch0 step3510 [D loss: -0.275177] [G loss: -0.814320]\n",
      "epoch0 step3515 [D loss: -0.434000] [G loss: -0.831068]\n",
      "epoch0 step3520 [D loss: -0.233556] [G loss: -1.120181]\n",
      "epoch0 step3525 [D loss: -0.082934] [G loss: -1.010666]\n",
      "epoch0 step3530 [D loss: -0.790008] [G loss: -0.876172]\n",
      "epoch0 step3535 [D loss: -0.849323] [G loss: -1.182770]\n",
      "epoch0 step3540 [D loss: -0.460979] [G loss: -1.262112]\n",
      "epoch0 step3545 [D loss: -0.859642] [G loss: -1.122617]\n",
      "epoch0 step3550 [D loss: -0.491552] [G loss: -1.336406]\n",
      "epoch0 step3555 [D loss: -0.513092] [G loss: -1.375703]\n",
      "epoch0 step3560 [D loss: -0.834311] [G loss: -1.738960]\n",
      "epoch0 step3565 [D loss: -0.738728] [G loss: -1.791483]\n",
      "epoch0 step3570 [D loss: -0.897139] [G loss: -1.493652]\n",
      "epoch0 step3575 [D loss: -0.916726] [G loss: -2.167991]\n",
      "epoch0 step3580 [D loss: -0.815093] [G loss: -1.506229]\n",
      "epoch0 step3585 [D loss: -0.998088] [G loss: -1.993290]\n",
      "epoch0 step3590 [D loss: -1.312912] [G loss: -1.290962]\n",
      "epoch0 step3595 [D loss: -1.197257] [G loss: -1.565485]\n",
      "epoch0 step3600 [D loss: -0.768217] [G loss: -1.893419]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.359816\n",
      "FID: 75.394478\n",
      "0 = 14.722874435138737\n",
      "1 = 0.11635599779801545\n",
      "2 = 0.9469000101089478\n",
      "3 = 0.9768000245094299\n",
      "4 = 0.9169999957084656\n",
      "5 = 0.9216833114624023\n",
      "6 = 0.9768000245094299\n",
      "7 = 10.837172971343975\n",
      "8 = 0.17213662782397834\n",
      "9 = 0.9114000201225281\n",
      "10 = 0.9146000146865845\n",
      "11 = 0.9082000255584717\n",
      "12 = 0.9087837934494019\n",
      "13 = 0.9146000146865845\n",
      "14 = 4.35982608795166\n",
      "15 = 7.751768112182617\n",
      "16 = 0.3843839764595032\n",
      "17 = 4.359816074371338\n",
      "18 = 75.39447784423828\n",
      "epoch0 step3605 [D loss: -1.119047] [G loss: -1.649935]\n",
      "epoch0 step3610 [D loss: -0.327529] [G loss: -1.725984]\n",
      "epoch0 step3615 [D loss: -0.706864] [G loss: -1.808570]\n",
      "epoch0 step3620 [D loss: -0.723386] [G loss: -1.447508]\n",
      "epoch0 step3625 [D loss: -0.751498] [G loss: -1.785019]\n",
      "epoch0 step3630 [D loss: -0.221820] [G loss: -1.604223]\n",
      "epoch0 step3635 [D loss: -1.120440] [G loss: -1.473275]\n",
      "epoch0 step3640 [D loss: -0.606722] [G loss: -2.234263]\n",
      "epoch0 step3645 [D loss: -0.391443] [G loss: -1.827917]\n",
      "epoch0 step3650 [D loss: -0.147241] [G loss: -1.431912]\n",
      "epoch0 step3655 [D loss: -0.761209] [G loss: -1.317882]\n",
      "epoch0 step3660 [D loss: -0.953189] [G loss: -1.332159]\n",
      "epoch0 step3665 [D loss: -0.895046] [G loss: -1.245242]\n",
      "epoch0 step3670 [D loss: -0.346390] [G loss: -1.223348]\n",
      "epoch0 step3675 [D loss: -0.932476] [G loss: -1.433836]\n",
      "epoch0 step3680 [D loss: -1.212232] [G loss: -1.100171]\n",
      "epoch0 step3685 [D loss: -0.459057] [G loss: -1.034488]\n",
      "epoch0 step3690 [D loss: 0.020379] [G loss: -1.532396]\n",
      "epoch0 step3695 [D loss: -1.020748] [G loss: -1.084369]\n",
      "epoch0 step3700 [D loss: -0.548937] [G loss: -1.099198]\n",
      "epoch0 step3705 [D loss: -1.260583] [G loss: -1.295080]\n",
      "epoch0 step3710 [D loss: -0.181992] [G loss: -0.765786]\n",
      "epoch0 step3715 [D loss: -1.245337] [G loss: -0.911377]\n",
      "epoch0 step3720 [D loss: -0.630672] [G loss: -1.583817]\n",
      "epoch0 step3725 [D loss: -0.202319] [G loss: -1.481672]\n",
      "epoch0 step3730 [D loss: -0.338196] [G loss: -1.159524]\n",
      "epoch0 step3735 [D loss: -0.675710] [G loss: -1.424108]\n",
      "epoch0 step3740 [D loss: -1.237411] [G loss: -1.339644]\n",
      "epoch0 step3745 [D loss: -1.345833] [G loss: -1.537124]\n",
      "epoch0 step3750 [D loss: -0.771647] [G loss: -1.258603]\n",
      "epoch0 step3755 [D loss: -0.777990] [G loss: -1.769533]\n",
      "epoch0 step3760 [D loss: -1.229197] [G loss: -1.993665]\n",
      "epoch0 step3765 [D loss: -0.341179] [G loss: -1.626778]\n",
      "epoch0 step3770 [D loss: -0.789153] [G loss: -2.093510]\n",
      "epoch0 step3775 [D loss: 0.156498] [G loss: -2.020950]\n",
      "epoch0 step3780 [D loss: -0.656657] [G loss: -2.897885]\n",
      "epoch0 step3785 [D loss: -0.200614] [G loss: -1.968681]\n",
      "epoch0 step3790 [D loss: -0.567565] [G loss: -2.026650]\n",
      "epoch0 step3795 [D loss: -0.574671] [G loss: -2.065628]\n",
      "epoch0 step3800 [D loss: -0.449998] [G loss: -2.119458]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.407360\n",
      "FID: 74.588318\n",
      "0 = 15.02575248308184\n",
      "1 = 0.14385000979277968\n",
      "2 = 0.9445000290870667\n",
      "3 = 0.9829999804496765\n",
      "4 = 0.906000018119812\n",
      "5 = 0.9127205014228821\n",
      "6 = 0.9829999804496765\n",
      "7 = 10.73938101003172\n",
      "8 = 0.172479088110026\n",
      "9 = 0.9089000225067139\n",
      "10 = 0.9107999801635742\n",
      "11 = 0.9070000052452087\n",
      "12 = 0.907352089881897\n",
      "13 = 0.9107999801635742\n",
      "14 = 4.407370567321777\n",
      "15 = 7.6737236976623535\n",
      "16 = 0.3841260075569153\n",
      "17 = 4.407360076904297\n",
      "18 = 74.58831787109375\n",
      "epoch0 step3805 [D loss: -0.361864] [G loss: -1.638122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 step3810 [D loss: -0.230763] [G loss: -2.320425]\n",
      "epoch0 step3815 [D loss: -0.789536] [G loss: -1.836075]\n",
      "epoch0 step3820 [D loss: -0.342610] [G loss: -1.390251]\n",
      "epoch0 step3825 [D loss: -0.577664] [G loss: -1.706506]\n",
      "epoch0 step3830 [D loss: -0.511746] [G loss: -1.810647]\n",
      "epoch0 step3835 [D loss: -0.377981] [G loss: -1.475823]\n",
      "epoch0 step3840 [D loss: -0.915153] [G loss: -1.434135]\n",
      "epoch0 step3845 [D loss: -0.716113] [G loss: -1.489326]\n",
      "epoch0 step3850 [D loss: -0.061824] [G loss: -1.236107]\n",
      "epoch0 step3855 [D loss: -0.728268] [G loss: -1.712600]\n",
      "epoch0 step3860 [D loss: -0.540397] [G loss: -1.490216]\n",
      "epoch0 step3865 [D loss: -0.906545] [G loss: -1.460908]\n",
      "epoch0 step3870 [D loss: -0.837867] [G loss: -0.727419]\n",
      "epoch0 step3875 [D loss: -1.147472] [G loss: -1.440714]\n",
      "epoch0 step3880 [D loss: -1.132622] [G loss: -1.285892]\n",
      "epoch0 step3885 [D loss: -0.874818] [G loss: -0.989802]\n",
      "epoch0 step3890 [D loss: -0.682155] [G loss: -1.247459]\n",
      "epoch0 step3895 [D loss: -0.845937] [G loss: -1.072150]\n",
      "epoch0 step3900 [D loss: -0.243732] [G loss: -1.199184]\n",
      "epoch0 step3905 [D loss: -1.017616] [G loss: -1.367124]\n",
      "epoch0 step3910 [D loss: -0.615261] [G loss: -1.596410]\n",
      "epoch0 step3915 [D loss: -0.679661] [G loss: -1.301975]\n",
      "epoch0 step3920 [D loss: -1.206135] [G loss: -0.878803]\n",
      "epoch0 step3925 [D loss: -0.389784] [G loss: -1.137442]\n",
      "epoch0 step3930 [D loss: -1.348751] [G loss: -1.303001]\n",
      "epoch0 step3935 [D loss: -0.823488] [G loss: -1.337943]\n",
      "epoch0 step3940 [D loss: -1.376564] [G loss: -1.173300]\n",
      "epoch0 step3945 [D loss: -0.695792] [G loss: -1.071726]\n",
      "epoch0 step3950 [D loss: -0.869296] [G loss: -1.260209]\n",
      "epoch0 step3955 [D loss: -0.366632] [G loss: -0.927169]\n",
      "epoch0 step3960 [D loss: -0.476174] [G loss: -0.892853]\n",
      "epoch0 step3965 [D loss: -0.853065] [G loss: -0.713230]\n",
      "epoch0 step3970 [D loss: -1.979862] [G loss: -0.353065]\n",
      "epoch0 step3975 [D loss: -0.932892] [G loss: -0.510114]\n",
      "epoch0 step3980 [D loss: -1.021648] [G loss: -0.741912]\n",
      "epoch0 step3985 [D loss: -1.290318] [G loss: -0.941496]\n",
      "epoch0 step3990 [D loss: -0.814721] [G loss: -0.581793]\n",
      "epoch0 step3995 [D loss: -0.486560] [G loss: -0.660065]\n",
      "epoch0 step4000 [D loss: -0.155025] [G loss: -0.887195]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.459982\n",
      "FID: 74.153976\n",
      "0 = 15.853170273208608\n",
      "1 = 0.2012441560832662\n",
      "2 = 0.9391999840736389\n",
      "3 = 0.9886000156402588\n",
      "4 = 0.8898000121116638\n",
      "5 = 0.8997087478637695\n",
      "6 = 0.9886000156402588\n",
      "7 = 10.665360614204403\n",
      "8 = 0.17291672335091393\n",
      "9 = 0.9034000039100647\n",
      "10 = 0.9093999862670898\n",
      "11 = 0.8974000215530396\n",
      "12 = 0.89861661195755\n",
      "13 = 0.9093999862670898\n",
      "14 = 4.459990978240967\n",
      "15 = 7.635313510894775\n",
      "16 = 0.39570513367652893\n",
      "17 = 4.459981918334961\n",
      "18 = 74.15397644042969\n",
      "epoch0 step4005 [D loss: -1.202263] [G loss: -0.690576]\n",
      "epoch0 step4010 [D loss: -1.286588] [G loss: -0.848632]\n",
      "epoch0 step4015 [D loss: -1.004046] [G loss: -0.682367]\n",
      "epoch0 step4020 [D loss: -0.735459] [G loss: -0.564765]\n",
      "epoch0 step4025 [D loss: -1.234548] [G loss: -0.589286]\n",
      "epoch0 step4030 [D loss: -0.410447] [G loss: -0.644208]\n",
      "epoch0 step4035 [D loss: -1.039752] [G loss: -0.753395]\n",
      "epoch0 step4040 [D loss: -1.130261] [G loss: -0.754547]\n",
      "epoch0 step4045 [D loss: -1.106571] [G loss: -0.715297]\n",
      "epoch0 step4050 [D loss: -0.827427] [G loss: -0.992638]\n",
      "epoch0 step4055 [D loss: -1.473592] [G loss: -0.326679]\n",
      "epoch0 step4060 [D loss: -1.475354] [G loss: -0.444619]\n",
      "epoch0 step4065 [D loss: -0.822775] [G loss: -0.704883]\n",
      "epoch0 step4070 [D loss: -0.821510] [G loss: -0.452090]\n",
      "epoch0 step4075 [D loss: -1.293133] [G loss: -0.399537]\n",
      "epoch0 step4080 [D loss: -0.431967] [G loss: -0.701676]\n",
      "epoch0 step4085 [D loss: -0.905539] [G loss: -0.757190]\n",
      "epoch0 step4090 [D loss: -0.529747] [G loss: -0.950759]\n",
      "epoch0 step4095 [D loss: -0.589176] [G loss: -1.025294]\n",
      "epoch0 step4100 [D loss: -0.637190] [G loss: -0.886740]\n",
      "epoch0 step4105 [D loss: 0.072867] [G loss: -1.332306]\n",
      "epoch0 step4110 [D loss: -0.738440] [G loss: -1.635437]\n",
      "epoch0 step4115 [D loss: 0.093342] [G loss: -1.535373]\n",
      "epoch0 step4120 [D loss: -1.139349] [G loss: -1.287202]\n",
      "epoch0 step4125 [D loss: -0.755328] [G loss: -1.040314]\n",
      "epoch0 step4130 [D loss: -1.118911] [G loss: -1.359225]\n",
      "epoch0 step4135 [D loss: -0.891680] [G loss: -0.948355]\n",
      "epoch0 step4140 [D loss: -0.800927] [G loss: -0.923064]\n",
      "epoch0 step4145 [D loss: -0.844469] [G loss: -1.159273]\n",
      "epoch0 step4150 [D loss: -0.932990] [G loss: -1.587320]\n",
      "epoch0 step4155 [D loss: -0.988077] [G loss: -0.970901]\n",
      "epoch0 step4160 [D loss: -1.173360] [G loss: -0.905133]\n",
      "epoch0 step4165 [D loss: -0.602018] [G loss: -0.994012]\n",
      "epoch0 step4170 [D loss: -0.436131] [G loss: -0.939808]\n",
      "epoch0 step4175 [D loss: -0.562256] [G loss: -1.065702]\n",
      "epoch0 step4180 [D loss: -0.987397] [G loss: -1.447388]\n",
      "epoch0 step4185 [D loss: -1.208562] [G loss: -1.245044]\n",
      "epoch0 step4190 [D loss: -0.940896] [G loss: -1.768793]\n",
      "epoch0 step4195 [D loss: -1.083275] [G loss: -1.791633]\n",
      "epoch0 step4200 [D loss: -0.937382] [G loss: -1.150509]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.636691\n",
      "FID: 66.042328\n",
      "0 = 14.51836253013609\n",
      "1 = 0.08807354013021923\n",
      "2 = 0.9294000267982483\n",
      "3 = 0.9833999872207642\n",
      "4 = 0.8754000067710876\n",
      "5 = 0.887545108795166\n",
      "6 = 0.9833999872207642\n",
      "7 = 10.489978762722057\n",
      "8 = 0.15623664798908649\n",
      "9 = 0.9035000205039978\n",
      "10 = 0.9083999991416931\n",
      "11 = 0.8985999822616577\n",
      "12 = 0.8995840549468994\n",
      "13 = 0.9083999991416931\n",
      "14 = 4.636703968048096\n",
      "15 = 8.499195098876953\n",
      "16 = 0.32714906334877014\n",
      "17 = 4.636690616607666\n",
      "18 = 66.04232788085938\n",
      "epoch0 step4205 [D loss: -0.381597] [G loss: -1.345421]\n",
      "epoch0 step4210 [D loss: -0.754251] [G loss: -1.474673]\n",
      "epoch0 step4215 [D loss: -0.848243] [G loss: -1.757263]\n",
      "epoch0 step4220 [D loss: -0.805281] [G loss: -1.584035]\n",
      "epoch0 step4225 [D loss: -0.989478] [G loss: -2.078740]\n",
      "epoch0 step4230 [D loss: 0.019727] [G loss: -1.887701]\n",
      "epoch0 step4235 [D loss: -0.582075] [G loss: -1.618764]\n",
      "epoch0 step4240 [D loss: -0.815832] [G loss: -1.758279]\n",
      "epoch0 step4245 [D loss: -1.004983] [G loss: -1.698254]\n",
      "epoch0 step4250 [D loss: -1.028442] [G loss: -0.445281]\n",
      "epoch0 step4255 [D loss: -1.058745] [G loss: -1.651880]\n",
      "epoch0 step4260 [D loss: -1.132570] [G loss: -0.966851]\n",
      "epoch0 step4265 [D loss: -0.468061] [G loss: -0.710022]\n",
      "epoch0 step4270 [D loss: -1.275577] [G loss: -1.241537]\n",
      "epoch0 step4275 [D loss: -1.571767] [G loss: -0.894920]\n",
      "epoch0 step4280 [D loss: -1.035533] [G loss: -1.116814]\n",
      "epoch0 step4285 [D loss: -1.090907] [G loss: -1.056665]\n",
      "epoch0 step4290 [D loss: -1.045771] [G loss: -0.530307]\n",
      "epoch0 step4295 [D loss: -0.996255] [G loss: -1.112726]\n",
      "epoch0 step4300 [D loss: -1.363533] [G loss: -0.636001]\n",
      "epoch0 step4305 [D loss: -0.874431] [G loss: -0.326852]\n",
      "epoch0 step4310 [D loss: -0.670572] [G loss: -0.754225]\n",
      "epoch0 step4315 [D loss: -0.288607] [G loss: -0.894036]\n",
      "epoch0 step4320 [D loss: -0.236635] [G loss: -1.298454]\n",
      "epoch0 step4325 [D loss: -0.351892] [G loss: -1.039254]\n",
      "epoch0 step4330 [D loss: -0.872928] [G loss: -1.382112]\n",
      "epoch0 step4335 [D loss: -0.329178] [G loss: -1.450024]\n",
      "epoch0 step4340 [D loss: -0.851213] [G loss: -1.675805]\n",
      "epoch0 step4345 [D loss: -0.601330] [G loss: -1.696502]\n",
      "epoch0 step4350 [D loss: -1.182911] [G loss: -1.564641]\n",
      "epoch0 step4355 [D loss: -0.988010] [G loss: -1.635316]\n",
      "epoch0 step4360 [D loss: -0.898364] [G loss: -1.820626]\n",
      "epoch0 step4365 [D loss: -0.890901] [G loss: -1.681594]\n",
      "epoch0 step4370 [D loss: -0.481998] [G loss: -1.710314]\n",
      "epoch0 step4375 [D loss: -0.393301] [G loss: -2.031254]\n",
      "epoch0 step4380 [D loss: -0.975399] [G loss: -1.994228]\n",
      "epoch0 step4385 [D loss: -1.526436] [G loss: -1.802110]\n",
      "epoch0 step4390 [D loss: -0.731874] [G loss: -2.098660]\n",
      "epoch0 step4395 [D loss: -0.920386] [G loss: -2.298002]\n",
      "epoch0 step4400 [D loss: -0.865444] [G loss: -2.229704]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.664247\n",
      "FID: 64.283333\n",
      "0 = 14.63920467872623\n",
      "1 = 0.09965125306868539\n",
      "2 = 0.9200999736785889\n",
      "3 = 0.9819999933242798\n",
      "4 = 0.8582000136375427\n",
      "5 = 0.873820960521698\n",
      "6 = 0.9819999933242798\n",
      "7 = 10.433891889810566\n",
      "8 = 0.15842525758413836\n",
      "9 = 0.9085999727249146\n",
      "10 = 0.9125999808311462\n",
      "11 = 0.9046000242233276\n",
      "12 = 0.9053571224212646\n",
      "13 = 0.9125999808311462\n",
      "14 = 4.664257526397705\n",
      "15 = 8.362259864807129\n",
      "16 = 0.3364293873310089\n",
      "17 = 4.664246559143066\n",
      "18 = 64.28333282470703\n",
      "epoch0 step4405 [D loss: -1.054338] [G loss: -2.013390]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 step4410 [D loss: -0.796653] [G loss: -1.994554]\n",
      "epoch0 step4415 [D loss: 0.064010] [G loss: -2.350518]\n",
      "epoch0 step4420 [D loss: -0.187150] [G loss: -2.359550]\n",
      "epoch0 step4425 [D loss: -0.973742] [G loss: -1.493815]\n",
      "epoch0 step4430 [D loss: -0.940920] [G loss: -1.667385]\n",
      "epoch0 step4435 [D loss: -1.101501] [G loss: -2.073791]\n",
      "epoch0 step4440 [D loss: -0.941570] [G loss: -1.397933]\n",
      "epoch0 step4445 [D loss: -0.709997] [G loss: -1.762396]\n",
      "epoch0 step4450 [D loss: -0.886315] [G loss: -1.510196]\n",
      "epoch0 step4455 [D loss: -0.643862] [G loss: -1.585264]\n",
      "epoch0 step4460 [D loss: -1.469446] [G loss: -1.671526]\n",
      "epoch0 step4465 [D loss: -1.333257] [G loss: -1.131757]\n",
      "epoch0 step4470 [D loss: -0.987031] [G loss: -1.641127]\n",
      "epoch0 step4475 [D loss: -1.270716] [G loss: -1.287811]\n",
      "epoch0 step4480 [D loss: -1.196948] [G loss: -0.817921]\n",
      "epoch0 step4485 [D loss: -1.239852] [G loss: -0.621312]\n",
      "epoch0 step4490 [D loss: -1.449255] [G loss: -0.880726]\n",
      "epoch0 step4495 [D loss: -0.613811] [G loss: -1.065516]\n",
      "epoch0 step4500 [D loss: -0.688493] [G loss: -0.853045]\n",
      "epoch0 step4505 [D loss: -0.827853] [G loss: -0.716239]\n",
      "epoch0 step4510 [D loss: -1.170493] [G loss: -0.215563]\n",
      "epoch0 step4515 [D loss: -1.815952] [G loss: -0.211213]\n",
      "epoch0 step4520 [D loss: -1.593219] [G loss: -0.219954]\n",
      "epoch0 step4525 [D loss: -0.230519] [G loss: -0.430907]\n",
      "epoch0 step4530 [D loss: -1.498843] [G loss: -0.144058]\n",
      "epoch0 step4535 [D loss: -0.586771] [G loss: -0.294349]\n",
      "epoch0 step4540 [D loss: -0.723400] [G loss: -0.545969]\n",
      "epoch0 step4545 [D loss: -1.344169] [G loss: -0.039080]\n",
      "epoch0 step4550 [D loss: -1.425018] [G loss: -0.075220]\n",
      "epoch0 step4555 [D loss: -1.144021] [G loss: -0.604488]\n",
      "epoch0 step4560 [D loss: -0.672281] [G loss: -0.486481]\n",
      "epoch0 step4565 [D loss: -1.193839] [G loss: -0.755225]\n",
      "epoch0 step4570 [D loss: -1.839731] [G loss: -0.446485]\n",
      "epoch0 step4575 [D loss: 0.065940] [G loss: -0.286839]\n",
      "epoch0 step4580 [D loss: -0.671003] [G loss: -0.720183]\n",
      "epoch0 step4585 [D loss: -0.138447] [G loss: -0.268249]\n",
      "epoch0 step4590 [D loss: -0.598116] [G loss: -0.399341]\n",
      "epoch0 step4595 [D loss: -0.717862] [G loss: -1.200874]\n",
      "epoch0 step4600 [D loss: -0.422119] [G loss: -0.491963]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.063695\n",
      "FID: 85.529587\n",
      "0 = 13.753959105205531\n",
      "1 = 0.1314052753208223\n",
      "2 = 0.9538000226020813\n",
      "3 = 0.9702000021934509\n",
      "4 = 0.9373999834060669\n",
      "5 = 0.93938809633255\n",
      "6 = 0.9702000021934509\n",
      "7 = 11.307222784900699\n",
      "8 = 0.1806775887039549\n",
      "9 = 0.9253000020980835\n",
      "10 = 0.9241999983787537\n",
      "11 = 0.9264000058174133\n",
      "12 = 0.9262377023696899\n",
      "13 = 0.9241999983787537\n",
      "14 = 4.063700199127197\n",
      "15 = 8.470467567443848\n",
      "16 = 0.3582092821598053\n",
      "17 = 4.063694953918457\n",
      "18 = 85.52958679199219\n",
      "epoch0 step4605 [D loss: -1.262725] [G loss: -0.903856]\n",
      "epoch0 step4610 [D loss: -1.025456] [G loss: -0.352126]\n",
      "epoch0 step4615 [D loss: -0.825280] [G loss: -0.825756]\n",
      "epoch0 step4620 [D loss: -0.572831] [G loss: -0.839987]\n",
      "epoch0 step4625 [D loss: -0.930888] [G loss: -0.954280]\n",
      "epoch0 step4630 [D loss: -0.523430] [G loss: -1.313977]\n",
      "epoch0 step4635 [D loss: -1.120580] [G loss: -1.569441]\n",
      "epoch0 step4640 [D loss: -1.147384] [G loss: -1.437499]\n",
      "epoch0 step4645 [D loss: -1.548102] [G loss: -1.223956]\n",
      "epoch0 step4650 [D loss: -0.711266] [G loss: -1.266397]\n",
      "epoch0 step4655 [D loss: -0.378157] [G loss: -1.938112]\n",
      "epoch0 step4660 [D loss: -0.985766] [G loss: -1.509659]\n",
      "epoch0 step4665 [D loss: -0.292550] [G loss: -1.907042]\n",
      "epoch0 step4670 [D loss: -0.712678] [G loss: -1.955009]\n",
      "epoch0 step4675 [D loss: -1.414236] [G loss: -1.776035]\n",
      "epoch0 step4680 [D loss: -0.656215] [G loss: -1.341638]\n",
      "epoch0 step4685 [D loss: -0.961244] [G loss: -1.336075]\n",
      "epoch0 step4690 [D loss: -1.327665] [G loss: -1.436759]\n",
      "epoch0 step4695 [D loss: -0.589764] [G loss: -2.166036]\n",
      "epoch0 step4700 [D loss: -0.230717] [G loss: -1.504185]\n",
      "epoch0 step4705 [D loss: -1.075265] [G loss: -0.790672]\n",
      "epoch0 step4710 [D loss: -1.319692] [G loss: -0.955134]\n",
      "epoch0 step4715 [D loss: -0.866722] [G loss: -1.486607]\n",
      "epoch0 step4720 [D loss: -0.026894] [G loss: -1.295568]\n",
      "epoch0 step4725 [D loss: 0.666108] [G loss: -1.254970]\n",
      "epoch0 step4730 [D loss: -0.443525] [G loss: -1.189348]\n",
      "epoch0 step4735 [D loss: -0.408179] [G loss: -1.408474]\n",
      "epoch0 step4740 [D loss: -1.103239] [G loss: -0.864907]\n",
      "epoch0 step4745 [D loss: -1.192597] [G loss: -1.070691]\n",
      "epoch0 step4750 [D loss: -0.439920] [G loss: -1.030924]\n",
      "epoch0 step4755 [D loss: -0.895201] [G loss: -0.937434]\n",
      "epoch0 step4760 [D loss: -0.769708] [G loss: -1.230399]\n",
      "epoch0 step4765 [D loss: -1.107251] [G loss: -1.473936]\n",
      "epoch0 step4770 [D loss: -1.083751] [G loss: -1.307997]\n",
      "epoch0 step4775 [D loss: -0.642613] [G loss: -1.351594]\n",
      "epoch0 step4780 [D loss: -0.638295] [G loss: -1.714903]\n",
      "epoch0 step4785 [D loss: -1.102104] [G loss: -1.128304]\n",
      "epoch0 step4790 [D loss: -0.730417] [G loss: -1.141992]\n",
      "epoch0 step4795 [D loss: -0.428178] [G loss: -1.265702]\n",
      "epoch0 step4800 [D loss: -0.843693] [G loss: -0.991592]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.588031\n",
      "FID: 67.571426\n",
      "0 = 14.221047671985536\n",
      "1 = 0.10214944113243808\n",
      "2 = 0.9297999739646912\n",
      "3 = 0.974399983882904\n",
      "4 = 0.885200023651123\n",
      "5 = 0.8946015238761902\n",
      "6 = 0.974399983882904\n",
      "7 = 10.547425879716823\n",
      "8 = 0.1603065343865964\n",
      "9 = 0.9035999774932861\n",
      "10 = 0.9092000126838684\n",
      "11 = 0.8980000019073486\n",
      "12 = 0.8991297483444214\n",
      "13 = 0.9092000126838684\n",
      "14 = 4.588043212890625\n",
      "15 = 8.545324325561523\n",
      "16 = 0.32139042019844055\n",
      "17 = 4.58803129196167\n",
      "18 = 67.57142639160156\n",
      "epoch0 step4805 [D loss: -1.316326] [G loss: -0.798705]\n",
      "epoch0 step4810 [D loss: -0.711323] [G loss: -1.085910]\n",
      "epoch0 step4815 [D loss: -0.463778] [G loss: -1.409766]\n",
      "epoch0 step4820 [D loss: -0.810340] [G loss: -1.050667]\n",
      "epoch0 step4825 [D loss: -0.572457] [G loss: -0.908798]\n",
      "epoch0 step4830 [D loss: -0.809438] [G loss: -1.199748]\n",
      "epoch0 step4835 [D loss: -0.935910] [G loss: -1.532613]\n",
      "epoch0 step4840 [D loss: -1.014738] [G loss: -1.408525]\n",
      "epoch0 step4845 [D loss: -1.567228] [G loss: -1.558853]\n",
      "epoch0 step4850 [D loss: -0.633277] [G loss: -1.550291]\n",
      "epoch0 step4855 [D loss: -0.974509] [G loss: -1.715956]\n",
      "epoch0 step4860 [D loss: -0.803143] [G loss: -1.402352]\n",
      "epoch0 step4865 [D loss: -1.172150] [G loss: -1.330783]\n",
      "epoch0 step4870 [D loss: -1.148825] [G loss: -0.962649]\n",
      "epoch0 step4875 [D loss: -1.243719] [G loss: -1.003801]\n",
      "epoch0 step4880 [D loss: -1.008863] [G loss: -0.455647]\n",
      "epoch0 step4885 [D loss: -0.385568] [G loss: -0.789530]\n",
      "epoch0 step4890 [D loss: -0.578158] [G loss: -0.967557]\n",
      "epoch0 step4895 [D loss: -0.428885] [G loss: -0.705222]\n",
      "epoch0 step4900 [D loss: -0.380020] [G loss: -0.495718]\n",
      "epoch0 step4905 [D loss: -0.559215] [G loss: -0.487345]\n",
      "epoch0 step4910 [D loss: -0.653610] [G loss: -0.452919]\n",
      "epoch0 step4915 [D loss: -0.934644] [G loss: -0.110767]\n",
      "epoch0 step4920 [D loss: -0.986514] [G loss: -0.841856]\n",
      "epoch0 step4925 [D loss: -1.108986] [G loss: -0.433801]\n",
      "epoch0 step4930 [D loss: -0.557708] [G loss: -0.330543]\n",
      "epoch0 step4935 [D loss: -1.047809] [G loss: -0.259720]\n",
      "epoch0 step4940 [D loss: -1.061361] [G loss: -0.379820]\n",
      "epoch0 step4945 [D loss: -1.468568] [G loss: -0.415033]\n",
      "epoch0 step4950 [D loss: -1.193235] [G loss: -0.427729]\n",
      "epoch0 step4955 [D loss: -1.191618] [G loss: -1.059656]\n",
      "epoch0 step4960 [D loss: -0.903146] [G loss: -0.334333]\n",
      "epoch0 step4965 [D loss: -1.778942] [G loss: 0.201409]\n",
      "epoch0 step4970 [D loss: -1.264189] [G loss: -0.118710]\n",
      "epoch0 step4975 [D loss: -2.097223] [G loss: -0.046047]\n",
      "epoch0 step4980 [D loss: -1.901174] [G loss: 0.338575]\n",
      "epoch0 step4985 [D loss: -1.819278] [G loss: -0.374433]\n",
      "epoch0 step4990 [D loss: -1.841533] [G loss: -0.230230]\n",
      "epoch0 step4995 [D loss: -1.601032] [G loss: -0.338509]\n",
      "epoch0 step5000 [D loss: -0.379093] [G loss: -0.435442]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.507566\n",
      "FID: 70.113228\n",
      "0 = 13.963071627044695\n",
      "1 = 0.06722428844978998\n",
      "2 = 0.9289000034332275\n",
      "3 = 0.972000002861023\n",
      "4 = 0.8858000040054321\n",
      "5 = 0.8948628306388855\n",
      "6 = 0.972000002861023\n",
      "7 = 10.69494763436314\n",
      "8 = 0.16164838209018068\n",
      "9 = 0.9085000157356262\n",
      "10 = 0.9132000207901001\n",
      "11 = 0.9038000106811523\n",
      "12 = 0.9046958684921265\n",
      "13 = 0.9132000207901001\n",
      "14 = 4.50757360458374\n",
      "15 = 8.515963554382324\n",
      "16 = 0.3345804512500763\n",
      "17 = 4.507565975189209\n",
      "18 = 70.11322784423828\n",
      "epoch0 step5005 [D loss: -1.114040] [G loss: 0.113021]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 step5010 [D loss: -0.478404] [G loss: 0.051253]\n",
      "epoch0 step5015 [D loss: -0.683891] [G loss: -0.173252]\n",
      "epoch0 step5020 [D loss: -0.612700] [G loss: -0.931256]\n",
      "epoch0 step5025 [D loss: -0.426529] [G loss: -0.683030]\n",
      "epoch0 step5030 [D loss: -0.965059] [G loss: -0.769136]\n",
      "epoch0 step5035 [D loss: -0.038958] [G loss: -0.818041]\n",
      "epoch0 step5040 [D loss: -0.695428] [G loss: -0.811189]\n",
      "epoch0 step5045 [D loss: -0.127066] [G loss: -0.525868]\n",
      "epoch0 step5050 [D loss: -0.864572] [G loss: -0.371886]\n",
      "epoch0 step5055 [D loss: -0.264299] [G loss: -1.052696]\n",
      "epoch0 step5060 [D loss: -0.189295] [G loss: -0.875844]\n",
      "epoch0 step5065 [D loss: -0.556695] [G loss: -0.614316]\n",
      "epoch0 step5070 [D loss: -0.060157] [G loss: -0.629610]\n",
      "epoch0 step5075 [D loss: -1.139115] [G loss: -0.857977]\n",
      "epoch0 step5080 [D loss: -1.110353] [G loss: -0.193209]\n",
      "epoch0 step5085 [D loss: -1.203720] [G loss: 0.038291]\n",
      "epoch0 step5090 [D loss: -0.453454] [G loss: -0.251380]\n",
      "epoch0 step5095 [D loss: -1.075820] [G loss: -0.115048]\n",
      "epoch0 step5100 [D loss: -1.149617] [G loss: 0.376658]\n",
      "epoch0 step5105 [D loss: -1.434223] [G loss: 0.738572]\n",
      "epoch0 step5110 [D loss: -0.530462] [G loss: 0.503953]\n",
      "epoch0 step5115 [D loss: -0.476804] [G loss: 0.279460]\n",
      "epoch0 step5120 [D loss: -0.706931] [G loss: 0.087092]\n",
      "epoch0 step5125 [D loss: -1.797577] [G loss: 0.476719]\n",
      "epoch0 step5130 [D loss: -1.214253] [G loss: 0.672566]\n",
      "epoch0 step5135 [D loss: -1.274119] [G loss: 0.190770]\n",
      "epoch0 step5140 [D loss: -0.561534] [G loss: 0.084940]\n",
      "epoch0 step5145 [D loss: -1.393723] [G loss: -0.016217]\n",
      "epoch0 step5150 [D loss: -1.425098] [G loss: -0.411375]\n",
      "epoch0 step5155 [D loss: -1.023259] [G loss: -0.249815]\n",
      "epoch0 step5160 [D loss: -0.695279] [G loss: -0.614374]\n",
      "epoch0 step5165 [D loss: -0.874498] [G loss: -0.197881]\n",
      "epoch0 step5170 [D loss: -1.004309] [G loss: -0.295321]\n",
      "epoch0 step5175 [D loss: -0.259774] [G loss: -1.071400]\n",
      "epoch0 step5180 [D loss: -0.506886] [G loss: -0.338707]\n",
      "epoch0 step5185 [D loss: -0.806121] [G loss: -0.908259]\n",
      "epoch0 step5190 [D loss: -0.268520] [G loss: -0.887401]\n",
      "epoch0 step5195 [D loss: -0.807745] [G loss: -1.175995]\n",
      "epoch0 step5200 [D loss: -1.011442] [G loss: -1.037406]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.626940\n",
      "FID: 66.744446\n",
      "0 = 14.314263011646288\n",
      "1 = 0.06828696639445854\n",
      "2 = 0.9093999862670898\n",
      "3 = 0.9787999987602234\n",
      "4 = 0.8399999737739563\n",
      "5 = 0.8595012426376343\n",
      "6 = 0.9787999987602234\n",
      "7 = 10.56507475442885\n",
      "8 = 0.16017895049202033\n",
      "9 = 0.9016000032424927\n",
      "10 = 0.9110000133514404\n",
      "11 = 0.8921999931335449\n",
      "12 = 0.8941892385482788\n",
      "13 = 0.9110000133514404\n",
      "14 = 4.626949787139893\n",
      "15 = 8.544198036193848\n",
      "16 = 0.32334068417549133\n",
      "17 = 4.6269402503967285\n",
      "18 = 66.74444580078125\n",
      "epoch0 step5205 [D loss: -0.785292] [G loss: -1.100531]\n",
      "epoch0 step5210 [D loss: -0.654435] [G loss: -1.400035]\n",
      "epoch0 step5215 [D loss: -1.011870] [G loss: -0.852346]\n",
      "epoch0 step5220 [D loss: -0.841531] [G loss: -1.020689]\n",
      "epoch0 step5225 [D loss: -1.189315] [G loss: -1.063374]\n",
      "epoch0 step5230 [D loss: -0.782482] [G loss: -0.285363]\n",
      "epoch0 step5235 [D loss: -1.405573] [G loss: -0.610099]\n",
      "epoch0 step5240 [D loss: -0.795752] [G loss: -0.607698]\n",
      "epoch0 step5245 [D loss: -1.433445] [G loss: -0.790386]\n",
      "epoch0 step5250 [D loss: -1.647465] [G loss: -0.815879]\n",
      "epoch0 step5255 [D loss: -1.709434] [G loss: -1.144083]\n",
      "epoch0 step5260 [D loss: -1.285250] [G loss: -0.483518]\n",
      "epoch0 step5265 [D loss: -1.386571] [G loss: -0.877329]\n",
      "epoch0 step5270 [D loss: -0.285725] [G loss: -1.160559]\n",
      "epoch0 step5275 [D loss: -1.085360] [G loss: -1.642331]\n",
      "epoch0 step5280 [D loss: -0.134767] [G loss: -1.342181]\n",
      "epoch0 step5285 [D loss: -0.539410] [G loss: -1.719261]\n",
      "epoch0 step5290 [D loss: -1.043242] [G loss: -1.308970]\n",
      "epoch0 step5295 [D loss: -1.228982] [G loss: -1.449239]\n",
      "epoch0 step5300 [D loss: -1.668507] [G loss: -1.619011]\n",
      "epoch0 step5305 [D loss: -0.441569] [G loss: -1.996232]\n",
      "epoch0 step5310 [D loss: -0.115440] [G loss: -1.706874]\n",
      "epoch0 step5315 [D loss: -0.905644] [G loss: -1.817009]\n",
      "epoch0 step5320 [D loss: -0.391110] [G loss: -1.879644]\n",
      "epoch0 step5325 [D loss: -0.129529] [G loss: -1.570409]\n",
      "epoch0 step5330 [D loss: -0.256870] [G loss: -1.472685]\n",
      "epoch0 step5335 [D loss: 0.052327] [G loss: -2.247725]\n",
      "epoch0 step5340 [D loss: -0.527931] [G loss: -1.644069]\n",
      "epoch0 step5345 [D loss: -0.402059] [G loss: -1.603259]\n",
      "epoch0 step5350 [D loss: -1.143839] [G loss: -1.097493]\n",
      "epoch0 step5355 [D loss: -1.199046] [G loss: -1.270883]\n",
      "epoch0 step5360 [D loss: -0.930360] [G loss: -1.410241]\n",
      "epoch0 step5365 [D loss: -0.699292] [G loss: -0.931861]\n",
      "epoch0 step5370 [D loss: -0.652196] [G loss: -1.240650]\n",
      "epoch0 step5375 [D loss: -0.759830] [G loss: -0.646261]\n",
      "epoch0 step5380 [D loss: -0.503763] [G loss: -0.880607]\n",
      "epoch0 step5385 [D loss: -0.698266] [G loss: -0.821084]\n",
      "epoch0 step5390 [D loss: -1.349461] [G loss: -0.840390]\n",
      "epoch0 step5395 [D loss: -0.966696] [G loss: -0.481950]\n",
      "epoch0 step5400 [D loss: -1.250604] [G loss: 0.137775]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.553705\n",
      "FID: 68.040871\n",
      "0 = 14.24237420539857\n",
      "1 = 0.08204214841108051\n",
      "2 = 0.9154999852180481\n",
      "3 = 0.975600004196167\n",
      "4 = 0.855400025844574\n",
      "5 = 0.8709158897399902\n",
      "6 = 0.975600004196167\n",
      "7 = 10.555582887363459\n",
      "8 = 0.16664775105265658\n",
      "9 = 0.9003999829292297\n",
      "10 = 0.9083999991416931\n",
      "11 = 0.8924000263214111\n",
      "12 = 0.8940944671630859\n",
      "13 = 0.9083999991416931\n",
      "14 = 4.553717136383057\n",
      "15 = 8.10881519317627\n",
      "16 = 0.3617187738418579\n",
      "17 = 4.553704738616943\n",
      "18 = 68.0408706665039\n",
      "epoch0 step5405 [D loss: -1.112853] [G loss: -0.447011]\n",
      "epoch0 step5410 [D loss: -1.047295] [G loss: -0.163967]\n",
      "epoch0 step5415 [D loss: -0.179506] [G loss: -0.386911]\n",
      "epoch0 step5420 [D loss: -0.786420] [G loss: 0.251556]\n",
      "epoch0 step5425 [D loss: -1.203941] [G loss: -0.075085]\n",
      "epoch0 step5430 [D loss: -0.414010] [G loss: 0.089223]\n",
      "epoch0 step5435 [D loss: -0.863404] [G loss: 0.439103]\n",
      "epoch0 step5440 [D loss: -0.812843] [G loss: 0.327446]\n",
      "epoch0 step5445 [D loss: -0.898658] [G loss: 0.126114]\n",
      "epoch0 step5450 [D loss: -0.741229] [G loss: 0.514887]\n",
      "epoch0 step5455 [D loss: -0.793857] [G loss: 0.178792]\n",
      "epoch0 step5460 [D loss: -1.262047] [G loss: 0.837521]\n",
      "epoch0 step5465 [D loss: -0.775064] [G loss: 0.091123]\n",
      "epoch0 step5470 [D loss: -1.722561] [G loss: -0.113205]\n",
      "epoch0 step5475 [D loss: -0.818136] [G loss: -0.027689]\n",
      "epoch0 step5480 [D loss: -1.000453] [G loss: -0.151913]\n",
      "epoch0 step5485 [D loss: -1.209008] [G loss: -0.304054]\n",
      "epoch0 step5490 [D loss: -1.146601] [G loss: -0.170386]\n",
      "epoch0 step5495 [D loss: -0.213636] [G loss: -0.947781]\n",
      "epoch0 step5500 [D loss: -1.340700] [G loss: -0.462710]\n",
      "epoch0 step5505 [D loss: -0.371585] [G loss: -0.109327]\n",
      "epoch0 step5510 [D loss: -1.037139] [G loss: -0.365349]\n",
      "epoch0 step5515 [D loss: -0.785172] [G loss: -0.026522]\n",
      "epoch0 step5520 [D loss: -0.781928] [G loss: -0.380686]\n",
      "epoch0 step5525 [D loss: -1.292946] [G loss: -0.011402]\n",
      "epoch0 step5530 [D loss: -0.488543] [G loss: 0.145107]\n",
      "epoch0 step5535 [D loss: -1.861164] [G loss: -0.048809]\n",
      "epoch0 step5540 [D loss: -1.509977] [G loss: 0.666995]\n",
      "epoch0 step5545 [D loss: -1.120889] [G loss: -0.500678]\n",
      "epoch0 step5550 [D loss: -1.060758] [G loss: -0.055295]\n",
      "epoch0 step5555 [D loss: -0.104017] [G loss: 0.468319]\n",
      "epoch0 step5560 [D loss: -1.360342] [G loss: -0.141585]\n",
      "epoch0 step5565 [D loss: -0.560497] [G loss: -0.238793]\n",
      "epoch0 step5570 [D loss: -0.204275] [G loss: -0.259257]\n",
      "epoch0 step5575 [D loss: -1.837704] [G loss: 0.120538]\n",
      "epoch0 step5580 [D loss: -0.228006] [G loss: 0.380035]\n",
      "epoch0 step5585 [D loss: -0.801902] [G loss: 0.364494]\n",
      "epoch0 step5590 [D loss: -0.724521] [G loss: 0.635631]\n",
      "epoch0 step5595 [D loss: -1.755978] [G loss: 0.914524]\n",
      "epoch0 step5600 [D loss: -1.259794] [G loss: 0.469545]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.679409\n",
      "FID: 65.147430\n",
      "0 = 14.256881251144414\n",
      "1 = 0.10341942113445446\n",
      "2 = 0.91839998960495\n",
      "3 = 0.9742000102996826\n",
      "4 = 0.8626000285148621\n",
      "5 = 0.8763943910598755\n",
      "6 = 0.9742000102996826\n",
      "7 = 10.49952594432831\n",
      "8 = 0.15739820127222837\n",
      "9 = 0.9025999903678894\n",
      "10 = 0.9038000106811523\n",
      "11 = 0.9014000296592712\n",
      "12 = 0.9016360640525818\n",
      "13 = 0.9038000106811523\n",
      "14 = 4.679418087005615\n",
      "15 = 8.610036849975586\n",
      "16 = 0.308720201253891\n",
      "17 = 4.679409027099609\n",
      "18 = 65.14743041992188\n",
      "epoch0 step5605 [D loss: 0.157854] [G loss: 0.464586]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 step5610 [D loss: -0.894235] [G loss: 0.071220]\n",
      "epoch0 step5615 [D loss: -1.089322] [G loss: 0.321291]\n",
      "epoch0 step5620 [D loss: -1.034557] [G loss: 0.483403]\n",
      "epoch0 step5625 [D loss: -1.681119] [G loss: 0.382106]\n",
      "epoch0 step5630 [D loss: -1.026254] [G loss: 0.200918]\n",
      "epoch0 step5635 [D loss: -1.213352] [G loss: 0.219740]\n",
      "epoch0 step5640 [D loss: -0.617741] [G loss: 0.233573]\n",
      "epoch0 step5645 [D loss: -0.516567] [G loss: 0.030394]\n",
      "epoch0 step5650 [D loss: -0.894240] [G loss: 0.518512]\n",
      "epoch0 step5655 [D loss: -0.894580] [G loss: 0.182289]\n",
      "epoch0 step5660 [D loss: -0.548862] [G loss: 0.214363]\n",
      "epoch0 step5665 [D loss: -1.390634] [G loss: -0.016359]\n",
      "epoch0 step5670 [D loss: -1.549554] [G loss: 1.169000]\n",
      "epoch0 step5675 [D loss: -1.619985] [G loss: -0.083128]\n",
      "epoch0 step5680 [D loss: -1.023776] [G loss: 0.046000]\n",
      "epoch0 step5685 [D loss: -0.895284] [G loss: 0.071059]\n",
      "epoch0 step5690 [D loss: -0.569512] [G loss: 0.152862]\n",
      "epoch0 step5695 [D loss: -1.016960] [G loss: 0.365348]\n",
      "epoch0 step5700 [D loss: -0.864210] [G loss: 0.114387]\n",
      "epoch0 step5705 [D loss: -0.929942] [G loss: 0.695072]\n",
      "epoch0 step5710 [D loss: -1.062779] [G loss: 0.377515]\n",
      "epoch0 step5715 [D loss: -0.732594] [G loss: 0.328859]\n",
      "epoch0 step5720 [D loss: -1.129351] [G loss: 0.848073]\n",
      "epoch0 step5725 [D loss: -0.153428] [G loss: -0.085585]\n",
      "epoch0 step5730 [D loss: -0.349410] [G loss: -0.356359]\n",
      "epoch0 step5735 [D loss: -1.360842] [G loss: 0.217353]\n",
      "epoch0 step5740 [D loss: -0.601152] [G loss: -0.332204]\n",
      "epoch0 step5745 [D loss: -1.263207] [G loss: 0.227262]\n",
      "epoch0 step5750 [D loss: -0.880829] [G loss: -0.468368]\n",
      "epoch0 step5755 [D loss: -0.840297] [G loss: 0.151881]\n",
      "epoch0 step5760 [D loss: -0.510769] [G loss: -0.520192]\n",
      "epoch0 step5765 [D loss: -0.703978] [G loss: 0.172043]\n",
      "epoch0 step5770 [D loss: -0.163243] [G loss: -0.253789]\n",
      "epoch0 step5775 [D loss: -0.019306] [G loss: -0.155300]\n",
      "epoch0 step5780 [D loss: -1.352354] [G loss: -0.555377]\n",
      "epoch0 step5785 [D loss: -0.718998] [G loss: -0.246537]\n",
      "epoch0 step5790 [D loss: -1.366278] [G loss: -0.339295]\n",
      "epoch0 step5795 [D loss: -0.835996] [G loss: 0.538089]\n",
      "epoch0 step5800 [D loss: -0.629100] [G loss: -0.112938]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.670798\n",
      "FID: 65.024712\n",
      "0 = 15.057640522289262\n",
      "1 = 0.15811305366592282\n",
      "2 = 0.920799970626831\n",
      "3 = 0.9782000184059143\n",
      "4 = 0.8633999824523926\n",
      "5 = 0.8774667978286743\n",
      "6 = 0.9782000184059143\n",
      "7 = 10.320046540474932\n",
      "8 = 0.1609803374231314\n",
      "9 = 0.895799994468689\n",
      "10 = 0.9031999707221985\n",
      "11 = 0.8884000182151794\n",
      "12 = 0.8900275826454163\n",
      "13 = 0.9031999707221985\n",
      "14 = 4.670805931091309\n",
      "15 = 8.090714454650879\n",
      "16 = 0.35104304552078247\n",
      "17 = 4.670797824859619\n",
      "18 = 65.02471160888672\n",
      "epoch0 step5805 [D loss: -0.440229] [G loss: 0.102494]\n",
      "epoch0 step5810 [D loss: -1.004028] [G loss: -0.233712]\n",
      "epoch0 step5815 [D loss: -1.002775] [G loss: 0.013327]\n",
      "epoch0 step5820 [D loss: -1.001738] [G loss: 0.400806]\n",
      "epoch0 step5825 [D loss: -0.018035] [G loss: -0.026592]\n",
      "epoch0 step5830 [D loss: -0.299257] [G loss: -0.219697]\n",
      "epoch0 step5835 [D loss: -1.101002] [G loss: -0.059969]\n",
      "epoch0 step5840 [D loss: -0.604439] [G loss: -0.437185]\n",
      "epoch0 step5845 [D loss: -1.548821] [G loss: -0.593032]\n",
      "epoch0 step5850 [D loss: -0.574848] [G loss: 0.092491]\n",
      "epoch0 step5855 [D loss: -1.523943] [G loss: 0.092749]\n",
      "epoch0 step5860 [D loss: -0.914045] [G loss: -0.098253]\n",
      "epoch0 step5865 [D loss: -1.611503] [G loss: -0.272651]\n",
      "epoch0 step5870 [D loss: -1.349898] [G loss: 0.143018]\n",
      "epoch0 step5875 [D loss: -1.041756] [G loss: 0.037230]\n",
      "epoch0 step5880 [D loss: -1.389519] [G loss: 0.212472]\n",
      "epoch0 step5885 [D loss: -1.548679] [G loss: 0.201940]\n",
      "epoch0 step5890 [D loss: -1.403552] [G loss: -0.016491]\n",
      "epoch0 step5895 [D loss: -1.099481] [G loss: 0.189480]\n",
      "epoch0 step5900 [D loss: -0.772891] [G loss: 0.772400]\n",
      "epoch0 step5905 [D loss: -0.005992] [G loss: 0.741537]\n",
      "epoch0 step5910 [D loss: 0.143526] [G loss: 0.382861]\n",
      "epoch0 step5915 [D loss: -1.056284] [G loss: 0.563187]\n",
      "epoch0 step5920 [D loss: -0.260435] [G loss: 0.461411]\n",
      "epoch0 step5925 [D loss: -0.947278] [G loss: 0.047079]\n",
      "epoch0 step5930 [D loss: -0.327320] [G loss: 0.580581]\n",
      "epoch0 step5935 [D loss: -0.553714] [G loss: 0.188558]\n",
      "epoch0 step5940 [D loss: -1.520530] [G loss: 0.317761]\n",
      "epoch0 step5945 [D loss: -0.399259] [G loss: 0.252470]\n",
      "epoch0 step5950 [D loss: -0.944236] [G loss: 0.264823]\n",
      "epoch0 step5955 [D loss: -0.486819] [G loss: 0.222301]\n",
      "epoch0 step5960 [D loss: -1.215803] [G loss: 0.115267]\n",
      "epoch0 step5965 [D loss: -0.799948] [G loss: 0.082691]\n",
      "epoch0 step5970 [D loss: -0.325502] [G loss: 0.115221]\n",
      "epoch0 step5975 [D loss: -0.738396] [G loss: -0.013369]\n",
      "epoch0 step5980 [D loss: -0.229707] [G loss: 0.059120]\n",
      "epoch0 step5985 [D loss: -0.763136] [G loss: 0.395153]\n",
      "epoch0 step5990 [D loss: -0.449173] [G loss: -0.239344]\n",
      "epoch0 step5995 [D loss: -0.145545] [G loss: -0.147275]\n",
      "epoch0 step6000 [D loss: -0.918517] [G loss: 0.376638]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.704599\n",
      "FID: 62.377575\n",
      "0 = 14.511931654071745\n",
      "1 = 0.11226646768124933\n",
      "2 = 0.8992999792098999\n",
      "3 = 0.9761999845504761\n",
      "4 = 0.8223999738693237\n",
      "5 = 0.8460738658905029\n",
      "6 = 0.9761999845504761\n",
      "7 = 10.242783889412879\n",
      "8 = 0.15719698989160524\n",
      "9 = 0.8873999714851379\n",
      "10 = 0.8985999822616577\n",
      "11 = 0.8762000203132629\n",
      "12 = 0.8789123892784119\n",
      "13 = 0.8985999822616577\n",
      "14 = 4.704612731933594\n",
      "15 = 8.227486610412598\n",
      "16 = 0.3413116931915283\n",
      "17 = 4.704598903656006\n",
      "18 = 62.3775749206543\n",
      "epoch0 step6005 [D loss: -0.485719] [G loss: -0.319135]\n",
      "epoch0 step6010 [D loss: -1.210201] [G loss: 0.327197]\n",
      "epoch0 step6015 [D loss: -1.042659] [G loss: 0.492664]\n",
      "epoch0 step6020 [D loss: -1.048489] [G loss: 0.965639]\n",
      "epoch0 step6025 [D loss: -0.982506] [G loss: 0.233765]\n",
      "epoch0 step6030 [D loss: -0.218065] [G loss: 0.614583]\n",
      "epoch0 step6035 [D loss: 0.181597] [G loss: 0.542500]\n",
      "epoch0 step6040 [D loss: -0.319085] [G loss: 0.600060]\n",
      "epoch0 step6045 [D loss: -1.180788] [G loss: 0.400782]\n",
      "epoch0 step6050 [D loss: -0.584417] [G loss: -0.005849]\n",
      "epoch0 step6055 [D loss: -1.341378] [G loss: 0.679485]\n",
      "epoch0 step6060 [D loss: -0.255613] [G loss: 0.500829]\n",
      "epoch0 step6065 [D loss: -0.709739] [G loss: 0.721878]\n",
      "epoch0 step6070 [D loss: -0.996236] [G loss: 0.349338]\n",
      "epoch0 step6075 [D loss: -1.062549] [G loss: 0.172335]\n",
      "epoch0 step6080 [D loss: -0.910349] [G loss: 0.403213]\n",
      "epoch0 step6085 [D loss: -1.698970] [G loss: 0.292884]\n",
      "epoch0 step6090 [D loss: -1.065892] [G loss: 0.236046]\n",
      "epoch0 step6095 [D loss: -0.409605] [G loss: -0.122261]\n",
      "epoch0 step6100 [D loss: -1.018344] [G loss: -0.141477]\n",
      "epoch0 step6105 [D loss: -0.872589] [G loss: -0.472685]\n",
      "epoch0 step6110 [D loss: -1.542345] [G loss: 0.224586]\n",
      "epoch0 step6115 [D loss: -0.462795] [G loss: -0.564262]\n",
      "epoch0 step6120 [D loss: -1.023921] [G loss: -0.653019]\n",
      "epoch0 step6125 [D loss: -1.520664] [G loss: -0.625420]\n",
      "epoch0 step6130 [D loss: -0.349293] [G loss: -1.105834]\n",
      "epoch0 step6135 [D loss: -1.026641] [G loss: -1.089427]\n",
      "epoch0 step6140 [D loss: -1.159929] [G loss: -0.867034]\n",
      "epoch0 step6145 [D loss: -1.179282] [G loss: -0.345713]\n",
      "epoch0 step6150 [D loss: -0.627568] [G loss: -0.522119]\n",
      "epoch0 step6155 [D loss: -0.838739] [G loss: -0.779370]\n",
      "epoch0 step6160 [D loss: -0.908435] [G loss: -0.258230]\n",
      "epoch0 step6165 [D loss: -1.243437] [G loss: -0.448249]\n",
      "epoch0 step6170 [D loss: -0.379479] [G loss: -0.664420]\n",
      "epoch0 step6175 [D loss: -0.662365] [G loss: -0.411512]\n",
      "epoch0 step6180 [D loss: -1.294268] [G loss: -0.931785]\n",
      "epoch0 step6185 [D loss: -0.955957] [G loss: -0.447484]\n",
      "epoch0 step6190 [D loss: -0.901108] [G loss: -1.016006]\n",
      "epoch0 step6195 [D loss: -0.641271] [G loss: 0.094572]\n",
      "epoch0 step6200 [D loss: -0.729146] [G loss: -0.092990]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.979527\n",
      "FID: 55.295403\n",
      "0 = 14.628228733348807\n",
      "1 = 0.13526536362798908\n",
      "2 = 0.900600016117096\n",
      "3 = 0.9815999865531921\n",
      "4 = 0.819599986076355\n",
      "5 = 0.8447504043579102\n",
      "6 = 0.9815999865531921\n",
      "7 = 9.928996059060108\n",
      "8 = 0.14624043816502913\n",
      "9 = 0.8816999793052673\n",
      "10 = 0.8916000127792358\n",
      "11 = 0.8718000054359436\n",
      "12 = 0.8742890954017639\n",
      "13 = 0.8916000127792358\n",
      "14 = 4.979539394378662\n",
      "15 = 8.527870178222656\n",
      "16 = 0.30428507924079895\n",
      "17 = 4.979526519775391\n",
      "18 = 55.29540252685547\n",
      "epoch0 step6205 [D loss: -0.852050] [G loss: -0.055559]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 step6210 [D loss: -1.138390] [G loss: -0.102071]\n",
      "epoch0 step6215 [D loss: -1.368806] [G loss: -0.089879]\n",
      "epoch0 step6220 [D loss: -1.104015] [G loss: 0.401256]\n",
      "epoch0 step6225 [D loss: -0.998835] [G loss: 0.020232]\n",
      "epoch0 step6230 [D loss: -0.807761] [G loss: 0.660395]\n",
      "epoch0 step6235 [D loss: -1.204261] [G loss: 0.526747]\n",
      "epoch0 step6240 [D loss: -0.691825] [G loss: -0.121401]\n",
      "epoch0 step6245 [D loss: -0.903630] [G loss: 0.421168]\n",
      "epoch0 step6250 [D loss: -0.389157] [G loss: -0.351438]\n",
      "epoch0 step6255 [D loss: -1.233133] [G loss: -0.395576]\n",
      "epoch0 step6260 [D loss: -0.795743] [G loss: -0.059217]\n",
      "epoch0 step6265 [D loss: -0.507573] [G loss: -0.456273]\n",
      "epoch0 step6270 [D loss: -0.327039] [G loss: -0.160366]\n",
      "epoch0 step6275 [D loss: -1.387588] [G loss: -0.698403]\n",
      "epoch0 step6280 [D loss: -0.940049] [G loss: -0.615360]\n",
      "epoch0 step6285 [D loss: -1.009915] [G loss: -0.549845]\n",
      "epoch0 step6290 [D loss: -1.136586] [G loss: 0.382051]\n",
      "epoch0 step6295 [D loss: -1.161982] [G loss: -0.441977]\n",
      "epoch0 step6300 [D loss: -0.384779] [G loss: -0.646494]\n",
      "epoch0 step6305 [D loss: -1.440512] [G loss: -0.178316]\n",
      "epoch0 step6310 [D loss: -0.905854] [G loss: -0.161498]\n",
      "epoch0 step6315 [D loss: -0.862705] [G loss: -0.624721]\n",
      "epoch0 step6320 [D loss: -1.990150] [G loss: -0.649615]\n",
      "epoch0 step6325 [D loss: -1.148322] [G loss: -0.237803]\n",
      "epoch0 step6330 [D loss: -0.400788] [G loss: -0.337663]\n",
      "epoch0 step6335 [D loss: -1.311624] [G loss: -0.283301]\n",
      "epoch0 step6340 [D loss: -0.666675] [G loss: 0.320053]\n",
      "epoch0 step6345 [D loss: -1.105579] [G loss: -0.062123]\n",
      "epoch0 step6350 [D loss: -0.524042] [G loss: -0.936940]\n",
      "epoch0 step6355 [D loss: -0.753859] [G loss: 0.432363]\n",
      "epoch0 step6360 [D loss: -0.590964] [G loss: -0.064526]\n",
      "epoch0 step6365 [D loss: -0.838592] [G loss: -0.836228]\n",
      "epoch0 step6370 [D loss: -0.375051] [G loss: -0.063831]\n",
      "epoch0 step6375 [D loss: -0.514610] [G loss: -0.337123]\n",
      "epoch0 step6380 [D loss: -0.869767] [G loss: -0.462403]\n",
      "epoch0 step6385 [D loss: -1.073203] [G loss: -0.371134]\n",
      "epoch0 step6390 [D loss: -0.588968] [G loss: 0.273632]\n",
      "epoch0 step6395 [D loss: -0.864964] [G loss: 0.388742]\n",
      "epoch0 step6400 [D loss: -1.229366] [G loss: -0.498344]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.981136\n",
      "FID: 55.920563\n",
      "0 = 14.590685949325545\n",
      "1 = 0.1348540527368413\n",
      "2 = 0.9028000235557556\n",
      "3 = 0.9729999899864197\n",
      "4 = 0.8325999975204468\n",
      "5 = 0.853209376335144\n",
      "6 = 0.9729999899864197\n",
      "7 = 10.0958725737095\n",
      "8 = 0.14704563698831669\n",
      "9 = 0.8921999931335449\n",
      "10 = 0.9049999713897705\n",
      "11 = 0.8794000148773193\n",
      "12 = 0.8824102878570557\n",
      "13 = 0.9049999713897705\n",
      "14 = 4.981151103973389\n",
      "15 = 8.736257553100586\n",
      "16 = 0.2842172384262085\n",
      "17 = 4.981135845184326\n",
      "18 = 55.920562744140625\n",
      "epoch0 step6405 [D loss: -1.589114] [G loss: 0.290273]\n",
      "epoch0 step6410 [D loss: -1.615375] [G loss: 0.264094]\n",
      "epoch0 step6415 [D loss: -1.267227] [G loss: 0.604603]\n",
      "epoch0 step6420 [D loss: -1.251290] [G loss: 0.455611]\n",
      "epoch0 step6425 [D loss: -1.544024] [G loss: 0.763368]\n",
      "epoch0 step6430 [D loss: -1.236045] [G loss: 0.686142]\n",
      "epoch0 step6435 [D loss: -1.492714] [G loss: 0.443911]\n",
      "epoch0 step6440 [D loss: -1.016072] [G loss: 0.145937]\n",
      "epoch0 step6445 [D loss: -1.311101] [G loss: -0.237180]\n",
      "epoch0 step6450 [D loss: -0.855450] [G loss: 0.327232]\n",
      "epoch0 step6455 [D loss: -0.272409] [G loss: -0.009084]\n",
      "epoch0 step6460 [D loss: -1.183765] [G loss: 0.011969]\n",
      "epoch0 step6465 [D loss: -1.347207] [G loss: 0.659724]\n",
      "epoch0 step6470 [D loss: -0.627989] [G loss: 0.318553]\n",
      "epoch0 step6475 [D loss: -0.767891] [G loss: 0.914174]\n",
      "epoch0 step6480 [D loss: -0.497629] [G loss: 0.584811]\n",
      "epoch0 step6485 [D loss: -0.602381] [G loss: 1.153321]\n",
      "epoch0 step6490 [D loss: -1.118916] [G loss: 0.831872]\n",
      "epoch0 step6495 [D loss: -0.693334] [G loss: 0.672055]\n",
      "epoch0 step6500 [D loss: -0.852213] [G loss: 0.395285]\n",
      "epoch0 step6505 [D loss: -0.756721] [G loss: 0.805125]\n",
      "epoch0 step6510 [D loss: -0.838189] [G loss: 0.500689]\n",
      "epoch0 step6515 [D loss: -0.636732] [G loss: 0.809221]\n",
      "epoch0 step6520 [D loss: -0.022680] [G loss: 0.580657]\n",
      "epoch0 step6525 [D loss: -1.174313] [G loss: 1.050591]\n",
      "epoch0 step6530 [D loss: -0.027496] [G loss: 0.742368]\n",
      "epoch0 step6535 [D loss: -1.299004] [G loss: 0.754620]\n",
      "epoch0 step6540 [D loss: -0.506663] [G loss: 0.541662]\n",
      "epoch0 step6545 [D loss: -0.413818] [G loss: 0.744478]\n",
      "epoch0 step6550 [D loss: -1.181536] [G loss: 0.485776]\n",
      "epoch0 step6555 [D loss: -0.511606] [G loss: 0.560161]\n",
      "epoch0 step6560 [D loss: -0.804148] [G loss: 0.903082]\n",
      "epoch0 step6565 [D loss: -0.813815] [G loss: 0.351168]\n",
      "epoch0 step6570 [D loss: -0.620593] [G loss: -0.025758]\n",
      "epoch0 step6575 [D loss: -0.686104] [G loss: -0.008076]\n",
      "epoch0 step6580 [D loss: -0.227218] [G loss: 0.555079]\n",
      "epoch0 step6585 [D loss: -0.542925] [G loss: 0.041232]\n",
      "epoch0 step6590 [D loss: -0.887209] [G loss: -0.151119]\n",
      "epoch0 step6595 [D loss: -0.205982] [G loss: -0.319604]\n",
      "epoch0 step6600 [D loss: -0.593884] [G loss: 0.531671]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.977338\n",
      "FID: 55.440983\n",
      "0 = 16.411014501380983\n",
      "1 = 0.2413295191819958\n",
      "2 = 0.9107000231742859\n",
      "3 = 0.9865999817848206\n",
      "4 = 0.8348000049591064\n",
      "5 = 0.8565723299980164\n",
      "6 = 0.9865999817848206\n",
      "7 = 10.161785222673425\n",
      "8 = 0.14699333780463575\n",
      "9 = 0.8988000154495239\n",
      "10 = 0.9100000262260437\n",
      "11 = 0.8876000046730042\n",
      "12 = 0.8900625705718994\n",
      "13 = 0.9100000262260437\n",
      "14 = 4.977349281311035\n",
      "15 = 8.638304710388184\n",
      "16 = 0.28893086314201355\n",
      "17 = 4.977337837219238\n",
      "18 = 55.440982818603516\n",
      "epoch0 step6605 [D loss: -0.574540] [G loss: -0.159279]\n",
      "epoch0 step6610 [D loss: -1.099177] [G loss: -0.056683]\n",
      "epoch0 step6615 [D loss: -0.348747] [G loss: 0.056704]\n",
      "epoch0 step6620 [D loss: -1.307345] [G loss: 0.836894]\n",
      "epoch0 step6625 [D loss: -0.813274] [G loss: 0.043870]\n",
      "epoch0 step6630 [D loss: -1.157912] [G loss: 0.632374]\n",
      "epoch0 step6635 [D loss: -1.687991] [G loss: 0.990347]\n",
      "epoch0 step6640 [D loss: -1.653574] [G loss: 1.097124]\n",
      "epoch0 step6645 [D loss: -1.495415] [G loss: 1.461902]\n",
      "epoch0 step6650 [D loss: -1.344961] [G loss: 0.941351]\n",
      "epoch0 step6655 [D loss: -0.773913] [G loss: 0.658546]\n",
      "epoch0 step6660 [D loss: -0.508291] [G loss: 1.439651]\n",
      "epoch0 step6665 [D loss: -0.771720] [G loss: 1.322417]\n",
      "epoch0 step6670 [D loss: -1.292402] [G loss: 1.490640]\n",
      "epoch0 step6675 [D loss: -0.868143] [G loss: 1.437254]\n",
      "epoch0 step6680 [D loss: -1.528901] [G loss: 1.403196]\n",
      "epoch0 step6685 [D loss: -1.008039] [G loss: 1.656202]\n",
      "epoch0 step6690 [D loss: -0.614888] [G loss: 1.077536]\n",
      "epoch0 step6695 [D loss: -0.381010] [G loss: 0.546912]\n",
      "epoch0 step6700 [D loss: -0.862806] [G loss: 1.153686]\n",
      "epoch0 step6705 [D loss: -1.148514] [G loss: 0.778186]\n",
      "epoch0 step6710 [D loss: -1.462930] [G loss: 0.886688]\n",
      "epoch0 step6715 [D loss: -1.114421] [G loss: 0.315764]\n",
      "epoch0 step6720 [D loss: -0.680977] [G loss: 0.527889]\n",
      "epoch0 step6725 [D loss: -0.505085] [G loss: 0.481731]\n",
      "epoch0 step6730 [D loss: -0.824875] [G loss: 0.311012]\n",
      "epoch0 step6735 [D loss: -0.374463] [G loss: -0.095808]\n",
      "epoch0 step6740 [D loss: -1.112499] [G loss: -0.452918]\n",
      "epoch0 step6745 [D loss: -0.811236] [G loss: -0.380344]\n",
      "epoch0 step6750 [D loss: -0.965812] [G loss: -0.917823]\n",
      "epoch0 step6755 [D loss: -0.828791] [G loss: 0.120677]\n",
      "epoch0 step6760 [D loss: -0.504046] [G loss: -0.322440]\n",
      "epoch0 step6765 [D loss: -0.500008] [G loss: -0.376680]\n",
      "epoch0 step6770 [D loss: -1.010793] [G loss: -0.709359]\n",
      "epoch0 step6775 [D loss: -1.451667] [G loss: -0.141772]\n",
      "epoch0 step6780 [D loss: -1.045982] [G loss: -0.452501]\n",
      "epoch0 step6785 [D loss: -0.993382] [G loss: -0.245270]\n",
      "epoch0 step6790 [D loss: -0.601952] [G loss: -0.403533]\n",
      "epoch0 step6795 [D loss: -1.046633] [G loss: -0.222669]\n",
      "epoch0 step6800 [D loss: -0.945065] [G loss: 0.317535]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.913619\n",
      "FID: 57.118496\n",
      "0 = 14.547043871402778\n",
      "1 = 0.11639082633636222\n",
      "2 = 0.8891000151634216\n",
      "3 = 0.9757999777793884\n",
      "4 = 0.8023999929428101\n",
      "5 = 0.8316004872322083\n",
      "6 = 0.9757999777793884\n",
      "7 = 10.09781803119182\n",
      "8 = 0.15141325218929022\n",
      "9 = 0.886900007724762\n",
      "10 = 0.8985999822616577\n",
      "11 = 0.8751999735832214\n",
      "12 = 0.8780535459518433\n",
      "13 = 0.8985999822616577\n",
      "14 = 4.913628578186035\n",
      "15 = 8.639800071716309\n",
      "16 = 0.29996323585510254\n",
      "17 = 4.913618564605713\n",
      "18 = 57.11849594116211\n",
      "epoch0 step6805 [D loss: -0.928293] [G loss: -0.277420]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 step6810 [D loss: -0.771262] [G loss: 0.091782]\n",
      "epoch0 step6815 [D loss: -0.830301] [G loss: -0.067930]\n",
      "epoch0 step6820 [D loss: -0.909311] [G loss: 0.172994]\n",
      "epoch0 step6825 [D loss: -0.323099] [G loss: 0.284327]\n",
      "epoch0 step6830 [D loss: -0.556922] [G loss: 0.522836]\n",
      "epoch0 step6835 [D loss: -0.195862] [G loss: -0.114963]\n",
      "epoch0 step6840 [D loss: -0.652488] [G loss: -0.012942]\n",
      "epoch0 step6845 [D loss: -0.617168] [G loss: -0.226647]\n",
      "epoch0 step6850 [D loss: -1.123294] [G loss: -0.238519]\n",
      "epoch0 step6855 [D loss: -0.978045] [G loss: -0.436321]\n",
      "epoch0 step6860 [D loss: -0.593827] [G loss: -0.231324]\n",
      "epoch0 step6865 [D loss: -0.738731] [G loss: -0.128292]\n",
      "epoch0 step6870 [D loss: -0.772573] [G loss: -0.390322]\n",
      "epoch0 step6875 [D loss: -0.650152] [G loss: -0.445569]\n",
      "epoch0 step6880 [D loss: -1.219436] [G loss: 0.313357]\n",
      "epoch0 step6885 [D loss: -0.200879] [G loss: 0.394883]\n",
      "epoch0 step6890 [D loss: -1.748945] [G loss: 0.079622]\n",
      "epoch0 step6895 [D loss: -0.026257] [G loss: -0.147127]\n",
      "epoch0 step6900 [D loss: -1.083942] [G loss: 0.226164]\n",
      "epoch0 step6905 [D loss: -1.522773] [G loss: -0.144579]\n",
      "epoch0 step6910 [D loss: -0.967374] [G loss: 0.302138]\n",
      "epoch0 step6915 [D loss: 0.064478] [G loss: -0.317240]\n",
      "epoch0 step6920 [D loss: -0.825740] [G loss: 0.118204]\n",
      "epoch0 step6925 [D loss: -0.840171] [G loss: 0.240370]\n",
      "epoch0 step6930 [D loss: -1.408358] [G loss: 0.115226]\n",
      "epoch0 step6935 [D loss: -0.706344] [G loss: 0.439161]\n",
      "epoch0 step6940 [D loss: -1.132086] [G loss: 0.374404]\n",
      "epoch0 step6945 [D loss: -1.264635] [G loss: -0.145058]\n",
      "epoch0 step6950 [D loss: -0.901657] [G loss: 0.186593]\n",
      "epoch0 step6955 [D loss: -0.527604] [G loss: 0.460751]\n",
      "epoch0 step6960 [D loss: -0.261777] [G loss: -0.413861]\n",
      "epoch0 step6965 [D loss: -0.954911] [G loss: -0.294803]\n",
      "epoch0 step6970 [D loss: -0.598111] [G loss: -0.240622]\n",
      "epoch0 step6975 [D loss: -0.737431] [G loss: 0.387225]\n",
      "epoch0 step6980 [D loss: -1.438591] [G loss: 0.105651]\n",
      "epoch0 step6985 [D loss: -0.185837] [G loss: -0.194963]\n",
      "epoch0 step6990 [D loss: -1.289003] [G loss: -0.291987]\n",
      "epoch0 step6995 [D loss: -0.797102] [G loss: -0.134561]\n",
      "epoch0 step7000 [D loss: -1.221387] [G loss: -0.050971]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.180716\n",
      "FID: 47.502396\n",
      "0 = 14.887785549926743\n",
      "1 = 0.13198505022181742\n",
      "2 = 0.8822000026702881\n",
      "3 = 0.9824000000953674\n",
      "4 = 0.7820000052452087\n",
      "5 = 0.818393886089325\n",
      "6 = 0.9824000000953674\n",
      "7 = 9.7938296778202\n",
      "8 = 0.13492872899973846\n",
      "9 = 0.8848999738693237\n",
      "10 = 0.9021999835968018\n",
      "11 = 0.8676000237464905\n",
      "12 = 0.8720278143882751\n",
      "13 = 0.9021999835968018\n",
      "14 = 5.180727481842041\n",
      "15 = 8.876361846923828\n",
      "16 = 0.26831480860710144\n",
      "17 = 5.180715560913086\n",
      "18 = 47.50239562988281\n",
      "epoch0 step7005 [D loss: -1.787031] [G loss: 0.380813]\n",
      "epoch0 step7010 [D loss: -1.721094] [G loss: -0.168093]\n",
      "epoch0 step7015 [D loss: -0.555316] [G loss: 0.158773]\n",
      "epoch0 step7020 [D loss: -0.693325] [G loss: -0.361286]\n",
      "epoch0 step7025 [D loss: -0.547538] [G loss: -0.845641]\n",
      "epoch0 step7030 [D loss: 0.036245] [G loss: -0.534058]\n",
      "epoch0 step7035 [D loss: -0.319204] [G loss: -0.280319]\n",
      "epoch0 step7040 [D loss: -0.840078] [G loss: -0.210676]\n",
      "epoch0 step7045 [D loss: -0.996089] [G loss: -0.227258]\n",
      "epoch0 step7050 [D loss: -0.125419] [G loss: 0.640507]\n",
      "epoch0 step7055 [D loss: -1.339794] [G loss: -0.083662]\n",
      "epoch0 step7060 [D loss: -1.652639] [G loss: -0.053389]\n",
      "epoch0 step7065 [D loss: -1.698699] [G loss: 0.809096]\n",
      "epoch0 step7070 [D loss: -1.232483] [G loss: 0.572252]\n",
      "epoch0 step7075 [D loss: -1.434848] [G loss: 0.690745]\n",
      "epoch0 step7080 [D loss: -1.383048] [G loss: 0.086473]\n",
      "epoch0 step7085 [D loss: -1.612582] [G loss: 1.041442]\n",
      "epoch0 step7090 [D loss: -2.002583] [G loss: 1.413077]\n",
      "epoch0 step7095 [D loss: -1.619443] [G loss: 0.936566]\n",
      "epoch0 step7100 [D loss: -0.680678] [G loss: 1.039627]\n",
      "epoch0 step7105 [D loss: -1.235074] [G loss: 1.571727]\n",
      "epoch0 step7110 [D loss: -0.280524] [G loss: 1.477575]\n",
      "epoch0 step7115 [D loss: -1.552975] [G loss: 1.137634]\n",
      "epoch0 step7120 [D loss: -1.439259] [G loss: 1.749485]\n",
      "epoch0 step7125 [D loss: -0.966244] [G loss: 1.363482]\n",
      "epoch0 step7130 [D loss: -1.810640] [G loss: 1.300190]\n",
      "epoch0 step7135 [D loss: -0.455380] [G loss: 0.989564]\n",
      "epoch0 step7140 [D loss: -1.033987] [G loss: 1.789730]\n",
      "epoch0 step7145 [D loss: -1.023629] [G loss: 0.955956]\n",
      "epoch0 step7150 [D loss: -0.470013] [G loss: 1.009439]\n",
      "epoch0 step7155 [D loss: -0.843043] [G loss: 1.167861]\n",
      "epoch0 step7160 [D loss: -0.900422] [G loss: 1.020896]\n",
      "epoch0 step7165 [D loss: 0.117296] [G loss: 1.039407]\n",
      "epoch0 step7170 [D loss: -0.603231] [G loss: 1.501675]\n",
      "epoch0 step7175 [D loss: -0.023167] [G loss: 0.737850]\n",
      "epoch0 step7180 [D loss: 0.149871] [G loss: 0.989868]\n",
      "epoch0 step7185 [D loss: -0.553233] [G loss: 1.416902]\n",
      "epoch0 step7190 [D loss: -1.243493] [G loss: 1.265665]\n",
      "epoch0 step7195 [D loss: -1.104926] [G loss: 1.040530]\n",
      "epoch0 step7200 [D loss: -0.462264] [G loss: 0.884692]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.080399\n",
      "FID: 51.527779\n",
      "0 = 14.272128010845192\n",
      "1 = 0.09004189575768706\n",
      "2 = 0.8842999935150146\n",
      "3 = 0.972599983215332\n",
      "4 = 0.7960000038146973\n",
      "5 = 0.8266190886497498\n",
      "6 = 0.972599983215332\n",
      "7 = 9.904589992094035\n",
      "8 = 0.14322546751851933\n",
      "9 = 0.8816999793052673\n",
      "10 = 0.8980000019073486\n",
      "11 = 0.8654000163078308\n",
      "12 = 0.8696494102478027\n",
      "13 = 0.8980000019073486\n",
      "14 = 5.080414772033691\n",
      "15 = 8.652240753173828\n",
      "16 = 0.2915423810482025\n",
      "17 = 5.080399036407471\n",
      "18 = 51.52777862548828\n",
      "epoch0 step7205 [D loss: -0.098483] [G loss: 1.078509]\n",
      "epoch0 step7210 [D loss: -0.421263] [G loss: 1.586970]\n",
      "epoch0 step7215 [D loss: -0.370624] [G loss: 1.242862]\n",
      "epoch0 step7220 [D loss: -0.486530] [G loss: 1.331601]\n",
      "epoch0 step7225 [D loss: -0.431491] [G loss: 0.726241]\n",
      "epoch0 step7230 [D loss: -0.342159] [G loss: 0.667787]\n",
      "epoch0 step7235 [D loss: -0.908437] [G loss: 0.898467]\n",
      "epoch0 step7240 [D loss: -1.053931] [G loss: 0.645936]\n",
      "epoch0 step7245 [D loss: -0.367669] [G loss: 0.708918]\n",
      "epoch0 step7250 [D loss: -1.508420] [G loss: 1.253364]\n",
      "epoch0 step7255 [D loss: -0.727877] [G loss: 1.023618]\n",
      "epoch0 step7260 [D loss: -1.567970] [G loss: 1.417099]\n",
      "epoch0 step7265 [D loss: -1.039775] [G loss: 0.842367]\n",
      "epoch0 step7270 [D loss: -1.029116] [G loss: 1.405892]\n",
      "epoch0 step7275 [D loss: -0.150541] [G loss: 0.960748]\n",
      "epoch0 step7280 [D loss: -0.707021] [G loss: 1.003105]\n",
      "epoch0 step7285 [D loss: -1.099363] [G loss: 0.814828]\n",
      "epoch0 step7290 [D loss: -0.406371] [G loss: 0.527844]\n",
      "epoch0 step7295 [D loss: -1.023534] [G loss: 1.000462]\n",
      "epoch0 step7300 [D loss: -1.211809] [G loss: 0.802678]\n",
      "epoch0 step7305 [D loss: -0.375877] [G loss: 0.705877]\n",
      "epoch0 step7310 [D loss: -1.162924] [G loss: 0.028196]\n",
      "epoch0 step7315 [D loss: -1.160544] [G loss: 0.213252]\n",
      "epoch0 step7320 [D loss: -1.332506] [G loss: 0.141464]\n",
      "epoch0 step7325 [D loss: -0.663855] [G loss: 0.442948]\n",
      "epoch0 step7330 [D loss: -1.072943] [G loss: 0.744884]\n",
      "epoch0 step7335 [D loss: -0.857856] [G loss: 0.656241]\n",
      "epoch0 step7340 [D loss: -1.114032] [G loss: 0.338811]\n",
      "epoch0 step7345 [D loss: -0.721050] [G loss: 0.509164]\n",
      "epoch0 step7350 [D loss: -0.165860] [G loss: 0.729940]\n",
      "epoch0 step7355 [D loss: -0.508695] [G loss: 1.023494]\n",
      "epoch0 step7360 [D loss: -0.795010] [G loss: 0.820653]\n",
      "epoch0 step7365 [D loss: -1.130819] [G loss: 1.021381]\n",
      "epoch0 step7370 [D loss: -0.601887] [G loss: 0.423852]\n",
      "epoch0 step7375 [D loss: -0.062073] [G loss: 0.618904]\n",
      "epoch0 step7380 [D loss: 0.233670] [G loss: 0.516306]\n",
      "epoch0 step7385 [D loss: -0.738974] [G loss: 0.689871]\n",
      "epoch0 step7390 [D loss: -0.376174] [G loss: 0.058585]\n",
      "epoch0 step7395 [D loss: -0.905419] [G loss: 0.543283]\n",
      "epoch0 step7400 [D loss: -0.962712] [G loss: 0.652093]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.882495\n",
      "FID: 60.541752\n",
      "0 = 13.394211725616499\n",
      "1 = 0.06824854995249112\n",
      "2 = 0.9014999866485596\n",
      "3 = 0.9602000117301941\n",
      "4 = 0.8428000211715698\n",
      "5 = 0.8593162894248962\n",
      "6 = 0.9602000117301941\n",
      "7 = 10.237136515998833\n",
      "8 = 0.15744325857015742\n",
      "9 = 0.8945000171661377\n",
      "10 = 0.901199996471405\n",
      "11 = 0.8877999782562256\n",
      "12 = 0.8892835974693298\n",
      "13 = 0.901199996471405\n",
      "14 = 4.882504463195801\n",
      "15 = 8.719344139099121\n",
      "16 = 0.2977926731109619\n",
      "17 = 4.882495403289795\n",
      "18 = 60.541751861572266\n",
      "epoch0 step7405 [D loss: -1.418490] [G loss: 0.384940]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 step7410 [D loss: -0.308204] [G loss: 0.472356]\n",
      "epoch0 step7415 [D loss: -0.210355] [G loss: -0.256833]\n",
      "epoch0 step7420 [D loss: -1.174127] [G loss: 0.652179]\n",
      "epoch0 step7425 [D loss: -0.926851] [G loss: 0.117767]\n",
      "epoch0 step7430 [D loss: -0.403969] [G loss: -0.118954]\n",
      "epoch0 step7435 [D loss: -1.398950] [G loss: 0.851336]\n",
      "epoch0 step7440 [D loss: -0.305827] [G loss: 0.959598]\n",
      "epoch0 step7445 [D loss: -0.314122] [G loss: 0.532923]\n",
      "epoch0 step7450 [D loss: -0.784814] [G loss: 0.477573]\n",
      "epoch0 step7455 [D loss: -0.684002] [G loss: 0.788624]\n",
      "epoch0 step7460 [D loss: -0.981405] [G loss: 1.320864]\n",
      "epoch0 step7465 [D loss: -1.726694] [G loss: 1.061773]\n",
      "epoch0 step7470 [D loss: -0.653651] [G loss: 0.693588]\n",
      "epoch0 step7475 [D loss: -0.988795] [G loss: 0.983967]\n",
      "epoch0 step7480 [D loss: -1.660952] [G loss: 1.185327]\n",
      "epoch0 step7485 [D loss: -0.486995] [G loss: 0.599907]\n",
      "epoch0 step7490 [D loss: -1.271819] [G loss: 0.479606]\n",
      "epoch0 step7495 [D loss: -1.291382] [G loss: 0.426765]\n",
      "epoch0 step7500 [D loss: -1.027268] [G loss: 0.776219]\n",
      "epoch0 step7505 [D loss: -1.015853] [G loss: 0.115796]\n",
      "epoch0 step7510 [D loss: -0.317627] [G loss: 1.485307]\n",
      "epoch0 step7515 [D loss: -0.513698] [G loss: -0.153250]\n",
      "epoch0 step7520 [D loss: -1.001853] [G loss: 0.965442]\n",
      "epoch0 step7525 [D loss: -0.111803] [G loss: 0.425637]\n",
      "epoch0 step7530 [D loss: -0.834329] [G loss: 0.541746]\n",
      "epoch0 step7535 [D loss: -0.772972] [G loss: 0.683278]\n",
      "epoch0 step7540 [D loss: -0.356820] [G loss: 0.911665]\n",
      "epoch0 step7545 [D loss: -0.678829] [G loss: 0.905915]\n",
      "epoch0 step7550 [D loss: -1.019066] [G loss: 0.800024]\n",
      "epoch0 step7555 [D loss: -0.566177] [G loss: 0.272314]\n",
      "epoch0 step7560 [D loss: -0.539726] [G loss: 0.422715]\n",
      "epoch0 step7565 [D loss: -0.463645] [G loss: 0.853659]\n",
      "epoch0 step7570 [D loss: -0.597675] [G loss: 1.112436]\n",
      "epoch0 step7575 [D loss: -1.033019] [G loss: 0.455059]\n",
      "epoch0 step7580 [D loss: -0.773517] [G loss: 0.541052]\n",
      "epoch0 step7585 [D loss: -0.897258] [G loss: 1.294217]\n",
      "epoch0 step7590 [D loss: -0.779605] [G loss: 0.519665]\n",
      "epoch0 step7595 [D loss: -0.575903] [G loss: 0.740654]\n",
      "epoch0 step7600 [D loss: 0.226545] [G loss: 0.926039]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.237489\n",
      "FID: 52.591297\n",
      "0 = 13.35371159973143\n",
      "1 = 0.074321474962658\n",
      "2 = 0.8984000086784363\n",
      "3 = 0.9570000171661377\n",
      "4 = 0.8398000001907349\n",
      "5 = 0.8566058278083801\n",
      "6 = 0.9570000171661377\n",
      "7 = 9.821508568787605\n",
      "8 = 0.14091250381923168\n",
      "9 = 0.8797000050544739\n",
      "10 = 0.8921999931335449\n",
      "11 = 0.8672000169754028\n",
      "12 = 0.8704390525817871\n",
      "13 = 0.8921999931335449\n",
      "14 = 5.237504482269287\n",
      "15 = 9.223904609680176\n",
      "16 = 0.22754698991775513\n",
      "17 = 5.237488746643066\n",
      "18 = 52.5912971496582\n",
      "epoch0 step7605 [D loss: -0.575871] [G loss: 0.594761]\n",
      "epoch0 step7610 [D loss: -0.330302] [G loss: 1.100753]\n",
      "epoch0 step7615 [D loss: -0.992827] [G loss: 0.849221]\n",
      "epoch0 step7620 [D loss: -0.542762] [G loss: 0.600335]\n",
      "epoch0 step7625 [D loss: -0.477303] [G loss: 0.633217]\n",
      "epoch0 step7630 [D loss: -1.170483] [G loss: 1.096388]\n",
      "epoch0 step7635 [D loss: -0.868549] [G loss: 0.349265]\n",
      "epoch0 step7640 [D loss: -0.022879] [G loss: -0.297711]\n",
      "epoch0 step7645 [D loss: -0.765607] [G loss: 0.294521]\n",
      "epoch0 step7650 [D loss: -0.288134] [G loss: 0.823407]\n",
      "epoch0 step7655 [D loss: -0.370946] [G loss: 0.088074]\n",
      "epoch0 step7660 [D loss: -0.511834] [G loss: 0.059449]\n",
      "epoch0 step7665 [D loss: -0.884860] [G loss: -0.072072]\n",
      "epoch0 step7670 [D loss: -0.273542] [G loss: -0.430230]\n",
      "epoch0 step7675 [D loss: -0.621676] [G loss: 0.788688]\n",
      "epoch0 step7680 [D loss: -0.637315] [G loss: 0.525657]\n",
      "epoch0 step7685 [D loss: -0.341798] [G loss: 0.204351]\n",
      "epoch0 step7690 [D loss: -1.778432] [G loss: 0.723849]\n",
      "epoch0 step7695 [D loss: 0.278607] [G loss: 0.906805]\n",
      "epoch0 step7700 [D loss: -0.969767] [G loss: 1.313673]\n",
      "epoch0 step7705 [D loss: -0.793339] [G loss: 0.758858]\n",
      "epoch0 step7710 [D loss: -0.962109] [G loss: 0.856155]\n",
      "epoch0 step7715 [D loss: -0.395382] [G loss: 0.963917]\n",
      "epoch0 step7720 [D loss: -0.959689] [G loss: 1.491676]\n",
      "epoch0 step7725 [D loss: -1.255431] [G loss: 1.164486]\n",
      "epoch0 step7730 [D loss: -0.739791] [G loss: 1.347155]\n",
      "epoch0 step7735 [D loss: -0.833610] [G loss: 0.799634]\n",
      "epoch0 step7740 [D loss: -0.386607] [G loss: 0.958492]\n",
      "epoch0 step7745 [D loss: -0.850963] [G loss: 1.687058]\n",
      "epoch0 step7750 [D loss: -1.051838] [G loss: 1.520169]\n",
      "epoch0 step7755 [D loss: -0.868410] [G loss: 1.115905]\n",
      "epoch0 step7760 [D loss: -0.779839] [G loss: 1.225204]\n",
      "epoch0 step7765 [D loss: -1.296038] [G loss: 1.255737]\n",
      "epoch0 step7770 [D loss: -0.750409] [G loss: 1.404649]\n",
      "epoch0 step7775 [D loss: -0.748881] [G loss: 1.065355]\n",
      "epoch0 step7780 [D loss: -0.447471] [G loss: 0.830506]\n",
      "epoch0 step7785 [D loss: -0.023201] [G loss: 0.511867]\n",
      "epoch0 step7790 [D loss: -0.765262] [G loss: 1.034195]\n",
      "epoch0 step7795 [D loss: -0.684776] [G loss: 0.907450]\n",
      "epoch0 step7800 [D loss: -0.385866] [G loss: 0.472491]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.413936\n",
      "FID: 47.109596\n",
      "0 = 14.010450063991566\n",
      "1 = 0.10153139078089991\n",
      "2 = 0.8835999965667725\n",
      "3 = 0.9642000198364258\n",
      "4 = 0.8029999732971191\n",
      "5 = 0.8303478956222534\n",
      "6 = 0.9642000198364258\n",
      "7 = 9.598485348129275\n",
      "8 = 0.13382870720215048\n",
      "9 = 0.870199978351593\n",
      "10 = 0.8849999904632568\n",
      "11 = 0.855400025844574\n",
      "12 = 0.8595570921897888\n",
      "13 = 0.8849999904632568\n",
      "14 = 5.413949966430664\n",
      "15 = 9.112933158874512\n",
      "16 = 0.23321710526943207\n",
      "17 = 5.413936138153076\n",
      "18 = 47.109596252441406\n",
      "epoch0 step7805 [D loss: -0.875240] [G loss: 0.853058]\n",
      "epoch0 step7810 [D loss: -1.579828] [G loss: 0.830260]\n",
      "epoch0 step7815 [D loss: -1.079741] [G loss: 1.562212]\n",
      "epoch0 step7820 [D loss: -0.910338] [G loss: 1.115822]\n",
      "epoch0 step7825 [D loss: -1.288994] [G loss: 0.913379]\n",
      "epoch0 step7830 [D loss: -0.143696] [G loss: 0.498839]\n",
      "epoch0 step7835 [D loss: -0.843989] [G loss: 0.322381]\n",
      "epoch0 step7840 [D loss: -0.869237] [G loss: -0.376421]\n",
      "epoch0 step7845 [D loss: -0.644658] [G loss: -0.301461]\n",
      "epoch0 step7850 [D loss: -0.299436] [G loss: 0.169696]\n",
      "epoch0 step7855 [D loss: -0.259848] [G loss: -0.698834]\n",
      "epoch0 step7860 [D loss: -1.233950] [G loss: -0.287565]\n",
      "epoch0 step7865 [D loss: 0.026467] [G loss: -0.426337]\n",
      "epoch0 step7870 [D loss: 0.105375] [G loss: -0.422029]\n",
      "epoch0 step7875 [D loss: -0.219876] [G loss: -0.646129]\n",
      "epoch0 step7880 [D loss: -0.695366] [G loss: -0.538572]\n",
      "epoch0 step7885 [D loss: -0.945611] [G loss: -1.000633]\n",
      "epoch0 step7890 [D loss: -0.794364] [G loss: -0.208742]\n",
      "epoch0 step7895 [D loss: -0.786464] [G loss: -0.268517]\n",
      "epoch0 step7900 [D loss: -0.689479] [G loss: 0.136123]\n",
      "epoch0 step7905 [D loss: -1.006974] [G loss: -0.140403]\n",
      "epoch0 step7910 [D loss: -0.854817] [G loss: -0.382088]\n",
      "epoch0 step7915 [D loss: -0.803743] [G loss: -0.086655]\n",
      "epoch0 step7920 [D loss: -2.237085] [G loss: -0.587586]\n",
      "epoch0 step7925 [D loss: -1.084473] [G loss: -0.199744]\n",
      "epoch0 step7930 [D loss: -0.643124] [G loss: -0.068357]\n",
      "epoch0 step7935 [D loss: -0.386493] [G loss: -0.162845]\n",
      "epoch0 step7940 [D loss: -1.304114] [G loss: -0.125635]\n",
      "epoch0 step7945 [D loss: -0.716685] [G loss: -0.518958]\n",
      "epoch0 step7950 [D loss: -1.128638] [G loss: -0.050545]\n",
      "epoch0 step7955 [D loss: -1.225943] [G loss: 0.360667]\n",
      "epoch0 step7960 [D loss: -0.584997] [G loss: 0.306876]\n",
      "epoch0 step7965 [D loss: -0.579890] [G loss: -0.068231]\n",
      "epoch0 step7970 [D loss: 0.133884] [G loss: 0.139089]\n",
      "epoch0 step7975 [D loss: -0.276454] [G loss: -0.639102]\n",
      "epoch0 step7980 [D loss: -0.638711] [G loss: -0.532787]\n",
      "epoch0 step7985 [D loss: 0.107688] [G loss: -0.316286]\n",
      "epoch0 step7990 [D loss: 0.204151] [G loss: -0.287304]\n",
      "epoch0 step7995 [D loss: 0.014012] [G loss: 0.314061]\n",
      "epoch0 step8000 [D loss: -0.087071] [G loss: -0.252705]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.274241\n",
      "FID: 49.492455\n",
      "0 = 14.310625188159959\n",
      "1 = 0.13358530832132776\n",
      "2 = 0.8845999836921692\n",
      "3 = 0.9648000001907349\n",
      "4 = 0.8044000267982483\n",
      "5 = 0.8314374089241028\n",
      "6 = 0.9648000001907349\n",
      "7 = 9.628510780167556\n",
      "8 = 0.14145795182563825\n",
      "9 = 0.8665000200271606\n",
      "10 = 0.8823999762535095\n",
      "11 = 0.850600004196167\n",
      "12 = 0.8552045226097107\n",
      "13 = 0.8823999762535095\n",
      "14 = 5.2742509841918945\n",
      "15 = 8.80610179901123\n",
      "16 = 0.27000758051872253\n",
      "17 = 5.274240970611572\n",
      "18 = 49.492454528808594\n",
      "epoch0 step8005 [D loss: 0.136062] [G loss: -0.864108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 step8010 [D loss: -1.057873] [G loss: -0.079316]\n",
      "epoch0 step8015 [D loss: -1.215318] [G loss: 0.610328]\n",
      "epoch0 step8020 [D loss: -0.086316] [G loss: 0.037537]\n",
      "epoch0 step8025 [D loss: -0.859438] [G loss: -0.248551]\n",
      "epoch0 step8030 [D loss: -0.445008] [G loss: 0.597906]\n",
      "epoch0 step8035 [D loss: -0.252322] [G loss: 0.548807]\n",
      "epoch0 step8040 [D loss: -0.905956] [G loss: 0.735661]\n",
      "epoch0 step8045 [D loss: 0.653861] [G loss: 0.606487]\n",
      "epoch0 step8050 [D loss: -0.823489] [G loss: 1.065035]\n",
      "epoch0 step8055 [D loss: -1.727122] [G loss: 1.212612]\n",
      "epoch0 step8060 [D loss: -1.259748] [G loss: 1.302117]\n",
      "epoch0 step8065 [D loss: -1.081865] [G loss: 1.507006]\n",
      "epoch0 step8070 [D loss: -0.684413] [G loss: 1.400537]\n",
      "epoch0 step8075 [D loss: -0.002876] [G loss: 2.159652]\n",
      "epoch0 step8080 [D loss: -0.849262] [G loss: 2.035758]\n",
      "epoch0 step8085 [D loss: -0.619240] [G loss: 2.014799]\n",
      "epoch0 step8090 [D loss: -0.247352] [G loss: 1.549504]\n",
      "epoch0 step8095 [D loss: -0.418553] [G loss: 2.280411]\n",
      "epoch0 step8100 [D loss: -0.808127] [G loss: 1.976119]\n",
      "epoch0 step8105 [D loss: -0.204176] [G loss: 1.706559]\n",
      "epoch0 step8110 [D loss: -1.288355] [G loss: 2.124454]\n",
      "epoch0 step8115 [D loss: -0.738775] [G loss: 1.729821]\n",
      "epoch0 step8120 [D loss: -0.040966] [G loss: 1.363193]\n",
      "epoch0 step8125 [D loss: -0.492197] [G loss: 1.619100]\n",
      "epoch0 step8130 [D loss: -1.082807] [G loss: 1.449779]\n",
      "epoch0 step8135 [D loss: -0.861461] [G loss: 1.686767]\n",
      "epoch0 step8140 [D loss: -0.980110] [G loss: 1.619239]\n",
      "epoch0 step8145 [D loss: -1.030906] [G loss: 1.771520]\n",
      "epoch0 step8150 [D loss: -0.936517] [G loss: 1.787466]\n",
      "epoch0 step8155 [D loss: -1.042717] [G loss: 1.769269]\n",
      "epoch0 step8160 [D loss: -1.379669] [G loss: 1.681469]\n",
      "epoch0 step8165 [D loss: -0.332328] [G loss: 1.227033]\n",
      "epoch0 step8170 [D loss: 0.139660] [G loss: 1.041003]\n",
      "epoch0 step8175 [D loss: -0.030806] [G loss: 1.852567]\n",
      "epoch0 step8180 [D loss: -1.357804] [G loss: 1.560801]\n",
      "epoch0 step8185 [D loss: -1.078330] [G loss: 0.639478]\n",
      "epoch0 step8190 [D loss: -0.518449] [G loss: 0.918826]\n",
      "epoch0 step8195 [D loss: -0.199483] [G loss: 1.111762]\n",
      "epoch0 step8200 [D loss: 0.189494] [G loss: 0.996390]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.566741\n",
      "FID: 39.621819\n",
      "0 = 14.195049420261386\n",
      "1 = 0.10729251355080788\n",
      "2 = 0.8646000027656555\n",
      "3 = 0.9703999757766724\n",
      "4 = 0.7588000297546387\n",
      "5 = 0.8009244203567505\n",
      "6 = 0.9703999757766724\n",
      "7 = 9.314362045192734\n",
      "8 = 0.1221362126805028\n",
      "9 = 0.8565000295639038\n",
      "10 = 0.876800000667572\n",
      "11 = 0.8361999988555908\n",
      "12 = 0.8425908088684082\n",
      "13 = 0.876800000667572\n",
      "14 = 5.5667595863342285\n",
      "15 = 9.316339492797852\n",
      "16 = 0.19812609255313873\n",
      "17 = 5.566741466522217\n",
      "18 = 39.62181854248047\n",
      "epoch0 step8205 [D loss: -0.593069] [G loss: 1.290253]\n",
      "epoch0 step8210 [D loss: -0.625283] [G loss: 0.696859]\n",
      "epoch0 step8215 [D loss: -0.647191] [G loss: 0.316841]\n",
      "epoch0 step8220 [D loss: -1.249086] [G loss: 0.815110]\n",
      "epoch0 step8225 [D loss: -0.717618] [G loss: 0.359984]\n",
      "epoch0 step8230 [D loss: -0.512017] [G loss: 0.592946]\n",
      "epoch0 step8235 [D loss: 0.262695] [G loss: 0.626966]\n",
      "epoch0 step8240 [D loss: -0.731945] [G loss: 0.327651]\n",
      "epoch0 step8245 [D loss: -1.770264] [G loss: 0.139895]\n",
      "epoch0 step8250 [D loss: -1.347025] [G loss: 0.317318]\n",
      "epoch0 step8255 [D loss: -1.158454] [G loss: -0.010844]\n",
      "epoch0 step8260 [D loss: -1.191089] [G loss: 0.646181]\n",
      "epoch0 step8265 [D loss: -0.969019] [G loss: 0.075641]\n",
      "epoch0 step8270 [D loss: -0.594347] [G loss: 0.126164]\n",
      "epoch0 step8275 [D loss: -0.472847] [G loss: 0.070283]\n",
      "epoch0 step8280 [D loss: -1.144324] [G loss: -0.543944]\n",
      "epoch0 step8285 [D loss: -0.614334] [G loss: -0.424372]\n",
      "epoch0 step8290 [D loss: -0.226868] [G loss: -0.376967]\n",
      "epoch0 step8295 [D loss: -0.779183] [G loss: -0.396282]\n",
      "epoch0 step8300 [D loss: -0.700503] [G loss: -0.138347]\n",
      "epoch0 step8305 [D loss: -0.940585] [G loss: -0.079367]\n",
      "epoch0 step8310 [D loss: -0.915212] [G loss: -0.250841]\n",
      "epoch0 step8315 [D loss: -0.625551] [G loss: -0.302362]\n",
      "epoch0 step8320 [D loss: -1.186913] [G loss: -0.400367]\n",
      "epoch0 step8325 [D loss: -0.770025] [G loss: -0.260888]\n",
      "epoch0 step8330 [D loss: -0.301445] [G loss: -0.122490]\n",
      "epoch0 step8335 [D loss: -0.492283] [G loss: -0.310132]\n",
      "epoch0 step8340 [D loss: -1.223091] [G loss: 0.734500]\n",
      "epoch0 step8345 [D loss: -0.688220] [G loss: -0.167835]\n",
      "epoch0 step8350 [D loss: -0.494524] [G loss: 0.055175]\n",
      "epoch0 step8355 [D loss: -0.473151] [G loss: 0.268283]\n",
      "epoch0 step8360 [D loss: -0.499631] [G loss: -0.199512]\n",
      "epoch0 step8365 [D loss: -1.151449] [G loss: 0.328539]\n",
      "epoch0 step8370 [D loss: -1.126116] [G loss: 0.745459]\n",
      "epoch0 step8375 [D loss: 0.224637] [G loss: 0.421718]\n",
      "epoch0 step8380 [D loss: -0.855770] [G loss: 0.690897]\n",
      "epoch0 step8385 [D loss: -0.508265] [G loss: 0.384433]\n",
      "epoch0 step8390 [D loss: -0.358867] [G loss: -0.065161]\n",
      "epoch0 step8395 [D loss: -0.258012] [G loss: 0.922018]\n",
      "epoch0 step8400 [D loss: -1.129399] [G loss: 0.467996]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.340393\n",
      "FID: 50.311932\n",
      "0 = 13.416979911613495\n",
      "1 = 0.09968713455372376\n",
      "2 = 0.8956000208854675\n",
      "3 = 0.954200029373169\n",
      "4 = 0.8370000123977661\n",
      "5 = 0.8540995121002197\n",
      "6 = 0.954200029373169\n",
      "7 = 9.743599341821676\n",
      "8 = 0.1393484882405502\n",
      "9 = 0.8729000091552734\n",
      "10 = 0.8889999985694885\n",
      "11 = 0.8568000197410583\n",
      "12 = 0.8612672090530396\n",
      "13 = 0.8889999985694885\n",
      "14 = 5.340405464172363\n",
      "15 = 9.333337783813477\n",
      "16 = 0.21445904672145844\n",
      "17 = 5.34039306640625\n",
      "18 = 50.31193161010742\n",
      "epoch0 step8405 [D loss: -0.925078] [G loss: 0.700749]\n",
      "epoch0 step8410 [D loss: -1.465622] [G loss: 0.067368]\n",
      "epoch0 step8415 [D loss: -0.607120] [G loss: -0.237692]\n",
      "epoch0 step8420 [D loss: -0.513235] [G loss: 0.589631]\n",
      "epoch0 step8425 [D loss: -1.379848] [G loss: 0.424181]\n",
      "epoch0 step8430 [D loss: -1.192623] [G loss: 0.925643]\n",
      "epoch0 step8435 [D loss: -0.465228] [G loss: 0.644438]\n",
      "epoch0 step8440 [D loss: -0.599389] [G loss: 1.194265]\n",
      "epoch0 step8445 [D loss: -0.772423] [G loss: 0.721748]\n",
      "epoch0 step8450 [D loss: -0.091544] [G loss: 1.002407]\n",
      "epoch0 step8455 [D loss: -0.389062] [G loss: 0.622352]\n",
      "epoch0 step8460 [D loss: -0.079896] [G loss: 0.797427]\n",
      "epoch0 step8465 [D loss: -0.556066] [G loss: 0.670663]\n",
      "epoch0 step8470 [D loss: 0.089000] [G loss: 0.576665]\n",
      "epoch0 step8475 [D loss: -0.736505] [G loss: 0.298611]\n",
      "epoch0 step8480 [D loss: -1.722004] [G loss: 0.498761]\n",
      "epoch0 step8485 [D loss: -0.695409] [G loss: 0.396455]\n",
      "epoch0 step8490 [D loss: -0.658788] [G loss: 0.498037]\n",
      "epoch0 step8495 [D loss: -0.892152] [G loss: 0.907076]\n",
      "epoch0 step8500 [D loss: -0.125605] [G loss: 1.115133]\n",
      "epoch0 step8505 [D loss: -0.683042] [G loss: 0.612521]\n",
      "epoch0 step8510 [D loss: -0.998387] [G loss: 0.952310]\n",
      "epoch0 step8515 [D loss: -1.616410] [G loss: 1.157420]\n",
      "epoch0 step8520 [D loss: -0.761532] [G loss: 0.547159]\n",
      "epoch0 step8525 [D loss: -2.013204] [G loss: 1.596995]\n",
      "epoch0 step8530 [D loss: -2.242818] [G loss: 0.870015]\n",
      "epoch0 step8535 [D loss: -1.223871] [G loss: 1.388685]\n",
      "epoch0 step8540 [D loss: -1.329538] [G loss: 0.879131]\n",
      "epoch0 step8545 [D loss: -1.025339] [G loss: 1.010830]\n",
      "epoch0 step8550 [D loss: -0.384098] [G loss: 0.546073]\n",
      "epoch0 step8555 [D loss: -0.781323] [G loss: 0.783157]\n",
      "epoch0 step8560 [D loss: -0.040973] [G loss: 0.566121]\n",
      "epoch0 step8565 [D loss: -1.482164] [G loss: 1.169314]\n",
      "epoch0 step8570 [D loss: -0.526393] [G loss: 0.593856]\n",
      "epoch0 step8575 [D loss: 0.171675] [G loss: 0.756508]\n",
      "epoch0 step8580 [D loss: 0.014362] [G loss: 0.908498]\n",
      "epoch0 step8585 [D loss: -0.135087] [G loss: 1.399549]\n",
      "epoch0 step8590 [D loss: -0.700589] [G loss: 1.282963]\n",
      "epoch0 step8595 [D loss: -0.430375] [G loss: 1.654721]\n",
      "epoch0 step8600 [D loss: -0.856635] [G loss: 1.408019]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.407072\n",
      "FID: 49.311390\n",
      "0 = 13.529563220405585\n",
      "1 = 0.06698357440531451\n",
      "2 = 0.8741999864578247\n",
      "3 = 0.9498000144958496\n",
      "4 = 0.7986000180244446\n",
      "5 = 0.8250521421432495\n",
      "6 = 0.9498000144958496\n",
      "7 = 9.575530126237872\n",
      "8 = 0.14378991609427258\n",
      "9 = 0.8637999892234802\n",
      "10 = 0.8737999796867371\n",
      "11 = 0.8537999987602234\n",
      "12 = 0.8566666841506958\n",
      "13 = 0.8737999796867371\n",
      "14 = 5.407087326049805\n",
      "15 = 8.858816146850586\n",
      "16 = 0.25479426980018616\n",
      "17 = 5.407072067260742\n",
      "18 = 49.3113899230957\n",
      "epoch0 step8605 [D loss: -1.057431] [G loss: 1.892947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 step8610 [D loss: 0.243774] [G loss: 1.760049]\n",
      "epoch0 step8615 [D loss: -0.833950] [G loss: 1.855110]\n",
      "epoch0 step8620 [D loss: -0.198739] [G loss: 1.888611]\n",
      "epoch0 step8625 [D loss: -1.065931] [G loss: 1.778723]\n",
      "epoch0 step8630 [D loss: -0.129107] [G loss: 1.710658]\n",
      "epoch0 step8635 [D loss: -0.694040] [G loss: 2.022117]\n",
      "epoch0 step8640 [D loss: -0.648086] [G loss: 1.566026]\n",
      "epoch0 step8645 [D loss: -0.930838] [G loss: 2.342918]\n",
      "epoch0 step8650 [D loss: -0.809278] [G loss: 2.417552]\n",
      "epoch0 step8655 [D loss: -0.926981] [G loss: 2.002301]\n",
      "epoch0 step8660 [D loss: -1.265081] [G loss: 1.747800]\n",
      "epoch0 step8665 [D loss: -1.383496] [G loss: 2.701904]\n",
      "epoch0 step8670 [D loss: -0.252639] [G loss: 1.435142]\n",
      "epoch0 step8675 [D loss: -0.958462] [G loss: 2.023147]\n",
      "epoch0 step8680 [D loss: -0.726190] [G loss: 1.817934]\n",
      "epoch0 step8685 [D loss: -0.615819] [G loss: 2.032258]\n",
      "epoch0 step8690 [D loss: -0.142600] [G loss: 1.790516]\n",
      "epoch0 step8695 [D loss: -0.777116] [G loss: 2.208806]\n",
      "epoch0 step8700 [D loss: -0.991338] [G loss: 2.211997]\n",
      "epoch0 step8705 [D loss: -1.501280] [G loss: 2.480543]\n",
      "epoch0 step8710 [D loss: -0.884480] [G loss: 2.318690]\n",
      "epoch0 step8715 [D loss: -1.425432] [G loss: 1.870427]\n",
      "epoch0 step8720 [D loss: -1.062257] [G loss: 2.314203]\n",
      "epoch0 step8725 [D loss: -0.351130] [G loss: 1.781100]\n",
      "epoch0 step8730 [D loss: -0.438486] [G loss: 1.682811]\n",
      "epoch0 step8735 [D loss: -0.045572] [G loss: 1.515294]\n",
      "epoch0 step8740 [D loss: -0.539948] [G loss: 1.306504]\n",
      "epoch0 step8745 [D loss: -1.025206] [G loss: 1.297435]\n",
      "epoch0 step8750 [D loss: -1.139363] [G loss: 1.755404]\n",
      "epoch0 step8755 [D loss: -0.500403] [G loss: 1.848935]\n",
      "epoch0 step8760 [D loss: -1.134780] [G loss: 1.792891]\n",
      "epoch0 step8765 [D loss: -1.061862] [G loss: 1.921324]\n",
      "epoch0 step8770 [D loss: -1.442006] [G loss: 1.265671]\n",
      "epoch0 step8775 [D loss: -0.402282] [G loss: 1.120768]\n",
      "epoch0 step8780 [D loss: -1.017319] [G loss: 1.292524]\n",
      "epoch0 step8785 [D loss: -1.206749] [G loss: 1.505028]\n",
      "epoch0 step8790 [D loss: -0.514080] [G loss: 1.731748]\n",
      "epoch0 step8795 [D loss: -1.280611] [G loss: 0.937937]\n",
      "epoch0 step8800 [D loss: -0.636538] [G loss: 1.274372]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.406104\n",
      "FID: 47.595226\n",
      "0 = 13.307801784515359\n",
      "1 = 0.07718937427546357\n",
      "2 = 0.8888999819755554\n",
      "3 = 0.9484000205993652\n",
      "4 = 0.8294000029563904\n",
      "5 = 0.8475424647331238\n",
      "6 = 0.9484000205993652\n",
      "7 = 9.602025105142578\n",
      "8 = 0.13875094026814005\n",
      "9 = 0.8702999949455261\n",
      "10 = 0.8840000033378601\n",
      "11 = 0.8565999865531921\n",
      "12 = 0.8604243993759155\n",
      "13 = 0.8840000033378601\n",
      "14 = 5.4061198234558105\n",
      "15 = 9.09681510925293\n",
      "16 = 0.23460936546325684\n",
      "17 = 5.40610408782959\n",
      "18 = 47.5952262878418\n",
      "epoch0 step8805 [D loss: -0.194862] [G loss: 1.340137]\n",
      "epoch0 step8810 [D loss: -0.422839] [G loss: 0.718733]\n",
      "epoch0 step8815 [D loss: -0.665954] [G loss: 1.099968]\n",
      "epoch0 step8820 [D loss: -1.380460] [G loss: 0.899566]\n",
      "epoch0 step8825 [D loss: -1.106165] [G loss: 0.914210]\n",
      "epoch0 step8830 [D loss: 0.416398] [G loss: 1.183536]\n",
      "epoch0 step8835 [D loss: -0.563939] [G loss: 0.443597]\n",
      "epoch0 step8840 [D loss: -0.673100] [G loss: 0.788754]\n",
      "epoch0 step8845 [D loss: -1.856530] [G loss: 0.863674]\n",
      "epoch0 step8850 [D loss: -0.636170] [G loss: 1.777378]\n",
      "epoch0 step8855 [D loss: -0.312570] [G loss: 0.914232]\n",
      "epoch0 step8860 [D loss: -1.255528] [G loss: 1.552155]\n",
      "epoch0 step8865 [D loss: -0.811623] [G loss: 1.037071]\n",
      "epoch0 step8870 [D loss: -0.966859] [G loss: 2.152216]\n",
      "epoch0 step8875 [D loss: -1.424004] [G loss: 1.694290]\n",
      "epoch0 step8880 [D loss: -0.979647] [G loss: 1.777177]\n",
      "epoch0 step8885 [D loss: -1.139271] [G loss: 1.662508]\n",
      "epoch0 step8890 [D loss: -2.011411] [G loss: 1.799575]\n",
      "epoch0 step8895 [D loss: -1.202039] [G loss: 1.427750]\n",
      "epoch0 step8900 [D loss: -0.869484] [G loss: 1.013164]\n",
      "epoch0 step8905 [D loss: -0.152603] [G loss: 1.281150]\n",
      "epoch0 step8910 [D loss: -0.310284] [G loss: 1.799428]\n",
      "epoch0 step8915 [D loss: 0.314724] [G loss: 1.820173]\n",
      "epoch0 step8920 [D loss: -0.569415] [G loss: 1.177497]\n",
      "epoch0 step8925 [D loss: -0.238119] [G loss: 1.213976]\n",
      "epoch0 step8930 [D loss: 0.076333] [G loss: 1.475942]\n",
      "epoch0 step8935 [D loss: -0.282263] [G loss: 1.895425]\n",
      "epoch0 step8940 [D loss: -0.751718] [G loss: 1.521897]\n",
      "epoch0 step8945 [D loss: -0.180342] [G loss: 2.210520]\n",
      "epoch0 step8950 [D loss: -0.151585] [G loss: 1.331362]\n",
      "epoch0 step8955 [D loss: 0.395980] [G loss: 1.750864]\n",
      "epoch0 step8960 [D loss: -0.481303] [G loss: 1.983221]\n",
      "epoch0 step8965 [D loss: -0.635596] [G loss: 1.294797]\n",
      "epoch0 step8970 [D loss: -0.672816] [G loss: 1.790448]\n",
      "epoch0 step8975 [D loss: -0.063406] [G loss: 1.631549]\n",
      "epoch0 step8980 [D loss: -0.826587] [G loss: 2.256817]\n",
      "epoch0 step8985 [D loss: -0.742821] [G loss: 2.848846]\n",
      "epoch0 step8990 [D loss: -0.734041] [G loss: 1.754803]\n",
      "epoch0 step8995 [D loss: -0.517969] [G loss: 2.292834]\n",
      "epoch0 step9000 [D loss: -1.214875] [G loss: 1.485441]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.561040\n",
      "FID: 42.126701\n",
      "0 = 13.18916477365493\n",
      "1 = 0.05259516673636351\n",
      "2 = 0.8766999840736389\n",
      "3 = 0.9470000267028809\n",
      "4 = 0.8064000010490417\n",
      "5 = 0.8302647471427917\n",
      "6 = 0.9470000267028809\n",
      "7 = 9.209593269968064\n",
      "8 = 0.12810475259223894\n",
      "9 = 0.8586999773979187\n",
      "10 = 0.8726000189781189\n",
      "11 = 0.8447999954223633\n",
      "12 = 0.8489978313446045\n",
      "13 = 0.8726000189781189\n",
      "14 = 5.561057090759277\n",
      "15 = 9.087136268615723\n",
      "16 = 0.23070627450942993\n",
      "17 = 5.56104040145874\n",
      "18 = 42.12670135498047\n",
      "epoch0 step9005 [D loss: -0.552670] [G loss: 1.689334]\n",
      "epoch0 step9010 [D loss: -0.323402] [G loss: 1.336475]\n",
      "epoch0 step9015 [D loss: -1.175951] [G loss: 1.822312]\n",
      "epoch0 step9020 [D loss: -0.582750] [G loss: 1.348392]\n",
      "epoch0 step9025 [D loss: -0.672052] [G loss: 1.855117]\n",
      "epoch0 step9030 [D loss: -1.674039] [G loss: 1.699322]\n",
      "epoch0 step9035 [D loss: -0.596880] [G loss: 2.254542]\n",
      "epoch0 step9040 [D loss: -0.124361] [G loss: 2.277266]\n",
      "epoch0 step9045 [D loss: -1.203274] [G loss: 2.115172]\n",
      "epoch0 step9050 [D loss: -0.445338] [G loss: 1.333004]\n",
      "epoch0 step9055 [D loss: -0.892201] [G loss: 2.343593]\n",
      "epoch0 step9060 [D loss: -0.439857] [G loss: 1.465391]\n",
      "epoch0 step9065 [D loss: -0.272021] [G loss: 2.022082]\n",
      "epoch0 step9070 [D loss: -0.825201] [G loss: 2.148736]\n",
      "epoch0 step9075 [D loss: -0.713103] [G loss: 1.624663]\n",
      "epoch0 step9080 [D loss: -1.112675] [G loss: 1.199305]\n",
      "epoch0 step9085 [D loss: -0.760726] [G loss: 1.645882]\n",
      "epoch0 step9090 [D loss: -0.836720] [G loss: 1.760197]\n",
      "epoch0 step9095 [D loss: -1.198741] [G loss: 1.816303]\n",
      "epoch0 step9100 [D loss: -0.482765] [G loss: 1.841084]\n",
      "epoch0 step9105 [D loss: -0.807327] [G loss: 1.419753]\n",
      "epoch0 step9110 [D loss: -1.354312] [G loss: 1.312601]\n",
      "epoch0 step9115 [D loss: -1.242913] [G loss: 0.841687]\n",
      "epoch0 step9120 [D loss: -2.005659] [G loss: 0.802012]\n",
      "epoch0 step9125 [D loss: -0.016670] [G loss: 1.032212]\n",
      "epoch0 step9130 [D loss: -0.172637] [G loss: 1.570714]\n",
      "epoch0 step9135 [D loss: -0.294646] [G loss: 1.174530]\n",
      "epoch0 step9140 [D loss: -0.796420] [G loss: 1.295409]\n",
      "epoch0 step9145 [D loss: 0.318526] [G loss: 0.755143]\n",
      "epoch0 step9150 [D loss: -0.378996] [G loss: 0.593790]\n",
      "epoch0 step9155 [D loss: -0.538031] [G loss: 0.830092]\n",
      "epoch0 step9160 [D loss: -0.693966] [G loss: 0.751631]\n",
      "epoch0 step9165 [D loss: -0.073752] [G loss: 0.415791]\n",
      "epoch0 step9170 [D loss: -1.571955] [G loss: 0.154871]\n",
      "epoch0 step9175 [D loss: -0.894285] [G loss: 0.371949]\n",
      "epoch0 step9180 [D loss: -1.249843] [G loss: -0.435989]\n",
      "epoch0 step9185 [D loss: -1.771220] [G loss: -0.002568]\n",
      "epoch0 step9190 [D loss: -1.971997] [G loss: 0.144989]\n",
      "epoch0 step9195 [D loss: 0.794241] [G loss: -0.659319]\n",
      "epoch0 step9200 [D loss: 0.679083] [G loss: -0.163728]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.688148\n",
      "FID: 39.987366\n",
      "0 = 13.308940663814534\n",
      "1 = 0.072688335594301\n",
      "2 = 0.8820000290870667\n",
      "3 = 0.9441999793052673\n",
      "4 = 0.8198000192642212\n",
      "5 = 0.8397367596626282\n",
      "6 = 0.9441999793052673\n",
      "7 = 9.16923267240523\n",
      "8 = 0.12276317042532918\n",
      "9 = 0.8482999801635742\n",
      "10 = 0.8676000237464905\n",
      "11 = 0.8289999961853027\n",
      "12 = 0.835355281829834\n",
      "13 = 0.8676000237464905\n",
      "14 = 5.688168525695801\n",
      "15 = 9.288562774658203\n",
      "16 = 0.20337671041488647\n",
      "17 = 5.688148021697998\n",
      "18 = 39.98736572265625\n",
      "epoch0 step9205 [D loss: -0.951030] [G loss: 0.266605]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 step9210 [D loss: -0.431664] [G loss: 0.270861]\n",
      "epoch0 step9215 [D loss: -0.632222] [G loss: -0.124014]\n",
      "epoch0 step9220 [D loss: -0.207612] [G loss: -0.570930]\n",
      "epoch0 step9225 [D loss: -0.531079] [G loss: 0.189569]\n",
      "epoch0 step9230 [D loss: -1.088395] [G loss: -0.048498]\n",
      "epoch0 step9235 [D loss: -1.041364] [G loss: 0.057594]\n",
      "epoch0 step9240 [D loss: -1.395522] [G loss: -0.432310]\n",
      "epoch0 step9245 [D loss: -2.147038] [G loss: 0.035392]\n",
      "epoch0 step9250 [D loss: -1.414928] [G loss: -0.371823]\n",
      "epoch0 step9255 [D loss: -1.412705] [G loss: -0.613368]\n",
      "epoch0 step9260 [D loss: -2.261460] [G loss: -0.364537]\n",
      "epoch0 step9265 [D loss: -0.815533] [G loss: -0.689847]\n",
      "epoch0 step9270 [D loss: -1.522590] [G loss: -0.817136]\n",
      "epoch0 step9275 [D loss: -1.502384] [G loss: -0.413840]\n",
      "epoch0 step9280 [D loss: 0.811465] [G loss: -0.747063]\n",
      "epoch0 step9285 [D loss: -0.090486] [G loss: -0.176739]\n",
      "epoch0 step9290 [D loss: -0.856293] [G loss: -0.494843]\n",
      "epoch0 step9295 [D loss: -0.764314] [G loss: 0.251525]\n",
      "epoch0 step9300 [D loss: -0.772397] [G loss: -0.249416]\n",
      "epoch0 step9305 [D loss: -1.245453] [G loss: -0.497302]\n",
      "epoch0 step9310 [D loss: -0.611183] [G loss: -0.847554]\n",
      "epoch0 step9315 [D loss: -1.273908] [G loss: -0.147609]\n",
      "epoch0 step9320 [D loss: -0.946550] [G loss: -0.560744]\n",
      "epoch0 step9325 [D loss: -1.062090] [G loss: -0.173287]\n",
      "epoch0 step9330 [D loss: -0.915077] [G loss: -0.277347]\n",
      "epoch0 step9335 [D loss: -1.419111] [G loss: -0.117288]\n",
      "epoch0 step9340 [D loss: -1.556964] [G loss: -0.499283]\n",
      "epoch0 step9345 [D loss: -1.035610] [G loss: -1.124571]\n",
      "epoch0 step9350 [D loss: -0.829271] [G loss: -0.926160]\n",
      "epoch0 step9355 [D loss: -0.157831] [G loss: -0.875803]\n",
      "epoch0 step9360 [D loss: -1.084235] [G loss: -1.064747]\n",
      "epoch0 step9365 [D loss: -1.720762] [G loss: -0.882461]\n",
      "epoch0 step9370 [D loss: -1.985052] [G loss: -0.597442]\n",
      "epoch0 step9375 [D loss: -1.846518] [G loss: -0.973923]\n",
      "epoch1 step9380 [D loss: -0.176208] [G loss: -0.832190]\n",
      "epoch1 step9385 [D loss: 0.389064] [G loss: -0.276357]\n",
      "epoch1 step9390 [D loss: -0.586745] [G loss: -0.869375]\n",
      "epoch1 step9395 [D loss: -1.118755] [G loss: 0.087494]\n",
      "epoch1 step9400 [D loss: -1.145438] [G loss: -0.532233]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.498816\n",
      "FID: 46.590889\n",
      "0 = 13.40946251554491\n",
      "1 = 0.13017755780506604\n",
      "2 = 0.9128999710083008\n",
      "3 = 0.9394000172615051\n",
      "4 = 0.8863999843597412\n",
      "5 = 0.8921177387237549\n",
      "6 = 0.9394000172615051\n",
      "7 = 9.488132045674325\n",
      "8 = 0.1342955420906712\n",
      "9 = 0.8738999962806702\n",
      "10 = 0.8799999952316284\n",
      "11 = 0.8677999973297119\n",
      "12 = 0.8693934082984924\n",
      "13 = 0.8799999952316284\n",
      "14 = 5.498827934265137\n",
      "15 = 9.364727020263672\n",
      "16 = 0.20487543940544128\n",
      "17 = 5.498816013336182\n",
      "18 = 46.59088897705078\n",
      "epoch1 step9405 [D loss: 0.437014] [G loss: -0.587222]\n",
      "epoch1 step9410 [D loss: 0.364328] [G loss: -0.310904]\n",
      "epoch1 step9415 [D loss: -0.096793] [G loss: 0.126109]\n",
      "epoch1 step9420 [D loss: -0.081353] [G loss: -0.906091]\n",
      "epoch1 step9425 [D loss: -0.654523] [G loss: -0.477949]\n",
      "epoch1 step9430 [D loss: -0.316115] [G loss: -0.294206]\n",
      "epoch1 step9435 [D loss: -0.197302] [G loss: 0.088593]\n",
      "epoch1 step9440 [D loss: -0.817972] [G loss: -0.300231]\n",
      "epoch1 step9445 [D loss: -0.486945] [G loss: -0.631706]\n",
      "epoch1 step9450 [D loss: -0.792821] [G loss: 0.222315]\n",
      "epoch1 step9455 [D loss: -0.646116] [G loss: 0.226490]\n",
      "epoch1 step9460 [D loss: 0.191828] [G loss: 0.494369]\n",
      "epoch1 step9465 [D loss: -0.759163] [G loss: 0.218792]\n",
      "epoch1 step9470 [D loss: -0.301134] [G loss: 0.818724]\n",
      "epoch1 step9475 [D loss: -1.052425] [G loss: 0.171328]\n",
      "epoch1 step9480 [D loss: -0.823157] [G loss: 0.286925]\n",
      "epoch1 step9485 [D loss: -0.179835] [G loss: 0.267710]\n",
      "epoch1 step9490 [D loss: -0.128433] [G loss: 0.406404]\n",
      "epoch1 step9495 [D loss: -0.502889] [G loss: 0.465272]\n",
      "epoch1 step9500 [D loss: -0.461959] [G loss: 1.093805]\n",
      "epoch1 step9505 [D loss: -0.362468] [G loss: 0.882113]\n",
      "epoch1 step9510 [D loss: -1.438002] [G loss: 0.810697]\n",
      "epoch1 step9515 [D loss: -1.086054] [G loss: 0.755689]\n",
      "epoch1 step9520 [D loss: -0.727783] [G loss: 1.036145]\n",
      "epoch1 step9525 [D loss: -0.549381] [G loss: 0.912059]\n",
      "epoch1 step9530 [D loss: -0.440094] [G loss: 0.945267]\n",
      "epoch1 step9535 [D loss: -0.393325] [G loss: 0.746020]\n",
      "epoch1 step9540 [D loss: 0.216514] [G loss: 0.847131]\n",
      "epoch1 step9545 [D loss: -0.744938] [G loss: 1.020969]\n",
      "epoch1 step9550 [D loss: -0.092232] [G loss: 1.207127]\n",
      "epoch1 step9555 [D loss: -0.049279] [G loss: 1.379567]\n",
      "epoch1 step9560 [D loss: -0.865105] [G loss: 0.853707]\n",
      "epoch1 step9565 [D loss: -0.178946] [G loss: 1.357125]\n",
      "epoch1 step9570 [D loss: 0.314563] [G loss: 1.532823]\n",
      "epoch1 step9575 [D loss: 0.330083] [G loss: 1.604468]\n",
      "epoch1 step9580 [D loss: 0.038278] [G loss: 1.373673]\n",
      "epoch1 step9585 [D loss: -0.217931] [G loss: 1.625762]\n",
      "epoch1 step9590 [D loss: -0.543594] [G loss: 1.591294]\n",
      "epoch1 step9595 [D loss: -1.326412] [G loss: 1.319993]\n",
      "epoch1 step9600 [D loss: -0.389274] [G loss: 2.078136]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.666415\n",
      "FID: 37.414154\n",
      "0 = 14.592575076484708\n",
      "1 = 0.1586031154629634\n",
      "2 = 0.8884999752044678\n",
      "3 = 0.9577999711036682\n",
      "4 = 0.8191999793052673\n",
      "5 = 0.8412085175514221\n",
      "6 = 0.9577999711036682\n",
      "7 = 9.1744224022627\n",
      "8 = 0.11966078975630463\n",
      "9 = 0.8565000295639038\n",
      "10 = 0.8751999735832214\n",
      "11 = 0.8378000259399414\n",
      "12 = 0.8436475992202759\n",
      "13 = 0.8751999735832214\n",
      "14 = 5.666438102722168\n",
      "15 = 9.154277801513672\n",
      "16 = 0.21458952128887177\n",
      "17 = 5.666415214538574\n",
      "18 = 37.414154052734375\n",
      "epoch1 step9605 [D loss: -0.500025] [G loss: 2.043284]\n",
      "epoch1 step9610 [D loss: -0.391821] [G loss: 2.037958]\n",
      "epoch1 step9615 [D loss: -1.175715] [G loss: 1.676851]\n",
      "epoch1 step9620 [D loss: -0.709362] [G loss: 2.319989]\n",
      "epoch1 step9625 [D loss: -0.298558] [G loss: 2.152855]\n",
      "epoch1 step9630 [D loss: -1.114714] [G loss: 2.037563]\n",
      "epoch1 step9635 [D loss: -0.767085] [G loss: 2.505929]\n",
      "epoch1 step9640 [D loss: -1.674866] [G loss: 2.440833]\n",
      "epoch1 step9645 [D loss: -1.595291] [G loss: 2.784642]\n",
      "epoch1 step9650 [D loss: -1.313146] [G loss: 2.397766]\n",
      "epoch1 step9655 [D loss: -0.301264] [G loss: 2.312073]\n",
      "epoch1 step9660 [D loss: -1.287420] [G loss: 2.323396]\n",
      "epoch1 step9665 [D loss: -0.936431] [G loss: 2.521965]\n",
      "epoch1 step9670 [D loss: -0.956742] [G loss: 3.106388]\n",
      "epoch1 step9675 [D loss: -0.711586] [G loss: 3.123833]\n",
      "epoch1 step9680 [D loss: -0.850102] [G loss: 3.412641]\n",
      "epoch1 step9685 [D loss: -0.589905] [G loss: 2.795139]\n",
      "epoch1 step9690 [D loss: -1.606889] [G loss: 3.182704]\n",
      "epoch1 step9695 [D loss: -0.725551] [G loss: 3.022953]\n",
      "epoch1 step9700 [D loss: -1.607329] [G loss: 3.065355]\n",
      "epoch1 step9705 [D loss: -1.589592] [G loss: 3.317177]\n",
      "epoch1 step9710 [D loss: -2.018755] [G loss: 3.432853]\n",
      "epoch1 step9715 [D loss: -1.001875] [G loss: 2.904066]\n",
      "epoch1 step9720 [D loss: -2.309895] [G loss: 3.080204]\n",
      "epoch1 step9725 [D loss: -1.409880] [G loss: 2.813608]\n",
      "epoch1 step9730 [D loss: -2.445360] [G loss: 3.544984]\n",
      "epoch1 step9735 [D loss: -1.758947] [G loss: 2.865016]\n",
      "epoch1 step9740 [D loss: -1.390267] [G loss: 2.973369]\n",
      "epoch1 step9745 [D loss: -0.791701] [G loss: 4.400266]\n",
      "epoch1 step9750 [D loss: -0.235188] [G loss: 3.772043]\n",
      "epoch1 step9755 [D loss: -0.003374] [G loss: 3.144066]\n",
      "epoch1 step9760 [D loss: 0.217134] [G loss: 3.069787]\n",
      "epoch1 step9765 [D loss: -0.635565] [G loss: 3.090864]\n",
      "epoch1 step9770 [D loss: -0.364855] [G loss: 3.515327]\n",
      "epoch1 step9775 [D loss: -0.770713] [G loss: 3.150711]\n",
      "epoch1 step9780 [D loss: -1.133606] [G loss: 3.383039]\n",
      "epoch1 step9785 [D loss: 0.024668] [G loss: 2.880091]\n",
      "epoch1 step9790 [D loss: -0.876620] [G loss: 3.376984]\n",
      "epoch1 step9795 [D loss: -0.671565] [G loss: 3.093098]\n",
      "epoch1 step9800 [D loss: -0.713582] [G loss: 2.968926]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.735065\n",
      "FID: 37.458931\n",
      "0 = 13.804881973266635\n",
      "1 = 0.0971152004173374\n",
      "2 = 0.8762999773025513\n",
      "3 = 0.944599986076355\n",
      "4 = 0.8080000281333923\n",
      "5 = 0.831075131893158\n",
      "6 = 0.944599986076355\n",
      "7 = 9.150171851992603\n",
      "8 = 0.12161536315188731\n",
      "9 = 0.8528000116348267\n",
      "10 = 0.8740000128746033\n",
      "11 = 0.83160001039505\n",
      "12 = 0.8384497165679932\n",
      "13 = 0.8740000128746033\n",
      "14 = 5.735086917877197\n",
      "15 = 9.048032760620117\n",
      "16 = 0.22747766971588135\n",
      "17 = 5.735065460205078\n",
      "18 = 37.45893096923828\n",
      "epoch1 step9805 [D loss: -2.547568] [G loss: 3.213470]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 step9810 [D loss: -1.337007] [G loss: 4.141191]\n",
      "epoch1 step9815 [D loss: -0.601307] [G loss: 3.569559]\n",
      "epoch1 step9820 [D loss: 0.344418] [G loss: 3.331740]\n",
      "epoch1 step9825 [D loss: -0.666327] [G loss: 3.782093]\n",
      "epoch1 step9830 [D loss: -1.469890] [G loss: 4.310434]\n",
      "epoch1 step9835 [D loss: -0.465447] [G loss: 3.520302]\n",
      "epoch1 step9840 [D loss: -0.629228] [G loss: 3.998116]\n",
      "epoch1 step9845 [D loss: -0.569711] [G loss: 3.840050]\n",
      "epoch1 step9850 [D loss: -0.183555] [G loss: 3.472955]\n",
      "epoch1 step9855 [D loss: -1.079375] [G loss: 3.711041]\n",
      "epoch1 step9860 [D loss: 0.211992] [G loss: 3.203741]\n",
      "epoch1 step9865 [D loss: 0.188468] [G loss: 3.159642]\n",
      "epoch1 step9870 [D loss: -0.492143] [G loss: 3.379826]\n",
      "epoch1 step9875 [D loss: 0.246091] [G loss: 3.075004]\n",
      "epoch1 step9880 [D loss: 0.015036] [G loss: 3.128992]\n",
      "epoch1 step9885 [D loss: -0.128160] [G loss: 2.659359]\n",
      "epoch1 step9890 [D loss: 0.695736] [G loss: 2.480595]\n",
      "epoch1 step9895 [D loss: -0.464683] [G loss: 2.645711]\n",
      "epoch1 step9900 [D loss: -0.700503] [G loss: 2.631276]\n",
      "epoch1 step9905 [D loss: -0.838544] [G loss: 3.158265]\n",
      "epoch1 step9910 [D loss: -0.292377] [G loss: 2.496539]\n",
      "epoch1 step9915 [D loss: 0.540629] [G loss: 2.059272]\n",
      "epoch1 step9920 [D loss: -0.940861] [G loss: 2.133183]\n",
      "epoch1 step9925 [D loss: -1.613679] [G loss: 2.486021]\n",
      "epoch1 step9930 [D loss: 0.015153] [G loss: 2.042841]\n",
      "epoch1 step9935 [D loss: -0.825488] [G loss: 2.198850]\n",
      "epoch1 step9940 [D loss: -0.701207] [G loss: 2.631663]\n",
      "epoch1 step9945 [D loss: -1.681866] [G loss: 3.053972]\n",
      "epoch1 step9950 [D loss: -1.003143] [G loss: 2.052115]\n",
      "epoch1 step9955 [D loss: -0.314592] [G loss: 2.548637]\n",
      "epoch1 step9960 [D loss: -0.620894] [G loss: 2.774883]\n",
      "epoch1 step9965 [D loss: -0.607535] [G loss: 2.911902]\n",
      "epoch1 step9970 [D loss: -0.844967] [G loss: 2.691014]\n",
      "epoch1 step9975 [D loss: -1.261146] [G loss: 3.370998]\n",
      "epoch1 step9980 [D loss: 0.449081] [G loss: 2.103800]\n",
      "epoch1 step9985 [D loss: -0.787051] [G loss: 1.631958]\n",
      "epoch1 step9990 [D loss: -0.814663] [G loss: 1.990299]\n",
      "epoch1 step9995 [D loss: -0.609084] [G loss: 2.884151]\n",
      "epoch1 step10000 [D loss: -0.595868] [G loss: 2.229685]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.868071\n",
      "FID: 35.320511\n",
      "0 = 13.898605729293829\n",
      "1 = 0.08844699660356432\n",
      "2 = 0.8582000136375427\n",
      "3 = 0.9602000117301941\n",
      "4 = 0.7562000155448914\n",
      "5 = 0.7975082993507385\n",
      "6 = 0.9602000117301941\n",
      "7 = 9.00834763774873\n",
      "8 = 0.1208656377470474\n",
      "9 = 0.8428999781608582\n",
      "10 = 0.8758000135421753\n",
      "11 = 0.8100000023841858\n",
      "12 = 0.8217301368713379\n",
      "13 = 0.8758000135421753\n",
      "14 = 5.86808967590332\n",
      "15 = 9.048567771911621\n",
      "16 = 0.22159190475940704\n",
      "17 = 5.868070602416992\n",
      "18 = 35.32051086425781\n",
      "epoch1 step10005 [D loss: -0.210951] [G loss: 1.870068]\n",
      "epoch1 step10010 [D loss: -0.200332] [G loss: 1.845780]\n",
      "epoch1 step10015 [D loss: -0.692816] [G loss: 1.775092]\n",
      "epoch1 step10020 [D loss: 0.097069] [G loss: 1.412781]\n",
      "epoch1 step10025 [D loss: -0.260545] [G loss: 2.069461]\n",
      "epoch1 step10030 [D loss: -0.515284] [G loss: 1.555072]\n",
      "epoch1 step10035 [D loss: -0.437267] [G loss: 1.590707]\n",
      "epoch1 step10040 [D loss: -0.621064] [G loss: 1.588525]\n",
      "epoch1 step10045 [D loss: -0.228789] [G loss: 1.371568]\n",
      "epoch1 step10050 [D loss: -0.116876] [G loss: 1.339146]\n",
      "epoch1 step10055 [D loss: -0.629829] [G loss: 1.091040]\n",
      "epoch1 step10060 [D loss: 0.206950] [G loss: 1.049289]\n",
      "epoch1 step10065 [D loss: -0.827746] [G loss: 1.078889]\n",
      "epoch1 step10070 [D loss: -0.076086] [G loss: 0.331224]\n",
      "epoch1 step10075 [D loss: -0.550983] [G loss: 1.666613]\n",
      "epoch1 step10080 [D loss: -1.222180] [G loss: 0.898422]\n",
      "epoch1 step10085 [D loss: -0.649495] [G loss: 0.988048]\n",
      "epoch1 step10090 [D loss: -0.507275] [G loss: 0.937907]\n",
      "epoch1 step10095 [D loss: -0.465791] [G loss: 1.147804]\n",
      "epoch1 step10100 [D loss: -0.091644] [G loss: 1.368281]\n",
      "epoch1 step10105 [D loss: -0.887109] [G loss: 1.525847]\n",
      "epoch1 step10110 [D loss: -1.722624] [G loss: 1.326622]\n",
      "epoch1 step10115 [D loss: -1.018234] [G loss: 1.683298]\n",
      "epoch1 step10120 [D loss: -0.772562] [G loss: 1.871700]\n",
      "epoch1 step10125 [D loss: -0.877026] [G loss: 1.888106]\n",
      "epoch1 step10130 [D loss: -1.079563] [G loss: 1.228156]\n",
      "epoch1 step10135 [D loss: -1.195141] [G loss: 1.719004]\n",
      "epoch1 step10140 [D loss: -2.454762] [G loss: 2.277483]\n",
      "epoch1 step10145 [D loss: -1.356743] [G loss: 2.657068]\n",
      "epoch1 step10150 [D loss: -0.341087] [G loss: 2.036970]\n",
      "epoch1 step10155 [D loss: -0.791123] [G loss: 1.249445]\n",
      "epoch1 step10160 [D loss: -1.151807] [G loss: 2.419173]\n",
      "epoch1 step10165 [D loss: -0.642656] [G loss: 1.773694]\n",
      "epoch1 step10170 [D loss: 0.021815] [G loss: 2.184704]\n",
      "epoch1 step10175 [D loss: 0.455995] [G loss: 1.618104]\n",
      "epoch1 step10180 [D loss: -0.341539] [G loss: 1.783246]\n",
      "epoch1 step10185 [D loss: -0.218546] [G loss: 1.850852]\n",
      "epoch1 step10190 [D loss: -0.784969] [G loss: 1.669511]\n",
      "epoch1 step10195 [D loss: -0.047136] [G loss: 1.869627]\n",
      "epoch1 step10200 [D loss: -0.886106] [G loss: 1.552671]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.935479\n",
      "FID: 31.491734\n",
      "0 = 13.667001898098025\n",
      "1 = 0.08562621178430849\n",
      "2 = 0.8611000180244446\n",
      "3 = 0.9473999738693237\n",
      "4 = 0.7748000025749207\n",
      "5 = 0.8079481720924377\n",
      "6 = 0.9473999738693237\n",
      "7 = 8.794249937582014\n",
      "8 = 0.11036344481104929\n",
      "9 = 0.8356999754905701\n",
      "10 = 0.8626000285148621\n",
      "11 = 0.8087999820709229\n",
      "12 = 0.8185613751411438\n",
      "13 = 0.8626000285148621\n",
      "14 = 5.935503005981445\n",
      "15 = 9.129266738891602\n",
      "16 = 0.20823583006858826\n",
      "17 = 5.935479164123535\n",
      "18 = 31.49173355102539\n",
      "epoch1 step10205 [D loss: -1.078096] [G loss: 1.734781]\n",
      "epoch1 step10210 [D loss: -0.460046] [G loss: 1.609651]\n",
      "epoch1 step10215 [D loss: -0.333162] [G loss: 1.543166]\n",
      "epoch1 step10220 [D loss: -0.444301] [G loss: 1.384923]\n",
      "epoch1 step10225 [D loss: -0.472654] [G loss: 1.055193]\n",
      "epoch1 step10230 [D loss: -0.120882] [G loss: 0.808273]\n",
      "epoch1 step10235 [D loss: -0.048269] [G loss: 0.937197]\n",
      "epoch1 step10240 [D loss: -0.815741] [G loss: 1.848681]\n",
      "epoch1 step10245 [D loss: -0.757670] [G loss: 1.104370]\n",
      "epoch1 step10250 [D loss: -1.047323] [G loss: 0.279950]\n",
      "epoch1 step10255 [D loss: -0.911883] [G loss: 0.910697]\n",
      "epoch1 step10260 [D loss: -1.212780] [G loss: 1.741037]\n",
      "epoch1 step10265 [D loss: -1.366923] [G loss: 1.231697]\n",
      "epoch1 step10270 [D loss: -0.656099] [G loss: 1.299344]\n",
      "epoch1 step10275 [D loss: -0.698991] [G loss: 1.112739]\n",
      "epoch1 step10280 [D loss: -1.855553] [G loss: 0.799385]\n",
      "epoch1 step10285 [D loss: -0.563905] [G loss: 0.971370]\n",
      "epoch1 step10290 [D loss: -2.089051] [G loss: 0.440847]\n",
      "epoch1 step10295 [D loss: -1.198459] [G loss: 0.705706]\n",
      "epoch1 step10300 [D loss: -0.821743] [G loss: 0.424059]\n",
      "epoch1 step10305 [D loss: -0.608708] [G loss: 0.623660]\n",
      "epoch1 step10310 [D loss: -0.444842] [G loss: 0.438117]\n",
      "epoch1 step10315 [D loss: -0.620454] [G loss: 1.234321]\n",
      "epoch1 step10320 [D loss: 0.065290] [G loss: 1.137552]\n",
      "epoch1 step10325 [D loss: -0.643014] [G loss: 1.047055]\n",
      "epoch1 step10330 [D loss: -1.347036] [G loss: 1.793095]\n",
      "epoch1 step10335 [D loss: -0.347937] [G loss: 0.621884]\n",
      "epoch1 step10340 [D loss: 0.055515] [G loss: 0.751806]\n",
      "epoch1 step10345 [D loss: -1.357263] [G loss: 1.533097]\n",
      "epoch1 step10350 [D loss: -1.468797] [G loss: 0.680724]\n",
      "epoch1 step10355 [D loss: -1.574671] [G loss: 0.578518]\n",
      "epoch1 step10360 [D loss: -0.703420] [G loss: 0.839860]\n",
      "epoch1 step10365 [D loss: -0.890954] [G loss: 0.736326]\n",
      "epoch1 step10370 [D loss: -0.682173] [G loss: 0.359466]\n",
      "epoch1 step10375 [D loss: -0.845874] [G loss: 0.116158]\n",
      "epoch1 step10380 [D loss: -0.493180] [G loss: 0.636256]\n",
      "epoch1 step10385 [D loss: 0.327311] [G loss: 0.790542]\n",
      "epoch1 step10390 [D loss: -0.542929] [G loss: 0.321994]\n",
      "epoch1 step10395 [D loss: -0.754495] [G loss: 0.580714]\n",
      "epoch1 step10400 [D loss: -1.444260] [G loss: 0.048737]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.044939\n",
      "FID: 29.138824\n",
      "0 = 13.996728177833553\n",
      "1 = 0.1355989647412236\n",
      "2 = 0.8640999794006348\n",
      "3 = 0.9524000287055969\n",
      "4 = 0.7757999897003174\n",
      "5 = 0.8094509840011597\n",
      "6 = 0.9524000287055969\n",
      "7 = 8.617105550909027\n",
      "8 = 0.10366177588043976\n",
      "9 = 0.8255000114440918\n",
      "10 = 0.8569999933242798\n",
      "11 = 0.7940000295639038\n",
      "12 = 0.8062088489532471\n",
      "13 = 0.8569999933242798\n",
      "14 = 6.044960021972656\n",
      "15 = 9.09611701965332\n",
      "16 = 0.21069984138011932\n",
      "17 = 6.044938564300537\n",
      "18 = 29.138824462890625\n",
      "epoch1 step10405 [D loss: -1.071079] [G loss: 0.530196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 step10410 [D loss: -1.730924] [G loss: 0.948574]\n",
      "epoch1 step10415 [D loss: -2.173468] [G loss: 0.589479]\n",
      "epoch1 step10420 [D loss: -1.173280] [G loss: 0.146849]\n",
      "epoch1 step10425 [D loss: -2.127474] [G loss: 0.970475]\n",
      "epoch1 step10430 [D loss: -1.780794] [G loss: 0.486244]\n",
      "epoch1 step10435 [D loss: 0.106076] [G loss: 0.241737]\n",
      "epoch1 step10440 [D loss: -1.011997] [G loss: -0.267705]\n",
      "epoch1 step10445 [D loss: -0.225850] [G loss: 0.097331]\n",
      "epoch1 step10450 [D loss: 0.129620] [G loss: -0.422749]\n",
      "epoch1 step10455 [D loss: -0.288900] [G loss: 0.150652]\n",
      "epoch1 step10460 [D loss: -1.109030] [G loss: -0.137371]\n",
      "epoch1 step10465 [D loss: 0.992515] [G loss: -0.877709]\n",
      "epoch1 step10470 [D loss: -0.803016] [G loss: -0.469538]\n",
      "epoch1 step10475 [D loss: -0.906135] [G loss: -0.174171]\n",
      "epoch1 step10480 [D loss: -0.518582] [G loss: -0.212992]\n",
      "epoch1 step10485 [D loss: -0.537771] [G loss: -0.659772]\n",
      "epoch1 step10490 [D loss: -0.675265] [G loss: -0.663803]\n",
      "epoch1 step10495 [D loss: -0.855724] [G loss: 0.202367]\n",
      "epoch1 step10500 [D loss: -0.811116] [G loss: -0.279771]\n",
      "epoch1 step10505 [D loss: -0.812014] [G loss: -0.297520]\n",
      "epoch1 step10510 [D loss: -0.176934] [G loss: -0.470187]\n",
      "epoch1 step10515 [D loss: 0.193057] [G loss: 0.403559]\n",
      "epoch1 step10520 [D loss: -0.203310] [G loss: 0.047514]\n",
      "epoch1 step10525 [D loss: 0.092751] [G loss: 0.426442]\n",
      "epoch1 step10530 [D loss: -0.627705] [G loss: -0.103187]\n",
      "epoch1 step10535 [D loss: -0.916708] [G loss: 0.121583]\n",
      "epoch1 step10540 [D loss: -0.281316] [G loss: 0.401803]\n",
      "epoch1 step10545 [D loss: -0.885054] [G loss: -0.094829]\n",
      "epoch1 step10550 [D loss: -0.359638] [G loss: 0.310928]\n",
      "epoch1 step10555 [D loss: -0.513427] [G loss: 0.061463]\n",
      "epoch1 step10560 [D loss: -0.569016] [G loss: -0.185847]\n",
      "epoch1 step10565 [D loss: -1.001288] [G loss: 0.689647]\n",
      "epoch1 step10570 [D loss: 0.269585] [G loss: 0.277152]\n",
      "epoch1 step10575 [D loss: -0.058205] [G loss: 0.176503]\n",
      "epoch1 step10580 [D loss: -0.521869] [G loss: 0.014130]\n",
      "epoch1 step10585 [D loss: -0.323027] [G loss: 0.243465]\n",
      "epoch1 step10590 [D loss: -0.093976] [G loss: 0.400338]\n",
      "epoch1 step10595 [D loss: -0.628863] [G loss: 0.383831]\n",
      "epoch1 step10600 [D loss: -0.216202] [G loss: 0.958435]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.980633\n",
      "FID: 30.968378\n",
      "0 = 13.939714191055282\n",
      "1 = 0.13128138575629733\n",
      "2 = 0.8651000261306763\n",
      "3 = 0.9552000164985657\n",
      "4 = 0.7749999761581421\n",
      "5 = 0.8093543648719788\n",
      "6 = 0.9552000164985657\n",
      "7 = 8.695401569747924\n",
      "8 = 0.10592327371234535\n",
      "9 = 0.8292999863624573\n",
      "10 = 0.8611999750137329\n",
      "11 = 0.7973999977111816\n",
      "12 = 0.8095506429672241\n",
      "13 = 0.8611999750137329\n",
      "14 = 5.98065710067749\n",
      "15 = 9.070923805236816\n",
      "16 = 0.21978147327899933\n",
      "17 = 5.98063325881958\n",
      "18 = 30.9683780670166\n",
      "epoch1 step10605 [D loss: -0.624120] [G loss: 0.658209]\n",
      "epoch1 step10610 [D loss: -0.269868] [G loss: 1.119660]\n",
      "epoch1 step10615 [D loss: -0.324709] [G loss: 0.867248]\n",
      "epoch1 step10620 [D loss: 0.182420] [G loss: 1.359624]\n",
      "epoch1 step10625 [D loss: -0.172995] [G loss: 1.847000]\n",
      "epoch1 step10630 [D loss: -1.092382] [G loss: 1.482257]\n",
      "epoch1 step10635 [D loss: -1.476672] [G loss: 2.057557]\n",
      "epoch1 step10640 [D loss: -0.971133] [G loss: 2.169907]\n",
      "epoch1 step10645 [D loss: -0.381804] [G loss: 1.891744]\n",
      "epoch1 step10650 [D loss: -0.416441] [G loss: 1.562160]\n",
      "epoch1 step10655 [D loss: -0.244304] [G loss: 2.084865]\n",
      "epoch1 step10660 [D loss: -1.681752] [G loss: 2.808545]\n",
      "epoch1 step10665 [D loss: -0.341721] [G loss: 2.187857]\n",
      "epoch1 step10670 [D loss: -0.831213] [G loss: 2.788847]\n",
      "epoch1 step10675 [D loss: -0.119567] [G loss: 2.660296]\n",
      "epoch1 step10680 [D loss: -2.299375] [G loss: 2.558628]\n",
      "epoch1 step10685 [D loss: -0.326667] [G loss: 1.614970]\n",
      "epoch1 step10690 [D loss: -0.441235] [G loss: 2.389822]\n",
      "epoch1 step10695 [D loss: -1.079825] [G loss: 1.813543]\n",
      "epoch1 step10700 [D loss: -0.398692] [G loss: 1.897689]\n",
      "epoch1 step10705 [D loss: -0.676445] [G loss: 2.134644]\n",
      "epoch1 step10710 [D loss: -0.311291] [G loss: 2.418372]\n",
      "epoch1 step10715 [D loss: -0.382310] [G loss: 1.852102]\n",
      "epoch1 step10720 [D loss: 0.761296] [G loss: 1.454865]\n",
      "epoch1 step10725 [D loss: -1.247531] [G loss: 1.920874]\n",
      "epoch1 step10730 [D loss: -0.613256] [G loss: 2.073694]\n",
      "epoch1 step10735 [D loss: -0.994627] [G loss: 1.719017]\n",
      "epoch1 step10740 [D loss: -0.165700] [G loss: 2.035107]\n",
      "epoch1 step10745 [D loss: -0.535308] [G loss: 2.619908]\n",
      "epoch1 step10750 [D loss: 0.198253] [G loss: 2.298990]\n",
      "epoch1 step10755 [D loss: -0.217224] [G loss: 1.509999]\n",
      "epoch1 step10760 [D loss: -1.091277] [G loss: 1.947603]\n",
      "epoch1 step10765 [D loss: -0.750818] [G loss: 1.281033]\n",
      "epoch1 step10770 [D loss: -0.512301] [G loss: 1.762457]\n",
      "epoch1 step10775 [D loss: -0.143564] [G loss: 1.774462]\n",
      "epoch1 step10780 [D loss: -0.770830] [G loss: 1.450433]\n",
      "epoch1 step10785 [D loss: -0.848151] [G loss: 1.443855]\n",
      "epoch1 step10790 [D loss: -0.018487] [G loss: 1.929946]\n",
      "epoch1 step10795 [D loss: -0.387841] [G loss: 1.284928]\n",
      "epoch1 step10800 [D loss: -1.180776] [G loss: 2.401563]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.901558\n",
      "FID: 35.297829\n",
      "0 = 13.356472972965234\n",
      "1 = 0.0875188807144284\n",
      "2 = 0.8741000294685364\n",
      "3 = 0.9336000084877014\n",
      "4 = 0.8145999908447266\n",
      "5 = 0.8343163728713989\n",
      "6 = 0.9336000084877014\n",
      "7 = 8.880186831307405\n",
      "8 = 0.11658730986882204\n",
      "9 = 0.8409000039100647\n",
      "10 = 0.8611999750137329\n",
      "11 = 0.8205999732017517\n",
      "12 = 0.8275994658470154\n",
      "13 = 0.8611999750137329\n",
      "14 = 5.901578903198242\n",
      "15 = 9.31203556060791\n",
      "16 = 0.18891273438930511\n",
      "17 = 5.9015583992004395\n",
      "18 = 35.297828674316406\n",
      "epoch1 step10805 [D loss: -0.940134] [G loss: 1.513081]\n",
      "epoch1 step10810 [D loss: -0.597819] [G loss: 1.576368]\n",
      "epoch1 step10815 [D loss: -0.774449] [G loss: 2.112315]\n",
      "epoch1 step10820 [D loss: -0.669540] [G loss: 1.299363]\n",
      "epoch1 step10825 [D loss: -1.459651] [G loss: 2.281678]\n",
      "epoch1 step10830 [D loss: -0.643021] [G loss: 2.274295]\n",
      "epoch1 step10835 [D loss: -0.706863] [G loss: 2.433167]\n",
      "epoch1 step10840 [D loss: -1.021539] [G loss: 1.983077]\n",
      "epoch1 step10845 [D loss: -0.820693] [G loss: 1.778240]\n",
      "epoch1 step10850 [D loss: -1.867737] [G loss: 2.276180]\n",
      "epoch1 step10855 [D loss: -0.713887] [G loss: 2.055385]\n",
      "epoch1 step10860 [D loss: -1.671679] [G loss: 2.781066]\n",
      "epoch1 step10865 [D loss: -0.526638] [G loss: 2.239651]\n",
      "epoch1 step10870 [D loss: -0.595330] [G loss: 2.184545]\n",
      "epoch1 step10875 [D loss: -1.307340] [G loss: 2.392070]\n",
      "epoch1 step10880 [D loss: -1.380516] [G loss: 2.713194]\n",
      "epoch1 step10885 [D loss: -1.628697] [G loss: 2.837586]\n",
      "epoch1 step10890 [D loss: -1.657836] [G loss: 2.314133]\n",
      "epoch1 step10895 [D loss: -2.943842] [G loss: 2.072083]\n",
      "epoch1 step10900 [D loss: -1.762908] [G loss: 2.168756]\n",
      "epoch1 step10905 [D loss: -0.101681] [G loss: 2.192358]\n",
      "epoch1 step10910 [D loss: -0.209268] [G loss: 1.866001]\n",
      "epoch1 step10915 [D loss: -0.255631] [G loss: 2.042667]\n",
      "epoch1 step10920 [D loss: -0.692528] [G loss: 2.098790]\n",
      "epoch1 step10925 [D loss: -1.069940] [G loss: 1.923886]\n",
      "epoch1 step10930 [D loss: -0.765494] [G loss: 1.549264]\n",
      "epoch1 step10935 [D loss: -0.210569] [G loss: 1.804850]\n",
      "epoch1 step10940 [D loss: -0.553573] [G loss: 2.045418]\n",
      "epoch1 step10945 [D loss: -0.110573] [G loss: 1.950912]\n",
      "epoch1 step10950 [D loss: 0.477204] [G loss: 1.397101]\n",
      "epoch1 step10955 [D loss: 0.114076] [G loss: 1.378704]\n",
      "epoch1 step10960 [D loss: -0.479693] [G loss: 2.006120]\n",
      "epoch1 step10965 [D loss: 0.435611] [G loss: 1.986300]\n",
      "epoch1 step10970 [D loss: -0.358490] [G loss: 1.493040]\n",
      "epoch1 step10975 [D loss: 0.446175] [G loss: 1.784507]\n",
      "epoch1 step10980 [D loss: -0.585939] [G loss: 1.654241]\n",
      "epoch1 step10985 [D loss: -0.800069] [G loss: 1.181377]\n",
      "epoch1 step10990 [D loss: -0.204042] [G loss: 1.801132]\n",
      "epoch1 step10995 [D loss: -0.498354] [G loss: 1.612713]\n",
      "epoch1 step11000 [D loss: -0.250982] [G loss: 1.804240]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.831926\n",
      "FID: 34.399124\n",
      "0 = 13.94160202341083\n",
      "1 = 0.12147118598020479\n",
      "2 = 0.8647000193595886\n",
      "3 = 0.9508000016212463\n",
      "4 = 0.7785999774932861\n",
      "5 = 0.8111243844032288\n",
      "6 = 0.9508000016212463\n",
      "7 = 8.893026610493655\n",
      "8 = 0.112957722612393\n",
      "9 = 0.8363000154495239\n",
      "10 = 0.8646000027656555\n",
      "11 = 0.8080000281333923\n",
      "12 = 0.8182850480079651\n",
      "13 = 0.8646000027656555\n",
      "14 = 5.831945896148682\n",
      "15 = 9.115567207336426\n",
      "16 = 0.21526694297790527\n",
      "17 = 5.831926345825195\n",
      "18 = 34.39912414550781\n",
      "epoch1 step11005 [D loss: -0.220847] [G loss: 2.109179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 step11010 [D loss: -0.189035] [G loss: 2.027754]\n",
      "epoch1 step11015 [D loss: -0.125199] [G loss: 1.670697]\n",
      "epoch1 step11020 [D loss: -0.621173] [G loss: 1.612744]\n",
      "epoch1 step11025 [D loss: 0.168397] [G loss: 1.767159]\n",
      "epoch1 step11030 [D loss: -1.000405] [G loss: 2.057075]\n",
      "epoch1 step11035 [D loss: 0.401391] [G loss: 0.878140]\n",
      "epoch1 step11040 [D loss: -0.158110] [G loss: 1.505684]\n",
      "epoch1 step11045 [D loss: 0.146489] [G loss: 1.614721]\n",
      "epoch1 step11050 [D loss: -0.640656] [G loss: 0.779379]\n",
      "epoch1 step11055 [D loss: -0.017649] [G loss: 1.528872]\n",
      "epoch1 step11060 [D loss: -0.357532] [G loss: 1.696485]\n",
      "epoch1 step11065 [D loss: 0.203259] [G loss: 1.376225]\n",
      "epoch1 step11070 [D loss: -0.469911] [G loss: 1.178984]\n",
      "epoch1 step11075 [D loss: -0.601762] [G loss: 1.475137]\n",
      "epoch1 step11080 [D loss: -0.841722] [G loss: 1.179084]\n",
      "epoch1 step11085 [D loss: 0.059977] [G loss: 0.426622]\n",
      "epoch1 step11090 [D loss: -0.918354] [G loss: 1.402796]\n",
      "epoch1 step11095 [D loss: -0.438078] [G loss: 1.175474]\n",
      "epoch1 step11100 [D loss: -1.400365] [G loss: 1.249914]\n",
      "epoch1 step11105 [D loss: -0.770463] [G loss: 1.219682]\n",
      "epoch1 step11110 [D loss: -0.500109] [G loss: 1.227114]\n",
      "epoch1 step11115 [D loss: -0.762303] [G loss: 0.978386]\n",
      "epoch1 step11120 [D loss: -1.339024] [G loss: 0.870391]\n",
      "epoch1 step11125 [D loss: -0.726758] [G loss: 1.435733]\n",
      "epoch1 step11130 [D loss: -1.164342] [G loss: 1.298124]\n",
      "epoch1 step11135 [D loss: -0.473890] [G loss: 0.787099]\n",
      "epoch1 step11140 [D loss: -0.898832] [G loss: 1.576206]\n",
      "epoch1 step11145 [D loss: 0.633095] [G loss: 0.541499]\n",
      "epoch1 step11150 [D loss: -0.776440] [G loss: 0.686424]\n",
      "epoch1 step11155 [D loss: -0.536389] [G loss: 1.604981]\n",
      "epoch1 step11160 [D loss: -1.120261] [G loss: 0.622832]\n",
      "epoch1 step11165 [D loss: -0.533397] [G loss: 0.420699]\n",
      "epoch1 step11170 [D loss: -0.723660] [G loss: 0.772743]\n",
      "epoch1 step11175 [D loss: -1.009730] [G loss: 0.629047]\n",
      "epoch1 step11180 [D loss: -1.337775] [G loss: 0.553239]\n",
      "epoch1 step11185 [D loss: -1.238713] [G loss: 0.615339]\n",
      "epoch1 step11190 [D loss: -0.997044] [G loss: 0.623052]\n",
      "epoch1 step11195 [D loss: -0.952156] [G loss: 1.143768]\n",
      "epoch1 step11200 [D loss: -1.000971] [G loss: 0.446086]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.056266\n",
      "FID: 30.182238\n",
      "0 = 13.424395846843732\n",
      "1 = 0.07632821495964505\n",
      "2 = 0.8543000221252441\n",
      "3 = 0.9490000009536743\n",
      "4 = 0.7595999836921692\n",
      "5 = 0.7978813052177429\n",
      "6 = 0.9490000009536743\n",
      "7 = 8.645975143837937\n",
      "8 = 0.10467968811950752\n",
      "9 = 0.8276000022888184\n",
      "10 = 0.8525999784469604\n",
      "11 = 0.8026000261306763\n",
      "12 = 0.8119999766349792\n",
      "13 = 0.8525999784469604\n",
      "14 = 6.056285381317139\n",
      "15 = 9.266823768615723\n",
      "16 = 0.1958106905221939\n",
      "17 = 6.056265830993652\n",
      "18 = 30.18223762512207\n",
      "epoch1 step11205 [D loss: -1.008653] [G loss: 0.416181]\n",
      "epoch1 step11210 [D loss: -1.268625] [G loss: 1.129167]\n",
      "epoch1 step11215 [D loss: -0.710179] [G loss: 0.407597]\n",
      "epoch1 step11220 [D loss: 0.112186] [G loss: 0.379029]\n",
      "epoch1 step11225 [D loss: -0.477412] [G loss: 0.081948]\n",
      "epoch1 step11230 [D loss: -0.096888] [G loss: 0.750331]\n",
      "epoch1 step11235 [D loss: -0.573158] [G loss: -0.021496]\n",
      "epoch1 step11240 [D loss: -0.478914] [G loss: 0.708599]\n",
      "epoch1 step11245 [D loss: -0.838945] [G loss: -0.262018]\n",
      "epoch1 step11250 [D loss: -0.190803] [G loss: 0.326763]\n",
      "epoch1 step11255 [D loss: -0.391479] [G loss: -0.026399]\n",
      "epoch1 step11260 [D loss: -0.275373] [G loss: -0.522695]\n",
      "epoch1 step11265 [D loss: -0.742899] [G loss: 0.353304]\n",
      "epoch1 step11270 [D loss: -0.675806] [G loss: 0.094126]\n",
      "epoch1 step11275 [D loss: -0.280969] [G loss: 0.072094]\n",
      "epoch1 step11280 [D loss: -0.560366] [G loss: 0.131916]\n",
      "epoch1 step11285 [D loss: -0.544467] [G loss: 0.570101]\n",
      "epoch1 step11290 [D loss: -1.035327] [G loss: 0.536427]\n",
      "epoch1 step11295 [D loss: -0.941237] [G loss: -0.118038]\n",
      "epoch1 step11300 [D loss: -0.875842] [G loss: 0.980352]\n",
      "epoch1 step11305 [D loss: -1.154797] [G loss: 0.547522]\n",
      "epoch1 step11310 [D loss: -0.739715] [G loss: 1.305959]\n",
      "epoch1 step11315 [D loss: -1.156826] [G loss: 1.231374]\n",
      "epoch1 step11320 [D loss: -0.778093] [G loss: 0.573537]\n",
      "epoch1 step11325 [D loss: -0.603865] [G loss: 0.966743]\n",
      "epoch1 step11330 [D loss: 0.644072] [G loss: 1.041949]\n",
      "epoch1 step11335 [D loss: 0.484297] [G loss: 0.784978]\n",
      "epoch1 step11340 [D loss: -1.759859] [G loss: 0.582063]\n",
      "epoch1 step11345 [D loss: -0.050571] [G loss: 0.709312]\n",
      "epoch1 step11350 [D loss: -1.180978] [G loss: 1.359561]\n",
      "epoch1 step11355 [D loss: -0.853995] [G loss: 1.671751]\n",
      "epoch1 step11360 [D loss: -0.614903] [G loss: 2.002199]\n",
      "epoch1 step11365 [D loss: -0.710884] [G loss: 1.653224]\n",
      "epoch1 step11370 [D loss: -0.157988] [G loss: 1.420217]\n",
      "epoch1 step11375 [D loss: 0.063572] [G loss: 1.885162]\n",
      "epoch1 step11380 [D loss: -0.778378] [G loss: 2.063163]\n",
      "epoch1 step11385 [D loss: -0.274177] [G loss: 1.891078]\n",
      "epoch1 step11390 [D loss: -0.666271] [G loss: 2.166269]\n",
      "epoch1 step11395 [D loss: -0.133924] [G loss: 1.522687]\n",
      "epoch1 step11400 [D loss: 0.538549] [G loss: 1.764803]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.915032\n",
      "FID: 36.373016\n",
      "0 = 13.36318498473163\n",
      "1 = 0.10998961919873136\n",
      "2 = 0.8952000141143799\n",
      "3 = 0.9383999705314636\n",
      "4 = 0.8519999980926514\n",
      "5 = 0.8637702465057373\n",
      "6 = 0.9383999705314636\n",
      "7 = 9.033278789854048\n",
      "8 = 0.11907256637030933\n",
      "9 = 0.8471999764442444\n",
      "10 = 0.864799976348877\n",
      "11 = 0.8295999765396118\n",
      "12 = 0.8353941440582275\n",
      "13 = 0.864799976348877\n",
      "14 = 5.915050983428955\n",
      "15 = 9.411619186401367\n",
      "16 = 0.1780693382024765\n",
      "17 = 5.915032386779785\n",
      "18 = 36.373016357421875\n",
      "epoch1 step11405 [D loss: 0.307358] [G loss: 1.366829]\n",
      "epoch1 step11410 [D loss: -0.077103] [G loss: 1.321839]\n",
      "epoch1 step11415 [D loss: -0.260656] [G loss: 1.564676]\n",
      "epoch1 step11420 [D loss: -0.463251] [G loss: 1.714176]\n",
      "epoch1 step11425 [D loss: -1.213432] [G loss: 1.906625]\n",
      "epoch1 step11430 [D loss: -0.802114] [G loss: 1.942133]\n",
      "epoch1 step11435 [D loss: -1.294589] [G loss: 1.839858]\n",
      "epoch1 step11440 [D loss: 0.108529] [G loss: 1.922192]\n",
      "epoch1 step11445 [D loss: -1.183630] [G loss: 1.864960]\n",
      "epoch1 step11450 [D loss: -0.902331] [G loss: 1.983896]\n",
      "epoch1 step11455 [D loss: -2.002932] [G loss: 2.233902]\n",
      "epoch1 step11460 [D loss: -0.970335] [G loss: 2.004889]\n",
      "epoch1 step11465 [D loss: -0.928555] [G loss: 1.192193]\n",
      "epoch1 step11470 [D loss: 0.035292] [G loss: 1.819669]\n",
      "epoch1 step11475 [D loss: 0.142279] [G loss: 1.357211]\n",
      "epoch1 step11480 [D loss: -0.940405] [G loss: 2.168111]\n",
      "epoch1 step11485 [D loss: -0.331779] [G loss: 1.690992]\n",
      "epoch1 step11490 [D loss: -1.137021] [G loss: 1.915004]\n",
      "epoch1 step11495 [D loss: -0.786993] [G loss: 1.953567]\n",
      "epoch1 step11500 [D loss: 0.149986] [G loss: 2.209515]\n",
      "epoch1 step11505 [D loss: -0.667990] [G loss: 2.193047]\n",
      "epoch1 step11510 [D loss: -0.633849] [G loss: 2.228599]\n",
      "epoch1 step11515 [D loss: -0.129984] [G loss: 1.831024]\n",
      "epoch1 step11520 [D loss: 0.376888] [G loss: 2.449955]\n",
      "epoch1 step11525 [D loss: -0.232629] [G loss: 2.418600]\n",
      "epoch1 step11530 [D loss: -0.702997] [G loss: 2.151440]\n",
      "epoch1 step11535 [D loss: -0.169346] [G loss: 1.951394]\n",
      "epoch1 step11540 [D loss: -1.445679] [G loss: 2.569605]\n",
      "epoch1 step11545 [D loss: -1.197132] [G loss: 2.501101]\n",
      "epoch1 step11550 [D loss: -0.319983] [G loss: 1.942790]\n",
      "epoch1 step11555 [D loss: -1.159261] [G loss: 2.225040]\n",
      "epoch1 step11560 [D loss: -0.673081] [G loss: 2.457097]\n",
      "epoch1 step11565 [D loss: -0.964717] [G loss: 2.266610]\n",
      "epoch1 step11570 [D loss: -0.680463] [G loss: 2.458295]\n",
      "epoch1 step11575 [D loss: -0.387653] [G loss: 2.014591]\n",
      "epoch1 step11580 [D loss: -1.087997] [G loss: 2.736377]\n",
      "epoch1 step11585 [D loss: -1.491114] [G loss: 2.831529]\n",
      "epoch1 step11590 [D loss: -1.367709] [G loss: 2.840098]\n",
      "epoch1 step11595 [D loss: -1.335430] [G loss: 3.073078]\n",
      "epoch1 step11600 [D loss: -1.151598] [G loss: 3.627330]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.676116\n",
      "FID: 41.897583\n",
      "0 = 13.739011075115185\n",
      "1 = 0.11169853827904068\n",
      "2 = 0.890500009059906\n",
      "3 = 0.9440000057220459\n",
      "4 = 0.8370000123977661\n",
      "5 = 0.8527551889419556\n",
      "6 = 0.9440000057220459\n",
      "7 = 9.304050214362158\n",
      "8 = 0.13002591388354093\n",
      "9 = 0.8603000044822693\n",
      "10 = 0.8755999803543091\n",
      "11 = 0.8450000286102295\n",
      "12 = 0.8496021628379822\n",
      "13 = 0.8755999803543091\n",
      "14 = 5.676138401031494\n",
      "15 = 9.2088041305542\n",
      "16 = 0.2065146267414093\n",
      "17 = 5.676116466522217\n",
      "18 = 41.8975830078125\n",
      "epoch1 step11605 [D loss: -1.347743] [G loss: 3.492631]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 step11610 [D loss: 0.282494] [G loss: 3.278780]\n",
      "epoch1 step11615 [D loss: -1.423562] [G loss: 3.485914]\n",
      "epoch1 step11620 [D loss: -0.131597] [G loss: 3.166033]\n",
      "epoch1 step11625 [D loss: -0.424348] [G loss: 3.302919]\n",
      "epoch1 step11630 [D loss: -0.886638] [G loss: 3.819523]\n",
      "epoch1 step11635 [D loss: -1.243785] [G loss: 3.564092]\n",
      "epoch1 step11640 [D loss: -0.281122] [G loss: 2.334782]\n",
      "epoch1 step11645 [D loss: -1.053106] [G loss: 3.833182]\n",
      "epoch1 step11650 [D loss: -1.640105] [G loss: 3.855301]\n",
      "epoch1 step11655 [D loss: -0.328337] [G loss: 3.714284]\n",
      "epoch1 step11660 [D loss: -0.997472] [G loss: 3.087342]\n",
      "epoch1 step11665 [D loss: -2.324560] [G loss: 3.335649]\n",
      "epoch1 step11670 [D loss: -2.151373] [G loss: 3.691060]\n",
      "epoch1 step11675 [D loss: -1.966452] [G loss: 3.037356]\n",
      "epoch1 step11680 [D loss: -2.227165] [G loss: 4.284584]\n",
      "epoch1 step11685 [D loss: -2.426691] [G loss: 3.997077]\n",
      "epoch1 step11690 [D loss: -2.724948] [G loss: 4.765819]\n",
      "epoch1 step11695 [D loss: -3.669877] [G loss: 4.480327]\n",
      "epoch1 step11700 [D loss: -0.167535] [G loss: 3.867588]\n",
      "epoch1 step11705 [D loss: -0.422355] [G loss: 3.704689]\n",
      "epoch1 step11710 [D loss: -0.987679] [G loss: 4.016125]\n",
      "epoch1 step11715 [D loss: -1.276867] [G loss: 4.521001]\n",
      "epoch1 step11720 [D loss: -1.013700] [G loss: 3.605078]\n",
      "epoch1 step11725 [D loss: 0.114982] [G loss: 3.469445]\n",
      "epoch1 step11730 [D loss: 0.059017] [G loss: 3.692100]\n",
      "epoch1 step11735 [D loss: 0.012421] [G loss: 3.636341]\n",
      "epoch1 step11740 [D loss: -0.182344] [G loss: 3.984471]\n",
      "epoch1 step11745 [D loss: -0.443665] [G loss: 3.424248]\n",
      "epoch1 step11750 [D loss: -0.798092] [G loss: 3.515445]\n",
      "epoch1 step11755 [D loss: -0.011134] [G loss: 3.527332]\n",
      "epoch1 step11760 [D loss: -0.222318] [G loss: 3.311657]\n",
      "epoch1 step11765 [D loss: -0.512077] [G loss: 3.227202]\n",
      "epoch1 step11770 [D loss: -0.008475] [G loss: 2.791401]\n",
      "epoch1 step11775 [D loss: 0.390596] [G loss: 2.754806]\n",
      "epoch1 step11780 [D loss: -0.174243] [G loss: 2.354209]\n",
      "epoch1 step11785 [D loss: 0.081491] [G loss: 2.644990]\n",
      "epoch1 step11790 [D loss: -0.757412] [G loss: 3.487171]\n",
      "epoch1 step11795 [D loss: 0.381684] [G loss: 2.731338]\n",
      "epoch1 step11800 [D loss: -0.359111] [G loss: 3.025269]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.648005\n",
      "FID: 40.300423\n",
      "0 = 13.255051689291022\n",
      "1 = 0.06366221348765264\n",
      "2 = 0.8733000159263611\n",
      "3 = 0.9366000294685364\n",
      "4 = 0.8100000023841858\n",
      "5 = 0.8313509821891785\n",
      "6 = 0.9366000294685364\n",
      "7 = 9.223513950467119\n",
      "8 = 0.1294576239163831\n",
      "9 = 0.8539000153541565\n",
      "10 = 0.8744000196456909\n",
      "11 = 0.8334000110626221\n",
      "12 = 0.839961588382721\n",
      "13 = 0.8744000196456909\n",
      "14 = 5.648021221160889\n",
      "15 = 9.045661926269531\n",
      "16 = 0.23409827053546906\n",
      "17 = 5.648004531860352\n",
      "18 = 40.30042266845703\n",
      "epoch1 step11805 [D loss: -0.420394] [G loss: 3.198514]\n",
      "epoch1 step11810 [D loss: 0.352661] [G loss: 3.849567]\n",
      "epoch1 step11815 [D loss: -0.481863] [G loss: 3.290069]\n",
      "epoch1 step11820 [D loss: -0.258314] [G loss: 3.504496]\n",
      "epoch1 step11825 [D loss: -1.052888] [G loss: 3.369726]\n",
      "epoch1 step11830 [D loss: -1.275606] [G loss: 3.438336]\n",
      "epoch1 step11835 [D loss: -0.232048] [G loss: 3.496256]\n",
      "epoch1 step11840 [D loss: -0.583959] [G loss: 3.253169]\n",
      "epoch1 step11845 [D loss: -0.091962] [G loss: 3.809546]\n",
      "epoch1 step11850 [D loss: -0.555501] [G loss: 3.594391]\n",
      "epoch1 step11855 [D loss: -1.302204] [G loss: 3.446771]\n",
      "epoch1 step11860 [D loss: -1.244606] [G loss: 3.996259]\n",
      "epoch1 step11865 [D loss: 0.107884] [G loss: 3.371168]\n",
      "epoch1 step11870 [D loss: -0.860360] [G loss: 3.626358]\n",
      "epoch1 step11875 [D loss: -0.945322] [G loss: 3.262306]\n",
      "epoch1 step11880 [D loss: -1.028682] [G loss: 3.426845]\n",
      "epoch1 step11885 [D loss: -1.189148] [G loss: 3.304993]\n",
      "epoch1 step11890 [D loss: -0.414355] [G loss: 2.972491]\n",
      "epoch1 step11895 [D loss: 0.243836] [G loss: 3.351382]\n",
      "epoch1 step11900 [D loss: -0.751633] [G loss: 3.328788]\n",
      "epoch1 step11905 [D loss: -0.647863] [G loss: 2.936753]\n",
      "epoch1 step11910 [D loss: -0.375497] [G loss: 2.796190]\n",
      "epoch1 step11915 [D loss: -0.606108] [G loss: 2.753112]\n",
      "epoch1 step11920 [D loss: -0.258831] [G loss: 2.258721]\n",
      "epoch1 step11925 [D loss: -0.394977] [G loss: 2.668034]\n",
      "epoch1 step11930 [D loss: 0.059986] [G loss: 2.863686]\n",
      "epoch1 step11935 [D loss: -0.575907] [G loss: 2.320125]\n",
      "epoch1 step11940 [D loss: -1.270657] [G loss: 2.835937]\n",
      "epoch1 step11945 [D loss: -0.352514] [G loss: 1.897615]\n",
      "epoch1 step11950 [D loss: -0.145899] [G loss: 2.375878]\n",
      "epoch1 step11955 [D loss: -0.882956] [G loss: 1.890300]\n",
      "epoch1 step11960 [D loss: -0.753414] [G loss: 1.551157]\n",
      "epoch1 step11965 [D loss: -1.024892] [G loss: 1.237394]\n",
      "epoch1 step11970 [D loss: -0.589925] [G loss: 2.143650]\n",
      "epoch1 step11975 [D loss: -0.353050] [G loss: 1.068283]\n",
      "epoch1 step11980 [D loss: -0.645579] [G loss: 1.225081]\n",
      "epoch1 step11985 [D loss: -1.375654] [G loss: 1.378414]\n",
      "epoch1 step11990 [D loss: -1.504865] [G loss: 1.482428]\n",
      "epoch1 step11995 [D loss: 0.231993] [G loss: 1.206234]\n",
      "epoch1 step12000 [D loss: 0.255812] [G loss: 0.630865]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.973977\n",
      "FID: 32.237305\n",
      "0 = 13.28071957206723\n",
      "1 = 0.0695976369018151\n",
      "2 = 0.857699990272522\n",
      "3 = 0.9472000002861023\n",
      "4 = 0.7681999802589417\n",
      "5 = 0.8033927083015442\n",
      "6 = 0.9472000002861023\n",
      "7 = 8.8425233010769\n",
      "8 = 0.10848638042984719\n",
      "9 = 0.8392999768257141\n",
      "10 = 0.8676000237464905\n",
      "11 = 0.8109999895095825\n",
      "12 = 0.8211243748664856\n",
      "13 = 0.8676000237464905\n",
      "14 = 5.9739990234375\n",
      "15 = 9.348380088806152\n",
      "16 = 0.17908968031406403\n",
      "17 = 5.973977088928223\n",
      "18 = 32.2373046875\n",
      "epoch1 step12005 [D loss: -0.983518] [G loss: 0.764607]\n",
      "epoch1 step12010 [D loss: -0.853278] [G loss: 1.317088]\n",
      "epoch1 step12015 [D loss: -0.931174] [G loss: 0.620751]\n",
      "epoch1 step12020 [D loss: -0.162755] [G loss: 0.820594]\n",
      "epoch1 step12025 [D loss: -0.621150] [G loss: 0.956372]\n",
      "epoch1 step12030 [D loss: -0.953214] [G loss: 0.492206]\n",
      "epoch1 step12035 [D loss: -0.491084] [G loss: 0.571338]\n",
      "epoch1 step12040 [D loss: -0.774614] [G loss: 0.703208]\n",
      "epoch1 step12045 [D loss: 0.050470] [G loss: 0.647100]\n",
      "epoch1 step12050 [D loss: -0.164783] [G loss: 0.321519]\n",
      "epoch1 step12055 [D loss: -0.483529] [G loss: 1.091240]\n",
      "epoch1 step12060 [D loss: -0.863992] [G loss: 0.742280]\n",
      "epoch1 step12065 [D loss: -0.818011] [G loss: 0.829637]\n",
      "epoch1 step12070 [D loss: -0.048994] [G loss: 0.668368]\n",
      "epoch1 step12075 [D loss: -0.191936] [G loss: 1.107699]\n",
      "epoch1 step12080 [D loss: -0.271082] [G loss: 1.546704]\n",
      "epoch1 step12085 [D loss: -1.952409] [G loss: 1.403561]\n",
      "epoch1 step12090 [D loss: -1.085314] [G loss: 0.821969]\n",
      "epoch1 step12095 [D loss: -0.536437] [G loss: 1.866482]\n",
      "epoch1 step12100 [D loss: -0.779871] [G loss: 1.640304]\n",
      "epoch1 step12105 [D loss: -1.375356] [G loss: 1.166548]\n",
      "epoch1 step12110 [D loss: -1.032166] [G loss: 1.437916]\n",
      "epoch1 step12115 [D loss: -0.133828] [G loss: 1.915195]\n",
      "epoch1 step12120 [D loss: 0.533518] [G loss: 1.972888]\n",
      "epoch1 step12125 [D loss: -0.236086] [G loss: 1.598292]\n",
      "epoch1 step12130 [D loss: -1.425707] [G loss: 2.600619]\n",
      "epoch1 step12135 [D loss: -0.315805] [G loss: 2.031797]\n",
      "epoch1 step12140 [D loss: -1.249402] [G loss: 2.874951]\n",
      "epoch1 step12145 [D loss: 0.816617] [G loss: 2.042067]\n",
      "epoch1 step12150 [D loss: -0.601995] [G loss: 2.500096]\n",
      "epoch1 step12155 [D loss: 0.443619] [G loss: 2.499926]\n",
      "epoch1 step12160 [D loss: 0.107801] [G loss: 1.404263]\n",
      "epoch1 step12165 [D loss: 0.146827] [G loss: 2.289353]\n",
      "epoch1 step12170 [D loss: -0.937840] [G loss: 1.858664]\n",
      "epoch1 step12175 [D loss: -0.649188] [G loss: 2.275428]\n",
      "epoch1 step12180 [D loss: -0.505336] [G loss: 1.756120]\n",
      "epoch1 step12185 [D loss: -0.244885] [G loss: 1.880670]\n",
      "epoch1 step12190 [D loss: -0.278491] [G loss: 1.822180]\n",
      "epoch1 step12195 [D loss: -0.758687] [G loss: 1.818079]\n",
      "epoch1 step12200 [D loss: -0.685341] [G loss: 1.623944]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.965449\n",
      "FID: 33.800831\n",
      "0 = 13.11084979171751\n",
      "1 = 0.07887291534619169\n",
      "2 = 0.8657000064849854\n",
      "3 = 0.9376000165939331\n",
      "4 = 0.7937999963760376\n",
      "5 = 0.8197237253189087\n",
      "6 = 0.9376000165939331\n",
      "7 = 8.80478712708947\n",
      "8 = 0.11095378917328232\n",
      "9 = 0.8274000287055969\n",
      "10 = 0.8528000116348267\n",
      "11 = 0.8019999861717224\n",
      "12 = 0.8115721344947815\n",
      "13 = 0.8528000116348267\n",
      "14 = 5.965471267700195\n",
      "15 = 9.351197242736816\n",
      "16 = 0.1825307160615921\n",
      "17 = 5.96544885635376\n",
      "18 = 33.80083084106445\n",
      "epoch1 step12205 [D loss: -1.090774] [G loss: 1.427372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 step12210 [D loss: -0.356155] [G loss: 1.507146]\n",
      "epoch1 step12215 [D loss: -0.555560] [G loss: 1.506048]\n",
      "epoch1 step12220 [D loss: -0.699762] [G loss: 1.928522]\n",
      "epoch1 step12225 [D loss: -1.087855] [G loss: 1.627288]\n",
      "epoch1 step12230 [D loss: -1.891077] [G loss: 1.376296]\n",
      "epoch1 step12235 [D loss: -0.840401] [G loss: 1.815561]\n",
      "epoch1 step12240 [D loss: -0.734530] [G loss: 0.676242]\n",
      "epoch1 step12245 [D loss: -0.926953] [G loss: 1.176126]\n",
      "epoch1 step12250 [D loss: -0.418066] [G loss: 1.101815]\n",
      "epoch1 step12255 [D loss: -0.319374] [G loss: 0.305201]\n",
      "epoch1 step12260 [D loss: -1.020667] [G loss: 0.584241]\n",
      "epoch1 step12265 [D loss: -0.310455] [G loss: 0.730956]\n",
      "epoch1 step12270 [D loss: -1.034547] [G loss: 1.703911]\n",
      "epoch1 step12275 [D loss: -0.030199] [G loss: 0.487061]\n",
      "epoch1 step12280 [D loss: -0.233964] [G loss: 1.629718]\n",
      "epoch1 step12285 [D loss: -1.027732] [G loss: 1.520873]\n",
      "epoch1 step12290 [D loss: -0.271249] [G loss: 1.942700]\n",
      "epoch1 step12295 [D loss: 0.046938] [G loss: 1.812313]\n",
      "epoch1 step12300 [D loss: -0.394419] [G loss: 1.435557]\n",
      "epoch1 step12305 [D loss: -0.977460] [G loss: 2.013432]\n",
      "epoch1 step12310 [D loss: -1.206788] [G loss: 2.295413]\n",
      "epoch1 step12315 [D loss: -0.440001] [G loss: 2.144402]\n",
      "epoch1 step12320 [D loss: -0.822541] [G loss: 1.828380]\n",
      "epoch1 step12325 [D loss: -0.101946] [G loss: 2.880452]\n",
      "epoch1 step12330 [D loss: -1.298777] [G loss: 1.927596]\n",
      "epoch1 step12335 [D loss: -0.789382] [G loss: 2.179030]\n",
      "epoch1 step12340 [D loss: -0.920778] [G loss: 2.470221]\n",
      "epoch1 step12345 [D loss: -0.363320] [G loss: 2.450428]\n",
      "epoch1 step12350 [D loss: -1.082942] [G loss: 2.129514]\n",
      "epoch1 step12355 [D loss: -0.257274] [G loss: 2.235941]\n",
      "epoch1 step12360 [D loss: -0.806728] [G loss: 2.529431]\n",
      "epoch1 step12365 [D loss: -0.659793] [G loss: 2.580070]\n",
      "epoch1 step12370 [D loss: -0.616188] [G loss: 2.202776]\n",
      "epoch1 step12375 [D loss: -0.848168] [G loss: 1.770514]\n",
      "epoch1 step12380 [D loss: 0.099233] [G loss: 1.766828]\n",
      "epoch1 step12385 [D loss: -0.475703] [G loss: 2.591355]\n",
      "epoch1 step12390 [D loss: -1.182480] [G loss: 2.359277]\n",
      "epoch1 step12395 [D loss: -1.184946] [G loss: 2.985870]\n",
      "epoch1 step12400 [D loss: -0.883664] [G loss: 2.210884]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.998155\n",
      "FID: 30.527660\n",
      "0 = 13.330625066280378\n",
      "1 = 0.06458615532729083\n",
      "2 = 0.8442000150680542\n",
      "3 = 0.9441999793052673\n",
      "4 = 0.7441999912261963\n",
      "5 = 0.7868333458900452\n",
      "6 = 0.9441999793052673\n",
      "7 = 8.708376499152163\n",
      "8 = 0.10526623533167376\n",
      "9 = 0.8264999985694885\n",
      "10 = 0.8578000068664551\n",
      "11 = 0.795199990272522\n",
      "12 = 0.8072652220726013\n",
      "13 = 0.8578000068664551\n",
      "14 = 5.998175144195557\n",
      "15 = 9.308502197265625\n",
      "16 = 0.18584300577640533\n",
      "17 = 5.998155117034912\n",
      "18 = 30.527660369873047\n",
      "epoch1 step12405 [D loss: -1.080109] [G loss: 3.158953]\n",
      "epoch1 step12410 [D loss: -1.224839] [G loss: 3.179110]\n",
      "epoch1 step12415 [D loss: -0.827080] [G loss: 2.607259]\n",
      "epoch1 step12420 [D loss: -0.495909] [G loss: 2.351416]\n",
      "epoch1 step12425 [D loss: -0.675072] [G loss: 2.393282]\n",
      "epoch1 step12430 [D loss: -2.206006] [G loss: 2.844921]\n",
      "epoch1 step12435 [D loss: -0.248322] [G loss: 2.238960]\n",
      "epoch1 step12440 [D loss: -0.319916] [G loss: 2.607272]\n",
      "epoch1 step12445 [D loss: -0.531743] [G loss: 1.922395]\n",
      "epoch1 step12450 [D loss: -0.257921] [G loss: 1.717252]\n",
      "epoch1 step12455 [D loss: -0.935270] [G loss: 2.240422]\n",
      "epoch1 step12460 [D loss: -0.165558] [G loss: 1.921737]\n",
      "epoch1 step12465 [D loss: -0.261064] [G loss: 2.352199]\n",
      "epoch1 step12470 [D loss: -0.657885] [G loss: 2.049521]\n",
      "epoch1 step12475 [D loss: -1.063034] [G loss: 2.264365]\n",
      "epoch1 step12480 [D loss: -1.526379] [G loss: 2.730062]\n",
      "epoch1 step12485 [D loss: -0.665374] [G loss: 3.231010]\n",
      "epoch1 step12490 [D loss: -1.109201] [G loss: 2.949964]\n",
      "epoch1 step12495 [D loss: -0.360568] [G loss: 2.780396]\n",
      "epoch1 step12500 [D loss: -0.996021] [G loss: 3.202545]\n",
      "epoch1 step12505 [D loss: -1.651313] [G loss: 3.764648]\n",
      "epoch1 step12510 [D loss: -1.425039] [G loss: 3.621392]\n",
      "epoch1 step12515 [D loss: -0.999576] [G loss: 3.530828]\n",
      "epoch1 step12520 [D loss: -2.789806] [G loss: 3.713443]\n",
      "epoch1 step12525 [D loss: -1.210566] [G loss: 4.356025]\n",
      "epoch1 step12530 [D loss: 0.857574] [G loss: 3.789855]\n",
      "epoch1 step12535 [D loss: -0.171135] [G loss: 3.790492]\n",
      "epoch1 step12540 [D loss: -0.016932] [G loss: 3.343074]\n",
      "epoch1 step12545 [D loss: -0.052292] [G loss: 3.068386]\n",
      "epoch1 step12550 [D loss: -1.145854] [G loss: 3.184458]\n",
      "epoch1 step12555 [D loss: -0.390416] [G loss: 3.211075]\n",
      "epoch1 step12560 [D loss: -0.010215] [G loss: 3.141976]\n",
      "epoch1 step12565 [D loss: -0.727050] [G loss: 3.116948]\n",
      "epoch1 step12570 [D loss: -0.545538] [G loss: 2.940958]\n",
      "epoch1 step12575 [D loss: -0.510287] [G loss: 2.604646]\n",
      "epoch1 step12580 [D loss: 0.339181] [G loss: 2.237953]\n",
      "epoch1 step12585 [D loss: -0.297104] [G loss: 3.247676]\n",
      "epoch1 step12590 [D loss: -0.191303] [G loss: 2.448052]\n",
      "epoch1 step12595 [D loss: 0.428630] [G loss: 2.447190]\n",
      "epoch1 step12600 [D loss: -0.051743] [G loss: 1.931354]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.728486\n",
      "FID: 38.841095\n",
      "0 = 13.210775581264526\n",
      "1 = 0.0687280793355973\n",
      "2 = 0.8646000027656555\n",
      "3 = 0.9405999779701233\n",
      "4 = 0.7886000275611877\n",
      "5 = 0.816493034362793\n",
      "6 = 0.9405999779701233\n",
      "7 = 9.077798667907743\n",
      "8 = 0.12345310547122046\n",
      "9 = 0.8471999764442444\n",
      "10 = 0.8715999722480774\n",
      "11 = 0.8227999806404114\n",
      "12 = 0.8310450315475464\n",
      "13 = 0.8715999722480774\n",
      "14 = 5.728504657745361\n",
      "15 = 9.170567512512207\n",
      "16 = 0.2098715901374817\n",
      "17 = 5.728486061096191\n",
      "18 = 38.841094970703125\n",
      "epoch1 step12605 [D loss: -0.668346] [G loss: 1.563445]\n",
      "epoch1 step12610 [D loss: -1.020746] [G loss: 1.783614]\n",
      "epoch1 step12615 [D loss: -0.541986] [G loss: 1.990424]\n",
      "epoch1 step12620 [D loss: -1.296290] [G loss: 2.308785]\n",
      "epoch1 step12625 [D loss: -0.275752] [G loss: 1.731536]\n",
      "epoch1 step12630 [D loss: -0.799737] [G loss: 1.947767]\n",
      "epoch1 step12635 [D loss: -0.886483] [G loss: 2.405209]\n",
      "epoch1 step12640 [D loss: -0.797580] [G loss: 1.933613]\n",
      "epoch1 step12645 [D loss: -0.745957] [G loss: 2.116822]\n",
      "epoch1 step12650 [D loss: -0.548854] [G loss: 2.231775]\n",
      "epoch1 step12655 [D loss: -0.802634] [G loss: 1.552748]\n",
      "epoch1 step12660 [D loss: -1.129723] [G loss: 1.848767]\n",
      "epoch1 step12665 [D loss: -0.755132] [G loss: 2.249210]\n",
      "epoch1 step12670 [D loss: -0.329950] [G loss: 2.443354]\n",
      "epoch1 step12675 [D loss: -0.720006] [G loss: 2.525439]\n",
      "epoch1 step12680 [D loss: -0.548603] [G loss: 1.965550]\n",
      "epoch1 step12685 [D loss: -1.291357] [G loss: 2.371263]\n",
      "epoch1 step12690 [D loss: -0.647599] [G loss: 1.818706]\n",
      "epoch1 step12695 [D loss: -0.667955] [G loss: 2.906288]\n",
      "epoch1 step12700 [D loss: -0.777586] [G loss: 2.360190]\n",
      "epoch1 step12705 [D loss: -1.147506] [G loss: 2.958850]\n",
      "epoch1 step12710 [D loss: 0.242342] [G loss: 2.762060]\n",
      "epoch1 step12715 [D loss: -0.401275] [G loss: 2.992125]\n",
      "epoch1 step12720 [D loss: -1.033739] [G loss: 2.896325]\n",
      "epoch1 step12725 [D loss: -0.204213] [G loss: 3.549801]\n",
      "epoch1 step12730 [D loss: -0.707110] [G loss: 3.651180]\n",
      "epoch1 step12735 [D loss: -0.900738] [G loss: 3.801414]\n",
      "epoch1 step12740 [D loss: -1.751572] [G loss: 3.731412]\n",
      "epoch1 step12745 [D loss: -0.426607] [G loss: 3.514941]\n",
      "epoch1 step12750 [D loss: 0.070659] [G loss: 3.707476]\n",
      "epoch1 step12755 [D loss: -0.875324] [G loss: 3.531551]\n",
      "epoch1 step12760 [D loss: -0.192725] [G loss: 3.013733]\n",
      "epoch1 step12765 [D loss: -0.647390] [G loss: 3.125107]\n",
      "epoch1 step12770 [D loss: -0.682845] [G loss: 3.447710]\n",
      "epoch1 step12775 [D loss: -0.846380] [G loss: 2.518529]\n",
      "epoch1 step12780 [D loss: -0.996810] [G loss: 3.630367]\n",
      "epoch1 step12785 [D loss: 0.815374] [G loss: 3.256623]\n",
      "epoch1 step12790 [D loss: -0.142560] [G loss: 3.178996]\n",
      "epoch1 step12795 [D loss: -0.360143] [G loss: 2.249014]\n",
      "epoch1 step12800 [D loss: -1.236838] [G loss: 3.198075]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.145424\n",
      "FID: 28.458807\n",
      "0 = 13.32966408848766\n",
      "1 = 0.061701441402075445\n",
      "2 = 0.829800009727478\n",
      "3 = 0.9441999793052673\n",
      "4 = 0.715399980545044\n",
      "5 = 0.7683919072151184\n",
      "6 = 0.9441999793052673\n",
      "7 = 8.591001581120477\n",
      "8 = 0.10241982930087803\n",
      "9 = 0.8241999745368958\n",
      "10 = 0.8575999736785889\n",
      "11 = 0.7907999753952026\n",
      "12 = 0.8038995265960693\n",
      "13 = 0.8575999736785889\n",
      "14 = 6.145448684692383\n",
      "15 = 9.360061645507812\n",
      "16 = 0.16974684596061707\n",
      "17 = 6.1454243659973145\n",
      "18 = 28.45880699157715\n",
      "epoch1 step12805 [D loss: -0.693883] [G loss: 2.693210]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 step12810 [D loss: -0.778373] [G loss: 2.987974]\n",
      "epoch1 step12815 [D loss: -0.391934] [G loss: 2.658306]\n",
      "epoch1 step12820 [D loss: -1.071062] [G loss: 2.742866]\n",
      "epoch1 step12825 [D loss: -1.823783] [G loss: 2.400071]\n",
      "epoch1 step12830 [D loss: -1.609012] [G loss: 3.001762]\n",
      "epoch1 step12835 [D loss: -1.509199] [G loss: 2.973165]\n",
      "epoch1 step12840 [D loss: -1.188011] [G loss: 3.268865]\n",
      "epoch1 step12845 [D loss: -0.833343] [G loss: 3.581451]\n",
      "epoch1 step12850 [D loss: -1.309327] [G loss: 3.641340]\n",
      "epoch1 step12855 [D loss: -0.175607] [G loss: 2.937341]\n",
      "epoch1 step12860 [D loss: -0.407613] [G loss: 2.990916]\n",
      "epoch1 step12865 [D loss: -0.191183] [G loss: 2.502093]\n",
      "epoch1 step12870 [D loss: -0.256593] [G loss: 2.581156]\n",
      "epoch1 step12875 [D loss: 0.212702] [G loss: 2.561800]\n",
      "epoch1 step12880 [D loss: -0.639546] [G loss: 2.754629]\n",
      "epoch1 step12885 [D loss: -0.799729] [G loss: 2.639312]\n",
      "epoch1 step12890 [D loss: -0.123341] [G loss: 3.165719]\n",
      "epoch1 step12895 [D loss: -0.247878] [G loss: 2.308505]\n",
      "epoch1 step12900 [D loss: 0.053143] [G loss: 2.964816]\n",
      "epoch1 step12905 [D loss: -0.495442] [G loss: 2.374956]\n",
      "epoch1 step12910 [D loss: -0.684312] [G loss: 2.174069]\n",
      "epoch1 step12915 [D loss: -0.246982] [G loss: 2.738661]\n",
      "epoch1 step12920 [D loss: -0.540650] [G loss: 2.953296]\n",
      "epoch1 step12925 [D loss: -0.542426] [G loss: 2.597790]\n",
      "epoch1 step12930 [D loss: -0.207486] [G loss: 2.519588]\n",
      "epoch1 step12935 [D loss: -1.104743] [G loss: 2.683065]\n",
      "epoch1 step12940 [D loss: -1.286748] [G loss: 2.750785]\n",
      "epoch1 step12945 [D loss: -1.276178] [G loss: 3.384090]\n",
      "epoch1 step12950 [D loss: -0.942984] [G loss: 3.318922]\n",
      "epoch1 step12955 [D loss: -1.383345] [G loss: 3.071204]\n",
      "epoch1 step12960 [D loss: -0.428697] [G loss: 3.027816]\n",
      "epoch1 step12965 [D loss: -1.023411] [G loss: 3.408833]\n",
      "epoch1 step12970 [D loss: -0.327782] [G loss: 3.108047]\n",
      "epoch1 step12975 [D loss: -0.813160] [G loss: 3.284202]\n",
      "epoch1 step12980 [D loss: -0.649584] [G loss: 3.049242]\n",
      "epoch1 step12985 [D loss: -0.477989] [G loss: 2.634385]\n",
      "epoch1 step12990 [D loss: -0.395443] [G loss: 3.776593]\n",
      "epoch1 step12995 [D loss: -0.556762] [G loss: 2.803063]\n",
      "epoch1 step13000 [D loss: -0.139144] [G loss: 3.600987]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.960258\n",
      "FID: 30.154472\n",
      "0 = 14.628070453834596\n",
      "1 = 0.17413371795058796\n",
      "2 = 0.8621000051498413\n",
      "3 = 0.9571999907493591\n",
      "4 = 0.7670000195503235\n",
      "5 = 0.8042345643043518\n",
      "6 = 0.9571999907493591\n",
      "7 = 8.700505643177033\n",
      "8 = 0.107207483147162\n",
      "9 = 0.8241000175476074\n",
      "10 = 0.8583999872207642\n",
      "11 = 0.7897999882698059\n",
      "12 = 0.8032940030097961\n",
      "13 = 0.8583999872207642\n",
      "14 = 5.960278034210205\n",
      "15 = 9.007533073425293\n",
      "16 = 0.22294913232326508\n",
      "17 = 5.960257530212402\n",
      "18 = 30.15447235107422\n",
      "epoch1 step13005 [D loss: 0.752465] [G loss: 3.414228]\n",
      "epoch1 step13010 [D loss: -2.266656] [G loss: 3.609822]\n",
      "epoch1 step13015 [D loss: -0.501303] [G loss: 1.942912]\n",
      "epoch1 step13020 [D loss: -0.186393] [G loss: 2.765048]\n",
      "epoch1 step13025 [D loss: -0.544001] [G loss: 2.952696]\n",
      "epoch1 step13030 [D loss: -0.521795] [G loss: 2.810319]\n",
      "epoch1 step13035 [D loss: -0.001575] [G loss: 2.660175]\n",
      "epoch1 step13040 [D loss: -1.170335] [G loss: 2.564820]\n",
      "epoch1 step13045 [D loss: -0.932738] [G loss: 2.314106]\n",
      "epoch1 step13050 [D loss: 0.071836] [G loss: 3.044337]\n",
      "epoch1 step13055 [D loss: 0.039541] [G loss: 2.751906]\n",
      "epoch1 step13060 [D loss: -0.421728] [G loss: 2.502921]\n",
      "epoch1 step13065 [D loss: -2.152084] [G loss: 2.475141]\n",
      "epoch1 step13070 [D loss: -1.025303] [G loss: 2.104393]\n",
      "epoch1 step13075 [D loss: -0.894289] [G loss: 2.357781]\n",
      "epoch1 step13080 [D loss: -1.662334] [G loss: 1.724265]\n",
      "epoch1 step13085 [D loss: -0.462970] [G loss: 1.935037]\n",
      "epoch1 step13090 [D loss: -0.824751] [G loss: 2.400646]\n",
      "epoch1 step13095 [D loss: -0.669927] [G loss: 2.054260]\n",
      "epoch1 step13100 [D loss: 0.169875] [G loss: 1.681791]\n",
      "epoch1 step13105 [D loss: -0.440436] [G loss: 1.239669]\n",
      "epoch1 step13110 [D loss: -0.730472] [G loss: 2.429751]\n",
      "epoch1 step13115 [D loss: -1.104942] [G loss: 1.580985]\n",
      "epoch1 step13120 [D loss: -0.757103] [G loss: 1.715527]\n",
      "epoch1 step13125 [D loss: -0.221291] [G loss: 1.750162]\n",
      "epoch1 step13130 [D loss: 0.019709] [G loss: 1.603263]\n",
      "epoch1 step13135 [D loss: -0.437202] [G loss: 1.143830]\n",
      "epoch1 step13140 [D loss: -0.334141] [G loss: 1.560884]\n",
      "epoch1 step13145 [D loss: -0.986546] [G loss: 0.768362]\n",
      "epoch1 step13150 [D loss: -1.246040] [G loss: 1.903815]\n",
      "epoch1 step13155 [D loss: -0.777199] [G loss: 0.525894]\n",
      "epoch1 step13160 [D loss: -0.343011] [G loss: 0.781068]\n",
      "epoch1 step13165 [D loss: -0.622136] [G loss: 0.514291]\n",
      "epoch1 step13170 [D loss: 0.110718] [G loss: 0.562220]\n",
      "epoch1 step13175 [D loss: -0.538496] [G loss: 0.486257]\n",
      "epoch1 step13180 [D loss: 0.114377] [G loss: 0.499792]\n",
      "epoch1 step13185 [D loss: -0.525248] [G loss: 0.684026]\n",
      "epoch1 step13190 [D loss: -0.476191] [G loss: 1.138042]\n",
      "epoch1 step13195 [D loss: -0.278092] [G loss: 0.772424]\n",
      "epoch1 step13200 [D loss: -0.314628] [G loss: 0.581039]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.995048\n",
      "FID: 30.650608\n",
      "0 = 13.665628152084357\n",
      "1 = 0.1096927930636177\n",
      "2 = 0.84170001745224\n",
      "3 = 0.9444000124931335\n",
      "4 = 0.7390000224113464\n",
      "5 = 0.7834743857383728\n",
      "6 = 0.9444000124931335\n",
      "7 = 8.67274690583945\n",
      "8 = 0.10715409628638631\n",
      "9 = 0.826200008392334\n",
      "10 = 0.8555999994277954\n",
      "11 = 0.7968000173568726\n",
      "12 = 0.8080846071243286\n",
      "13 = 0.8555999994277954\n",
      "14 = 5.995072841644287\n",
      "15 = 9.080195426940918\n",
      "16 = 0.21616002917289734\n",
      "17 = 5.9950480461120605\n",
      "18 = 30.65060806274414\n",
      "epoch1 step13205 [D loss: -1.136505] [G loss: 1.184268]\n",
      "epoch1 step13210 [D loss: -0.953009] [G loss: 0.973761]\n",
      "epoch1 step13215 [D loss: -0.941548] [G loss: 1.519325]\n",
      "epoch1 step13220 [D loss: -0.802726] [G loss: 1.311544]\n",
      "epoch1 step13225 [D loss: -0.170595] [G loss: 1.709844]\n",
      "epoch1 step13230 [D loss: -0.342901] [G loss: 1.058766]\n",
      "epoch1 step13235 [D loss: -0.932932] [G loss: 1.650005]\n",
      "epoch1 step13240 [D loss: -0.162962] [G loss: 1.610533]\n",
      "epoch1 step13245 [D loss: -1.024891] [G loss: 0.917896]\n",
      "epoch1 step13250 [D loss: -0.994917] [G loss: 1.068716]\n",
      "epoch1 step13255 [D loss: -0.301958] [G loss: 0.746659]\n",
      "epoch1 step13260 [D loss: -0.562046] [G loss: 1.426109]\n",
      "epoch1 step13265 [D loss: -0.514827] [G loss: 0.970292]\n",
      "epoch1 step13270 [D loss: 0.240593] [G loss: 1.082563]\n",
      "epoch1 step13275 [D loss: 0.438965] [G loss: 1.276474]\n",
      "epoch1 step13280 [D loss: -0.495994] [G loss: 1.354800]\n",
      "epoch1 step13285 [D loss: 0.112022] [G loss: 1.648762]\n",
      "epoch1 step13290 [D loss: -0.164356] [G loss: 1.205418]\n",
      "epoch1 step13295 [D loss: -0.783368] [G loss: 1.600303]\n",
      "epoch1 step13300 [D loss: -0.303193] [G loss: 1.278818]\n",
      "epoch1 step13305 [D loss: -0.250692] [G loss: 1.540768]\n",
      "epoch1 step13310 [D loss: 0.360791] [G loss: 1.319478]\n",
      "epoch1 step13315 [D loss: -0.336848] [G loss: 1.772484]\n",
      "epoch1 step13320 [D loss: -1.191252] [G loss: 1.458394]\n",
      "epoch1 step13325 [D loss: -1.059246] [G loss: 1.642631]\n",
      "epoch1 step13330 [D loss: 0.316484] [G loss: 2.971936]\n",
      "epoch1 step13335 [D loss: -0.053281] [G loss: 2.248603]\n",
      "epoch1 step13340 [D loss: -0.651500] [G loss: 2.261835]\n",
      "epoch1 step13345 [D loss: -1.562830] [G loss: 2.569137]\n",
      "epoch1 step13350 [D loss: -0.409757] [G loss: 3.204825]\n",
      "epoch1 step13355 [D loss: -0.739181] [G loss: 3.553936]\n",
      "epoch1 step13360 [D loss: -1.003276] [G loss: 3.057817]\n",
      "epoch1 step13365 [D loss: -0.290460] [G loss: 2.799325]\n",
      "epoch1 step13370 [D loss: -1.058262] [G loss: 2.621024]\n",
      "epoch1 step13375 [D loss: -0.441835] [G loss: 3.411755]\n",
      "epoch1 step13380 [D loss: -1.052723] [G loss: 3.189912]\n",
      "epoch1 step13385 [D loss: -0.772652] [G loss: 3.040677]\n",
      "epoch1 step13390 [D loss: -1.890888] [G loss: 2.572769]\n",
      "epoch1 step13395 [D loss: -1.120953] [G loss: 3.216492]\n",
      "epoch1 step13400 [D loss: -0.844281] [G loss: 2.668807]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.232728\n",
      "FID: 24.509945\n",
      "0 = 13.843185830593168\n",
      "1 = 0.11586987108980137\n",
      "2 = 0.8343999981880188\n",
      "3 = 0.9453999996185303\n",
      "4 = 0.7233999967575073\n",
      "5 = 0.7736497521400452\n",
      "6 = 0.9453999996185303\n",
      "7 = 8.39801253249645\n",
      "8 = 0.09321121526044808\n",
      "9 = 0.8108000159263611\n",
      "10 = 0.8482000231742859\n",
      "11 = 0.7734000086784363\n",
      "12 = 0.7891700863838196\n",
      "13 = 0.8482000231742859\n",
      "14 = 6.232752799987793\n",
      "15 = 9.212735176086426\n",
      "16 = 0.1891523152589798\n",
      "17 = 6.232728004455566\n",
      "18 = 24.509944915771484\n",
      "epoch1 step13405 [D loss: -0.251197] [G loss: 3.666561]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 step13410 [D loss: -1.356518] [G loss: 3.305222]\n",
      "epoch1 step13415 [D loss: -0.688984] [G loss: 3.031167]\n",
      "epoch1 step13420 [D loss: -1.011686] [G loss: 3.535079]\n",
      "epoch1 step13425 [D loss: -0.444269] [G loss: 3.089267]\n",
      "epoch1 step13430 [D loss: -1.710914] [G loss: 3.066867]\n",
      "epoch1 step13435 [D loss: -1.623542] [G loss: 3.432263]\n",
      "epoch1 step13440 [D loss: -0.246204] [G loss: 2.926486]\n",
      "epoch1 step13445 [D loss: -0.718355] [G loss: 3.386167]\n",
      "epoch1 step13450 [D loss: -1.374320] [G loss: 3.624593]\n",
      "epoch1 step13455 [D loss: -0.482131] [G loss: 3.121471]\n",
      "epoch1 step13460 [D loss: -1.178286] [G loss: 3.751564]\n",
      "epoch1 step13465 [D loss: -1.249000] [G loss: 3.499553]\n",
      "epoch1 step13470 [D loss: -0.284124] [G loss: 3.583341]\n",
      "epoch1 step13475 [D loss: -0.101358] [G loss: 3.893160]\n",
      "epoch1 step13480 [D loss: -0.580188] [G loss: 3.988066]\n",
      "epoch1 step13485 [D loss: -0.579488] [G loss: 3.851873]\n",
      "epoch1 step13490 [D loss: 0.164572] [G loss: 3.104585]\n",
      "epoch1 step13495 [D loss: -0.919672] [G loss: 3.520856]\n",
      "epoch1 step13500 [D loss: -1.116352] [G loss: 4.276299]\n",
      "epoch1 step13505 [D loss: -0.486111] [G loss: 3.125495]\n",
      "epoch1 step13510 [D loss: -0.620054] [G loss: 4.162476]\n",
      "epoch1 step13515 [D loss: -0.241974] [G loss: 4.409439]\n",
      "epoch1 step13520 [D loss: -0.604216] [G loss: 4.367573]\n",
      "epoch1 step13525 [D loss: -0.328302] [G loss: 4.107284]\n",
      "epoch1 step13530 [D loss: -0.145905] [G loss: 4.521802]\n",
      "epoch1 step13535 [D loss: -0.731203] [G loss: 4.164137]\n",
      "epoch1 step13540 [D loss: -0.157054] [G loss: 4.176020]\n",
      "epoch1 step13545 [D loss: -0.554982] [G loss: 4.310055]\n",
      "epoch1 step13550 [D loss: -0.940020] [G loss: 3.674059]\n",
      "epoch1 step13555 [D loss: -0.362893] [G loss: 4.507783]\n",
      "epoch1 step13560 [D loss: -1.714541] [G loss: 4.498616]\n",
      "epoch1 step13565 [D loss: -0.923554] [G loss: 4.253327]\n",
      "epoch1 step13570 [D loss: -1.321050] [G loss: 4.281987]\n",
      "epoch1 step13575 [D loss: -0.299669] [G loss: 4.125814]\n",
      "epoch1 step13580 [D loss: -1.205258] [G loss: 4.292344]\n",
      "epoch1 step13585 [D loss: -0.697213] [G loss: 4.468142]\n",
      "epoch1 step13590 [D loss: -0.055639] [G loss: 3.813297]\n",
      "epoch1 step13595 [D loss: -0.416678] [G loss: 3.627970]\n",
      "epoch1 step13600 [D loss: -0.550126] [G loss: 3.797806]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.175990\n",
      "FID: 26.096003\n",
      "0 = 13.463549016094234\n",
      "1 = 0.08622209069754323\n",
      "2 = 0.8313999772071838\n",
      "3 = 0.9472000002861023\n",
      "4 = 0.7156000137329102\n",
      "5 = 0.7690808773040771\n",
      "6 = 0.9472000002861023\n",
      "7 = 8.41844921965599\n",
      "8 = 0.09708082422334889\n",
      "9 = 0.8131999969482422\n",
      "10 = 0.8497999906539917\n",
      "11 = 0.7766000032424927\n",
      "12 = 0.7918375134468079\n",
      "13 = 0.8497999906539917\n",
      "14 = 6.1760125160217285\n",
      "15 = 9.24026107788086\n",
      "16 = 0.18466801941394806\n",
      "17 = 6.175990104675293\n",
      "18 = 26.09600257873535\n",
      "epoch1 step13605 [D loss: -0.331151] [G loss: 3.447553]\n",
      "epoch1 step13610 [D loss: -1.333363] [G loss: 4.356575]\n",
      "epoch1 step13615 [D loss: -0.759838] [G loss: 4.028944]\n",
      "epoch1 step13620 [D loss: -1.052495] [G loss: 3.914847]\n",
      "epoch1 step13625 [D loss: -0.957328] [G loss: 3.778527]\n",
      "epoch1 step13630 [D loss: -0.409327] [G loss: 3.758342]\n",
      "epoch1 step13635 [D loss: -1.604317] [G loss: 3.816884]\n",
      "epoch1 step13640 [D loss: -1.209411] [G loss: 4.432114]\n",
      "epoch1 step13645 [D loss: -1.131216] [G loss: 4.207636]\n",
      "epoch1 step13650 [D loss: -0.549400] [G loss: 4.408626]\n",
      "epoch1 step13655 [D loss: -1.021081] [G loss: 4.434107]\n",
      "epoch1 step13660 [D loss: -0.723568] [G loss: 4.199870]\n",
      "epoch1 step13665 [D loss: -1.342798] [G loss: 4.795906]\n",
      "epoch1 step13670 [D loss: -1.569917] [G loss: 5.218355]\n",
      "epoch1 step13675 [D loss: -1.342768] [G loss: 3.930480]\n",
      "epoch1 step13680 [D loss: -0.593175] [G loss: 4.156132]\n",
      "epoch1 step13685 [D loss: 0.320223] [G loss: 4.456209]\n",
      "epoch1 step13690 [D loss: -0.094881] [G loss: 4.208137]\n",
      "epoch1 step13695 [D loss: -0.180732] [G loss: 4.467853]\n",
      "epoch1 step13700 [D loss: 0.373759] [G loss: 3.064234]\n",
      "epoch1 step13705 [D loss: -0.126659] [G loss: 3.893456]\n",
      "epoch1 step13710 [D loss: -0.278706] [G loss: 3.723556]\n",
      "epoch1 step13715 [D loss: -0.931045] [G loss: 3.260264]\n",
      "epoch1 step13720 [D loss: -0.573726] [G loss: 3.874226]\n",
      "epoch1 step13725 [D loss: -0.120692] [G loss: 3.207763]\n",
      "epoch1 step13730 [D loss: -0.366531] [G loss: 3.190885]\n",
      "epoch1 step13735 [D loss: -0.577597] [G loss: 3.101230]\n",
      "epoch1 step13740 [D loss: 0.123962] [G loss: 3.317759]\n",
      "epoch1 step13745 [D loss: 0.722526] [G loss: 3.475412]\n",
      "epoch1 step13750 [D loss: -0.471101] [G loss: 3.153019]\n",
      "epoch1 step13755 [D loss: -0.865087] [G loss: 2.866053]\n",
      "epoch1 step13760 [D loss: -0.451612] [G loss: 3.068508]\n",
      "epoch1 step13765 [D loss: -0.842709] [G loss: 2.984466]\n",
      "epoch1 step13770 [D loss: -0.639514] [G loss: 3.209304]\n",
      "epoch1 step13775 [D loss: -1.353934] [G loss: 3.401722]\n",
      "epoch1 step13780 [D loss: -0.846640] [G loss: 2.695386]\n",
      "epoch1 step13785 [D loss: -1.392527] [G loss: 2.983486]\n",
      "epoch1 step13790 [D loss: -0.763426] [G loss: 3.173295]\n",
      "epoch1 step13795 [D loss: -0.766021] [G loss: 3.066581]\n",
      "epoch1 step13800 [D loss: -1.087027] [G loss: 3.566025]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.848968\n",
      "FID: 33.750542\n",
      "0 = 14.704563973426833\n",
      "1 = 0.16474047856465016\n",
      "2 = 0.8449000120162964\n",
      "3 = 0.9682000279426575\n",
      "4 = 0.7215999960899353\n",
      "5 = 0.7766725420951843\n",
      "6 = 0.9682000279426575\n",
      "7 = 8.829347526192652\n",
      "8 = 0.11727545933971986\n",
      "9 = 0.8352000117301941\n",
      "10 = 0.8641999959945679\n",
      "11 = 0.8062000274658203\n",
      "12 = 0.816824197769165\n",
      "13 = 0.8641999959945679\n",
      "14 = 5.848989963531494\n",
      "15 = 8.818310737609863\n",
      "16 = 0.24505570530891418\n",
      "17 = 5.848968029022217\n",
      "18 = 33.75054168701172\n",
      "epoch1 step13805 [D loss: 0.114931] [G loss: 3.098698]\n",
      "epoch1 step13810 [D loss: -1.297735] [G loss: 3.578318]\n",
      "epoch1 step13815 [D loss: -1.430555] [G loss: 3.520076]\n",
      "epoch1 step13820 [D loss: -0.017825] [G loss: 2.964002]\n",
      "epoch1 step13825 [D loss: -1.148128] [G loss: 3.081501]\n",
      "epoch1 step13830 [D loss: -0.478442] [G loss: 3.639133]\n",
      "epoch1 step13835 [D loss: -0.847449] [G loss: 3.037017]\n",
      "epoch1 step13840 [D loss: -0.883936] [G loss: 2.863293]\n",
      "epoch1 step13845 [D loss: -0.601454] [G loss: 2.966608]\n",
      "epoch1 step13850 [D loss: -0.357459] [G loss: 3.286046]\n",
      "epoch1 step13855 [D loss: -1.819631] [G loss: 3.994512]\n",
      "epoch1 step13860 [D loss: -1.703258] [G loss: 3.706726]\n",
      "epoch1 step13865 [D loss: -1.144965] [G loss: 2.778838]\n",
      "epoch1 step13870 [D loss: -1.910375] [G loss: 3.894113]\n",
      "epoch1 step13875 [D loss: -1.140037] [G loss: 3.565021]\n",
      "epoch1 step13880 [D loss: -2.015054] [G loss: 3.105862]\n",
      "epoch1 step13885 [D loss: -1.088081] [G loss: 3.133831]\n",
      "epoch1 step13890 [D loss: -1.912160] [G loss: 3.263885]\n",
      "epoch1 step13895 [D loss: -1.356239] [G loss: 4.199871]\n",
      "epoch1 step13900 [D loss: -1.239072] [G loss: 4.075913]\n",
      "epoch1 step13905 [D loss: -1.758524] [G loss: 3.380823]\n",
      "epoch1 step13910 [D loss: -0.767992] [G loss: 3.364471]\n",
      "epoch1 step13915 [D loss: -0.824904] [G loss: 4.183773]\n",
      "epoch1 step13920 [D loss: -2.078874] [G loss: 4.011927]\n",
      "epoch1 step13925 [D loss: -1.907386] [G loss: 3.336674]\n",
      "epoch1 step13930 [D loss: -0.564947] [G loss: 3.329261]\n",
      "epoch1 step13935 [D loss: -1.724194] [G loss: 3.676053]\n",
      "epoch1 step13940 [D loss: -1.879982] [G loss: 3.426694]\n",
      "epoch1 step13945 [D loss: -0.746400] [G loss: 3.159857]\n",
      "epoch1 step13950 [D loss: -0.403848] [G loss: 3.429825]\n",
      "epoch1 step13955 [D loss: -0.293656] [G loss: 3.249911]\n",
      "epoch1 step13960 [D loss: -0.599942] [G loss: 3.264288]\n",
      "epoch1 step13965 [D loss: -0.451184] [G loss: 3.555386]\n",
      "epoch1 step13970 [D loss: 0.270118] [G loss: 3.419779]\n",
      "epoch1 step13975 [D loss: -1.059567] [G loss: 2.837840]\n",
      "epoch1 step13980 [D loss: -1.455540] [G loss: 3.859329]\n",
      "epoch1 step13985 [D loss: -0.757050] [G loss: 2.679645]\n",
      "epoch1 step13990 [D loss: 0.051424] [G loss: 3.631993]\n",
      "epoch1 step13995 [D loss: -0.793666] [G loss: 3.357926]\n",
      "epoch1 step14000 [D loss: -0.731824] [G loss: 2.844493]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.225476\n",
      "FID: 25.565109\n",
      "0 = 13.12458829908369\n",
      "1 = 0.0615011507872555\n",
      "2 = 0.8337000012397766\n",
      "3 = 0.9381999969482422\n",
      "4 = 0.729200005531311\n",
      "5 = 0.7760132551193237\n",
      "6 = 0.9381999969482422\n",
      "7 = 8.314906889975065\n",
      "8 = 0.09298264856391197\n",
      "9 = 0.8159000277519226\n",
      "10 = 0.8474000096321106\n",
      "11 = 0.7843999862670898\n",
      "12 = 0.797177791595459\n",
      "13 = 0.8474000096321106\n",
      "14 = 6.225497245788574\n",
      "15 = 9.32828426361084\n",
      "16 = 0.17522037029266357\n",
      "17 = 6.225476264953613\n",
      "18 = 25.565109252929688\n",
      "epoch1 step14005 [D loss: -1.135462] [G loss: 2.946026]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 step14010 [D loss: -0.588385] [G loss: 2.827384]\n",
      "epoch1 step14015 [D loss: 0.014686] [G loss: 1.790900]\n",
      "epoch1 step14020 [D loss: -0.599079] [G loss: 1.971330]\n",
      "epoch1 step14025 [D loss: -1.231818] [G loss: 2.610588]\n",
      "epoch1 step14030 [D loss: -1.159072] [G loss: 2.062947]\n",
      "epoch1 step14035 [D loss: -0.406002] [G loss: 1.599859]\n",
      "epoch1 step14040 [D loss: -0.805615] [G loss: 2.299507]\n",
      "epoch1 step14045 [D loss: -0.796926] [G loss: 2.343394]\n",
      "epoch1 step14050 [D loss: -0.625538] [G loss: 2.056788]\n",
      "epoch1 step14055 [D loss: -0.588834] [G loss: 1.728452]\n",
      "epoch1 step14060 [D loss: -0.956337] [G loss: 1.805417]\n",
      "epoch1 step14065 [D loss: -0.602163] [G loss: 2.013108]\n",
      "epoch1 step14070 [D loss: -0.816216] [G loss: 2.082631]\n",
      "epoch1 step14075 [D loss: -2.063231] [G loss: 2.104490]\n",
      "epoch1 step14080 [D loss: -2.013106] [G loss: 2.171183]\n",
      "epoch1 step14085 [D loss: -1.118190] [G loss: 1.289219]\n",
      "epoch1 step14090 [D loss: -1.171982] [G loss: 1.704309]\n",
      "epoch1 step14095 [D loss: 0.119164] [G loss: 2.129062]\n",
      "epoch1 step14100 [D loss: 0.988474] [G loss: 2.201870]\n",
      "epoch1 step14105 [D loss: 0.070769] [G loss: 1.828882]\n",
      "epoch1 step14110 [D loss: 0.514335] [G loss: 2.902454]\n",
      "epoch1 step14115 [D loss: 0.057809] [G loss: 2.781464]\n",
      "epoch1 step14120 [D loss: 0.298023] [G loss: 2.573230]\n",
      "epoch1 step14125 [D loss: 0.176557] [G loss: 2.839906]\n",
      "epoch1 step14130 [D loss: -0.090344] [G loss: 2.009501]\n",
      "epoch1 step14135 [D loss: -0.669984] [G loss: 2.016424]\n",
      "epoch1 step14140 [D loss: -0.777263] [G loss: 2.496093]\n",
      "epoch1 step14145 [D loss: -0.572360] [G loss: 1.928159]\n",
      "epoch1 step14150 [D loss: -0.618161] [G loss: 2.048159]\n",
      "epoch1 step14155 [D loss: -0.848801] [G loss: 2.102870]\n",
      "epoch1 step14160 [D loss: -0.538880] [G loss: 1.601453]\n",
      "epoch1 step14165 [D loss: -0.631275] [G loss: 2.130531]\n",
      "epoch1 step14170 [D loss: -0.605405] [G loss: 1.674361]\n",
      "epoch1 step14175 [D loss: -1.032252] [G loss: 1.959177]\n",
      "epoch1 step14180 [D loss: -1.748907] [G loss: 2.160341]\n",
      "epoch1 step14185 [D loss: -0.928334] [G loss: 1.677680]\n",
      "epoch1 step14190 [D loss: -0.458838] [G loss: 1.596273]\n",
      "epoch1 step14195 [D loss: -0.112893] [G loss: 1.835571]\n",
      "epoch1 step14200 [D loss: -0.453400] [G loss: 1.370994]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.153046\n",
      "FID: 30.562016\n",
      "0 = 13.24339465613363\n",
      "1 = 0.09508266566646993\n",
      "2 = 0.8622999787330627\n",
      "3 = 0.9305999875068665\n",
      "4 = 0.7940000295639038\n",
      "5 = 0.8187577128410339\n",
      "6 = 0.9305999875068665\n",
      "7 = 8.57026924192904\n",
      "8 = 0.10793666600279005\n",
      "9 = 0.8248999714851379\n",
      "10 = 0.8501999974250793\n",
      "11 = 0.7996000051498413\n",
      "12 = 0.8092518448829651\n",
      "13 = 0.8501999974250793\n",
      "14 = 6.153066635131836\n",
      "15 = 9.412303924560547\n",
      "16 = 0.16369645297527313\n",
      "17 = 6.153046131134033\n",
      "18 = 30.562015533447266\n",
      "epoch1 step14205 [D loss: -0.633126] [G loss: 1.484996]\n",
      "epoch1 step14210 [D loss: -1.065233] [G loss: 1.670430]\n",
      "epoch1 step14215 [D loss: -0.262591] [G loss: 1.704235]\n",
      "epoch1 step14220 [D loss: -0.789980] [G loss: 1.555280]\n",
      "epoch1 step14225 [D loss: -0.889383] [G loss: 2.028849]\n",
      "epoch1 step14230 [D loss: -0.119705] [G loss: 1.507455]\n",
      "epoch1 step14235 [D loss: -0.006701] [G loss: 1.909921]\n",
      "epoch1 step14240 [D loss: -0.866802] [G loss: 1.803702]\n",
      "epoch1 step14245 [D loss: -0.341313] [G loss: 1.533489]\n",
      "epoch1 step14250 [D loss: -0.992219] [G loss: 2.332084]\n",
      "epoch1 step14255 [D loss: 0.296726] [G loss: 2.790492]\n",
      "epoch1 step14260 [D loss: -0.481845] [G loss: 2.131442]\n",
      "epoch1 step14265 [D loss: -0.439953] [G loss: 2.530679]\n",
      "epoch1 step14270 [D loss: -0.744257] [G loss: 2.629900]\n",
      "epoch1 step14275 [D loss: -0.509467] [G loss: 2.665334]\n",
      "epoch1 step14280 [D loss: -1.088101] [G loss: 2.480781]\n",
      "epoch1 step14285 [D loss: -0.617812] [G loss: 1.755009]\n",
      "epoch1 step14290 [D loss: -0.407564] [G loss: 2.330028]\n",
      "epoch1 step14295 [D loss: -0.071889] [G loss: 3.253207]\n",
      "epoch1 step14300 [D loss: -0.892129] [G loss: 2.621356]\n",
      "epoch1 step14305 [D loss: -0.489560] [G loss: 2.469261]\n",
      "epoch1 step14310 [D loss: -1.518660] [G loss: 2.103382]\n",
      "epoch1 step14315 [D loss: -0.655079] [G loss: 2.740046]\n",
      "epoch1 step14320 [D loss: -0.976136] [G loss: 3.078651]\n",
      "epoch1 step14325 [D loss: -0.322235] [G loss: 2.690646]\n",
      "epoch1 step14330 [D loss: -0.015393] [G loss: 2.955608]\n",
      "epoch1 step14335 [D loss: -0.380849] [G loss: 2.941052]\n",
      "epoch1 step14340 [D loss: -0.716556] [G loss: 2.965673]\n",
      "epoch1 step14345 [D loss: -1.800106] [G loss: 2.709877]\n",
      "epoch1 step14350 [D loss: -1.574044] [G loss: 3.313696]\n",
      "epoch1 step14355 [D loss: -1.806183] [G loss: 3.504301]\n",
      "epoch1 step14360 [D loss: -1.994365] [G loss: 3.591217]\n",
      "epoch1 step14365 [D loss: -1.829068] [G loss: 3.887678]\n",
      "epoch1 step14370 [D loss: -1.103794] [G loss: 3.623802]\n",
      "epoch1 step14375 [D loss: -1.191615] [G loss: 3.915406]\n",
      "epoch1 step14380 [D loss: -0.088718] [G loss: 3.557680]\n",
      "epoch1 step14385 [D loss: -1.196904] [G loss: 4.410430]\n",
      "epoch1 step14390 [D loss: -0.079864] [G loss: 4.051977]\n",
      "epoch1 step14395 [D loss: 0.243431] [G loss: 3.340159]\n",
      "epoch1 step14400 [D loss: 0.222343] [G loss: 3.202106]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.263069\n",
      "FID: 25.258783\n",
      "0 = 13.3578635881424\n",
      "1 = 0.08469040869190475\n",
      "2 = 0.8414999842643738\n",
      "3 = 0.9404000043869019\n",
      "4 = 0.7426000237464905\n",
      "5 = 0.7851060032844543\n",
      "6 = 0.9404000043869019\n",
      "7 = 8.364349343287953\n",
      "8 = 0.0957105984008053\n",
      "9 = 0.8181999921798706\n",
      "10 = 0.8515999913215637\n",
      "11 = 0.7847999930381775\n",
      "12 = 0.7982752323150635\n",
      "13 = 0.8515999913215637\n",
      "14 = 6.263094425201416\n",
      "15 = 9.389854431152344\n",
      "16 = 0.1619044840335846\n",
      "17 = 6.263068675994873\n",
      "18 = 25.2587833404541\n",
      "epoch1 step14405 [D loss: -0.304918] [G loss: 3.370332]\n",
      "epoch1 step14410 [D loss: -0.747442] [G loss: 3.349009]\n",
      "epoch1 step14415 [D loss: -0.202777] [G loss: 3.319198]\n",
      "epoch1 step14420 [D loss: -1.292882] [G loss: 3.155377]\n",
      "epoch1 step14425 [D loss: -0.265443] [G loss: 3.083529]\n",
      "epoch1 step14430 [D loss: -0.458422] [G loss: 2.963212]\n",
      "epoch1 step14435 [D loss: 0.194155] [G loss: 3.215910]\n",
      "epoch1 step14440 [D loss: -1.470164] [G loss: 3.634526]\n",
      "epoch1 step14445 [D loss: -0.482435] [G loss: 3.236032]\n",
      "epoch1 step14450 [D loss: -0.231627] [G loss: 3.721945]\n",
      "epoch1 step14455 [D loss: -0.568308] [G loss: 3.382793]\n",
      "epoch1 step14460 [D loss: -0.641681] [G loss: 3.926470]\n",
      "epoch1 step14465 [D loss: -0.386733] [G loss: 4.218222]\n",
      "epoch1 step14470 [D loss: -0.673166] [G loss: 4.260522]\n",
      "epoch1 step14475 [D loss: -0.642537] [G loss: 4.820316]\n",
      "epoch1 step14480 [D loss: 0.021835] [G loss: 3.891095]\n",
      "epoch1 step14485 [D loss: 0.238841] [G loss: 3.946589]\n",
      "epoch1 step14490 [D loss: -0.651772] [G loss: 4.742503]\n",
      "epoch1 step14495 [D loss: -1.044229] [G loss: 3.909538]\n",
      "epoch1 step14500 [D loss: -0.700676] [G loss: 4.036365]\n",
      "epoch1 step14505 [D loss: -1.274109] [G loss: 4.883531]\n",
      "epoch1 step14510 [D loss: -1.449601] [G loss: 4.086315]\n",
      "epoch1 step14515 [D loss: -0.323956] [G loss: 4.166199]\n",
      "epoch1 step14520 [D loss: -0.432755] [G loss: 3.990584]\n",
      "epoch1 step14525 [D loss: -1.239137] [G loss: 4.076353]\n",
      "epoch1 step14530 [D loss: -1.439428] [G loss: 3.931823]\n",
      "epoch1 step14535 [D loss: 0.083637] [G loss: 3.181278]\n",
      "epoch1 step14540 [D loss: -0.055983] [G loss: 4.014493]\n",
      "epoch1 step14545 [D loss: 0.522434] [G loss: 3.675116]\n",
      "epoch1 step14550 [D loss: 0.014688] [G loss: 3.338798]\n",
      "epoch1 step14555 [D loss: -0.141598] [G loss: 3.188973]\n",
      "epoch1 step14560 [D loss: 0.400733] [G loss: 3.775519]\n",
      "epoch1 step14565 [D loss: 0.333227] [G loss: 3.652257]\n",
      "epoch1 step14570 [D loss: -0.260122] [G loss: 3.838038]\n",
      "epoch1 step14575 [D loss: 0.847952] [G loss: 3.258458]\n",
      "epoch1 step14580 [D loss: -1.397535] [G loss: 3.314914]\n",
      "epoch1 step14585 [D loss: -0.243469] [G loss: 3.306849]\n",
      "epoch1 step14590 [D loss: -0.166773] [G loss: 3.780129]\n",
      "epoch1 step14595 [D loss: -0.555542] [G loss: 3.915983]\n",
      "epoch1 step14600 [D loss: 0.494923] [G loss: 3.899118]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.150810\n",
      "FID: 27.410145\n",
      "0 = 13.134067154216732\n",
      "1 = 0.0656524963903704\n",
      "2 = 0.8483999967575073\n",
      "3 = 0.9369999766349792\n",
      "4 = 0.7598000168800354\n",
      "5 = 0.7959564924240112\n",
      "6 = 0.9369999766349792\n",
      "7 = 8.433508679437605\n",
      "8 = 0.1023196825455311\n",
      "9 = 0.8246999979019165\n",
      "10 = 0.8579999804496765\n",
      "11 = 0.7914000153541565\n",
      "12 = 0.8044252991676331\n",
      "13 = 0.8579999804496765\n",
      "14 = 6.150834083557129\n",
      "15 = 9.369800567626953\n",
      "16 = 0.16938889026641846\n",
      "17 = 6.150810241699219\n",
      "18 = 27.410144805908203\n",
      "epoch1 step14605 [D loss: -1.221927] [G loss: 4.113994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 step14610 [D loss: -1.152440] [G loss: 3.654790]\n",
      "epoch1 step14615 [D loss: -0.902035] [G loss: 4.331903]\n",
      "epoch1 step14620 [D loss: -0.706735] [G loss: 3.684894]\n",
      "epoch1 step14625 [D loss: -0.342304] [G loss: 3.734104]\n",
      "epoch1 step14630 [D loss: -0.449832] [G loss: 3.997860]\n",
      "epoch1 step14635 [D loss: -1.020497] [G loss: 3.703362]\n",
      "epoch1 step14640 [D loss: -0.496451] [G loss: 3.495632]\n",
      "epoch1 step14645 [D loss: -0.065104] [G loss: 2.746774]\n",
      "epoch1 step14650 [D loss: -0.003222] [G loss: 2.563338]\n",
      "epoch1 step14655 [D loss: -0.232087] [G loss: 2.663708]\n",
      "epoch1 step14660 [D loss: -0.860939] [G loss: 2.868279]\n",
      "epoch1 step14665 [D loss: 0.212487] [G loss: 2.885153]\n",
      "epoch1 step14670 [D loss: -0.503824] [G loss: 2.573019]\n",
      "epoch1 step14675 [D loss: -0.649692] [G loss: 2.919658]\n",
      "epoch1 step14680 [D loss: -0.427695] [G loss: 2.493642]\n",
      "epoch1 step14685 [D loss: -0.591363] [G loss: 3.079958]\n",
      "epoch1 step14690 [D loss: -0.360742] [G loss: 2.414376]\n",
      "epoch1 step14695 [D loss: -0.214285] [G loss: 2.092516]\n",
      "epoch1 step14700 [D loss: -0.186944] [G loss: 2.412214]\n",
      "epoch1 step14705 [D loss: -0.273674] [G loss: 1.636398]\n",
      "epoch1 step14710 [D loss: -0.338790] [G loss: 1.779448]\n",
      "epoch1 step14715 [D loss: 0.083741] [G loss: 2.244730]\n",
      "epoch1 step14720 [D loss: -0.840137] [G loss: 2.502559]\n",
      "epoch1 step14725 [D loss: -0.559370] [G loss: 1.900623]\n",
      "epoch1 step14730 [D loss: 0.115391] [G loss: 2.135483]\n",
      "epoch1 step14735 [D loss: -0.258769] [G loss: 2.106415]\n",
      "epoch1 step14740 [D loss: -0.870098] [G loss: 2.187844]\n",
      "epoch1 step14745 [D loss: -1.547976] [G loss: 2.615122]\n",
      "epoch1 step14750 [D loss: -0.432770] [G loss: 2.140885]\n",
      "epoch1 step14755 [D loss: -0.012189] [G loss: 2.851360]\n",
      "epoch1 step14760 [D loss: 0.062352] [G loss: 2.462800]\n",
      "epoch1 step14765 [D loss: -0.405997] [G loss: 2.781629]\n",
      "epoch1 step14770 [D loss: -0.605855] [G loss: 3.008158]\n",
      "epoch1 step14775 [D loss: -0.096186] [G loss: 2.645616]\n",
      "epoch1 step14780 [D loss: -0.785125] [G loss: 2.534029]\n",
      "epoch1 step14785 [D loss: -0.557753] [G loss: 2.854930]\n",
      "epoch1 step14790 [D loss: 0.662928] [G loss: 2.903160]\n",
      "epoch1 step14795 [D loss: -0.185477] [G loss: 2.257186]\n",
      "epoch1 step14800 [D loss: 0.014958] [G loss: 2.649160]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.212060\n",
      "FID: 25.413431\n",
      "0 = 13.106877127170602\n",
      "1 = 0.05984683036346388\n",
      "2 = 0.8389000296592712\n",
      "3 = 0.9345999956130981\n",
      "4 = 0.7432000041007996\n",
      "5 = 0.7844552397727966\n",
      "6 = 0.9345999956130981\n",
      "7 = 8.316773290729529\n",
      "8 = 0.09518792187502693\n",
      "9 = 0.8212000131607056\n",
      "10 = 0.8482000231742859\n",
      "11 = 0.7942000031471252\n",
      "12 = 0.8047438263893127\n",
      "13 = 0.8482000231742859\n",
      "14 = 6.2120842933654785\n",
      "15 = 9.316890716552734\n",
      "16 = 0.17737159132957458\n",
      "17 = 6.212060451507568\n",
      "18 = 25.41343116760254\n",
      "epoch1 step14805 [D loss: -0.059168] [G loss: 2.822027]\n",
      "epoch1 step14810 [D loss: -0.886292] [G loss: 3.115404]\n",
      "epoch1 step14815 [D loss: -0.549852] [G loss: 2.808245]\n",
      "epoch1 step14820 [D loss: -0.585972] [G loss: 2.844932]\n",
      "epoch1 step14825 [D loss: -0.502591] [G loss: 2.880293]\n",
      "epoch1 step14830 [D loss: -0.417663] [G loss: 2.454893]\n",
      "epoch1 step14835 [D loss: -1.664337] [G loss: 3.165385]\n",
      "epoch1 step14840 [D loss: -1.783897] [G loss: 2.859030]\n",
      "epoch1 step14845 [D loss: -0.663593] [G loss: 2.603083]\n",
      "epoch1 step14850 [D loss: -0.745234] [G loss: 2.151180]\n",
      "epoch1 step14855 [D loss: -1.008402] [G loss: 3.007961]\n",
      "epoch1 step14860 [D loss: -0.402289] [G loss: 2.425243]\n",
      "epoch1 step14865 [D loss: -1.396369] [G loss: 2.830801]\n",
      "epoch1 step14870 [D loss: 0.301677] [G loss: 2.077119]\n",
      "epoch1 step14875 [D loss: -1.135409] [G loss: 2.350652]\n",
      "epoch1 step14880 [D loss: -0.889936] [G loss: 2.228025]\n",
      "epoch1 step14885 [D loss: -1.027817] [G loss: 2.736921]\n",
      "epoch1 step14890 [D loss: -0.296682] [G loss: 2.085632]\n",
      "epoch1 step14895 [D loss: -1.420671] [G loss: 2.961557]\n",
      "epoch1 step14900 [D loss: -0.932157] [G loss: 2.598025]\n",
      "epoch1 step14905 [D loss: -0.889298] [G loss: 2.379575]\n",
      "epoch1 step14910 [D loss: -1.810805] [G loss: 2.861575]\n",
      "epoch1 step14915 [D loss: -0.568357] [G loss: 3.176050]\n",
      "epoch1 step14920 [D loss: -1.111749] [G loss: 1.855557]\n",
      "epoch1 step14925 [D loss: -0.419491] [G loss: 2.316677]\n",
      "epoch1 step14930 [D loss: -0.634381] [G loss: 2.622818]\n",
      "epoch1 step14935 [D loss: -2.032812] [G loss: 2.575151]\n",
      "epoch1 step14940 [D loss: -0.882697] [G loss: 2.653658]\n",
      "epoch1 step14945 [D loss: -0.448718] [G loss: 2.153178]\n",
      "epoch1 step14950 [D loss: -1.414941] [G loss: 3.299513]\n",
      "epoch1 step14955 [D loss: -0.266651] [G loss: 2.975988]\n",
      "epoch1 step14960 [D loss: 0.458549] [G loss: 3.290860]\n",
      "epoch1 step14965 [D loss: 0.186852] [G loss: 2.480400]\n",
      "epoch1 step14970 [D loss: 0.057211] [G loss: 3.210880]\n",
      "epoch1 step14975 [D loss: -0.934537] [G loss: 3.271717]\n",
      "epoch1 step14980 [D loss: -0.603682] [G loss: 3.211016]\n",
      "epoch1 step14985 [D loss: -0.482383] [G loss: 3.999620]\n",
      "epoch1 step14990 [D loss: 0.094082] [G loss: 3.317816]\n",
      "epoch1 step14995 [D loss: 0.137210] [G loss: 3.436554]\n",
      "epoch1 step15000 [D loss: -0.514358] [G loss: 3.188922]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.186383\n",
      "FID: 27.771946\n",
      "0 = 13.496880829048184\n",
      "1 = 0.09155631503414625\n",
      "2 = 0.8428999781608582\n",
      "3 = 0.9362000226974487\n",
      "4 = 0.7495999932289124\n",
      "5 = 0.7889769077301025\n",
      "6 = 0.9362000226974487\n",
      "7 = 8.468016061806699\n",
      "8 = 0.10088060789344103\n",
      "9 = 0.817799985408783\n",
      "10 = 0.8492000102996826\n",
      "11 = 0.7864000201225281\n",
      "12 = 0.7990214824676514\n",
      "13 = 0.8492000102996826\n",
      "14 = 6.186403751373291\n",
      "15 = 9.317023277282715\n",
      "16 = 0.17732055485248566\n",
      "17 = 6.186383247375488\n",
      "18 = 27.77194595336914\n",
      "epoch1 step15005 [D loss: -0.027313] [G loss: 3.111745]\n",
      "epoch1 step15010 [D loss: -0.297930] [G loss: 2.627304]\n",
      "epoch1 step15015 [D loss: -0.929137] [G loss: 3.040147]\n",
      "epoch1 step15020 [D loss: -0.705038] [G loss: 3.121567]\n",
      "epoch1 step15025 [D loss: -0.126882] [G loss: 2.762210]\n",
      "epoch1 step15030 [D loss: -0.207562] [G loss: 3.605043]\n",
      "epoch1 step15035 [D loss: -0.525785] [G loss: 3.460937]\n",
      "epoch1 step15040 [D loss: -0.137296] [G loss: 3.268742]\n",
      "epoch1 step15045 [D loss: -1.233805] [G loss: 3.095314]\n",
      "epoch1 step15050 [D loss: -1.818496] [G loss: 3.907322]\n",
      "epoch1 step15055 [D loss: -0.528816] [G loss: 3.701424]\n",
      "epoch1 step15060 [D loss: -0.104046] [G loss: 3.417410]\n",
      "epoch1 step15065 [D loss: 0.086687] [G loss: 3.759499]\n",
      "epoch1 step15070 [D loss: -1.096597] [G loss: 3.316058]\n",
      "epoch1 step15075 [D loss: -0.338446] [G loss: 3.255277]\n",
      "epoch1 step15080 [D loss: 0.085245] [G loss: 3.213089]\n",
      "epoch1 step15085 [D loss: -0.329027] [G loss: 3.632749]\n",
      "epoch1 step15090 [D loss: -0.989302] [G loss: 3.624983]\n",
      "epoch1 step15095 [D loss: -0.471734] [G loss: 3.378923]\n",
      "epoch1 step15100 [D loss: -0.731135] [G loss: 3.164134]\n",
      "epoch1 step15105 [D loss: -0.467597] [G loss: 3.317684]\n",
      "epoch1 step15110 [D loss: -0.759094] [G loss: 2.967525]\n",
      "epoch1 step15115 [D loss: -1.312449] [G loss: 3.235813]\n",
      "epoch1 step15120 [D loss: -1.189989] [G loss: 3.253730]\n",
      "epoch1 step15125 [D loss: -0.796508] [G loss: 3.149512]\n",
      "epoch1 step15130 [D loss: -0.140257] [G loss: 2.083101]\n",
      "epoch1 step15135 [D loss: -0.252325] [G loss: 3.215408]\n",
      "epoch1 step15140 [D loss: -0.355258] [G loss: 2.615793]\n",
      "epoch1 step15145 [D loss: 0.079176] [G loss: 2.340320]\n",
      "epoch1 step15150 [D loss: -0.642540] [G loss: 2.423929]\n",
      "epoch1 step15155 [D loss: -1.697467] [G loss: 2.637750]\n",
      "epoch1 step15160 [D loss: -0.566776] [G loss: 2.426904]\n",
      "epoch1 step15165 [D loss: -1.091464] [G loss: 2.688875]\n",
      "epoch1 step15170 [D loss: -0.939608] [G loss: 2.943852]\n",
      "epoch1 step15175 [D loss: 0.246174] [G loss: 2.539384]\n",
      "epoch1 step15180 [D loss: -1.044181] [G loss: 2.924486]\n",
      "epoch1 step15185 [D loss: -0.931876] [G loss: 2.623027]\n",
      "epoch1 step15190 [D loss: -0.865215] [G loss: 2.812615]\n",
      "epoch1 step15195 [D loss: -1.300251] [G loss: 2.914535]\n",
      "epoch1 step15200 [D loss: -0.692870] [G loss: 2.528418]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.077358\n",
      "FID: 30.519186\n",
      "0 = 13.34441405773162\n",
      "1 = 0.09213713223657324\n",
      "2 = 0.8410000205039978\n",
      "3 = 0.9215999841690063\n",
      "4 = 0.7603999972343445\n",
      "5 = 0.7936617136001587\n",
      "6 = 0.9215999841690063\n",
      "7 = 8.551565333127925\n",
      "8 = 0.11184731934856099\n",
      "9 = 0.8248000144958496\n",
      "10 = 0.8482000231742859\n",
      "11 = 0.8014000058174133\n",
      "12 = 0.8102789521217346\n",
      "13 = 0.8482000231742859\n",
      "14 = 6.0773797035217285\n",
      "15 = 9.124283790588379\n",
      "16 = 0.20441369712352753\n",
      "17 = 6.077357769012451\n",
      "18 = 30.51918601989746\n",
      "epoch1 step15205 [D loss: -0.950426] [G loss: 2.673524]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 step15210 [D loss: -0.898588] [G loss: 2.944842]\n",
      "epoch1 step15215 [D loss: -0.035750] [G loss: 2.746422]\n",
      "epoch1 step15220 [D loss: -0.093438] [G loss: 1.959020]\n",
      "epoch1 step15225 [D loss: 0.086905] [G loss: 2.661640]\n",
      "epoch1 step15230 [D loss: -0.414123] [G loss: 3.219577]\n",
      "epoch1 step15235 [D loss: -1.014735] [G loss: 2.967185]\n",
      "epoch1 step15240 [D loss: -0.430741] [G loss: 2.939793]\n",
      "epoch1 step15245 [D loss: -1.448364] [G loss: 3.073198]\n",
      "epoch1 step15250 [D loss: -1.093034] [G loss: 3.180818]\n",
      "epoch1 step15255 [D loss: -0.806789] [G loss: 2.996412]\n",
      "epoch1 step15260 [D loss: -0.533062] [G loss: 3.306336]\n",
      "epoch1 step15265 [D loss: -1.372683] [G loss: 3.396975]\n",
      "epoch1 step15270 [D loss: -0.399198] [G loss: 3.295639]\n",
      "epoch1 step15275 [D loss: -0.116251] [G loss: 3.526030]\n",
      "epoch1 step15280 [D loss: 0.603014] [G loss: 3.540409]\n",
      "epoch1 step15285 [D loss: -0.195729] [G loss: 3.505556]\n",
      "epoch1 step15290 [D loss: -0.152782] [G loss: 3.615073]\n",
      "epoch1 step15295 [D loss: -0.138327] [G loss: 4.815433]\n",
      "epoch1 step15300 [D loss: -1.098189] [G loss: 4.331131]\n",
      "epoch1 step15305 [D loss: -1.015008] [G loss: 4.215015]\n",
      "epoch1 step15310 [D loss: -0.952180] [G loss: 4.286150]\n",
      "epoch1 step15315 [D loss: -0.562306] [G loss: 4.364236]\n",
      "epoch1 step15320 [D loss: -0.805307] [G loss: 4.010311]\n",
      "epoch1 step15325 [D loss: -0.570782] [G loss: 3.663258]\n",
      "epoch1 step15330 [D loss: -1.619908] [G loss: 4.115960]\n",
      "epoch1 step15335 [D loss: 0.503780] [G loss: 3.798913]\n",
      "epoch1 step15340 [D loss: -0.793456] [G loss: 3.526116]\n",
      "epoch1 step15345 [D loss: -0.884142] [G loss: 3.676088]\n",
      "epoch1 step15350 [D loss: 0.217728] [G loss: 3.815923]\n",
      "epoch1 step15355 [D loss: 0.103603] [G loss: 3.284856]\n",
      "epoch1 step15360 [D loss: -0.560709] [G loss: 3.747617]\n",
      "epoch1 step15365 [D loss: -1.525706] [G loss: 3.593440]\n",
      "epoch1 step15370 [D loss: -0.890861] [G loss: 3.577627]\n",
      "epoch1 step15375 [D loss: -0.473356] [G loss: 3.943522]\n",
      "epoch1 step15380 [D loss: -0.199942] [G loss: 3.903028]\n",
      "epoch1 step15385 [D loss: -1.710303] [G loss: 4.217872]\n",
      "epoch1 step15390 [D loss: -0.949753] [G loss: 3.374413]\n",
      "epoch1 step15395 [D loss: -1.327325] [G loss: 3.803545]\n",
      "epoch1 step15400 [D loss: -0.214446] [G loss: 3.823068]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.210519\n",
      "FID: 27.161369\n",
      "0 = 13.003405316781986\n",
      "1 = 0.07087566756214979\n",
      "2 = 0.8478999733924866\n",
      "3 = 0.9215999841690063\n",
      "4 = 0.7742000222206116\n",
      "5 = 0.803207278251648\n",
      "6 = 0.9215999841690063\n",
      "7 = 8.401949249386776\n",
      "8 = 0.09844953675323348\n",
      "9 = 0.8181999921798706\n",
      "10 = 0.8414000272750854\n",
      "11 = 0.7950000166893005\n",
      "12 = 0.8040902018547058\n",
      "13 = 0.8414000272750854\n",
      "14 = 6.210538864135742\n",
      "15 = 9.305635452270508\n",
      "16 = 0.1802743673324585\n",
      "17 = 6.210518836975098\n",
      "18 = 27.16136932373047\n",
      "epoch1 step15405 [D loss: -0.255139] [G loss: 3.349232]\n",
      "epoch1 step15410 [D loss: 0.061839] [G loss: 3.945804]\n",
      "epoch1 step15415 [D loss: -0.072723] [G loss: 3.580149]\n",
      "epoch1 step15420 [D loss: -1.466605] [G loss: 4.088821]\n",
      "epoch1 step15425 [D loss: -0.588087] [G loss: 3.783362]\n",
      "epoch1 step15430 [D loss: -0.073139] [G loss: 3.517999]\n",
      "epoch1 step15435 [D loss: -0.238413] [G loss: 3.728508]\n",
      "epoch1 step15440 [D loss: -0.034789] [G loss: 3.995977]\n",
      "epoch1 step15445 [D loss: -0.710720] [G loss: 3.673620]\n",
      "epoch1 step15450 [D loss: -0.366220] [G loss: 4.376066]\n",
      "epoch1 step15455 [D loss: -0.557753] [G loss: 3.784106]\n",
      "epoch1 step15460 [D loss: -1.205198] [G loss: 3.689846]\n",
      "epoch1 step15465 [D loss: -1.162629] [G loss: 4.354884]\n",
      "epoch1 step15470 [D loss: -0.791696] [G loss: 2.948071]\n",
      "epoch1 step15475 [D loss: -0.775394] [G loss: 4.026010]\n",
      "epoch1 step15480 [D loss: 0.487491] [G loss: 4.238017]\n",
      "epoch1 step15485 [D loss: -0.684577] [G loss: 4.258711]\n",
      "epoch1 step15490 [D loss: -0.298985] [G loss: 4.251091]\n",
      "epoch1 step15495 [D loss: -0.845949] [G loss: 3.588353]\n",
      "epoch1 step15500 [D loss: -0.751613] [G loss: 3.458189]\n",
      "epoch1 step15505 [D loss: -0.168210] [G loss: 3.789327]\n",
      "epoch1 step15510 [D loss: 0.506859] [G loss: 3.392413]\n",
      "epoch1 step15515 [D loss: -0.406130] [G loss: 3.535022]\n",
      "epoch1 step15520 [D loss: -0.670226] [G loss: 3.285115]\n",
      "epoch1 step15525 [D loss: -0.515053] [G loss: 3.269769]\n",
      "epoch1 step15530 [D loss: -0.325568] [G loss: 3.432065]\n",
      "epoch1 step15535 [D loss: -0.387559] [G loss: 3.197238]\n",
      "epoch1 step15540 [D loss: -0.836897] [G loss: 3.168737]\n",
      "epoch1 step15545 [D loss: 0.228209] [G loss: 3.179312]\n",
      "epoch1 step15550 [D loss: -0.150311] [G loss: 3.077259]\n",
      "epoch1 step15555 [D loss: -0.777251] [G loss: 3.040201]\n",
      "epoch1 step15560 [D loss: -1.308854] [G loss: 3.106611]\n",
      "epoch1 step15565 [D loss: -1.221522] [G loss: 2.068821]\n",
      "epoch1 step15570 [D loss: -0.882069] [G loss: 2.738733]\n",
      "epoch1 step15575 [D loss: -0.388144] [G loss: 2.741487]\n",
      "epoch1 step15580 [D loss: 0.311612] [G loss: 2.894432]\n",
      "epoch1 step15585 [D loss: -1.008803] [G loss: 3.200250]\n",
      "epoch1 step15590 [D loss: 1.224537] [G loss: 2.510756]\n",
      "epoch1 step15595 [D loss: -0.696429] [G loss: 2.794745]\n",
      "epoch1 step15600 [D loss: -1.051487] [G loss: 3.385469]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.253846\n",
      "FID: 24.870838\n",
      "0 = 13.115014152526838\n",
      "1 = 0.08077329024568863\n",
      "2 = 0.8306999802589417\n",
      "3 = 0.9241999983787537\n",
      "4 = 0.7372000217437744\n",
      "5 = 0.7786015272140503\n",
      "6 = 0.9241999983787537\n",
      "7 = 8.318120706820485\n",
      "8 = 0.09362084711334966\n",
      "9 = 0.8137999773025513\n",
      "10 = 0.8435999751091003\n",
      "11 = 0.7839999794960022\n",
      "12 = 0.796149492263794\n",
      "13 = 0.8435999751091003\n",
      "14 = 6.25386905670166\n",
      "15 = 9.303969383239746\n",
      "16 = 0.17763516306877136\n",
      "17 = 6.253846168518066\n",
      "18 = 24.870838165283203\n",
      "epoch1 step15605 [D loss: -0.481471] [G loss: 3.048558]\n",
      "epoch1 step15610 [D loss: -0.521016] [G loss: 2.868735]\n",
      "epoch1 step15615 [D loss: -0.921396] [G loss: 2.479538]\n",
      "epoch1 step15620 [D loss: -0.350789] [G loss: 2.423908]\n",
      "epoch1 step15625 [D loss: -0.836330] [G loss: 3.172464]\n",
      "epoch1 step15630 [D loss: -0.418035] [G loss: 2.979125]\n",
      "epoch1 step15635 [D loss: 0.010302] [G loss: 3.420990]\n",
      "epoch1 step15640 [D loss: 0.320704] [G loss: 2.456001]\n",
      "epoch1 step15645 [D loss: -0.318159] [G loss: 3.085470]\n",
      "epoch1 step15650 [D loss: -0.444596] [G loss: 2.273789]\n",
      "epoch1 step15655 [D loss: -0.504514] [G loss: 2.695995]\n",
      "epoch1 step15660 [D loss: -0.991934] [G loss: 2.351165]\n",
      "epoch1 step15665 [D loss: -1.036658] [G loss: 3.120599]\n",
      "epoch1 step15670 [D loss: -0.825786] [G loss: 3.671414]\n",
      "epoch1 step15675 [D loss: -0.476273] [G loss: 3.540521]\n",
      "epoch1 step15680 [D loss: -1.128276] [G loss: 2.727722]\n",
      "epoch1 step15685 [D loss: 0.411355] [G loss: 2.642991]\n",
      "epoch1 step15690 [D loss: -0.624018] [G loss: 2.365140]\n",
      "epoch1 step15695 [D loss: -0.208973] [G loss: 3.553628]\n",
      "epoch1 step15700 [D loss: -1.170352] [G loss: 3.054951]\n",
      "epoch1 step15705 [D loss: -0.033218] [G loss: 3.344848]\n",
      "epoch1 step15710 [D loss: -0.595233] [G loss: 3.017423]\n",
      "epoch1 step15715 [D loss: -0.840067] [G loss: 2.979000]\n",
      "epoch1 step15720 [D loss: -1.319942] [G loss: 2.819618]\n",
      "epoch1 step15725 [D loss: -1.170954] [G loss: 2.921443]\n",
      "epoch1 step15730 [D loss: -0.713138] [G loss: 3.057330]\n",
      "epoch1 step15735 [D loss: -0.489580] [G loss: 3.721828]\n",
      "epoch1 step15740 [D loss: 0.045450] [G loss: 2.634068]\n",
      "epoch1 step15745 [D loss: -0.999024] [G loss: 2.832875]\n",
      "epoch1 step15750 [D loss: -0.054585] [G loss: 2.959239]\n",
      "epoch1 step15755 [D loss: -0.756252] [G loss: 2.911395]\n",
      "epoch1 step15760 [D loss: -1.082181] [G loss: 2.747740]\n",
      "epoch1 step15765 [D loss: -0.220893] [G loss: 2.855130]\n",
      "epoch1 step15770 [D loss: -0.604321] [G loss: 3.390270]\n",
      "epoch1 step15775 [D loss: -0.431511] [G loss: 2.906528]\n",
      "epoch1 step15780 [D loss: -1.223201] [G loss: 2.259671]\n",
      "epoch1 step15785 [D loss: -1.097872] [G loss: 3.447039]\n",
      "epoch1 step15790 [D loss: -1.571584] [G loss: 3.047124]\n",
      "epoch1 step15795 [D loss: -1.810508] [G loss: 3.209028]\n",
      "epoch1 step15800 [D loss: -0.624472] [G loss: 3.163843]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.137569\n",
      "FID: 29.175264\n",
      "0 = 13.021232753944355\n",
      "1 = 0.09120016749182597\n",
      "2 = 0.8550999760627747\n",
      "3 = 0.9157999753952026\n",
      "4 = 0.7943999767303467\n",
      "5 = 0.8166577219963074\n",
      "6 = 0.9157999753952026\n",
      "7 = 8.591788181042672\n",
      "8 = 0.10452412625202853\n",
      "9 = 0.8242999911308289\n",
      "10 = 0.8503999710083008\n",
      "11 = 0.7982000112533569\n",
      "12 = 0.8082113862037659\n",
      "13 = 0.8503999710083008\n",
      "14 = 6.137594223022461\n",
      "15 = 9.401127815246582\n",
      "16 = 0.172307088971138\n",
      "17 = 6.137569427490234\n",
      "18 = 29.175264358520508\n",
      "epoch1 step15805 [D loss: -1.270913] [G loss: 2.809463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 step15810 [D loss: -0.497893] [G loss: 3.009753]\n",
      "epoch1 step15815 [D loss: -0.565425] [G loss: 2.992278]\n",
      "epoch1 step15820 [D loss: -0.919645] [G loss: 2.452664]\n",
      "epoch1 step15825 [D loss: 0.145768] [G loss: 2.018452]\n",
      "epoch1 step15830 [D loss: -0.829073] [G loss: 2.320480]\n",
      "epoch1 step15835 [D loss: -0.432210] [G loss: 2.532527]\n",
      "epoch1 step15840 [D loss: -0.722013] [G loss: 2.716692]\n",
      "epoch1 step15845 [D loss: -0.913919] [G loss: 2.964917]\n",
      "epoch1 step15850 [D loss: -1.838970] [G loss: 2.903021]\n",
      "epoch1 step15855 [D loss: -0.867724] [G loss: 2.974428]\n",
      "epoch1 step15860 [D loss: -0.502189] [G loss: 3.294843]\n",
      "epoch1 step15865 [D loss: -1.285406] [G loss: 3.413795]\n",
      "epoch1 step15870 [D loss: -0.851352] [G loss: 3.200282]\n",
      "epoch1 step15875 [D loss: -0.554240] [G loss: 2.931016]\n",
      "epoch1 step15880 [D loss: -0.232334] [G loss: 3.398462]\n",
      "epoch1 step15885 [D loss: -0.727573] [G loss: 2.698081]\n",
      "epoch1 step15890 [D loss: -0.153813] [G loss: 2.834302]\n",
      "epoch1 step15895 [D loss: -0.161283] [G loss: 2.735001]\n",
      "epoch1 step15900 [D loss: -0.772767] [G loss: 3.426047]\n",
      "epoch1 step15905 [D loss: -0.164686] [G loss: 2.784362]\n",
      "epoch1 step15910 [D loss: -1.044368] [G loss: 3.406703]\n",
      "epoch1 step15915 [D loss: -1.604922] [G loss: 2.699723]\n",
      "epoch1 step15920 [D loss: 0.361931] [G loss: 2.480113]\n",
      "epoch1 step15925 [D loss: -0.419469] [G loss: 2.519510]\n",
      "epoch1 step15930 [D loss: -0.005372] [G loss: 2.947973]\n",
      "epoch1 step15935 [D loss: -0.182876] [G loss: 3.697904]\n",
      "epoch1 step15940 [D loss: -0.695880] [G loss: 2.596138]\n",
      "epoch1 step15945 [D loss: -1.079128] [G loss: 3.260465]\n",
      "epoch1 step15950 [D loss: -0.219005] [G loss: 2.573263]\n",
      "epoch1 step15955 [D loss: -0.958675] [G loss: 3.198200]\n",
      "epoch1 step15960 [D loss: -0.511873] [G loss: 2.639770]\n",
      "epoch1 step15965 [D loss: -1.003913] [G loss: 2.186378]\n",
      "epoch1 step15970 [D loss: -1.065706] [G loss: 2.358074]\n",
      "epoch1 step15975 [D loss: 0.062977] [G loss: 2.183081]\n",
      "epoch1 step15980 [D loss: -0.744513] [G loss: 2.065149]\n",
      "epoch1 step15985 [D loss: -0.398855] [G loss: 2.239019]\n",
      "epoch1 step15990 [D loss: -0.690056] [G loss: 2.504455]\n",
      "epoch1 step15995 [D loss: -1.075934] [G loss: 2.495889]\n",
      "epoch1 step16000 [D loss: 0.126752] [G loss: 2.744224]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.112981\n",
      "FID: 25.877968\n",
      "0 = 14.9135951824188\n",
      "1 = 0.20011758923792755\n",
      "2 = 0.8597999811172485\n",
      "3 = 0.948199987411499\n",
      "4 = 0.771399974822998\n",
      "5 = 0.8057444095611572\n",
      "6 = 0.948199987411499\n",
      "7 = 8.676361181974414\n",
      "8 = 0.10208348384508728\n",
      "9 = 0.8165000081062317\n",
      "10 = 0.850600004196167\n",
      "11 = 0.7824000120162964\n",
      "12 = 0.7962928414344788\n",
      "13 = 0.850600004196167\n",
      "14 = 6.11300802230835\n",
      "15 = 9.072566986083984\n",
      "16 = 0.2111186683177948\n",
      "17 = 6.112980842590332\n",
      "18 = 25.877967834472656\n",
      "epoch1 step16005 [D loss: -0.843882] [G loss: 2.887858]\n",
      "epoch1 step16010 [D loss: -0.868459] [G loss: 3.548854]\n",
      "epoch1 step16015 [D loss: -0.837676] [G loss: 3.275695]\n",
      "epoch1 step16020 [D loss: -0.841266] [G loss: 3.244356]\n",
      "epoch1 step16025 [D loss: -0.674666] [G loss: 3.801313]\n",
      "epoch1 step16030 [D loss: 0.145806] [G loss: 3.549807]\n",
      "epoch1 step16035 [D loss: -1.094243] [G loss: 3.030614]\n",
      "epoch1 step16040 [D loss: -0.714702] [G loss: 3.273310]\n",
      "epoch1 step16045 [D loss: -0.713166] [G loss: 3.317596]\n",
      "epoch1 step16050 [D loss: -1.303480] [G loss: 3.472023]\n",
      "epoch1 step16055 [D loss: -1.073734] [G loss: 3.513792]\n",
      "epoch1 step16060 [D loss: -0.902225] [G loss: 3.372765]\n",
      "epoch1 step16065 [D loss: -1.295418] [G loss: 3.342663]\n",
      "epoch1 step16070 [D loss: -0.998140] [G loss: 4.240600]\n",
      "epoch1 step16075 [D loss: -0.012210] [G loss: 3.309524]\n",
      "epoch1 step16080 [D loss: -0.193733] [G loss: 3.010241]\n",
      "epoch1 step16085 [D loss: -0.131637] [G loss: 3.002829]\n",
      "epoch1 step16090 [D loss: -0.899929] [G loss: 3.610805]\n",
      "epoch1 step16095 [D loss: 0.077801] [G loss: 2.711741]\n",
      "epoch1 step16100 [D loss: -0.933187] [G loss: 2.533909]\n",
      "epoch1 step16105 [D loss: -0.731472] [G loss: 3.339565]\n",
      "epoch1 step16110 [D loss: -1.189565] [G loss: 3.358616]\n",
      "epoch1 step16115 [D loss: -0.385387] [G loss: 2.782065]\n",
      "epoch1 step16120 [D loss: 0.134451] [G loss: 2.497602]\n",
      "epoch1 step16125 [D loss: -0.561551] [G loss: 2.684364]\n",
      "epoch1 step16130 [D loss: 0.485329] [G loss: 1.975465]\n",
      "epoch1 step16135 [D loss: 0.082891] [G loss: 2.567274]\n",
      "epoch1 step16140 [D loss: -0.272695] [G loss: 2.499262]\n",
      "epoch1 step16145 [D loss: -0.334800] [G loss: 1.936481]\n",
      "epoch1 step16150 [D loss: -0.798616] [G loss: 2.386219]\n",
      "epoch1 step16155 [D loss: -0.007193] [G loss: 2.642473]\n",
      "epoch1 step16160 [D loss: -0.528985] [G loss: 1.730897]\n",
      "epoch1 step16165 [D loss: -0.560092] [G loss: 2.874783]\n",
      "epoch1 step16170 [D loss: -0.691819] [G loss: 2.222361]\n",
      "epoch1 step16175 [D loss: -0.615238] [G loss: 2.453554]\n",
      "epoch1 step16180 [D loss: -0.677004] [G loss: 2.427025]\n",
      "epoch1 step16185 [D loss: -0.054855] [G loss: 2.305566]\n",
      "epoch1 step16190 [D loss: -0.159632] [G loss: 2.265817]\n",
      "epoch1 step16195 [D loss: -1.185983] [G loss: 2.896747]\n",
      "epoch1 step16200 [D loss: -0.638065] [G loss: 2.553442]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.254590\n",
      "FID: 23.664074\n",
      "0 = 13.723911459255207\n",
      "1 = 0.11764538637543252\n",
      "2 = 0.8364999890327454\n",
      "3 = 0.9391999840736389\n",
      "4 = 0.7337999939918518\n",
      "5 = 0.7791604399681091\n",
      "6 = 0.9391999840736389\n",
      "7 = 8.298817137432101\n",
      "8 = 0.09304096398527416\n",
      "9 = 0.8112999796867371\n",
      "10 = 0.8503999710083008\n",
      "11 = 0.7721999883651733\n",
      "12 = 0.7887219190597534\n",
      "13 = 0.8503999710083008\n",
      "14 = 6.2546162605285645\n",
      "15 = 9.359355926513672\n",
      "16 = 0.16100925207138062\n",
      "17 = 6.254590034484863\n",
      "18 = 23.664073944091797\n",
      "epoch1 step16205 [D loss: -0.870276] [G loss: 2.862324]\n",
      "epoch1 step16210 [D loss: 0.070878] [G loss: 2.815309]\n",
      "epoch1 step16215 [D loss: -1.238004] [G loss: 2.471605]\n",
      "epoch1 step16220 [D loss: 0.312281] [G loss: 2.279924]\n",
      "epoch1 step16225 [D loss: -0.306033] [G loss: 2.139848]\n",
      "epoch1 step16230 [D loss: -0.602208] [G loss: 2.412978]\n",
      "epoch1 step16235 [D loss: -0.837286] [G loss: 2.086167]\n",
      "epoch1 step16240 [D loss: -1.103991] [G loss: 3.449838]\n",
      "epoch1 step16245 [D loss: 0.004604] [G loss: 2.659786]\n",
      "epoch1 step16250 [D loss: -0.927077] [G loss: 2.736024]\n",
      "epoch1 step16255 [D loss: -0.047958] [G loss: 2.559383]\n",
      "epoch1 step16260 [D loss: -0.069049] [G loss: 2.713914]\n",
      "epoch1 step16265 [D loss: -0.503039] [G loss: 2.333370]\n",
      "epoch1 step16270 [D loss: 0.424412] [G loss: 2.898266]\n",
      "epoch1 step16275 [D loss: -1.394685] [G loss: 3.019622]\n",
      "epoch1 step16280 [D loss: -1.747611] [G loss: 3.199310]\n",
      "epoch1 step16285 [D loss: 0.242755] [G loss: 2.496637]\n",
      "epoch1 step16290 [D loss: -0.300422] [G loss: 3.449760]\n",
      "epoch1 step16295 [D loss: -0.782663] [G loss: 2.646076]\n",
      "epoch1 step16300 [D loss: -1.099845] [G loss: 2.768596]\n",
      "epoch1 step16305 [D loss: -1.332631] [G loss: 3.780925]\n",
      "epoch1 step16310 [D loss: -0.917447] [G loss: 2.768187]\n",
      "epoch1 step16315 [D loss: -1.028298] [G loss: 2.821207]\n",
      "epoch1 step16320 [D loss: -0.625960] [G loss: 3.743500]\n",
      "epoch1 step16325 [D loss: -0.039805] [G loss: 2.665374]\n",
      "epoch1 step16330 [D loss: -0.442030] [G loss: 3.640631]\n",
      "epoch1 step16335 [D loss: -0.710119] [G loss: 3.291873]\n",
      "epoch1 step16340 [D loss: 0.519129] [G loss: 3.486421]\n",
      "epoch1 step16345 [D loss: 0.307371] [G loss: 3.427789]\n",
      "epoch1 step16350 [D loss: -1.126381] [G loss: 3.890941]\n",
      "epoch1 step16355 [D loss: -0.017088] [G loss: 3.652897]\n",
      "epoch1 step16360 [D loss: -0.092181] [G loss: 3.749386]\n",
      "epoch1 step16365 [D loss: -0.091021] [G loss: 3.470049]\n",
      "epoch1 step16370 [D loss: -1.198686] [G loss: 4.175305]\n",
      "epoch1 step16375 [D loss: -0.840332] [G loss: 3.482049]\n",
      "epoch1 step16380 [D loss: -0.284247] [G loss: 3.031523]\n",
      "epoch1 step16385 [D loss: -1.188492] [G loss: 2.958395]\n",
      "epoch1 step16390 [D loss: -0.818880] [G loss: 3.364024]\n",
      "epoch1 step16395 [D loss: -0.460787] [G loss: 3.514652]\n",
      "epoch1 step16400 [D loss: -1.036797] [G loss: 3.016610]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.232397\n",
      "FID: 23.132669\n",
      "0 = 13.40489826755521\n",
      "1 = 0.08323011363560606\n",
      "2 = 0.8371000289916992\n",
      "3 = 0.9355999827384949\n",
      "4 = 0.7386000156402588\n",
      "5 = 0.7816207408905029\n",
      "6 = 0.9355999827384949\n",
      "7 = 8.345083702301975\n",
      "8 = 0.09218757758703038\n",
      "9 = 0.8133000135421753\n",
      "10 = 0.853600025177002\n",
      "11 = 0.7730000019073486\n",
      "12 = 0.7899315357208252\n",
      "13 = 0.853600025177002\n",
      "14 = 6.232417106628418\n",
      "15 = 9.378680229187012\n",
      "16 = 0.16433274745941162\n",
      "17 = 6.232397079467773\n",
      "18 = 23.13266944885254\n",
      "epoch1 step16405 [D loss: -1.250848] [G loss: 3.622151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 step16410 [D loss: -0.411717] [G loss: 3.560094]\n",
      "epoch1 step16415 [D loss: -0.984015] [G loss: 3.430869]\n",
      "epoch1 step16420 [D loss: 0.275064] [G loss: 2.370047]\n",
      "epoch1 step16425 [D loss: -0.747650] [G loss: 3.287603]\n",
      "epoch1 step16430 [D loss: -1.267273] [G loss: 4.083712]\n",
      "epoch1 step16435 [D loss: -2.329804] [G loss: 3.199862]\n",
      "epoch1 step16440 [D loss: -2.010761] [G loss: 3.859615]\n",
      "epoch1 step16445 [D loss: -1.504812] [G loss: 3.317593]\n",
      "epoch1 step16450 [D loss: -1.108042] [G loss: 4.118834]\n",
      "epoch1 step16455 [D loss: -0.542218] [G loss: 3.272151]\n",
      "epoch1 step16460 [D loss: -1.609198] [G loss: 4.356859]\n",
      "epoch1 step16465 [D loss: -1.885628] [G loss: 4.075111]\n",
      "epoch1 step16470 [D loss: -0.017979] [G loss: 3.949485]\n",
      "epoch1 step16475 [D loss: 0.664813] [G loss: 4.459090]\n",
      "epoch1 step16480 [D loss: -0.312440] [G loss: 4.056411]\n",
      "epoch1 step16485 [D loss: -0.636040] [G loss: 4.267460]\n",
      "epoch1 step16490 [D loss: -0.801797] [G loss: 4.121649]\n",
      "epoch1 step16495 [D loss: -1.640608] [G loss: 4.356865]\n",
      "epoch1 step16500 [D loss: -0.479741] [G loss: 3.729234]\n",
      "epoch1 step16505 [D loss: -0.789052] [G loss: 3.681511]\n",
      "epoch1 step16510 [D loss: -0.984568] [G loss: 3.595715]\n",
      "epoch1 step16515 [D loss: -0.453681] [G loss: 4.113268]\n",
      "epoch1 step16520 [D loss: -0.108929] [G loss: 3.855635]\n",
      "epoch1 step16525 [D loss: -0.010314] [G loss: 4.756936]\n",
      "epoch1 step16530 [D loss: -0.533104] [G loss: 4.018288]\n",
      "epoch1 step16535 [D loss: -0.099844] [G loss: 4.246630]\n",
      "epoch1 step16540 [D loss: 0.188854] [G loss: 4.318333]\n",
      "epoch1 step16545 [D loss: -0.492269] [G loss: 3.725839]\n",
      "epoch1 step16550 [D loss: 0.038142] [G loss: 3.671934]\n",
      "epoch1 step16555 [D loss: -0.261205] [G loss: 4.159963]\n",
      "epoch1 step16560 [D loss: -0.326595] [G loss: 4.187830]\n",
      "epoch1 step16565 [D loss: -0.687804] [G loss: 3.518853]\n",
      "epoch1 step16570 [D loss: 0.560013] [G loss: 4.008580]\n",
      "epoch1 step16575 [D loss: -0.442043] [G loss: 4.114467]\n",
      "epoch1 step16580 [D loss: -0.415730] [G loss: 5.012119]\n",
      "epoch1 step16585 [D loss: -0.531158] [G loss: 4.460936]\n",
      "epoch1 step16590 [D loss: 0.472375] [G loss: 3.720493]\n",
      "epoch1 step16595 [D loss: -0.401806] [G loss: 4.161414]\n",
      "epoch1 step16600 [D loss: -0.142500] [G loss: 3.878585]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.062682\n",
      "FID: 28.771065\n",
      "0 = 13.163183600902562\n",
      "1 = 0.06123794437020626\n",
      "2 = 0.839900016784668\n",
      "3 = 0.9259999990463257\n",
      "4 = 0.7537999749183655\n",
      "5 = 0.7899675965309143\n",
      "6 = 0.9259999990463257\n",
      "7 = 8.534221720910075\n",
      "8 = 0.1043517693348113\n",
      "9 = 0.8248999714851379\n",
      "10 = 0.8539999723434448\n",
      "11 = 0.795799970626831\n",
      "12 = 0.8070307970046997\n",
      "13 = 0.8539999723434448\n",
      "14 = 6.062705039978027\n",
      "15 = 9.198197364807129\n",
      "16 = 0.20056694746017456\n",
      "17 = 6.062681674957275\n",
      "18 = 28.77106475830078\n",
      "epoch1 step16605 [D loss: -0.166749] [G loss: 4.237153]\n",
      "epoch1 step16610 [D loss: 0.510607] [G loss: 3.182287]\n",
      "epoch1 step16615 [D loss: 0.372494] [G loss: 3.977014]\n",
      "epoch1 step16620 [D loss: -0.263302] [G loss: 3.977935]\n",
      "epoch1 step16625 [D loss: -0.378759] [G loss: 3.755606]\n",
      "epoch1 step16630 [D loss: -1.071187] [G loss: 3.756778]\n",
      "epoch1 step16635 [D loss: -0.729360] [G loss: 3.661011]\n",
      "epoch1 step16640 [D loss: -0.402878] [G loss: 3.921749]\n",
      "epoch1 step16645 [D loss: -0.824019] [G loss: 4.632899]\n",
      "epoch1 step16650 [D loss: 0.069776] [G loss: 4.482557]\n",
      "epoch1 step16655 [D loss: -0.954369] [G loss: 4.290412]\n",
      "epoch1 step16660 [D loss: -0.594647] [G loss: 3.778854]\n",
      "epoch1 step16665 [D loss: -1.159341] [G loss: 4.126614]\n",
      "epoch1 step16670 [D loss: -0.286810] [G loss: 3.726660]\n",
      "epoch1 step16675 [D loss: -0.935613] [G loss: 4.018930]\n",
      "epoch1 step16680 [D loss: -1.111998] [G loss: 3.660846]\n",
      "epoch1 step16685 [D loss: -1.489008] [G loss: 3.428628]\n",
      "epoch1 step16690 [D loss: -0.553143] [G loss: 3.408286]\n",
      "epoch1 step16695 [D loss: -0.373307] [G loss: 2.641054]\n",
      "epoch1 step16700 [D loss: -0.869059] [G loss: 3.770414]\n",
      "epoch1 step16705 [D loss: -0.704185] [G loss: 3.685352]\n",
      "epoch1 step16710 [D loss: -0.207922] [G loss: 3.859074]\n",
      "epoch1 step16715 [D loss: -0.056683] [G loss: 2.703841]\n",
      "epoch1 step16720 [D loss: 0.229690] [G loss: 1.684746]\n",
      "epoch1 step16725 [D loss: -0.958841] [G loss: 2.693813]\n",
      "epoch1 step16730 [D loss: -1.020747] [G loss: 2.737859]\n",
      "epoch1 step16735 [D loss: -0.523296] [G loss: 2.899351]\n",
      "epoch1 step16740 [D loss: -1.689219] [G loss: 3.116833]\n",
      "epoch1 step16745 [D loss: -0.230297] [G loss: 3.548643]\n",
      "epoch1 step16750 [D loss: -0.112707] [G loss: 3.352301]\n",
      "epoch1 step16755 [D loss: -1.280443] [G loss: 3.013511]\n",
      "epoch1 step16760 [D loss: -0.791856] [G loss: 2.550871]\n",
      "epoch1 step16765 [D loss: -0.475645] [G loss: 2.927110]\n",
      "epoch1 step16770 [D loss: 0.188928] [G loss: 3.377577]\n",
      "epoch1 step16775 [D loss: -1.323524] [G loss: 3.000732]\n",
      "epoch1 step16780 [D loss: -0.606851] [G loss: 3.355942]\n",
      "epoch1 step16785 [D loss: -0.085522] [G loss: 2.805324]\n",
      "epoch1 step16790 [D loss: -0.843565] [G loss: 3.208740]\n",
      "epoch1 step16795 [D loss: 0.170042] [G loss: 3.296391]\n",
      "epoch1 step16800 [D loss: -0.862030] [G loss: 2.861736]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.219462\n",
      "FID: 25.796940\n",
      "0 = 12.816381284999862\n",
      "1 = 0.05471800906792408\n",
      "2 = 0.835099995136261\n",
      "3 = 0.9233999848365784\n",
      "4 = 0.7468000054359436\n",
      "5 = 0.7848036885261536\n",
      "6 = 0.9233999848365784\n",
      "7 = 8.347246390116222\n",
      "8 = 0.09659950707667227\n",
      "9 = 0.8152999877929688\n",
      "10 = 0.842199981212616\n",
      "11 = 0.7883999943733215\n",
      "12 = 0.7992028594017029\n",
      "13 = 0.842199981212616\n",
      "14 = 6.219485282897949\n",
      "15 = 9.344444274902344\n",
      "16 = 0.17261061072349548\n",
      "17 = 6.2194623947143555\n",
      "18 = 25.796939849853516\n",
      "epoch1 step16805 [D loss: -0.936449] [G loss: 3.495661]\n",
      "epoch1 step16810 [D loss: -0.662664] [G loss: 3.554376]\n",
      "epoch1 step16815 [D loss: 0.082362] [G loss: 3.929643]\n",
      "epoch1 step16820 [D loss: -0.623152] [G loss: 3.876292]\n",
      "epoch1 step16825 [D loss: -0.626332] [G loss: 4.005094]\n",
      "epoch1 step16830 [D loss: -0.329933] [G loss: 3.964086]\n",
      "epoch1 step16835 [D loss: -0.940086] [G loss: 4.817127]\n",
      "epoch1 step16840 [D loss: 0.372980] [G loss: 3.765033]\n",
      "epoch1 step16845 [D loss: -1.580211] [G loss: 4.041775]\n",
      "epoch1 step16850 [D loss: -0.799019] [G loss: 3.368576]\n",
      "epoch1 step16855 [D loss: -0.830541] [G loss: 4.452253]\n",
      "epoch1 step16860 [D loss: -0.580488] [G loss: 3.956543]\n",
      "epoch1 step16865 [D loss: -1.486403] [G loss: 3.616033]\n",
      "epoch1 step16870 [D loss: 0.279607] [G loss: 2.847961]\n",
      "epoch1 step16875 [D loss: -0.829305] [G loss: 2.934968]\n",
      "epoch1 step16880 [D loss: -0.760556] [G loss: 3.502654]\n",
      "epoch1 step16885 [D loss: -0.701292] [G loss: 3.389428]\n",
      "epoch1 step16890 [D loss: 0.273594] [G loss: 2.839211]\n",
      "epoch1 step16895 [D loss: -0.245255] [G loss: 3.001391]\n",
      "epoch1 step16900 [D loss: -0.269392] [G loss: 2.603570]\n",
      "epoch1 step16905 [D loss: -0.468230] [G loss: 3.222423]\n",
      "epoch1 step16910 [D loss: -0.094843] [G loss: 2.737235]\n",
      "epoch1 step16915 [D loss: 0.214014] [G loss: 3.305360]\n",
      "epoch1 step16920 [D loss: -0.309970] [G loss: 2.648126]\n",
      "epoch1 step16925 [D loss: -0.473522] [G loss: 2.804081]\n",
      "epoch1 step16930 [D loss: -0.769968] [G loss: 3.022145]\n",
      "epoch1 step16935 [D loss: -0.131420] [G loss: 2.976542]\n",
      "epoch1 step16940 [D loss: -0.210477] [G loss: 2.965249]\n",
      "epoch1 step16945 [D loss: -1.046170] [G loss: 3.547164]\n",
      "epoch1 step16950 [D loss: -0.743755] [G loss: 3.479196]\n",
      "epoch1 step16955 [D loss: -0.753316] [G loss: 3.843787]\n",
      "epoch1 step16960 [D loss: -0.683093] [G loss: 3.294028]\n",
      "epoch1 step16965 [D loss: 0.263308] [G loss: 3.575187]\n",
      "epoch1 step16970 [D loss: -0.493464] [G loss: 3.922393]\n",
      "epoch1 step16975 [D loss: 0.225683] [G loss: 3.235640]\n",
      "epoch1 step16980 [D loss: -0.669305] [G loss: 3.778920]\n",
      "epoch1 step16985 [D loss: -0.417214] [G loss: 4.334173]\n",
      "epoch1 step16990 [D loss: -0.508819] [G loss: 3.709829]\n",
      "epoch1 step16995 [D loss: 0.754873] [G loss: 4.074401]\n",
      "epoch1 step17000 [D loss: -0.170082] [G loss: 3.439397]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.288145\n",
      "FID: 25.629534\n",
      "0 = 13.067119103860875\n",
      "1 = 0.07546670662145377\n",
      "2 = 0.8421000242233276\n",
      "3 = 0.9232000112533569\n",
      "4 = 0.7609999775886536\n",
      "5 = 0.7943555116653442\n",
      "6 = 0.9232000112533569\n",
      "7 = 8.391743852591535\n",
      "8 = 0.09649146667858598\n",
      "9 = 0.8194000124931335\n",
      "10 = 0.8533999919891357\n",
      "11 = 0.7853999733924866\n",
      "12 = 0.7990636825561523\n",
      "13 = 0.8533999919891357\n",
      "14 = 6.288170337677002\n",
      "15 = 9.363085746765137\n",
      "16 = 0.1665143072605133\n",
      "17 = 6.288144588470459\n",
      "18 = 25.629533767700195\n",
      "epoch1 step17005 [D loss: -0.290919] [G loss: 4.181608]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 step17010 [D loss: -0.778968] [G loss: 3.889010]\n",
      "epoch1 step17015 [D loss: -0.099248] [G loss: 3.574934]\n",
      "epoch1 step17020 [D loss: 0.081735] [G loss: 2.899927]\n",
      "epoch1 step17025 [D loss: -0.103174] [G loss: 3.238915]\n",
      "epoch1 step17030 [D loss: -0.878269] [G loss: 3.091575]\n",
      "epoch1 step17035 [D loss: -0.613075] [G loss: 2.561027]\n",
      "epoch1 step17040 [D loss: 0.480831] [G loss: 2.832575]\n",
      "epoch1 step17045 [D loss: -0.278088] [G loss: 2.666847]\n",
      "epoch1 step17050 [D loss: 0.078279] [G loss: 3.166627]\n",
      "epoch1 step17055 [D loss: -0.153214] [G loss: 3.158406]\n",
      "epoch1 step17060 [D loss: -0.622139] [G loss: 3.380534]\n",
      "epoch1 step17065 [D loss: -0.898475] [G loss: 3.721253]\n",
      "epoch1 step17070 [D loss: -1.728085] [G loss: 3.700644]\n",
      "epoch1 step17075 [D loss: -0.049256] [G loss: 3.416451]\n",
      "epoch1 step17080 [D loss: -0.373356] [G loss: 3.478582]\n",
      "epoch1 step17085 [D loss: -0.785362] [G loss: 3.525987]\n",
      "epoch1 step17090 [D loss: -1.739978] [G loss: 4.109011]\n",
      "epoch1 step17095 [D loss: 0.142664] [G loss: 3.427519]\n",
      "epoch1 step17100 [D loss: -0.620554] [G loss: 4.010280]\n",
      "epoch1 step17105 [D loss: -0.355923] [G loss: 4.513084]\n",
      "epoch1 step17110 [D loss: -1.265260] [G loss: 4.143815]\n",
      "epoch1 step17115 [D loss: -0.769099] [G loss: 3.421531]\n",
      "epoch1 step17120 [D loss: -1.643064] [G loss: 4.721054]\n",
      "epoch1 step17125 [D loss: -0.911054] [G loss: 3.274498]\n",
      "epoch1 step17130 [D loss: -0.570105] [G loss: 3.693619]\n",
      "epoch1 step17135 [D loss: -0.982061] [G loss: 3.918537]\n",
      "epoch1 step17140 [D loss: -0.936241] [G loss: 3.749643]\n",
      "epoch1 step17145 [D loss: -0.796112] [G loss: 3.480358]\n",
      "epoch1 step17150 [D loss: -0.737492] [G loss: 3.272785]\n",
      "epoch1 step17155 [D loss: -0.695687] [G loss: 3.298750]\n",
      "epoch1 step17160 [D loss: 0.141009] [G loss: 3.885859]\n",
      "epoch1 step17165 [D loss: 0.112490] [G loss: 3.594935]\n",
      "epoch1 step17170 [D loss: -0.130152] [G loss: 3.257819]\n",
      "epoch1 step17175 [D loss: -0.219649] [G loss: 3.762144]\n",
      "epoch1 step17180 [D loss: -0.752800] [G loss: 3.395415]\n",
      "epoch1 step17185 [D loss: -1.375791] [G loss: 3.672810]\n",
      "epoch1 step17190 [D loss: -0.278636] [G loss: 3.653264]\n",
      "epoch1 step17195 [D loss: -0.956342] [G loss: 3.795619]\n",
      "epoch1 step17200 [D loss: -0.296349] [G loss: 3.391732]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.190321\n",
      "FID: 27.033703\n",
      "0 = 13.043625416803344\n",
      "1 = 0.07061786041631275\n",
      "2 = 0.8258000016212463\n",
      "3 = 0.9196000099182129\n",
      "4 = 0.7319999933242798\n",
      "5 = 0.7743347883224487\n",
      "6 = 0.9196000099182129\n",
      "7 = 8.475977656292915\n",
      "8 = 0.10177062790432477\n",
      "9 = 0.8082000017166138\n",
      "10 = 0.8374000191688538\n",
      "11 = 0.7789999842643738\n",
      "12 = 0.7911942601203918\n",
      "13 = 0.8374000191688538\n",
      "14 = 6.19034481048584\n",
      "15 = 9.349505424499512\n",
      "16 = 0.17506389319896698\n",
      "17 = 6.19032096862793\n",
      "18 = 27.033702850341797\n",
      "epoch1 step17205 [D loss: 0.086873] [G loss: 3.295749]\n",
      "epoch1 step17210 [D loss: 0.075764] [G loss: 2.560677]\n",
      "epoch1 step17215 [D loss: -0.046406] [G loss: 2.794766]\n",
      "epoch1 step17220 [D loss: -1.352113] [G loss: 2.652164]\n",
      "epoch1 step17225 [D loss: -0.221630] [G loss: 2.011315]\n",
      "epoch1 step17230 [D loss: -1.671131] [G loss: 2.847510]\n",
      "epoch1 step17235 [D loss: -0.905548] [G loss: 2.482239]\n",
      "epoch1 step17240 [D loss: -0.307873] [G loss: 2.040894]\n",
      "epoch1 step17245 [D loss: -0.401936] [G loss: 2.842733]\n",
      "epoch1 step17250 [D loss: 0.274499] [G loss: 2.932551]\n",
      "epoch1 step17255 [D loss: -0.720474] [G loss: 2.588924]\n",
      "epoch1 step17260 [D loss: -1.252314] [G loss: 3.229545]\n",
      "epoch1 step17265 [D loss: -0.330815] [G loss: 2.547260]\n",
      "epoch1 step17270 [D loss: -0.745458] [G loss: 3.406720]\n",
      "epoch1 step17275 [D loss: -1.781397] [G loss: 2.832009]\n",
      "epoch1 step17280 [D loss: -0.820024] [G loss: 2.943301]\n",
      "epoch1 step17285 [D loss: -1.522707] [G loss: 3.191668]\n",
      "epoch1 step17290 [D loss: -1.165778] [G loss: 3.623258]\n",
      "epoch1 step17295 [D loss: -2.110438] [G loss: 2.864168]\n",
      "epoch1 step17300 [D loss: -1.217335] [G loss: 2.157293]\n",
      "epoch1 step17305 [D loss: -0.256533] [G loss: 3.049107]\n",
      "epoch1 step17310 [D loss: -0.352611] [G loss: 2.405733]\n",
      "epoch1 step17315 [D loss: -1.066488] [G loss: 3.062121]\n",
      "epoch1 step17320 [D loss: -0.887079] [G loss: 2.537644]\n",
      "epoch1 step17325 [D loss: -0.650833] [G loss: 2.456081]\n",
      "epoch1 step17330 [D loss: -0.671645] [G loss: 2.688309]\n",
      "epoch1 step17335 [D loss: -0.344091] [G loss: 3.164420]\n",
      "epoch1 step17340 [D loss: 0.324018] [G loss: 2.184729]\n",
      "epoch1 step17345 [D loss: 0.125443] [G loss: 2.852173]\n",
      "epoch1 step17350 [D loss: -0.642816] [G loss: 2.510675]\n",
      "epoch1 step17355 [D loss: 0.546174] [G loss: 2.737342]\n",
      "epoch1 step17360 [D loss: -0.553526] [G loss: 2.463710]\n",
      "epoch1 step17365 [D loss: -0.755217] [G loss: 2.271328]\n",
      "epoch1 step17370 [D loss: 0.139926] [G loss: 3.174550]\n",
      "epoch1 step17375 [D loss: 0.092210] [G loss: 2.867949]\n",
      "epoch1 step17380 [D loss: -0.822923] [G loss: 2.544449]\n",
      "epoch1 step17385 [D loss: -0.140733] [G loss: 2.513243]\n",
      "epoch1 step17390 [D loss: -0.168066] [G loss: 2.868249]\n",
      "epoch1 step17395 [D loss: -0.107559] [G loss: 2.099675]\n",
      "epoch1 step17400 [D loss: -0.805007] [G loss: 2.482303]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.132173\n",
      "FID: 25.172976\n",
      "0 = 13.836025288105024\n",
      "1 = 0.14067288748980467\n",
      "2 = 0.8428000211715698\n",
      "3 = 0.9437999725341797\n",
      "4 = 0.7418000102043152\n",
      "5 = 0.7851913571357727\n",
      "6 = 0.9437999725341797\n",
      "7 = 8.34000489752292\n",
      "8 = 0.09686938854085586\n",
      "9 = 0.8073999881744385\n",
      "10 = 0.8474000096321106\n",
      "11 = 0.7674000263214111\n",
      "12 = 0.7846296429634094\n",
      "13 = 0.8474000096321106\n",
      "14 = 6.132198333740234\n",
      "15 = 9.057442665100098\n",
      "16 = 0.2123161256313324\n",
      "17 = 6.13217306137085\n",
      "18 = 25.172975540161133\n",
      "epoch1 step17405 [D loss: -1.460565] [G loss: 2.325980]\n",
      "epoch1 step17410 [D loss: -1.141430] [G loss: 3.263102]\n",
      "epoch1 step17415 [D loss: -1.020527] [G loss: 2.740859]\n",
      "epoch1 step17420 [D loss: -1.351381] [G loss: 3.479571]\n",
      "epoch1 step17425 [D loss: -1.229815] [G loss: 3.245621]\n",
      "epoch1 step17430 [D loss: -1.497581] [G loss: 2.777122]\n",
      "epoch1 step17435 [D loss: -1.269938] [G loss: 3.838104]\n",
      "epoch1 step17440 [D loss: -0.191556] [G loss: 4.050927]\n",
      "epoch1 step17445 [D loss: -1.041523] [G loss: 3.692728]\n",
      "epoch1 step17450 [D loss: -0.470488] [G loss: 3.868145]\n",
      "epoch1 step17455 [D loss: -1.250688] [G loss: 3.481545]\n",
      "epoch1 step17460 [D loss: -0.243016] [G loss: 3.172048]\n",
      "epoch1 step17465 [D loss: -0.978164] [G loss: 4.028792]\n",
      "epoch1 step17470 [D loss: -0.625260] [G loss: 3.811348]\n",
      "epoch1 step17475 [D loss: -0.817648] [G loss: 3.670676]\n",
      "epoch1 step17480 [D loss: -1.827902] [G loss: 4.042331]\n",
      "epoch1 step17485 [D loss: -0.510732] [G loss: 3.350114]\n",
      "epoch1 step17490 [D loss: -0.238631] [G loss: 4.018901]\n",
      "epoch1 step17495 [D loss: -0.331343] [G loss: 3.568108]\n",
      "epoch1 step17500 [D loss: -0.389001] [G loss: 4.279334]\n",
      "epoch1 step17505 [D loss: -0.296988] [G loss: 5.054332]\n",
      "epoch1 step17510 [D loss: -0.572606] [G loss: 4.304536]\n",
      "epoch1 step17515 [D loss: -0.515094] [G loss: 4.692200]\n",
      "epoch1 step17520 [D loss: -0.982839] [G loss: 4.427355]\n",
      "epoch1 step17525 [D loss: -0.594739] [G loss: 4.300543]\n",
      "epoch1 step17530 [D loss: -2.325882] [G loss: 5.329233]\n",
      "epoch1 step17535 [D loss: -0.629552] [G loss: 3.978453]\n",
      "epoch1 step17540 [D loss: -0.800586] [G loss: 4.990416]\n",
      "epoch1 step17545 [D loss: -0.374489] [G loss: 5.132916]\n",
      "epoch1 step17550 [D loss: -0.301336] [G loss: 4.810187]\n",
      "epoch1 step17555 [D loss: -1.622611] [G loss: 4.167973]\n",
      "epoch1 step17560 [D loss: -1.587313] [G loss: 3.423686]\n",
      "epoch1 step17565 [D loss: -0.705720] [G loss: 4.446621]\n",
      "epoch1 step17570 [D loss: -1.717226] [G loss: 4.366040]\n",
      "epoch1 step17575 [D loss: -0.783980] [G loss: 4.395802]\n",
      "epoch1 step17580 [D loss: -0.647914] [G loss: 3.507735]\n",
      "epoch1 step17585 [D loss: -1.084664] [G loss: 4.933849]\n",
      "epoch1 step17590 [D loss: -0.921393] [G loss: 4.315698]\n",
      "epoch1 step17595 [D loss: -0.888677] [G loss: 4.247726]\n",
      "epoch1 step17600 [D loss: -0.588951] [G loss: 3.990995]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.419114\n",
      "FID: 22.370497\n",
      "0 = 13.123194653415686\n",
      "1 = 0.06701382212616314\n",
      "2 = 0.8353000283241272\n",
      "3 = 0.926800012588501\n",
      "4 = 0.7437999844551086\n",
      "5 = 0.7834319472312927\n",
      "6 = 0.926800012588501\n",
      "7 = 8.226929402112987\n",
      "8 = 0.08922129077934549\n",
      "9 = 0.8112000226974487\n",
      "10 = 0.8518000245094299\n",
      "11 = 0.7706000208854675\n",
      "12 = 0.7878283262252808\n",
      "13 = 0.8518000245094299\n",
      "14 = 6.419136047363281\n",
      "15 = 9.423951148986816\n",
      "16 = 0.14879201352596283\n",
      "17 = 6.419113636016846\n",
      "18 = 22.37049674987793\n",
      "epoch1 step17605 [D loss: -0.332617] [G loss: 3.955259]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 step17610 [D loss: -0.649748] [G loss: 4.112869]\n",
      "epoch1 step17615 [D loss: -1.217355] [G loss: 3.822608]\n",
      "epoch1 step17620 [D loss: -0.663501] [G loss: 3.594763]\n",
      "epoch1 step17625 [D loss: -0.299588] [G loss: 3.720955]\n",
      "epoch1 step17630 [D loss: -0.813596] [G loss: 2.876492]\n",
      "epoch1 step17635 [D loss: -1.161781] [G loss: 3.443769]\n",
      "epoch1 step17640 [D loss: -0.455470] [G loss: 2.740489]\n",
      "epoch1 step17645 [D loss: -0.292526] [G loss: 3.029451]\n",
      "epoch1 step17650 [D loss: -1.100860] [G loss: 2.309132]\n",
      "epoch1 step17655 [D loss: -0.692184] [G loss: 2.636846]\n",
      "epoch1 step17660 [D loss: -0.032210] [G loss: 2.449805]\n",
      "epoch1 step17665 [D loss: -0.686093] [G loss: 2.567140]\n",
      "epoch1 step17670 [D loss: 0.405908] [G loss: 2.160001]\n",
      "epoch1 step17675 [D loss: -0.629428] [G loss: 2.281687]\n",
      "epoch1 step17680 [D loss: -1.090546] [G loss: 2.327066]\n",
      "epoch1 step17685 [D loss: -1.031391] [G loss: 2.590653]\n",
      "epoch1 step17690 [D loss: -1.442847] [G loss: 2.585434]\n",
      "epoch1 step17695 [D loss: -0.752349] [G loss: 2.317147]\n",
      "epoch1 step17700 [D loss: -1.320626] [G loss: 2.657975]\n",
      "epoch1 step17705 [D loss: -0.423807] [G loss: 2.852983]\n",
      "epoch1 step17710 [D loss: 0.026459] [G loss: 2.271517]\n",
      "epoch1 step17715 [D loss: 0.235352] [G loss: 3.309042]\n",
      "epoch1 step17720 [D loss: 0.494090] [G loss: 2.807343]\n",
      "epoch1 step17725 [D loss: -0.267682] [G loss: 2.734234]\n",
      "epoch1 step17730 [D loss: -0.003407] [G loss: 2.802210]\n",
      "epoch1 step17735 [D loss: 0.333321] [G loss: 2.522232]\n",
      "epoch1 step17740 [D loss: -0.055609] [G loss: 2.680871]\n",
      "epoch1 step17745 [D loss: 0.058218] [G loss: 3.013536]\n",
      "epoch1 step17750 [D loss: -0.600269] [G loss: 2.739594]\n",
      "epoch1 step17755 [D loss: -0.020433] [G loss: 2.730480]\n",
      "epoch1 step17760 [D loss: -1.647021] [G loss: 2.796555]\n",
      "epoch1 step17765 [D loss: -0.502412] [G loss: 2.559897]\n",
      "epoch1 step17770 [D loss: -0.992593] [G loss: 2.805197]\n",
      "epoch1 step17775 [D loss: -0.424644] [G loss: 2.362742]\n",
      "epoch1 step17780 [D loss: -0.581442] [G loss: 2.316293]\n",
      "epoch1 step17785 [D loss: -1.088114] [G loss: 2.400028]\n",
      "epoch1 step17790 [D loss: -1.894034] [G loss: 2.896484]\n",
      "epoch1 step17795 [D loss: 0.239131] [G loss: 2.347455]\n",
      "epoch1 step17800 [D loss: -0.392798] [G loss: 3.442608]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.032274\n",
      "FID: 31.780365\n",
      "0 = 12.967570523118965\n",
      "1 = 0.10358239665468508\n",
      "2 = 0.8646000027656555\n",
      "3 = 0.9233999848365784\n",
      "4 = 0.8058000206947327\n",
      "5 = 0.8262348175048828\n",
      "6 = 0.9233999848365784\n",
      "7 = 8.674073711693273\n",
      "8 = 0.11111966073733473\n",
      "9 = 0.8294000029563904\n",
      "10 = 0.8560000061988831\n",
      "11 = 0.8027999997138977\n",
      "12 = 0.812761127948761\n",
      "13 = 0.8560000061988831\n",
      "14 = 6.03230094909668\n",
      "15 = 9.338116645812988\n",
      "16 = 0.18931283056735992\n",
      "17 = 6.03227424621582\n",
      "18 = 31.780364990234375\n",
      "epoch1 step17805 [D loss: -1.474047] [G loss: 3.341738]\n",
      "epoch1 step17810 [D loss: -0.224122] [G loss: 2.926981]\n",
      "epoch1 step17815 [D loss: -1.250757] [G loss: 2.832256]\n",
      "epoch1 step17820 [D loss: -0.652173] [G loss: 3.464023]\n",
      "epoch1 step17825 [D loss: 0.017387] [G loss: 3.797495]\n",
      "epoch1 step17830 [D loss: -0.796276] [G loss: 3.074780]\n",
      "epoch1 step17835 [D loss: -0.962051] [G loss: 3.426653]\n",
      "epoch1 step17840 [D loss: -0.642429] [G loss: 2.906972]\n",
      "epoch1 step17845 [D loss: 0.763250] [G loss: 2.806713]\n",
      "epoch1 step17850 [D loss: -0.680297] [G loss: 3.019582]\n",
      "epoch1 step17855 [D loss: -0.481952] [G loss: 3.208058]\n",
      "epoch1 step17860 [D loss: -0.490568] [G loss: 2.973196]\n",
      "epoch1 step17865 [D loss: -1.138310] [G loss: 2.611588]\n",
      "epoch1 step17870 [D loss: -1.680831] [G loss: 2.736529]\n",
      "epoch1 step17875 [D loss: -1.302676] [G loss: 3.547399]\n",
      "epoch1 step17880 [D loss: -0.987882] [G loss: 3.545580]\n",
      "epoch1 step17885 [D loss: -0.903248] [G loss: 2.617410]\n",
      "epoch1 step17890 [D loss: -0.947290] [G loss: 2.833751]\n",
      "epoch1 step17895 [D loss: -1.240630] [G loss: 2.899544]\n",
      "epoch1 step17900 [D loss: -1.151101] [G loss: 3.744111]\n",
      "epoch1 step17905 [D loss: -0.687722] [G loss: 3.151999]\n",
      "epoch1 step17910 [D loss: -1.030905] [G loss: 2.486508]\n",
      "epoch1 step17915 [D loss: -1.083650] [G loss: 3.906871]\n",
      "epoch1 step17920 [D loss: -0.872413] [G loss: 3.338295]\n",
      "epoch1 step17925 [D loss: -0.787536] [G loss: 3.827820]\n",
      "epoch1 step17930 [D loss: -0.575509] [G loss: 4.096809]\n",
      "epoch1 step17935 [D loss: -1.374852] [G loss: 3.784588]\n",
      "epoch1 step17940 [D loss: -0.107648] [G loss: 2.852530]\n",
      "epoch1 step17945 [D loss: -0.671757] [G loss: 3.231000]\n",
      "epoch1 step17950 [D loss: -0.380435] [G loss: 3.627983]\n",
      "epoch1 step17955 [D loss: 0.728295] [G loss: 3.752514]\n",
      "epoch1 step17960 [D loss: -0.639608] [G loss: 4.187999]\n",
      "epoch1 step17965 [D loss: -0.123045] [G loss: 3.935273]\n",
      "epoch1 step17970 [D loss: 0.247057] [G loss: 3.587044]\n",
      "epoch1 step17975 [D loss: -1.042212] [G loss: 4.490982]\n",
      "epoch1 step17980 [D loss: -0.446958] [G loss: 4.314602]\n",
      "epoch1 step17985 [D loss: 0.336822] [G loss: 4.494278]\n",
      "epoch1 step17990 [D loss: -0.240895] [G loss: 4.793099]\n",
      "epoch1 step17995 [D loss: -0.389167] [G loss: 3.622086]\n",
      "epoch1 step18000 [D loss: -0.716841] [G loss: 4.585948]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.088558\n",
      "FID: 26.581846\n",
      "0 = 13.026486915731457\n",
      "1 = 0.06676074383741248\n",
      "2 = 0.8445000052452087\n",
      "3 = 0.9186000227928162\n",
      "4 = 0.7703999876976013\n",
      "5 = 0.8000348210334778\n",
      "6 = 0.9186000227928162\n",
      "7 = 8.378456205821031\n",
      "8 = 0.10104472886521747\n",
      "9 = 0.8241999745368958\n",
      "10 = 0.854200005531311\n",
      "11 = 0.7942000031471252\n",
      "12 = 0.8058490753173828\n",
      "13 = 0.854200005531311\n",
      "14 = 6.088584899902344\n",
      "15 = 9.21691608428955\n",
      "16 = 0.18969494104385376\n",
      "17 = 6.088557720184326\n",
      "18 = 26.581846237182617\n",
      "epoch1 step18005 [D loss: 0.750680] [G loss: 4.077931]\n",
      "epoch1 step18010 [D loss: -1.024056] [G loss: 4.334446]\n",
      "epoch1 step18015 [D loss: -1.063749] [G loss: 4.894740]\n",
      "epoch1 step18020 [D loss: -1.467136] [G loss: 4.769068]\n",
      "epoch1 step18025 [D loss: -1.043397] [G loss: 5.008889]\n",
      "epoch1 step18030 [D loss: -0.408261] [G loss: 4.675744]\n",
      "epoch1 step18035 [D loss: -0.673305] [G loss: 4.943510]\n",
      "epoch1 step18040 [D loss: -0.355118] [G loss: 4.686708]\n",
      "epoch1 step18045 [D loss: -1.509871] [G loss: 4.725027]\n",
      "epoch1 step18050 [D loss: -0.736452] [G loss: 5.266635]\n",
      "epoch1 step18055 [D loss: -0.693177] [G loss: 4.801722]\n",
      "epoch1 step18060 [D loss: -0.341861] [G loss: 5.171968]\n",
      "epoch1 step18065 [D loss: -0.259828] [G loss: 5.602912]\n",
      "epoch1 step18070 [D loss: -0.924655] [G loss: 5.620214]\n",
      "epoch1 step18075 [D loss: -0.330431] [G loss: 5.070623]\n",
      "epoch1 step18080 [D loss: -1.816633] [G loss: 5.722572]\n",
      "epoch1 step18085 [D loss: -0.610903] [G loss: 5.863033]\n",
      "epoch1 step18090 [D loss: -0.821017] [G loss: 5.632719]\n",
      "epoch1 step18095 [D loss: -0.363728] [G loss: 5.933078]\n",
      "epoch1 step18100 [D loss: -0.211302] [G loss: 5.121954]\n",
      "epoch1 step18105 [D loss: -0.578873] [G loss: 5.849349]\n",
      "epoch1 step18110 [D loss: -0.262160] [G loss: 5.158588]\n",
      "epoch1 step18115 [D loss: -0.283359] [G loss: 5.222237]\n",
      "epoch1 step18120 [D loss: -0.250086] [G loss: 4.604563]\n",
      "epoch1 step18125 [D loss: -0.754090] [G loss: 5.895381]\n",
      "epoch1 step18130 [D loss: -0.616528] [G loss: 4.890744]\n",
      "epoch1 step18135 [D loss: -0.023811] [G loss: 5.185619]\n",
      "epoch1 step18140 [D loss: -0.551263] [G loss: 4.995405]\n",
      "epoch1 step18145 [D loss: -0.702229] [G loss: 5.426993]\n",
      "epoch1 step18150 [D loss: -0.222708] [G loss: 4.829418]\n",
      "epoch1 step18155 [D loss: -0.715286] [G loss: 4.612700]\n",
      "epoch1 step18160 [D loss: -0.990128] [G loss: 4.970633]\n",
      "epoch1 step18165 [D loss: 0.142029] [G loss: 5.105802]\n",
      "epoch1 step18170 [D loss: -1.554848] [G loss: 5.699873]\n",
      "epoch1 step18175 [D loss: -0.344335] [G loss: 5.205673]\n",
      "epoch1 step18180 [D loss: -0.847841] [G loss: 5.147031]\n",
      "epoch1 step18185 [D loss: -0.468099] [G loss: 5.017315]\n",
      "epoch1 step18190 [D loss: -0.180051] [G loss: 4.963018]\n",
      "epoch1 step18195 [D loss: -0.774914] [G loss: 4.547266]\n",
      "epoch1 step18200 [D loss: -0.739958] [G loss: 5.288764]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.273865\n",
      "FID: 26.651558\n",
      "0 = 12.864414533329057\n",
      "1 = 0.07274735184401823\n",
      "2 = 0.8446000218391418\n",
      "3 = 0.9138000011444092\n",
      "4 = 0.7753999829292297\n",
      "5 = 0.8027055263519287\n",
      "6 = 0.9138000011444092\n",
      "7 = 8.358682074522962\n",
      "8 = 0.10260298416824674\n",
      "9 = 0.8238999843597412\n",
      "10 = 0.8474000096321106\n",
      "11 = 0.8004000186920166\n",
      "12 = 0.8093600869178772\n",
      "13 = 0.8474000096321106\n",
      "14 = 6.273889064788818\n",
      "15 = 9.327256202697754\n",
      "16 = 0.16793213784694672\n",
      "17 = 6.27386474609375\n",
      "18 = 26.65155792236328\n",
      "epoch1 step18205 [D loss: -1.027018] [G loss: 4.972839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 step18210 [D loss: -1.523164] [G loss: 4.601234]\n",
      "epoch1 step18215 [D loss: -0.644508] [G loss: 5.289176]\n",
      "epoch1 step18220 [D loss: -1.342544] [G loss: 5.506022]\n",
      "epoch1 step18225 [D loss: -1.309950] [G loss: 4.972464]\n",
      "epoch1 step18230 [D loss: -0.204686] [G loss: 5.120680]\n",
      "epoch1 step18235 [D loss: -1.586630] [G loss: 5.988533]\n",
      "epoch1 step18240 [D loss: -1.983504] [G loss: 5.692831]\n",
      "epoch1 step18245 [D loss: -0.696578] [G loss: 5.609623]\n",
      "epoch1 step18250 [D loss: -0.273362] [G loss: 5.671617]\n",
      "epoch1 step18255 [D loss: -1.232461] [G loss: 5.689946]\n",
      "epoch1 step18260 [D loss: -0.400626] [G loss: 4.871078]\n",
      "epoch1 step18265 [D loss: -0.990919] [G loss: 5.331460]\n",
      "epoch1 step18270 [D loss: -0.752359] [G loss: 5.175484]\n",
      "epoch1 step18275 [D loss: -1.105567] [G loss: 5.639173]\n",
      "epoch1 step18280 [D loss: 0.590906] [G loss: 5.550768]\n",
      "epoch1 step18285 [D loss: 0.918442] [G loss: 4.472809]\n",
      "epoch1 step18290 [D loss: 1.073916] [G loss: 5.384997]\n",
      "epoch1 step18295 [D loss: 0.850342] [G loss: 5.023259]\n",
      "epoch1 step18300 [D loss: -0.123695] [G loss: 3.995426]\n",
      "epoch1 step18305 [D loss: 0.078639] [G loss: 4.410376]\n",
      "epoch1 step18310 [D loss: -0.168443] [G loss: 4.774664]\n",
      "epoch1 step18315 [D loss: -0.309621] [G loss: 4.365632]\n",
      "epoch1 step18320 [D loss: -0.199233] [G loss: 4.907247]\n",
      "epoch1 step18325 [D loss: -0.217815] [G loss: 4.395506]\n",
      "epoch1 step18330 [D loss: -0.455530] [G loss: 4.761405]\n",
      "epoch1 step18335 [D loss: -0.285124] [G loss: 3.981648]\n",
      "epoch1 step18340 [D loss: -0.773541] [G loss: 4.691973]\n",
      "epoch1 step18345 [D loss: -0.809363] [G loss: 4.321434]\n",
      "epoch1 step18350 [D loss: -1.018504] [G loss: 4.509672]\n",
      "epoch1 step18355 [D loss: -0.568628] [G loss: 4.632959]\n",
      "epoch1 step18360 [D loss: -0.325680] [G loss: 4.798089]\n",
      "epoch1 step18365 [D loss: -0.579718] [G loss: 4.076540]\n",
      "epoch1 step18370 [D loss: -1.665141] [G loss: 3.943460]\n",
      "epoch1 step18375 [D loss: -0.222267] [G loss: 4.755194]\n",
      "epoch1 step18380 [D loss: -0.758906] [G loss: 4.055974]\n",
      "epoch1 step18385 [D loss: -0.725067] [G loss: 3.910717]\n",
      "epoch1 step18390 [D loss: -1.084260] [G loss: 4.032945]\n",
      "epoch1 step18395 [D loss: -1.072554] [G loss: 4.302494]\n",
      "epoch1 step18400 [D loss: 1.086759] [G loss: 3.880041]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.430351\n",
      "FID: 21.006176\n",
      "0 = 12.902450514078142\n",
      "1 = 0.056282754474465\n",
      "2 = 0.8155999779701233\n",
      "3 = 0.9204000234603882\n",
      "4 = 0.7107999920845032\n",
      "5 = 0.7609127163887024\n",
      "6 = 0.9204000234603882\n",
      "7 = 7.962535694575328\n",
      "8 = 0.0856756208269853\n",
      "9 = 0.7907999753952026\n",
      "10 = 0.8324000239372253\n",
      "11 = 0.7491999864578247\n",
      "12 = 0.7684637904167175\n",
      "13 = 0.8324000239372253\n",
      "14 = 6.430373191833496\n",
      "15 = 9.316328048706055\n",
      "16 = 0.16949959099292755\n",
      "17 = 6.4303507804870605\n",
      "18 = 21.006175994873047\n",
      "epoch1 step18405 [D loss: -0.749107] [G loss: 4.369047]\n",
      "epoch1 step18410 [D loss: 0.155773] [G loss: 4.338603]\n",
      "epoch1 step18415 [D loss: -0.261262] [G loss: 4.670727]\n",
      "epoch1 step18420 [D loss: -0.334189] [G loss: 4.692877]\n",
      "epoch1 step18425 [D loss: 1.177759] [G loss: 3.967818]\n",
      "epoch1 step18430 [D loss: 0.006821] [G loss: 3.236426]\n",
      "epoch1 step18435 [D loss: -0.433477] [G loss: 4.058674]\n",
      "epoch1 step18440 [D loss: -0.343898] [G loss: 4.365469]\n",
      "epoch1 step18445 [D loss: 0.179910] [G loss: 4.131547]\n",
      "epoch1 step18450 [D loss: -1.482235] [G loss: 4.035481]\n",
      "epoch1 step18455 [D loss: -1.029113] [G loss: 4.338655]\n",
      "epoch1 step18460 [D loss: -1.127709] [G loss: 4.570719]\n",
      "epoch1 step18465 [D loss: -0.194773] [G loss: 3.936311]\n",
      "epoch1 step18470 [D loss: -1.187606] [G loss: 3.750091]\n",
      "epoch1 step18475 [D loss: -0.820400] [G loss: 4.097887]\n",
      "epoch1 step18480 [D loss: -0.435315] [G loss: 3.932235]\n",
      "epoch1 step18485 [D loss: -1.504030] [G loss: 4.272618]\n",
      "epoch1 step18490 [D loss: -1.399420] [G loss: 3.517905]\n",
      "epoch1 step18495 [D loss: -2.389100] [G loss: 3.310802]\n",
      "epoch1 step18500 [D loss: -1.325783] [G loss: 3.472404]\n",
      "epoch1 step18505 [D loss: -0.322850] [G loss: 4.003927]\n",
      "epoch1 step18510 [D loss: -0.839462] [G loss: 3.778841]\n",
      "epoch1 step18515 [D loss: -0.321190] [G loss: 3.766334]\n",
      "epoch1 step18520 [D loss: -1.487126] [G loss: 4.263776]\n",
      "epoch1 step18525 [D loss: -1.019686] [G loss: 3.339919]\n",
      "epoch1 step18530 [D loss: 0.343085] [G loss: 3.259729]\n",
      "epoch1 step18535 [D loss: -0.822242] [G loss: 3.868014]\n",
      "epoch1 step18540 [D loss: -0.829588] [G loss: 2.723420]\n",
      "epoch1 step18545 [D loss: -0.956898] [G loss: 2.412984]\n",
      "epoch1 step18550 [D loss: -1.374252] [G loss: 2.309115]\n",
      "epoch1 step18555 [D loss: -1.871319] [G loss: 2.789522]\n",
      "epoch1 step18560 [D loss: -0.640029] [G loss: 1.892689]\n",
      "epoch1 step18565 [D loss: -0.632855] [G loss: 1.859586]\n",
      "epoch1 step18570 [D loss: 1.094069] [G loss: 3.107840]\n",
      "epoch1 step18575 [D loss: 0.451100] [G loss: 2.599924]\n",
      "epoch1 step18580 [D loss: 0.404333] [G loss: 2.652561]\n",
      "epoch1 step18585 [D loss: -0.746661] [G loss: 2.710237]\n",
      "epoch1 step18590 [D loss: -1.180608] [G loss: 2.262821]\n",
      "epoch1 step18595 [D loss: -2.272320] [G loss: 2.855928]\n",
      "epoch1 step18600 [D loss: -1.610021] [G loss: 1.778691]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.371503\n",
      "FID: 22.296614\n",
      "0 = 13.032951471233314\n",
      "1 = 0.07421714379429728\n",
      "2 = 0.8235999941825867\n",
      "3 = 0.9192000031471252\n",
      "4 = 0.7279999852180481\n",
      "5 = 0.7716588377952576\n",
      "6 = 0.9192000031471252\n",
      "7 = 8.156384907746316\n",
      "8 = 0.09037359157957968\n",
      "9 = 0.7946000099182129\n",
      "10 = 0.8353999853134155\n",
      "11 = 0.7537999749183655\n",
      "12 = 0.7723742723464966\n",
      "13 = 0.8353999853134155\n",
      "14 = 6.371528625488281\n",
      "15 = 9.302403450012207\n",
      "16 = 0.17652180790901184\n",
      "17 = 6.371502876281738\n",
      "18 = 22.296613693237305\n",
      "epoch1 step18605 [D loss: -1.580201] [G loss: 2.436179]\n",
      "epoch1 step18610 [D loss: -1.202802] [G loss: 1.720330]\n",
      "epoch1 step18615 [D loss: -2.079601] [G loss: 2.088954]\n",
      "epoch1 step18620 [D loss: -1.605216] [G loss: 2.039121]\n",
      "epoch1 step18625 [D loss: -1.338855] [G loss: 1.500037]\n",
      "epoch1 step18630 [D loss: -1.197734] [G loss: 0.707442]\n",
      "epoch1 step18635 [D loss: -1.324625] [G loss: 1.421921]\n",
      "epoch1 step18640 [D loss: -2.657929] [G loss: 1.931883]\n",
      "epoch1 step18645 [D loss: -1.741650] [G loss: 0.977345]\n",
      "epoch1 step18650 [D loss: -0.903958] [G loss: 1.612506]\n",
      "epoch1 step18655 [D loss: 2.004560] [G loss: 1.613963]\n",
      "epoch1 step18660 [D loss: -0.002919] [G loss: 1.478153]\n",
      "epoch1 step18665 [D loss: -0.318772] [G loss: 2.522221]\n",
      "epoch1 step18670 [D loss: -0.730840] [G loss: 2.320832]\n",
      "epoch1 step18675 [D loss: -0.939171] [G loss: 1.741876]\n",
      "epoch1 step18680 [D loss: -0.454215] [G loss: 2.056659]\n",
      "epoch1 step18685 [D loss: -1.396131] [G loss: 2.224562]\n",
      "epoch1 step18690 [D loss: -0.506083] [G loss: 1.882657]\n",
      "epoch1 step18695 [D loss: -1.388804] [G loss: 1.952725]\n",
      "epoch1 step18700 [D loss: -1.387197] [G loss: 1.032824]\n",
      "epoch1 step18705 [D loss: -1.750935] [G loss: 1.210950]\n",
      "epoch1 step18710 [D loss: -1.329234] [G loss: 1.181753]\n",
      "epoch1 step18715 [D loss: -1.347696] [G loss: 1.070637]\n",
      "epoch1 step18720 [D loss: -1.344298] [G loss: 1.359947]\n",
      "epoch1 step18725 [D loss: 0.349490] [G loss: 0.302538]\n",
      "epoch1 step18730 [D loss: -2.512354] [G loss: 0.703129]\n",
      "epoch1 step18735 [D loss: -1.743531] [G loss: 0.772355]\n",
      "epoch1 step18740 [D loss: -1.841189] [G loss: -0.029730]\n",
      "epoch1 step18745 [D loss: -2.204168] [G loss: 0.685329]\n",
      "epoch1 step18750 [D loss: -1.966874] [G loss: 0.732925]\n",
      "epoch2 step18755 [D loss: 0.076523] [G loss: 1.537634]\n",
      "epoch2 step18760 [D loss: 0.509796] [G loss: 1.396177]\n",
      "epoch2 step18765 [D loss: 0.203254] [G loss: 1.136291]\n",
      "epoch2 step18770 [D loss: 0.806121] [G loss: 1.295061]\n",
      "epoch2 step18775 [D loss: -0.734896] [G loss: 1.799853]\n",
      "epoch2 step18780 [D loss: -0.089134] [G loss: 1.813909]\n",
      "epoch2 step18785 [D loss: 0.106741] [G loss: 0.424164]\n",
      "epoch2 step18790 [D loss: 0.074748] [G loss: 1.402074]\n",
      "epoch2 step18795 [D loss: 0.293329] [G loss: 2.007054]\n",
      "epoch2 step18800 [D loss: 0.122354] [G loss: 1.712754]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.161397\n",
      "FID: 28.690729\n",
      "0 = 13.179624657344766\n",
      "1 = 0.1124632669454713\n",
      "2 = 0.8585000038146973\n",
      "3 = 0.9103999733924866\n",
      "4 = 0.8065999746322632\n",
      "5 = 0.8247870802879333\n",
      "6 = 0.9103999733924866\n",
      "7 = 8.452639378511911\n",
      "8 = 0.10664055792837863\n",
      "9 = 0.824999988079071\n",
      "10 = 0.843999981880188\n",
      "11 = 0.8059999942779541\n",
      "12 = 0.813102126121521\n",
      "13 = 0.843999981880188\n",
      "14 = 6.161420822143555\n",
      "15 = 9.42332649230957\n",
      "16 = 0.16136041283607483\n",
      "17 = 6.161397457122803\n",
      "18 = 28.69072914123535\n",
      "epoch2 step18805 [D loss: -0.735021] [G loss: 1.938889]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2 step18810 [D loss: -0.094631] [G loss: 1.716181]\n",
      "epoch2 step18815 [D loss: -1.200427] [G loss: 1.465670]\n",
      "epoch2 step18820 [D loss: -0.041240] [G loss: 1.256876]\n",
      "epoch2 step18825 [D loss: -0.551678] [G loss: 2.373036]\n",
      "epoch2 step18830 [D loss: -0.884641] [G loss: 2.184572]\n",
      "epoch2 step18835 [D loss: -0.129130] [G loss: 2.124436]\n",
      "epoch2 step18840 [D loss: -0.516307] [G loss: 2.546764]\n",
      "epoch2 step18845 [D loss: -0.834892] [G loss: 1.853416]\n",
      "epoch2 step18850 [D loss: 0.622669] [G loss: 2.613356]\n",
      "epoch2 step18855 [D loss: -0.323565] [G loss: 2.249964]\n",
      "epoch2 step18860 [D loss: 0.540972] [G loss: 2.214070]\n",
      "epoch2 step18865 [D loss: -0.643604] [G loss: 2.211092]\n",
      "epoch2 step18870 [D loss: -0.140480] [G loss: 2.478733]\n",
      "epoch2 step18875 [D loss: -0.711712] [G loss: 2.614985]\n",
      "epoch2 step18880 [D loss: 0.011622] [G loss: 2.944768]\n",
      "epoch2 step18885 [D loss: -0.847821] [G loss: 3.096925]\n",
      "epoch2 step18890 [D loss: -0.118153] [G loss: 2.243008]\n",
      "epoch2 step18895 [D loss: -0.581760] [G loss: 2.242461]\n",
      "epoch2 step18900 [D loss: -0.198741] [G loss: 2.076913]\n",
      "epoch2 step18905 [D loss: 0.673422] [G loss: 1.926933]\n",
      "epoch2 step18910 [D loss: 0.039414] [G loss: 2.267469]\n",
      "epoch2 step18915 [D loss: -0.145955] [G loss: 3.342025]\n",
      "epoch2 step18920 [D loss: -0.668570] [G loss: 3.361343]\n",
      "epoch2 step18925 [D loss: -0.647328] [G loss: 2.770419]\n",
      "epoch2 step18930 [D loss: -0.716807] [G loss: 3.073904]\n",
      "epoch2 step18935 [D loss: -0.618700] [G loss: 3.243528]\n",
      "epoch2 step18940 [D loss: 0.760315] [G loss: 3.455218]\n",
      "epoch2 step18945 [D loss: 0.346268] [G loss: 3.286774]\n",
      "epoch2 step18950 [D loss: -0.226243] [G loss: 3.036394]\n",
      "epoch2 step18955 [D loss: -0.615662] [G loss: 2.954328]\n",
      "epoch2 step18960 [D loss: 0.341113] [G loss: 2.363903]\n",
      "epoch2 step18965 [D loss: 1.109518] [G loss: 3.310178]\n",
      "epoch2 step18970 [D loss: -0.878831] [G loss: 3.437340]\n",
      "epoch2 step18975 [D loss: -0.331657] [G loss: 3.953909]\n",
      "epoch2 step18980 [D loss: -0.172296] [G loss: 3.175811]\n",
      "epoch2 step18985 [D loss: -0.259711] [G loss: 3.794491]\n",
      "epoch2 step18990 [D loss: 0.398862] [G loss: 3.996957]\n",
      "epoch2 step18995 [D loss: -0.554044] [G loss: 3.757398]\n",
      "epoch2 step19000 [D loss: -0.277769] [G loss: 3.338440]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.227539\n",
      "FID: 22.037558\n",
      "0 = 14.504761558532724\n",
      "1 = 0.17120751905150938\n",
      "2 = 0.8680999875068665\n",
      "3 = 0.9380000233650208\n",
      "4 = 0.7982000112533569\n",
      "5 = 0.8229513764381409\n",
      "6 = 0.9380000233650208\n",
      "7 = 8.333644957017881\n",
      "8 = 0.09312420838294778\n",
      "9 = 0.8183000087738037\n",
      "10 = 0.8533999919891357\n",
      "11 = 0.7832000255584717\n",
      "12 = 0.7974210381507874\n",
      "13 = 0.8533999919891357\n",
      "14 = 6.227563858032227\n",
      "15 = 9.134819030761719\n",
      "16 = 0.19741150736808777\n",
      "17 = 6.227538585662842\n",
      "18 = 22.03755760192871\n",
      "epoch2 step19005 [D loss: -0.109797] [G loss: 3.378715]\n",
      "epoch2 step19010 [D loss: -0.386268] [G loss: 4.182858]\n",
      "epoch2 step19015 [D loss: -0.803490] [G loss: 4.107562]\n",
      "epoch2 step19020 [D loss: -0.541660] [G loss: 4.618221]\n",
      "epoch2 step19025 [D loss: -1.142974] [G loss: 4.164199]\n",
      "epoch2 step19030 [D loss: -0.825657] [G loss: 4.554128]\n",
      "epoch2 step19035 [D loss: -0.393190] [G loss: 4.414860]\n",
      "epoch2 step19040 [D loss: -0.900622] [G loss: 5.022577]\n",
      "epoch2 step19045 [D loss: -1.685782] [G loss: 5.322418]\n",
      "epoch2 step19050 [D loss: -0.330637] [G loss: 5.419841]\n",
      "epoch2 step19055 [D loss: -1.222792] [G loss: 4.565812]\n",
      "epoch2 step19060 [D loss: -0.905050] [G loss: 4.582951]\n",
      "epoch2 step19065 [D loss: -1.241787] [G loss: 5.372293]\n",
      "epoch2 step19070 [D loss: -0.574481] [G loss: 4.956513]\n",
      "epoch2 step19075 [D loss: -0.220114] [G loss: 5.116053]\n",
      "epoch2 step19080 [D loss: -1.034164] [G loss: 5.174858]\n",
      "epoch2 step19085 [D loss: -1.264834] [G loss: 5.546950]\n",
      "epoch2 step19090 [D loss: -1.993259] [G loss: 6.311673]\n",
      "epoch2 step19095 [D loss: -1.727965] [G loss: 5.421936]\n",
      "epoch2 step19100 [D loss: -1.944016] [G loss: 6.333338]\n",
      "epoch2 step19105 [D loss: -1.476933] [G loss: 5.784502]\n",
      "epoch2 step19110 [D loss: -1.664799] [G loss: 5.132162]\n",
      "epoch2 step19115 [D loss: -0.762583] [G loss: 6.318971]\n",
      "epoch2 step19120 [D loss: -0.251691] [G loss: 5.767519]\n",
      "epoch2 step19125 [D loss: -0.051667] [G loss: 5.931871]\n",
      "epoch2 step19130 [D loss: -0.415027] [G loss: 5.747553]\n",
      "epoch2 step19135 [D loss: 0.504356] [G loss: 5.370011]\n",
      "epoch2 step19140 [D loss: -0.343646] [G loss: 6.002083]\n",
      "epoch2 step19145 [D loss: -0.741073] [G loss: 5.766805]\n",
      "epoch2 step19150 [D loss: -0.478884] [G loss: 6.075388]\n",
      "epoch2 step19155 [D loss: -0.634938] [G loss: 5.750034]\n",
      "epoch2 step19160 [D loss: -1.568573] [G loss: 5.456528]\n",
      "epoch2 step19165 [D loss: -0.324132] [G loss: 5.934212]\n",
      "epoch2 step19170 [D loss: -0.606989] [G loss: 5.781243]\n",
      "epoch2 step19175 [D loss: -0.451717] [G loss: 5.935271]\n",
      "epoch2 step19180 [D loss: -1.032865] [G loss: 5.651784]\n",
      "epoch2 step19185 [D loss: -2.266292] [G loss: 6.963371]\n",
      "epoch2 step19190 [D loss: -1.818685] [G loss: 6.935579]\n",
      "epoch2 step19195 [D loss: -0.494459] [G loss: 5.570024]\n",
      "epoch2 step19200 [D loss: -1.336561] [G loss: 6.530786]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.255016\n",
      "FID: 22.338966\n",
      "0 = 14.054360476493853\n",
      "1 = 0.1385144696991619\n",
      "2 = 0.858299970626831\n",
      "3 = 0.9326000213623047\n",
      "4 = 0.7839999794960022\n",
      "5 = 0.8119449615478516\n",
      "6 = 0.9326000213623047\n",
      "7 = 8.261818045139297\n",
      "8 = 0.09355588525949082\n",
      "9 = 0.8144999742507935\n",
      "10 = 0.8461999893188477\n",
      "11 = 0.782800018787384\n",
      "12 = 0.7957494854927063\n",
      "13 = 0.8461999893188477\n",
      "14 = 6.255044937133789\n",
      "15 = 8.980062484741211\n",
      "16 = 0.21609215438365936\n",
      "17 = 6.255016326904297\n",
      "18 = 22.338966369628906\n",
      "epoch2 step19205 [D loss: -0.559732] [G loss: 7.311563]\n",
      "epoch2 step19210 [D loss: -0.224826] [G loss: 7.434721]\n",
      "epoch2 step19215 [D loss: 0.238354] [G loss: 6.357090]\n",
      "epoch2 step19220 [D loss: -0.312593] [G loss: 6.754579]\n",
      "epoch2 step19225 [D loss: -0.264533] [G loss: 6.052391]\n",
      "epoch2 step19230 [D loss: -0.039412] [G loss: 6.160822]\n",
      "epoch2 step19235 [D loss: 0.554720] [G loss: 6.787385]\n",
      "epoch2 step19240 [D loss: -0.829159] [G loss: 6.145018]\n",
      "epoch2 step19245 [D loss: -0.136455] [G loss: 5.879288]\n",
      "epoch2 step19250 [D loss: 0.405929] [G loss: 5.821486]\n",
      "epoch2 step19255 [D loss: -0.584586] [G loss: 6.113634]\n",
      "epoch2 step19260 [D loss: -0.159510] [G loss: 5.777847]\n",
      "epoch2 step19265 [D loss: -0.086879] [G loss: 6.311420]\n",
      "epoch2 step19270 [D loss: -0.668815] [G loss: 5.632978]\n",
      "epoch2 step19275 [D loss: -1.051829] [G loss: 5.077368]\n",
      "epoch2 step19280 [D loss: -0.927409] [G loss: 6.125010]\n",
      "epoch2 step19285 [D loss: -0.954734] [G loss: 6.400804]\n",
      "epoch2 step19290 [D loss: -0.239727] [G loss: 5.331087]\n",
      "epoch2 step19295 [D loss: -1.399466] [G loss: 5.400820]\n",
      "epoch2 step19300 [D loss: -1.012446] [G loss: 6.463951]\n",
      "epoch2 step19305 [D loss: -0.867411] [G loss: 5.695797]\n",
      "epoch2 step19310 [D loss: -0.933102] [G loss: 6.109596]\n",
      "epoch2 step19315 [D loss: -0.994163] [G loss: 6.783581]\n",
      "epoch2 step19320 [D loss: 0.138458] [G loss: 6.320186]\n",
      "epoch2 step19325 [D loss: 0.313337] [G loss: 6.404624]\n",
      "epoch2 step19330 [D loss: -1.434413] [G loss: 6.507991]\n",
      "epoch2 step19335 [D loss: -1.370462] [G loss: 6.762597]\n",
      "epoch2 step19340 [D loss: -0.937978] [G loss: 6.660318]\n",
      "epoch2 step19345 [D loss: -1.109218] [G loss: 6.637530]\n",
      "epoch2 step19350 [D loss: -0.566967] [G loss: 6.236396]\n",
      "epoch2 step19355 [D loss: -0.027051] [G loss: 6.413845]\n",
      "epoch2 step19360 [D loss: -1.103851] [G loss: 5.936965]\n",
      "epoch2 step19365 [D loss: -1.132986] [G loss: 6.230197]\n",
      "epoch2 step19370 [D loss: -0.691531] [G loss: 7.018521]\n",
      "epoch2 step19375 [D loss: -0.727170] [G loss: 5.841172]\n",
      "epoch2 step19380 [D loss: -0.745907] [G loss: 5.166351]\n",
      "epoch2 step19385 [D loss: -0.450021] [G loss: 5.782755]\n",
      "epoch2 step19390 [D loss: -0.005357] [G loss: 5.493063]\n",
      "epoch2 step19395 [D loss: -0.306637] [G loss: 5.930847]\n",
      "epoch2 step19400 [D loss: -0.525394] [G loss: 5.425802]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.503193\n",
      "FID: 17.946327\n",
      "0 = 13.732521299123723\n",
      "1 = 0.10798469834188902\n",
      "2 = 0.8197000026702881\n",
      "3 = 0.9381999969482422\n",
      "4 = 0.701200008392334\n",
      "5 = 0.7584478855133057\n",
      "6 = 0.9381999969482422\n",
      "7 = 8.023317672967895\n",
      "8 = 0.08065439678961453\n",
      "9 = 0.7912999987602234\n",
      "10 = 0.8424000144004822\n",
      "11 = 0.7401999831199646\n",
      "12 = 0.7642896175384521\n",
      "13 = 0.8424000144004822\n",
      "14 = 6.503223896026611\n",
      "15 = 9.251249313354492\n",
      "16 = 0.17312611639499664\n",
      "17 = 6.503193378448486\n",
      "18 = 17.946327209472656\n",
      "epoch2 step19405 [D loss: -0.507588] [G loss: 5.294470]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2 step19410 [D loss: -0.250375] [G loss: 5.295011]\n",
      "epoch2 step19415 [D loss: -0.959167] [G loss: 5.174724]\n",
      "epoch2 step19420 [D loss: -0.311875] [G loss: 5.171381]\n",
      "epoch2 step19425 [D loss: -0.262848] [G loss: 5.042976]\n",
      "epoch2 step19430 [D loss: -0.934055] [G loss: 5.949934]\n",
      "epoch2 step19435 [D loss: -0.802307] [G loss: 4.709016]\n",
      "epoch2 step19440 [D loss: 0.529117] [G loss: 4.719538]\n",
      "epoch2 step19445 [D loss: -0.124777] [G loss: 5.210021]\n",
      "epoch2 step19450 [D loss: -0.796874] [G loss: 4.835960]\n",
      "epoch2 step19455 [D loss: 0.309683] [G loss: 5.028053]\n",
      "epoch2 step19460 [D loss: -0.230910] [G loss: 4.882609]\n",
      "epoch2 step19465 [D loss: -0.379643] [G loss: 4.622582]\n",
      "epoch2 step19470 [D loss: -0.759209] [G loss: 4.865193]\n",
      "epoch2 step19475 [D loss: -0.393804] [G loss: 5.736609]\n",
      "epoch2 step19480 [D loss: -0.908192] [G loss: 4.897458]\n",
      "epoch2 step19485 [D loss: -0.901999] [G loss: 5.080070]\n",
      "epoch2 step19490 [D loss: -0.902147] [G loss: 5.521368]\n",
      "epoch2 step19495 [D loss: -0.987427] [G loss: 4.750596]\n",
      "epoch2 step19500 [D loss: -2.110886] [G loss: 5.687026]\n",
      "epoch2 step19505 [D loss: -0.360773] [G loss: 5.085228]\n",
      "epoch2 step19510 [D loss: -1.531861] [G loss: 5.736592]\n",
      "epoch2 step19515 [D loss: -1.622329] [G loss: 5.687082]\n",
      "epoch2 step19520 [D loss: -1.144480] [G loss: 5.881045]\n",
      "epoch2 step19525 [D loss: 0.287412] [G loss: 6.106412]\n",
      "epoch2 step19530 [D loss: 0.605860] [G loss: 6.297913]\n",
      "epoch2 step19535 [D loss: -0.594395] [G loss: 6.432129]\n",
      "epoch2 step19540 [D loss: 0.792167] [G loss: 6.054347]\n",
      "epoch2 step19545 [D loss: 0.228442] [G loss: 5.820810]\n",
      "epoch2 step19550 [D loss: -0.127205] [G loss: 5.287608]\n",
      "epoch2 step19555 [D loss: 0.386312] [G loss: 5.531700]\n",
      "epoch2 step19560 [D loss: -0.378517] [G loss: 5.419079]\n",
      "epoch2 step19565 [D loss: -0.146858] [G loss: 5.423455]\n",
      "epoch2 step19570 [D loss: 0.253275] [G loss: 5.249747]\n",
      "epoch2 step19575 [D loss: -0.684921] [G loss: 5.419287]\n",
      "epoch2 step19580 [D loss: 0.649452] [G loss: 4.834089]\n",
      "epoch2 step19585 [D loss: -0.334664] [G loss: 4.924729]\n",
      "epoch2 step19590 [D loss: -0.556929] [G loss: 4.704103]\n",
      "epoch2 step19595 [D loss: -0.735966] [G loss: 5.195254]\n",
      "epoch2 step19600 [D loss: -0.289670] [G loss: 4.433969]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.372728\n",
      "FID: 20.760643\n",
      "0 = 14.207910823726651\n",
      "1 = 0.1461813271512981\n",
      "2 = 0.8258000016212463\n",
      "3 = 0.9485999941825867\n",
      "4 = 0.703000009059906\n",
      "5 = 0.7615606784820557\n",
      "6 = 0.9485999941825867\n",
      "7 = 8.14201683869361\n",
      "8 = 0.08889401209160372\n",
      "9 = 0.8008000254631042\n",
      "10 = 0.843999981880188\n",
      "11 = 0.7576000094413757\n",
      "12 = 0.776877760887146\n",
      "13 = 0.843999981880188\n",
      "14 = 6.3727545738220215\n",
      "15 = 9.044499397277832\n",
      "16 = 0.20754924416542053\n",
      "17 = 6.372727870941162\n",
      "18 = 20.760643005371094\n",
      "epoch2 step19605 [D loss: -1.298805] [G loss: 4.100798]\n",
      "epoch2 step19610 [D loss: -1.047189] [G loss: 4.826581]\n",
      "epoch2 step19615 [D loss: 0.116484] [G loss: 4.607545]\n",
      "epoch2 step19620 [D loss: 0.172579] [G loss: 4.221124]\n",
      "epoch2 step19625 [D loss: -0.230662] [G loss: 3.598661]\n",
      "epoch2 step19630 [D loss: -0.984395] [G loss: 4.396367]\n",
      "epoch2 step19635 [D loss: -0.632761] [G loss: 5.205720]\n",
      "epoch2 step19640 [D loss: -1.046936] [G loss: 4.225511]\n",
      "epoch2 step19645 [D loss: -1.153244] [G loss: 4.688761]\n",
      "epoch2 step19650 [D loss: -0.306459] [G loss: 3.742604]\n",
      "epoch2 step19655 [D loss: -0.772094] [G loss: 3.558027]\n",
      "epoch2 step19660 [D loss: -0.966175] [G loss: 3.348304]\n",
      "epoch2 step19665 [D loss: -1.086751] [G loss: 4.381127]\n",
      "epoch2 step19670 [D loss: -1.564596] [G loss: 3.319158]\n",
      "epoch2 step19675 [D loss: -1.890603] [G loss: 3.491428]\n",
      "epoch2 step19680 [D loss: -1.717119] [G loss: 3.126766]\n",
      "epoch2 step19685 [D loss: -2.139087] [G loss: 2.354701]\n",
      "epoch2 step19690 [D loss: -0.509653] [G loss: 3.196768]\n",
      "epoch2 step19695 [D loss: -0.124732] [G loss: 2.367612]\n",
      "epoch2 step19700 [D loss: -0.435586] [G loss: 2.751700]\n",
      "epoch2 step19705 [D loss: -0.722049] [G loss: 3.214373]\n",
      "epoch2 step19710 [D loss: -1.259228] [G loss: 3.333892]\n",
      "epoch2 step19715 [D loss: -0.140385] [G loss: 2.910340]\n",
      "epoch2 step19720 [D loss: -0.887661] [G loss: 2.383887]\n",
      "epoch2 step19725 [D loss: -0.305750] [G loss: 2.673941]\n",
      "epoch2 step19730 [D loss: -0.753914] [G loss: 2.489089]\n",
      "epoch2 step19735 [D loss: -0.796267] [G loss: 3.366546]\n",
      "epoch2 step19740 [D loss: -1.572497] [G loss: 2.783667]\n",
      "epoch2 step19745 [D loss: 0.152010] [G loss: 2.855805]\n",
      "epoch2 step19750 [D loss: -1.001832] [G loss: 2.210343]\n",
      "epoch2 step19755 [D loss: -1.216505] [G loss: 2.239910]\n",
      "epoch2 step19760 [D loss: 0.325168] [G loss: 2.014956]\n",
      "epoch2 step19765 [D loss: -0.754064] [G loss: 2.070058]\n",
      "epoch2 step19770 [D loss: -0.566894] [G loss: 1.769696]\n",
      "epoch2 step19775 [D loss: -1.237722] [G loss: 2.036566]\n",
      "epoch2 step19780 [D loss: -1.224735] [G loss: 1.348597]\n",
      "epoch2 step19785 [D loss: -1.215139] [G loss: 2.075624]\n",
      "epoch2 step19790 [D loss: -1.305383] [G loss: 2.087584]\n",
      "epoch2 step19795 [D loss: -0.910380] [G loss: 1.302768]\n",
      "epoch2 step19800 [D loss: -1.754452] [G loss: 2.400671]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.481041\n",
      "FID: 20.796526\n",
      "0 = 13.015497643184672\n",
      "1 = 0.08521032453851461\n",
      "2 = 0.8295999765396118\n",
      "3 = 0.9157999753952026\n",
      "4 = 0.743399977684021\n",
      "5 = 0.781132698059082\n",
      "6 = 0.9157999753952026\n",
      "7 = 8.062657809567456\n",
      "8 = 0.08683104246879834\n",
      "9 = 0.7936000227928162\n",
      "10 = 0.8288000226020813\n",
      "11 = 0.758400022983551\n",
      "12 = 0.7742899656295776\n",
      "13 = 0.8288000226020813\n",
      "14 = 6.481069564819336\n",
      "15 = 9.307600975036621\n",
      "16 = 0.16896185278892517\n",
      "17 = 6.481040954589844\n",
      "18 = 20.796525955200195\n",
      "epoch2 step19805 [D loss: -0.620921] [G loss: 1.882924]\n",
      "epoch2 step19810 [D loss: -0.774141] [G loss: 1.840849]\n",
      "epoch2 step19815 [D loss: -0.393717] [G loss: 1.749995]\n",
      "epoch2 step19820 [D loss: -1.341819] [G loss: 1.127849]\n",
      "epoch2 step19825 [D loss: -1.236535] [G loss: 1.971454]\n",
      "epoch2 step19830 [D loss: 0.438585] [G loss: 2.176198]\n",
      "epoch2 step19835 [D loss: -0.871890] [G loss: 2.048096]\n",
      "epoch2 step19840 [D loss: -1.103719] [G loss: 1.759786]\n",
      "epoch2 step19845 [D loss: -0.223718] [G loss: 1.633251]\n",
      "epoch2 step19850 [D loss: -0.126367] [G loss: 1.429368]\n",
      "epoch2 step19855 [D loss: -0.217208] [G loss: 1.937392]\n",
      "epoch2 step19860 [D loss: -0.486705] [G loss: 2.237853]\n",
      "epoch2 step19865 [D loss: -1.182355] [G loss: 1.381584]\n",
      "epoch2 step19870 [D loss: -1.990725] [G loss: 1.835202]\n",
      "epoch2 step19875 [D loss: 0.461533] [G loss: 1.502100]\n",
      "epoch2 step19880 [D loss: 0.202177] [G loss: 0.649097]\n",
      "epoch2 step19885 [D loss: -0.448300] [G loss: 1.665325]\n",
      "epoch2 step19890 [D loss: -0.458339] [G loss: 1.007191]\n",
      "epoch2 step19895 [D loss: -0.494123] [G loss: 1.578948]\n",
      "epoch2 step19900 [D loss: -0.716906] [G loss: 1.784255]\n",
      "epoch2 step19905 [D loss: -0.667410] [G loss: 1.485934]\n",
      "epoch2 step19910 [D loss: -0.158960] [G loss: 1.868314]\n",
      "epoch2 step19915 [D loss: -0.035460] [G loss: 1.620985]\n",
      "epoch2 step19920 [D loss: 0.264506] [G loss: 2.142722]\n",
      "epoch2 step19925 [D loss: -0.344229] [G loss: 1.378494]\n",
      "epoch2 step19930 [D loss: -0.215545] [G loss: 1.703860]\n",
      "epoch2 step19935 [D loss: -0.424495] [G loss: 2.025460]\n",
      "epoch2 step19940 [D loss: -0.303022] [G loss: 1.247579]\n",
      "epoch2 step19945 [D loss: -0.896049] [G loss: 2.038559]\n",
      "epoch2 step19950 [D loss: 0.121857] [G loss: 1.601137]\n",
      "epoch2 step19955 [D loss: -0.643628] [G loss: 2.549183]\n",
      "epoch2 step19960 [D loss: -0.732015] [G loss: 2.398634]\n",
      "epoch2 step19965 [D loss: -0.523095] [G loss: 1.150548]\n",
      "epoch2 step19970 [D loss: -0.313733] [G loss: 1.883688]\n",
      "epoch2 step19975 [D loss: -1.191798] [G loss: 1.616909]\n",
      "epoch2 step19980 [D loss: 0.451372] [G loss: 1.664369]\n",
      "epoch2 step19985 [D loss: -0.451205] [G loss: 2.669660]\n",
      "epoch2 step19990 [D loss: 0.386194] [G loss: 2.696917]\n",
      "epoch2 step19995 [D loss: -0.698834] [G loss: 2.426770]\n",
      "epoch2 step20000 [D loss: -0.512370] [G loss: 2.482300]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.413966\n",
      "FID: 21.226278\n",
      "0 = 13.695802482604975\n",
      "1 = 0.1440756550572927\n",
      "2 = 0.8398000001907349\n",
      "3 = 0.9297999739646912\n",
      "4 = 0.7498000264167786\n",
      "5 = 0.7879660725593567\n",
      "6 = 0.9297999739646912\n",
      "7 = 8.029745377695559\n",
      "8 = 0.08625595735625081\n",
      "9 = 0.7965999841690063\n",
      "10 = 0.8360000252723694\n",
      "11 = 0.7572000026702881\n",
      "12 = 0.7749351263046265\n",
      "13 = 0.8360000252723694\n",
      "14 = 6.4139885902404785\n",
      "15 = 9.117674827575684\n",
      "16 = 0.1987505555152893\n",
      "17 = 6.413965702056885\n",
      "18 = 21.22627830505371\n",
      "epoch2 step20005 [D loss: -0.471447] [G loss: 2.764983]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2 step20010 [D loss: -1.193931] [G loss: 2.552629]\n",
      "epoch2 step20015 [D loss: -0.469688] [G loss: 2.781788]\n",
      "epoch2 step20020 [D loss: 0.607007] [G loss: 3.578234]\n",
      "epoch2 step20025 [D loss: -0.261286] [G loss: 3.122334]\n",
      "epoch2 step20030 [D loss: -0.425100] [G loss: 3.064339]\n",
      "epoch2 step20035 [D loss: -0.626207] [G loss: 3.201352]\n",
      "epoch2 step20040 [D loss: -1.185627] [G loss: 3.039867]\n",
      "epoch2 step20045 [D loss: -0.694944] [G loss: 3.732325]\n",
      "epoch2 step20050 [D loss: -1.681597] [G loss: 3.057280]\n",
      "epoch2 step20055 [D loss: -1.532743] [G loss: 3.565114]\n",
      "epoch2 step20060 [D loss: -0.606526] [G loss: 3.283386]\n",
      "epoch2 step20065 [D loss: -0.240931] [G loss: 2.747184]\n",
      "epoch2 step20070 [D loss: -0.297195] [G loss: 3.229921]\n",
      "epoch2 step20075 [D loss: 0.769934] [G loss: 3.125777]\n",
      "epoch2 step20080 [D loss: -0.048771] [G loss: 2.638711]\n",
      "epoch2 step20085 [D loss: -0.448108] [G loss: 3.534308]\n",
      "epoch2 step20090 [D loss: 0.134580] [G loss: 3.667224]\n",
      "epoch2 step20095 [D loss: 0.432931] [G loss: 3.363011]\n",
      "epoch2 step20100 [D loss: 0.376471] [G loss: 2.751080]\n",
      "epoch2 step20105 [D loss: -0.924383] [G loss: 3.173551]\n",
      "epoch2 step20110 [D loss: -0.868432] [G loss: 3.918605]\n",
      "epoch2 step20115 [D loss: -0.683387] [G loss: 4.128474]\n",
      "epoch2 step20120 [D loss: -0.471168] [G loss: 3.637635]\n",
      "epoch2 step20125 [D loss: 0.067442] [G loss: 3.543216]\n",
      "epoch2 step20130 [D loss: 0.207775] [G loss: 3.792681]\n",
      "epoch2 step20135 [D loss: -0.145831] [G loss: 2.990651]\n",
      "epoch2 step20140 [D loss: -0.673414] [G loss: 3.337276]\n",
      "epoch2 step20145 [D loss: -0.203862] [G loss: 3.795744]\n",
      "epoch2 step20150 [D loss: -1.499475] [G loss: 3.005551]\n",
      "epoch2 step20155 [D loss: -0.221188] [G loss: 3.269936]\n",
      "epoch2 step20160 [D loss: -0.705519] [G loss: 3.673104]\n",
      "epoch2 step20165 [D loss: -0.007776] [G loss: 3.824271]\n",
      "epoch2 step20170 [D loss: -0.660173] [G loss: 4.029819]\n",
      "epoch2 step20175 [D loss: -1.239221] [G loss: 4.110356]\n",
      "epoch2 step20180 [D loss: -0.398626] [G loss: 3.681396]\n",
      "epoch2 step20185 [D loss: -0.875997] [G loss: 3.675101]\n",
      "epoch2 step20190 [D loss: -1.494700] [G loss: 4.200433]\n",
      "epoch2 step20195 [D loss: -0.333414] [G loss: 3.543800]\n",
      "epoch2 step20200 [D loss: -1.287856] [G loss: 4.315969]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.922771\n",
      "FID: 31.705286\n",
      "0 = 12.967185658359458\n",
      "1 = 0.10877937534013352\n",
      "2 = 0.864300012588501\n",
      "3 = 0.9101999998092651\n",
      "4 = 0.8184000253677368\n",
      "5 = 0.8336691856384277\n",
      "6 = 0.9101999998092651\n",
      "7 = 8.636020137572288\n",
      "8 = 0.11113682422872266\n",
      "9 = 0.8245000243186951\n",
      "10 = 0.8468000292778015\n",
      "11 = 0.8022000193595886\n",
      "12 = 0.8106452226638794\n",
      "13 = 0.8468000292778015\n",
      "14 = 5.922790050506592\n",
      "15 = 9.355799674987793\n",
      "16 = 0.1846754550933838\n",
      "17 = 5.922771453857422\n",
      "18 = 31.705286026000977\n",
      "epoch2 step20205 [D loss: -0.078513] [G loss: 3.863511]\n",
      "epoch2 step20210 [D loss: -0.330393] [G loss: 4.427421]\n",
      "epoch2 step20215 [D loss: -0.965148] [G loss: 4.468363]\n",
      "epoch2 step20220 [D loss: -0.809448] [G loss: 3.758652]\n",
      "epoch2 step20225 [D loss: -1.707556] [G loss: 4.453939]\n",
      "epoch2 step20230 [D loss: -1.173977] [G loss: 4.348185]\n",
      "epoch2 step20235 [D loss: -1.655951] [G loss: 4.901270]\n",
      "epoch2 step20240 [D loss: -0.408509] [G loss: 4.423522]\n",
      "epoch2 step20245 [D loss: -0.288361] [G loss: 5.180866]\n",
      "epoch2 step20250 [D loss: -0.609428] [G loss: 4.818330]\n",
      "epoch2 step20255 [D loss: -1.837599] [G loss: 5.313313]\n",
      "epoch2 step20260 [D loss: -0.633339] [G loss: 4.570437]\n",
      "epoch2 step20265 [D loss: -0.700155] [G loss: 4.160759]\n",
      "epoch2 step20270 [D loss: -1.689210] [G loss: 4.556506]\n",
      "epoch2 step20275 [D loss: -0.793038] [G loss: 5.252837]\n",
      "epoch2 step20280 [D loss: -0.051269] [G loss: 3.991161]\n",
      "epoch2 step20285 [D loss: 0.860971] [G loss: 4.248923]\n",
      "epoch2 step20290 [D loss: -0.312478] [G loss: 4.137805]\n",
      "epoch2 step20295 [D loss: -0.232024] [G loss: 4.915155]\n",
      "epoch2 step20300 [D loss: -0.586320] [G loss: 4.346649]\n",
      "epoch2 step20305 [D loss: -0.540924] [G loss: 4.188446]\n",
      "epoch2 step20310 [D loss: -0.122019] [G loss: 4.451396]\n",
      "epoch2 step20315 [D loss: -0.676983] [G loss: 5.134752]\n",
      "epoch2 step20320 [D loss: -0.531681] [G loss: 4.747104]\n",
      "epoch2 step20325 [D loss: -0.218494] [G loss: 4.029920]\n",
      "epoch2 step20330 [D loss: -0.861622] [G loss: 3.866509]\n",
      "epoch2 step20335 [D loss: -1.009407] [G loss: 3.751654]\n",
      "epoch2 step20340 [D loss: -0.569519] [G loss: 3.786117]\n",
      "epoch2 step20345 [D loss: -0.272795] [G loss: 3.991486]\n",
      "epoch2 step20350 [D loss: -0.151154] [G loss: 4.093817]\n",
      "epoch2 step20355 [D loss: -1.033980] [G loss: 4.514291]\n",
      "epoch2 step20360 [D loss: -1.208242] [G loss: 4.026349]\n",
      "epoch2 step20365 [D loss: -0.905279] [G loss: 4.236918]\n",
      "epoch2 step20370 [D loss: -0.231542] [G loss: 4.444593]\n",
      "epoch2 step20375 [D loss: 0.249273] [G loss: 4.582287]\n",
      "epoch2 step20380 [D loss: -0.486497] [G loss: 3.911549]\n",
      "epoch2 step20385 [D loss: 0.158223] [G loss: 4.204572]\n",
      "epoch2 step20390 [D loss: -0.597195] [G loss: 4.327893]\n",
      "epoch2 step20395 [D loss: 0.192654] [G loss: 4.443639]\n",
      "epoch2 step20400 [D loss: -0.202140] [G loss: 4.109090]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.395044\n",
      "FID: 20.142710\n",
      "0 = 14.065975586271259\n",
      "1 = 0.15102618784899105\n",
      "2 = 0.8321999907493591\n",
      "3 = 0.9386000037193298\n",
      "4 = 0.7257999777793884\n",
      "5 = 0.7739115953445435\n",
      "6 = 0.9386000037193298\n",
      "7 = 8.153674923086154\n",
      "8 = 0.0843921785174543\n",
      "9 = 0.8051999807357788\n",
      "10 = 0.8471999764442444\n",
      "11 = 0.7631999850273132\n",
      "12 = 0.7815498113632202\n",
      "13 = 0.8471999764442444\n",
      "14 = 6.395073413848877\n",
      "15 = 9.086468696594238\n",
      "16 = 0.20076636970043182\n",
      "17 = 6.395044326782227\n",
      "18 = 20.142709732055664\n",
      "epoch2 step20405 [D loss: -0.341520] [G loss: 4.426649]\n",
      "epoch2 step20410 [D loss: -0.893701] [G loss: 4.008089]\n",
      "epoch2 step20415 [D loss: -0.540474] [G loss: 4.563614]\n",
      "epoch2 step20420 [D loss: -0.949958] [G loss: 3.879497]\n",
      "epoch2 step20425 [D loss: -0.758861] [G loss: 4.918035]\n",
      "epoch2 step20430 [D loss: -0.222085] [G loss: 4.738397]\n",
      "epoch2 step20435 [D loss: -0.444477] [G loss: 4.437662]\n",
      "epoch2 step20440 [D loss: 0.009380] [G loss: 3.957554]\n",
      "epoch2 step20445 [D loss: 0.230017] [G loss: 3.120537]\n",
      "epoch2 step20450 [D loss: -0.437095] [G loss: 3.047524]\n",
      "epoch2 step20455 [D loss: -1.017455] [G loss: 3.095442]\n",
      "epoch2 step20460 [D loss: -0.837316] [G loss: 3.104310]\n",
      "epoch2 step20465 [D loss: -0.950539] [G loss: 3.563614]\n",
      "epoch2 step20470 [D loss: -0.002492] [G loss: 3.893278]\n",
      "epoch2 step20475 [D loss: -0.413019] [G loss: 3.517147]\n",
      "epoch2 step20480 [D loss: -0.291697] [G loss: 3.952749]\n",
      "epoch2 step20485 [D loss: -0.769551] [G loss: 3.480827]\n",
      "epoch2 step20490 [D loss: 0.026225] [G loss: 3.498116]\n",
      "epoch2 step20495 [D loss: -0.017368] [G loss: 3.769985]\n",
      "epoch2 step20500 [D loss: 0.137769] [G loss: 3.275241]\n",
      "epoch2 step20505 [D loss: -0.794823] [G loss: 3.800382]\n",
      "epoch2 step20510 [D loss: -0.624840] [G loss: 3.479344]\n",
      "epoch2 step20515 [D loss: -0.375391] [G loss: 4.405145]\n",
      "epoch2 step20520 [D loss: -0.379202] [G loss: 4.049333]\n",
      "epoch2 step20525 [D loss: -1.133080] [G loss: 4.013174]\n",
      "epoch2 step20530 [D loss: -0.667878] [G loss: 3.865242]\n",
      "epoch2 step20535 [D loss: -0.430804] [G loss: 3.062578]\n",
      "epoch2 step20540 [D loss: -0.965159] [G loss: 3.395310]\n",
      "epoch2 step20545 [D loss: -0.500706] [G loss: 3.395043]\n",
      "epoch2 step20550 [D loss: -0.531291] [G loss: 3.671508]\n",
      "epoch2 step20555 [D loss: -1.683971] [G loss: 3.925517]\n",
      "epoch2 step20560 [D loss: -0.835328] [G loss: 3.323100]\n",
      "epoch2 step20565 [D loss: -0.627885] [G loss: 3.646246]\n",
      "epoch2 step20570 [D loss: -1.464176] [G loss: 4.376538]\n",
      "epoch2 step20575 [D loss: -0.884035] [G loss: 3.939716]\n",
      "epoch2 step20580 [D loss: -0.512967] [G loss: 3.693467]\n",
      "epoch2 step20585 [D loss: -0.134305] [G loss: 3.203123]\n",
      "epoch2 step20590 [D loss: -0.596969] [G loss: 3.090147]\n",
      "epoch2 step20595 [D loss: 0.061756] [G loss: 3.269397]\n",
      "epoch2 step20600 [D loss: -0.498685] [G loss: 2.732219]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.512076\n",
      "FID: 19.878298\n",
      "0 = 13.18875831747054\n",
      "1 = 0.08429041260562534\n",
      "2 = 0.8235999941825867\n",
      "3 = 0.925599992275238\n",
      "4 = 0.7215999960899353\n",
      "5 = 0.7687707543373108\n",
      "6 = 0.925599992275238\n",
      "7 = 7.991540837669388\n",
      "8 = 0.08458900157057384\n",
      "9 = 0.7937999963760376\n",
      "10 = 0.8345999717712402\n",
      "11 = 0.753000020980835\n",
      "12 = 0.7716346383094788\n",
      "13 = 0.8345999717712402\n",
      "14 = 6.512100696563721\n",
      "15 = 9.280808448791504\n",
      "16 = 0.1753736436367035\n",
      "17 = 6.512076377868652\n",
      "18 = 19.878297805786133\n",
      "epoch2 step20605 [D loss: -0.392461] [G loss: 2.866967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2 step20610 [D loss: 0.222862] [G loss: 3.013736]\n",
      "epoch2 step20615 [D loss: -1.044292] [G loss: 3.096592]\n",
      "epoch2 step20620 [D loss: -0.609483] [G loss: 3.255102]\n",
      "epoch2 step20625 [D loss: -1.094830] [G loss: 2.828357]\n",
      "epoch2 step20630 [D loss: -1.559045] [G loss: 2.938668]\n",
      "epoch2 step20635 [D loss: -0.718774] [G loss: 2.691768]\n",
      "epoch2 step20640 [D loss: -1.001678] [G loss: 2.460458]\n",
      "epoch2 step20645 [D loss: -1.097309] [G loss: 3.416516]\n",
      "epoch2 step20650 [D loss: -0.074762] [G loss: 2.861025]\n",
      "epoch2 step20655 [D loss: -0.010605] [G loss: 2.605067]\n",
      "epoch2 step20660 [D loss: -0.483263] [G loss: 2.892667]\n",
      "epoch2 step20665 [D loss: -0.793794] [G loss: 3.166831]\n",
      "epoch2 step20670 [D loss: -1.308262] [G loss: 2.625617]\n",
      "epoch2 step20675 [D loss: -0.069132] [G loss: 2.879701]\n",
      "epoch2 step20680 [D loss: -1.453757] [G loss: 3.134841]\n",
      "epoch2 step20685 [D loss: -0.940142] [G loss: 3.945381]\n",
      "epoch2 step20690 [D loss: -0.450550] [G loss: 3.009500]\n",
      "epoch2 step20695 [D loss: -0.745449] [G loss: 2.684607]\n",
      "epoch2 step20700 [D loss: -0.157699] [G loss: 2.940141]\n",
      "epoch2 step20705 [D loss: 1.050189] [G loss: 3.115471]\n",
      "epoch2 step20710 [D loss: 0.256539] [G loss: 3.311356]\n",
      "epoch2 step20715 [D loss: -0.464925] [G loss: 3.670837]\n",
      "epoch2 step20720 [D loss: 0.150337] [G loss: 3.270131]\n",
      "epoch2 step20725 [D loss: -0.571863] [G loss: 3.999652]\n",
      "epoch2 step20730 [D loss: -0.542912] [G loss: 4.059859]\n",
      "epoch2 step20735 [D loss: -1.639684] [G loss: 4.917239]\n",
      "epoch2 step20740 [D loss: 0.212780] [G loss: 4.804566]\n",
      "epoch2 step20745 [D loss: -0.092429] [G loss: 4.284910]\n",
      "epoch2 step20750 [D loss: -0.903633] [G loss: 4.419883]\n",
      "epoch2 step20755 [D loss: -1.079352] [G loss: 4.458379]\n",
      "epoch2 step20760 [D loss: -0.166541] [G loss: 4.763018]\n",
      "epoch2 step20765 [D loss: -0.272035] [G loss: 4.392035]\n",
      "epoch2 step20770 [D loss: -0.570407] [G loss: 4.652471]\n",
      "epoch2 step20775 [D loss: 0.236977] [G loss: 4.128828]\n",
      "epoch2 step20780 [D loss: -0.588014] [G loss: 3.933448]\n",
      "epoch2 step20785 [D loss: -0.882446] [G loss: 4.322178]\n",
      "epoch2 step20790 [D loss: -0.127279] [G loss: 4.555910]\n",
      "epoch2 step20795 [D loss: -1.845537] [G loss: 4.011141]\n",
      "epoch2 step20800 [D loss: -0.329981] [G loss: 3.986453]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.477122\n",
      "FID: 18.716602\n",
      "0 = 13.531417907238009\n",
      "1 = 0.11528040079914124\n",
      "2 = 0.8342000246047974\n",
      "3 = 0.91839998960495\n",
      "4 = 0.75\n",
      "5 = 0.7860321998596191\n",
      "6 = 0.91839998960495\n",
      "7 = 8.09287675187587\n",
      "8 = 0.08242123861202778\n",
      "9 = 0.8055999875068665\n",
      "10 = 0.8539999723434448\n",
      "11 = 0.7572000026702881\n",
      "12 = 0.7786287665367126\n",
      "13 = 0.8539999723434448\n",
      "14 = 6.477148056030273\n",
      "15 = 9.447356224060059\n",
      "16 = 0.14470307528972626\n",
      "17 = 6.4771223068237305\n",
      "18 = 18.716602325439453\n",
      "epoch2 step20805 [D loss: -0.435066] [G loss: 4.097874]\n",
      "epoch2 step20810 [D loss: -1.312256] [G loss: 3.915140]\n",
      "epoch2 step20815 [D loss: -0.364399] [G loss: 3.011168]\n",
      "epoch2 step20820 [D loss: -0.579598] [G loss: 3.508612]\n",
      "epoch2 step20825 [D loss: -0.777535] [G loss: 3.787863]\n",
      "epoch2 step20830 [D loss: -0.536069] [G loss: 3.735863]\n",
      "epoch2 step20835 [D loss: -0.838848] [G loss: 3.611836]\n",
      "epoch2 step20840 [D loss: -1.644383] [G loss: 3.963416]\n",
      "epoch2 step20845 [D loss: -0.954025] [G loss: 3.984878]\n",
      "epoch2 step20850 [D loss: -0.624689] [G loss: 3.638149]\n",
      "epoch2 step20855 [D loss: -0.241489] [G loss: 3.481441]\n",
      "epoch2 step20860 [D loss: -0.521065] [G loss: 3.475831]\n",
      "epoch2 step20865 [D loss: -0.137790] [G loss: 3.767823]\n",
      "epoch2 step20870 [D loss: 0.221318] [G loss: 3.560646]\n",
      "epoch2 step20875 [D loss: -0.232044] [G loss: 3.779272]\n",
      "epoch2 step20880 [D loss: -0.049846] [G loss: 3.800320]\n",
      "epoch2 step20885 [D loss: -0.073587] [G loss: 4.098358]\n",
      "epoch2 step20890 [D loss: -1.098278] [G loss: 4.256339]\n",
      "epoch2 step20895 [D loss: 0.381039] [G loss: 3.871418]\n",
      "epoch2 step20900 [D loss: -0.779713] [G loss: 4.650151]\n",
      "epoch2 step20905 [D loss: -0.256463] [G loss: 4.108835]\n",
      "epoch2 step20910 [D loss: -0.413749] [G loss: 3.761889]\n",
      "epoch2 step20915 [D loss: -0.490583] [G loss: 3.425026]\n",
      "epoch2 step20920 [D loss: -0.762899] [G loss: 3.481795]\n",
      "epoch2 step20925 [D loss: -1.003409] [G loss: 3.730030]\n",
      "epoch2 step20930 [D loss: -0.174112] [G loss: 3.887763]\n",
      "epoch2 step20935 [D loss: -0.823054] [G loss: 3.352312]\n",
      "epoch2 step20940 [D loss: -0.608805] [G loss: 3.631964]\n",
      "epoch2 step20945 [D loss: -0.434237] [G loss: 3.587566]\n",
      "epoch2 step20950 [D loss: 0.227459] [G loss: 4.265021]\n",
      "epoch2 step20955 [D loss: -0.820962] [G loss: 3.381361]\n",
      "epoch2 step20960 [D loss: -1.486707] [G loss: 4.225284]\n",
      "epoch2 step20965 [D loss: -2.110922] [G loss: 4.052726]\n",
      "epoch2 step20970 [D loss: -0.943689] [G loss: 3.797561]\n",
      "epoch2 step20975 [D loss: -1.732922] [G loss: 5.057543]\n",
      "epoch2 step20980 [D loss: -1.501556] [G loss: 4.760762]\n",
      "epoch2 step20985 [D loss: 0.539311] [G loss: 4.820633]\n",
      "epoch2 step20990 [D loss: -1.311840] [G loss: 4.904643]\n",
      "epoch2 step20995 [D loss: -0.013900] [G loss: 4.162365]\n",
      "epoch2 step21000 [D loss: -0.662905] [G loss: 4.044592]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.267087\n",
      "FID: 24.408941\n",
      "0 = 13.498062058448848\n",
      "1 = 0.09774836963747614\n",
      "2 = 0.8409000039100647\n",
      "3 = 0.9246000051498413\n",
      "4 = 0.7572000026702881\n",
      "5 = 0.7920164465904236\n",
      "6 = 0.9246000051498413\n",
      "7 = 8.367678496813783\n",
      "8 = 0.09728015959582288\n",
      "9 = 0.8130999803543091\n",
      "10 = 0.8529999852180481\n",
      "11 = 0.7731999754905701\n",
      "12 = 0.7899610996246338\n",
      "13 = 0.8529999852180481\n",
      "14 = 6.267107963562012\n",
      "15 = 9.35146713256836\n",
      "16 = 0.1661352962255478\n",
      "17 = 6.267086505889893\n",
      "18 = 24.4089412689209\n",
      "epoch2 step21005 [D loss: -0.712087] [G loss: 4.114135]\n",
      "epoch2 step21010 [D loss: -0.847963] [G loss: 4.209158]\n",
      "epoch2 step21015 [D loss: -0.923799] [G loss: 4.438008]\n",
      "epoch2 step21020 [D loss: -0.420217] [G loss: 4.323502]\n",
      "epoch2 step21025 [D loss: -1.378320] [G loss: 5.094481]\n",
      "epoch2 step21030 [D loss: -0.554221] [G loss: 4.848223]\n",
      "epoch2 step21035 [D loss: -0.617240] [G loss: 4.164730]\n",
      "epoch2 step21040 [D loss: -2.432738] [G loss: 4.531982]\n",
      "epoch2 step21045 [D loss: -3.556483] [G loss: 4.936327]\n",
      "epoch2 step21050 [D loss: -3.028315] [G loss: 4.626986]\n",
      "epoch2 step21055 [D loss: -3.136165] [G loss: 5.044335]\n",
      "epoch2 step21060 [D loss: -1.775609] [G loss: 4.738717]\n",
      "epoch2 step21065 [D loss: -2.857544] [G loss: 5.641125]\n",
      "epoch2 step21070 [D loss: -3.692427] [G loss: 6.413889]\n",
      "epoch2 step21075 [D loss: -0.828798] [G loss: 5.890851]\n",
      "epoch2 step21080 [D loss: -0.845153] [G loss: 6.347046]\n",
      "epoch2 step21085 [D loss: -1.003924] [G loss: 6.551828]\n",
      "epoch2 step21090 [D loss: -0.733416] [G loss: 5.360466]\n",
      "epoch2 step21095 [D loss: -0.133659] [G loss: 4.845288]\n",
      "epoch2 step21100 [D loss: -1.334945] [G loss: 5.999833]\n",
      "epoch2 step21105 [D loss: -0.789386] [G loss: 6.497150]\n",
      "epoch2 step21110 [D loss: 0.523795] [G loss: 5.647498]\n",
      "epoch2 step21115 [D loss: 0.234240] [G loss: 5.059658]\n",
      "epoch2 step21120 [D loss: -1.027938] [G loss: 5.791470]\n",
      "epoch2 step21125 [D loss: -1.433692] [G loss: 4.904304]\n",
      "epoch2 step21130 [D loss: -1.001838] [G loss: 5.733668]\n",
      "epoch2 step21135 [D loss: -0.134129] [G loss: 5.644676]\n",
      "epoch2 step21140 [D loss: -0.739382] [G loss: 5.663776]\n",
      "epoch2 step21145 [D loss: -0.214803] [G loss: 4.970530]\n",
      "epoch2 step21150 [D loss: 0.492968] [G loss: 5.182211]\n",
      "epoch2 step21155 [D loss: -1.184169] [G loss: 5.286823]\n",
      "epoch2 step21160 [D loss: 1.011211] [G loss: 4.144494]\n",
      "epoch2 step21165 [D loss: -0.751808] [G loss: 4.946686]\n",
      "epoch2 step21170 [D loss: 0.100106] [G loss: 4.604498]\n",
      "epoch2 step21175 [D loss: -0.280665] [G loss: 4.960594]\n",
      "epoch2 step21180 [D loss: -0.765736] [G loss: 4.823352]\n",
      "epoch2 step21185 [D loss: -0.467593] [G loss: 5.054427]\n",
      "epoch2 step21190 [D loss: -0.391990] [G loss: 5.238793]\n",
      "epoch2 step21195 [D loss: -0.389594] [G loss: 4.901744]\n",
      "epoch2 step21200 [D loss: -1.060832] [G loss: 5.192183]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.316146\n",
      "FID: 23.653059\n",
      "0 = 13.058412665128724\n",
      "1 = 0.05713725232838639\n",
      "2 = 0.8219000101089478\n",
      "3 = 0.9161999821662903\n",
      "4 = 0.7275999784469604\n",
      "5 = 0.7708228230476379\n",
      "6 = 0.9161999821662903\n",
      "7 = 8.260815818142893\n",
      "8 = 0.09674748057157996\n",
      "9 = 0.8062000274658203\n",
      "10 = 0.8429999947547913\n",
      "11 = 0.7694000005722046\n",
      "12 = 0.7852086424827576\n",
      "13 = 0.8429999947547913\n",
      "14 = 6.316171646118164\n",
      "15 = 9.220192909240723\n",
      "16 = 0.18380962312221527\n",
      "17 = 6.316145896911621\n",
      "18 = 23.653059005737305\n",
      "epoch2 step21205 [D loss: -0.952674] [G loss: 5.164834]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2 step21210 [D loss: -0.441677] [G loss: 5.286713]\n",
      "epoch2 step21215 [D loss: -0.306274] [G loss: 5.640915]\n",
      "epoch2 step21220 [D loss: -1.018184] [G loss: 5.239234]\n",
      "epoch2 step21225 [D loss: -1.525331] [G loss: 5.298369]\n",
      "epoch2 step21230 [D loss: -0.630870] [G loss: 5.605033]\n",
      "epoch2 step21235 [D loss: -0.872700] [G loss: 5.288306]\n",
      "epoch2 step21240 [D loss: -0.864741] [G loss: 5.593971]\n",
      "epoch2 step21245 [D loss: -0.484037] [G loss: 5.280611]\n",
      "epoch2 step21250 [D loss: -1.107179] [G loss: 5.551740]\n",
      "epoch2 step21255 [D loss: -0.417569] [G loss: 5.267421]\n",
      "epoch2 step21260 [D loss: -0.609382] [G loss: 4.259057]\n",
      "epoch2 step21265 [D loss: -0.556485] [G loss: 4.643561]\n",
      "epoch2 step21270 [D loss: -0.437819] [G loss: 5.068345]\n",
      "epoch2 step21275 [D loss: -0.483396] [G loss: 4.420075]\n",
      "epoch2 step21280 [D loss: -0.592407] [G loss: 4.519432]\n",
      "epoch2 step21285 [D loss: -0.925793] [G loss: 4.616540]\n",
      "epoch2 step21290 [D loss: -0.239832] [G loss: 4.141085]\n",
      "epoch2 step21295 [D loss: -0.187079] [G loss: 3.958030]\n",
      "epoch2 step21300 [D loss: -0.499543] [G loss: 4.247430]\n",
      "epoch2 step21305 [D loss: -1.111742] [G loss: 5.058941]\n",
      "epoch2 step21310 [D loss: -0.951194] [G loss: 4.433198]\n",
      "epoch2 step21315 [D loss: 0.243585] [G loss: 3.361566]\n",
      "epoch2 step21320 [D loss: -0.569047] [G loss: 3.823520]\n",
      "epoch2 step21325 [D loss: 0.288052] [G loss: 2.578265]\n",
      "epoch2 step21330 [D loss: -0.646507] [G loss: 3.846016]\n",
      "epoch2 step21335 [D loss: -0.774774] [G loss: 3.309705]\n",
      "epoch2 step21340 [D loss: -0.428640] [G loss: 3.232061]\n",
      "epoch2 step21345 [D loss: -1.344936] [G loss: 3.423799]\n",
      "epoch2 step21350 [D loss: -1.734505] [G loss: 3.181171]\n",
      "epoch2 step21355 [D loss: -0.672140] [G loss: 2.775503]\n",
      "epoch2 step21360 [D loss: 0.387901] [G loss: 3.057603]\n",
      "epoch2 step21365 [D loss: -0.797789] [G loss: 3.315191]\n",
      "epoch2 step21370 [D loss: -0.692653] [G loss: 3.595686]\n",
      "epoch2 step21375 [D loss: 0.359224] [G loss: 3.316519]\n",
      "epoch2 step21380 [D loss: -0.103207] [G loss: 3.044617]\n",
      "epoch2 step21385 [D loss: -0.912356] [G loss: 3.607574]\n",
      "epoch2 step21390 [D loss: -0.808457] [G loss: 3.872232]\n",
      "epoch2 step21395 [D loss: -0.275914] [G loss: 2.771627]\n",
      "epoch2 step21400 [D loss: -0.194320] [G loss: 3.263066]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.240755\n",
      "FID: 25.286581\n",
      "0 = 12.799107586956012\n",
      "1 = 0.06948363999393412\n",
      "2 = 0.8324999809265137\n",
      "3 = 0.9147999882698059\n",
      "4 = 0.7501999735832214\n",
      "5 = 0.7855057716369629\n",
      "6 = 0.9147999882698059\n",
      "7 = 8.28060262619258\n",
      "8 = 0.09993019051507604\n",
      "9 = 0.805899977684021\n",
      "10 = 0.8464000225067139\n",
      "11 = 0.7653999924659729\n",
      "12 = 0.7829787135124207\n",
      "13 = 0.8464000225067139\n",
      "14 = 6.240780353546143\n",
      "15 = 9.283761024475098\n",
      "16 = 0.1858435571193695\n",
      "17 = 6.2407546043396\n",
      "18 = 25.28658103942871\n",
      "epoch2 step21405 [D loss: -0.675235] [G loss: 3.252649]\n",
      "epoch2 step21410 [D loss: 0.474347] [G loss: 2.511834]\n",
      "epoch2 step21415 [D loss: -0.490020] [G loss: 2.694787]\n",
      "epoch2 step21420 [D loss: -1.037602] [G loss: 2.624571]\n",
      "epoch2 step21425 [D loss: -1.106328] [G loss: 2.166680]\n",
      "epoch2 step21430 [D loss: 0.489160] [G loss: 3.272074]\n",
      "epoch2 step21435 [D loss: -0.164656] [G loss: 3.438712]\n",
      "epoch2 step21440 [D loss: 0.391238] [G loss: 2.308847]\n",
      "epoch2 step21445 [D loss: -0.939946] [G loss: 2.851803]\n",
      "epoch2 step21450 [D loss: 0.260263] [G loss: 2.694013]\n",
      "epoch2 step21455 [D loss: -1.492094] [G loss: 4.116426]\n",
      "epoch2 step21460 [D loss: -1.195902] [G loss: 2.663700]\n",
      "epoch2 step21465 [D loss: -0.852903] [G loss: 3.293479]\n",
      "epoch2 step21470 [D loss: -0.421565] [G loss: 3.142921]\n",
      "epoch2 step21475 [D loss: -1.037591] [G loss: 4.302986]\n",
      "epoch2 step21480 [D loss: -0.532686] [G loss: 3.466703]\n",
      "epoch2 step21485 [D loss: -1.025531] [G loss: 3.277842]\n",
      "epoch2 step21490 [D loss: -0.846471] [G loss: 3.415081]\n",
      "epoch2 step21495 [D loss: -0.227818] [G loss: 4.017828]\n",
      "epoch2 step21500 [D loss: -0.641935] [G loss: 3.727793]\n",
      "epoch2 step21505 [D loss: -0.470875] [G loss: 3.836584]\n",
      "epoch2 step21510 [D loss: -1.152681] [G loss: 4.589734]\n",
      "epoch2 step21515 [D loss: -1.517261] [G loss: 4.452084]\n",
      "epoch2 step21520 [D loss: 0.007239] [G loss: 4.423895]\n",
      "epoch2 step21525 [D loss: 1.190338] [G loss: 4.225896]\n",
      "epoch2 step21530 [D loss: -0.832519] [G loss: 4.614785]\n",
      "epoch2 step21535 [D loss: -0.089065] [G loss: 4.274928]\n",
      "epoch2 step21540 [D loss: -0.100337] [G loss: 4.252177]\n",
      "epoch2 step21545 [D loss: -0.753951] [G loss: 3.519503]\n",
      "epoch2 step21550 [D loss: -0.572120] [G loss: 4.256574]\n",
      "epoch2 step21555 [D loss: 0.299373] [G loss: 4.163565]\n",
      "epoch2 step21560 [D loss: -0.821379] [G loss: 3.440742]\n",
      "epoch2 step21565 [D loss: 0.639008] [G loss: 3.358846]\n",
      "epoch2 step21570 [D loss: -0.645214] [G loss: 4.243413]\n",
      "epoch2 step21575 [D loss: -0.867106] [G loss: 4.537562]\n",
      "epoch2 step21580 [D loss: -0.015214] [G loss: 3.930661]\n",
      "epoch2 step21585 [D loss: -0.692236] [G loss: 4.562421]\n",
      "epoch2 step21590 [D loss: -1.075180] [G loss: 3.868745]\n",
      "epoch2 step21595 [D loss: -0.269141] [G loss: 3.544977]\n",
      "epoch2 step21600 [D loss: -0.907486] [G loss: 3.610206]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.522264\n",
      "FID: 18.825087\n",
      "0 = 12.846804427766786\n",
      "1 = 0.06308661776432767\n",
      "2 = 0.8141000270843506\n",
      "3 = 0.9156000018119812\n",
      "4 = 0.7125999927520752\n",
      "5 = 0.761097252368927\n",
      "6 = 0.9156000018119812\n",
      "7 = 7.867974533081068\n",
      "8 = 0.08171310492833331\n",
      "9 = 0.7907000184059143\n",
      "10 = 0.8345999717712402\n",
      "11 = 0.7468000054359436\n",
      "12 = 0.7672366499900818\n",
      "13 = 0.8345999717712402\n",
      "14 = 6.522285461425781\n",
      "15 = 9.31379222869873\n",
      "16 = 0.16857925057411194\n",
      "17 = 6.522263526916504\n",
      "18 = 18.82508659362793\n",
      "epoch2 step21605 [D loss: -0.587300] [G loss: 3.936307]\n",
      "epoch2 step21610 [D loss: -0.837241] [G loss: 3.870376]\n",
      "epoch2 step21615 [D loss: 0.065977] [G loss: 3.545229]\n",
      "epoch2 step21620 [D loss: -0.665708] [G loss: 3.466530]\n",
      "epoch2 step21625 [D loss: -0.391304] [G loss: 3.719162]\n",
      "epoch2 step21630 [D loss: -0.021559] [G loss: 3.018345]\n",
      "epoch2 step21635 [D loss: -0.935892] [G loss: 3.350484]\n",
      "epoch2 step21640 [D loss: 0.635847] [G loss: 2.913895]\n",
      "epoch2 step21645 [D loss: -0.146519] [G loss: 2.537691]\n",
      "epoch2 step21650 [D loss: -0.314155] [G loss: 3.597285]\n",
      "epoch2 step21655 [D loss: -0.406162] [G loss: 3.766213]\n",
      "epoch2 step21660 [D loss: -0.782058] [G loss: 3.754515]\n",
      "epoch2 step21665 [D loss: 0.042438] [G loss: 3.887395]\n",
      "epoch2 step21670 [D loss: -0.730819] [G loss: 4.463531]\n",
      "epoch2 step21675 [D loss: -0.726197] [G loss: 3.407817]\n",
      "epoch2 step21680 [D loss: -0.949065] [G loss: 3.797144]\n",
      "epoch2 step21685 [D loss: -0.079822] [G loss: 4.279830]\n",
      "epoch2 step21690 [D loss: -0.354152] [G loss: 3.850552]\n",
      "epoch2 step21695 [D loss: 0.160463] [G loss: 4.042073]\n",
      "epoch2 step21700 [D loss: -0.254453] [G loss: 3.766545]\n",
      "epoch2 step21705 [D loss: 0.058856] [G loss: 4.303814]\n",
      "epoch2 step21710 [D loss: -1.215802] [G loss: 5.178774]\n",
      "epoch2 step21715 [D loss: -0.019938] [G loss: 4.280445]\n",
      "epoch2 step21720 [D loss: -0.367775] [G loss: 4.328759]\n",
      "epoch2 step21725 [D loss: 0.117855] [G loss: 4.963208]\n",
      "epoch2 step21730 [D loss: 0.090052] [G loss: 4.724624]\n",
      "epoch2 step21735 [D loss: -0.708255] [G loss: 4.736352]\n",
      "epoch2 step21740 [D loss: -0.090488] [G loss: 5.343300]\n",
      "epoch2 step21745 [D loss: -0.133992] [G loss: 4.923141]\n",
      "epoch2 step21750 [D loss: -1.027665] [G loss: 5.427695]\n",
      "epoch2 step21755 [D loss: -0.619147] [G loss: 5.005079]\n",
      "epoch2 step21760 [D loss: -1.611872] [G loss: 5.042717]\n",
      "epoch2 step21765 [D loss: -0.750493] [G loss: 5.670212]\n",
      "epoch2 step21770 [D loss: -0.806221] [G loss: 5.252753]\n",
      "epoch2 step21775 [D loss: -0.415536] [G loss: 5.041816]\n",
      "epoch2 step21780 [D loss: -0.913227] [G loss: 5.932816]\n",
      "epoch2 step21785 [D loss: -0.567429] [G loss: 5.282836]\n",
      "epoch2 step21790 [D loss: -0.370368] [G loss: 5.823996]\n",
      "epoch2 step21795 [D loss: -0.583101] [G loss: 6.106180]\n",
      "epoch2 step21800 [D loss: -0.967746] [G loss: 5.377756]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.495519\n",
      "FID: 17.112883\n",
      "0 = 13.325541735744512\n",
      "1 = 0.10447735547479577\n",
      "2 = 0.8072999715805054\n",
      "3 = 0.921999990940094\n",
      "4 = 0.6926000118255615\n",
      "5 = 0.7499593496322632\n",
      "6 = 0.921999990940094\n",
      "7 = 7.872477288150775\n",
      "8 = 0.0781417828653155\n",
      "9 = 0.777400016784668\n",
      "10 = 0.8256000280380249\n",
      "11 = 0.729200005531311\n",
      "12 = 0.7530098557472229\n",
      "13 = 0.8256000280380249\n",
      "14 = 6.495541572570801\n",
      "15 = 9.118945121765137\n",
      "16 = 0.19633126258850098\n",
      "17 = 6.495519161224365\n",
      "18 = 17.112882614135742\n",
      "epoch2 step21805 [D loss: -1.841046] [G loss: 5.145878]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2 step21810 [D loss: -0.489778] [G loss: 5.545082]\n",
      "epoch2 step21815 [D loss: 0.405768] [G loss: 5.871353]\n",
      "epoch2 step21820 [D loss: -1.032270] [G loss: 5.361922]\n",
      "epoch2 step21825 [D loss: 0.662586] [G loss: 5.201454]\n",
      "epoch2 step21830 [D loss: -0.653120] [G loss: 5.963811]\n",
      "epoch2 step21835 [D loss: -0.112146] [G loss: 5.260811]\n",
      "epoch2 step21840 [D loss: -0.996950] [G loss: 6.142733]\n",
      "epoch2 step21845 [D loss: -1.679315] [G loss: 6.340502]\n",
      "epoch2 step21850 [D loss: 0.220037] [G loss: 5.667640]\n",
      "epoch2 step21855 [D loss: -0.773373] [G loss: 5.873892]\n",
      "epoch2 step21860 [D loss: -1.068965] [G loss: 5.802057]\n",
      "epoch2 step21865 [D loss: -1.298761] [G loss: 5.111966]\n",
      "epoch2 step21870 [D loss: -0.838841] [G loss: 6.139821]\n",
      "epoch2 step21875 [D loss: -0.798900] [G loss: 6.858711]\n",
      "epoch2 step21880 [D loss: -1.139899] [G loss: 6.578978]\n",
      "epoch2 step21885 [D loss: -1.550089] [G loss: 6.235443]\n",
      "epoch2 step21890 [D loss: -2.392681] [G loss: 7.127064]\n",
      "epoch2 step21895 [D loss: -2.902171] [G loss: 6.179914]\n",
      "epoch2 step21900 [D loss: -0.846283] [G loss: 6.036830]\n",
      "epoch2 step21905 [D loss: -0.743211] [G loss: 6.742781]\n",
      "epoch2 step21910 [D loss: 0.254632] [G loss: 6.862746]\n",
      "epoch2 step21915 [D loss: 0.741836] [G loss: 5.749770]\n",
      "epoch2 step21920 [D loss: -0.399946] [G loss: 5.936749]\n",
      "epoch2 step21925 [D loss: 0.111078] [G loss: 6.163185]\n",
      "epoch2 step21930 [D loss: -0.473720] [G loss: 6.064087]\n",
      "epoch2 step21935 [D loss: 0.519143] [G loss: 5.307589]\n",
      "epoch2 step21940 [D loss: -1.084735] [G loss: 6.234159]\n",
      "epoch2 step21945 [D loss: -0.262575] [G loss: 5.829227]\n",
      "epoch2 step21950 [D loss: -0.696746] [G loss: 5.125901]\n",
      "epoch2 step21955 [D loss: -0.891339] [G loss: 5.249559]\n",
      "epoch2 step21960 [D loss: 0.153409] [G loss: 5.352419]\n",
      "epoch2 step21965 [D loss: -0.527771] [G loss: 5.005237]\n",
      "epoch2 step21970 [D loss: -0.253515] [G loss: 4.592534]\n",
      "epoch2 step21975 [D loss: -0.842378] [G loss: 5.260256]\n",
      "epoch2 step21980 [D loss: -0.200640] [G loss: 4.718416]\n",
      "epoch2 step21985 [D loss: -0.674903] [G loss: 4.245065]\n",
      "epoch2 step21990 [D loss: -0.008573] [G loss: 4.690288]\n",
      "epoch2 step21995 [D loss: -0.803888] [G loss: 4.808056]\n",
      "epoch2 step22000 [D loss: -1.328430] [G loss: 4.471971]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.367342\n",
      "FID: 22.220064\n",
      "0 = 13.074771284008017\n",
      "1 = 0.0611103052991664\n",
      "2 = 0.8079000115394592\n",
      "3 = 0.9240000247955322\n",
      "4 = 0.6917999982833862\n",
      "5 = 0.7498782873153687\n",
      "6 = 0.9240000247955322\n",
      "7 = 8.029807588219626\n",
      "8 = 0.09401538162998768\n",
      "9 = 0.7924000024795532\n",
      "10 = 0.8313999772071838\n",
      "11 = 0.7534000277519226\n",
      "12 = 0.7712430357933044\n",
      "13 = 0.8313999772071838\n",
      "14 = 6.367370128631592\n",
      "15 = 9.245269775390625\n",
      "16 = 0.17962908744812012\n",
      "17 = 6.367341995239258\n",
      "18 = 22.220064163208008\n",
      "epoch2 step22005 [D loss: -0.989078] [G loss: 4.361295]\n",
      "epoch2 step22010 [D loss: -1.065091] [G loss: 3.903758]\n",
      "epoch2 step22015 [D loss: -0.960438] [G loss: 4.597329]\n",
      "epoch2 step22020 [D loss: -0.758232] [G loss: 4.334371]\n",
      "epoch2 step22025 [D loss: -1.126671] [G loss: 4.237062]\n",
      "epoch2 step22030 [D loss: -0.771153] [G loss: 4.552486]\n",
      "epoch2 step22035 [D loss: -0.718460] [G loss: 4.349075]\n",
      "epoch2 step22040 [D loss: -1.607457] [G loss: 4.838493]\n",
      "epoch2 step22045 [D loss: -0.972856] [G loss: 4.352592]\n",
      "epoch2 step22050 [D loss: -0.279086] [G loss: 5.202272]\n",
      "epoch2 step22055 [D loss: -1.421812] [G loss: 4.559046]\n",
      "epoch2 step22060 [D loss: -1.081649] [G loss: 4.667274]\n",
      "epoch2 step22065 [D loss: -0.373036] [G loss: 4.618157]\n",
      "epoch2 step22070 [D loss: -1.107088] [G loss: 5.169806]\n",
      "epoch2 step22075 [D loss: -0.631573] [G loss: 5.035703]\n",
      "epoch2 step22080 [D loss: -1.285647] [G loss: 5.063718]\n",
      "epoch2 step22085 [D loss: -0.171378] [G loss: 5.108642]\n",
      "epoch2 step22090 [D loss: -0.367278] [G loss: 5.408817]\n",
      "epoch2 step22095 [D loss: -0.750805] [G loss: 5.861229]\n",
      "epoch2 step22100 [D loss: -0.678546] [G loss: 5.974383]\n",
      "epoch2 step22105 [D loss: 0.223177] [G loss: 4.897663]\n",
      "epoch2 step22110 [D loss: -1.850511] [G loss: 5.780107]\n",
      "epoch2 step22115 [D loss: -0.303065] [G loss: 5.383930]\n",
      "epoch2 step22120 [D loss: -0.368663] [G loss: 5.916773]\n",
      "epoch2 step22125 [D loss: -0.169652] [G loss: 4.962201]\n",
      "epoch2 step22130 [D loss: -0.721769] [G loss: 5.493592]\n",
      "epoch2 step22135 [D loss: -1.634909] [G loss: 5.583013]\n",
      "epoch2 step22140 [D loss: -0.847988] [G loss: 5.424986]\n",
      "epoch2 step22145 [D loss: -1.113986] [G loss: 5.285346]\n",
      "epoch2 step22150 [D loss: -0.047227] [G loss: 4.493292]\n",
      "epoch2 step22155 [D loss: 0.139129] [G loss: 5.489702]\n",
      "epoch2 step22160 [D loss: 0.207993] [G loss: 4.927037]\n",
      "epoch2 step22165 [D loss: -0.049150] [G loss: 5.109121]\n",
      "epoch2 step22170 [D loss: -0.780836] [G loss: 5.427737]\n",
      "epoch2 step22175 [D loss: -0.287001] [G loss: 5.540143]\n",
      "epoch2 step22180 [D loss: -0.240639] [G loss: 5.031063]\n",
      "epoch2 step22185 [D loss: -1.307294] [G loss: 5.492341]\n",
      "epoch2 step22190 [D loss: -0.315103] [G loss: 5.376055]\n",
      "epoch2 step22195 [D loss: -1.000863] [G loss: 5.531356]\n",
      "epoch2 step22200 [D loss: -0.625810] [G loss: 5.613922]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.738501\n",
      "FID: 14.587852\n",
      "0 = 13.437389240360243\n",
      "1 = 0.09448778398463295\n",
      "2 = 0.785099983215332\n",
      "3 = 0.9354000091552734\n",
      "4 = 0.6348000168800354\n",
      "5 = 0.7192065119743347\n",
      "6 = 0.9354000091552734\n",
      "7 = 7.725516019737713\n",
      "8 = 0.06709204702077214\n",
      "9 = 0.784600019454956\n",
      "10 = 0.8361999988555908\n",
      "11 = 0.7329999804496765\n",
      "12 = 0.757976770401001\n",
      "13 = 0.8361999988555908\n",
      "14 = 6.738522052764893\n",
      "15 = 9.334513664245605\n",
      "16 = 0.1587321013212204\n",
      "17 = 6.738500595092773\n",
      "18 = 14.587852478027344\n",
      "epoch2 step22205 [D loss: -0.675014] [G loss: 6.090463]\n",
      "epoch2 step22210 [D loss: -1.479976] [G loss: 5.579973]\n",
      "epoch2 step22215 [D loss: -1.791969] [G loss: 4.848037]\n",
      "epoch2 step22220 [D loss: -1.762130] [G loss: 5.015359]\n",
      "epoch2 step22225 [D loss: -0.751751] [G loss: 5.236966]\n",
      "epoch2 step22230 [D loss: -0.200292] [G loss: 5.364524]\n",
      "epoch2 step22235 [D loss: -0.260056] [G loss: 5.081393]\n",
      "epoch2 step22240 [D loss: -0.780432] [G loss: 4.861518]\n",
      "epoch2 step22245 [D loss: -0.863343] [G loss: 4.417576]\n",
      "epoch2 step22250 [D loss: 0.427720] [G loss: 4.524556]\n",
      "epoch2 step22255 [D loss: -0.260646] [G loss: 5.005282]\n",
      "epoch2 step22260 [D loss: -0.232027] [G loss: 5.271309]\n",
      "epoch2 step22265 [D loss: -0.109064] [G loss: 4.521489]\n",
      "epoch2 step22270 [D loss: -0.055666] [G loss: 3.946631]\n",
      "epoch2 step22275 [D loss: -0.778292] [G loss: 4.118926]\n",
      "epoch2 step22280 [D loss: -0.062467] [G loss: 4.691385]\n",
      "epoch2 step22285 [D loss: -0.706596] [G loss: 4.527768]\n",
      "epoch2 step22290 [D loss: -0.653668] [G loss: 4.313453]\n",
      "epoch2 step22295 [D loss: -0.342336] [G loss: 4.195627]\n",
      "epoch2 step22300 [D loss: -0.700646] [G loss: 4.404360]\n",
      "epoch2 step22305 [D loss: -0.667063] [G loss: 3.967741]\n",
      "epoch2 step22310 [D loss: -0.239126] [G loss: 3.884092]\n",
      "epoch2 step22315 [D loss: -0.179510] [G loss: 4.295197]\n",
      "epoch2 step22320 [D loss: -0.920712] [G loss: 3.714816]\n",
      "epoch2 step22325 [D loss: -1.657161] [G loss: 4.427756]\n",
      "epoch2 step22330 [D loss: -0.693075] [G loss: 4.377750]\n",
      "epoch2 step22335 [D loss: -0.640443] [G loss: 4.765291]\n",
      "epoch2 step22340 [D loss: -0.680237] [G loss: 4.618021]\n",
      "epoch2 step22345 [D loss: -1.108684] [G loss: 5.131604]\n",
      "epoch2 step22350 [D loss: -0.611100] [G loss: 4.250115]\n",
      "epoch2 step22355 [D loss: -1.349591] [G loss: 4.807732]\n",
      "epoch2 step22360 [D loss: -0.314217] [G loss: 4.367827]\n",
      "epoch2 step22365 [D loss: -0.480031] [G loss: 4.638374]\n",
      "epoch2 step22370 [D loss: -0.065858] [G loss: 4.719798]\n",
      "epoch2 step22375 [D loss: -0.316103] [G loss: 4.408782]\n",
      "epoch2 step22380 [D loss: -0.109980] [G loss: 4.639727]\n",
      "epoch2 step22385 [D loss: -1.164803] [G loss: 3.588733]\n",
      "epoch2 step22390 [D loss: -1.135207] [G loss: 4.600924]\n",
      "epoch2 step22395 [D loss: -0.245746] [G loss: 4.508912]\n",
      "epoch2 step22400 [D loss: -0.642090] [G loss: 5.319678]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.557141\n",
      "FID: 17.610079\n",
      "0 = 13.494669190120707\n",
      "1 = 0.11549270897513841\n",
      "2 = 0.8170999884605408\n",
      "3 = 0.9179999828338623\n",
      "4 = 0.7161999940872192\n",
      "5 = 0.7638542056083679\n",
      "6 = 0.9179999828338623\n",
      "7 = 7.986548816323282\n",
      "8 = 0.08131092428312373\n",
      "9 = 0.7953000068664551\n",
      "10 = 0.8393999934196472\n",
      "11 = 0.7512000203132629\n",
      "12 = 0.7713655829429626\n",
      "13 = 0.8393999934196472\n",
      "14 = 6.557168483734131\n",
      "15 = 9.325424194335938\n",
      "16 = 0.16194206476211548\n",
      "17 = 6.557140827178955\n",
      "18 = 17.610078811645508\n",
      "epoch2 step22405 [D loss: 0.815996] [G loss: 4.606171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2 step22410 [D loss: -0.847189] [G loss: 4.550842]\n",
      "epoch2 step22415 [D loss: -0.511472] [G loss: 4.660670]\n",
      "epoch2 step22420 [D loss: -1.458130] [G loss: 4.343267]\n",
      "epoch2 step22425 [D loss: -0.610078] [G loss: 4.156451]\n",
      "epoch2 step22430 [D loss: -0.652913] [G loss: 4.181283]\n",
      "epoch2 step22435 [D loss: -0.836916] [G loss: 4.242087]\n",
      "epoch2 step22440 [D loss: -0.825863] [G loss: 4.320102]\n",
      "epoch2 step22445 [D loss: -1.044352] [G loss: 3.772170]\n",
      "epoch2 step22450 [D loss: -0.406106] [G loss: 4.156034]\n",
      "epoch2 step22455 [D loss: -0.511772] [G loss: 3.967922]\n",
      "epoch2 step22460 [D loss: -0.460209] [G loss: 3.701296]\n",
      "epoch2 step22465 [D loss: -0.738278] [G loss: 3.626853]\n",
      "epoch2 step22470 [D loss: -0.674477] [G loss: 3.788753]\n",
      "epoch2 step22475 [D loss: -0.016470] [G loss: 3.564682]\n",
      "epoch2 step22480 [D loss: -1.072342] [G loss: 3.431899]\n",
      "epoch2 step22485 [D loss: 0.061755] [G loss: 3.321154]\n",
      "epoch2 step22490 [D loss: -0.592717] [G loss: 3.792995]\n",
      "epoch2 step22495 [D loss: -1.049520] [G loss: 4.110732]\n",
      "epoch2 step22500 [D loss: -1.030163] [G loss: 3.537872]\n",
      "epoch2 step22505 [D loss: -0.555124] [G loss: 3.800790]\n",
      "epoch2 step22510 [D loss: -0.427687] [G loss: 3.487435]\n",
      "epoch2 step22515 [D loss: -0.450370] [G loss: 3.452955]\n",
      "epoch2 step22520 [D loss: -0.893498] [G loss: 2.926916]\n",
      "epoch2 step22525 [D loss: -1.364918] [G loss: 3.651763]\n",
      "epoch2 step22530 [D loss: -1.282114] [G loss: 3.476559]\n",
      "epoch2 step22535 [D loss: -0.699920] [G loss: 2.694974]\n",
      "epoch2 step22540 [D loss: -0.855905] [G loss: 2.941382]\n",
      "epoch2 step22545 [D loss: -0.839788] [G loss: 3.344365]\n",
      "epoch2 step22550 [D loss: -0.757049] [G loss: 2.795028]\n",
      "epoch2 step22555 [D loss: -1.623842] [G loss: 2.684716]\n",
      "epoch2 step22560 [D loss: -0.255986] [G loss: 2.846570]\n",
      "epoch2 step22565 [D loss: -0.274043] [G loss: 3.135703]\n",
      "epoch2 step22570 [D loss: 1.051701] [G loss: 2.468568]\n",
      "epoch2 step22575 [D loss: -1.103222] [G loss: 2.484652]\n",
      "epoch2 step22580 [D loss: -0.556010] [G loss: 3.668760]\n",
      "epoch2 step22585 [D loss: 0.051175] [G loss: 2.867718]\n",
      "epoch2 step22590 [D loss: -0.058168] [G loss: 3.445337]\n",
      "epoch2 step22595 [D loss: -0.053667] [G loss: 2.522883]\n",
      "epoch2 step22600 [D loss: -0.298754] [G loss: 3.320094]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.430141\n",
      "FID: 18.815531\n",
      "0 = 13.471582966566091\n",
      "1 = 0.11850355575956838\n",
      "2 = 0.8141000270843506\n",
      "3 = 0.9175999760627747\n",
      "4 = 0.7106000185012817\n",
      "5 = 0.7602319717407227\n",
      "6 = 0.9175999760627747\n",
      "7 = 8.022446950793261\n",
      "8 = 0.08344539419255376\n",
      "9 = 0.7983999848365784\n",
      "10 = 0.8389999866485596\n",
      "11 = 0.7577999830245972\n",
      "12 = 0.7759896516799927\n",
      "13 = 0.8389999866485596\n",
      "14 = 6.430164813995361\n",
      "15 = 9.205902099609375\n",
      "16 = 0.18745926022529602\n",
      "17 = 6.430141448974609\n",
      "18 = 18.81553077697754\n",
      "epoch2 step22605 [D loss: 0.007140] [G loss: 2.726120]\n",
      "epoch2 step22610 [D loss: -1.219549] [G loss: 3.720469]\n",
      "epoch2 step22615 [D loss: -1.905768] [G loss: 3.503358]\n",
      "epoch2 step22620 [D loss: -0.442851] [G loss: 2.255659]\n",
      "epoch2 step22625 [D loss: -1.100110] [G loss: 2.768835]\n",
      "epoch2 step22630 [D loss: -1.475191] [G loss: 2.139792]\n",
      "epoch2 step22635 [D loss: -0.783601] [G loss: 2.649563]\n",
      "epoch2 step22640 [D loss: -0.521709] [G loss: 2.359171]\n",
      "epoch2 step22645 [D loss: -1.360813] [G loss: 2.720411]\n",
      "epoch2 step22650 [D loss: 0.456234] [G loss: 2.457504]\n",
      "epoch2 step22655 [D loss: -0.027224] [G loss: 2.806027]\n",
      "epoch2 step22660 [D loss: -0.584801] [G loss: 2.971294]\n",
      "epoch2 step22665 [D loss: -0.792410] [G loss: 3.279893]\n",
      "epoch2 step22670 [D loss: -0.769576] [G loss: 3.097524]\n",
      "epoch2 step22675 [D loss: 0.171009] [G loss: 3.493252]\n",
      "epoch2 step22680 [D loss: -0.072821] [G loss: 2.964725]\n",
      "epoch2 step22685 [D loss: 0.561448] [G loss: 2.755461]\n",
      "epoch2 step22690 [D loss: 0.173210] [G loss: 2.685999]\n",
      "epoch2 step22695 [D loss: -0.523144] [G loss: 3.827374]\n",
      "epoch2 step22700 [D loss: -0.545623] [G loss: 3.380576]\n",
      "epoch2 step22705 [D loss: -0.201222] [G loss: 3.540125]\n",
      "epoch2 step22710 [D loss: -0.345322] [G loss: 4.320311]\n",
      "epoch2 step22715 [D loss: -1.556449] [G loss: 4.436847]\n",
      "epoch2 step22720 [D loss: -0.952264] [G loss: 4.931086]\n",
      "epoch2 step22725 [D loss: -1.260943] [G loss: 4.003013]\n",
      "epoch2 step22730 [D loss: -1.518570] [G loss: 5.436598]\n",
      "epoch2 step22735 [D loss: -1.593262] [G loss: 5.164176]\n",
      "epoch2 step22740 [D loss: -1.544860] [G loss: 4.988818]\n",
      "epoch2 step22745 [D loss: -0.639267] [G loss: 5.041821]\n",
      "epoch2 step22750 [D loss: -0.945795] [G loss: 5.965698]\n",
      "epoch2 step22755 [D loss: -1.008792] [G loss: 4.382628]\n",
      "epoch2 step22760 [D loss: -1.710740] [G loss: 4.900471]\n",
      "epoch2 step22765 [D loss: -0.156613] [G loss: 4.741205]\n",
      "epoch2 step22770 [D loss: -0.560578] [G loss: 4.940536]\n",
      "epoch2 step22775 [D loss: -0.309149] [G loss: 5.453274]\n",
      "epoch2 step22780 [D loss: 0.002860] [G loss: 4.842994]\n",
      "epoch2 step22785 [D loss: -0.541038] [G loss: 5.200218]\n",
      "epoch2 step22790 [D loss: -1.341952] [G loss: 5.502506]\n",
      "epoch2 step22795 [D loss: -1.127327] [G loss: 5.657107]\n",
      "epoch2 step22800 [D loss: -1.635899] [G loss: 5.680503]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.395841\n",
      "FID: 20.289490\n",
      "0 = 12.966152635622057\n",
      "1 = 0.08135929093156005\n",
      "2 = 0.8159000277519226\n",
      "3 = 0.9160000085830688\n",
      "4 = 0.7157999873161316\n",
      "5 = 0.7632061243057251\n",
      "6 = 0.9160000085830688\n",
      "7 = 7.877149832749372\n",
      "8 = 0.08834450405191711\n",
      "9 = 0.7906000018119812\n",
      "10 = 0.8303999900817871\n",
      "11 = 0.7508000135421753\n",
      "12 = 0.7691737413406372\n",
      "13 = 0.8303999900817871\n",
      "14 = 6.395867824554443\n",
      "15 = 9.232991218566895\n",
      "16 = 0.18682704865932465\n",
      "17 = 6.395841121673584\n",
      "18 = 20.28948974609375\n",
      "epoch2 step22805 [D loss: -1.850090] [G loss: 5.500720]\n",
      "epoch2 step22810 [D loss: -1.402155] [G loss: 5.137639]\n",
      "epoch2 step22815 [D loss: -0.994709] [G loss: 5.823301]\n",
      "epoch2 step22820 [D loss: -1.512544] [G loss: 5.678480]\n",
      "epoch2 step22825 [D loss: -1.427939] [G loss: 5.973439]\n",
      "epoch2 step22830 [D loss: 0.087968] [G loss: 6.052649]\n",
      "epoch2 step22835 [D loss: -1.050525] [G loss: 5.069011]\n",
      "epoch2 step22840 [D loss: -0.855431] [G loss: 5.488000]\n",
      "epoch2 step22845 [D loss: -0.678838] [G loss: 5.469620]\n",
      "epoch2 step22850 [D loss: -0.140855] [G loss: 5.409506]\n",
      "epoch2 step22855 [D loss: 0.339527] [G loss: 5.287697]\n",
      "epoch2 step22860 [D loss: -0.875475] [G loss: 6.464320]\n",
      "epoch2 step22865 [D loss: -0.041606] [G loss: 5.853131]\n",
      "epoch2 step22870 [D loss: -0.911075] [G loss: 5.622867]\n",
      "epoch2 step22875 [D loss: -0.890934] [G loss: 6.040662]\n",
      "epoch2 step22880 [D loss: -0.304681] [G loss: 5.312006]\n",
      "epoch2 step22885 [D loss: -0.673989] [G loss: 6.464162]\n",
      "epoch2 step22890 [D loss: -0.587432] [G loss: 5.973033]\n",
      "epoch2 step22895 [D loss: -0.978643] [G loss: 6.613592]\n",
      "epoch2 step22900 [D loss: -1.074396] [G loss: 5.652256]\n",
      "epoch2 step22905 [D loss: -0.654110] [G loss: 5.817647]\n",
      "epoch2 step22910 [D loss: -0.438255] [G loss: 6.379359]\n",
      "epoch2 step22915 [D loss: -0.600959] [G loss: 6.134115]\n",
      "epoch2 step22920 [D loss: -0.330889] [G loss: 6.592713]\n",
      "epoch2 step22925 [D loss: -1.793624] [G loss: 6.078239]\n",
      "epoch2 step22930 [D loss: -0.738974] [G loss: 6.401228]\n",
      "epoch2 step22935 [D loss: -1.540668] [G loss: 6.298571]\n",
      "epoch2 step22940 [D loss: -1.422927] [G loss: 6.749695]\n",
      "epoch2 step22945 [D loss: -1.702662] [G loss: 6.788661]\n",
      "epoch2 step22950 [D loss: -0.101018] [G loss: 6.951818]\n",
      "epoch2 step22955 [D loss: -0.656384] [G loss: 6.279984]\n",
      "epoch2 step22960 [D loss: -0.727688] [G loss: 6.166421]\n",
      "epoch2 step22965 [D loss: -0.009075] [G loss: 6.306490]\n",
      "epoch2 step22970 [D loss: -0.427576] [G loss: 6.665681]\n",
      "epoch2 step22975 [D loss: 0.372533] [G loss: 6.348052]\n",
      "epoch2 step22980 [D loss: 1.303931] [G loss: 6.188386]\n",
      "epoch2 step22985 [D loss: -0.999644] [G loss: 7.317946]\n",
      "epoch2 step22990 [D loss: -0.196005] [G loss: 5.745645]\n",
      "epoch2 step22995 [D loss: -1.508073] [G loss: 6.365948]\n",
      "epoch2 step23000 [D loss: -0.664825] [G loss: 6.328308]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.660481\n",
      "FID: 15.327191\n",
      "0 = 13.04473327140807\n",
      "1 = 0.0783147415120432\n",
      "2 = 0.79830002784729\n",
      "3 = 0.9246000051498413\n",
      "4 = 0.671999990940094\n",
      "5 = 0.7381446361541748\n",
      "6 = 0.9246000051498413\n",
      "7 = 7.664260971498489\n",
      "8 = 0.07098742908354003\n",
      "9 = 0.7854999899864197\n",
      "10 = 0.829800009727478\n",
      "11 = 0.7411999702453613\n",
      "12 = 0.7622634768486023\n",
      "13 = 0.829800009727478\n",
      "14 = 6.6605072021484375\n",
      "15 = 9.358309745788574\n",
      "16 = 0.15419378876686096\n",
      "17 = 6.6604814529418945\n",
      "18 = 15.327191352844238\n",
      "epoch2 step23005 [D loss: -0.751704] [G loss: 6.926664]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2 step23010 [D loss: -1.464280] [G loss: 6.640067]\n",
      "epoch2 step23015 [D loss: -1.425487] [G loss: 7.108136]\n",
      "epoch2 step23020 [D loss: -1.575754] [G loss: 6.722465]\n",
      "epoch2 step23025 [D loss: -2.136346] [G loss: 6.892454]\n",
      "epoch2 step23030 [D loss: -0.206394] [G loss: 6.465666]\n",
      "epoch2 step23035 [D loss: -0.885408] [G loss: 6.630024]\n",
      "epoch2 step23040 [D loss: -0.885143] [G loss: 7.254249]\n",
      "epoch2 step23045 [D loss: -0.560435] [G loss: 6.219210]\n",
      "epoch2 step23050 [D loss: -2.199597] [G loss: 7.186421]\n",
      "epoch2 step23055 [D loss: -1.591791] [G loss: 7.221220]\n",
      "epoch2 step23060 [D loss: 0.266272] [G loss: 6.560816]\n",
      "epoch2 step23065 [D loss: -0.001482] [G loss: 6.507523]\n",
      "epoch2 step23070 [D loss: -0.286884] [G loss: 6.105286]\n",
      "epoch2 step23075 [D loss: 0.042759] [G loss: 5.699341]\n",
      "epoch2 step23080 [D loss: 0.514490] [G loss: 5.670031]\n",
      "epoch2 step23085 [D loss: -0.639147] [G loss: 5.776550]\n",
      "epoch2 step23090 [D loss: -0.423188] [G loss: 6.212831]\n",
      "epoch2 step23095 [D loss: -0.753346] [G loss: 5.798500]\n",
      "epoch2 step23100 [D loss: -0.164852] [G loss: 6.176103]\n",
      "epoch2 step23105 [D loss: -0.572995] [G loss: 5.818780]\n",
      "epoch2 step23110 [D loss: -0.002245] [G loss: 5.653659]\n",
      "epoch2 step23115 [D loss: -0.097823] [G loss: 5.043811]\n",
      "epoch2 step23120 [D loss: 0.320202] [G loss: 5.572456]\n",
      "epoch2 step23125 [D loss: -0.694558] [G loss: 5.410623]\n",
      "epoch2 step23130 [D loss: -1.561090] [G loss: 4.770033]\n",
      "epoch2 step23135 [D loss: 0.255478] [G loss: 4.988424]\n",
      "epoch2 step23140 [D loss: -0.632663] [G loss: 4.952396]\n",
      "epoch2 step23145 [D loss: -0.272291] [G loss: 5.309232]\n",
      "epoch2 step23150 [D loss: -0.218069] [G loss: 5.244119]\n",
      "epoch2 step23155 [D loss: 0.134847] [G loss: 4.985234]\n",
      "epoch2 step23160 [D loss: -1.227170] [G loss: 5.661129]\n",
      "epoch2 step23165 [D loss: -0.986266] [G loss: 5.357398]\n",
      "epoch2 step23170 [D loss: 0.123216] [G loss: 5.865879]\n",
      "epoch2 step23175 [D loss: -1.138159] [G loss: 5.911355]\n",
      "epoch2 step23180 [D loss: -0.478641] [G loss: 5.731325]\n",
      "epoch2 step23185 [D loss: -0.472130] [G loss: 4.922931]\n",
      "epoch2 step23190 [D loss: -0.715518] [G loss: 5.505450]\n",
      "epoch2 step23195 [D loss: -0.946215] [G loss: 5.223502]\n",
      "epoch2 step23200 [D loss: 0.767363] [G loss: 5.702183]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.536408\n",
      "FID: 16.049767\n",
      "0 = 14.06021254029274\n",
      "1 = 0.1481139018733948\n",
      "2 = 0.819100022315979\n",
      "3 = 0.9485999941825867\n",
      "4 = 0.6895999908447266\n",
      "5 = 0.7534551024436951\n",
      "6 = 0.9485999941825867\n",
      "7 = 7.833504182648664\n",
      "8 = 0.07251510857314158\n",
      "9 = 0.7968000173568726\n",
      "10 = 0.8434000015258789\n",
      "11 = 0.7501999735832214\n",
      "12 = 0.7714965343475342\n",
      "13 = 0.8434000015258789\n",
      "14 = 6.536435127258301\n",
      "15 = 9.110067367553711\n",
      "16 = 0.19321689009666443\n",
      "17 = 6.536408424377441\n",
      "18 = 16.049766540527344\n",
      "epoch2 step23205 [D loss: -0.577707] [G loss: 5.044839]\n",
      "epoch2 step23210 [D loss: -0.515601] [G loss: 5.097453]\n",
      "epoch2 step23215 [D loss: -0.655276] [G loss: 4.775576]\n",
      "epoch2 step23220 [D loss: 0.030653] [G loss: 5.344581]\n",
      "epoch2 step23225 [D loss: -0.753227] [G loss: 5.142699]\n",
      "epoch2 step23230 [D loss: -0.902820] [G loss: 4.627599]\n",
      "epoch2 step23235 [D loss: -1.488088] [G loss: 4.861698]\n",
      "epoch2 step23240 [D loss: -0.394774] [G loss: 5.167577]\n",
      "epoch2 step23245 [D loss: -0.575080] [G loss: 4.451982]\n",
      "epoch2 step23250 [D loss: -1.391361] [G loss: 4.499922]\n",
      "epoch2 step23255 [D loss: -2.506546] [G loss: 4.970325]\n",
      "epoch2 step23260 [D loss: -1.879140] [G loss: 4.956980]\n",
      "epoch2 step23265 [D loss: -1.856032] [G loss: 5.020470]\n",
      "epoch2 step23270 [D loss: -0.844927] [G loss: 5.372169]\n",
      "epoch2 step23275 [D loss: -0.592124] [G loss: 4.755202]\n",
      "epoch2 step23280 [D loss: -1.996053] [G loss: 5.644251]\n",
      "epoch2 step23285 [D loss: -0.649312] [G loss: 4.760445]\n",
      "epoch2 step23290 [D loss: -1.409724] [G loss: 5.134752]\n",
      "epoch2 step23295 [D loss: -2.547292] [G loss: 4.521871]\n",
      "epoch2 step23300 [D loss: -1.401287] [G loss: 4.657568]\n",
      "epoch2 step23305 [D loss: -1.669120] [G loss: 5.092520]\n",
      "epoch2 step23310 [D loss: -2.611225] [G loss: 4.793995]\n",
      "epoch2 step23315 [D loss: -2.059216] [G loss: 4.824652]\n",
      "epoch2 step23320 [D loss: -1.006237] [G loss: 4.369656]\n",
      "epoch2 step23325 [D loss: 0.052746] [G loss: 4.500225]\n",
      "epoch2 step23330 [D loss: -0.642512] [G loss: 5.489505]\n",
      "epoch2 step23335 [D loss: -0.106046] [G loss: 4.304287]\n",
      "epoch2 step23340 [D loss: -0.598207] [G loss: 4.270279]\n",
      "epoch2 step23345 [D loss: -0.378125] [G loss: 4.469893]\n",
      "epoch2 step23350 [D loss: -0.501513] [G loss: 4.949018]\n",
      "epoch2 step23355 [D loss: -0.264371] [G loss: 4.615908]\n",
      "epoch2 step23360 [D loss: 0.071784] [G loss: 4.194641]\n",
      "epoch2 step23365 [D loss: -0.038828] [G loss: 4.331728]\n",
      "epoch2 step23370 [D loss: -0.834296] [G loss: 4.256716]\n",
      "epoch2 step23375 [D loss: 0.370563] [G loss: 4.016432]\n",
      "epoch2 step23380 [D loss: 0.635906] [G loss: 3.605391]\n",
      "epoch2 step23385 [D loss: 0.069961] [G loss: 3.434297]\n",
      "epoch2 step23390 [D loss: -0.415143] [G loss: 4.018009]\n",
      "epoch2 step23395 [D loss: -0.610555] [G loss: 4.243803]\n",
      "epoch2 step23400 [D loss: -1.864089] [G loss: 3.633843]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.712094\n",
      "FID: 15.967322\n",
      "0 = 12.84441693954469\n",
      "1 = 0.06302517542317182\n",
      "2 = 0.7997000217437744\n",
      "3 = 0.9196000099182129\n",
      "4 = 0.6797999739646912\n",
      "5 = 0.7417325377464294\n",
      "6 = 0.9196000099182129\n",
      "7 = 7.667291671657544\n",
      "8 = 0.07233487497025823\n",
      "9 = 0.7810999751091003\n",
      "10 = 0.826200008392334\n",
      "11 = 0.7360000014305115\n",
      "12 = 0.7578426003456116\n",
      "13 = 0.826200008392334\n",
      "14 = 6.712121486663818\n",
      "15 = 9.34777545928955\n",
      "16 = 0.15879975259304047\n",
      "17 = 6.712094306945801\n",
      "18 = 15.96732234954834\n",
      "epoch2 step23405 [D loss: -1.563212] [G loss: 3.964205]\n",
      "epoch2 step23410 [D loss: -0.792001] [G loss: 4.053553]\n",
      "epoch2 step23415 [D loss: -0.522163] [G loss: 3.328609]\n",
      "epoch2 step23420 [D loss: -0.379645] [G loss: 3.339799]\n",
      "epoch2 step23425 [D loss: -0.474153] [G loss: 3.094390]\n",
      "epoch2 step23430 [D loss: -1.924026] [G loss: 3.523501]\n",
      "epoch2 step23435 [D loss: -1.405174] [G loss: 2.861805]\n",
      "epoch2 step23440 [D loss: -1.545559] [G loss: 3.336616]\n",
      "epoch2 step23445 [D loss: -0.960257] [G loss: 2.974574]\n",
      "epoch2 step23450 [D loss: -1.169489] [G loss: 3.013969]\n",
      "epoch2 step23455 [D loss: -1.539784] [G loss: 3.954965]\n",
      "epoch2 step23460 [D loss: -1.533308] [G loss: 3.474079]\n",
      "epoch2 step23465 [D loss: -1.874258] [G loss: 3.349856]\n",
      "epoch2 step23470 [D loss: 1.130825] [G loss: 2.910466]\n",
      "epoch2 step23475 [D loss: 0.094240] [G loss: 4.011664]\n",
      "epoch2 step23480 [D loss: 0.610204] [G loss: 3.934150]\n",
      "epoch2 step23485 [D loss: -0.142960] [G loss: 3.038073]\n",
      "epoch2 step23490 [D loss: 0.682754] [G loss: 4.201554]\n",
      "epoch2 step23495 [D loss: 0.421837] [G loss: 3.597780]\n",
      "epoch2 step23500 [D loss: 0.790378] [G loss: 4.350751]\n",
      "epoch2 step23505 [D loss: 0.416033] [G loss: 3.812172]\n",
      "epoch2 step23510 [D loss: -1.559610] [G loss: 4.544533]\n",
      "epoch2 step23515 [D loss: 0.074468] [G loss: 3.971714]\n",
      "epoch2 step23520 [D loss: -0.804834] [G loss: 3.703462]\n",
      "epoch2 step23525 [D loss: -0.720154] [G loss: 3.016598]\n",
      "epoch2 step23530 [D loss: -0.614659] [G loss: 3.701231]\n",
      "epoch2 step23535 [D loss: -0.786902] [G loss: 3.201708]\n",
      "epoch2 step23540 [D loss: -1.038910] [G loss: 3.635289]\n",
      "epoch2 step23545 [D loss: 0.382734] [G loss: 2.918638]\n",
      "epoch2 step23550 [D loss: -0.634189] [G loss: 3.316936]\n",
      "epoch2 step23555 [D loss: -1.022131] [G loss: 3.454701]\n",
      "epoch2 step23560 [D loss: -0.443127] [G loss: 2.697947]\n",
      "epoch2 step23565 [D loss: 0.290386] [G loss: 2.675549]\n",
      "epoch2 step23570 [D loss: 0.370998] [G loss: 3.025418]\n",
      "epoch2 step23575 [D loss: -0.759105] [G loss: 2.973342]\n",
      "epoch2 step23580 [D loss: 0.064649] [G loss: 2.735557]\n",
      "epoch2 step23585 [D loss: -0.958536] [G loss: 2.952918]\n",
      "epoch2 step23590 [D loss: 0.059767] [G loss: 2.805906]\n",
      "epoch2 step23595 [D loss: 0.172292] [G loss: 2.737941]\n",
      "epoch2 step23600 [D loss: -1.584899] [G loss: 3.056379]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.457646\n",
      "FID: 21.748020\n",
      "0 = 12.73380635385511\n",
      "1 = 0.08743029951832915\n",
      "2 = 0.8278999924659729\n",
      "3 = 0.8876000046730042\n",
      "4 = 0.7681999802589417\n",
      "5 = 0.7929247617721558\n",
      "6 = 0.8876000046730042\n",
      "7 = 7.961376979470253\n",
      "8 = 0.08993790709805688\n",
      "9 = 0.7968000173568726\n",
      "10 = 0.8226000070571899\n",
      "11 = 0.7710000276565552\n",
      "12 = 0.7822365760803223\n",
      "13 = 0.8226000070571899\n",
      "14 = 6.457670211791992\n",
      "15 = 9.466103553771973\n",
      "16 = 0.1439678966999054\n",
      "17 = 6.457645893096924\n",
      "18 = 21.74802017211914\n",
      "epoch2 step23605 [D loss: 0.008705] [G loss: 3.382149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2 step23610 [D loss: -1.200684] [G loss: 2.977176]\n",
      "epoch2 step23615 [D loss: 0.079363] [G loss: 3.122059]\n",
      "epoch2 step23620 [D loss: 0.349532] [G loss: 2.769298]\n",
      "epoch2 step23625 [D loss: -0.887231] [G loss: 4.019876]\n",
      "epoch2 step23630 [D loss: -0.035748] [G loss: 3.760381]\n",
      "epoch2 step23635 [D loss: -1.010592] [G loss: 3.392943]\n",
      "epoch2 step23640 [D loss: -0.709728] [G loss: 3.667611]\n",
      "epoch2 step23645 [D loss: -1.435232] [G loss: 3.139276]\n",
      "epoch2 step23650 [D loss: -0.516745] [G loss: 2.358389]\n",
      "epoch2 step23655 [D loss: -1.272910] [G loss: 3.290163]\n",
      "epoch2 step23660 [D loss: -1.399494] [G loss: 3.243395]\n",
      "epoch2 step23665 [D loss: -1.624267] [G loss: 3.306545]\n",
      "epoch2 step23670 [D loss: -0.324995] [G loss: 3.835542]\n",
      "epoch2 step23675 [D loss: 0.406168] [G loss: 3.925169]\n",
      "epoch2 step23680 [D loss: 0.352043] [G loss: 3.637930]\n",
      "epoch2 step23685 [D loss: -1.597892] [G loss: 4.184291]\n",
      "epoch2 step23690 [D loss: -0.459180] [G loss: 3.808746]\n",
      "epoch2 step23695 [D loss: -0.857644] [G loss: 4.282126]\n",
      "epoch2 step23700 [D loss: -0.011660] [G loss: 4.040554]\n",
      "epoch2 step23705 [D loss: -1.243625] [G loss: 4.129824]\n",
      "epoch2 step23710 [D loss: -0.400078] [G loss: 3.876617]\n",
      "epoch2 step23715 [D loss: -0.736106] [G loss: 3.852326]\n",
      "epoch2 step23720 [D loss: -1.742825] [G loss: 5.367301]\n",
      "epoch2 step23725 [D loss: -1.239245] [G loss: 4.114517]\n",
      "epoch2 step23730 [D loss: -1.104790] [G loss: 4.670900]\n",
      "epoch2 step23735 [D loss: -1.088715] [G loss: 4.107356]\n",
      "epoch2 step23740 [D loss: -2.780713] [G loss: 5.347569]\n",
      "epoch2 step23745 [D loss: -1.250243] [G loss: 5.261596]\n",
      "epoch2 step23750 [D loss: -1.025923] [G loss: 5.366742]\n",
      "epoch2 step23755 [D loss: -0.265944] [G loss: 5.012982]\n",
      "epoch2 step23760 [D loss: -1.727509] [G loss: 5.380455]\n",
      "epoch2 step23765 [D loss: 0.135224] [G loss: 5.031769]\n",
      "epoch2 step23770 [D loss: 0.427165] [G loss: 4.711424]\n",
      "epoch2 step23775 [D loss: 0.235866] [G loss: 4.606959]\n",
      "epoch2 step23780 [D loss: 0.338282] [G loss: 4.865921]\n",
      "epoch2 step23785 [D loss: -0.342446] [G loss: 4.546824]\n",
      "epoch2 step23790 [D loss: -0.551212] [G loss: 4.629135]\n",
      "epoch2 step23795 [D loss: -0.297265] [G loss: 4.108515]\n",
      "epoch2 step23800 [D loss: -0.767388] [G loss: 4.305834]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.504818\n",
      "FID: 16.203293\n",
      "0 = 13.562324204969432\n",
      "1 = 0.12375690325353682\n",
      "2 = 0.8133999705314636\n",
      "3 = 0.9205999970436096\n",
      "4 = 0.7062000036239624\n",
      "5 = 0.7580698132514954\n",
      "6 = 0.9205999970436096\n",
      "7 = 7.797815092897417\n",
      "8 = 0.07606851460883748\n",
      "9 = 0.79339998960495\n",
      "10 = 0.8378000259399414\n",
      "11 = 0.7490000128746033\n",
      "12 = 0.7694709897041321\n",
      "13 = 0.8378000259399414\n",
      "14 = 6.504847049713135\n",
      "15 = 9.284996032714844\n",
      "16 = 0.1702234148979187\n",
      "17 = 6.504818439483643\n",
      "18 = 16.203292846679688\n",
      "epoch2 step23805 [D loss: -0.345421] [G loss: 4.927386]\n",
      "epoch2 step23810 [D loss: -0.782334] [G loss: 4.373232]\n",
      "epoch2 step23815 [D loss: -1.171515] [G loss: 3.576816]\n",
      "epoch2 step23820 [D loss: -1.082840] [G loss: 4.107463]\n",
      "epoch2 step23825 [D loss: -0.038080] [G loss: 4.693900]\n",
      "epoch2 step23830 [D loss: -1.022034] [G loss: 4.345012]\n",
      "epoch2 step23835 [D loss: -0.213770] [G loss: 4.853501]\n",
      "epoch2 step23840 [D loss: -0.507410] [G loss: 5.320101]\n",
      "epoch2 step23845 [D loss: 0.031012] [G loss: 5.203068]\n",
      "epoch2 step23850 [D loss: -0.906709] [G loss: 5.461558]\n",
      "epoch2 step23855 [D loss: -0.201300] [G loss: 5.134128]\n",
      "epoch2 step23860 [D loss: -0.760245] [G loss: 6.267140]\n",
      "epoch2 step23865 [D loss: -0.518232] [G loss: 5.937051]\n",
      "epoch2 step23870 [D loss: -1.544212] [G loss: 6.059657]\n",
      "epoch2 step23875 [D loss: -1.191027] [G loss: 6.036320]\n",
      "epoch2 step23880 [D loss: -1.150741] [G loss: 5.399134]\n",
      "epoch2 step23885 [D loss: -1.457650] [G loss: 5.776169]\n",
      "epoch2 step23890 [D loss: -1.270415] [G loss: 5.964288]\n",
      "epoch2 step23895 [D loss: -1.413813] [G loss: 6.018801]\n",
      "epoch2 step23900 [D loss: -1.362025] [G loss: 5.332828]\n",
      "epoch2 step23905 [D loss: -1.040447] [G loss: 5.959409]\n",
      "epoch2 step23910 [D loss: -0.136786] [G loss: 5.967690]\n",
      "epoch2 step23915 [D loss: 0.224806] [G loss: 6.089182]\n",
      "epoch2 step23920 [D loss: -0.831584] [G loss: 6.005862]\n",
      "epoch2 step23925 [D loss: -0.975186] [G loss: 6.103616]\n",
      "epoch2 step23930 [D loss: -0.235976] [G loss: 5.244967]\n",
      "epoch2 step23935 [D loss: 0.109252] [G loss: 6.361256]\n",
      "epoch2 step23940 [D loss: -0.650501] [G loss: 5.468047]\n",
      "epoch2 step23945 [D loss: -0.461485] [G loss: 5.448786]\n",
      "epoch2 step23950 [D loss: -0.068871] [G loss: 5.027498]\n",
      "epoch2 step23955 [D loss: -0.428258] [G loss: 5.551720]\n",
      "epoch2 step23960 [D loss: -0.088496] [G loss: 5.946734]\n",
      "epoch2 step23965 [D loss: -0.905748] [G loss: 4.835914]\n",
      "epoch2 step23970 [D loss: -1.214573] [G loss: 5.628561]\n",
      "epoch2 step23975 [D loss: -1.959615] [G loss: 5.795795]\n",
      "epoch2 step23980 [D loss: -0.196581] [G loss: 4.744843]\n",
      "epoch2 step23985 [D loss: -0.562662] [G loss: 5.348372]\n",
      "epoch2 step23990 [D loss: -1.386856] [G loss: 5.708597]\n",
      "epoch2 step23995 [D loss: -0.735302] [G loss: 5.437023]\n",
      "epoch2 step24000 [D loss: -0.622462] [G loss: 5.820264]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.505648\n",
      "FID: 17.999569\n",
      "0 = 12.886653456020346\n",
      "1 = 0.06633440506930349\n",
      "2 = 0.8219000101089478\n",
      "3 = 0.9067999720573425\n",
      "4 = 0.7369999885559082\n",
      "5 = 0.7751752734184265\n",
      "6 = 0.9067999720573425\n",
      "7 = 7.848789701008781\n",
      "8 = 0.08037233965847787\n",
      "9 = 0.7932000160217285\n",
      "10 = 0.8313999772071838\n",
      "11 = 0.7549999952316284\n",
      "12 = 0.7723894715309143\n",
      "13 = 0.8313999772071838\n",
      "14 = 6.505675315856934\n",
      "15 = 9.478076934814453\n",
      "16 = 0.13932639360427856\n",
      "17 = 6.505648136138916\n",
      "18 = 17.999568939208984\n",
      "epoch2 step24005 [D loss: -0.496293] [G loss: 5.726067]\n",
      "epoch2 step24010 [D loss: -1.073507] [G loss: 5.139432]\n",
      "epoch2 step24015 [D loss: -0.495902] [G loss: 5.480483]\n",
      "epoch2 step24020 [D loss: -0.201456] [G loss: 4.666606]\n",
      "epoch2 step24025 [D loss: -0.245550] [G loss: 5.115393]\n",
      "epoch2 step24030 [D loss: -1.367539] [G loss: 5.308963]\n",
      "epoch2 step24035 [D loss: -1.132119] [G loss: 4.448986]\n",
      "epoch2 step24040 [D loss: -0.389607] [G loss: 5.084931]\n",
      "epoch2 step24045 [D loss: -0.473384] [G loss: 4.699522]\n",
      "epoch2 step24050 [D loss: -0.163318] [G loss: 3.490194]\n",
      "epoch2 step24055 [D loss: -0.052439] [G loss: 4.746912]\n",
      "epoch2 step24060 [D loss: -0.253167] [G loss: 4.057085]\n",
      "epoch2 step24065 [D loss: -0.296735] [G loss: 3.710295]\n",
      "epoch2 step24070 [D loss: -0.968178] [G loss: 4.037307]\n",
      "epoch2 step24075 [D loss: -0.761347] [G loss: 3.703617]\n",
      "epoch2 step24080 [D loss: -0.103957] [G loss: 3.612603]\n",
      "epoch2 step24085 [D loss: -1.043074] [G loss: 3.271076]\n",
      "epoch2 step24090 [D loss: -0.299385] [G loss: 3.809794]\n",
      "epoch2 step24095 [D loss: 0.141699] [G loss: 3.448689]\n",
      "epoch2 step24100 [D loss: -0.740177] [G loss: 4.327168]\n",
      "epoch2 step24105 [D loss: 0.157692] [G loss: 3.134877]\n",
      "epoch2 step24110 [D loss: -0.579217] [G loss: 4.127888]\n",
      "epoch2 step24115 [D loss: -0.267846] [G loss: 4.008669]\n",
      "epoch2 step24120 [D loss: -0.606360] [G loss: 3.708007]\n",
      "epoch2 step24125 [D loss: 0.332348] [G loss: 3.011469]\n",
      "epoch2 step24130 [D loss: -0.687299] [G loss: 3.746542]\n",
      "epoch2 step24135 [D loss: -0.161014] [G loss: 4.089606]\n",
      "epoch2 step24140 [D loss: -1.308566] [G loss: 3.436064]\n",
      "epoch2 step24145 [D loss: -0.242085] [G loss: 4.148485]\n",
      "epoch2 step24150 [D loss: -0.889693] [G loss: 4.142067]\n",
      "epoch2 step24155 [D loss: -0.517796] [G loss: 3.973388]\n",
      "epoch2 step24160 [D loss: -0.015624] [G loss: 3.995289]\n",
      "epoch2 step24165 [D loss: 0.832645] [G loss: 3.994487]\n",
      "epoch2 step24170 [D loss: 0.559340] [G loss: 4.184835]\n",
      "epoch2 step24175 [D loss: -0.677139] [G loss: 4.330775]\n",
      "epoch2 step24180 [D loss: -0.595940] [G loss: 4.103580]\n",
      "epoch2 step24185 [D loss: -0.182893] [G loss: 4.427638]\n",
      "epoch2 step24190 [D loss: -1.191414] [G loss: 4.232450]\n",
      "epoch2 step24195 [D loss: -0.759772] [G loss: 4.948176]\n",
      "epoch2 step24200 [D loss: -0.480282] [G loss: 3.937626]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.452082\n",
      "FID: 18.489517\n",
      "0 = 12.920314673137671\n",
      "1 = 0.06563342812322873\n",
      "2 = 0.8201000094413757\n",
      "3 = 0.9192000031471252\n",
      "4 = 0.7210000157356262\n",
      "5 = 0.7671507000923157\n",
      "6 = 0.9192000031471252\n",
      "7 = 7.803145648169534\n",
      "8 = 0.08134463740834558\n",
      "9 = 0.7896999716758728\n",
      "10 = 0.8289999961853027\n",
      "11 = 0.7504000067710876\n",
      "12 = 0.7685889005661011\n",
      "13 = 0.8289999961853027\n",
      "14 = 6.4521074295043945\n",
      "15 = 9.355124473571777\n",
      "16 = 0.15884459018707275\n",
      "17 = 6.45208215713501\n",
      "18 = 18.489517211914062\n",
      "epoch2 step24205 [D loss: -1.616320] [G loss: 4.433381]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2 step24210 [D loss: -1.427121] [G loss: 4.358672]\n",
      "epoch2 step24215 [D loss: -1.051167] [G loss: 4.581463]\n",
      "epoch2 step24220 [D loss: -1.562118] [G loss: 3.479707]\n",
      "epoch2 step24225 [D loss: -0.582469] [G loss: 3.516474]\n",
      "epoch2 step24230 [D loss: -0.411718] [G loss: 3.664499]\n",
      "epoch2 step24235 [D loss: 0.447071] [G loss: 3.417484]\n",
      "epoch2 step24240 [D loss: -2.042863] [G loss: 3.710211]\n",
      "epoch2 step24245 [D loss: 0.021767] [G loss: 3.399730]\n",
      "epoch2 step24250 [D loss: -1.204481] [G loss: 3.547736]\n",
      "epoch2 step24255 [D loss: -1.606427] [G loss: 4.918138]\n",
      "epoch2 step24260 [D loss: -0.808239] [G loss: 3.397677]\n",
      "epoch2 step24265 [D loss: -1.057665] [G loss: 4.367046]\n",
      "epoch2 step24270 [D loss: -1.049767] [G loss: 3.877032]\n",
      "epoch2 step24275 [D loss: -0.265164] [G loss: 4.154594]\n",
      "epoch2 step24280 [D loss: -0.988603] [G loss: 3.997005]\n",
      "epoch2 step24285 [D loss: -1.891829] [G loss: 3.873571]\n",
      "epoch2 step24290 [D loss: -1.112369] [G loss: 4.167654]\n",
      "epoch2 step24295 [D loss: -0.921183] [G loss: 4.669662]\n",
      "epoch2 step24300 [D loss: -1.258869] [G loss: 5.066510]\n",
      "epoch2 step24305 [D loss: -0.845663] [G loss: 4.396024]\n",
      "epoch2 step24310 [D loss: -0.823500] [G loss: 4.266235]\n",
      "epoch2 step24315 [D loss: -0.466455] [G loss: 3.884923]\n",
      "epoch2 step24320 [D loss: -1.173494] [G loss: 4.279341]\n",
      "epoch2 step24325 [D loss: -1.591394] [G loss: 4.543515]\n",
      "epoch2 step24330 [D loss: 0.157820] [G loss: 5.021597]\n",
      "epoch2 step24335 [D loss: 0.621722] [G loss: 4.773218]\n",
      "epoch2 step24340 [D loss: 0.146348] [G loss: 4.469054]\n",
      "epoch2 step24345 [D loss: 0.497843] [G loss: 4.660918]\n",
      "epoch2 step24350 [D loss: 0.340619] [G loss: 5.139148]\n",
      "epoch2 step24355 [D loss: 0.358932] [G loss: 4.808053]\n",
      "epoch2 step24360 [D loss: -0.178858] [G loss: 4.932673]\n",
      "epoch2 step24365 [D loss: -0.628655] [G loss: 5.041950]\n",
      "epoch2 step24370 [D loss: -0.571265] [G loss: 4.531218]\n",
      "epoch2 step24375 [D loss: -1.075576] [G loss: 4.954574]\n",
      "epoch2 step24380 [D loss: -0.545210] [G loss: 5.039117]\n",
      "epoch2 step24385 [D loss: -0.762570] [G loss: 4.811003]\n",
      "epoch2 step24390 [D loss: -0.564547] [G loss: 5.018517]\n",
      "epoch2 step24395 [D loss: -0.989880] [G loss: 5.117661]\n",
      "epoch2 step24400 [D loss: -0.908543] [G loss: 4.813278]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.166404\n",
      "FID: 27.717268\n",
      "0 = 12.983175269174584\n",
      "1 = 0.12005812270501989\n",
      "2 = 0.8481000065803528\n",
      "3 = 0.9003999829292297\n",
      "4 = 0.795799970626831\n",
      "5 = 0.815136730670929\n",
      "6 = 0.9003999829292297\n",
      "7 = 8.456812252187735\n",
      "8 = 0.10537998561445636\n",
      "9 = 0.8151999711990356\n",
      "10 = 0.8367999792098999\n",
      "11 = 0.7936000227928162\n",
      "12 = 0.8021472096443176\n",
      "13 = 0.8367999792098999\n",
      "14 = 6.166425704956055\n",
      "15 = 9.38730239868164\n",
      "16 = 0.17406605184078217\n",
      "17 = 6.166403770446777\n",
      "18 = 27.717267990112305\n",
      "epoch2 step24405 [D loss: -0.823355] [G loss: 4.957252]\n",
      "epoch2 step24410 [D loss: -0.187078] [G loss: 5.011550]\n",
      "epoch2 step24415 [D loss: -1.488743] [G loss: 5.072290]\n",
      "epoch2 step24420 [D loss: -1.398619] [G loss: 5.726674]\n",
      "epoch2 step24425 [D loss: -1.508915] [G loss: 5.875029]\n",
      "epoch2 step24430 [D loss: -0.703205] [G loss: 5.271068]\n",
      "epoch2 step24435 [D loss: -0.757409] [G loss: 5.875244]\n",
      "epoch2 step24440 [D loss: -0.379815] [G loss: 5.428422]\n",
      "epoch2 step24445 [D loss: 0.151906] [G loss: 5.276375]\n",
      "epoch2 step24450 [D loss: -1.563089] [G loss: 5.209641]\n",
      "epoch2 step24455 [D loss: -0.717550] [G loss: 5.398147]\n",
      "epoch2 step24460 [D loss: -0.922607] [G loss: 5.605152]\n",
      "epoch2 step24465 [D loss: -1.450878] [G loss: 5.851126]\n",
      "epoch2 step24470 [D loss: -1.143856] [G loss: 4.682324]\n",
      "epoch2 step24475 [D loss: -0.915936] [G loss: 5.112527]\n",
      "epoch2 step24480 [D loss: -0.649559] [G loss: 5.245743]\n",
      "epoch2 step24485 [D loss: -0.423274] [G loss: 5.325318]\n",
      "epoch2 step24490 [D loss: -0.199609] [G loss: 4.330814]\n",
      "epoch2 step24495 [D loss: -1.608526] [G loss: 4.654888]\n",
      "epoch2 step24500 [D loss: -0.607312] [G loss: 3.914905]\n",
      "epoch2 step24505 [D loss: -0.615466] [G loss: 4.876905]\n",
      "epoch2 step24510 [D loss: -0.470895] [G loss: 4.824799]\n",
      "epoch2 step24515 [D loss: -0.096889] [G loss: 4.673623]\n",
      "epoch2 step24520 [D loss: -0.944043] [G loss: 4.659066]\n",
      "epoch2 step24525 [D loss: -0.802159] [G loss: 4.668376]\n",
      "epoch2 step24530 [D loss: -0.000567] [G loss: 4.797122]\n",
      "epoch2 step24535 [D loss: -0.014266] [G loss: 4.118038]\n",
      "epoch2 step24540 [D loss: -2.009371] [G loss: 4.494469]\n",
      "epoch2 step24545 [D loss: 0.708806] [G loss: 4.224415]\n",
      "epoch2 step24550 [D loss: 0.247041] [G loss: 4.491819]\n",
      "epoch2 step24555 [D loss: -0.944853] [G loss: 4.327206]\n",
      "epoch2 step24560 [D loss: -1.073525] [G loss: 4.220595]\n",
      "epoch2 step24565 [D loss: -0.706869] [G loss: 5.222267]\n",
      "epoch2 step24570 [D loss: -1.314628] [G loss: 4.226803]\n",
      "epoch2 step24575 [D loss: 0.650810] [G loss: 4.289182]\n",
      "epoch2 step24580 [D loss: 1.026097] [G loss: 4.582030]\n",
      "epoch2 step24585 [D loss: -0.525783] [G loss: 3.680589]\n",
      "epoch2 step24590 [D loss: -0.167821] [G loss: 4.073078]\n",
      "epoch2 step24595 [D loss: -1.414087] [G loss: 3.681516]\n",
      "epoch2 step24600 [D loss: -0.392931] [G loss: 3.696261]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.475680\n",
      "FID: 20.041014\n",
      "0 = 13.237621270275088\n",
      "1 = 0.097562210581104\n",
      "2 = 0.8083000183105469\n",
      "3 = 0.9101999998092651\n",
      "4 = 0.7063999772071838\n",
      "5 = 0.7561056613922119\n",
      "6 = 0.9101999998092651\n",
      "7 = 7.906055387139356\n",
      "8 = 0.08916582505253795\n",
      "9 = 0.7889000177383423\n",
      "10 = 0.8277999758720398\n",
      "11 = 0.75\n",
      "12 = 0.7680460214614868\n",
      "13 = 0.8277999758720398\n",
      "14 = 6.475705623626709\n",
      "15 = 9.154762268066406\n",
      "16 = 0.188867449760437\n",
      "17 = 6.475679874420166\n",
      "18 = 20.041013717651367\n",
      "epoch2 step24605 [D loss: -0.415207] [G loss: 4.870612]\n",
      "epoch2 step24610 [D loss: -0.521233] [G loss: 4.460661]\n",
      "epoch2 step24615 [D loss: -1.141334] [G loss: 4.659218]\n",
      "epoch2 step24620 [D loss: -1.747025] [G loss: 4.680619]\n",
      "epoch2 step24625 [D loss: -2.167304] [G loss: 4.956873]\n",
      "epoch2 step24630 [D loss: -1.437466] [G loss: 4.592599]\n",
      "epoch2 step24635 [D loss: -2.359477] [G loss: 5.189861]\n",
      "epoch2 step24640 [D loss: -1.196704] [G loss: 4.599436]\n",
      "epoch2 step24645 [D loss: -0.493822] [G loss: 5.570896]\n",
      "epoch2 step24650 [D loss: 0.190574] [G loss: 5.741525]\n",
      "epoch2 step24655 [D loss: -0.034775] [G loss: 6.042205]\n",
      "epoch2 step24660 [D loss: -0.392367] [G loss: 6.064692]\n",
      "epoch2 step24665 [D loss: -1.052782] [G loss: 5.720054]\n",
      "epoch2 step24670 [D loss: -0.167253] [G loss: 5.186005]\n",
      "epoch2 step24675 [D loss: -0.252854] [G loss: 6.018411]\n",
      "epoch2 step24680 [D loss: -0.391467] [G loss: 6.039843]\n",
      "epoch2 step24685 [D loss: 0.147737] [G loss: 6.121651]\n",
      "epoch2 step24690 [D loss: -0.738312] [G loss: 5.763027]\n",
      "epoch2 step24695 [D loss: -0.540298] [G loss: 6.425966]\n",
      "epoch2 step24700 [D loss: 0.547199] [G loss: 5.966839]\n",
      "epoch2 step24705 [D loss: -0.546512] [G loss: 6.590436]\n",
      "epoch2 step24710 [D loss: -0.221622] [G loss: 6.289640]\n",
      "epoch2 step24715 [D loss: -1.229199] [G loss: 6.683650]\n",
      "epoch2 step24720 [D loss: -0.469388] [G loss: 5.599276]\n",
      "epoch2 step24725 [D loss: -0.230705] [G loss: 6.197432]\n",
      "epoch2 step24730 [D loss: -1.332851] [G loss: 6.110283]\n",
      "epoch2 step24735 [D loss: 0.116406] [G loss: 5.098417]\n",
      "epoch2 step24740 [D loss: -0.534552] [G loss: 6.410095]\n",
      "epoch2 step24745 [D loss: -0.647904] [G loss: 5.878418]\n",
      "epoch2 step24750 [D loss: -0.642004] [G loss: 6.963445]\n",
      "epoch2 step24755 [D loss: -0.629407] [G loss: 5.463449]\n",
      "epoch2 step24760 [D loss: -0.324208] [G loss: 6.075566]\n",
      "epoch2 step24765 [D loss: -0.716522] [G loss: 5.565711]\n",
      "epoch2 step24770 [D loss: -1.557968] [G loss: 6.598378]\n",
      "epoch2 step24775 [D loss: -0.335683] [G loss: 6.531168]\n",
      "epoch2 step24780 [D loss: -1.022525] [G loss: 5.580066]\n",
      "epoch2 step24785 [D loss: -1.236090] [G loss: 6.251968]\n",
      "epoch2 step24790 [D loss: -1.185768] [G loss: 6.559097]\n",
      "epoch2 step24795 [D loss: 0.414712] [G loss: 6.493501]\n",
      "epoch2 step24800 [D loss: -0.063506] [G loss: 6.238394]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.594689\n",
      "FID: 16.506042\n",
      "0 = 13.050266910553047\n",
      "1 = 0.0828266635514697\n",
      "2 = 0.8004999756813049\n",
      "3 = 0.9089999794960022\n",
      "4 = 0.6919999718666077\n",
      "5 = 0.7469186782836914\n",
      "6 = 0.9089999794960022\n",
      "7 = 7.8258573086738545\n",
      "8 = 0.07606381307203589\n",
      "9 = 0.7850000262260437\n",
      "10 = 0.8259999752044678\n",
      "11 = 0.7440000176429749\n",
      "12 = 0.7634010910987854\n",
      "13 = 0.8259999752044678\n",
      "14 = 6.594714641571045\n",
      "15 = 9.360014915466309\n",
      "16 = 0.1562589406967163\n",
      "17 = 6.594688892364502\n",
      "18 = 16.50604248046875\n",
      "epoch2 step24805 [D loss: -1.440494] [G loss: 5.904819]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2 step24810 [D loss: 0.693089] [G loss: 6.029506]\n",
      "epoch2 step24815 [D loss: 0.197667] [G loss: 5.725284]\n",
      "epoch2 step24820 [D loss: -0.531022] [G loss: 6.015978]\n",
      "epoch2 step24825 [D loss: 0.399741] [G loss: 5.522002]\n",
      "epoch2 step24830 [D loss: 0.212083] [G loss: 5.255403]\n",
      "epoch2 step24835 [D loss: -0.578259] [G loss: 5.646446]\n",
      "epoch2 step24840 [D loss: -1.543828] [G loss: 5.119759]\n",
      "epoch2 step24845 [D loss: -0.298331] [G loss: 4.493123]\n",
      "epoch2 step24850 [D loss: -0.904591] [G loss: 5.541657]\n",
      "epoch2 step24855 [D loss: -0.372489] [G loss: 5.354405]\n",
      "epoch2 step24860 [D loss: 0.528997] [G loss: 5.693798]\n",
      "epoch2 step24865 [D loss: -0.317663] [G loss: 5.701313]\n",
      "epoch2 step24870 [D loss: -0.783315] [G loss: 4.717588]\n",
      "epoch2 step24875 [D loss: -0.600607] [G loss: 5.116263]\n",
      "epoch2 step24880 [D loss: -0.300892] [G loss: 4.836961]\n",
      "epoch2 step24885 [D loss: -0.662106] [G loss: 4.797168]\n",
      "epoch2 step24890 [D loss: -0.042027] [G loss: 4.395060]\n",
      "epoch2 step24895 [D loss: -0.854098] [G loss: 5.237026]\n",
      "epoch2 step24900 [D loss: 0.058174] [G loss: 4.905523]\n",
      "epoch2 step24905 [D loss: -0.968853] [G loss: 5.136698]\n",
      "epoch2 step24910 [D loss: -1.076481] [G loss: 5.116125]\n",
      "epoch2 step24915 [D loss: -0.150686] [G loss: 4.800239]\n",
      "epoch2 step24920 [D loss: -1.201704] [G loss: 4.217622]\n",
      "epoch2 step24925 [D loss: -0.872598] [G loss: 4.337577]\n",
      "epoch2 step24930 [D loss: -0.051860] [G loss: 3.817138]\n",
      "epoch2 step24935 [D loss: -1.151733] [G loss: 4.946331]\n",
      "epoch2 step24940 [D loss: -0.314015] [G loss: 3.530010]\n",
      "epoch2 step24945 [D loss: -0.646391] [G loss: 3.731788]\n",
      "epoch2 step24950 [D loss: -0.525800] [G loss: 4.333298]\n",
      "epoch2 step24955 [D loss: -0.925833] [G loss: 4.444722]\n",
      "epoch2 step24960 [D loss: -0.360483] [G loss: 4.115862]\n",
      "epoch2 step24965 [D loss: -0.118456] [G loss: 4.152037]\n",
      "epoch2 step24970 [D loss: -0.526719] [G loss: 4.243547]\n",
      "epoch2 step24975 [D loss: -0.890921] [G loss: 4.810246]\n",
      "epoch2 step24980 [D loss: 0.158712] [G loss: 4.706718]\n",
      "epoch2 step24985 [D loss: -0.198382] [G loss: 4.792354]\n",
      "epoch2 step24990 [D loss: -0.954728] [G loss: 4.979284]\n",
      "epoch2 step24995 [D loss: -0.365226] [G loss: 4.490126]\n",
      "epoch2 step25000 [D loss: -0.595828] [G loss: 4.623907]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.505098\n",
      "FID: 19.035269\n",
      "0 = 12.735872493934684\n",
      "1 = 0.07117023755062712\n",
      "2 = 0.8119000196456909\n",
      "3 = 0.8902000188827515\n",
      "4 = 0.7336000204086304\n",
      "5 = 0.7696697115898132\n",
      "6 = 0.8902000188827515\n",
      "7 = 7.840130455410466\n",
      "8 = 0.0812962620418975\n",
      "9 = 0.7878000140190125\n",
      "10 = 0.8222000002861023\n",
      "11 = 0.7534000277519226\n",
      "12 = 0.7692739367485046\n",
      "13 = 0.8222000002861023\n",
      "14 = 6.505124092102051\n",
      "15 = 9.40187931060791\n",
      "16 = 0.15413658320903778\n",
      "17 = 6.50509786605835\n",
      "18 = 19.035268783569336\n",
      "epoch2 step25005 [D loss: -0.524148] [G loss: 4.567239]\n",
      "epoch2 step25010 [D loss: -0.382192] [G loss: 4.752823]\n",
      "epoch2 step25015 [D loss: 0.013059] [G loss: 4.137768]\n",
      "epoch2 step25020 [D loss: 0.085199] [G loss: 4.406068]\n",
      "epoch2 step25025 [D loss: -0.837869] [G loss: 3.781732]\n",
      "epoch2 step25030 [D loss: -0.383751] [G loss: 4.208010]\n",
      "epoch2 step25035 [D loss: -0.744935] [G loss: 4.075824]\n",
      "epoch2 step25040 [D loss: 0.054901] [G loss: 4.662508]\n",
      "epoch2 step25045 [D loss: -0.542565] [G loss: 4.152069]\n",
      "epoch2 step25050 [D loss: -0.592125] [G loss: 4.397215]\n",
      "epoch2 step25055 [D loss: -0.222105] [G loss: 4.674206]\n",
      "epoch2 step25060 [D loss: 0.318045] [G loss: 4.639072]\n",
      "epoch2 step25065 [D loss: -0.789542] [G loss: 4.994630]\n",
      "epoch2 step25070 [D loss: -1.735124] [G loss: 4.876535]\n",
      "epoch2 step25075 [D loss: -1.410909] [G loss: 4.804893]\n",
      "epoch2 step25080 [D loss: -0.618787] [G loss: 4.511644]\n",
      "epoch2 step25085 [D loss: -1.638898] [G loss: 4.982896]\n",
      "epoch2 step25090 [D loss: -1.494919] [G loss: 4.282587]\n",
      "epoch2 step25095 [D loss: -1.716933] [G loss: 5.012730]\n",
      "epoch2 step25100 [D loss: -0.947713] [G loss: 4.994215]\n",
      "epoch2 step25105 [D loss: -0.794249] [G loss: 5.477576]\n",
      "epoch2 step25110 [D loss: -0.321767] [G loss: 4.938684]\n",
      "epoch2 step25115 [D loss: -1.124621] [G loss: 4.752963]\n",
      "epoch2 step25120 [D loss: -0.151930] [G loss: 5.024734]\n",
      "epoch2 step25125 [D loss: -1.643625] [G loss: 4.786574]\n",
      "epoch2 step25130 [D loss: -1.728990] [G loss: 5.238707]\n",
      "epoch2 step25135 [D loss: -1.660835] [G loss: 5.365836]\n",
      "epoch2 step25140 [D loss: 0.626976] [G loss: 4.716772]\n",
      "epoch2 step25145 [D loss: -1.449516] [G loss: 4.980865]\n",
      "epoch2 step25150 [D loss: 0.864460] [G loss: 5.233358]\n",
      "epoch2 step25155 [D loss: -0.885403] [G loss: 4.690077]\n",
      "epoch2 step25160 [D loss: -0.150174] [G loss: 4.935545]\n",
      "epoch2 step25165 [D loss: -1.180888] [G loss: 5.228555]\n",
      "epoch2 step25170 [D loss: -0.056649] [G loss: 4.884717]\n",
      "epoch2 step25175 [D loss: -0.802437] [G loss: 5.454034]\n",
      "epoch2 step25180 [D loss: -0.339497] [G loss: 5.106911]\n",
      "epoch2 step25185 [D loss: -0.121477] [G loss: 4.335783]\n",
      "epoch2 step25190 [D loss: -1.752597] [G loss: 4.456393]\n",
      "epoch2 step25195 [D loss: 0.000147] [G loss: 5.097828]\n",
      "epoch2 step25200 [D loss: -0.066497] [G loss: 4.449837]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.445481\n",
      "FID: 21.557953\n",
      "0 = 12.990779432249091\n",
      "1 = 0.08912972038362996\n",
      "2 = 0.8162000179290771\n",
      "3 = 0.8935999870300293\n",
      "4 = 0.7387999892234802\n",
      "5 = 0.7738136649131775\n",
      "6 = 0.8935999870300293\n",
      "7 = 8.08801457321643\n",
      "8 = 0.09417690986578225\n",
      "9 = 0.7949000000953674\n",
      "10 = 0.8325999975204468\n",
      "11 = 0.7572000026702881\n",
      "12 = 0.7742235660552979\n",
      "13 = 0.8325999975204468\n",
      "14 = 6.445507526397705\n",
      "15 = 9.404269218444824\n",
      "16 = 0.15988580882549286\n",
      "17 = 6.445481300354004\n",
      "18 = 21.557952880859375\n",
      "epoch2 step25205 [D loss: -1.148934] [G loss: 4.818383]\n",
      "epoch2 step25210 [D loss: -1.243218] [G loss: 4.650829]\n",
      "epoch2 step25215 [D loss: -1.561484] [G loss: 4.061788]\n",
      "epoch2 step25220 [D loss: -0.808479] [G loss: 4.793580]\n",
      "epoch2 step25225 [D loss: -1.506755] [G loss: 4.564159]\n",
      "epoch2 step25230 [D loss: -1.390700] [G loss: 4.210669]\n",
      "epoch2 step25235 [D loss: -1.043238] [G loss: 3.915914]\n",
      "epoch2 step25240 [D loss: -1.225784] [G loss: 4.268949]\n",
      "epoch2 step25245 [D loss: -1.146104] [G loss: 4.119690]\n",
      "epoch2 step25250 [D loss: -1.058169] [G loss: 4.174231]\n",
      "epoch2 step25255 [D loss: -0.017981] [G loss: 4.298063]\n",
      "epoch2 step25260 [D loss: -0.803181] [G loss: 4.638669]\n",
      "epoch2 step25265 [D loss: 0.167321] [G loss: 4.226482]\n",
      "epoch2 step25270 [D loss: -0.950588] [G loss: 4.276091]\n",
      "epoch2 step25275 [D loss: 0.168135] [G loss: 4.670587]\n",
      "epoch2 step25280 [D loss: 0.322684] [G loss: 3.307964]\n",
      "epoch2 step25285 [D loss: -0.175045] [G loss: 4.582250]\n",
      "epoch2 step25290 [D loss: -0.699482] [G loss: 3.939895]\n",
      "epoch2 step25295 [D loss: 0.196034] [G loss: 4.504559]\n",
      "epoch2 step25300 [D loss: 0.301098] [G loss: 3.955806]\n",
      "epoch2 step25305 [D loss: 0.944200] [G loss: 4.649963]\n",
      "epoch2 step25310 [D loss: -0.739475] [G loss: 4.492279]\n",
      "epoch2 step25315 [D loss: 0.000294] [G loss: 4.308579]\n",
      "epoch2 step25320 [D loss: -0.856724] [G loss: 4.300189]\n",
      "epoch2 step25325 [D loss: -1.479332] [G loss: 4.002839]\n",
      "epoch2 step25330 [D loss: -0.757386] [G loss: 4.057321]\n",
      "epoch2 step25335 [D loss: -0.524579] [G loss: 3.597888]\n",
      "epoch2 step25340 [D loss: -1.552655] [G loss: 4.543685]\n",
      "epoch2 step25345 [D loss: -1.130437] [G loss: 3.021339]\n",
      "epoch2 step25350 [D loss: -0.908051] [G loss: 3.760145]\n",
      "epoch2 step25355 [D loss: -0.930485] [G loss: 3.217208]\n",
      "epoch2 step25360 [D loss: -0.703907] [G loss: 3.927552]\n",
      "epoch2 step25365 [D loss: -1.112306] [G loss: 3.783117]\n",
      "epoch2 step25370 [D loss: -0.942230] [G loss: 4.986602]\n",
      "epoch2 step25375 [D loss: -0.026903] [G loss: 4.343599]\n",
      "epoch2 step25380 [D loss: -0.074039] [G loss: 5.271637]\n",
      "epoch2 step25385 [D loss: -1.165398] [G loss: 4.326030]\n",
      "epoch2 step25390 [D loss: -1.422492] [G loss: 4.409501]\n",
      "epoch2 step25395 [D loss: -1.167480] [G loss: 4.573577]\n",
      "epoch2 step25400 [D loss: -1.970636] [G loss: 5.777021]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.672127\n",
      "FID: 16.796583\n",
      "0 = 13.384089745235409\n",
      "1 = 0.11415917467098323\n",
      "2 = 0.8220999836921692\n",
      "3 = 0.9079999923706055\n",
      "4 = 0.7361999750137329\n",
      "5 = 0.7748762369155884\n",
      "6 = 0.9079999923706055\n",
      "7 = 7.836154202079784\n",
      "8 = 0.07956887185352066\n",
      "9 = 0.7922999858856201\n",
      "10 = 0.8361999988555908\n",
      "11 = 0.7483999729156494\n",
      "12 = 0.7687074542045593\n",
      "13 = 0.8361999988555908\n",
      "14 = 6.672155857086182\n",
      "15 = 9.426789283752441\n",
      "16 = 0.14125043153762817\n",
      "17 = 6.672126770019531\n",
      "18 = 16.79658317565918\n",
      "epoch2 step25405 [D loss: -1.605391] [G loss: 4.879117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2 step25410 [D loss: -1.917166] [G loss: 5.077962]\n",
      "epoch2 step25415 [D loss: -0.465078] [G loss: 4.455549]\n",
      "epoch2 step25420 [D loss: -1.183241] [G loss: 4.759642]\n",
      "epoch2 step25425 [D loss: 0.168992] [G loss: 4.253730]\n",
      "epoch2 step25430 [D loss: -0.832175] [G loss: 4.846607]\n",
      "epoch2 step25435 [D loss: -0.354217] [G loss: 4.955091]\n",
      "epoch2 step25440 [D loss: -0.712785] [G loss: 4.934542]\n",
      "epoch2 step25445 [D loss: 0.592459] [G loss: 4.571003]\n",
      "epoch2 step25450 [D loss: -0.835078] [G loss: 4.611103]\n",
      "epoch2 step25455 [D loss: -1.539134] [G loss: 4.933789]\n",
      "epoch2 step25460 [D loss: -0.410858] [G loss: 4.711171]\n",
      "epoch2 step25465 [D loss: 0.295620] [G loss: 4.844910]\n",
      "epoch2 step25470 [D loss: 0.556128] [G loss: 4.601314]\n",
      "epoch2 step25475 [D loss: 0.179771] [G loss: 4.282680]\n",
      "epoch2 step25480 [D loss: 0.018828] [G loss: 4.216325]\n",
      "epoch2 step25485 [D loss: -0.409135] [G loss: 4.712934]\n",
      "epoch2 step25490 [D loss: -1.591991] [G loss: 4.477122]\n",
      "epoch2 step25495 [D loss: 0.161540] [G loss: 3.801818]\n",
      "epoch2 step25500 [D loss: 0.503113] [G loss: 4.126225]\n",
      "epoch2 step25505 [D loss: 0.712983] [G loss: 4.107961]\n",
      "epoch2 step25510 [D loss: -0.740999] [G loss: 4.450749]\n",
      "epoch2 step25515 [D loss: 0.782397] [G loss: 3.934337]\n",
      "epoch2 step25520 [D loss: -0.078530] [G loss: 4.566295]\n",
      "epoch2 step25525 [D loss: -0.613671] [G loss: 4.189197]\n",
      "epoch2 step25530 [D loss: 0.011077] [G loss: 4.126019]\n",
      "epoch2 step25535 [D loss: -0.180671] [G loss: 4.193802]\n",
      "epoch2 step25540 [D loss: -0.232957] [G loss: 3.980045]\n",
      "epoch2 step25545 [D loss: -0.776160] [G loss: 3.673563]\n",
      "epoch2 step25550 [D loss: -1.899266] [G loss: 3.211464]\n",
      "epoch2 step25555 [D loss: -1.088101] [G loss: 4.309978]\n",
      "epoch2 step25560 [D loss: -0.893382] [G loss: 3.810574]\n",
      "epoch2 step25565 [D loss: -0.327011] [G loss: 4.410298]\n",
      "epoch2 step25570 [D loss: -0.571785] [G loss: 4.214864]\n",
      "epoch2 step25575 [D loss: -0.758918] [G loss: 3.613508]\n",
      "epoch2 step25580 [D loss: -0.347278] [G loss: 3.281114]\n",
      "epoch2 step25585 [D loss: 0.150449] [G loss: 3.405106]\n",
      "epoch2 step25590 [D loss: -0.719754] [G loss: 3.859680]\n",
      "epoch2 step25595 [D loss: -0.309189] [G loss: 4.376395]\n",
      "epoch2 step25600 [D loss: -0.821574] [G loss: 2.925765]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.651529\n",
      "FID: 16.117704\n",
      "0 = 13.121367813444147\n",
      "1 = 0.09322847902410218\n",
      "2 = 0.8065000176429749\n",
      "3 = 0.9085999727249146\n",
      "4 = 0.7044000029563904\n",
      "5 = 0.7545258402824402\n",
      "6 = 0.9085999727249146\n",
      "7 = 7.726171369051938\n",
      "8 = 0.07531807526651904\n",
      "9 = 0.784600019454956\n",
      "10 = 0.824999988079071\n",
      "11 = 0.7441999912261963\n",
      "12 = 0.7633234858512878\n",
      "13 = 0.824999988079071\n",
      "14 = 6.651552200317383\n",
      "15 = 9.361284255981445\n",
      "16 = 0.15064500272274017\n",
      "17 = 6.651528835296631\n",
      "18 = 16.117704391479492\n",
      "epoch2 step25605 [D loss: -0.364143] [G loss: 3.675964]\n",
      "epoch2 step25610 [D loss: -0.650815] [G loss: 3.541825]\n",
      "epoch2 step25615 [D loss: 0.082931] [G loss: 3.162654]\n",
      "epoch2 step25620 [D loss: -1.131170] [G loss: 3.364639]\n",
      "epoch2 step25625 [D loss: 0.363565] [G loss: 4.506569]\n",
      "epoch2 step25630 [D loss: -1.500254] [G loss: 4.102770]\n",
      "epoch2 step25635 [D loss: -0.228936] [G loss: 3.686693]\n",
      "epoch2 step25640 [D loss: -0.951117] [G loss: 4.653517]\n",
      "epoch2 step25645 [D loss: -0.129128] [G loss: 3.537168]\n",
      "epoch2 step25650 [D loss: -1.234730] [G loss: 4.090948]\n",
      "epoch2 step25655 [D loss: -0.553631] [G loss: 4.641417]\n",
      "epoch2 step25660 [D loss: -0.584054] [G loss: 4.474021]\n",
      "epoch2 step25665 [D loss: -0.072632] [G loss: 3.899994]\n",
      "epoch2 step25670 [D loss: -1.393963] [G loss: 4.387230]\n",
      "epoch2 step25675 [D loss: -1.134361] [G loss: 4.700846]\n",
      "epoch2 step25680 [D loss: 0.168688] [G loss: 4.428481]\n",
      "epoch2 step25685 [D loss: -1.088261] [G loss: 5.313381]\n",
      "epoch2 step25690 [D loss: -0.016936] [G loss: 4.077468]\n",
      "epoch2 step25695 [D loss: -1.803732] [G loss: 4.941311]\n",
      "epoch2 step25700 [D loss: 0.705624] [G loss: 4.855256]\n",
      "epoch2 step25705 [D loss: -0.020659] [G loss: 4.511889]\n",
      "epoch2 step25710 [D loss: -1.194546] [G loss: 5.102484]\n",
      "epoch2 step25715 [D loss: -0.112405] [G loss: 4.862684]\n",
      "epoch2 step25720 [D loss: -0.920309] [G loss: 4.719041]\n",
      "epoch2 step25725 [D loss: -0.244795] [G loss: 4.592355]\n",
      "epoch2 step25730 [D loss: -0.889414] [G loss: 4.679536]\n",
      "epoch2 step25735 [D loss: -0.615944] [G loss: 5.147854]\n",
      "epoch2 step25740 [D loss: -1.177255] [G loss: 5.574610]\n",
      "epoch2 step25745 [D loss: -1.410534] [G loss: 5.379635]\n",
      "epoch2 step25750 [D loss: -0.523553] [G loss: 5.402983]\n",
      "epoch2 step25755 [D loss: -1.156452] [G loss: 4.958774]\n",
      "epoch2 step25760 [D loss: -1.680820] [G loss: 5.386651]\n",
      "epoch2 step25765 [D loss: -0.783554] [G loss: 5.106717]\n",
      "epoch2 step25770 [D loss: -0.999418] [G loss: 5.102951]\n",
      "epoch2 step25775 [D loss: -0.598289] [G loss: 5.173272]\n",
      "epoch2 step25780 [D loss: -0.333623] [G loss: 5.260465]\n",
      "epoch2 step25785 [D loss: -0.865899] [G loss: 4.468168]\n",
      "epoch2 step25790 [D loss: 0.186744] [G loss: 5.242563]\n",
      "epoch2 step25795 [D loss: -0.858466] [G loss: 4.907507]\n",
      "epoch2 step25800 [D loss: -0.120995] [G loss: 5.128188]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.700859\n",
      "FID: 15.402249\n",
      "0 = 13.09719743032456\n",
      "1 = 0.07688298005654755\n",
      "2 = 0.8064000010490417\n",
      "3 = 0.9187999963760376\n",
      "4 = 0.6940000057220459\n",
      "5 = 0.7501633167266846\n",
      "6 = 0.9187999963760376\n",
      "7 = 7.827754137897469\n",
      "8 = 0.0759783511698996\n",
      "9 = 0.7850000262260437\n",
      "10 = 0.8331999778747559\n",
      "11 = 0.7368000149726868\n",
      "12 = 0.7599416375160217\n",
      "13 = 0.8331999778747559\n",
      "14 = 6.700890064239502\n",
      "15 = 9.376270294189453\n",
      "16 = 0.15302138030529022\n",
      "17 = 6.7008585929870605\n",
      "18 = 15.402249336242676\n",
      "epoch2 step25805 [D loss: -1.554263] [G loss: 5.507999]\n",
      "epoch2 step25810 [D loss: -1.073634] [G loss: 5.676763]\n",
      "epoch2 step25815 [D loss: -2.581635] [G loss: 5.106425]\n",
      "epoch2 step25820 [D loss: -1.478250] [G loss: 5.254515]\n",
      "epoch2 step25825 [D loss: -1.392789] [G loss: 4.923584]\n",
      "epoch2 step25830 [D loss: -1.427287] [G loss: 5.151323]\n",
      "epoch2 step25835 [D loss: -2.743304] [G loss: 6.734484]\n",
      "epoch2 step25840 [D loss: -1.080027] [G loss: 5.918029]\n",
      "epoch2 step25845 [D loss: 0.576728] [G loss: 5.190746]\n",
      "epoch2 step25850 [D loss: -0.240200] [G loss: 5.235460]\n",
      "epoch2 step25855 [D loss: 0.031627] [G loss: 5.606386]\n",
      "epoch2 step25860 [D loss: -0.191031] [G loss: 5.222923]\n",
      "epoch2 step25865 [D loss: -0.656803] [G loss: 5.216570]\n",
      "epoch2 step25870 [D loss: -0.444048] [G loss: 5.766174]\n",
      "epoch2 step25875 [D loss: -0.494337] [G loss: 5.571848]\n",
      "epoch2 step25880 [D loss: -1.078168] [G loss: 5.240899]\n",
      "epoch2 step25885 [D loss: -1.226313] [G loss: 4.947183]\n",
      "epoch2 step25890 [D loss: -1.052746] [G loss: 6.261017]\n",
      "epoch2 step25895 [D loss: -0.575653] [G loss: 5.473678]\n",
      "epoch2 step25900 [D loss: -0.321813] [G loss: 5.568639]\n",
      "epoch2 step25905 [D loss: -0.759840] [G loss: 5.856413]\n",
      "epoch2 step25910 [D loss: -0.005913] [G loss: 4.627541]\n",
      "epoch2 step25915 [D loss: -0.574019] [G loss: 5.244461]\n",
      "epoch2 step25920 [D loss: 0.232871] [G loss: 4.958035]\n",
      "epoch2 step25925 [D loss: -0.063106] [G loss: 4.557651]\n",
      "epoch2 step25930 [D loss: 0.169175] [G loss: 5.023579]\n",
      "epoch2 step25935 [D loss: -0.680850] [G loss: 4.645282]\n",
      "epoch2 step25940 [D loss: -0.616234] [G loss: 4.975264]\n",
      "epoch2 step25945 [D loss: -0.108561] [G loss: 6.037188]\n",
      "epoch2 step25950 [D loss: -0.147493] [G loss: 4.854568]\n",
      "epoch2 step25955 [D loss: 0.073519] [G loss: 5.058458]\n",
      "epoch2 step25960 [D loss: -0.020424] [G loss: 5.371692]\n",
      "epoch2 step25965 [D loss: -0.285031] [G loss: 4.905970]\n",
      "epoch2 step25970 [D loss: -0.334771] [G loss: 5.104894]\n",
      "epoch2 step25975 [D loss: -0.459754] [G loss: 5.042088]\n",
      "epoch2 step25980 [D loss: -0.012276] [G loss: 5.058751]\n",
      "epoch2 step25985 [D loss: -0.471949] [G loss: 5.182304]\n",
      "epoch2 step25990 [D loss: -0.492013] [G loss: 4.622449]\n",
      "epoch2 step25995 [D loss: -0.304330] [G loss: 5.093187]\n",
      "epoch2 step26000 [D loss: -0.288995] [G loss: 4.527808]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.495320\n",
      "FID: 18.816261\n",
      "0 = 12.932334930181511\n",
      "1 = 0.05666692715005283\n",
      "2 = 0.8077999949455261\n",
      "3 = 0.9100000262260437\n",
      "4 = 0.7056000232696533\n",
      "5 = 0.755562961101532\n",
      "6 = 0.9100000262260437\n",
      "7 = 7.909356951642028\n",
      "8 = 0.08420692941236825\n",
      "9 = 0.795199990272522\n",
      "10 = 0.8370000123977661\n",
      "11 = 0.7534000277519226\n",
      "12 = 0.7724252343177795\n",
      "13 = 0.8370000123977661\n",
      "14 = 6.49534273147583\n",
      "15 = 9.3203763961792\n",
      "16 = 0.16640354692935944\n",
      "17 = 6.495319843292236\n",
      "18 = 18.816261291503906\n",
      "epoch2 step26005 [D loss: -0.879929] [G loss: 5.633069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2 step26010 [D loss: -0.224830] [G loss: 4.353711]\n",
      "epoch2 step26015 [D loss: -0.939404] [G loss: 5.177507]\n",
      "epoch2 step26020 [D loss: -0.791700] [G loss: 4.786784]\n",
      "epoch2 step26025 [D loss: -1.033603] [G loss: 4.753540]\n",
      "epoch2 step26030 [D loss: -1.072772] [G loss: 5.193017]\n",
      "epoch2 step26035 [D loss: 0.286986] [G loss: 5.353028]\n",
      "epoch2 step26040 [D loss: 0.517217] [G loss: 4.952826]\n",
      "epoch2 step26045 [D loss: 0.004997] [G loss: 5.160956]\n",
      "epoch2 step26050 [D loss: -1.119197] [G loss: 4.598965]\n",
      "epoch2 step26055 [D loss: -0.576137] [G loss: 4.403251]\n",
      "epoch2 step26060 [D loss: -0.393978] [G loss: 4.480090]\n",
      "epoch2 step26065 [D loss: -0.220757] [G loss: 4.600807]\n",
      "epoch2 step26070 [D loss: 0.277932] [G loss: 4.447167]\n",
      "epoch2 step26075 [D loss: -0.918940] [G loss: 4.882312]\n",
      "epoch2 step26080 [D loss: -0.559571] [G loss: 4.498059]\n",
      "epoch2 step26085 [D loss: -1.249879] [G loss: 4.773473]\n",
      "epoch2 step26090 [D loss: 0.624358] [G loss: 4.763062]\n",
      "epoch2 step26095 [D loss: -0.433677] [G loss: 4.771024]\n",
      "epoch2 step26100 [D loss: 0.019364] [G loss: 4.733829]\n",
      "epoch2 step26105 [D loss: -1.460903] [G loss: 4.396858]\n",
      "epoch2 step26110 [D loss: -0.012999] [G loss: 4.482916]\n",
      "epoch2 step26115 [D loss: -0.358216] [G loss: 4.552273]\n",
      "epoch2 step26120 [D loss: -0.308695] [G loss: 3.853765]\n",
      "epoch2 step26125 [D loss: -0.883124] [G loss: 4.238438]\n",
      "epoch2 step26130 [D loss: -0.286992] [G loss: 4.071286]\n",
      "epoch2 step26135 [D loss: 0.511431] [G loss: 3.763071]\n",
      "epoch2 step26140 [D loss: -1.206656] [G loss: 3.707092]\n",
      "epoch2 step26145 [D loss: -0.128537] [G loss: 3.800070]\n",
      "epoch2 step26150 [D loss: 0.143814] [G loss: 3.817921]\n",
      "epoch2 step26155 [D loss: -0.837255] [G loss: 3.846613]\n",
      "epoch2 step26160 [D loss: -0.191583] [G loss: 4.250497]\n",
      "epoch2 step26165 [D loss: -0.076578] [G loss: 4.389301]\n",
      "epoch2 step26170 [D loss: -0.248324] [G loss: 3.628909]\n",
      "epoch2 step26175 [D loss: 0.311850] [G loss: 4.173157]\n",
      "epoch2 step26180 [D loss: -0.530346] [G loss: 3.946742]\n",
      "epoch2 step26185 [D loss: -1.594806] [G loss: 4.429733]\n",
      "epoch2 step26190 [D loss: -0.673221] [G loss: 3.986312]\n",
      "epoch2 step26195 [D loss: -0.241165] [G loss: 4.532018]\n",
      "epoch2 step26200 [D loss: -0.704213] [G loss: 5.163084]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.653659\n",
      "FID: 15.163825\n",
      "0 = 12.68161815223698\n",
      "1 = 0.05192682274460013\n",
      "2 = 0.7990999817848206\n",
      "3 = 0.901199996471405\n",
      "4 = 0.6970000267028809\n",
      "5 = 0.7483806610107422\n",
      "6 = 0.901199996471405\n",
      "7 = 7.616796397161472\n",
      "8 = 0.07114845937533978\n",
      "9 = 0.7732999920845032\n",
      "10 = 0.8167999982833862\n",
      "11 = 0.7297999858856201\n",
      "12 = 0.7514259219169617\n",
      "13 = 0.8167999982833862\n",
      "14 = 6.653687953948975\n",
      "15 = 9.417275428771973\n",
      "16 = 0.14663761854171753\n",
      "17 = 6.653659343719482\n",
      "18 = 15.163825035095215\n",
      "epoch2 step26205 [D loss: -0.805544] [G loss: 4.037238]\n",
      "epoch2 step26210 [D loss: -1.599766] [G loss: 4.884637]\n",
      "epoch2 step26215 [D loss: -0.643780] [G loss: 4.933915]\n",
      "epoch2 step26220 [D loss: -0.829162] [G loss: 5.310255]\n",
      "epoch2 step26225 [D loss: -0.408602] [G loss: 5.461001]\n",
      "epoch2 step26230 [D loss: -0.115168] [G loss: 5.305492]\n",
      "epoch2 step26235 [D loss: -0.434909] [G loss: 5.015987]\n",
      "epoch2 step26240 [D loss: -1.059001] [G loss: 5.027390]\n",
      "epoch2 step26245 [D loss: -1.321020] [G loss: 5.019215]\n",
      "epoch2 step26250 [D loss: -0.576823] [G loss: 4.871112]\n",
      "epoch2 step26255 [D loss: -0.498398] [G loss: 4.571177]\n",
      "epoch2 step26260 [D loss: -0.551849] [G loss: 4.434445]\n",
      "epoch2 step26265 [D loss: -0.276925] [G loss: 4.924064]\n",
      "epoch2 step26270 [D loss: -0.187371] [G loss: 4.791117]\n",
      "epoch2 step26275 [D loss: -0.498691] [G loss: 4.802508]\n",
      "epoch2 step26280 [D loss: -0.038777] [G loss: 4.700621]\n",
      "epoch2 step26285 [D loss: -0.651233] [G loss: 4.108672]\n",
      "epoch2 step26290 [D loss: -0.284500] [G loss: 4.561326]\n",
      "epoch2 step26295 [D loss: -0.845265] [G loss: 4.562994]\n",
      "epoch2 step26300 [D loss: -0.601205] [G loss: 4.773304]\n",
      "epoch2 step26305 [D loss: -1.086644] [G loss: 3.991510]\n",
      "epoch2 step26310 [D loss: -0.180247] [G loss: 4.716296]\n",
      "epoch2 step26315 [D loss: -0.661257] [G loss: 4.871088]\n",
      "epoch2 step26320 [D loss: -0.581906] [G loss: 5.419868]\n",
      "epoch2 step26325 [D loss: -0.956019] [G loss: 5.051552]\n",
      "epoch2 step26330 [D loss: 0.054184] [G loss: 5.168547]\n",
      "epoch2 step26335 [D loss: -0.110607] [G loss: 4.422873]\n",
      "epoch2 step26340 [D loss: -0.826795] [G loss: 5.156112]\n",
      "epoch2 step26345 [D loss: -0.967586] [G loss: 5.425157]\n",
      "epoch2 step26350 [D loss: -1.257748] [G loss: 4.970334]\n",
      "epoch2 step26355 [D loss: 0.002537] [G loss: 5.180304]\n",
      "epoch2 step26360 [D loss: -1.919714] [G loss: 6.423956]\n",
      "epoch2 step26365 [D loss: -1.205017] [G loss: 5.862421]\n",
      "epoch2 step26370 [D loss: 0.240035] [G loss: 4.979949]\n",
      "epoch2 step26375 [D loss: 0.258951] [G loss: 4.596981]\n",
      "epoch2 step26380 [D loss: -0.281673] [G loss: 4.650434]\n",
      "epoch2 step26385 [D loss: 0.082180] [G loss: 4.770164]\n",
      "epoch2 step26390 [D loss: -0.658086] [G loss: 5.420174]\n",
      "epoch2 step26395 [D loss: -0.964720] [G loss: 5.890400]\n",
      "epoch2 step26400 [D loss: -0.706497] [G loss: 5.210153]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.570894\n",
      "FID: 19.683893\n",
      "0 = 12.536100552558887\n",
      "1 = 0.060909049410657064\n",
      "2 = 0.8075000047683716\n",
      "3 = 0.8906000256538391\n",
      "4 = 0.724399983882904\n",
      "5 = 0.7636768817901611\n",
      "6 = 0.8906000256538391\n",
      "7 = 7.952615585315224\n",
      "8 = 0.08811887138104549\n",
      "9 = 0.785099983215332\n",
      "10 = 0.8226000070571899\n",
      "11 = 0.7476000189781189\n",
      "12 = 0.7652093172073364\n",
      "13 = 0.8226000070571899\n",
      "14 = 6.57091760635376\n",
      "15 = 9.368645668029785\n",
      "16 = 0.16211003065109253\n",
      "17 = 6.570894241333008\n",
      "18 = 19.68389320373535\n",
      "epoch2 step26405 [D loss: -0.620861] [G loss: 5.338456]\n",
      "epoch2 step26410 [D loss: -0.768541] [G loss: 5.403829]\n",
      "epoch2 step26415 [D loss: 0.353304] [G loss: 4.649307]\n",
      "epoch2 step26420 [D loss: -2.140123] [G loss: 5.545269]\n",
      "epoch2 step26425 [D loss: -0.247301] [G loss: 5.296329]\n",
      "epoch2 step26430 [D loss: -0.450547] [G loss: 4.760731]\n",
      "epoch2 step26435 [D loss: -0.555184] [G loss: 5.421215]\n",
      "epoch2 step26440 [D loss: -1.001649] [G loss: 6.121067]\n",
      "epoch2 step26445 [D loss: -0.287317] [G loss: 5.553750]\n",
      "epoch2 step26450 [D loss: -1.029088] [G loss: 5.303294]\n",
      "epoch2 step26455 [D loss: -0.751246] [G loss: 5.737931]\n",
      "epoch2 step26460 [D loss: -1.312336] [G loss: 6.075547]\n",
      "epoch2 step26465 [D loss: -1.093917] [G loss: 5.670601]\n",
      "epoch2 step26470 [D loss: -0.760085] [G loss: 6.603288]\n",
      "epoch2 step26475 [D loss: -1.248137] [G loss: 6.188973]\n",
      "epoch2 step26480 [D loss: -0.182201] [G loss: 6.378727]\n",
      "epoch2 step26485 [D loss: 0.549244] [G loss: 6.491096]\n",
      "epoch2 step26490 [D loss: -0.312884] [G loss: 6.574105]\n",
      "epoch2 step26495 [D loss: -0.863451] [G loss: 5.168021]\n",
      "epoch2 step26500 [D loss: -1.941623] [G loss: 6.082401]\n",
      "epoch2 step26505 [D loss: 0.307785] [G loss: 5.678411]\n",
      "epoch2 step26510 [D loss: -0.216527] [G loss: 5.245955]\n",
      "epoch2 step26515 [D loss: -0.734802] [G loss: 5.739494]\n",
      "epoch2 step26520 [D loss: -1.627692] [G loss: 5.725947]\n",
      "epoch2 step26525 [D loss: -0.426544] [G loss: 5.765739]\n",
      "epoch2 step26530 [D loss: -0.648880] [G loss: 5.553326]\n",
      "epoch2 step26535 [D loss: 0.495870] [G loss: 5.482811]\n",
      "epoch2 step26540 [D loss: 0.304256] [G loss: 5.695055]\n",
      "epoch2 step26545 [D loss: -0.601164] [G loss: 5.337623]\n",
      "epoch2 step26550 [D loss: -0.062062] [G loss: 5.513460]\n",
      "epoch2 step26555 [D loss: -1.460764] [G loss: 6.074276]\n",
      "epoch2 step26560 [D loss: -1.148855] [G loss: 5.458966]\n",
      "epoch2 step26565 [D loss: 0.345028] [G loss: 5.670307]\n",
      "epoch2 step26570 [D loss: -0.688947] [G loss: 5.141668]\n",
      "epoch2 step26575 [D loss: -0.630159] [G loss: 5.642362]\n",
      "epoch2 step26580 [D loss: 0.041401] [G loss: 5.278152]\n",
      "epoch2 step26585 [D loss: 0.122151] [G loss: 4.957133]\n",
      "epoch2 step26590 [D loss: -0.258089] [G loss: 4.666640]\n",
      "epoch2 step26595 [D loss: -0.270721] [G loss: 4.358602]\n",
      "epoch2 step26600 [D loss: -0.465306] [G loss: 3.808289]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.641800\n",
      "FID: 17.992283\n",
      "0 = 12.790390151071577\n",
      "1 = 0.06537227104136704\n",
      "2 = 0.7943000197410583\n",
      "3 = 0.8949999809265137\n",
      "4 = 0.6935999989509583\n",
      "5 = 0.7449641823768616\n",
      "6 = 0.8949999809265137\n",
      "7 = 7.890742850255962\n",
      "8 = 0.08350751475251554\n",
      "9 = 0.7817999720573425\n",
      "10 = 0.824999988079071\n",
      "11 = 0.7386000156402588\n",
      "12 = 0.75938880443573\n",
      "13 = 0.824999988079071\n",
      "14 = 6.641829967498779\n",
      "15 = 9.406146049499512\n",
      "16 = 0.15331867337226868\n",
      "17 = 6.641800403594971\n",
      "18 = 17.99228286743164\n",
      "epoch2 step26605 [D loss: -1.593598] [G loss: 4.606287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2 step26610 [D loss: -0.860714] [G loss: 4.916122]\n",
      "epoch2 step26615 [D loss: -0.298329] [G loss: 3.849606]\n",
      "epoch2 step26620 [D loss: 0.303375] [G loss: 4.625732]\n",
      "epoch2 step26625 [D loss: -0.889803] [G loss: 4.346993]\n",
      "epoch2 step26630 [D loss: 0.126807] [G loss: 4.278937]\n",
      "epoch2 step26635 [D loss: -0.061045] [G loss: 3.897648]\n",
      "epoch2 step26640 [D loss: 0.586208] [G loss: 3.631099]\n",
      "epoch2 step26645 [D loss: -0.050232] [G loss: 3.921164]\n",
      "epoch2 step26650 [D loss: -0.627124] [G loss: 4.069397]\n",
      "epoch2 step26655 [D loss: -1.407035] [G loss: 4.589221]\n",
      "epoch2 step26660 [D loss: -1.038933] [G loss: 4.236797]\n",
      "epoch2 step26665 [D loss: -1.687770] [G loss: 4.329873]\n",
      "epoch2 step26670 [D loss: -1.583254] [G loss: 4.572412]\n",
      "epoch2 step26675 [D loss: -0.937259] [G loss: 4.788840]\n",
      "epoch2 step26680 [D loss: -1.094186] [G loss: 4.912695]\n",
      "epoch2 step26685 [D loss: -0.361702] [G loss: 4.824980]\n",
      "epoch2 step26690 [D loss: -0.905648] [G loss: 4.778338]\n",
      "epoch2 step26695 [D loss: 0.209615] [G loss: 3.998726]\n",
      "epoch2 step26700 [D loss: -0.070585] [G loss: 3.264323]\n",
      "epoch2 step26705 [D loss: -1.517809] [G loss: 4.766431]\n",
      "epoch2 step26710 [D loss: -0.265848] [G loss: 4.321418]\n",
      "epoch2 step26715 [D loss: -0.717404] [G loss: 3.985173]\n",
      "epoch2 step26720 [D loss: -0.688969] [G loss: 3.931541]\n",
      "epoch2 step26725 [D loss: -0.441130] [G loss: 4.271472]\n",
      "epoch2 step26730 [D loss: -0.511428] [G loss: 3.462740]\n",
      "epoch2 step26735 [D loss: 0.280646] [G loss: 3.511038]\n",
      "epoch2 step26740 [D loss: -0.530233] [G loss: 3.727926]\n",
      "epoch2 step26745 [D loss: 0.010516] [G loss: 3.223200]\n",
      "epoch2 step26750 [D loss: -0.920830] [G loss: 3.182190]\n",
      "epoch2 step26755 [D loss: 0.695790] [G loss: 3.822273]\n",
      "epoch2 step26760 [D loss: 0.840780] [G loss: 3.976209]\n",
      "epoch2 step26765 [D loss: -0.719955] [G loss: 3.418944]\n",
      "epoch2 step26770 [D loss: -0.217810] [G loss: 4.390074]\n",
      "epoch2 step26775 [D loss: -0.564381] [G loss: 3.990345]\n",
      "epoch2 step26780 [D loss: -1.333031] [G loss: 4.449948]\n",
      "epoch2 step26785 [D loss: -0.254450] [G loss: 3.636286]\n",
      "epoch2 step26790 [D loss: -0.388363] [G loss: 3.408514]\n",
      "epoch2 step26795 [D loss: -1.310624] [G loss: 3.761233]\n",
      "epoch2 step26800 [D loss: -0.231443] [G loss: 3.937201]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.577171\n",
      "FID: 17.568666\n",
      "0 = 13.09157589693073\n",
      "1 = 0.09625706634343746\n",
      "2 = 0.8098999857902527\n",
      "3 = 0.9114000201225281\n",
      "4 = 0.7084000110626221\n",
      "5 = 0.7576059699058533\n",
      "6 = 0.9114000201225281\n",
      "7 = 7.778595719587807\n",
      "8 = 0.08401488703552072\n",
      "9 = 0.7882999777793884\n",
      "10 = 0.8331999778747559\n",
      "11 = 0.743399977684021\n",
      "12 = 0.7645439505577087\n",
      "13 = 0.8331999778747559\n",
      "14 = 6.577192306518555\n",
      "15 = 9.22652816772461\n",
      "16 = 0.17533957958221436\n",
      "17 = 6.5771708488464355\n",
      "18 = 17.568666458129883\n",
      "epoch2 step26805 [D loss: -0.924501] [G loss: 4.588753]\n",
      "epoch2 step26810 [D loss: -2.132891] [G loss: 5.803719]\n",
      "epoch2 step26815 [D loss: -0.651616] [G loss: 4.132394]\n",
      "epoch2 step26820 [D loss: 0.171051] [G loss: 4.381505]\n",
      "epoch2 step26825 [D loss: 0.755406] [G loss: 4.333266]\n",
      "epoch2 step26830 [D loss: -0.079015] [G loss: 5.728148]\n",
      "epoch2 step26835 [D loss: 0.359804] [G loss: 5.383635]\n",
      "epoch2 step26840 [D loss: -0.727949] [G loss: 5.292887]\n",
      "epoch2 step26845 [D loss: -0.720316] [G loss: 5.030253]\n",
      "epoch2 step26850 [D loss: -1.254990] [G loss: 4.998785]\n",
      "epoch2 step26855 [D loss: -0.921572] [G loss: 4.765357]\n",
      "epoch2 step26860 [D loss: -1.459698] [G loss: 4.991186]\n",
      "epoch2 step26865 [D loss: -0.186629] [G loss: 5.260703]\n",
      "epoch2 step26870 [D loss: -0.341340] [G loss: 5.239198]\n",
      "epoch2 step26875 [D loss: -0.898168] [G loss: 5.563809]\n",
      "epoch2 step26880 [D loss: -0.095262] [G loss: 5.500620]\n",
      "epoch2 step26885 [D loss: -0.428818] [G loss: 5.967390]\n",
      "epoch2 step26890 [D loss: -1.387749] [G loss: 5.228104]\n",
      "epoch2 step26895 [D loss: -1.840683] [G loss: 6.003838]\n",
      "epoch2 step26900 [D loss: -2.408574] [G loss: 5.586479]\n",
      "epoch2 step26905 [D loss: -1.815417] [G loss: 6.042070]\n",
      "epoch2 step26910 [D loss: -0.757047] [G loss: 6.402094]\n",
      "epoch2 step26915 [D loss: -1.325785] [G loss: 6.286999]\n",
      "epoch2 step26920 [D loss: -0.714111] [G loss: 6.663693]\n",
      "epoch2 step26925 [D loss: 0.449012] [G loss: 5.477028]\n",
      "epoch2 step26930 [D loss: -0.665642] [G loss: 5.239897]\n",
      "epoch2 step26935 [D loss: -1.103930] [G loss: 5.640908]\n",
      "epoch2 step26940 [D loss: -0.522342] [G loss: 5.963989]\n",
      "epoch2 step26945 [D loss: -0.420034] [G loss: 5.712859]\n",
      "epoch2 step26950 [D loss: -0.488265] [G loss: 5.748915]\n",
      "epoch2 step26955 [D loss: -0.410522] [G loss: 6.433179]\n",
      "epoch2 step26960 [D loss: -0.191562] [G loss: 5.204319]\n",
      "epoch2 step26965 [D loss: -1.399892] [G loss: 5.489777]\n",
      "epoch2 step26970 [D loss: -1.491110] [G loss: 5.751769]\n",
      "epoch2 step26975 [D loss: -1.627860] [G loss: 6.164381]\n",
      "epoch2 step26980 [D loss: -0.744435] [G loss: 6.041384]\n",
      "epoch2 step26985 [D loss: -1.558768] [G loss: 5.495316]\n",
      "epoch2 step26990 [D loss: -0.005074] [G loss: 4.630482]\n",
      "epoch2 step26995 [D loss: -1.131017] [G loss: 5.180931]\n",
      "epoch2 step27000 [D loss: -0.999252] [G loss: 4.820123]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.798288\n",
      "FID: 14.049846\n",
      "0 = 12.882515628147154\n",
      "1 = 0.07591949123762799\n",
      "2 = 0.7930999994277954\n",
      "3 = 0.9075999855995178\n",
      "4 = 0.678600013256073\n",
      "5 = 0.7384865880012512\n",
      "6 = 0.9075999855995178\n",
      "7 = 7.605198158442983\n",
      "8 = 0.0698592091632838\n",
      "9 = 0.782800018787384\n",
      "10 = 0.8274000287055969\n",
      "11 = 0.7382000088691711\n",
      "12 = 0.759640097618103\n",
      "13 = 0.8274000287055969\n",
      "14 = 6.798316478729248\n",
      "15 = 9.491754531860352\n",
      "16 = 0.12220098078250885\n",
      "17 = 6.798288345336914\n",
      "18 = 14.049845695495605\n",
      "epoch2 step27005 [D loss: -0.487493] [G loss: 5.479339]\n",
      "epoch2 step27010 [D loss: -0.484023] [G loss: 5.312227]\n",
      "epoch2 step27015 [D loss: 0.440202] [G loss: 4.172125]\n",
      "epoch2 step27020 [D loss: -0.155200] [G loss: 4.922431]\n",
      "epoch2 step27025 [D loss: -0.974234] [G loss: 4.749595]\n",
      "epoch2 step27030 [D loss: -1.072656] [G loss: 4.965830]\n",
      "epoch2 step27035 [D loss: -0.437938] [G loss: 4.536549]\n",
      "epoch2 step27040 [D loss: -0.344118] [G loss: 4.819341]\n",
      "epoch2 step27045 [D loss: -1.605090] [G loss: 4.105728]\n",
      "epoch2 step27050 [D loss: -1.005217] [G loss: 4.313194]\n",
      "epoch2 step27055 [D loss: -1.318702] [G loss: 3.509540]\n",
      "epoch2 step27060 [D loss: -1.726795] [G loss: 4.587456]\n",
      "epoch2 step27065 [D loss: -0.906556] [G loss: 3.274806]\n",
      "epoch2 step27070 [D loss: -1.863059] [G loss: 4.268455]\n",
      "epoch2 step27075 [D loss: -0.757907] [G loss: 3.553715]\n",
      "epoch2 step27080 [D loss: 0.134237] [G loss: 3.111643]\n",
      "epoch2 step27085 [D loss: 0.387068] [G loss: 4.469890]\n",
      "epoch2 step27090 [D loss: 1.290473] [G loss: 3.818491]\n",
      "epoch2 step27095 [D loss: -0.012176] [G loss: 4.942818]\n",
      "epoch2 step27100 [D loss: -0.934375] [G loss: 4.534722]\n",
      "epoch2 step27105 [D loss: -0.012731] [G loss: 4.464731]\n",
      "epoch2 step27110 [D loss: -0.417264] [G loss: 4.059082]\n",
      "epoch2 step27115 [D loss: 0.165870] [G loss: 4.036862]\n",
      "epoch2 step27120 [D loss: -0.476558] [G loss: 4.327379]\n",
      "epoch2 step27125 [D loss: -1.414384] [G loss: 4.237117]\n",
      "epoch2 step27130 [D loss: -0.769710] [G loss: 4.131418]\n",
      "epoch2 step27135 [D loss: -0.621073] [G loss: 3.775535]\n",
      "epoch2 step27140 [D loss: -0.090062] [G loss: 3.816667]\n",
      "epoch2 step27145 [D loss: -0.125724] [G loss: 3.915308]\n",
      "epoch2 step27150 [D loss: -1.098636] [G loss: 4.011001]\n",
      "epoch2 step27155 [D loss: -0.137169] [G loss: 3.957556]\n",
      "epoch2 step27160 [D loss: -0.239244] [G loss: 3.945923]\n",
      "epoch2 step27165 [D loss: -1.043518] [G loss: 4.038991]\n",
      "epoch2 step27170 [D loss: -0.026397] [G loss: 4.392735]\n",
      "epoch2 step27175 [D loss: -0.228778] [G loss: 4.170384]\n",
      "epoch2 step27180 [D loss: -0.250842] [G loss: 3.966404]\n",
      "epoch2 step27185 [D loss: -1.147347] [G loss: 4.482672]\n",
      "epoch2 step27190 [D loss: 0.102136] [G loss: 3.883809]\n",
      "epoch2 step27195 [D loss: -1.241920] [G loss: 4.124292]\n",
      "epoch2 step27200 [D loss: -0.947518] [G loss: 4.067903]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.722711\n",
      "FID: 16.911634\n",
      "0 = 12.870858417701712\n",
      "1 = 0.0806048677134122\n",
      "2 = 0.8026999831199646\n",
      "3 = 0.8978000283241272\n",
      "4 = 0.7075999975204468\n",
      "5 = 0.7543269991874695\n",
      "6 = 0.8978000283241272\n",
      "7 = 7.7911202503204535\n",
      "8 = 0.08016665147660945\n",
      "9 = 0.785099983215332\n",
      "10 = 0.8274000287055969\n",
      "11 = 0.7427999973297119\n",
      "12 = 0.7628619074821472\n",
      "13 = 0.8274000287055969\n",
      "14 = 6.722738742828369\n",
      "15 = 9.433341026306152\n",
      "16 = 0.14384043216705322\n",
      "17 = 6.722711086273193\n",
      "18 = 16.91163444519043\n",
      "epoch2 step27205 [D loss: -0.450928] [G loss: 4.544814]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2 step27210 [D loss: -0.656474] [G loss: 4.552397]\n",
      "epoch2 step27215 [D loss: -0.426268] [G loss: 3.962425]\n",
      "epoch2 step27220 [D loss: 0.269857] [G loss: 3.592992]\n",
      "epoch2 step27225 [D loss: -0.713138] [G loss: 4.075009]\n",
      "epoch2 step27230 [D loss: -0.097899] [G loss: 4.014720]\n",
      "epoch2 step27235 [D loss: -0.892153] [G loss: 4.727136]\n",
      "epoch2 step27240 [D loss: -0.681055] [G loss: 3.732184]\n",
      "epoch2 step27245 [D loss: -0.979900] [G loss: 3.911400]\n",
      "epoch2 step27250 [D loss: -0.505707] [G loss: 3.918012]\n",
      "epoch2 step27255 [D loss: -1.443568] [G loss: 4.756754]\n",
      "epoch2 step27260 [D loss: -0.035911] [G loss: 4.380606]\n",
      "epoch2 step27265 [D loss: -1.786058] [G loss: 5.166171]\n",
      "epoch2 step27270 [D loss: -0.945489] [G loss: 4.766307]\n",
      "epoch2 step27275 [D loss: -1.582793] [G loss: 4.612142]\n",
      "epoch2 step27280 [D loss: -1.874286] [G loss: 4.603604]\n",
      "epoch2 step27285 [D loss: -0.739554] [G loss: 4.757292]\n",
      "epoch2 step27290 [D loss: -0.928639] [G loss: 4.990372]\n",
      "epoch2 step27295 [D loss: -0.461998] [G loss: 4.495224]\n",
      "epoch2 step27300 [D loss: -0.518126] [G loss: 4.061138]\n",
      "epoch2 step27305 [D loss: -0.520419] [G loss: 4.125876]\n",
      "epoch2 step27310 [D loss: -0.586087] [G loss: 5.108709]\n",
      "epoch2 step27315 [D loss: -0.369028] [G loss: 4.572940]\n",
      "epoch2 step27320 [D loss: -0.751470] [G loss: 4.539172]\n",
      "epoch2 step27325 [D loss: 0.586067] [G loss: 4.917051]\n",
      "epoch2 step27330 [D loss: 0.441636] [G loss: 4.713832]\n",
      "epoch2 step27335 [D loss: 0.047276] [G loss: 5.449696]\n",
      "epoch2 step27340 [D loss: -0.307645] [G loss: 5.010094]\n",
      "epoch2 step27345 [D loss: 0.237406] [G loss: 4.693141]\n",
      "epoch2 step27350 [D loss: -0.088656] [G loss: 5.841682]\n",
      "epoch2 step27355 [D loss: -1.376440] [G loss: 6.209818]\n",
      "epoch2 step27360 [D loss: -0.160585] [G loss: 4.662229]\n",
      "epoch2 step27365 [D loss: -0.516756] [G loss: 6.092631]\n",
      "epoch2 step27370 [D loss: -0.651981] [G loss: 5.430882]\n",
      "epoch2 step27375 [D loss: 0.307933] [G loss: 6.003964]\n",
      "epoch2 step27380 [D loss: -0.458100] [G loss: 5.704100]\n",
      "epoch2 step27385 [D loss: -0.195243] [G loss: 5.860982]\n",
      "epoch2 step27390 [D loss: -0.668132] [G loss: 5.643465]\n",
      "epoch2 step27395 [D loss: -0.987218] [G loss: 6.210891]\n",
      "epoch2 step27400 [D loss: -0.672260] [G loss: 5.698645]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.513879\n",
      "FID: 20.404566\n",
      "0 = 12.75741075320243\n",
      "1 = 0.0680990439147606\n",
      "2 = 0.8098000288009644\n",
      "3 = 0.8916000127792358\n",
      "4 = 0.7279999852180481\n",
      "5 = 0.7662426829338074\n",
      "6 = 0.8916000127792358\n",
      "7 = 7.7834868337392855\n",
      "8 = 0.0909350910719786\n",
      "9 = 0.7940999865531921\n",
      "10 = 0.823199987411499\n",
      "11 = 0.7649999856948853\n",
      "12 = 0.7779247760772705\n",
      "13 = 0.823199987411499\n",
      "14 = 6.5138959884643555\n",
      "15 = 9.25629997253418\n",
      "16 = 0.1732189655303955\n",
      "17 = 6.513879299163818\n",
      "18 = 20.404565811157227\n",
      "epoch2 step27405 [D loss: 0.122048] [G loss: 5.726127]\n",
      "epoch2 step27410 [D loss: -0.564455] [G loss: 6.232798]\n",
      "epoch2 step27415 [D loss: -0.145391] [G loss: 5.960530]\n",
      "epoch2 step27420 [D loss: 0.091272] [G loss: 5.771799]\n",
      "epoch2 step27425 [D loss: -0.283452] [G loss: 5.899899]\n",
      "epoch2 step27430 [D loss: 0.395402] [G loss: 6.076309]\n",
      "epoch2 step27435 [D loss: 0.101075] [G loss: 6.128539]\n",
      "epoch2 step27440 [D loss: 0.119248] [G loss: 6.545034]\n",
      "epoch2 step27445 [D loss: -0.216446] [G loss: 5.656607]\n",
      "epoch2 step27450 [D loss: -0.818295] [G loss: 6.152642]\n",
      "epoch2 step27455 [D loss: -0.472097] [G loss: 6.407316]\n",
      "epoch2 step27460 [D loss: -0.085970] [G loss: 6.876540]\n",
      "epoch2 step27465 [D loss: -0.536142] [G loss: 6.491736]\n",
      "epoch2 step27470 [D loss: -0.820901] [G loss: 6.162734]\n",
      "epoch2 step27475 [D loss: 0.277912] [G loss: 6.578193]\n",
      "epoch2 step27480 [D loss: 0.765054] [G loss: 5.737618]\n",
      "epoch2 step27485 [D loss: -0.819057] [G loss: 6.545904]\n",
      "epoch2 step27490 [D loss: -0.223419] [G loss: 6.036454]\n",
      "epoch2 step27495 [D loss: -0.691253] [G loss: 6.127994]\n",
      "epoch2 step27500 [D loss: -0.862331] [G loss: 6.231796]\n",
      "epoch2 step27505 [D loss: -0.759457] [G loss: 6.461670]\n",
      "epoch2 step27510 [D loss: -0.570795] [G loss: 6.626572]\n",
      "epoch2 step27515 [D loss: -0.832458] [G loss: 6.134809]\n",
      "epoch2 step27520 [D loss: -1.214140] [G loss: 6.465088]\n",
      "epoch2 step27525 [D loss: -0.903289] [G loss: 5.509829]\n",
      "epoch2 step27530 [D loss: -0.710446] [G loss: 5.432495]\n",
      "epoch2 step27535 [D loss: -0.658395] [G loss: 6.122690]\n",
      "epoch2 step27540 [D loss: -0.300044] [G loss: 6.553470]\n",
      "epoch2 step27545 [D loss: -0.882888] [G loss: 5.753704]\n",
      "epoch2 step27550 [D loss: 0.256343] [G loss: 5.732173]\n",
      "epoch2 step27555 [D loss: -0.006997] [G loss: 5.945757]\n",
      "epoch2 step27560 [D loss: -1.218011] [G loss: 5.185560]\n",
      "epoch2 step27565 [D loss: 0.029191] [G loss: 4.241700]\n",
      "epoch2 step27570 [D loss: -0.604775] [G loss: 4.646297]\n",
      "epoch2 step27575 [D loss: -0.310027] [G loss: 5.538127]\n",
      "epoch2 step27580 [D loss: -0.837705] [G loss: 4.777490]\n",
      "epoch2 step27585 [D loss: -1.291743] [G loss: 5.843997]\n",
      "epoch2 step27590 [D loss: -0.510183] [G loss: 5.421405]\n",
      "epoch2 step27595 [D loss: -0.544096] [G loss: 5.357715]\n",
      "epoch2 step27600 [D loss: -1.509983] [G loss: 4.886767]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.430500\n",
      "FID: 21.745687\n",
      "0 = 12.46844268636705\n",
      "1 = 0.08042201194062255\n",
      "2 = 0.8282999992370605\n",
      "3 = 0.8885999917984009\n",
      "4 = 0.7680000066757202\n",
      "5 = 0.7929680347442627\n",
      "6 = 0.8885999917984009\n",
      "7 = 7.937617956423771\n",
      "8 = 0.09075531633426291\n",
      "9 = 0.7973999977111816\n",
      "10 = 0.8212000131607056\n",
      "11 = 0.7735999822616577\n",
      "12 = 0.7838869690895081\n",
      "13 = 0.8212000131607056\n",
      "14 = 6.430535316467285\n",
      "15 = 9.313307762145996\n",
      "16 = 0.17101669311523438\n",
      "17 = 6.430500030517578\n",
      "18 = 21.74568748474121\n",
      "epoch2 step27605 [D loss: -1.001006] [G loss: 5.150327]\n",
      "epoch2 step27610 [D loss: -0.833820] [G loss: 5.164515]\n",
      "epoch2 step27615 [D loss: -1.626851] [G loss: 6.442167]\n",
      "epoch2 step27620 [D loss: -0.954676] [G loss: 5.915179]\n",
      "epoch2 step27625 [D loss: -0.957128] [G loss: 6.461422]\n",
      "epoch2 step27630 [D loss: -1.796294] [G loss: 5.860140]\n",
      "epoch2 step27635 [D loss: -0.895854] [G loss: 6.307276]\n",
      "epoch2 step27640 [D loss: -1.736218] [G loss: 5.390304]\n",
      "epoch2 step27645 [D loss: -1.748719] [G loss: 5.899522]\n",
      "epoch2 step27650 [D loss: -0.851250] [G loss: 6.132377]\n",
      "epoch2 step27655 [D loss: 1.263110] [G loss: 5.784219]\n",
      "epoch2 step27660 [D loss: -0.431764] [G loss: 5.732513]\n",
      "epoch2 step27665 [D loss: 0.423762] [G loss: 5.281174]\n",
      "epoch2 step27670 [D loss: 0.328578] [G loss: 5.651549]\n",
      "epoch2 step27675 [D loss: -0.946589] [G loss: 5.727940]\n",
      "epoch2 step27680 [D loss: -0.315545] [G loss: 5.110972]\n",
      "epoch2 step27685 [D loss: -1.010363] [G loss: 5.309059]\n",
      "epoch2 step27690 [D loss: -0.876619] [G loss: 5.463806]\n",
      "epoch2 step27695 [D loss: -0.008287] [G loss: 5.607757]\n",
      "epoch2 step27700 [D loss: -0.147813] [G loss: 5.486866]\n",
      "epoch2 step27705 [D loss: 0.013709] [G loss: 5.574979]\n",
      "epoch2 step27710 [D loss: -0.256631] [G loss: 5.391752]\n",
      "epoch2 step27715 [D loss: -0.783631] [G loss: 6.143270]\n",
      "epoch2 step27720 [D loss: -0.275450] [G loss: 5.586998]\n",
      "epoch2 step27725 [D loss: -0.793506] [G loss: 5.963030]\n",
      "epoch2 step27730 [D loss: -0.229454] [G loss: 5.582492]\n",
      "epoch2 step27735 [D loss: -1.089169] [G loss: 5.440413]\n",
      "epoch2 step27740 [D loss: -1.945371] [G loss: 5.293306]\n",
      "epoch2 step27745 [D loss: -1.118208] [G loss: 5.793604]\n",
      "epoch2 step27750 [D loss: -0.703646] [G loss: 5.999364]\n",
      "epoch2 step27755 [D loss: -1.169328] [G loss: 6.045121]\n",
      "epoch2 step27760 [D loss: -1.404850] [G loss: 5.719022]\n",
      "epoch2 step27765 [D loss: -0.347904] [G loss: 5.920498]\n",
      "epoch2 step27770 [D loss: -0.482314] [G loss: 5.916290]\n",
      "epoch2 step27775 [D loss: -0.704066] [G loss: 4.691031]\n",
      "epoch2 step27780 [D loss: -0.121641] [G loss: 5.867230]\n",
      "epoch2 step27785 [D loss: 0.214937] [G loss: 5.172531]\n",
      "epoch2 step27790 [D loss: -0.539988] [G loss: 5.130632]\n",
      "epoch2 step27795 [D loss: -0.107847] [G loss: 5.611624]\n",
      "epoch2 step27800 [D loss: 0.458824] [G loss: 5.434012]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.638618\n",
      "FID: 16.464428\n",
      "0 = 12.488968460845904\n",
      "1 = 0.05148415827379934\n",
      "2 = 0.7918000221252441\n",
      "3 = 0.8866000175476074\n",
      "4 = 0.6970000267028809\n",
      "5 = 0.7452925443649292\n",
      "6 = 0.8866000175476074\n",
      "7 = 7.630899798917774\n",
      "8 = 0.07487996350173387\n",
      "9 = 0.7766000032424927\n",
      "10 = 0.8209999799728394\n",
      "11 = 0.732200026512146\n",
      "12 = 0.7540411353111267\n",
      "13 = 0.8209999799728394\n",
      "14 = 6.6386494636535645\n",
      "15 = 9.323934555053711\n",
      "16 = 0.16512809693813324\n",
      "17 = 6.638618469238281\n",
      "18 = 16.464427947998047\n",
      "epoch2 step27805 [D loss: -0.705027] [G loss: 5.370725]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2 step27810 [D loss: -0.574397] [G loss: 5.243158]\n",
      "epoch2 step27815 [D loss: -0.677309] [G loss: 6.191843]\n",
      "epoch2 step27820 [D loss: -0.105387] [G loss: 5.956665]\n",
      "epoch2 step27825 [D loss: 0.626862] [G loss: 5.575821]\n",
      "epoch2 step27830 [D loss: -0.338454] [G loss: 6.069637]\n",
      "epoch2 step27835 [D loss: -1.064290] [G loss: 5.230464]\n",
      "epoch2 step27840 [D loss: -1.862913] [G loss: 5.429855]\n",
      "epoch2 step27845 [D loss: -1.433859] [G loss: 6.015338]\n",
      "epoch2 step27850 [D loss: 0.266470] [G loss: 5.508861]\n",
      "epoch2 step27855 [D loss: -1.161806] [G loss: 5.651776]\n",
      "epoch2 step27860 [D loss: -1.687951] [G loss: 5.698512]\n",
      "epoch2 step27865 [D loss: -0.962061] [G loss: 4.584971]\n",
      "epoch2 step27870 [D loss: -2.462487] [G loss: 5.417894]\n",
      "epoch2 step27875 [D loss: -0.875824] [G loss: 5.247661]\n",
      "epoch2 step27880 [D loss: -0.086773] [G loss: 4.986926]\n",
      "epoch2 step27885 [D loss: -0.615499] [G loss: 5.669911]\n",
      "epoch2 step27890 [D loss: -0.975838] [G loss: 5.208021]\n",
      "epoch2 step27895 [D loss: -0.598441] [G loss: 5.031321]\n",
      "epoch2 step27900 [D loss: -0.185690] [G loss: 4.927246]\n",
      "epoch2 step27905 [D loss: -0.775002] [G loss: 5.172389]\n",
      "epoch2 step27910 [D loss: 0.042891] [G loss: 4.982715]\n",
      "epoch2 step27915 [D loss: -0.066936] [G loss: 4.512949]\n",
      "epoch2 step27920 [D loss: -0.757820] [G loss: 3.685079]\n",
      "epoch2 step27925 [D loss: -0.044897] [G loss: 3.170034]\n",
      "epoch2 step27930 [D loss: -0.666316] [G loss: 4.348215]\n",
      "epoch2 step27935 [D loss: -1.541503] [G loss: 4.013582]\n",
      "epoch2 step27940 [D loss: -2.125179] [G loss: 4.285856]\n",
      "epoch2 step27945 [D loss: 0.444613] [G loss: 4.020093]\n",
      "epoch2 step27950 [D loss: 0.469111] [G loss: 3.496154]\n",
      "epoch2 step27955 [D loss: -0.021335] [G loss: 3.539772]\n",
      "epoch2 step27960 [D loss: 0.416180] [G loss: 4.109858]\n",
      "epoch2 step27965 [D loss: -0.968906] [G loss: 4.092616]\n",
      "epoch2 step27970 [D loss: -1.174422] [G loss: 3.280032]\n",
      "epoch2 step27975 [D loss: -0.684942] [G loss: 3.487095]\n",
      "epoch2 step27980 [D loss: -0.938802] [G loss: 3.426292]\n",
      "epoch2 step27985 [D loss: -2.219645] [G loss: 3.489319]\n",
      "epoch2 step27990 [D loss: -0.403086] [G loss: 2.858766]\n",
      "epoch2 step27995 [D loss: -2.440810] [G loss: 3.304888]\n",
      "epoch2 step28000 [D loss: -1.093806] [G loss: 3.206785]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.893905\n",
      "FID: 13.473762\n",
      "0 = 12.969492340612415\n",
      "1 = 0.08394320166247342\n",
      "2 = 0.7960000038146973\n",
      "3 = 0.9028000235557556\n",
      "4 = 0.6891999840736389\n",
      "5 = 0.7439024448394775\n",
      "6 = 0.9028000235557556\n",
      "7 = 7.562576097619532\n",
      "8 = 0.06901108843398474\n",
      "9 = 0.7770000100135803\n",
      "10 = 0.8289999961853027\n",
      "11 = 0.7250000238418579\n",
      "12 = 0.7509058117866516\n",
      "13 = 0.8289999961853027\n",
      "14 = 6.893933296203613\n",
      "15 = 9.390384674072266\n",
      "16 = 0.14634864032268524\n",
      "17 = 6.893904685974121\n",
      "18 = 13.473761558532715\n",
      "epoch2 step28005 [D loss: -1.341577] [G loss: 2.200248]\n",
      "epoch2 step28010 [D loss: -1.578919] [G loss: 3.008181]\n",
      "epoch2 step28015 [D loss: -1.359622] [G loss: 1.849066]\n",
      "epoch2 step28020 [D loss: -2.842112] [G loss: 2.917430]\n",
      "epoch2 step28025 [D loss: -0.930496] [G loss: 2.556814]\n",
      "epoch2 step28030 [D loss: 2.341356] [G loss: 2.531144]\n",
      "epoch2 step28035 [D loss: 1.420646] [G loss: 2.745860]\n",
      "epoch2 step28040 [D loss: 1.399665] [G loss: 2.562995]\n",
      "epoch2 step28045 [D loss: -0.509974] [G loss: 3.710775]\n",
      "epoch2 step28050 [D loss: -1.901234] [G loss: 3.367419]\n",
      "epoch2 step28055 [D loss: 0.198005] [G loss: 2.313271]\n",
      "epoch2 step28060 [D loss: -1.633938] [G loss: 2.741233]\n",
      "epoch2 step28065 [D loss: 0.107640] [G loss: 2.400390]\n",
      "epoch2 step28070 [D loss: -0.822531] [G loss: 3.011299]\n",
      "epoch2 step28075 [D loss: -0.534254] [G loss: 2.257951]\n",
      "epoch2 step28080 [D loss: -2.551525] [G loss: 2.551440]\n",
      "epoch2 step28085 [D loss: -0.693336] [G loss: 2.441530]\n",
      "epoch2 step28090 [D loss: -0.891409] [G loss: 1.887972]\n",
      "epoch2 step28095 [D loss: -0.544488] [G loss: 2.173429]\n",
      "epoch2 step28100 [D loss: -1.891683] [G loss: 2.282601]\n",
      "epoch2 step28105 [D loss: -1.509037] [G loss: 1.209918]\n",
      "epoch2 step28110 [D loss: -1.696352] [G loss: 1.449526]\n",
      "epoch2 step28115 [D loss: -3.513022] [G loss: 2.481740]\n",
      "epoch2 step28120 [D loss: -2.082997] [G loss: 1.464724]\n",
      "epoch2 step28125 [D loss: -2.904024] [G loss: 1.593696]\n",
      "epoch3 step28130 [D loss: 0.018675] [G loss: 2.131337]\n",
      "epoch3 step28135 [D loss: 0.492385] [G loss: 1.765686]\n",
      "epoch3 step28140 [D loss: 0.164319] [G loss: 2.152516]\n",
      "epoch3 step28145 [D loss: 0.343907] [G loss: 2.338705]\n",
      "epoch3 step28150 [D loss: -0.121667] [G loss: 2.676029]\n",
      "epoch3 step28155 [D loss: -0.968109] [G loss: 2.944588]\n",
      "epoch3 step28160 [D loss: 0.393892] [G loss: 2.290132]\n",
      "epoch3 step28165 [D loss: -0.628399] [G loss: 2.775182]\n",
      "epoch3 step28170 [D loss: -0.731882] [G loss: 3.356505]\n",
      "epoch3 step28175 [D loss: -0.708634] [G loss: 2.650371]\n",
      "epoch3 step28180 [D loss: -0.304776] [G loss: 2.696320]\n",
      "epoch3 step28185 [D loss: 0.005117] [G loss: 2.713644]\n",
      "epoch3 step28190 [D loss: -0.119923] [G loss: 1.779488]\n",
      "epoch3 step28195 [D loss: -0.494547] [G loss: 2.020433]\n",
      "epoch3 step28200 [D loss: -0.765443] [G loss: 3.106470]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.564089\n",
      "FID: 19.841940\n",
      "0 = 13.186501124191288\n",
      "1 = 0.12148983075319691\n",
      "2 = 0.8489999771118164\n",
      "3 = 0.8952000141143799\n",
      "4 = 0.8027999997138977\n",
      "5 = 0.8194800615310669\n",
      "6 = 0.8952000141143799\n",
      "7 = 7.909763796615595\n",
      "8 = 0.0883350579675221\n",
      "9 = 0.8025000095367432\n",
      "10 = 0.8281999826431274\n",
      "11 = 0.7767999768257141\n",
      "12 = 0.7877116203308105\n",
      "13 = 0.8281999826431274\n",
      "14 = 6.564114093780518\n",
      "15 = 9.462132453918457\n",
      "16 = 0.141847625374794\n",
      "17 = 6.564088821411133\n",
      "18 = 19.84193992614746\n",
      "epoch3 step28205 [D loss: -1.216177] [G loss: 3.149845]\n",
      "epoch3 step28210 [D loss: -0.463459] [G loss: 2.718069]\n",
      "epoch3 step28215 [D loss: -0.630229] [G loss: 2.595336]\n",
      "epoch3 step28220 [D loss: -1.036476] [G loss: 3.150474]\n",
      "epoch3 step28225 [D loss: -0.502544] [G loss: 3.075300]\n",
      "epoch3 step28230 [D loss: -0.878263] [G loss: 2.730267]\n",
      "epoch3 step28235 [D loss: 0.727357] [G loss: 2.775196]\n",
      "epoch3 step28240 [D loss: -0.367016] [G loss: 2.511760]\n",
      "epoch3 step28245 [D loss: 0.220198] [G loss: 3.209374]\n",
      "epoch3 step28250 [D loss: -0.005185] [G loss: 2.566336]\n",
      "epoch3 step28255 [D loss: -0.862144] [G loss: 3.371620]\n",
      "epoch3 step28260 [D loss: -1.121470] [G loss: 3.416089]\n",
      "epoch3 step28265 [D loss: -0.164160] [G loss: 2.900335]\n",
      "epoch3 step28270 [D loss: 0.390991] [G loss: 3.274717]\n",
      "epoch3 step28275 [D loss: -0.602751] [G loss: 3.728310]\n",
      "epoch3 step28280 [D loss: -1.196888] [G loss: 3.606676]\n",
      "epoch3 step28285 [D loss: -0.831133] [G loss: 3.459795]\n",
      "epoch3 step28290 [D loss: 0.176659] [G loss: 3.236427]\n",
      "epoch3 step28295 [D loss: -0.049127] [G loss: 3.366897]\n",
      "epoch3 step28300 [D loss: 0.687079] [G loss: 3.610142]\n",
      "epoch3 step28305 [D loss: -0.718959] [G loss: 3.357582]\n",
      "epoch3 step28310 [D loss: -0.704678] [G loss: 3.608705]\n",
      "epoch3 step28315 [D loss: 0.443364] [G loss: 4.059668]\n",
      "epoch3 step28320 [D loss: 0.626180] [G loss: 3.599759]\n",
      "epoch3 step28325 [D loss: -0.236108] [G loss: 3.919970]\n",
      "epoch3 step28330 [D loss: 0.224274] [G loss: 3.404314]\n",
      "epoch3 step28335 [D loss: 0.243109] [G loss: 3.580663]\n",
      "epoch3 step28340 [D loss: 0.009285] [G loss: 3.505310]\n",
      "epoch3 step28345 [D loss: -0.402042] [G loss: 4.146311]\n",
      "epoch3 step28350 [D loss: -0.005859] [G loss: 3.942673]\n",
      "epoch3 step28355 [D loss: -0.296540] [G loss: 3.996702]\n",
      "epoch3 step28360 [D loss: 0.678751] [G loss: 3.838610]\n",
      "epoch3 step28365 [D loss: -0.368654] [G loss: 4.435372]\n",
      "epoch3 step28370 [D loss: -0.505705] [G loss: 3.958010]\n",
      "epoch3 step28375 [D loss: -0.317778] [G loss: 4.868610]\n",
      "epoch3 step28380 [D loss: -0.043905] [G loss: 4.117693]\n",
      "epoch3 step28385 [D loss: -0.448600] [G loss: 5.106313]\n",
      "epoch3 step28390 [D loss: -1.136615] [G loss: 4.744243]\n",
      "epoch3 step28395 [D loss: -0.794984] [G loss: 5.578446]\n",
      "epoch3 step28400 [D loss: -0.661013] [G loss: 5.183105]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.599374\n",
      "FID: 18.730753\n",
      "0 = 13.546725653553008\n",
      "1 = 0.13006533081552274\n",
      "2 = 0.8575999736785889\n",
      "3 = 0.8980000019073486\n",
      "4 = 0.8172000050544739\n",
      "5 = 0.8308660387992859\n",
      "6 = 0.8980000019073486\n",
      "7 = 7.849232310390509\n",
      "8 = 0.08631467412355315\n",
      "9 = 0.8011999726295471\n",
      "10 = 0.83160001039505\n",
      "11 = 0.770799994468689\n",
      "12 = 0.7839366793632507\n",
      "13 = 0.83160001039505\n",
      "14 = 6.599400043487549\n",
      "15 = 9.386272430419922\n",
      "16 = 0.15034490823745728\n",
      "17 = 6.599373817443848\n",
      "18 = 18.73075294494629\n",
      "epoch3 step28405 [D loss: -0.326049] [G loss: 4.853761]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch3 step28410 [D loss: -1.430477] [G loss: 4.999389]\n",
      "epoch3 step28415 [D loss: -0.214335] [G loss: 5.201573]\n",
      "epoch3 step28420 [D loss: -0.157944] [G loss: 5.235126]\n",
      "epoch3 step28425 [D loss: -0.134204] [G loss: 6.358264]\n",
      "epoch3 step28430 [D loss: -0.035796] [G loss: 5.837418]\n",
      "epoch3 step28435 [D loss: -1.239727] [G loss: 6.138647]\n",
      "epoch3 step28440 [D loss: -1.087844] [G loss: 6.480717]\n",
      "epoch3 step28445 [D loss: -0.873764] [G loss: 6.078594]\n",
      "epoch3 step28450 [D loss: -0.613235] [G loss: 6.105792]\n",
      "epoch3 step28455 [D loss: -2.062571] [G loss: 5.899911]\n",
      "epoch3 step28460 [D loss: -1.939180] [G loss: 6.461747]\n",
      "epoch3 step28465 [D loss: -1.212442] [G loss: 6.318507]\n",
      "epoch3 step28470 [D loss: -1.885039] [G loss: 5.877553]\n",
      "epoch3 step28475 [D loss: -1.471407] [G loss: 6.762487]\n",
      "epoch3 step28480 [D loss: -2.788255] [G loss: 5.969330]\n",
      "epoch3 step28485 [D loss: -3.120666] [G loss: 6.738311]\n",
      "epoch3 step28490 [D loss: -2.461019] [G loss: 6.827312]\n",
      "epoch3 step28495 [D loss: -1.134088] [G loss: 6.842113]\n",
      "epoch3 step28500 [D loss: 0.148404] [G loss: 6.417702]\n",
      "epoch3 step28505 [D loss: -0.052986] [G loss: 6.461750]\n",
      "epoch3 step28510 [D loss: 0.276611] [G loss: 6.432089]\n",
      "epoch3 step28515 [D loss: -0.011065] [G loss: 6.725821]\n",
      "epoch3 step28520 [D loss: -1.320755] [G loss: 6.174965]\n",
      "epoch3 step28525 [D loss: 0.173034] [G loss: 6.494619]\n",
      "epoch3 step28530 [D loss: -0.202005] [G loss: 6.287323]\n",
      "epoch3 step28535 [D loss: -0.832704] [G loss: 7.176841]\n",
      "epoch3 step28540 [D loss: -1.468538] [G loss: 6.285841]\n",
      "epoch3 step28545 [D loss: -0.262376] [G loss: 6.594009]\n",
      "epoch3 step28550 [D loss: 0.014398] [G loss: 7.004972]\n",
      "epoch3 step28555 [D loss: -2.326735] [G loss: 7.208834]\n",
      "epoch3 step28560 [D loss: -1.060600] [G loss: 7.331007]\n",
      "epoch3 step28565 [D loss: -1.197444] [G loss: 7.118184]\n",
      "epoch3 step28570 [D loss: -1.324427] [G loss: 7.884044]\n",
      "epoch3 step28575 [D loss: -1.171433] [G loss: 7.795617]\n",
      "epoch3 step28580 [D loss: -0.515144] [G loss: 7.438094]\n",
      "epoch3 step28585 [D loss: 0.148856] [G loss: 7.253226]\n",
      "epoch3 step28590 [D loss: 0.169187] [G loss: 7.619892]\n",
      "epoch3 step28595 [D loss: -0.809011] [G loss: 7.482187]\n",
      "epoch3 step28600 [D loss: -0.369917] [G loss: 7.086666]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.627113\n",
      "FID: 16.481781\n",
      "0 = 13.106912139606512\n",
      "1 = 0.08622485582135568\n",
      "2 = 0.8241000175476074\n",
      "3 = 0.8948000073432922\n",
      "4 = 0.7534000277519226\n",
      "5 = 0.7839495539665222\n",
      "6 = 0.8948000073432922\n",
      "7 = 7.730904797983182\n",
      "8 = 0.07907593865454067\n",
      "9 = 0.7894999980926514\n",
      "10 = 0.8276000022888184\n",
      "11 = 0.7513999938964844\n",
      "12 = 0.7690020203590393\n",
      "13 = 0.8276000022888184\n",
      "14 = 6.627135276794434\n",
      "15 = 9.282370567321777\n",
      "16 = 0.16197513043880463\n",
      "17 = 6.627113342285156\n",
      "18 = 16.481781005859375\n",
      "epoch3 step28605 [D loss: -0.006314] [G loss: 7.082462]\n",
      "epoch3 step28610 [D loss: 0.176758] [G loss: 7.237554]\n",
      "epoch3 step28615 [D loss: -0.858893] [G loss: 6.928552]\n",
      "epoch3 step28620 [D loss: -0.208092] [G loss: 6.974404]\n",
      "epoch3 step28625 [D loss: 0.121790] [G loss: 6.970227]\n",
      "epoch3 step28630 [D loss: -0.815824] [G loss: 7.263768]\n",
      "epoch3 step28635 [D loss: -0.757760] [G loss: 7.234458]\n",
      "epoch3 step28640 [D loss: -0.551412] [G loss: 6.680971]\n",
      "epoch3 step28645 [D loss: -0.266739] [G loss: 7.064813]\n",
      "epoch3 step28650 [D loss: -0.989754] [G loss: 6.429461]\n",
      "epoch3 step28655 [D loss: -0.653761] [G loss: 6.885745]\n",
      "epoch3 step28660 [D loss: -0.534186] [G loss: 7.014478]\n",
      "epoch3 step28665 [D loss: -0.926828] [G loss: 6.710334]\n",
      "epoch3 step28670 [D loss: -1.852750] [G loss: 6.853572]\n",
      "epoch3 step28675 [D loss: -2.355352] [G loss: 6.851884]\n",
      "epoch3 step28680 [D loss: -0.571677] [G loss: 7.478473]\n",
      "epoch3 step28685 [D loss: -1.571058] [G loss: 6.323416]\n",
      "epoch3 step28690 [D loss: -0.549381] [G loss: 7.525967]\n",
      "epoch3 step28695 [D loss: -0.716752] [G loss: 6.941898]\n",
      "epoch3 step28700 [D loss: -0.285858] [G loss: 7.467785]\n",
      "epoch3 step28705 [D loss: -1.929656] [G loss: 7.684102]\n",
      "epoch3 step28710 [D loss: -1.163700] [G loss: 8.381557]\n",
      "epoch3 step28715 [D loss: -1.385384] [G loss: 7.976409]\n",
      "epoch3 step28720 [D loss: -1.332238] [G loss: 7.734740]\n",
      "epoch3 step28725 [D loss: -1.072743] [G loss: 8.274059]\n",
      "epoch3 step28730 [D loss: -1.411279] [G loss: 7.945024]\n",
      "epoch3 step28735 [D loss: -1.477228] [G loss: 7.872882]\n",
      "epoch3 step28740 [D loss: -0.630074] [G loss: 7.869872]\n",
      "epoch3 step28745 [D loss: -0.727603] [G loss: 6.886187]\n",
      "epoch3 step28750 [D loss: -0.776746] [G loss: 6.863168]\n",
      "epoch3 step28755 [D loss: -0.186482] [G loss: 6.308043]\n",
      "epoch3 step28760 [D loss: -0.485098] [G loss: 6.766692]\n",
      "epoch3 step28765 [D loss: 0.454777] [G loss: 7.049167]\n",
      "epoch3 step28770 [D loss: 0.246353] [G loss: 7.009044]\n",
      "epoch3 step28775 [D loss: -0.272555] [G loss: 6.459733]\n",
      "epoch3 step28780 [D loss: -0.223985] [G loss: 6.693391]\n",
      "epoch3 step28785 [D loss: -0.156475] [G loss: 6.913751]\n",
      "epoch3 step28790 [D loss: -0.606904] [G loss: 6.445345]\n",
      "epoch3 step28795 [D loss: -0.119312] [G loss: 6.111019]\n",
      "epoch3 step28800 [D loss: 0.056712] [G loss: 5.789659]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.931467\n",
      "FID: 11.071495\n",
      "0 = 13.30898888912202\n",
      "1 = 0.08684957447815235\n",
      "2 = 0.7955999970436096\n",
      "3 = 0.9264000058174133\n",
      "4 = 0.6647999882698059\n",
      "5 = 0.7343056201934814\n",
      "6 = 0.9264000058174133\n",
      "7 = 7.439187265467666\n",
      "8 = 0.06274651548885923\n",
      "9 = 0.7781000137329102\n",
      "10 = 0.8307999968528748\n",
      "11 = 0.7253999710083008\n",
      "12 = 0.7515831589698792\n",
      "13 = 0.8307999968528748\n",
      "14 = 6.931499481201172\n",
      "15 = 9.363447189331055\n",
      "16 = 0.1409783810377121\n",
      "17 = 6.931467056274414\n",
      "18 = 11.071495056152344\n",
      "epoch3 step28805 [D loss: 0.110991] [G loss: 5.989689]\n",
      "epoch3 step28810 [D loss: 0.009591] [G loss: 5.810493]\n",
      "epoch3 step28815 [D loss: 0.097775] [G loss: 5.992815]\n",
      "epoch3 step28820 [D loss: -0.955376] [G loss: 6.034966]\n",
      "epoch3 step28825 [D loss: -1.095891] [G loss: 5.993040]\n",
      "epoch3 step28830 [D loss: -1.203660] [G loss: 6.168121]\n",
      "epoch3 step28835 [D loss: -1.176027] [G loss: 6.311602]\n",
      "epoch3 step28840 [D loss: -0.283317] [G loss: 6.448013]\n",
      "epoch3 step28845 [D loss: -0.629142] [G loss: 6.692999]\n",
      "epoch3 step28850 [D loss: -0.598777] [G loss: 6.668653]\n",
      "epoch3 step28855 [D loss: -0.318024] [G loss: 6.811368]\n",
      "epoch3 step28860 [D loss: -0.620530] [G loss: 6.328949]\n",
      "epoch3 step28865 [D loss: -1.117242] [G loss: 6.381785]\n",
      "epoch3 step28870 [D loss: -0.763538] [G loss: 6.152106]\n",
      "epoch3 step28875 [D loss: -2.358567] [G loss: 6.809237]\n",
      "epoch3 step28880 [D loss: 0.129782] [G loss: 6.540481]\n",
      "epoch3 step28885 [D loss: -1.824735] [G loss: 6.114456]\n",
      "epoch3 step28890 [D loss: -2.746205] [G loss: 6.903701]\n",
      "epoch3 step28895 [D loss: 0.214125] [G loss: 6.886744]\n",
      "epoch3 step28900 [D loss: -0.684664] [G loss: 7.015856]\n",
      "epoch3 step28905 [D loss: -0.412100] [G loss: 6.606367]\n",
      "epoch3 step28910 [D loss: 0.395610] [G loss: 6.515424]\n",
      "epoch3 step28915 [D loss: 1.111272] [G loss: 6.216949]\n",
      "epoch3 step28920 [D loss: 0.253524] [G loss: 5.659441]\n",
      "epoch3 step28925 [D loss: 0.419456] [G loss: 5.817366]\n",
      "epoch3 step28930 [D loss: 0.058492] [G loss: 5.457954]\n",
      "epoch3 step28935 [D loss: 0.391826] [G loss: 6.379808]\n",
      "epoch3 step28940 [D loss: -0.060393] [G loss: 6.305633]\n",
      "epoch3 step28945 [D loss: 0.312821] [G loss: 5.663762]\n",
      "epoch3 step28950 [D loss: 0.339961] [G loss: 5.523131]\n",
      "epoch3 step28955 [D loss: -1.003245] [G loss: 5.467784]\n",
      "epoch3 step28960 [D loss: -0.024216] [G loss: 5.336462]\n",
      "epoch3 step28965 [D loss: -0.562847] [G loss: 6.230771]\n",
      "epoch3 step28970 [D loss: -0.807625] [G loss: 4.907160]\n",
      "epoch3 step28975 [D loss: -0.443763] [G loss: 5.599888]\n",
      "epoch3 step28980 [D loss: -0.674916] [G loss: 5.591331]\n",
      "epoch3 step28985 [D loss: -0.437496] [G loss: 4.750092]\n",
      "epoch3 step28990 [D loss: -0.110069] [G loss: 5.040803]\n",
      "epoch3 step28995 [D loss: -1.460433] [G loss: 4.644333]\n",
      "epoch3 step29000 [D loss: 0.307001] [G loss: 3.801564]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.747535\n",
      "FID: 14.174853\n",
      "0 = 13.522548115587245\n",
      "1 = 0.1150091524213879\n",
      "2 = 0.8119000196456909\n",
      "3 = 0.9279999732971191\n",
      "4 = 0.6958000063896179\n",
      "5 = 0.753124475479126\n",
      "6 = 0.9279999732971191\n",
      "7 = 7.649817750310896\n",
      "8 = 0.07558193146885694\n",
      "9 = 0.7749999761581421\n",
      "10 = 0.8209999799728394\n",
      "11 = 0.7289999723434448\n",
      "12 = 0.7518315315246582\n",
      "13 = 0.8209999799728394\n",
      "14 = 6.747567653656006\n",
      "15 = 9.155861854553223\n",
      "16 = 0.18217451870441437\n",
      "17 = 6.74753475189209\n",
      "18 = 14.174853324890137\n",
      "epoch3 step29005 [D loss: -0.452881] [G loss: 4.456835]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch3 step29010 [D loss: -0.597878] [G loss: 4.689691]\n",
      "epoch3 step29015 [D loss: -1.144052] [G loss: 5.091580]\n",
      "epoch3 step29020 [D loss: -0.429314] [G loss: 4.050103]\n",
      "epoch3 step29025 [D loss: -1.531300] [G loss: 4.891928]\n",
      "epoch3 step29030 [D loss: -1.099022] [G loss: 3.477994]\n",
      "epoch3 step29035 [D loss: -0.087910] [G loss: 4.012681]\n",
      "epoch3 step29040 [D loss: -1.612131] [G loss: 3.928114]\n",
      "epoch3 step29045 [D loss: -1.234252] [G loss: 4.113688]\n",
      "epoch3 step29050 [D loss: -0.238082] [G loss: 4.366629]\n",
      "epoch3 step29055 [D loss: -1.762682] [G loss: 4.310939]\n",
      "epoch3 step29060 [D loss: -1.045702] [G loss: 4.219803]\n",
      "epoch3 step29065 [D loss: -1.459406] [G loss: 3.925587]\n",
      "epoch3 step29070 [D loss: -0.637589] [G loss: 4.513494]\n",
      "epoch3 step29075 [D loss: -0.831001] [G loss: 3.686595]\n",
      "epoch3 step29080 [D loss: -0.940470] [G loss: 4.396534]\n",
      "epoch3 step29085 [D loss: -0.634995] [G loss: 4.461990]\n",
      "epoch3 step29090 [D loss: -1.378559] [G loss: 4.264518]\n",
      "epoch3 step29095 [D loss: -1.105211] [G loss: 4.198702]\n",
      "epoch3 step29100 [D loss: -0.636455] [G loss: 3.786412]\n",
      "epoch3 step29105 [D loss: -1.118470] [G loss: 3.957898]\n",
      "epoch3 step29110 [D loss: -0.629259] [G loss: 3.119212]\n",
      "epoch3 step29115 [D loss: -0.546924] [G loss: 3.476861]\n",
      "epoch3 step29120 [D loss: -0.479130] [G loss: 2.377267]\n",
      "epoch3 step29125 [D loss: -0.012601] [G loss: 3.302331]\n",
      "epoch3 step29130 [D loss: -1.092500] [G loss: 3.686987]\n",
      "epoch3 step29135 [D loss: -1.276659] [G loss: 3.234158]\n",
      "epoch3 step29140 [D loss: -1.767210] [G loss: 3.731758]\n",
      "epoch3 step29145 [D loss: -0.936485] [G loss: 2.935390]\n",
      "epoch3 step29150 [D loss: -0.996015] [G loss: 3.214304]\n",
      "epoch3 step29155 [D loss: -1.376292] [G loss: 3.036361]\n",
      "epoch3 step29160 [D loss: -1.246082] [G loss: 3.944662]\n",
      "epoch3 step29165 [D loss: -1.157000] [G loss: 2.860579]\n",
      "epoch3 step29170 [D loss: -1.232710] [G loss: 3.256117]\n",
      "epoch3 step29175 [D loss: -1.780011] [G loss: 3.140142]\n",
      "epoch3 step29180 [D loss: 0.209624] [G loss: 2.744495]\n",
      "epoch3 step29185 [D loss: -0.608956] [G loss: 3.485911]\n",
      "epoch3 step29190 [D loss: -1.219834] [G loss: 2.192807]\n",
      "epoch3 step29195 [D loss: -1.071150] [G loss: 2.914433]\n",
      "epoch3 step29200 [D loss: 0.156753] [G loss: 3.112947]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.631849\n",
      "FID: 17.426653\n",
      "0 = 12.473932960748671\n",
      "1 = 0.07286115077024889\n",
      "2 = 0.8187000155448914\n",
      "3 = 0.8763999938964844\n",
      "4 = 0.7609999775886536\n",
      "5 = 0.7857270836830139\n",
      "6 = 0.8763999938964844\n",
      "7 = 7.788561532092087\n",
      "8 = 0.0840978521156679\n",
      "9 = 0.7802000045776367\n",
      "10 = 0.8176000118255615\n",
      "11 = 0.7427999973297119\n",
      "12 = 0.7606996893882751\n",
      "13 = 0.8176000118255615\n",
      "14 = 6.631875514984131\n",
      "15 = 9.337081909179688\n",
      "16 = 0.16977205872535706\n",
      "17 = 6.6318488121032715\n",
      "18 = 17.426652908325195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#-*-coding:utf-8-*-\n",
    "from __future__ import print_function, division\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "import util\n",
    "import utils\n",
    "import tensorflow.contrib.gan as tfgan\n",
    "num_images_to_eval = 500\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, imgs, transform=None):\n",
    "        # super().__init__()\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.imgs[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = torch.from_numpy(img)\n",
    "        return img\n",
    "\n",
    "\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import ot\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.models as models\n",
    "\n",
    "from scipy import linalg\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def giveName(iter):  # 7 digit name.\n",
    "    ans = str(iter)\n",
    "    return ans.zfill(7)\n",
    "\n",
    "def make_dataset(dataset, dataroot, imageSize):\n",
    "    \"\"\"\n",
    "    :param dataset: must be in 'cifar10 | lsun | imagenet | folder | lfw | fake'\n",
    "    :return: pytorch dataset for DataLoader to utilize\n",
    "    \"\"\"\n",
    "    if dataset in ['imagenet', 'folder', 'lfw']:\n",
    "        print(os.getcwd() + dataroot)  # \n",
    "        # folder dataset\n",
    "        # dataset = dset.ImageFolder(root=dataroot,\n",
    "        dataset = dset.ImageFolder(root=os.getcwd() + dataroot,\n",
    "                                   transform=transforms.Compose([\n",
    "                                       transforms.Resize(imageSize),\n",
    "                                       # transforms.CenterCrop(imageSize),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(\n",
    "                                           (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                   ]))\n",
    "    elif dataset == 'lsun':\n",
    "        dataset = dset.LSUN(db_path=dataroot, classes=['bedroom_train'],\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.Resize(imageSize),\n",
    "                                transforms.CenterCrop(imageSize),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(\n",
    "                                    (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                            ]))\n",
    "    elif dataset == 'cifar10':\n",
    "        dataset = dset.CIFAR10(root=dataroot, download=True,\n",
    "                               transform=transforms.Compose([\n",
    "                                   transforms.Resize(imageSize),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize(\n",
    "                                       (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                               ]))\n",
    "    elif dataset == 'celeba':\n",
    "        dataset = dset.ImageFolder(root=dataroot,\n",
    "                                   transform=transforms.Compose([\n",
    "                                       transforms.CenterCrop(138),\n",
    "                                       transforms.Resize(imageSize),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(\n",
    "                                           (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                   ]))\n",
    "    else:\n",
    "        raise Exception('--dataset must be in cifar10 | lsun | imagenet | folder | lfw | fake')\n",
    "    assert dataset\n",
    "    return dataset\n",
    "\n",
    "MNIST_CLASSIFIER_FROZEN_GRAPH = './classify_mnist_graph_def.pb'\n",
    "INPUT_TENSOR = 'inputs:0'\n",
    "OUTPUT_TENSOR = 'logits:0'\n",
    "# CONV_TENSOR = 'fc3/Relu:0'\n",
    "CONV_TENSOR = 'fc4/BiasAdd:0'\n",
    "class ConvNetFeatureSaver(object):\n",
    "    def __init__(self, model='cnn', workers=4, batchSize=64):\n",
    "        '''\n",
    "        model: inception_v3, vgg13, vgg16, vgg19, resnet18, resnet34,\n",
    "               resnet50, resnet101, or resnet152\n",
    "        '''\n",
    "        self.model = model\n",
    "        self.batch_size = batchSize\n",
    "        self.workers = workers\n",
    "        if self.model.find('tfgan') >= 0:\n",
    "            print('tfgan')\n",
    "\n",
    "        elif self.model.find('vgg') >= 0:\n",
    "            self.vgg = getattr(models, model)(pretrained=True).cuda().eval()\n",
    "            self.trans = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                                     (0.229, 0.224, 0.225)),\n",
    "            ])\n",
    "        elif self.model.find('resnet') >= 0:\n",
    "            resnet = getattr(models, model)(pretrained=True)\n",
    "            resnet.cuda().eval()\n",
    "            resnet_feature = nn.Sequential(resnet.conv1, resnet.bn1,\n",
    "                                           resnet.relu,\n",
    "                                           resnet.maxpool, resnet.layer1,\n",
    "                                           resnet.layer2, resnet.layer3,\n",
    "                                           resnet.layer4).cuda().eval()\n",
    "            self.resnet = resnet\n",
    "            self.resnet_feature = resnet_feature\n",
    "            self.trans = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                                     (0.229, 0.224, 0.225)),\n",
    "            ])\n",
    "        elif self.model == 'inception' or self.model == 'inception_v3':\n",
    "            inception = models.inception_v3(\n",
    "                pretrained=True, transform_input=False).cuda().eval()\n",
    "            inception_feature = nn.Sequential(inception.Conv2d_1a_3x3,\n",
    "                                              inception.Conv2d_2a_3x3,\n",
    "                                              inception.Conv2d_2b_3x3,\n",
    "                                              nn.MaxPool2d(3, 2),\n",
    "                                              inception.Conv2d_3b_1x1,\n",
    "                                              inception.Conv2d_4a_3x3,\n",
    "                                              nn.MaxPool2d(3, 2),\n",
    "                                              inception.Mixed_5b,\n",
    "                                              inception.Mixed_5c,\n",
    "                                              inception.Mixed_5d,\n",
    "                                              inception.Mixed_6a,\n",
    "                                              inception.Mixed_6b,\n",
    "                                              inception.Mixed_6c,\n",
    "                                              inception.Mixed_6d,\n",
    "                                              inception.Mixed_7a,\n",
    "                                              inception.Mixed_7b,\n",
    "                                              inception.Mixed_7c,\n",
    "                                              ).cuda().eval()\n",
    "            self.inception = inception\n",
    "            self.inception_feature = inception_feature\n",
    "            self.trans = transforms.Compose([\n",
    "                transforms.Resize(299),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ])\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def save(self, imgFolder, dataloader, save2disk=False):\n",
    "        feature_pixl, feature_conv, feature_smax, feature_logit = [], [], [], []\n",
    "\n",
    "        for img in dataloader:\n",
    "            with torch.no_grad():\n",
    "                input = img.cuda()\n",
    "                if self.model == 'tfgan':\n",
    "                    gen_imgs = np.array(img)\n",
    "                    eval_images = tf.convert_to_tensor(gen_imgs)\n",
    "                    flogit = util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, OUTPUT_TENSOR)\n",
    "                    fconv = util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, CONV_TENSOR)\n",
    "                    flogit,fconv=tf.Session().run([flogit,fconv])\n",
    "\n",
    "                    flogit=torch.from_numpy(flogit)\n",
    "                    fconv=torch.from_numpy(fconv)\n",
    "                elif self.model == 'vgg' or self.model == 'vgg16':\n",
    "                    print(self.vgg.features(input).shape)\n",
    "                    fconv = self.vgg.features(input).view(input.size(0), -1)  # reshape\n",
    "                    flogit = self.vgg.classifier(fconv)\n",
    "                    # flogit = self.vgg.logitifier(fconv)\n",
    "                elif self.model.find('resnet') >= 0:\n",
    "                    fconv = self.resnet_feature(\n",
    "                        input).mean(3).mean(2).squeeze()\n",
    "                    flogit = self.resnet.fc(fconv)\n",
    "                elif self.model == 'inception' or self.model == 'inception_v3':\n",
    "                    fconv = self.inception_feature(\n",
    "                        input).mean(3).mean(2).squeeze()\n",
    "                    flogit = self.inception.fc(fconv)\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "                fsmax = F.softmax(flogit)\n",
    "                '''\n",
    "                1.feature_pixl 2.feature_conv 3.feature_logit 4.feature_smax\n",
    "                '''\n",
    "                feature_pixl.append(img)\n",
    "                feature_conv.append(fconv.data.cpu())\n",
    "                feature_logit.append(flogit.data.cpu())\n",
    "                feature_smax.append(fsmax.data.cpu())\n",
    "\n",
    "        feature_pixl = torch.cat(feature_pixl, 0).to('cpu')\n",
    "        feature_conv = torch.cat(feature_conv, 0).to('cpu')\n",
    "        feature_logit = torch.cat(feature_logit, 0).to('cpu')\n",
    "        feature_smax = torch.cat(feature_smax, 0).to('cpu')\n",
    "\n",
    "        return feature_pixl, feature_conv, feature_logit, feature_smax\n",
    "\n",
    "    # return feature_pixl, feature_conv, feature_logit, feature_smax\n",
    "\n",
    "\n",
    "def distance(X, Y, sqrt):\n",
    "    nX = X.size(0)\n",
    "    nY = Y.size(0)\n",
    "    X = X.view(nX, -1)\n",
    "    X2 = (X * X).sum(1).resize_(nX, 1)\n",
    "    Y = Y.view(nY, -1)\n",
    "    Y2 = (Y * Y).sum(1).resize_(nY, 1)\n",
    "\n",
    "    M = torch.zeros(nX, nY)\n",
    "    M.copy_(X2.expand(nX, nY) + Y2.expand(nY, nX).transpose(0, 1) -\n",
    "            2 * torch.mm(X, Y.transpose(0, 1)))\n",
    "\n",
    "    del X, X2, Y, Y2\n",
    "\n",
    "    if sqrt:\n",
    "        M = ((M + M.abs()) / 2).sqrt()\n",
    "\n",
    "    return M\n",
    "\n",
    "\n",
    "def wasserstein(M, sqrt):\n",
    "    if sqrt:\n",
    "        M = M.abs().sqrt()\n",
    "    emd = ot.emd2([], [], M.numpy())\n",
    "\n",
    "    return emd\n",
    "\n",
    "\n",
    "class Score_knn:\n",
    "    acc = 0\n",
    "    acc_real = 0\n",
    "    acc_fake = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    ft = 0\n",
    "\n",
    "\n",
    "def knn(Mxx, Mxy, Myy, k, sqrt):\n",
    "    n0 = Mxx.size(0)\n",
    "    n1 = Myy.size(0)\n",
    "    label = torch.cat((torch.ones(n0), torch.zeros(n1)))\n",
    "    M = torch.cat((torch.cat((Mxx, Mxy), 1), torch.cat(\n",
    "        (Mxy.transpose(0, 1), Myy), 1)), 0)\n",
    "    if sqrt:\n",
    "        M = M.abs().sqrt()\n",
    "    INFINITY = float('inf')\n",
    "    val, idx = (M + torch.diag(INFINITY * torch.ones(n0 + n1))\n",
    "                ).topk(k, 0, False)\n",
    "\n",
    "    count = torch.zeros(n0 + n1)\n",
    "    for i in range(0, k):\n",
    "        count = count + label.index_select(0, idx[i])\n",
    "    pred = torch.ge(count, (float(k) / 2) * torch.ones(n0 + n1)).float()\n",
    "\n",
    "    s = Score_knn()\n",
    "    s.tp = (pred * label).sum()\n",
    "    s.fp = (pred * (1 - label)).sum()\n",
    "    s.fn = ((1 - pred) * label).sum()\n",
    "    s.tn = ((1 - pred) * (1 - label)).sum()\n",
    "    s.precision = s.tp / (s.tp + s.fp + 1e-10)\n",
    "    s.recall = s.tp / (s.tp + s.fn + 1e-10)\n",
    "    s.acc_t = s.tp / (s.tp + s.fn)\n",
    "    s.acc_f = s.tn / (s.tn + s.fp)\n",
    "    s.acc = torch.eq(label, pred).float().mean()\n",
    "    s.k = k\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "def mmd(Mxx, Mxy, Myy, sigma):\n",
    "    scale = Mxx.mean()\n",
    "    Mxx = torch.exp(-Mxx / (scale * 2 * sigma * sigma))\n",
    "    Mxy = torch.exp(-Mxy / (scale * 2 * sigma * sigma))\n",
    "    Myy = torch.exp(-Myy / (scale * 2 * sigma * sigma))\n",
    "    mmd = math.sqrt(Mxx.mean() + Myy.mean() - 2 * Mxy.mean())\n",
    "\n",
    "    return mmd\n",
    "\n",
    "\n",
    "def entropy_score(X, Y, epsilons):\n",
    "    Mxy = distance(X, Y, False)\n",
    "    scores = []\n",
    "    for epsilon in epsilons:\n",
    "        scores.append(ent(Mxy.t(), epsilon))\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "def ent(M, epsilon):\n",
    "    n0 = M.size(0)\n",
    "    n1 = M.size(1)\n",
    "    neighbors = M.lt(epsilon).float()\n",
    "    sums = neighbors.sum(0).repeat(n0, 1)\n",
    "    sums[sums.eq(0)] = 1\n",
    "    neighbors = neighbors.div(sums)\n",
    "    probs = neighbors.sum(1) / n1\n",
    "    rem = 1 - probs.sum()\n",
    "    if rem < 0:\n",
    "        rem = 0\n",
    "    probs = torch.cat((probs, rem * torch.ones(1)), 0)\n",
    "    e = {}\n",
    "    e['probs'] = probs\n",
    "    probs = probs[probs.gt(0)]\n",
    "    e['ent'] = -probs.mul(probs.log()).sum()\n",
    "\n",
    "    return e\n",
    "\n",
    "\n",
    "eps = 1e-20\n",
    "\n",
    "\n",
    "def inception_score(X):\n",
    "    kl = X * ((X + eps).log() - (X.mean(0) + eps).log().expand_as(X))\n",
    "    score = np.exp(kl.sum(1).mean())\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def mode_score(X, Y):\n",
    "    kl1 = X * ((X + eps).log() - (X.mean(0) + eps).log().expand_as(X))\n",
    "    kl2 = X.mean(0) * ((X.mean(0) + eps).log() - (Y.mean(0) + eps).log())\n",
    "    score = np.exp(kl1.sum(1).mean() - kl2.sum())\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def fid(X, Y):\n",
    "    m = X.mean(0)\n",
    "    m_w = Y.mean(0)\n",
    "    X_np = X.numpy()\n",
    "    Y_np = Y.numpy()\n",
    "\n",
    "    C = np.cov(X_np.transpose())\n",
    "    C_w = np.cov(Y_np.transpose())\n",
    "    C_C_w_sqrt = linalg.sqrtm(C.dot(C_w), True).real\n",
    "\n",
    "    score = m.dot(m) + m_w.dot(m_w) - 2 * m_w.dot(m) + \\\n",
    "            np.trace(C + C_w - 2 * C_C_w_sqrt)\n",
    "    return np.sqrt(score)\n",
    "\n",
    "\n",
    "class Score:\n",
    "    emd = 0\n",
    "    mmd = 0\n",
    "    knn = None\n",
    "\n",
    "\n",
    "def compute_score(real, fake, k=1, sigma=1, sqrt=True):\n",
    "    Mxx = distance(real, real, False)\n",
    "    Mxy = distance(real, fake, False)\n",
    "    Myy = distance(fake, fake, False)\n",
    "\n",
    "    s = Score()\n",
    "    s.emd = wasserstein(Mxy, sqrt)\n",
    "    s.mmd = mmd(Mxx, Mxy, Myy, sigma)\n",
    "    s.knn = knn(Mxx, Mxy, Myy, k, sqrt)\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "dataset:path\n",
    "imageSize:\n",
    "dataroot_real:path\n",
    "batchSize\n",
    "saveFolder_r:\n",
    "conv_model:\n",
    "'''\n",
    "\n",
    "\n",
    "def compute_score_raw(real_dataloader, fake_dataloader, batchSize, saveFolder_r, saveFolder_f, conv_model='resnet34',\n",
    "                      workers=4):\n",
    "    convnet_feature_saver = ConvNetFeatureSaver(model=conv_model,\n",
    "                                                batchSize=batchSize, workers=workers)\n",
    "    print(saveFolder_r)\n",
    "    print(saveFolder_f)\n",
    "    feature_r = convnet_feature_saver.save(saveFolder_r, real_dataloader, False)\n",
    "    feature_f = convnet_feature_saver.save(saveFolder_f, fake_dataloader, False)\n",
    "\n",
    "    # 4 feature spaces and 7 scores + incep + modescore + fid\n",
    "    score = np.zeros(2 * 7 + 5)\n",
    "    for i in range(0, 2):\n",
    "        print('compute score in space: ' + str(i))\n",
    "        Mxx = distance(feature_r[i], feature_r[i], False)\n",
    "        Mxy = distance(feature_r[i], feature_f[i], False)\n",
    "        Myy = distance(feature_f[i], feature_f[i], False)\n",
    "\n",
    "        score[i * 7] = wasserstein(Mxy, True)\n",
    "        score[i * 7 + 1] = mmd(Mxx, Mxy, Myy, 1)\n",
    "        tmp = knn(Mxx, Mxy, Myy, 1, False)\n",
    "        score[(i * 7 + 2):(i * 7 + 7)] = \\\n",
    "            tmp.acc, tmp.acc_t, tmp.acc_f, tmp.precision, tmp.recall\n",
    "\n",
    "\n",
    "    score[14] = inception_score(feature_f[3])\n",
    "    score[15] = mode_score(feature_r[3], feature_f[3])\n",
    "    score[16] = fid(feature_r[3], feature_f[3])\n",
    "\n",
    "    return score\n",
    "labels_name=['w_pixl','mmd_pixl','acc_pixl','acc_t_pixl','acc_f_pixl','acc_precision_pixl','acc_recall_pixl',\n",
    "             'w_conv','mmd_conv','acc_conv','acc_t_conv','acc_f_conv','acc_precision_conv','acc_recall_conv',\n",
    "             'is','mode_score','fid' ,'tf_is','tf_fid']\n",
    "if not os.path.isdir('saved_models_{}'.format('acgan')):\n",
    "    os.mkdir('saved_models_{}'.format('acgan'))\n",
    "f = open('saved_models_{}/log_collapse1.txt'.format('acgan'), mode='w')\n",
    "import torch.utils.data as Data\n",
    "\n",
    "# Large amount of credit goes to:\n",
    "# https://github.com/keras-team/keras-contrib/blob/master/examples/improved_wgan.py\n",
    "# which I've used as a reference for this implementation\n",
    "\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.merge import _Merge\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import RMSprop\n",
    "from functools import partial\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "class RandomWeightedAverage(_Merge):\n",
    "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
    "    def _merge_function(self, inputs):\n",
    "        alpha = K.random_uniform((32, 1, 1, 1))\n",
    "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
    "\n",
    "class WGANGP():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "        self.x = []\n",
    "        self.y = np.zeros((31, 1), dtype=np.int)\n",
    "        self.y = list(self.y)\n",
    "        for i in range(31):\n",
    "            self.y[i] = []\n",
    "\n",
    "        # Following parameter and optimizer set as recommended in paper\n",
    "        self.n_critic = 5\n",
    "        optimizer = RMSprop(lr=0.00005)\n",
    "\n",
    "        # Build the generator and critic\n",
    "        self.generator = self.build_generator()\n",
    "        self.critic = self.build_critic()\n",
    "\n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #       for the Critic\n",
    "        #-------------------------------\n",
    "\n",
    "        # Freeze generator's layers while training critic\n",
    "        self.generator.trainable = False\n",
    "\n",
    "        # Image input (real sample)\n",
    "        real_img = Input(shape=self.img_shape)\n",
    "\n",
    "        # Noise input\n",
    "        z_disc = Input(shape=(self.latent_dim,))\n",
    "        # Generate image based of noise (fake sample)\n",
    "        fake_img = self.generator(z_disc)\n",
    "\n",
    "        # Discriminator determines validity of the real and fake images\n",
    "        fake = self.critic(fake_img)\n",
    "        valid = self.critic(real_img)\n",
    "\n",
    "        # Construct weighted average between real and fake images\n",
    "        interpolated_img = RandomWeightedAverage()([real_img, fake_img])\n",
    "        # Determine validity of weighted sample\n",
    "        validity_interpolated = self.critic(interpolated_img)\n",
    "\n",
    "        # Use Python partial to provide loss function with additional\n",
    "        # 'averaged_samples' argument\n",
    "        partial_gp_loss = partial(self.gradient_penalty_loss,\n",
    "                          averaged_samples=interpolated_img)\n",
    "        partial_gp_loss.__name__ = 'gradient_penalty' # Keras requires function names\n",
    "\n",
    "        self.critic_model = Model(inputs=[real_img, z_disc],\n",
    "                            outputs=[valid, fake, validity_interpolated])\n",
    "        self.critic_model.compile(loss=[self.wasserstein_loss,\n",
    "                                              self.wasserstein_loss,\n",
    "                                              partial_gp_loss],\n",
    "                                        optimizer=optimizer,\n",
    "                                        loss_weights=[1, 1, 10])\n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #         for Generator\n",
    "        #-------------------------------\n",
    "\n",
    "        # For the generator we freeze the critic's layers\n",
    "        self.critic.trainable = False\n",
    "        self.generator.trainable = True\n",
    "\n",
    "        # Sampled noise for input to generator\n",
    "        z_gen = Input(shape=(100,))\n",
    "        # Generate images based of noise\n",
    "        img = self.generator(z_gen)\n",
    "        # Discriminator determines validity\n",
    "        valid = self.critic(img)\n",
    "        # Defines generator model\n",
    "        self.generator_model = Model(z_gen, valid)\n",
    "        self.generator_model.compile(loss=self.wasserstein_loss, optimizer=optimizer)\n",
    "\n",
    "\n",
    "    def gradient_penalty_loss(self, y_true, y_pred, averaged_samples):\n",
    "        \"\"\"\n",
    "        Computes gradient penalty based on prediction and weighted real / fake samples\n",
    "        \"\"\"\n",
    "        gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "        # compute the euclidean norm by squaring ...\n",
    "        gradients_sqr = K.square(gradients)\n",
    "        #   ... summing over the rows ...\n",
    "        gradients_sqr_sum = K.sum(gradients_sqr,\n",
    "                                  axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "        #   ... and sqrt\n",
    "        gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "        # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
    "        gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "        # return the mean as loss over all the batch samples\n",
    "        return K.mean(gradient_penalty)\n",
    "\n",
    "\n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((7, 7, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=4, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=4, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=4, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_critic(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(16, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (X_test, _) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        # Rescale -1 to 1\n",
    "        X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "        # X_test = X_test / 127.5 - 1.\n",
    "        X_test = np.expand_dims(X_test, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = -np.ones((batch_size, 1))\n",
    "        fake =  np.ones((batch_size, 1))\n",
    "        dummy = np.zeros((batch_size, 1)) # Dummy gt for gradient penalty\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for index in range(nb_batches):\n",
    "                for _ in range(self.n_critic):\n",
    "                    global_step += 1\n",
    "                    imgs = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                    # Sample generator input\n",
    "                    noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "                    # Train the critic\n",
    "                    d_loss = self.critic_model.train_on_batch([imgs, noise],\n",
    "                                                              [valid, fake, dummy])\n",
    "\n",
    "                    # ---------------------\n",
    "                    #  Train Generator\n",
    "                    # ---------------------\n",
    "\n",
    "                g_loss = self.generator_model.train_on_batch(noise, valid)\n",
    "\n",
    "                # Plot the progress\n",
    "                print(\"epoch%d step%d [D loss: %f] [G loss: %f]\" % (epoch,global_step, d_loss[0], g_loss))\n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                sampleSize = 5000\n",
    "                # If at save interval => save generated image samples\n",
    "                if global_step % sample_interval == 0:\n",
    "                    s = self.metrics(global_step, X_test, sampleSize)\n",
    "                    if global_step>29000:\n",
    "                        break\n",
    "        for i in range(len(s)):\n",
    "            self.y[i] = [float(j) / max(self.y[i]) for j in self.y[i]]#\n",
    "\n",
    "        for i in range(len(s)):\n",
    "            font1={'size':8}\n",
    "\n",
    "            plt.plot(self.x, self.y[i], label=labels_name[i])\n",
    "            plt.legend(loc='lower right',prop=font1)\n",
    "            plt.savefig('saved_models_acgan/{}.png'.format(labels_name[i]))\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "    def metrics(self, epoch, X_test, sampleSize):\n",
    "        self.x.append(epoch)\n",
    "        r, c = 10, sampleSize // 10\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "#         sampled_labels = np.array([num for _ in range(r) for num in range(c)])\n",
    "        gen_imgs = self.generator.predict([noise])\n",
    "        x_dataset = MyDataset(X_test[:sampleSize])\n",
    "        # print(x_dataset[0].shape)\n",
    "        x_real_loader = Data.DataLoader(dataset=x_dataset, batch_size=sampleSize, shuffle=True)\n",
    "        x_fake_dataset = MyDataset(gen_imgs)\n",
    "        x_fake_loader = Data.DataLoader(dataset=x_fake_dataset, batch_size=sampleSize, shuffle=True)\n",
    "        s = compute_score_raw(x_real_loader, x_fake_loader, 256, '/real/', './fake', conv_model='tfgan',\n",
    "                              workers=int(1))\n",
    "        real_images = tf.convert_to_tensor(X_test)  # real images\n",
    "        # MNIST_CLASSIFIER_FROZEN_GRAPH = '.\\classify_mnist_graph_def.pb'\n",
    "        gen_imgs = np.array(gen_imgs)\n",
    "        eval_images = tf.convert_to_tensor(gen_imgs)\n",
    "        eval_score = utils.mnist_score(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH)  # IS score\n",
    "        frechet_distance = utils.mnist_frechet_distance(real_images, eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH)\n",
    "        mnist_score, f_distance = sess.run([eval_score, frechet_distance])\n",
    "        # print(mnist_score)\n",
    "        # print(f_distance)\n",
    "        # s[14]=mnist_score\n",
    "        # s[16]=f_distance\n",
    "        s[17] = mnist_score\n",
    "        s[18] = f_distance\n",
    "        print('IS socre: %f' % mnist_score)\n",
    "        print('FID: %f' % f_distance)\n",
    "\n",
    "        for i in range(len(s)):\n",
    "            print(i, \"=\", s[i])\n",
    "        for i in range(len(s)):\n",
    "            self.y[i].append(s[i])\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('epoch:' + str(epoch))\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('%.8f' % (i) for i in s)\n",
    "        f.writelines('\\n')\n",
    "        return s\n",
    "if __name__ == '__main__':\n",
    "    wgan = WGANGP()\n",
    "    wgan.train(epochs=4, batch_size=32, sample_interval=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
