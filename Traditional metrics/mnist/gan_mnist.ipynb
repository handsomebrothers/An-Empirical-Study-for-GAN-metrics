{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#-*-coding:utf-8-*-\n",
    "from __future__ import print_function, division\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "import util\n",
    "import utils\n",
    "import tensorflow.contrib.gan as tfgan\n",
    "num_images_to_eval = 500\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, imgs, transform=None):\n",
    "        # super().__init__()\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.imgs[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = torch.from_numpy(img)\n",
    "        return img\n",
    "\n",
    "\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import ot\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.models as models\n",
    "\n",
    "from scipy import linalg\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def giveName(iter):  # 7 digit name.\n",
    "    ans = str(iter)\n",
    "    return ans.zfill(7)\n",
    "\n",
    "def make_dataset(dataset, dataroot, imageSize):\n",
    "    \"\"\"\n",
    "    :param dataset: must be in 'cifar10 | lsun | imagenet | folder | lfw | fake'\n",
    "    :return: pytorch dataset for DataLoader to utilize\n",
    "    \"\"\"\n",
    "    if dataset in ['imagenet', 'folder', 'lfw']:\n",
    "        print(os.getcwd() + dataroot)  # 函数的作用是用于返回当前工作目录\n",
    "        # folder dataset\n",
    "        # dataset = dset.ImageFolder(root=dataroot,\n",
    "        dataset = dset.ImageFolder(root=os.getcwd() + dataroot,\n",
    "                                   transform=transforms.Compose([\n",
    "                                       transforms.Resize(imageSize),\n",
    "                                       # transforms.CenterCrop(imageSize),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(\n",
    "                                           (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                   ]))\n",
    "    elif dataset == 'lsun':\n",
    "        dataset = dset.LSUN(db_path=dataroot, classes=['bedroom_train'],\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.Resize(imageSize),\n",
    "                                transforms.CenterCrop(imageSize),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(\n",
    "                                    (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                            ]))\n",
    "    elif dataset == 'cifar10':\n",
    "        dataset = dset.CIFAR10(root=dataroot, download=True,\n",
    "                               transform=transforms.Compose([\n",
    "                                   transforms.Resize(imageSize),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize(\n",
    "                                       (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                               ]))\n",
    "    elif dataset == 'celeba':\n",
    "        dataset = dset.ImageFolder(root=dataroot,\n",
    "                                   transform=transforms.Compose([\n",
    "                                       transforms.CenterCrop(138),\n",
    "                                       transforms.Resize(imageSize),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(\n",
    "                                           (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                   ]))\n",
    "    else:\n",
    "        raise Exception('--dataset must be in cifar10 | lsun | imagenet | folder | lfw | fake')\n",
    "    assert dataset\n",
    "    return dataset\n",
    "\n",
    "MNIST_CLASSIFIER_FROZEN_GRAPH = './classify_mnist_graph_def.pb'\n",
    "INPUT_TENSOR = 'inputs:0'\n",
    "OUTPUT_TENSOR = 'logits:0'\n",
    "# CONV_TENSOR = 'fc3/Relu:0'\n",
    "CONV_TENSOR = 'fc4/BiasAdd:0'\n",
    "class ConvNetFeatureSaver(object):\n",
    "    def __init__(self, model='cnn', workers=4, batchSize=64):\n",
    "        '''\n",
    "        model: inception_v3, vgg13, vgg16, vgg19, resnet18, resnet34,\n",
    "               resnet50, resnet101, or resnet152\n",
    "        '''\n",
    "        self.model = model\n",
    "        self.batch_size = batchSize\n",
    "        self.workers = workers\n",
    "        if self.model.find('tfgan') >= 0:\n",
    "            print('tfgan')\n",
    "\n",
    "        elif self.model.find('vgg') >= 0:\n",
    "            self.vgg = getattr(models, model)(pretrained=True).cuda().eval()\n",
    "            self.trans = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                                     (0.229, 0.224, 0.225)),\n",
    "            ])\n",
    "        elif self.model.find('resnet') >= 0:\n",
    "            resnet = getattr(models, model)(pretrained=True)\n",
    "            resnet.cuda().eval()\n",
    "            resnet_feature = nn.Sequential(resnet.conv1, resnet.bn1,\n",
    "                                           resnet.relu,\n",
    "                                           resnet.maxpool, resnet.layer1,\n",
    "                                           resnet.layer2, resnet.layer3,\n",
    "                                           resnet.layer4).cuda().eval()\n",
    "            self.resnet = resnet\n",
    "            self.resnet_feature = resnet_feature\n",
    "            self.trans = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                                     (0.229, 0.224, 0.225)),\n",
    "            ])\n",
    "        elif self.model == 'inception' or self.model == 'inception_v3':\n",
    "            inception = models.inception_v3(\n",
    "                pretrained=True, transform_input=False).cuda().eval()\n",
    "            inception_feature = nn.Sequential(inception.Conv2d_1a_3x3,\n",
    "                                              inception.Conv2d_2a_3x3,\n",
    "                                              inception.Conv2d_2b_3x3,\n",
    "                                              nn.MaxPool2d(3, 2),\n",
    "                                              inception.Conv2d_3b_1x1,\n",
    "                                              inception.Conv2d_4a_3x3,\n",
    "                                              nn.MaxPool2d(3, 2),\n",
    "                                              inception.Mixed_5b,\n",
    "                                              inception.Mixed_5c,\n",
    "                                              inception.Mixed_5d,\n",
    "                                              inception.Mixed_6a,\n",
    "                                              inception.Mixed_6b,\n",
    "                                              inception.Mixed_6c,\n",
    "                                              inception.Mixed_6d,\n",
    "                                              inception.Mixed_7a,\n",
    "                                              inception.Mixed_7b,\n",
    "                                              inception.Mixed_7c,\n",
    "                                              ).cuda().eval()\n",
    "            self.inception = inception\n",
    "            self.inception_feature = inception_feature\n",
    "            self.trans = transforms.Compose([\n",
    "                transforms.Resize(299),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ])\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def save(self, imgFolder, dataloader, save2disk=False):\n",
    "        feature_pixl, feature_conv, feature_smax, feature_logit = [], [], [], []\n",
    "\n",
    "        for img in dataloader:\n",
    "            with torch.no_grad():\n",
    "                input = img.cuda()\n",
    "                if self.model == 'tfgan':\n",
    "                    gen_imgs = np.array(img)\n",
    "                    eval_images = tf.convert_to_tensor(gen_imgs)\n",
    "                    flogit = util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, OUTPUT_TENSOR)\n",
    "                    fconv = util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, CONV_TENSOR)\n",
    "                    flogit,fconv=tf.Session().run([flogit,fconv])\n",
    "\n",
    "                    flogit=torch.from_numpy(flogit)\n",
    "                    fconv=torch.from_numpy(fconv)\n",
    "                elif self.model == 'vgg' or self.model == 'vgg16':\n",
    "                    print(self.vgg.features(input).shape)\n",
    "                    fconv = self.vgg.features(input).view(input.size(0), -1)  # 相当于reshape\n",
    "                    flogit = self.vgg.classifier(fconv)\n",
    "                    # flogit = self.vgg.logitifier(fconv)\n",
    "                elif self.model.find('resnet') >= 0:\n",
    "                    fconv = self.resnet_feature(\n",
    "                        input).mean(3).mean(2).squeeze()\n",
    "                    flogit = self.resnet.fc(fconv)\n",
    "                elif self.model == 'inception' or self.model == 'inception_v3':\n",
    "                    fconv = self.inception_feature(\n",
    "                        input).mean(3).mean(2).squeeze()\n",
    "                    flogit = self.inception.fc(fconv)\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "                fsmax = F.softmax(flogit)\n",
    "                '''\n",
    "                总共有四个空间：1.feature_pixl 2.feature_conv 3.feature_logit 4.feature_smax\n",
    "                '''\n",
    "                feature_pixl.append(img)\n",
    "                feature_conv.append(fconv.data.cpu())\n",
    "                feature_logit.append(flogit.data.cpu())\n",
    "                feature_smax.append(fsmax.data.cpu())\n",
    "\n",
    "        feature_pixl = torch.cat(feature_pixl, 0).to('cpu')\n",
    "        feature_conv = torch.cat(feature_conv, 0).to('cpu')\n",
    "        feature_logit = torch.cat(feature_logit, 0).to('cpu')\n",
    "        feature_smax = torch.cat(feature_smax, 0).to('cpu')\n",
    "\n",
    "        return feature_pixl, feature_conv, feature_logit, feature_smax\n",
    "\n",
    "    # return feature_pixl, feature_conv, feature_logit, feature_smax\n",
    "\n",
    "\n",
    "def distance(X, Y, sqrt):\n",
    "    nX = X.size(0)\n",
    "    nY = Y.size(0)\n",
    "    X = X.view(nX, -1)\n",
    "    X2 = (X * X).sum(1).resize_(nX, 1)\n",
    "    Y = Y.view(nY, -1)\n",
    "    Y2 = (Y * Y).sum(1).resize_(nY, 1)\n",
    "\n",
    "    M = torch.zeros(nX, nY)\n",
    "    M.copy_(X2.expand(nX, nY) + Y2.expand(nY, nX).transpose(0, 1) -\n",
    "            2 * torch.mm(X, Y.transpose(0, 1)))\n",
    "\n",
    "    del X, X2, Y, Y2\n",
    "\n",
    "    if sqrt:\n",
    "        M = ((M + M.abs()) / 2).sqrt()\n",
    "\n",
    "    return M\n",
    "\n",
    "\n",
    "def wasserstein(M, sqrt):\n",
    "    if sqrt:\n",
    "        M = M.abs().sqrt()\n",
    "    emd = ot.emd2([], [], M.numpy())\n",
    "\n",
    "    return emd\n",
    "\n",
    "\n",
    "class Score_knn:\n",
    "    acc = 0\n",
    "    acc_real = 0\n",
    "    acc_fake = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    ft = 0\n",
    "\n",
    "\n",
    "def knn(Mxx, Mxy, Myy, k, sqrt):\n",
    "    n0 = Mxx.size(0)\n",
    "    n1 = Myy.size(0)\n",
    "    label = torch.cat((torch.ones(n0), torch.zeros(n1)))\n",
    "    M = torch.cat((torch.cat((Mxx, Mxy), 1), torch.cat(\n",
    "        (Mxy.transpose(0, 1), Myy), 1)), 0)\n",
    "    if sqrt:\n",
    "        M = M.abs().sqrt()\n",
    "    INFINITY = float('inf')\n",
    "    val, idx = (M + torch.diag(INFINITY * torch.ones(n0 + n1))\n",
    "                ).topk(k, 0, False)\n",
    "\n",
    "    count = torch.zeros(n0 + n1)\n",
    "    for i in range(0, k):\n",
    "        count = count + label.index_select(0, idx[i])\n",
    "    pred = torch.ge(count, (float(k) / 2) * torch.ones(n0 + n1)).float()\n",
    "\n",
    "    s = Score_knn()\n",
    "    s.tp = (pred * label).sum()\n",
    "    s.fp = (pred * (1 - label)).sum()\n",
    "    s.fn = ((1 - pred) * label).sum()\n",
    "    s.tn = ((1 - pred) * (1 - label)).sum()\n",
    "    s.precision = s.tp / (s.tp + s.fp + 1e-10)\n",
    "    s.recall = s.tp / (s.tp + s.fn + 1e-10)\n",
    "    s.acc_t = s.tp / (s.tp + s.fn)\n",
    "    s.acc_f = s.tn / (s.tn + s.fp)\n",
    "    s.acc = torch.eq(label, pred).float().mean()\n",
    "    s.k = k\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "def mmd(Mxx, Mxy, Myy, sigma):\n",
    "    scale = Mxx.mean()\n",
    "    Mxx = torch.exp(-Mxx / (scale * 2 * sigma * sigma))\n",
    "    Mxy = torch.exp(-Mxy / (scale * 2 * sigma * sigma))\n",
    "    Myy = torch.exp(-Myy / (scale * 2 * sigma * sigma))\n",
    "    mmd = math.sqrt(Mxx.mean() + Myy.mean() - 2 * Mxy.mean())\n",
    "\n",
    "    return mmd\n",
    "\n",
    "\n",
    "def entropy_score(X, Y, epsilons):\n",
    "    Mxy = distance(X, Y, False)\n",
    "    scores = []\n",
    "    for epsilon in epsilons:\n",
    "        scores.append(ent(Mxy.t(), epsilon))\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "def ent(M, epsilon):\n",
    "    n0 = M.size(0)\n",
    "    n1 = M.size(1)\n",
    "    neighbors = M.lt(epsilon).float()\n",
    "    sums = neighbors.sum(0).repeat(n0, 1)\n",
    "    sums[sums.eq(0)] = 1\n",
    "    neighbors = neighbors.div(sums)\n",
    "    probs = neighbors.sum(1) / n1\n",
    "    rem = 1 - probs.sum()\n",
    "    if rem < 0:\n",
    "        rem = 0\n",
    "    probs = torch.cat((probs, rem * torch.ones(1)), 0)\n",
    "    e = {}\n",
    "    e['probs'] = probs\n",
    "    probs = probs[probs.gt(0)]\n",
    "    e['ent'] = -probs.mul(probs.log()).sum()\n",
    "\n",
    "    return e\n",
    "\n",
    "\n",
    "eps = 1e-20\n",
    "\n",
    "\n",
    "def inception_score(X):\n",
    "    kl = X * ((X + eps).log() - (X.mean(0) + eps).log().expand_as(X))\n",
    "    score = np.exp(kl.sum(1).mean())\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def mode_score(X, Y):\n",
    "    kl1 = X * ((X + eps).log() - (X.mean(0) + eps).log().expand_as(X))\n",
    "    kl2 = X.mean(0) * ((X.mean(0) + eps).log() - (Y.mean(0) + eps).log())\n",
    "    score = np.exp(kl1.sum(1).mean() - kl2.sum())\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def fid(X, Y):\n",
    "    m = X.mean(0)\n",
    "    m_w = Y.mean(0)\n",
    "    X_np = X.numpy()\n",
    "    Y_np = Y.numpy()\n",
    "\n",
    "    C = np.cov(X_np.transpose())\n",
    "    C_w = np.cov(Y_np.transpose())\n",
    "    C_C_w_sqrt = linalg.sqrtm(C.dot(C_w), True).real\n",
    "\n",
    "    score = m.dot(m) + m_w.dot(m_w) - 2 * m_w.dot(m) + \\\n",
    "            np.trace(C + C_w - 2 * C_C_w_sqrt)\n",
    "    return np.sqrt(score)\n",
    "\n",
    "\n",
    "class Score:\n",
    "    emd = 0\n",
    "    mmd = 0\n",
    "    knn = None\n",
    "\n",
    "\n",
    "def compute_score(real, fake, k=1, sigma=1, sqrt=True):\n",
    "    Mxx = distance(real, real, False)\n",
    "    Mxy = distance(real, fake, False)\n",
    "    Myy = distance(fake, fake, False)\n",
    "\n",
    "    s = Score()\n",
    "    s.emd = wasserstein(Mxy, sqrt)\n",
    "    s.mmd = mmd(Mxx, Mxy, Myy, sigma)\n",
    "    s.knn = knn(Mxx, Mxy, Myy, k, sqrt)\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "'''\n",
    "参数说明：\n",
    "dataset:真实数据集的path\n",
    "imageSize:图片的大小\n",
    "dataroot_real:真实数据所在的path\n",
    "batchSize\n",
    "saveFolder_r:真实数据的保存位置\n",
    "conv_model:卷积模型\n",
    "'''\n",
    "\n",
    "\n",
    "def compute_score_raw(real_dataloader, fake_dataloader, batchSize, saveFolder_r, saveFolder_f, conv_model='resnet34',\n",
    "                      workers=4):\n",
    "    convnet_feature_saver = ConvNetFeatureSaver(model=conv_model,\n",
    "                                                batchSize=batchSize, workers=workers)\n",
    "    print(saveFolder_r)\n",
    "    print(saveFolder_f)\n",
    "    feature_r = convnet_feature_saver.save(saveFolder_r, real_dataloader, False)\n",
    "    feature_f = convnet_feature_saver.save(saveFolder_f, fake_dataloader, False)\n",
    "\n",
    "    # 4 feature spaces and 7 scores + incep + modescore + fid\n",
    "    score = np.zeros(2 * 7 + 5)\n",
    "    for i in range(0, 2):\n",
    "        print('compute score in space: ' + str(i))\n",
    "        Mxx = distance(feature_r[i], feature_r[i], False)\n",
    "        Mxy = distance(feature_r[i], feature_f[i], False)\n",
    "        Myy = distance(feature_f[i], feature_f[i], False)\n",
    "\n",
    "        score[i * 7] = wasserstein(Mxy, True)\n",
    "        score[i * 7 + 1] = mmd(Mxx, Mxy, Myy, 1)\n",
    "        tmp = knn(Mxx, Mxy, Myy, 1, False)\n",
    "        score[(i * 7 + 2):(i * 7 + 7)] = \\\n",
    "            tmp.acc, tmp.acc_t, tmp.acc_f, tmp.precision, tmp.recall\n",
    "\n",
    "\n",
    "    score[14] = inception_score(feature_f[3])\n",
    "    score[15] = mode_score(feature_r[3], feature_f[3])\n",
    "    score[16] = fid(feature_r[3], feature_f[3])\n",
    "\n",
    "    return score\n",
    "labels_name=['w_pixl','mmd_pixl','acc_pixl','acc_t_pixl','acc_f_pixl','acc_precision_pixl','acc_recall_pixl',\n",
    "             'w_conv','mmd_conv','acc_conv','acc_t_conv','acc_f_conv','acc_precision_conv','acc_recall_conv',\n",
    "             'is','mode_score','fid' ,'tf_is','tf_fid']\n",
    "if not os.path.isdir('saved_models_{}'.format('gan')):\n",
    "    os.mkdir('saved_models_{}'.format('gan'))\n",
    "f = open('saved_models_{}/log_collapse1.txt'.format('gan'), mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 533,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 784)               803600    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,493,520\n",
      "Trainable params: 1,489,936\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n",
      "(60000, 28, 28, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:1 [D loss: 0.663298, acc.: 50.78%] [G loss: 0.757927]\n",
      "epoch:0 step:2 [D loss: 0.388150, acc.: 75.78%] [G loss: 0.830100]\n",
      "epoch:0 step:3 [D loss: 0.319754, acc.: 82.03%] [G loss: 0.970625]\n",
      "epoch:0 step:4 [D loss: 0.257659, acc.: 94.53%] [G loss: 1.130331]\n",
      "epoch:0 step:5 [D loss: 0.208820, acc.: 99.22%] [G loss: 1.314896]\n",
      "epoch:0 step:6 [D loss: 0.181514, acc.: 98.44%] [G loss: 1.455617]\n",
      "epoch:0 step:7 [D loss: 0.155705, acc.: 100.00%] [G loss: 1.585458]\n",
      "epoch:0 step:8 [D loss: 0.131330, acc.: 100.00%] [G loss: 1.672815]\n",
      "epoch:0 step:9 [D loss: 0.108730, acc.: 100.00%] [G loss: 1.768958]\n",
      "epoch:0 step:10 [D loss: 0.119974, acc.: 100.00%] [G loss: 1.871513]\n",
      "epoch:0 step:11 [D loss: 0.099573, acc.: 100.00%] [G loss: 1.987071]\n",
      "epoch:0 step:12 [D loss: 0.090734, acc.: 100.00%] [G loss: 2.059163]\n",
      "epoch:0 step:13 [D loss: 0.084835, acc.: 100.00%] [G loss: 2.129321]\n",
      "epoch:0 step:14 [D loss: 0.082055, acc.: 100.00%] [G loss: 2.212976]\n",
      "epoch:0 step:15 [D loss: 0.076771, acc.: 100.00%] [G loss: 2.320686]\n",
      "epoch:0 step:16 [D loss: 0.067285, acc.: 100.00%] [G loss: 2.415643]\n",
      "epoch:0 step:17 [D loss: 0.061688, acc.: 100.00%] [G loss: 2.453359]\n",
      "epoch:0 step:18 [D loss: 0.050090, acc.: 100.00%] [G loss: 2.413810]\n",
      "epoch:0 step:19 [D loss: 0.059550, acc.: 100.00%] [G loss: 2.516603]\n",
      "epoch:0 step:20 [D loss: 0.062002, acc.: 100.00%] [G loss: 2.646755]\n",
      "epoch:0 step:21 [D loss: 0.049396, acc.: 100.00%] [G loss: 2.685097]\n",
      "epoch:0 step:22 [D loss: 0.046416, acc.: 100.00%] [G loss: 2.751763]\n",
      "epoch:0 step:23 [D loss: 0.040558, acc.: 100.00%] [G loss: 2.681274]\n",
      "epoch:0 step:24 [D loss: 0.046986, acc.: 100.00%] [G loss: 2.815876]\n",
      "epoch:0 step:25 [D loss: 0.037599, acc.: 100.00%] [G loss: 2.906085]\n",
      "epoch:0 step:26 [D loss: 0.039870, acc.: 100.00%] [G loss: 2.857863]\n",
      "epoch:0 step:27 [D loss: 0.036908, acc.: 100.00%] [G loss: 2.994503]\n",
      "epoch:0 step:28 [D loss: 0.032670, acc.: 100.00%] [G loss: 3.033017]\n",
      "epoch:0 step:29 [D loss: 0.030907, acc.: 100.00%] [G loss: 3.077055]\n",
      "epoch:0 step:30 [D loss: 0.033055, acc.: 100.00%] [G loss: 3.072052]\n",
      "epoch:0 step:31 [D loss: 0.028849, acc.: 100.00%] [G loss: 3.081824]\n",
      "epoch:0 step:32 [D loss: 0.027929, acc.: 100.00%] [G loss: 3.158452]\n",
      "epoch:0 step:33 [D loss: 0.032635, acc.: 100.00%] [G loss: 3.191853]\n",
      "epoch:0 step:34 [D loss: 0.030010, acc.: 100.00%] [G loss: 3.224974]\n",
      "epoch:0 step:35 [D loss: 0.029184, acc.: 100.00%] [G loss: 3.390463]\n",
      "epoch:0 step:36 [D loss: 0.027137, acc.: 100.00%] [G loss: 3.410371]\n",
      "epoch:0 step:37 [D loss: 0.026405, acc.: 100.00%] [G loss: 3.343509]\n",
      "epoch:0 step:38 [D loss: 0.025143, acc.: 100.00%] [G loss: 3.402687]\n",
      "epoch:0 step:39 [D loss: 0.025162, acc.: 100.00%] [G loss: 3.457425]\n",
      "epoch:0 step:40 [D loss: 0.021401, acc.: 100.00%] [G loss: 3.493966]\n",
      "epoch:0 step:41 [D loss: 0.021283, acc.: 100.00%] [G loss: 3.559669]\n",
      "epoch:0 step:42 [D loss: 0.024750, acc.: 100.00%] [G loss: 3.609065]\n",
      "epoch:0 step:43 [D loss: 0.024457, acc.: 100.00%] [G loss: 3.567586]\n",
      "epoch:0 step:44 [D loss: 0.025761, acc.: 100.00%] [G loss: 3.681414]\n",
      "epoch:0 step:45 [D loss: 0.017739, acc.: 100.00%] [G loss: 3.770698]\n",
      "epoch:0 step:46 [D loss: 0.024457, acc.: 100.00%] [G loss: 3.725573]\n",
      "epoch:0 step:47 [D loss: 0.024216, acc.: 100.00%] [G loss: 3.649229]\n",
      "epoch:0 step:48 [D loss: 0.017828, acc.: 100.00%] [G loss: 3.791943]\n",
      "epoch:0 step:49 [D loss: 0.016474, acc.: 100.00%] [G loss: 3.786683]\n",
      "epoch:0 step:50 [D loss: 0.024700, acc.: 100.00%] [G loss: 3.896195]\n",
      "epoch:0 step:51 [D loss: 0.019064, acc.: 100.00%] [G loss: 3.866987]\n",
      "epoch:0 step:52 [D loss: 0.018084, acc.: 100.00%] [G loss: 3.897117]\n",
      "epoch:0 step:53 [D loss: 0.021442, acc.: 100.00%] [G loss: 3.940216]\n",
      "epoch:0 step:54 [D loss: 0.017562, acc.: 100.00%] [G loss: 4.006507]\n",
      "epoch:0 step:55 [D loss: 0.019473, acc.: 100.00%] [G loss: 3.837002]\n",
      "epoch:0 step:56 [D loss: 0.025767, acc.: 100.00%] [G loss: 4.014453]\n",
      "epoch:0 step:57 [D loss: 0.022085, acc.: 100.00%] [G loss: 3.990615]\n",
      "epoch:0 step:58 [D loss: 0.017752, acc.: 100.00%] [G loss: 4.052448]\n",
      "epoch:0 step:59 [D loss: 0.019620, acc.: 100.00%] [G loss: 3.999958]\n",
      "epoch:0 step:60 [D loss: 0.021278, acc.: 100.00%] [G loss: 4.207562]\n",
      "epoch:0 step:61 [D loss: 0.015542, acc.: 100.00%] [G loss: 4.239906]\n",
      "epoch:0 step:62 [D loss: 0.017026, acc.: 100.00%] [G loss: 4.281753]\n",
      "epoch:0 step:63 [D loss: 0.018860, acc.: 100.00%] [G loss: 4.341619]\n",
      "epoch:0 step:64 [D loss: 0.014719, acc.: 100.00%] [G loss: 4.271983]\n",
      "epoch:0 step:65 [D loss: 0.014625, acc.: 100.00%] [G loss: 4.263393]\n",
      "epoch:0 step:66 [D loss: 0.017629, acc.: 100.00%] [G loss: 4.187339]\n",
      "epoch:0 step:67 [D loss: 0.018574, acc.: 100.00%] [G loss: 4.208749]\n",
      "epoch:0 step:68 [D loss: 0.014507, acc.: 100.00%] [G loss: 4.310176]\n",
      "epoch:0 step:69 [D loss: 0.014666, acc.: 100.00%] [G loss: 4.265500]\n",
      "epoch:0 step:70 [D loss: 0.017646, acc.: 100.00%] [G loss: 4.342703]\n",
      "epoch:0 step:71 [D loss: 0.020606, acc.: 100.00%] [G loss: 4.296985]\n",
      "epoch:0 step:72 [D loss: 0.017359, acc.: 100.00%] [G loss: 4.257119]\n",
      "epoch:0 step:73 [D loss: 0.018826, acc.: 100.00%] [G loss: 4.283046]\n",
      "epoch:0 step:74 [D loss: 0.022926, acc.: 100.00%] [G loss: 4.347145]\n",
      "epoch:0 step:75 [D loss: 0.026721, acc.: 99.22%] [G loss: 4.341865]\n",
      "epoch:0 step:76 [D loss: 0.019299, acc.: 100.00%] [G loss: 4.442859]\n",
      "epoch:0 step:77 [D loss: 0.018954, acc.: 100.00%] [G loss: 4.326499]\n",
      "epoch:0 step:78 [D loss: 0.021404, acc.: 100.00%] [G loss: 4.568412]\n",
      "epoch:0 step:79 [D loss: 0.024272, acc.: 100.00%] [G loss: 4.614066]\n",
      "epoch:0 step:80 [D loss: 0.022827, acc.: 100.00%] [G loss: 4.506213]\n",
      "epoch:0 step:81 [D loss: 0.024466, acc.: 100.00%] [G loss: 4.384681]\n",
      "epoch:0 step:82 [D loss: 0.019467, acc.: 100.00%] [G loss: 4.610594]\n",
      "epoch:0 step:83 [D loss: 0.021610, acc.: 100.00%] [G loss: 4.561902]\n",
      "epoch:0 step:84 [D loss: 0.029205, acc.: 99.22%] [G loss: 4.696170]\n",
      "epoch:0 step:85 [D loss: 0.030749, acc.: 100.00%] [G loss: 4.337449]\n",
      "epoch:0 step:86 [D loss: 0.017973, acc.: 100.00%] [G loss: 4.391630]\n",
      "epoch:0 step:87 [D loss: 0.026049, acc.: 100.00%] [G loss: 4.647143]\n",
      "epoch:0 step:88 [D loss: 0.020487, acc.: 100.00%] [G loss: 4.501904]\n",
      "epoch:0 step:89 [D loss: 0.036954, acc.: 99.22%] [G loss: 4.550389]\n",
      "epoch:0 step:90 [D loss: 0.034484, acc.: 100.00%] [G loss: 4.526815]\n",
      "epoch:0 step:91 [D loss: 0.027583, acc.: 99.22%] [G loss: 4.675566]\n",
      "epoch:0 step:92 [D loss: 0.045269, acc.: 100.00%] [G loss: 5.081522]\n",
      "epoch:0 step:93 [D loss: 0.156483, acc.: 95.31%] [G loss: 3.841756]\n",
      "epoch:0 step:94 [D loss: 0.222300, acc.: 90.62%] [G loss: 4.515527]\n",
      "epoch:0 step:95 [D loss: 0.033942, acc.: 100.00%] [G loss: 5.047190]\n",
      "epoch:0 step:96 [D loss: 0.079455, acc.: 98.44%] [G loss: 3.985038]\n",
      "epoch:0 step:97 [D loss: 0.058643, acc.: 99.22%] [G loss: 4.425202]\n",
      "epoch:0 step:98 [D loss: 0.027822, acc.: 100.00%] [G loss: 4.886070]\n",
      "epoch:0 step:99 [D loss: 0.094162, acc.: 96.88%] [G loss: 4.568993]\n",
      "epoch:0 step:100 [D loss: 0.033795, acc.: 100.00%] [G loss: 4.666113]\n",
      "epoch:0 step:101 [D loss: 0.123233, acc.: 96.09%] [G loss: 4.534829]\n",
      "epoch:0 step:102 [D loss: 0.041998, acc.: 99.22%] [G loss: 4.211938]\n",
      "epoch:0 step:103 [D loss: 0.054462, acc.: 97.66%] [G loss: 3.989514]\n",
      "epoch:0 step:104 [D loss: 0.075127, acc.: 98.44%] [G loss: 4.094099]\n",
      "epoch:0 step:105 [D loss: 0.135974, acc.: 92.97%] [G loss: 4.831979]\n",
      "epoch:0 step:106 [D loss: 0.870533, acc.: 71.88%] [G loss: 3.292081]\n",
      "epoch:0 step:107 [D loss: 0.596312, acc.: 76.56%] [G loss: 2.221975]\n",
      "epoch:0 step:108 [D loss: 0.497361, acc.: 78.91%] [G loss: 2.985726]\n",
      "epoch:0 step:109 [D loss: 0.160998, acc.: 90.62%] [G loss: 3.871953]\n",
      "epoch:0 step:110 [D loss: 0.121513, acc.: 93.75%] [G loss: 4.055199]\n",
      "epoch:0 step:111 [D loss: 0.048809, acc.: 99.22%] [G loss: 4.041615]\n",
      "epoch:0 step:112 [D loss: 0.056037, acc.: 100.00%] [G loss: 4.130967]\n",
      "epoch:0 step:113 [D loss: 0.092273, acc.: 97.66%] [G loss: 3.894383]\n",
      "epoch:0 step:114 [D loss: 0.125594, acc.: 92.97%] [G loss: 3.557341]\n",
      "epoch:0 step:115 [D loss: 0.061410, acc.: 99.22%] [G loss: 3.616421]\n",
      "epoch:0 step:116 [D loss: 0.128864, acc.: 96.88%] [G loss: 3.544672]\n",
      "epoch:0 step:117 [D loss: 0.116736, acc.: 95.31%] [G loss: 3.585782]\n",
      "epoch:0 step:118 [D loss: 0.096884, acc.: 99.22%] [G loss: 3.257441]\n",
      "epoch:0 step:119 [D loss: 0.099724, acc.: 96.88%] [G loss: 3.011620]\n",
      "epoch:0 step:120 [D loss: 0.268366, acc.: 89.06%] [G loss: 2.859908]\n",
      "epoch:0 step:121 [D loss: 0.090702, acc.: 97.66%] [G loss: 3.774656]\n",
      "epoch:0 step:122 [D loss: 0.504064, acc.: 79.69%] [G loss: 2.589821]\n",
      "epoch:0 step:123 [D loss: 0.197059, acc.: 89.06%] [G loss: 3.014870]\n",
      "epoch:0 step:124 [D loss: 0.068495, acc.: 98.44%] [G loss: 3.487971]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:125 [D loss: 0.143434, acc.: 94.53%] [G loss: 3.064080]\n",
      "epoch:0 step:126 [D loss: 0.117529, acc.: 96.09%] [G loss: 3.195534]\n",
      "epoch:0 step:127 [D loss: 0.169024, acc.: 92.97%] [G loss: 3.673248]\n",
      "epoch:0 step:128 [D loss: 0.659523, acc.: 74.22%] [G loss: 2.170269]\n",
      "epoch:0 step:129 [D loss: 0.325656, acc.: 80.47%] [G loss: 2.971516]\n",
      "epoch:0 step:130 [D loss: 0.073177, acc.: 100.00%] [G loss: 3.711769]\n",
      "epoch:0 step:131 [D loss: 0.231556, acc.: 90.62%] [G loss: 3.173753]\n",
      "epoch:0 step:132 [D loss: 0.105474, acc.: 98.44%] [G loss: 3.534911]\n",
      "epoch:0 step:133 [D loss: 0.293424, acc.: 86.72%] [G loss: 2.602341]\n",
      "epoch:0 step:134 [D loss: 0.159712, acc.: 93.75%] [G loss: 3.202981]\n",
      "epoch:0 step:135 [D loss: 0.153330, acc.: 95.31%] [G loss: 3.463265]\n",
      "epoch:0 step:136 [D loss: 0.378796, acc.: 81.25%] [G loss: 2.961875]\n",
      "epoch:0 step:137 [D loss: 0.137794, acc.: 92.97%] [G loss: 3.565311]\n",
      "epoch:0 step:138 [D loss: 0.527048, acc.: 78.91%] [G loss: 2.813664]\n",
      "epoch:0 step:139 [D loss: 0.103123, acc.: 96.09%] [G loss: 3.445244]\n",
      "epoch:0 step:140 [D loss: 0.453031, acc.: 79.69%] [G loss: 2.409004]\n",
      "epoch:0 step:141 [D loss: 0.150469, acc.: 93.75%] [G loss: 3.371261]\n",
      "epoch:0 step:142 [D loss: 0.182937, acc.: 97.66%] [G loss: 3.172792]\n",
      "epoch:0 step:143 [D loss: 0.256318, acc.: 90.62%] [G loss: 3.235705]\n",
      "epoch:0 step:144 [D loss: 0.522029, acc.: 78.12%] [G loss: 1.985209]\n",
      "epoch:0 step:145 [D loss: 0.334250, acc.: 79.69%] [G loss: 3.316738]\n",
      "epoch:0 step:146 [D loss: 0.295871, acc.: 84.38%] [G loss: 2.424638]\n",
      "epoch:0 step:147 [D loss: 0.163823, acc.: 92.97%] [G loss: 2.940511]\n",
      "epoch:0 step:148 [D loss: 0.235715, acc.: 91.41%] [G loss: 3.238939]\n",
      "epoch:0 step:149 [D loss: 0.543985, acc.: 73.44%] [G loss: 2.588308]\n",
      "epoch:0 step:150 [D loss: 0.143982, acc.: 94.53%] [G loss: 3.246299]\n",
      "epoch:0 step:151 [D loss: 0.507792, acc.: 79.69%] [G loss: 2.008941]\n",
      "epoch:0 step:152 [D loss: 0.175174, acc.: 94.53%] [G loss: 2.674833]\n",
      "epoch:0 step:153 [D loss: 0.207395, acc.: 93.75%] [G loss: 3.127274]\n",
      "epoch:0 step:154 [D loss: 0.385165, acc.: 78.12%] [G loss: 2.380513]\n",
      "epoch:0 step:155 [D loss: 0.227509, acc.: 91.41%] [G loss: 3.307666]\n",
      "epoch:0 step:156 [D loss: 0.592285, acc.: 71.88%] [G loss: 2.035625]\n",
      "epoch:0 step:157 [D loss: 0.229370, acc.: 87.50%] [G loss: 2.650979]\n",
      "epoch:0 step:158 [D loss: 0.136501, acc.: 98.44%] [G loss: 3.189991]\n",
      "epoch:0 step:159 [D loss: 0.324396, acc.: 89.84%] [G loss: 2.633102]\n",
      "epoch:0 step:160 [D loss: 0.361388, acc.: 82.03%] [G loss: 2.471873]\n",
      "epoch:0 step:161 [D loss: 0.173832, acc.: 92.19%] [G loss: 3.413292]\n",
      "epoch:0 step:162 [D loss: 0.672844, acc.: 69.53%] [G loss: 1.802370]\n",
      "epoch:0 step:163 [D loss: 0.307655, acc.: 80.47%] [G loss: 2.855795]\n",
      "epoch:0 step:164 [D loss: 0.151731, acc.: 99.22%] [G loss: 3.010625]\n",
      "epoch:0 step:165 [D loss: 0.551010, acc.: 71.88%] [G loss: 2.201992]\n",
      "epoch:0 step:166 [D loss: 0.201342, acc.: 88.28%] [G loss: 3.052577]\n",
      "epoch:0 step:167 [D loss: 0.226486, acc.: 91.41%] [G loss: 2.944400]\n",
      "epoch:0 step:168 [D loss: 0.300833, acc.: 85.94%] [G loss: 2.786152]\n",
      "epoch:0 step:169 [D loss: 0.318474, acc.: 85.16%] [G loss: 2.710212]\n",
      "epoch:0 step:170 [D loss: 0.285028, acc.: 91.41%] [G loss: 2.548190]\n",
      "epoch:0 step:171 [D loss: 0.341803, acc.: 85.94%] [G loss: 2.634095]\n",
      "epoch:0 step:172 [D loss: 0.365593, acc.: 82.81%] [G loss: 2.531626]\n",
      "epoch:0 step:173 [D loss: 0.258372, acc.: 88.28%] [G loss: 2.988041]\n",
      "epoch:0 step:174 [D loss: 0.430882, acc.: 79.69%] [G loss: 2.917649]\n",
      "epoch:0 step:175 [D loss: 0.349639, acc.: 83.59%] [G loss: 2.452430]\n",
      "epoch:0 step:176 [D loss: 0.236446, acc.: 91.41%] [G loss: 3.350816]\n",
      "epoch:0 step:177 [D loss: 0.558473, acc.: 68.75%] [G loss: 2.214714]\n",
      "epoch:0 step:178 [D loss: 0.225352, acc.: 86.72%] [G loss: 3.359932]\n",
      "epoch:0 step:179 [D loss: 0.537705, acc.: 73.44%] [G loss: 2.017503]\n",
      "epoch:0 step:180 [D loss: 0.226177, acc.: 88.28%] [G loss: 2.903035]\n",
      "epoch:0 step:181 [D loss: 0.276314, acc.: 91.41%] [G loss: 2.688271]\n",
      "epoch:0 step:182 [D loss: 0.254225, acc.: 92.19%] [G loss: 2.793538]\n",
      "epoch:0 step:183 [D loss: 0.345464, acc.: 82.03%] [G loss: 2.408173]\n",
      "epoch:0 step:184 [D loss: 0.391011, acc.: 78.12%] [G loss: 2.544953]\n",
      "epoch:0 step:185 [D loss: 0.494756, acc.: 71.09%] [G loss: 2.520212]\n",
      "epoch:0 step:186 [D loss: 0.326240, acc.: 82.03%] [G loss: 2.843789]\n",
      "epoch:0 step:187 [D loss: 0.547440, acc.: 69.53%] [G loss: 2.109035]\n",
      "epoch:0 step:188 [D loss: 0.390167, acc.: 75.78%] [G loss: 2.691037]\n",
      "epoch:0 step:189 [D loss: 0.357800, acc.: 82.81%] [G loss: 2.721697]\n",
      "epoch:0 step:190 [D loss: 0.381311, acc.: 82.81%] [G loss: 2.133443]\n",
      "epoch:0 step:191 [D loss: 0.318511, acc.: 84.38%] [G loss: 2.983356]\n",
      "epoch:0 step:192 [D loss: 0.709067, acc.: 60.94%] [G loss: 1.917542]\n",
      "epoch:0 step:193 [D loss: 0.271954, acc.: 85.16%] [G loss: 3.123349]\n",
      "epoch:0 step:194 [D loss: 0.488306, acc.: 73.44%] [G loss: 2.275493]\n",
      "epoch:0 step:195 [D loss: 0.374568, acc.: 79.69%] [G loss: 2.901067]\n",
      "epoch:0 step:196 [D loss: 0.680171, acc.: 58.59%] [G loss: 1.872125]\n",
      "epoch:0 step:197 [D loss: 0.309204, acc.: 83.59%] [G loss: 3.237726]\n",
      "epoch:0 step:198 [D loss: 0.868596, acc.: 48.44%] [G loss: 1.546922]\n",
      "epoch:0 step:199 [D loss: 0.274351, acc.: 85.16%] [G loss: 2.503945]\n",
      "epoch:0 step:200 [D loss: 0.679328, acc.: 64.84%] [G loss: 1.848315]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "WARNING:tensorflow:From /home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/contrib/gan/python/eval/python/classifier_metrics_impl.py:185: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute score in space: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/ot/lp/__init__.py:211: UserWarning: numItermax reached before optimality. Try to increase numItermax.\n",
      "  check_result(result_code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute score in space: 1\n",
      "IS socre: 1.302011\n",
      "FID: 263.863464\n",
      "0 = 21.41226276111609\n",
      "1 = 0.4219566548762566\n",
      "2 = 1.0\n",
      "3 = 1.0\n",
      "4 = 1.0\n",
      "5 = 1.0\n",
      "6 = 1.0\n",
      "7 = 16.500725511479413\n",
      "8 = 0.255160476453342\n",
      "9 = 0.9991000294685364\n",
      "10 = 0.998199999332428\n",
      "11 = 1.0\n",
      "12 = 1.0\n",
      "13 = 0.998199999332428\n",
      "14 = 1.302011489868164\n",
      "15 = 5.098011016845703\n",
      "16 = 0.8933330178260803\n",
      "17 = 1.3020113706588745\n",
      "18 = 263.86346435546875\n",
      "epoch:0 step:201 [D loss: 0.272414, acc.: 85.94%] [G loss: 2.818226]\n",
      "epoch:0 step:202 [D loss: 0.726587, acc.: 58.59%] [G loss: 1.703037]\n",
      "epoch:0 step:203 [D loss: 0.403784, acc.: 81.25%] [G loss: 2.182783]\n",
      "epoch:0 step:204 [D loss: 0.446375, acc.: 78.91%] [G loss: 2.225812]\n",
      "epoch:0 step:205 [D loss: 0.462482, acc.: 76.56%] [G loss: 2.212677]\n",
      "epoch:0 step:206 [D loss: 0.477684, acc.: 74.22%] [G loss: 2.158021]\n",
      "epoch:0 step:207 [D loss: 0.527662, acc.: 70.31%] [G loss: 1.893764]\n",
      "epoch:0 step:208 [D loss: 0.391501, acc.: 81.25%] [G loss: 2.478865]\n",
      "epoch:0 step:209 [D loss: 0.535971, acc.: 73.44%] [G loss: 1.998896]\n",
      "epoch:0 step:210 [D loss: 0.398580, acc.: 80.47%] [G loss: 2.279556]\n",
      "epoch:0 step:211 [D loss: 0.505131, acc.: 73.44%] [G loss: 2.197849]\n",
      "epoch:0 step:212 [D loss: 0.508785, acc.: 74.22%] [G loss: 2.288686]\n",
      "epoch:0 step:213 [D loss: 0.509237, acc.: 72.66%] [G loss: 2.601772]\n",
      "epoch:0 step:214 [D loss: 0.650114, acc.: 62.50%] [G loss: 1.480743]\n",
      "epoch:0 step:215 [D loss: 0.352415, acc.: 76.56%] [G loss: 2.770012]\n",
      "epoch:0 step:216 [D loss: 0.623346, acc.: 62.50%] [G loss: 1.679994]\n",
      "epoch:0 step:217 [D loss: 0.340811, acc.: 84.38%] [G loss: 2.471945]\n",
      "epoch:0 step:218 [D loss: 0.725235, acc.: 54.69%] [G loss: 1.582633]\n",
      "epoch:0 step:219 [D loss: 0.405736, acc.: 78.91%] [G loss: 2.352791]\n",
      "epoch:0 step:220 [D loss: 1.284450, acc.: 23.44%] [G loss: 0.640836]\n",
      "epoch:0 step:221 [D loss: 0.593941, acc.: 60.16%] [G loss: 1.556653]\n",
      "epoch:0 step:222 [D loss: 0.364591, acc.: 82.03%] [G loss: 2.549430]\n",
      "epoch:0 step:223 [D loss: 0.629951, acc.: 64.06%] [G loss: 1.528547]\n",
      "epoch:0 step:224 [D loss: 0.580963, acc.: 60.94%] [G loss: 1.784383]\n",
      "epoch:0 step:225 [D loss: 0.593252, acc.: 65.62%] [G loss: 1.711742]\n",
      "epoch:0 step:226 [D loss: 0.483672, acc.: 75.78%] [G loss: 1.974756]\n",
      "epoch:0 step:227 [D loss: 0.662689, acc.: 58.59%] [G loss: 1.441743]\n",
      "epoch:0 step:228 [D loss: 0.447517, acc.: 78.91%] [G loss: 2.405034]\n",
      "epoch:0 step:229 [D loss: 0.860927, acc.: 45.31%] [G loss: 1.157575]\n",
      "epoch:0 step:230 [D loss: 0.497264, acc.: 71.09%] [G loss: 1.937321]\n",
      "epoch:0 step:231 [D loss: 0.508935, acc.: 78.12%] [G loss: 1.840286]\n",
      "epoch:0 step:232 [D loss: 0.559204, acc.: 72.66%] [G loss: 1.842050]\n",
      "epoch:0 step:233 [D loss: 0.806228, acc.: 49.22%] [G loss: 1.234686]\n",
      "epoch:0 step:234 [D loss: 0.521008, acc.: 65.62%] [G loss: 1.724452]\n",
      "epoch:0 step:235 [D loss: 0.604387, acc.: 65.62%] [G loss: 1.687165]\n",
      "epoch:0 step:236 [D loss: 0.646966, acc.: 60.16%] [G loss: 1.286578]\n",
      "epoch:0 step:237 [D loss: 0.660460, acc.: 56.25%] [G loss: 1.464267]\n",
      "epoch:0 step:238 [D loss: 0.571354, acc.: 67.19%] [G loss: 1.481322]\n",
      "epoch:0 step:239 [D loss: 0.664629, acc.: 61.72%] [G loss: 1.458007]\n",
      "epoch:0 step:240 [D loss: 0.529685, acc.: 69.53%] [G loss: 1.699430]\n",
      "epoch:0 step:241 [D loss: 0.717005, acc.: 51.56%] [G loss: 1.328071]\n",
      "epoch:0 step:242 [D loss: 0.570096, acc.: 64.84%] [G loss: 1.493830]\n",
      "epoch:0 step:243 [D loss: 0.749706, acc.: 43.75%] [G loss: 1.104618]\n",
      "epoch:0 step:244 [D loss: 0.602402, acc.: 60.16%] [G loss: 1.462694]\n",
      "epoch:0 step:245 [D loss: 0.732179, acc.: 48.44%] [G loss: 1.073530]\n",
      "epoch:0 step:246 [D loss: 0.716586, acc.: 50.78%] [G loss: 1.112612]\n",
      "epoch:0 step:247 [D loss: 0.661690, acc.: 50.00%] [G loss: 1.126225]\n",
      "epoch:0 step:248 [D loss: 0.689595, acc.: 53.91%] [G loss: 1.161674]\n",
      "epoch:0 step:249 [D loss: 0.754550, acc.: 42.19%] [G loss: 0.974782]\n",
      "epoch:0 step:250 [D loss: 0.612291, acc.: 61.72%] [G loss: 1.298256]\n",
      "epoch:0 step:251 [D loss: 0.721311, acc.: 51.56%] [G loss: 1.045629]\n",
      "epoch:0 step:252 [D loss: 0.714751, acc.: 49.22%] [G loss: 1.037488]\n",
      "epoch:0 step:253 [D loss: 0.662358, acc.: 57.03%] [G loss: 1.144885]\n",
      "epoch:0 step:254 [D loss: 0.633694, acc.: 64.06%] [G loss: 1.061254]\n",
      "epoch:0 step:255 [D loss: 0.680285, acc.: 56.25%] [G loss: 1.115236]\n",
      "epoch:0 step:256 [D loss: 0.728253, acc.: 47.66%] [G loss: 1.024276]\n",
      "epoch:0 step:257 [D loss: 0.579432, acc.: 68.75%] [G loss: 1.177191]\n",
      "epoch:0 step:258 [D loss: 0.672315, acc.: 57.81%] [G loss: 1.115668]\n",
      "epoch:0 step:259 [D loss: 0.685603, acc.: 50.00%] [G loss: 1.083742]\n",
      "epoch:0 step:260 [D loss: 0.681241, acc.: 52.34%] [G loss: 0.946611]\n",
      "epoch:0 step:261 [D loss: 0.706290, acc.: 48.44%] [G loss: 0.960892]\n",
      "epoch:0 step:262 [D loss: 0.709117, acc.: 44.53%] [G loss: 0.932201]\n",
      "epoch:0 step:263 [D loss: 0.882910, acc.: 29.69%] [G loss: 0.663911]\n",
      "epoch:0 step:264 [D loss: 0.702648, acc.: 46.88%] [G loss: 0.728027]\n",
      "epoch:0 step:265 [D loss: 0.690231, acc.: 43.75%] [G loss: 0.817443]\n",
      "epoch:0 step:266 [D loss: 0.687271, acc.: 48.44%] [G loss: 0.878838]\n",
      "epoch:0 step:267 [D loss: 0.696081, acc.: 46.09%] [G loss: 0.823750]\n",
      "epoch:0 step:268 [D loss: 0.742514, acc.: 40.62%] [G loss: 0.726354]\n",
      "epoch:0 step:269 [D loss: 0.770897, acc.: 40.62%] [G loss: 0.652993]\n",
      "epoch:0 step:270 [D loss: 0.707236, acc.: 45.31%] [G loss: 0.734534]\n",
      "epoch:0 step:271 [D loss: 0.696691, acc.: 50.00%] [G loss: 0.790321]\n",
      "epoch:0 step:272 [D loss: 0.718716, acc.: 42.97%] [G loss: 0.694006]\n",
      "epoch:0 step:273 [D loss: 0.668178, acc.: 46.88%] [G loss: 0.750161]\n",
      "epoch:0 step:274 [D loss: 0.707474, acc.: 43.75%] [G loss: 0.715851]\n",
      "epoch:0 step:275 [D loss: 0.723941, acc.: 44.53%] [G loss: 0.670722]\n",
      "epoch:0 step:276 [D loss: 0.709208, acc.: 47.66%] [G loss: 0.657485]\n",
      "epoch:0 step:277 [D loss: 0.699649, acc.: 45.31%] [G loss: 0.649903]\n",
      "epoch:0 step:278 [D loss: 0.703034, acc.: 45.31%] [G loss: 0.658219]\n",
      "epoch:0 step:279 [D loss: 0.670627, acc.: 46.09%] [G loss: 0.657916]\n",
      "epoch:0 step:280 [D loss: 0.690267, acc.: 45.31%] [G loss: 0.674994]\n",
      "epoch:0 step:281 [D loss: 0.722775, acc.: 41.41%] [G loss: 0.655668]\n",
      "epoch:0 step:282 [D loss: 0.702729, acc.: 42.97%] [G loss: 0.623879]\n",
      "epoch:0 step:283 [D loss: 0.673953, acc.: 49.22%] [G loss: 0.669741]\n",
      "epoch:0 step:284 [D loss: 0.691841, acc.: 53.12%] [G loss: 0.696932]\n",
      "epoch:0 step:285 [D loss: 0.682768, acc.: 53.12%] [G loss: 0.679905]\n",
      "epoch:0 step:286 [D loss: 0.691291, acc.: 43.75%] [G loss: 0.687768]\n",
      "epoch:0 step:287 [D loss: 0.679553, acc.: 45.31%] [G loss: 0.677567]\n",
      "epoch:0 step:288 [D loss: 0.690143, acc.: 40.62%] [G loss: 0.674653]\n",
      "epoch:0 step:289 [D loss: 0.675987, acc.: 45.31%] [G loss: 0.680543]\n",
      "epoch:0 step:290 [D loss: 0.703946, acc.: 40.62%] [G loss: 0.672089]\n",
      "epoch:0 step:291 [D loss: 0.753608, acc.: 35.16%] [G loss: 0.603232]\n",
      "epoch:0 step:292 [D loss: 0.704135, acc.: 42.97%] [G loss: 0.622777]\n",
      "epoch:0 step:293 [D loss: 0.692733, acc.: 44.53%] [G loss: 0.633474]\n",
      "epoch:0 step:294 [D loss: 0.679193, acc.: 45.31%] [G loss: 0.634456]\n",
      "epoch:0 step:295 [D loss: 0.687195, acc.: 45.31%] [G loss: 0.631786]\n",
      "epoch:0 step:296 [D loss: 0.677354, acc.: 48.44%] [G loss: 0.631590]\n",
      "epoch:0 step:297 [D loss: 0.676563, acc.: 46.88%] [G loss: 0.637000]\n",
      "epoch:0 step:298 [D loss: 0.675774, acc.: 45.31%] [G loss: 0.631659]\n",
      "epoch:0 step:299 [D loss: 0.669780, acc.: 50.00%] [G loss: 0.632025]\n",
      "epoch:0 step:300 [D loss: 0.668961, acc.: 46.88%] [G loss: 0.638605]\n",
      "epoch:0 step:301 [D loss: 0.720330, acc.: 43.75%] [G loss: 0.625616]\n",
      "epoch:0 step:302 [D loss: 0.683490, acc.: 46.09%] [G loss: 0.629513]\n",
      "epoch:0 step:303 [D loss: 0.707903, acc.: 39.84%] [G loss: 0.618137]\n",
      "epoch:0 step:304 [D loss: 0.681760, acc.: 46.09%] [G loss: 0.623785]\n",
      "epoch:0 step:305 [D loss: 0.669808, acc.: 44.53%] [G loss: 0.638778]\n",
      "epoch:0 step:306 [D loss: 0.669666, acc.: 46.88%] [G loss: 0.653464]\n",
      "epoch:0 step:307 [D loss: 0.650703, acc.: 48.44%] [G loss: 0.656267]\n",
      "epoch:0 step:308 [D loss: 0.693230, acc.: 46.09%] [G loss: 0.652196]\n",
      "epoch:0 step:309 [D loss: 0.671113, acc.: 43.75%] [G loss: 0.667089]\n",
      "epoch:0 step:310 [D loss: 0.677370, acc.: 42.97%] [G loss: 0.659796]\n",
      "epoch:0 step:311 [D loss: 0.673769, acc.: 46.88%] [G loss: 0.645744]\n",
      "epoch:0 step:312 [D loss: 0.712704, acc.: 42.19%] [G loss: 0.636761]\n",
      "epoch:0 step:313 [D loss: 0.695402, acc.: 45.31%] [G loss: 0.629616]\n",
      "epoch:0 step:314 [D loss: 0.660375, acc.: 49.22%] [G loss: 0.634910]\n",
      "epoch:0 step:315 [D loss: 0.658514, acc.: 49.22%] [G loss: 0.642147]\n",
      "epoch:0 step:316 [D loss: 0.679520, acc.: 47.66%] [G loss: 0.633755]\n",
      "epoch:0 step:317 [D loss: 0.673537, acc.: 46.88%] [G loss: 0.631120]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:318 [D loss: 0.671238, acc.: 50.00%] [G loss: 0.627162]\n",
      "epoch:0 step:319 [D loss: 0.674035, acc.: 47.66%] [G loss: 0.646152]\n",
      "epoch:0 step:320 [D loss: 0.647654, acc.: 48.44%] [G loss: 0.656838]\n",
      "epoch:0 step:321 [D loss: 0.672661, acc.: 46.88%] [G loss: 0.647062]\n",
      "epoch:0 step:322 [D loss: 0.660975, acc.: 50.00%] [G loss: 0.646167]\n",
      "epoch:0 step:323 [D loss: 0.646449, acc.: 50.00%] [G loss: 0.658999]\n",
      "epoch:0 step:324 [D loss: 0.650817, acc.: 53.12%] [G loss: 0.680866]\n",
      "epoch:0 step:325 [D loss: 0.649585, acc.: 50.78%] [G loss: 0.692420]\n",
      "epoch:0 step:326 [D loss: 0.652832, acc.: 46.88%] [G loss: 0.677533]\n",
      "epoch:0 step:327 [D loss: 0.639245, acc.: 50.78%] [G loss: 0.666542]\n",
      "epoch:0 step:328 [D loss: 0.653127, acc.: 53.91%] [G loss: 0.666523]\n",
      "epoch:0 step:329 [D loss: 0.644041, acc.: 54.69%] [G loss: 0.664031]\n",
      "epoch:0 step:330 [D loss: 0.655432, acc.: 54.69%] [G loss: 0.663051]\n",
      "epoch:0 step:331 [D loss: 0.644052, acc.: 54.69%] [G loss: 0.666553]\n",
      "epoch:0 step:332 [D loss: 0.657435, acc.: 50.00%] [G loss: 0.666629]\n",
      "epoch:0 step:333 [D loss: 0.653456, acc.: 51.56%] [G loss: 0.660067]\n",
      "epoch:0 step:334 [D loss: 0.661025, acc.: 50.00%] [G loss: 0.663916]\n",
      "epoch:0 step:335 [D loss: 0.642545, acc.: 50.78%] [G loss: 0.686551]\n",
      "epoch:0 step:336 [D loss: 0.637134, acc.: 50.00%] [G loss: 0.692330]\n",
      "epoch:0 step:337 [D loss: 0.621476, acc.: 52.34%] [G loss: 0.690950]\n",
      "epoch:0 step:338 [D loss: 0.642162, acc.: 47.66%] [G loss: 0.676657]\n",
      "epoch:0 step:339 [D loss: 0.651423, acc.: 50.00%] [G loss: 0.663975]\n",
      "epoch:0 step:340 [D loss: 0.655429, acc.: 52.34%] [G loss: 0.686120]\n",
      "epoch:0 step:341 [D loss: 0.660203, acc.: 49.22%] [G loss: 0.709002]\n",
      "epoch:0 step:342 [D loss: 0.640796, acc.: 50.78%] [G loss: 0.731017]\n",
      "epoch:0 step:343 [D loss: 0.643147, acc.: 53.91%] [G loss: 0.742837]\n",
      "epoch:0 step:344 [D loss: 0.646622, acc.: 57.03%] [G loss: 0.751896]\n",
      "epoch:0 step:345 [D loss: 0.710981, acc.: 39.84%] [G loss: 0.703516]\n",
      "epoch:0 step:346 [D loss: 0.692148, acc.: 43.75%] [G loss: 0.673321]\n",
      "epoch:0 step:347 [D loss: 0.683003, acc.: 50.00%] [G loss: 0.685562]\n",
      "epoch:0 step:348 [D loss: 0.683251, acc.: 46.09%] [G loss: 0.669156]\n",
      "epoch:0 step:349 [D loss: 0.701019, acc.: 46.09%] [G loss: 0.655207]\n",
      "epoch:0 step:350 [D loss: 0.671452, acc.: 47.66%] [G loss: 0.678244]\n",
      "epoch:0 step:351 [D loss: 0.666175, acc.: 54.69%] [G loss: 0.689231]\n",
      "epoch:0 step:352 [D loss: 0.670286, acc.: 55.47%] [G loss: 0.687103]\n",
      "epoch:0 step:353 [D loss: 0.649049, acc.: 56.25%] [G loss: 0.688721]\n",
      "epoch:0 step:354 [D loss: 0.664891, acc.: 61.72%] [G loss: 0.697275]\n",
      "epoch:0 step:355 [D loss: 0.639270, acc.: 59.38%] [G loss: 0.719192]\n",
      "epoch:0 step:356 [D loss: 0.652833, acc.: 53.12%] [G loss: 0.712911]\n",
      "epoch:0 step:357 [D loss: 0.658008, acc.: 54.69%] [G loss: 0.716429]\n",
      "epoch:0 step:358 [D loss: 0.646789, acc.: 55.47%] [G loss: 0.702353]\n",
      "epoch:0 step:359 [D loss: 0.654605, acc.: 54.69%] [G loss: 0.703671]\n",
      "epoch:0 step:360 [D loss: 0.657022, acc.: 53.91%] [G loss: 0.693970]\n",
      "epoch:0 step:361 [D loss: 0.640589, acc.: 52.34%] [G loss: 0.692037]\n",
      "epoch:0 step:362 [D loss: 0.657014, acc.: 49.22%] [G loss: 0.689633]\n",
      "epoch:0 step:363 [D loss: 0.638333, acc.: 52.34%] [G loss: 0.690617]\n",
      "epoch:0 step:364 [D loss: 0.637923, acc.: 56.25%] [G loss: 0.694079]\n",
      "epoch:0 step:365 [D loss: 0.660376, acc.: 52.34%] [G loss: 0.705814]\n",
      "epoch:0 step:366 [D loss: 0.652436, acc.: 47.66%] [G loss: 0.692472]\n",
      "epoch:0 step:367 [D loss: 0.642316, acc.: 50.00%] [G loss: 0.685816]\n",
      "epoch:0 step:368 [D loss: 0.672434, acc.: 50.00%] [G loss: 0.691268]\n",
      "epoch:0 step:369 [D loss: 0.670206, acc.: 50.00%] [G loss: 0.691406]\n",
      "epoch:0 step:370 [D loss: 0.667954, acc.: 46.88%] [G loss: 0.679176]\n",
      "epoch:0 step:371 [D loss: 0.664343, acc.: 48.44%] [G loss: 0.678216]\n",
      "epoch:0 step:372 [D loss: 0.658639, acc.: 53.12%] [G loss: 0.689594]\n",
      "epoch:0 step:373 [D loss: 0.660126, acc.: 52.34%] [G loss: 0.686264]\n",
      "epoch:0 step:374 [D loss: 0.660092, acc.: 52.34%] [G loss: 0.695183]\n",
      "epoch:0 step:375 [D loss: 0.637955, acc.: 51.56%] [G loss: 0.708541]\n",
      "epoch:0 step:376 [D loss: 0.644825, acc.: 50.78%] [G loss: 0.717461]\n",
      "epoch:0 step:377 [D loss: 0.646061, acc.: 49.22%] [G loss: 0.709970]\n",
      "epoch:0 step:378 [D loss: 0.632574, acc.: 50.00%] [G loss: 0.721895]\n",
      "epoch:0 step:379 [D loss: 0.655455, acc.: 52.34%] [G loss: 0.720816]\n",
      "epoch:0 step:380 [D loss: 0.668684, acc.: 48.44%] [G loss: 0.704504]\n",
      "epoch:0 step:381 [D loss: 0.668114, acc.: 46.88%] [G loss: 0.689243]\n",
      "epoch:0 step:382 [D loss: 0.672501, acc.: 43.75%] [G loss: 0.686841]\n",
      "epoch:0 step:383 [D loss: 0.652786, acc.: 50.00%] [G loss: 0.687364]\n",
      "epoch:0 step:384 [D loss: 0.656288, acc.: 48.44%] [G loss: 0.693099]\n",
      "epoch:0 step:385 [D loss: 0.654730, acc.: 50.78%] [G loss: 0.694821]\n",
      "epoch:0 step:386 [D loss: 0.637350, acc.: 53.12%] [G loss: 0.696842]\n",
      "epoch:0 step:387 [D loss: 0.641048, acc.: 53.12%] [G loss: 0.718723]\n",
      "epoch:0 step:388 [D loss: 0.650059, acc.: 48.44%] [G loss: 0.724332]\n",
      "epoch:0 step:389 [D loss: 0.646679, acc.: 49.22%] [G loss: 0.708183]\n",
      "epoch:0 step:390 [D loss: 0.643017, acc.: 48.44%] [G loss: 0.710711]\n",
      "epoch:0 step:391 [D loss: 0.641570, acc.: 50.78%] [G loss: 0.714941]\n",
      "epoch:0 step:392 [D loss: 0.633291, acc.: 50.00%] [G loss: 0.711266]\n",
      "epoch:0 step:393 [D loss: 0.664496, acc.: 44.53%] [G loss: 0.700507]\n",
      "epoch:0 step:394 [D loss: 0.655698, acc.: 47.66%] [G loss: 0.678594]\n",
      "epoch:0 step:395 [D loss: 0.638856, acc.: 51.56%] [G loss: 0.677576]\n",
      "epoch:0 step:396 [D loss: 0.659692, acc.: 42.97%] [G loss: 0.687389]\n",
      "epoch:0 step:397 [D loss: 0.635378, acc.: 53.12%] [G loss: 0.705305]\n",
      "epoch:0 step:398 [D loss: 0.619432, acc.: 55.47%] [G loss: 0.718118]\n",
      "epoch:0 step:399 [D loss: 0.615590, acc.: 59.38%] [G loss: 0.712413]\n",
      "epoch:0 step:400 [D loss: 0.644225, acc.: 50.78%] [G loss: 0.722393]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 1.700739\n",
      "FID: 245.191986\n",
      "0 = 16.417780749893172\n",
      "1 = 0.26724244383789814\n",
      "2 = 0.9998999834060669\n",
      "3 = 0.9998000264167786\n",
      "4 = 1.0\n",
      "5 = 1.0\n",
      "6 = 0.9998000264167786\n",
      "7 = 16.09746634671691\n",
      "8 = 0.254734039735085\n",
      "9 = 0.9980999827384949\n",
      "10 = 0.9962000250816345\n",
      "11 = 1.0\n",
      "12 = 1.0\n",
      "13 = 0.9962000250816345\n",
      "14 = 1.700740098953247\n",
      "15 = 5.930663585662842\n",
      "16 = 0.7368293404579163\n",
      "17 = 1.700738787651062\n",
      "18 = 245.19198608398438\n",
      "epoch:0 step:401 [D loss: 0.619529, acc.: 51.56%] [G loss: 0.722723]\n",
      "epoch:0 step:402 [D loss: 0.634328, acc.: 54.69%] [G loss: 0.723742]\n",
      "epoch:0 step:403 [D loss: 0.641577, acc.: 56.25%] [G loss: 0.707639]\n",
      "epoch:0 step:404 [D loss: 0.649211, acc.: 51.56%] [G loss: 0.684039]\n",
      "epoch:0 step:405 [D loss: 0.618463, acc.: 52.34%] [G loss: 0.700124]\n",
      "epoch:0 step:406 [D loss: 0.634740, acc.: 50.00%] [G loss: 0.699473]\n",
      "epoch:0 step:407 [D loss: 0.643261, acc.: 53.91%] [G loss: 0.700888]\n",
      "epoch:0 step:408 [D loss: 0.630816, acc.: 51.56%] [G loss: 0.714741]\n",
      "epoch:0 step:409 [D loss: 0.631244, acc.: 57.03%] [G loss: 0.711300]\n",
      "epoch:0 step:410 [D loss: 0.635812, acc.: 55.47%] [G loss: 0.702811]\n",
      "epoch:0 step:411 [D loss: 0.664111, acc.: 50.78%] [G loss: 0.697018]\n",
      "epoch:0 step:412 [D loss: 0.651638, acc.: 51.56%] [G loss: 0.696850]\n",
      "epoch:0 step:413 [D loss: 0.658376, acc.: 52.34%] [G loss: 0.698701]\n",
      "epoch:0 step:414 [D loss: 0.648133, acc.: 50.78%] [G loss: 0.709268]\n",
      "epoch:0 step:415 [D loss: 0.647116, acc.: 53.12%] [G loss: 0.704751]\n",
      "epoch:0 step:416 [D loss: 0.653916, acc.: 62.50%] [G loss: 0.698004]\n",
      "epoch:0 step:417 [D loss: 0.667924, acc.: 53.91%] [G loss: 0.701010]\n",
      "epoch:0 step:418 [D loss: 0.661851, acc.: 52.34%] [G loss: 0.705176]\n",
      "epoch:0 step:419 [D loss: 0.650640, acc.: 50.00%] [G loss: 0.709401]\n",
      "epoch:0 step:420 [D loss: 0.655048, acc.: 49.22%] [G loss: 0.710778]\n",
      "epoch:0 step:421 [D loss: 0.672397, acc.: 46.88%] [G loss: 0.713992]\n",
      "epoch:0 step:422 [D loss: 0.674744, acc.: 46.88%] [G loss: 0.703904]\n",
      "epoch:0 step:423 [D loss: 0.659108, acc.: 46.88%] [G loss: 0.702444]\n",
      "epoch:0 step:424 [D loss: 0.664933, acc.: 48.44%] [G loss: 0.703431]\n",
      "epoch:0 step:425 [D loss: 0.656238, acc.: 48.44%] [G loss: 0.698847]\n",
      "epoch:0 step:426 [D loss: 0.655643, acc.: 52.34%] [G loss: 0.718753]\n",
      "epoch:0 step:427 [D loss: 0.649852, acc.: 50.78%] [G loss: 0.730866]\n",
      "epoch:0 step:428 [D loss: 0.654955, acc.: 47.66%] [G loss: 0.728348]\n",
      "epoch:0 step:429 [D loss: 0.639090, acc.: 60.94%] [G loss: 0.751171]\n",
      "epoch:0 step:430 [D loss: 0.655235, acc.: 56.25%] [G loss: 0.747075]\n",
      "epoch:0 step:431 [D loss: 0.664424, acc.: 48.44%] [G loss: 0.714892]\n",
      "epoch:0 step:432 [D loss: 0.679024, acc.: 47.66%] [G loss: 0.699776]\n",
      "epoch:0 step:433 [D loss: 0.656723, acc.: 50.78%] [G loss: 0.697096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:434 [D loss: 0.659867, acc.: 53.12%] [G loss: 0.697423]\n",
      "epoch:0 step:435 [D loss: 0.660482, acc.: 52.34%] [G loss: 0.707403]\n",
      "epoch:0 step:436 [D loss: 0.661601, acc.: 48.44%] [G loss: 0.705628]\n",
      "epoch:0 step:437 [D loss: 0.689524, acc.: 46.88%] [G loss: 0.706447]\n",
      "epoch:0 step:438 [D loss: 0.656607, acc.: 50.78%] [G loss: 0.717181]\n",
      "epoch:0 step:439 [D loss: 0.647013, acc.: 53.91%] [G loss: 0.715251]\n",
      "epoch:0 step:440 [D loss: 0.641045, acc.: 56.25%] [G loss: 0.727183]\n",
      "epoch:0 step:441 [D loss: 0.654597, acc.: 50.78%] [G loss: 0.726339]\n",
      "epoch:0 step:442 [D loss: 0.662469, acc.: 49.22%] [G loss: 0.712942]\n",
      "epoch:0 step:443 [D loss: 0.672845, acc.: 47.66%] [G loss: 0.693441]\n",
      "epoch:0 step:444 [D loss: 0.660094, acc.: 47.66%] [G loss: 0.688771]\n",
      "epoch:0 step:445 [D loss: 0.668373, acc.: 50.78%] [G loss: 0.694006]\n",
      "epoch:0 step:446 [D loss: 0.667790, acc.: 48.44%] [G loss: 0.701360]\n",
      "epoch:0 step:447 [D loss: 0.644369, acc.: 56.25%] [G loss: 0.700259]\n",
      "epoch:0 step:448 [D loss: 0.677522, acc.: 47.66%] [G loss: 0.689813]\n",
      "epoch:0 step:449 [D loss: 0.673755, acc.: 52.34%] [G loss: 0.685061]\n",
      "epoch:0 step:450 [D loss: 0.654183, acc.: 51.56%] [G loss: 0.706429]\n",
      "epoch:0 step:451 [D loss: 0.652055, acc.: 51.56%] [G loss: 0.716610]\n",
      "epoch:0 step:452 [D loss: 0.669254, acc.: 51.56%] [G loss: 0.732825]\n",
      "epoch:0 step:453 [D loss: 0.656944, acc.: 50.00%] [G loss: 0.744016]\n",
      "epoch:0 step:454 [D loss: 0.659992, acc.: 52.34%] [G loss: 0.747680]\n",
      "epoch:0 step:455 [D loss: 0.658123, acc.: 54.69%] [G loss: 0.725014]\n",
      "epoch:0 step:456 [D loss: 0.645054, acc.: 57.03%] [G loss: 0.710181]\n",
      "epoch:0 step:457 [D loss: 0.647905, acc.: 53.12%] [G loss: 0.704608]\n",
      "epoch:0 step:458 [D loss: 0.653189, acc.: 52.34%] [G loss: 0.712659]\n",
      "epoch:0 step:459 [D loss: 0.645700, acc.: 53.91%] [G loss: 0.725835]\n",
      "epoch:0 step:460 [D loss: 0.632035, acc.: 49.22%] [G loss: 0.728387]\n",
      "epoch:0 step:461 [D loss: 0.626650, acc.: 64.06%] [G loss: 0.715895]\n",
      "epoch:0 step:462 [D loss: 0.655915, acc.: 60.94%] [G loss: 0.702088]\n",
      "epoch:0 step:463 [D loss: 0.651508, acc.: 61.72%] [G loss: 0.680073]\n",
      "epoch:0 step:464 [D loss: 0.656298, acc.: 55.47%] [G loss: 0.683023]\n",
      "epoch:0 step:465 [D loss: 0.663852, acc.: 54.69%] [G loss: 0.693079]\n",
      "epoch:0 step:466 [D loss: 0.634444, acc.: 60.94%] [G loss: 0.697207]\n",
      "epoch:0 step:467 [D loss: 0.651442, acc.: 59.38%] [G loss: 0.711893]\n",
      "epoch:0 step:468 [D loss: 0.662348, acc.: 57.81%] [G loss: 0.724516]\n",
      "epoch:0 step:469 [D loss: 0.635148, acc.: 60.94%] [G loss: 0.740828]\n",
      "epoch:0 step:470 [D loss: 0.655542, acc.: 56.25%] [G loss: 0.756487]\n",
      "epoch:0 step:471 [D loss: 0.646622, acc.: 57.81%] [G loss: 0.762691]\n",
      "epoch:0 step:472 [D loss: 0.636256, acc.: 62.50%] [G loss: 0.750096]\n",
      "epoch:0 step:473 [D loss: 0.674020, acc.: 55.47%] [G loss: 0.722901]\n",
      "epoch:0 step:474 [D loss: 0.660362, acc.: 57.03%] [G loss: 0.697607]\n",
      "epoch:0 step:475 [D loss: 0.672123, acc.: 56.25%] [G loss: 0.702061]\n",
      "epoch:0 step:476 [D loss: 0.655056, acc.: 59.38%] [G loss: 0.717726]\n",
      "epoch:0 step:477 [D loss: 0.675477, acc.: 51.56%] [G loss: 0.722430]\n",
      "epoch:0 step:478 [D loss: 0.658768, acc.: 60.94%] [G loss: 0.717330]\n",
      "epoch:0 step:479 [D loss: 0.648280, acc.: 60.94%] [G loss: 0.715995]\n",
      "epoch:0 step:480 [D loss: 0.646698, acc.: 53.91%] [G loss: 0.731847]\n",
      "epoch:0 step:481 [D loss: 0.631515, acc.: 52.34%] [G loss: 0.733750]\n",
      "epoch:0 step:482 [D loss: 0.660645, acc.: 53.91%] [G loss: 0.731668]\n",
      "epoch:0 step:483 [D loss: 0.641116, acc.: 51.56%] [G loss: 0.734688]\n",
      "epoch:0 step:484 [D loss: 0.635065, acc.: 50.78%] [G loss: 0.732833]\n",
      "epoch:0 step:485 [D loss: 0.627972, acc.: 51.56%] [G loss: 0.733680]\n",
      "epoch:0 step:486 [D loss: 0.639962, acc.: 50.78%] [G loss: 0.734008]\n",
      "epoch:0 step:487 [D loss: 0.637504, acc.: 50.00%] [G loss: 0.734328]\n",
      "epoch:0 step:488 [D loss: 0.620250, acc.: 54.69%] [G loss: 0.721560]\n",
      "epoch:0 step:489 [D loss: 0.659525, acc.: 49.22%] [G loss: 0.706213]\n",
      "epoch:0 step:490 [D loss: 0.632322, acc.: 60.94%] [G loss: 0.705544]\n",
      "epoch:0 step:491 [D loss: 0.646888, acc.: 58.59%] [G loss: 0.717396]\n",
      "epoch:0 step:492 [D loss: 0.643806, acc.: 61.72%] [G loss: 0.724067]\n",
      "epoch:0 step:493 [D loss: 0.636993, acc.: 61.72%] [G loss: 0.729932]\n",
      "epoch:0 step:494 [D loss: 0.640598, acc.: 59.38%] [G loss: 0.731898]\n",
      "epoch:0 step:495 [D loss: 0.659790, acc.: 57.81%] [G loss: 0.734614]\n",
      "epoch:0 step:496 [D loss: 0.653469, acc.: 50.78%] [G loss: 0.732243]\n",
      "epoch:0 step:497 [D loss: 0.654194, acc.: 50.00%] [G loss: 0.756914]\n",
      "epoch:0 step:498 [D loss: 0.629698, acc.: 63.28%] [G loss: 0.761447]\n",
      "epoch:0 step:499 [D loss: 0.634890, acc.: 64.84%] [G loss: 0.750237]\n",
      "epoch:0 step:500 [D loss: 0.666366, acc.: 51.56%] [G loss: 0.725006]\n",
      "epoch:0 step:501 [D loss: 0.656871, acc.: 55.47%] [G loss: 0.713854]\n",
      "epoch:0 step:502 [D loss: 0.662494, acc.: 57.81%] [G loss: 0.735571]\n",
      "epoch:0 step:503 [D loss: 0.633727, acc.: 60.94%] [G loss: 0.733086]\n",
      "epoch:0 step:504 [D loss: 0.637666, acc.: 59.38%] [G loss: 0.717300]\n",
      "epoch:0 step:505 [D loss: 0.652757, acc.: 57.03%] [G loss: 0.731899]\n",
      "epoch:0 step:506 [D loss: 0.638233, acc.: 53.12%] [G loss: 0.748514]\n",
      "epoch:0 step:507 [D loss: 0.609453, acc.: 73.44%] [G loss: 0.749249]\n",
      "epoch:0 step:508 [D loss: 0.598642, acc.: 76.56%] [G loss: 0.758330]\n",
      "epoch:0 step:509 [D loss: 0.677039, acc.: 59.38%] [G loss: 0.750500]\n",
      "epoch:0 step:510 [D loss: 0.662231, acc.: 60.94%] [G loss: 0.741603]\n",
      "epoch:0 step:511 [D loss: 0.666608, acc.: 64.06%] [G loss: 0.721354]\n",
      "epoch:0 step:512 [D loss: 0.647819, acc.: 57.03%] [G loss: 0.723931]\n",
      "epoch:0 step:513 [D loss: 0.632394, acc.: 58.59%] [G loss: 0.751652]\n",
      "epoch:0 step:514 [D loss: 0.626372, acc.: 68.75%] [G loss: 0.760995]\n",
      "epoch:0 step:515 [D loss: 0.617681, acc.: 74.22%] [G loss: 0.793104]\n",
      "epoch:0 step:516 [D loss: 0.638682, acc.: 70.31%] [G loss: 0.782969]\n",
      "epoch:0 step:517 [D loss: 0.669941, acc.: 55.47%] [G loss: 0.748187]\n",
      "epoch:0 step:518 [D loss: 0.648562, acc.: 60.94%] [G loss: 0.749258]\n",
      "epoch:0 step:519 [D loss: 0.623767, acc.: 60.94%] [G loss: 0.768047]\n",
      "epoch:0 step:520 [D loss: 0.631241, acc.: 67.19%] [G loss: 0.762340]\n",
      "epoch:0 step:521 [D loss: 0.630176, acc.: 76.56%] [G loss: 0.760959]\n",
      "epoch:0 step:522 [D loss: 0.630645, acc.: 66.41%] [G loss: 0.757695]\n",
      "epoch:0 step:523 [D loss: 0.624908, acc.: 64.84%] [G loss: 0.761881]\n",
      "epoch:0 step:524 [D loss: 0.625159, acc.: 65.62%] [G loss: 0.752399]\n",
      "epoch:0 step:525 [D loss: 0.629432, acc.: 57.03%] [G loss: 0.741936]\n",
      "epoch:0 step:526 [D loss: 0.601207, acc.: 57.81%] [G loss: 0.749816]\n",
      "epoch:0 step:527 [D loss: 0.604817, acc.: 58.59%] [G loss: 0.773024]\n",
      "epoch:0 step:528 [D loss: 0.609829, acc.: 71.09%] [G loss: 0.774930]\n",
      "epoch:0 step:529 [D loss: 0.586624, acc.: 78.12%] [G loss: 0.782601]\n",
      "epoch:0 step:530 [D loss: 0.578069, acc.: 80.47%] [G loss: 0.792153]\n",
      "epoch:0 step:531 [D loss: 0.598283, acc.: 71.88%] [G loss: 0.782385]\n",
      "epoch:0 step:532 [D loss: 0.612514, acc.: 69.53%] [G loss: 0.781381]\n",
      "epoch:0 step:533 [D loss: 0.599457, acc.: 71.88%] [G loss: 0.771249]\n",
      "epoch:0 step:534 [D loss: 0.599128, acc.: 70.31%] [G loss: 0.765724]\n",
      "epoch:0 step:535 [D loss: 0.626162, acc.: 65.62%] [G loss: 0.763821]\n",
      "epoch:0 step:536 [D loss: 0.607102, acc.: 66.41%] [G loss: 0.783738]\n",
      "epoch:0 step:537 [D loss: 0.617995, acc.: 67.19%] [G loss: 0.774397]\n",
      "epoch:0 step:538 [D loss: 0.606249, acc.: 57.03%] [G loss: 0.798664]\n",
      "epoch:0 step:539 [D loss: 0.608750, acc.: 63.28%] [G loss: 0.794220]\n",
      "epoch:0 step:540 [D loss: 0.609124, acc.: 67.19%] [G loss: 0.768633]\n",
      "epoch:0 step:541 [D loss: 0.590174, acc.: 75.00%] [G loss: 0.772456]\n",
      "epoch:0 step:542 [D loss: 0.644187, acc.: 57.81%] [G loss: 0.757282]\n",
      "epoch:0 step:543 [D loss: 0.636241, acc.: 57.03%] [G loss: 0.735649]\n",
      "epoch:0 step:544 [D loss: 0.611311, acc.: 57.81%] [G loss: 0.753834]\n",
      "epoch:0 step:545 [D loss: 0.624371, acc.: 65.62%] [G loss: 0.763237]\n",
      "epoch:0 step:546 [D loss: 0.614444, acc.: 62.50%] [G loss: 0.779638]\n",
      "epoch:0 step:547 [D loss: 0.617741, acc.: 63.28%] [G loss: 0.778319]\n",
      "epoch:0 step:548 [D loss: 0.649179, acc.: 60.94%] [G loss: 0.794964]\n",
      "epoch:0 step:549 [D loss: 0.675810, acc.: 54.69%] [G loss: 0.797583]\n",
      "epoch:0 step:550 [D loss: 0.654264, acc.: 60.16%] [G loss: 0.780497]\n",
      "epoch:0 step:551 [D loss: 0.650421, acc.: 57.03%] [G loss: 0.799927]\n",
      "epoch:0 step:552 [D loss: 0.674102, acc.: 47.66%] [G loss: 0.808255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:553 [D loss: 0.660970, acc.: 57.81%] [G loss: 0.770423]\n",
      "epoch:0 step:554 [D loss: 0.668411, acc.: 53.12%] [G loss: 0.772049]\n",
      "epoch:0 step:555 [D loss: 0.661513, acc.: 56.25%] [G loss: 0.817897]\n",
      "epoch:0 step:556 [D loss: 0.660091, acc.: 57.81%] [G loss: 0.845836]\n",
      "epoch:0 step:557 [D loss: 0.658449, acc.: 60.94%] [G loss: 0.825911]\n",
      "epoch:0 step:558 [D loss: 0.624959, acc.: 61.72%] [G loss: 0.832290]\n",
      "epoch:0 step:559 [D loss: 0.677594, acc.: 57.03%] [G loss: 0.790962]\n",
      "epoch:0 step:560 [D loss: 0.649133, acc.: 58.59%] [G loss: 0.790910]\n",
      "epoch:0 step:561 [D loss: 0.671331, acc.: 57.81%] [G loss: 0.794386]\n",
      "epoch:0 step:562 [D loss: 0.674729, acc.: 54.69%] [G loss: 0.819699]\n",
      "epoch:0 step:563 [D loss: 0.672118, acc.: 52.34%] [G loss: 0.810665]\n",
      "epoch:0 step:564 [D loss: 0.662212, acc.: 53.91%] [G loss: 0.785523]\n",
      "epoch:0 step:565 [D loss: 0.709382, acc.: 37.50%] [G loss: 0.733142]\n",
      "epoch:0 step:566 [D loss: 0.705914, acc.: 41.41%] [G loss: 0.710240]\n",
      "epoch:0 step:567 [D loss: 0.645784, acc.: 51.56%] [G loss: 0.752957]\n",
      "epoch:0 step:568 [D loss: 0.629975, acc.: 65.62%] [G loss: 0.768374]\n",
      "epoch:0 step:569 [D loss: 0.645401, acc.: 61.72%] [G loss: 0.753304]\n",
      "epoch:0 step:570 [D loss: 0.642766, acc.: 53.12%] [G loss: 0.737292]\n",
      "epoch:0 step:571 [D loss: 0.631066, acc.: 55.47%] [G loss: 0.721186]\n",
      "epoch:0 step:572 [D loss: 0.632322, acc.: 58.59%] [G loss: 0.746940]\n",
      "epoch:0 step:573 [D loss: 0.601013, acc.: 67.19%] [G loss: 0.788883]\n",
      "epoch:0 step:574 [D loss: 0.589334, acc.: 71.09%] [G loss: 0.828860]\n",
      "epoch:0 step:575 [D loss: 0.592359, acc.: 75.00%] [G loss: 0.832479]\n",
      "epoch:0 step:576 [D loss: 0.650009, acc.: 63.28%] [G loss: 0.788282]\n",
      "epoch:0 step:577 [D loss: 0.663563, acc.: 57.81%] [G loss: 0.788934]\n",
      "epoch:0 step:578 [D loss: 0.623502, acc.: 67.19%] [G loss: 0.811376]\n",
      "epoch:0 step:579 [D loss: 0.635421, acc.: 56.25%] [G loss: 0.787913]\n",
      "epoch:0 step:580 [D loss: 0.649668, acc.: 57.03%] [G loss: 0.806093]\n",
      "epoch:0 step:581 [D loss: 0.612098, acc.: 62.50%] [G loss: 0.779486]\n",
      "epoch:0 step:582 [D loss: 0.621694, acc.: 67.97%] [G loss: 0.815995]\n",
      "epoch:0 step:583 [D loss: 0.635359, acc.: 68.75%] [G loss: 0.765387]\n",
      "epoch:0 step:584 [D loss: 0.691230, acc.: 56.25%] [G loss: 0.766127]\n",
      "epoch:0 step:585 [D loss: 0.641745, acc.: 64.84%] [G loss: 0.747782]\n",
      "epoch:0 step:586 [D loss: 0.686409, acc.: 64.84%] [G loss: 0.750183]\n",
      "epoch:0 step:587 [D loss: 0.669594, acc.: 58.59%] [G loss: 0.741929]\n",
      "epoch:0 step:588 [D loss: 0.670409, acc.: 56.25%] [G loss: 0.734280]\n",
      "epoch:0 step:589 [D loss: 0.657488, acc.: 60.94%] [G loss: 0.745397]\n",
      "epoch:0 step:590 [D loss: 0.642319, acc.: 58.59%] [G loss: 0.783426]\n",
      "epoch:0 step:591 [D loss: 0.632321, acc.: 64.84%] [G loss: 0.782956]\n",
      "epoch:0 step:592 [D loss: 0.629066, acc.: 71.09%] [G loss: 0.754505]\n",
      "epoch:0 step:593 [D loss: 0.654848, acc.: 63.28%] [G loss: 0.744477]\n",
      "epoch:0 step:594 [D loss: 0.648143, acc.: 59.38%] [G loss: 0.760845]\n",
      "epoch:0 step:595 [D loss: 0.644009, acc.: 63.28%] [G loss: 0.758436]\n",
      "epoch:0 step:596 [D loss: 0.626437, acc.: 66.41%] [G loss: 0.765557]\n",
      "epoch:0 step:597 [D loss: 0.632211, acc.: 67.97%] [G loss: 0.778696]\n",
      "epoch:0 step:598 [D loss: 0.629094, acc.: 68.75%] [G loss: 0.757462]\n",
      "epoch:0 step:599 [D loss: 0.643514, acc.: 64.84%] [G loss: 0.736922]\n",
      "epoch:0 step:600 [D loss: 0.648409, acc.: 60.16%] [G loss: 0.757504]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 2.391726\n",
      "FID: 188.427155\n",
      "0 = 15.92415579509733\n",
      "1 = 0.2420447143986221\n",
      "2 = 0.9993000030517578\n",
      "3 = 0.9986000061035156\n",
      "4 = 1.0\n",
      "5 = 1.0\n",
      "6 = 0.9986000061035156\n",
      "7 = 14.566347409856235\n",
      "8 = 0.23503782008589072\n",
      "9 = 0.9955000281333923\n",
      "10 = 0.9909999966621399\n",
      "11 = 1.0\n",
      "12 = 1.0\n",
      "13 = 0.9909999966621399\n",
      "14 = 2.3917253017425537\n",
      "15 = 7.20103120803833\n",
      "16 = 0.5807348489761353\n",
      "17 = 2.391726016998291\n",
      "18 = 188.42715454101562\n",
      "epoch:0 step:601 [D loss: 0.615661, acc.: 60.16%] [G loss: 0.757573]\n",
      "epoch:0 step:602 [D loss: 0.626058, acc.: 60.94%] [G loss: 0.748281]\n",
      "epoch:0 step:603 [D loss: 0.638646, acc.: 57.81%] [G loss: 0.775233]\n",
      "epoch:0 step:604 [D loss: 0.648806, acc.: 64.06%] [G loss: 0.745560]\n",
      "epoch:0 step:605 [D loss: 0.638078, acc.: 60.94%] [G loss: 0.753740]\n",
      "epoch:0 step:606 [D loss: 0.637005, acc.: 64.06%] [G loss: 0.767455]\n",
      "epoch:0 step:607 [D loss: 0.636752, acc.: 62.50%] [G loss: 0.751586]\n",
      "epoch:0 step:608 [D loss: 0.632986, acc.: 62.50%] [G loss: 0.759461]\n",
      "epoch:0 step:609 [D loss: 0.635515, acc.: 63.28%] [G loss: 0.767115]\n",
      "epoch:0 step:610 [D loss: 0.632205, acc.: 65.62%] [G loss: 0.781643]\n",
      "epoch:0 step:611 [D loss: 0.612738, acc.: 69.53%] [G loss: 0.766570]\n",
      "epoch:0 step:612 [D loss: 0.655334, acc.: 57.81%] [G loss: 0.764561]\n",
      "epoch:0 step:613 [D loss: 0.613499, acc.: 66.41%] [G loss: 0.780551]\n",
      "epoch:0 step:614 [D loss: 0.654637, acc.: 59.38%] [G loss: 0.796934]\n",
      "epoch:0 step:615 [D loss: 0.648616, acc.: 62.50%] [G loss: 0.765663]\n",
      "epoch:0 step:616 [D loss: 0.645343, acc.: 68.75%] [G loss: 0.763399]\n",
      "epoch:0 step:617 [D loss: 0.641115, acc.: 67.97%] [G loss: 0.724297]\n",
      "epoch:0 step:618 [D loss: 0.661913, acc.: 63.28%] [G loss: 0.756727]\n",
      "epoch:0 step:619 [D loss: 0.643682, acc.: 67.19%] [G loss: 0.758211]\n",
      "epoch:0 step:620 [D loss: 0.617935, acc.: 71.09%] [G loss: 0.776274]\n",
      "epoch:0 step:621 [D loss: 0.662087, acc.: 57.03%] [G loss: 0.770960]\n",
      "epoch:0 step:622 [D loss: 0.679400, acc.: 59.38%] [G loss: 0.763237]\n",
      "epoch:0 step:623 [D loss: 0.668221, acc.: 55.47%] [G loss: 0.786652]\n",
      "epoch:0 step:624 [D loss: 0.628473, acc.: 66.41%] [G loss: 0.825892]\n",
      "epoch:0 step:625 [D loss: 0.626907, acc.: 64.84%] [G loss: 0.806640]\n",
      "epoch:0 step:626 [D loss: 0.626470, acc.: 65.62%] [G loss: 0.785092]\n",
      "epoch:0 step:627 [D loss: 0.637835, acc.: 58.59%] [G loss: 0.766463]\n",
      "epoch:0 step:628 [D loss: 0.637281, acc.: 61.72%] [G loss: 0.787857]\n",
      "epoch:0 step:629 [D loss: 0.610434, acc.: 70.31%] [G loss: 0.815551]\n",
      "epoch:0 step:630 [D loss: 0.638058, acc.: 64.06%] [G loss: 0.794758]\n",
      "epoch:0 step:631 [D loss: 0.620445, acc.: 65.62%] [G loss: 0.771327]\n",
      "epoch:0 step:632 [D loss: 0.608630, acc.: 71.09%] [G loss: 0.770583]\n",
      "epoch:0 step:633 [D loss: 0.634214, acc.: 60.16%] [G loss: 0.784510]\n",
      "epoch:0 step:634 [D loss: 0.597220, acc.: 71.09%] [G loss: 0.822162]\n",
      "epoch:0 step:635 [D loss: 0.607908, acc.: 71.88%] [G loss: 0.809907]\n",
      "epoch:0 step:636 [D loss: 0.651094, acc.: 62.50%] [G loss: 0.785609]\n",
      "epoch:0 step:637 [D loss: 0.645825, acc.: 61.72%] [G loss: 0.786703]\n",
      "epoch:0 step:638 [D loss: 0.641742, acc.: 59.38%] [G loss: 0.798302]\n",
      "epoch:0 step:639 [D loss: 0.667895, acc.: 56.25%] [G loss: 0.771914]\n",
      "epoch:0 step:640 [D loss: 0.672135, acc.: 53.12%] [G loss: 0.731678]\n",
      "epoch:0 step:641 [D loss: 0.655517, acc.: 57.81%] [G loss: 0.742928]\n",
      "epoch:0 step:642 [D loss: 0.654341, acc.: 60.16%] [G loss: 0.765930]\n",
      "epoch:0 step:643 [D loss: 0.652034, acc.: 58.59%] [G loss: 0.756304]\n",
      "epoch:0 step:644 [D loss: 0.663273, acc.: 57.03%] [G loss: 0.735545]\n",
      "epoch:0 step:645 [D loss: 0.672002, acc.: 51.56%] [G loss: 0.739943]\n",
      "epoch:0 step:646 [D loss: 0.659256, acc.: 60.94%] [G loss: 0.784018]\n",
      "epoch:0 step:647 [D loss: 0.643499, acc.: 64.84%] [G loss: 0.799031]\n",
      "epoch:0 step:648 [D loss: 0.600641, acc.: 73.44%] [G loss: 0.832546]\n",
      "epoch:0 step:649 [D loss: 0.652955, acc.: 60.94%] [G loss: 0.809075]\n",
      "epoch:0 step:650 [D loss: 0.624449, acc.: 57.81%] [G loss: 0.822053]\n",
      "epoch:0 step:651 [D loss: 0.619468, acc.: 70.31%] [G loss: 0.818821]\n",
      "epoch:0 step:652 [D loss: 0.654088, acc.: 59.38%] [G loss: 0.804869]\n",
      "epoch:0 step:653 [D loss: 0.640664, acc.: 60.94%] [G loss: 0.794775]\n",
      "epoch:0 step:654 [D loss: 0.645011, acc.: 54.69%] [G loss: 0.781314]\n",
      "epoch:0 step:655 [D loss: 0.660908, acc.: 46.09%] [G loss: 0.748796]\n",
      "epoch:0 step:656 [D loss: 0.640666, acc.: 59.38%] [G loss: 0.745131]\n",
      "epoch:0 step:657 [D loss: 0.639223, acc.: 61.72%] [G loss: 0.728761]\n",
      "epoch:0 step:658 [D loss: 0.611200, acc.: 72.66%] [G loss: 0.739297]\n",
      "epoch:0 step:659 [D loss: 0.625787, acc.: 69.53%] [G loss: 0.751951]\n",
      "epoch:0 step:660 [D loss: 0.610162, acc.: 68.75%] [G loss: 0.762990]\n",
      "epoch:0 step:661 [D loss: 0.621015, acc.: 66.41%] [G loss: 0.781909]\n",
      "epoch:0 step:662 [D loss: 0.684770, acc.: 50.00%] [G loss: 0.775712]\n",
      "epoch:0 step:663 [D loss: 0.647218, acc.: 59.38%] [G loss: 0.779038]\n",
      "epoch:0 step:664 [D loss: 0.616255, acc.: 74.22%] [G loss: 0.778711]\n",
      "epoch:0 step:665 [D loss: 0.627943, acc.: 71.09%] [G loss: 0.798588]\n",
      "epoch:0 step:666 [D loss: 0.630897, acc.: 63.28%] [G loss: 0.796706]\n",
      "epoch:0 step:667 [D loss: 0.626202, acc.: 66.41%] [G loss: 0.827416]\n",
      "epoch:0 step:668 [D loss: 0.638754, acc.: 69.53%] [G loss: 0.830560]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:669 [D loss: 0.630547, acc.: 62.50%] [G loss: 0.841952]\n",
      "epoch:0 step:670 [D loss: 0.630148, acc.: 67.97%] [G loss: 0.875152]\n",
      "epoch:0 step:671 [D loss: 0.651751, acc.: 64.84%] [G loss: 0.813278]\n",
      "epoch:0 step:672 [D loss: 0.676392, acc.: 59.38%] [G loss: 0.784381]\n",
      "epoch:0 step:673 [D loss: 0.667037, acc.: 62.50%] [G loss: 0.811615]\n",
      "epoch:0 step:674 [D loss: 0.616051, acc.: 66.41%] [G loss: 0.901285]\n",
      "epoch:0 step:675 [D loss: 0.657936, acc.: 55.47%] [G loss: 0.829892]\n",
      "epoch:0 step:676 [D loss: 0.630675, acc.: 60.94%] [G loss: 0.811706]\n",
      "epoch:0 step:677 [D loss: 0.590713, acc.: 64.06%] [G loss: 0.835117]\n",
      "epoch:0 step:678 [D loss: 0.618392, acc.: 68.75%] [G loss: 0.852667]\n",
      "epoch:0 step:679 [D loss: 0.632555, acc.: 64.06%] [G loss: 0.815361]\n",
      "epoch:0 step:680 [D loss: 0.656409, acc.: 53.12%] [G loss: 0.778486]\n",
      "epoch:0 step:681 [D loss: 0.623378, acc.: 66.41%] [G loss: 0.792544]\n",
      "epoch:0 step:682 [D loss: 0.625603, acc.: 62.50%] [G loss: 0.810980]\n",
      "epoch:0 step:683 [D loss: 0.605557, acc.: 70.31%] [G loss: 0.774748]\n",
      "epoch:0 step:684 [D loss: 0.621747, acc.: 74.22%] [G loss: 0.801950]\n",
      "epoch:0 step:685 [D loss: 0.637054, acc.: 70.31%] [G loss: 0.814938]\n",
      "epoch:0 step:686 [D loss: 0.649488, acc.: 56.25%] [G loss: 0.835029]\n",
      "epoch:0 step:687 [D loss: 0.634834, acc.: 58.59%] [G loss: 0.856087]\n",
      "epoch:0 step:688 [D loss: 0.639984, acc.: 57.81%] [G loss: 0.852691]\n",
      "epoch:0 step:689 [D loss: 0.636109, acc.: 64.84%] [G loss: 0.837774]\n",
      "epoch:0 step:690 [D loss: 0.663495, acc.: 56.25%] [G loss: 0.816342]\n",
      "epoch:0 step:691 [D loss: 0.651201, acc.: 58.59%] [G loss: 0.804802]\n",
      "epoch:0 step:692 [D loss: 0.643100, acc.: 55.47%] [G loss: 0.818482]\n",
      "epoch:0 step:693 [D loss: 0.634770, acc.: 66.41%] [G loss: 0.780728]\n",
      "epoch:0 step:694 [D loss: 0.624847, acc.: 63.28%] [G loss: 0.797475]\n",
      "epoch:0 step:695 [D loss: 0.657011, acc.: 55.47%] [G loss: 0.801568]\n",
      "epoch:0 step:696 [D loss: 0.624305, acc.: 64.06%] [G loss: 0.786369]\n",
      "epoch:0 step:697 [D loss: 0.660850, acc.: 64.84%] [G loss: 0.785143]\n",
      "epoch:0 step:698 [D loss: 0.605184, acc.: 67.19%] [G loss: 0.794464]\n",
      "epoch:0 step:699 [D loss: 0.611354, acc.: 70.31%] [G loss: 0.787921]\n",
      "epoch:0 step:700 [D loss: 0.614899, acc.: 70.31%] [G loss: 0.809828]\n",
      "epoch:0 step:701 [D loss: 0.611941, acc.: 71.09%] [G loss: 0.867682]\n",
      "epoch:0 step:702 [D loss: 0.630406, acc.: 70.31%] [G loss: 0.851645]\n",
      "epoch:0 step:703 [D loss: 0.612857, acc.: 71.88%] [G loss: 0.846119]\n",
      "epoch:0 step:704 [D loss: 0.622648, acc.: 75.00%] [G loss: 0.838862]\n",
      "epoch:0 step:705 [D loss: 0.620946, acc.: 71.09%] [G loss: 0.805654]\n",
      "epoch:0 step:706 [D loss: 0.596280, acc.: 71.88%] [G loss: 0.813872]\n",
      "epoch:0 step:707 [D loss: 0.584792, acc.: 77.34%] [G loss: 0.819457]\n",
      "epoch:0 step:708 [D loss: 0.586315, acc.: 75.78%] [G loss: 0.828946]\n",
      "epoch:0 step:709 [D loss: 0.570623, acc.: 78.91%] [G loss: 0.841695]\n",
      "epoch:0 step:710 [D loss: 0.663225, acc.: 61.72%] [G loss: 0.830045]\n",
      "epoch:0 step:711 [D loss: 0.627898, acc.: 65.62%] [G loss: 0.814864]\n",
      "epoch:0 step:712 [D loss: 0.598367, acc.: 72.66%] [G loss: 0.794209]\n",
      "epoch:0 step:713 [D loss: 0.604494, acc.: 67.97%] [G loss: 0.798661]\n",
      "epoch:0 step:714 [D loss: 0.606853, acc.: 71.88%] [G loss: 0.782294]\n",
      "epoch:0 step:715 [D loss: 0.647449, acc.: 60.94%] [G loss: 0.785594]\n",
      "epoch:0 step:716 [D loss: 0.636307, acc.: 62.50%] [G loss: 0.815551]\n",
      "epoch:0 step:717 [D loss: 0.625175, acc.: 67.97%] [G loss: 0.819082]\n",
      "epoch:0 step:718 [D loss: 0.631382, acc.: 63.28%] [G loss: 0.808614]\n",
      "epoch:0 step:719 [D loss: 0.644972, acc.: 59.38%] [G loss: 0.839884]\n",
      "epoch:0 step:720 [D loss: 0.650240, acc.: 60.16%] [G loss: 0.816722]\n",
      "epoch:0 step:721 [D loss: 0.670528, acc.: 57.03%] [G loss: 0.821580]\n",
      "epoch:0 step:722 [D loss: 0.644896, acc.: 60.16%] [G loss: 0.810286]\n",
      "epoch:0 step:723 [D loss: 0.670796, acc.: 55.47%] [G loss: 0.808906]\n",
      "epoch:0 step:724 [D loss: 0.640891, acc.: 62.50%] [G loss: 0.828087]\n",
      "epoch:0 step:725 [D loss: 0.645802, acc.: 58.59%] [G loss: 0.818825]\n",
      "epoch:0 step:726 [D loss: 0.622228, acc.: 61.72%] [G loss: 0.819142]\n",
      "epoch:0 step:727 [D loss: 0.656110, acc.: 58.59%] [G loss: 0.791960]\n",
      "epoch:0 step:728 [D loss: 0.632451, acc.: 66.41%] [G loss: 0.820478]\n",
      "epoch:0 step:729 [D loss: 0.630380, acc.: 68.75%] [G loss: 0.835808]\n",
      "epoch:0 step:730 [D loss: 0.619596, acc.: 69.53%] [G loss: 0.853571]\n",
      "epoch:0 step:731 [D loss: 0.575358, acc.: 76.56%] [G loss: 0.862454]\n",
      "epoch:0 step:732 [D loss: 0.596674, acc.: 69.53%] [G loss: 0.862278]\n",
      "epoch:0 step:733 [D loss: 0.582531, acc.: 74.22%] [G loss: 0.908613]\n",
      "epoch:0 step:734 [D loss: 0.659473, acc.: 60.94%] [G loss: 0.830189]\n",
      "epoch:0 step:735 [D loss: 0.644019, acc.: 62.50%] [G loss: 0.819064]\n",
      "epoch:0 step:736 [D loss: 0.617328, acc.: 62.50%] [G loss: 0.837279]\n",
      "epoch:0 step:737 [D loss: 0.621104, acc.: 62.50%] [G loss: 0.822176]\n",
      "epoch:0 step:738 [D loss: 0.631375, acc.: 63.28%] [G loss: 0.811241]\n",
      "epoch:0 step:739 [D loss: 0.643918, acc.: 57.03%] [G loss: 0.770193]\n",
      "epoch:0 step:740 [D loss: 0.643041, acc.: 60.16%] [G loss: 0.776688]\n",
      "epoch:0 step:741 [D loss: 0.632037, acc.: 62.50%] [G loss: 0.794112]\n",
      "epoch:0 step:742 [D loss: 0.612938, acc.: 66.41%] [G loss: 0.797054]\n",
      "epoch:0 step:743 [D loss: 0.609868, acc.: 65.62%] [G loss: 0.799052]\n",
      "epoch:0 step:744 [D loss: 0.637421, acc.: 63.28%] [G loss: 0.802995]\n",
      "epoch:0 step:745 [D loss: 0.632640, acc.: 66.41%] [G loss: 0.806562]\n",
      "epoch:0 step:746 [D loss: 0.574141, acc.: 79.69%] [G loss: 0.810887]\n",
      "epoch:0 step:747 [D loss: 0.585837, acc.: 77.34%] [G loss: 0.836769]\n",
      "epoch:0 step:748 [D loss: 0.611436, acc.: 73.44%] [G loss: 0.869438]\n",
      "epoch:0 step:749 [D loss: 0.605045, acc.: 74.22%] [G loss: 0.874022]\n",
      "epoch:0 step:750 [D loss: 0.604691, acc.: 73.44%] [G loss: 0.863577]\n",
      "epoch:0 step:751 [D loss: 0.592747, acc.: 74.22%] [G loss: 0.845220]\n",
      "epoch:0 step:752 [D loss: 0.582359, acc.: 82.03%] [G loss: 0.847328]\n",
      "epoch:0 step:753 [D loss: 0.572253, acc.: 75.78%] [G loss: 0.866775]\n",
      "epoch:0 step:754 [D loss: 0.587492, acc.: 77.34%] [G loss: 0.897770]\n",
      "epoch:0 step:755 [D loss: 0.576587, acc.: 82.03%] [G loss: 0.905950]\n",
      "epoch:0 step:756 [D loss: 0.594614, acc.: 75.00%] [G loss: 0.858060]\n",
      "epoch:0 step:757 [D loss: 0.587155, acc.: 74.22%] [G loss: 0.860480]\n",
      "epoch:0 step:758 [D loss: 0.566466, acc.: 80.47%] [G loss: 0.868218]\n",
      "epoch:0 step:759 [D loss: 0.579116, acc.: 69.53%] [G loss: 0.885490]\n",
      "epoch:0 step:760 [D loss: 0.573262, acc.: 76.56%] [G loss: 0.897378]\n",
      "epoch:0 step:761 [D loss: 0.571547, acc.: 77.34%] [G loss: 0.888060]\n",
      "epoch:0 step:762 [D loss: 0.585166, acc.: 67.19%] [G loss: 0.880238]\n",
      "epoch:0 step:763 [D loss: 0.551707, acc.: 79.69%] [G loss: 0.907662]\n",
      "epoch:0 step:764 [D loss: 0.574365, acc.: 78.12%] [G loss: 0.900019]\n",
      "epoch:0 step:765 [D loss: 0.631449, acc.: 64.06%] [G loss: 0.860385]\n",
      "epoch:0 step:766 [D loss: 0.650336, acc.: 63.28%] [G loss: 0.816874]\n",
      "epoch:0 step:767 [D loss: 0.583706, acc.: 71.88%] [G loss: 0.827716]\n",
      "epoch:0 step:768 [D loss: 0.580335, acc.: 76.56%] [G loss: 0.842925]\n",
      "epoch:0 step:769 [D loss: 0.548393, acc.: 82.81%] [G loss: 0.875440]\n",
      "epoch:0 step:770 [D loss: 0.565872, acc.: 82.81%] [G loss: 0.891150]\n",
      "epoch:0 step:771 [D loss: 0.597620, acc.: 75.00%] [G loss: 0.881747]\n",
      "epoch:0 step:772 [D loss: 0.571566, acc.: 77.34%] [G loss: 0.882805]\n",
      "epoch:0 step:773 [D loss: 0.568637, acc.: 81.25%] [G loss: 0.868238]\n",
      "epoch:0 step:774 [D loss: 0.570011, acc.: 80.47%] [G loss: 0.879677]\n",
      "epoch:0 step:775 [D loss: 0.568382, acc.: 75.78%] [G loss: 0.909861]\n",
      "epoch:0 step:776 [D loss: 0.592531, acc.: 72.66%] [G loss: 0.879373]\n",
      "epoch:0 step:777 [D loss: 0.598491, acc.: 75.78%] [G loss: 0.853695]\n",
      "epoch:0 step:778 [D loss: 0.628899, acc.: 65.62%] [G loss: 0.866529]\n",
      "epoch:0 step:779 [D loss: 0.599805, acc.: 79.69%] [G loss: 0.843980]\n",
      "epoch:0 step:780 [D loss: 0.602078, acc.: 72.66%] [G loss: 0.820346]\n",
      "epoch:0 step:781 [D loss: 0.553903, acc.: 75.78%] [G loss: 0.857040]\n",
      "epoch:0 step:782 [D loss: 0.581774, acc.: 71.88%] [G loss: 0.925990]\n",
      "epoch:0 step:783 [D loss: 0.630770, acc.: 64.06%] [G loss: 0.904867]\n",
      "epoch:0 step:784 [D loss: 0.636024, acc.: 58.59%] [G loss: 0.909276]\n",
      "epoch:0 step:785 [D loss: 0.587043, acc.: 72.66%] [G loss: 0.898875]\n",
      "epoch:0 step:786 [D loss: 0.577529, acc.: 67.97%] [G loss: 0.944227]\n",
      "epoch:0 step:787 [D loss: 0.627444, acc.: 60.16%] [G loss: 0.931372]\n",
      "epoch:0 step:788 [D loss: 0.607320, acc.: 71.88%] [G loss: 0.882021]\n",
      "epoch:0 step:789 [D loss: 0.578853, acc.: 74.22%] [G loss: 0.900399]\n",
      "epoch:0 step:790 [D loss: 0.578766, acc.: 73.44%] [G loss: 0.894747]\n",
      "epoch:0 step:791 [D loss: 0.567784, acc.: 74.22%] [G loss: 0.921595]\n",
      "epoch:0 step:792 [D loss: 0.568959, acc.: 78.12%] [G loss: 0.935294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:793 [D loss: 0.624179, acc.: 65.62%] [G loss: 0.950181]\n",
      "epoch:0 step:794 [D loss: 0.662341, acc.: 59.38%] [G loss: 0.929129]\n",
      "epoch:0 step:795 [D loss: 0.602485, acc.: 70.31%] [G loss: 0.953531]\n",
      "epoch:0 step:796 [D loss: 0.588775, acc.: 75.00%] [G loss: 0.954689]\n",
      "epoch:0 step:797 [D loss: 0.680421, acc.: 60.94%] [G loss: 0.867191]\n",
      "epoch:0 step:798 [D loss: 0.627141, acc.: 67.97%] [G loss: 0.895199]\n",
      "epoch:0 step:799 [D loss: 0.631735, acc.: 64.06%] [G loss: 0.888845]\n",
      "epoch:0 step:800 [D loss: 0.636593, acc.: 60.94%] [G loss: 0.882308]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 3.021288\n",
      "FID: 172.840790\n",
      "0 = 16.09531172046661\n",
      "1 = 0.2373084550723297\n",
      "2 = 0.9998999834060669\n",
      "3 = 0.9998000264167786\n",
      "4 = 1.0\n",
      "5 = 1.0\n",
      "6 = 0.9998000264167786\n",
      "7 = 13.924996334171295\n",
      "8 = 0.2262658116837943\n",
      "9 = 0.9947500228881836\n",
      "10 = 0.9894999861717224\n",
      "11 = 1.0\n",
      "12 = 1.0\n",
      "13 = 0.9894999861717224\n",
      "14 = 3.0212934017181396\n",
      "15 = 6.80390739440918\n",
      "16 = 0.5144102573394775\n",
      "17 = 3.0212883949279785\n",
      "18 = 172.84078979492188\n",
      "epoch:0 step:801 [D loss: 0.587589, acc.: 69.53%] [G loss: 0.864478]\n",
      "epoch:0 step:802 [D loss: 0.597948, acc.: 69.53%] [G loss: 0.863330]\n",
      "epoch:0 step:803 [D loss: 0.623042, acc.: 67.97%] [G loss: 0.901412]\n",
      "epoch:0 step:804 [D loss: 0.650168, acc.: 64.06%] [G loss: 0.864429]\n",
      "epoch:0 step:805 [D loss: 0.644167, acc.: 63.28%] [G loss: 0.865474]\n",
      "epoch:0 step:806 [D loss: 0.612339, acc.: 65.62%] [G loss: 0.943372]\n",
      "epoch:0 step:807 [D loss: 0.598022, acc.: 75.78%] [G loss: 0.975724]\n",
      "epoch:0 step:808 [D loss: 0.629559, acc.: 62.50%] [G loss: 0.934883]\n",
      "epoch:0 step:809 [D loss: 0.629062, acc.: 65.62%] [G loss: 0.903688]\n",
      "epoch:0 step:810 [D loss: 0.617735, acc.: 66.41%] [G loss: 0.923099]\n",
      "epoch:0 step:811 [D loss: 0.631565, acc.: 58.59%] [G loss: 0.935727]\n",
      "epoch:0 step:812 [D loss: 0.638889, acc.: 67.97%] [G loss: 0.887578]\n",
      "epoch:0 step:813 [D loss: 0.623116, acc.: 64.84%] [G loss: 0.937734]\n",
      "epoch:0 step:814 [D loss: 0.586110, acc.: 79.69%] [G loss: 0.969310]\n",
      "epoch:0 step:815 [D loss: 0.597230, acc.: 70.31%] [G loss: 1.020078]\n",
      "epoch:0 step:816 [D loss: 0.578916, acc.: 75.00%] [G loss: 0.961943]\n",
      "epoch:0 step:817 [D loss: 0.600437, acc.: 70.31%] [G loss: 0.924594]\n",
      "epoch:0 step:818 [D loss: 0.633689, acc.: 64.06%] [G loss: 0.881106]\n",
      "epoch:0 step:819 [D loss: 0.611506, acc.: 57.81%] [G loss: 0.905782]\n",
      "epoch:0 step:820 [D loss: 0.645674, acc.: 60.16%] [G loss: 0.869628]\n",
      "epoch:0 step:821 [D loss: 0.626844, acc.: 57.81%] [G loss: 0.849605]\n",
      "epoch:0 step:822 [D loss: 0.596710, acc.: 75.00%] [G loss: 0.877579]\n",
      "epoch:0 step:823 [D loss: 0.596984, acc.: 67.97%] [G loss: 0.878055]\n",
      "epoch:0 step:824 [D loss: 0.615475, acc.: 70.31%] [G loss: 0.836810]\n",
      "epoch:0 step:825 [D loss: 0.590313, acc.: 69.53%] [G loss: 0.860722]\n",
      "epoch:0 step:826 [D loss: 0.593062, acc.: 68.75%] [G loss: 0.910313]\n",
      "epoch:0 step:827 [D loss: 0.593730, acc.: 77.34%] [G loss: 0.905398]\n",
      "epoch:0 step:828 [D loss: 0.618059, acc.: 74.22%] [G loss: 0.894053]\n",
      "epoch:0 step:829 [D loss: 0.577546, acc.: 76.56%] [G loss: 0.951864]\n",
      "epoch:0 step:830 [D loss: 0.580439, acc.: 76.56%] [G loss: 0.929157]\n",
      "epoch:0 step:831 [D loss: 0.607222, acc.: 71.88%] [G loss: 0.914180]\n",
      "epoch:0 step:832 [D loss: 0.584164, acc.: 74.22%] [G loss: 0.921089]\n",
      "epoch:0 step:833 [D loss: 0.586956, acc.: 74.22%] [G loss: 0.910070]\n",
      "epoch:0 step:834 [D loss: 0.641372, acc.: 63.28%] [G loss: 0.908193]\n",
      "epoch:0 step:835 [D loss: 0.587050, acc.: 75.78%] [G loss: 0.884877]\n",
      "epoch:0 step:836 [D loss: 0.614433, acc.: 72.66%] [G loss: 0.863704]\n",
      "epoch:0 step:837 [D loss: 0.615309, acc.: 65.62%] [G loss: 0.902024]\n",
      "epoch:0 step:838 [D loss: 0.599472, acc.: 75.00%] [G loss: 0.950198]\n",
      "epoch:0 step:839 [D loss: 0.672877, acc.: 53.91%] [G loss: 0.866172]\n",
      "epoch:0 step:840 [D loss: 0.637346, acc.: 60.16%] [G loss: 0.870035]\n",
      "epoch:0 step:841 [D loss: 0.613388, acc.: 67.97%] [G loss: 0.860439]\n",
      "epoch:0 step:842 [D loss: 0.672334, acc.: 57.03%] [G loss: 0.853298]\n",
      "epoch:0 step:843 [D loss: 0.618228, acc.: 65.62%] [G loss: 0.901111]\n",
      "epoch:0 step:844 [D loss: 0.632278, acc.: 65.62%] [G loss: 0.880672]\n",
      "epoch:0 step:845 [D loss: 0.625226, acc.: 70.31%] [G loss: 0.884378]\n",
      "epoch:0 step:846 [D loss: 0.661446, acc.: 57.81%] [G loss: 0.826647]\n",
      "epoch:0 step:847 [D loss: 0.672591, acc.: 55.47%] [G loss: 0.824075]\n",
      "epoch:0 step:848 [D loss: 0.629363, acc.: 66.41%] [G loss: 0.836438]\n",
      "epoch:0 step:849 [D loss: 0.632983, acc.: 64.84%] [G loss: 0.829325]\n",
      "epoch:0 step:850 [D loss: 0.627786, acc.: 63.28%] [G loss: 0.854505]\n",
      "epoch:0 step:851 [D loss: 0.607602, acc.: 67.97%] [G loss: 0.860348]\n",
      "epoch:0 step:852 [D loss: 0.582790, acc.: 71.88%] [G loss: 0.869096]\n",
      "epoch:0 step:853 [D loss: 0.598357, acc.: 66.41%] [G loss: 0.966569]\n",
      "epoch:0 step:854 [D loss: 0.579852, acc.: 73.44%] [G loss: 0.963954]\n",
      "epoch:0 step:855 [D loss: 0.657176, acc.: 56.25%] [G loss: 0.852754]\n",
      "epoch:0 step:856 [D loss: 0.620691, acc.: 65.62%] [G loss: 0.823535]\n",
      "epoch:0 step:857 [D loss: 0.617295, acc.: 65.62%] [G loss: 0.879032]\n",
      "epoch:0 step:858 [D loss: 0.668831, acc.: 57.03%] [G loss: 0.884995]\n",
      "epoch:0 step:859 [D loss: 0.633514, acc.: 67.97%] [G loss: 0.872961]\n",
      "epoch:0 step:860 [D loss: 0.583289, acc.: 75.00%] [G loss: 0.907547]\n",
      "epoch:0 step:861 [D loss: 0.624805, acc.: 71.09%] [G loss: 0.898371]\n",
      "epoch:0 step:862 [D loss: 0.624433, acc.: 64.84%] [G loss: 0.883541]\n",
      "epoch:0 step:863 [D loss: 0.595452, acc.: 72.66%] [G loss: 0.905090]\n",
      "epoch:0 step:864 [D loss: 0.588170, acc.: 73.44%] [G loss: 0.846432]\n",
      "epoch:0 step:865 [D loss: 0.626255, acc.: 67.19%] [G loss: 0.815133]\n",
      "epoch:0 step:866 [D loss: 0.601633, acc.: 71.88%] [G loss: 0.836358]\n",
      "epoch:0 step:867 [D loss: 0.626809, acc.: 64.06%] [G loss: 0.852929]\n",
      "epoch:0 step:868 [D loss: 0.607399, acc.: 70.31%] [G loss: 0.864940]\n",
      "epoch:0 step:869 [D loss: 0.606665, acc.: 71.88%] [G loss: 0.854374]\n",
      "epoch:0 step:870 [D loss: 0.631797, acc.: 66.41%] [G loss: 0.839921]\n",
      "epoch:0 step:871 [D loss: 0.590646, acc.: 69.53%] [G loss: 0.847704]\n",
      "epoch:0 step:872 [D loss: 0.635566, acc.: 60.94%] [G loss: 0.926585]\n",
      "epoch:0 step:873 [D loss: 0.604942, acc.: 67.97%] [G loss: 1.000791]\n",
      "epoch:0 step:874 [D loss: 0.618820, acc.: 72.66%] [G loss: 0.915879]\n",
      "epoch:0 step:875 [D loss: 0.625060, acc.: 71.09%] [G loss: 0.889630]\n",
      "epoch:0 step:876 [D loss: 0.630222, acc.: 70.31%] [G loss: 0.882237]\n",
      "epoch:0 step:877 [D loss: 0.641497, acc.: 63.28%] [G loss: 0.884528]\n",
      "epoch:0 step:878 [D loss: 0.588335, acc.: 70.31%] [G loss: 0.923327]\n",
      "epoch:0 step:879 [D loss: 0.600392, acc.: 74.22%] [G loss: 0.909668]\n",
      "epoch:0 step:880 [D loss: 0.635721, acc.: 69.53%] [G loss: 0.881986]\n",
      "epoch:0 step:881 [D loss: 0.601351, acc.: 71.88%] [G loss: 0.880503]\n",
      "epoch:0 step:882 [D loss: 0.595222, acc.: 68.75%] [G loss: 0.916788]\n",
      "epoch:0 step:883 [D loss: 0.595299, acc.: 71.09%] [G loss: 0.979083]\n",
      "epoch:0 step:884 [D loss: 0.546350, acc.: 82.81%] [G loss: 0.963759]\n",
      "epoch:0 step:885 [D loss: 0.569026, acc.: 75.78%] [G loss: 0.955773]\n",
      "epoch:0 step:886 [D loss: 0.568175, acc.: 78.12%] [G loss: 0.934925]\n",
      "epoch:0 step:887 [D loss: 0.540639, acc.: 76.56%] [G loss: 0.976545]\n",
      "epoch:0 step:888 [D loss: 0.564186, acc.: 71.88%] [G loss: 0.956948]\n",
      "epoch:0 step:889 [D loss: 0.577147, acc.: 68.75%] [G loss: 0.942238]\n",
      "epoch:0 step:890 [D loss: 0.569953, acc.: 76.56%] [G loss: 0.942652]\n",
      "epoch:0 step:891 [D loss: 0.637899, acc.: 65.62%] [G loss: 0.846528]\n",
      "epoch:0 step:892 [D loss: 0.687666, acc.: 50.00%] [G loss: 0.836242]\n",
      "epoch:0 step:893 [D loss: 0.589362, acc.: 73.44%] [G loss: 0.911919]\n",
      "epoch:0 step:894 [D loss: 0.575344, acc.: 74.22%] [G loss: 0.932225]\n",
      "epoch:0 step:895 [D loss: 0.598608, acc.: 75.00%] [G loss: 0.921772]\n",
      "epoch:0 step:896 [D loss: 0.603349, acc.: 68.75%] [G loss: 0.942401]\n",
      "epoch:0 step:897 [D loss: 0.566136, acc.: 78.12%] [G loss: 0.960054]\n",
      "epoch:0 step:898 [D loss: 0.592898, acc.: 80.47%] [G loss: 0.920580]\n",
      "epoch:0 step:899 [D loss: 0.589564, acc.: 75.00%] [G loss: 0.912420]\n",
      "epoch:0 step:900 [D loss: 0.583493, acc.: 76.56%] [G loss: 0.931011]\n",
      "epoch:0 step:901 [D loss: 0.555136, acc.: 78.12%] [G loss: 0.968682]\n",
      "epoch:0 step:902 [D loss: 0.606014, acc.: 73.44%] [G loss: 0.969201]\n",
      "epoch:0 step:903 [D loss: 0.598875, acc.: 67.19%] [G loss: 1.000950]\n",
      "epoch:0 step:904 [D loss: 0.580029, acc.: 70.31%] [G loss: 0.988279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:905 [D loss: 0.612037, acc.: 64.84%] [G loss: 0.956602]\n",
      "epoch:0 step:906 [D loss: 0.588734, acc.: 64.84%] [G loss: 0.947575]\n",
      "epoch:0 step:907 [D loss: 0.604381, acc.: 62.50%] [G loss: 0.900955]\n",
      "epoch:0 step:908 [D loss: 0.583742, acc.: 74.22%] [G loss: 0.914899]\n",
      "epoch:0 step:909 [D loss: 0.558238, acc.: 75.78%] [G loss: 0.932097]\n",
      "epoch:0 step:910 [D loss: 0.607283, acc.: 64.84%] [G loss: 0.902175]\n",
      "epoch:0 step:911 [D loss: 0.590458, acc.: 64.84%] [G loss: 0.902846]\n",
      "epoch:0 step:912 [D loss: 0.561010, acc.: 74.22%] [G loss: 0.924509]\n",
      "epoch:0 step:913 [D loss: 0.587045, acc.: 72.66%] [G loss: 0.958055]\n",
      "epoch:0 step:914 [D loss: 0.568460, acc.: 76.56%] [G loss: 0.984837]\n",
      "epoch:0 step:915 [D loss: 0.644297, acc.: 64.84%] [G loss: 0.937996]\n",
      "epoch:0 step:916 [D loss: 0.624214, acc.: 62.50%] [G loss: 0.960990]\n",
      "epoch:0 step:917 [D loss: 0.606434, acc.: 72.66%] [G loss: 0.979423]\n",
      "epoch:0 step:918 [D loss: 0.575957, acc.: 72.66%] [G loss: 1.009743]\n",
      "epoch:0 step:919 [D loss: 0.609866, acc.: 65.62%] [G loss: 0.972386]\n",
      "epoch:0 step:920 [D loss: 0.729888, acc.: 43.75%] [G loss: 0.860833]\n",
      "epoch:0 step:921 [D loss: 0.597981, acc.: 70.31%] [G loss: 0.889602]\n",
      "epoch:0 step:922 [D loss: 0.640186, acc.: 59.38%] [G loss: 0.877371]\n",
      "epoch:0 step:923 [D loss: 0.557121, acc.: 80.47%] [G loss: 0.925849]\n",
      "epoch:0 step:924 [D loss: 0.556618, acc.: 79.69%] [G loss: 0.971153]\n",
      "epoch:0 step:925 [D loss: 0.530656, acc.: 83.59%] [G loss: 1.007583]\n",
      "epoch:0 step:926 [D loss: 0.524224, acc.: 80.47%] [G loss: 1.068519]\n",
      "epoch:0 step:927 [D loss: 0.546266, acc.: 78.91%] [G loss: 1.048414]\n",
      "epoch:0 step:928 [D loss: 0.650855, acc.: 65.62%] [G loss: 0.989255]\n",
      "epoch:0 step:929 [D loss: 0.507452, acc.: 81.25%] [G loss: 1.127377]\n",
      "epoch:0 step:930 [D loss: 0.567783, acc.: 71.88%] [G loss: 1.113058]\n",
      "epoch:0 step:931 [D loss: 0.689112, acc.: 59.38%] [G loss: 0.892193]\n",
      "epoch:0 step:932 [D loss: 0.640243, acc.: 59.38%] [G loss: 0.903602]\n",
      "epoch:0 step:933 [D loss: 0.580973, acc.: 67.97%] [G loss: 1.033609]\n",
      "epoch:0 step:934 [D loss: 0.590838, acc.: 74.22%] [G loss: 1.035939]\n",
      "epoch:0 step:935 [D loss: 0.533287, acc.: 82.03%] [G loss: 1.144056]\n",
      "epoch:0 step:936 [D loss: 0.522771, acc.: 81.25%] [G loss: 1.168386]\n",
      "epoch:0 step:937 [D loss: 0.646943, acc.: 63.28%] [G loss: 1.016425]\n",
      "epoch:1 step:938 [D loss: 0.671340, acc.: 56.25%] [G loss: 0.910242]\n",
      "epoch:1 step:939 [D loss: 0.668523, acc.: 55.47%] [G loss: 0.912754]\n",
      "epoch:1 step:940 [D loss: 0.646585, acc.: 57.81%] [G loss: 0.981419]\n",
      "epoch:1 step:941 [D loss: 0.633080, acc.: 69.53%] [G loss: 0.936443]\n",
      "epoch:1 step:942 [D loss: 0.589840, acc.: 71.88%] [G loss: 0.968996]\n",
      "epoch:1 step:943 [D loss: 0.586128, acc.: 72.66%] [G loss: 1.070270]\n",
      "epoch:1 step:944 [D loss: 0.585004, acc.: 78.12%] [G loss: 1.058618]\n",
      "epoch:1 step:945 [D loss: 0.602968, acc.: 73.44%] [G loss: 0.988994]\n",
      "epoch:1 step:946 [D loss: 0.611123, acc.: 66.41%] [G loss: 0.983021]\n",
      "epoch:1 step:947 [D loss: 0.648209, acc.: 57.03%] [G loss: 1.020872]\n",
      "epoch:1 step:948 [D loss: 0.628525, acc.: 61.72%] [G loss: 0.989293]\n",
      "epoch:1 step:949 [D loss: 0.609816, acc.: 59.38%] [G loss: 0.940524]\n",
      "epoch:1 step:950 [D loss: 0.625264, acc.: 63.28%] [G loss: 1.029804]\n",
      "epoch:1 step:951 [D loss: 0.630400, acc.: 67.97%] [G loss: 1.005029]\n",
      "epoch:1 step:952 [D loss: 0.625745, acc.: 64.84%] [G loss: 0.987644]\n",
      "epoch:1 step:953 [D loss: 0.616701, acc.: 70.31%] [G loss: 0.994050]\n",
      "epoch:1 step:954 [D loss: 0.652812, acc.: 60.16%] [G loss: 0.947510]\n",
      "epoch:1 step:955 [D loss: 0.629727, acc.: 70.31%] [G loss: 1.045725]\n",
      "epoch:1 step:956 [D loss: 0.636486, acc.: 67.19%] [G loss: 1.051391]\n",
      "epoch:1 step:957 [D loss: 0.650952, acc.: 63.28%] [G loss: 0.970989]\n",
      "epoch:1 step:958 [D loss: 0.584781, acc.: 70.31%] [G loss: 0.935255]\n",
      "epoch:1 step:959 [D loss: 0.511690, acc.: 88.28%] [G loss: 1.020987]\n",
      "epoch:1 step:960 [D loss: 0.646668, acc.: 65.62%] [G loss: 0.935067]\n",
      "epoch:1 step:961 [D loss: 0.645410, acc.: 64.06%] [G loss: 0.893524]\n",
      "epoch:1 step:962 [D loss: 0.615522, acc.: 67.97%] [G loss: 0.921381]\n",
      "epoch:1 step:963 [D loss: 0.592465, acc.: 72.66%] [G loss: 0.992738]\n",
      "epoch:1 step:964 [D loss: 0.578409, acc.: 75.00%] [G loss: 1.012922]\n",
      "epoch:1 step:965 [D loss: 0.597694, acc.: 67.97%] [G loss: 0.947116]\n",
      "epoch:1 step:966 [D loss: 0.587929, acc.: 74.22%] [G loss: 0.952243]\n",
      "epoch:1 step:967 [D loss: 0.603385, acc.: 81.25%] [G loss: 0.866195]\n",
      "epoch:1 step:968 [D loss: 0.587951, acc.: 71.88%] [G loss: 0.943857]\n",
      "epoch:1 step:969 [D loss: 0.571599, acc.: 75.78%] [G loss: 0.961745]\n",
      "epoch:1 step:970 [D loss: 0.586161, acc.: 67.19%] [G loss: 0.924019]\n",
      "epoch:1 step:971 [D loss: 0.586309, acc.: 71.09%] [G loss: 0.930549]\n",
      "epoch:1 step:972 [D loss: 0.586976, acc.: 74.22%] [G loss: 0.968832]\n",
      "epoch:1 step:973 [D loss: 0.560908, acc.: 79.69%] [G loss: 1.001132]\n",
      "epoch:1 step:974 [D loss: 0.634144, acc.: 65.62%] [G loss: 0.922621]\n",
      "epoch:1 step:975 [D loss: 0.646176, acc.: 60.94%] [G loss: 0.925966]\n",
      "epoch:1 step:976 [D loss: 0.588196, acc.: 74.22%] [G loss: 0.892950]\n",
      "epoch:1 step:977 [D loss: 0.534222, acc.: 78.91%] [G loss: 0.939149]\n",
      "epoch:1 step:978 [D loss: 0.608313, acc.: 71.09%] [G loss: 0.894421]\n",
      "epoch:1 step:979 [D loss: 0.596057, acc.: 73.44%] [G loss: 0.885657]\n",
      "epoch:1 step:980 [D loss: 0.599533, acc.: 71.88%] [G loss: 0.861600]\n",
      "epoch:1 step:981 [D loss: 0.624811, acc.: 64.06%] [G loss: 0.878878]\n",
      "epoch:1 step:982 [D loss: 0.595515, acc.: 73.44%] [G loss: 0.921234]\n",
      "epoch:1 step:983 [D loss: 0.554806, acc.: 83.59%] [G loss: 0.938673]\n",
      "epoch:1 step:984 [D loss: 0.590101, acc.: 80.47%] [G loss: 0.902339]\n",
      "epoch:1 step:985 [D loss: 0.595351, acc.: 76.56%] [G loss: 0.886109]\n",
      "epoch:1 step:986 [D loss: 0.606023, acc.: 71.88%] [G loss: 0.895143]\n",
      "epoch:1 step:987 [D loss: 0.606124, acc.: 67.19%] [G loss: 0.869599]\n",
      "epoch:1 step:988 [D loss: 0.574363, acc.: 76.56%] [G loss: 0.871744]\n",
      "epoch:1 step:989 [D loss: 0.599146, acc.: 71.09%] [G loss: 0.924057]\n",
      "epoch:1 step:990 [D loss: 0.605851, acc.: 71.09%] [G loss: 0.936402]\n",
      "epoch:1 step:991 [D loss: 0.592699, acc.: 69.53%] [G loss: 0.903104]\n",
      "epoch:1 step:992 [D loss: 0.601366, acc.: 71.88%] [G loss: 0.905181]\n",
      "epoch:1 step:993 [D loss: 0.638443, acc.: 63.28%] [G loss: 0.865339]\n",
      "epoch:1 step:994 [D loss: 0.629609, acc.: 62.50%] [G loss: 0.853728]\n",
      "epoch:1 step:995 [D loss: 0.564262, acc.: 79.69%] [G loss: 0.872324]\n",
      "epoch:1 step:996 [D loss: 0.593275, acc.: 71.88%] [G loss: 0.914242]\n",
      "epoch:1 step:997 [D loss: 0.596910, acc.: 73.44%] [G loss: 0.930837]\n",
      "epoch:1 step:998 [D loss: 0.597310, acc.: 69.53%] [G loss: 0.902074]\n",
      "epoch:1 step:999 [D loss: 0.614686, acc.: 64.06%] [G loss: 0.877383]\n",
      "epoch:1 step:1000 [D loss: 0.584559, acc.: 71.09%] [G loss: 0.916795]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 3.429018\n",
      "FID: 136.657959\n",
      "0 = 15.191205035591103\n",
      "1 = 0.19071024255155963\n",
      "2 = 0.9988999962806702\n",
      "3 = 0.9977999925613403\n",
      "4 = 1.0\n",
      "5 = 1.0\n",
      "6 = 0.9977999925613403\n",
      "7 = 13.29474591014387\n",
      "8 = 0.2090548102499908\n",
      "9 = 0.9898499846458435\n",
      "10 = 0.9800000190734863\n",
      "11 = 0.9997000098228455\n",
      "12 = 0.9996939897537231\n",
      "13 = 0.9800000190734863\n",
      "14 = 3.4290242195129395\n",
      "15 = 7.581937313079834\n",
      "16 = 0.4757923483848572\n",
      "17 = 3.429018259048462\n",
      "18 = 136.657958984375\n",
      "epoch:1 step:1001 [D loss: 0.604053, acc.: 72.66%] [G loss: 0.892919]\n",
      "epoch:1 step:1002 [D loss: 0.611060, acc.: 67.19%] [G loss: 0.878088]\n",
      "epoch:1 step:1003 [D loss: 0.598715, acc.: 68.75%] [G loss: 0.877149]\n",
      "epoch:1 step:1004 [D loss: 0.616710, acc.: 62.50%] [G loss: 0.860570]\n",
      "epoch:1 step:1005 [D loss: 0.621564, acc.: 67.19%] [G loss: 0.879415]\n",
      "epoch:1 step:1006 [D loss: 0.625981, acc.: 69.53%] [G loss: 0.849000]\n",
      "epoch:1 step:1007 [D loss: 0.649324, acc.: 55.47%] [G loss: 0.853392]\n",
      "epoch:1 step:1008 [D loss: 0.620470, acc.: 63.28%] [G loss: 0.869544]\n",
      "epoch:1 step:1009 [D loss: 0.603535, acc.: 69.53%] [G loss: 0.866393]\n",
      "epoch:1 step:1010 [D loss: 0.585167, acc.: 74.22%] [G loss: 0.902074]\n",
      "epoch:1 step:1011 [D loss: 0.615625, acc.: 69.53%] [G loss: 0.876530]\n",
      "epoch:1 step:1012 [D loss: 0.599573, acc.: 71.88%] [G loss: 0.906634]\n",
      "epoch:1 step:1013 [D loss: 0.624924, acc.: 62.50%] [G loss: 0.919525]\n",
      "epoch:1 step:1014 [D loss: 0.579771, acc.: 69.53%] [G loss: 0.940775]\n",
      "epoch:1 step:1015 [D loss: 0.682590, acc.: 56.25%] [G loss: 0.890531]\n",
      "epoch:1 step:1016 [D loss: 0.629202, acc.: 69.53%] [G loss: 0.873521]\n",
      "epoch:1 step:1017 [D loss: 0.649202, acc.: 63.28%] [G loss: 0.910355]\n",
      "epoch:1 step:1018 [D loss: 0.612023, acc.: 69.53%] [G loss: 0.967085]\n",
      "epoch:1 step:1019 [D loss: 0.609594, acc.: 68.75%] [G loss: 0.999316]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1020 [D loss: 0.613595, acc.: 67.97%] [G loss: 1.002585]\n",
      "epoch:1 step:1021 [D loss: 0.592819, acc.: 75.78%] [G loss: 0.964755]\n",
      "epoch:1 step:1022 [D loss: 0.614997, acc.: 72.66%] [G loss: 0.861288]\n",
      "epoch:1 step:1023 [D loss: 0.594951, acc.: 68.75%] [G loss: 0.911201]\n",
      "epoch:1 step:1024 [D loss: 0.561949, acc.: 75.78%] [G loss: 0.947770]\n",
      "epoch:1 step:1025 [D loss: 0.588707, acc.: 72.66%] [G loss: 0.963866]\n",
      "epoch:1 step:1026 [D loss: 0.614951, acc.: 64.06%] [G loss: 0.998050]\n",
      "epoch:1 step:1027 [D loss: 0.624095, acc.: 67.19%] [G loss: 0.910652]\n",
      "epoch:1 step:1028 [D loss: 0.618578, acc.: 64.06%] [G loss: 0.966386]\n",
      "epoch:1 step:1029 [D loss: 0.597559, acc.: 60.16%] [G loss: 0.940970]\n",
      "epoch:1 step:1030 [D loss: 0.599723, acc.: 67.19%] [G loss: 0.904583]\n",
      "epoch:1 step:1031 [D loss: 0.616042, acc.: 65.62%] [G loss: 0.900606]\n",
      "epoch:1 step:1032 [D loss: 0.606609, acc.: 70.31%] [G loss: 0.927747]\n",
      "epoch:1 step:1033 [D loss: 0.591264, acc.: 68.75%] [G loss: 0.947524]\n",
      "epoch:1 step:1034 [D loss: 0.593670, acc.: 70.31%] [G loss: 0.932809]\n",
      "epoch:1 step:1035 [D loss: 0.613722, acc.: 67.19%] [G loss: 0.929245]\n",
      "epoch:1 step:1036 [D loss: 0.612401, acc.: 69.53%] [G loss: 0.894867]\n",
      "epoch:1 step:1037 [D loss: 0.608771, acc.: 65.62%] [G loss: 0.946105]\n",
      "epoch:1 step:1038 [D loss: 0.623180, acc.: 69.53%] [G loss: 0.896546]\n",
      "epoch:1 step:1039 [D loss: 0.645721, acc.: 60.94%] [G loss: 0.855594]\n",
      "epoch:1 step:1040 [D loss: 0.605526, acc.: 66.41%] [G loss: 0.872706]\n",
      "epoch:1 step:1041 [D loss: 0.585246, acc.: 73.44%] [G loss: 0.879823]\n",
      "epoch:1 step:1042 [D loss: 0.609273, acc.: 71.88%] [G loss: 0.915358]\n",
      "epoch:1 step:1043 [D loss: 0.647177, acc.: 62.50%] [G loss: 0.908283]\n",
      "epoch:1 step:1044 [D loss: 0.628902, acc.: 62.50%] [G loss: 0.901308]\n",
      "epoch:1 step:1045 [D loss: 0.630437, acc.: 62.50%] [G loss: 0.851615]\n",
      "epoch:1 step:1046 [D loss: 0.608201, acc.: 65.62%] [G loss: 0.865385]\n",
      "epoch:1 step:1047 [D loss: 0.597586, acc.: 69.53%] [G loss: 0.866303]\n",
      "epoch:1 step:1048 [D loss: 0.635243, acc.: 60.94%] [G loss: 0.903832]\n",
      "epoch:1 step:1049 [D loss: 0.626063, acc.: 64.84%] [G loss: 0.888752]\n",
      "epoch:1 step:1050 [D loss: 0.649753, acc.: 65.62%] [G loss: 0.840487]\n",
      "epoch:1 step:1051 [D loss: 0.620569, acc.: 67.97%] [G loss: 0.895832]\n",
      "epoch:1 step:1052 [D loss: 0.629322, acc.: 70.31%] [G loss: 0.911478]\n",
      "epoch:1 step:1053 [D loss: 0.617352, acc.: 67.97%] [G loss: 0.899215]\n",
      "epoch:1 step:1054 [D loss: 0.586801, acc.: 75.00%] [G loss: 0.882992]\n",
      "epoch:1 step:1055 [D loss: 0.612191, acc.: 71.09%] [G loss: 0.886077]\n",
      "epoch:1 step:1056 [D loss: 0.588347, acc.: 75.78%] [G loss: 0.920777]\n",
      "epoch:1 step:1057 [D loss: 0.642041, acc.: 64.84%] [G loss: 0.851287]\n",
      "epoch:1 step:1058 [D loss: 0.594783, acc.: 73.44%] [G loss: 0.842282]\n",
      "epoch:1 step:1059 [D loss: 0.602194, acc.: 72.66%] [G loss: 0.848664]\n",
      "epoch:1 step:1060 [D loss: 0.597478, acc.: 64.06%] [G loss: 0.863660]\n",
      "epoch:1 step:1061 [D loss: 0.608167, acc.: 67.19%] [G loss: 0.858026]\n",
      "epoch:1 step:1062 [D loss: 0.612321, acc.: 64.84%] [G loss: 0.884095]\n",
      "epoch:1 step:1063 [D loss: 0.595239, acc.: 70.31%] [G loss: 0.871283]\n",
      "epoch:1 step:1064 [D loss: 0.539646, acc.: 89.84%] [G loss: 0.896713]\n",
      "epoch:1 step:1065 [D loss: 0.600575, acc.: 70.31%] [G loss: 0.850467]\n",
      "epoch:1 step:1066 [D loss: 0.642472, acc.: 59.38%] [G loss: 0.878882]\n",
      "epoch:1 step:1067 [D loss: 0.559520, acc.: 75.78%] [G loss: 0.871500]\n",
      "epoch:1 step:1068 [D loss: 0.556520, acc.: 75.78%] [G loss: 0.920697]\n",
      "epoch:1 step:1069 [D loss: 0.592010, acc.: 74.22%] [G loss: 0.938364]\n",
      "epoch:1 step:1070 [D loss: 0.640139, acc.: 63.28%] [G loss: 0.882021]\n",
      "epoch:1 step:1071 [D loss: 0.604814, acc.: 67.97%] [G loss: 0.911950]\n",
      "epoch:1 step:1072 [D loss: 0.579892, acc.: 75.78%] [G loss: 0.927943]\n",
      "epoch:1 step:1073 [D loss: 0.592814, acc.: 73.44%] [G loss: 0.892319]\n",
      "epoch:1 step:1074 [D loss: 0.625587, acc.: 66.41%] [G loss: 0.878814]\n",
      "epoch:1 step:1075 [D loss: 0.592083, acc.: 71.09%] [G loss: 0.894321]\n",
      "epoch:1 step:1076 [D loss: 0.634053, acc.: 64.06%] [G loss: 0.879921]\n",
      "epoch:1 step:1077 [D loss: 0.612159, acc.: 67.97%] [G loss: 0.884568]\n",
      "epoch:1 step:1078 [D loss: 0.608701, acc.: 67.19%] [G loss: 0.878268]\n",
      "epoch:1 step:1079 [D loss: 0.613444, acc.: 64.06%] [G loss: 0.903011]\n",
      "epoch:1 step:1080 [D loss: 0.632563, acc.: 66.41%] [G loss: 0.906778]\n",
      "epoch:1 step:1081 [D loss: 0.607929, acc.: 69.53%] [G loss: 0.917917]\n",
      "epoch:1 step:1082 [D loss: 0.621953, acc.: 67.19%] [G loss: 0.915138]\n",
      "epoch:1 step:1083 [D loss: 0.601807, acc.: 70.31%] [G loss: 0.909206]\n",
      "epoch:1 step:1084 [D loss: 0.624130, acc.: 67.97%] [G loss: 0.905654]\n",
      "epoch:1 step:1085 [D loss: 0.600561, acc.: 71.88%] [G loss: 0.901171]\n",
      "epoch:1 step:1086 [D loss: 0.596300, acc.: 69.53%] [G loss: 0.969350]\n",
      "epoch:1 step:1087 [D loss: 0.623955, acc.: 71.09%] [G loss: 0.895299]\n",
      "epoch:1 step:1088 [D loss: 0.597917, acc.: 71.88%] [G loss: 0.870316]\n",
      "epoch:1 step:1089 [D loss: 0.571194, acc.: 75.00%] [G loss: 0.887817]\n",
      "epoch:1 step:1090 [D loss: 0.621087, acc.: 62.50%] [G loss: 0.884054]\n",
      "epoch:1 step:1091 [D loss: 0.597828, acc.: 69.53%] [G loss: 0.905655]\n",
      "epoch:1 step:1092 [D loss: 0.594708, acc.: 69.53%] [G loss: 0.913821]\n",
      "epoch:1 step:1093 [D loss: 0.604554, acc.: 63.28%] [G loss: 0.923974]\n",
      "epoch:1 step:1094 [D loss: 0.589264, acc.: 74.22%] [G loss: 0.936280]\n",
      "epoch:1 step:1095 [D loss: 0.606370, acc.: 67.19%] [G loss: 0.913446]\n",
      "epoch:1 step:1096 [D loss: 0.575585, acc.: 71.88%] [G loss: 0.947655]\n",
      "epoch:1 step:1097 [D loss: 0.614728, acc.: 70.31%] [G loss: 0.894183]\n",
      "epoch:1 step:1098 [D loss: 0.593946, acc.: 69.53%] [G loss: 0.917415]\n",
      "epoch:1 step:1099 [D loss: 0.531436, acc.: 78.12%] [G loss: 0.960186]\n",
      "epoch:1 step:1100 [D loss: 0.532876, acc.: 81.25%] [G loss: 1.027457]\n",
      "epoch:1 step:1101 [D loss: 0.551555, acc.: 75.78%] [G loss: 1.016040]\n",
      "epoch:1 step:1102 [D loss: 0.571893, acc.: 73.44%] [G loss: 0.994134]\n",
      "epoch:1 step:1103 [D loss: 0.570197, acc.: 71.88%] [G loss: 0.985290]\n",
      "epoch:1 step:1104 [D loss: 0.629687, acc.: 67.97%] [G loss: 0.966903]\n",
      "epoch:1 step:1105 [D loss: 0.572159, acc.: 71.88%] [G loss: 0.924555]\n",
      "epoch:1 step:1106 [D loss: 0.569935, acc.: 76.56%] [G loss: 0.944083]\n",
      "epoch:1 step:1107 [D loss: 0.548813, acc.: 81.25%] [G loss: 0.968398]\n",
      "epoch:1 step:1108 [D loss: 0.568973, acc.: 75.78%] [G loss: 1.001430]\n",
      "epoch:1 step:1109 [D loss: 0.582047, acc.: 71.88%] [G loss: 0.991400]\n",
      "epoch:1 step:1110 [D loss: 0.554852, acc.: 81.25%] [G loss: 0.932224]\n",
      "epoch:1 step:1111 [D loss: 0.581374, acc.: 75.78%] [G loss: 0.930209]\n",
      "epoch:1 step:1112 [D loss: 0.557774, acc.: 74.22%] [G loss: 0.943093]\n",
      "epoch:1 step:1113 [D loss: 0.570912, acc.: 75.78%] [G loss: 0.916512]\n",
      "epoch:1 step:1114 [D loss: 0.588332, acc.: 74.22%] [G loss: 0.935482]\n",
      "epoch:1 step:1115 [D loss: 0.570944, acc.: 77.34%] [G loss: 0.955352]\n",
      "epoch:1 step:1116 [D loss: 0.605006, acc.: 71.88%] [G loss: 0.918817]\n",
      "epoch:1 step:1117 [D loss: 0.598120, acc.: 71.09%] [G loss: 0.913840]\n",
      "epoch:1 step:1118 [D loss: 0.588011, acc.: 70.31%] [G loss: 0.933314]\n",
      "epoch:1 step:1119 [D loss: 0.613346, acc.: 71.88%] [G loss: 0.937036]\n",
      "epoch:1 step:1120 [D loss: 0.606093, acc.: 67.19%] [G loss: 0.916930]\n",
      "epoch:1 step:1121 [D loss: 0.574321, acc.: 77.34%] [G loss: 0.895460]\n",
      "epoch:1 step:1122 [D loss: 0.603491, acc.: 71.09%] [G loss: 0.873548]\n",
      "epoch:1 step:1123 [D loss: 0.583128, acc.: 74.22%] [G loss: 0.901618]\n",
      "epoch:1 step:1124 [D loss: 0.621744, acc.: 64.06%] [G loss: 0.877492]\n",
      "epoch:1 step:1125 [D loss: 0.577957, acc.: 72.66%] [G loss: 0.900829]\n",
      "epoch:1 step:1126 [D loss: 0.610153, acc.: 73.44%] [G loss: 0.919451]\n",
      "epoch:1 step:1127 [D loss: 0.531054, acc.: 83.59%] [G loss: 0.931970]\n",
      "epoch:1 step:1128 [D loss: 0.594699, acc.: 72.66%] [G loss: 0.939205]\n",
      "epoch:1 step:1129 [D loss: 0.594165, acc.: 73.44%] [G loss: 0.947555]\n",
      "epoch:1 step:1130 [D loss: 0.612235, acc.: 68.75%] [G loss: 0.941149]\n",
      "epoch:1 step:1131 [D loss: 0.562406, acc.: 75.00%] [G loss: 0.964717]\n",
      "epoch:1 step:1132 [D loss: 0.594273, acc.: 70.31%] [G loss: 1.021525]\n",
      "epoch:1 step:1133 [D loss: 0.594750, acc.: 72.66%] [G loss: 0.977133]\n",
      "epoch:1 step:1134 [D loss: 0.574261, acc.: 75.78%] [G loss: 0.977229]\n",
      "epoch:1 step:1135 [D loss: 0.595833, acc.: 70.31%] [G loss: 0.965730]\n",
      "epoch:1 step:1136 [D loss: 0.588152, acc.: 71.88%] [G loss: 0.990583]\n",
      "epoch:1 step:1137 [D loss: 0.659869, acc.: 60.94%] [G loss: 0.925477]\n",
      "epoch:1 step:1138 [D loss: 0.611985, acc.: 69.53%] [G loss: 0.902174]\n",
      "epoch:1 step:1139 [D loss: 0.604421, acc.: 69.53%] [G loss: 0.909168]\n",
      "epoch:1 step:1140 [D loss: 0.669237, acc.: 53.12%] [G loss: 0.895683]\n",
      "epoch:1 step:1141 [D loss: 0.652056, acc.: 63.28%] [G loss: 0.858258]\n",
      "epoch:1 step:1142 [D loss: 0.570987, acc.: 74.22%] [G loss: 0.960070]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1143 [D loss: 0.591692, acc.: 69.53%] [G loss: 0.968702]\n",
      "epoch:1 step:1144 [D loss: 0.590653, acc.: 71.88%] [G loss: 1.004422]\n",
      "epoch:1 step:1145 [D loss: 0.582098, acc.: 71.09%] [G loss: 0.988801]\n",
      "epoch:1 step:1146 [D loss: 0.584902, acc.: 75.00%] [G loss: 0.998880]\n",
      "epoch:1 step:1147 [D loss: 0.639625, acc.: 62.50%] [G loss: 0.910485]\n",
      "epoch:1 step:1148 [D loss: 0.621746, acc.: 67.19%] [G loss: 0.905531]\n",
      "epoch:1 step:1149 [D loss: 0.592256, acc.: 70.31%] [G loss: 0.926191]\n",
      "epoch:1 step:1150 [D loss: 0.591637, acc.: 67.97%] [G loss: 0.975868]\n",
      "epoch:1 step:1151 [D loss: 0.665303, acc.: 59.38%] [G loss: 0.930875]\n",
      "epoch:1 step:1152 [D loss: 0.666992, acc.: 57.03%] [G loss: 0.923337]\n",
      "epoch:1 step:1153 [D loss: 0.653175, acc.: 61.72%] [G loss: 0.947200]\n",
      "epoch:1 step:1154 [D loss: 0.592634, acc.: 74.22%] [G loss: 0.972536]\n",
      "epoch:1 step:1155 [D loss: 0.564799, acc.: 82.03%] [G loss: 1.013597]\n",
      "epoch:1 step:1156 [D loss: 0.619742, acc.: 64.06%] [G loss: 0.999864]\n",
      "epoch:1 step:1157 [D loss: 0.647215, acc.: 58.59%] [G loss: 0.968490]\n",
      "epoch:1 step:1158 [D loss: 0.536409, acc.: 80.47%] [G loss: 0.962293]\n",
      "epoch:1 step:1159 [D loss: 0.563926, acc.: 73.44%] [G loss: 1.016604]\n",
      "epoch:1 step:1160 [D loss: 0.536608, acc.: 77.34%] [G loss: 1.023164]\n",
      "epoch:1 step:1161 [D loss: 0.635192, acc.: 62.50%] [G loss: 0.971808]\n",
      "epoch:1 step:1162 [D loss: 0.659325, acc.: 58.59%] [G loss: 0.948325]\n",
      "epoch:1 step:1163 [D loss: 0.600278, acc.: 71.88%] [G loss: 0.986414]\n",
      "epoch:1 step:1164 [D loss: 0.590979, acc.: 78.12%] [G loss: 0.936743]\n",
      "epoch:1 step:1165 [D loss: 0.576130, acc.: 70.31%] [G loss: 0.934699]\n",
      "epoch:1 step:1166 [D loss: 0.611258, acc.: 73.44%] [G loss: 0.928091]\n",
      "epoch:1 step:1167 [D loss: 0.538733, acc.: 77.34%] [G loss: 0.991826]\n",
      "epoch:1 step:1168 [D loss: 0.587691, acc.: 74.22%] [G loss: 1.037071]\n",
      "epoch:1 step:1169 [D loss: 0.515594, acc.: 81.25%] [G loss: 1.061120]\n",
      "epoch:1 step:1170 [D loss: 0.702939, acc.: 55.47%] [G loss: 0.955972]\n",
      "epoch:1 step:1171 [D loss: 0.643624, acc.: 60.16%] [G loss: 0.911515]\n",
      "epoch:1 step:1172 [D loss: 0.613620, acc.: 63.28%] [G loss: 0.938345]\n",
      "epoch:1 step:1173 [D loss: 0.580648, acc.: 76.56%] [G loss: 0.952124]\n",
      "epoch:1 step:1174 [D loss: 0.585988, acc.: 75.00%] [G loss: 0.957095]\n",
      "epoch:1 step:1175 [D loss: 0.631565, acc.: 62.50%] [G loss: 0.955580]\n",
      "epoch:1 step:1176 [D loss: 0.604733, acc.: 68.75%] [G loss: 0.947326]\n",
      "epoch:1 step:1177 [D loss: 0.584171, acc.: 73.44%] [G loss: 0.958562]\n",
      "epoch:1 step:1178 [D loss: 0.600196, acc.: 65.62%] [G loss: 0.944259]\n",
      "epoch:1 step:1179 [D loss: 0.608436, acc.: 64.06%] [G loss: 0.946743]\n",
      "epoch:1 step:1180 [D loss: 0.597848, acc.: 64.06%] [G loss: 0.958976]\n",
      "epoch:1 step:1181 [D loss: 0.582047, acc.: 71.09%] [G loss: 0.968477]\n",
      "epoch:1 step:1182 [D loss: 0.596758, acc.: 67.19%] [G loss: 0.979337]\n",
      "epoch:1 step:1183 [D loss: 0.641940, acc.: 57.81%] [G loss: 0.970207]\n",
      "epoch:1 step:1184 [D loss: 0.635854, acc.: 62.50%] [G loss: 0.960567]\n",
      "epoch:1 step:1185 [D loss: 0.618994, acc.: 64.84%] [G loss: 0.897320]\n",
      "epoch:1 step:1186 [D loss: 0.641312, acc.: 64.84%] [G loss: 0.884095]\n",
      "epoch:1 step:1187 [D loss: 0.675214, acc.: 56.25%] [G loss: 0.941139]\n",
      "epoch:1 step:1188 [D loss: 0.635786, acc.: 64.84%] [G loss: 0.936274]\n",
      "epoch:1 step:1189 [D loss: 0.608424, acc.: 64.06%] [G loss: 0.878281]\n",
      "epoch:1 step:1190 [D loss: 0.587253, acc.: 67.19%] [G loss: 0.946401]\n",
      "epoch:1 step:1191 [D loss: 0.540317, acc.: 81.25%] [G loss: 0.967380]\n",
      "epoch:1 step:1192 [D loss: 0.591685, acc.: 70.31%] [G loss: 0.976715]\n",
      "epoch:1 step:1193 [D loss: 0.562711, acc.: 77.34%] [G loss: 0.990669]\n",
      "epoch:1 step:1194 [D loss: 0.562162, acc.: 80.47%] [G loss: 0.991467]\n",
      "epoch:1 step:1195 [D loss: 0.563604, acc.: 78.12%] [G loss: 0.981631]\n",
      "epoch:1 step:1196 [D loss: 0.547575, acc.: 78.12%] [G loss: 1.007780]\n",
      "epoch:1 step:1197 [D loss: 0.562687, acc.: 76.56%] [G loss: 0.985039]\n",
      "epoch:1 step:1198 [D loss: 0.597713, acc.: 69.53%] [G loss: 1.004092]\n",
      "epoch:1 step:1199 [D loss: 0.557824, acc.: 78.12%] [G loss: 1.013533]\n",
      "epoch:1 step:1200 [D loss: 0.688923, acc.: 58.59%] [G loss: 0.924013]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 3.537125\n",
      "FID: 127.789162\n",
      "0 = 14.563361584329591\n",
      "1 = 0.16898094198449506\n",
      "2 = 0.9974499940872192\n",
      "3 = 0.9948999881744385\n",
      "4 = 1.0\n",
      "5 = 1.0\n",
      "6 = 0.9948999881744385\n",
      "7 = 12.939964370596446\n",
      "8 = 0.2190239417170828\n",
      "9 = 0.983299970626831\n",
      "10 = 0.9696000218391418\n",
      "11 = 0.996999979019165\n",
      "12 = 0.9969154596328735\n",
      "13 = 0.9696000218391418\n",
      "14 = 3.537135601043701\n",
      "15 = 8.106955528259277\n",
      "16 = 0.42891573905944824\n",
      "17 = 3.5371246337890625\n",
      "18 = 127.7891616821289\n",
      "epoch:1 step:1201 [D loss: 0.600852, acc.: 70.31%] [G loss: 1.000568]\n",
      "epoch:1 step:1202 [D loss: 0.600244, acc.: 70.31%] [G loss: 0.930741]\n",
      "epoch:1 step:1203 [D loss: 0.583749, acc.: 75.78%] [G loss: 0.929233]\n",
      "epoch:1 step:1204 [D loss: 0.568611, acc.: 79.69%] [G loss: 0.931160]\n",
      "epoch:1 step:1205 [D loss: 0.586629, acc.: 72.66%] [G loss: 0.925552]\n",
      "epoch:1 step:1206 [D loss: 0.614559, acc.: 71.88%] [G loss: 0.891435]\n",
      "epoch:1 step:1207 [D loss: 0.592856, acc.: 72.66%] [G loss: 0.906421]\n",
      "epoch:1 step:1208 [D loss: 0.578687, acc.: 70.31%] [G loss: 0.927756]\n",
      "epoch:1 step:1209 [D loss: 0.587957, acc.: 69.53%] [G loss: 0.958091]\n",
      "epoch:1 step:1210 [D loss: 0.552921, acc.: 75.78%] [G loss: 0.916210]\n",
      "epoch:1 step:1211 [D loss: 0.559903, acc.: 79.69%] [G loss: 0.925877]\n",
      "epoch:1 step:1212 [D loss: 0.645159, acc.: 60.16%] [G loss: 0.913543]\n",
      "epoch:1 step:1213 [D loss: 0.609338, acc.: 68.75%] [G loss: 0.882445]\n",
      "epoch:1 step:1214 [D loss: 0.633522, acc.: 64.06%] [G loss: 0.929747]\n",
      "epoch:1 step:1215 [D loss: 0.634058, acc.: 63.28%] [G loss: 0.920564]\n",
      "epoch:1 step:1216 [D loss: 0.579702, acc.: 73.44%] [G loss: 0.970267]\n",
      "epoch:1 step:1217 [D loss: 0.624165, acc.: 68.75%] [G loss: 0.937860]\n",
      "epoch:1 step:1218 [D loss: 0.643893, acc.: 57.03%] [G loss: 0.930306]\n",
      "epoch:1 step:1219 [D loss: 0.657755, acc.: 60.94%] [G loss: 0.913770]\n",
      "epoch:1 step:1220 [D loss: 0.628321, acc.: 60.16%] [G loss: 0.877768]\n",
      "epoch:1 step:1221 [D loss: 0.595772, acc.: 68.75%] [G loss: 0.874763]\n",
      "epoch:1 step:1222 [D loss: 0.586874, acc.: 69.53%] [G loss: 0.926454]\n",
      "epoch:1 step:1223 [D loss: 0.597529, acc.: 70.31%] [G loss: 0.961131]\n",
      "epoch:1 step:1224 [D loss: 0.616467, acc.: 66.41%] [G loss: 0.924076]\n",
      "epoch:1 step:1225 [D loss: 0.644845, acc.: 57.03%] [G loss: 0.938525]\n",
      "epoch:1 step:1226 [D loss: 0.648843, acc.: 60.16%] [G loss: 0.915676]\n",
      "epoch:1 step:1227 [D loss: 0.638005, acc.: 61.72%] [G loss: 1.006270]\n",
      "epoch:1 step:1228 [D loss: 0.654208, acc.: 63.28%] [G loss: 0.977826]\n",
      "epoch:1 step:1229 [D loss: 0.605616, acc.: 65.62%] [G loss: 0.956391]\n",
      "epoch:1 step:1230 [D loss: 0.601273, acc.: 69.53%] [G loss: 1.033285]\n",
      "epoch:1 step:1231 [D loss: 0.604464, acc.: 70.31%] [G loss: 0.985075]\n",
      "epoch:1 step:1232 [D loss: 0.597174, acc.: 72.66%] [G loss: 0.959190]\n",
      "epoch:1 step:1233 [D loss: 0.553805, acc.: 78.91%] [G loss: 1.028066]\n",
      "epoch:1 step:1234 [D loss: 0.608544, acc.: 69.53%] [G loss: 0.964393]\n",
      "epoch:1 step:1235 [D loss: 0.636218, acc.: 61.72%] [G loss: 0.978605]\n",
      "epoch:1 step:1236 [D loss: 0.600128, acc.: 69.53%] [G loss: 0.927728]\n",
      "epoch:1 step:1237 [D loss: 0.595752, acc.: 72.66%] [G loss: 0.911910]\n",
      "epoch:1 step:1238 [D loss: 0.618850, acc.: 64.84%] [G loss: 0.873572]\n",
      "epoch:1 step:1239 [D loss: 0.627361, acc.: 64.84%] [G loss: 0.927203]\n",
      "epoch:1 step:1240 [D loss: 0.615164, acc.: 69.53%] [G loss: 0.938154]\n",
      "epoch:1 step:1241 [D loss: 0.557808, acc.: 80.47%] [G loss: 0.972497]\n",
      "epoch:1 step:1242 [D loss: 0.613934, acc.: 72.66%] [G loss: 0.949378]\n",
      "epoch:1 step:1243 [D loss: 0.572368, acc.: 75.78%] [G loss: 0.930807]\n",
      "epoch:1 step:1244 [D loss: 0.545798, acc.: 76.56%] [G loss: 0.965688]\n",
      "epoch:1 step:1245 [D loss: 0.536803, acc.: 78.91%] [G loss: 0.997811]\n",
      "epoch:1 step:1246 [D loss: 0.565494, acc.: 78.12%] [G loss: 1.043661]\n",
      "epoch:1 step:1247 [D loss: 0.549303, acc.: 79.69%] [G loss: 1.007215]\n",
      "epoch:1 step:1248 [D loss: 0.570736, acc.: 73.44%] [G loss: 1.037077]\n",
      "epoch:1 step:1249 [D loss: 0.545983, acc.: 79.69%] [G loss: 0.978655]\n",
      "epoch:1 step:1250 [D loss: 0.549660, acc.: 76.56%] [G loss: 1.008912]\n",
      "epoch:1 step:1251 [D loss: 0.532719, acc.: 79.69%] [G loss: 1.104300]\n",
      "epoch:1 step:1252 [D loss: 0.533827, acc.: 79.69%] [G loss: 1.062306]\n",
      "epoch:1 step:1253 [D loss: 0.698573, acc.: 61.72%] [G loss: 0.954179]\n",
      "epoch:1 step:1254 [D loss: 0.645758, acc.: 61.72%] [G loss: 0.911374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1255 [D loss: 0.649899, acc.: 57.03%] [G loss: 0.934665]\n",
      "epoch:1 step:1256 [D loss: 0.570571, acc.: 76.56%] [G loss: 0.931208]\n",
      "epoch:1 step:1257 [D loss: 0.568904, acc.: 77.34%] [G loss: 1.038047]\n",
      "epoch:1 step:1258 [D loss: 0.572831, acc.: 75.78%] [G loss: 0.991798]\n",
      "epoch:1 step:1259 [D loss: 0.562842, acc.: 80.47%] [G loss: 0.959125]\n",
      "epoch:1 step:1260 [D loss: 0.602973, acc.: 71.09%] [G loss: 0.953811]\n",
      "epoch:1 step:1261 [D loss: 0.597086, acc.: 70.31%] [G loss: 0.953300]\n",
      "epoch:1 step:1262 [D loss: 0.573747, acc.: 75.00%] [G loss: 0.972832]\n",
      "epoch:1 step:1263 [D loss: 0.557054, acc.: 78.91%] [G loss: 0.985885]\n",
      "epoch:1 step:1264 [D loss: 0.564849, acc.: 77.34%] [G loss: 0.982870]\n",
      "epoch:1 step:1265 [D loss: 0.552607, acc.: 75.78%] [G loss: 1.010132]\n",
      "epoch:1 step:1266 [D loss: 0.610519, acc.: 69.53%] [G loss: 0.994877]\n",
      "epoch:1 step:1267 [D loss: 0.618310, acc.: 64.06%] [G loss: 0.991819]\n",
      "epoch:1 step:1268 [D loss: 0.574117, acc.: 73.44%] [G loss: 1.029733]\n",
      "epoch:1 step:1269 [D loss: 0.590396, acc.: 68.75%] [G loss: 0.945182]\n",
      "epoch:1 step:1270 [D loss: 0.568112, acc.: 74.22%] [G loss: 0.966386]\n",
      "epoch:1 step:1271 [D loss: 0.601466, acc.: 71.88%] [G loss: 0.911099]\n",
      "epoch:1 step:1272 [D loss: 0.567140, acc.: 72.66%] [G loss: 1.009302]\n",
      "epoch:1 step:1273 [D loss: 0.562987, acc.: 78.91%] [G loss: 1.002383]\n",
      "epoch:1 step:1274 [D loss: 0.550251, acc.: 78.12%] [G loss: 0.995152]\n",
      "epoch:1 step:1275 [D loss: 0.581070, acc.: 72.66%] [G loss: 0.956197]\n",
      "epoch:1 step:1276 [D loss: 0.570883, acc.: 77.34%] [G loss: 0.938612]\n",
      "epoch:1 step:1277 [D loss: 0.569894, acc.: 78.91%] [G loss: 0.967509]\n",
      "epoch:1 step:1278 [D loss: 0.618011, acc.: 67.19%] [G loss: 0.923986]\n",
      "epoch:1 step:1279 [D loss: 0.631722, acc.: 63.28%] [G loss: 0.908944]\n",
      "epoch:1 step:1280 [D loss: 0.530875, acc.: 82.81%] [G loss: 0.977513]\n",
      "epoch:1 step:1281 [D loss: 0.512337, acc.: 86.72%] [G loss: 1.015990]\n",
      "epoch:1 step:1282 [D loss: 0.583720, acc.: 71.09%] [G loss: 0.983732]\n",
      "epoch:1 step:1283 [D loss: 0.571658, acc.: 79.69%] [G loss: 0.894835]\n",
      "epoch:1 step:1284 [D loss: 0.565335, acc.: 72.66%] [G loss: 0.957339]\n",
      "epoch:1 step:1285 [D loss: 0.648050, acc.: 62.50%] [G loss: 0.951470]\n",
      "epoch:1 step:1286 [D loss: 0.678207, acc.: 56.25%] [G loss: 0.889489]\n",
      "epoch:1 step:1287 [D loss: 0.562155, acc.: 77.34%] [G loss: 0.939063]\n",
      "epoch:1 step:1288 [D loss: 0.578765, acc.: 75.78%] [G loss: 0.927544]\n",
      "epoch:1 step:1289 [D loss: 0.592394, acc.: 67.97%] [G loss: 0.966564]\n",
      "epoch:1 step:1290 [D loss: 0.556126, acc.: 78.91%] [G loss: 1.044084]\n",
      "epoch:1 step:1291 [D loss: 0.542051, acc.: 72.66%] [G loss: 1.054128]\n",
      "epoch:1 step:1292 [D loss: 0.554032, acc.: 76.56%] [G loss: 1.135045]\n",
      "epoch:1 step:1293 [D loss: 0.607777, acc.: 71.09%] [G loss: 1.026698]\n",
      "epoch:1 step:1294 [D loss: 0.548502, acc.: 74.22%] [G loss: 1.056010]\n",
      "epoch:1 step:1295 [D loss: 0.570498, acc.: 74.22%] [G loss: 1.018736]\n",
      "epoch:1 step:1296 [D loss: 0.544916, acc.: 79.69%] [G loss: 0.994528]\n",
      "epoch:1 step:1297 [D loss: 0.546258, acc.: 75.78%] [G loss: 0.996559]\n",
      "epoch:1 step:1298 [D loss: 0.570005, acc.: 72.66%] [G loss: 1.004408]\n",
      "epoch:1 step:1299 [D loss: 0.582411, acc.: 70.31%] [G loss: 0.972142]\n",
      "epoch:1 step:1300 [D loss: 0.573803, acc.: 82.03%] [G loss: 0.924973]\n",
      "epoch:1 step:1301 [D loss: 0.581940, acc.: 71.88%] [G loss: 0.980865]\n",
      "epoch:1 step:1302 [D loss: 0.603277, acc.: 64.84%] [G loss: 1.044811]\n",
      "epoch:1 step:1303 [D loss: 0.556881, acc.: 76.56%] [G loss: 1.068836]\n",
      "epoch:1 step:1304 [D loss: 0.573780, acc.: 75.78%] [G loss: 1.004768]\n",
      "epoch:1 step:1305 [D loss: 0.582388, acc.: 75.00%] [G loss: 0.966328]\n",
      "epoch:1 step:1306 [D loss: 0.602907, acc.: 67.19%] [G loss: 0.926628]\n",
      "epoch:1 step:1307 [D loss: 0.603280, acc.: 68.75%] [G loss: 0.950865]\n",
      "epoch:1 step:1308 [D loss: 0.556470, acc.: 81.25%] [G loss: 0.975856]\n",
      "epoch:1 step:1309 [D loss: 0.605396, acc.: 67.19%] [G loss: 0.911722]\n",
      "epoch:1 step:1310 [D loss: 0.610080, acc.: 70.31%] [G loss: 0.928625]\n",
      "epoch:1 step:1311 [D loss: 0.552400, acc.: 77.34%] [G loss: 0.960893]\n",
      "epoch:1 step:1312 [D loss: 0.587087, acc.: 69.53%] [G loss: 0.960452]\n",
      "epoch:1 step:1313 [D loss: 0.644868, acc.: 58.59%] [G loss: 0.960688]\n",
      "epoch:1 step:1314 [D loss: 0.597811, acc.: 70.31%] [G loss: 0.952590]\n",
      "epoch:1 step:1315 [D loss: 0.547040, acc.: 75.78%] [G loss: 0.993584]\n",
      "epoch:1 step:1316 [D loss: 0.608111, acc.: 74.22%] [G loss: 0.980643]\n",
      "epoch:1 step:1317 [D loss: 0.594204, acc.: 71.88%] [G loss: 0.934834]\n",
      "epoch:1 step:1318 [D loss: 0.540762, acc.: 78.91%] [G loss: 1.020510]\n",
      "epoch:1 step:1319 [D loss: 0.618814, acc.: 65.62%] [G loss: 0.932563]\n",
      "epoch:1 step:1320 [D loss: 0.571856, acc.: 77.34%] [G loss: 0.950158]\n",
      "epoch:1 step:1321 [D loss: 0.594289, acc.: 71.88%] [G loss: 0.928584]\n",
      "epoch:1 step:1322 [D loss: 0.610703, acc.: 62.50%] [G loss: 0.994464]\n",
      "epoch:1 step:1323 [D loss: 0.602039, acc.: 71.09%] [G loss: 0.989391]\n",
      "epoch:1 step:1324 [D loss: 0.609396, acc.: 63.28%] [G loss: 0.963268]\n",
      "epoch:1 step:1325 [D loss: 0.577714, acc.: 77.34%] [G loss: 0.976811]\n",
      "epoch:1 step:1326 [D loss: 0.611984, acc.: 68.75%] [G loss: 0.981544]\n",
      "epoch:1 step:1327 [D loss: 0.624160, acc.: 69.53%] [G loss: 1.011749]\n",
      "epoch:1 step:1328 [D loss: 0.580598, acc.: 73.44%] [G loss: 0.983643]\n",
      "epoch:1 step:1329 [D loss: 0.563704, acc.: 78.12%] [G loss: 0.953450]\n",
      "epoch:1 step:1330 [D loss: 0.588020, acc.: 74.22%] [G loss: 0.991783]\n",
      "epoch:1 step:1331 [D loss: 0.532758, acc.: 82.81%] [G loss: 0.963908]\n",
      "epoch:1 step:1332 [D loss: 0.554168, acc.: 76.56%] [G loss: 0.955439]\n",
      "epoch:1 step:1333 [D loss: 0.626182, acc.: 67.19%] [G loss: 0.936084]\n",
      "epoch:1 step:1334 [D loss: 0.491636, acc.: 87.50%] [G loss: 1.023988]\n",
      "epoch:1 step:1335 [D loss: 0.499455, acc.: 82.03%] [G loss: 1.073401]\n",
      "epoch:1 step:1336 [D loss: 0.509757, acc.: 81.25%] [G loss: 1.092412]\n",
      "epoch:1 step:1337 [D loss: 0.594993, acc.: 72.66%] [G loss: 0.948024]\n",
      "epoch:1 step:1338 [D loss: 0.587428, acc.: 65.62%] [G loss: 0.904064]\n",
      "epoch:1 step:1339 [D loss: 0.507111, acc.: 78.12%] [G loss: 0.991444]\n",
      "epoch:1 step:1340 [D loss: 0.520875, acc.: 81.25%] [G loss: 1.103679]\n",
      "epoch:1 step:1341 [D loss: 0.597080, acc.: 72.66%] [G loss: 1.042343]\n",
      "epoch:1 step:1342 [D loss: 0.608008, acc.: 64.84%] [G loss: 1.037241]\n",
      "epoch:1 step:1343 [D loss: 0.556380, acc.: 72.66%] [G loss: 1.028574]\n",
      "epoch:1 step:1344 [D loss: 0.571724, acc.: 74.22%] [G loss: 1.025867]\n",
      "epoch:1 step:1345 [D loss: 0.615582, acc.: 70.31%] [G loss: 1.023135]\n",
      "epoch:1 step:1346 [D loss: 0.581564, acc.: 73.44%] [G loss: 0.959348]\n",
      "epoch:1 step:1347 [D loss: 0.607559, acc.: 64.06%] [G loss: 0.972489]\n",
      "epoch:1 step:1348 [D loss: 0.589681, acc.: 71.09%] [G loss: 0.984153]\n",
      "epoch:1 step:1349 [D loss: 0.612683, acc.: 72.66%] [G loss: 1.014207]\n",
      "epoch:1 step:1350 [D loss: 0.599886, acc.: 71.09%] [G loss: 1.001940]\n",
      "epoch:1 step:1351 [D loss: 0.571704, acc.: 78.12%] [G loss: 0.978597]\n",
      "epoch:1 step:1352 [D loss: 0.570553, acc.: 70.31%] [G loss: 0.994559]\n",
      "epoch:1 step:1353 [D loss: 0.601868, acc.: 65.62%] [G loss: 1.073085]\n",
      "epoch:1 step:1354 [D loss: 0.585727, acc.: 68.75%] [G loss: 1.008087]\n",
      "epoch:1 step:1355 [D loss: 0.608531, acc.: 67.97%] [G loss: 0.957246]\n",
      "epoch:1 step:1356 [D loss: 0.588191, acc.: 67.19%] [G loss: 0.948840]\n",
      "epoch:1 step:1357 [D loss: 0.605705, acc.: 67.19%] [G loss: 1.032756]\n",
      "epoch:1 step:1358 [D loss: 0.588780, acc.: 75.00%] [G loss: 0.995156]\n",
      "epoch:1 step:1359 [D loss: 0.610454, acc.: 64.84%] [G loss: 0.933998]\n",
      "epoch:1 step:1360 [D loss: 0.570821, acc.: 76.56%] [G loss: 0.945001]\n",
      "epoch:1 step:1361 [D loss: 0.603926, acc.: 69.53%] [G loss: 0.943839]\n",
      "epoch:1 step:1362 [D loss: 0.545971, acc.: 80.47%] [G loss: 1.052050]\n",
      "epoch:1 step:1363 [D loss: 0.524441, acc.: 78.12%] [G loss: 1.048175]\n",
      "epoch:1 step:1364 [D loss: 0.517631, acc.: 75.78%] [G loss: 1.041672]\n",
      "epoch:1 step:1365 [D loss: 0.586283, acc.: 72.66%] [G loss: 0.965537]\n",
      "epoch:1 step:1366 [D loss: 0.559410, acc.: 76.56%] [G loss: 1.022985]\n",
      "epoch:1 step:1367 [D loss: 0.560422, acc.: 78.91%] [G loss: 1.052230]\n",
      "epoch:1 step:1368 [D loss: 0.602751, acc.: 67.97%] [G loss: 0.968992]\n",
      "epoch:1 step:1369 [D loss: 0.597350, acc.: 69.53%] [G loss: 0.981437]\n",
      "epoch:1 step:1370 [D loss: 0.621035, acc.: 66.41%] [G loss: 0.958013]\n",
      "epoch:1 step:1371 [D loss: 0.595191, acc.: 70.31%] [G loss: 0.981146]\n",
      "epoch:1 step:1372 [D loss: 0.574459, acc.: 75.00%] [G loss: 1.038984]\n",
      "epoch:1 step:1373 [D loss: 0.580025, acc.: 70.31%] [G loss: 0.979487]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1374 [D loss: 0.639036, acc.: 59.38%] [G loss: 0.907132]\n",
      "epoch:1 step:1375 [D loss: 0.610510, acc.: 63.28%] [G loss: 0.994531]\n",
      "epoch:1 step:1376 [D loss: 0.550562, acc.: 75.78%] [G loss: 1.073982]\n",
      "epoch:1 step:1377 [D loss: 0.543291, acc.: 75.78%] [G loss: 1.081941]\n",
      "epoch:1 step:1378 [D loss: 0.584510, acc.: 75.00%] [G loss: 1.047200]\n",
      "epoch:1 step:1379 [D loss: 0.559762, acc.: 75.78%] [G loss: 1.006896]\n",
      "epoch:1 step:1380 [D loss: 0.559687, acc.: 76.56%] [G loss: 1.027519]\n",
      "epoch:1 step:1381 [D loss: 0.582430, acc.: 72.66%] [G loss: 1.040611]\n",
      "epoch:1 step:1382 [D loss: 0.550717, acc.: 77.34%] [G loss: 1.054588]\n",
      "epoch:1 step:1383 [D loss: 0.566628, acc.: 75.78%] [G loss: 1.044415]\n",
      "epoch:1 step:1384 [D loss: 0.518423, acc.: 82.81%] [G loss: 1.090826]\n",
      "epoch:1 step:1385 [D loss: 0.617065, acc.: 65.62%] [G loss: 0.965199]\n",
      "epoch:1 step:1386 [D loss: 0.584617, acc.: 68.75%] [G loss: 1.014779]\n",
      "epoch:1 step:1387 [D loss: 0.552450, acc.: 74.22%] [G loss: 1.058527]\n",
      "epoch:1 step:1388 [D loss: 0.544179, acc.: 75.00%] [G loss: 1.102918]\n",
      "epoch:1 step:1389 [D loss: 0.519659, acc.: 79.69%] [G loss: 1.056280]\n",
      "epoch:1 step:1390 [D loss: 0.594235, acc.: 66.41%] [G loss: 1.070809]\n",
      "epoch:1 step:1391 [D loss: 0.543285, acc.: 78.91%] [G loss: 1.060719]\n",
      "epoch:1 step:1392 [D loss: 0.605596, acc.: 66.41%] [G loss: 1.073618]\n",
      "epoch:1 step:1393 [D loss: 0.615794, acc.: 63.28%] [G loss: 0.976085]\n",
      "epoch:1 step:1394 [D loss: 0.574840, acc.: 67.97%] [G loss: 0.982082]\n",
      "epoch:1 step:1395 [D loss: 0.558535, acc.: 74.22%] [G loss: 0.995944]\n",
      "epoch:1 step:1396 [D loss: 0.573978, acc.: 71.09%] [G loss: 0.986149]\n",
      "epoch:1 step:1397 [D loss: 0.552265, acc.: 74.22%] [G loss: 1.024446]\n",
      "epoch:1 step:1398 [D loss: 0.563944, acc.: 77.34%] [G loss: 1.032253]\n",
      "epoch:1 step:1399 [D loss: 0.570002, acc.: 72.66%] [G loss: 1.002779]\n",
      "epoch:1 step:1400 [D loss: 0.566864, acc.: 74.22%] [G loss: 1.000569]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.263594\n",
      "FID: 104.360298\n",
      "0 = 14.862176362896003\n",
      "1 = 0.16142071521561355\n",
      "2 = 0.9987999796867371\n",
      "3 = 0.9976000189781189\n",
      "4 = 1.0\n",
      "5 = 1.0\n",
      "6 = 0.9976000189781189\n",
      "7 = 12.003426745629309\n",
      "8 = 0.1906417839290828\n",
      "9 = 0.973550021648407\n",
      "10 = 0.9528999924659729\n",
      "11 = 0.9941999912261963\n",
      "12 = 0.9939501285552979\n",
      "13 = 0.9528999924659729\n",
      "14 = 4.263614654541016\n",
      "15 = 8.009418487548828\n",
      "16 = 0.38397127389907837\n",
      "17 = 4.263594150543213\n",
      "18 = 104.36029815673828\n",
      "epoch:1 step:1401 [D loss: 0.570794, acc.: 78.91%] [G loss: 0.942111]\n",
      "epoch:1 step:1402 [D loss: 0.607192, acc.: 74.22%] [G loss: 0.930394]\n",
      "epoch:1 step:1403 [D loss: 0.561980, acc.: 77.34%] [G loss: 0.938398]\n",
      "epoch:1 step:1404 [D loss: 0.567557, acc.: 77.34%] [G loss: 0.986979]\n",
      "epoch:1 step:1405 [D loss: 0.551834, acc.: 73.44%] [G loss: 0.954700]\n",
      "epoch:1 step:1406 [D loss: 0.581424, acc.: 69.53%] [G loss: 1.009871]\n",
      "epoch:1 step:1407 [D loss: 0.566692, acc.: 71.88%] [G loss: 1.038796]\n",
      "epoch:1 step:1408 [D loss: 0.522361, acc.: 78.91%] [G loss: 1.081764]\n",
      "epoch:1 step:1409 [D loss: 0.530376, acc.: 76.56%] [G loss: 1.127927]\n",
      "epoch:1 step:1410 [D loss: 0.630634, acc.: 60.94%] [G loss: 0.941805]\n",
      "epoch:1 step:1411 [D loss: 0.589392, acc.: 70.31%] [G loss: 1.009125]\n",
      "epoch:1 step:1412 [D loss: 0.497824, acc.: 86.72%] [G loss: 1.018764]\n",
      "epoch:1 step:1413 [D loss: 0.597910, acc.: 72.66%] [G loss: 0.963819]\n",
      "epoch:1 step:1414 [D loss: 0.645064, acc.: 64.06%] [G loss: 0.907341]\n",
      "epoch:1 step:1415 [D loss: 0.594168, acc.: 67.97%] [G loss: 0.937504]\n",
      "epoch:1 step:1416 [D loss: 0.595914, acc.: 74.22%] [G loss: 0.941729]\n",
      "epoch:1 step:1417 [D loss: 0.561644, acc.: 75.78%] [G loss: 1.006216]\n",
      "epoch:1 step:1418 [D loss: 0.555288, acc.: 78.91%] [G loss: 0.983754]\n",
      "epoch:1 step:1419 [D loss: 0.606233, acc.: 71.09%] [G loss: 0.919818]\n",
      "epoch:1 step:1420 [D loss: 0.591892, acc.: 69.53%] [G loss: 0.982613]\n",
      "epoch:1 step:1421 [D loss: 0.557689, acc.: 80.47%] [G loss: 1.058952]\n",
      "epoch:1 step:1422 [D loss: 0.539173, acc.: 82.03%] [G loss: 1.033846]\n",
      "epoch:1 step:1423 [D loss: 0.556852, acc.: 75.78%] [G loss: 1.019760]\n",
      "epoch:1 step:1424 [D loss: 0.540369, acc.: 78.91%] [G loss: 1.022876]\n",
      "epoch:1 step:1425 [D loss: 0.554799, acc.: 72.66%] [G loss: 1.049053]\n",
      "epoch:1 step:1426 [D loss: 0.603914, acc.: 70.31%] [G loss: 1.017799]\n",
      "epoch:1 step:1427 [D loss: 0.593691, acc.: 68.75%] [G loss: 1.000404]\n",
      "epoch:1 step:1428 [D loss: 0.549083, acc.: 78.91%] [G loss: 1.035993]\n",
      "epoch:1 step:1429 [D loss: 0.623272, acc.: 66.41%] [G loss: 0.952728]\n",
      "epoch:1 step:1430 [D loss: 0.568519, acc.: 69.53%] [G loss: 0.917373]\n",
      "epoch:1 step:1431 [D loss: 0.579762, acc.: 75.00%] [G loss: 0.932471]\n",
      "epoch:1 step:1432 [D loss: 0.611399, acc.: 67.19%] [G loss: 1.005210]\n",
      "epoch:1 step:1433 [D loss: 0.585198, acc.: 71.09%] [G loss: 0.985942]\n",
      "epoch:1 step:1434 [D loss: 0.589422, acc.: 70.31%] [G loss: 1.070726]\n",
      "epoch:1 step:1435 [D loss: 0.517146, acc.: 82.03%] [G loss: 1.086128]\n",
      "epoch:1 step:1436 [D loss: 0.515720, acc.: 82.81%] [G loss: 1.082282]\n",
      "epoch:1 step:1437 [D loss: 0.663543, acc.: 65.62%] [G loss: 0.972516]\n",
      "epoch:1 step:1438 [D loss: 0.626442, acc.: 67.19%] [G loss: 0.932577]\n",
      "epoch:1 step:1439 [D loss: 0.578599, acc.: 74.22%] [G loss: 0.915847]\n",
      "epoch:1 step:1440 [D loss: 0.520700, acc.: 78.91%] [G loss: 1.026959]\n",
      "epoch:1 step:1441 [D loss: 0.511534, acc.: 82.81%] [G loss: 1.088449]\n",
      "epoch:1 step:1442 [D loss: 0.572190, acc.: 71.88%] [G loss: 1.002574]\n",
      "epoch:1 step:1443 [D loss: 0.513123, acc.: 81.25%] [G loss: 1.058761]\n",
      "epoch:1 step:1444 [D loss: 0.506681, acc.: 78.91%] [G loss: 1.052849]\n",
      "epoch:1 step:1445 [D loss: 0.460141, acc.: 85.16%] [G loss: 1.093115]\n",
      "epoch:1 step:1446 [D loss: 0.580467, acc.: 64.06%] [G loss: 1.055713]\n",
      "epoch:1 step:1447 [D loss: 0.600938, acc.: 65.62%] [G loss: 0.988486]\n",
      "epoch:1 step:1448 [D loss: 0.627099, acc.: 64.84%] [G loss: 0.952374]\n",
      "epoch:1 step:1449 [D loss: 0.582155, acc.: 71.88%] [G loss: 0.914319]\n",
      "epoch:1 step:1450 [D loss: 0.537149, acc.: 75.78%] [G loss: 1.030089]\n",
      "epoch:1 step:1451 [D loss: 0.573156, acc.: 71.88%] [G loss: 1.023593]\n",
      "epoch:1 step:1452 [D loss: 0.542295, acc.: 80.47%] [G loss: 1.010722]\n",
      "epoch:1 step:1453 [D loss: 0.562174, acc.: 77.34%] [G loss: 0.925497]\n",
      "epoch:1 step:1454 [D loss: 0.596613, acc.: 70.31%] [G loss: 0.927270]\n",
      "epoch:1 step:1455 [D loss: 0.537713, acc.: 82.03%] [G loss: 0.962786]\n",
      "epoch:1 step:1456 [D loss: 0.552015, acc.: 74.22%] [G loss: 1.016145]\n",
      "epoch:1 step:1457 [D loss: 0.559161, acc.: 71.88%] [G loss: 0.978295]\n",
      "epoch:1 step:1458 [D loss: 0.598020, acc.: 72.66%] [G loss: 0.984163]\n",
      "epoch:1 step:1459 [D loss: 0.581756, acc.: 72.66%] [G loss: 1.014794]\n",
      "epoch:1 step:1460 [D loss: 0.576337, acc.: 74.22%] [G loss: 0.929335]\n",
      "epoch:1 step:1461 [D loss: 0.594695, acc.: 70.31%] [G loss: 0.954803]\n",
      "epoch:1 step:1462 [D loss: 0.634071, acc.: 69.53%] [G loss: 0.896833]\n",
      "epoch:1 step:1463 [D loss: 0.586451, acc.: 68.75%] [G loss: 0.960499]\n",
      "epoch:1 step:1464 [D loss: 0.594474, acc.: 69.53%] [G loss: 0.996716]\n",
      "epoch:1 step:1465 [D loss: 0.624784, acc.: 69.53%] [G loss: 0.944684]\n",
      "epoch:1 step:1466 [D loss: 0.583914, acc.: 72.66%] [G loss: 0.971619]\n",
      "epoch:1 step:1467 [D loss: 0.566850, acc.: 76.56%] [G loss: 0.944371]\n",
      "epoch:1 step:1468 [D loss: 0.582421, acc.: 73.44%] [G loss: 0.974349]\n",
      "epoch:1 step:1469 [D loss: 0.574451, acc.: 75.78%] [G loss: 0.976041]\n",
      "epoch:1 step:1470 [D loss: 0.611130, acc.: 67.97%] [G loss: 0.892197]\n",
      "epoch:1 step:1471 [D loss: 0.565163, acc.: 70.31%] [G loss: 0.962400]\n",
      "epoch:1 step:1472 [D loss: 0.600803, acc.: 71.09%] [G loss: 0.974446]\n",
      "epoch:1 step:1473 [D loss: 0.565416, acc.: 72.66%] [G loss: 1.042235]\n",
      "epoch:1 step:1474 [D loss: 0.566216, acc.: 72.66%] [G loss: 1.073919]\n",
      "epoch:1 step:1475 [D loss: 0.577667, acc.: 68.75%] [G loss: 1.022479]\n",
      "epoch:1 step:1476 [D loss: 0.591738, acc.: 67.19%] [G loss: 0.954273]\n",
      "epoch:1 step:1477 [D loss: 0.577394, acc.: 75.00%] [G loss: 0.940451]\n",
      "epoch:1 step:1478 [D loss: 0.552065, acc.: 72.66%] [G loss: 0.962732]\n",
      "epoch:1 step:1479 [D loss: 0.641808, acc.: 63.28%] [G loss: 0.957521]\n",
      "epoch:1 step:1480 [D loss: 0.624818, acc.: 64.84%] [G loss: 0.941644]\n",
      "epoch:1 step:1481 [D loss: 0.542305, acc.: 76.56%] [G loss: 1.011384]\n",
      "epoch:1 step:1482 [D loss: 0.545633, acc.: 75.78%] [G loss: 1.020910]\n",
      "epoch:1 step:1483 [D loss: 0.536255, acc.: 76.56%] [G loss: 1.002815]\n",
      "epoch:1 step:1484 [D loss: 0.512076, acc.: 78.91%] [G loss: 1.051111]\n",
      "epoch:1 step:1485 [D loss: 0.603205, acc.: 67.19%] [G loss: 0.944669]\n",
      "epoch:1 step:1486 [D loss: 0.558070, acc.: 75.00%] [G loss: 0.926777]\n",
      "epoch:1 step:1487 [D loss: 0.587307, acc.: 70.31%] [G loss: 0.965284]\n",
      "epoch:1 step:1488 [D loss: 0.570017, acc.: 71.88%] [G loss: 0.929033]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1489 [D loss: 0.567083, acc.: 69.53%] [G loss: 0.969721]\n",
      "epoch:1 step:1490 [D loss: 0.526503, acc.: 79.69%] [G loss: 1.001345]\n",
      "epoch:1 step:1491 [D loss: 0.553793, acc.: 72.66%] [G loss: 0.985900]\n",
      "epoch:1 step:1492 [D loss: 0.531206, acc.: 72.66%] [G loss: 1.040126]\n",
      "epoch:1 step:1493 [D loss: 0.485015, acc.: 84.38%] [G loss: 0.972667]\n",
      "epoch:1 step:1494 [D loss: 0.548735, acc.: 71.88%] [G loss: 1.018324]\n",
      "epoch:1 step:1495 [D loss: 0.513984, acc.: 75.78%] [G loss: 1.003426]\n",
      "epoch:1 step:1496 [D loss: 0.631305, acc.: 67.97%] [G loss: 0.986069]\n",
      "epoch:1 step:1497 [D loss: 0.583809, acc.: 75.78%] [G loss: 0.993763]\n",
      "epoch:1 step:1498 [D loss: 0.599615, acc.: 75.00%] [G loss: 0.996333]\n",
      "epoch:1 step:1499 [D loss: 0.573467, acc.: 74.22%] [G loss: 1.007484]\n",
      "epoch:1 step:1500 [D loss: 0.549687, acc.: 74.22%] [G loss: 1.039670]\n",
      "epoch:1 step:1501 [D loss: 0.566388, acc.: 75.78%] [G loss: 1.098860]\n",
      "epoch:1 step:1502 [D loss: 0.598059, acc.: 73.44%] [G loss: 1.075696]\n",
      "epoch:1 step:1503 [D loss: 0.613347, acc.: 66.41%] [G loss: 0.968419]\n",
      "epoch:1 step:1504 [D loss: 0.535526, acc.: 80.47%] [G loss: 1.009871]\n",
      "epoch:1 step:1505 [D loss: 0.532737, acc.: 80.47%] [G loss: 0.988322]\n",
      "epoch:1 step:1506 [D loss: 0.564056, acc.: 75.78%] [G loss: 0.976106]\n",
      "epoch:1 step:1507 [D loss: 0.556440, acc.: 75.78%] [G loss: 0.992770]\n",
      "epoch:1 step:1508 [D loss: 0.527974, acc.: 80.47%] [G loss: 1.016528]\n",
      "epoch:1 step:1509 [D loss: 0.557838, acc.: 77.34%] [G loss: 1.011806]\n",
      "epoch:1 step:1510 [D loss: 0.548258, acc.: 73.44%] [G loss: 0.969669]\n",
      "epoch:1 step:1511 [D loss: 0.526921, acc.: 78.91%] [G loss: 1.059542]\n",
      "epoch:1 step:1512 [D loss: 0.467995, acc.: 82.03%] [G loss: 1.073159]\n",
      "epoch:1 step:1513 [D loss: 0.579469, acc.: 69.53%] [G loss: 0.990928]\n",
      "epoch:1 step:1514 [D loss: 0.552391, acc.: 76.56%] [G loss: 0.972802]\n",
      "epoch:1 step:1515 [D loss: 0.556998, acc.: 75.78%] [G loss: 0.973766]\n",
      "epoch:1 step:1516 [D loss: 0.547866, acc.: 75.00%] [G loss: 0.932705]\n",
      "epoch:1 step:1517 [D loss: 0.562017, acc.: 74.22%] [G loss: 0.984131]\n",
      "epoch:1 step:1518 [D loss: 0.566446, acc.: 71.88%] [G loss: 1.016622]\n",
      "epoch:1 step:1519 [D loss: 0.503173, acc.: 78.12%] [G loss: 1.066812]\n",
      "epoch:1 step:1520 [D loss: 0.538539, acc.: 78.91%] [G loss: 1.065737]\n",
      "epoch:1 step:1521 [D loss: 0.617295, acc.: 64.84%] [G loss: 1.004542]\n",
      "epoch:1 step:1522 [D loss: 0.569512, acc.: 73.44%] [G loss: 0.984800]\n",
      "epoch:1 step:1523 [D loss: 0.595615, acc.: 70.31%] [G loss: 0.984176]\n",
      "epoch:1 step:1524 [D loss: 0.597582, acc.: 71.09%] [G loss: 0.989212]\n",
      "epoch:1 step:1525 [D loss: 0.588478, acc.: 66.41%] [G loss: 0.962110]\n",
      "epoch:1 step:1526 [D loss: 0.543824, acc.: 75.00%] [G loss: 1.059160]\n",
      "epoch:1 step:1527 [D loss: 0.543061, acc.: 74.22%] [G loss: 1.059981]\n",
      "epoch:1 step:1528 [D loss: 0.563099, acc.: 75.00%] [G loss: 1.049299]\n",
      "epoch:1 step:1529 [D loss: 0.480448, acc.: 85.16%] [G loss: 1.012401]\n",
      "epoch:1 step:1530 [D loss: 0.535865, acc.: 79.69%] [G loss: 1.057289]\n",
      "epoch:1 step:1531 [D loss: 0.565190, acc.: 73.44%] [G loss: 0.928104]\n",
      "epoch:1 step:1532 [D loss: 0.598927, acc.: 70.31%] [G loss: 0.980978]\n",
      "epoch:1 step:1533 [D loss: 0.531106, acc.: 77.34%] [G loss: 1.053640]\n",
      "epoch:1 step:1534 [D loss: 0.537780, acc.: 76.56%] [G loss: 1.082603]\n",
      "epoch:1 step:1535 [D loss: 0.500996, acc.: 75.00%] [G loss: 1.042223]\n",
      "epoch:1 step:1536 [D loss: 0.580403, acc.: 68.75%] [G loss: 0.967329]\n",
      "epoch:1 step:1537 [D loss: 0.634189, acc.: 67.19%] [G loss: 1.017255]\n",
      "epoch:1 step:1538 [D loss: 0.564973, acc.: 72.66%] [G loss: 0.962518]\n",
      "epoch:1 step:1539 [D loss: 0.553449, acc.: 75.00%] [G loss: 0.999609]\n",
      "epoch:1 step:1540 [D loss: 0.511283, acc.: 74.22%] [G loss: 1.079345]\n",
      "epoch:1 step:1541 [D loss: 0.607476, acc.: 65.62%] [G loss: 0.996674]\n",
      "epoch:1 step:1542 [D loss: 0.493883, acc.: 84.38%] [G loss: 1.047400]\n",
      "epoch:1 step:1543 [D loss: 0.562524, acc.: 70.31%] [G loss: 1.105389]\n",
      "epoch:1 step:1544 [D loss: 0.594302, acc.: 66.41%] [G loss: 0.998005]\n",
      "epoch:1 step:1545 [D loss: 0.577845, acc.: 70.31%] [G loss: 0.974997]\n",
      "epoch:1 step:1546 [D loss: 0.551509, acc.: 74.22%] [G loss: 1.065993]\n",
      "epoch:1 step:1547 [D loss: 0.588570, acc.: 64.84%] [G loss: 1.047270]\n",
      "epoch:1 step:1548 [D loss: 0.590266, acc.: 70.31%] [G loss: 1.079745]\n",
      "epoch:1 step:1549 [D loss: 0.591501, acc.: 65.62%] [G loss: 1.088789]\n",
      "epoch:1 step:1550 [D loss: 0.496164, acc.: 82.81%] [G loss: 1.155771]\n",
      "epoch:1 step:1551 [D loss: 0.609440, acc.: 74.22%] [G loss: 1.086384]\n",
      "epoch:1 step:1552 [D loss: 0.609911, acc.: 65.62%] [G loss: 1.043246]\n",
      "epoch:1 step:1553 [D loss: 0.520275, acc.: 79.69%] [G loss: 1.113480]\n",
      "epoch:1 step:1554 [D loss: 0.588884, acc.: 71.09%] [G loss: 1.061198]\n",
      "epoch:1 step:1555 [D loss: 0.537888, acc.: 75.78%] [G loss: 1.161587]\n",
      "epoch:1 step:1556 [D loss: 0.550269, acc.: 73.44%] [G loss: 1.103184]\n",
      "epoch:1 step:1557 [D loss: 0.548373, acc.: 79.69%] [G loss: 1.139428]\n",
      "epoch:1 step:1558 [D loss: 0.563764, acc.: 71.88%] [G loss: 1.110423]\n",
      "epoch:1 step:1559 [D loss: 0.635333, acc.: 64.84%] [G loss: 1.071501]\n",
      "epoch:1 step:1560 [D loss: 0.572069, acc.: 69.53%] [G loss: 1.091270]\n",
      "epoch:1 step:1561 [D loss: 0.551975, acc.: 75.00%] [G loss: 1.103743]\n",
      "epoch:1 step:1562 [D loss: 0.566975, acc.: 72.66%] [G loss: 1.055298]\n",
      "epoch:1 step:1563 [D loss: 0.540080, acc.: 74.22%] [G loss: 1.092771]\n",
      "epoch:1 step:1564 [D loss: 0.599904, acc.: 66.41%] [G loss: 1.044232]\n",
      "epoch:1 step:1565 [D loss: 0.537611, acc.: 79.69%] [G loss: 1.053256]\n",
      "epoch:1 step:1566 [D loss: 0.571730, acc.: 75.78%] [G loss: 1.048721]\n",
      "epoch:1 step:1567 [D loss: 0.541468, acc.: 71.88%] [G loss: 1.007161]\n",
      "epoch:1 step:1568 [D loss: 0.587903, acc.: 70.31%] [G loss: 1.001070]\n",
      "epoch:1 step:1569 [D loss: 0.589054, acc.: 71.09%] [G loss: 1.137355]\n",
      "epoch:1 step:1570 [D loss: 0.513975, acc.: 77.34%] [G loss: 1.151913]\n",
      "epoch:1 step:1571 [D loss: 0.570923, acc.: 72.66%] [G loss: 1.099031]\n",
      "epoch:1 step:1572 [D loss: 0.524020, acc.: 82.81%] [G loss: 1.072961]\n",
      "epoch:1 step:1573 [D loss: 0.636948, acc.: 63.28%] [G loss: 0.962475]\n",
      "epoch:1 step:1574 [D loss: 0.587309, acc.: 67.97%] [G loss: 0.984647]\n",
      "epoch:1 step:1575 [D loss: 0.503231, acc.: 82.03%] [G loss: 1.001379]\n",
      "epoch:1 step:1576 [D loss: 0.518689, acc.: 75.78%] [G loss: 1.073283]\n",
      "epoch:1 step:1577 [D loss: 0.535693, acc.: 78.91%] [G loss: 1.085034]\n",
      "epoch:1 step:1578 [D loss: 0.529760, acc.: 75.00%] [G loss: 1.067380]\n",
      "epoch:1 step:1579 [D loss: 0.552497, acc.: 73.44%] [G loss: 1.149405]\n",
      "epoch:1 step:1580 [D loss: 0.585055, acc.: 66.41%] [G loss: 1.076847]\n",
      "epoch:1 step:1581 [D loss: 0.558131, acc.: 75.00%] [G loss: 1.051225]\n",
      "epoch:1 step:1582 [D loss: 0.546213, acc.: 78.91%] [G loss: 1.004656]\n",
      "epoch:1 step:1583 [D loss: 0.568378, acc.: 69.53%] [G loss: 0.979802]\n",
      "epoch:1 step:1584 [D loss: 0.583525, acc.: 64.06%] [G loss: 0.999199]\n",
      "epoch:1 step:1585 [D loss: 0.531413, acc.: 71.09%] [G loss: 1.069263]\n",
      "epoch:1 step:1586 [D loss: 0.571304, acc.: 71.88%] [G loss: 1.069543]\n",
      "epoch:1 step:1587 [D loss: 0.525920, acc.: 74.22%] [G loss: 1.141936]\n",
      "epoch:1 step:1588 [D loss: 0.539844, acc.: 69.53%] [G loss: 1.065867]\n",
      "epoch:1 step:1589 [D loss: 0.688305, acc.: 54.69%] [G loss: 1.048757]\n",
      "epoch:1 step:1590 [D loss: 0.631527, acc.: 61.72%] [G loss: 1.036575]\n",
      "epoch:1 step:1591 [D loss: 0.538842, acc.: 77.34%] [G loss: 1.083521]\n",
      "epoch:1 step:1592 [D loss: 0.616517, acc.: 64.84%] [G loss: 1.017920]\n",
      "epoch:1 step:1593 [D loss: 0.593438, acc.: 67.97%] [G loss: 0.896438]\n",
      "epoch:1 step:1594 [D loss: 0.550555, acc.: 73.44%] [G loss: 1.021967]\n",
      "epoch:1 step:1595 [D loss: 0.531623, acc.: 81.25%] [G loss: 1.011729]\n",
      "epoch:1 step:1596 [D loss: 0.517029, acc.: 76.56%] [G loss: 1.037497]\n",
      "epoch:1 step:1597 [D loss: 0.540365, acc.: 75.78%] [G loss: 1.006655]\n",
      "epoch:1 step:1598 [D loss: 0.534275, acc.: 77.34%] [G loss: 1.048164]\n",
      "epoch:1 step:1599 [D loss: 0.623414, acc.: 68.75%] [G loss: 1.011058]\n",
      "epoch:1 step:1600 [D loss: 0.584945, acc.: 68.75%] [G loss: 1.037936]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.379974\n",
      "FID: 94.164711\n",
      "0 = 14.834191656684897\n",
      "1 = 0.1525142400377966\n",
      "2 = 0.9977499842643738\n",
      "3 = 0.9955000281333923\n",
      "4 = 1.0\n",
      "5 = 1.0\n",
      "6 = 0.9955000281333923\n",
      "7 = 11.649120614981657\n",
      "8 = 0.19059957115789566\n",
      "9 = 0.9728999733924866\n",
      "10 = 0.953000009059906\n",
      "11 = 0.9927999973297119\n",
      "12 = 0.9925015568733215\n",
      "13 = 0.953000009059906\n",
      "14 = 4.3799967765808105\n",
      "15 = 8.13530158996582\n",
      "16 = 0.36801740527153015\n",
      "17 = 4.379973888397217\n",
      "18 = 94.16471099853516\n",
      "epoch:1 step:1601 [D loss: 0.528181, acc.: 77.34%] [G loss: 1.031804]\n",
      "epoch:1 step:1602 [D loss: 0.591441, acc.: 67.97%] [G loss: 1.092535]\n",
      "epoch:1 step:1603 [D loss: 0.536624, acc.: 74.22%] [G loss: 1.031172]\n",
      "epoch:1 step:1604 [D loss: 0.559590, acc.: 71.88%] [G loss: 1.012948]\n",
      "epoch:1 step:1605 [D loss: 0.598327, acc.: 71.88%] [G loss: 0.973800]\n",
      "epoch:1 step:1606 [D loss: 0.550925, acc.: 76.56%] [G loss: 1.021250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1607 [D loss: 0.570790, acc.: 71.88%] [G loss: 0.993058]\n",
      "epoch:1 step:1608 [D loss: 0.606285, acc.: 64.06%] [G loss: 0.998566]\n",
      "epoch:1 step:1609 [D loss: 0.651696, acc.: 61.72%] [G loss: 0.900172]\n",
      "epoch:1 step:1610 [D loss: 0.613693, acc.: 68.75%] [G loss: 0.944948]\n",
      "epoch:1 step:1611 [D loss: 0.585959, acc.: 65.62%] [G loss: 1.000867]\n",
      "epoch:1 step:1612 [D loss: 0.574370, acc.: 71.09%] [G loss: 1.059154]\n",
      "epoch:1 step:1613 [D loss: 0.584604, acc.: 66.41%] [G loss: 1.096732]\n",
      "epoch:1 step:1614 [D loss: 0.540672, acc.: 78.12%] [G loss: 1.075016]\n",
      "epoch:1 step:1615 [D loss: 0.541610, acc.: 75.00%] [G loss: 1.074541]\n",
      "epoch:1 step:1616 [D loss: 0.564625, acc.: 75.00%] [G loss: 0.959739]\n",
      "epoch:1 step:1617 [D loss: 0.538233, acc.: 75.78%] [G loss: 1.019371]\n",
      "epoch:1 step:1618 [D loss: 0.575260, acc.: 70.31%] [G loss: 1.011492]\n",
      "epoch:1 step:1619 [D loss: 0.566420, acc.: 74.22%] [G loss: 0.978039]\n",
      "epoch:1 step:1620 [D loss: 0.579404, acc.: 69.53%] [G loss: 1.016883]\n",
      "epoch:1 step:1621 [D loss: 0.554660, acc.: 78.12%] [G loss: 1.047887]\n",
      "epoch:1 step:1622 [D loss: 0.562160, acc.: 75.78%] [G loss: 1.005327]\n",
      "epoch:1 step:1623 [D loss: 0.581602, acc.: 68.75%] [G loss: 0.941321]\n",
      "epoch:1 step:1624 [D loss: 0.556492, acc.: 71.09%] [G loss: 0.925185]\n",
      "epoch:1 step:1625 [D loss: 0.593872, acc.: 64.84%] [G loss: 1.022402]\n",
      "epoch:1 step:1626 [D loss: 0.567126, acc.: 75.00%] [G loss: 1.064662]\n",
      "epoch:1 step:1627 [D loss: 0.586163, acc.: 67.19%] [G loss: 1.027850]\n",
      "epoch:1 step:1628 [D loss: 0.595444, acc.: 68.75%] [G loss: 1.007247]\n",
      "epoch:1 step:1629 [D loss: 0.573358, acc.: 70.31%] [G loss: 0.915669]\n",
      "epoch:1 step:1630 [D loss: 0.555772, acc.: 69.53%] [G loss: 1.026850]\n",
      "epoch:1 step:1631 [D loss: 0.528577, acc.: 85.16%] [G loss: 1.019261]\n",
      "epoch:1 step:1632 [D loss: 0.562965, acc.: 72.66%] [G loss: 0.980044]\n",
      "epoch:1 step:1633 [D loss: 0.573133, acc.: 70.31%] [G loss: 0.959787]\n",
      "epoch:1 step:1634 [D loss: 0.545558, acc.: 76.56%] [G loss: 1.029981]\n",
      "epoch:1 step:1635 [D loss: 0.585285, acc.: 70.31%] [G loss: 1.028003]\n",
      "epoch:1 step:1636 [D loss: 0.573542, acc.: 68.75%] [G loss: 1.024479]\n",
      "epoch:1 step:1637 [D loss: 0.590013, acc.: 67.97%] [G loss: 1.061482]\n",
      "epoch:1 step:1638 [D loss: 0.569492, acc.: 67.97%] [G loss: 1.052809]\n",
      "epoch:1 step:1639 [D loss: 0.538257, acc.: 77.34%] [G loss: 1.063314]\n",
      "epoch:1 step:1640 [D loss: 0.619550, acc.: 67.97%] [G loss: 1.014149]\n",
      "epoch:1 step:1641 [D loss: 0.612062, acc.: 66.41%] [G loss: 0.998557]\n",
      "epoch:1 step:1642 [D loss: 0.546931, acc.: 75.00%] [G loss: 0.949378]\n",
      "epoch:1 step:1643 [D loss: 0.570188, acc.: 71.09%] [G loss: 0.984177]\n",
      "epoch:1 step:1644 [D loss: 0.491400, acc.: 82.03%] [G loss: 1.055708]\n",
      "epoch:1 step:1645 [D loss: 0.530256, acc.: 75.00%] [G loss: 1.120000]\n",
      "epoch:1 step:1646 [D loss: 0.543487, acc.: 75.78%] [G loss: 1.113893]\n",
      "epoch:1 step:1647 [D loss: 0.699998, acc.: 53.12%] [G loss: 1.021257]\n",
      "epoch:1 step:1648 [D loss: 0.650565, acc.: 63.28%] [G loss: 0.974966]\n",
      "epoch:1 step:1649 [D loss: 0.578470, acc.: 71.88%] [G loss: 1.025887]\n",
      "epoch:1 step:1650 [D loss: 0.583952, acc.: 70.31%] [G loss: 0.982098]\n",
      "epoch:1 step:1651 [D loss: 0.568934, acc.: 69.53%] [G loss: 1.039020]\n",
      "epoch:1 step:1652 [D loss: 0.625900, acc.: 67.19%] [G loss: 0.949662]\n",
      "epoch:1 step:1653 [D loss: 0.652337, acc.: 60.16%] [G loss: 0.958532]\n",
      "epoch:1 step:1654 [D loss: 0.611569, acc.: 71.09%] [G loss: 0.897136]\n",
      "epoch:1 step:1655 [D loss: 0.604275, acc.: 71.88%] [G loss: 0.889982]\n",
      "epoch:1 step:1656 [D loss: 0.591218, acc.: 67.19%] [G loss: 0.935954]\n",
      "epoch:1 step:1657 [D loss: 0.619108, acc.: 67.19%] [G loss: 0.993625]\n",
      "epoch:1 step:1658 [D loss: 0.616534, acc.: 64.06%] [G loss: 1.039638]\n",
      "epoch:1 step:1659 [D loss: 0.612577, acc.: 68.75%] [G loss: 0.970408]\n",
      "epoch:1 step:1660 [D loss: 0.615265, acc.: 70.31%] [G loss: 0.986591]\n",
      "epoch:1 step:1661 [D loss: 0.579284, acc.: 69.53%] [G loss: 1.009547]\n",
      "epoch:1 step:1662 [D loss: 0.569280, acc.: 76.56%] [G loss: 0.998423]\n",
      "epoch:1 step:1663 [D loss: 0.581255, acc.: 70.31%] [G loss: 1.024296]\n",
      "epoch:1 step:1664 [D loss: 0.613057, acc.: 69.53%] [G loss: 0.904159]\n",
      "epoch:1 step:1665 [D loss: 0.626741, acc.: 64.84%] [G loss: 0.860165]\n",
      "epoch:1 step:1666 [D loss: 0.583271, acc.: 67.19%] [G loss: 0.912602]\n",
      "epoch:1 step:1667 [D loss: 0.549946, acc.: 74.22%] [G loss: 0.988841]\n",
      "epoch:1 step:1668 [D loss: 0.529628, acc.: 76.56%] [G loss: 1.014444]\n",
      "epoch:1 step:1669 [D loss: 0.532569, acc.: 78.12%] [G loss: 0.990556]\n",
      "epoch:1 step:1670 [D loss: 0.558743, acc.: 77.34%] [G loss: 0.967415]\n",
      "epoch:1 step:1671 [D loss: 0.570985, acc.: 74.22%] [G loss: 0.986841]\n",
      "epoch:1 step:1672 [D loss: 0.631720, acc.: 64.06%] [G loss: 0.972620]\n",
      "epoch:1 step:1673 [D loss: 0.567819, acc.: 71.88%] [G loss: 0.990781]\n",
      "epoch:1 step:1674 [D loss: 0.559584, acc.: 73.44%] [G loss: 0.997974]\n",
      "epoch:1 step:1675 [D loss: 0.621152, acc.: 67.97%] [G loss: 0.991432]\n",
      "epoch:1 step:1676 [D loss: 0.632130, acc.: 59.38%] [G loss: 0.974555]\n",
      "epoch:1 step:1677 [D loss: 0.645485, acc.: 62.50%] [G loss: 0.959314]\n",
      "epoch:1 step:1678 [D loss: 0.554897, acc.: 77.34%] [G loss: 0.992970]\n",
      "epoch:1 step:1679 [D loss: 0.627340, acc.: 66.41%] [G loss: 0.956582]\n",
      "epoch:1 step:1680 [D loss: 0.555346, acc.: 75.00%] [G loss: 0.919201]\n",
      "epoch:1 step:1681 [D loss: 0.597716, acc.: 65.62%] [G loss: 0.963858]\n",
      "epoch:1 step:1682 [D loss: 0.575190, acc.: 73.44%] [G loss: 0.987639]\n",
      "epoch:1 step:1683 [D loss: 0.514340, acc.: 82.03%] [G loss: 1.003345]\n",
      "epoch:1 step:1684 [D loss: 0.499405, acc.: 82.03%] [G loss: 0.997309]\n",
      "epoch:1 step:1685 [D loss: 0.551025, acc.: 75.00%] [G loss: 0.965947]\n",
      "epoch:1 step:1686 [D loss: 0.545306, acc.: 75.78%] [G loss: 1.040923]\n",
      "epoch:1 step:1687 [D loss: 0.572649, acc.: 74.22%] [G loss: 0.980958]\n",
      "epoch:1 step:1688 [D loss: 0.600129, acc.: 71.09%] [G loss: 1.022966]\n",
      "epoch:1 step:1689 [D loss: 0.552297, acc.: 82.03%] [G loss: 1.079082]\n",
      "epoch:1 step:1690 [D loss: 0.510294, acc.: 78.91%] [G loss: 1.076465]\n",
      "epoch:1 step:1691 [D loss: 0.546444, acc.: 76.56%] [G loss: 1.066037]\n",
      "epoch:1 step:1692 [D loss: 0.567204, acc.: 72.66%] [G loss: 0.994010]\n",
      "epoch:1 step:1693 [D loss: 0.608345, acc.: 64.84%] [G loss: 1.090191]\n",
      "epoch:1 step:1694 [D loss: 0.553127, acc.: 75.78%] [G loss: 1.097534]\n",
      "epoch:1 step:1695 [D loss: 0.615913, acc.: 61.72%] [G loss: 1.019793]\n",
      "epoch:1 step:1696 [D loss: 0.577855, acc.: 67.97%] [G loss: 1.012743]\n",
      "epoch:1 step:1697 [D loss: 0.583873, acc.: 67.97%] [G loss: 1.012159]\n",
      "epoch:1 step:1698 [D loss: 0.559541, acc.: 73.44%] [G loss: 1.022871]\n",
      "epoch:1 step:1699 [D loss: 0.561122, acc.: 79.69%] [G loss: 0.958320]\n",
      "epoch:1 step:1700 [D loss: 0.580204, acc.: 72.66%] [G loss: 0.985841]\n",
      "epoch:1 step:1701 [D loss: 0.555697, acc.: 72.66%] [G loss: 1.019016]\n",
      "epoch:1 step:1702 [D loss: 0.656176, acc.: 60.94%] [G loss: 1.051750]\n",
      "epoch:1 step:1703 [D loss: 0.623642, acc.: 65.62%] [G loss: 1.031520]\n",
      "epoch:1 step:1704 [D loss: 0.593616, acc.: 68.75%] [G loss: 0.957025]\n",
      "epoch:1 step:1705 [D loss: 0.587164, acc.: 66.41%] [G loss: 0.946980]\n",
      "epoch:1 step:1706 [D loss: 0.558610, acc.: 71.09%] [G loss: 1.018286]\n",
      "epoch:1 step:1707 [D loss: 0.615078, acc.: 63.28%] [G loss: 1.010915]\n",
      "epoch:1 step:1708 [D loss: 0.572550, acc.: 75.00%] [G loss: 1.032279]\n",
      "epoch:1 step:1709 [D loss: 0.592436, acc.: 71.88%] [G loss: 1.007361]\n",
      "epoch:1 step:1710 [D loss: 0.585688, acc.: 71.09%] [G loss: 0.974408]\n",
      "epoch:1 step:1711 [D loss: 0.599798, acc.: 67.97%] [G loss: 1.004487]\n",
      "epoch:1 step:1712 [D loss: 0.537489, acc.: 72.66%] [G loss: 1.027453]\n",
      "epoch:1 step:1713 [D loss: 0.560810, acc.: 73.44%] [G loss: 0.958409]\n",
      "epoch:1 step:1714 [D loss: 0.556396, acc.: 69.53%] [G loss: 0.907626]\n",
      "epoch:1 step:1715 [D loss: 0.626033, acc.: 67.19%] [G loss: 0.973124]\n",
      "epoch:1 step:1716 [D loss: 0.568467, acc.: 73.44%] [G loss: 0.993816]\n",
      "epoch:1 step:1717 [D loss: 0.630810, acc.: 64.06%] [G loss: 0.988615]\n",
      "epoch:1 step:1718 [D loss: 0.538266, acc.: 78.91%] [G loss: 1.003445]\n",
      "epoch:1 step:1719 [D loss: 0.590291, acc.: 66.41%] [G loss: 0.948765]\n",
      "epoch:1 step:1720 [D loss: 0.672285, acc.: 53.91%] [G loss: 0.952975]\n",
      "epoch:1 step:1721 [D loss: 0.595657, acc.: 73.44%] [G loss: 0.939466]\n",
      "epoch:1 step:1722 [D loss: 0.609966, acc.: 64.06%] [G loss: 0.950223]\n",
      "epoch:1 step:1723 [D loss: 0.527272, acc.: 82.03%] [G loss: 1.059361]\n",
      "epoch:1 step:1724 [D loss: 0.627275, acc.: 61.72%] [G loss: 0.901941]\n",
      "epoch:1 step:1725 [D loss: 0.631858, acc.: 64.84%] [G loss: 0.974581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1726 [D loss: 0.549997, acc.: 79.69%] [G loss: 1.012997]\n",
      "epoch:1 step:1727 [D loss: 0.579598, acc.: 70.31%] [G loss: 1.071975]\n",
      "epoch:1 step:1728 [D loss: 0.550195, acc.: 72.66%] [G loss: 1.005140]\n",
      "epoch:1 step:1729 [D loss: 0.510064, acc.: 80.47%] [G loss: 1.064728]\n",
      "epoch:1 step:1730 [D loss: 0.612328, acc.: 67.97%] [G loss: 1.064004]\n",
      "epoch:1 step:1731 [D loss: 0.618288, acc.: 66.41%] [G loss: 0.919287]\n",
      "epoch:1 step:1732 [D loss: 0.617833, acc.: 67.19%] [G loss: 0.986524]\n",
      "epoch:1 step:1733 [D loss: 0.539016, acc.: 76.56%] [G loss: 1.043737]\n",
      "epoch:1 step:1734 [D loss: 0.625795, acc.: 67.97%] [G loss: 1.047677]\n",
      "epoch:1 step:1735 [D loss: 0.563967, acc.: 72.66%] [G loss: 1.003865]\n",
      "epoch:1 step:1736 [D loss: 0.591174, acc.: 70.31%] [G loss: 1.032419]\n",
      "epoch:1 step:1737 [D loss: 0.564050, acc.: 78.91%] [G loss: 1.038342]\n",
      "epoch:1 step:1738 [D loss: 0.526446, acc.: 75.00%] [G loss: 1.082514]\n",
      "epoch:1 step:1739 [D loss: 0.525041, acc.: 77.34%] [G loss: 1.103374]\n",
      "epoch:1 step:1740 [D loss: 0.575655, acc.: 67.19%] [G loss: 1.079012]\n",
      "epoch:1 step:1741 [D loss: 0.599894, acc.: 69.53%] [G loss: 1.001399]\n",
      "epoch:1 step:1742 [D loss: 0.599462, acc.: 69.53%] [G loss: 0.954980]\n",
      "epoch:1 step:1743 [D loss: 0.591375, acc.: 71.88%] [G loss: 0.987339]\n",
      "epoch:1 step:1744 [D loss: 0.588455, acc.: 70.31%] [G loss: 1.018859]\n",
      "epoch:1 step:1745 [D loss: 0.595201, acc.: 76.56%] [G loss: 0.919658]\n",
      "epoch:1 step:1746 [D loss: 0.637260, acc.: 59.38%] [G loss: 0.975688]\n",
      "epoch:1 step:1747 [D loss: 0.565771, acc.: 71.09%] [G loss: 0.973176]\n",
      "epoch:1 step:1748 [D loss: 0.630610, acc.: 63.28%] [G loss: 0.990395]\n",
      "epoch:1 step:1749 [D loss: 0.653136, acc.: 66.41%] [G loss: 0.915568]\n",
      "epoch:1 step:1750 [D loss: 0.631886, acc.: 66.41%] [G loss: 0.953553]\n",
      "epoch:1 step:1751 [D loss: 0.615735, acc.: 67.19%] [G loss: 0.966819]\n",
      "epoch:1 step:1752 [D loss: 0.556398, acc.: 72.66%] [G loss: 1.020467]\n",
      "epoch:1 step:1753 [D loss: 0.566277, acc.: 74.22%] [G loss: 1.062841]\n",
      "epoch:1 step:1754 [D loss: 0.641744, acc.: 59.38%] [G loss: 0.982861]\n",
      "epoch:1 step:1755 [D loss: 0.633101, acc.: 64.06%] [G loss: 0.939735]\n",
      "epoch:1 step:1756 [D loss: 0.592311, acc.: 69.53%] [G loss: 0.986491]\n",
      "epoch:1 step:1757 [D loss: 0.602836, acc.: 70.31%] [G loss: 0.959758]\n",
      "epoch:1 step:1758 [D loss: 0.636657, acc.: 67.19%] [G loss: 0.900000]\n",
      "epoch:1 step:1759 [D loss: 0.546291, acc.: 81.25%] [G loss: 0.968589]\n",
      "epoch:1 step:1760 [D loss: 0.577122, acc.: 73.44%] [G loss: 0.994276]\n",
      "epoch:1 step:1761 [D loss: 0.660431, acc.: 60.16%] [G loss: 0.963399]\n",
      "epoch:1 step:1762 [D loss: 0.613682, acc.: 64.84%] [G loss: 0.954015]\n",
      "epoch:1 step:1763 [D loss: 0.642829, acc.: 64.06%] [G loss: 0.932360]\n",
      "epoch:1 step:1764 [D loss: 0.622596, acc.: 63.28%] [G loss: 0.940771]\n",
      "epoch:1 step:1765 [D loss: 0.630326, acc.: 63.28%] [G loss: 0.949516]\n",
      "epoch:1 step:1766 [D loss: 0.583938, acc.: 75.00%] [G loss: 0.943151]\n",
      "epoch:1 step:1767 [D loss: 0.532855, acc.: 78.91%] [G loss: 0.927911]\n",
      "epoch:1 step:1768 [D loss: 0.619001, acc.: 70.31%] [G loss: 0.917005]\n",
      "epoch:1 step:1769 [D loss: 0.565282, acc.: 71.88%] [G loss: 0.975364]\n",
      "epoch:1 step:1770 [D loss: 0.555496, acc.: 74.22%] [G loss: 0.975437]\n",
      "epoch:1 step:1771 [D loss: 0.596712, acc.: 66.41%] [G loss: 0.969234]\n",
      "epoch:1 step:1772 [D loss: 0.601036, acc.: 67.97%] [G loss: 0.972966]\n",
      "epoch:1 step:1773 [D loss: 0.639961, acc.: 61.72%] [G loss: 0.964808]\n",
      "epoch:1 step:1774 [D loss: 0.569770, acc.: 75.00%] [G loss: 1.035358]\n",
      "epoch:1 step:1775 [D loss: 0.568569, acc.: 71.88%] [G loss: 1.034913]\n",
      "epoch:1 step:1776 [D loss: 0.606643, acc.: 67.97%] [G loss: 1.006630]\n",
      "epoch:1 step:1777 [D loss: 0.600041, acc.: 70.31%] [G loss: 0.961277]\n",
      "epoch:1 step:1778 [D loss: 0.547891, acc.: 74.22%] [G loss: 1.025279]\n",
      "epoch:1 step:1779 [D loss: 0.583621, acc.: 77.34%] [G loss: 0.960408]\n",
      "epoch:1 step:1780 [D loss: 0.666604, acc.: 61.72%] [G loss: 0.941381]\n",
      "epoch:1 step:1781 [D loss: 0.557465, acc.: 75.00%] [G loss: 0.959324]\n",
      "epoch:1 step:1782 [D loss: 0.589874, acc.: 72.66%] [G loss: 0.951829]\n",
      "epoch:1 step:1783 [D loss: 0.568661, acc.: 78.12%] [G loss: 0.956060]\n",
      "epoch:1 step:1784 [D loss: 0.609557, acc.: 69.53%] [G loss: 0.936335]\n",
      "epoch:1 step:1785 [D loss: 0.566593, acc.: 75.00%] [G loss: 0.969216]\n",
      "epoch:1 step:1786 [D loss: 0.621718, acc.: 66.41%] [G loss: 0.962758]\n",
      "epoch:1 step:1787 [D loss: 0.576559, acc.: 66.41%] [G loss: 0.958390]\n",
      "epoch:1 step:1788 [D loss: 0.580046, acc.: 68.75%] [G loss: 0.888703]\n",
      "epoch:1 step:1789 [D loss: 0.564329, acc.: 71.09%] [G loss: 0.911606]\n",
      "epoch:1 step:1790 [D loss: 0.539537, acc.: 70.31%] [G loss: 1.010529]\n",
      "epoch:1 step:1791 [D loss: 0.545367, acc.: 75.00%] [G loss: 1.066642]\n",
      "epoch:1 step:1792 [D loss: 0.592326, acc.: 69.53%] [G loss: 0.928063]\n",
      "epoch:1 step:1793 [D loss: 0.602682, acc.: 69.53%] [G loss: 0.958899]\n",
      "epoch:1 step:1794 [D loss: 0.548597, acc.: 74.22%] [G loss: 0.968749]\n",
      "epoch:1 step:1795 [D loss: 0.662872, acc.: 60.16%] [G loss: 0.966249]\n",
      "epoch:1 step:1796 [D loss: 0.627040, acc.: 73.44%] [G loss: 0.950952]\n",
      "epoch:1 step:1797 [D loss: 0.560862, acc.: 75.00%] [G loss: 1.047085]\n",
      "epoch:1 step:1798 [D loss: 0.642632, acc.: 63.28%] [G loss: 0.959247]\n",
      "epoch:1 step:1799 [D loss: 0.578955, acc.: 74.22%] [G loss: 0.967700]\n",
      "epoch:1 step:1800 [D loss: 0.616503, acc.: 67.19%] [G loss: 0.977191]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.925051\n",
      "FID: 86.495842\n",
      "0 = 13.829564599180204\n",
      "1 = 0.1321637634176546\n",
      "2 = 0.9950500130653381\n",
      "3 = 0.9901000261306763\n",
      "4 = 1.0\n",
      "5 = 1.0\n",
      "6 = 0.9901000261306763\n",
      "7 = 11.146032778358418\n",
      "8 = 0.1818478950150007\n",
      "9 = 0.9589499831199646\n",
      "10 = 0.9309999942779541\n",
      "11 = 0.9868999719619751\n",
      "12 = 0.9861243367195129\n",
      "13 = 0.9309999942779541\n",
      "14 = 4.925072193145752\n",
      "15 = 8.751006126403809\n",
      "16 = 0.29280826449394226\n",
      "17 = 4.925050735473633\n",
      "18 = 86.49584197998047\n",
      "epoch:1 step:1801 [D loss: 0.594278, acc.: 67.97%] [G loss: 0.987505]\n",
      "epoch:1 step:1802 [D loss: 0.587856, acc.: 71.09%] [G loss: 0.957630]\n",
      "epoch:1 step:1803 [D loss: 0.572227, acc.: 78.12%] [G loss: 0.989186]\n",
      "epoch:1 step:1804 [D loss: 0.638702, acc.: 58.59%] [G loss: 1.023532]\n",
      "epoch:1 step:1805 [D loss: 0.611826, acc.: 67.97%] [G loss: 0.985290]\n",
      "epoch:1 step:1806 [D loss: 0.578712, acc.: 75.78%] [G loss: 0.978231]\n",
      "epoch:1 step:1807 [D loss: 0.585569, acc.: 75.00%] [G loss: 1.043761]\n",
      "epoch:1 step:1808 [D loss: 0.551638, acc.: 74.22%] [G loss: 0.984631]\n",
      "epoch:1 step:1809 [D loss: 0.560567, acc.: 76.56%] [G loss: 0.992843]\n",
      "epoch:1 step:1810 [D loss: 0.592216, acc.: 71.09%] [G loss: 1.027950]\n",
      "epoch:1 step:1811 [D loss: 0.563087, acc.: 74.22%] [G loss: 1.025299]\n",
      "epoch:1 step:1812 [D loss: 0.547758, acc.: 75.78%] [G loss: 1.018079]\n",
      "epoch:1 step:1813 [D loss: 0.575447, acc.: 71.09%] [G loss: 1.023049]\n",
      "epoch:1 step:1814 [D loss: 0.562327, acc.: 74.22%] [G loss: 1.016003]\n",
      "epoch:1 step:1815 [D loss: 0.658790, acc.: 63.28%] [G loss: 0.965493]\n",
      "epoch:1 step:1816 [D loss: 0.631921, acc.: 67.97%] [G loss: 0.956172]\n",
      "epoch:1 step:1817 [D loss: 0.654603, acc.: 59.38%] [G loss: 0.953429]\n",
      "epoch:1 step:1818 [D loss: 0.604833, acc.: 67.19%] [G loss: 1.039094]\n",
      "epoch:1 step:1819 [D loss: 0.618348, acc.: 70.31%] [G loss: 0.945533]\n",
      "epoch:1 step:1820 [D loss: 0.608522, acc.: 63.28%] [G loss: 0.933148]\n",
      "epoch:1 step:1821 [D loss: 0.596559, acc.: 66.41%] [G loss: 0.998892]\n",
      "epoch:1 step:1822 [D loss: 0.555502, acc.: 75.78%] [G loss: 0.969734]\n",
      "epoch:1 step:1823 [D loss: 0.527202, acc.: 79.69%] [G loss: 1.104741]\n",
      "epoch:1 step:1824 [D loss: 0.540217, acc.: 77.34%] [G loss: 1.112667]\n",
      "epoch:1 step:1825 [D loss: 0.572537, acc.: 67.97%] [G loss: 1.047659]\n",
      "epoch:1 step:1826 [D loss: 0.576321, acc.: 78.12%] [G loss: 1.050059]\n",
      "epoch:1 step:1827 [D loss: 0.539799, acc.: 76.56%] [G loss: 1.027484]\n",
      "epoch:1 step:1828 [D loss: 0.602547, acc.: 68.75%] [G loss: 0.960479]\n",
      "epoch:1 step:1829 [D loss: 0.709956, acc.: 53.12%] [G loss: 0.941747]\n",
      "epoch:1 step:1830 [D loss: 0.595481, acc.: 67.97%] [G loss: 0.981729]\n",
      "epoch:1 step:1831 [D loss: 0.571707, acc.: 70.31%] [G loss: 1.021778]\n",
      "epoch:1 step:1832 [D loss: 0.585681, acc.: 69.53%] [G loss: 1.021996]\n",
      "epoch:1 step:1833 [D loss: 0.557133, acc.: 74.22%] [G loss: 1.028162]\n",
      "epoch:1 step:1834 [D loss: 0.602150, acc.: 66.41%] [G loss: 1.000186]\n",
      "epoch:1 step:1835 [D loss: 0.574588, acc.: 70.31%] [G loss: 1.066482]\n",
      "epoch:1 step:1836 [D loss: 0.582486, acc.: 74.22%] [G loss: 1.065583]\n",
      "epoch:1 step:1837 [D loss: 0.540169, acc.: 75.78%] [G loss: 1.046923]\n",
      "epoch:1 step:1838 [D loss: 0.574560, acc.: 71.09%] [G loss: 0.975453]\n",
      "epoch:1 step:1839 [D loss: 0.597853, acc.: 70.31%] [G loss: 0.943811]\n",
      "epoch:1 step:1840 [D loss: 0.591682, acc.: 71.88%] [G loss: 0.917640]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1841 [D loss: 0.580655, acc.: 75.00%] [G loss: 1.059008]\n",
      "epoch:1 step:1842 [D loss: 0.595726, acc.: 65.62%] [G loss: 0.991036]\n",
      "epoch:1 step:1843 [D loss: 0.585763, acc.: 71.88%] [G loss: 0.971539]\n",
      "epoch:1 step:1844 [D loss: 0.598992, acc.: 74.22%] [G loss: 1.018902]\n",
      "epoch:1 step:1845 [D loss: 0.564992, acc.: 71.88%] [G loss: 1.051040]\n",
      "epoch:1 step:1846 [D loss: 0.560954, acc.: 77.34%] [G loss: 1.042008]\n",
      "epoch:1 step:1847 [D loss: 0.545633, acc.: 77.34%] [G loss: 1.089263]\n",
      "epoch:1 step:1848 [D loss: 0.549018, acc.: 70.31%] [G loss: 1.043083]\n",
      "epoch:1 step:1849 [D loss: 0.568212, acc.: 72.66%] [G loss: 1.004778]\n",
      "epoch:1 step:1850 [D loss: 0.616317, acc.: 63.28%] [G loss: 0.956907]\n",
      "epoch:1 step:1851 [D loss: 0.600205, acc.: 67.19%] [G loss: 1.023379]\n",
      "epoch:1 step:1852 [D loss: 0.621952, acc.: 70.31%] [G loss: 0.969346]\n",
      "epoch:1 step:1853 [D loss: 0.593787, acc.: 71.09%] [G loss: 0.962373]\n",
      "epoch:1 step:1854 [D loss: 0.640458, acc.: 67.97%] [G loss: 0.955783]\n",
      "epoch:1 step:1855 [D loss: 0.565715, acc.: 71.88%] [G loss: 1.004210]\n",
      "epoch:1 step:1856 [D loss: 0.554206, acc.: 71.88%] [G loss: 1.092190]\n",
      "epoch:1 step:1857 [D loss: 0.666261, acc.: 59.38%] [G loss: 0.951425]\n",
      "epoch:1 step:1858 [D loss: 0.518443, acc.: 79.69%] [G loss: 0.999835]\n",
      "epoch:1 step:1859 [D loss: 0.633291, acc.: 67.97%] [G loss: 0.882431]\n",
      "epoch:1 step:1860 [D loss: 0.487542, acc.: 83.59%] [G loss: 0.888071]\n",
      "epoch:1 step:1861 [D loss: 0.510442, acc.: 78.91%] [G loss: 1.013863]\n",
      "epoch:1 step:1862 [D loss: 0.522778, acc.: 78.91%] [G loss: 1.035628]\n",
      "epoch:1 step:1863 [D loss: 0.535100, acc.: 78.91%] [G loss: 1.067340]\n",
      "epoch:1 step:1864 [D loss: 0.596968, acc.: 67.97%] [G loss: 1.119714]\n",
      "epoch:1 step:1865 [D loss: 0.710161, acc.: 59.38%] [G loss: 1.038598]\n",
      "epoch:1 step:1866 [D loss: 0.539223, acc.: 75.78%] [G loss: 1.063095]\n",
      "epoch:1 step:1867 [D loss: 0.476477, acc.: 82.03%] [G loss: 1.160098]\n",
      "epoch:1 step:1868 [D loss: 0.657576, acc.: 64.06%] [G loss: 0.966308]\n",
      "epoch:1 step:1869 [D loss: 0.643433, acc.: 67.19%] [G loss: 0.948002]\n",
      "epoch:1 step:1870 [D loss: 0.583319, acc.: 73.44%] [G loss: 0.950606]\n",
      "epoch:1 step:1871 [D loss: 0.596129, acc.: 72.66%] [G loss: 1.013421]\n",
      "epoch:1 step:1872 [D loss: 0.520315, acc.: 79.69%] [G loss: 1.020572]\n",
      "epoch:1 step:1873 [D loss: 0.452849, acc.: 82.81%] [G loss: 1.103738]\n",
      "epoch:1 step:1874 [D loss: 0.598339, acc.: 63.28%] [G loss: 1.069321]\n",
      "epoch:2 step:1875 [D loss: 0.560946, acc.: 76.56%] [G loss: 1.121488]\n",
      "epoch:2 step:1876 [D loss: 0.582291, acc.: 67.97%] [G loss: 1.057769]\n",
      "epoch:2 step:1877 [D loss: 0.631570, acc.: 61.72%] [G loss: 1.041672]\n",
      "epoch:2 step:1878 [D loss: 0.569023, acc.: 67.19%] [G loss: 1.079671]\n",
      "epoch:2 step:1879 [D loss: 0.576279, acc.: 75.00%] [G loss: 1.075835]\n",
      "epoch:2 step:1880 [D loss: 0.562259, acc.: 71.88%] [G loss: 1.031019]\n",
      "epoch:2 step:1881 [D loss: 0.557991, acc.: 74.22%] [G loss: 1.014380]\n",
      "epoch:2 step:1882 [D loss: 0.575164, acc.: 70.31%] [G loss: 1.035741]\n",
      "epoch:2 step:1883 [D loss: 0.588725, acc.: 69.53%] [G loss: 1.067743]\n",
      "epoch:2 step:1884 [D loss: 0.544315, acc.: 75.00%] [G loss: 1.087493]\n",
      "epoch:2 step:1885 [D loss: 0.526292, acc.: 74.22%] [G loss: 0.999558]\n",
      "epoch:2 step:1886 [D loss: 0.590507, acc.: 66.41%] [G loss: 1.008793]\n",
      "epoch:2 step:1887 [D loss: 0.553148, acc.: 71.88%] [G loss: 1.015791]\n",
      "epoch:2 step:1888 [D loss: 0.599318, acc.: 72.66%] [G loss: 1.002286]\n",
      "epoch:2 step:1889 [D loss: 0.559509, acc.: 80.47%] [G loss: 1.031411]\n",
      "epoch:2 step:1890 [D loss: 0.552743, acc.: 75.78%] [G loss: 1.056741]\n",
      "epoch:2 step:1891 [D loss: 0.606034, acc.: 64.84%] [G loss: 1.079717]\n",
      "epoch:2 step:1892 [D loss: 0.647896, acc.: 64.84%] [G loss: 1.044339]\n",
      "epoch:2 step:1893 [D loss: 0.655060, acc.: 60.94%] [G loss: 0.983736]\n",
      "epoch:2 step:1894 [D loss: 0.728410, acc.: 50.00%] [G loss: 0.857827]\n",
      "epoch:2 step:1895 [D loss: 0.587290, acc.: 74.22%] [G loss: 0.904463]\n",
      "epoch:2 step:1896 [D loss: 0.521279, acc.: 77.34%] [G loss: 0.983492]\n",
      "epoch:2 step:1897 [D loss: 0.625946, acc.: 62.50%] [G loss: 0.970290]\n",
      "epoch:2 step:1898 [D loss: 0.605250, acc.: 67.19%] [G loss: 0.940689]\n",
      "epoch:2 step:1899 [D loss: 0.573379, acc.: 74.22%] [G loss: 0.982669]\n",
      "epoch:2 step:1900 [D loss: 0.582335, acc.: 70.31%] [G loss: 0.934939]\n",
      "epoch:2 step:1901 [D loss: 0.561155, acc.: 69.53%] [G loss: 0.978441]\n",
      "epoch:2 step:1902 [D loss: 0.598502, acc.: 66.41%] [G loss: 0.962463]\n",
      "epoch:2 step:1903 [D loss: 0.581313, acc.: 71.09%] [G loss: 1.007139]\n",
      "epoch:2 step:1904 [D loss: 0.600714, acc.: 67.97%] [G loss: 0.933950]\n",
      "epoch:2 step:1905 [D loss: 0.553031, acc.: 78.12%] [G loss: 0.934844]\n",
      "epoch:2 step:1906 [D loss: 0.599975, acc.: 70.31%] [G loss: 0.985695]\n",
      "epoch:2 step:1907 [D loss: 0.560531, acc.: 75.78%] [G loss: 1.025506]\n",
      "epoch:2 step:1908 [D loss: 0.613716, acc.: 63.28%] [G loss: 0.994425]\n",
      "epoch:2 step:1909 [D loss: 0.518973, acc.: 77.34%] [G loss: 1.005368]\n",
      "epoch:2 step:1910 [D loss: 0.512831, acc.: 84.38%] [G loss: 1.113463]\n",
      "epoch:2 step:1911 [D loss: 0.598706, acc.: 66.41%] [G loss: 1.014511]\n",
      "epoch:2 step:1912 [D loss: 0.674554, acc.: 60.94%] [G loss: 0.919048]\n",
      "epoch:2 step:1913 [D loss: 0.530293, acc.: 80.47%] [G loss: 0.990734]\n",
      "epoch:2 step:1914 [D loss: 0.561159, acc.: 78.12%] [G loss: 1.009785]\n",
      "epoch:2 step:1915 [D loss: 0.573957, acc.: 72.66%] [G loss: 0.973203]\n",
      "epoch:2 step:1916 [D loss: 0.571693, acc.: 74.22%] [G loss: 0.980908]\n",
      "epoch:2 step:1917 [D loss: 0.587604, acc.: 67.19%] [G loss: 0.967739]\n",
      "epoch:2 step:1918 [D loss: 0.638097, acc.: 65.62%] [G loss: 1.099067]\n",
      "epoch:2 step:1919 [D loss: 0.608152, acc.: 65.62%] [G loss: 1.053908]\n",
      "epoch:2 step:1920 [D loss: 0.592011, acc.: 67.19%] [G loss: 0.966075]\n",
      "epoch:2 step:1921 [D loss: 0.584923, acc.: 68.75%] [G loss: 1.029150]\n",
      "epoch:2 step:1922 [D loss: 0.593344, acc.: 71.09%] [G loss: 1.019337]\n",
      "epoch:2 step:1923 [D loss: 0.599032, acc.: 71.09%] [G loss: 1.037838]\n",
      "epoch:2 step:1924 [D loss: 0.573510, acc.: 72.66%] [G loss: 1.018821]\n",
      "epoch:2 step:1925 [D loss: 0.617336, acc.: 66.41%] [G loss: 0.986003]\n",
      "epoch:2 step:1926 [D loss: 0.606968, acc.: 75.00%] [G loss: 0.979489]\n",
      "epoch:2 step:1927 [D loss: 0.589554, acc.: 75.78%] [G loss: 0.983028]\n",
      "epoch:2 step:1928 [D loss: 0.582807, acc.: 71.09%] [G loss: 0.991332]\n",
      "epoch:2 step:1929 [D loss: 0.569459, acc.: 71.09%] [G loss: 1.060836]\n",
      "epoch:2 step:1930 [D loss: 0.625835, acc.: 64.06%] [G loss: 0.989921]\n",
      "epoch:2 step:1931 [D loss: 0.592476, acc.: 64.06%] [G loss: 1.031733]\n",
      "epoch:2 step:1932 [D loss: 0.596028, acc.: 72.66%] [G loss: 1.044671]\n",
      "epoch:2 step:1933 [D loss: 0.587000, acc.: 67.97%] [G loss: 0.980008]\n",
      "epoch:2 step:1934 [D loss: 0.609397, acc.: 67.97%] [G loss: 1.091457]\n",
      "epoch:2 step:1935 [D loss: 0.558710, acc.: 74.22%] [G loss: 0.974266]\n",
      "epoch:2 step:1936 [D loss: 0.642865, acc.: 63.28%] [G loss: 0.891247]\n",
      "epoch:2 step:1937 [D loss: 0.579762, acc.: 72.66%] [G loss: 0.964729]\n",
      "epoch:2 step:1938 [D loss: 0.662817, acc.: 60.16%] [G loss: 0.928723]\n",
      "epoch:2 step:1939 [D loss: 0.629982, acc.: 65.62%] [G loss: 0.907032]\n",
      "epoch:2 step:1940 [D loss: 0.628695, acc.: 62.50%] [G loss: 0.896296]\n",
      "epoch:2 step:1941 [D loss: 0.612873, acc.: 64.06%] [G loss: 0.925376]\n",
      "epoch:2 step:1942 [D loss: 0.569965, acc.: 78.91%] [G loss: 1.001319]\n",
      "epoch:2 step:1943 [D loss: 0.594219, acc.: 68.75%] [G loss: 0.979319]\n",
      "epoch:2 step:1944 [D loss: 0.599415, acc.: 68.75%] [G loss: 0.937609]\n",
      "epoch:2 step:1945 [D loss: 0.574157, acc.: 71.88%] [G loss: 0.972476]\n",
      "epoch:2 step:1946 [D loss: 0.559344, acc.: 69.53%] [G loss: 1.006569]\n",
      "epoch:2 step:1947 [D loss: 0.619167, acc.: 69.53%] [G loss: 0.972226]\n",
      "epoch:2 step:1948 [D loss: 0.554905, acc.: 73.44%] [G loss: 1.006694]\n",
      "epoch:2 step:1949 [D loss: 0.517235, acc.: 77.34%] [G loss: 1.052072]\n",
      "epoch:2 step:1950 [D loss: 0.545586, acc.: 71.88%] [G loss: 1.023289]\n",
      "epoch:2 step:1951 [D loss: 0.544420, acc.: 75.78%] [G loss: 1.058503]\n",
      "epoch:2 step:1952 [D loss: 0.613518, acc.: 72.66%] [G loss: 0.988809]\n",
      "epoch:2 step:1953 [D loss: 0.637737, acc.: 58.59%] [G loss: 0.932151]\n",
      "epoch:2 step:1954 [D loss: 0.626258, acc.: 62.50%] [G loss: 0.956828]\n",
      "epoch:2 step:1955 [D loss: 0.605034, acc.: 68.75%] [G loss: 0.882267]\n",
      "epoch:2 step:1956 [D loss: 0.576761, acc.: 68.75%] [G loss: 0.955004]\n",
      "epoch:2 step:1957 [D loss: 0.561016, acc.: 72.66%] [G loss: 0.986710]\n",
      "epoch:2 step:1958 [D loss: 0.582238, acc.: 66.41%] [G loss: 0.922944]\n",
      "epoch:2 step:1959 [D loss: 0.571942, acc.: 74.22%] [G loss: 0.971172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1960 [D loss: 0.556034, acc.: 75.00%] [G loss: 1.002071]\n",
      "epoch:2 step:1961 [D loss: 0.585115, acc.: 70.31%] [G loss: 0.965521]\n",
      "epoch:2 step:1962 [D loss: 0.564861, acc.: 73.44%] [G loss: 0.957828]\n",
      "epoch:2 step:1963 [D loss: 0.582807, acc.: 64.06%] [G loss: 0.925833]\n",
      "epoch:2 step:1964 [D loss: 0.586311, acc.: 71.09%] [G loss: 0.969640]\n",
      "epoch:2 step:1965 [D loss: 0.631637, acc.: 66.41%] [G loss: 0.964145]\n",
      "epoch:2 step:1966 [D loss: 0.590221, acc.: 73.44%] [G loss: 1.013291]\n",
      "epoch:2 step:1967 [D loss: 0.581444, acc.: 65.62%] [G loss: 1.016849]\n",
      "epoch:2 step:1968 [D loss: 0.561554, acc.: 75.78%] [G loss: 0.992924]\n",
      "epoch:2 step:1969 [D loss: 0.587804, acc.: 69.53%] [G loss: 0.979768]\n",
      "epoch:2 step:1970 [D loss: 0.591928, acc.: 66.41%] [G loss: 1.007074]\n",
      "epoch:2 step:1971 [D loss: 0.559623, acc.: 74.22%] [G loss: 0.971303]\n",
      "epoch:2 step:1972 [D loss: 0.611709, acc.: 64.84%] [G loss: 0.947170]\n",
      "epoch:2 step:1973 [D loss: 0.572482, acc.: 71.09%] [G loss: 0.923185]\n",
      "epoch:2 step:1974 [D loss: 0.586444, acc.: 70.31%] [G loss: 0.989136]\n",
      "epoch:2 step:1975 [D loss: 0.578731, acc.: 71.88%] [G loss: 0.933308]\n",
      "epoch:2 step:1976 [D loss: 0.609643, acc.: 64.06%] [G loss: 0.911264]\n",
      "epoch:2 step:1977 [D loss: 0.555843, acc.: 69.53%] [G loss: 0.936394]\n",
      "epoch:2 step:1978 [D loss: 0.593576, acc.: 66.41%] [G loss: 1.000031]\n",
      "epoch:2 step:1979 [D loss: 0.574961, acc.: 70.31%] [G loss: 1.008441]\n",
      "epoch:2 step:1980 [D loss: 0.640562, acc.: 64.06%] [G loss: 0.946501]\n",
      "epoch:2 step:1981 [D loss: 0.649157, acc.: 59.38%] [G loss: 0.965547]\n",
      "epoch:2 step:1982 [D loss: 0.607833, acc.: 72.66%] [G loss: 0.962860]\n",
      "epoch:2 step:1983 [D loss: 0.638036, acc.: 66.41%] [G loss: 0.913600]\n",
      "epoch:2 step:1984 [D loss: 0.573000, acc.: 70.31%] [G loss: 0.894683]\n",
      "epoch:2 step:1985 [D loss: 0.579307, acc.: 75.00%] [G loss: 0.978721]\n",
      "epoch:2 step:1986 [D loss: 0.559095, acc.: 74.22%] [G loss: 0.995836]\n",
      "epoch:2 step:1987 [D loss: 0.624934, acc.: 64.84%] [G loss: 1.058642]\n",
      "epoch:2 step:1988 [D loss: 0.602376, acc.: 64.06%] [G loss: 0.990711]\n",
      "epoch:2 step:1989 [D loss: 0.565031, acc.: 74.22%] [G loss: 1.100672]\n",
      "epoch:2 step:1990 [D loss: 0.573874, acc.: 69.53%] [G loss: 1.054432]\n",
      "epoch:2 step:1991 [D loss: 0.574977, acc.: 71.88%] [G loss: 1.068045]\n",
      "epoch:2 step:1992 [D loss: 0.572544, acc.: 72.66%] [G loss: 1.079587]\n",
      "epoch:2 step:1993 [D loss: 0.598037, acc.: 69.53%] [G loss: 1.121874]\n",
      "epoch:2 step:1994 [D loss: 0.700644, acc.: 63.28%] [G loss: 1.012221]\n",
      "epoch:2 step:1995 [D loss: 0.670816, acc.: 57.81%] [G loss: 0.892428]\n",
      "epoch:2 step:1996 [D loss: 0.617863, acc.: 64.84%] [G loss: 0.912437]\n",
      "epoch:2 step:1997 [D loss: 0.635574, acc.: 62.50%] [G loss: 0.914759]\n",
      "epoch:2 step:1998 [D loss: 0.655278, acc.: 60.94%] [G loss: 1.003129]\n",
      "epoch:2 step:1999 [D loss: 0.596630, acc.: 68.75%] [G loss: 0.944902]\n",
      "epoch:2 step:2000 [D loss: 0.626268, acc.: 63.28%] [G loss: 0.958264]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.299485\n",
      "FID: 64.746651\n",
      "0 = 13.493807009267853\n",
      "1 = 0.119885228425732\n",
      "2 = 0.9907000064849854\n",
      "3 = 0.9814000129699707\n",
      "4 = 1.0\n",
      "5 = 1.0\n",
      "6 = 0.9814000129699707\n",
      "7 = 10.284325661623484\n",
      "8 = 0.15765285159362194\n",
      "9 = 0.940750002861023\n",
      "10 = 0.9071999788284302\n",
      "11 = 0.9743000268936157\n",
      "12 = 0.9724515080451965\n",
      "13 = 0.9071999788284302\n",
      "14 = 5.299517631530762\n",
      "15 = 8.984735488891602\n",
      "16 = 0.274934858083725\n",
      "17 = 5.299485206604004\n",
      "18 = 64.74665069580078\n",
      "epoch:2 step:2001 [D loss: 0.591258, acc.: 71.09%] [G loss: 0.964412]\n",
      "epoch:2 step:2002 [D loss: 0.608399, acc.: 63.28%] [G loss: 0.989935]\n",
      "epoch:2 step:2003 [D loss: 0.646497, acc.: 59.38%] [G loss: 0.975050]\n",
      "epoch:2 step:2004 [D loss: 0.564533, acc.: 70.31%] [G loss: 0.917738]\n",
      "epoch:2 step:2005 [D loss: 0.552076, acc.: 73.44%] [G loss: 1.000499]\n",
      "epoch:2 step:2006 [D loss: 0.610525, acc.: 65.62%] [G loss: 0.960588]\n",
      "epoch:2 step:2007 [D loss: 0.654752, acc.: 67.97%] [G loss: 0.945375]\n",
      "epoch:2 step:2008 [D loss: 0.554582, acc.: 78.12%] [G loss: 0.920724]\n",
      "epoch:2 step:2009 [D loss: 0.540710, acc.: 75.78%] [G loss: 0.986004]\n",
      "epoch:2 step:2010 [D loss: 0.601277, acc.: 70.31%] [G loss: 0.953843]\n",
      "epoch:2 step:2011 [D loss: 0.617066, acc.: 68.75%] [G loss: 0.916275]\n",
      "epoch:2 step:2012 [D loss: 0.641636, acc.: 59.38%] [G loss: 0.893678]\n",
      "epoch:2 step:2013 [D loss: 0.645768, acc.: 64.06%] [G loss: 0.970297]\n",
      "epoch:2 step:2014 [D loss: 0.609654, acc.: 64.84%] [G loss: 0.940851]\n",
      "epoch:2 step:2015 [D loss: 0.579412, acc.: 72.66%] [G loss: 0.908373]\n",
      "epoch:2 step:2016 [D loss: 0.576975, acc.: 70.31%] [G loss: 1.007112]\n",
      "epoch:2 step:2017 [D loss: 0.646949, acc.: 60.94%] [G loss: 1.063847]\n",
      "epoch:2 step:2018 [D loss: 0.577530, acc.: 65.62%] [G loss: 1.014236]\n",
      "epoch:2 step:2019 [D loss: 0.558966, acc.: 75.78%] [G loss: 1.037600]\n",
      "epoch:2 step:2020 [D loss: 0.617575, acc.: 64.84%] [G loss: 0.952295]\n",
      "epoch:2 step:2021 [D loss: 0.601784, acc.: 68.75%] [G loss: 0.947136]\n",
      "epoch:2 step:2022 [D loss: 0.611165, acc.: 67.97%] [G loss: 0.967400]\n",
      "epoch:2 step:2023 [D loss: 0.564308, acc.: 71.88%] [G loss: 0.962132]\n",
      "epoch:2 step:2024 [D loss: 0.653979, acc.: 66.41%] [G loss: 0.896933]\n",
      "epoch:2 step:2025 [D loss: 0.619115, acc.: 64.06%] [G loss: 0.879207]\n",
      "epoch:2 step:2026 [D loss: 0.546181, acc.: 74.22%] [G loss: 0.997271]\n",
      "epoch:2 step:2027 [D loss: 0.616956, acc.: 64.06%] [G loss: 0.941374]\n",
      "epoch:2 step:2028 [D loss: 0.621369, acc.: 65.62%] [G loss: 0.935568]\n",
      "epoch:2 step:2029 [D loss: 0.560342, acc.: 71.09%] [G loss: 1.004779]\n",
      "epoch:2 step:2030 [D loss: 0.570672, acc.: 77.34%] [G loss: 1.046595]\n",
      "epoch:2 step:2031 [D loss: 0.594815, acc.: 67.97%] [G loss: 1.093429]\n",
      "epoch:2 step:2032 [D loss: 0.601701, acc.: 70.31%] [G loss: 0.968959]\n",
      "epoch:2 step:2033 [D loss: 0.579080, acc.: 69.53%] [G loss: 1.007298]\n",
      "epoch:2 step:2034 [D loss: 0.649149, acc.: 62.50%] [G loss: 0.956818]\n",
      "epoch:2 step:2035 [D loss: 0.619392, acc.: 65.62%] [G loss: 0.915971]\n",
      "epoch:2 step:2036 [D loss: 0.552142, acc.: 72.66%] [G loss: 0.978949]\n",
      "epoch:2 step:2037 [D loss: 0.565145, acc.: 71.88%] [G loss: 0.967729]\n",
      "epoch:2 step:2038 [D loss: 0.571790, acc.: 71.09%] [G loss: 1.013613]\n",
      "epoch:2 step:2039 [D loss: 0.582948, acc.: 70.31%] [G loss: 0.979656]\n",
      "epoch:2 step:2040 [D loss: 0.575673, acc.: 71.88%] [G loss: 1.000346]\n",
      "epoch:2 step:2041 [D loss: 0.653469, acc.: 61.72%] [G loss: 1.005433]\n",
      "epoch:2 step:2042 [D loss: 0.565986, acc.: 78.12%] [G loss: 0.959520]\n",
      "epoch:2 step:2043 [D loss: 0.633707, acc.: 61.72%] [G loss: 0.978083]\n",
      "epoch:2 step:2044 [D loss: 0.564820, acc.: 78.12%] [G loss: 0.984511]\n",
      "epoch:2 step:2045 [D loss: 0.569035, acc.: 76.56%] [G loss: 0.912877]\n",
      "epoch:2 step:2046 [D loss: 0.608870, acc.: 73.44%] [G loss: 0.955925]\n",
      "epoch:2 step:2047 [D loss: 0.572685, acc.: 74.22%] [G loss: 0.864975]\n",
      "epoch:2 step:2048 [D loss: 0.573898, acc.: 71.88%] [G loss: 0.941334]\n",
      "epoch:2 step:2049 [D loss: 0.576620, acc.: 76.56%] [G loss: 0.980367]\n",
      "epoch:2 step:2050 [D loss: 0.592808, acc.: 70.31%] [G loss: 1.013290]\n",
      "epoch:2 step:2051 [D loss: 0.575251, acc.: 68.75%] [G loss: 0.964660]\n",
      "epoch:2 step:2052 [D loss: 0.598937, acc.: 66.41%] [G loss: 0.953564]\n",
      "epoch:2 step:2053 [D loss: 0.639300, acc.: 60.94%] [G loss: 0.961763]\n",
      "epoch:2 step:2054 [D loss: 0.638684, acc.: 60.94%] [G loss: 0.950347]\n",
      "epoch:2 step:2055 [D loss: 0.602907, acc.: 67.97%] [G loss: 0.901448]\n",
      "epoch:2 step:2056 [D loss: 0.622985, acc.: 67.97%] [G loss: 0.936691]\n",
      "epoch:2 step:2057 [D loss: 0.617921, acc.: 73.44%] [G loss: 0.898664]\n",
      "epoch:2 step:2058 [D loss: 0.618316, acc.: 70.31%] [G loss: 0.893972]\n",
      "epoch:2 step:2059 [D loss: 0.643530, acc.: 64.06%] [G loss: 0.877682]\n",
      "epoch:2 step:2060 [D loss: 0.634297, acc.: 70.31%] [G loss: 0.914079]\n",
      "epoch:2 step:2061 [D loss: 0.648947, acc.: 57.03%] [G loss: 0.968040]\n",
      "epoch:2 step:2062 [D loss: 0.585134, acc.: 72.66%] [G loss: 0.906930]\n",
      "epoch:2 step:2063 [D loss: 0.591493, acc.: 70.31%] [G loss: 0.887235]\n",
      "epoch:2 step:2064 [D loss: 0.587726, acc.: 75.78%] [G loss: 0.972828]\n",
      "epoch:2 step:2065 [D loss: 0.580357, acc.: 75.00%] [G loss: 0.932257]\n",
      "epoch:2 step:2066 [D loss: 0.604980, acc.: 68.75%] [G loss: 1.003629]\n",
      "epoch:2 step:2067 [D loss: 0.615898, acc.: 64.84%] [G loss: 0.971310]\n",
      "epoch:2 step:2068 [D loss: 0.559490, acc.: 75.78%] [G loss: 0.991654]\n",
      "epoch:2 step:2069 [D loss: 0.583355, acc.: 73.44%] [G loss: 1.035872]\n",
      "epoch:2 step:2070 [D loss: 0.654112, acc.: 57.81%] [G loss: 0.945146]\n",
      "epoch:2 step:2071 [D loss: 0.600002, acc.: 65.62%] [G loss: 0.994911]\n",
      "epoch:2 step:2072 [D loss: 0.653852, acc.: 59.38%] [G loss: 1.019009]\n",
      "epoch:2 step:2073 [D loss: 0.631602, acc.: 64.06%] [G loss: 0.983526]\n",
      "epoch:2 step:2074 [D loss: 0.635341, acc.: 64.06%] [G loss: 0.937582]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2075 [D loss: 0.615647, acc.: 67.19%] [G loss: 0.955523]\n",
      "epoch:2 step:2076 [D loss: 0.610095, acc.: 71.88%] [G loss: 0.913893]\n",
      "epoch:2 step:2077 [D loss: 0.674652, acc.: 61.72%] [G loss: 0.856834]\n",
      "epoch:2 step:2078 [D loss: 0.598717, acc.: 64.84%] [G loss: 0.818023]\n",
      "epoch:2 step:2079 [D loss: 0.567569, acc.: 72.66%] [G loss: 0.907809]\n",
      "epoch:2 step:2080 [D loss: 0.568483, acc.: 74.22%] [G loss: 0.907188]\n",
      "epoch:2 step:2081 [D loss: 0.524810, acc.: 80.47%] [G loss: 1.013081]\n",
      "epoch:2 step:2082 [D loss: 0.590678, acc.: 68.75%] [G loss: 0.961724]\n",
      "epoch:2 step:2083 [D loss: 0.580483, acc.: 71.09%] [G loss: 0.939360]\n",
      "epoch:2 step:2084 [D loss: 0.623331, acc.: 68.75%] [G loss: 0.962956]\n",
      "epoch:2 step:2085 [D loss: 0.624546, acc.: 64.84%] [G loss: 0.924653]\n",
      "epoch:2 step:2086 [D loss: 0.610891, acc.: 67.19%] [G loss: 0.956430]\n",
      "epoch:2 step:2087 [D loss: 0.600553, acc.: 65.62%] [G loss: 0.922643]\n",
      "epoch:2 step:2088 [D loss: 0.658118, acc.: 57.03%] [G loss: 0.906518]\n",
      "epoch:2 step:2089 [D loss: 0.697625, acc.: 55.47%] [G loss: 0.867208]\n",
      "epoch:2 step:2090 [D loss: 0.622197, acc.: 66.41%] [G loss: 0.853055]\n",
      "epoch:2 step:2091 [D loss: 0.587188, acc.: 70.31%] [G loss: 0.922220]\n",
      "epoch:2 step:2092 [D loss: 0.578656, acc.: 74.22%] [G loss: 0.941287]\n",
      "epoch:2 step:2093 [D loss: 0.608616, acc.: 66.41%] [G loss: 0.943163]\n",
      "epoch:2 step:2094 [D loss: 0.662100, acc.: 60.94%] [G loss: 0.865445]\n",
      "epoch:2 step:2095 [D loss: 0.549388, acc.: 71.09%] [G loss: 0.971392]\n",
      "epoch:2 step:2096 [D loss: 0.568810, acc.: 72.66%] [G loss: 0.935487]\n",
      "epoch:2 step:2097 [D loss: 0.527560, acc.: 76.56%] [G loss: 0.973895]\n",
      "epoch:2 step:2098 [D loss: 0.675762, acc.: 64.06%] [G loss: 0.847799]\n",
      "epoch:2 step:2099 [D loss: 0.712994, acc.: 53.12%] [G loss: 0.854944]\n",
      "epoch:2 step:2100 [D loss: 0.600038, acc.: 69.53%] [G loss: 0.919129]\n",
      "epoch:2 step:2101 [D loss: 0.609589, acc.: 67.19%] [G loss: 0.897258]\n",
      "epoch:2 step:2102 [D loss: 0.656123, acc.: 57.03%] [G loss: 0.922554]\n",
      "epoch:2 step:2103 [D loss: 0.638004, acc.: 70.31%] [G loss: 0.903972]\n",
      "epoch:2 step:2104 [D loss: 0.578459, acc.: 66.41%] [G loss: 0.940961]\n",
      "epoch:2 step:2105 [D loss: 0.576089, acc.: 67.19%] [G loss: 0.996815]\n",
      "epoch:2 step:2106 [D loss: 0.538322, acc.: 74.22%] [G loss: 0.992713]\n",
      "epoch:2 step:2107 [D loss: 0.646320, acc.: 63.28%] [G loss: 0.981611]\n",
      "epoch:2 step:2108 [D loss: 0.679308, acc.: 57.03%] [G loss: 0.956150]\n",
      "epoch:2 step:2109 [D loss: 0.568636, acc.: 78.12%] [G loss: 0.965939]\n",
      "epoch:2 step:2110 [D loss: 0.574600, acc.: 76.56%] [G loss: 0.963627]\n",
      "epoch:2 step:2111 [D loss: 0.622534, acc.: 64.84%] [G loss: 0.980948]\n",
      "epoch:2 step:2112 [D loss: 0.619442, acc.: 68.75%] [G loss: 0.973443]\n",
      "epoch:2 step:2113 [D loss: 0.585384, acc.: 71.88%] [G loss: 0.967902]\n",
      "epoch:2 step:2114 [D loss: 0.579107, acc.: 69.53%] [G loss: 0.918158]\n",
      "epoch:2 step:2115 [D loss: 0.575483, acc.: 68.75%] [G loss: 0.977193]\n",
      "epoch:2 step:2116 [D loss: 0.621385, acc.: 64.06%] [G loss: 0.949907]\n",
      "epoch:2 step:2117 [D loss: 0.593346, acc.: 69.53%] [G loss: 0.957682]\n",
      "epoch:2 step:2118 [D loss: 0.568149, acc.: 75.00%] [G loss: 0.960946]\n",
      "epoch:2 step:2119 [D loss: 0.600326, acc.: 64.84%] [G loss: 0.976781]\n",
      "epoch:2 step:2120 [D loss: 0.615810, acc.: 69.53%] [G loss: 0.990095]\n",
      "epoch:2 step:2121 [D loss: 0.618017, acc.: 66.41%] [G loss: 0.888724]\n",
      "epoch:2 step:2122 [D loss: 0.616468, acc.: 68.75%] [G loss: 0.967290]\n",
      "epoch:2 step:2123 [D loss: 0.636503, acc.: 62.50%] [G loss: 0.947573]\n",
      "epoch:2 step:2124 [D loss: 0.651290, acc.: 60.16%] [G loss: 0.939983]\n",
      "epoch:2 step:2125 [D loss: 0.623229, acc.: 67.97%] [G loss: 0.962986]\n",
      "epoch:2 step:2126 [D loss: 0.617776, acc.: 69.53%] [G loss: 0.917650]\n",
      "epoch:2 step:2127 [D loss: 0.577613, acc.: 69.53%] [G loss: 0.899278]\n",
      "epoch:2 step:2128 [D loss: 0.573189, acc.: 72.66%] [G loss: 0.971633]\n",
      "epoch:2 step:2129 [D loss: 0.606171, acc.: 67.19%] [G loss: 0.924543]\n",
      "epoch:2 step:2130 [D loss: 0.598133, acc.: 67.97%] [G loss: 0.947053]\n",
      "epoch:2 step:2131 [D loss: 0.603920, acc.: 71.88%] [G loss: 0.942837]\n",
      "epoch:2 step:2132 [D loss: 0.604844, acc.: 71.09%] [G loss: 0.987556]\n",
      "epoch:2 step:2133 [D loss: 0.577615, acc.: 72.66%] [G loss: 0.992797]\n",
      "epoch:2 step:2134 [D loss: 0.589567, acc.: 71.09%] [G loss: 0.944973]\n",
      "epoch:2 step:2135 [D loss: 0.611924, acc.: 64.84%] [G loss: 0.906383]\n",
      "epoch:2 step:2136 [D loss: 0.613223, acc.: 68.75%] [G loss: 0.893587]\n",
      "epoch:2 step:2137 [D loss: 0.684021, acc.: 59.38%] [G loss: 0.870756]\n",
      "epoch:2 step:2138 [D loss: 0.609346, acc.: 65.62%] [G loss: 0.874316]\n",
      "epoch:2 step:2139 [D loss: 0.620293, acc.: 70.31%] [G loss: 0.928080]\n",
      "epoch:2 step:2140 [D loss: 0.616012, acc.: 69.53%] [G loss: 0.937782]\n",
      "epoch:2 step:2141 [D loss: 0.662404, acc.: 55.47%] [G loss: 0.888400]\n",
      "epoch:2 step:2142 [D loss: 0.631190, acc.: 63.28%] [G loss: 0.937030]\n",
      "epoch:2 step:2143 [D loss: 0.619273, acc.: 67.19%] [G loss: 0.911858]\n",
      "epoch:2 step:2144 [D loss: 0.608905, acc.: 64.84%] [G loss: 0.911472]\n",
      "epoch:2 step:2145 [D loss: 0.547452, acc.: 73.44%] [G loss: 0.917626]\n",
      "epoch:2 step:2146 [D loss: 0.614742, acc.: 67.97%] [G loss: 0.916172]\n",
      "epoch:2 step:2147 [D loss: 0.537596, acc.: 76.56%] [G loss: 0.944743]\n",
      "epoch:2 step:2148 [D loss: 0.658907, acc.: 59.38%] [G loss: 0.965111]\n",
      "epoch:2 step:2149 [D loss: 0.657251, acc.: 63.28%] [G loss: 0.892134]\n",
      "epoch:2 step:2150 [D loss: 0.648711, acc.: 57.03%] [G loss: 0.919471]\n",
      "epoch:2 step:2151 [D loss: 0.659599, acc.: 54.69%] [G loss: 0.846078]\n",
      "epoch:2 step:2152 [D loss: 0.640451, acc.: 65.62%] [G loss: 0.954771]\n",
      "epoch:2 step:2153 [D loss: 0.632066, acc.: 62.50%] [G loss: 0.982898]\n",
      "epoch:2 step:2154 [D loss: 0.639227, acc.: 64.06%] [G loss: 0.990781]\n",
      "epoch:2 step:2155 [D loss: 0.678024, acc.: 54.69%] [G loss: 0.834768]\n",
      "epoch:2 step:2156 [D loss: 0.618180, acc.: 62.50%] [G loss: 0.853115]\n",
      "epoch:2 step:2157 [D loss: 0.596110, acc.: 67.19%] [G loss: 0.935978]\n",
      "epoch:2 step:2158 [D loss: 0.571718, acc.: 75.00%] [G loss: 0.918379]\n",
      "epoch:2 step:2159 [D loss: 0.599720, acc.: 74.22%] [G loss: 0.933931]\n",
      "epoch:2 step:2160 [D loss: 0.557180, acc.: 74.22%] [G loss: 0.941230]\n",
      "epoch:2 step:2161 [D loss: 0.634604, acc.: 64.84%] [G loss: 0.939027]\n",
      "epoch:2 step:2162 [D loss: 0.612870, acc.: 66.41%] [G loss: 0.936265]\n",
      "epoch:2 step:2163 [D loss: 0.603474, acc.: 67.19%] [G loss: 0.954090]\n",
      "epoch:2 step:2164 [D loss: 0.637560, acc.: 66.41%] [G loss: 0.986016]\n",
      "epoch:2 step:2165 [D loss: 0.620377, acc.: 61.72%] [G loss: 0.933610]\n",
      "epoch:2 step:2166 [D loss: 0.614256, acc.: 66.41%] [G loss: 0.858388]\n",
      "epoch:2 step:2167 [D loss: 0.575476, acc.: 70.31%] [G loss: 0.909752]\n",
      "epoch:2 step:2168 [D loss: 0.633337, acc.: 60.16%] [G loss: 0.899799]\n",
      "epoch:2 step:2169 [D loss: 0.601525, acc.: 72.66%] [G loss: 0.942254]\n",
      "epoch:2 step:2170 [D loss: 0.585793, acc.: 61.72%] [G loss: 0.943271]\n",
      "epoch:2 step:2171 [D loss: 0.603331, acc.: 68.75%] [G loss: 0.971452]\n",
      "epoch:2 step:2172 [D loss: 0.589826, acc.: 74.22%] [G loss: 0.951152]\n",
      "epoch:2 step:2173 [D loss: 0.627485, acc.: 65.62%] [G loss: 0.957695]\n",
      "epoch:2 step:2174 [D loss: 0.615518, acc.: 64.84%] [G loss: 0.949511]\n",
      "epoch:2 step:2175 [D loss: 0.624320, acc.: 67.19%] [G loss: 0.965108]\n",
      "epoch:2 step:2176 [D loss: 0.593959, acc.: 71.88%] [G loss: 0.929277]\n",
      "epoch:2 step:2177 [D loss: 0.594787, acc.: 74.22%] [G loss: 0.948650]\n",
      "epoch:2 step:2178 [D loss: 0.548492, acc.: 74.22%] [G loss: 0.952832]\n",
      "epoch:2 step:2179 [D loss: 0.597998, acc.: 65.62%] [G loss: 0.962157]\n",
      "epoch:2 step:2180 [D loss: 0.594997, acc.: 73.44%] [G loss: 1.000809]\n",
      "epoch:2 step:2181 [D loss: 0.581444, acc.: 71.09%] [G loss: 0.936589]\n",
      "epoch:2 step:2182 [D loss: 0.588481, acc.: 67.97%] [G loss: 1.023387]\n",
      "epoch:2 step:2183 [D loss: 0.584804, acc.: 73.44%] [G loss: 0.955757]\n",
      "epoch:2 step:2184 [D loss: 0.537040, acc.: 75.00%] [G loss: 1.062463]\n",
      "epoch:2 step:2185 [D loss: 0.561260, acc.: 69.53%] [G loss: 1.063021]\n",
      "epoch:2 step:2186 [D loss: 0.497180, acc.: 77.34%] [G loss: 1.153438]\n",
      "epoch:2 step:2187 [D loss: 0.512943, acc.: 73.44%] [G loss: 1.102195]\n",
      "epoch:2 step:2188 [D loss: 0.572792, acc.: 75.00%] [G loss: 1.187351]\n",
      "epoch:2 step:2189 [D loss: 0.539350, acc.: 73.44%] [G loss: 1.144592]\n",
      "epoch:2 step:2190 [D loss: 0.735628, acc.: 58.59%] [G loss: 1.029620]\n",
      "epoch:2 step:2191 [D loss: 0.627757, acc.: 68.75%] [G loss: 0.909035]\n",
      "epoch:2 step:2192 [D loss: 0.591358, acc.: 72.66%] [G loss: 0.994628]\n",
      "epoch:2 step:2193 [D loss: 0.592180, acc.: 73.44%] [G loss: 0.946958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2194 [D loss: 0.574039, acc.: 79.69%] [G loss: 0.966063]\n",
      "epoch:2 step:2195 [D loss: 0.586588, acc.: 71.09%] [G loss: 0.983922]\n",
      "epoch:2 step:2196 [D loss: 0.594209, acc.: 66.41%] [G loss: 0.970047]\n",
      "epoch:2 step:2197 [D loss: 0.597602, acc.: 64.84%] [G loss: 0.950132]\n",
      "epoch:2 step:2198 [D loss: 0.606245, acc.: 65.62%] [G loss: 0.958193]\n",
      "epoch:2 step:2199 [D loss: 0.592841, acc.: 74.22%] [G loss: 0.949281]\n",
      "epoch:2 step:2200 [D loss: 0.624727, acc.: 68.75%] [G loss: 1.008530]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.442069\n",
      "FID: 62.581429\n",
      "0 = 13.287014972829787\n",
      "1 = 0.10692188773684026\n",
      "2 = 0.9885500073432922\n",
      "3 = 0.9771000146865845\n",
      "4 = 1.0\n",
      "5 = 1.0\n",
      "6 = 0.9771000146865845\n",
      "7 = 10.173481461453433\n",
      "8 = 0.1603808804843993\n",
      "9 = 0.9266999959945679\n",
      "10 = 0.8944000005722046\n",
      "11 = 0.9589999914169312\n",
      "12 = 0.9561684727668762\n",
      "13 = 0.8944000005722046\n",
      "14 = 5.442109107971191\n",
      "15 = 9.096559524536133\n",
      "16 = 0.24246488511562347\n",
      "17 = 5.442069053649902\n",
      "18 = 62.58142852783203\n",
      "epoch:2 step:2201 [D loss: 0.556299, acc.: 75.78%] [G loss: 0.998848]\n",
      "epoch:2 step:2202 [D loss: 0.635995, acc.: 64.06%] [G loss: 0.974736]\n",
      "epoch:2 step:2203 [D loss: 0.606518, acc.: 65.62%] [G loss: 0.955553]\n",
      "epoch:2 step:2204 [D loss: 0.596967, acc.: 65.62%] [G loss: 0.972872]\n",
      "epoch:2 step:2205 [D loss: 0.591751, acc.: 72.66%] [G loss: 0.973235]\n",
      "epoch:2 step:2206 [D loss: 0.570990, acc.: 73.44%] [G loss: 0.996443]\n",
      "epoch:2 step:2207 [D loss: 0.587105, acc.: 71.88%] [G loss: 1.002341]\n",
      "epoch:2 step:2208 [D loss: 0.585473, acc.: 71.88%] [G loss: 0.944184]\n",
      "epoch:2 step:2209 [D loss: 0.582095, acc.: 73.44%] [G loss: 1.002370]\n",
      "epoch:2 step:2210 [D loss: 0.609905, acc.: 66.41%] [G loss: 1.011104]\n",
      "epoch:2 step:2211 [D loss: 0.567203, acc.: 71.88%] [G loss: 0.950438]\n",
      "epoch:2 step:2212 [D loss: 0.613434, acc.: 64.84%] [G loss: 0.932546]\n",
      "epoch:2 step:2213 [D loss: 0.617184, acc.: 64.06%] [G loss: 0.970409]\n",
      "epoch:2 step:2214 [D loss: 0.580305, acc.: 76.56%] [G loss: 0.945742]\n",
      "epoch:2 step:2215 [D loss: 0.650880, acc.: 61.72%] [G loss: 0.929809]\n",
      "epoch:2 step:2216 [D loss: 0.625341, acc.: 66.41%] [G loss: 0.891998]\n",
      "epoch:2 step:2217 [D loss: 0.580324, acc.: 69.53%] [G loss: 1.000275]\n",
      "epoch:2 step:2218 [D loss: 0.539422, acc.: 78.91%] [G loss: 0.973051]\n",
      "epoch:2 step:2219 [D loss: 0.574584, acc.: 75.00%] [G loss: 1.025338]\n",
      "epoch:2 step:2220 [D loss: 0.567111, acc.: 69.53%] [G loss: 1.061266]\n",
      "epoch:2 step:2221 [D loss: 0.589600, acc.: 66.41%] [G loss: 1.081001]\n",
      "epoch:2 step:2222 [D loss: 0.676820, acc.: 61.72%] [G loss: 0.998873]\n",
      "epoch:2 step:2223 [D loss: 0.719227, acc.: 55.47%] [G loss: 0.905241]\n",
      "epoch:2 step:2224 [D loss: 0.577740, acc.: 72.66%] [G loss: 0.929104]\n",
      "epoch:2 step:2225 [D loss: 0.557041, acc.: 78.12%] [G loss: 1.002353]\n",
      "epoch:2 step:2226 [D loss: 0.630620, acc.: 60.94%] [G loss: 0.912466]\n",
      "epoch:2 step:2227 [D loss: 0.619951, acc.: 67.97%] [G loss: 0.957275]\n",
      "epoch:2 step:2228 [D loss: 0.580717, acc.: 71.09%] [G loss: 0.999829]\n",
      "epoch:2 step:2229 [D loss: 0.608588, acc.: 65.62%] [G loss: 1.030054]\n",
      "epoch:2 step:2230 [D loss: 0.631231, acc.: 60.94%] [G loss: 1.033128]\n",
      "epoch:2 step:2231 [D loss: 0.574564, acc.: 73.44%] [G loss: 1.029549]\n",
      "epoch:2 step:2232 [D loss: 0.568419, acc.: 71.88%] [G loss: 1.006215]\n",
      "epoch:2 step:2233 [D loss: 0.568812, acc.: 71.88%] [G loss: 1.006362]\n",
      "epoch:2 step:2234 [D loss: 0.628972, acc.: 66.41%] [G loss: 0.998999]\n",
      "epoch:2 step:2235 [D loss: 0.567498, acc.: 77.34%] [G loss: 0.983381]\n",
      "epoch:2 step:2236 [D loss: 0.635948, acc.: 64.06%] [G loss: 0.887175]\n",
      "epoch:2 step:2237 [D loss: 0.579034, acc.: 71.88%] [G loss: 0.953270]\n",
      "epoch:2 step:2238 [D loss: 0.591585, acc.: 72.66%] [G loss: 0.956302]\n",
      "epoch:2 step:2239 [D loss: 0.585030, acc.: 65.62%] [G loss: 0.913170]\n",
      "epoch:2 step:2240 [D loss: 0.612404, acc.: 63.28%] [G loss: 1.006141]\n",
      "epoch:2 step:2241 [D loss: 0.607768, acc.: 68.75%] [G loss: 0.982880]\n",
      "epoch:2 step:2242 [D loss: 0.624427, acc.: 66.41%] [G loss: 0.938253]\n",
      "epoch:2 step:2243 [D loss: 0.632499, acc.: 63.28%] [G loss: 0.944088]\n",
      "epoch:2 step:2244 [D loss: 0.610605, acc.: 69.53%] [G loss: 0.990445]\n",
      "epoch:2 step:2245 [D loss: 0.599928, acc.: 65.62%] [G loss: 0.937127]\n",
      "epoch:2 step:2246 [D loss: 0.593932, acc.: 67.19%] [G loss: 0.985802]\n",
      "epoch:2 step:2247 [D loss: 0.626137, acc.: 70.31%] [G loss: 0.916632]\n",
      "epoch:2 step:2248 [D loss: 0.562255, acc.: 71.88%] [G loss: 0.967948]\n",
      "epoch:2 step:2249 [D loss: 0.616357, acc.: 64.84%] [G loss: 0.989035]\n",
      "epoch:2 step:2250 [D loss: 0.646968, acc.: 59.38%] [G loss: 0.852482]\n",
      "epoch:2 step:2251 [D loss: 0.626054, acc.: 70.31%] [G loss: 0.828779]\n",
      "epoch:2 step:2252 [D loss: 0.593996, acc.: 69.53%] [G loss: 0.936917]\n",
      "epoch:2 step:2253 [D loss: 0.607173, acc.: 67.97%] [G loss: 0.946910]\n",
      "epoch:2 step:2254 [D loss: 0.607810, acc.: 67.97%] [G loss: 0.945749]\n",
      "epoch:2 step:2255 [D loss: 0.535103, acc.: 79.69%] [G loss: 0.956163]\n",
      "epoch:2 step:2256 [D loss: 0.574218, acc.: 74.22%] [G loss: 0.986033]\n",
      "epoch:2 step:2257 [D loss: 0.605656, acc.: 67.97%] [G loss: 0.977715]\n",
      "epoch:2 step:2258 [D loss: 0.594941, acc.: 67.97%] [G loss: 0.985830]\n",
      "epoch:2 step:2259 [D loss: 0.607110, acc.: 64.84%] [G loss: 0.966658]\n",
      "epoch:2 step:2260 [D loss: 0.665330, acc.: 60.94%] [G loss: 0.940243]\n",
      "epoch:2 step:2261 [D loss: 0.638324, acc.: 61.72%] [G loss: 0.935632]\n",
      "epoch:2 step:2262 [D loss: 0.602988, acc.: 71.09%] [G loss: 0.983065]\n",
      "epoch:2 step:2263 [D loss: 0.583681, acc.: 73.44%] [G loss: 1.016332]\n",
      "epoch:2 step:2264 [D loss: 0.600426, acc.: 70.31%] [G loss: 0.989384]\n",
      "epoch:2 step:2265 [D loss: 0.573313, acc.: 76.56%] [G loss: 0.968966]\n",
      "epoch:2 step:2266 [D loss: 0.562561, acc.: 74.22%] [G loss: 0.992946]\n",
      "epoch:2 step:2267 [D loss: 0.608497, acc.: 68.75%] [G loss: 0.950887]\n",
      "epoch:2 step:2268 [D loss: 0.558163, acc.: 78.91%] [G loss: 0.926759]\n",
      "epoch:2 step:2269 [D loss: 0.589211, acc.: 71.88%] [G loss: 0.898027]\n",
      "epoch:2 step:2270 [D loss: 0.685869, acc.: 54.69%] [G loss: 0.939135]\n",
      "epoch:2 step:2271 [D loss: 0.549826, acc.: 74.22%] [G loss: 1.032538]\n",
      "epoch:2 step:2272 [D loss: 0.553478, acc.: 75.78%] [G loss: 0.980200]\n",
      "epoch:2 step:2273 [D loss: 0.540988, acc.: 76.56%] [G loss: 1.015486]\n",
      "epoch:2 step:2274 [D loss: 0.661066, acc.: 61.72%] [G loss: 0.948378]\n",
      "epoch:2 step:2275 [D loss: 0.589099, acc.: 72.66%] [G loss: 0.897361]\n",
      "epoch:2 step:2276 [D loss: 0.557545, acc.: 71.88%] [G loss: 0.985018]\n",
      "epoch:2 step:2277 [D loss: 0.628113, acc.: 67.97%] [G loss: 0.924989]\n",
      "epoch:2 step:2278 [D loss: 0.615098, acc.: 67.19%] [G loss: 0.893063]\n",
      "epoch:2 step:2279 [D loss: 0.610624, acc.: 66.41%] [G loss: 0.931343]\n",
      "epoch:2 step:2280 [D loss: 0.605709, acc.: 66.41%] [G loss: 0.930217]\n",
      "epoch:2 step:2281 [D loss: 0.589571, acc.: 65.62%] [G loss: 0.883803]\n",
      "epoch:2 step:2282 [D loss: 0.592726, acc.: 67.19%] [G loss: 0.924442]\n",
      "epoch:2 step:2283 [D loss: 0.614651, acc.: 66.41%] [G loss: 0.919720]\n",
      "epoch:2 step:2284 [D loss: 0.628964, acc.: 67.97%] [G loss: 0.918634]\n",
      "epoch:2 step:2285 [D loss: 0.621284, acc.: 67.97%] [G loss: 0.910076]\n",
      "epoch:2 step:2286 [D loss: 0.622113, acc.: 65.62%] [G loss: 0.927647]\n",
      "epoch:2 step:2287 [D loss: 0.588474, acc.: 74.22%] [G loss: 0.925364]\n",
      "epoch:2 step:2288 [D loss: 0.670641, acc.: 61.72%] [G loss: 0.964761]\n",
      "epoch:2 step:2289 [D loss: 0.595500, acc.: 69.53%] [G loss: 1.025636]\n",
      "epoch:2 step:2290 [D loss: 0.615061, acc.: 64.84%] [G loss: 0.963694]\n",
      "epoch:2 step:2291 [D loss: 0.695412, acc.: 56.25%] [G loss: 0.962123]\n",
      "epoch:2 step:2292 [D loss: 0.644534, acc.: 65.62%] [G loss: 0.886897]\n",
      "epoch:2 step:2293 [D loss: 0.627953, acc.: 64.06%] [G loss: 0.857883]\n",
      "epoch:2 step:2294 [D loss: 0.633575, acc.: 61.72%] [G loss: 0.904415]\n",
      "epoch:2 step:2295 [D loss: 0.645786, acc.: 64.06%] [G loss: 0.897599]\n",
      "epoch:2 step:2296 [D loss: 0.601244, acc.: 69.53%] [G loss: 0.955702]\n",
      "epoch:2 step:2297 [D loss: 0.662348, acc.: 64.84%] [G loss: 0.914428]\n",
      "epoch:2 step:2298 [D loss: 0.626842, acc.: 68.75%] [G loss: 0.901041]\n",
      "epoch:2 step:2299 [D loss: 0.602613, acc.: 72.66%] [G loss: 0.964783]\n",
      "epoch:2 step:2300 [D loss: 0.566152, acc.: 75.78%] [G loss: 0.947371]\n",
      "epoch:2 step:2301 [D loss: 0.531229, acc.: 75.78%] [G loss: 0.915035]\n",
      "epoch:2 step:2302 [D loss: 0.549858, acc.: 74.22%] [G loss: 1.027670]\n",
      "epoch:2 step:2303 [D loss: 0.584322, acc.: 71.09%] [G loss: 0.994314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2304 [D loss: 0.574804, acc.: 71.09%] [G loss: 1.138634]\n",
      "epoch:2 step:2305 [D loss: 0.579695, acc.: 76.56%] [G loss: 1.041390]\n",
      "epoch:2 step:2306 [D loss: 0.661146, acc.: 57.03%] [G loss: 0.926443]\n",
      "epoch:2 step:2307 [D loss: 0.577713, acc.: 71.09%] [G loss: 0.955979]\n",
      "epoch:2 step:2308 [D loss: 0.607208, acc.: 67.97%] [G loss: 0.849240]\n",
      "epoch:2 step:2309 [D loss: 0.592421, acc.: 72.66%] [G loss: 0.892055]\n",
      "epoch:2 step:2310 [D loss: 0.601056, acc.: 66.41%] [G loss: 0.877039]\n",
      "epoch:2 step:2311 [D loss: 0.675841, acc.: 59.38%] [G loss: 0.909648]\n",
      "epoch:2 step:2312 [D loss: 0.637620, acc.: 62.50%] [G loss: 0.882238]\n",
      "epoch:2 step:2313 [D loss: 0.592000, acc.: 71.09%] [G loss: 0.951533]\n",
      "epoch:2 step:2314 [D loss: 0.609900, acc.: 67.97%] [G loss: 0.948014]\n",
      "epoch:2 step:2315 [D loss: 0.621276, acc.: 66.41%] [G loss: 0.931183]\n",
      "epoch:2 step:2316 [D loss: 0.633726, acc.: 66.41%] [G loss: 0.876591]\n",
      "epoch:2 step:2317 [D loss: 0.553454, acc.: 76.56%] [G loss: 0.947919]\n",
      "epoch:2 step:2318 [D loss: 0.600732, acc.: 70.31%] [G loss: 0.909059]\n",
      "epoch:2 step:2319 [D loss: 0.589158, acc.: 71.09%] [G loss: 0.949375]\n",
      "epoch:2 step:2320 [D loss: 0.578170, acc.: 74.22%] [G loss: 0.988877]\n",
      "epoch:2 step:2321 [D loss: 0.552992, acc.: 75.00%] [G loss: 1.034017]\n",
      "epoch:2 step:2322 [D loss: 0.590331, acc.: 72.66%] [G loss: 1.019251]\n",
      "epoch:2 step:2323 [D loss: 0.580065, acc.: 69.53%] [G loss: 1.014677]\n",
      "epoch:2 step:2324 [D loss: 0.527040, acc.: 77.34%] [G loss: 1.033299]\n",
      "epoch:2 step:2325 [D loss: 0.549658, acc.: 75.78%] [G loss: 0.990301]\n",
      "epoch:2 step:2326 [D loss: 0.553763, acc.: 73.44%] [G loss: 1.048728]\n",
      "epoch:2 step:2327 [D loss: 0.568218, acc.: 70.31%] [G loss: 1.015814]\n",
      "epoch:2 step:2328 [D loss: 0.630492, acc.: 64.06%] [G loss: 0.938218]\n",
      "epoch:2 step:2329 [D loss: 0.635048, acc.: 62.50%] [G loss: 0.940429]\n",
      "epoch:2 step:2330 [D loss: 0.626859, acc.: 66.41%] [G loss: 0.957980]\n",
      "epoch:2 step:2331 [D loss: 0.612330, acc.: 65.62%] [G loss: 0.919296]\n",
      "epoch:2 step:2332 [D loss: 0.604447, acc.: 65.62%] [G loss: 0.883754]\n",
      "epoch:2 step:2333 [D loss: 0.648303, acc.: 60.16%] [G loss: 0.943980]\n",
      "epoch:2 step:2334 [D loss: 0.599766, acc.: 64.84%] [G loss: 0.925858]\n",
      "epoch:2 step:2335 [D loss: 0.595776, acc.: 68.75%] [G loss: 0.940419]\n",
      "epoch:2 step:2336 [D loss: 0.575735, acc.: 73.44%] [G loss: 0.900798]\n",
      "epoch:2 step:2337 [D loss: 0.618411, acc.: 67.97%] [G loss: 0.888782]\n",
      "epoch:2 step:2338 [D loss: 0.612242, acc.: 69.53%] [G loss: 0.899074]\n",
      "epoch:2 step:2339 [D loss: 0.641761, acc.: 64.84%] [G loss: 0.928084]\n",
      "epoch:2 step:2340 [D loss: 0.609552, acc.: 67.97%] [G loss: 0.998538]\n",
      "epoch:2 step:2341 [D loss: 0.641109, acc.: 61.72%] [G loss: 1.001707]\n",
      "epoch:2 step:2342 [D loss: 0.597849, acc.: 70.31%] [G loss: 0.963143]\n",
      "epoch:2 step:2343 [D loss: 0.596193, acc.: 64.06%] [G loss: 1.036106]\n",
      "epoch:2 step:2344 [D loss: 0.614384, acc.: 67.97%] [G loss: 1.018286]\n",
      "epoch:2 step:2345 [D loss: 0.559787, acc.: 76.56%] [G loss: 1.038205]\n",
      "epoch:2 step:2346 [D loss: 0.571105, acc.: 71.88%] [G loss: 1.020259]\n",
      "epoch:2 step:2347 [D loss: 0.643398, acc.: 67.97%] [G loss: 0.941953]\n",
      "epoch:2 step:2348 [D loss: 0.534120, acc.: 80.47%] [G loss: 0.972079]\n",
      "epoch:2 step:2349 [D loss: 0.555980, acc.: 70.31%] [G loss: 1.050619]\n",
      "epoch:2 step:2350 [D loss: 0.601765, acc.: 71.09%] [G loss: 1.015135]\n",
      "epoch:2 step:2351 [D loss: 0.713785, acc.: 55.47%] [G loss: 0.906788]\n",
      "epoch:2 step:2352 [D loss: 0.666995, acc.: 64.84%] [G loss: 0.908513]\n",
      "epoch:2 step:2353 [D loss: 0.626975, acc.: 67.19%] [G loss: 0.891654]\n",
      "epoch:2 step:2354 [D loss: 0.608619, acc.: 73.44%] [G loss: 0.897019]\n",
      "epoch:2 step:2355 [D loss: 0.591991, acc.: 73.44%] [G loss: 0.905187]\n",
      "epoch:2 step:2356 [D loss: 0.627033, acc.: 66.41%] [G loss: 0.866897]\n",
      "epoch:2 step:2357 [D loss: 0.625527, acc.: 65.62%] [G loss: 0.859716]\n",
      "epoch:2 step:2358 [D loss: 0.573844, acc.: 77.34%] [G loss: 0.933471]\n",
      "epoch:2 step:2359 [D loss: 0.573780, acc.: 75.78%] [G loss: 0.953105]\n",
      "epoch:2 step:2360 [D loss: 0.677390, acc.: 60.16%] [G loss: 0.951777]\n",
      "epoch:2 step:2361 [D loss: 0.569278, acc.: 76.56%] [G loss: 0.938475]\n",
      "epoch:2 step:2362 [D loss: 0.585357, acc.: 73.44%] [G loss: 0.972488]\n",
      "epoch:2 step:2363 [D loss: 0.639750, acc.: 66.41%] [G loss: 0.981221]\n",
      "epoch:2 step:2364 [D loss: 0.606192, acc.: 71.88%] [G loss: 0.979870]\n",
      "epoch:2 step:2365 [D loss: 0.607633, acc.: 64.84%] [G loss: 0.913698]\n",
      "epoch:2 step:2366 [D loss: 0.623033, acc.: 63.28%] [G loss: 0.944414]\n",
      "epoch:2 step:2367 [D loss: 0.628556, acc.: 63.28%] [G loss: 0.955925]\n",
      "epoch:2 step:2368 [D loss: 0.597632, acc.: 71.09%] [G loss: 0.967208]\n",
      "epoch:2 step:2369 [D loss: 0.630559, acc.: 66.41%] [G loss: 0.936285]\n",
      "epoch:2 step:2370 [D loss: 0.596567, acc.: 70.31%] [G loss: 0.937546]\n",
      "epoch:2 step:2371 [D loss: 0.604909, acc.: 71.09%] [G loss: 1.008152]\n",
      "epoch:2 step:2372 [D loss: 0.554014, acc.: 73.44%] [G loss: 1.031648]\n",
      "epoch:2 step:2373 [D loss: 0.542379, acc.: 72.66%] [G loss: 1.022271]\n",
      "epoch:2 step:2374 [D loss: 0.722065, acc.: 53.91%] [G loss: 0.882045]\n",
      "epoch:2 step:2375 [D loss: 0.718068, acc.: 53.12%] [G loss: 0.908926]\n",
      "epoch:2 step:2376 [D loss: 0.643569, acc.: 66.41%] [G loss: 0.882576]\n",
      "epoch:2 step:2377 [D loss: 0.566695, acc.: 76.56%] [G loss: 0.903290]\n",
      "epoch:2 step:2378 [D loss: 0.533826, acc.: 78.91%] [G loss: 0.990135]\n",
      "epoch:2 step:2379 [D loss: 0.614880, acc.: 64.84%] [G loss: 0.941289]\n",
      "epoch:2 step:2380 [D loss: 0.571924, acc.: 68.75%] [G loss: 0.977446]\n",
      "epoch:2 step:2381 [D loss: 0.608577, acc.: 65.62%] [G loss: 1.026389]\n",
      "epoch:2 step:2382 [D loss: 0.595241, acc.: 65.62%] [G loss: 1.018648]\n",
      "epoch:2 step:2383 [D loss: 0.634364, acc.: 64.06%] [G loss: 1.104054]\n",
      "epoch:2 step:2384 [D loss: 0.608940, acc.: 72.66%] [G loss: 0.955366]\n",
      "epoch:2 step:2385 [D loss: 0.661211, acc.: 60.94%] [G loss: 0.929328]\n",
      "epoch:2 step:2386 [D loss: 0.605081, acc.: 71.09%] [G loss: 0.950821]\n",
      "epoch:2 step:2387 [D loss: 0.582835, acc.: 65.62%] [G loss: 0.922675]\n",
      "epoch:2 step:2388 [D loss: 0.571640, acc.: 73.44%] [G loss: 0.965584]\n",
      "epoch:2 step:2389 [D loss: 0.553535, acc.: 75.78%] [G loss: 0.998870]\n",
      "epoch:2 step:2390 [D loss: 0.554662, acc.: 77.34%] [G loss: 0.940178]\n",
      "epoch:2 step:2391 [D loss: 0.707269, acc.: 53.91%] [G loss: 0.902366]\n",
      "epoch:2 step:2392 [D loss: 0.567474, acc.: 77.34%] [G loss: 0.998526]\n",
      "epoch:2 step:2393 [D loss: 0.565262, acc.: 71.88%] [G loss: 0.975689]\n",
      "epoch:2 step:2394 [D loss: 0.578311, acc.: 71.88%] [G loss: 0.980991]\n",
      "epoch:2 step:2395 [D loss: 0.573870, acc.: 76.56%] [G loss: 0.971098]\n",
      "epoch:2 step:2396 [D loss: 0.602735, acc.: 71.88%] [G loss: 0.949987]\n",
      "epoch:2 step:2397 [D loss: 0.565188, acc.: 72.66%] [G loss: 0.992516]\n",
      "epoch:2 step:2398 [D loss: 0.630933, acc.: 67.19%] [G loss: 0.939192]\n",
      "epoch:2 step:2399 [D loss: 0.632661, acc.: 65.62%] [G loss: 0.971017]\n",
      "epoch:2 step:2400 [D loss: 0.612489, acc.: 65.62%] [G loss: 0.991623]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.774277\n",
      "FID: 55.211723\n",
      "0 = 12.872843379783658\n",
      "1 = 0.10190875377696712\n",
      "2 = 0.9848499894142151\n",
      "3 = 0.9696999788284302\n",
      "4 = 1.0\n",
      "5 = 1.0\n",
      "6 = 0.9696999788284302\n",
      "7 = 9.860792297363355\n",
      "8 = 0.14775369647932068\n",
      "9 = 0.9222999811172485\n",
      "10 = 0.8902000188827515\n",
      "11 = 0.9544000029563904\n",
      "12 = 0.951271653175354\n",
      "13 = 0.8902000188827515\n",
      "14 = 5.77432107925415\n",
      "15 = 9.298201560974121\n",
      "16 = 0.21178919076919556\n",
      "17 = 5.774277210235596\n",
      "18 = 55.21172332763672\n",
      "epoch:2 step:2401 [D loss: 0.665267, acc.: 60.16%] [G loss: 0.985461]\n",
      "epoch:2 step:2402 [D loss: 0.673002, acc.: 59.38%] [G loss: 0.882328]\n",
      "epoch:2 step:2403 [D loss: 0.618881, acc.: 62.50%] [G loss: 0.952819]\n",
      "epoch:2 step:2404 [D loss: 0.539257, acc.: 82.81%] [G loss: 0.998360]\n",
      "epoch:2 step:2405 [D loss: 0.640260, acc.: 69.53%] [G loss: 0.898117]\n",
      "epoch:2 step:2406 [D loss: 0.600783, acc.: 70.31%] [G loss: 0.964004]\n",
      "epoch:2 step:2407 [D loss: 0.656603, acc.: 60.16%] [G loss: 0.923838]\n",
      "epoch:2 step:2408 [D loss: 0.604366, acc.: 69.53%] [G loss: 0.976527]\n",
      "epoch:2 step:2409 [D loss: 0.600817, acc.: 69.53%] [G loss: 0.929501]\n",
      "epoch:2 step:2410 [D loss: 0.598188, acc.: 75.00%] [G loss: 0.874550]\n",
      "epoch:2 step:2411 [D loss: 0.577264, acc.: 75.78%] [G loss: 0.968104]\n",
      "epoch:2 step:2412 [D loss: 0.589912, acc.: 69.53%] [G loss: 0.931611]\n",
      "epoch:2 step:2413 [D loss: 0.621745, acc.: 63.28%] [G loss: 0.921958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2414 [D loss: 0.631303, acc.: 62.50%] [G loss: 0.900345]\n",
      "epoch:2 step:2415 [D loss: 0.589862, acc.: 71.88%] [G loss: 0.925040]\n",
      "epoch:2 step:2416 [D loss: 0.668633, acc.: 60.94%] [G loss: 0.916972]\n",
      "epoch:2 step:2417 [D loss: 0.685409, acc.: 57.03%] [G loss: 0.890785]\n",
      "epoch:2 step:2418 [D loss: 0.621379, acc.: 67.19%] [G loss: 0.949728]\n",
      "epoch:2 step:2419 [D loss: 0.634457, acc.: 62.50%] [G loss: 0.962318]\n",
      "epoch:2 step:2420 [D loss: 0.551203, acc.: 75.78%] [G loss: 0.948790]\n",
      "epoch:2 step:2421 [D loss: 0.586680, acc.: 69.53%] [G loss: 0.972134]\n",
      "epoch:2 step:2422 [D loss: 0.602230, acc.: 66.41%] [G loss: 0.959820]\n",
      "epoch:2 step:2423 [D loss: 0.568320, acc.: 72.66%] [G loss: 0.970860]\n",
      "epoch:2 step:2424 [D loss: 0.599064, acc.: 68.75%] [G loss: 0.938734]\n",
      "epoch:2 step:2425 [D loss: 0.575659, acc.: 71.09%] [G loss: 0.970435]\n",
      "epoch:2 step:2426 [D loss: 0.605945, acc.: 64.06%] [G loss: 0.992491]\n",
      "epoch:2 step:2427 [D loss: 0.609079, acc.: 68.75%] [G loss: 0.954518]\n",
      "epoch:2 step:2428 [D loss: 0.566044, acc.: 69.53%] [G loss: 1.022476]\n",
      "epoch:2 step:2429 [D loss: 0.575387, acc.: 73.44%] [G loss: 0.979193]\n",
      "epoch:2 step:2430 [D loss: 0.538692, acc.: 75.00%] [G loss: 0.969778]\n",
      "epoch:2 step:2431 [D loss: 0.587150, acc.: 68.75%] [G loss: 1.018604]\n",
      "epoch:2 step:2432 [D loss: 0.576706, acc.: 70.31%] [G loss: 0.979484]\n",
      "epoch:2 step:2433 [D loss: 0.663246, acc.: 60.16%] [G loss: 0.974062]\n",
      "epoch:2 step:2434 [D loss: 0.655405, acc.: 60.94%] [G loss: 0.883811]\n",
      "epoch:2 step:2435 [D loss: 0.591413, acc.: 64.84%] [G loss: 0.985062]\n",
      "epoch:2 step:2436 [D loss: 0.628212, acc.: 66.41%] [G loss: 0.969931]\n",
      "epoch:2 step:2437 [D loss: 0.599549, acc.: 71.09%] [G loss: 0.961476]\n",
      "epoch:2 step:2438 [D loss: 0.587014, acc.: 64.84%] [G loss: 1.012007]\n",
      "epoch:2 step:2439 [D loss: 0.652467, acc.: 64.84%] [G loss: 0.961729]\n",
      "epoch:2 step:2440 [D loss: 0.692072, acc.: 57.03%] [G loss: 0.926824]\n",
      "epoch:2 step:2441 [D loss: 0.589296, acc.: 68.75%] [G loss: 0.904981]\n",
      "epoch:2 step:2442 [D loss: 0.607482, acc.: 67.19%] [G loss: 0.963307]\n",
      "epoch:2 step:2443 [D loss: 0.661193, acc.: 59.38%] [G loss: 0.866374]\n",
      "epoch:2 step:2444 [D loss: 0.622897, acc.: 68.75%] [G loss: 0.934445]\n",
      "epoch:2 step:2445 [D loss: 0.585685, acc.: 70.31%] [G loss: 0.989807]\n",
      "epoch:2 step:2446 [D loss: 0.599484, acc.: 72.66%] [G loss: 0.949370]\n",
      "epoch:2 step:2447 [D loss: 0.608943, acc.: 66.41%] [G loss: 0.938195]\n",
      "epoch:2 step:2448 [D loss: 0.591282, acc.: 65.62%] [G loss: 0.899616]\n",
      "epoch:2 step:2449 [D loss: 0.529623, acc.: 75.78%] [G loss: 0.993483]\n",
      "epoch:2 step:2450 [D loss: 0.603367, acc.: 68.75%] [G loss: 0.990300]\n",
      "epoch:2 step:2451 [D loss: 0.586396, acc.: 67.19%] [G loss: 1.017869]\n",
      "epoch:2 step:2452 [D loss: 0.624683, acc.: 60.94%] [G loss: 1.005828]\n",
      "epoch:2 step:2453 [D loss: 0.594268, acc.: 68.75%] [G loss: 1.038471]\n",
      "epoch:2 step:2454 [D loss: 0.588665, acc.: 71.09%] [G loss: 0.971231]\n",
      "epoch:2 step:2455 [D loss: 0.566034, acc.: 71.09%] [G loss: 0.925408]\n",
      "epoch:2 step:2456 [D loss: 0.507405, acc.: 83.59%] [G loss: 0.940353]\n",
      "epoch:2 step:2457 [D loss: 0.570683, acc.: 74.22%] [G loss: 0.956413]\n",
      "epoch:2 step:2458 [D loss: 0.572186, acc.: 75.00%] [G loss: 0.949714]\n",
      "epoch:2 step:2459 [D loss: 0.640379, acc.: 61.72%] [G loss: 0.956223]\n",
      "epoch:2 step:2460 [D loss: 0.599040, acc.: 66.41%] [G loss: 0.922505]\n",
      "epoch:2 step:2461 [D loss: 0.615703, acc.: 65.62%] [G loss: 0.946823]\n",
      "epoch:2 step:2462 [D loss: 0.610856, acc.: 68.75%] [G loss: 0.927272]\n",
      "epoch:2 step:2463 [D loss: 0.556101, acc.: 72.66%] [G loss: 1.007746]\n",
      "epoch:2 step:2464 [D loss: 0.636074, acc.: 58.59%] [G loss: 0.984669]\n",
      "epoch:2 step:2465 [D loss: 0.651568, acc.: 56.25%] [G loss: 0.896595]\n",
      "epoch:2 step:2466 [D loss: 0.533708, acc.: 76.56%] [G loss: 0.933488]\n",
      "epoch:2 step:2467 [D loss: 0.616745, acc.: 67.19%] [G loss: 0.938367]\n",
      "epoch:2 step:2468 [D loss: 0.614959, acc.: 64.06%] [G loss: 0.949443]\n",
      "epoch:2 step:2469 [D loss: 0.594474, acc.: 69.53%] [G loss: 0.975861]\n",
      "epoch:2 step:2470 [D loss: 0.618096, acc.: 64.06%] [G loss: 0.921731]\n",
      "epoch:2 step:2471 [D loss: 0.610718, acc.: 69.53%] [G loss: 0.929165]\n",
      "epoch:2 step:2472 [D loss: 0.581231, acc.: 73.44%] [G loss: 0.972316]\n",
      "epoch:2 step:2473 [D loss: 0.629480, acc.: 67.19%] [G loss: 0.937550]\n",
      "epoch:2 step:2474 [D loss: 0.691411, acc.: 58.59%] [G loss: 0.950631]\n",
      "epoch:2 step:2475 [D loss: 0.624726, acc.: 64.84%] [G loss: 0.936716]\n",
      "epoch:2 step:2476 [D loss: 0.578465, acc.: 73.44%] [G loss: 0.909003]\n",
      "epoch:2 step:2477 [D loss: 0.571109, acc.: 72.66%] [G loss: 0.956175]\n",
      "epoch:2 step:2478 [D loss: 0.682020, acc.: 62.50%] [G loss: 0.910393]\n",
      "epoch:2 step:2479 [D loss: 0.597090, acc.: 67.97%] [G loss: 0.965667]\n",
      "epoch:2 step:2480 [D loss: 0.568432, acc.: 73.44%] [G loss: 0.943585]\n",
      "epoch:2 step:2481 [D loss: 0.635711, acc.: 63.28%] [G loss: 0.940562]\n",
      "epoch:2 step:2482 [D loss: 0.607269, acc.: 67.19%] [G loss: 0.972936]\n",
      "epoch:2 step:2483 [D loss: 0.606343, acc.: 70.31%] [G loss: 0.932691]\n",
      "epoch:2 step:2484 [D loss: 0.602031, acc.: 71.09%] [G loss: 0.994995]\n",
      "epoch:2 step:2485 [D loss: 0.603765, acc.: 70.31%] [G loss: 0.891658]\n",
      "epoch:2 step:2486 [D loss: 0.575815, acc.: 76.56%] [G loss: 0.987718]\n",
      "epoch:2 step:2487 [D loss: 0.590121, acc.: 73.44%] [G loss: 0.914619]\n",
      "epoch:2 step:2488 [D loss: 0.604313, acc.: 71.09%] [G loss: 0.915110]\n",
      "epoch:2 step:2489 [D loss: 0.633562, acc.: 64.84%] [G loss: 0.925016]\n",
      "epoch:2 step:2490 [D loss: 0.609322, acc.: 71.09%] [G loss: 0.944627]\n",
      "epoch:2 step:2491 [D loss: 0.553163, acc.: 75.78%] [G loss: 0.918492]\n",
      "epoch:2 step:2492 [D loss: 0.585746, acc.: 69.53%] [G loss: 0.915876]\n",
      "epoch:2 step:2493 [D loss: 0.615166, acc.: 64.84%] [G loss: 0.935102]\n",
      "epoch:2 step:2494 [D loss: 0.618303, acc.: 64.06%] [G loss: 0.907959]\n",
      "epoch:2 step:2495 [D loss: 0.665903, acc.: 56.25%] [G loss: 0.911500]\n",
      "epoch:2 step:2496 [D loss: 0.681945, acc.: 58.59%] [G loss: 0.893531]\n",
      "epoch:2 step:2497 [D loss: 0.641322, acc.: 67.19%] [G loss: 0.979972]\n",
      "epoch:2 step:2498 [D loss: 0.641723, acc.: 60.16%] [G loss: 1.003214]\n",
      "epoch:2 step:2499 [D loss: 0.603531, acc.: 74.22%] [G loss: 0.966112]\n",
      "epoch:2 step:2500 [D loss: 0.583131, acc.: 76.56%] [G loss: 0.956464]\n",
      "epoch:2 step:2501 [D loss: 0.579786, acc.: 72.66%] [G loss: 0.952527]\n",
      "epoch:2 step:2502 [D loss: 0.603530, acc.: 67.19%] [G loss: 0.945305]\n",
      "epoch:2 step:2503 [D loss: 0.598250, acc.: 65.62%] [G loss: 0.987553]\n",
      "epoch:2 step:2504 [D loss: 0.573857, acc.: 71.88%] [G loss: 0.950675]\n",
      "epoch:2 step:2505 [D loss: 0.564673, acc.: 78.91%] [G loss: 1.009291]\n",
      "epoch:2 step:2506 [D loss: 0.569774, acc.: 70.31%] [G loss: 1.007947]\n",
      "epoch:2 step:2507 [D loss: 0.601458, acc.: 68.75%] [G loss: 0.962789]\n",
      "epoch:2 step:2508 [D loss: 0.590902, acc.: 71.09%] [G loss: 0.946500]\n",
      "epoch:2 step:2509 [D loss: 0.596683, acc.: 67.19%] [G loss: 1.012969]\n",
      "epoch:2 step:2510 [D loss: 0.609561, acc.: 64.06%] [G loss: 1.000472]\n",
      "epoch:2 step:2511 [D loss: 0.576451, acc.: 71.09%] [G loss: 0.933653]\n",
      "epoch:2 step:2512 [D loss: 0.575971, acc.: 70.31%] [G loss: 0.941063]\n",
      "epoch:2 step:2513 [D loss: 0.588179, acc.: 72.66%] [G loss: 0.936647]\n",
      "epoch:2 step:2514 [D loss: 0.541484, acc.: 75.00%] [G loss: 0.984899]\n",
      "epoch:2 step:2515 [D loss: 0.547832, acc.: 75.00%] [G loss: 0.983228]\n",
      "epoch:2 step:2516 [D loss: 0.563262, acc.: 75.00%] [G loss: 1.019638]\n",
      "epoch:2 step:2517 [D loss: 0.613472, acc.: 68.75%] [G loss: 0.979117]\n",
      "epoch:2 step:2518 [D loss: 0.611809, acc.: 66.41%] [G loss: 0.899701]\n",
      "epoch:2 step:2519 [D loss: 0.595047, acc.: 73.44%] [G loss: 0.908157]\n",
      "epoch:2 step:2520 [D loss: 0.598417, acc.: 71.09%] [G loss: 0.953871]\n",
      "epoch:2 step:2521 [D loss: 0.613084, acc.: 66.41%] [G loss: 0.994818]\n",
      "epoch:2 step:2522 [D loss: 0.567535, acc.: 71.09%] [G loss: 0.997397]\n",
      "epoch:2 step:2523 [D loss: 0.577726, acc.: 69.53%] [G loss: 1.004121]\n",
      "epoch:2 step:2524 [D loss: 0.619121, acc.: 67.19%] [G loss: 1.021942]\n",
      "epoch:2 step:2525 [D loss: 0.571037, acc.: 70.31%] [G loss: 0.966043]\n",
      "epoch:2 step:2526 [D loss: 0.628567, acc.: 62.50%] [G loss: 0.950361]\n",
      "epoch:2 step:2527 [D loss: 0.642290, acc.: 57.81%] [G loss: 0.922943]\n",
      "epoch:2 step:2528 [D loss: 0.639780, acc.: 58.59%] [G loss: 0.949578]\n",
      "epoch:2 step:2529 [D loss: 0.610889, acc.: 67.97%] [G loss: 0.946314]\n",
      "epoch:2 step:2530 [D loss: 0.593522, acc.: 67.97%] [G loss: 1.028804]\n",
      "epoch:2 step:2531 [D loss: 0.571703, acc.: 73.44%] [G loss: 0.936536]\n",
      "epoch:2 step:2532 [D loss: 0.621675, acc.: 67.97%] [G loss: 0.978343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2533 [D loss: 0.598535, acc.: 69.53%] [G loss: 0.963365]\n",
      "epoch:2 step:2534 [D loss: 0.583580, acc.: 73.44%] [G loss: 0.990771]\n",
      "epoch:2 step:2535 [D loss: 0.577855, acc.: 72.66%] [G loss: 0.978202]\n",
      "epoch:2 step:2536 [D loss: 0.621721, acc.: 67.97%] [G loss: 0.951966]\n",
      "epoch:2 step:2537 [D loss: 0.576497, acc.: 68.75%] [G loss: 0.923395]\n",
      "epoch:2 step:2538 [D loss: 0.600445, acc.: 73.44%] [G loss: 0.967793]\n",
      "epoch:2 step:2539 [D loss: 0.576565, acc.: 71.88%] [G loss: 0.947356]\n",
      "epoch:2 step:2540 [D loss: 0.596307, acc.: 71.09%] [G loss: 0.958925]\n",
      "epoch:2 step:2541 [D loss: 0.645323, acc.: 61.72%] [G loss: 0.914584]\n",
      "epoch:2 step:2542 [D loss: 0.612379, acc.: 67.97%] [G loss: 0.922282]\n",
      "epoch:2 step:2543 [D loss: 0.600485, acc.: 70.31%] [G loss: 0.895926]\n",
      "epoch:2 step:2544 [D loss: 0.578785, acc.: 77.34%] [G loss: 0.990766]\n",
      "epoch:2 step:2545 [D loss: 0.616841, acc.: 66.41%] [G loss: 0.926474]\n",
      "epoch:2 step:2546 [D loss: 0.663682, acc.: 66.41%] [G loss: 0.946824]\n",
      "epoch:2 step:2547 [D loss: 0.647593, acc.: 60.94%] [G loss: 0.952419]\n",
      "epoch:2 step:2548 [D loss: 0.632507, acc.: 66.41%] [G loss: 0.945538]\n",
      "epoch:2 step:2549 [D loss: 0.582961, acc.: 72.66%] [G loss: 0.910459]\n",
      "epoch:2 step:2550 [D loss: 0.576867, acc.: 68.75%] [G loss: 0.976576]\n",
      "epoch:2 step:2551 [D loss: 0.587177, acc.: 70.31%] [G loss: 0.980411]\n",
      "epoch:2 step:2552 [D loss: 0.592831, acc.: 67.97%] [G loss: 0.959447]\n",
      "epoch:2 step:2553 [D loss: 0.575127, acc.: 72.66%] [G loss: 0.998354]\n",
      "epoch:2 step:2554 [D loss: 0.575637, acc.: 74.22%] [G loss: 1.005670]\n",
      "epoch:2 step:2555 [D loss: 0.557300, acc.: 79.69%] [G loss: 0.990715]\n",
      "epoch:2 step:2556 [D loss: 0.621800, acc.: 69.53%] [G loss: 0.892427]\n",
      "epoch:2 step:2557 [D loss: 0.609515, acc.: 67.97%] [G loss: 0.919039]\n",
      "epoch:2 step:2558 [D loss: 0.588601, acc.: 71.09%] [G loss: 0.931949]\n",
      "epoch:2 step:2559 [D loss: 0.608523, acc.: 66.41%] [G loss: 0.905527]\n",
      "epoch:2 step:2560 [D loss: 0.611843, acc.: 66.41%] [G loss: 0.926417]\n",
      "epoch:2 step:2561 [D loss: 0.648732, acc.: 62.50%] [G loss: 0.917486]\n",
      "epoch:2 step:2562 [D loss: 0.632164, acc.: 64.84%] [G loss: 0.971913]\n",
      "epoch:2 step:2563 [D loss: 0.589174, acc.: 73.44%] [G loss: 0.964418]\n",
      "epoch:2 step:2564 [D loss: 0.579633, acc.: 69.53%] [G loss: 1.038563]\n",
      "epoch:2 step:2565 [D loss: 0.563360, acc.: 75.78%] [G loss: 0.947036]\n",
      "epoch:2 step:2566 [D loss: 0.607073, acc.: 67.97%] [G loss: 0.958015]\n",
      "epoch:2 step:2567 [D loss: 0.582108, acc.: 72.66%] [G loss: 1.012452]\n",
      "epoch:2 step:2568 [D loss: 0.558778, acc.: 75.78%] [G loss: 1.061882]\n",
      "epoch:2 step:2569 [D loss: 0.605849, acc.: 69.53%] [G loss: 0.981606]\n",
      "epoch:2 step:2570 [D loss: 0.670422, acc.: 57.81%] [G loss: 0.909286]\n",
      "epoch:2 step:2571 [D loss: 0.602727, acc.: 65.62%] [G loss: 0.929647]\n",
      "epoch:2 step:2572 [D loss: 0.621528, acc.: 65.62%] [G loss: 0.957898]\n",
      "epoch:2 step:2573 [D loss: 0.569728, acc.: 77.34%] [G loss: 0.950230]\n",
      "epoch:2 step:2574 [D loss: 0.585494, acc.: 69.53%] [G loss: 0.953353]\n",
      "epoch:2 step:2575 [D loss: 0.630187, acc.: 64.06%] [G loss: 0.970751]\n",
      "epoch:2 step:2576 [D loss: 0.660547, acc.: 60.16%] [G loss: 0.964703]\n",
      "epoch:2 step:2577 [D loss: 0.611251, acc.: 70.31%] [G loss: 0.942945]\n",
      "epoch:2 step:2578 [D loss: 0.669618, acc.: 59.38%] [G loss: 0.904184]\n",
      "epoch:2 step:2579 [D loss: 0.594083, acc.: 73.44%] [G loss: 0.923321]\n",
      "epoch:2 step:2580 [D loss: 0.606608, acc.: 68.75%] [G loss: 0.889556]\n",
      "epoch:2 step:2581 [D loss: 0.567861, acc.: 73.44%] [G loss: 1.004730]\n",
      "epoch:2 step:2582 [D loss: 0.546672, acc.: 78.12%] [G loss: 0.996216]\n",
      "epoch:2 step:2583 [D loss: 0.586292, acc.: 69.53%] [G loss: 0.963502]\n",
      "epoch:2 step:2584 [D loss: 0.668061, acc.: 57.03%] [G loss: 0.943913]\n",
      "epoch:2 step:2585 [D loss: 0.642153, acc.: 63.28%] [G loss: 0.993587]\n",
      "epoch:2 step:2586 [D loss: 0.605337, acc.: 63.28%] [G loss: 0.978569]\n",
      "epoch:2 step:2587 [D loss: 0.614055, acc.: 65.62%] [G loss: 0.931153]\n",
      "epoch:2 step:2588 [D loss: 0.580969, acc.: 69.53%] [G loss: 1.003357]\n",
      "epoch:2 step:2589 [D loss: 0.616146, acc.: 67.19%] [G loss: 0.872504]\n",
      "epoch:2 step:2590 [D loss: 0.637511, acc.: 67.97%] [G loss: 0.939889]\n",
      "epoch:2 step:2591 [D loss: 0.613895, acc.: 71.09%] [G loss: 0.908187]\n",
      "epoch:2 step:2592 [D loss: 0.577829, acc.: 75.00%] [G loss: 0.897695]\n",
      "epoch:2 step:2593 [D loss: 0.555438, acc.: 76.56%] [G loss: 0.926038]\n",
      "epoch:2 step:2594 [D loss: 0.636979, acc.: 64.06%] [G loss: 0.954087]\n",
      "epoch:2 step:2595 [D loss: 0.628699, acc.: 65.62%] [G loss: 0.999332]\n",
      "epoch:2 step:2596 [D loss: 0.593259, acc.: 71.88%] [G loss: 1.000318]\n",
      "epoch:2 step:2597 [D loss: 0.632880, acc.: 63.28%] [G loss: 0.939467]\n",
      "epoch:2 step:2598 [D loss: 0.628633, acc.: 62.50%] [G loss: 0.992734]\n",
      "epoch:2 step:2599 [D loss: 0.626847, acc.: 68.75%] [G loss: 0.987829]\n",
      "epoch:2 step:2600 [D loss: 0.625954, acc.: 64.06%] [G loss: 1.002844]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 5.426545\n",
      "FID: 63.895554\n",
      "0 = 13.177276849365258\n",
      "1 = 0.10515746344083034\n",
      "2 = 0.987500011920929\n",
      "3 = 0.9750000238418579\n",
      "4 = 1.0\n",
      "5 = 1.0\n",
      "6 = 0.9750000238418579\n",
      "7 = 10.237200856625995\n",
      "8 = 0.16770062004343234\n",
      "9 = 0.9187999963760376\n",
      "10 = 0.8881999850273132\n",
      "11 = 0.949400007724762\n",
      "12 = 0.9461014270782471\n",
      "13 = 0.8881999850273132\n",
      "14 = 5.426577568054199\n",
      "15 = 8.781573295593262\n",
      "16 = 0.281790167093277\n",
      "17 = 5.426544666290283\n",
      "18 = 63.89555358886719\n",
      "epoch:2 step:2601 [D loss: 0.630666, acc.: 67.97%] [G loss: 0.955746]\n",
      "epoch:2 step:2602 [D loss: 0.652127, acc.: 63.28%] [G loss: 0.895933]\n",
      "epoch:2 step:2603 [D loss: 0.634375, acc.: 62.50%] [G loss: 0.899497]\n",
      "epoch:2 step:2604 [D loss: 0.622708, acc.: 64.84%] [G loss: 0.951570]\n",
      "epoch:2 step:2605 [D loss: 0.595127, acc.: 71.09%] [G loss: 0.926072]\n",
      "epoch:2 step:2606 [D loss: 0.602166, acc.: 69.53%] [G loss: 0.940834]\n",
      "epoch:2 step:2607 [D loss: 0.588639, acc.: 68.75%] [G loss: 0.979222]\n",
      "epoch:2 step:2608 [D loss: 0.582576, acc.: 70.31%] [G loss: 0.881686]\n",
      "epoch:2 step:2609 [D loss: 0.590908, acc.: 73.44%] [G loss: 0.881941]\n",
      "epoch:2 step:2610 [D loss: 0.534679, acc.: 80.47%] [G loss: 0.896194]\n",
      "epoch:2 step:2611 [D loss: 0.589447, acc.: 68.75%] [G loss: 0.994301]\n",
      "epoch:2 step:2612 [D loss: 0.656637, acc.: 59.38%] [G loss: 0.919033]\n",
      "epoch:2 step:2613 [D loss: 0.685229, acc.: 62.50%] [G loss: 0.941732]\n",
      "epoch:2 step:2614 [D loss: 0.660253, acc.: 62.50%] [G loss: 0.931810]\n",
      "epoch:2 step:2615 [D loss: 0.621379, acc.: 64.84%] [G loss: 0.901730]\n",
      "epoch:2 step:2616 [D loss: 0.653064, acc.: 64.06%] [G loss: 0.940856]\n",
      "epoch:2 step:2617 [D loss: 0.605587, acc.: 69.53%] [G loss: 0.958246]\n",
      "epoch:2 step:2618 [D loss: 0.621452, acc.: 64.84%] [G loss: 0.884753]\n",
      "epoch:2 step:2619 [D loss: 0.632100, acc.: 69.53%] [G loss: 0.862891]\n",
      "epoch:2 step:2620 [D loss: 0.552811, acc.: 72.66%] [G loss: 0.938117]\n",
      "epoch:2 step:2621 [D loss: 0.536283, acc.: 77.34%] [G loss: 0.934881]\n",
      "epoch:2 step:2622 [D loss: 0.614517, acc.: 67.97%] [G loss: 1.030350]\n",
      "epoch:2 step:2623 [D loss: 0.635993, acc.: 62.50%] [G loss: 0.922129]\n",
      "epoch:2 step:2624 [D loss: 0.636463, acc.: 67.97%] [G loss: 0.946962]\n",
      "epoch:2 step:2625 [D loss: 0.612581, acc.: 63.28%] [G loss: 0.955190]\n",
      "epoch:2 step:2626 [D loss: 0.571743, acc.: 71.88%] [G loss: 0.949065]\n",
      "epoch:2 step:2627 [D loss: 0.562713, acc.: 72.66%] [G loss: 0.984459]\n",
      "epoch:2 step:2628 [D loss: 0.546267, acc.: 75.78%] [G loss: 0.987003]\n",
      "epoch:2 step:2629 [D loss: 0.591102, acc.: 70.31%] [G loss: 0.978561]\n",
      "epoch:2 step:2630 [D loss: 0.605956, acc.: 66.41%] [G loss: 1.009795]\n",
      "epoch:2 step:2631 [D loss: 0.583730, acc.: 68.75%] [G loss: 0.978795]\n",
      "epoch:2 step:2632 [D loss: 0.598475, acc.: 64.06%] [G loss: 0.943407]\n",
      "epoch:2 step:2633 [D loss: 0.600597, acc.: 68.75%] [G loss: 0.956781]\n",
      "epoch:2 step:2634 [D loss: 0.606866, acc.: 66.41%] [G loss: 0.896827]\n",
      "epoch:2 step:2635 [D loss: 0.600775, acc.: 64.84%] [G loss: 0.895618]\n",
      "epoch:2 step:2636 [D loss: 0.620194, acc.: 64.84%] [G loss: 0.932307]\n",
      "epoch:2 step:2637 [D loss: 0.553715, acc.: 70.31%] [G loss: 0.915826]\n",
      "epoch:2 step:2638 [D loss: 0.589518, acc.: 65.62%] [G loss: 1.000140]\n",
      "epoch:2 step:2639 [D loss: 0.669310, acc.: 62.50%] [G loss: 0.918861]\n",
      "epoch:2 step:2640 [D loss: 0.665836, acc.: 59.38%] [G loss: 0.910285]\n",
      "epoch:2 step:2641 [D loss: 0.618154, acc.: 71.09%] [G loss: 0.894152]\n",
      "epoch:2 step:2642 [D loss: 0.645427, acc.: 64.06%] [G loss: 0.987999]\n",
      "epoch:2 step:2643 [D loss: 0.557858, acc.: 75.00%] [G loss: 1.009427]\n",
      "epoch:2 step:2644 [D loss: 0.621022, acc.: 64.06%] [G loss: 0.950155]\n",
      "epoch:2 step:2645 [D loss: 0.540336, acc.: 76.56%] [G loss: 0.959605]\n",
      "epoch:2 step:2646 [D loss: 0.613823, acc.: 66.41%] [G loss: 0.995204]\n",
      "epoch:2 step:2647 [D loss: 0.590620, acc.: 70.31%] [G loss: 0.978436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2648 [D loss: 0.608888, acc.: 66.41%] [G loss: 0.979355]\n",
      "epoch:2 step:2649 [D loss: 0.586672, acc.: 65.62%] [G loss: 1.060529]\n",
      "epoch:2 step:2650 [D loss: 0.657677, acc.: 62.50%] [G loss: 0.960408]\n",
      "epoch:2 step:2651 [D loss: 0.623470, acc.: 68.75%] [G loss: 0.921434]\n",
      "epoch:2 step:2652 [D loss: 0.664509, acc.: 60.94%] [G loss: 0.949483]\n",
      "epoch:2 step:2653 [D loss: 0.630213, acc.: 66.41%] [G loss: 0.947726]\n",
      "epoch:2 step:2654 [D loss: 0.595118, acc.: 64.84%] [G loss: 0.951745]\n",
      "epoch:2 step:2655 [D loss: 0.549782, acc.: 73.44%] [G loss: 1.024240]\n",
      "epoch:2 step:2656 [D loss: 0.595276, acc.: 66.41%] [G loss: 0.978634]\n",
      "epoch:2 step:2657 [D loss: 0.667028, acc.: 64.84%] [G loss: 0.975052]\n",
      "epoch:2 step:2658 [D loss: 0.662376, acc.: 64.06%] [G loss: 0.904536]\n",
      "epoch:2 step:2659 [D loss: 0.597013, acc.: 71.88%] [G loss: 0.881890]\n",
      "epoch:2 step:2660 [D loss: 0.596640, acc.: 68.75%] [G loss: 0.979283]\n",
      "epoch:2 step:2661 [D loss: 0.625404, acc.: 64.84%] [G loss: 0.946271]\n",
      "epoch:2 step:2662 [D loss: 0.625819, acc.: 62.50%] [G loss: 0.970181]\n",
      "epoch:2 step:2663 [D loss: 0.619201, acc.: 65.62%] [G loss: 0.908813]\n",
      "epoch:2 step:2664 [D loss: 0.573030, acc.: 70.31%] [G loss: 0.910285]\n",
      "epoch:2 step:2665 [D loss: 0.595060, acc.: 68.75%] [G loss: 0.879145]\n",
      "epoch:2 step:2666 [D loss: 0.557206, acc.: 70.31%] [G loss: 0.963263]\n",
      "epoch:2 step:2667 [D loss: 0.624372, acc.: 68.75%] [G loss: 0.911253]\n",
      "epoch:2 step:2668 [D loss: 0.634560, acc.: 65.62%] [G loss: 0.950158]\n",
      "epoch:2 step:2669 [D loss: 0.597654, acc.: 68.75%] [G loss: 0.944099]\n",
      "epoch:2 step:2670 [D loss: 0.600512, acc.: 68.75%] [G loss: 0.955948]\n",
      "epoch:2 step:2671 [D loss: 0.668428, acc.: 58.59%] [G loss: 0.966476]\n",
      "epoch:2 step:2672 [D loss: 0.590268, acc.: 68.75%] [G loss: 0.995989]\n",
      "epoch:2 step:2673 [D loss: 0.593967, acc.: 72.66%] [G loss: 0.912359]\n",
      "epoch:2 step:2674 [D loss: 0.640828, acc.: 64.84%] [G loss: 0.934737]\n",
      "epoch:2 step:2675 [D loss: 0.591993, acc.: 70.31%] [G loss: 0.962564]\n",
      "epoch:2 step:2676 [D loss: 0.568437, acc.: 71.88%] [G loss: 0.986231]\n",
      "epoch:2 step:2677 [D loss: 0.577626, acc.: 73.44%] [G loss: 0.979451]\n",
      "epoch:2 step:2678 [D loss: 0.591554, acc.: 68.75%] [G loss: 0.943459]\n",
      "epoch:2 step:2679 [D loss: 0.604959, acc.: 68.75%] [G loss: 0.935344]\n",
      "epoch:2 step:2680 [D loss: 0.628870, acc.: 66.41%] [G loss: 0.937431]\n",
      "epoch:2 step:2681 [D loss: 0.548004, acc.: 73.44%] [G loss: 0.993851]\n",
      "epoch:2 step:2682 [D loss: 0.648479, acc.: 60.16%] [G loss: 0.957009]\n",
      "epoch:2 step:2683 [D loss: 0.620397, acc.: 71.09%] [G loss: 0.883205]\n",
      "epoch:2 step:2684 [D loss: 0.615740, acc.: 65.62%] [G loss: 0.873255]\n",
      "epoch:2 step:2685 [D loss: 0.656515, acc.: 65.62%] [G loss: 0.908128]\n",
      "epoch:2 step:2686 [D loss: 0.648385, acc.: 66.41%] [G loss: 0.989764]\n",
      "epoch:2 step:2687 [D loss: 0.612930, acc.: 64.84%] [G loss: 0.998298]\n",
      "epoch:2 step:2688 [D loss: 0.597912, acc.: 71.09%] [G loss: 0.957039]\n",
      "epoch:2 step:2689 [D loss: 0.601677, acc.: 66.41%] [G loss: 1.009931]\n",
      "epoch:2 step:2690 [D loss: 0.601707, acc.: 67.97%] [G loss: 1.023053]\n",
      "epoch:2 step:2691 [D loss: 0.631968, acc.: 65.62%] [G loss: 0.938860]\n",
      "epoch:2 step:2692 [D loss: 0.620117, acc.: 66.41%] [G loss: 0.910041]\n",
      "epoch:2 step:2693 [D loss: 0.619880, acc.: 66.41%] [G loss: 0.927848]\n",
      "epoch:2 step:2694 [D loss: 0.645329, acc.: 64.84%] [G loss: 0.934928]\n",
      "epoch:2 step:2695 [D loss: 0.599520, acc.: 71.88%] [G loss: 0.901899]\n",
      "epoch:2 step:2696 [D loss: 0.572500, acc.: 75.00%] [G loss: 0.970345]\n",
      "epoch:2 step:2697 [D loss: 0.579013, acc.: 75.00%] [G loss: 1.001921]\n",
      "epoch:2 step:2698 [D loss: 0.645769, acc.: 62.50%] [G loss: 0.942457]\n",
      "epoch:2 step:2699 [D loss: 0.608440, acc.: 65.62%] [G loss: 0.890857]\n",
      "epoch:2 step:2700 [D loss: 0.636581, acc.: 66.41%] [G loss: 0.914466]\n",
      "epoch:2 step:2701 [D loss: 0.676645, acc.: 57.81%] [G loss: 0.923480]\n",
      "epoch:2 step:2702 [D loss: 0.695275, acc.: 53.12%] [G loss: 0.956521]\n",
      "epoch:2 step:2703 [D loss: 0.596533, acc.: 69.53%] [G loss: 0.961715]\n",
      "epoch:2 step:2704 [D loss: 0.577912, acc.: 68.75%] [G loss: 0.928150]\n",
      "epoch:2 step:2705 [D loss: 0.682806, acc.: 57.81%] [G loss: 0.921338]\n",
      "epoch:2 step:2706 [D loss: 0.578520, acc.: 70.31%] [G loss: 0.914025]\n",
      "epoch:2 step:2707 [D loss: 0.590934, acc.: 67.97%] [G loss: 0.945663]\n",
      "epoch:2 step:2708 [D loss: 0.602821, acc.: 71.09%] [G loss: 0.960180]\n",
      "epoch:2 step:2709 [D loss: 0.599664, acc.: 73.44%] [G loss: 0.956645]\n",
      "epoch:2 step:2710 [D loss: 0.629865, acc.: 66.41%] [G loss: 0.967074]\n",
      "epoch:2 step:2711 [D loss: 0.596601, acc.: 71.09%] [G loss: 0.955275]\n",
      "epoch:2 step:2712 [D loss: 0.576012, acc.: 71.09%] [G loss: 1.059257]\n",
      "epoch:2 step:2713 [D loss: 0.658042, acc.: 59.38%] [G loss: 0.906308]\n",
      "epoch:2 step:2714 [D loss: 0.645173, acc.: 64.06%] [G loss: 0.931866]\n",
      "epoch:2 step:2715 [D loss: 0.601360, acc.: 67.97%] [G loss: 0.960263]\n",
      "epoch:2 step:2716 [D loss: 0.576303, acc.: 75.00%] [G loss: 0.928725]\n",
      "epoch:2 step:2717 [D loss: 0.638628, acc.: 63.28%] [G loss: 0.925607]\n",
      "epoch:2 step:2718 [D loss: 0.620269, acc.: 66.41%] [G loss: 0.978911]\n",
      "epoch:2 step:2719 [D loss: 0.622156, acc.: 67.19%] [G loss: 0.955570]\n",
      "epoch:2 step:2720 [D loss: 0.576833, acc.: 74.22%] [G loss: 0.914156]\n",
      "epoch:2 step:2721 [D loss: 0.619035, acc.: 68.75%] [G loss: 0.914751]\n",
      "epoch:2 step:2722 [D loss: 0.584459, acc.: 69.53%] [G loss: 0.911060]\n",
      "epoch:2 step:2723 [D loss: 0.588858, acc.: 71.88%] [G loss: 0.934818]\n",
      "epoch:2 step:2724 [D loss: 0.600542, acc.: 67.19%] [G loss: 0.896749]\n",
      "epoch:2 step:2725 [D loss: 0.632038, acc.: 62.50%] [G loss: 0.876343]\n",
      "epoch:2 step:2726 [D loss: 0.598187, acc.: 72.66%] [G loss: 0.943639]\n",
      "epoch:2 step:2727 [D loss: 0.600172, acc.: 68.75%] [G loss: 0.999205]\n",
      "epoch:2 step:2728 [D loss: 0.520720, acc.: 78.91%] [G loss: 0.971951]\n",
      "epoch:2 step:2729 [D loss: 0.587203, acc.: 71.09%] [G loss: 0.942860]\n",
      "epoch:2 step:2730 [D loss: 0.631787, acc.: 65.62%] [G loss: 0.946238]\n",
      "epoch:2 step:2731 [D loss: 0.592497, acc.: 67.97%] [G loss: 0.936093]\n",
      "epoch:2 step:2732 [D loss: 0.748600, acc.: 43.75%] [G loss: 0.961073]\n",
      "epoch:2 step:2733 [D loss: 0.604835, acc.: 67.97%] [G loss: 0.951153]\n",
      "epoch:2 step:2734 [D loss: 0.577720, acc.: 72.66%] [G loss: 1.019504]\n",
      "epoch:2 step:2735 [D loss: 0.654405, acc.: 64.84%] [G loss: 0.929247]\n",
      "epoch:2 step:2736 [D loss: 0.639081, acc.: 66.41%] [G loss: 0.877020]\n",
      "epoch:2 step:2737 [D loss: 0.604548, acc.: 66.41%] [G loss: 0.930818]\n",
      "epoch:2 step:2738 [D loss: 0.612132, acc.: 71.88%] [G loss: 0.929730]\n",
      "epoch:2 step:2739 [D loss: 0.648984, acc.: 61.72%] [G loss: 0.927351]\n",
      "epoch:2 step:2740 [D loss: 0.618709, acc.: 65.62%] [G loss: 0.919917]\n",
      "epoch:2 step:2741 [D loss: 0.638265, acc.: 64.84%] [G loss: 0.895069]\n",
      "epoch:2 step:2742 [D loss: 0.645393, acc.: 57.03%] [G loss: 0.910411]\n",
      "epoch:2 step:2743 [D loss: 0.598911, acc.: 72.66%] [G loss: 0.917115]\n",
      "epoch:2 step:2744 [D loss: 0.615623, acc.: 65.62%] [G loss: 0.898551]\n",
      "epoch:2 step:2745 [D loss: 0.567902, acc.: 68.75%] [G loss: 0.919671]\n",
      "epoch:2 step:2746 [D loss: 0.570660, acc.: 70.31%] [G loss: 0.919999]\n",
      "epoch:2 step:2747 [D loss: 0.622039, acc.: 60.94%] [G loss: 0.946545]\n",
      "epoch:2 step:2748 [D loss: 0.595753, acc.: 71.09%] [G loss: 0.991743]\n",
      "epoch:2 step:2749 [D loss: 0.586388, acc.: 67.19%] [G loss: 0.958628]\n",
      "epoch:2 step:2750 [D loss: 0.629488, acc.: 67.97%] [G loss: 0.901699]\n",
      "epoch:2 step:2751 [D loss: 0.605877, acc.: 65.62%] [G loss: 0.939915]\n",
      "epoch:2 step:2752 [D loss: 0.623110, acc.: 67.19%] [G loss: 0.897029]\n",
      "epoch:2 step:2753 [D loss: 0.603023, acc.: 67.19%] [G loss: 0.944135]\n",
      "epoch:2 step:2754 [D loss: 0.655322, acc.: 63.28%] [G loss: 0.911885]\n",
      "epoch:2 step:2755 [D loss: 0.646948, acc.: 60.94%] [G loss: 0.937817]\n",
      "epoch:2 step:2756 [D loss: 0.628916, acc.: 67.97%] [G loss: 0.874603]\n",
      "epoch:2 step:2757 [D loss: 0.625721, acc.: 67.97%] [G loss: 0.914474]\n",
      "epoch:2 step:2758 [D loss: 0.538125, acc.: 78.91%] [G loss: 1.018595]\n",
      "epoch:2 step:2759 [D loss: 0.552694, acc.: 75.00%] [G loss: 1.078385]\n",
      "epoch:2 step:2760 [D loss: 0.544728, acc.: 73.44%] [G loss: 1.033660]\n",
      "epoch:2 step:2761 [D loss: 0.553593, acc.: 69.53%] [G loss: 1.035955]\n",
      "epoch:2 step:2762 [D loss: 0.597911, acc.: 68.75%] [G loss: 1.020087]\n",
      "epoch:2 step:2763 [D loss: 0.601805, acc.: 65.62%] [G loss: 0.947499]\n",
      "epoch:2 step:2764 [D loss: 0.514946, acc.: 75.00%] [G loss: 1.016670]\n",
      "epoch:2 step:2765 [D loss: 0.684469, acc.: 60.16%] [G loss: 0.887415]\n",
      "epoch:2 step:2766 [D loss: 0.666758, acc.: 58.59%] [G loss: 0.892149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2767 [D loss: 0.629697, acc.: 68.75%] [G loss: 0.906755]\n",
      "epoch:2 step:2768 [D loss: 0.586197, acc.: 71.09%] [G loss: 0.949608]\n",
      "epoch:2 step:2769 [D loss: 0.605633, acc.: 73.44%] [G loss: 0.942427]\n",
      "epoch:2 step:2770 [D loss: 0.608912, acc.: 67.19%] [G loss: 0.947130]\n",
      "epoch:2 step:2771 [D loss: 0.539084, acc.: 76.56%] [G loss: 0.945441]\n",
      "epoch:2 step:2772 [D loss: 0.614211, acc.: 70.31%] [G loss: 0.977728]\n",
      "epoch:2 step:2773 [D loss: 0.539080, acc.: 75.00%] [G loss: 0.961772]\n",
      "epoch:2 step:2774 [D loss: 0.577326, acc.: 73.44%] [G loss: 0.997850]\n",
      "epoch:2 step:2775 [D loss: 0.581423, acc.: 75.00%] [G loss: 0.931852]\n",
      "epoch:2 step:2776 [D loss: 0.664359, acc.: 62.50%] [G loss: 0.924937]\n",
      "epoch:2 step:2777 [D loss: 0.614210, acc.: 67.97%] [G loss: 0.944556]\n",
      "epoch:2 step:2778 [D loss: 0.639249, acc.: 60.16%] [G loss: 0.918448]\n",
      "epoch:2 step:2779 [D loss: 0.601835, acc.: 68.75%] [G loss: 0.905493]\n",
      "epoch:2 step:2780 [D loss: 0.609681, acc.: 71.09%] [G loss: 1.002742]\n",
      "epoch:2 step:2781 [D loss: 0.681429, acc.: 55.47%] [G loss: 0.979699]\n",
      "epoch:2 step:2782 [D loss: 0.589679, acc.: 71.88%] [G loss: 0.950246]\n",
      "epoch:2 step:2783 [D loss: 0.577946, acc.: 73.44%] [G loss: 0.981433]\n",
      "epoch:2 step:2784 [D loss: 0.585012, acc.: 70.31%] [G loss: 0.969260]\n",
      "epoch:2 step:2785 [D loss: 0.555887, acc.: 73.44%] [G loss: 0.922925]\n",
      "epoch:2 step:2786 [D loss: 0.526842, acc.: 79.69%] [G loss: 0.973495]\n",
      "epoch:2 step:2787 [D loss: 0.633211, acc.: 64.06%] [G loss: 1.031397]\n",
      "epoch:2 step:2788 [D loss: 0.616507, acc.: 67.19%] [G loss: 1.000785]\n",
      "epoch:2 step:2789 [D loss: 0.614265, acc.: 65.62%] [G loss: 0.956433]\n",
      "epoch:2 step:2790 [D loss: 0.612700, acc.: 62.50%] [G loss: 1.001848]\n",
      "epoch:2 step:2791 [D loss: 0.606563, acc.: 67.19%] [G loss: 0.962285]\n",
      "epoch:2 step:2792 [D loss: 0.604492, acc.: 67.97%] [G loss: 0.957893]\n",
      "epoch:2 step:2793 [D loss: 0.578863, acc.: 77.34%] [G loss: 1.029419]\n",
      "epoch:2 step:2794 [D loss: 0.706251, acc.: 58.59%] [G loss: 0.991706]\n",
      "epoch:2 step:2795 [D loss: 0.536273, acc.: 77.34%] [G loss: 0.994308]\n",
      "epoch:2 step:2796 [D loss: 0.697610, acc.: 56.25%] [G loss: 0.836695]\n",
      "epoch:2 step:2797 [D loss: 0.548660, acc.: 79.69%] [G loss: 0.940243]\n",
      "epoch:2 step:2798 [D loss: 0.512297, acc.: 82.81%] [G loss: 0.921776]\n",
      "epoch:2 step:2799 [D loss: 0.561963, acc.: 72.66%] [G loss: 0.955818]\n",
      "epoch:2 step:2800 [D loss: 0.561381, acc.: 75.00%] [G loss: 1.045017]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.000500\n",
      "FID: 47.178570\n",
      "0 = 13.060017864942537\n",
      "1 = 0.09728506116205703\n",
      "2 = 0.9815000295639038\n",
      "3 = 0.963100016117096\n",
      "4 = 0.9998999834060669\n",
      "5 = 0.9998961687088013\n",
      "6 = 0.963100016117096\n",
      "7 = 9.405046989989293\n",
      "8 = 0.14439757067467598\n",
      "9 = 0.8948000073432922\n",
      "10 = 0.8600999712944031\n",
      "11 = 0.9294999837875366\n",
      "12 = 0.9242424368858337\n",
      "13 = 0.8600999712944031\n",
      "14 = 6.000545978546143\n",
      "15 = 9.273009300231934\n",
      "16 = 0.20557783544063568\n",
      "17 = 6.000499725341797\n",
      "18 = 47.17856979370117\n",
      "epoch:2 step:2801 [D loss: 0.578206, acc.: 74.22%] [G loss: 1.021534]\n",
      "epoch:2 step:2802 [D loss: 0.848807, acc.: 54.69%] [G loss: 0.980540]\n",
      "epoch:2 step:2803 [D loss: 0.609404, acc.: 68.75%] [G loss: 1.079895]\n",
      "epoch:2 step:2804 [D loss: 0.531792, acc.: 73.44%] [G loss: 1.127578]\n",
      "epoch:2 step:2805 [D loss: 0.606681, acc.: 65.62%] [G loss: 1.097963]\n",
      "epoch:2 step:2806 [D loss: 0.685265, acc.: 53.91%] [G loss: 0.939440]\n",
      "epoch:2 step:2807 [D loss: 0.656169, acc.: 64.06%] [G loss: 0.968404]\n",
      "epoch:2 step:2808 [D loss: 0.612402, acc.: 71.09%] [G loss: 0.906527]\n",
      "epoch:2 step:2809 [D loss: 0.588214, acc.: 73.44%] [G loss: 1.032847]\n",
      "epoch:2 step:2810 [D loss: 0.524487, acc.: 77.34%] [G loss: 1.050210]\n",
      "epoch:2 step:2811 [D loss: 0.552129, acc.: 78.91%] [G loss: 1.047539]\n",
      "epoch:3 step:2812 [D loss: 0.617929, acc.: 67.19%] [G loss: 1.067598]\n",
      "epoch:3 step:2813 [D loss: 0.599090, acc.: 68.75%] [G loss: 1.025273]\n",
      "epoch:3 step:2814 [D loss: 0.671518, acc.: 58.59%] [G loss: 0.986490]\n",
      "epoch:3 step:2815 [D loss: 0.621762, acc.: 63.28%] [G loss: 1.032261]\n",
      "epoch:3 step:2816 [D loss: 0.605934, acc.: 71.88%] [G loss: 1.054372]\n",
      "epoch:3 step:2817 [D loss: 0.562036, acc.: 77.34%] [G loss: 1.000968]\n",
      "epoch:3 step:2818 [D loss: 0.589895, acc.: 71.09%] [G loss: 0.982870]\n",
      "epoch:3 step:2819 [D loss: 0.593178, acc.: 73.44%] [G loss: 0.966123]\n",
      "epoch:3 step:2820 [D loss: 0.613852, acc.: 67.97%] [G loss: 0.992241]\n",
      "epoch:3 step:2821 [D loss: 0.605157, acc.: 65.62%] [G loss: 0.926906]\n",
      "epoch:3 step:2822 [D loss: 0.573057, acc.: 69.53%] [G loss: 0.986380]\n",
      "epoch:3 step:2823 [D loss: 0.616654, acc.: 64.06%] [G loss: 1.035561]\n",
      "epoch:3 step:2824 [D loss: 0.584802, acc.: 74.22%] [G loss: 0.967658]\n",
      "epoch:3 step:2825 [D loss: 0.587014, acc.: 69.53%] [G loss: 0.965119]\n",
      "epoch:3 step:2826 [D loss: 0.554663, acc.: 70.31%] [G loss: 0.954564]\n",
      "epoch:3 step:2827 [D loss: 0.550483, acc.: 79.69%] [G loss: 0.970031]\n",
      "epoch:3 step:2828 [D loss: 0.638637, acc.: 60.16%] [G loss: 0.981149]\n",
      "epoch:3 step:2829 [D loss: 0.677953, acc.: 64.84%] [G loss: 1.024008]\n",
      "epoch:3 step:2830 [D loss: 0.633102, acc.: 64.06%] [G loss: 0.991327]\n",
      "epoch:3 step:2831 [D loss: 0.667362, acc.: 60.16%] [G loss: 0.969049]\n",
      "epoch:3 step:2832 [D loss: 0.612514, acc.: 67.19%] [G loss: 0.924740]\n",
      "epoch:3 step:2833 [D loss: 0.556369, acc.: 75.78%] [G loss: 0.972684]\n",
      "epoch:3 step:2834 [D loss: 0.623425, acc.: 69.53%] [G loss: 0.948976]\n",
      "epoch:3 step:2835 [D loss: 0.602106, acc.: 70.31%] [G loss: 0.958697]\n",
      "epoch:3 step:2836 [D loss: 0.594561, acc.: 71.88%] [G loss: 0.897138]\n",
      "epoch:3 step:2837 [D loss: 0.586160, acc.: 72.66%] [G loss: 0.951928]\n",
      "epoch:3 step:2838 [D loss: 0.583481, acc.: 70.31%] [G loss: 0.928732]\n",
      "epoch:3 step:2839 [D loss: 0.584266, acc.: 72.66%] [G loss: 0.983498]\n",
      "epoch:3 step:2840 [D loss: 0.600244, acc.: 71.88%] [G loss: 0.968168]\n",
      "epoch:3 step:2841 [D loss: 0.597122, acc.: 67.19%] [G loss: 0.960573]\n",
      "epoch:3 step:2842 [D loss: 0.576379, acc.: 75.00%] [G loss: 0.908346]\n",
      "epoch:3 step:2843 [D loss: 0.620644, acc.: 67.97%] [G loss: 0.942199]\n",
      "epoch:3 step:2844 [D loss: 0.534072, acc.: 75.78%] [G loss: 0.948051]\n",
      "epoch:3 step:2845 [D loss: 0.561230, acc.: 75.78%] [G loss: 0.961662]\n",
      "epoch:3 step:2846 [D loss: 0.585302, acc.: 71.88%] [G loss: 0.942872]\n",
      "epoch:3 step:2847 [D loss: 0.539729, acc.: 74.22%] [G loss: 1.079348]\n",
      "epoch:3 step:2848 [D loss: 0.611446, acc.: 67.97%] [G loss: 1.003166]\n",
      "epoch:3 step:2849 [D loss: 0.667026, acc.: 59.38%] [G loss: 0.946165]\n",
      "epoch:3 step:2850 [D loss: 0.553125, acc.: 80.47%] [G loss: 0.968364]\n",
      "epoch:3 step:2851 [D loss: 0.569162, acc.: 73.44%] [G loss: 0.975237]\n",
      "epoch:3 step:2852 [D loss: 0.610115, acc.: 71.88%] [G loss: 0.960249]\n",
      "epoch:3 step:2853 [D loss: 0.605800, acc.: 64.06%] [G loss: 0.975425]\n",
      "epoch:3 step:2854 [D loss: 0.671269, acc.: 59.38%] [G loss: 1.011763]\n",
      "epoch:3 step:2855 [D loss: 0.614973, acc.: 64.06%] [G loss: 0.912814]\n",
      "epoch:3 step:2856 [D loss: 0.629343, acc.: 66.41%] [G loss: 1.034692]\n",
      "epoch:3 step:2857 [D loss: 0.572266, acc.: 75.78%] [G loss: 0.958629]\n",
      "epoch:3 step:2858 [D loss: 0.611748, acc.: 65.62%] [G loss: 0.934613]\n",
      "epoch:3 step:2859 [D loss: 0.632255, acc.: 67.97%] [G loss: 0.953308]\n",
      "epoch:3 step:2860 [D loss: 0.629231, acc.: 64.84%] [G loss: 0.976207]\n",
      "epoch:3 step:2861 [D loss: 0.607085, acc.: 68.75%] [G loss: 1.029153]\n",
      "epoch:3 step:2862 [D loss: 0.615439, acc.: 70.31%] [G loss: 0.960311]\n",
      "epoch:3 step:2863 [D loss: 0.623176, acc.: 65.62%] [G loss: 0.960367]\n",
      "epoch:3 step:2864 [D loss: 0.605515, acc.: 65.62%] [G loss: 0.924874]\n",
      "epoch:3 step:2865 [D loss: 0.615360, acc.: 67.97%] [G loss: 0.911682]\n",
      "epoch:3 step:2866 [D loss: 0.598414, acc.: 71.09%] [G loss: 0.987417]\n",
      "epoch:3 step:2867 [D loss: 0.625161, acc.: 64.84%] [G loss: 0.950668]\n",
      "epoch:3 step:2868 [D loss: 0.604006, acc.: 68.75%] [G loss: 0.951959]\n",
      "epoch:3 step:2869 [D loss: 0.605965, acc.: 72.66%] [G loss: 1.037678]\n",
      "epoch:3 step:2870 [D loss: 0.571440, acc.: 75.78%] [G loss: 0.973351]\n",
      "epoch:3 step:2871 [D loss: 0.567397, acc.: 71.88%] [G loss: 0.944460]\n",
      "epoch:3 step:2872 [D loss: 0.627496, acc.: 62.50%] [G loss: 0.916428]\n",
      "epoch:3 step:2873 [D loss: 0.648278, acc.: 59.38%] [G loss: 0.940030]\n",
      "epoch:3 step:2874 [D loss: 0.612386, acc.: 71.88%] [G loss: 0.981889]\n",
      "epoch:3 step:2875 [D loss: 0.651791, acc.: 57.81%] [G loss: 0.950142]\n",
      "epoch:3 step:2876 [D loss: 0.601839, acc.: 69.53%] [G loss: 0.920453]\n",
      "epoch:3 step:2877 [D loss: 0.584549, acc.: 74.22%] [G loss: 0.959981]\n",
      "epoch:3 step:2878 [D loss: 0.629754, acc.: 65.62%] [G loss: 0.904801]\n",
      "epoch:3 step:2879 [D loss: 0.587411, acc.: 72.66%] [G loss: 0.915724]\n",
      "epoch:3 step:2880 [D loss: 0.588898, acc.: 73.44%] [G loss: 0.987310]\n",
      "epoch:3 step:2881 [D loss: 0.577424, acc.: 73.44%] [G loss: 0.949770]\n",
      "epoch:3 step:2882 [D loss: 0.599692, acc.: 65.62%] [G loss: 0.928220]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2883 [D loss: 0.550765, acc.: 76.56%] [G loss: 0.872924]\n",
      "epoch:3 step:2884 [D loss: 0.569461, acc.: 71.09%] [G loss: 0.927182]\n",
      "epoch:3 step:2885 [D loss: 0.608762, acc.: 68.75%] [G loss: 0.989696]\n",
      "epoch:3 step:2886 [D loss: 0.551493, acc.: 71.09%] [G loss: 0.963238]\n",
      "epoch:3 step:2887 [D loss: 0.568954, acc.: 69.53%] [G loss: 0.878339]\n",
      "epoch:3 step:2888 [D loss: 0.594956, acc.: 69.53%] [G loss: 1.013043]\n",
      "epoch:3 step:2889 [D loss: 0.676714, acc.: 60.94%] [G loss: 0.976420]\n",
      "epoch:3 step:2890 [D loss: 0.633438, acc.: 66.41%] [G loss: 0.968625]\n",
      "epoch:3 step:2891 [D loss: 0.592134, acc.: 71.09%] [G loss: 1.015897]\n",
      "epoch:3 step:2892 [D loss: 0.662076, acc.: 59.38%] [G loss: 0.954169]\n",
      "epoch:3 step:2893 [D loss: 0.523551, acc.: 75.78%] [G loss: 0.950504]\n",
      "epoch:3 step:2894 [D loss: 0.584080, acc.: 75.00%] [G loss: 0.996817]\n",
      "epoch:3 step:2895 [D loss: 0.583880, acc.: 71.88%] [G loss: 0.989473]\n",
      "epoch:3 step:2896 [D loss: 0.603543, acc.: 67.19%] [G loss: 1.008973]\n",
      "epoch:3 step:2897 [D loss: 0.579802, acc.: 63.28%] [G loss: 0.982327]\n",
      "epoch:3 step:2898 [D loss: 0.600646, acc.: 66.41%] [G loss: 0.969687]\n",
      "epoch:3 step:2899 [D loss: 0.593074, acc.: 70.31%] [G loss: 0.983833]\n",
      "epoch:3 step:2900 [D loss: 0.553609, acc.: 75.78%] [G loss: 1.024640]\n",
      "epoch:3 step:2901 [D loss: 0.619199, acc.: 71.88%] [G loss: 0.952223]\n",
      "epoch:3 step:2902 [D loss: 0.615525, acc.: 67.19%] [G loss: 0.961685]\n",
      "epoch:3 step:2903 [D loss: 0.568753, acc.: 71.09%] [G loss: 0.982750]\n",
      "epoch:3 step:2904 [D loss: 0.599195, acc.: 69.53%] [G loss: 0.980022]\n",
      "epoch:3 step:2905 [D loss: 0.592756, acc.: 67.19%] [G loss: 1.025947]\n",
      "epoch:3 step:2906 [D loss: 0.582942, acc.: 67.19%] [G loss: 1.005564]\n",
      "epoch:3 step:2907 [D loss: 0.579631, acc.: 74.22%] [G loss: 0.955367]\n",
      "epoch:3 step:2908 [D loss: 0.577217, acc.: 74.22%] [G loss: 0.965637]\n",
      "epoch:3 step:2909 [D loss: 0.631887, acc.: 60.94%] [G loss: 0.970841]\n",
      "epoch:3 step:2910 [D loss: 0.636468, acc.: 67.97%] [G loss: 1.001212]\n",
      "epoch:3 step:2911 [D loss: 0.580531, acc.: 72.66%] [G loss: 0.976669]\n",
      "epoch:3 step:2912 [D loss: 0.647167, acc.: 64.06%] [G loss: 1.006540]\n",
      "epoch:3 step:2913 [D loss: 0.626807, acc.: 67.97%] [G loss: 0.990725]\n",
      "epoch:3 step:2914 [D loss: 0.568735, acc.: 78.12%] [G loss: 0.999675]\n",
      "epoch:3 step:2915 [D loss: 0.601741, acc.: 71.88%] [G loss: 0.964647]\n",
      "epoch:3 step:2916 [D loss: 0.581257, acc.: 80.47%] [G loss: 0.952307]\n",
      "epoch:3 step:2917 [D loss: 0.579188, acc.: 73.44%] [G loss: 0.977418]\n",
      "epoch:3 step:2918 [D loss: 0.626685, acc.: 58.59%] [G loss: 1.012202]\n",
      "epoch:3 step:2919 [D loss: 0.670455, acc.: 67.19%] [G loss: 0.903993]\n",
      "epoch:3 step:2920 [D loss: 0.656811, acc.: 56.25%] [G loss: 0.925630]\n",
      "epoch:3 step:2921 [D loss: 0.601772, acc.: 67.19%] [G loss: 0.955604]\n",
      "epoch:3 step:2922 [D loss: 0.563949, acc.: 76.56%] [G loss: 0.979694]\n",
      "epoch:3 step:2923 [D loss: 0.569262, acc.: 71.09%] [G loss: 0.928399]\n",
      "epoch:3 step:2924 [D loss: 0.603435, acc.: 68.75%] [G loss: 0.906034]\n",
      "epoch:3 step:2925 [D loss: 0.643277, acc.: 64.06%] [G loss: 0.902941]\n",
      "epoch:3 step:2926 [D loss: 0.576084, acc.: 75.00%] [G loss: 0.972276]\n",
      "epoch:3 step:2927 [D loss: 0.559517, acc.: 71.88%] [G loss: 1.030886]\n",
      "epoch:3 step:2928 [D loss: 0.535509, acc.: 77.34%] [G loss: 1.104210]\n",
      "epoch:3 step:2929 [D loss: 0.613014, acc.: 64.06%] [G loss: 1.034081]\n",
      "epoch:3 step:2930 [D loss: 0.528267, acc.: 80.47%] [G loss: 1.052350]\n",
      "epoch:3 step:2931 [D loss: 0.700536, acc.: 63.28%] [G loss: 0.957531]\n",
      "epoch:3 step:2932 [D loss: 0.694473, acc.: 57.81%] [G loss: 0.882808]\n",
      "epoch:3 step:2933 [D loss: 0.572997, acc.: 67.19%] [G loss: 0.949603]\n",
      "epoch:3 step:2934 [D loss: 0.636793, acc.: 67.19%] [G loss: 0.933173]\n",
      "epoch:3 step:2935 [D loss: 0.635566, acc.: 65.62%] [G loss: 0.940803]\n",
      "epoch:3 step:2936 [D loss: 0.644074, acc.: 65.62%] [G loss: 0.902584]\n",
      "epoch:3 step:2937 [D loss: 0.583567, acc.: 71.09%] [G loss: 0.988773]\n",
      "epoch:3 step:2938 [D loss: 0.649822, acc.: 62.50%] [G loss: 0.981382]\n",
      "epoch:3 step:2939 [D loss: 0.649571, acc.: 64.06%] [G loss: 0.927475]\n",
      "epoch:3 step:2940 [D loss: 0.636649, acc.: 66.41%] [G loss: 0.940463]\n",
      "epoch:3 step:2941 [D loss: 0.590072, acc.: 72.66%] [G loss: 0.909503]\n",
      "epoch:3 step:2942 [D loss: 0.583328, acc.: 66.41%] [G loss: 0.960430]\n",
      "epoch:3 step:2943 [D loss: 0.611014, acc.: 70.31%] [G loss: 0.951831]\n",
      "epoch:3 step:2944 [D loss: 0.630516, acc.: 65.62%] [G loss: 0.991675]\n",
      "epoch:3 step:2945 [D loss: 0.591700, acc.: 62.50%] [G loss: 1.014023]\n",
      "epoch:3 step:2946 [D loss: 0.619550, acc.: 64.84%] [G loss: 0.982148]\n",
      "epoch:3 step:2947 [D loss: 0.618673, acc.: 61.72%] [G loss: 0.950556]\n",
      "epoch:3 step:2948 [D loss: 0.595908, acc.: 68.75%] [G loss: 0.932609]\n",
      "epoch:3 step:2949 [D loss: 0.580442, acc.: 75.00%] [G loss: 0.925711]\n",
      "epoch:3 step:2950 [D loss: 0.629397, acc.: 64.84%] [G loss: 0.894746]\n",
      "epoch:3 step:2951 [D loss: 0.619874, acc.: 64.84%] [G loss: 0.919759]\n",
      "epoch:3 step:2952 [D loss: 0.603507, acc.: 71.09%] [G loss: 0.889870]\n",
      "epoch:3 step:2953 [D loss: 0.634800, acc.: 64.06%] [G loss: 0.926574]\n",
      "epoch:3 step:2954 [D loss: 0.635299, acc.: 67.19%] [G loss: 0.883141]\n",
      "epoch:3 step:2955 [D loss: 0.597868, acc.: 69.53%] [G loss: 0.931539]\n",
      "epoch:3 step:2956 [D loss: 0.592196, acc.: 68.75%] [G loss: 0.979565]\n",
      "epoch:3 step:2957 [D loss: 0.656765, acc.: 59.38%] [G loss: 0.988415]\n",
      "epoch:3 step:2958 [D loss: 0.652878, acc.: 62.50%] [G loss: 0.953528]\n",
      "epoch:3 step:2959 [D loss: 0.639922, acc.: 60.16%] [G loss: 0.902353]\n",
      "epoch:3 step:2960 [D loss: 0.602355, acc.: 72.66%] [G loss: 0.856108]\n",
      "epoch:3 step:2961 [D loss: 0.650490, acc.: 61.72%] [G loss: 0.935171]\n",
      "epoch:3 step:2962 [D loss: 0.567941, acc.: 77.34%] [G loss: 0.948689]\n",
      "epoch:3 step:2963 [D loss: 0.573927, acc.: 72.66%] [G loss: 0.981637]\n",
      "epoch:3 step:2964 [D loss: 0.613897, acc.: 66.41%] [G loss: 0.906314]\n",
      "epoch:3 step:2965 [D loss: 0.594272, acc.: 69.53%] [G loss: 0.955741]\n",
      "epoch:3 step:2966 [D loss: 0.579947, acc.: 71.88%] [G loss: 0.982966]\n",
      "epoch:3 step:2967 [D loss: 0.588259, acc.: 70.31%] [G loss: 0.945319]\n",
      "epoch:3 step:2968 [D loss: 0.604897, acc.: 70.31%] [G loss: 0.968691]\n",
      "epoch:3 step:2969 [D loss: 0.616675, acc.: 69.53%] [G loss: 0.934033]\n",
      "epoch:3 step:2970 [D loss: 0.614775, acc.: 67.19%] [G loss: 0.984193]\n",
      "epoch:3 step:2971 [D loss: 0.642765, acc.: 62.50%] [G loss: 0.951340]\n",
      "epoch:3 step:2972 [D loss: 0.577618, acc.: 70.31%] [G loss: 0.977799]\n",
      "epoch:3 step:2973 [D loss: 0.566111, acc.: 75.00%] [G loss: 0.938908]\n",
      "epoch:3 step:2974 [D loss: 0.606964, acc.: 69.53%] [G loss: 0.967837]\n",
      "epoch:3 step:2975 [D loss: 0.583254, acc.: 68.75%] [G loss: 0.937741]\n",
      "epoch:3 step:2976 [D loss: 0.606129, acc.: 64.84%] [G loss: 0.968536]\n",
      "epoch:3 step:2977 [D loss: 0.572672, acc.: 73.44%] [G loss: 1.017636]\n",
      "epoch:3 step:2978 [D loss: 0.647887, acc.: 62.50%] [G loss: 0.901278]\n",
      "epoch:3 step:2979 [D loss: 0.629414, acc.: 66.41%] [G loss: 0.938519]\n",
      "epoch:3 step:2980 [D loss: 0.623793, acc.: 65.62%] [G loss: 0.932430]\n",
      "epoch:3 step:2981 [D loss: 0.603197, acc.: 69.53%] [G loss: 0.890121]\n",
      "epoch:3 step:2982 [D loss: 0.581141, acc.: 75.78%] [G loss: 0.927434]\n",
      "epoch:3 step:2983 [D loss: 0.654460, acc.: 63.28%] [G loss: 0.899591]\n",
      "epoch:3 step:2984 [D loss: 0.588708, acc.: 70.31%] [G loss: 0.885853]\n",
      "epoch:3 step:2985 [D loss: 0.607857, acc.: 65.62%] [G loss: 0.860706]\n",
      "epoch:3 step:2986 [D loss: 0.583986, acc.: 74.22%] [G loss: 0.912686]\n",
      "epoch:3 step:2987 [D loss: 0.617717, acc.: 67.19%] [G loss: 0.895357]\n",
      "epoch:3 step:2988 [D loss: 0.609507, acc.: 67.19%] [G loss: 0.961432]\n",
      "epoch:3 step:2989 [D loss: 0.636998, acc.: 65.62%] [G loss: 0.908915]\n",
      "epoch:3 step:2990 [D loss: 0.655275, acc.: 57.03%] [G loss: 0.913056]\n",
      "epoch:3 step:2991 [D loss: 0.637023, acc.: 64.06%] [G loss: 0.970236]\n",
      "epoch:3 step:2992 [D loss: 0.633529, acc.: 65.62%] [G loss: 0.932306]\n",
      "epoch:3 step:2993 [D loss: 0.648406, acc.: 63.28%] [G loss: 0.953883]\n",
      "epoch:3 step:2994 [D loss: 0.617005, acc.: 64.06%] [G loss: 0.936997]\n",
      "epoch:3 step:2995 [D loss: 0.635336, acc.: 67.19%] [G loss: 0.893800]\n",
      "epoch:3 step:2996 [D loss: 0.614239, acc.: 65.62%] [G loss: 0.960804]\n",
      "epoch:3 step:2997 [D loss: 0.659812, acc.: 60.16%] [G loss: 0.926562]\n",
      "epoch:3 step:2998 [D loss: 0.676453, acc.: 57.81%] [G loss: 0.905609]\n",
      "epoch:3 step:2999 [D loss: 0.607008, acc.: 67.97%] [G loss: 0.875935]\n",
      "epoch:3 step:3000 [D loss: 0.626145, acc.: 64.06%] [G loss: 0.882939]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.266088\n",
      "FID: 39.422939\n",
      "0 = 12.72156787958148\n",
      "1 = 0.09591216010524779\n",
      "2 = 0.9770500063896179\n",
      "3 = 0.954200029373169\n",
      "4 = 0.9998999834060669\n",
      "5 = 0.9998952150344849\n",
      "6 = 0.954200029373169\n",
      "7 = 8.943510739052272\n",
      "8 = 0.1310673669176097\n",
      "9 = 0.8708500266075134\n",
      "10 = 0.8343999981880188\n",
      "11 = 0.9072999954223633\n",
      "12 = 0.9000107645988464\n",
      "13 = 0.8343999981880188\n",
      "14 = 6.266139030456543\n",
      "15 = 9.333678245544434\n",
      "16 = 0.18292556703090668\n",
      "17 = 6.266088008880615\n",
      "18 = 39.42293930053711\n",
      "epoch:3 step:3001 [D loss: 0.610486, acc.: 67.19%] [G loss: 0.891171]\n",
      "epoch:3 step:3002 [D loss: 0.592569, acc.: 70.31%] [G loss: 0.924465]\n",
      "epoch:3 step:3003 [D loss: 0.605831, acc.: 64.06%] [G loss: 0.990927]\n",
      "epoch:3 step:3004 [D loss: 0.621730, acc.: 63.28%] [G loss: 0.982569]\n",
      "epoch:3 step:3005 [D loss: 0.562059, acc.: 75.78%] [G loss: 0.981169]\n",
      "epoch:3 step:3006 [D loss: 0.583133, acc.: 70.31%] [G loss: 0.899972]\n",
      "epoch:3 step:3007 [D loss: 0.625760, acc.: 65.62%] [G loss: 0.937613]\n",
      "epoch:3 step:3008 [D loss: 0.574034, acc.: 69.53%] [G loss: 0.954358]\n",
      "epoch:3 step:3009 [D loss: 0.534143, acc.: 74.22%] [G loss: 0.969304]\n",
      "epoch:3 step:3010 [D loss: 0.631932, acc.: 62.50%] [G loss: 0.903681]\n",
      "epoch:3 step:3011 [D loss: 0.616013, acc.: 68.75%] [G loss: 0.978762]\n",
      "epoch:3 step:3012 [D loss: 0.659058, acc.: 57.03%] [G loss: 0.958270]\n",
      "epoch:3 step:3013 [D loss: 0.633274, acc.: 65.62%] [G loss: 0.954089]\n",
      "epoch:3 step:3014 [D loss: 0.685624, acc.: 60.94%] [G loss: 0.895114]\n",
      "epoch:3 step:3015 [D loss: 0.593922, acc.: 68.75%] [G loss: 0.940620]\n",
      "epoch:3 step:3016 [D loss: 0.640200, acc.: 64.84%] [G loss: 0.990418]\n",
      "epoch:3 step:3017 [D loss: 0.566345, acc.: 73.44%] [G loss: 0.979776]\n",
      "epoch:3 step:3018 [D loss: 0.527360, acc.: 79.69%] [G loss: 1.009564]\n",
      "epoch:3 step:3019 [D loss: 0.552133, acc.: 76.56%] [G loss: 1.009109]\n",
      "epoch:3 step:3020 [D loss: 0.571351, acc.: 72.66%] [G loss: 0.977721]\n",
      "epoch:3 step:3021 [D loss: 0.643798, acc.: 67.19%] [G loss: 0.948369]\n",
      "epoch:3 step:3022 [D loss: 0.627949, acc.: 62.50%] [G loss: 0.916850]\n",
      "epoch:3 step:3023 [D loss: 0.639758, acc.: 61.72%] [G loss: 0.932445]\n",
      "epoch:3 step:3024 [D loss: 0.602646, acc.: 66.41%] [G loss: 0.976991]\n",
      "epoch:3 step:3025 [D loss: 0.668678, acc.: 56.25%] [G loss: 0.955700]\n",
      "epoch:3 step:3026 [D loss: 0.670806, acc.: 56.25%] [G loss: 0.983150]\n",
      "epoch:3 step:3027 [D loss: 0.596706, acc.: 69.53%] [G loss: 0.966695]\n",
      "epoch:3 step:3028 [D loss: 0.599239, acc.: 65.62%] [G loss: 0.905926]\n",
      "epoch:3 step:3029 [D loss: 0.584028, acc.: 71.09%] [G loss: 0.963458]\n",
      "epoch:3 step:3030 [D loss: 0.608517, acc.: 69.53%] [G loss: 0.933986]\n",
      "epoch:3 step:3031 [D loss: 0.642560, acc.: 60.16%] [G loss: 0.900457]\n",
      "epoch:3 step:3032 [D loss: 0.555734, acc.: 73.44%] [G loss: 0.951771]\n",
      "epoch:3 step:3033 [D loss: 0.550910, acc.: 73.44%] [G loss: 0.992507]\n",
      "epoch:3 step:3034 [D loss: 0.577582, acc.: 66.41%] [G loss: 0.975211]\n",
      "epoch:3 step:3035 [D loss: 0.642070, acc.: 62.50%] [G loss: 0.901000]\n",
      "epoch:3 step:3036 [D loss: 0.687722, acc.: 59.38%] [G loss: 0.889827]\n",
      "epoch:3 step:3037 [D loss: 0.646724, acc.: 63.28%] [G loss: 0.862447]\n",
      "epoch:3 step:3038 [D loss: 0.722966, acc.: 51.56%] [G loss: 0.884149]\n",
      "epoch:3 step:3039 [D loss: 0.673914, acc.: 60.16%] [G loss: 0.913329]\n",
      "epoch:3 step:3040 [D loss: 0.612892, acc.: 72.66%] [G loss: 0.931725]\n",
      "epoch:3 step:3041 [D loss: 0.553843, acc.: 73.44%] [G loss: 0.924411]\n",
      "epoch:3 step:3042 [D loss: 0.552979, acc.: 73.44%] [G loss: 0.987980]\n",
      "epoch:3 step:3043 [D loss: 0.581277, acc.: 71.88%] [G loss: 1.066588]\n",
      "epoch:3 step:3044 [D loss: 0.642690, acc.: 63.28%] [G loss: 0.933209]\n",
      "epoch:3 step:3045 [D loss: 0.672732, acc.: 60.94%] [G loss: 0.912681]\n",
      "epoch:3 step:3046 [D loss: 0.622623, acc.: 68.75%] [G loss: 0.910069]\n",
      "epoch:3 step:3047 [D loss: 0.593136, acc.: 67.97%] [G loss: 0.913475]\n",
      "epoch:3 step:3048 [D loss: 0.634300, acc.: 64.84%] [G loss: 0.947091]\n",
      "epoch:3 step:3049 [D loss: 0.620109, acc.: 71.09%] [G loss: 0.940074]\n",
      "epoch:3 step:3050 [D loss: 0.621672, acc.: 68.75%] [G loss: 0.946609]\n",
      "epoch:3 step:3051 [D loss: 0.578957, acc.: 72.66%] [G loss: 0.949804]\n",
      "epoch:3 step:3052 [D loss: 0.592105, acc.: 75.78%] [G loss: 1.009024]\n",
      "epoch:3 step:3053 [D loss: 0.581734, acc.: 74.22%] [G loss: 0.904044]\n",
      "epoch:3 step:3054 [D loss: 0.602093, acc.: 68.75%] [G loss: 0.908401]\n",
      "epoch:3 step:3055 [D loss: 0.565804, acc.: 74.22%] [G loss: 0.946878]\n",
      "epoch:3 step:3056 [D loss: 0.601833, acc.: 71.88%] [G loss: 0.924140]\n",
      "epoch:3 step:3057 [D loss: 0.605811, acc.: 66.41%] [G loss: 0.954244]\n",
      "epoch:3 step:3058 [D loss: 0.645504, acc.: 60.94%] [G loss: 0.978715]\n",
      "epoch:3 step:3059 [D loss: 0.660724, acc.: 60.16%] [G loss: 1.027300]\n",
      "epoch:3 step:3060 [D loss: 0.647999, acc.: 63.28%] [G loss: 0.938179]\n",
      "epoch:3 step:3061 [D loss: 0.701421, acc.: 54.69%] [G loss: 0.912193]\n",
      "epoch:3 step:3062 [D loss: 0.655675, acc.: 60.16%] [G loss: 0.907130]\n",
      "epoch:3 step:3063 [D loss: 0.661224, acc.: 60.16%] [G loss: 0.875977]\n",
      "epoch:3 step:3064 [D loss: 0.630660, acc.: 58.59%] [G loss: 0.929523]\n",
      "epoch:3 step:3065 [D loss: 0.587343, acc.: 76.56%] [G loss: 0.878188]\n",
      "epoch:3 step:3066 [D loss: 0.607259, acc.: 64.06%] [G loss: 0.899053]\n",
      "epoch:3 step:3067 [D loss: 0.627735, acc.: 66.41%] [G loss: 0.892188]\n",
      "epoch:3 step:3068 [D loss: 0.577243, acc.: 72.66%] [G loss: 0.963333]\n",
      "epoch:3 step:3069 [D loss: 0.591586, acc.: 75.78%] [G loss: 0.961949]\n",
      "epoch:3 step:3070 [D loss: 0.555884, acc.: 78.12%] [G loss: 0.939256]\n",
      "epoch:3 step:3071 [D loss: 0.588070, acc.: 69.53%] [G loss: 0.987127]\n",
      "epoch:3 step:3072 [D loss: 0.578914, acc.: 74.22%] [G loss: 0.981561]\n",
      "epoch:3 step:3073 [D loss: 0.596666, acc.: 66.41%] [G loss: 0.967584]\n",
      "epoch:3 step:3074 [D loss: 0.701864, acc.: 53.12%] [G loss: 0.909037]\n",
      "epoch:3 step:3075 [D loss: 0.575589, acc.: 71.88%] [G loss: 0.980482]\n",
      "epoch:3 step:3076 [D loss: 0.684091, acc.: 58.59%] [G loss: 0.994447]\n",
      "epoch:3 step:3077 [D loss: 0.567252, acc.: 78.12%] [G loss: 0.899064]\n",
      "epoch:3 step:3078 [D loss: 0.580618, acc.: 76.56%] [G loss: 0.881271]\n",
      "epoch:3 step:3079 [D loss: 0.620262, acc.: 61.72%] [G loss: 0.952923]\n",
      "epoch:3 step:3080 [D loss: 0.617265, acc.: 67.97%] [G loss: 0.882353]\n",
      "epoch:3 step:3081 [D loss: 0.621803, acc.: 64.84%] [G loss: 0.889545]\n",
      "epoch:3 step:3082 [D loss: 0.606028, acc.: 67.19%] [G loss: 0.953534]\n",
      "epoch:3 step:3083 [D loss: 0.633918, acc.: 61.72%] [G loss: 0.965637]\n",
      "epoch:3 step:3084 [D loss: 0.635357, acc.: 61.72%] [G loss: 0.900469]\n",
      "epoch:3 step:3085 [D loss: 0.638975, acc.: 60.94%] [G loss: 0.967599]\n",
      "epoch:3 step:3086 [D loss: 0.663078, acc.: 63.28%] [G loss: 1.004786]\n",
      "epoch:3 step:3087 [D loss: 0.623282, acc.: 66.41%] [G loss: 0.971728]\n",
      "epoch:3 step:3088 [D loss: 0.655048, acc.: 62.50%] [G loss: 0.956968]\n",
      "epoch:3 step:3089 [D loss: 0.622199, acc.: 71.88%] [G loss: 0.951379]\n",
      "epoch:3 step:3090 [D loss: 0.574939, acc.: 73.44%] [G loss: 0.969512]\n",
      "epoch:3 step:3091 [D loss: 0.582663, acc.: 68.75%] [G loss: 0.962010]\n",
      "epoch:3 step:3092 [D loss: 0.702681, acc.: 60.16%] [G loss: 0.898687]\n",
      "epoch:3 step:3093 [D loss: 0.664367, acc.: 60.16%] [G loss: 0.911303]\n",
      "epoch:3 step:3094 [D loss: 0.601600, acc.: 71.88%] [G loss: 0.923823]\n",
      "epoch:3 step:3095 [D loss: 0.523493, acc.: 84.38%] [G loss: 0.950948]\n",
      "epoch:3 step:3096 [D loss: 0.595518, acc.: 68.75%] [G loss: 0.943631]\n",
      "epoch:3 step:3097 [D loss: 0.536906, acc.: 78.91%] [G loss: 0.946729]\n",
      "epoch:3 step:3098 [D loss: 0.572206, acc.: 75.00%] [G loss: 0.964878]\n",
      "epoch:3 step:3099 [D loss: 0.595743, acc.: 67.97%] [G loss: 0.922094]\n",
      "epoch:3 step:3100 [D loss: 0.599110, acc.: 67.97%] [G loss: 0.966974]\n",
      "epoch:3 step:3101 [D loss: 0.596173, acc.: 68.75%] [G loss: 0.954759]\n",
      "epoch:3 step:3102 [D loss: 0.667360, acc.: 60.16%] [G loss: 0.990674]\n",
      "epoch:3 step:3103 [D loss: 0.645949, acc.: 64.84%] [G loss: 1.034602]\n",
      "epoch:3 step:3104 [D loss: 0.613305, acc.: 69.53%] [G loss: 1.036392]\n",
      "epoch:3 step:3105 [D loss: 0.627887, acc.: 65.62%] [G loss: 0.947379]\n",
      "epoch:3 step:3106 [D loss: 0.613643, acc.: 68.75%] [G loss: 0.922057]\n",
      "epoch:3 step:3107 [D loss: 0.581178, acc.: 71.09%] [G loss: 0.988518]\n",
      "epoch:3 step:3108 [D loss: 0.635564, acc.: 64.06%] [G loss: 0.960546]\n",
      "epoch:3 step:3109 [D loss: 0.593818, acc.: 71.09%] [G loss: 0.966367]\n",
      "epoch:3 step:3110 [D loss: 0.584559, acc.: 73.44%] [G loss: 0.986972]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3111 [D loss: 0.587615, acc.: 72.66%] [G loss: 0.964723]\n",
      "epoch:3 step:3112 [D loss: 0.666296, acc.: 61.72%] [G loss: 0.942108]\n",
      "epoch:3 step:3113 [D loss: 0.613374, acc.: 69.53%] [G loss: 0.908892]\n",
      "epoch:3 step:3114 [D loss: 0.571368, acc.: 73.44%] [G loss: 0.929458]\n",
      "epoch:3 step:3115 [D loss: 0.586069, acc.: 75.78%] [G loss: 0.895673]\n",
      "epoch:3 step:3116 [D loss: 0.590976, acc.: 71.88%] [G loss: 0.960922]\n",
      "epoch:3 step:3117 [D loss: 0.608615, acc.: 65.62%] [G loss: 0.943147]\n",
      "epoch:3 step:3118 [D loss: 0.572093, acc.: 71.09%] [G loss: 0.955444]\n",
      "epoch:3 step:3119 [D loss: 0.589556, acc.: 73.44%] [G loss: 0.959916]\n",
      "epoch:3 step:3120 [D loss: 0.548984, acc.: 76.56%] [G loss: 0.912996]\n",
      "epoch:3 step:3121 [D loss: 0.546008, acc.: 72.66%] [G loss: 0.933015]\n",
      "epoch:3 step:3122 [D loss: 0.603740, acc.: 69.53%] [G loss: 1.022354]\n",
      "epoch:3 step:3123 [D loss: 0.477452, acc.: 82.81%] [G loss: 1.071568]\n",
      "epoch:3 step:3124 [D loss: 0.549452, acc.: 70.31%] [G loss: 1.122631]\n",
      "epoch:3 step:3125 [D loss: 0.514788, acc.: 76.56%] [G loss: 1.108042]\n",
      "epoch:3 step:3126 [D loss: 0.578574, acc.: 68.75%] [G loss: 1.094066]\n",
      "epoch:3 step:3127 [D loss: 0.725422, acc.: 54.69%] [G loss: 0.950084]\n",
      "epoch:3 step:3128 [D loss: 0.611899, acc.: 67.19%] [G loss: 0.923281]\n",
      "epoch:3 step:3129 [D loss: 0.581793, acc.: 75.00%] [G loss: 0.900084]\n",
      "epoch:3 step:3130 [D loss: 0.615091, acc.: 65.62%] [G loss: 0.925785]\n",
      "epoch:3 step:3131 [D loss: 0.590060, acc.: 67.19%] [G loss: 0.965654]\n",
      "epoch:3 step:3132 [D loss: 0.573580, acc.: 69.53%] [G loss: 0.927839]\n",
      "epoch:3 step:3133 [D loss: 0.550191, acc.: 78.91%] [G loss: 0.965903]\n",
      "epoch:3 step:3134 [D loss: 0.647797, acc.: 64.06%] [G loss: 0.912831]\n",
      "epoch:3 step:3135 [D loss: 0.600752, acc.: 65.62%] [G loss: 0.905717]\n",
      "epoch:3 step:3136 [D loss: 0.611158, acc.: 68.75%] [G loss: 0.897858]\n",
      "epoch:3 step:3137 [D loss: 0.577724, acc.: 70.31%] [G loss: 0.976540]\n",
      "epoch:3 step:3138 [D loss: 0.572133, acc.: 73.44%] [G loss: 0.934044]\n",
      "epoch:3 step:3139 [D loss: 0.630200, acc.: 64.06%] [G loss: 0.965685]\n",
      "epoch:3 step:3140 [D loss: 0.607325, acc.: 65.62%] [G loss: 0.939001]\n",
      "epoch:3 step:3141 [D loss: 0.590881, acc.: 72.66%] [G loss: 0.901048]\n",
      "epoch:3 step:3142 [D loss: 0.573430, acc.: 75.78%] [G loss: 0.940479]\n",
      "epoch:3 step:3143 [D loss: 0.565873, acc.: 80.47%] [G loss: 0.979786]\n",
      "epoch:3 step:3144 [D loss: 0.603551, acc.: 69.53%] [G loss: 0.949382]\n",
      "epoch:3 step:3145 [D loss: 0.609951, acc.: 67.97%] [G loss: 0.956230]\n",
      "epoch:3 step:3146 [D loss: 0.592079, acc.: 65.62%] [G loss: 0.954398]\n",
      "epoch:3 step:3147 [D loss: 0.631687, acc.: 61.72%] [G loss: 1.001498]\n",
      "epoch:3 step:3148 [D loss: 0.620218, acc.: 69.53%] [G loss: 1.022102]\n",
      "epoch:3 step:3149 [D loss: 0.584131, acc.: 73.44%] [G loss: 0.982486]\n",
      "epoch:3 step:3150 [D loss: 0.616032, acc.: 64.84%] [G loss: 0.972864]\n",
      "epoch:3 step:3151 [D loss: 0.616651, acc.: 63.28%] [G loss: 0.909011]\n",
      "epoch:3 step:3152 [D loss: 0.693383, acc.: 61.72%] [G loss: 0.952807]\n",
      "epoch:3 step:3153 [D loss: 0.640991, acc.: 58.59%] [G loss: 0.890681]\n",
      "epoch:3 step:3154 [D loss: 0.580726, acc.: 68.75%] [G loss: 0.966527]\n",
      "epoch:3 step:3155 [D loss: 0.583445, acc.: 72.66%] [G loss: 0.941300]\n",
      "epoch:3 step:3156 [D loss: 0.572948, acc.: 75.00%] [G loss: 1.019217]\n",
      "epoch:3 step:3157 [D loss: 0.583299, acc.: 67.19%] [G loss: 1.114192]\n",
      "epoch:3 step:3158 [D loss: 0.515698, acc.: 78.91%] [G loss: 1.087820]\n",
      "epoch:3 step:3159 [D loss: 0.708884, acc.: 60.16%] [G loss: 0.935232]\n",
      "epoch:3 step:3160 [D loss: 0.704109, acc.: 52.34%] [G loss: 0.891236]\n",
      "epoch:3 step:3161 [D loss: 0.621509, acc.: 64.84%] [G loss: 0.899477]\n",
      "epoch:3 step:3162 [D loss: 0.618178, acc.: 61.72%] [G loss: 0.966057]\n",
      "epoch:3 step:3163 [D loss: 0.677532, acc.: 61.72%] [G loss: 0.987335]\n",
      "epoch:3 step:3164 [D loss: 0.583611, acc.: 67.19%] [G loss: 0.953986]\n",
      "epoch:3 step:3165 [D loss: 0.558711, acc.: 75.78%] [G loss: 1.064282]\n",
      "epoch:3 step:3166 [D loss: 0.604315, acc.: 68.75%] [G loss: 0.973129]\n",
      "epoch:3 step:3167 [D loss: 0.640550, acc.: 64.06%] [G loss: 0.970559]\n",
      "epoch:3 step:3168 [D loss: 0.591434, acc.: 64.84%] [G loss: 0.985620]\n",
      "epoch:3 step:3169 [D loss: 0.574313, acc.: 68.75%] [G loss: 0.989866]\n",
      "epoch:3 step:3170 [D loss: 0.571214, acc.: 69.53%] [G loss: 0.944728]\n",
      "epoch:3 step:3171 [D loss: 0.547151, acc.: 74.22%] [G loss: 1.000486]\n",
      "epoch:3 step:3172 [D loss: 0.589772, acc.: 67.97%] [G loss: 0.968744]\n",
      "epoch:3 step:3173 [D loss: 0.633025, acc.: 61.72%] [G loss: 0.962710]\n",
      "epoch:3 step:3174 [D loss: 0.618672, acc.: 69.53%] [G loss: 0.918475]\n",
      "epoch:3 step:3175 [D loss: 0.565865, acc.: 74.22%] [G loss: 0.931400]\n",
      "epoch:3 step:3176 [D loss: 0.564960, acc.: 74.22%] [G loss: 0.931670]\n",
      "epoch:3 step:3177 [D loss: 0.591438, acc.: 67.19%] [G loss: 1.020738]\n",
      "epoch:3 step:3178 [D loss: 0.588905, acc.: 68.75%] [G loss: 0.978247]\n",
      "epoch:3 step:3179 [D loss: 0.627001, acc.: 67.97%] [G loss: 0.977941]\n",
      "epoch:3 step:3180 [D loss: 0.633808, acc.: 64.84%] [G loss: 0.944305]\n",
      "epoch:3 step:3181 [D loss: 0.586586, acc.: 74.22%] [G loss: 1.006049]\n",
      "epoch:3 step:3182 [D loss: 0.587183, acc.: 67.97%] [G loss: 1.016602]\n",
      "epoch:3 step:3183 [D loss: 0.631346, acc.: 67.19%] [G loss: 0.958394]\n",
      "epoch:3 step:3184 [D loss: 0.649301, acc.: 61.72%] [G loss: 0.923290]\n",
      "epoch:3 step:3185 [D loss: 0.596193, acc.: 68.75%] [G loss: 0.879111]\n",
      "epoch:3 step:3186 [D loss: 0.603446, acc.: 70.31%] [G loss: 0.905805]\n",
      "epoch:3 step:3187 [D loss: 0.666143, acc.: 63.28%] [G loss: 0.880290]\n",
      "epoch:3 step:3188 [D loss: 0.651938, acc.: 63.28%] [G loss: 0.922240]\n",
      "epoch:3 step:3189 [D loss: 0.565543, acc.: 73.44%] [G loss: 0.993300]\n",
      "epoch:3 step:3190 [D loss: 0.663122, acc.: 58.59%] [G loss: 0.936324]\n",
      "epoch:3 step:3191 [D loss: 0.655366, acc.: 58.59%] [G loss: 0.876126]\n",
      "epoch:3 step:3192 [D loss: 0.568928, acc.: 73.44%] [G loss: 0.962636]\n",
      "epoch:3 step:3193 [D loss: 0.601079, acc.: 70.31%] [G loss: 0.960204]\n",
      "epoch:3 step:3194 [D loss: 0.622593, acc.: 61.72%] [G loss: 0.940152]\n",
      "epoch:3 step:3195 [D loss: 0.583371, acc.: 70.31%] [G loss: 0.996510]\n",
      "epoch:3 step:3196 [D loss: 0.610051, acc.: 64.84%] [G loss: 0.939193]\n",
      "epoch:3 step:3197 [D loss: 0.649162, acc.: 62.50%] [G loss: 0.947513]\n",
      "epoch:3 step:3198 [D loss: 0.620032, acc.: 69.53%] [G loss: 0.955972]\n",
      "epoch:3 step:3199 [D loss: 0.574420, acc.: 73.44%] [G loss: 0.979615]\n",
      "epoch:3 step:3200 [D loss: 0.634464, acc.: 63.28%] [G loss: 0.870009]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.361752\n",
      "FID: 37.546318\n",
      "0 = 12.555526615333545\n",
      "1 = 0.08656773520382934\n",
      "2 = 0.9749500155448914\n",
      "3 = 0.9498999714851379\n",
      "4 = 1.0\n",
      "5 = 1.0\n",
      "6 = 0.9498999714851379\n",
      "7 = 8.705286836105577\n",
      "8 = 0.12777817468074762\n",
      "9 = 0.8644000291824341\n",
      "10 = 0.8288999795913696\n",
      "11 = 0.8999000191688538\n",
      "12 = 0.8922497034072876\n",
      "13 = 0.8288999795913696\n",
      "14 = 6.361806392669678\n",
      "15 = 9.448101997375488\n",
      "16 = 0.17096349596977234\n",
      "17 = 6.361751556396484\n",
      "18 = 37.54631805419922\n",
      "epoch:3 step:3201 [D loss: 0.651131, acc.: 60.94%] [G loss: 0.882245]\n",
      "epoch:3 step:3202 [D loss: 0.612839, acc.: 67.97%] [G loss: 0.980706]\n",
      "epoch:3 step:3203 [D loss: 0.585848, acc.: 73.44%] [G loss: 0.916558]\n",
      "epoch:3 step:3204 [D loss: 0.641337, acc.: 60.16%] [G loss: 0.892758]\n",
      "epoch:3 step:3205 [D loss: 0.631469, acc.: 63.28%] [G loss: 0.951376]\n",
      "epoch:3 step:3206 [D loss: 0.645149, acc.: 61.72%] [G loss: 0.948090]\n",
      "epoch:3 step:3207 [D loss: 0.675867, acc.: 55.47%] [G loss: 0.937364]\n",
      "epoch:3 step:3208 [D loss: 0.603302, acc.: 69.53%] [G loss: 1.007607]\n",
      "epoch:3 step:3209 [D loss: 0.558620, acc.: 71.88%] [G loss: 0.997557]\n",
      "epoch:3 step:3210 [D loss: 0.548024, acc.: 77.34%] [G loss: 0.970953]\n",
      "epoch:3 step:3211 [D loss: 0.617764, acc.: 65.62%] [G loss: 0.953165]\n",
      "epoch:3 step:3212 [D loss: 0.666457, acc.: 57.03%] [G loss: 0.874653]\n",
      "epoch:3 step:3213 [D loss: 0.578402, acc.: 68.75%] [G loss: 0.944941]\n",
      "epoch:3 step:3214 [D loss: 0.705479, acc.: 53.12%] [G loss: 1.020451]\n",
      "epoch:3 step:3215 [D loss: 0.663600, acc.: 55.47%] [G loss: 0.951810]\n",
      "epoch:3 step:3216 [D loss: 0.606739, acc.: 71.09%] [G loss: 0.916680]\n",
      "epoch:3 step:3217 [D loss: 0.605790, acc.: 65.62%] [G loss: 0.971895]\n",
      "epoch:3 step:3218 [D loss: 0.625566, acc.: 60.94%] [G loss: 0.917003]\n",
      "epoch:3 step:3219 [D loss: 0.607183, acc.: 67.97%] [G loss: 0.933089]\n",
      "epoch:3 step:3220 [D loss: 0.580762, acc.: 70.31%] [G loss: 0.922615]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3221 [D loss: 0.646807, acc.: 58.59%] [G loss: 0.955806]\n",
      "epoch:3 step:3222 [D loss: 0.629775, acc.: 62.50%] [G loss: 0.895790]\n",
      "epoch:3 step:3223 [D loss: 0.612321, acc.: 65.62%] [G loss: 0.964103]\n",
      "epoch:3 step:3224 [D loss: 0.653690, acc.: 63.28%] [G loss: 0.972976]\n",
      "epoch:3 step:3225 [D loss: 0.617119, acc.: 70.31%] [G loss: 0.940413]\n",
      "epoch:3 step:3226 [D loss: 0.627893, acc.: 66.41%] [G loss: 0.928523]\n",
      "epoch:3 step:3227 [D loss: 0.627946, acc.: 64.84%] [G loss: 0.959438]\n",
      "epoch:3 step:3228 [D loss: 0.652950, acc.: 62.50%] [G loss: 0.919659]\n",
      "epoch:3 step:3229 [D loss: 0.648622, acc.: 60.94%] [G loss: 0.877983]\n",
      "epoch:3 step:3230 [D loss: 0.635064, acc.: 63.28%] [G loss: 0.888817]\n",
      "epoch:3 step:3231 [D loss: 0.632140, acc.: 64.84%] [G loss: 1.018882]\n",
      "epoch:3 step:3232 [D loss: 0.663784, acc.: 57.03%] [G loss: 0.916592]\n",
      "epoch:3 step:3233 [D loss: 0.689256, acc.: 52.34%] [G loss: 0.962866]\n",
      "epoch:3 step:3234 [D loss: 0.640674, acc.: 60.16%] [G loss: 0.973448]\n",
      "epoch:3 step:3235 [D loss: 0.636321, acc.: 66.41%] [G loss: 0.940754]\n",
      "epoch:3 step:3236 [D loss: 0.604769, acc.: 67.19%] [G loss: 0.969280]\n",
      "epoch:3 step:3237 [D loss: 0.580322, acc.: 75.00%] [G loss: 0.992820]\n",
      "epoch:3 step:3238 [D loss: 0.525512, acc.: 76.56%] [G loss: 0.982297]\n",
      "epoch:3 step:3239 [D loss: 0.572246, acc.: 67.19%] [G loss: 0.987243]\n",
      "epoch:3 step:3240 [D loss: 0.627600, acc.: 64.06%] [G loss: 1.032870]\n",
      "epoch:3 step:3241 [D loss: 0.612874, acc.: 67.97%] [G loss: 0.977601]\n",
      "epoch:3 step:3242 [D loss: 0.619547, acc.: 65.62%] [G loss: 1.017306]\n",
      "epoch:3 step:3243 [D loss: 0.655425, acc.: 58.59%] [G loss: 0.970721]\n",
      "epoch:3 step:3244 [D loss: 0.646920, acc.: 62.50%] [G loss: 1.000439]\n",
      "epoch:3 step:3245 [D loss: 0.641110, acc.: 66.41%] [G loss: 0.989874]\n",
      "epoch:3 step:3246 [D loss: 0.620956, acc.: 64.06%] [G loss: 0.981841]\n",
      "epoch:3 step:3247 [D loss: 0.621578, acc.: 64.06%] [G loss: 1.001178]\n",
      "epoch:3 step:3248 [D loss: 0.726139, acc.: 53.91%] [G loss: 0.960015]\n",
      "epoch:3 step:3249 [D loss: 0.637789, acc.: 67.97%] [G loss: 0.903279]\n",
      "epoch:3 step:3250 [D loss: 0.627315, acc.: 64.84%] [G loss: 0.936573]\n",
      "epoch:3 step:3251 [D loss: 0.610700, acc.: 67.19%] [G loss: 0.976205]\n",
      "epoch:3 step:3252 [D loss: 0.594834, acc.: 69.53%] [G loss: 1.002694]\n",
      "epoch:3 step:3253 [D loss: 0.639445, acc.: 60.94%] [G loss: 0.975835]\n",
      "epoch:3 step:3254 [D loss: 0.641904, acc.: 60.94%] [G loss: 0.973770]\n",
      "epoch:3 step:3255 [D loss: 0.618916, acc.: 67.19%] [G loss: 1.037500]\n",
      "epoch:3 step:3256 [D loss: 0.562480, acc.: 78.91%] [G loss: 1.043676]\n",
      "epoch:3 step:3257 [D loss: 0.606480, acc.: 67.97%] [G loss: 1.001098]\n",
      "epoch:3 step:3258 [D loss: 0.583606, acc.: 69.53%] [G loss: 0.954045]\n",
      "epoch:3 step:3259 [D loss: 0.654110, acc.: 67.97%] [G loss: 0.982111]\n",
      "epoch:3 step:3260 [D loss: 0.632658, acc.: 61.72%] [G loss: 0.976590]\n",
      "epoch:3 step:3261 [D loss: 0.583213, acc.: 73.44%] [G loss: 0.977803]\n",
      "epoch:3 step:3262 [D loss: 0.576789, acc.: 70.31%] [G loss: 0.979960]\n",
      "epoch:3 step:3263 [D loss: 0.607957, acc.: 67.97%] [G loss: 1.019317]\n",
      "epoch:3 step:3264 [D loss: 0.595649, acc.: 67.19%] [G loss: 0.996998]\n",
      "epoch:3 step:3265 [D loss: 0.616528, acc.: 68.75%] [G loss: 1.028346]\n",
      "epoch:3 step:3266 [D loss: 0.648124, acc.: 63.28%] [G loss: 0.982688]\n",
      "epoch:3 step:3267 [D loss: 0.679682, acc.: 60.94%] [G loss: 0.881143]\n",
      "epoch:3 step:3268 [D loss: 0.617806, acc.: 64.84%] [G loss: 0.982959]\n",
      "epoch:3 step:3269 [D loss: 0.712088, acc.: 52.34%] [G loss: 0.977248]\n",
      "epoch:3 step:3270 [D loss: 0.647925, acc.: 58.59%] [G loss: 0.923021]\n",
      "epoch:3 step:3271 [D loss: 0.666272, acc.: 57.81%] [G loss: 0.988930]\n",
      "epoch:3 step:3272 [D loss: 0.627571, acc.: 66.41%] [G loss: 0.909006]\n",
      "epoch:3 step:3273 [D loss: 0.611735, acc.: 64.84%] [G loss: 0.980333]\n",
      "epoch:3 step:3274 [D loss: 0.638881, acc.: 67.19%] [G loss: 0.926350]\n",
      "epoch:3 step:3275 [D loss: 0.620294, acc.: 67.19%] [G loss: 0.953167]\n",
      "epoch:3 step:3276 [D loss: 0.673662, acc.: 63.28%] [G loss: 0.913657]\n",
      "epoch:3 step:3277 [D loss: 0.609519, acc.: 69.53%] [G loss: 0.929148]\n",
      "epoch:3 step:3278 [D loss: 0.590412, acc.: 72.66%] [G loss: 0.991956]\n",
      "epoch:3 step:3279 [D loss: 0.639558, acc.: 64.06%] [G loss: 0.940322]\n",
      "epoch:3 step:3280 [D loss: 0.624828, acc.: 61.72%] [G loss: 0.981148]\n",
      "epoch:3 step:3281 [D loss: 0.612593, acc.: 63.28%] [G loss: 0.918303]\n",
      "epoch:3 step:3282 [D loss: 0.512915, acc.: 81.25%] [G loss: 0.972123]\n",
      "epoch:3 step:3283 [D loss: 0.578022, acc.: 72.66%] [G loss: 1.037882]\n",
      "epoch:3 step:3284 [D loss: 0.689159, acc.: 57.81%] [G loss: 0.993183]\n",
      "epoch:3 step:3285 [D loss: 0.596340, acc.: 74.22%] [G loss: 0.937192]\n",
      "epoch:3 step:3286 [D loss: 0.605226, acc.: 71.09%] [G loss: 0.927453]\n",
      "epoch:3 step:3287 [D loss: 0.652249, acc.: 62.50%] [G loss: 1.019301]\n",
      "epoch:3 step:3288 [D loss: 0.696192, acc.: 53.12%] [G loss: 0.919355]\n",
      "epoch:3 step:3289 [D loss: 0.682304, acc.: 52.34%] [G loss: 0.934467]\n",
      "epoch:3 step:3290 [D loss: 0.630149, acc.: 69.53%] [G loss: 0.914076]\n",
      "epoch:3 step:3291 [D loss: 0.625109, acc.: 66.41%] [G loss: 0.968302]\n",
      "epoch:3 step:3292 [D loss: 0.604604, acc.: 65.62%] [G loss: 1.027681]\n",
      "epoch:3 step:3293 [D loss: 0.708471, acc.: 50.78%] [G loss: 0.939627]\n",
      "epoch:3 step:3294 [D loss: 0.636585, acc.: 60.94%] [G loss: 0.893725]\n",
      "epoch:3 step:3295 [D loss: 0.595652, acc.: 69.53%] [G loss: 0.959441]\n",
      "epoch:3 step:3296 [D loss: 0.608628, acc.: 71.09%] [G loss: 0.925427]\n",
      "epoch:3 step:3297 [D loss: 0.623268, acc.: 71.88%] [G loss: 0.945272]\n",
      "epoch:3 step:3298 [D loss: 0.596539, acc.: 73.44%] [G loss: 0.928107]\n",
      "epoch:3 step:3299 [D loss: 0.597359, acc.: 67.19%] [G loss: 0.969897]\n",
      "epoch:3 step:3300 [D loss: 0.674473, acc.: 59.38%] [G loss: 0.886637]\n",
      "epoch:3 step:3301 [D loss: 0.672028, acc.: 59.38%] [G loss: 0.898944]\n",
      "epoch:3 step:3302 [D loss: 0.629927, acc.: 64.84%] [G loss: 0.951965]\n",
      "epoch:3 step:3303 [D loss: 0.671331, acc.: 60.94%] [G loss: 0.908360]\n",
      "epoch:3 step:3304 [D loss: 0.627169, acc.: 64.06%] [G loss: 0.940477]\n",
      "epoch:3 step:3305 [D loss: 0.608406, acc.: 70.31%] [G loss: 0.910762]\n",
      "epoch:3 step:3306 [D loss: 0.629010, acc.: 70.31%] [G loss: 1.008349]\n",
      "epoch:3 step:3307 [D loss: 0.597074, acc.: 72.66%] [G loss: 0.972878]\n",
      "epoch:3 step:3308 [D loss: 0.601054, acc.: 64.06%] [G loss: 0.919159]\n",
      "epoch:3 step:3309 [D loss: 0.558533, acc.: 72.66%] [G loss: 0.933882]\n",
      "epoch:3 step:3310 [D loss: 0.591371, acc.: 69.53%] [G loss: 0.969658]\n",
      "epoch:3 step:3311 [D loss: 0.727468, acc.: 53.12%] [G loss: 0.935897]\n",
      "epoch:3 step:3312 [D loss: 0.715284, acc.: 53.12%] [G loss: 0.876805]\n",
      "epoch:3 step:3313 [D loss: 0.647514, acc.: 70.31%] [G loss: 0.944845]\n",
      "epoch:3 step:3314 [D loss: 0.563923, acc.: 74.22%] [G loss: 1.020066]\n",
      "epoch:3 step:3315 [D loss: 0.587909, acc.: 67.97%] [G loss: 1.082153]\n",
      "epoch:3 step:3316 [D loss: 0.607844, acc.: 67.19%] [G loss: 1.009111]\n",
      "epoch:3 step:3317 [D loss: 0.608622, acc.: 68.75%] [G loss: 1.012062]\n",
      "epoch:3 step:3318 [D loss: 0.581418, acc.: 68.75%] [G loss: 0.982300]\n",
      "epoch:3 step:3319 [D loss: 0.567118, acc.: 67.97%] [G loss: 1.037481]\n",
      "epoch:3 step:3320 [D loss: 0.675411, acc.: 59.38%] [G loss: 0.914630]\n",
      "epoch:3 step:3321 [D loss: 0.667005, acc.: 60.16%] [G loss: 0.874314]\n",
      "epoch:3 step:3322 [D loss: 0.659259, acc.: 62.50%] [G loss: 0.980265]\n",
      "epoch:3 step:3323 [D loss: 0.625634, acc.: 66.41%] [G loss: 0.957993]\n",
      "epoch:3 step:3324 [D loss: 0.594763, acc.: 69.53%] [G loss: 0.924141]\n",
      "epoch:3 step:3325 [D loss: 0.608967, acc.: 66.41%] [G loss: 0.930546]\n",
      "epoch:3 step:3326 [D loss: 0.590148, acc.: 67.19%] [G loss: 0.958622]\n",
      "epoch:3 step:3327 [D loss: 0.585903, acc.: 73.44%] [G loss: 0.960906]\n",
      "epoch:3 step:3328 [D loss: 0.650818, acc.: 60.16%] [G loss: 0.920163]\n",
      "epoch:3 step:3329 [D loss: 0.577584, acc.: 69.53%] [G loss: 0.940576]\n",
      "epoch:3 step:3330 [D loss: 0.580417, acc.: 71.88%] [G loss: 0.964192]\n",
      "epoch:3 step:3331 [D loss: 0.610138, acc.: 65.62%] [G loss: 0.992045]\n",
      "epoch:3 step:3332 [D loss: 0.552090, acc.: 76.56%] [G loss: 0.983603]\n",
      "epoch:3 step:3333 [D loss: 0.596023, acc.: 64.84%] [G loss: 0.951416]\n",
      "epoch:3 step:3334 [D loss: 0.585787, acc.: 68.75%] [G loss: 0.913577]\n",
      "epoch:3 step:3335 [D loss: 0.627077, acc.: 67.97%] [G loss: 0.904627]\n",
      "epoch:3 step:3336 [D loss: 0.652399, acc.: 62.50%] [G loss: 0.963493]\n",
      "epoch:3 step:3337 [D loss: 0.618999, acc.: 64.06%] [G loss: 0.960346]\n",
      "epoch:3 step:3338 [D loss: 0.630628, acc.: 63.28%] [G loss: 0.928144]\n",
      "epoch:3 step:3339 [D loss: 0.666353, acc.: 62.50%] [G loss: 0.899400]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3340 [D loss: 0.619389, acc.: 70.31%] [G loss: 0.954416]\n",
      "epoch:3 step:3341 [D loss: 0.593796, acc.: 71.88%] [G loss: 0.966669]\n",
      "epoch:3 step:3342 [D loss: 0.665164, acc.: 59.38%] [G loss: 0.924051]\n",
      "epoch:3 step:3343 [D loss: 0.614145, acc.: 65.62%] [G loss: 0.875889]\n",
      "epoch:3 step:3344 [D loss: 0.613187, acc.: 67.97%] [G loss: 0.914167]\n",
      "epoch:3 step:3345 [D loss: 0.593429, acc.: 66.41%] [G loss: 0.928881]\n",
      "epoch:3 step:3346 [D loss: 0.660777, acc.: 60.94%] [G loss: 0.865041]\n",
      "epoch:3 step:3347 [D loss: 0.646248, acc.: 64.06%] [G loss: 0.930176]\n",
      "epoch:3 step:3348 [D loss: 0.633463, acc.: 60.94%] [G loss: 0.932942]\n",
      "epoch:3 step:3349 [D loss: 0.649025, acc.: 62.50%] [G loss: 0.890164]\n",
      "epoch:3 step:3350 [D loss: 0.659163, acc.: 59.38%] [G loss: 0.880740]\n",
      "epoch:3 step:3351 [D loss: 0.645494, acc.: 61.72%] [G loss: 0.959666]\n",
      "epoch:3 step:3352 [D loss: 0.619395, acc.: 68.75%] [G loss: 0.921018]\n",
      "epoch:3 step:3353 [D loss: 0.701978, acc.: 51.56%] [G loss: 0.874095]\n",
      "epoch:3 step:3354 [D loss: 0.693415, acc.: 56.25%] [G loss: 0.913719]\n",
      "epoch:3 step:3355 [D loss: 0.621762, acc.: 68.75%] [G loss: 0.944778]\n",
      "epoch:3 step:3356 [D loss: 0.610912, acc.: 65.62%] [G loss: 0.997245]\n",
      "epoch:3 step:3357 [D loss: 0.580924, acc.: 74.22%] [G loss: 1.030716]\n",
      "epoch:3 step:3358 [D loss: 0.586954, acc.: 67.97%] [G loss: 0.906009]\n",
      "epoch:3 step:3359 [D loss: 0.636044, acc.: 64.06%] [G loss: 0.987230]\n",
      "epoch:3 step:3360 [D loss: 0.585640, acc.: 71.09%] [G loss: 0.960035]\n",
      "epoch:3 step:3361 [D loss: 0.639483, acc.: 65.62%] [G loss: 0.964394]\n",
      "epoch:3 step:3362 [D loss: 0.576429, acc.: 68.75%] [G loss: 0.959831]\n",
      "epoch:3 step:3363 [D loss: 0.580858, acc.: 71.88%] [G loss: 0.937175]\n",
      "epoch:3 step:3364 [D loss: 0.650958, acc.: 60.94%] [G loss: 0.898320]\n",
      "epoch:3 step:3365 [D loss: 0.600481, acc.: 71.09%] [G loss: 0.934899]\n",
      "epoch:3 step:3366 [D loss: 0.625714, acc.: 61.72%] [G loss: 0.932016]\n",
      "epoch:3 step:3367 [D loss: 0.627764, acc.: 58.59%] [G loss: 0.970359]\n",
      "epoch:3 step:3368 [D loss: 0.634931, acc.: 60.16%] [G loss: 0.986788]\n",
      "epoch:3 step:3369 [D loss: 0.589857, acc.: 70.31%] [G loss: 0.972503]\n",
      "epoch:3 step:3370 [D loss: 0.636387, acc.: 62.50%] [G loss: 0.931339]\n",
      "epoch:3 step:3371 [D loss: 0.681443, acc.: 58.59%] [G loss: 0.920884]\n",
      "epoch:3 step:3372 [D loss: 0.613735, acc.: 68.75%] [G loss: 0.960689]\n",
      "epoch:3 step:3373 [D loss: 0.658588, acc.: 57.81%] [G loss: 0.907489]\n",
      "epoch:3 step:3374 [D loss: 0.654965, acc.: 61.72%] [G loss: 0.961853]\n",
      "epoch:3 step:3375 [D loss: 0.605885, acc.: 69.53%] [G loss: 0.978482]\n",
      "epoch:3 step:3376 [D loss: 0.688426, acc.: 57.81%] [G loss: 1.013932]\n",
      "epoch:3 step:3377 [D loss: 0.702477, acc.: 54.69%] [G loss: 0.963609]\n",
      "epoch:3 step:3378 [D loss: 0.608989, acc.: 69.53%] [G loss: 0.985661]\n",
      "epoch:3 step:3379 [D loss: 0.620025, acc.: 68.75%] [G loss: 0.929429]\n",
      "epoch:3 step:3380 [D loss: 0.662074, acc.: 60.94%] [G loss: 0.956515]\n",
      "epoch:3 step:3381 [D loss: 0.671849, acc.: 58.59%] [G loss: 0.885876]\n",
      "epoch:3 step:3382 [D loss: 0.629661, acc.: 63.28%] [G loss: 0.919337]\n",
      "epoch:3 step:3383 [D loss: 0.620969, acc.: 67.19%] [G loss: 0.871613]\n",
      "epoch:3 step:3384 [D loss: 0.604487, acc.: 69.53%] [G loss: 0.885534]\n",
      "epoch:3 step:3385 [D loss: 0.567773, acc.: 73.44%] [G loss: 0.965844]\n",
      "epoch:3 step:3386 [D loss: 0.567954, acc.: 75.00%] [G loss: 0.979809]\n",
      "epoch:3 step:3387 [D loss: 0.662087, acc.: 57.03%] [G loss: 1.008569]\n",
      "epoch:3 step:3388 [D loss: 0.682999, acc.: 62.50%] [G loss: 0.891112]\n",
      "epoch:3 step:3389 [D loss: 0.667369, acc.: 57.03%] [G loss: 0.909412]\n",
      "epoch:3 step:3390 [D loss: 0.660642, acc.: 63.28%] [G loss: 0.931016]\n",
      "epoch:3 step:3391 [D loss: 0.657658, acc.: 60.94%] [G loss: 0.868109]\n",
      "epoch:3 step:3392 [D loss: 0.634942, acc.: 62.50%] [G loss: 0.893307]\n",
      "epoch:3 step:3393 [D loss: 0.591831, acc.: 71.09%] [G loss: 0.921421]\n",
      "epoch:3 step:3394 [D loss: 0.658517, acc.: 55.47%] [G loss: 0.983364]\n",
      "epoch:3 step:3395 [D loss: 0.651482, acc.: 62.50%] [G loss: 0.963572]\n",
      "epoch:3 step:3396 [D loss: 0.674315, acc.: 64.06%] [G loss: 0.911107]\n",
      "epoch:3 step:3397 [D loss: 0.658735, acc.: 60.16%] [G loss: 0.901962]\n",
      "epoch:3 step:3398 [D loss: 0.684037, acc.: 55.47%] [G loss: 0.908981]\n",
      "epoch:3 step:3399 [D loss: 0.661450, acc.: 62.50%] [G loss: 0.882228]\n",
      "epoch:3 step:3400 [D loss: 0.599637, acc.: 65.62%] [G loss: 0.973006]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.287990\n",
      "FID: 40.993908\n",
      "0 = 12.704389321518004\n",
      "1 = 0.08737574337709914\n",
      "2 = 0.9736499786376953\n",
      "3 = 0.9477999806404114\n",
      "4 = 0.9994999766349792\n",
      "5 = 0.9994727373123169\n",
      "6 = 0.9477999806404114\n",
      "7 = 8.8952546068728\n",
      "8 = 0.13839651357856933\n",
      "9 = 0.86285001039505\n",
      "10 = 0.8299000263214111\n",
      "11 = 0.895799994468689\n",
      "12 = 0.8884487748146057\n",
      "13 = 0.8299000263214111\n",
      "14 = 6.2880377769470215\n",
      "15 = 9.41899585723877\n",
      "16 = 0.1774684637784958\n",
      "17 = 6.287989616394043\n",
      "18 = 40.9939079284668\n",
      "epoch:3 step:3401 [D loss: 0.693505, acc.: 62.50%] [G loss: 0.986091]\n",
      "epoch:3 step:3402 [D loss: 0.637792, acc.: 61.72%] [G loss: 0.943570]\n",
      "epoch:3 step:3403 [D loss: 0.582834, acc.: 75.78%] [G loss: 0.950271]\n",
      "epoch:3 step:3404 [D loss: 0.658870, acc.: 55.47%] [G loss: 0.979358]\n",
      "epoch:3 step:3405 [D loss: 0.646183, acc.: 64.84%] [G loss: 0.942111]\n",
      "epoch:3 step:3406 [D loss: 0.641020, acc.: 60.94%] [G loss: 0.887852]\n",
      "epoch:3 step:3407 [D loss: 0.603728, acc.: 67.19%] [G loss: 0.955726]\n",
      "epoch:3 step:3408 [D loss: 0.615053, acc.: 67.97%] [G loss: 0.900794]\n",
      "epoch:3 step:3409 [D loss: 0.581179, acc.: 72.66%] [G loss: 0.912337]\n",
      "epoch:3 step:3410 [D loss: 0.590665, acc.: 71.09%] [G loss: 0.918666]\n",
      "epoch:3 step:3411 [D loss: 0.687759, acc.: 55.47%] [G loss: 0.896935]\n",
      "epoch:3 step:3412 [D loss: 0.637227, acc.: 58.59%] [G loss: 0.955486]\n",
      "epoch:3 step:3413 [D loss: 0.623590, acc.: 66.41%] [G loss: 0.946646]\n",
      "epoch:3 step:3414 [D loss: 0.603432, acc.: 69.53%] [G loss: 0.958209]\n",
      "epoch:3 step:3415 [D loss: 0.623802, acc.: 67.19%] [G loss: 0.903861]\n",
      "epoch:3 step:3416 [D loss: 0.590198, acc.: 73.44%] [G loss: 0.893848]\n",
      "epoch:3 step:3417 [D loss: 0.637961, acc.: 67.97%] [G loss: 0.933383]\n",
      "epoch:3 step:3418 [D loss: 0.667106, acc.: 60.94%] [G loss: 0.895766]\n",
      "epoch:3 step:3419 [D loss: 0.631604, acc.: 65.62%] [G loss: 0.948445]\n",
      "epoch:3 step:3420 [D loss: 0.602319, acc.: 67.97%] [G loss: 0.934232]\n",
      "epoch:3 step:3421 [D loss: 0.620545, acc.: 67.19%] [G loss: 0.893854]\n",
      "epoch:3 step:3422 [D loss: 0.612413, acc.: 72.66%] [G loss: 0.908644]\n",
      "epoch:3 step:3423 [D loss: 0.642575, acc.: 57.81%] [G loss: 0.885966]\n",
      "epoch:3 step:3424 [D loss: 0.602099, acc.: 68.75%] [G loss: 0.913602]\n",
      "epoch:3 step:3425 [D loss: 0.644690, acc.: 59.38%] [G loss: 0.943355]\n",
      "epoch:3 step:3426 [D loss: 0.666153, acc.: 57.03%] [G loss: 0.961107]\n",
      "epoch:3 step:3427 [D loss: 0.634386, acc.: 67.19%] [G loss: 0.999395]\n",
      "epoch:3 step:3428 [D loss: 0.592136, acc.: 71.09%] [G loss: 0.942140]\n",
      "epoch:3 step:3429 [D loss: 0.608010, acc.: 69.53%] [G loss: 0.902951]\n",
      "epoch:3 step:3430 [D loss: 0.609955, acc.: 64.06%] [G loss: 0.881432]\n",
      "epoch:3 step:3431 [D loss: 0.653341, acc.: 62.50%] [G loss: 0.924783]\n",
      "epoch:3 step:3432 [D loss: 0.698220, acc.: 56.25%] [G loss: 0.931965]\n",
      "epoch:3 step:3433 [D loss: 0.671718, acc.: 58.59%] [G loss: 0.885117]\n",
      "epoch:3 step:3434 [D loss: 0.658970, acc.: 60.16%] [G loss: 0.890373]\n",
      "epoch:3 step:3435 [D loss: 0.630360, acc.: 64.84%] [G loss: 0.937509]\n",
      "epoch:3 step:3436 [D loss: 0.679002, acc.: 57.03%] [G loss: 0.877199]\n",
      "epoch:3 step:3437 [D loss: 0.609579, acc.: 70.31%] [G loss: 0.913320]\n",
      "epoch:3 step:3438 [D loss: 0.621253, acc.: 66.41%] [G loss: 0.910417]\n",
      "epoch:3 step:3439 [D loss: 0.659098, acc.: 63.28%] [G loss: 0.904930]\n",
      "epoch:3 step:3440 [D loss: 0.593424, acc.: 73.44%] [G loss: 0.914310]\n",
      "epoch:3 step:3441 [D loss: 0.622458, acc.: 67.97%] [G loss: 0.918026]\n",
      "epoch:3 step:3442 [D loss: 0.588234, acc.: 75.00%] [G loss: 0.905267]\n",
      "epoch:3 step:3443 [D loss: 0.625062, acc.: 61.72%] [G loss: 0.932364]\n",
      "epoch:3 step:3444 [D loss: 0.605878, acc.: 70.31%] [G loss: 0.951073]\n",
      "epoch:3 step:3445 [D loss: 0.619178, acc.: 67.97%] [G loss: 0.965445]\n",
      "epoch:3 step:3446 [D loss: 0.601536, acc.: 70.31%] [G loss: 0.941503]\n",
      "epoch:3 step:3447 [D loss: 0.624537, acc.: 68.75%] [G loss: 0.972542]\n",
      "epoch:3 step:3448 [D loss: 0.609593, acc.: 65.62%] [G loss: 0.943965]\n",
      "epoch:3 step:3449 [D loss: 0.653682, acc.: 59.38%] [G loss: 0.917876]\n",
      "epoch:3 step:3450 [D loss: 0.569329, acc.: 75.78%] [G loss: 0.962096]\n",
      "epoch:3 step:3451 [D loss: 0.546152, acc.: 75.78%] [G loss: 1.022412]\n",
      "epoch:3 step:3452 [D loss: 0.577033, acc.: 71.88%] [G loss: 0.957403]\n",
      "epoch:3 step:3453 [D loss: 0.574241, acc.: 66.41%] [G loss: 0.994587]\n",
      "epoch:3 step:3454 [D loss: 0.665134, acc.: 59.38%] [G loss: 0.937928]\n",
      "epoch:3 step:3455 [D loss: 0.661939, acc.: 61.72%] [G loss: 0.905650]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3456 [D loss: 0.677476, acc.: 62.50%] [G loss: 0.919314]\n",
      "epoch:3 step:3457 [D loss: 0.634667, acc.: 62.50%] [G loss: 0.907780]\n",
      "epoch:3 step:3458 [D loss: 0.550847, acc.: 74.22%] [G loss: 0.985346]\n",
      "epoch:3 step:3459 [D loss: 0.549564, acc.: 75.78%] [G loss: 1.040635]\n",
      "epoch:3 step:3460 [D loss: 0.606717, acc.: 67.97%] [G loss: 1.020043]\n",
      "epoch:3 step:3461 [D loss: 0.642881, acc.: 66.41%] [G loss: 1.047688]\n",
      "epoch:3 step:3462 [D loss: 0.588518, acc.: 67.97%] [G loss: 1.009967]\n",
      "epoch:3 step:3463 [D loss: 0.659454, acc.: 62.50%] [G loss: 0.946381]\n",
      "epoch:3 step:3464 [D loss: 0.641614, acc.: 64.06%] [G loss: 0.945965]\n",
      "epoch:3 step:3465 [D loss: 0.601632, acc.: 67.97%] [G loss: 1.010534]\n",
      "epoch:3 step:3466 [D loss: 0.645275, acc.: 64.84%] [G loss: 0.907616]\n",
      "epoch:3 step:3467 [D loss: 0.627360, acc.: 65.62%] [G loss: 0.867045]\n",
      "epoch:3 step:3468 [D loss: 0.630449, acc.: 62.50%] [G loss: 0.890066]\n",
      "epoch:3 step:3469 [D loss: 0.634169, acc.: 65.62%] [G loss: 0.906581]\n",
      "epoch:3 step:3470 [D loss: 0.599925, acc.: 67.97%] [G loss: 0.915717]\n",
      "epoch:3 step:3471 [D loss: 0.585027, acc.: 71.88%] [G loss: 0.958365]\n",
      "epoch:3 step:3472 [D loss: 0.621085, acc.: 67.19%] [G loss: 0.991565]\n",
      "epoch:3 step:3473 [D loss: 0.633234, acc.: 65.62%] [G loss: 0.931037]\n",
      "epoch:3 step:3474 [D loss: 0.570840, acc.: 72.66%] [G loss: 0.969169]\n",
      "epoch:3 step:3475 [D loss: 0.598652, acc.: 67.97%] [G loss: 0.978670]\n",
      "epoch:3 step:3476 [D loss: 0.592500, acc.: 71.09%] [G loss: 1.012605]\n",
      "epoch:3 step:3477 [D loss: 0.644450, acc.: 64.06%] [G loss: 0.970613]\n",
      "epoch:3 step:3478 [D loss: 0.670618, acc.: 57.81%] [G loss: 0.910578]\n",
      "epoch:3 step:3479 [D loss: 0.653283, acc.: 60.94%] [G loss: 0.858352]\n",
      "epoch:3 step:3480 [D loss: 0.588334, acc.: 69.53%] [G loss: 0.846678]\n",
      "epoch:3 step:3481 [D loss: 0.684980, acc.: 50.78%] [G loss: 0.922414]\n",
      "epoch:3 step:3482 [D loss: 0.642925, acc.: 63.28%] [G loss: 0.932924]\n",
      "epoch:3 step:3483 [D loss: 0.664742, acc.: 60.16%] [G loss: 0.947885]\n",
      "epoch:3 step:3484 [D loss: 0.628436, acc.: 70.31%] [G loss: 0.920490]\n",
      "epoch:3 step:3485 [D loss: 0.578305, acc.: 71.09%] [G loss: 0.919983]\n",
      "epoch:3 step:3486 [D loss: 0.629562, acc.: 64.84%] [G loss: 0.995803]\n",
      "epoch:3 step:3487 [D loss: 0.639105, acc.: 65.62%] [G loss: 0.993180]\n",
      "epoch:3 step:3488 [D loss: 0.578151, acc.: 71.09%] [G loss: 0.872922]\n",
      "epoch:3 step:3489 [D loss: 0.631240, acc.: 62.50%] [G loss: 0.866684]\n",
      "epoch:3 step:3490 [D loss: 0.661285, acc.: 59.38%] [G loss: 0.902224]\n",
      "epoch:3 step:3491 [D loss: 0.613594, acc.: 67.19%] [G loss: 0.915958]\n",
      "epoch:3 step:3492 [D loss: 0.603359, acc.: 65.62%] [G loss: 0.930112]\n",
      "epoch:3 step:3493 [D loss: 0.620004, acc.: 66.41%] [G loss: 0.962494]\n",
      "epoch:3 step:3494 [D loss: 0.669198, acc.: 57.03%] [G loss: 0.975872]\n",
      "epoch:3 step:3495 [D loss: 0.641765, acc.: 62.50%] [G loss: 0.899376]\n",
      "epoch:3 step:3496 [D loss: 0.606142, acc.: 69.53%] [G loss: 0.959183]\n",
      "epoch:3 step:3497 [D loss: 0.647490, acc.: 63.28%] [G loss: 0.903922]\n",
      "epoch:3 step:3498 [D loss: 0.681351, acc.: 54.69%] [G loss: 0.921444]\n",
      "epoch:3 step:3499 [D loss: 0.617949, acc.: 72.66%] [G loss: 0.956246]\n",
      "epoch:3 step:3500 [D loss: 0.617538, acc.: 66.41%] [G loss: 0.929547]\n",
      "epoch:3 step:3501 [D loss: 0.653168, acc.: 61.72%] [G loss: 0.990388]\n",
      "epoch:3 step:3502 [D loss: 0.620012, acc.: 68.75%] [G loss: 1.039522]\n",
      "epoch:3 step:3503 [D loss: 0.649416, acc.: 64.84%] [G loss: 0.959297]\n",
      "epoch:3 step:3504 [D loss: 0.614324, acc.: 67.97%] [G loss: 1.000282]\n",
      "epoch:3 step:3505 [D loss: 0.627400, acc.: 62.50%] [G loss: 0.945361]\n",
      "epoch:3 step:3506 [D loss: 0.619121, acc.: 64.06%] [G loss: 0.991889]\n",
      "epoch:3 step:3507 [D loss: 0.662718, acc.: 57.81%] [G loss: 1.000167]\n",
      "epoch:3 step:3508 [D loss: 0.573958, acc.: 71.09%] [G loss: 1.004369]\n",
      "epoch:3 step:3509 [D loss: 0.599798, acc.: 67.97%] [G loss: 0.913176]\n",
      "epoch:3 step:3510 [D loss: 0.611578, acc.: 69.53%] [G loss: 0.937508]\n",
      "epoch:3 step:3511 [D loss: 0.605113, acc.: 65.62%] [G loss: 0.953048]\n",
      "epoch:3 step:3512 [D loss: 0.580832, acc.: 70.31%] [G loss: 0.950696]\n",
      "epoch:3 step:3513 [D loss: 0.654141, acc.: 61.72%] [G loss: 0.957812]\n",
      "epoch:3 step:3514 [D loss: 0.668471, acc.: 60.94%] [G loss: 0.871515]\n",
      "epoch:3 step:3515 [D loss: 0.667668, acc.: 56.25%] [G loss: 0.844611]\n",
      "epoch:3 step:3516 [D loss: 0.622480, acc.: 67.19%] [G loss: 0.850834]\n",
      "epoch:3 step:3517 [D loss: 0.635371, acc.: 62.50%] [G loss: 0.858198]\n",
      "epoch:3 step:3518 [D loss: 0.583337, acc.: 71.88%] [G loss: 0.912709]\n",
      "epoch:3 step:3519 [D loss: 0.545950, acc.: 75.00%] [G loss: 0.988674]\n",
      "epoch:3 step:3520 [D loss: 0.615945, acc.: 68.75%] [G loss: 1.000121]\n",
      "epoch:3 step:3521 [D loss: 0.683058, acc.: 56.25%] [G loss: 0.922778]\n",
      "epoch:3 step:3522 [D loss: 0.646369, acc.: 63.28%] [G loss: 0.901898]\n",
      "epoch:3 step:3523 [D loss: 0.639262, acc.: 66.41%] [G loss: 0.903432]\n",
      "epoch:3 step:3524 [D loss: 0.682548, acc.: 57.81%] [G loss: 0.875423]\n",
      "epoch:3 step:3525 [D loss: 0.616656, acc.: 69.53%] [G loss: 0.880691]\n",
      "epoch:3 step:3526 [D loss: 0.625721, acc.: 65.62%] [G loss: 0.836703]\n",
      "epoch:3 step:3527 [D loss: 0.697110, acc.: 56.25%] [G loss: 0.844070]\n",
      "epoch:3 step:3528 [D loss: 0.626696, acc.: 61.72%] [G loss: 0.937608]\n",
      "epoch:3 step:3529 [D loss: 0.640289, acc.: 64.06%] [G loss: 0.936485]\n",
      "epoch:3 step:3530 [D loss: 0.660357, acc.: 64.06%] [G loss: 0.964864]\n",
      "epoch:3 step:3531 [D loss: 0.681751, acc.: 60.94%] [G loss: 0.940055]\n",
      "epoch:3 step:3532 [D loss: 0.669664, acc.: 57.81%] [G loss: 0.939557]\n",
      "epoch:3 step:3533 [D loss: 0.631896, acc.: 60.94%] [G loss: 0.902987]\n",
      "epoch:3 step:3534 [D loss: 0.627926, acc.: 67.19%] [G loss: 0.851878]\n",
      "epoch:3 step:3535 [D loss: 0.636975, acc.: 61.72%] [G loss: 0.916671]\n",
      "epoch:3 step:3536 [D loss: 0.577006, acc.: 68.75%] [G loss: 0.978900]\n",
      "epoch:3 step:3537 [D loss: 0.634523, acc.: 64.84%] [G loss: 0.964089]\n",
      "epoch:3 step:3538 [D loss: 0.661065, acc.: 55.47%] [G loss: 0.909282]\n",
      "epoch:3 step:3539 [D loss: 0.634548, acc.: 66.41%] [G loss: 0.873424]\n",
      "epoch:3 step:3540 [D loss: 0.635167, acc.: 67.19%] [G loss: 0.891156]\n",
      "epoch:3 step:3541 [D loss: 0.608664, acc.: 66.41%] [G loss: 0.923062]\n",
      "epoch:3 step:3542 [D loss: 0.639785, acc.: 62.50%] [G loss: 0.890954]\n",
      "epoch:3 step:3543 [D loss: 0.581713, acc.: 68.75%] [G loss: 0.931789]\n",
      "epoch:3 step:3544 [D loss: 0.604320, acc.: 68.75%] [G loss: 0.961463]\n",
      "epoch:3 step:3545 [D loss: 0.643806, acc.: 65.62%] [G loss: 0.930647]\n",
      "epoch:3 step:3546 [D loss: 0.644947, acc.: 64.84%] [G loss: 0.949526]\n",
      "epoch:3 step:3547 [D loss: 0.585884, acc.: 66.41%] [G loss: 0.988593]\n",
      "epoch:3 step:3548 [D loss: 0.633447, acc.: 64.06%] [G loss: 0.969598]\n",
      "epoch:3 step:3549 [D loss: 0.643576, acc.: 62.50%] [G loss: 0.914977]\n",
      "epoch:3 step:3550 [D loss: 0.687681, acc.: 55.47%] [G loss: 0.931511]\n",
      "epoch:3 step:3551 [D loss: 0.634806, acc.: 63.28%] [G loss: 0.902999]\n",
      "epoch:3 step:3552 [D loss: 0.607498, acc.: 66.41%] [G loss: 0.931978]\n",
      "epoch:3 step:3553 [D loss: 0.661420, acc.: 60.94%] [G loss: 0.869542]\n",
      "epoch:3 step:3554 [D loss: 0.560541, acc.: 75.00%] [G loss: 0.931349]\n",
      "epoch:3 step:3555 [D loss: 0.646786, acc.: 67.19%] [G loss: 0.923721]\n",
      "epoch:3 step:3556 [D loss: 0.644242, acc.: 57.03%] [G loss: 0.927282]\n",
      "epoch:3 step:3557 [D loss: 0.617310, acc.: 64.84%] [G loss: 0.955190]\n",
      "epoch:3 step:3558 [D loss: 0.560302, acc.: 76.56%] [G loss: 1.007313]\n",
      "epoch:3 step:3559 [D loss: 0.612528, acc.: 70.31%] [G loss: 0.903349]\n",
      "epoch:3 step:3560 [D loss: 0.674230, acc.: 60.16%] [G loss: 0.876657]\n",
      "epoch:3 step:3561 [D loss: 0.661129, acc.: 60.16%] [G loss: 0.942942]\n",
      "epoch:3 step:3562 [D loss: 0.592060, acc.: 68.75%] [G loss: 0.922266]\n",
      "epoch:3 step:3563 [D loss: 0.667757, acc.: 57.81%] [G loss: 0.890407]\n",
      "epoch:3 step:3564 [D loss: 0.600158, acc.: 69.53%] [G loss: 0.913252]\n",
      "epoch:3 step:3565 [D loss: 0.562221, acc.: 70.31%] [G loss: 0.932455]\n",
      "epoch:3 step:3566 [D loss: 0.609031, acc.: 65.62%] [G loss: 0.949873]\n",
      "epoch:3 step:3567 [D loss: 0.636761, acc.: 62.50%] [G loss: 0.880450]\n",
      "epoch:3 step:3568 [D loss: 0.596697, acc.: 66.41%] [G loss: 0.891764]\n",
      "epoch:3 step:3569 [D loss: 0.615183, acc.: 62.50%] [G loss: 0.939423]\n",
      "epoch:3 step:3570 [D loss: 0.662967, acc.: 64.84%] [G loss: 0.918322]\n",
      "epoch:3 step:3571 [D loss: 0.646459, acc.: 60.16%] [G loss: 0.892901]\n",
      "epoch:3 step:3572 [D loss: 0.620169, acc.: 67.97%] [G loss: 0.919026]\n",
      "epoch:3 step:3573 [D loss: 0.608256, acc.: 67.19%] [G loss: 0.916503]\n",
      "epoch:3 step:3574 [D loss: 0.583677, acc.: 69.53%] [G loss: 0.874826]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3575 [D loss: 0.628736, acc.: 60.94%] [G loss: 0.950705]\n",
      "epoch:3 step:3576 [D loss: 0.691275, acc.: 59.38%] [G loss: 0.876925]\n",
      "epoch:3 step:3577 [D loss: 0.706908, acc.: 56.25%] [G loss: 0.920752]\n",
      "epoch:3 step:3578 [D loss: 0.621339, acc.: 65.62%] [G loss: 0.944416]\n",
      "epoch:3 step:3579 [D loss: 0.653612, acc.: 55.47%] [G loss: 0.907690]\n",
      "epoch:3 step:3580 [D loss: 0.632554, acc.: 67.19%] [G loss: 0.882354]\n",
      "epoch:3 step:3581 [D loss: 0.636780, acc.: 64.06%] [G loss: 0.985249]\n",
      "epoch:3 step:3582 [D loss: 0.646201, acc.: 63.28%] [G loss: 0.988379]\n",
      "epoch:3 step:3583 [D loss: 0.606520, acc.: 69.53%] [G loss: 1.014086]\n",
      "epoch:3 step:3584 [D loss: 0.638535, acc.: 62.50%] [G loss: 0.983561]\n",
      "epoch:3 step:3585 [D loss: 0.646411, acc.: 72.66%] [G loss: 0.892299]\n",
      "epoch:3 step:3586 [D loss: 0.628471, acc.: 64.84%] [G loss: 0.963785]\n",
      "epoch:3 step:3587 [D loss: 0.642159, acc.: 66.41%] [G loss: 0.925662]\n",
      "epoch:3 step:3588 [D loss: 0.649109, acc.: 57.81%] [G loss: 0.901638]\n",
      "epoch:3 step:3589 [D loss: 0.647516, acc.: 63.28%] [G loss: 0.893861]\n",
      "epoch:3 step:3590 [D loss: 0.601594, acc.: 66.41%] [G loss: 0.923871]\n",
      "epoch:3 step:3591 [D loss: 0.615341, acc.: 64.84%] [G loss: 0.943680]\n",
      "epoch:3 step:3592 [D loss: 0.584976, acc.: 69.53%] [G loss: 1.017793]\n",
      "epoch:3 step:3593 [D loss: 0.565911, acc.: 68.75%] [G loss: 1.060037]\n",
      "epoch:3 step:3594 [D loss: 0.679226, acc.: 59.38%] [G loss: 0.993178]\n",
      "epoch:3 step:3595 [D loss: 0.691594, acc.: 60.94%] [G loss: 0.902009]\n",
      "epoch:3 step:3596 [D loss: 0.611326, acc.: 71.88%] [G loss: 0.960093]\n",
      "epoch:3 step:3597 [D loss: 0.587548, acc.: 75.78%] [G loss: 0.954444]\n",
      "epoch:3 step:3598 [D loss: 0.660149, acc.: 61.72%] [G loss: 0.957711]\n",
      "epoch:3 step:3599 [D loss: 0.709980, acc.: 50.00%] [G loss: 0.906807]\n",
      "epoch:3 step:3600 [D loss: 0.603255, acc.: 71.09%] [G loss: 0.891522]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.245879\n",
      "FID: 41.275242\n",
      "0 = 12.584348574638348\n",
      "1 = 0.0834225336146359\n",
      "2 = 0.9761999845504761\n",
      "3 = 0.9524999856948853\n",
      "4 = 0.9998999834060669\n",
      "5 = 0.9998950362205505\n",
      "6 = 0.9524999856948853\n",
      "7 = 8.940778824150575\n",
      "8 = 0.1344827087235295\n",
      "9 = 0.8745499849319458\n",
      "10 = 0.84579998254776\n",
      "11 = 0.9032999873161316\n",
      "12 = 0.8974005579948425\n",
      "13 = 0.84579998254776\n",
      "14 = 6.245929718017578\n",
      "15 = 9.481435775756836\n",
      "16 = 0.16559948027133942\n",
      "17 = 6.24587869644165\n",
      "18 = 41.27524185180664\n",
      "epoch:3 step:3601 [D loss: 0.627989, acc.: 65.62%] [G loss: 0.920831]\n",
      "epoch:3 step:3602 [D loss: 0.669923, acc.: 57.81%] [G loss: 0.929781]\n",
      "epoch:3 step:3603 [D loss: 0.545980, acc.: 78.12%] [G loss: 1.040705]\n",
      "epoch:3 step:3604 [D loss: 0.598903, acc.: 67.97%] [G loss: 0.949853]\n",
      "epoch:3 step:3605 [D loss: 0.657290, acc.: 58.59%] [G loss: 0.918086]\n",
      "epoch:3 step:3606 [D loss: 0.668423, acc.: 58.59%] [G loss: 0.865685]\n",
      "epoch:3 step:3607 [D loss: 0.620300, acc.: 68.75%] [G loss: 0.919444]\n",
      "epoch:3 step:3608 [D loss: 0.637545, acc.: 64.06%] [G loss: 1.007596]\n",
      "epoch:3 step:3609 [D loss: 0.582197, acc.: 72.66%] [G loss: 0.971457]\n",
      "epoch:3 step:3610 [D loss: 0.658045, acc.: 60.16%] [G loss: 0.979584]\n",
      "epoch:3 step:3611 [D loss: 0.610191, acc.: 71.09%] [G loss: 0.936930]\n",
      "epoch:3 step:3612 [D loss: 0.601550, acc.: 64.06%] [G loss: 1.022047]\n",
      "epoch:3 step:3613 [D loss: 0.550911, acc.: 70.31%] [G loss: 0.991558]\n",
      "epoch:3 step:3614 [D loss: 0.578284, acc.: 71.88%] [G loss: 0.971079]\n",
      "epoch:3 step:3615 [D loss: 0.616606, acc.: 70.31%] [G loss: 0.953943]\n",
      "epoch:3 step:3616 [D loss: 0.613254, acc.: 65.62%] [G loss: 0.843810]\n",
      "epoch:3 step:3617 [D loss: 0.607884, acc.: 67.97%] [G loss: 0.837095]\n",
      "epoch:3 step:3618 [D loss: 0.552091, acc.: 75.78%] [G loss: 0.953228]\n",
      "epoch:3 step:3619 [D loss: 0.648453, acc.: 59.38%] [G loss: 0.928498]\n",
      "epoch:3 step:3620 [D loss: 0.641720, acc.: 66.41%] [G loss: 0.899477]\n",
      "epoch:3 step:3621 [D loss: 0.621554, acc.: 65.62%] [G loss: 0.875174]\n",
      "epoch:3 step:3622 [D loss: 0.672689, acc.: 54.69%] [G loss: 0.887066]\n",
      "epoch:3 step:3623 [D loss: 0.669327, acc.: 57.03%] [G loss: 0.887164]\n",
      "epoch:3 step:3624 [D loss: 0.608087, acc.: 66.41%] [G loss: 0.919529]\n",
      "epoch:3 step:3625 [D loss: 0.667365, acc.: 56.25%] [G loss: 0.937992]\n",
      "epoch:3 step:3626 [D loss: 0.606607, acc.: 64.84%] [G loss: 0.955595]\n",
      "epoch:3 step:3627 [D loss: 0.632412, acc.: 62.50%] [G loss: 0.928428]\n",
      "epoch:3 step:3628 [D loss: 0.659237, acc.: 59.38%] [G loss: 0.872571]\n",
      "epoch:3 step:3629 [D loss: 0.636093, acc.: 61.72%] [G loss: 0.865165]\n",
      "epoch:3 step:3630 [D loss: 0.641153, acc.: 63.28%] [G loss: 0.895566]\n",
      "epoch:3 step:3631 [D loss: 0.644322, acc.: 60.16%] [G loss: 0.959653]\n",
      "epoch:3 step:3632 [D loss: 0.635449, acc.: 62.50%] [G loss: 0.870732]\n",
      "epoch:3 step:3633 [D loss: 0.579749, acc.: 74.22%] [G loss: 0.932162]\n",
      "epoch:3 step:3634 [D loss: 0.631459, acc.: 60.94%] [G loss: 0.936555]\n",
      "epoch:3 step:3635 [D loss: 0.664064, acc.: 64.06%] [G loss: 0.891533]\n",
      "epoch:3 step:3636 [D loss: 0.651808, acc.: 56.25%] [G loss: 0.869453]\n",
      "epoch:3 step:3637 [D loss: 0.699820, acc.: 51.56%] [G loss: 0.866193]\n",
      "epoch:3 step:3638 [D loss: 0.663020, acc.: 63.28%] [G loss: 0.957815]\n",
      "epoch:3 step:3639 [D loss: 0.633432, acc.: 64.84%] [G loss: 0.924486]\n",
      "epoch:3 step:3640 [D loss: 0.624316, acc.: 65.62%] [G loss: 0.921115]\n",
      "epoch:3 step:3641 [D loss: 0.626392, acc.: 68.75%] [G loss: 0.913343]\n",
      "epoch:3 step:3642 [D loss: 0.655076, acc.: 60.16%] [G loss: 0.871333]\n",
      "epoch:3 step:3643 [D loss: 0.603254, acc.: 70.31%] [G loss: 0.912804]\n",
      "epoch:3 step:3644 [D loss: 0.638544, acc.: 64.06%] [G loss: 0.966191]\n",
      "epoch:3 step:3645 [D loss: 0.618018, acc.: 71.88%] [G loss: 0.845497]\n",
      "epoch:3 step:3646 [D loss: 0.624992, acc.: 64.06%] [G loss: 0.842907]\n",
      "epoch:3 step:3647 [D loss: 0.663768, acc.: 62.50%] [G loss: 0.850699]\n",
      "epoch:3 step:3648 [D loss: 0.638044, acc.: 67.19%] [G loss: 0.895539]\n",
      "epoch:3 step:3649 [D loss: 0.642441, acc.: 64.84%] [G loss: 0.958895]\n",
      "epoch:3 step:3650 [D loss: 0.649669, acc.: 62.50%] [G loss: 0.905978]\n",
      "epoch:3 step:3651 [D loss: 0.611397, acc.: 70.31%] [G loss: 0.936121]\n",
      "epoch:3 step:3652 [D loss: 0.615378, acc.: 73.44%] [G loss: 0.906550]\n",
      "epoch:3 step:3653 [D loss: 0.612660, acc.: 71.09%] [G loss: 0.915294]\n",
      "epoch:3 step:3654 [D loss: 0.649842, acc.: 60.94%] [G loss: 0.923557]\n",
      "epoch:3 step:3655 [D loss: 0.686419, acc.: 58.59%] [G loss: 0.968000]\n",
      "epoch:3 step:3656 [D loss: 0.645865, acc.: 62.50%] [G loss: 0.896630]\n",
      "epoch:3 step:3657 [D loss: 0.642229, acc.: 64.06%] [G loss: 0.865505]\n",
      "epoch:3 step:3658 [D loss: 0.640828, acc.: 62.50%] [G loss: 0.889815]\n",
      "epoch:3 step:3659 [D loss: 0.614701, acc.: 65.62%] [G loss: 0.931619]\n",
      "epoch:3 step:3660 [D loss: 0.633395, acc.: 69.53%] [G loss: 0.904867]\n",
      "epoch:3 step:3661 [D loss: 0.661743, acc.: 56.25%] [G loss: 0.901252]\n",
      "epoch:3 step:3662 [D loss: 0.661403, acc.: 57.03%] [G loss: 0.829052]\n",
      "epoch:3 step:3663 [D loss: 0.627813, acc.: 64.84%] [G loss: 0.901917]\n",
      "epoch:3 step:3664 [D loss: 0.630725, acc.: 66.41%] [G loss: 0.906213]\n",
      "epoch:3 step:3665 [D loss: 0.593463, acc.: 68.75%] [G loss: 0.903945]\n",
      "epoch:3 step:3666 [D loss: 0.617164, acc.: 67.19%] [G loss: 0.989196]\n",
      "epoch:3 step:3667 [D loss: 0.662382, acc.: 62.50%] [G loss: 0.898219]\n",
      "epoch:3 step:3668 [D loss: 0.593345, acc.: 69.53%] [G loss: 0.900714]\n",
      "epoch:3 step:3669 [D loss: 0.728095, acc.: 48.44%] [G loss: 0.916910]\n",
      "epoch:3 step:3670 [D loss: 0.598659, acc.: 70.31%] [G loss: 0.980438]\n",
      "epoch:3 step:3671 [D loss: 0.623938, acc.: 66.41%] [G loss: 0.978384]\n",
      "epoch:3 step:3672 [D loss: 0.681952, acc.: 53.12%] [G loss: 0.906280]\n",
      "epoch:3 step:3673 [D loss: 0.647787, acc.: 64.06%] [G loss: 0.840874]\n",
      "epoch:3 step:3674 [D loss: 0.597992, acc.: 71.09%] [G loss: 0.904374]\n",
      "epoch:3 step:3675 [D loss: 0.640792, acc.: 66.41%] [G loss: 0.881137]\n",
      "epoch:3 step:3676 [D loss: 0.659569, acc.: 61.72%] [G loss: 0.920714]\n",
      "epoch:3 step:3677 [D loss: 0.631691, acc.: 62.50%] [G loss: 0.858532]\n",
      "epoch:3 step:3678 [D loss: 0.670671, acc.: 60.16%] [G loss: 0.873633]\n",
      "epoch:3 step:3679 [D loss: 0.635975, acc.: 67.19%] [G loss: 0.952064]\n",
      "epoch:3 step:3680 [D loss: 0.630068, acc.: 63.28%] [G loss: 0.922777]\n",
      "epoch:3 step:3681 [D loss: 0.618666, acc.: 70.31%] [G loss: 0.878273]\n",
      "epoch:3 step:3682 [D loss: 0.605528, acc.: 69.53%] [G loss: 0.888390]\n",
      "epoch:3 step:3683 [D loss: 0.666723, acc.: 60.94%] [G loss: 0.928470]\n",
      "epoch:3 step:3684 [D loss: 0.665971, acc.: 55.47%] [G loss: 0.905191]\n",
      "epoch:3 step:3685 [D loss: 0.657038, acc.: 64.06%] [G loss: 0.934364]\n",
      "epoch:3 step:3686 [D loss: 0.597102, acc.: 71.09%] [G loss: 0.870464]\n",
      "epoch:3 step:3687 [D loss: 0.643412, acc.: 64.84%] [G loss: 0.887020]\n",
      "epoch:3 step:3688 [D loss: 0.632161, acc.: 63.28%] [G loss: 0.955005]\n",
      "epoch:3 step:3689 [D loss: 0.682541, acc.: 56.25%] [G loss: 0.882579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3690 [D loss: 0.650490, acc.: 62.50%] [G loss: 0.912433]\n",
      "epoch:3 step:3691 [D loss: 0.675001, acc.: 53.91%] [G loss: 0.893459]\n",
      "epoch:3 step:3692 [D loss: 0.632757, acc.: 65.62%] [G loss: 0.890861]\n",
      "epoch:3 step:3693 [D loss: 0.660368, acc.: 60.94%] [G loss: 0.855895]\n",
      "epoch:3 step:3694 [D loss: 0.627477, acc.: 71.09%] [G loss: 0.920857]\n",
      "epoch:3 step:3695 [D loss: 0.573646, acc.: 67.97%] [G loss: 0.994602]\n",
      "epoch:3 step:3696 [D loss: 0.627034, acc.: 64.06%] [G loss: 0.995106]\n",
      "epoch:3 step:3697 [D loss: 0.638654, acc.: 64.84%] [G loss: 0.985184]\n",
      "epoch:3 step:3698 [D loss: 0.657974, acc.: 65.62%] [G loss: 0.935794]\n",
      "epoch:3 step:3699 [D loss: 0.627522, acc.: 62.50%] [G loss: 0.910831]\n",
      "epoch:3 step:3700 [D loss: 0.610950, acc.: 67.97%] [G loss: 0.931769]\n",
      "epoch:3 step:3701 [D loss: 0.580140, acc.: 70.31%] [G loss: 0.982476]\n",
      "epoch:3 step:3702 [D loss: 0.731134, acc.: 49.22%] [G loss: 0.920378]\n",
      "epoch:3 step:3703 [D loss: 0.706809, acc.: 50.00%] [G loss: 0.855491]\n",
      "epoch:3 step:3704 [D loss: 0.629226, acc.: 66.41%] [G loss: 0.902919]\n",
      "epoch:3 step:3705 [D loss: 0.584518, acc.: 73.44%] [G loss: 0.957169]\n",
      "epoch:3 step:3706 [D loss: 0.614857, acc.: 67.97%] [G loss: 0.933717]\n",
      "epoch:3 step:3707 [D loss: 0.635469, acc.: 65.62%] [G loss: 0.947232]\n",
      "epoch:3 step:3708 [D loss: 0.614782, acc.: 65.62%] [G loss: 0.948799]\n",
      "epoch:3 step:3709 [D loss: 0.612436, acc.: 67.19%] [G loss: 0.955153]\n",
      "epoch:3 step:3710 [D loss: 0.647035, acc.: 57.81%] [G loss: 0.987244]\n",
      "epoch:3 step:3711 [D loss: 0.574043, acc.: 71.88%] [G loss: 0.982926]\n",
      "epoch:3 step:3712 [D loss: 0.637674, acc.: 58.59%] [G loss: 0.994952]\n",
      "epoch:3 step:3713 [D loss: 0.682614, acc.: 57.81%] [G loss: 0.998104]\n",
      "epoch:3 step:3714 [D loss: 0.651678, acc.: 65.62%] [G loss: 0.971272]\n",
      "epoch:3 step:3715 [D loss: 0.607424, acc.: 68.75%] [G loss: 0.939106]\n",
      "epoch:3 step:3716 [D loss: 0.569474, acc.: 75.00%] [G loss: 0.983453]\n",
      "epoch:3 step:3717 [D loss: 0.618190, acc.: 64.84%] [G loss: 0.998105]\n",
      "epoch:3 step:3718 [D loss: 0.683484, acc.: 57.81%] [G loss: 0.903860]\n",
      "epoch:3 step:3719 [D loss: 0.633380, acc.: 63.28%] [G loss: 0.910760]\n",
      "epoch:3 step:3720 [D loss: 0.627451, acc.: 68.75%] [G loss: 0.970686]\n",
      "epoch:3 step:3721 [D loss: 0.601248, acc.: 72.66%] [G loss: 0.949042]\n",
      "epoch:3 step:3722 [D loss: 0.614100, acc.: 63.28%] [G loss: 0.965411]\n",
      "epoch:3 step:3723 [D loss: 0.528415, acc.: 71.88%] [G loss: 1.062061]\n",
      "epoch:3 step:3724 [D loss: 0.695534, acc.: 57.03%] [G loss: 1.028044]\n",
      "epoch:3 step:3725 [D loss: 0.631529, acc.: 64.06%] [G loss: 0.958984]\n",
      "epoch:3 step:3726 [D loss: 0.663259, acc.: 64.06%] [G loss: 0.913411]\n",
      "epoch:3 step:3727 [D loss: 0.634578, acc.: 68.75%] [G loss: 0.902360]\n",
      "epoch:3 step:3728 [D loss: 0.617688, acc.: 67.19%] [G loss: 0.905646]\n",
      "epoch:3 step:3729 [D loss: 0.576129, acc.: 76.56%] [G loss: 0.887866]\n",
      "epoch:3 step:3730 [D loss: 0.584396, acc.: 71.88%] [G loss: 0.978880]\n",
      "epoch:3 step:3731 [D loss: 0.750325, acc.: 43.75%] [G loss: 0.967210]\n",
      "epoch:3 step:3732 [D loss: 0.576172, acc.: 76.56%] [G loss: 0.995926]\n",
      "epoch:3 step:3733 [D loss: 0.646112, acc.: 58.59%] [G loss: 0.845151]\n",
      "epoch:3 step:3734 [D loss: 0.558129, acc.: 77.34%] [G loss: 0.902544]\n",
      "epoch:3 step:3735 [D loss: 0.585642, acc.: 73.44%] [G loss: 0.976971]\n",
      "epoch:3 step:3736 [D loss: 0.540237, acc.: 74.22%] [G loss: 1.037035]\n",
      "epoch:3 step:3737 [D loss: 0.548997, acc.: 76.56%] [G loss: 1.053559]\n",
      "epoch:3 step:3738 [D loss: 0.622174, acc.: 60.16%] [G loss: 1.131146]\n",
      "epoch:3 step:3739 [D loss: 0.851383, acc.: 56.25%] [G loss: 1.029779]\n",
      "epoch:3 step:3740 [D loss: 0.649056, acc.: 66.41%] [G loss: 1.157891]\n",
      "epoch:3 step:3741 [D loss: 0.550970, acc.: 68.75%] [G loss: 1.090248]\n",
      "epoch:3 step:3742 [D loss: 0.724405, acc.: 54.69%] [G loss: 0.889411]\n",
      "epoch:3 step:3743 [D loss: 0.711417, acc.: 54.69%] [G loss: 0.826355]\n",
      "epoch:3 step:3744 [D loss: 0.668864, acc.: 56.25%] [G loss: 0.867932]\n",
      "epoch:3 step:3745 [D loss: 0.586797, acc.: 70.31%] [G loss: 0.921697]\n",
      "epoch:3 step:3746 [D loss: 0.617937, acc.: 66.41%] [G loss: 0.910307]\n",
      "epoch:3 step:3747 [D loss: 0.534147, acc.: 78.12%] [G loss: 0.980542]\n",
      "epoch:3 step:3748 [D loss: 0.526840, acc.: 78.12%] [G loss: 1.016963]\n",
      "epoch:4 step:3749 [D loss: 0.618533, acc.: 62.50%] [G loss: 1.034632]\n",
      "epoch:4 step:3750 [D loss: 0.716701, acc.: 48.44%] [G loss: 0.976834]\n",
      "epoch:4 step:3751 [D loss: 0.663758, acc.: 60.16%] [G loss: 1.028444]\n",
      "epoch:4 step:3752 [D loss: 0.614003, acc.: 64.84%] [G loss: 1.026712]\n",
      "epoch:4 step:3753 [D loss: 0.635304, acc.: 63.28%] [G loss: 1.014969]\n",
      "epoch:4 step:3754 [D loss: 0.581690, acc.: 73.44%] [G loss: 1.003664]\n",
      "epoch:4 step:3755 [D loss: 0.605524, acc.: 70.31%] [G loss: 0.976078]\n",
      "epoch:4 step:3756 [D loss: 0.651148, acc.: 64.06%] [G loss: 0.888735]\n",
      "epoch:4 step:3757 [D loss: 0.615148, acc.: 68.75%] [G loss: 0.835563]\n",
      "epoch:4 step:3758 [D loss: 0.681980, acc.: 54.69%] [G loss: 0.921402]\n",
      "epoch:4 step:3759 [D loss: 0.597367, acc.: 71.88%] [G loss: 0.918804]\n",
      "epoch:4 step:3760 [D loss: 0.643103, acc.: 64.06%] [G loss: 1.005596]\n",
      "epoch:4 step:3761 [D loss: 0.600752, acc.: 69.53%] [G loss: 0.951237]\n",
      "epoch:4 step:3762 [D loss: 0.603536, acc.: 73.44%] [G loss: 0.958501]\n",
      "epoch:4 step:3763 [D loss: 0.584228, acc.: 70.31%] [G loss: 0.882007]\n",
      "epoch:4 step:3764 [D loss: 0.620004, acc.: 67.19%] [G loss: 0.967127]\n",
      "epoch:4 step:3765 [D loss: 0.677460, acc.: 56.25%] [G loss: 0.947852]\n",
      "epoch:4 step:3766 [D loss: 0.670275, acc.: 61.72%] [G loss: 0.910595]\n",
      "epoch:4 step:3767 [D loss: 0.670053, acc.: 62.50%] [G loss: 0.926845]\n",
      "epoch:4 step:3768 [D loss: 0.680138, acc.: 57.81%] [G loss: 0.911529]\n",
      "epoch:4 step:3769 [D loss: 0.638067, acc.: 66.41%] [G loss: 0.935681]\n",
      "epoch:4 step:3770 [D loss: 0.544128, acc.: 79.69%] [G loss: 0.999035]\n",
      "epoch:4 step:3771 [D loss: 0.677849, acc.: 63.28%] [G loss: 0.934032]\n",
      "epoch:4 step:3772 [D loss: 0.656008, acc.: 64.06%] [G loss: 0.919289]\n",
      "epoch:4 step:3773 [D loss: 0.622704, acc.: 66.41%] [G loss: 0.886809]\n",
      "epoch:4 step:3774 [D loss: 0.664727, acc.: 60.16%] [G loss: 0.933196]\n",
      "epoch:4 step:3775 [D loss: 0.650387, acc.: 62.50%] [G loss: 0.905404]\n",
      "epoch:4 step:3776 [D loss: 0.606007, acc.: 68.75%] [G loss: 0.914762]\n",
      "epoch:4 step:3777 [D loss: 0.588512, acc.: 73.44%] [G loss: 0.918129]\n",
      "epoch:4 step:3778 [D loss: 0.661949, acc.: 59.38%] [G loss: 0.899600]\n",
      "epoch:4 step:3779 [D loss: 0.676505, acc.: 58.59%] [G loss: 0.968902]\n",
      "epoch:4 step:3780 [D loss: 0.646833, acc.: 57.81%] [G loss: 0.905121]\n",
      "epoch:4 step:3781 [D loss: 0.622826, acc.: 65.62%] [G loss: 0.897654]\n",
      "epoch:4 step:3782 [D loss: 0.623658, acc.: 68.75%] [G loss: 0.941797]\n",
      "epoch:4 step:3783 [D loss: 0.585811, acc.: 71.09%] [G loss: 0.980387]\n",
      "epoch:4 step:3784 [D loss: 0.548418, acc.: 73.44%] [G loss: 1.012845]\n",
      "epoch:4 step:3785 [D loss: 0.636754, acc.: 67.19%] [G loss: 0.959284]\n",
      "epoch:4 step:3786 [D loss: 0.718642, acc.: 53.91%] [G loss: 0.885340]\n",
      "epoch:4 step:3787 [D loss: 0.613029, acc.: 65.62%] [G loss: 0.944623]\n",
      "epoch:4 step:3788 [D loss: 0.614406, acc.: 65.62%] [G loss: 1.011812]\n",
      "epoch:4 step:3789 [D loss: 0.656461, acc.: 60.16%] [G loss: 0.902768]\n",
      "epoch:4 step:3790 [D loss: 0.619790, acc.: 57.03%] [G loss: 0.902769]\n",
      "epoch:4 step:3791 [D loss: 0.654114, acc.: 60.94%] [G loss: 0.932898]\n",
      "epoch:4 step:3792 [D loss: 0.672976, acc.: 58.59%] [G loss: 0.915284]\n",
      "epoch:4 step:3793 [D loss: 0.625940, acc.: 64.84%] [G loss: 0.949397]\n",
      "epoch:4 step:3794 [D loss: 0.635219, acc.: 66.41%] [G loss: 0.940418]\n",
      "epoch:4 step:3795 [D loss: 0.634815, acc.: 66.41%] [G loss: 0.960128]\n",
      "epoch:4 step:3796 [D loss: 0.624655, acc.: 66.41%] [G loss: 0.948850]\n",
      "epoch:4 step:3797 [D loss: 0.594036, acc.: 68.75%] [G loss: 1.000127]\n",
      "epoch:4 step:3798 [D loss: 0.625941, acc.: 64.06%] [G loss: 0.980771]\n",
      "epoch:4 step:3799 [D loss: 0.642812, acc.: 67.19%] [G loss: 0.941460]\n",
      "epoch:4 step:3800 [D loss: 0.567077, acc.: 73.44%] [G loss: 0.902421]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.920725\n",
      "FID: 25.511057\n",
      "0 = 12.375392610263804\n",
      "1 = 0.07957186817714032\n",
      "2 = 0.9668999910354614\n",
      "3 = 0.9341999888420105\n",
      "4 = 0.9995999932289124\n",
      "5 = 0.9995720386505127\n",
      "6 = 0.9341999888420105\n",
      "7 = 7.832142711848024\n",
      "8 = 0.10920702433368634\n",
      "9 = 0.8284500241279602\n",
      "10 = 0.7957000136375427\n",
      "11 = 0.8611999750137329\n",
      "12 = 0.8514713644981384\n",
      "13 = 0.7957000136375427\n",
      "14 = 6.920785903930664\n",
      "15 = 9.531311988830566\n",
      "16 = 0.1379532516002655\n",
      "17 = 6.920724868774414\n",
      "18 = 25.511056900024414\n",
      "epoch:4 step:3801 [D loss: 0.642988, acc.: 62.50%] [G loss: 0.842657]\n",
      "epoch:4 step:3802 [D loss: 0.649840, acc.: 61.72%] [G loss: 0.952025]\n",
      "epoch:4 step:3803 [D loss: 0.566243, acc.: 75.78%] [G loss: 0.921168]\n",
      "epoch:4 step:3804 [D loss: 0.644444, acc.: 64.84%] [G loss: 0.914479]\n",
      "epoch:4 step:3805 [D loss: 0.625381, acc.: 65.62%] [G loss: 0.886279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3806 [D loss: 0.656831, acc.: 53.91%] [G loss: 0.921569]\n",
      "epoch:4 step:3807 [D loss: 0.632232, acc.: 69.53%] [G loss: 1.007254]\n",
      "epoch:4 step:3808 [D loss: 0.621448, acc.: 70.31%] [G loss: 0.973122]\n",
      "epoch:4 step:3809 [D loss: 0.648808, acc.: 63.28%] [G loss: 0.909683]\n",
      "epoch:4 step:3810 [D loss: 0.673594, acc.: 58.59%] [G loss: 0.964135]\n",
      "epoch:4 step:3811 [D loss: 0.667203, acc.: 59.38%] [G loss: 0.943695]\n",
      "epoch:4 step:3812 [D loss: 0.628710, acc.: 65.62%] [G loss: 0.917793]\n",
      "epoch:4 step:3813 [D loss: 0.651240, acc.: 64.84%] [G loss: 0.846407]\n",
      "epoch:4 step:3814 [D loss: 0.618716, acc.: 72.66%] [G loss: 0.872236]\n",
      "epoch:4 step:3815 [D loss: 0.652880, acc.: 67.97%] [G loss: 0.870494]\n",
      "epoch:4 step:3816 [D loss: 0.618261, acc.: 69.53%] [G loss: 0.903701]\n",
      "epoch:4 step:3817 [D loss: 0.615344, acc.: 64.84%] [G loss: 0.934034]\n",
      "epoch:4 step:3818 [D loss: 0.632161, acc.: 61.72%] [G loss: 0.925121]\n",
      "epoch:4 step:3819 [D loss: 0.646267, acc.: 59.38%] [G loss: 0.897080]\n",
      "epoch:4 step:3820 [D loss: 0.588411, acc.: 73.44%] [G loss: 0.884192]\n",
      "epoch:4 step:3821 [D loss: 0.601555, acc.: 69.53%] [G loss: 0.932954]\n",
      "epoch:4 step:3822 [D loss: 0.635480, acc.: 61.72%] [G loss: 0.954836]\n",
      "epoch:4 step:3823 [D loss: 0.603362, acc.: 71.88%] [G loss: 0.952777]\n",
      "epoch:4 step:3824 [D loss: 0.599084, acc.: 60.16%] [G loss: 0.953278]\n",
      "epoch:4 step:3825 [D loss: 0.573843, acc.: 72.66%] [G loss: 0.968170]\n",
      "epoch:4 step:3826 [D loss: 0.713133, acc.: 60.16%] [G loss: 0.875820]\n",
      "epoch:4 step:3827 [D loss: 0.653244, acc.: 64.06%] [G loss: 0.960590]\n",
      "epoch:4 step:3828 [D loss: 0.637041, acc.: 62.50%] [G loss: 0.887253]\n",
      "epoch:4 step:3829 [D loss: 0.654464, acc.: 64.06%] [G loss: 0.928700]\n",
      "epoch:4 step:3830 [D loss: 0.624309, acc.: 62.50%] [G loss: 0.836628]\n",
      "epoch:4 step:3831 [D loss: 0.586729, acc.: 67.19%] [G loss: 0.952428]\n",
      "epoch:4 step:3832 [D loss: 0.597923, acc.: 66.41%] [G loss: 0.933340]\n",
      "epoch:4 step:3833 [D loss: 0.586131, acc.: 72.66%] [G loss: 0.997774]\n",
      "epoch:4 step:3834 [D loss: 0.603075, acc.: 70.31%] [G loss: 0.930452]\n",
      "epoch:4 step:3835 [D loss: 0.641111, acc.: 64.84%] [G loss: 0.920692]\n",
      "epoch:4 step:3836 [D loss: 0.655640, acc.: 64.84%] [G loss: 0.898115]\n",
      "epoch:4 step:3837 [D loss: 0.606331, acc.: 71.09%] [G loss: 0.898027]\n",
      "epoch:4 step:3838 [D loss: 0.645764, acc.: 59.38%] [G loss: 0.942002]\n",
      "epoch:4 step:3839 [D loss: 0.640576, acc.: 60.16%] [G loss: 0.885556]\n",
      "epoch:4 step:3840 [D loss: 0.623334, acc.: 67.19%] [G loss: 0.947062]\n",
      "epoch:4 step:3841 [D loss: 0.604027, acc.: 69.53%] [G loss: 0.918563]\n",
      "epoch:4 step:3842 [D loss: 0.667169, acc.: 57.03%] [G loss: 1.048382]\n",
      "epoch:4 step:3843 [D loss: 0.634678, acc.: 62.50%] [G loss: 0.918338]\n",
      "epoch:4 step:3844 [D loss: 0.660445, acc.: 59.38%] [G loss: 0.918871]\n",
      "epoch:4 step:3845 [D loss: 0.545613, acc.: 75.78%] [G loss: 0.913566]\n",
      "epoch:4 step:3846 [D loss: 0.653700, acc.: 64.06%] [G loss: 0.914192]\n",
      "epoch:4 step:3847 [D loss: 0.644986, acc.: 60.94%] [G loss: 0.938528]\n",
      "epoch:4 step:3848 [D loss: 0.615333, acc.: 67.19%] [G loss: 0.951178]\n",
      "epoch:4 step:3849 [D loss: 0.642608, acc.: 64.84%] [G loss: 0.930071]\n",
      "epoch:4 step:3850 [D loss: 0.662162, acc.: 60.16%] [G loss: 0.890547]\n",
      "epoch:4 step:3851 [D loss: 0.580114, acc.: 74.22%] [G loss: 0.901872]\n",
      "epoch:4 step:3852 [D loss: 0.630997, acc.: 64.06%] [G loss: 0.877226]\n",
      "epoch:4 step:3853 [D loss: 0.695337, acc.: 55.47%] [G loss: 0.956322]\n",
      "epoch:4 step:3854 [D loss: 0.624001, acc.: 69.53%] [G loss: 0.975493]\n",
      "epoch:4 step:3855 [D loss: 0.665373, acc.: 60.94%] [G loss: 0.997076]\n",
      "epoch:4 step:3856 [D loss: 0.687174, acc.: 57.81%] [G loss: 0.977062]\n",
      "epoch:4 step:3857 [D loss: 0.671645, acc.: 64.06%] [G loss: 0.945588]\n",
      "epoch:4 step:3858 [D loss: 0.609042, acc.: 66.41%] [G loss: 0.898560]\n",
      "epoch:4 step:3859 [D loss: 0.609802, acc.: 67.19%] [G loss: 0.882598]\n",
      "epoch:4 step:3860 [D loss: 0.572859, acc.: 68.75%] [G loss: 0.939709]\n",
      "epoch:4 step:3861 [D loss: 0.667626, acc.: 61.72%] [G loss: 0.947975]\n",
      "epoch:4 step:3862 [D loss: 0.613922, acc.: 75.00%] [G loss: 0.957062]\n",
      "epoch:4 step:3863 [D loss: 0.612171, acc.: 70.31%] [G loss: 0.967113]\n",
      "epoch:4 step:3864 [D loss: 0.606783, acc.: 62.50%] [G loss: 0.925107]\n",
      "epoch:4 step:3865 [D loss: 0.595676, acc.: 69.53%] [G loss: 1.018333]\n",
      "epoch:4 step:3866 [D loss: 0.621987, acc.: 67.19%] [G loss: 1.028838]\n",
      "epoch:4 step:3867 [D loss: 0.557280, acc.: 70.31%] [G loss: 1.023615]\n",
      "epoch:4 step:3868 [D loss: 0.673082, acc.: 63.28%] [G loss: 0.939578]\n",
      "epoch:4 step:3869 [D loss: 0.713448, acc.: 60.16%] [G loss: 0.894902]\n",
      "epoch:4 step:3870 [D loss: 0.608121, acc.: 71.09%] [G loss: 0.987754]\n",
      "epoch:4 step:3871 [D loss: 0.638373, acc.: 65.62%] [G loss: 0.953786]\n",
      "epoch:4 step:3872 [D loss: 0.673790, acc.: 62.50%] [G loss: 0.959542]\n",
      "epoch:4 step:3873 [D loss: 0.697492, acc.: 56.25%] [G loss: 0.937148]\n",
      "epoch:4 step:3874 [D loss: 0.585630, acc.: 68.75%] [G loss: 0.900671]\n",
      "epoch:4 step:3875 [D loss: 0.654649, acc.: 66.41%] [G loss: 0.893519]\n",
      "epoch:4 step:3876 [D loss: 0.652028, acc.: 62.50%] [G loss: 0.872717]\n",
      "epoch:4 step:3877 [D loss: 0.640786, acc.: 67.19%] [G loss: 0.856527]\n",
      "epoch:4 step:3878 [D loss: 0.635874, acc.: 64.06%] [G loss: 0.820232]\n",
      "epoch:4 step:3879 [D loss: 0.620536, acc.: 66.41%] [G loss: 0.969496]\n",
      "epoch:4 step:3880 [D loss: 0.632137, acc.: 61.72%] [G loss: 0.911324]\n",
      "epoch:4 step:3881 [D loss: 0.641502, acc.: 67.19%] [G loss: 0.918935]\n",
      "epoch:4 step:3882 [D loss: 0.595609, acc.: 67.19%] [G loss: 0.942101]\n",
      "epoch:4 step:3883 [D loss: 0.613896, acc.: 64.84%] [G loss: 0.942957]\n",
      "epoch:4 step:3884 [D loss: 0.600796, acc.: 71.09%] [G loss: 0.899860]\n",
      "epoch:4 step:3885 [D loss: 0.664879, acc.: 60.16%] [G loss: 0.893978]\n",
      "epoch:4 step:3886 [D loss: 0.624760, acc.: 62.50%] [G loss: 0.892966]\n",
      "epoch:4 step:3887 [D loss: 0.667638, acc.: 56.25%] [G loss: 0.931010]\n",
      "epoch:4 step:3888 [D loss: 0.635082, acc.: 62.50%] [G loss: 0.845664]\n",
      "epoch:4 step:3889 [D loss: 0.657453, acc.: 57.81%] [G loss: 0.969596]\n",
      "epoch:4 step:3890 [D loss: 0.658295, acc.: 64.06%] [G loss: 0.954339]\n",
      "epoch:4 step:3891 [D loss: 0.635404, acc.: 64.06%] [G loss: 0.962249]\n",
      "epoch:4 step:3892 [D loss: 0.587680, acc.: 70.31%] [G loss: 0.962975]\n",
      "epoch:4 step:3893 [D loss: 0.616735, acc.: 72.66%] [G loss: 1.030914]\n",
      "epoch:4 step:3894 [D loss: 0.619855, acc.: 71.09%] [G loss: 0.960236]\n",
      "epoch:4 step:3895 [D loss: 0.638508, acc.: 61.72%] [G loss: 0.893506]\n",
      "epoch:4 step:3896 [D loss: 0.667525, acc.: 61.72%] [G loss: 0.952161]\n",
      "epoch:4 step:3897 [D loss: 0.632290, acc.: 63.28%] [G loss: 0.968316]\n",
      "epoch:4 step:3898 [D loss: 0.664231, acc.: 64.84%] [G loss: 0.857702]\n",
      "epoch:4 step:3899 [D loss: 0.595275, acc.: 66.41%] [G loss: 0.881674]\n",
      "epoch:4 step:3900 [D loss: 0.586964, acc.: 72.66%] [G loss: 0.937762]\n",
      "epoch:4 step:3901 [D loss: 0.665255, acc.: 60.16%] [G loss: 0.960447]\n",
      "epoch:4 step:3902 [D loss: 0.668210, acc.: 59.38%] [G loss: 0.902507]\n",
      "epoch:4 step:3903 [D loss: 0.595939, acc.: 76.56%] [G loss: 0.987365]\n",
      "epoch:4 step:3904 [D loss: 0.590400, acc.: 67.97%] [G loss: 0.921998]\n",
      "epoch:4 step:3905 [D loss: 0.637096, acc.: 64.84%] [G loss: 0.973463]\n",
      "epoch:4 step:3906 [D loss: 0.636339, acc.: 70.31%] [G loss: 0.925719]\n",
      "epoch:4 step:3907 [D loss: 0.640035, acc.: 63.28%] [G loss: 0.943465]\n",
      "epoch:4 step:3908 [D loss: 0.702503, acc.: 55.47%] [G loss: 0.940050]\n",
      "epoch:4 step:3909 [D loss: 0.617307, acc.: 68.75%] [G loss: 0.949425]\n",
      "epoch:4 step:3910 [D loss: 0.598265, acc.: 70.31%] [G loss: 1.007708]\n",
      "epoch:4 step:3911 [D loss: 0.656199, acc.: 65.62%] [G loss: 0.920442]\n",
      "epoch:4 step:3912 [D loss: 0.630809, acc.: 66.41%] [G loss: 0.974064]\n",
      "epoch:4 step:3913 [D loss: 0.597901, acc.: 67.97%] [G loss: 0.932144]\n",
      "epoch:4 step:3914 [D loss: 0.578472, acc.: 71.09%] [G loss: 0.897052]\n",
      "epoch:4 step:3915 [D loss: 0.609755, acc.: 67.19%] [G loss: 0.872662]\n",
      "epoch:4 step:3916 [D loss: 0.660424, acc.: 63.28%] [G loss: 0.886212]\n",
      "epoch:4 step:3917 [D loss: 0.675812, acc.: 63.28%] [G loss: 0.902201]\n",
      "epoch:4 step:3918 [D loss: 0.647663, acc.: 68.75%] [G loss: 0.897840]\n",
      "epoch:4 step:3919 [D loss: 0.613057, acc.: 62.50%] [G loss: 0.986476]\n",
      "epoch:4 step:3920 [D loss: 0.637952, acc.: 65.62%] [G loss: 0.937988]\n",
      "epoch:4 step:3921 [D loss: 0.592071, acc.: 72.66%] [G loss: 0.839793]\n",
      "epoch:4 step:3922 [D loss: 0.643267, acc.: 66.41%] [G loss: 0.857379]\n",
      "epoch:4 step:3923 [D loss: 0.621112, acc.: 64.84%] [G loss: 0.888269]\n",
      "epoch:4 step:3924 [D loss: 0.622263, acc.: 71.09%] [G loss: 0.879527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3925 [D loss: 0.613556, acc.: 69.53%] [G loss: 0.887923]\n",
      "epoch:4 step:3926 [D loss: 0.646032, acc.: 61.72%] [G loss: 0.869600]\n",
      "epoch:4 step:3927 [D loss: 0.651473, acc.: 58.59%] [G loss: 0.900037]\n",
      "epoch:4 step:3928 [D loss: 0.673289, acc.: 54.69%] [G loss: 0.891116]\n",
      "epoch:4 step:3929 [D loss: 0.658095, acc.: 60.94%] [G loss: 0.820899]\n",
      "epoch:4 step:3930 [D loss: 0.683258, acc.: 60.94%] [G loss: 0.884899]\n",
      "epoch:4 step:3931 [D loss: 0.695073, acc.: 57.81%] [G loss: 0.948799]\n",
      "epoch:4 step:3932 [D loss: 0.613276, acc.: 72.66%] [G loss: 0.975038]\n",
      "epoch:4 step:3933 [D loss: 0.617922, acc.: 67.19%] [G loss: 0.866615]\n",
      "epoch:4 step:3934 [D loss: 0.647342, acc.: 69.53%] [G loss: 0.927571]\n",
      "epoch:4 step:3935 [D loss: 0.643130, acc.: 61.72%] [G loss: 0.873105]\n",
      "epoch:4 step:3936 [D loss: 0.706849, acc.: 53.12%] [G loss: 0.873961]\n",
      "epoch:4 step:3937 [D loss: 0.635336, acc.: 64.84%] [G loss: 0.823798]\n",
      "epoch:4 step:3938 [D loss: 0.629312, acc.: 66.41%] [G loss: 0.899719]\n",
      "epoch:4 step:3939 [D loss: 0.596659, acc.: 68.75%] [G loss: 0.927251]\n",
      "epoch:4 step:3940 [D loss: 0.633867, acc.: 67.19%] [G loss: 0.940250]\n",
      "epoch:4 step:3941 [D loss: 0.648060, acc.: 63.28%] [G loss: 0.947154]\n",
      "epoch:4 step:3942 [D loss: 0.610922, acc.: 67.19%] [G loss: 0.962215]\n",
      "epoch:4 step:3943 [D loss: 0.640027, acc.: 63.28%] [G loss: 0.953966]\n",
      "epoch:4 step:3944 [D loss: 0.661448, acc.: 61.72%] [G loss: 0.952585]\n",
      "epoch:4 step:3945 [D loss: 0.639059, acc.: 60.94%] [G loss: 0.932618]\n",
      "epoch:4 step:3946 [D loss: 0.600527, acc.: 64.06%] [G loss: 0.978377]\n",
      "epoch:4 step:3947 [D loss: 0.660478, acc.: 67.19%] [G loss: 0.988664]\n",
      "epoch:4 step:3948 [D loss: 0.645746, acc.: 61.72%] [G loss: 0.938566]\n",
      "epoch:4 step:3949 [D loss: 0.635844, acc.: 67.19%] [G loss: 0.877781]\n",
      "epoch:4 step:3950 [D loss: 0.653846, acc.: 55.47%] [G loss: 0.876491]\n",
      "epoch:4 step:3951 [D loss: 0.717693, acc.: 56.25%] [G loss: 0.868292]\n",
      "epoch:4 step:3952 [D loss: 0.683830, acc.: 53.91%] [G loss: 0.895020]\n",
      "epoch:4 step:3953 [D loss: 0.626595, acc.: 67.97%] [G loss: 0.907158]\n",
      "epoch:4 step:3954 [D loss: 0.622516, acc.: 67.19%] [G loss: 0.949987]\n",
      "epoch:4 step:3955 [D loss: 0.589837, acc.: 68.75%] [G loss: 0.961580]\n",
      "epoch:4 step:3956 [D loss: 0.567034, acc.: 73.44%] [G loss: 0.992630]\n",
      "epoch:4 step:3957 [D loss: 0.632416, acc.: 59.38%] [G loss: 0.996187]\n",
      "epoch:4 step:3958 [D loss: 0.651055, acc.: 64.06%] [G loss: 0.891911]\n",
      "epoch:4 step:3959 [D loss: 0.667796, acc.: 59.38%] [G loss: 0.901061]\n",
      "epoch:4 step:3960 [D loss: 0.672800, acc.: 61.72%] [G loss: 0.903456]\n",
      "epoch:4 step:3961 [D loss: 0.641140, acc.: 63.28%] [G loss: 0.877979]\n",
      "epoch:4 step:3962 [D loss: 0.723501, acc.: 44.53%] [G loss: 0.883270]\n",
      "epoch:4 step:3963 [D loss: 0.683428, acc.: 52.34%] [G loss: 0.885132]\n",
      "epoch:4 step:3964 [D loss: 0.639730, acc.: 64.84%] [G loss: 0.940007]\n",
      "epoch:4 step:3965 [D loss: 0.649659, acc.: 59.38%] [G loss: 0.939632]\n",
      "epoch:4 step:3966 [D loss: 0.621648, acc.: 64.84%] [G loss: 0.928872]\n",
      "epoch:4 step:3967 [D loss: 0.582009, acc.: 73.44%] [G loss: 0.903312]\n",
      "epoch:4 step:3968 [D loss: 0.703718, acc.: 53.91%] [G loss: 0.883757]\n",
      "epoch:4 step:3969 [D loss: 0.578727, acc.: 69.53%] [G loss: 0.944387]\n",
      "epoch:4 step:3970 [D loss: 0.564443, acc.: 75.78%] [G loss: 0.958619]\n",
      "epoch:4 step:3971 [D loss: 0.554240, acc.: 73.44%] [G loss: 1.016122]\n",
      "epoch:4 step:3972 [D loss: 0.759330, acc.: 54.69%] [G loss: 0.894560]\n",
      "epoch:4 step:3973 [D loss: 0.660036, acc.: 59.38%] [G loss: 0.906083]\n",
      "epoch:4 step:3974 [D loss: 0.627156, acc.: 64.06%] [G loss: 0.821578]\n",
      "epoch:4 step:3975 [D loss: 0.685719, acc.: 57.81%] [G loss: 0.825786]\n",
      "epoch:4 step:3976 [D loss: 0.699964, acc.: 51.56%] [G loss: 0.889640]\n",
      "epoch:4 step:3977 [D loss: 0.604585, acc.: 70.31%] [G loss: 0.882606]\n",
      "epoch:4 step:3978 [D loss: 0.607380, acc.: 70.31%] [G loss: 0.935286]\n",
      "epoch:4 step:3979 [D loss: 0.544577, acc.: 72.66%] [G loss: 0.974866]\n",
      "epoch:4 step:3980 [D loss: 0.577786, acc.: 70.31%] [G loss: 0.956510]\n",
      "epoch:4 step:3981 [D loss: 0.679009, acc.: 60.94%] [G loss: 0.881577]\n",
      "epoch:4 step:3982 [D loss: 0.657207, acc.: 60.16%] [G loss: 0.893836]\n",
      "epoch:4 step:3983 [D loss: 0.624562, acc.: 64.84%] [G loss: 0.914555]\n",
      "epoch:4 step:3984 [D loss: 0.651476, acc.: 57.03%] [G loss: 0.910412]\n",
      "epoch:4 step:3985 [D loss: 0.648406, acc.: 59.38%] [G loss: 0.965755]\n",
      "epoch:4 step:3986 [D loss: 0.662443, acc.: 58.59%] [G loss: 0.938820]\n",
      "epoch:4 step:3987 [D loss: 0.639279, acc.: 66.41%] [G loss: 0.935742]\n",
      "epoch:4 step:3988 [D loss: 0.614231, acc.: 69.53%] [G loss: 0.914111]\n",
      "epoch:4 step:3989 [D loss: 0.631780, acc.: 69.53%] [G loss: 0.900539]\n",
      "epoch:4 step:3990 [D loss: 0.629868, acc.: 64.84%] [G loss: 0.911731]\n",
      "epoch:4 step:3991 [D loss: 0.582047, acc.: 73.44%] [G loss: 0.931710]\n",
      "epoch:4 step:3992 [D loss: 0.651951, acc.: 60.94%] [G loss: 0.924859]\n",
      "epoch:4 step:3993 [D loss: 0.598129, acc.: 69.53%] [G loss: 0.960953]\n",
      "epoch:4 step:3994 [D loss: 0.679822, acc.: 60.16%] [G loss: 0.879772]\n",
      "epoch:4 step:3995 [D loss: 0.644723, acc.: 65.62%] [G loss: 0.948920]\n",
      "epoch:4 step:3996 [D loss: 0.630501, acc.: 66.41%] [G loss: 0.907829]\n",
      "epoch:4 step:3997 [D loss: 0.615137, acc.: 62.50%] [G loss: 0.891396]\n",
      "epoch:4 step:3998 [D loss: 0.706343, acc.: 53.91%] [G loss: 0.888336]\n",
      "epoch:4 step:3999 [D loss: 0.672954, acc.: 56.25%] [G loss: 0.828842]\n",
      "epoch:4 step:4000 [D loss: 0.648653, acc.: 64.06%] [G loss: 0.828089]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.648180\n",
      "FID: 31.863771\n",
      "0 = 12.448136816644672\n",
      "1 = 0.07928220115154216\n",
      "2 = 0.9667999744415283\n",
      "3 = 0.934499979019165\n",
      "4 = 0.9991000294685364\n",
      "5 = 0.9990378618240356\n",
      "6 = 0.934499979019165\n",
      "7 = 8.286297428864264\n",
      "8 = 0.12148590577562494\n",
      "9 = 0.8414999842643738\n",
      "10 = 0.8084999918937683\n",
      "11 = 0.8744999766349792\n",
      "12 = 0.8656316995620728\n",
      "13 = 0.8084999918937683\n",
      "14 = 6.648237228393555\n",
      "15 = 9.52590560913086\n",
      "16 = 0.14188052713871002\n",
      "17 = 6.6481804847717285\n",
      "18 = 31.863771438598633\n",
      "epoch:4 step:4001 [D loss: 0.624572, acc.: 65.62%] [G loss: 0.927040]\n",
      "epoch:4 step:4002 [D loss: 0.594771, acc.: 75.00%] [G loss: 0.907431]\n",
      "epoch:4 step:4003 [D loss: 0.614865, acc.: 71.09%] [G loss: 0.931470]\n",
      "epoch:4 step:4004 [D loss: 0.652811, acc.: 67.19%] [G loss: 0.901197]\n",
      "epoch:4 step:4005 [D loss: 0.587008, acc.: 72.66%] [G loss: 0.891612]\n",
      "epoch:4 step:4006 [D loss: 0.605688, acc.: 67.19%] [G loss: 0.889146]\n",
      "epoch:4 step:4007 [D loss: 0.582049, acc.: 72.66%] [G loss: 0.942438]\n",
      "epoch:4 step:4008 [D loss: 0.649220, acc.: 60.94%] [G loss: 0.924952]\n",
      "epoch:4 step:4009 [D loss: 0.682557, acc.: 60.16%] [G loss: 0.927103]\n",
      "epoch:4 step:4010 [D loss: 0.645326, acc.: 64.06%] [G loss: 0.925929]\n",
      "epoch:4 step:4011 [D loss: 0.756579, acc.: 50.78%] [G loss: 0.911546]\n",
      "epoch:4 step:4012 [D loss: 0.643154, acc.: 62.50%] [G loss: 0.929994]\n",
      "epoch:4 step:4013 [D loss: 0.733380, acc.: 49.22%] [G loss: 0.877539]\n",
      "epoch:4 step:4014 [D loss: 0.651506, acc.: 61.72%] [G loss: 0.887797]\n",
      "epoch:4 step:4015 [D loss: 0.634587, acc.: 61.72%] [G loss: 0.934556]\n",
      "epoch:4 step:4016 [D loss: 0.651983, acc.: 62.50%] [G loss: 0.920513]\n",
      "epoch:4 step:4017 [D loss: 0.652746, acc.: 64.84%] [G loss: 0.900695]\n",
      "epoch:4 step:4018 [D loss: 0.653620, acc.: 62.50%] [G loss: 0.912494]\n",
      "epoch:4 step:4019 [D loss: 0.611255, acc.: 67.97%] [G loss: 0.958115]\n",
      "epoch:4 step:4020 [D loss: 0.676316, acc.: 54.69%] [G loss: 0.962465]\n",
      "epoch:4 step:4021 [D loss: 0.638778, acc.: 67.19%] [G loss: 0.943257]\n",
      "epoch:4 step:4022 [D loss: 0.608737, acc.: 68.75%] [G loss: 0.897175]\n",
      "epoch:4 step:4023 [D loss: 0.675681, acc.: 60.94%] [G loss: 0.919681]\n",
      "epoch:4 step:4024 [D loss: 0.702781, acc.: 57.03%] [G loss: 0.951376]\n",
      "epoch:4 step:4025 [D loss: 0.664299, acc.: 61.72%] [G loss: 0.931500]\n",
      "epoch:4 step:4026 [D loss: 0.660337, acc.: 59.38%] [G loss: 0.902722]\n",
      "epoch:4 step:4027 [D loss: 0.637421, acc.: 64.84%] [G loss: 0.918181]\n",
      "epoch:4 step:4028 [D loss: 0.583185, acc.: 72.66%] [G loss: 0.931685]\n",
      "epoch:4 step:4029 [D loss: 0.687647, acc.: 60.94%] [G loss: 0.921080]\n",
      "epoch:4 step:4030 [D loss: 0.653236, acc.: 64.84%] [G loss: 0.926608]\n",
      "epoch:4 step:4031 [D loss: 0.605517, acc.: 73.44%] [G loss: 0.898943]\n",
      "epoch:4 step:4032 [D loss: 0.565255, acc.: 73.44%] [G loss: 0.884398]\n",
      "epoch:4 step:4033 [D loss: 0.618768, acc.: 67.19%] [G loss: 0.953315]\n",
      "epoch:4 step:4034 [D loss: 0.576165, acc.: 75.00%] [G loss: 0.896819]\n",
      "epoch:4 step:4035 [D loss: 0.617345, acc.: 64.06%] [G loss: 0.929923]\n",
      "epoch:4 step:4036 [D loss: 0.655084, acc.: 60.94%] [G loss: 0.895190]\n",
      "epoch:4 step:4037 [D loss: 0.603599, acc.: 67.97%] [G loss: 0.913729]\n",
      "epoch:4 step:4038 [D loss: 0.652977, acc.: 60.16%] [G loss: 0.930614]\n",
      "epoch:4 step:4039 [D loss: 0.669989, acc.: 61.72%] [G loss: 0.840731]\n",
      "epoch:4 step:4040 [D loss: 0.624698, acc.: 65.62%] [G loss: 0.866654]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4041 [D loss: 0.659109, acc.: 65.62%] [G loss: 0.901668]\n",
      "epoch:4 step:4042 [D loss: 0.644558, acc.: 63.28%] [G loss: 0.945167]\n",
      "epoch:4 step:4043 [D loss: 0.632124, acc.: 62.50%] [G loss: 0.935949]\n",
      "epoch:4 step:4044 [D loss: 0.598845, acc.: 71.09%] [G loss: 0.925374]\n",
      "epoch:4 step:4045 [D loss: 0.689743, acc.: 57.81%] [G loss: 0.905580]\n",
      "epoch:4 step:4046 [D loss: 0.617334, acc.: 67.97%] [G loss: 0.958632]\n",
      "epoch:4 step:4047 [D loss: 0.621385, acc.: 66.41%] [G loss: 0.925662]\n",
      "epoch:4 step:4048 [D loss: 0.614434, acc.: 68.75%] [G loss: 0.929441]\n",
      "epoch:4 step:4049 [D loss: 0.696785, acc.: 60.16%] [G loss: 0.905167]\n",
      "epoch:4 step:4050 [D loss: 0.616830, acc.: 67.19%] [G loss: 0.896446]\n",
      "epoch:4 step:4051 [D loss: 0.633144, acc.: 66.41%] [G loss: 0.869751]\n",
      "epoch:4 step:4052 [D loss: 0.642352, acc.: 67.19%] [G loss: 0.839643]\n",
      "epoch:4 step:4053 [D loss: 0.606011, acc.: 68.75%] [G loss: 0.926519]\n",
      "epoch:4 step:4054 [D loss: 0.640557, acc.: 64.06%] [G loss: 0.918620]\n",
      "epoch:4 step:4055 [D loss: 0.640916, acc.: 63.28%] [G loss: 0.913870]\n",
      "epoch:4 step:4056 [D loss: 0.644359, acc.: 63.28%] [G loss: 0.947566]\n",
      "epoch:4 step:4057 [D loss: 0.603525, acc.: 69.53%] [G loss: 0.950302]\n",
      "epoch:4 step:4058 [D loss: 0.600167, acc.: 71.09%] [G loss: 0.915700]\n",
      "epoch:4 step:4059 [D loss: 0.583140, acc.: 71.09%] [G loss: 0.873879]\n",
      "epoch:4 step:4060 [D loss: 0.614002, acc.: 60.94%] [G loss: 0.939147]\n",
      "epoch:4 step:4061 [D loss: 0.575788, acc.: 71.09%] [G loss: 1.001019]\n",
      "epoch:4 step:4062 [D loss: 0.563370, acc.: 72.66%] [G loss: 1.054981]\n",
      "epoch:4 step:4063 [D loss: 0.589608, acc.: 68.75%] [G loss: 0.934403]\n",
      "epoch:4 step:4064 [D loss: 0.798754, acc.: 49.22%] [G loss: 0.887561]\n",
      "epoch:4 step:4065 [D loss: 0.636953, acc.: 67.97%] [G loss: 0.912579]\n",
      "epoch:4 step:4066 [D loss: 0.615734, acc.: 70.31%] [G loss: 0.937791]\n",
      "epoch:4 step:4067 [D loss: 0.604097, acc.: 67.19%] [G loss: 0.951557]\n",
      "epoch:4 step:4068 [D loss: 0.603827, acc.: 67.19%] [G loss: 0.866589]\n",
      "epoch:4 step:4069 [D loss: 0.588426, acc.: 67.97%] [G loss: 0.965359]\n",
      "epoch:4 step:4070 [D loss: 0.616888, acc.: 65.62%] [G loss: 0.956055]\n",
      "epoch:4 step:4071 [D loss: 0.654374, acc.: 61.72%] [G loss: 0.921551]\n",
      "epoch:4 step:4072 [D loss: 0.660399, acc.: 61.72%] [G loss: 0.890022]\n",
      "epoch:4 step:4073 [D loss: 0.649697, acc.: 64.06%] [G loss: 0.868803]\n",
      "epoch:4 step:4074 [D loss: 0.624942, acc.: 67.97%] [G loss: 0.874427]\n",
      "epoch:4 step:4075 [D loss: 0.615863, acc.: 65.62%] [G loss: 0.922962]\n",
      "epoch:4 step:4076 [D loss: 0.624794, acc.: 62.50%] [G loss: 0.935612]\n",
      "epoch:4 step:4077 [D loss: 0.628174, acc.: 62.50%] [G loss: 0.917947]\n",
      "epoch:4 step:4078 [D loss: 0.719633, acc.: 51.56%] [G loss: 0.872603]\n",
      "epoch:4 step:4079 [D loss: 0.594385, acc.: 71.88%] [G loss: 0.915157]\n",
      "epoch:4 step:4080 [D loss: 0.649650, acc.: 63.28%] [G loss: 0.911421]\n",
      "epoch:4 step:4081 [D loss: 0.639324, acc.: 61.72%] [G loss: 0.824735]\n",
      "epoch:4 step:4082 [D loss: 0.688337, acc.: 60.94%] [G loss: 0.900309]\n",
      "epoch:4 step:4083 [D loss: 0.572477, acc.: 74.22%] [G loss: 0.931821]\n",
      "epoch:4 step:4084 [D loss: 0.640491, acc.: 60.94%] [G loss: 0.888627]\n",
      "epoch:4 step:4085 [D loss: 0.616919, acc.: 67.19%] [G loss: 0.953904]\n",
      "epoch:4 step:4086 [D loss: 0.675065, acc.: 61.72%] [G loss: 0.996617]\n",
      "epoch:4 step:4087 [D loss: 0.634846, acc.: 68.75%] [G loss: 0.923374]\n",
      "epoch:4 step:4088 [D loss: 0.621552, acc.: 64.84%] [G loss: 0.958002]\n",
      "epoch:4 step:4089 [D loss: 0.697201, acc.: 56.25%] [G loss: 0.919384]\n",
      "epoch:4 step:4090 [D loss: 0.715526, acc.: 49.22%] [G loss: 0.956217]\n",
      "epoch:4 step:4091 [D loss: 0.597001, acc.: 71.88%] [G loss: 0.969417]\n",
      "epoch:4 step:4092 [D loss: 0.607797, acc.: 67.97%] [G loss: 0.949234]\n",
      "epoch:4 step:4093 [D loss: 0.606739, acc.: 67.97%] [G loss: 0.958502]\n",
      "epoch:4 step:4094 [D loss: 0.590645, acc.: 66.41%] [G loss: 0.964248]\n",
      "epoch:4 step:4095 [D loss: 0.540760, acc.: 75.00%] [G loss: 1.083545]\n",
      "epoch:4 step:4096 [D loss: 0.737611, acc.: 57.03%] [G loss: 0.975908]\n",
      "epoch:4 step:4097 [D loss: 0.772073, acc.: 41.41%] [G loss: 0.950634]\n",
      "epoch:4 step:4098 [D loss: 0.612238, acc.: 70.31%] [G loss: 0.889697]\n",
      "epoch:4 step:4099 [D loss: 0.686900, acc.: 60.16%] [G loss: 0.922567]\n",
      "epoch:4 step:4100 [D loss: 0.662691, acc.: 60.94%] [G loss: 0.994427]\n",
      "epoch:4 step:4101 [D loss: 0.620308, acc.: 64.06%] [G loss: 0.957251]\n",
      "epoch:4 step:4102 [D loss: 0.608121, acc.: 68.75%] [G loss: 1.009591]\n",
      "epoch:4 step:4103 [D loss: 0.658432, acc.: 64.06%] [G loss: 0.887893]\n",
      "epoch:4 step:4104 [D loss: 0.660724, acc.: 62.50%] [G loss: 0.920800]\n",
      "epoch:4 step:4105 [D loss: 0.655947, acc.: 60.94%] [G loss: 0.878942]\n",
      "epoch:4 step:4106 [D loss: 0.591600, acc.: 69.53%] [G loss: 0.890065]\n",
      "epoch:4 step:4107 [D loss: 0.588000, acc.: 70.31%] [G loss: 0.930986]\n",
      "epoch:4 step:4108 [D loss: 0.568319, acc.: 71.09%] [G loss: 0.939913]\n",
      "epoch:4 step:4109 [D loss: 0.602381, acc.: 67.19%] [G loss: 0.961612]\n",
      "epoch:4 step:4110 [D loss: 0.650997, acc.: 57.81%] [G loss: 0.835778]\n",
      "epoch:4 step:4111 [D loss: 0.646912, acc.: 55.47%] [G loss: 0.913417]\n",
      "epoch:4 step:4112 [D loss: 0.614408, acc.: 66.41%] [G loss: 0.915419]\n",
      "epoch:4 step:4113 [D loss: 0.629773, acc.: 61.72%] [G loss: 0.928794]\n",
      "epoch:4 step:4114 [D loss: 0.626096, acc.: 64.06%] [G loss: 0.934206]\n",
      "epoch:4 step:4115 [D loss: 0.643035, acc.: 59.38%] [G loss: 0.997053]\n",
      "epoch:4 step:4116 [D loss: 0.658626, acc.: 59.38%] [G loss: 0.956819]\n",
      "epoch:4 step:4117 [D loss: 0.659569, acc.: 61.72%] [G loss: 0.891709]\n",
      "epoch:4 step:4118 [D loss: 0.640087, acc.: 64.06%] [G loss: 0.893289]\n",
      "epoch:4 step:4119 [D loss: 0.557285, acc.: 80.47%] [G loss: 0.888183]\n",
      "epoch:4 step:4120 [D loss: 0.635188, acc.: 65.62%] [G loss: 0.990559]\n",
      "epoch:4 step:4121 [D loss: 0.666355, acc.: 59.38%] [G loss: 0.875879]\n",
      "epoch:4 step:4122 [D loss: 0.609839, acc.: 67.19%] [G loss: 0.949582]\n",
      "epoch:4 step:4123 [D loss: 0.671791, acc.: 57.03%] [G loss: 0.926228]\n",
      "epoch:4 step:4124 [D loss: 0.700358, acc.: 53.91%] [G loss: 0.818943]\n",
      "epoch:4 step:4125 [D loss: 0.715165, acc.: 54.69%] [G loss: 0.842040]\n",
      "epoch:4 step:4126 [D loss: 0.601208, acc.: 74.22%] [G loss: 0.864689]\n",
      "epoch:4 step:4127 [D loss: 0.677612, acc.: 57.03%] [G loss: 0.878717]\n",
      "epoch:4 step:4128 [D loss: 0.684956, acc.: 53.12%] [G loss: 0.912756]\n",
      "epoch:4 step:4129 [D loss: 0.563564, acc.: 72.66%] [G loss: 0.934700]\n",
      "epoch:4 step:4130 [D loss: 0.651604, acc.: 64.84%] [G loss: 0.975584]\n",
      "epoch:4 step:4131 [D loss: 0.667480, acc.: 62.50%] [G loss: 0.885970]\n",
      "epoch:4 step:4132 [D loss: 0.615334, acc.: 69.53%] [G loss: 0.864215]\n",
      "epoch:4 step:4133 [D loss: 0.630431, acc.: 67.97%] [G loss: 0.825807]\n",
      "epoch:4 step:4134 [D loss: 0.669286, acc.: 56.25%] [G loss: 0.884877]\n",
      "epoch:4 step:4135 [D loss: 0.667590, acc.: 61.72%] [G loss: 0.861359]\n",
      "epoch:4 step:4136 [D loss: 0.608163, acc.: 72.66%] [G loss: 0.924661]\n",
      "epoch:4 step:4137 [D loss: 0.611404, acc.: 67.97%] [G loss: 0.981829]\n",
      "epoch:4 step:4138 [D loss: 0.703223, acc.: 55.47%] [G loss: 0.907871]\n",
      "epoch:4 step:4139 [D loss: 0.604223, acc.: 66.41%] [G loss: 0.899274]\n",
      "epoch:4 step:4140 [D loss: 0.610389, acc.: 68.75%] [G loss: 0.942734]\n",
      "epoch:4 step:4141 [D loss: 0.640179, acc.: 67.19%] [G loss: 0.897685]\n",
      "epoch:4 step:4142 [D loss: 0.626826, acc.: 64.84%] [G loss: 0.938020]\n",
      "epoch:4 step:4143 [D loss: 0.622314, acc.: 65.62%] [G loss: 0.925910]\n",
      "epoch:4 step:4144 [D loss: 0.651625, acc.: 60.94%] [G loss: 0.945637]\n",
      "epoch:4 step:4145 [D loss: 0.589490, acc.: 71.88%] [G loss: 0.909633]\n",
      "epoch:4 step:4146 [D loss: 0.592079, acc.: 69.53%] [G loss: 0.979570]\n",
      "epoch:4 step:4147 [D loss: 0.585891, acc.: 68.75%] [G loss: 0.983612]\n",
      "epoch:4 step:4148 [D loss: 0.762901, acc.: 46.88%] [G loss: 0.897868]\n",
      "epoch:4 step:4149 [D loss: 0.635389, acc.: 62.50%] [G loss: 0.896864]\n",
      "epoch:4 step:4150 [D loss: 0.603400, acc.: 70.31%] [G loss: 0.892813]\n",
      "epoch:4 step:4151 [D loss: 0.673980, acc.: 58.59%] [G loss: 0.887947]\n",
      "epoch:4 step:4152 [D loss: 0.689774, acc.: 55.47%] [G loss: 0.952587]\n",
      "epoch:4 step:4153 [D loss: 0.637928, acc.: 66.41%] [G loss: 0.967745]\n",
      "epoch:4 step:4154 [D loss: 0.657658, acc.: 63.28%] [G loss: 0.983108]\n",
      "epoch:4 step:4155 [D loss: 0.665963, acc.: 61.72%] [G loss: 1.003227]\n",
      "epoch:4 step:4156 [D loss: 0.689953, acc.: 53.91%] [G loss: 0.922720]\n",
      "epoch:4 step:4157 [D loss: 0.633576, acc.: 60.94%] [G loss: 0.888838]\n",
      "epoch:4 step:4158 [D loss: 0.663068, acc.: 64.84%] [G loss: 0.912265]\n",
      "epoch:4 step:4159 [D loss: 0.689851, acc.: 53.12%] [G loss: 0.940847]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4160 [D loss: 0.692989, acc.: 54.69%] [G loss: 0.926898]\n",
      "epoch:4 step:4161 [D loss: 0.654788, acc.: 65.62%] [G loss: 0.901199]\n",
      "epoch:4 step:4162 [D loss: 0.670709, acc.: 59.38%] [G loss: 0.902351]\n",
      "epoch:4 step:4163 [D loss: 0.649298, acc.: 63.28%] [G loss: 0.921634]\n",
      "epoch:4 step:4164 [D loss: 0.618742, acc.: 69.53%] [G loss: 0.952865]\n",
      "epoch:4 step:4165 [D loss: 0.655326, acc.: 64.84%] [G loss: 0.954268]\n",
      "epoch:4 step:4166 [D loss: 0.725372, acc.: 50.78%] [G loss: 0.892240]\n",
      "epoch:4 step:4167 [D loss: 0.685536, acc.: 55.47%] [G loss: 0.882244]\n",
      "epoch:4 step:4168 [D loss: 0.649297, acc.: 59.38%] [G loss: 0.915760]\n",
      "epoch:4 step:4169 [D loss: 0.677156, acc.: 59.38%] [G loss: 0.870308]\n",
      "epoch:4 step:4170 [D loss: 0.638857, acc.: 60.16%] [G loss: 0.946456]\n",
      "epoch:4 step:4171 [D loss: 0.650998, acc.: 67.19%] [G loss: 0.935192]\n",
      "epoch:4 step:4172 [D loss: 0.639585, acc.: 60.94%] [G loss: 0.876677]\n",
      "epoch:4 step:4173 [D loss: 0.646513, acc.: 61.72%] [G loss: 0.913465]\n",
      "epoch:4 step:4174 [D loss: 0.610810, acc.: 72.66%] [G loss: 0.942919]\n",
      "epoch:4 step:4175 [D loss: 0.597145, acc.: 70.31%] [G loss: 1.001228]\n",
      "epoch:4 step:4176 [D loss: 0.583506, acc.: 71.09%] [G loss: 0.985415]\n",
      "epoch:4 step:4177 [D loss: 0.595478, acc.: 72.66%] [G loss: 0.999509]\n",
      "epoch:4 step:4178 [D loss: 0.608184, acc.: 66.41%] [G loss: 0.968113]\n",
      "epoch:4 step:4179 [D loss: 0.678099, acc.: 58.59%] [G loss: 0.954738]\n",
      "epoch:4 step:4180 [D loss: 0.671061, acc.: 54.69%] [G loss: 0.899952]\n",
      "epoch:4 step:4181 [D loss: 0.671785, acc.: 60.16%] [G loss: 0.968769]\n",
      "epoch:4 step:4182 [D loss: 0.623439, acc.: 66.41%] [G loss: 0.918525]\n",
      "epoch:4 step:4183 [D loss: 0.628329, acc.: 62.50%] [G loss: 0.937695]\n",
      "epoch:4 step:4184 [D loss: 0.600749, acc.: 67.97%] [G loss: 0.939268]\n",
      "epoch:4 step:4185 [D loss: 0.757844, acc.: 52.34%] [G loss: 0.851892]\n",
      "epoch:4 step:4186 [D loss: 0.667644, acc.: 65.62%] [G loss: 0.792089]\n",
      "epoch:4 step:4187 [D loss: 0.669370, acc.: 59.38%] [G loss: 0.846888]\n",
      "epoch:4 step:4188 [D loss: 0.616384, acc.: 68.75%] [G loss: 0.893210]\n",
      "epoch:4 step:4189 [D loss: 0.668311, acc.: 60.16%] [G loss: 0.892786]\n",
      "epoch:4 step:4190 [D loss: 0.674058, acc.: 58.59%] [G loss: 0.899281]\n",
      "epoch:4 step:4191 [D loss: 0.626953, acc.: 66.41%] [G loss: 0.878115]\n",
      "epoch:4 step:4192 [D loss: 0.642565, acc.: 67.19%] [G loss: 0.908559]\n",
      "epoch:4 step:4193 [D loss: 0.623759, acc.: 67.19%] [G loss: 0.906482]\n",
      "epoch:4 step:4194 [D loss: 0.654837, acc.: 60.94%] [G loss: 0.908490]\n",
      "epoch:4 step:4195 [D loss: 0.590662, acc.: 70.31%] [G loss: 0.941638]\n",
      "epoch:4 step:4196 [D loss: 0.674352, acc.: 56.25%] [G loss: 0.879930]\n",
      "epoch:4 step:4197 [D loss: 0.666635, acc.: 64.06%] [G loss: 0.894647]\n",
      "epoch:4 step:4198 [D loss: 0.605351, acc.: 64.84%] [G loss: 0.881611]\n",
      "epoch:4 step:4199 [D loss: 0.610052, acc.: 70.31%] [G loss: 0.908784]\n",
      "epoch:4 step:4200 [D loss: 0.587940, acc.: 70.31%] [G loss: 0.964598]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.969482\n",
      "FID: 23.818157\n",
      "0 = 12.230877205252586\n",
      "1 = 0.07360505812927774\n",
      "2 = 0.9602000117301941\n",
      "3 = 0.9211999773979187\n",
      "4 = 0.9991999864578247\n",
      "5 = 0.9991323351860046\n",
      "6 = 0.9211999773979187\n",
      "7 = 7.618585152769106\n",
      "8 = 0.10200930395889017\n",
      "9 = 0.8160499930381775\n",
      "10 = 0.7796000242233276\n",
      "11 = 0.8525000214576721\n",
      "12 = 0.8409017324447632\n",
      "13 = 0.7796000242233276\n",
      "14 = 6.969543933868408\n",
      "15 = 9.559978485107422\n",
      "16 = 0.13114327192306519\n",
      "17 = 6.969482421875\n",
      "18 = 23.818157196044922\n",
      "epoch:4 step:4201 [D loss: 0.627740, acc.: 63.28%] [G loss: 0.903257]\n",
      "epoch:4 step:4202 [D loss: 0.632946, acc.: 66.41%] [G loss: 0.924123]\n",
      "epoch:4 step:4203 [D loss: 0.630102, acc.: 63.28%] [G loss: 0.875326]\n",
      "epoch:4 step:4204 [D loss: 0.651204, acc.: 64.06%] [G loss: 0.922600]\n",
      "epoch:4 step:4205 [D loss: 0.617115, acc.: 71.09%] [G loss: 0.925323]\n",
      "epoch:4 step:4206 [D loss: 0.691701, acc.: 55.47%] [G loss: 0.874351]\n",
      "epoch:4 step:4207 [D loss: 0.647946, acc.: 62.50%] [G loss: 0.866525]\n",
      "epoch:4 step:4208 [D loss: 0.622045, acc.: 64.06%] [G loss: 0.824511]\n",
      "epoch:4 step:4209 [D loss: 0.656849, acc.: 60.94%] [G loss: 0.851275]\n",
      "epoch:4 step:4210 [D loss: 0.594831, acc.: 71.09%] [G loss: 0.867644]\n",
      "epoch:4 step:4211 [D loss: 0.670562, acc.: 60.16%] [G loss: 0.819466]\n",
      "epoch:4 step:4212 [D loss: 0.639419, acc.: 60.94%] [G loss: 0.914945]\n",
      "epoch:4 step:4213 [D loss: 0.681974, acc.: 56.25%] [G loss: 0.846875]\n",
      "epoch:4 step:4214 [D loss: 0.635427, acc.: 60.94%] [G loss: 0.913702]\n",
      "epoch:4 step:4215 [D loss: 0.662228, acc.: 57.81%] [G loss: 0.901340]\n",
      "epoch:4 step:4216 [D loss: 0.677073, acc.: 53.91%] [G loss: 0.937179]\n",
      "epoch:4 step:4217 [D loss: 0.593677, acc.: 64.06%] [G loss: 0.941567]\n",
      "epoch:4 step:4218 [D loss: 0.674805, acc.: 55.47%] [G loss: 0.920109]\n",
      "epoch:4 step:4219 [D loss: 0.564959, acc.: 71.09%] [G loss: 0.974903]\n",
      "epoch:4 step:4220 [D loss: 0.567795, acc.: 68.75%] [G loss: 0.981490]\n",
      "epoch:4 step:4221 [D loss: 0.707872, acc.: 54.69%] [G loss: 0.970610]\n",
      "epoch:4 step:4222 [D loss: 0.650608, acc.: 63.28%] [G loss: 0.922284]\n",
      "epoch:4 step:4223 [D loss: 0.608192, acc.: 67.97%] [G loss: 1.014471]\n",
      "epoch:4 step:4224 [D loss: 0.667692, acc.: 63.28%] [G loss: 1.015517]\n",
      "epoch:4 step:4225 [D loss: 0.787762, acc.: 45.31%] [G loss: 0.857180]\n",
      "epoch:4 step:4226 [D loss: 0.692808, acc.: 60.16%] [G loss: 0.891305]\n",
      "epoch:4 step:4227 [D loss: 0.669200, acc.: 60.16%] [G loss: 0.864488]\n",
      "epoch:4 step:4228 [D loss: 0.631965, acc.: 67.97%] [G loss: 0.873173]\n",
      "epoch:4 step:4229 [D loss: 0.629199, acc.: 69.53%] [G loss: 0.882305]\n",
      "epoch:4 step:4230 [D loss: 0.667930, acc.: 55.47%] [G loss: 0.870018]\n",
      "epoch:4 step:4231 [D loss: 0.716605, acc.: 55.47%] [G loss: 0.896591]\n",
      "epoch:4 step:4232 [D loss: 0.630633, acc.: 65.62%] [G loss: 0.957420]\n",
      "epoch:4 step:4233 [D loss: 0.627733, acc.: 60.94%] [G loss: 0.930727]\n",
      "epoch:4 step:4234 [D loss: 0.668906, acc.: 60.16%] [G loss: 0.872823]\n",
      "epoch:4 step:4235 [D loss: 0.676360, acc.: 60.94%] [G loss: 0.942325]\n",
      "epoch:4 step:4236 [D loss: 0.613117, acc.: 64.84%] [G loss: 0.963083]\n",
      "epoch:4 step:4237 [D loss: 0.652520, acc.: 62.50%] [G loss: 0.880083]\n",
      "epoch:4 step:4238 [D loss: 0.666661, acc.: 62.50%] [G loss: 0.917921]\n",
      "epoch:4 step:4239 [D loss: 0.631464, acc.: 65.62%] [G loss: 0.890466]\n",
      "epoch:4 step:4240 [D loss: 0.672110, acc.: 59.38%] [G loss: 0.919214]\n",
      "epoch:4 step:4241 [D loss: 0.650301, acc.: 64.84%] [G loss: 0.895569]\n",
      "epoch:4 step:4242 [D loss: 0.637583, acc.: 64.06%] [G loss: 0.857818]\n",
      "epoch:4 step:4243 [D loss: 0.593162, acc.: 71.88%] [G loss: 0.925881]\n",
      "epoch:4 step:4244 [D loss: 0.633378, acc.: 60.16%] [G loss: 0.896483]\n",
      "epoch:4 step:4245 [D loss: 0.591537, acc.: 69.53%] [G loss: 1.023247]\n",
      "epoch:4 step:4246 [D loss: 0.568995, acc.: 77.34%] [G loss: 0.991720]\n",
      "epoch:4 step:4247 [D loss: 0.562366, acc.: 74.22%] [G loss: 1.015625]\n",
      "epoch:4 step:4248 [D loss: 0.743189, acc.: 51.56%] [G loss: 0.907378]\n",
      "epoch:4 step:4249 [D loss: 0.730084, acc.: 50.00%] [G loss: 0.851803]\n",
      "epoch:4 step:4250 [D loss: 0.655668, acc.: 64.84%] [G loss: 0.823417]\n",
      "epoch:4 step:4251 [D loss: 0.591922, acc.: 69.53%] [G loss: 0.870413]\n",
      "epoch:4 step:4252 [D loss: 0.618063, acc.: 64.06%] [G loss: 0.914591]\n",
      "epoch:4 step:4253 [D loss: 0.614509, acc.: 65.62%] [G loss: 0.907266]\n",
      "epoch:4 step:4254 [D loss: 0.653178, acc.: 59.38%] [G loss: 0.949038]\n",
      "epoch:4 step:4255 [D loss: 0.611257, acc.: 64.06%] [G loss: 0.941372]\n",
      "epoch:4 step:4256 [D loss: 0.579553, acc.: 71.09%] [G loss: 1.055269]\n",
      "epoch:4 step:4257 [D loss: 0.690926, acc.: 58.59%] [G loss: 0.986811]\n",
      "epoch:4 step:4258 [D loss: 0.678920, acc.: 60.94%] [G loss: 0.933780]\n",
      "epoch:4 step:4259 [D loss: 0.712244, acc.: 52.34%] [G loss: 0.988764]\n",
      "epoch:4 step:4260 [D loss: 0.640546, acc.: 67.19%] [G loss: 0.916550]\n",
      "epoch:4 step:4261 [D loss: 0.623190, acc.: 68.75%] [G loss: 0.971058]\n",
      "epoch:4 step:4262 [D loss: 0.657884, acc.: 60.16%] [G loss: 0.943505]\n",
      "epoch:4 step:4263 [D loss: 0.568192, acc.: 72.66%] [G loss: 0.999557]\n",
      "epoch:4 step:4264 [D loss: 0.646148, acc.: 64.84%] [G loss: 0.892518]\n",
      "epoch:4 step:4265 [D loss: 0.727295, acc.: 51.56%] [G loss: 0.834196]\n",
      "epoch:4 step:4266 [D loss: 0.590436, acc.: 73.44%] [G loss: 0.922449]\n",
      "epoch:4 step:4267 [D loss: 0.640311, acc.: 60.16%] [G loss: 0.873400]\n",
      "epoch:4 step:4268 [D loss: 0.597928, acc.: 64.06%] [G loss: 0.908320]\n",
      "epoch:4 step:4269 [D loss: 0.601253, acc.: 72.66%] [G loss: 0.957354]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4270 [D loss: 0.579898, acc.: 65.62%] [G loss: 0.957504]\n",
      "epoch:4 step:4271 [D loss: 0.638757, acc.: 64.84%] [G loss: 0.887626]\n",
      "epoch:4 step:4272 [D loss: 0.643163, acc.: 64.84%] [G loss: 0.885617]\n",
      "epoch:4 step:4273 [D loss: 0.678786, acc.: 55.47%] [G loss: 0.904081]\n",
      "epoch:4 step:4274 [D loss: 0.663665, acc.: 62.50%] [G loss: 0.907373]\n",
      "epoch:4 step:4275 [D loss: 0.647240, acc.: 62.50%] [G loss: 0.943811]\n",
      "epoch:4 step:4276 [D loss: 0.693360, acc.: 53.91%] [G loss: 0.906228]\n",
      "epoch:4 step:4277 [D loss: 0.657647, acc.: 61.72%] [G loss: 0.893611]\n",
      "epoch:4 step:4278 [D loss: 0.622149, acc.: 66.41%] [G loss: 0.904274]\n",
      "epoch:4 step:4279 [D loss: 0.681128, acc.: 57.81%] [G loss: 0.821259]\n",
      "epoch:4 step:4280 [D loss: 0.626738, acc.: 67.19%] [G loss: 0.929859]\n",
      "epoch:4 step:4281 [D loss: 0.676132, acc.: 58.59%] [G loss: 0.903649]\n",
      "epoch:4 step:4282 [D loss: 0.595031, acc.: 75.78%] [G loss: 0.872833]\n",
      "epoch:4 step:4283 [D loss: 0.666321, acc.: 61.72%] [G loss: 0.863670]\n",
      "epoch:4 step:4284 [D loss: 0.661425, acc.: 55.47%] [G loss: 0.898253]\n",
      "epoch:4 step:4285 [D loss: 0.653001, acc.: 60.16%] [G loss: 0.866262]\n",
      "epoch:4 step:4286 [D loss: 0.693443, acc.: 56.25%] [G loss: 0.914381]\n",
      "epoch:4 step:4287 [D loss: 0.649071, acc.: 60.16%] [G loss: 0.913171]\n",
      "epoch:4 step:4288 [D loss: 0.643171, acc.: 64.06%] [G loss: 0.956698]\n",
      "epoch:4 step:4289 [D loss: 0.621857, acc.: 67.97%] [G loss: 0.913395]\n",
      "epoch:4 step:4290 [D loss: 0.687577, acc.: 60.94%] [G loss: 0.895356]\n",
      "epoch:4 step:4291 [D loss: 0.686010, acc.: 57.03%] [G loss: 0.910103]\n",
      "epoch:4 step:4292 [D loss: 0.613159, acc.: 66.41%] [G loss: 0.815781]\n",
      "epoch:4 step:4293 [D loss: 0.621028, acc.: 66.41%] [G loss: 0.965008]\n",
      "epoch:4 step:4294 [D loss: 0.602426, acc.: 68.75%] [G loss: 0.907538]\n",
      "epoch:4 step:4295 [D loss: 0.623120, acc.: 64.84%] [G loss: 0.953231]\n",
      "epoch:4 step:4296 [D loss: 0.600227, acc.: 67.97%] [G loss: 0.980444]\n",
      "epoch:4 step:4297 [D loss: 0.570798, acc.: 72.66%] [G loss: 1.016233]\n",
      "epoch:4 step:4298 [D loss: 0.626949, acc.: 64.06%] [G loss: 0.923403]\n",
      "epoch:4 step:4299 [D loss: 0.678285, acc.: 51.56%] [G loss: 0.913944]\n",
      "epoch:4 step:4300 [D loss: 0.640919, acc.: 66.41%] [G loss: 0.960243]\n",
      "epoch:4 step:4301 [D loss: 0.660573, acc.: 54.69%] [G loss: 0.904434]\n",
      "epoch:4 step:4302 [D loss: 0.588684, acc.: 72.66%] [G loss: 0.939295]\n",
      "epoch:4 step:4303 [D loss: 0.589501, acc.: 73.44%] [G loss: 0.893226]\n",
      "epoch:4 step:4304 [D loss: 0.590294, acc.: 74.22%] [G loss: 0.862870]\n",
      "epoch:4 step:4305 [D loss: 0.610223, acc.: 68.75%] [G loss: 0.931457]\n",
      "epoch:4 step:4306 [D loss: 0.555238, acc.: 72.66%] [G loss: 0.980205]\n",
      "epoch:4 step:4307 [D loss: 0.686801, acc.: 59.38%] [G loss: 0.930357]\n",
      "epoch:4 step:4308 [D loss: 0.683149, acc.: 59.38%] [G loss: 0.921840]\n",
      "epoch:4 step:4309 [D loss: 0.640293, acc.: 58.59%] [G loss: 0.938120]\n",
      "epoch:4 step:4310 [D loss: 0.643804, acc.: 56.25%] [G loss: 0.991577]\n",
      "epoch:4 step:4311 [D loss: 0.636972, acc.: 67.97%] [G loss: 0.970826]\n",
      "epoch:4 step:4312 [D loss: 0.610635, acc.: 68.75%] [G loss: 0.951412]\n",
      "epoch:4 step:4313 [D loss: 0.712909, acc.: 52.34%] [G loss: 0.964597]\n",
      "epoch:4 step:4314 [D loss: 0.736072, acc.: 50.78%] [G loss: 0.981839]\n",
      "epoch:4 step:4315 [D loss: 0.642489, acc.: 61.72%] [G loss: 0.909511]\n",
      "epoch:4 step:4316 [D loss: 0.664986, acc.: 58.59%] [G loss: 0.943175]\n",
      "epoch:4 step:4317 [D loss: 0.696050, acc.: 53.91%] [G loss: 0.888396]\n",
      "epoch:4 step:4318 [D loss: 0.621601, acc.: 63.28%] [G loss: 0.921232]\n",
      "epoch:4 step:4319 [D loss: 0.627756, acc.: 67.97%] [G loss: 0.849090]\n",
      "epoch:4 step:4320 [D loss: 0.660150, acc.: 64.06%] [G loss: 0.858192]\n",
      "epoch:4 step:4321 [D loss: 0.611126, acc.: 66.41%] [G loss: 0.874446]\n",
      "epoch:4 step:4322 [D loss: 0.567463, acc.: 73.44%] [G loss: 0.913652]\n",
      "epoch:4 step:4323 [D loss: 0.567329, acc.: 71.88%] [G loss: 0.860084]\n",
      "epoch:4 step:4324 [D loss: 0.622412, acc.: 64.84%] [G loss: 0.903166]\n",
      "epoch:4 step:4325 [D loss: 0.653538, acc.: 62.50%] [G loss: 0.910454]\n",
      "epoch:4 step:4326 [D loss: 0.628394, acc.: 61.72%] [G loss: 0.890110]\n",
      "epoch:4 step:4327 [D loss: 0.644256, acc.: 69.53%] [G loss: 0.839750]\n",
      "epoch:4 step:4328 [D loss: 0.693233, acc.: 57.81%] [G loss: 0.879692]\n",
      "epoch:4 step:4329 [D loss: 0.622235, acc.: 65.62%] [G loss: 0.918454]\n",
      "epoch:4 step:4330 [D loss: 0.629485, acc.: 66.41%] [G loss: 0.962319]\n",
      "epoch:4 step:4331 [D loss: 0.674844, acc.: 60.16%] [G loss: 0.944283]\n",
      "epoch:4 step:4332 [D loss: 0.702567, acc.: 53.12%] [G loss: 0.858144]\n",
      "epoch:4 step:4333 [D loss: 0.646786, acc.: 60.16%] [G loss: 0.907476]\n",
      "epoch:4 step:4334 [D loss: 0.655097, acc.: 61.72%] [G loss: 0.878475]\n",
      "epoch:4 step:4335 [D loss: 0.685490, acc.: 61.72%] [G loss: 0.909845]\n",
      "epoch:4 step:4336 [D loss: 0.642700, acc.: 65.62%] [G loss: 0.917651]\n",
      "epoch:4 step:4337 [D loss: 0.604380, acc.: 71.09%] [G loss: 0.865099]\n",
      "epoch:4 step:4338 [D loss: 0.650824, acc.: 65.62%] [G loss: 0.904443]\n",
      "epoch:4 step:4339 [D loss: 0.690982, acc.: 54.69%] [G loss: 0.870276]\n",
      "epoch:4 step:4340 [D loss: 0.617705, acc.: 74.22%] [G loss: 0.905229]\n",
      "epoch:4 step:4341 [D loss: 0.644160, acc.: 65.62%] [G loss: 0.949944]\n",
      "epoch:4 step:4342 [D loss: 0.668814, acc.: 63.28%] [G loss: 0.938970]\n",
      "epoch:4 step:4343 [D loss: 0.687593, acc.: 61.72%] [G loss: 0.910469]\n",
      "epoch:4 step:4344 [D loss: 0.651021, acc.: 62.50%] [G loss: 0.928812]\n",
      "epoch:4 step:4345 [D loss: 0.635968, acc.: 66.41%] [G loss: 0.883071]\n",
      "epoch:4 step:4346 [D loss: 0.620635, acc.: 67.97%] [G loss: 0.954012]\n",
      "epoch:4 step:4347 [D loss: 0.623973, acc.: 71.09%] [G loss: 0.896393]\n",
      "epoch:4 step:4348 [D loss: 0.710961, acc.: 52.34%] [G loss: 0.837966]\n",
      "epoch:4 step:4349 [D loss: 0.661591, acc.: 55.47%] [G loss: 0.881257]\n",
      "epoch:4 step:4350 [D loss: 0.667434, acc.: 64.06%] [G loss: 0.858357]\n",
      "epoch:4 step:4351 [D loss: 0.613618, acc.: 67.97%] [G loss: 0.879365]\n",
      "epoch:4 step:4352 [D loss: 0.631618, acc.: 64.84%] [G loss: 0.915008]\n",
      "epoch:4 step:4353 [D loss: 0.630534, acc.: 59.38%] [G loss: 0.925819]\n",
      "epoch:4 step:4354 [D loss: 0.677263, acc.: 55.47%] [G loss: 0.896654]\n",
      "epoch:4 step:4355 [D loss: 0.646491, acc.: 63.28%] [G loss: 0.847169]\n",
      "epoch:4 step:4356 [D loss: 0.655764, acc.: 62.50%] [G loss: 0.850951]\n",
      "epoch:4 step:4357 [D loss: 0.663697, acc.: 64.06%] [G loss: 0.944651]\n",
      "epoch:4 step:4358 [D loss: 0.631901, acc.: 61.72%] [G loss: 0.892347]\n",
      "epoch:4 step:4359 [D loss: 0.648922, acc.: 58.59%] [G loss: 0.911271]\n",
      "epoch:4 step:4360 [D loss: 0.648314, acc.: 64.84%] [G loss: 0.880329]\n",
      "epoch:4 step:4361 [D loss: 0.615443, acc.: 68.75%] [G loss: 0.878253]\n",
      "epoch:4 step:4362 [D loss: 0.630264, acc.: 66.41%] [G loss: 0.857272]\n",
      "epoch:4 step:4363 [D loss: 0.690083, acc.: 50.78%] [G loss: 0.900183]\n",
      "epoch:4 step:4364 [D loss: 0.653063, acc.: 65.62%] [G loss: 0.910286]\n",
      "epoch:4 step:4365 [D loss: 0.583400, acc.: 68.75%] [G loss: 0.952423]\n",
      "epoch:4 step:4366 [D loss: 0.677261, acc.: 57.81%] [G loss: 0.904174]\n",
      "epoch:4 step:4367 [D loss: 0.629521, acc.: 64.06%] [G loss: 0.906368]\n",
      "epoch:4 step:4368 [D loss: 0.638261, acc.: 66.41%] [G loss: 0.849427]\n",
      "epoch:4 step:4369 [D loss: 0.695593, acc.: 50.00%] [G loss: 0.919575]\n",
      "epoch:4 step:4370 [D loss: 0.692250, acc.: 57.81%] [G loss: 0.852411]\n",
      "epoch:4 step:4371 [D loss: 0.628175, acc.: 65.62%] [G loss: 0.888561]\n",
      "epoch:4 step:4372 [D loss: 0.642119, acc.: 59.38%] [G loss: 0.914975]\n",
      "epoch:4 step:4373 [D loss: 0.675075, acc.: 56.25%] [G loss: 0.916412]\n",
      "epoch:4 step:4374 [D loss: 0.633587, acc.: 69.53%] [G loss: 0.921629]\n",
      "epoch:4 step:4375 [D loss: 0.609133, acc.: 66.41%] [G loss: 0.881185]\n",
      "epoch:4 step:4376 [D loss: 0.638935, acc.: 66.41%] [G loss: 0.867808]\n",
      "epoch:4 step:4377 [D loss: 0.613810, acc.: 71.09%] [G loss: 0.879566]\n",
      "epoch:4 step:4378 [D loss: 0.645990, acc.: 60.94%] [G loss: 0.921512]\n",
      "epoch:4 step:4379 [D loss: 0.600345, acc.: 67.97%] [G loss: 0.904057]\n",
      "epoch:4 step:4380 [D loss: 0.633348, acc.: 63.28%] [G loss: 0.896186]\n",
      "epoch:4 step:4381 [D loss: 0.629136, acc.: 64.06%] [G loss: 0.891462]\n",
      "epoch:4 step:4382 [D loss: 0.621851, acc.: 70.31%] [G loss: 0.969888]\n",
      "epoch:4 step:4383 [D loss: 0.624588, acc.: 64.84%] [G loss: 0.971108]\n",
      "epoch:4 step:4384 [D loss: 0.658918, acc.: 59.38%] [G loss: 0.893851]\n",
      "epoch:4 step:4385 [D loss: 0.638587, acc.: 60.94%] [G loss: 0.853627]\n",
      "epoch:4 step:4386 [D loss: 0.674154, acc.: 55.47%] [G loss: 0.940160]\n",
      "epoch:4 step:4387 [D loss: 0.642792, acc.: 63.28%] [G loss: 0.917694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4388 [D loss: 0.614096, acc.: 65.62%] [G loss: 0.961637]\n",
      "epoch:4 step:4389 [D loss: 0.576369, acc.: 70.31%] [G loss: 1.038271]\n",
      "epoch:4 step:4390 [D loss: 0.598356, acc.: 69.53%] [G loss: 1.084351]\n",
      "epoch:4 step:4391 [D loss: 0.736550, acc.: 57.03%] [G loss: 0.961982]\n",
      "epoch:4 step:4392 [D loss: 0.708268, acc.: 53.12%] [G loss: 0.941103]\n",
      "epoch:4 step:4393 [D loss: 0.660849, acc.: 64.84%] [G loss: 0.877479]\n",
      "epoch:4 step:4394 [D loss: 0.590788, acc.: 75.00%] [G loss: 0.890204]\n",
      "epoch:4 step:4395 [D loss: 0.618771, acc.: 68.75%] [G loss: 0.918239]\n",
      "epoch:4 step:4396 [D loss: 0.605794, acc.: 64.84%] [G loss: 0.964571]\n",
      "epoch:4 step:4397 [D loss: 0.595721, acc.: 67.19%] [G loss: 0.947438]\n",
      "epoch:4 step:4398 [D loss: 0.594000, acc.: 69.53%] [G loss: 0.957051]\n",
      "epoch:4 step:4399 [D loss: 0.643901, acc.: 64.84%] [G loss: 0.922854]\n",
      "epoch:4 step:4400 [D loss: 0.721893, acc.: 48.44%] [G loss: 0.929532]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 6.959799\n",
      "FID: 26.446501\n",
      "0 = 12.346505664849232\n",
      "1 = 0.07928821535228296\n",
      "2 = 0.9623500108718872\n",
      "3 = 0.9262999892234802\n",
      "4 = 0.9983999729156494\n",
      "5 = 0.9982756972312927\n",
      "6 = 0.9262999892234802\n",
      "7 = 7.841546388292322\n",
      "8 = 0.1059283380288126\n",
      "9 = 0.8126500248908997\n",
      "10 = 0.7748000025749207\n",
      "11 = 0.8504999876022339\n",
      "12 = 0.8382560014724731\n",
      "13 = 0.7748000025749207\n",
      "14 = 6.959859848022461\n",
      "15 = 9.582225799560547\n",
      "16 = 0.1241752952337265\n",
      "17 = 6.959799289703369\n",
      "18 = 26.446500778198242\n",
      "epoch:4 step:4401 [D loss: 0.661045, acc.: 59.38%] [G loss: 0.888898]\n",
      "epoch:4 step:4402 [D loss: 0.618667, acc.: 64.06%] [G loss: 0.961013]\n",
      "epoch:4 step:4403 [D loss: 0.651510, acc.: 60.94%] [G loss: 0.890352]\n",
      "epoch:4 step:4404 [D loss: 0.621383, acc.: 67.97%] [G loss: 0.875689]\n",
      "epoch:4 step:4405 [D loss: 0.630804, acc.: 71.09%] [G loss: 0.873369]\n",
      "epoch:4 step:4406 [D loss: 0.645060, acc.: 60.16%] [G loss: 0.918432]\n",
      "epoch:4 step:4407 [D loss: 0.615570, acc.: 66.41%] [G loss: 0.900706]\n",
      "epoch:4 step:4408 [D loss: 0.620762, acc.: 65.62%] [G loss: 0.933614]\n",
      "epoch:4 step:4409 [D loss: 0.599672, acc.: 68.75%] [G loss: 0.907322]\n",
      "epoch:4 step:4410 [D loss: 0.651061, acc.: 64.84%] [G loss: 0.955461]\n",
      "epoch:4 step:4411 [D loss: 0.638304, acc.: 66.41%] [G loss: 0.940373]\n",
      "epoch:4 step:4412 [D loss: 0.646386, acc.: 67.19%] [G loss: 0.945112]\n",
      "epoch:4 step:4413 [D loss: 0.595334, acc.: 69.53%] [G loss: 0.914890]\n",
      "epoch:4 step:4414 [D loss: 0.612692, acc.: 67.97%] [G loss: 0.902999]\n",
      "epoch:4 step:4415 [D loss: 0.662225, acc.: 58.59%] [G loss: 0.896466]\n",
      "epoch:4 step:4416 [D loss: 0.710569, acc.: 51.56%] [G loss: 0.894206]\n",
      "epoch:4 step:4417 [D loss: 0.616517, acc.: 67.19%] [G loss: 0.846646]\n",
      "epoch:4 step:4418 [D loss: 0.668449, acc.: 61.72%] [G loss: 0.867033]\n",
      "epoch:4 step:4419 [D loss: 0.660863, acc.: 66.41%] [G loss: 0.854485]\n",
      "epoch:4 step:4420 [D loss: 0.696222, acc.: 51.56%] [G loss: 0.882456]\n",
      "epoch:4 step:4421 [D loss: 0.653123, acc.: 63.28%] [G loss: 0.945249]\n",
      "epoch:4 step:4422 [D loss: 0.644058, acc.: 65.62%] [G loss: 0.929970]\n",
      "epoch:4 step:4423 [D loss: 0.682711, acc.: 57.03%] [G loss: 0.880014]\n",
      "epoch:4 step:4424 [D loss: 0.633599, acc.: 67.19%] [G loss: 0.879634]\n",
      "epoch:4 step:4425 [D loss: 0.644165, acc.: 64.84%] [G loss: 0.895540]\n",
      "epoch:4 step:4426 [D loss: 0.678231, acc.: 59.38%] [G loss: 0.969699]\n",
      "epoch:4 step:4427 [D loss: 0.626567, acc.: 65.62%] [G loss: 0.923520]\n",
      "epoch:4 step:4428 [D loss: 0.612788, acc.: 71.09%] [G loss: 0.930244]\n",
      "epoch:4 step:4429 [D loss: 0.638991, acc.: 60.94%] [G loss: 0.908149]\n",
      "epoch:4 step:4430 [D loss: 0.682472, acc.: 57.03%] [G loss: 0.985601]\n",
      "epoch:4 step:4431 [D loss: 0.672812, acc.: 56.25%] [G loss: 0.863055]\n",
      "epoch:4 step:4432 [D loss: 0.621064, acc.: 69.53%] [G loss: 0.914878]\n",
      "epoch:4 step:4433 [D loss: 0.635316, acc.: 60.16%] [G loss: 0.922989]\n",
      "epoch:4 step:4434 [D loss: 0.651779, acc.: 62.50%] [G loss: 0.913705]\n",
      "epoch:4 step:4435 [D loss: 0.697730, acc.: 58.59%] [G loss: 0.875241]\n",
      "epoch:4 step:4436 [D loss: 0.672149, acc.: 56.25%] [G loss: 0.909158]\n",
      "epoch:4 step:4437 [D loss: 0.644932, acc.: 62.50%] [G loss: 0.893950]\n",
      "epoch:4 step:4438 [D loss: 0.596822, acc.: 70.31%] [G loss: 0.959064]\n",
      "epoch:4 step:4439 [D loss: 0.591588, acc.: 69.53%] [G loss: 0.987017]\n",
      "epoch:4 step:4440 [D loss: 0.665622, acc.: 60.94%] [G loss: 0.935704]\n",
      "epoch:4 step:4441 [D loss: 0.629315, acc.: 66.41%] [G loss: 0.984765]\n",
      "epoch:4 step:4442 [D loss: 0.598206, acc.: 68.75%] [G loss: 0.927538]\n",
      "epoch:4 step:4443 [D loss: 0.648923, acc.: 60.16%] [G loss: 0.913918]\n",
      "epoch:4 step:4444 [D loss: 0.665027, acc.: 57.03%] [G loss: 0.894614]\n",
      "epoch:4 step:4445 [D loss: 0.602803, acc.: 73.44%] [G loss: 0.906307]\n",
      "epoch:4 step:4446 [D loss: 0.615376, acc.: 67.97%] [G loss: 0.911759]\n",
      "epoch:4 step:4447 [D loss: 0.597849, acc.: 71.88%] [G loss: 0.924411]\n",
      "epoch:4 step:4448 [D loss: 0.617772, acc.: 63.28%] [G loss: 0.955989]\n",
      "epoch:4 step:4449 [D loss: 0.599941, acc.: 68.75%] [G loss: 0.947050]\n",
      "epoch:4 step:4450 [D loss: 0.686957, acc.: 60.94%] [G loss: 0.879231]\n",
      "epoch:4 step:4451 [D loss: 0.696250, acc.: 57.03%] [G loss: 0.848407]\n",
      "epoch:4 step:4452 [D loss: 0.653088, acc.: 64.06%] [G loss: 0.894532]\n",
      "epoch:4 step:4453 [D loss: 0.661308, acc.: 58.59%] [G loss: 0.905621]\n",
      "epoch:4 step:4454 [D loss: 0.642918, acc.: 61.72%] [G loss: 0.947486]\n",
      "epoch:4 step:4455 [D loss: 0.601693, acc.: 70.31%] [G loss: 0.908864]\n",
      "epoch:4 step:4456 [D loss: 0.585052, acc.: 69.53%] [G loss: 1.009591]\n",
      "epoch:4 step:4457 [D loss: 0.595186, acc.: 72.66%] [G loss: 0.937974]\n",
      "epoch:4 step:4458 [D loss: 0.721394, acc.: 51.56%] [G loss: 0.874591]\n",
      "epoch:4 step:4459 [D loss: 0.689008, acc.: 55.47%] [G loss: 0.949812]\n",
      "epoch:4 step:4460 [D loss: 0.665329, acc.: 54.69%] [G loss: 0.887056]\n",
      "epoch:4 step:4461 [D loss: 0.666609, acc.: 58.59%] [G loss: 0.939041]\n",
      "epoch:4 step:4462 [D loss: 0.645436, acc.: 60.94%] [G loss: 0.883580]\n",
      "epoch:4 step:4463 [D loss: 0.647539, acc.: 60.16%] [G loss: 0.841032]\n",
      "epoch:4 step:4464 [D loss: 0.673792, acc.: 57.81%] [G loss: 0.829214]\n",
      "epoch:4 step:4465 [D loss: 0.626369, acc.: 68.75%] [G loss: 0.919188]\n",
      "epoch:4 step:4466 [D loss: 0.658568, acc.: 63.28%] [G loss: 0.873803]\n",
      "epoch:4 step:4467 [D loss: 0.599514, acc.: 67.97%] [G loss: 0.900819]\n",
      "epoch:4 step:4468 [D loss: 0.641214, acc.: 62.50%] [G loss: 0.943073]\n",
      "epoch:4 step:4469 [D loss: 0.667576, acc.: 60.16%] [G loss: 0.948304]\n",
      "epoch:4 step:4470 [D loss: 0.711889, acc.: 53.91%] [G loss: 0.940338]\n",
      "epoch:4 step:4471 [D loss: 0.658210, acc.: 60.94%] [G loss: 0.913417]\n",
      "epoch:4 step:4472 [D loss: 0.638719, acc.: 63.28%] [G loss: 0.966667]\n",
      "epoch:4 step:4473 [D loss: 0.625046, acc.: 66.41%] [G loss: 0.942000]\n",
      "epoch:4 step:4474 [D loss: 0.643327, acc.: 60.16%] [G loss: 0.913063]\n",
      "epoch:4 step:4475 [D loss: 0.714998, acc.: 48.44%] [G loss: 0.847769]\n",
      "epoch:4 step:4476 [D loss: 0.708835, acc.: 50.78%] [G loss: 0.836130]\n",
      "epoch:4 step:4477 [D loss: 0.698381, acc.: 53.91%] [G loss: 0.840376]\n",
      "epoch:4 step:4478 [D loss: 0.609513, acc.: 69.53%] [G loss: 0.894096]\n",
      "epoch:4 step:4479 [D loss: 0.624987, acc.: 62.50%] [G loss: 0.929817]\n",
      "epoch:4 step:4480 [D loss: 0.627222, acc.: 67.19%] [G loss: 0.898933]\n",
      "epoch:4 step:4481 [D loss: 0.632045, acc.: 60.94%] [G loss: 0.908501]\n",
      "epoch:4 step:4482 [D loss: 0.620072, acc.: 66.41%] [G loss: 0.902873]\n",
      "epoch:4 step:4483 [D loss: 0.645875, acc.: 61.72%] [G loss: 0.897886]\n",
      "epoch:4 step:4484 [D loss: 0.609552, acc.: 67.97%] [G loss: 0.932690]\n",
      "epoch:4 step:4485 [D loss: 0.625364, acc.: 63.28%] [G loss: 0.859444]\n",
      "epoch:4 step:4486 [D loss: 0.688707, acc.: 52.34%] [G loss: 0.816920]\n",
      "epoch:4 step:4487 [D loss: 0.695101, acc.: 54.69%] [G loss: 0.858012]\n",
      "epoch:4 step:4488 [D loss: 0.670001, acc.: 60.16%] [G loss: 0.835586]\n",
      "epoch:4 step:4489 [D loss: 0.664575, acc.: 60.16%] [G loss: 0.850695]\n",
      "epoch:4 step:4490 [D loss: 0.666449, acc.: 60.16%] [G loss: 0.917582]\n",
      "epoch:4 step:4491 [D loss: 0.647848, acc.: 64.06%] [G loss: 0.928619]\n",
      "epoch:4 step:4492 [D loss: 0.648711, acc.: 62.50%] [G loss: 0.863823]\n",
      "epoch:4 step:4493 [D loss: 0.610126, acc.: 69.53%] [G loss: 0.900771]\n",
      "epoch:4 step:4494 [D loss: 0.607529, acc.: 66.41%] [G loss: 0.888199]\n",
      "epoch:4 step:4495 [D loss: 0.594126, acc.: 70.31%] [G loss: 0.923443]\n",
      "epoch:4 step:4496 [D loss: 0.665393, acc.: 59.38%] [G loss: 0.844794]\n",
      "epoch:4 step:4497 [D loss: 0.655837, acc.: 64.06%] [G loss: 0.901940]\n",
      "epoch:4 step:4498 [D loss: 0.662219, acc.: 63.28%] [G loss: 0.910297]\n",
      "epoch:4 step:4499 [D loss: 0.656089, acc.: 55.47%] [G loss: 0.928560]\n",
      "epoch:4 step:4500 [D loss: 0.633632, acc.: 64.84%] [G loss: 0.885037]\n",
      "epoch:4 step:4501 [D loss: 0.645147, acc.: 62.50%] [G loss: 0.925317]\n",
      "epoch:4 step:4502 [D loss: 0.604113, acc.: 71.88%] [G loss: 0.835932]\n",
      "epoch:4 step:4503 [D loss: 0.593220, acc.: 67.19%] [G loss: 0.894080]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4504 [D loss: 0.643081, acc.: 64.84%] [G loss: 0.885698]\n",
      "epoch:4 step:4505 [D loss: 0.687540, acc.: 53.12%] [G loss: 0.930188]\n",
      "epoch:4 step:4506 [D loss: 0.645154, acc.: 63.28%] [G loss: 0.842391]\n",
      "epoch:4 step:4507 [D loss: 0.675031, acc.: 57.03%] [G loss: 0.810300]\n",
      "epoch:4 step:4508 [D loss: 0.667925, acc.: 57.81%] [G loss: 0.843035]\n",
      "epoch:4 step:4509 [D loss: 0.648425, acc.: 56.25%] [G loss: 0.902051]\n",
      "epoch:4 step:4510 [D loss: 0.684727, acc.: 60.94%] [G loss: 0.883447]\n",
      "epoch:4 step:4511 [D loss: 0.635716, acc.: 63.28%] [G loss: 0.825009]\n",
      "epoch:4 step:4512 [D loss: 0.691719, acc.: 55.47%] [G loss: 0.847364]\n",
      "epoch:4 step:4513 [D loss: 0.711055, acc.: 57.03%] [G loss: 0.878741]\n",
      "epoch:4 step:4514 [D loss: 0.683576, acc.: 53.91%] [G loss: 0.827891]\n",
      "epoch:4 step:4515 [D loss: 0.605861, acc.: 77.34%] [G loss: 0.927240]\n",
      "epoch:4 step:4516 [D loss: 0.648534, acc.: 66.41%] [G loss: 0.966784]\n",
      "epoch:4 step:4517 [D loss: 0.647473, acc.: 59.38%] [G loss: 0.969540]\n",
      "epoch:4 step:4518 [D loss: 0.667610, acc.: 60.16%] [G loss: 0.999952]\n",
      "epoch:4 step:4519 [D loss: 0.647493, acc.: 60.16%] [G loss: 0.998517]\n",
      "epoch:4 step:4520 [D loss: 0.625938, acc.: 72.66%] [G loss: 0.966290]\n",
      "epoch:4 step:4521 [D loss: 0.659940, acc.: 56.25%] [G loss: 0.867428]\n",
      "epoch:4 step:4522 [D loss: 0.631136, acc.: 65.62%] [G loss: 0.959139]\n",
      "epoch:4 step:4523 [D loss: 0.616148, acc.: 66.41%] [G loss: 0.968654]\n",
      "epoch:4 step:4524 [D loss: 0.622980, acc.: 67.19%] [G loss: 0.906748]\n",
      "epoch:4 step:4525 [D loss: 0.649964, acc.: 57.81%] [G loss: 0.933473]\n",
      "epoch:4 step:4526 [D loss: 0.649115, acc.: 61.72%] [G loss: 0.903105]\n",
      "epoch:4 step:4527 [D loss: 0.665180, acc.: 62.50%] [G loss: 0.926947]\n",
      "epoch:4 step:4528 [D loss: 0.626764, acc.: 67.19%] [G loss: 0.934518]\n",
      "epoch:4 step:4529 [D loss: 0.585531, acc.: 68.75%] [G loss: 0.987471]\n",
      "epoch:4 step:4530 [D loss: 0.602359, acc.: 69.53%] [G loss: 1.031743]\n",
      "epoch:4 step:4531 [D loss: 0.664370, acc.: 58.59%] [G loss: 0.950723]\n",
      "epoch:4 step:4532 [D loss: 0.767240, acc.: 49.22%] [G loss: 0.876702]\n",
      "epoch:4 step:4533 [D loss: 0.666763, acc.: 60.16%] [G loss: 0.900454]\n",
      "epoch:4 step:4534 [D loss: 0.630388, acc.: 63.28%] [G loss: 0.881495]\n",
      "epoch:4 step:4535 [D loss: 0.655757, acc.: 63.28%] [G loss: 0.915480]\n",
      "epoch:4 step:4536 [D loss: 0.670414, acc.: 57.03%] [G loss: 0.918343]\n",
      "epoch:4 step:4537 [D loss: 0.601742, acc.: 67.19%] [G loss: 0.895116]\n",
      "epoch:4 step:4538 [D loss: 0.629976, acc.: 67.97%] [G loss: 0.948679]\n",
      "epoch:4 step:4539 [D loss: 0.709566, acc.: 53.91%] [G loss: 0.874553]\n",
      "epoch:4 step:4540 [D loss: 0.587732, acc.: 70.31%] [G loss: 0.915404]\n",
      "epoch:4 step:4541 [D loss: 0.617978, acc.: 67.97%] [G loss: 0.936436]\n",
      "epoch:4 step:4542 [D loss: 0.738701, acc.: 51.56%] [G loss: 0.886780]\n",
      "epoch:4 step:4543 [D loss: 0.632028, acc.: 65.62%] [G loss: 0.959632]\n",
      "epoch:4 step:4544 [D loss: 0.623761, acc.: 67.97%] [G loss: 0.939476]\n",
      "epoch:4 step:4545 [D loss: 0.664357, acc.: 54.69%] [G loss: 0.862400]\n",
      "epoch:4 step:4546 [D loss: 0.637860, acc.: 61.72%] [G loss: 0.903173]\n",
      "epoch:4 step:4547 [D loss: 0.610597, acc.: 65.62%] [G loss: 0.943595]\n",
      "epoch:4 step:4548 [D loss: 0.650788, acc.: 62.50%] [G loss: 0.890123]\n",
      "epoch:4 step:4549 [D loss: 0.579888, acc.: 73.44%] [G loss: 0.970672]\n",
      "epoch:4 step:4550 [D loss: 0.573731, acc.: 72.66%] [G loss: 1.017033]\n",
      "epoch:4 step:4551 [D loss: 0.600494, acc.: 70.31%] [G loss: 0.954789]\n",
      "epoch:4 step:4552 [D loss: 0.674163, acc.: 61.72%] [G loss: 0.907790]\n",
      "epoch:4 step:4553 [D loss: 0.653942, acc.: 61.72%] [G loss: 0.849486]\n",
      "epoch:4 step:4554 [D loss: 0.659111, acc.: 60.94%] [G loss: 0.970906]\n",
      "epoch:4 step:4555 [D loss: 0.597678, acc.: 71.09%] [G loss: 0.918091]\n",
      "epoch:4 step:4556 [D loss: 0.707932, acc.: 54.69%] [G loss: 0.860061]\n",
      "epoch:4 step:4557 [D loss: 0.732857, acc.: 48.44%] [G loss: 0.865194]\n",
      "epoch:4 step:4558 [D loss: 0.648802, acc.: 67.19%] [G loss: 0.841345]\n",
      "epoch:4 step:4559 [D loss: 0.669844, acc.: 57.03%] [G loss: 0.914012]\n",
      "epoch:4 step:4560 [D loss: 0.690717, acc.: 53.91%] [G loss: 0.888579]\n",
      "epoch:4 step:4561 [D loss: 0.694623, acc.: 57.03%] [G loss: 0.851512]\n",
      "epoch:4 step:4562 [D loss: 0.634288, acc.: 64.06%] [G loss: 0.908438]\n",
      "epoch:4 step:4563 [D loss: 0.607009, acc.: 67.97%] [G loss: 0.958242]\n",
      "epoch:4 step:4564 [D loss: 0.616186, acc.: 65.62%] [G loss: 0.912699]\n",
      "epoch:4 step:4565 [D loss: 0.675189, acc.: 59.38%] [G loss: 0.892053]\n",
      "epoch:4 step:4566 [D loss: 0.668519, acc.: 60.94%] [G loss: 0.897684]\n",
      "epoch:4 step:4567 [D loss: 0.651706, acc.: 57.03%] [G loss: 0.900109]\n",
      "epoch:4 step:4568 [D loss: 0.672635, acc.: 59.38%] [G loss: 0.953362]\n",
      "epoch:4 step:4569 [D loss: 0.630601, acc.: 68.75%] [G loss: 0.880126]\n",
      "epoch:4 step:4570 [D loss: 0.617926, acc.: 66.41%] [G loss: 0.917134]\n",
      "epoch:4 step:4571 [D loss: 0.629187, acc.: 64.06%] [G loss: 0.878806]\n",
      "epoch:4 step:4572 [D loss: 0.680021, acc.: 57.81%] [G loss: 0.849130]\n",
      "epoch:4 step:4573 [D loss: 0.631083, acc.: 68.75%] [G loss: 0.864444]\n",
      "epoch:4 step:4574 [D loss: 0.655581, acc.: 60.94%] [G loss: 0.944218]\n",
      "epoch:4 step:4575 [D loss: 0.660563, acc.: 57.03%] [G loss: 0.913202]\n",
      "epoch:4 step:4576 [D loss: 0.693311, acc.: 53.91%] [G loss: 0.940254]\n",
      "epoch:4 step:4577 [D loss: 0.674515, acc.: 57.81%] [G loss: 0.948370]\n",
      "epoch:4 step:4578 [D loss: 0.657331, acc.: 64.06%] [G loss: 0.941772]\n",
      "epoch:4 step:4579 [D loss: 0.639080, acc.: 67.97%] [G loss: 0.902222]\n",
      "epoch:4 step:4580 [D loss: 0.600533, acc.: 71.09%] [G loss: 0.936854]\n",
      "epoch:4 step:4581 [D loss: 0.631437, acc.: 67.19%] [G loss: 0.876566]\n",
      "epoch:4 step:4582 [D loss: 0.671702, acc.: 57.03%] [G loss: 0.948830]\n",
      "epoch:4 step:4583 [D loss: 0.638154, acc.: 62.50%] [G loss: 0.891070]\n",
      "epoch:4 step:4584 [D loss: 0.625169, acc.: 69.53%] [G loss: 0.920721]\n",
      "epoch:4 step:4585 [D loss: 0.640464, acc.: 61.72%] [G loss: 0.909257]\n",
      "epoch:4 step:4586 [D loss: 0.626244, acc.: 68.75%] [G loss: 0.896240]\n",
      "epoch:4 step:4587 [D loss: 0.636118, acc.: 61.72%] [G loss: 0.886830]\n",
      "epoch:4 step:4588 [D loss: 0.632463, acc.: 65.62%] [G loss: 0.973474]\n",
      "epoch:4 step:4589 [D loss: 0.622043, acc.: 64.06%] [G loss: 0.878784]\n",
      "epoch:4 step:4590 [D loss: 0.617432, acc.: 66.41%] [G loss: 0.973983]\n",
      "epoch:4 step:4591 [D loss: 0.690255, acc.: 56.25%] [G loss: 0.872211]\n",
      "epoch:4 step:4592 [D loss: 0.661426, acc.: 60.94%] [G loss: 0.921702]\n",
      "epoch:4 step:4593 [D loss: 0.654003, acc.: 67.19%] [G loss: 0.898818]\n",
      "epoch:4 step:4594 [D loss: 0.645207, acc.: 59.38%] [G loss: 0.877208]\n",
      "epoch:4 step:4595 [D loss: 0.665456, acc.: 59.38%] [G loss: 0.926146]\n",
      "epoch:4 step:4596 [D loss: 0.647806, acc.: 71.09%] [G loss: 0.919998]\n",
      "epoch:4 step:4597 [D loss: 0.639007, acc.: 66.41%] [G loss: 0.844103]\n",
      "epoch:4 step:4598 [D loss: 0.661829, acc.: 60.94%] [G loss: 0.852475]\n",
      "epoch:4 step:4599 [D loss: 0.660905, acc.: 58.59%] [G loss: 0.828531]\n",
      "epoch:4 step:4600 [D loss: 0.643807, acc.: 59.38%] [G loss: 0.877247]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.178144\n",
      "FID: 21.695793\n",
      "0 = 12.111424885392202\n",
      "1 = 0.07302947627644883\n",
      "2 = 0.958050012588501\n",
      "3 = 0.9172000288963318\n",
      "4 = 0.9988999962806702\n",
      "5 = 0.998802125453949\n",
      "6 = 0.9172000288963318\n",
      "7 = 7.475780143260924\n",
      "8 = 0.10129276549855963\n",
      "9 = 0.8049499988555908\n",
      "10 = 0.772599995136261\n",
      "11 = 0.8373000025749207\n",
      "12 = 0.8260450959205627\n",
      "13 = 0.772599995136261\n",
      "14 = 7.178205490112305\n",
      "15 = 9.568477630615234\n",
      "16 = 0.11990858614444733\n",
      "17 = 7.1781439781188965\n",
      "18 = 21.69579315185547\n",
      "epoch:4 step:4601 [D loss: 0.606927, acc.: 68.75%] [G loss: 0.882385]\n",
      "epoch:4 step:4602 [D loss: 0.612486, acc.: 67.97%] [G loss: 0.954517]\n",
      "epoch:4 step:4603 [D loss: 0.635944, acc.: 67.19%] [G loss: 0.916856]\n",
      "epoch:4 step:4604 [D loss: 0.691386, acc.: 54.69%] [G loss: 0.890390]\n",
      "epoch:4 step:4605 [D loss: 0.591160, acc.: 70.31%] [G loss: 0.899729]\n",
      "epoch:4 step:4606 [D loss: 0.728767, acc.: 47.66%] [G loss: 0.870026]\n",
      "epoch:4 step:4607 [D loss: 0.617656, acc.: 64.84%] [G loss: 0.932522]\n",
      "epoch:4 step:4608 [D loss: 0.611968, acc.: 66.41%] [G loss: 0.949165]\n",
      "epoch:4 step:4609 [D loss: 0.667583, acc.: 56.25%] [G loss: 0.889459]\n",
      "epoch:4 step:4610 [D loss: 0.672902, acc.: 55.47%] [G loss: 0.866187]\n",
      "epoch:4 step:4611 [D loss: 0.641112, acc.: 60.16%] [G loss: 0.859443]\n",
      "epoch:4 step:4612 [D loss: 0.676165, acc.: 58.59%] [G loss: 0.897287]\n",
      "epoch:4 step:4613 [D loss: 0.694003, acc.: 53.12%] [G loss: 0.884558]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4614 [D loss: 0.642385, acc.: 64.06%] [G loss: 0.945495]\n",
      "epoch:4 step:4615 [D loss: 0.698429, acc.: 51.56%] [G loss: 0.878368]\n",
      "epoch:4 step:4616 [D loss: 0.639088, acc.: 64.84%] [G loss: 0.846591]\n",
      "epoch:4 step:4617 [D loss: 0.622160, acc.: 68.75%] [G loss: 0.925996]\n",
      "epoch:4 step:4618 [D loss: 0.624264, acc.: 69.53%] [G loss: 0.895339]\n",
      "epoch:4 step:4619 [D loss: 0.618549, acc.: 64.06%] [G loss: 0.927917]\n",
      "epoch:4 step:4620 [D loss: 0.636598, acc.: 65.62%] [G loss: 0.869397]\n",
      "epoch:4 step:4621 [D loss: 0.661721, acc.: 60.16%] [G loss: 0.866964]\n",
      "epoch:4 step:4622 [D loss: 0.672443, acc.: 57.81%] [G loss: 0.914637]\n",
      "epoch:4 step:4623 [D loss: 0.593731, acc.: 67.97%] [G loss: 0.938966]\n",
      "epoch:4 step:4624 [D loss: 0.642732, acc.: 57.03%] [G loss: 0.870331]\n",
      "epoch:4 step:4625 [D loss: 0.663213, acc.: 57.81%] [G loss: 0.914267]\n",
      "epoch:4 step:4626 [D loss: 0.714207, acc.: 52.34%] [G loss: 0.929450]\n",
      "epoch:4 step:4627 [D loss: 0.655454, acc.: 60.94%] [G loss: 0.894037]\n",
      "epoch:4 step:4628 [D loss: 0.703140, acc.: 50.00%] [G loss: 0.918810]\n",
      "epoch:4 step:4629 [D loss: 0.617502, acc.: 64.06%] [G loss: 0.933537]\n",
      "epoch:4 step:4630 [D loss: 0.633202, acc.: 67.19%] [G loss: 0.892500]\n",
      "epoch:4 step:4631 [D loss: 0.658443, acc.: 63.28%] [G loss: 0.891156]\n",
      "epoch:4 step:4632 [D loss: 0.632526, acc.: 62.50%] [G loss: 0.896310]\n",
      "epoch:4 step:4633 [D loss: 0.629813, acc.: 66.41%] [G loss: 0.931987]\n",
      "epoch:4 step:4634 [D loss: 0.649876, acc.: 63.28%] [G loss: 1.014726]\n",
      "epoch:4 step:4635 [D loss: 0.660347, acc.: 64.84%] [G loss: 0.990327]\n",
      "epoch:4 step:4636 [D loss: 0.680771, acc.: 54.69%] [G loss: 0.903039]\n",
      "epoch:4 step:4637 [D loss: 0.633977, acc.: 63.28%] [G loss: 0.927659]\n",
      "epoch:4 step:4638 [D loss: 0.565428, acc.: 74.22%] [G loss: 0.902684]\n",
      "epoch:4 step:4639 [D loss: 0.685078, acc.: 53.91%] [G loss: 0.854761]\n",
      "epoch:4 step:4640 [D loss: 0.693745, acc.: 53.12%] [G loss: 0.909431]\n",
      "epoch:4 step:4641 [D loss: 0.642109, acc.: 65.62%] [G loss: 0.850674]\n",
      "epoch:4 step:4642 [D loss: 0.585060, acc.: 74.22%] [G loss: 0.951330]\n",
      "epoch:4 step:4643 [D loss: 0.632085, acc.: 64.06%] [G loss: 0.927482]\n",
      "epoch:4 step:4644 [D loss: 0.646402, acc.: 61.72%] [G loss: 0.962997]\n",
      "epoch:4 step:4645 [D loss: 0.622329, acc.: 69.53%] [G loss: 0.901741]\n",
      "epoch:4 step:4646 [D loss: 0.586753, acc.: 72.66%] [G loss: 0.943811]\n",
      "epoch:4 step:4647 [D loss: 0.584305, acc.: 71.09%] [G loss: 0.939013]\n",
      "epoch:4 step:4648 [D loss: 0.630864, acc.: 64.84%] [G loss: 0.940287]\n",
      "epoch:4 step:4649 [D loss: 0.675609, acc.: 57.03%] [G loss: 0.951640]\n",
      "epoch:4 step:4650 [D loss: 0.718803, acc.: 52.34%] [G loss: 0.961375]\n",
      "epoch:4 step:4651 [D loss: 0.683422, acc.: 60.16%] [G loss: 0.869795]\n",
      "epoch:4 step:4652 [D loss: 0.642328, acc.: 66.41%] [G loss: 0.893062]\n",
      "epoch:4 step:4653 [D loss: 0.632078, acc.: 63.28%] [G loss: 0.956175]\n",
      "epoch:4 step:4654 [D loss: 0.628152, acc.: 67.97%] [G loss: 0.920717]\n",
      "epoch:4 step:4655 [D loss: 0.685024, acc.: 56.25%] [G loss: 0.918326]\n",
      "epoch:4 step:4656 [D loss: 0.624897, acc.: 67.97%] [G loss: 0.963887]\n",
      "epoch:4 step:4657 [D loss: 0.646010, acc.: 71.88%] [G loss: 0.930443]\n",
      "epoch:4 step:4658 [D loss: 0.624344, acc.: 67.19%] [G loss: 0.934380]\n",
      "epoch:4 step:4659 [D loss: 0.642349, acc.: 59.38%] [G loss: 0.987648]\n",
      "epoch:4 step:4660 [D loss: 0.585113, acc.: 71.09%] [G loss: 0.987755]\n",
      "epoch:4 step:4661 [D loss: 0.689517, acc.: 52.34%] [G loss: 0.947336]\n",
      "epoch:4 step:4662 [D loss: 0.661576, acc.: 53.91%] [G loss: 0.998156]\n",
      "epoch:4 step:4663 [D loss: 0.691664, acc.: 53.91%] [G loss: 0.942494]\n",
      "epoch:4 step:4664 [D loss: 0.652033, acc.: 62.50%] [G loss: 0.953450]\n",
      "epoch:4 step:4665 [D loss: 0.632759, acc.: 64.84%] [G loss: 0.881230]\n",
      "epoch:4 step:4666 [D loss: 0.599772, acc.: 67.97%] [G loss: 0.892182]\n",
      "epoch:4 step:4667 [D loss: 0.625623, acc.: 67.97%] [G loss: 0.942772]\n",
      "epoch:4 step:4668 [D loss: 0.730627, acc.: 47.66%] [G loss: 0.895091]\n",
      "epoch:4 step:4669 [D loss: 0.582861, acc.: 73.44%] [G loss: 0.983889]\n",
      "epoch:4 step:4670 [D loss: 0.684152, acc.: 61.72%] [G loss: 0.912021]\n",
      "epoch:4 step:4671 [D loss: 0.635211, acc.: 67.19%] [G loss: 0.930900]\n",
      "epoch:4 step:4672 [D loss: 0.573253, acc.: 74.22%] [G loss: 1.011944]\n",
      "epoch:4 step:4673 [D loss: 0.591835, acc.: 71.09%] [G loss: 0.986393]\n",
      "epoch:4 step:4674 [D loss: 0.598679, acc.: 74.22%] [G loss: 1.026616]\n",
      "epoch:4 step:4675 [D loss: 0.590167, acc.: 69.53%] [G loss: 1.056831]\n",
      "epoch:4 step:4676 [D loss: 0.835653, acc.: 50.78%] [G loss: 1.048200]\n",
      "epoch:4 step:4677 [D loss: 0.640743, acc.: 65.62%] [G loss: 1.166590]\n",
      "epoch:4 step:4678 [D loss: 0.565847, acc.: 73.44%] [G loss: 1.051268]\n",
      "epoch:4 step:4679 [D loss: 0.775434, acc.: 40.62%] [G loss: 0.915105]\n",
      "epoch:4 step:4680 [D loss: 0.699196, acc.: 53.12%] [G loss: 0.916941]\n",
      "epoch:4 step:4681 [D loss: 0.646427, acc.: 60.94%] [G loss: 0.894327]\n",
      "epoch:4 step:4682 [D loss: 0.648956, acc.: 67.19%] [G loss: 0.931445]\n",
      "epoch:4 step:4683 [D loss: 0.589344, acc.: 68.75%] [G loss: 0.993059]\n",
      "epoch:4 step:4684 [D loss: 0.566544, acc.: 72.66%] [G loss: 0.994658]\n",
      "epoch:4 step:4685 [D loss: 0.558736, acc.: 71.88%] [G loss: 1.045681]\n",
      "epoch:5 step:4686 [D loss: 0.660912, acc.: 61.72%] [G loss: 1.000347]\n",
      "epoch:5 step:4687 [D loss: 0.694591, acc.: 54.69%] [G loss: 0.914298]\n",
      "epoch:5 step:4688 [D loss: 0.685379, acc.: 57.81%] [G loss: 0.950426]\n",
      "epoch:5 step:4689 [D loss: 0.650785, acc.: 59.38%] [G loss: 0.942337]\n",
      "epoch:5 step:4690 [D loss: 0.636043, acc.: 64.06%] [G loss: 0.926898]\n",
      "epoch:5 step:4691 [D loss: 0.613819, acc.: 67.97%] [G loss: 0.970003]\n",
      "epoch:5 step:4692 [D loss: 0.591695, acc.: 68.75%] [G loss: 0.958129]\n",
      "epoch:5 step:4693 [D loss: 0.685382, acc.: 52.34%] [G loss: 0.944762]\n",
      "epoch:5 step:4694 [D loss: 0.649876, acc.: 58.59%] [G loss: 0.940302]\n",
      "epoch:5 step:4695 [D loss: 0.639011, acc.: 60.94%] [G loss: 0.967987]\n",
      "epoch:5 step:4696 [D loss: 0.638327, acc.: 63.28%] [G loss: 0.965633]\n",
      "epoch:5 step:4697 [D loss: 0.634522, acc.: 69.53%] [G loss: 0.916865]\n",
      "epoch:5 step:4698 [D loss: 0.621230, acc.: 67.19%] [G loss: 0.872015]\n",
      "epoch:5 step:4699 [D loss: 0.667920, acc.: 53.12%] [G loss: 0.945605]\n",
      "epoch:5 step:4700 [D loss: 0.642676, acc.: 60.94%] [G loss: 0.963561]\n",
      "epoch:5 step:4701 [D loss: 0.593581, acc.: 69.53%] [G loss: 0.936481]\n",
      "epoch:5 step:4702 [D loss: 0.697096, acc.: 53.12%] [G loss: 0.915891]\n",
      "epoch:5 step:4703 [D loss: 0.664978, acc.: 57.81%] [G loss: 0.908833]\n",
      "epoch:5 step:4704 [D loss: 0.667970, acc.: 64.06%] [G loss: 0.895220]\n",
      "epoch:5 step:4705 [D loss: 0.698174, acc.: 53.91%] [G loss: 0.880607]\n",
      "epoch:5 step:4706 [D loss: 0.622424, acc.: 67.97%] [G loss: 0.954890]\n",
      "epoch:5 step:4707 [D loss: 0.593868, acc.: 69.53%] [G loss: 0.956765]\n",
      "epoch:5 step:4708 [D loss: 0.638354, acc.: 66.41%] [G loss: 0.914219]\n",
      "epoch:5 step:4709 [D loss: 0.651839, acc.: 61.72%] [G loss: 0.867914]\n",
      "epoch:5 step:4710 [D loss: 0.687396, acc.: 57.03%] [G loss: 0.854060]\n",
      "epoch:5 step:4711 [D loss: 0.678265, acc.: 59.38%] [G loss: 0.877155]\n",
      "epoch:5 step:4712 [D loss: 0.637057, acc.: 60.94%] [G loss: 0.931580]\n",
      "epoch:5 step:4713 [D loss: 0.615084, acc.: 69.53%] [G loss: 0.865365]\n",
      "epoch:5 step:4714 [D loss: 0.591585, acc.: 71.09%] [G loss: 0.886723]\n",
      "epoch:5 step:4715 [D loss: 0.632795, acc.: 60.94%] [G loss: 0.905864]\n",
      "epoch:5 step:4716 [D loss: 0.610069, acc.: 64.84%] [G loss: 0.939086]\n",
      "epoch:5 step:4717 [D loss: 0.618366, acc.: 64.06%] [G loss: 0.842618]\n",
      "epoch:5 step:4718 [D loss: 0.620064, acc.: 64.06%] [G loss: 0.935047]\n",
      "epoch:5 step:4719 [D loss: 0.649349, acc.: 60.94%] [G loss: 0.852373]\n",
      "epoch:5 step:4720 [D loss: 0.640886, acc.: 60.94%] [G loss: 0.950073]\n",
      "epoch:5 step:4721 [D loss: 0.590193, acc.: 67.19%] [G loss: 0.939105]\n",
      "epoch:5 step:4722 [D loss: 0.686890, acc.: 52.34%] [G loss: 0.892596]\n",
      "epoch:5 step:4723 [D loss: 0.681948, acc.: 57.03%] [G loss: 0.910260]\n",
      "epoch:5 step:4724 [D loss: 0.619180, acc.: 66.41%] [G loss: 0.910345]\n",
      "epoch:5 step:4725 [D loss: 0.597258, acc.: 68.75%] [G loss: 0.961036]\n",
      "epoch:5 step:4726 [D loss: 0.639925, acc.: 67.19%] [G loss: 0.932855]\n",
      "epoch:5 step:4727 [D loss: 0.649563, acc.: 63.28%] [G loss: 0.946096]\n",
      "epoch:5 step:4728 [D loss: 0.618877, acc.: 70.31%] [G loss: 0.965996]\n",
      "epoch:5 step:4729 [D loss: 0.668021, acc.: 59.38%] [G loss: 0.916679]\n",
      "epoch:5 step:4730 [D loss: 0.673563, acc.: 60.16%] [G loss: 0.847631]\n",
      "epoch:5 step:4731 [D loss: 0.615494, acc.: 62.50%] [G loss: 0.940804]\n",
      "epoch:5 step:4732 [D loss: 0.615918, acc.: 68.75%] [G loss: 0.910459]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4733 [D loss: 0.623770, acc.: 62.50%] [G loss: 0.902783]\n",
      "epoch:5 step:4734 [D loss: 0.671036, acc.: 59.38%] [G loss: 0.931108]\n",
      "epoch:5 step:4735 [D loss: 0.645084, acc.: 62.50%] [G loss: 0.952706]\n",
      "epoch:5 step:4736 [D loss: 0.677326, acc.: 62.50%] [G loss: 0.880138]\n",
      "epoch:5 step:4737 [D loss: 0.649585, acc.: 60.94%] [G loss: 0.906218]\n",
      "epoch:5 step:4738 [D loss: 0.614818, acc.: 65.62%] [G loss: 0.962143]\n",
      "epoch:5 step:4739 [D loss: 0.623700, acc.: 64.84%] [G loss: 0.955745]\n",
      "epoch:5 step:4740 [D loss: 0.606377, acc.: 67.19%] [G loss: 0.934470]\n",
      "epoch:5 step:4741 [D loss: 0.666771, acc.: 62.50%] [G loss: 1.042627]\n",
      "epoch:5 step:4742 [D loss: 0.687084, acc.: 53.12%] [G loss: 0.972159]\n",
      "epoch:5 step:4743 [D loss: 0.661308, acc.: 55.47%] [G loss: 0.926175]\n",
      "epoch:5 step:4744 [D loss: 0.614762, acc.: 67.19%] [G loss: 0.929177]\n",
      "epoch:5 step:4745 [D loss: 0.644817, acc.: 63.28%] [G loss: 0.931721]\n",
      "epoch:5 step:4746 [D loss: 0.671299, acc.: 60.94%] [G loss: 0.855678]\n",
      "epoch:5 step:4747 [D loss: 0.663320, acc.: 58.59%] [G loss: 0.899588]\n",
      "epoch:5 step:4748 [D loss: 0.663785, acc.: 60.16%] [G loss: 0.899007]\n",
      "epoch:5 step:4749 [D loss: 0.675155, acc.: 56.25%] [G loss: 0.849999]\n",
      "epoch:5 step:4750 [D loss: 0.671962, acc.: 55.47%] [G loss: 0.861321]\n",
      "epoch:5 step:4751 [D loss: 0.663665, acc.: 61.72%] [G loss: 0.924456]\n",
      "epoch:5 step:4752 [D loss: 0.661917, acc.: 65.62%] [G loss: 0.894878]\n",
      "epoch:5 step:4753 [D loss: 0.647200, acc.: 64.84%] [G loss: 0.899511]\n",
      "epoch:5 step:4754 [D loss: 0.642058, acc.: 64.84%] [G loss: 0.897509]\n",
      "epoch:5 step:4755 [D loss: 0.630563, acc.: 67.97%] [G loss: 0.900835]\n",
      "epoch:5 step:4756 [D loss: 0.636379, acc.: 61.72%] [G loss: 0.937413]\n",
      "epoch:5 step:4757 [D loss: 0.616189, acc.: 67.97%] [G loss: 0.917062]\n",
      "epoch:5 step:4758 [D loss: 0.656607, acc.: 61.72%] [G loss: 0.855599]\n",
      "epoch:5 step:4759 [D loss: 0.603999, acc.: 69.53%] [G loss: 0.829091]\n",
      "epoch:5 step:4760 [D loss: 0.627926, acc.: 62.50%] [G loss: 0.901628]\n",
      "epoch:5 step:4761 [D loss: 0.604435, acc.: 68.75%] [G loss: 0.962005]\n",
      "epoch:5 step:4762 [D loss: 0.550153, acc.: 71.88%] [G loss: 1.009254]\n",
      "epoch:5 step:4763 [D loss: 0.741476, acc.: 53.12%] [G loss: 0.865069]\n",
      "epoch:5 step:4764 [D loss: 0.662655, acc.: 64.84%] [G loss: 0.873468]\n",
      "epoch:5 step:4765 [D loss: 0.690651, acc.: 58.59%] [G loss: 0.882706]\n",
      "epoch:5 step:4766 [D loss: 0.693040, acc.: 56.25%] [G loss: 0.895082]\n",
      "epoch:5 step:4767 [D loss: 0.633618, acc.: 62.50%] [G loss: 0.842866]\n",
      "epoch:5 step:4768 [D loss: 0.613471, acc.: 66.41%] [G loss: 0.914548]\n",
      "epoch:5 step:4769 [D loss: 0.621744, acc.: 67.97%] [G loss: 0.885754]\n",
      "epoch:5 step:4770 [D loss: 0.672724, acc.: 60.94%] [G loss: 0.907145]\n",
      "epoch:5 step:4771 [D loss: 0.611985, acc.: 70.31%] [G loss: 0.869945]\n",
      "epoch:5 step:4772 [D loss: 0.633025, acc.: 65.62%] [G loss: 0.874130]\n",
      "epoch:5 step:4773 [D loss: 0.656299, acc.: 66.41%] [G loss: 0.874840]\n",
      "epoch:5 step:4774 [D loss: 0.621573, acc.: 70.31%] [G loss: 0.835362]\n",
      "epoch:5 step:4775 [D loss: 0.639435, acc.: 60.16%] [G loss: 0.905011]\n",
      "epoch:5 step:4776 [D loss: 0.646536, acc.: 62.50%] [G loss: 0.848776]\n",
      "epoch:5 step:4777 [D loss: 0.630395, acc.: 63.28%] [G loss: 0.901521]\n",
      "epoch:5 step:4778 [D loss: 0.633685, acc.: 63.28%] [G loss: 0.950540]\n",
      "epoch:5 step:4779 [D loss: 0.656556, acc.: 63.28%] [G loss: 0.899850]\n",
      "epoch:5 step:4780 [D loss: 0.611250, acc.: 61.72%] [G loss: 0.921553]\n",
      "epoch:5 step:4781 [D loss: 0.630526, acc.: 64.84%] [G loss: 0.845635]\n",
      "epoch:5 step:4782 [D loss: 0.600299, acc.: 67.97%] [G loss: 0.942756]\n",
      "epoch:5 step:4783 [D loss: 0.647196, acc.: 63.28%] [G loss: 0.870332]\n",
      "epoch:5 step:4784 [D loss: 0.670037, acc.: 57.03%] [G loss: 1.020773]\n",
      "epoch:5 step:4785 [D loss: 0.604946, acc.: 70.31%] [G loss: 0.978861]\n",
      "epoch:5 step:4786 [D loss: 0.619332, acc.: 64.06%] [G loss: 0.940510]\n",
      "epoch:5 step:4787 [D loss: 0.666399, acc.: 62.50%] [G loss: 0.922248]\n",
      "epoch:5 step:4788 [D loss: 0.614006, acc.: 67.97%] [G loss: 0.928096]\n",
      "epoch:5 step:4789 [D loss: 0.668282, acc.: 61.72%] [G loss: 0.945361]\n",
      "epoch:5 step:4790 [D loss: 0.685083, acc.: 56.25%] [G loss: 0.910322]\n",
      "epoch:5 step:4791 [D loss: 0.613343, acc.: 72.66%] [G loss: 0.921915]\n",
      "epoch:5 step:4792 [D loss: 0.629325, acc.: 66.41%] [G loss: 0.974136]\n",
      "epoch:5 step:4793 [D loss: 0.720374, acc.: 54.69%] [G loss: 0.947390]\n",
      "epoch:5 step:4794 [D loss: 0.640270, acc.: 63.28%] [G loss: 0.954121]\n",
      "epoch:5 step:4795 [D loss: 0.621932, acc.: 65.62%] [G loss: 0.912505]\n",
      "epoch:5 step:4796 [D loss: 0.613320, acc.: 67.19%] [G loss: 0.932673]\n",
      "epoch:5 step:4797 [D loss: 0.602848, acc.: 75.00%] [G loss: 0.930046]\n",
      "epoch:5 step:4798 [D loss: 0.622699, acc.: 70.31%] [G loss: 0.934538]\n",
      "epoch:5 step:4799 [D loss: 0.672210, acc.: 62.50%] [G loss: 0.991504]\n",
      "epoch:5 step:4800 [D loss: 0.628345, acc.: 60.16%] [G loss: 1.007139]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.020505\n",
      "FID: 22.669449\n",
      "0 = 12.188899365949693\n",
      "1 = 0.06906289078960066\n",
      "2 = 0.9571999907493591\n",
      "3 = 0.9171000123023987\n",
      "4 = 0.9973000288009644\n",
      "5 = 0.9970645904541016\n",
      "6 = 0.9171000123023987\n",
      "7 = 7.652273592066756\n",
      "8 = 0.10245706822153484\n",
      "9 = 0.8095499873161316\n",
      "10 = 0.7730000019073486\n",
      "11 = 0.8460999727249146\n",
      "12 = 0.8339626789093018\n",
      "13 = 0.7730000019073486\n",
      "14 = 7.020568370819092\n",
      "15 = 9.601847648620605\n",
      "16 = 0.1205240935087204\n",
      "17 = 7.020505428314209\n",
      "18 = 22.669448852539062\n",
      "epoch:5 step:4801 [D loss: 0.632090, acc.: 64.84%] [G loss: 0.998526]\n",
      "epoch:5 step:4802 [D loss: 0.645072, acc.: 63.28%] [G loss: 0.991313]\n",
      "epoch:5 step:4803 [D loss: 0.640666, acc.: 64.06%] [G loss: 0.941953]\n",
      "epoch:5 step:4804 [D loss: 0.638621, acc.: 66.41%] [G loss: 1.018533]\n",
      "epoch:5 step:4805 [D loss: 0.721655, acc.: 57.03%] [G loss: 0.899085]\n",
      "epoch:5 step:4806 [D loss: 0.692758, acc.: 56.25%] [G loss: 0.912591]\n",
      "epoch:5 step:4807 [D loss: 0.614246, acc.: 67.19%] [G loss: 0.917474]\n",
      "epoch:5 step:4808 [D loss: 0.622578, acc.: 65.62%] [G loss: 0.988956]\n",
      "epoch:5 step:4809 [D loss: 0.647565, acc.: 59.38%] [G loss: 0.943521]\n",
      "epoch:5 step:4810 [D loss: 0.680694, acc.: 60.94%] [G loss: 0.883061]\n",
      "epoch:5 step:4811 [D loss: 0.620881, acc.: 69.53%] [G loss: 0.930275]\n",
      "epoch:5 step:4812 [D loss: 0.668047, acc.: 64.06%] [G loss: 0.899361]\n",
      "epoch:5 step:4813 [D loss: 0.649901, acc.: 60.16%] [G loss: 0.862465]\n",
      "epoch:5 step:4814 [D loss: 0.668736, acc.: 55.47%] [G loss: 0.879037]\n",
      "epoch:5 step:4815 [D loss: 0.647611, acc.: 60.94%] [G loss: 0.890934]\n",
      "epoch:5 step:4816 [D loss: 0.642366, acc.: 63.28%] [G loss: 0.891635]\n",
      "epoch:5 step:4817 [D loss: 0.654395, acc.: 60.94%] [G loss: 0.883518]\n",
      "epoch:5 step:4818 [D loss: 0.684081, acc.: 63.28%] [G loss: 0.931796]\n",
      "epoch:5 step:4819 [D loss: 0.612809, acc.: 64.84%] [G loss: 0.939975]\n",
      "epoch:5 step:4820 [D loss: 0.620715, acc.: 63.28%] [G loss: 0.956791]\n",
      "epoch:5 step:4821 [D loss: 0.648773, acc.: 60.16%] [G loss: 0.911933]\n",
      "epoch:5 step:4822 [D loss: 0.721285, acc.: 50.00%] [G loss: 0.821522]\n",
      "epoch:5 step:4823 [D loss: 0.681699, acc.: 52.34%] [G loss: 0.875640]\n",
      "epoch:5 step:4824 [D loss: 0.692382, acc.: 57.03%] [G loss: 0.851431]\n",
      "epoch:5 step:4825 [D loss: 0.667698, acc.: 58.59%] [G loss: 0.877928]\n",
      "epoch:5 step:4826 [D loss: 0.639070, acc.: 68.75%] [G loss: 0.878599]\n",
      "epoch:5 step:4827 [D loss: 0.687246, acc.: 55.47%] [G loss: 0.885636]\n",
      "epoch:5 step:4828 [D loss: 0.661454, acc.: 60.94%] [G loss: 0.835414]\n",
      "epoch:5 step:4829 [D loss: 0.611999, acc.: 68.75%] [G loss: 0.924749]\n",
      "epoch:5 step:4830 [D loss: 0.619173, acc.: 67.97%] [G loss: 1.002207]\n",
      "epoch:5 step:4831 [D loss: 0.653512, acc.: 58.59%] [G loss: 0.945904]\n",
      "epoch:5 step:4832 [D loss: 0.678435, acc.: 55.47%] [G loss: 0.914353]\n",
      "epoch:5 step:4833 [D loss: 0.690800, acc.: 51.56%] [G loss: 0.864778]\n",
      "epoch:5 step:4834 [D loss: 0.593578, acc.: 72.66%] [G loss: 0.914465]\n",
      "epoch:5 step:4835 [D loss: 0.720772, acc.: 48.44%] [G loss: 0.886090]\n",
      "epoch:5 step:4836 [D loss: 0.632673, acc.: 63.28%] [G loss: 0.887418]\n",
      "epoch:5 step:4837 [D loss: 0.640262, acc.: 64.84%] [G loss: 0.940013]\n",
      "epoch:5 step:4838 [D loss: 0.679765, acc.: 56.25%] [G loss: 0.927299]\n",
      "epoch:5 step:4839 [D loss: 0.681476, acc.: 52.34%] [G loss: 0.926772]\n",
      "epoch:5 step:4840 [D loss: 0.625525, acc.: 66.41%] [G loss: 0.961779]\n",
      "epoch:5 step:4841 [D loss: 0.611421, acc.: 69.53%] [G loss: 0.937919]\n",
      "epoch:5 step:4842 [D loss: 0.627058, acc.: 64.84%] [G loss: 0.941575]\n",
      "epoch:5 step:4843 [D loss: 0.672056, acc.: 59.38%] [G loss: 0.923373]\n",
      "epoch:5 step:4844 [D loss: 0.625322, acc.: 61.72%] [G loss: 0.928967]\n",
      "epoch:5 step:4845 [D loss: 0.705724, acc.: 55.47%] [G loss: 0.827956]\n",
      "epoch:5 step:4846 [D loss: 0.633637, acc.: 65.62%] [G loss: 0.922478]\n",
      "epoch:5 step:4847 [D loss: 0.639832, acc.: 57.03%] [G loss: 0.953586]\n",
      "epoch:5 step:4848 [D loss: 0.601788, acc.: 69.53%] [G loss: 0.887849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4849 [D loss: 0.637389, acc.: 62.50%] [G loss: 0.904458]\n",
      "epoch:5 step:4850 [D loss: 0.596518, acc.: 68.75%] [G loss: 0.886076]\n",
      "epoch:5 step:4851 [D loss: 0.622738, acc.: 67.97%] [G loss: 0.880574]\n",
      "epoch:5 step:4852 [D loss: 0.637459, acc.: 64.84%] [G loss: 0.870951]\n",
      "epoch:5 step:4853 [D loss: 0.629051, acc.: 68.75%] [G loss: 0.867194]\n",
      "epoch:5 step:4854 [D loss: 0.682804, acc.: 57.81%] [G loss: 0.898845]\n",
      "epoch:5 step:4855 [D loss: 0.660800, acc.: 57.03%] [G loss: 0.889313]\n",
      "epoch:5 step:4856 [D loss: 0.607719, acc.: 66.41%] [G loss: 0.890292]\n",
      "epoch:5 step:4857 [D loss: 0.693016, acc.: 53.91%] [G loss: 0.887242]\n",
      "epoch:5 step:4858 [D loss: 0.622476, acc.: 64.06%] [G loss: 0.962139]\n",
      "epoch:5 step:4859 [D loss: 0.657980, acc.: 57.03%] [G loss: 0.927358]\n",
      "epoch:5 step:4860 [D loss: 0.651140, acc.: 62.50%] [G loss: 0.905813]\n",
      "epoch:5 step:4861 [D loss: 0.682067, acc.: 55.47%] [G loss: 0.817754]\n",
      "epoch:5 step:4862 [D loss: 0.613333, acc.: 67.19%] [G loss: 0.860597]\n",
      "epoch:5 step:4863 [D loss: 0.654831, acc.: 60.94%] [G loss: 0.861853]\n",
      "epoch:5 step:4864 [D loss: 0.672162, acc.: 61.72%] [G loss: 0.836281]\n",
      "epoch:5 step:4865 [D loss: 0.660111, acc.: 65.62%] [G loss: 0.837505]\n",
      "epoch:5 step:4866 [D loss: 0.709419, acc.: 52.34%] [G loss: 0.840610]\n",
      "epoch:5 step:4867 [D loss: 0.706573, acc.: 51.56%] [G loss: 0.850232]\n",
      "epoch:5 step:4868 [D loss: 0.672062, acc.: 57.81%] [G loss: 0.927064]\n",
      "epoch:5 step:4869 [D loss: 0.699580, acc.: 56.25%] [G loss: 0.901487]\n",
      "epoch:5 step:4870 [D loss: 0.662863, acc.: 60.16%] [G loss: 0.884138]\n",
      "epoch:5 step:4871 [D loss: 0.654854, acc.: 63.28%] [G loss: 0.904653]\n",
      "epoch:5 step:4872 [D loss: 0.640890, acc.: 62.50%] [G loss: 0.940579]\n",
      "epoch:5 step:4873 [D loss: 0.730722, acc.: 48.44%] [G loss: 0.848694]\n",
      "epoch:5 step:4874 [D loss: 0.657806, acc.: 57.03%] [G loss: 0.825516]\n",
      "epoch:5 step:4875 [D loss: 0.633035, acc.: 64.06%] [G loss: 0.890885]\n",
      "epoch:5 step:4876 [D loss: 0.616218, acc.: 67.19%] [G loss: 0.923985]\n",
      "epoch:5 step:4877 [D loss: 0.645941, acc.: 63.28%] [G loss: 0.890065]\n",
      "epoch:5 step:4878 [D loss: 0.653352, acc.: 63.28%] [G loss: 0.922208]\n",
      "epoch:5 step:4879 [D loss: 0.608383, acc.: 66.41%] [G loss: 0.853963]\n",
      "epoch:5 step:4880 [D loss: 0.665316, acc.: 62.50%] [G loss: 0.901717]\n",
      "epoch:5 step:4881 [D loss: 0.675540, acc.: 60.94%] [G loss: 0.857885]\n",
      "epoch:5 step:4882 [D loss: 0.620584, acc.: 67.97%] [G loss: 0.928839]\n",
      "epoch:5 step:4883 [D loss: 0.660500, acc.: 58.59%] [G loss: 0.947667]\n",
      "epoch:5 step:4884 [D loss: 0.627018, acc.: 69.53%] [G loss: 0.933017]\n",
      "epoch:5 step:4885 [D loss: 0.692012, acc.: 55.47%] [G loss: 0.906191]\n",
      "epoch:5 step:4886 [D loss: 0.659112, acc.: 60.94%] [G loss: 0.906572]\n",
      "epoch:5 step:4887 [D loss: 0.662393, acc.: 59.38%] [G loss: 0.925281]\n",
      "epoch:5 step:4888 [D loss: 0.715648, acc.: 55.47%] [G loss: 0.783179]\n",
      "epoch:5 step:4889 [D loss: 0.630404, acc.: 64.84%] [G loss: 0.849629]\n",
      "epoch:5 step:4890 [D loss: 0.644924, acc.: 59.38%] [G loss: 0.935528]\n",
      "epoch:5 step:4891 [D loss: 0.579070, acc.: 75.00%] [G loss: 0.938730]\n",
      "epoch:5 step:4892 [D loss: 0.579109, acc.: 71.88%] [G loss: 0.926945]\n",
      "epoch:5 step:4893 [D loss: 0.575107, acc.: 71.88%] [G loss: 0.934851]\n",
      "epoch:5 step:4894 [D loss: 0.630454, acc.: 64.84%] [G loss: 0.959811]\n",
      "epoch:5 step:4895 [D loss: 0.733634, acc.: 53.12%] [G loss: 0.927338]\n",
      "epoch:5 step:4896 [D loss: 0.694546, acc.: 53.91%] [G loss: 0.870149]\n",
      "epoch:5 step:4897 [D loss: 0.716871, acc.: 57.81%] [G loss: 0.832723]\n",
      "epoch:5 step:4898 [D loss: 0.662475, acc.: 60.16%] [G loss: 0.874485]\n",
      "epoch:5 step:4899 [D loss: 0.698735, acc.: 57.03%] [G loss: 0.866349]\n",
      "epoch:5 step:4900 [D loss: 0.689335, acc.: 56.25%] [G loss: 0.819317]\n",
      "epoch:5 step:4901 [D loss: 0.672755, acc.: 59.38%] [G loss: 0.903788]\n",
      "epoch:5 step:4902 [D loss: 0.637794, acc.: 63.28%] [G loss: 0.904097]\n",
      "epoch:5 step:4903 [D loss: 0.642603, acc.: 63.28%] [G loss: 0.873282]\n",
      "epoch:5 step:4904 [D loss: 0.604604, acc.: 68.75%] [G loss: 0.899511]\n",
      "epoch:5 step:4905 [D loss: 0.724075, acc.: 51.56%] [G loss: 0.872293]\n",
      "epoch:5 step:4906 [D loss: 0.646092, acc.: 66.41%] [G loss: 0.988441]\n",
      "epoch:5 step:4907 [D loss: 0.562484, acc.: 71.09%] [G loss: 1.005358]\n",
      "epoch:5 step:4908 [D loss: 0.581587, acc.: 68.75%] [G loss: 1.032385]\n",
      "epoch:5 step:4909 [D loss: 0.744978, acc.: 56.25%] [G loss: 0.941267]\n",
      "epoch:5 step:4910 [D loss: 0.675515, acc.: 60.16%] [G loss: 0.819226]\n",
      "epoch:5 step:4911 [D loss: 0.671207, acc.: 55.47%] [G loss: 0.867960]\n",
      "epoch:5 step:4912 [D loss: 0.652790, acc.: 63.28%] [G loss: 0.873134]\n",
      "epoch:5 step:4913 [D loss: 0.664807, acc.: 57.03%] [G loss: 0.797614]\n",
      "epoch:5 step:4914 [D loss: 0.638080, acc.: 65.62%] [G loss: 0.854174]\n",
      "epoch:5 step:4915 [D loss: 0.616887, acc.: 66.41%] [G loss: 0.930777]\n",
      "epoch:5 step:4916 [D loss: 0.611583, acc.: 62.50%] [G loss: 0.932343]\n",
      "epoch:5 step:4917 [D loss: 0.586344, acc.: 65.62%] [G loss: 1.001513]\n",
      "epoch:5 step:4918 [D loss: 0.669209, acc.: 62.50%] [G loss: 0.890863]\n",
      "epoch:5 step:4919 [D loss: 0.670128, acc.: 64.84%] [G loss: 0.879683]\n",
      "epoch:5 step:4920 [D loss: 0.668352, acc.: 51.56%] [G loss: 0.932960]\n",
      "epoch:5 step:4921 [D loss: 0.645595, acc.: 62.50%] [G loss: 0.886648]\n",
      "epoch:5 step:4922 [D loss: 0.682495, acc.: 57.03%] [G loss: 0.937064]\n",
      "epoch:5 step:4923 [D loss: 0.639706, acc.: 64.84%] [G loss: 0.917371]\n",
      "epoch:5 step:4924 [D loss: 0.639025, acc.: 65.62%] [G loss: 0.911870]\n",
      "epoch:5 step:4925 [D loss: 0.619722, acc.: 68.75%] [G loss: 0.926442]\n",
      "epoch:5 step:4926 [D loss: 0.651182, acc.: 58.59%] [G loss: 0.946305]\n",
      "epoch:5 step:4927 [D loss: 0.634811, acc.: 62.50%] [G loss: 0.891060]\n",
      "epoch:5 step:4928 [D loss: 0.625348, acc.: 67.19%] [G loss: 0.949198]\n",
      "epoch:5 step:4929 [D loss: 0.622712, acc.: 67.19%] [G loss: 0.917977]\n",
      "epoch:5 step:4930 [D loss: 0.576718, acc.: 67.97%] [G loss: 0.970958]\n",
      "epoch:5 step:4931 [D loss: 0.665232, acc.: 57.03%] [G loss: 0.951123]\n",
      "epoch:5 step:4932 [D loss: 0.636260, acc.: 67.19%] [G loss: 0.913730]\n",
      "epoch:5 step:4933 [D loss: 0.678307, acc.: 60.16%] [G loss: 0.856389]\n",
      "epoch:5 step:4934 [D loss: 0.694618, acc.: 51.56%] [G loss: 0.917940]\n",
      "epoch:5 step:4935 [D loss: 0.699171, acc.: 57.81%] [G loss: 0.853048]\n",
      "epoch:5 step:4936 [D loss: 0.673067, acc.: 62.50%] [G loss: 0.828628]\n",
      "epoch:5 step:4937 [D loss: 0.663843, acc.: 60.94%] [G loss: 0.914280]\n",
      "epoch:5 step:4938 [D loss: 0.624038, acc.: 66.41%] [G loss: 0.895510]\n",
      "epoch:5 step:4939 [D loss: 0.614108, acc.: 66.41%] [G loss: 0.959628]\n",
      "epoch:5 step:4940 [D loss: 0.624056, acc.: 65.62%] [G loss: 0.924942]\n",
      "epoch:5 step:4941 [D loss: 0.605755, acc.: 70.31%] [G loss: 0.965810]\n",
      "epoch:5 step:4942 [D loss: 0.651681, acc.: 61.72%] [G loss: 0.877725]\n",
      "epoch:5 step:4943 [D loss: 0.644174, acc.: 62.50%] [G loss: 0.905795]\n",
      "epoch:5 step:4944 [D loss: 0.641978, acc.: 66.41%] [G loss: 0.941011]\n",
      "epoch:5 step:4945 [D loss: 0.638267, acc.: 63.28%] [G loss: 0.916705]\n",
      "epoch:5 step:4946 [D loss: 0.645734, acc.: 56.25%] [G loss: 0.887206]\n",
      "epoch:5 step:4947 [D loss: 0.615231, acc.: 63.28%] [G loss: 0.913942]\n",
      "epoch:5 step:4948 [D loss: 0.688475, acc.: 55.47%] [G loss: 0.914111]\n",
      "epoch:5 step:4949 [D loss: 0.596751, acc.: 75.78%] [G loss: 0.890137]\n",
      "epoch:5 step:4950 [D loss: 0.732367, acc.: 54.69%] [G loss: 0.876890]\n",
      "epoch:5 step:4951 [D loss: 0.686982, acc.: 53.91%] [G loss: 0.871646]\n",
      "epoch:5 step:4952 [D loss: 0.677795, acc.: 54.69%] [G loss: 0.945807]\n",
      "epoch:5 step:4953 [D loss: 0.665333, acc.: 61.72%] [G loss: 0.933318]\n",
      "epoch:5 step:4954 [D loss: 0.648743, acc.: 64.06%] [G loss: 0.975361]\n",
      "epoch:5 step:4955 [D loss: 0.655188, acc.: 60.16%] [G loss: 0.949283]\n",
      "epoch:5 step:4956 [D loss: 0.580478, acc.: 72.66%] [G loss: 0.894959]\n",
      "epoch:5 step:4957 [D loss: 0.678651, acc.: 55.47%] [G loss: 0.936161]\n",
      "epoch:5 step:4958 [D loss: 0.662087, acc.: 59.38%] [G loss: 0.955701]\n",
      "epoch:5 step:4959 [D loss: 0.654766, acc.: 64.06%] [G loss: 0.857308]\n",
      "epoch:5 step:4960 [D loss: 0.656432, acc.: 64.06%] [G loss: 0.924493]\n",
      "epoch:5 step:4961 [D loss: 0.656153, acc.: 64.06%] [G loss: 0.889451]\n",
      "epoch:5 step:4962 [D loss: 0.697125, acc.: 53.12%] [G loss: 0.898634]\n",
      "epoch:5 step:4963 [D loss: 0.635258, acc.: 66.41%] [G loss: 0.912696]\n",
      "epoch:5 step:4964 [D loss: 0.671591, acc.: 58.59%] [G loss: 1.018369]\n",
      "epoch:5 step:4965 [D loss: 0.636223, acc.: 61.72%] [G loss: 0.916589]\n",
      "epoch:5 step:4966 [D loss: 0.699748, acc.: 61.72%] [G loss: 0.861453]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4967 [D loss: 0.682856, acc.: 60.16%] [G loss: 0.846047]\n",
      "epoch:5 step:4968 [D loss: 0.640104, acc.: 64.84%] [G loss: 0.872623]\n",
      "epoch:5 step:4969 [D loss: 0.628565, acc.: 69.53%] [G loss: 0.890560]\n",
      "epoch:5 step:4970 [D loss: 0.584039, acc.: 68.75%] [G loss: 0.859657]\n",
      "epoch:5 step:4971 [D loss: 0.566912, acc.: 75.78%] [G loss: 0.962622]\n",
      "epoch:5 step:4972 [D loss: 0.669399, acc.: 59.38%] [G loss: 0.894564]\n",
      "epoch:5 step:4973 [D loss: 0.647658, acc.: 63.28%] [G loss: 0.887163]\n",
      "epoch:5 step:4974 [D loss: 0.599793, acc.: 66.41%] [G loss: 0.929730]\n",
      "epoch:5 step:4975 [D loss: 0.651344, acc.: 63.28%] [G loss: 0.962989]\n",
      "epoch:5 step:4976 [D loss: 0.692414, acc.: 58.59%] [G loss: 0.924604]\n",
      "epoch:5 step:4977 [D loss: 0.696081, acc.: 57.81%] [G loss: 0.904702]\n",
      "epoch:5 step:4978 [D loss: 0.625584, acc.: 64.06%] [G loss: 0.947136]\n",
      "epoch:5 step:4979 [D loss: 0.679521, acc.: 60.16%] [G loss: 0.894328]\n",
      "epoch:5 step:4980 [D loss: 0.641789, acc.: 62.50%] [G loss: 0.898018]\n",
      "epoch:5 step:4981 [D loss: 0.616479, acc.: 64.06%] [G loss: 0.869880]\n",
      "epoch:5 step:4982 [D loss: 0.632743, acc.: 63.28%] [G loss: 0.866451]\n",
      "epoch:5 step:4983 [D loss: 0.644721, acc.: 61.72%] [G loss: 0.890390]\n",
      "epoch:5 step:4984 [D loss: 0.608687, acc.: 67.97%] [G loss: 0.874973]\n",
      "epoch:5 step:4985 [D loss: 0.642188, acc.: 71.88%] [G loss: 0.934502]\n",
      "epoch:5 step:4986 [D loss: 0.707901, acc.: 50.78%] [G loss: 0.943903]\n",
      "epoch:5 step:4987 [D loss: 0.668793, acc.: 62.50%] [G loss: 0.905297]\n",
      "epoch:5 step:4988 [D loss: 0.608034, acc.: 67.19%] [G loss: 0.879869]\n",
      "epoch:5 step:4989 [D loss: 0.639434, acc.: 70.31%] [G loss: 0.866835]\n",
      "epoch:5 step:4990 [D loss: 0.630251, acc.: 64.84%] [G loss: 0.943047]\n",
      "epoch:5 step:4991 [D loss: 0.657582, acc.: 56.25%] [G loss: 0.936374]\n",
      "epoch:5 step:4992 [D loss: 0.628829, acc.: 64.06%] [G loss: 0.898791]\n",
      "epoch:5 step:4993 [D loss: 0.655738, acc.: 63.28%] [G loss: 0.813823]\n",
      "epoch:5 step:4994 [D loss: 0.619227, acc.: 63.28%] [G loss: 0.957415]\n",
      "epoch:5 step:4995 [D loss: 0.596485, acc.: 75.00%] [G loss: 0.938788]\n",
      "epoch:5 step:4996 [D loss: 0.616346, acc.: 65.62%] [G loss: 0.971131]\n",
      "epoch:5 step:4997 [D loss: 0.571615, acc.: 71.88%] [G loss: 0.999932]\n",
      "epoch:5 step:4998 [D loss: 0.607244, acc.: 71.88%] [G loss: 1.009481]\n",
      "epoch:5 step:4999 [D loss: 0.622041, acc.: 61.72%] [G loss: 0.982196]\n",
      "epoch:5 step:5000 [D loss: 0.592226, acc.: 66.41%] [G loss: 0.992034]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.243155\n",
      "FID: 19.280447\n",
      "0 = 12.289494590258652\n",
      "1 = 0.07131330522087641\n",
      "2 = 0.9517999887466431\n",
      "3 = 0.906499981880188\n",
      "4 = 0.9970999956130981\n",
      "5 = 0.9968110918998718\n",
      "6 = 0.906499981880188\n",
      "7 = 7.272354810512064\n",
      "8 = 0.09393927223630238\n",
      "9 = 0.7947999835014343\n",
      "10 = 0.761900007724762\n",
      "11 = 0.8277000188827515\n",
      "12 = 0.8155640959739685\n",
      "13 = 0.761900007724762\n",
      "14 = 7.243215560913086\n",
      "15 = 9.606756210327148\n",
      "16 = 0.10864599794149399\n",
      "17 = 7.243154525756836\n",
      "18 = 19.280447006225586\n",
      "epoch:5 step:5001 [D loss: 0.796896, acc.: 41.41%] [G loss: 0.947212]\n",
      "epoch:5 step:5002 [D loss: 0.623573, acc.: 62.50%] [G loss: 0.880334]\n",
      "epoch:5 step:5003 [D loss: 0.603559, acc.: 66.41%] [G loss: 0.931687]\n",
      "epoch:5 step:5004 [D loss: 0.679142, acc.: 53.91%] [G loss: 0.929356]\n",
      "epoch:5 step:5005 [D loss: 0.605075, acc.: 67.97%] [G loss: 0.968233]\n",
      "epoch:5 step:5006 [D loss: 0.569364, acc.: 78.12%] [G loss: 0.948406]\n",
      "epoch:5 step:5007 [D loss: 0.643228, acc.: 60.94%] [G loss: 0.990318]\n",
      "epoch:5 step:5008 [D loss: 0.655927, acc.: 60.16%] [G loss: 0.925233]\n",
      "epoch:5 step:5009 [D loss: 0.642203, acc.: 61.72%] [G loss: 0.938197]\n",
      "epoch:5 step:5010 [D loss: 0.655639, acc.: 62.50%] [G loss: 0.830751]\n",
      "epoch:5 step:5011 [D loss: 0.624100, acc.: 68.75%] [G loss: 0.887407]\n",
      "epoch:5 step:5012 [D loss: 0.636297, acc.: 62.50%] [G loss: 0.882758]\n",
      "epoch:5 step:5013 [D loss: 0.647422, acc.: 57.03%] [G loss: 0.947254]\n",
      "epoch:5 step:5014 [D loss: 0.648567, acc.: 60.94%] [G loss: 0.936508]\n",
      "epoch:5 step:5015 [D loss: 0.647090, acc.: 60.94%] [G loss: 0.906393]\n",
      "epoch:5 step:5016 [D loss: 0.638251, acc.: 64.06%] [G loss: 0.902656]\n",
      "epoch:5 step:5017 [D loss: 0.591926, acc.: 71.88%] [G loss: 0.874220]\n",
      "epoch:5 step:5018 [D loss: 0.606692, acc.: 67.97%] [G loss: 0.902074]\n",
      "epoch:5 step:5019 [D loss: 0.631795, acc.: 62.50%] [G loss: 0.919437]\n",
      "epoch:5 step:5020 [D loss: 0.623401, acc.: 62.50%] [G loss: 0.950019]\n",
      "epoch:5 step:5021 [D loss: 0.615978, acc.: 69.53%] [G loss: 0.909612]\n",
      "epoch:5 step:5022 [D loss: 0.635470, acc.: 64.84%] [G loss: 0.899080]\n",
      "epoch:5 step:5023 [D loss: 0.661673, acc.: 59.38%] [G loss: 0.917040]\n",
      "epoch:5 step:5024 [D loss: 0.616143, acc.: 68.75%] [G loss: 0.895980]\n",
      "epoch:5 step:5025 [D loss: 0.619833, acc.: 68.75%] [G loss: 0.881879]\n",
      "epoch:5 step:5026 [D loss: 0.687749, acc.: 54.69%] [G loss: 0.876467]\n",
      "epoch:5 step:5027 [D loss: 0.680848, acc.: 59.38%] [G loss: 0.854510]\n",
      "epoch:5 step:5028 [D loss: 0.582273, acc.: 67.19%] [G loss: 0.853370]\n",
      "epoch:5 step:5029 [D loss: 0.607185, acc.: 65.62%] [G loss: 0.916455]\n",
      "epoch:5 step:5030 [D loss: 0.617120, acc.: 63.28%] [G loss: 0.920858]\n",
      "epoch:5 step:5031 [D loss: 0.603691, acc.: 64.06%] [G loss: 0.954320]\n",
      "epoch:5 step:5032 [D loss: 0.587041, acc.: 67.97%] [G loss: 0.984976]\n",
      "epoch:5 step:5033 [D loss: 0.724481, acc.: 53.91%] [G loss: 0.914840]\n",
      "epoch:5 step:5034 [D loss: 0.785564, acc.: 44.53%] [G loss: 0.872684]\n",
      "epoch:5 step:5035 [D loss: 0.657540, acc.: 57.81%] [G loss: 0.927330]\n",
      "epoch:5 step:5036 [D loss: 0.665190, acc.: 60.94%] [G loss: 0.949117]\n",
      "epoch:5 step:5037 [D loss: 0.673544, acc.: 64.06%] [G loss: 0.971847]\n",
      "epoch:5 step:5038 [D loss: 0.634522, acc.: 61.72%] [G loss: 0.971448]\n",
      "epoch:5 step:5039 [D loss: 0.590862, acc.: 67.97%] [G loss: 0.997055]\n",
      "epoch:5 step:5040 [D loss: 0.655612, acc.: 56.25%] [G loss: 0.947239]\n",
      "epoch:5 step:5041 [D loss: 0.692481, acc.: 60.16%] [G loss: 0.889338]\n",
      "epoch:5 step:5042 [D loss: 0.684073, acc.: 56.25%] [G loss: 0.842810]\n",
      "epoch:5 step:5043 [D loss: 0.616411, acc.: 64.84%] [G loss: 0.938999]\n",
      "epoch:5 step:5044 [D loss: 0.616387, acc.: 66.41%] [G loss: 0.940562]\n",
      "epoch:5 step:5045 [D loss: 0.573987, acc.: 71.88%] [G loss: 0.914368]\n",
      "epoch:5 step:5046 [D loss: 0.593209, acc.: 66.41%] [G loss: 0.930729]\n",
      "epoch:5 step:5047 [D loss: 0.636741, acc.: 63.28%] [G loss: 0.928862]\n",
      "epoch:5 step:5048 [D loss: 0.642412, acc.: 59.38%] [G loss: 0.876357]\n",
      "epoch:5 step:5049 [D loss: 0.619003, acc.: 60.16%] [G loss: 0.894401]\n",
      "epoch:5 step:5050 [D loss: 0.601074, acc.: 70.31%] [G loss: 0.933935]\n",
      "epoch:5 step:5051 [D loss: 0.655603, acc.: 58.59%] [G loss: 0.890925]\n",
      "epoch:5 step:5052 [D loss: 0.668618, acc.: 58.59%] [G loss: 0.901336]\n",
      "epoch:5 step:5053 [D loss: 0.647288, acc.: 64.06%] [G loss: 0.808310]\n",
      "epoch:5 step:5054 [D loss: 0.702944, acc.: 57.81%] [G loss: 0.839127]\n",
      "epoch:5 step:5055 [D loss: 0.662947, acc.: 56.25%] [G loss: 0.848124]\n",
      "epoch:5 step:5056 [D loss: 0.621999, acc.: 69.53%] [G loss: 0.897470]\n",
      "epoch:5 step:5057 [D loss: 0.674736, acc.: 56.25%] [G loss: 0.953492]\n",
      "epoch:5 step:5058 [D loss: 0.673339, acc.: 58.59%] [G loss: 0.911804]\n",
      "epoch:5 step:5059 [D loss: 0.596019, acc.: 67.19%] [G loss: 0.869082]\n",
      "epoch:5 step:5060 [D loss: 0.691895, acc.: 53.91%] [G loss: 0.898333]\n",
      "epoch:5 step:5061 [D loss: 0.705653, acc.: 48.44%] [G loss: 0.865618]\n",
      "epoch:5 step:5062 [D loss: 0.685446, acc.: 62.50%] [G loss: 0.913447]\n",
      "epoch:5 step:5063 [D loss: 0.621147, acc.: 69.53%] [G loss: 0.875905]\n",
      "epoch:5 step:5064 [D loss: 0.674321, acc.: 57.03%] [G loss: 0.915401]\n",
      "epoch:5 step:5065 [D loss: 0.698842, acc.: 52.34%] [G loss: 0.953267]\n",
      "epoch:5 step:5066 [D loss: 0.606803, acc.: 68.75%] [G loss: 0.918892]\n",
      "epoch:5 step:5067 [D loss: 0.651416, acc.: 62.50%] [G loss: 0.948574]\n",
      "epoch:5 step:5068 [D loss: 0.652359, acc.: 60.94%] [G loss: 0.870994]\n",
      "epoch:5 step:5069 [D loss: 0.649919, acc.: 60.94%] [G loss: 0.886657]\n",
      "epoch:5 step:5070 [D loss: 0.643585, acc.: 65.62%] [G loss: 0.911656]\n",
      "epoch:5 step:5071 [D loss: 0.651284, acc.: 60.16%] [G loss: 0.927702]\n",
      "epoch:5 step:5072 [D loss: 0.636243, acc.: 61.72%] [G loss: 0.894910]\n",
      "epoch:5 step:5073 [D loss: 0.632914, acc.: 66.41%] [G loss: 0.913163]\n",
      "epoch:5 step:5074 [D loss: 0.659364, acc.: 58.59%] [G loss: 0.920396]\n",
      "epoch:5 step:5075 [D loss: 0.705549, acc.: 57.03%] [G loss: 0.903052]\n",
      "epoch:5 step:5076 [D loss: 0.634047, acc.: 68.75%] [G loss: 0.925742]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5077 [D loss: 0.604752, acc.: 73.44%] [G loss: 0.891655]\n",
      "epoch:5 step:5078 [D loss: 0.647632, acc.: 64.06%] [G loss: 0.874305]\n",
      "epoch:5 step:5079 [D loss: 0.650665, acc.: 60.16%] [G loss: 0.887765]\n",
      "epoch:5 step:5080 [D loss: 0.636144, acc.: 60.94%] [G loss: 0.837794]\n",
      "epoch:5 step:5081 [D loss: 0.694159, acc.: 50.78%] [G loss: 0.870297]\n",
      "epoch:5 step:5082 [D loss: 0.617300, acc.: 67.97%] [G loss: 0.880073]\n",
      "epoch:5 step:5083 [D loss: 0.625851, acc.: 64.84%] [G loss: 0.862851]\n",
      "epoch:5 step:5084 [D loss: 0.587089, acc.: 73.44%] [G loss: 0.991436]\n",
      "epoch:5 step:5085 [D loss: 0.717584, acc.: 52.34%] [G loss: 0.886209]\n",
      "epoch:5 step:5086 [D loss: 0.687277, acc.: 52.34%] [G loss: 0.872777]\n",
      "epoch:5 step:5087 [D loss: 0.659816, acc.: 61.72%] [G loss: 0.888544]\n",
      "epoch:5 step:5088 [D loss: 0.650173, acc.: 57.81%] [G loss: 0.840855]\n",
      "epoch:5 step:5089 [D loss: 0.664759, acc.: 59.38%] [G loss: 0.877365]\n",
      "epoch:5 step:5090 [D loss: 0.654568, acc.: 61.72%] [G loss: 0.916704]\n",
      "epoch:5 step:5091 [D loss: 0.617603, acc.: 64.06%] [G loss: 0.936105]\n",
      "epoch:5 step:5092 [D loss: 0.657440, acc.: 60.94%] [G loss: 0.882175]\n",
      "epoch:5 step:5093 [D loss: 0.692329, acc.: 54.69%] [G loss: 0.847543]\n",
      "epoch:5 step:5094 [D loss: 0.654145, acc.: 61.72%] [G loss: 0.883617]\n",
      "epoch:5 step:5095 [D loss: 0.674013, acc.: 57.81%] [G loss: 0.842331]\n",
      "epoch:5 step:5096 [D loss: 0.639073, acc.: 60.94%] [G loss: 0.852183]\n",
      "epoch:5 step:5097 [D loss: 0.667584, acc.: 53.91%] [G loss: 0.978044]\n",
      "epoch:5 step:5098 [D loss: 0.656177, acc.: 60.16%] [G loss: 0.923637]\n",
      "epoch:5 step:5099 [D loss: 0.645189, acc.: 63.28%] [G loss: 0.919199]\n",
      "epoch:5 step:5100 [D loss: 0.613520, acc.: 64.06%] [G loss: 0.931016]\n",
      "epoch:5 step:5101 [D loss: 0.637237, acc.: 64.06%] [G loss: 0.937758]\n",
      "epoch:5 step:5102 [D loss: 0.694805, acc.: 58.59%] [G loss: 0.938538]\n",
      "epoch:5 step:5103 [D loss: 0.733638, acc.: 47.66%] [G loss: 0.894068]\n",
      "epoch:5 step:5104 [D loss: 0.670979, acc.: 60.16%] [G loss: 0.862321]\n",
      "epoch:5 step:5105 [D loss: 0.629361, acc.: 66.41%] [G loss: 0.914557]\n",
      "epoch:5 step:5106 [D loss: 0.674894, acc.: 59.38%] [G loss: 0.870552]\n",
      "epoch:5 step:5107 [D loss: 0.694126, acc.: 55.47%] [G loss: 0.875519]\n",
      "epoch:5 step:5108 [D loss: 0.631279, acc.: 69.53%] [G loss: 0.936720]\n",
      "epoch:5 step:5109 [D loss: 0.691468, acc.: 54.69%] [G loss: 0.864063]\n",
      "epoch:5 step:5110 [D loss: 0.661470, acc.: 60.16%] [G loss: 0.906433]\n",
      "epoch:5 step:5111 [D loss: 0.615314, acc.: 63.28%] [G loss: 0.921570]\n",
      "epoch:5 step:5112 [D loss: 0.598405, acc.: 66.41%] [G loss: 0.930679]\n",
      "epoch:5 step:5113 [D loss: 0.596545, acc.: 66.41%] [G loss: 0.910975]\n",
      "epoch:5 step:5114 [D loss: 0.608622, acc.: 66.41%] [G loss: 0.897006]\n",
      "epoch:5 step:5115 [D loss: 0.618642, acc.: 67.19%] [G loss: 0.923555]\n",
      "epoch:5 step:5116 [D loss: 0.629516, acc.: 66.41%] [G loss: 0.962522]\n",
      "epoch:5 step:5117 [D loss: 0.676152, acc.: 55.47%] [G loss: 0.960110]\n",
      "epoch:5 step:5118 [D loss: 0.680664, acc.: 54.69%] [G loss: 0.886731]\n",
      "epoch:5 step:5119 [D loss: 0.642710, acc.: 64.06%] [G loss: 0.848475]\n",
      "epoch:5 step:5120 [D loss: 0.681351, acc.: 58.59%] [G loss: 0.961455]\n",
      "epoch:5 step:5121 [D loss: 0.646070, acc.: 66.41%] [G loss: 0.970824]\n",
      "epoch:5 step:5122 [D loss: 0.749442, acc.: 49.22%] [G loss: 0.915142]\n",
      "epoch:5 step:5123 [D loss: 0.673965, acc.: 59.38%] [G loss: 0.910021]\n",
      "epoch:5 step:5124 [D loss: 0.628619, acc.: 70.31%] [G loss: 0.868344]\n",
      "epoch:5 step:5125 [D loss: 0.667035, acc.: 53.12%] [G loss: 0.880824]\n",
      "epoch:5 step:5126 [D loss: 0.632617, acc.: 62.50%] [G loss: 0.872707]\n",
      "epoch:5 step:5127 [D loss: 0.669713, acc.: 54.69%] [G loss: 0.868359]\n",
      "epoch:5 step:5128 [D loss: 0.638104, acc.: 63.28%] [G loss: 0.943621]\n",
      "epoch:5 step:5129 [D loss: 0.632882, acc.: 68.75%] [G loss: 0.869772]\n",
      "epoch:5 step:5130 [D loss: 0.632209, acc.: 59.38%] [G loss: 0.904863]\n",
      "epoch:5 step:5131 [D loss: 0.650983, acc.: 65.62%] [G loss: 0.905670]\n",
      "epoch:5 step:5132 [D loss: 0.605031, acc.: 67.19%] [G loss: 0.905407]\n",
      "epoch:5 step:5133 [D loss: 0.656819, acc.: 55.47%] [G loss: 0.885445]\n",
      "epoch:5 step:5134 [D loss: 0.658780, acc.: 60.16%] [G loss: 0.901590]\n",
      "epoch:5 step:5135 [D loss: 0.658945, acc.: 60.16%] [G loss: 0.917497]\n",
      "epoch:5 step:5136 [D loss: 0.608844, acc.: 67.19%] [G loss: 0.915380]\n",
      "epoch:5 step:5137 [D loss: 0.620634, acc.: 67.97%] [G loss: 0.980462]\n",
      "epoch:5 step:5138 [D loss: 0.655464, acc.: 62.50%] [G loss: 0.960246]\n",
      "epoch:5 step:5139 [D loss: 0.652458, acc.: 60.16%] [G loss: 0.921486]\n",
      "epoch:5 step:5140 [D loss: 0.665904, acc.: 58.59%] [G loss: 0.888608]\n",
      "epoch:5 step:5141 [D loss: 0.679221, acc.: 56.25%] [G loss: 0.932618]\n",
      "epoch:5 step:5142 [D loss: 0.624013, acc.: 63.28%] [G loss: 0.932134]\n",
      "epoch:5 step:5143 [D loss: 0.707643, acc.: 51.56%] [G loss: 0.877146]\n",
      "epoch:5 step:5144 [D loss: 0.710099, acc.: 56.25%] [G loss: 0.882098]\n",
      "epoch:5 step:5145 [D loss: 0.663420, acc.: 64.06%] [G loss: 0.890450]\n",
      "epoch:5 step:5146 [D loss: 0.646730, acc.: 57.03%] [G loss: 0.903129]\n",
      "epoch:5 step:5147 [D loss: 0.664566, acc.: 61.72%] [G loss: 0.902179]\n",
      "epoch:5 step:5148 [D loss: 0.640682, acc.: 67.19%] [G loss: 0.837607]\n",
      "epoch:5 step:5149 [D loss: 0.625984, acc.: 66.41%] [G loss: 0.906820]\n",
      "epoch:5 step:5150 [D loss: 0.690839, acc.: 57.81%] [G loss: 0.778855]\n",
      "epoch:5 step:5151 [D loss: 0.646192, acc.: 62.50%] [G loss: 0.872221]\n",
      "epoch:5 step:5152 [D loss: 0.618018, acc.: 65.62%] [G loss: 0.893463]\n",
      "epoch:5 step:5153 [D loss: 0.654261, acc.: 66.41%] [G loss: 0.877724]\n",
      "epoch:5 step:5154 [D loss: 0.603776, acc.: 68.75%] [G loss: 0.967633]\n",
      "epoch:5 step:5155 [D loss: 0.681308, acc.: 54.69%] [G loss: 0.948251]\n",
      "epoch:5 step:5156 [D loss: 0.586669, acc.: 68.75%] [G loss: 1.002300]\n",
      "epoch:5 step:5157 [D loss: 0.588652, acc.: 68.75%] [G loss: 0.977538]\n",
      "epoch:5 step:5158 [D loss: 0.800745, acc.: 41.41%] [G loss: 0.917339]\n",
      "epoch:5 step:5159 [D loss: 0.692881, acc.: 57.03%] [G loss: 0.905086]\n",
      "epoch:5 step:5160 [D loss: 0.610231, acc.: 63.28%] [G loss: 0.958025]\n",
      "epoch:5 step:5161 [D loss: 0.678535, acc.: 58.59%] [G loss: 0.991129]\n",
      "epoch:5 step:5162 [D loss: 0.733042, acc.: 49.22%] [G loss: 0.851432]\n",
      "epoch:5 step:5163 [D loss: 0.703281, acc.: 56.25%] [G loss: 0.877721]\n",
      "epoch:5 step:5164 [D loss: 0.681764, acc.: 55.47%] [G loss: 0.792505]\n",
      "epoch:5 step:5165 [D loss: 0.662012, acc.: 60.94%] [G loss: 0.883823]\n",
      "epoch:5 step:5166 [D loss: 0.604374, acc.: 71.88%] [G loss: 0.868986]\n",
      "epoch:5 step:5167 [D loss: 0.685711, acc.: 61.72%] [G loss: 0.883882]\n",
      "epoch:5 step:5168 [D loss: 0.671414, acc.: 62.50%] [G loss: 0.917714]\n",
      "epoch:5 step:5169 [D loss: 0.636531, acc.: 65.62%] [G loss: 0.905417]\n",
      "epoch:5 step:5170 [D loss: 0.625510, acc.: 65.62%] [G loss: 0.953629]\n",
      "epoch:5 step:5171 [D loss: 0.649940, acc.: 65.62%] [G loss: 0.903053]\n",
      "epoch:5 step:5172 [D loss: 0.656125, acc.: 67.97%] [G loss: 0.810498]\n",
      "epoch:5 step:5173 [D loss: 0.636092, acc.: 64.06%] [G loss: 0.856730]\n",
      "epoch:5 step:5174 [D loss: 0.676007, acc.: 58.59%] [G loss: 0.844893]\n",
      "epoch:5 step:5175 [D loss: 0.671072, acc.: 63.28%] [G loss: 0.868208]\n",
      "epoch:5 step:5176 [D loss: 0.659209, acc.: 58.59%] [G loss: 0.862539]\n",
      "epoch:5 step:5177 [D loss: 0.653010, acc.: 63.28%] [G loss: 0.819621]\n",
      "epoch:5 step:5178 [D loss: 0.621319, acc.: 72.66%] [G loss: 0.862507]\n",
      "epoch:5 step:5179 [D loss: 0.638171, acc.: 67.97%] [G loss: 0.876007]\n",
      "epoch:5 step:5180 [D loss: 0.619514, acc.: 63.28%] [G loss: 0.962653]\n",
      "epoch:5 step:5181 [D loss: 0.680920, acc.: 60.16%] [G loss: 0.900306]\n",
      "epoch:5 step:5182 [D loss: 0.657865, acc.: 59.38%] [G loss: 0.971954]\n",
      "epoch:5 step:5183 [D loss: 0.598693, acc.: 71.09%] [G loss: 0.949850]\n",
      "epoch:5 step:5184 [D loss: 0.567459, acc.: 75.78%] [G loss: 0.954849]\n",
      "epoch:5 step:5185 [D loss: 0.701384, acc.: 54.69%] [G loss: 0.874633]\n",
      "epoch:5 step:5186 [D loss: 0.722455, acc.: 51.56%] [G loss: 0.809452]\n",
      "epoch:5 step:5187 [D loss: 0.677545, acc.: 56.25%] [G loss: 0.871826]\n",
      "epoch:5 step:5188 [D loss: 0.647494, acc.: 66.41%] [G loss: 0.847764]\n",
      "epoch:5 step:5189 [D loss: 0.616778, acc.: 64.06%] [G loss: 0.910161]\n",
      "epoch:5 step:5190 [D loss: 0.602141, acc.: 71.09%] [G loss: 0.994235]\n",
      "epoch:5 step:5191 [D loss: 0.699815, acc.: 52.34%] [G loss: 0.975683]\n",
      "epoch:5 step:5192 [D loss: 0.619336, acc.: 62.50%] [G loss: 0.969282]\n",
      "epoch:5 step:5193 [D loss: 0.572740, acc.: 72.66%] [G loss: 1.000834]\n",
      "epoch:5 step:5194 [D loss: 0.716860, acc.: 57.81%] [G loss: 0.935696]\n",
      "epoch:5 step:5195 [D loss: 0.723241, acc.: 49.22%] [G loss: 0.881344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5196 [D loss: 0.710267, acc.: 50.00%] [G loss: 0.820745]\n",
      "epoch:5 step:5197 [D loss: 0.651990, acc.: 60.94%] [G loss: 0.836824]\n",
      "epoch:5 step:5198 [D loss: 0.603994, acc.: 69.53%] [G loss: 0.879155]\n",
      "epoch:5 step:5199 [D loss: 0.653276, acc.: 66.41%] [G loss: 0.866452]\n",
      "epoch:5 step:5200 [D loss: 0.569876, acc.: 71.88%] [G loss: 0.997540]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.297394\n",
      "FID: 17.221346\n",
      "0 = 12.228175817728017\n",
      "1 = 0.06979433500588407\n",
      "2 = 0.9593999981880188\n",
      "3 = 0.9225999712944031\n",
      "4 = 0.9962000250816345\n",
      "5 = 0.9958981275558472\n",
      "6 = 0.9225999712944031\n",
      "7 = 7.118505284899433\n",
      "8 = 0.08914576870840972\n",
      "9 = 0.7824500203132629\n",
      "10 = 0.7495999932289124\n",
      "11 = 0.8152999877929688\n",
      "12 = 0.802311897277832\n",
      "13 = 0.7495999932289124\n",
      "14 = 7.297460556030273\n",
      "15 = 9.50279712677002\n",
      "16 = 0.13370244204998016\n",
      "17 = 7.297393798828125\n",
      "18 = 17.221345901489258\n",
      "epoch:5 step:5201 [D loss: 0.641106, acc.: 64.84%] [G loss: 0.927811]\n",
      "epoch:5 step:5202 [D loss: 0.719323, acc.: 51.56%] [G loss: 0.928605]\n",
      "epoch:5 step:5203 [D loss: 0.605425, acc.: 64.06%] [G loss: 0.943464]\n",
      "epoch:5 step:5204 [D loss: 0.655940, acc.: 57.03%] [G loss: 0.949971]\n",
      "epoch:5 step:5205 [D loss: 0.628746, acc.: 64.06%] [G loss: 0.920428]\n",
      "epoch:5 step:5206 [D loss: 0.606938, acc.: 75.78%] [G loss: 0.940700]\n",
      "epoch:5 step:5207 [D loss: 0.635015, acc.: 64.84%] [G loss: 0.882292]\n",
      "epoch:5 step:5208 [D loss: 0.682832, acc.: 57.03%] [G loss: 0.878551]\n",
      "epoch:5 step:5209 [D loss: 0.626425, acc.: 64.84%] [G loss: 0.939933]\n",
      "epoch:5 step:5210 [D loss: 0.627472, acc.: 67.97%] [G loss: 0.961399]\n",
      "epoch:5 step:5211 [D loss: 0.612381, acc.: 65.62%] [G loss: 0.916445]\n",
      "epoch:5 step:5212 [D loss: 0.649455, acc.: 67.19%] [G loss: 0.918974]\n",
      "epoch:5 step:5213 [D loss: 0.682415, acc.: 56.25%] [G loss: 0.882292]\n",
      "epoch:5 step:5214 [D loss: 0.698146, acc.: 53.12%] [G loss: 0.882055]\n",
      "epoch:5 step:5215 [D loss: 0.669583, acc.: 61.72%] [G loss: 0.971728]\n",
      "epoch:5 step:5216 [D loss: 0.673475, acc.: 57.03%] [G loss: 0.996620]\n",
      "epoch:5 step:5217 [D loss: 0.657534, acc.: 59.38%] [G loss: 0.934725]\n",
      "epoch:5 step:5218 [D loss: 0.645891, acc.: 56.25%] [G loss: 0.969502]\n",
      "epoch:5 step:5219 [D loss: 0.602324, acc.: 67.19%] [G loss: 0.952160]\n",
      "epoch:5 step:5220 [D loss: 0.735043, acc.: 49.22%] [G loss: 0.861594]\n",
      "epoch:5 step:5221 [D loss: 0.698675, acc.: 53.12%] [G loss: 0.848253]\n",
      "epoch:5 step:5222 [D loss: 0.692816, acc.: 53.12%] [G loss: 0.883116]\n",
      "epoch:5 step:5223 [D loss: 0.686166, acc.: 50.00%] [G loss: 0.856739]\n",
      "epoch:5 step:5224 [D loss: 0.657023, acc.: 60.16%] [G loss: 0.884245]\n",
      "epoch:5 step:5225 [D loss: 0.668286, acc.: 58.59%] [G loss: 0.896135]\n",
      "epoch:5 step:5226 [D loss: 0.639101, acc.: 67.97%] [G loss: 0.854931]\n",
      "epoch:5 step:5227 [D loss: 0.689691, acc.: 52.34%] [G loss: 0.804597]\n",
      "epoch:5 step:5228 [D loss: 0.679021, acc.: 57.03%] [G loss: 0.812224]\n",
      "epoch:5 step:5229 [D loss: 0.684181, acc.: 54.69%] [G loss: 0.877346]\n",
      "epoch:5 step:5230 [D loss: 0.614830, acc.: 68.75%] [G loss: 0.906575]\n",
      "epoch:5 step:5231 [D loss: 0.597263, acc.: 71.88%] [G loss: 0.898618]\n",
      "epoch:5 step:5232 [D loss: 0.637854, acc.: 64.84%] [G loss: 0.935331]\n",
      "epoch:5 step:5233 [D loss: 0.618821, acc.: 65.62%] [G loss: 0.915183]\n",
      "epoch:5 step:5234 [D loss: 0.587093, acc.: 70.31%] [G loss: 0.889983]\n",
      "epoch:5 step:5235 [D loss: 0.650366, acc.: 65.62%] [G loss: 0.895723]\n",
      "epoch:5 step:5236 [D loss: 0.637621, acc.: 58.59%] [G loss: 0.917853]\n",
      "epoch:5 step:5237 [D loss: 0.672918, acc.: 55.47%] [G loss: 0.936791]\n",
      "epoch:5 step:5238 [D loss: 0.652672, acc.: 60.94%] [G loss: 0.915337]\n",
      "epoch:5 step:5239 [D loss: 0.611743, acc.: 67.19%] [G loss: 0.898442]\n",
      "epoch:5 step:5240 [D loss: 0.589993, acc.: 74.22%] [G loss: 0.883638]\n",
      "epoch:5 step:5241 [D loss: 0.615405, acc.: 67.19%] [G loss: 0.935572]\n",
      "epoch:5 step:5242 [D loss: 0.666716, acc.: 64.06%] [G loss: 0.903025]\n",
      "epoch:5 step:5243 [D loss: 0.591535, acc.: 70.31%] [G loss: 0.938684]\n",
      "epoch:5 step:5244 [D loss: 0.658005, acc.: 63.28%] [G loss: 0.942632]\n",
      "epoch:5 step:5245 [D loss: 0.666333, acc.: 57.03%] [G loss: 0.985463]\n",
      "epoch:5 step:5246 [D loss: 0.612600, acc.: 67.19%] [G loss: 0.963387]\n",
      "epoch:5 step:5247 [D loss: 0.680846, acc.: 54.69%] [G loss: 0.938646]\n",
      "epoch:5 step:5248 [D loss: 0.671081, acc.: 54.69%] [G loss: 0.923648]\n",
      "epoch:5 step:5249 [D loss: 0.575418, acc.: 77.34%] [G loss: 0.964852]\n",
      "epoch:5 step:5250 [D loss: 0.707654, acc.: 52.34%] [G loss: 0.937919]\n",
      "epoch:5 step:5251 [D loss: 0.725409, acc.: 49.22%] [G loss: 0.911967]\n",
      "epoch:5 step:5252 [D loss: 0.617831, acc.: 70.31%] [G loss: 0.900629]\n",
      "epoch:5 step:5253 [D loss: 0.637761, acc.: 64.06%] [G loss: 0.888898]\n",
      "epoch:5 step:5254 [D loss: 0.723678, acc.: 47.66%] [G loss: 0.863268]\n",
      "epoch:5 step:5255 [D loss: 0.623735, acc.: 67.19%] [G loss: 0.820854]\n",
      "epoch:5 step:5256 [D loss: 0.638239, acc.: 64.84%] [G loss: 0.857037]\n",
      "epoch:5 step:5257 [D loss: 0.655410, acc.: 57.81%] [G loss: 0.855678]\n",
      "epoch:5 step:5258 [D loss: 0.607342, acc.: 70.31%] [G loss: 0.881267]\n",
      "epoch:5 step:5259 [D loss: 0.555466, acc.: 74.22%] [G loss: 0.853952]\n",
      "epoch:5 step:5260 [D loss: 0.607457, acc.: 61.72%] [G loss: 0.898326]\n",
      "epoch:5 step:5261 [D loss: 0.685704, acc.: 48.44%] [G loss: 0.938587]\n",
      "epoch:5 step:5262 [D loss: 0.656234, acc.: 60.94%] [G loss: 0.899016]\n",
      "epoch:5 step:5263 [D loss: 0.649415, acc.: 60.16%] [G loss: 0.861644]\n",
      "epoch:5 step:5264 [D loss: 0.638963, acc.: 61.72%] [G loss: 0.888313]\n",
      "epoch:5 step:5265 [D loss: 0.664069, acc.: 60.94%] [G loss: 0.947904]\n",
      "epoch:5 step:5266 [D loss: 0.586793, acc.: 71.09%] [G loss: 0.972935]\n",
      "epoch:5 step:5267 [D loss: 0.567935, acc.: 67.97%] [G loss: 1.013721]\n",
      "epoch:5 step:5268 [D loss: 0.672390, acc.: 56.25%] [G loss: 0.960503]\n",
      "epoch:5 step:5269 [D loss: 0.650985, acc.: 60.94%] [G loss: 0.908825]\n",
      "epoch:5 step:5270 [D loss: 0.687458, acc.: 55.47%] [G loss: 0.875098]\n",
      "epoch:5 step:5271 [D loss: 0.686609, acc.: 51.56%] [G loss: 0.907037]\n",
      "epoch:5 step:5272 [D loss: 0.738031, acc.: 46.09%] [G loss: 0.898366]\n",
      "epoch:5 step:5273 [D loss: 0.702870, acc.: 56.25%] [G loss: 0.888009]\n",
      "epoch:5 step:5274 [D loss: 0.657451, acc.: 61.72%] [G loss: 0.878274]\n",
      "epoch:5 step:5275 [D loss: 0.646807, acc.: 62.50%] [G loss: 0.893905]\n",
      "epoch:5 step:5276 [D loss: 0.630668, acc.: 62.50%] [G loss: 0.914773]\n",
      "epoch:5 step:5277 [D loss: 0.606208, acc.: 70.31%] [G loss: 0.934883]\n",
      "epoch:5 step:5278 [D loss: 0.665729, acc.: 57.81%] [G loss: 0.904962]\n",
      "epoch:5 step:5279 [D loss: 0.698251, acc.: 59.38%] [G loss: 0.940405]\n",
      "epoch:5 step:5280 [D loss: 0.648646, acc.: 61.72%] [G loss: 0.939036]\n",
      "epoch:5 step:5281 [D loss: 0.697780, acc.: 53.12%] [G loss: 0.864189]\n",
      "epoch:5 step:5282 [D loss: 0.620316, acc.: 67.97%] [G loss: 0.907560]\n",
      "epoch:5 step:5283 [D loss: 0.617183, acc.: 64.84%] [G loss: 0.910298]\n",
      "epoch:5 step:5284 [D loss: 0.647908, acc.: 62.50%] [G loss: 0.905328]\n",
      "epoch:5 step:5285 [D loss: 0.705788, acc.: 55.47%] [G loss: 0.885808]\n",
      "epoch:5 step:5286 [D loss: 0.683424, acc.: 56.25%] [G loss: 0.905934]\n",
      "epoch:5 step:5287 [D loss: 0.689855, acc.: 52.34%] [G loss: 0.904186]\n",
      "epoch:5 step:5288 [D loss: 0.675960, acc.: 60.16%] [G loss: 0.853216]\n",
      "epoch:5 step:5289 [D loss: 0.635889, acc.: 65.62%] [G loss: 0.857833]\n",
      "epoch:5 step:5290 [D loss: 0.578844, acc.: 71.09%] [G loss: 0.911245]\n",
      "epoch:5 step:5291 [D loss: 0.651974, acc.: 60.16%] [G loss: 0.862022]\n",
      "epoch:5 step:5292 [D loss: 0.625240, acc.: 62.50%] [G loss: 0.845672]\n",
      "epoch:5 step:5293 [D loss: 0.650549, acc.: 64.84%] [G loss: 0.854447]\n",
      "epoch:5 step:5294 [D loss: 0.637574, acc.: 61.72%] [G loss: 0.912233]\n",
      "epoch:5 step:5295 [D loss: 0.657061, acc.: 60.16%] [G loss: 0.899547]\n",
      "epoch:5 step:5296 [D loss: 0.609753, acc.: 65.62%] [G loss: 0.797863]\n",
      "epoch:5 step:5297 [D loss: 0.641490, acc.: 60.94%] [G loss: 0.900618]\n",
      "epoch:5 step:5298 [D loss: 0.595056, acc.: 69.53%] [G loss: 0.904794]\n",
      "epoch:5 step:5299 [D loss: 0.681746, acc.: 57.03%] [G loss: 0.859462]\n",
      "epoch:5 step:5300 [D loss: 0.687798, acc.: 53.12%] [G loss: 0.885428]\n",
      "epoch:5 step:5301 [D loss: 0.651257, acc.: 64.06%] [G loss: 0.885655]\n",
      "epoch:5 step:5302 [D loss: 0.665540, acc.: 57.81%] [G loss: 0.831558]\n",
      "epoch:5 step:5303 [D loss: 0.667206, acc.: 66.41%] [G loss: 0.920649]\n",
      "epoch:5 step:5304 [D loss: 0.666056, acc.: 57.03%] [G loss: 0.899236]\n",
      "epoch:5 step:5305 [D loss: 0.669165, acc.: 60.16%] [G loss: 0.934071]\n",
      "epoch:5 step:5306 [D loss: 0.692966, acc.: 52.34%] [G loss: 0.922168]\n",
      "epoch:5 step:5307 [D loss: 0.700517, acc.: 53.12%] [G loss: 0.851404]\n",
      "epoch:5 step:5308 [D loss: 0.613685, acc.: 67.19%] [G loss: 0.885719]\n",
      "epoch:5 step:5309 [D loss: 0.615768, acc.: 69.53%] [G loss: 0.875623]\n",
      "epoch:5 step:5310 [D loss: 0.703574, acc.: 53.12%] [G loss: 0.832001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5311 [D loss: 0.677668, acc.: 57.81%] [G loss: 0.899736]\n",
      "epoch:5 step:5312 [D loss: 0.644559, acc.: 64.84%] [G loss: 0.875652]\n",
      "epoch:5 step:5313 [D loss: 0.694508, acc.: 57.03%] [G loss: 0.850328]\n",
      "epoch:5 step:5314 [D loss: 0.634424, acc.: 67.97%] [G loss: 0.833553]\n",
      "epoch:5 step:5315 [D loss: 0.642018, acc.: 63.28%] [G loss: 0.860346]\n",
      "epoch:5 step:5316 [D loss: 0.605615, acc.: 65.62%] [G loss: 0.875201]\n",
      "epoch:5 step:5317 [D loss: 0.641655, acc.: 64.06%] [G loss: 0.897281]\n",
      "epoch:5 step:5318 [D loss: 0.640394, acc.: 61.72%] [G loss: 0.881899]\n",
      "epoch:5 step:5319 [D loss: 0.615733, acc.: 67.19%] [G loss: 0.910441]\n",
      "epoch:5 step:5320 [D loss: 0.653626, acc.: 61.72%] [G loss: 0.952633]\n",
      "epoch:5 step:5321 [D loss: 0.697744, acc.: 53.91%] [G loss: 0.867341]\n",
      "epoch:5 step:5322 [D loss: 0.634386, acc.: 64.84%] [G loss: 0.934403]\n",
      "epoch:5 step:5323 [D loss: 0.666487, acc.: 56.25%] [G loss: 0.915484]\n",
      "epoch:5 step:5324 [D loss: 0.626818, acc.: 68.75%] [G loss: 0.901450]\n",
      "epoch:5 step:5325 [D loss: 0.665912, acc.: 58.59%] [G loss: 0.897222]\n",
      "epoch:5 step:5326 [D loss: 0.619169, acc.: 71.88%] [G loss: 0.964058]\n",
      "epoch:5 step:5327 [D loss: 0.578424, acc.: 67.19%] [G loss: 1.044318]\n",
      "epoch:5 step:5328 [D loss: 0.641426, acc.: 61.72%] [G loss: 1.024916]\n",
      "epoch:5 step:5329 [D loss: 0.706333, acc.: 50.78%] [G loss: 0.928864]\n",
      "epoch:5 step:5330 [D loss: 0.684897, acc.: 60.16%] [G loss: 0.876467]\n",
      "epoch:5 step:5331 [D loss: 0.634840, acc.: 61.72%] [G loss: 0.942300]\n",
      "epoch:5 step:5332 [D loss: 0.623510, acc.: 69.53%] [G loss: 0.938171]\n",
      "epoch:5 step:5333 [D loss: 0.567721, acc.: 75.00%] [G loss: 0.985634]\n",
      "epoch:5 step:5334 [D loss: 0.618371, acc.: 64.06%] [G loss: 0.952828]\n",
      "epoch:5 step:5335 [D loss: 0.631094, acc.: 64.06%] [G loss: 0.945248]\n",
      "epoch:5 step:5336 [D loss: 0.624528, acc.: 63.28%] [G loss: 0.956591]\n",
      "epoch:5 step:5337 [D loss: 0.709009, acc.: 45.31%] [G loss: 0.923403]\n",
      "epoch:5 step:5338 [D loss: 0.690849, acc.: 51.56%] [G loss: 0.961890]\n",
      "epoch:5 step:5339 [D loss: 0.658689, acc.: 61.72%] [G loss: 0.932547]\n",
      "epoch:5 step:5340 [D loss: 0.657802, acc.: 61.72%] [G loss: 0.942773]\n",
      "epoch:5 step:5341 [D loss: 0.683099, acc.: 54.69%] [G loss: 0.938849]\n",
      "epoch:5 step:5342 [D loss: 0.654583, acc.: 64.84%] [G loss: 0.911847]\n",
      "epoch:5 step:5343 [D loss: 0.634006, acc.: 64.06%] [G loss: 0.913197]\n",
      "epoch:5 step:5344 [D loss: 0.605939, acc.: 64.84%] [G loss: 0.917615]\n",
      "epoch:5 step:5345 [D loss: 0.590694, acc.: 66.41%] [G loss: 0.867919]\n",
      "epoch:5 step:5346 [D loss: 0.672271, acc.: 63.28%] [G loss: 0.917002]\n",
      "epoch:5 step:5347 [D loss: 0.685875, acc.: 57.03%] [G loss: 0.876820]\n",
      "epoch:5 step:5348 [D loss: 0.666270, acc.: 63.28%] [G loss: 0.895269]\n",
      "epoch:5 step:5349 [D loss: 0.671961, acc.: 54.69%] [G loss: 0.930430]\n",
      "epoch:5 step:5350 [D loss: 0.612123, acc.: 70.31%] [G loss: 0.959152]\n",
      "epoch:5 step:5351 [D loss: 0.667622, acc.: 56.25%] [G loss: 0.920765]\n",
      "epoch:5 step:5352 [D loss: 0.665628, acc.: 53.12%] [G loss: 0.912309]\n",
      "epoch:5 step:5353 [D loss: 0.663799, acc.: 60.16%] [G loss: 0.857611]\n",
      "epoch:5 step:5354 [D loss: 0.655773, acc.: 54.69%] [G loss: 0.887249]\n",
      "epoch:5 step:5355 [D loss: 0.704243, acc.: 50.00%] [G loss: 0.928189]\n",
      "epoch:5 step:5356 [D loss: 0.664980, acc.: 61.72%] [G loss: 0.933270]\n",
      "epoch:5 step:5357 [D loss: 0.683606, acc.: 56.25%] [G loss: 0.927766]\n",
      "epoch:5 step:5358 [D loss: 0.657040, acc.: 60.94%] [G loss: 0.908124]\n",
      "epoch:5 step:5359 [D loss: 0.668322, acc.: 60.16%] [G loss: 0.987970]\n",
      "epoch:5 step:5360 [D loss: 0.693266, acc.: 59.38%] [G loss: 0.906711]\n",
      "epoch:5 step:5361 [D loss: 0.670356, acc.: 55.47%] [G loss: 0.874108]\n",
      "epoch:5 step:5362 [D loss: 0.628800, acc.: 67.19%] [G loss: 0.845959]\n",
      "epoch:5 step:5363 [D loss: 0.650127, acc.: 64.06%] [G loss: 0.918472]\n",
      "epoch:5 step:5364 [D loss: 0.645315, acc.: 59.38%] [G loss: 0.892109]\n",
      "epoch:5 step:5365 [D loss: 0.650921, acc.: 60.94%] [G loss: 0.863012]\n",
      "epoch:5 step:5366 [D loss: 0.608729, acc.: 67.97%] [G loss: 0.921014]\n",
      "epoch:5 step:5367 [D loss: 0.652284, acc.: 62.50%] [G loss: 0.896333]\n",
      "epoch:5 step:5368 [D loss: 0.650649, acc.: 63.28%] [G loss: 0.818960]\n",
      "epoch:5 step:5369 [D loss: 0.640258, acc.: 66.41%] [G loss: 0.913656]\n",
      "epoch:5 step:5370 [D loss: 0.653473, acc.: 61.72%] [G loss: 0.937904]\n",
      "epoch:5 step:5371 [D loss: 0.668518, acc.: 57.81%] [G loss: 0.858778]\n",
      "epoch:5 step:5372 [D loss: 0.666013, acc.: 60.94%] [G loss: 0.950469]\n",
      "epoch:5 step:5373 [D loss: 0.631667, acc.: 65.62%] [G loss: 0.935302]\n",
      "epoch:5 step:5374 [D loss: 0.637678, acc.: 69.53%] [G loss: 0.898406]\n",
      "epoch:5 step:5375 [D loss: 0.616127, acc.: 67.19%] [G loss: 0.940979]\n",
      "epoch:5 step:5376 [D loss: 0.607448, acc.: 69.53%] [G loss: 0.975873]\n",
      "epoch:5 step:5377 [D loss: 0.645283, acc.: 62.50%] [G loss: 0.970505]\n",
      "epoch:5 step:5378 [D loss: 0.652754, acc.: 60.16%] [G loss: 0.994404]\n",
      "epoch:5 step:5379 [D loss: 0.639030, acc.: 63.28%] [G loss: 0.987440]\n",
      "epoch:5 step:5380 [D loss: 0.637078, acc.: 65.62%] [G loss: 0.984598]\n",
      "epoch:5 step:5381 [D loss: 0.651170, acc.: 57.81%] [G loss: 0.914415]\n",
      "epoch:5 step:5382 [D loss: 0.603951, acc.: 69.53%] [G loss: 0.941812]\n",
      "epoch:5 step:5383 [D loss: 0.647740, acc.: 64.06%] [G loss: 0.930710]\n",
      "epoch:5 step:5384 [D loss: 0.641449, acc.: 63.28%] [G loss: 0.917979]\n",
      "epoch:5 step:5385 [D loss: 0.652731, acc.: 61.72%] [G loss: 0.981967]\n",
      "epoch:5 step:5386 [D loss: 0.643214, acc.: 65.62%] [G loss: 0.988225]\n",
      "epoch:5 step:5387 [D loss: 0.694628, acc.: 55.47%] [G loss: 0.935704]\n",
      "epoch:5 step:5388 [D loss: 0.668782, acc.: 63.28%] [G loss: 0.896997]\n",
      "epoch:5 step:5389 [D loss: 0.654645, acc.: 62.50%] [G loss: 0.858621]\n",
      "epoch:5 step:5390 [D loss: 0.628997, acc.: 67.19%] [G loss: 0.886444]\n",
      "epoch:5 step:5391 [D loss: 0.626379, acc.: 68.75%] [G loss: 0.837693]\n",
      "epoch:5 step:5392 [D loss: 0.628796, acc.: 64.84%] [G loss: 0.877840]\n",
      "epoch:5 step:5393 [D loss: 0.595878, acc.: 67.97%] [G loss: 0.926216]\n",
      "epoch:5 step:5394 [D loss: 0.617214, acc.: 68.75%] [G loss: 0.926094]\n",
      "epoch:5 step:5395 [D loss: 0.711629, acc.: 50.78%] [G loss: 0.890358]\n",
      "epoch:5 step:5396 [D loss: 0.706096, acc.: 51.56%] [G loss: 0.904759]\n",
      "epoch:5 step:5397 [D loss: 0.630451, acc.: 70.31%] [G loss: 0.910226]\n",
      "epoch:5 step:5398 [D loss: 0.680791, acc.: 58.59%] [G loss: 0.860411]\n",
      "epoch:5 step:5399 [D loss: 0.681774, acc.: 59.38%] [G loss: 0.927674]\n",
      "epoch:5 step:5400 [D loss: 0.651933, acc.: 55.47%] [G loss: 0.923827]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.280303\n",
      "FID: 17.880808\n",
      "0 = 12.021713083767883\n",
      "1 = 0.06582748419293341\n",
      "2 = 0.9488499760627747\n",
      "3 = 0.9021000266075134\n",
      "4 = 0.9955999851226807\n",
      "5 = 0.9951461553573608\n",
      "6 = 0.9021000266075134\n",
      "7 = 7.05537334274054\n",
      "8 = 0.0881479522899989\n",
      "9 = 0.7904000282287598\n",
      "10 = 0.754800021648407\n",
      "11 = 0.8259999752044678\n",
      "12 = 0.8126614689826965\n",
      "13 = 0.754800021648407\n",
      "14 = 7.28036642074585\n",
      "15 = 9.606431007385254\n",
      "16 = 0.11214485764503479\n",
      "17 = 7.28030252456665\n",
      "18 = 17.880807876586914\n",
      "epoch:5 step:5401 [D loss: 0.675070, acc.: 53.91%] [G loss: 0.850754]\n",
      "epoch:5 step:5402 [D loss: 0.663133, acc.: 60.16%] [G loss: 0.897017]\n",
      "epoch:5 step:5403 [D loss: 0.645865, acc.: 67.19%] [G loss: 0.932948]\n",
      "epoch:5 step:5404 [D loss: 0.632420, acc.: 63.28%] [G loss: 0.923273]\n",
      "epoch:5 step:5405 [D loss: 0.678842, acc.: 57.81%] [G loss: 0.946346]\n",
      "epoch:5 step:5406 [D loss: 0.643739, acc.: 59.38%] [G loss: 0.950467]\n",
      "epoch:5 step:5407 [D loss: 0.665093, acc.: 60.94%] [G loss: 0.880155]\n",
      "epoch:5 step:5408 [D loss: 0.666884, acc.: 60.94%] [G loss: 0.848185]\n",
      "epoch:5 step:5409 [D loss: 0.622233, acc.: 67.19%] [G loss: 0.850918]\n",
      "epoch:5 step:5410 [D loss: 0.648616, acc.: 57.81%] [G loss: 0.952794]\n",
      "epoch:5 step:5411 [D loss: 0.642407, acc.: 57.03%] [G loss: 0.925165]\n",
      "epoch:5 step:5412 [D loss: 0.651733, acc.: 58.59%] [G loss: 0.900648]\n",
      "epoch:5 step:5413 [D loss: 0.637857, acc.: 67.19%] [G loss: 0.816273]\n",
      "epoch:5 step:5414 [D loss: 0.691387, acc.: 55.47%] [G loss: 0.796910]\n",
      "epoch:5 step:5415 [D loss: 0.642100, acc.: 67.97%] [G loss: 0.854535]\n",
      "epoch:5 step:5416 [D loss: 0.622662, acc.: 71.09%] [G loss: 0.939764]\n",
      "epoch:5 step:5417 [D loss: 0.627869, acc.: 67.97%] [G loss: 0.909094]\n",
      "epoch:5 step:5418 [D loss: 0.653667, acc.: 61.72%] [G loss: 0.916858]\n",
      "epoch:5 step:5419 [D loss: 0.669024, acc.: 55.47%] [G loss: 0.915666]\n",
      "epoch:5 step:5420 [D loss: 0.698121, acc.: 52.34%] [G loss: 0.936484]\n",
      "epoch:5 step:5421 [D loss: 0.578142, acc.: 73.44%] [G loss: 0.931029]\n",
      "epoch:5 step:5422 [D loss: 0.652834, acc.: 59.38%] [G loss: 0.945179]\n",
      "epoch:5 step:5423 [D loss: 0.669444, acc.: 54.69%] [G loss: 0.861057]\n",
      "epoch:5 step:5424 [D loss: 0.675016, acc.: 57.81%] [G loss: 0.915442]\n",
      "epoch:5 step:5425 [D loss: 0.689054, acc.: 57.03%] [G loss: 0.855234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5426 [D loss: 0.644927, acc.: 61.72%] [G loss: 0.901741]\n",
      "epoch:5 step:5427 [D loss: 0.633286, acc.: 64.84%] [G loss: 0.904249]\n",
      "epoch:5 step:5428 [D loss: 0.598756, acc.: 70.31%] [G loss: 0.881305]\n",
      "epoch:5 step:5429 [D loss: 0.701789, acc.: 59.38%] [G loss: 0.926118]\n",
      "epoch:5 step:5430 [D loss: 0.676696, acc.: 62.50%] [G loss: 0.839857]\n",
      "epoch:5 step:5431 [D loss: 0.671561, acc.: 56.25%] [G loss: 0.869286]\n",
      "epoch:5 step:5432 [D loss: 0.638116, acc.: 63.28%] [G loss: 0.836863]\n",
      "epoch:5 step:5433 [D loss: 0.671468, acc.: 53.12%] [G loss: 0.924296]\n",
      "epoch:5 step:5434 [D loss: 0.649227, acc.: 58.59%] [G loss: 0.898268]\n",
      "epoch:5 step:5435 [D loss: 0.633319, acc.: 62.50%] [G loss: 0.855773]\n",
      "epoch:5 step:5436 [D loss: 0.635526, acc.: 65.62%] [G loss: 0.886217]\n",
      "epoch:5 step:5437 [D loss: 0.651396, acc.: 61.72%] [G loss: 0.850568]\n",
      "epoch:5 step:5438 [D loss: 0.667591, acc.: 61.72%] [G loss: 0.898048]\n",
      "epoch:5 step:5439 [D loss: 0.601167, acc.: 67.19%] [G loss: 0.902186]\n",
      "epoch:5 step:5440 [D loss: 0.616227, acc.: 67.19%] [G loss: 0.942631]\n",
      "epoch:5 step:5441 [D loss: 0.620052, acc.: 66.41%] [G loss: 0.921155]\n",
      "epoch:5 step:5442 [D loss: 0.649303, acc.: 62.50%] [G loss: 0.965929]\n",
      "epoch:5 step:5443 [D loss: 0.706257, acc.: 52.34%] [G loss: 0.880602]\n",
      "epoch:5 step:5444 [D loss: 0.676094, acc.: 57.03%] [G loss: 0.837422]\n",
      "epoch:5 step:5445 [D loss: 0.628644, acc.: 63.28%] [G loss: 0.861524]\n",
      "epoch:5 step:5446 [D loss: 0.689241, acc.: 58.59%] [G loss: 0.876249]\n",
      "epoch:5 step:5447 [D loss: 0.661866, acc.: 58.59%] [G loss: 0.856882]\n",
      "epoch:5 step:5448 [D loss: 0.649208, acc.: 60.94%] [G loss: 0.926860]\n",
      "epoch:5 step:5449 [D loss: 0.682652, acc.: 58.59%] [G loss: 0.866629]\n",
      "epoch:5 step:5450 [D loss: 0.730046, acc.: 52.34%] [G loss: 0.833698]\n",
      "epoch:5 step:5451 [D loss: 0.680338, acc.: 55.47%] [G loss: 0.888778]\n",
      "epoch:5 step:5452 [D loss: 0.662482, acc.: 60.94%] [G loss: 0.884341]\n",
      "epoch:5 step:5453 [D loss: 0.686614, acc.: 57.03%] [G loss: 0.914094]\n",
      "epoch:5 step:5454 [D loss: 0.636665, acc.: 69.53%] [G loss: 0.924932]\n",
      "epoch:5 step:5455 [D loss: 0.682616, acc.: 56.25%] [G loss: 0.962553]\n",
      "epoch:5 step:5456 [D loss: 0.663912, acc.: 57.81%] [G loss: 0.986291]\n",
      "epoch:5 step:5457 [D loss: 0.660584, acc.: 64.06%] [G loss: 0.938414]\n",
      "epoch:5 step:5458 [D loss: 0.631985, acc.: 68.75%] [G loss: 0.942757]\n",
      "epoch:5 step:5459 [D loss: 0.686374, acc.: 61.72%] [G loss: 0.876586]\n",
      "epoch:5 step:5460 [D loss: 0.594184, acc.: 67.19%] [G loss: 0.883480]\n",
      "epoch:5 step:5461 [D loss: 0.607213, acc.: 64.84%] [G loss: 0.870528]\n",
      "epoch:5 step:5462 [D loss: 0.662383, acc.: 59.38%] [G loss: 0.876377]\n",
      "epoch:5 step:5463 [D loss: 0.625396, acc.: 67.97%] [G loss: 0.918624]\n",
      "epoch:5 step:5464 [D loss: 0.695111, acc.: 57.81%] [G loss: 0.890553]\n",
      "epoch:5 step:5465 [D loss: 0.664410, acc.: 57.03%] [G loss: 0.927246]\n",
      "epoch:5 step:5466 [D loss: 0.570446, acc.: 70.31%] [G loss: 0.976903]\n",
      "epoch:5 step:5467 [D loss: 0.622178, acc.: 64.06%] [G loss: 0.978412]\n",
      "epoch:5 step:5468 [D loss: 0.718960, acc.: 55.47%] [G loss: 0.969485]\n",
      "epoch:5 step:5469 [D loss: 0.684664, acc.: 61.72%] [G loss: 0.852195]\n",
      "epoch:5 step:5470 [D loss: 0.661757, acc.: 64.06%] [G loss: 0.942171]\n",
      "epoch:5 step:5471 [D loss: 0.602307, acc.: 70.31%] [G loss: 0.905285]\n",
      "epoch:5 step:5472 [D loss: 0.683420, acc.: 60.16%] [G loss: 0.943914]\n",
      "epoch:5 step:5473 [D loss: 0.739714, acc.: 49.22%] [G loss: 0.920467]\n",
      "epoch:5 step:5474 [D loss: 0.600225, acc.: 74.22%] [G loss: 0.925380]\n",
      "epoch:5 step:5475 [D loss: 0.659899, acc.: 60.94%] [G loss: 0.962945]\n",
      "epoch:5 step:5476 [D loss: 0.673069, acc.: 56.25%] [G loss: 0.917196]\n",
      "epoch:5 step:5477 [D loss: 0.594610, acc.: 73.44%] [G loss: 0.908590]\n",
      "epoch:5 step:5478 [D loss: 0.652747, acc.: 58.59%] [G loss: 0.923400]\n",
      "epoch:5 step:5479 [D loss: 0.689615, acc.: 49.22%] [G loss: 0.890990]\n",
      "epoch:5 step:5480 [D loss: 0.693052, acc.: 53.12%] [G loss: 0.880506]\n",
      "epoch:5 step:5481 [D loss: 0.627135, acc.: 67.19%] [G loss: 0.941043]\n",
      "epoch:5 step:5482 [D loss: 0.666542, acc.: 61.72%] [G loss: 0.903315]\n",
      "epoch:5 step:5483 [D loss: 0.668227, acc.: 57.03%] [G loss: 0.929844]\n",
      "epoch:5 step:5484 [D loss: 0.624831, acc.: 64.06%] [G loss: 0.973065]\n",
      "epoch:5 step:5485 [D loss: 0.606850, acc.: 67.19%] [G loss: 0.951336]\n",
      "epoch:5 step:5486 [D loss: 0.590224, acc.: 69.53%] [G loss: 0.952797]\n",
      "epoch:5 step:5487 [D loss: 0.629168, acc.: 67.19%] [G loss: 1.010953]\n",
      "epoch:5 step:5488 [D loss: 0.597083, acc.: 71.88%] [G loss: 0.967844]\n",
      "epoch:5 step:5489 [D loss: 0.704886, acc.: 52.34%] [G loss: 0.905256]\n",
      "epoch:5 step:5490 [D loss: 0.622575, acc.: 63.28%] [G loss: 0.900401]\n",
      "epoch:5 step:5491 [D loss: 0.679645, acc.: 52.34%] [G loss: 0.859921]\n",
      "epoch:5 step:5492 [D loss: 0.596590, acc.: 68.75%] [G loss: 0.915548]\n",
      "epoch:5 step:5493 [D loss: 0.668461, acc.: 56.25%] [G loss: 0.859167]\n",
      "epoch:5 step:5494 [D loss: 0.663380, acc.: 61.72%] [G loss: 0.869436]\n",
      "epoch:5 step:5495 [D loss: 0.689073, acc.: 58.59%] [G loss: 0.898098]\n",
      "epoch:5 step:5496 [D loss: 0.665698, acc.: 60.94%] [G loss: 0.868448]\n",
      "epoch:5 step:5497 [D loss: 0.667030, acc.: 63.28%] [G loss: 0.831307]\n",
      "epoch:5 step:5498 [D loss: 0.637755, acc.: 67.97%] [G loss: 0.817407]\n",
      "epoch:5 step:5499 [D loss: 0.644155, acc.: 65.62%] [G loss: 0.851157]\n",
      "epoch:5 step:5500 [D loss: 0.619354, acc.: 67.19%] [G loss: 0.931782]\n",
      "epoch:5 step:5501 [D loss: 0.656483, acc.: 62.50%] [G loss: 0.958954]\n",
      "epoch:5 step:5502 [D loss: 0.636858, acc.: 64.06%] [G loss: 0.878809]\n",
      "epoch:5 step:5503 [D loss: 0.697706, acc.: 51.56%] [G loss: 0.877151]\n",
      "epoch:5 step:5504 [D loss: 0.664438, acc.: 60.94%] [G loss: 0.949117]\n",
      "epoch:5 step:5505 [D loss: 0.709814, acc.: 51.56%] [G loss: 0.888572]\n",
      "epoch:5 step:5506 [D loss: 0.648514, acc.: 61.72%] [G loss: 0.898193]\n",
      "epoch:5 step:5507 [D loss: 0.624490, acc.: 67.19%] [G loss: 0.904913]\n",
      "epoch:5 step:5508 [D loss: 0.673785, acc.: 55.47%] [G loss: 0.896636]\n",
      "epoch:5 step:5509 [D loss: 0.698611, acc.: 58.59%] [G loss: 0.827335]\n",
      "epoch:5 step:5510 [D loss: 0.648070, acc.: 60.94%] [G loss: 0.921303]\n",
      "epoch:5 step:5511 [D loss: 0.679701, acc.: 53.91%] [G loss: 0.947421]\n",
      "epoch:5 step:5512 [D loss: 0.692552, acc.: 51.56%] [G loss: 0.845778]\n",
      "epoch:5 step:5513 [D loss: 0.655808, acc.: 62.50%] [G loss: 0.906450]\n",
      "epoch:5 step:5514 [D loss: 0.640168, acc.: 61.72%] [G loss: 0.901221]\n",
      "epoch:5 step:5515 [D loss: 0.641556, acc.: 64.06%] [G loss: 0.848689]\n",
      "epoch:5 step:5516 [D loss: 0.677656, acc.: 59.38%] [G loss: 0.868296]\n",
      "epoch:5 step:5517 [D loss: 0.606100, acc.: 68.75%] [G loss: 0.843127]\n",
      "epoch:5 step:5518 [D loss: 0.662539, acc.: 60.16%] [G loss: 0.848639]\n",
      "epoch:5 step:5519 [D loss: 0.676360, acc.: 60.16%] [G loss: 0.843729]\n",
      "epoch:5 step:5520 [D loss: 0.641743, acc.: 66.41%] [G loss: 0.870208]\n",
      "epoch:5 step:5521 [D loss: 0.636163, acc.: 67.97%] [G loss: 0.898214]\n",
      "epoch:5 step:5522 [D loss: 0.625811, acc.: 67.19%] [G loss: 0.870592]\n",
      "epoch:5 step:5523 [D loss: 0.631942, acc.: 64.84%] [G loss: 0.933758]\n",
      "epoch:5 step:5524 [D loss: 0.645030, acc.: 64.84%] [G loss: 0.881733]\n",
      "epoch:5 step:5525 [D loss: 0.633702, acc.: 65.62%] [G loss: 0.903516]\n",
      "epoch:5 step:5526 [D loss: 0.635305, acc.: 65.62%] [G loss: 0.858214]\n",
      "epoch:5 step:5527 [D loss: 0.587033, acc.: 67.97%] [G loss: 0.959237]\n",
      "epoch:5 step:5528 [D loss: 0.704884, acc.: 58.59%] [G loss: 0.908895]\n",
      "epoch:5 step:5529 [D loss: 0.712171, acc.: 56.25%] [G loss: 0.897573]\n",
      "epoch:5 step:5530 [D loss: 0.618578, acc.: 65.62%] [G loss: 0.873867]\n",
      "epoch:5 step:5531 [D loss: 0.648138, acc.: 66.41%] [G loss: 0.870175]\n",
      "epoch:5 step:5532 [D loss: 0.656975, acc.: 60.16%] [G loss: 0.871153]\n",
      "epoch:5 step:5533 [D loss: 0.635032, acc.: 63.28%] [G loss: 0.904370]\n",
      "epoch:5 step:5534 [D loss: 0.640486, acc.: 60.16%] [G loss: 0.860882]\n",
      "epoch:5 step:5535 [D loss: 0.659844, acc.: 60.16%] [G loss: 0.892207]\n",
      "epoch:5 step:5536 [D loss: 0.692852, acc.: 55.47%] [G loss: 0.847678]\n",
      "epoch:5 step:5537 [D loss: 0.647210, acc.: 60.16%] [G loss: 0.905229]\n",
      "epoch:5 step:5538 [D loss: 0.611088, acc.: 67.97%] [G loss: 0.935068]\n",
      "epoch:5 step:5539 [D loss: 0.606180, acc.: 70.31%] [G loss: 0.909115]\n",
      "epoch:5 step:5540 [D loss: 0.654115, acc.: 62.50%] [G loss: 0.895640]\n",
      "epoch:5 step:5541 [D loss: 0.641212, acc.: 64.84%] [G loss: 0.821470]\n",
      "epoch:5 step:5542 [D loss: 0.639067, acc.: 64.84%] [G loss: 0.896332]\n",
      "epoch:5 step:5543 [D loss: 0.763527, acc.: 45.31%] [G loss: 0.852744]\n",
      "epoch:5 step:5544 [D loss: 0.658965, acc.: 58.59%] [G loss: 0.872405]\n",
      "epoch:5 step:5545 [D loss: 0.589966, acc.: 70.31%] [G loss: 0.928410]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5546 [D loss: 0.680238, acc.: 58.59%] [G loss: 0.924504]\n",
      "epoch:5 step:5547 [D loss: 0.649150, acc.: 60.94%] [G loss: 0.864845]\n",
      "epoch:5 step:5548 [D loss: 0.659927, acc.: 55.47%] [G loss: 0.831301]\n",
      "epoch:5 step:5549 [D loss: 0.691314, acc.: 55.47%] [G loss: 0.869368]\n",
      "epoch:5 step:5550 [D loss: 0.678838, acc.: 53.12%] [G loss: 0.830493]\n",
      "epoch:5 step:5551 [D loss: 0.660790, acc.: 58.59%] [G loss: 0.873549]\n",
      "epoch:5 step:5552 [D loss: 0.724089, acc.: 43.75%] [G loss: 0.861209]\n",
      "epoch:5 step:5553 [D loss: 0.615799, acc.: 64.84%] [G loss: 0.850734]\n",
      "epoch:5 step:5554 [D loss: 0.647711, acc.: 60.94%] [G loss: 0.875752]\n",
      "epoch:5 step:5555 [D loss: 0.660312, acc.: 62.50%] [G loss: 0.901102]\n",
      "epoch:5 step:5556 [D loss: 0.615269, acc.: 65.62%] [G loss: 0.911459]\n",
      "epoch:5 step:5557 [D loss: 0.617630, acc.: 66.41%] [G loss: 0.868866]\n",
      "epoch:5 step:5558 [D loss: 0.673065, acc.: 63.28%] [G loss: 0.873070]\n",
      "epoch:5 step:5559 [D loss: 0.668554, acc.: 61.72%] [G loss: 0.881273]\n",
      "epoch:5 step:5560 [D loss: 0.619122, acc.: 59.38%] [G loss: 0.870387]\n",
      "epoch:5 step:5561 [D loss: 0.652260, acc.: 60.16%] [G loss: 0.906804]\n",
      "epoch:5 step:5562 [D loss: 0.705531, acc.: 56.25%] [G loss: 0.862136]\n",
      "epoch:5 step:5563 [D loss: 0.673919, acc.: 55.47%] [G loss: 0.877420]\n",
      "epoch:5 step:5564 [D loss: 0.663072, acc.: 57.81%] [G loss: 0.874884]\n",
      "epoch:5 step:5565 [D loss: 0.661038, acc.: 65.62%] [G loss: 0.834570]\n",
      "epoch:5 step:5566 [D loss: 0.599968, acc.: 71.88%] [G loss: 0.839414]\n",
      "epoch:5 step:5567 [D loss: 0.668889, acc.: 57.03%] [G loss: 0.876515]\n",
      "epoch:5 step:5568 [D loss: 0.658865, acc.: 60.94%] [G loss: 0.907767]\n",
      "epoch:5 step:5569 [D loss: 0.610079, acc.: 70.31%] [G loss: 0.962763]\n",
      "epoch:5 step:5570 [D loss: 0.625426, acc.: 64.06%] [G loss: 0.970201]\n",
      "epoch:5 step:5571 [D loss: 0.599795, acc.: 75.00%] [G loss: 1.046690]\n",
      "epoch:5 step:5572 [D loss: 0.652417, acc.: 64.84%] [G loss: 0.953017]\n",
      "epoch:5 step:5573 [D loss: 0.672013, acc.: 58.59%] [G loss: 0.897419]\n",
      "epoch:5 step:5574 [D loss: 0.635847, acc.: 65.62%] [G loss: 0.912536]\n",
      "epoch:5 step:5575 [D loss: 0.610086, acc.: 69.53%] [G loss: 0.900850]\n",
      "epoch:5 step:5576 [D loss: 0.728032, acc.: 55.47%] [G loss: 0.914998]\n",
      "epoch:5 step:5577 [D loss: 0.695191, acc.: 56.25%] [G loss: 0.855050]\n",
      "epoch:5 step:5578 [D loss: 0.638335, acc.: 64.84%] [G loss: 0.960055]\n",
      "epoch:5 step:5579 [D loss: 0.627112, acc.: 71.09%] [G loss: 0.964285]\n",
      "epoch:5 step:5580 [D loss: 0.645387, acc.: 67.19%] [G loss: 0.994217]\n",
      "epoch:5 step:5581 [D loss: 0.674634, acc.: 62.50%] [G loss: 0.955639]\n",
      "epoch:5 step:5582 [D loss: 0.642288, acc.: 67.19%] [G loss: 0.966364]\n",
      "epoch:5 step:5583 [D loss: 0.613028, acc.: 69.53%] [G loss: 0.963566]\n",
      "epoch:5 step:5584 [D loss: 0.604667, acc.: 64.06%] [G loss: 0.961339]\n",
      "epoch:5 step:5585 [D loss: 0.601234, acc.: 66.41%] [G loss: 0.957793]\n",
      "epoch:5 step:5586 [D loss: 0.621504, acc.: 69.53%] [G loss: 0.942510]\n",
      "epoch:5 step:5587 [D loss: 0.707521, acc.: 55.47%] [G loss: 0.886771]\n",
      "epoch:5 step:5588 [D loss: 0.678836, acc.: 62.50%] [G loss: 0.870024]\n",
      "epoch:5 step:5589 [D loss: 0.706370, acc.: 56.25%] [G loss: 0.951093]\n",
      "epoch:5 step:5590 [D loss: 0.599689, acc.: 71.09%] [G loss: 0.956520]\n",
      "epoch:5 step:5591 [D loss: 0.666772, acc.: 60.94%] [G loss: 1.002832]\n",
      "epoch:5 step:5592 [D loss: 0.684244, acc.: 57.03%] [G loss: 0.892152]\n",
      "epoch:5 step:5593 [D loss: 0.601200, acc.: 68.75%] [G loss: 0.933564]\n",
      "epoch:5 step:5594 [D loss: 0.624201, acc.: 63.28%] [G loss: 0.931505]\n",
      "epoch:5 step:5595 [D loss: 0.655615, acc.: 58.59%] [G loss: 0.881063]\n",
      "epoch:5 step:5596 [D loss: 0.663011, acc.: 59.38%] [G loss: 0.909555]\n",
      "epoch:5 step:5597 [D loss: 0.628132, acc.: 64.06%] [G loss: 0.949749]\n",
      "epoch:5 step:5598 [D loss: 0.624423, acc.: 61.72%] [G loss: 1.002617]\n",
      "epoch:5 step:5599 [D loss: 0.648349, acc.: 59.38%] [G loss: 0.959234]\n",
      "epoch:5 step:5600 [D loss: 0.734004, acc.: 50.00%] [G loss: 0.934181]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.437899\n",
      "FID: 17.980547\n",
      "0 = 12.026325966882723\n",
      "1 = 0.06659894921330155\n",
      "2 = 0.9503499865531921\n",
      "3 = 0.9035000205039978\n",
      "4 = 0.9972000122070312\n",
      "5 = 0.9969105124473572\n",
      "6 = 0.9035000205039978\n",
      "7 = 6.927898779565077\n",
      "8 = 0.09174816381295768\n",
      "9 = 0.7822999954223633\n",
      "10 = 0.745199978351593\n",
      "11 = 0.8194000124931335\n",
      "12 = 0.8049254417419434\n",
      "13 = 0.745199978351593\n",
      "14 = 7.437964916229248\n",
      "15 = 9.600482940673828\n",
      "16 = 0.10627847909927368\n",
      "17 = 7.437898635864258\n",
      "18 = 17.980546951293945\n",
      "epoch:5 step:5601 [D loss: 0.683402, acc.: 53.91%] [G loss: 0.867535]\n",
      "epoch:5 step:5602 [D loss: 0.682870, acc.: 57.03%] [G loss: 0.920056]\n",
      "epoch:5 step:5603 [D loss: 0.583130, acc.: 75.78%] [G loss: 0.886868]\n",
      "epoch:5 step:5604 [D loss: 0.647087, acc.: 62.50%] [G loss: 0.964920]\n",
      "epoch:5 step:5605 [D loss: 0.714297, acc.: 48.44%] [G loss: 0.858941]\n",
      "epoch:5 step:5606 [D loss: 0.647270, acc.: 65.62%] [G loss: 0.887284]\n",
      "epoch:5 step:5607 [D loss: 0.641229, acc.: 67.19%] [G loss: 0.891829]\n",
      "epoch:5 step:5608 [D loss: 0.602937, acc.: 72.66%] [G loss: 0.890280]\n",
      "epoch:5 step:5609 [D loss: 0.607756, acc.: 75.78%] [G loss: 0.853092]\n",
      "epoch:5 step:5610 [D loss: 0.573644, acc.: 76.56%] [G loss: 0.979274]\n",
      "epoch:5 step:5611 [D loss: 0.596055, acc.: 72.66%] [G loss: 0.955929]\n",
      "epoch:5 step:5612 [D loss: 0.609323, acc.: 70.31%] [G loss: 0.921823]\n",
      "epoch:5 step:5613 [D loss: 0.750719, acc.: 54.69%] [G loss: 0.934216]\n",
      "epoch:5 step:5614 [D loss: 0.583308, acc.: 69.53%] [G loss: 1.077143]\n",
      "epoch:5 step:5615 [D loss: 0.567052, acc.: 69.53%] [G loss: 1.065263]\n",
      "epoch:5 step:5616 [D loss: 0.713846, acc.: 55.47%] [G loss: 0.999367]\n",
      "epoch:5 step:5617 [D loss: 0.685956, acc.: 57.81%] [G loss: 0.895842]\n",
      "epoch:5 step:5618 [D loss: 0.670851, acc.: 62.50%] [G loss: 0.980693]\n",
      "epoch:5 step:5619 [D loss: 0.649120, acc.: 60.94%] [G loss: 0.876815]\n",
      "epoch:5 step:5620 [D loss: 0.609563, acc.: 71.09%] [G loss: 0.918234]\n",
      "epoch:5 step:5621 [D loss: 0.533282, acc.: 77.34%] [G loss: 0.985125]\n",
      "epoch:5 step:5622 [D loss: 0.554103, acc.: 72.66%] [G loss: 1.100472]\n",
      "epoch:6 step:5623 [D loss: 0.727496, acc.: 58.59%] [G loss: 0.984682]\n",
      "epoch:6 step:5624 [D loss: 0.699589, acc.: 57.81%] [G loss: 0.920739]\n",
      "epoch:6 step:5625 [D loss: 0.684513, acc.: 57.03%] [G loss: 0.880866]\n",
      "epoch:6 step:5626 [D loss: 0.636386, acc.: 63.28%] [G loss: 0.906987]\n",
      "epoch:6 step:5627 [D loss: 0.696457, acc.: 57.81%] [G loss: 0.915168]\n",
      "epoch:6 step:5628 [D loss: 0.650650, acc.: 60.94%] [G loss: 0.970655]\n",
      "epoch:6 step:5629 [D loss: 0.642766, acc.: 65.62%] [G loss: 0.967023]\n",
      "epoch:6 step:5630 [D loss: 0.661462, acc.: 57.03%] [G loss: 0.939650]\n",
      "epoch:6 step:5631 [D loss: 0.618244, acc.: 71.09%] [G loss: 0.884253]\n",
      "epoch:6 step:5632 [D loss: 0.681139, acc.: 55.47%] [G loss: 0.875169]\n",
      "epoch:6 step:5633 [D loss: 0.610862, acc.: 64.06%] [G loss: 0.837026]\n",
      "epoch:6 step:5634 [D loss: 0.619594, acc.: 63.28%] [G loss: 0.911745]\n",
      "epoch:6 step:5635 [D loss: 0.649719, acc.: 64.06%] [G loss: 0.931447]\n",
      "epoch:6 step:5636 [D loss: 0.654267, acc.: 60.94%] [G loss: 0.976336]\n",
      "epoch:6 step:5637 [D loss: 0.610503, acc.: 68.75%] [G loss: 1.005734]\n",
      "epoch:6 step:5638 [D loss: 0.632814, acc.: 65.62%] [G loss: 0.972079]\n",
      "epoch:6 step:5639 [D loss: 0.686122, acc.: 56.25%] [G loss: 0.994443]\n",
      "epoch:6 step:5640 [D loss: 0.682080, acc.: 50.78%] [G loss: 0.976971]\n",
      "epoch:6 step:5641 [D loss: 0.678154, acc.: 58.59%] [G loss: 0.936455]\n",
      "epoch:6 step:5642 [D loss: 0.704747, acc.: 52.34%] [G loss: 0.940079]\n",
      "epoch:6 step:5643 [D loss: 0.666581, acc.: 58.59%] [G loss: 0.949941]\n",
      "epoch:6 step:5644 [D loss: 0.609560, acc.: 71.88%] [G loss: 0.945589]\n",
      "epoch:6 step:5645 [D loss: 0.681247, acc.: 59.38%] [G loss: 0.892005]\n",
      "epoch:6 step:5646 [D loss: 0.716981, acc.: 53.91%] [G loss: 0.900589]\n",
      "epoch:6 step:5647 [D loss: 0.640370, acc.: 63.28%] [G loss: 0.856182]\n",
      "epoch:6 step:5648 [D loss: 0.705804, acc.: 52.34%] [G loss: 0.880177]\n",
      "epoch:6 step:5649 [D loss: 0.686635, acc.: 53.12%] [G loss: 0.946659]\n",
      "epoch:6 step:5650 [D loss: 0.614416, acc.: 61.72%] [G loss: 0.926567]\n",
      "epoch:6 step:5651 [D loss: 0.640173, acc.: 61.72%] [G loss: 0.873253]\n",
      "epoch:6 step:5652 [D loss: 0.596064, acc.: 66.41%] [G loss: 0.878999]\n",
      "epoch:6 step:5653 [D loss: 0.627442, acc.: 65.62%] [G loss: 0.911305]\n",
      "epoch:6 step:5654 [D loss: 0.649016, acc.: 64.06%] [G loss: 0.821788]\n",
      "epoch:6 step:5655 [D loss: 0.623138, acc.: 61.72%] [G loss: 0.934639]\n",
      "epoch:6 step:5656 [D loss: 0.629795, acc.: 63.28%] [G loss: 0.868914]\n",
      "epoch:6 step:5657 [D loss: 0.681619, acc.: 59.38%] [G loss: 0.851480]\n",
      "epoch:6 step:5658 [D loss: 0.597754, acc.: 64.06%] [G loss: 0.961553]\n",
      "epoch:6 step:5659 [D loss: 0.665742, acc.: 60.94%] [G loss: 0.923518]\n",
      "epoch:6 step:5660 [D loss: 0.730871, acc.: 53.91%] [G loss: 0.863850]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5661 [D loss: 0.644354, acc.: 60.94%] [G loss: 0.890931]\n",
      "epoch:6 step:5662 [D loss: 0.606372, acc.: 74.22%] [G loss: 0.912516]\n",
      "epoch:6 step:5663 [D loss: 0.685967, acc.: 60.16%] [G loss: 0.877398]\n",
      "epoch:6 step:5664 [D loss: 0.651345, acc.: 64.84%] [G loss: 0.909196]\n",
      "epoch:6 step:5665 [D loss: 0.638858, acc.: 60.94%] [G loss: 0.967401]\n",
      "epoch:6 step:5666 [D loss: 0.724898, acc.: 42.19%] [G loss: 0.924945]\n",
      "epoch:6 step:5667 [D loss: 0.678065, acc.: 57.81%] [G loss: 0.974515]\n",
      "epoch:6 step:5668 [D loss: 0.684565, acc.: 54.69%] [G loss: 0.947783]\n",
      "epoch:6 step:5669 [D loss: 0.625640, acc.: 67.19%] [G loss: 0.887559]\n",
      "epoch:6 step:5670 [D loss: 0.650039, acc.: 61.72%] [G loss: 0.875886]\n",
      "epoch:6 step:5671 [D loss: 0.628369, acc.: 70.31%] [G loss: 0.934655]\n",
      "epoch:6 step:5672 [D loss: 0.645417, acc.: 59.38%] [G loss: 0.930824]\n",
      "epoch:6 step:5673 [D loss: 0.691670, acc.: 59.38%] [G loss: 0.888631]\n",
      "epoch:6 step:5674 [D loss: 0.654006, acc.: 60.16%] [G loss: 0.949315]\n",
      "epoch:6 step:5675 [D loss: 0.655613, acc.: 58.59%] [G loss: 0.958726]\n",
      "epoch:6 step:5676 [D loss: 0.634504, acc.: 69.53%] [G loss: 0.934743]\n",
      "epoch:6 step:5677 [D loss: 0.613735, acc.: 64.06%] [G loss: 0.983459]\n",
      "epoch:6 step:5678 [D loss: 0.624815, acc.: 68.75%] [G loss: 0.944978]\n",
      "epoch:6 step:5679 [D loss: 0.670886, acc.: 53.91%] [G loss: 0.936596]\n",
      "epoch:6 step:5680 [D loss: 0.645988, acc.: 60.94%] [G loss: 0.899018]\n",
      "epoch:6 step:5681 [D loss: 0.620769, acc.: 67.97%] [G loss: 0.900441]\n",
      "epoch:6 step:5682 [D loss: 0.669761, acc.: 61.72%] [G loss: 0.934937]\n",
      "epoch:6 step:5683 [D loss: 0.655194, acc.: 63.28%] [G loss: 0.870288]\n",
      "epoch:6 step:5684 [D loss: 0.676433, acc.: 56.25%] [G loss: 0.926572]\n",
      "epoch:6 step:5685 [D loss: 0.656130, acc.: 60.16%] [G loss: 0.924424]\n",
      "epoch:6 step:5686 [D loss: 0.688037, acc.: 62.50%] [G loss: 0.894959]\n",
      "epoch:6 step:5687 [D loss: 0.691406, acc.: 58.59%] [G loss: 0.893816]\n",
      "epoch:6 step:5688 [D loss: 0.608883, acc.: 67.97%] [G loss: 0.907878]\n",
      "epoch:6 step:5689 [D loss: 0.639778, acc.: 64.06%] [G loss: 0.882388]\n",
      "epoch:6 step:5690 [D loss: 0.638771, acc.: 64.84%] [G loss: 0.842953]\n",
      "epoch:6 step:5691 [D loss: 0.616142, acc.: 71.09%] [G loss: 0.876269]\n",
      "epoch:6 step:5692 [D loss: 0.587963, acc.: 74.22%] [G loss: 0.913938]\n",
      "epoch:6 step:5693 [D loss: 0.693370, acc.: 49.22%] [G loss: 0.926993]\n",
      "epoch:6 step:5694 [D loss: 0.637581, acc.: 62.50%] [G loss: 0.920251]\n",
      "epoch:6 step:5695 [D loss: 0.670025, acc.: 56.25%] [G loss: 0.873566]\n",
      "epoch:6 step:5696 [D loss: 0.594716, acc.: 67.97%] [G loss: 0.851251]\n",
      "epoch:6 step:5697 [D loss: 0.653878, acc.: 57.03%] [G loss: 0.962783]\n",
      "epoch:6 step:5698 [D loss: 0.588273, acc.: 68.75%] [G loss: 1.023895]\n",
      "epoch:6 step:5699 [D loss: 0.620019, acc.: 62.50%] [G loss: 1.054256]\n",
      "epoch:6 step:5700 [D loss: 0.756164, acc.: 49.22%] [G loss: 0.898602]\n",
      "epoch:6 step:5701 [D loss: 0.658810, acc.: 59.38%] [G loss: 0.870501]\n",
      "epoch:6 step:5702 [D loss: 0.665258, acc.: 56.25%] [G loss: 0.888323]\n",
      "epoch:6 step:5703 [D loss: 0.740724, acc.: 50.78%] [G loss: 0.843617]\n",
      "epoch:6 step:5704 [D loss: 0.667501, acc.: 57.81%] [G loss: 0.917751]\n",
      "epoch:6 step:5705 [D loss: 0.627289, acc.: 62.50%] [G loss: 0.990095]\n",
      "epoch:6 step:5706 [D loss: 0.612154, acc.: 66.41%] [G loss: 0.998688]\n",
      "epoch:6 step:5707 [D loss: 0.661791, acc.: 57.81%] [G loss: 0.939759]\n",
      "epoch:6 step:5708 [D loss: 0.632508, acc.: 66.41%] [G loss: 0.920263]\n",
      "epoch:6 step:5709 [D loss: 0.642083, acc.: 64.06%] [G loss: 0.895745]\n",
      "epoch:6 step:5710 [D loss: 0.635269, acc.: 61.72%] [G loss: 0.920963]\n",
      "epoch:6 step:5711 [D loss: 0.619707, acc.: 66.41%] [G loss: 0.968760]\n",
      "epoch:6 step:5712 [D loss: 0.657531, acc.: 61.72%] [G loss: 0.910601]\n",
      "epoch:6 step:5713 [D loss: 0.614986, acc.: 68.75%] [G loss: 0.915537]\n",
      "epoch:6 step:5714 [D loss: 0.619717, acc.: 69.53%] [G loss: 0.944930]\n",
      "epoch:6 step:5715 [D loss: 0.631680, acc.: 63.28%] [G loss: 0.888389]\n",
      "epoch:6 step:5716 [D loss: 0.642085, acc.: 60.94%] [G loss: 0.906330]\n",
      "epoch:6 step:5717 [D loss: 0.634534, acc.: 60.16%] [G loss: 0.943979]\n",
      "epoch:6 step:5718 [D loss: 0.639578, acc.: 62.50%] [G loss: 0.991913]\n",
      "epoch:6 step:5719 [D loss: 0.586372, acc.: 67.19%] [G loss: 0.961081]\n",
      "epoch:6 step:5720 [D loss: 0.657360, acc.: 54.69%] [G loss: 0.932027]\n",
      "epoch:6 step:5721 [D loss: 0.651300, acc.: 63.28%] [G loss: 0.882083]\n",
      "epoch:6 step:5722 [D loss: 0.612178, acc.: 66.41%] [G loss: 0.930287]\n",
      "epoch:6 step:5723 [D loss: 0.629772, acc.: 64.06%] [G loss: 0.925650]\n",
      "epoch:6 step:5724 [D loss: 0.659976, acc.: 60.94%] [G loss: 0.894850]\n",
      "epoch:6 step:5725 [D loss: 0.649371, acc.: 59.38%] [G loss: 0.932394]\n",
      "epoch:6 step:5726 [D loss: 0.705004, acc.: 55.47%] [G loss: 0.849251]\n",
      "epoch:6 step:5727 [D loss: 0.669547, acc.: 60.94%] [G loss: 0.879397]\n",
      "epoch:6 step:5728 [D loss: 0.629574, acc.: 67.97%] [G loss: 0.939941]\n",
      "epoch:6 step:5729 [D loss: 0.648140, acc.: 67.19%] [G loss: 1.020634]\n",
      "epoch:6 step:5730 [D loss: 0.687021, acc.: 53.91%] [G loss: 1.006291]\n",
      "epoch:6 step:5731 [D loss: 0.686027, acc.: 60.94%] [G loss: 0.958295]\n",
      "epoch:6 step:5732 [D loss: 0.656099, acc.: 60.94%] [G loss: 0.906735]\n",
      "epoch:6 step:5733 [D loss: 0.633016, acc.: 65.62%] [G loss: 0.962349]\n",
      "epoch:6 step:5734 [D loss: 0.615288, acc.: 68.75%] [G loss: 0.895578]\n",
      "epoch:6 step:5735 [D loss: 0.646017, acc.: 57.81%] [G loss: 0.917398]\n",
      "epoch:6 step:5736 [D loss: 0.663153, acc.: 61.72%] [G loss: 0.969536]\n",
      "epoch:6 step:5737 [D loss: 0.595082, acc.: 64.84%] [G loss: 1.004226]\n",
      "epoch:6 step:5738 [D loss: 0.621864, acc.: 63.28%] [G loss: 0.911063]\n",
      "epoch:6 step:5739 [D loss: 0.677035, acc.: 62.50%] [G loss: 0.950345]\n",
      "epoch:6 step:5740 [D loss: 0.625677, acc.: 69.53%] [G loss: 0.901304]\n",
      "epoch:6 step:5741 [D loss: 0.633207, acc.: 67.97%] [G loss: 1.012138]\n",
      "epoch:6 step:5742 [D loss: 0.705635, acc.: 58.59%] [G loss: 0.943602]\n",
      "epoch:6 step:5743 [D loss: 0.715226, acc.: 53.12%] [G loss: 0.917167]\n",
      "epoch:6 step:5744 [D loss: 0.632432, acc.: 69.53%] [G loss: 0.931617]\n",
      "epoch:6 step:5745 [D loss: 0.629134, acc.: 64.06%] [G loss: 0.973251]\n",
      "epoch:6 step:5746 [D loss: 0.719244, acc.: 51.56%] [G loss: 1.000275]\n",
      "epoch:6 step:5747 [D loss: 0.673548, acc.: 53.12%] [G loss: 0.984655]\n",
      "epoch:6 step:5748 [D loss: 0.616832, acc.: 65.62%] [G loss: 0.942071]\n",
      "epoch:6 step:5749 [D loss: 0.652310, acc.: 64.06%] [G loss: 0.874388]\n",
      "epoch:6 step:5750 [D loss: 0.685998, acc.: 56.25%] [G loss: 0.863908]\n",
      "epoch:6 step:5751 [D loss: 0.676978, acc.: 54.69%] [G loss: 0.845586]\n",
      "epoch:6 step:5752 [D loss: 0.633633, acc.: 62.50%] [G loss: 0.891151]\n",
      "epoch:6 step:5753 [D loss: 0.606189, acc.: 67.19%] [G loss: 0.915373]\n",
      "epoch:6 step:5754 [D loss: 0.623769, acc.: 67.19%] [G loss: 0.901648]\n",
      "epoch:6 step:5755 [D loss: 0.648723, acc.: 67.19%] [G loss: 0.948443]\n",
      "epoch:6 step:5756 [D loss: 0.626192, acc.: 64.84%] [G loss: 0.931539]\n",
      "epoch:6 step:5757 [D loss: 0.646596, acc.: 60.94%] [G loss: 0.912730]\n",
      "epoch:6 step:5758 [D loss: 0.632779, acc.: 64.06%] [G loss: 0.945472]\n",
      "epoch:6 step:5759 [D loss: 0.677446, acc.: 59.38%] [G loss: 0.907876]\n",
      "epoch:6 step:5760 [D loss: 0.665931, acc.: 57.03%] [G loss: 0.895174]\n",
      "epoch:6 step:5761 [D loss: 0.680479, acc.: 60.94%] [G loss: 0.899051]\n",
      "epoch:6 step:5762 [D loss: 0.708655, acc.: 49.22%] [G loss: 0.946757]\n",
      "epoch:6 step:5763 [D loss: 0.659005, acc.: 60.94%] [G loss: 0.875307]\n",
      "epoch:6 step:5764 [D loss: 0.651565, acc.: 60.16%] [G loss: 0.876719]\n",
      "epoch:6 step:5765 [D loss: 0.655481, acc.: 60.16%] [G loss: 0.853759]\n",
      "epoch:6 step:5766 [D loss: 0.690432, acc.: 60.16%] [G loss: 0.882014]\n",
      "epoch:6 step:5767 [D loss: 0.624915, acc.: 69.53%] [G loss: 0.890793]\n",
      "epoch:6 step:5768 [D loss: 0.664494, acc.: 58.59%] [G loss: 0.856210]\n",
      "epoch:6 step:5769 [D loss: 0.679163, acc.: 55.47%] [G loss: 0.817954]\n",
      "epoch:6 step:5770 [D loss: 0.655737, acc.: 63.28%] [G loss: 0.812431]\n",
      "epoch:6 step:5771 [D loss: 0.667180, acc.: 57.03%] [G loss: 0.849610]\n",
      "epoch:6 step:5772 [D loss: 0.718214, acc.: 52.34%] [G loss: 0.891570]\n",
      "epoch:6 step:5773 [D loss: 0.635435, acc.: 64.06%] [G loss: 0.881780]\n",
      "epoch:6 step:5774 [D loss: 0.669572, acc.: 60.16%] [G loss: 0.856448]\n",
      "epoch:6 step:5775 [D loss: 0.721023, acc.: 50.78%] [G loss: 0.877982]\n",
      "epoch:6 step:5776 [D loss: 0.670367, acc.: 54.69%] [G loss: 0.906579]\n",
      "epoch:6 step:5777 [D loss: 0.630205, acc.: 64.84%] [G loss: 0.923220]\n",
      "epoch:6 step:5778 [D loss: 0.643137, acc.: 63.28%] [G loss: 0.948372]\n",
      "epoch:6 step:5779 [D loss: 0.668046, acc.: 54.69%] [G loss: 0.899192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5780 [D loss: 0.637407, acc.: 67.19%] [G loss: 0.918941]\n",
      "epoch:6 step:5781 [D loss: 0.626005, acc.: 64.84%] [G loss: 0.920549]\n",
      "epoch:6 step:5782 [D loss: 0.689959, acc.: 55.47%] [G loss: 0.945623]\n",
      "epoch:6 step:5783 [D loss: 0.643617, acc.: 62.50%] [G loss: 1.036384]\n",
      "epoch:6 step:5784 [D loss: 0.686305, acc.: 58.59%] [G loss: 0.916187]\n",
      "epoch:6 step:5785 [D loss: 0.643846, acc.: 65.62%] [G loss: 0.882512]\n",
      "epoch:6 step:5786 [D loss: 0.629468, acc.: 67.97%] [G loss: 0.912221]\n",
      "epoch:6 step:5787 [D loss: 0.617946, acc.: 66.41%] [G loss: 0.883835]\n",
      "epoch:6 step:5788 [D loss: 0.640180, acc.: 61.72%] [G loss: 0.958332]\n",
      "epoch:6 step:5789 [D loss: 0.664254, acc.: 59.38%] [G loss: 0.868286]\n",
      "epoch:6 step:5790 [D loss: 0.656559, acc.: 60.16%] [G loss: 0.886484]\n",
      "epoch:6 step:5791 [D loss: 0.650514, acc.: 61.72%] [G loss: 0.890154]\n",
      "epoch:6 step:5792 [D loss: 0.651155, acc.: 61.72%] [G loss: 0.893602]\n",
      "epoch:6 step:5793 [D loss: 0.646543, acc.: 60.94%] [G loss: 0.906196]\n",
      "epoch:6 step:5794 [D loss: 0.650976, acc.: 62.50%] [G loss: 0.923552]\n",
      "epoch:6 step:5795 [D loss: 0.637746, acc.: 66.41%] [G loss: 0.869598]\n",
      "epoch:6 step:5796 [D loss: 0.672062, acc.: 55.47%] [G loss: 0.916467]\n",
      "epoch:6 step:5797 [D loss: 0.652792, acc.: 61.72%] [G loss: 0.889178]\n",
      "epoch:6 step:5798 [D loss: 0.636118, acc.: 64.84%] [G loss: 0.858610]\n",
      "epoch:6 step:5799 [D loss: 0.668388, acc.: 62.50%] [G loss: 0.897178]\n",
      "epoch:6 step:5800 [D loss: 0.658976, acc.: 60.94%] [G loss: 0.865595]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.544043\n",
      "FID: 12.125834\n",
      "0 = 11.876597424006508\n",
      "1 = 0.059135475891990315\n",
      "2 = 0.9433000087738037\n",
      "3 = 0.8925999999046326\n",
      "4 = 0.9940000176429749\n",
      "5 = 0.9933229684829712\n",
      "6 = 0.8925999999046326\n",
      "7 = 6.5059456360995584\n",
      "8 = 0.07357508979607824\n",
      "9 = 0.7575500011444092\n",
      "10 = 0.7207000255584717\n",
      "11 = 0.7943999767303467\n",
      "12 = 0.778041660785675\n",
      "13 = 0.7207000255584717\n",
      "14 = 7.544105052947998\n",
      "15 = 9.599637985229492\n",
      "16 = 0.10160238295793533\n",
      "17 = 7.544042587280273\n",
      "18 = 12.125833511352539\n",
      "epoch:6 step:5801 [D loss: 0.650361, acc.: 60.94%] [G loss: 0.879130]\n",
      "epoch:6 step:5802 [D loss: 0.735917, acc.: 50.78%] [G loss: 0.913375]\n",
      "epoch:6 step:5803 [D loss: 0.682719, acc.: 57.81%] [G loss: 0.900958]\n",
      "epoch:6 step:5804 [D loss: 0.713450, acc.: 50.78%] [G loss: 0.864825]\n",
      "epoch:6 step:5805 [D loss: 0.683848, acc.: 55.47%] [G loss: 0.936744]\n",
      "epoch:6 step:5806 [D loss: 0.663092, acc.: 64.84%] [G loss: 0.857932]\n",
      "epoch:6 step:5807 [D loss: 0.669492, acc.: 60.16%] [G loss: 0.870096]\n",
      "epoch:6 step:5808 [D loss: 0.672404, acc.: 62.50%] [G loss: 0.882547]\n",
      "epoch:6 step:5809 [D loss: 0.638700, acc.: 66.41%] [G loss: 0.904829]\n",
      "epoch:6 step:5810 [D loss: 0.739011, acc.: 48.44%] [G loss: 0.869162]\n",
      "epoch:6 step:5811 [D loss: 0.637364, acc.: 64.84%] [G loss: 0.871200]\n",
      "epoch:6 step:5812 [D loss: 0.661271, acc.: 53.91%] [G loss: 0.906609]\n",
      "epoch:6 step:5813 [D loss: 0.639366, acc.: 65.62%] [G loss: 0.915220]\n",
      "epoch:6 step:5814 [D loss: 0.636340, acc.: 66.41%] [G loss: 0.932903]\n",
      "epoch:6 step:5815 [D loss: 0.633758, acc.: 61.72%] [G loss: 0.930304]\n",
      "epoch:6 step:5816 [D loss: 0.649510, acc.: 64.06%] [G loss: 0.889391]\n",
      "epoch:6 step:5817 [D loss: 0.623127, acc.: 64.84%] [G loss: 0.949321]\n",
      "epoch:6 step:5818 [D loss: 0.691108, acc.: 59.38%] [G loss: 0.888557]\n",
      "epoch:6 step:5819 [D loss: 0.663650, acc.: 60.16%] [G loss: 0.866901]\n",
      "epoch:6 step:5820 [D loss: 0.597485, acc.: 67.19%] [G loss: 0.865508]\n",
      "epoch:6 step:5821 [D loss: 0.624616, acc.: 68.75%] [G loss: 0.901769]\n",
      "epoch:6 step:5822 [D loss: 0.733640, acc.: 47.66%] [G loss: 0.898866]\n",
      "epoch:6 step:5823 [D loss: 0.696562, acc.: 51.56%] [G loss: 0.846881]\n",
      "epoch:6 step:5824 [D loss: 0.680102, acc.: 55.47%] [G loss: 0.867395]\n",
      "epoch:6 step:5825 [D loss: 0.700273, acc.: 54.69%] [G loss: 0.871179]\n",
      "epoch:6 step:5826 [D loss: 0.654609, acc.: 62.50%] [G loss: 0.841344]\n",
      "epoch:6 step:5827 [D loss: 0.639875, acc.: 60.94%] [G loss: 0.888801]\n",
      "epoch:6 step:5828 [D loss: 0.625332, acc.: 58.59%] [G loss: 0.879004]\n",
      "epoch:6 step:5829 [D loss: 0.606453, acc.: 67.19%] [G loss: 0.877393]\n",
      "epoch:6 step:5830 [D loss: 0.639796, acc.: 65.62%] [G loss: 0.897398]\n",
      "epoch:6 step:5831 [D loss: 0.624184, acc.: 62.50%] [G loss: 0.913525]\n",
      "epoch:6 step:5832 [D loss: 0.711809, acc.: 55.47%] [G loss: 0.883015]\n",
      "epoch:6 step:5833 [D loss: 0.677473, acc.: 61.72%] [G loss: 0.918187]\n",
      "epoch:6 step:5834 [D loss: 0.652843, acc.: 62.50%] [G loss: 0.861552]\n",
      "epoch:6 step:5835 [D loss: 0.622624, acc.: 67.97%] [G loss: 0.895946]\n",
      "epoch:6 step:5836 [D loss: 0.674097, acc.: 55.47%] [G loss: 0.884676]\n",
      "epoch:6 step:5837 [D loss: 0.670917, acc.: 57.81%] [G loss: 0.882184]\n",
      "epoch:6 step:5838 [D loss: 0.644279, acc.: 63.28%] [G loss: 0.891405]\n",
      "epoch:6 step:5839 [D loss: 0.679597, acc.: 60.94%] [G loss: 0.886476]\n",
      "epoch:6 step:5840 [D loss: 0.625821, acc.: 67.19%] [G loss: 0.897044]\n",
      "epoch:6 step:5841 [D loss: 0.633651, acc.: 63.28%] [G loss: 0.863746]\n",
      "epoch:6 step:5842 [D loss: 0.745967, acc.: 51.56%] [G loss: 0.872077]\n",
      "epoch:6 step:5843 [D loss: 0.620340, acc.: 65.62%] [G loss: 0.954810]\n",
      "epoch:6 step:5844 [D loss: 0.621840, acc.: 61.72%] [G loss: 0.968061]\n",
      "epoch:6 step:5845 [D loss: 0.602073, acc.: 67.19%] [G loss: 0.956632]\n",
      "epoch:6 step:5846 [D loss: 0.680920, acc.: 58.59%] [G loss: 0.916215]\n",
      "epoch:6 step:5847 [D loss: 0.673604, acc.: 60.94%] [G loss: 0.869145]\n",
      "epoch:6 step:5848 [D loss: 0.672936, acc.: 53.91%] [G loss: 0.910054]\n",
      "epoch:6 step:5849 [D loss: 0.648197, acc.: 60.94%] [G loss: 0.897552]\n",
      "epoch:6 step:5850 [D loss: 0.709407, acc.: 48.44%] [G loss: 0.877508]\n",
      "epoch:6 step:5851 [D loss: 0.629969, acc.: 64.06%] [G loss: 0.897246]\n",
      "epoch:6 step:5852 [D loss: 0.592053, acc.: 72.66%] [G loss: 0.927523]\n",
      "epoch:6 step:5853 [D loss: 0.541430, acc.: 68.75%] [G loss: 0.959040]\n",
      "epoch:6 step:5854 [D loss: 0.551849, acc.: 73.44%] [G loss: 1.013302]\n",
      "epoch:6 step:5855 [D loss: 0.766766, acc.: 50.78%] [G loss: 0.940565]\n",
      "epoch:6 step:5856 [D loss: 0.690709, acc.: 57.81%] [G loss: 0.943962]\n",
      "epoch:6 step:5857 [D loss: 0.691293, acc.: 55.47%] [G loss: 0.926351]\n",
      "epoch:6 step:5858 [D loss: 0.656676, acc.: 63.28%] [G loss: 0.892023]\n",
      "epoch:6 step:5859 [D loss: 0.653045, acc.: 60.94%] [G loss: 0.940129]\n",
      "epoch:6 step:5860 [D loss: 0.690848, acc.: 57.03%] [G loss: 0.934341]\n",
      "epoch:6 step:5861 [D loss: 0.656199, acc.: 64.06%] [G loss: 0.952278]\n",
      "epoch:6 step:5862 [D loss: 0.655904, acc.: 59.38%] [G loss: 0.968130]\n",
      "epoch:6 step:5863 [D loss: 0.640900, acc.: 63.28%] [G loss: 0.940208]\n",
      "epoch:6 step:5864 [D loss: 0.644871, acc.: 58.59%] [G loss: 0.992318]\n",
      "epoch:6 step:5865 [D loss: 0.649878, acc.: 61.72%] [G loss: 0.901566]\n",
      "epoch:6 step:5866 [D loss: 0.647624, acc.: 64.84%] [G loss: 0.932305]\n",
      "epoch:6 step:5867 [D loss: 0.607803, acc.: 71.09%] [G loss: 0.944566]\n",
      "epoch:6 step:5868 [D loss: 0.684374, acc.: 60.16%] [G loss: 0.921968]\n",
      "epoch:6 step:5869 [D loss: 0.655815, acc.: 58.59%] [G loss: 0.926251]\n",
      "epoch:6 step:5870 [D loss: 0.619463, acc.: 65.62%] [G loss: 0.890307]\n",
      "epoch:6 step:5871 [D loss: 0.688052, acc.: 54.69%] [G loss: 0.910266]\n",
      "epoch:6 step:5872 [D loss: 0.739626, acc.: 46.09%] [G loss: 0.870444]\n",
      "epoch:6 step:5873 [D loss: 0.688411, acc.: 57.81%] [G loss: 0.916312]\n",
      "epoch:6 step:5874 [D loss: 0.652660, acc.: 63.28%] [G loss: 0.918460]\n",
      "epoch:6 step:5875 [D loss: 0.621715, acc.: 68.75%] [G loss: 0.884920]\n",
      "epoch:6 step:5876 [D loss: 0.605676, acc.: 71.09%] [G loss: 0.874944]\n",
      "epoch:6 step:5877 [D loss: 0.664764, acc.: 60.94%] [G loss: 0.934107]\n",
      "epoch:6 step:5878 [D loss: 0.618964, acc.: 65.62%] [G loss: 0.927921]\n",
      "epoch:6 step:5879 [D loss: 0.664541, acc.: 60.94%] [G loss: 0.893199]\n",
      "epoch:6 step:5880 [D loss: 0.667779, acc.: 54.69%] [G loss: 0.913761]\n",
      "epoch:6 step:5881 [D loss: 0.653638, acc.: 66.41%] [G loss: 0.956487]\n",
      "epoch:6 step:5882 [D loss: 0.701270, acc.: 51.56%] [G loss: 0.976178]\n",
      "epoch:6 step:5883 [D loss: 0.647552, acc.: 58.59%] [G loss: 0.873799]\n",
      "epoch:6 step:5884 [D loss: 0.621246, acc.: 64.84%] [G loss: 0.917215]\n",
      "epoch:6 step:5885 [D loss: 0.692389, acc.: 56.25%] [G loss: 0.915553]\n",
      "epoch:6 step:5886 [D loss: 0.634328, acc.: 69.53%] [G loss: 0.952023]\n",
      "epoch:6 step:5887 [D loss: 0.693649, acc.: 60.94%] [G loss: 0.884462]\n",
      "epoch:6 step:5888 [D loss: 0.661788, acc.: 60.16%] [G loss: 0.930945]\n",
      "epoch:6 step:5889 [D loss: 0.616058, acc.: 67.19%] [G loss: 0.866646]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5890 [D loss: 0.640220, acc.: 60.94%] [G loss: 0.838226]\n",
      "epoch:6 step:5891 [D loss: 0.650518, acc.: 62.50%] [G loss: 0.866554]\n",
      "epoch:6 step:5892 [D loss: 0.612248, acc.: 69.53%] [G loss: 0.864710]\n",
      "epoch:6 step:5893 [D loss: 0.620122, acc.: 66.41%] [G loss: 0.896241]\n",
      "epoch:6 step:5894 [D loss: 0.694765, acc.: 54.69%] [G loss: 0.898426]\n",
      "epoch:6 step:5895 [D loss: 0.662356, acc.: 61.72%] [G loss: 0.901657]\n",
      "epoch:6 step:5896 [D loss: 0.663692, acc.: 56.25%] [G loss: 0.862446]\n",
      "epoch:6 step:5897 [D loss: 0.672368, acc.: 58.59%] [G loss: 0.918415]\n",
      "epoch:6 step:5898 [D loss: 0.644361, acc.: 65.62%] [G loss: 0.868152]\n",
      "epoch:6 step:5899 [D loss: 0.704126, acc.: 51.56%] [G loss: 0.847470]\n",
      "epoch:6 step:5900 [D loss: 0.712122, acc.: 50.00%] [G loss: 0.859252]\n",
      "epoch:6 step:5901 [D loss: 0.631235, acc.: 65.62%] [G loss: 0.879745]\n",
      "epoch:6 step:5902 [D loss: 0.615941, acc.: 66.41%] [G loss: 0.900859]\n",
      "epoch:6 step:5903 [D loss: 0.687741, acc.: 59.38%] [G loss: 0.856164]\n",
      "epoch:6 step:5904 [D loss: 0.693002, acc.: 58.59%] [G loss: 0.840546]\n",
      "epoch:6 step:5905 [D loss: 0.640960, acc.: 62.50%] [G loss: 0.862471]\n",
      "epoch:6 step:5906 [D loss: 0.639304, acc.: 64.06%] [G loss: 0.896928]\n",
      "epoch:6 step:5907 [D loss: 0.618113, acc.: 68.75%] [G loss: 0.863119]\n",
      "epoch:6 step:5908 [D loss: 0.601824, acc.: 71.09%] [G loss: 0.921088]\n",
      "epoch:6 step:5909 [D loss: 0.657282, acc.: 59.38%] [G loss: 0.871665]\n",
      "epoch:6 step:5910 [D loss: 0.682580, acc.: 57.03%] [G loss: 0.919524]\n",
      "epoch:6 step:5911 [D loss: 0.590270, acc.: 73.44%] [G loss: 0.936225]\n",
      "epoch:6 step:5912 [D loss: 0.673089, acc.: 57.03%] [G loss: 0.876032]\n",
      "epoch:6 step:5913 [D loss: 0.686771, acc.: 53.91%] [G loss: 0.895526]\n",
      "epoch:6 step:5914 [D loss: 0.640784, acc.: 65.62%] [G loss: 0.890012]\n",
      "epoch:6 step:5915 [D loss: 0.644849, acc.: 63.28%] [G loss: 0.890629]\n",
      "epoch:6 step:5916 [D loss: 0.686674, acc.: 53.12%] [G loss: 0.862360]\n",
      "epoch:6 step:5917 [D loss: 0.649774, acc.: 60.94%] [G loss: 0.824499]\n",
      "epoch:6 step:5918 [D loss: 0.617620, acc.: 68.75%] [G loss: 0.883963]\n",
      "epoch:6 step:5919 [D loss: 0.661325, acc.: 60.16%] [G loss: 0.849273]\n",
      "epoch:6 step:5920 [D loss: 0.643015, acc.: 62.50%] [G loss: 0.916185]\n",
      "epoch:6 step:5921 [D loss: 0.633860, acc.: 59.38%] [G loss: 0.947677]\n",
      "epoch:6 step:5922 [D loss: 0.638576, acc.: 64.84%] [G loss: 0.917944]\n",
      "epoch:6 step:5923 [D loss: 0.711918, acc.: 53.12%] [G loss: 0.943831]\n",
      "epoch:6 step:5924 [D loss: 0.656801, acc.: 58.59%] [G loss: 0.875661]\n",
      "epoch:6 step:5925 [D loss: 0.661817, acc.: 59.38%] [G loss: 0.895973]\n",
      "epoch:6 step:5926 [D loss: 0.602617, acc.: 67.97%] [G loss: 0.923604]\n",
      "epoch:6 step:5927 [D loss: 0.611714, acc.: 69.53%] [G loss: 0.923175]\n",
      "epoch:6 step:5928 [D loss: 0.653218, acc.: 58.59%] [G loss: 0.933536]\n",
      "epoch:6 step:5929 [D loss: 0.637956, acc.: 58.59%] [G loss: 0.847913]\n",
      "epoch:6 step:5930 [D loss: 0.659982, acc.: 57.81%] [G loss: 0.888633]\n",
      "epoch:6 step:5931 [D loss: 0.609910, acc.: 65.62%] [G loss: 0.940175]\n",
      "epoch:6 step:5932 [D loss: 0.667706, acc.: 59.38%] [G loss: 0.910894]\n",
      "epoch:6 step:5933 [D loss: 0.631852, acc.: 62.50%] [G loss: 0.911008]\n",
      "epoch:6 step:5934 [D loss: 0.639563, acc.: 60.94%] [G loss: 0.974356]\n",
      "epoch:6 step:5935 [D loss: 0.609145, acc.: 68.75%] [G loss: 1.035917]\n",
      "epoch:6 step:5936 [D loss: 0.574485, acc.: 71.09%] [G loss: 0.998507]\n",
      "epoch:6 step:5937 [D loss: 0.609859, acc.: 65.62%] [G loss: 0.927134]\n",
      "epoch:6 step:5938 [D loss: 0.779280, acc.: 48.44%] [G loss: 0.937303]\n",
      "epoch:6 step:5939 [D loss: 0.707951, acc.: 52.34%] [G loss: 0.938817]\n",
      "epoch:6 step:5940 [D loss: 0.611631, acc.: 65.62%] [G loss: 0.897051]\n",
      "epoch:6 step:5941 [D loss: 0.672407, acc.: 58.59%] [G loss: 0.904108]\n",
      "epoch:6 step:5942 [D loss: 0.619353, acc.: 65.62%] [G loss: 0.945729]\n",
      "epoch:6 step:5943 [D loss: 0.563573, acc.: 72.66%] [G loss: 0.942710]\n",
      "epoch:6 step:5944 [D loss: 0.656977, acc.: 60.94%] [G loss: 0.958764]\n",
      "epoch:6 step:5945 [D loss: 0.701450, acc.: 55.47%] [G loss: 0.912947]\n",
      "epoch:6 step:5946 [D loss: 0.662057, acc.: 63.28%] [G loss: 0.941864]\n",
      "epoch:6 step:5947 [D loss: 0.658688, acc.: 60.16%] [G loss: 0.901638]\n",
      "epoch:6 step:5948 [D loss: 0.663875, acc.: 64.84%] [G loss: 0.910810]\n",
      "epoch:6 step:5949 [D loss: 0.625828, acc.: 62.50%] [G loss: 0.876498]\n",
      "epoch:6 step:5950 [D loss: 0.653993, acc.: 60.16%] [G loss: 0.956816]\n",
      "epoch:6 step:5951 [D loss: 0.668860, acc.: 57.81%] [G loss: 0.926794]\n",
      "epoch:6 step:5952 [D loss: 0.675166, acc.: 55.47%] [G loss: 0.914641]\n",
      "epoch:6 step:5953 [D loss: 0.640084, acc.: 61.72%] [G loss: 0.932633]\n",
      "epoch:6 step:5954 [D loss: 0.606407, acc.: 66.41%] [G loss: 0.951756]\n",
      "epoch:6 step:5955 [D loss: 0.622894, acc.: 64.84%] [G loss: 0.919652]\n",
      "epoch:6 step:5956 [D loss: 0.687625, acc.: 57.81%] [G loss: 0.901025]\n",
      "epoch:6 step:5957 [D loss: 0.633255, acc.: 65.62%] [G loss: 0.967889]\n",
      "epoch:6 step:5958 [D loss: 0.625686, acc.: 67.97%] [G loss: 0.954257]\n",
      "epoch:6 step:5959 [D loss: 0.681851, acc.: 60.94%] [G loss: 0.962304]\n",
      "epoch:6 step:5960 [D loss: 0.648341, acc.: 60.16%] [G loss: 0.923403]\n",
      "epoch:6 step:5961 [D loss: 0.665475, acc.: 62.50%] [G loss: 0.915675]\n",
      "epoch:6 step:5962 [D loss: 0.633201, acc.: 64.06%] [G loss: 0.922932]\n",
      "epoch:6 step:5963 [D loss: 0.698349, acc.: 60.16%] [G loss: 0.845621]\n",
      "epoch:6 step:5964 [D loss: 0.724432, acc.: 48.44%] [G loss: 0.859270]\n",
      "epoch:6 step:5965 [D loss: 0.586645, acc.: 67.19%] [G loss: 0.869467]\n",
      "epoch:6 step:5966 [D loss: 0.616053, acc.: 65.62%] [G loss: 0.934361]\n",
      "epoch:6 step:5967 [D loss: 0.589499, acc.: 68.75%] [G loss: 0.937792]\n",
      "epoch:6 step:5968 [D loss: 0.645118, acc.: 53.91%] [G loss: 0.986459]\n",
      "epoch:6 step:5969 [D loss: 0.532623, acc.: 73.44%] [G loss: 0.999783]\n",
      "epoch:6 step:5970 [D loss: 0.733932, acc.: 53.12%] [G loss: 0.930037]\n",
      "epoch:6 step:5971 [D loss: 0.739682, acc.: 45.31%] [G loss: 0.899580]\n",
      "epoch:6 step:5972 [D loss: 0.646371, acc.: 60.16%] [G loss: 0.869798]\n",
      "epoch:6 step:5973 [D loss: 0.655603, acc.: 64.84%] [G loss: 0.885380]\n",
      "epoch:6 step:5974 [D loss: 0.653455, acc.: 58.59%] [G loss: 0.999714]\n",
      "epoch:6 step:5975 [D loss: 0.631781, acc.: 61.72%] [G loss: 0.925656]\n",
      "epoch:6 step:5976 [D loss: 0.610046, acc.: 63.28%] [G loss: 0.975029]\n",
      "epoch:6 step:5977 [D loss: 0.678503, acc.: 60.16%] [G loss: 0.927524]\n",
      "epoch:6 step:5978 [D loss: 0.701802, acc.: 59.38%] [G loss: 0.942488]\n",
      "epoch:6 step:5979 [D loss: 0.640479, acc.: 59.38%] [G loss: 0.983924]\n",
      "epoch:6 step:5980 [D loss: 0.590279, acc.: 67.19%] [G loss: 0.994771]\n",
      "epoch:6 step:5981 [D loss: 0.596796, acc.: 68.75%] [G loss: 0.976333]\n",
      "epoch:6 step:5982 [D loss: 0.616345, acc.: 64.06%] [G loss: 0.944371]\n",
      "epoch:6 step:5983 [D loss: 0.621328, acc.: 64.84%] [G loss: 0.967402]\n",
      "epoch:6 step:5984 [D loss: 0.714272, acc.: 53.91%] [G loss: 0.934217]\n",
      "epoch:6 step:5985 [D loss: 0.685173, acc.: 53.91%] [G loss: 0.861079]\n",
      "epoch:6 step:5986 [D loss: 0.592952, acc.: 69.53%] [G loss: 0.917970]\n",
      "epoch:6 step:5987 [D loss: 0.640636, acc.: 64.06%] [G loss: 0.933396]\n",
      "epoch:6 step:5988 [D loss: 0.667116, acc.: 56.25%] [G loss: 0.894028]\n",
      "epoch:6 step:5989 [D loss: 0.629095, acc.: 62.50%] [G loss: 0.901186]\n",
      "epoch:6 step:5990 [D loss: 0.660233, acc.: 57.81%] [G loss: 0.892185]\n",
      "epoch:6 step:5991 [D loss: 0.708975, acc.: 51.56%] [G loss: 0.932995]\n",
      "epoch:6 step:5992 [D loss: 0.624680, acc.: 60.94%] [G loss: 0.968826]\n",
      "epoch:6 step:5993 [D loss: 0.614079, acc.: 71.09%] [G loss: 0.957706]\n",
      "epoch:6 step:5994 [D loss: 0.638129, acc.: 64.06%] [G loss: 0.929033]\n",
      "epoch:6 step:5995 [D loss: 0.700858, acc.: 53.12%] [G loss: 0.966224]\n",
      "epoch:6 step:5996 [D loss: 0.600225, acc.: 68.75%] [G loss: 0.923982]\n",
      "epoch:6 step:5997 [D loss: 0.659228, acc.: 62.50%] [G loss: 0.939653]\n",
      "epoch:6 step:5998 [D loss: 0.718453, acc.: 48.44%] [G loss: 0.892763]\n",
      "epoch:6 step:5999 [D loss: 0.714154, acc.: 52.34%] [G loss: 0.859043]\n",
      "epoch:6 step:6000 [D loss: 0.681573, acc.: 57.81%] [G loss: 0.951463]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.366568\n",
      "FID: 15.986276\n",
      "0 = 11.852982346272448\n",
      "1 = 0.05591513245131715\n",
      "2 = 0.9361000061035156\n",
      "3 = 0.8790000081062317\n",
      "4 = 0.9932000041007996\n",
      "5 = 0.9923233389854431\n",
      "6 = 0.8790000081062317\n",
      "7 = 6.8859034793287615\n",
      "8 = 0.08590558933463331\n",
      "9 = 0.777999997138977\n",
      "10 = 0.7444999814033508\n",
      "11 = 0.8115000128746033\n",
      "12 = 0.797963559627533\n",
      "13 = 0.7444999814033508\n",
      "14 = 7.366633892059326\n",
      "15 = 9.5936279296875\n",
      "16 = 0.10807254910469055\n",
      "17 = 7.366568088531494\n",
      "18 = 15.986275672912598\n",
      "epoch:6 step:6001 [D loss: 0.672425, acc.: 56.25%] [G loss: 0.906011]\n",
      "epoch:6 step:6002 [D loss: 0.650767, acc.: 59.38%] [G loss: 0.896600]\n",
      "epoch:6 step:6003 [D loss: 0.631210, acc.: 60.94%] [G loss: 0.899088]\n",
      "epoch:6 step:6004 [D loss: 0.664913, acc.: 58.59%] [G loss: 0.942683]\n",
      "epoch:6 step:6005 [D loss: 0.698510, acc.: 53.12%] [G loss: 0.856719]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6006 [D loss: 0.638396, acc.: 63.28%] [G loss: 0.887856]\n",
      "epoch:6 step:6007 [D loss: 0.640542, acc.: 66.41%] [G loss: 0.881338]\n",
      "epoch:6 step:6008 [D loss: 0.660405, acc.: 60.16%] [G loss: 0.846788]\n",
      "epoch:6 step:6009 [D loss: 0.674191, acc.: 57.81%] [G loss: 0.846015]\n",
      "epoch:6 step:6010 [D loss: 0.605209, acc.: 71.09%] [G loss: 0.919783]\n",
      "epoch:6 step:6011 [D loss: 0.661391, acc.: 63.28%] [G loss: 0.879229]\n",
      "epoch:6 step:6012 [D loss: 0.642719, acc.: 68.75%] [G loss: 0.904462]\n",
      "epoch:6 step:6013 [D loss: 0.628759, acc.: 64.84%] [G loss: 0.905639]\n",
      "epoch:6 step:6014 [D loss: 0.634192, acc.: 63.28%] [G loss: 0.904215]\n",
      "epoch:6 step:6015 [D loss: 0.676584, acc.: 57.81%] [G loss: 0.850163]\n",
      "epoch:6 step:6016 [D loss: 0.649841, acc.: 57.81%] [G loss: 0.871255]\n",
      "epoch:6 step:6017 [D loss: 0.673811, acc.: 52.34%] [G loss: 0.840965]\n",
      "epoch:6 step:6018 [D loss: 0.652956, acc.: 57.81%] [G loss: 0.898203]\n",
      "epoch:6 step:6019 [D loss: 0.611788, acc.: 67.97%] [G loss: 0.859623]\n",
      "epoch:6 step:6020 [D loss: 0.629769, acc.: 66.41%] [G loss: 0.929465]\n",
      "epoch:6 step:6021 [D loss: 0.617834, acc.: 65.62%] [G loss: 0.908759]\n",
      "epoch:6 step:6022 [D loss: 0.696131, acc.: 50.78%] [G loss: 0.867847]\n",
      "epoch:6 step:6023 [D loss: 0.710005, acc.: 53.12%] [G loss: 0.837156]\n",
      "epoch:6 step:6024 [D loss: 0.649248, acc.: 64.84%] [G loss: 0.880363]\n",
      "epoch:6 step:6025 [D loss: 0.672474, acc.: 54.69%] [G loss: 0.874852]\n",
      "epoch:6 step:6026 [D loss: 0.687300, acc.: 55.47%] [G loss: 0.928057]\n",
      "epoch:6 step:6027 [D loss: 0.644578, acc.: 67.19%] [G loss: 0.931642]\n",
      "epoch:6 step:6028 [D loss: 0.625317, acc.: 66.41%] [G loss: 0.924273]\n",
      "epoch:6 step:6029 [D loss: 0.709308, acc.: 48.44%] [G loss: 0.932773]\n",
      "epoch:6 step:6030 [D loss: 0.699088, acc.: 55.47%] [G loss: 0.948108]\n",
      "epoch:6 step:6031 [D loss: 0.653342, acc.: 55.47%] [G loss: 0.916286]\n",
      "epoch:6 step:6032 [D loss: 0.670426, acc.: 58.59%] [G loss: 0.941842]\n",
      "epoch:6 step:6033 [D loss: 0.611274, acc.: 65.62%] [G loss: 0.910217]\n",
      "epoch:6 step:6034 [D loss: 0.645860, acc.: 64.06%] [G loss: 0.897601]\n",
      "epoch:6 step:6035 [D loss: 0.646273, acc.: 66.41%] [G loss: 0.819279]\n",
      "epoch:6 step:6036 [D loss: 0.658468, acc.: 64.84%] [G loss: 0.826894]\n",
      "epoch:6 step:6037 [D loss: 0.681151, acc.: 55.47%] [G loss: 0.861965]\n",
      "epoch:6 step:6038 [D loss: 0.632020, acc.: 64.84%] [G loss: 0.877470]\n",
      "epoch:6 step:6039 [D loss: 0.699073, acc.: 53.91%] [G loss: 0.904644]\n",
      "epoch:6 step:6040 [D loss: 0.699361, acc.: 56.25%] [G loss: 0.874389]\n",
      "epoch:6 step:6041 [D loss: 0.678010, acc.: 58.59%] [G loss: 0.841717]\n",
      "epoch:6 step:6042 [D loss: 0.669547, acc.: 58.59%] [G loss: 0.886575]\n",
      "epoch:6 step:6043 [D loss: 0.686374, acc.: 58.59%] [G loss: 0.890325]\n",
      "epoch:6 step:6044 [D loss: 0.720379, acc.: 47.66%] [G loss: 0.898801]\n",
      "epoch:6 step:6045 [D loss: 0.668462, acc.: 60.94%] [G loss: 0.873984]\n",
      "epoch:6 step:6046 [D loss: 0.676925, acc.: 64.84%] [G loss: 0.930307]\n",
      "epoch:6 step:6047 [D loss: 0.618425, acc.: 63.28%] [G loss: 0.892656]\n",
      "epoch:6 step:6048 [D loss: 0.638482, acc.: 67.19%] [G loss: 0.944319]\n",
      "epoch:6 step:6049 [D loss: 0.624480, acc.: 67.19%] [G loss: 0.920633]\n",
      "epoch:6 step:6050 [D loss: 0.598732, acc.: 70.31%] [G loss: 0.938458]\n",
      "epoch:6 step:6051 [D loss: 0.632097, acc.: 57.81%] [G loss: 0.924875]\n",
      "epoch:6 step:6052 [D loss: 0.618328, acc.: 66.41%] [G loss: 0.917152]\n",
      "epoch:6 step:6053 [D loss: 0.657180, acc.: 55.47%] [G loss: 0.868906]\n",
      "epoch:6 step:6054 [D loss: 0.678600, acc.: 53.91%] [G loss: 0.894849]\n",
      "epoch:6 step:6055 [D loss: 0.700752, acc.: 53.91%] [G loss: 0.904260]\n",
      "epoch:6 step:6056 [D loss: 0.665170, acc.: 62.50%] [G loss: 0.862508]\n",
      "epoch:6 step:6057 [D loss: 0.640892, acc.: 64.06%] [G loss: 0.880653]\n",
      "epoch:6 step:6058 [D loss: 0.642540, acc.: 64.84%] [G loss: 0.912521]\n",
      "epoch:6 step:6059 [D loss: 0.761955, acc.: 46.09%] [G loss: 0.887216]\n",
      "epoch:6 step:6060 [D loss: 0.690350, acc.: 54.69%] [G loss: 0.877829]\n",
      "epoch:6 step:6061 [D loss: 0.697419, acc.: 53.12%] [G loss: 0.927358]\n",
      "epoch:6 step:6062 [D loss: 0.660141, acc.: 64.06%] [G loss: 0.930392]\n",
      "epoch:6 step:6063 [D loss: 0.678454, acc.: 60.16%] [G loss: 0.989337]\n",
      "epoch:6 step:6064 [D loss: 0.634487, acc.: 61.72%] [G loss: 0.883238]\n",
      "epoch:6 step:6065 [D loss: 0.675196, acc.: 61.72%] [G loss: 0.883098]\n",
      "epoch:6 step:6066 [D loss: 0.652667, acc.: 65.62%] [G loss: 0.898168]\n",
      "epoch:6 step:6067 [D loss: 0.617868, acc.: 65.62%] [G loss: 0.935603]\n",
      "epoch:6 step:6068 [D loss: 0.609410, acc.: 72.66%] [G loss: 0.913036]\n",
      "epoch:6 step:6069 [D loss: 0.654125, acc.: 66.41%] [G loss: 0.923792]\n",
      "epoch:6 step:6070 [D loss: 0.705778, acc.: 57.81%] [G loss: 0.821166]\n",
      "epoch:6 step:6071 [D loss: 0.657934, acc.: 63.28%] [G loss: 0.856623]\n",
      "epoch:6 step:6072 [D loss: 0.680507, acc.: 62.50%] [G loss: 0.811024]\n",
      "epoch:6 step:6073 [D loss: 0.636391, acc.: 67.19%] [G loss: 0.871951]\n",
      "epoch:6 step:6074 [D loss: 0.652888, acc.: 62.50%] [G loss: 0.944081]\n",
      "epoch:6 step:6075 [D loss: 0.603716, acc.: 65.62%] [G loss: 0.916075]\n",
      "epoch:6 step:6076 [D loss: 0.659443, acc.: 58.59%] [G loss: 0.862024]\n",
      "epoch:6 step:6077 [D loss: 0.674411, acc.: 55.47%] [G loss: 0.879532]\n",
      "epoch:6 step:6078 [D loss: 0.691037, acc.: 53.91%] [G loss: 0.850198]\n",
      "epoch:6 step:6079 [D loss: 0.624861, acc.: 66.41%] [G loss: 0.846475]\n",
      "epoch:6 step:6080 [D loss: 0.706619, acc.: 53.91%] [G loss: 0.860400]\n",
      "epoch:6 step:6081 [D loss: 0.683122, acc.: 49.22%] [G loss: 0.868461]\n",
      "epoch:6 step:6082 [D loss: 0.672734, acc.: 57.81%] [G loss: 0.826647]\n",
      "epoch:6 step:6083 [D loss: 0.640054, acc.: 63.28%] [G loss: 0.829298]\n",
      "epoch:6 step:6084 [D loss: 0.669085, acc.: 56.25%] [G loss: 0.866595]\n",
      "epoch:6 step:6085 [D loss: 0.667870, acc.: 55.47%] [G loss: 0.846427]\n",
      "epoch:6 step:6086 [D loss: 0.663651, acc.: 57.03%] [G loss: 0.873600]\n",
      "epoch:6 step:6087 [D loss: 0.706477, acc.: 57.81%] [G loss: 0.842696]\n",
      "epoch:6 step:6088 [D loss: 0.623738, acc.: 64.06%] [G loss: 0.830033]\n",
      "epoch:6 step:6089 [D loss: 0.654926, acc.: 59.38%] [G loss: 0.884402]\n",
      "epoch:6 step:6090 [D loss: 0.645450, acc.: 60.16%] [G loss: 0.869075]\n",
      "epoch:6 step:6091 [D loss: 0.626951, acc.: 67.97%] [G loss: 0.945535]\n",
      "epoch:6 step:6092 [D loss: 0.659798, acc.: 57.03%] [G loss: 0.943702]\n",
      "epoch:6 step:6093 [D loss: 0.585380, acc.: 73.44%] [G loss: 0.995697]\n",
      "epoch:6 step:6094 [D loss: 0.631129, acc.: 62.50%] [G loss: 0.978306]\n",
      "epoch:6 step:6095 [D loss: 0.724702, acc.: 48.44%] [G loss: 0.914940]\n",
      "epoch:6 step:6096 [D loss: 0.672133, acc.: 58.59%] [G loss: 0.938839]\n",
      "epoch:6 step:6097 [D loss: 0.624159, acc.: 63.28%] [G loss: 0.970950]\n",
      "epoch:6 step:6098 [D loss: 0.645850, acc.: 66.41%] [G loss: 0.931766]\n",
      "epoch:6 step:6099 [D loss: 0.785115, acc.: 42.19%] [G loss: 0.882172]\n",
      "epoch:6 step:6100 [D loss: 0.682764, acc.: 57.81%] [G loss: 0.819488]\n",
      "epoch:6 step:6101 [D loss: 0.629654, acc.: 70.31%] [G loss: 0.895606]\n",
      "epoch:6 step:6102 [D loss: 0.665583, acc.: 56.25%] [G loss: 0.946057]\n",
      "epoch:6 step:6103 [D loss: 0.641937, acc.: 60.94%] [G loss: 0.949774]\n",
      "epoch:6 step:6104 [D loss: 0.714055, acc.: 51.56%] [G loss: 0.912340]\n",
      "epoch:6 step:6105 [D loss: 0.676994, acc.: 60.94%] [G loss: 0.877118]\n",
      "epoch:6 step:6106 [D loss: 0.627888, acc.: 64.84%] [G loss: 0.924128]\n",
      "epoch:6 step:6107 [D loss: 0.631904, acc.: 60.16%] [G loss: 0.954179]\n",
      "epoch:6 step:6108 [D loss: 0.666633, acc.: 61.72%] [G loss: 0.872830]\n",
      "epoch:6 step:6109 [D loss: 0.669155, acc.: 59.38%] [G loss: 0.881759]\n",
      "epoch:6 step:6110 [D loss: 0.632652, acc.: 63.28%] [G loss: 0.895849]\n",
      "epoch:6 step:6111 [D loss: 0.724778, acc.: 50.00%] [G loss: 0.856939]\n",
      "epoch:6 step:6112 [D loss: 0.672253, acc.: 63.28%] [G loss: 0.942358]\n",
      "epoch:6 step:6113 [D loss: 0.650496, acc.: 64.06%] [G loss: 0.915613]\n",
      "epoch:6 step:6114 [D loss: 0.676475, acc.: 60.94%] [G loss: 0.929188]\n",
      "epoch:6 step:6115 [D loss: 0.648010, acc.: 60.94%] [G loss: 0.882232]\n",
      "epoch:6 step:6116 [D loss: 0.631272, acc.: 67.19%] [G loss: 0.885557]\n",
      "epoch:6 step:6117 [D loss: 0.637836, acc.: 66.41%] [G loss: 0.861688]\n",
      "epoch:6 step:6118 [D loss: 0.672875, acc.: 61.72%] [G loss: 0.910130]\n",
      "epoch:6 step:6119 [D loss: 0.643634, acc.: 62.50%] [G loss: 0.891380]\n",
      "epoch:6 step:6120 [D loss: 0.637532, acc.: 65.62%] [G loss: 0.895109]\n",
      "epoch:6 step:6121 [D loss: 0.597140, acc.: 72.66%] [G loss: 0.958978]\n",
      "epoch:6 step:6122 [D loss: 0.701266, acc.: 60.94%] [G loss: 0.917536]\n",
      "epoch:6 step:6123 [D loss: 0.725275, acc.: 54.69%] [G loss: 0.811495]\n",
      "epoch:6 step:6124 [D loss: 0.680071, acc.: 53.12%] [G loss: 0.876966]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6125 [D loss: 0.652764, acc.: 63.28%] [G loss: 0.897845]\n",
      "epoch:6 step:6126 [D loss: 0.568209, acc.: 75.78%] [G loss: 0.921819]\n",
      "epoch:6 step:6127 [D loss: 0.600121, acc.: 66.41%] [G loss: 0.858182]\n",
      "epoch:6 step:6128 [D loss: 0.674320, acc.: 53.91%] [G loss: 0.927368]\n",
      "epoch:6 step:6129 [D loss: 0.620258, acc.: 64.06%] [G loss: 0.904795]\n",
      "epoch:6 step:6130 [D loss: 0.590070, acc.: 64.84%] [G loss: 0.954327]\n",
      "epoch:6 step:6131 [D loss: 0.689800, acc.: 54.69%] [G loss: 0.871669]\n",
      "epoch:6 step:6132 [D loss: 0.708527, acc.: 54.69%] [G loss: 0.909227]\n",
      "epoch:6 step:6133 [D loss: 0.711876, acc.: 50.78%] [G loss: 0.830793]\n",
      "epoch:6 step:6134 [D loss: 0.677086, acc.: 57.03%] [G loss: 0.825138]\n",
      "epoch:6 step:6135 [D loss: 0.609657, acc.: 67.97%] [G loss: 0.925263]\n",
      "epoch:6 step:6136 [D loss: 0.664914, acc.: 62.50%] [G loss: 0.905202]\n",
      "epoch:6 step:6137 [D loss: 0.594007, acc.: 71.09%] [G loss: 0.943749]\n",
      "epoch:6 step:6138 [D loss: 0.645875, acc.: 62.50%] [G loss: 0.937793]\n",
      "epoch:6 step:6139 [D loss: 0.657918, acc.: 60.94%] [G loss: 0.897141]\n",
      "epoch:6 step:6140 [D loss: 0.637282, acc.: 64.06%] [G loss: 0.917043]\n",
      "epoch:6 step:6141 [D loss: 0.636446, acc.: 58.59%] [G loss: 0.951831]\n",
      "epoch:6 step:6142 [D loss: 0.608637, acc.: 69.53%] [G loss: 0.888405]\n",
      "epoch:6 step:6143 [D loss: 0.619438, acc.: 63.28%] [G loss: 0.864130]\n",
      "epoch:6 step:6144 [D loss: 0.643286, acc.: 61.72%] [G loss: 0.927272]\n",
      "epoch:6 step:6145 [D loss: 0.624567, acc.: 66.41%] [G loss: 0.848063]\n",
      "epoch:6 step:6146 [D loss: 0.683823, acc.: 53.12%] [G loss: 0.890990]\n",
      "epoch:6 step:6147 [D loss: 0.665938, acc.: 58.59%] [G loss: 0.877364]\n",
      "epoch:6 step:6148 [D loss: 0.655938, acc.: 60.16%] [G loss: 0.967659]\n",
      "epoch:6 step:6149 [D loss: 0.653278, acc.: 64.06%] [G loss: 0.869132]\n",
      "epoch:6 step:6150 [D loss: 0.677341, acc.: 57.03%] [G loss: 0.895928]\n",
      "epoch:6 step:6151 [D loss: 0.680126, acc.: 53.12%] [G loss: 0.871715]\n",
      "epoch:6 step:6152 [D loss: 0.623439, acc.: 60.94%] [G loss: 0.876718]\n",
      "epoch:6 step:6153 [D loss: 0.675853, acc.: 58.59%] [G loss: 0.864516]\n",
      "epoch:6 step:6154 [D loss: 0.689188, acc.: 62.50%] [G loss: 0.858447]\n",
      "epoch:6 step:6155 [D loss: 0.660116, acc.: 58.59%] [G loss: 0.881434]\n",
      "epoch:6 step:6156 [D loss: 0.602871, acc.: 68.75%] [G loss: 0.875204]\n",
      "epoch:6 step:6157 [D loss: 0.696941, acc.: 52.34%] [G loss: 0.826348]\n",
      "epoch:6 step:6158 [D loss: 0.658906, acc.: 60.94%] [G loss: 0.825291]\n",
      "epoch:6 step:6159 [D loss: 0.670760, acc.: 60.16%] [G loss: 0.854229]\n",
      "epoch:6 step:6160 [D loss: 0.680332, acc.: 56.25%] [G loss: 0.913192]\n",
      "epoch:6 step:6161 [D loss: 0.632605, acc.: 64.84%] [G loss: 0.887743]\n",
      "epoch:6 step:6162 [D loss: 0.683474, acc.: 57.81%] [G loss: 0.931268]\n",
      "epoch:6 step:6163 [D loss: 0.624816, acc.: 64.06%] [G loss: 0.891674]\n",
      "epoch:6 step:6164 [D loss: 0.676006, acc.: 54.69%] [G loss: 0.868260]\n",
      "epoch:6 step:6165 [D loss: 0.670978, acc.: 60.94%] [G loss: 0.817264]\n",
      "epoch:6 step:6166 [D loss: 0.693042, acc.: 56.25%] [G loss: 0.896783]\n",
      "epoch:6 step:6167 [D loss: 0.639495, acc.: 65.62%] [G loss: 0.831840]\n",
      "epoch:6 step:6168 [D loss: 0.621577, acc.: 67.97%] [G loss: 0.932979]\n",
      "epoch:6 step:6169 [D loss: 0.622283, acc.: 65.62%] [G loss: 0.961136]\n",
      "epoch:6 step:6170 [D loss: 0.610267, acc.: 66.41%] [G loss: 0.982315]\n",
      "epoch:6 step:6171 [D loss: 0.630144, acc.: 66.41%] [G loss: 0.923006]\n",
      "epoch:6 step:6172 [D loss: 0.623842, acc.: 65.62%] [G loss: 0.966744]\n",
      "epoch:6 step:6173 [D loss: 0.625114, acc.: 59.38%] [G loss: 0.925248]\n",
      "epoch:6 step:6174 [D loss: 0.653653, acc.: 62.50%] [G loss: 0.923614]\n",
      "epoch:6 step:6175 [D loss: 0.692504, acc.: 53.12%] [G loss: 0.911887]\n",
      "epoch:6 step:6176 [D loss: 0.574215, acc.: 66.41%] [G loss: 0.936838]\n",
      "epoch:6 step:6177 [D loss: 0.627200, acc.: 66.41%] [G loss: 0.950993]\n",
      "epoch:6 step:6178 [D loss: 0.597480, acc.: 66.41%] [G loss: 0.967299]\n",
      "epoch:6 step:6179 [D loss: 0.651087, acc.: 64.06%] [G loss: 0.912222]\n",
      "epoch:6 step:6180 [D loss: 0.600128, acc.: 67.19%] [G loss: 0.900172]\n",
      "epoch:6 step:6181 [D loss: 0.701056, acc.: 55.47%] [G loss: 0.871814]\n",
      "epoch:6 step:6182 [D loss: 0.739626, acc.: 51.56%] [G loss: 0.905393]\n",
      "epoch:6 step:6183 [D loss: 0.627982, acc.: 64.06%] [G loss: 0.926042]\n",
      "epoch:6 step:6184 [D loss: 0.643129, acc.: 69.53%] [G loss: 0.929538]\n",
      "epoch:6 step:6185 [D loss: 0.642694, acc.: 64.06%] [G loss: 0.906066]\n",
      "epoch:6 step:6186 [D loss: 0.589589, acc.: 72.66%] [G loss: 0.919945]\n",
      "epoch:6 step:6187 [D loss: 0.695259, acc.: 54.69%] [G loss: 0.979431]\n",
      "epoch:6 step:6188 [D loss: 0.731479, acc.: 53.12%] [G loss: 0.899411]\n",
      "epoch:6 step:6189 [D loss: 0.645362, acc.: 63.28%] [G loss: 0.947087]\n",
      "epoch:6 step:6190 [D loss: 0.596714, acc.: 68.75%] [G loss: 0.863945]\n",
      "epoch:6 step:6191 [D loss: 0.716789, acc.: 50.78%] [G loss: 0.856370]\n",
      "epoch:6 step:6192 [D loss: 0.644551, acc.: 64.84%] [G loss: 0.851990]\n",
      "epoch:6 step:6193 [D loss: 0.637461, acc.: 59.38%] [G loss: 0.862219]\n",
      "epoch:6 step:6194 [D loss: 0.634136, acc.: 61.72%] [G loss: 0.865485]\n",
      "epoch:6 step:6195 [D loss: 0.606917, acc.: 67.19%] [G loss: 0.892706]\n",
      "epoch:6 step:6196 [D loss: 0.582827, acc.: 71.09%] [G loss: 0.875504]\n",
      "epoch:6 step:6197 [D loss: 0.573217, acc.: 67.19%] [G loss: 0.920694]\n",
      "epoch:6 step:6198 [D loss: 0.695765, acc.: 54.69%] [G loss: 0.921462]\n",
      "epoch:6 step:6199 [D loss: 0.693357, acc.: 64.84%] [G loss: 0.903770]\n",
      "epoch:6 step:6200 [D loss: 0.661553, acc.: 64.06%] [G loss: 0.955002]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.468212\n",
      "FID: 15.959558\n",
      "0 = 11.874779389238265\n",
      "1 = 0.05881205264498016\n",
      "2 = 0.9423999786376953\n",
      "3 = 0.890500009059906\n",
      "4 = 0.9943000078201294\n",
      "5 = 0.9936398267745972\n",
      "6 = 0.890500009059906\n",
      "7 = 6.903025639086961\n",
      "8 = 0.08867582740881634\n",
      "9 = 0.771049976348877\n",
      "10 = 0.7379000186920166\n",
      "11 = 0.8041999936103821\n",
      "12 = 0.7902966737747192\n",
      "13 = 0.7379000186920166\n",
      "14 = 7.468276500701904\n",
      "15 = 9.59412670135498\n",
      "16 = 0.10462982952594757\n",
      "17 = 7.468212127685547\n",
      "18 = 15.95955753326416\n",
      "epoch:6 step:6201 [D loss: 0.654645, acc.: 59.38%] [G loss: 0.912181]\n",
      "epoch:6 step:6202 [D loss: 0.639622, acc.: 60.94%] [G loss: 0.945145]\n",
      "epoch:6 step:6203 [D loss: 0.625438, acc.: 64.84%] [G loss: 0.876174]\n",
      "epoch:6 step:6204 [D loss: 0.603262, acc.: 66.41%] [G loss: 0.944482]\n",
      "epoch:6 step:6205 [D loss: 0.686225, acc.: 63.28%] [G loss: 0.937946]\n",
      "epoch:6 step:6206 [D loss: 0.690750, acc.: 51.56%] [G loss: 0.859632]\n",
      "epoch:6 step:6207 [D loss: 0.636428, acc.: 62.50%] [G loss: 0.880364]\n",
      "epoch:6 step:6208 [D loss: 0.690682, acc.: 60.94%] [G loss: 0.810036]\n",
      "epoch:6 step:6209 [D loss: 0.641541, acc.: 67.19%] [G loss: 0.850866]\n",
      "epoch:6 step:6210 [D loss: 0.663602, acc.: 58.59%] [G loss: 0.908809]\n",
      "epoch:6 step:6211 [D loss: 0.602034, acc.: 68.75%] [G loss: 0.976290]\n",
      "epoch:6 step:6212 [D loss: 0.692158, acc.: 59.38%] [G loss: 0.927925]\n",
      "epoch:6 step:6213 [D loss: 0.723052, acc.: 50.00%] [G loss: 0.896088]\n",
      "epoch:6 step:6214 [D loss: 0.674693, acc.: 56.25%] [G loss: 0.913119]\n",
      "epoch:6 step:6215 [D loss: 0.627319, acc.: 67.97%] [G loss: 0.946407]\n",
      "epoch:6 step:6216 [D loss: 0.691291, acc.: 51.56%] [G loss: 0.857911]\n",
      "epoch:6 step:6217 [D loss: 0.655398, acc.: 54.69%] [G loss: 0.895894]\n",
      "epoch:6 step:6218 [D loss: 0.645895, acc.: 59.38%] [G loss: 0.849941]\n",
      "epoch:6 step:6219 [D loss: 0.670186, acc.: 59.38%] [G loss: 0.837610]\n",
      "epoch:6 step:6220 [D loss: 0.648036, acc.: 59.38%] [G loss: 0.892734]\n",
      "epoch:6 step:6221 [D loss: 0.657438, acc.: 63.28%] [G loss: 0.913772]\n",
      "epoch:6 step:6222 [D loss: 0.736265, acc.: 55.47%] [G loss: 0.834736]\n",
      "epoch:6 step:6223 [D loss: 0.643000, acc.: 61.72%] [G loss: 0.820667]\n",
      "epoch:6 step:6224 [D loss: 0.676645, acc.: 55.47%] [G loss: 0.833696]\n",
      "epoch:6 step:6225 [D loss: 0.620348, acc.: 66.41%] [G loss: 0.889849]\n",
      "epoch:6 step:6226 [D loss: 0.687491, acc.: 56.25%] [G loss: 0.939097]\n",
      "epoch:6 step:6227 [D loss: 0.625176, acc.: 66.41%] [G loss: 0.889476]\n",
      "epoch:6 step:6228 [D loss: 0.691946, acc.: 52.34%] [G loss: 0.859886]\n",
      "epoch:6 step:6229 [D loss: 0.610814, acc.: 70.31%] [G loss: 0.917309]\n",
      "epoch:6 step:6230 [D loss: 0.679801, acc.: 59.38%] [G loss: 0.931635]\n",
      "epoch:6 step:6231 [D loss: 0.619387, acc.: 68.75%] [G loss: 0.844538]\n",
      "epoch:6 step:6232 [D loss: 0.655567, acc.: 60.94%] [G loss: 0.842344]\n",
      "epoch:6 step:6233 [D loss: 0.635949, acc.: 61.72%] [G loss: 0.885827]\n",
      "epoch:6 step:6234 [D loss: 0.656772, acc.: 62.50%] [G loss: 0.860017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6235 [D loss: 0.620439, acc.: 67.97%] [G loss: 0.902310]\n",
      "epoch:6 step:6236 [D loss: 0.648062, acc.: 63.28%] [G loss: 0.885518]\n",
      "epoch:6 step:6237 [D loss: 0.683642, acc.: 60.16%] [G loss: 0.839209]\n",
      "epoch:6 step:6238 [D loss: 0.645944, acc.: 61.72%] [G loss: 0.886985]\n",
      "epoch:6 step:6239 [D loss: 0.610650, acc.: 67.19%] [G loss: 0.927805]\n",
      "epoch:6 step:6240 [D loss: 0.658365, acc.: 60.16%] [G loss: 0.857690]\n",
      "epoch:6 step:6241 [D loss: 0.690305, acc.: 60.94%] [G loss: 0.866729]\n",
      "epoch:6 step:6242 [D loss: 0.633028, acc.: 65.62%] [G loss: 0.881693]\n",
      "epoch:6 step:6243 [D loss: 0.700898, acc.: 53.91%] [G loss: 0.873919]\n",
      "epoch:6 step:6244 [D loss: 0.681043, acc.: 60.16%] [G loss: 0.808083]\n",
      "epoch:6 step:6245 [D loss: 0.667771, acc.: 52.34%] [G loss: 0.850704]\n",
      "epoch:6 step:6246 [D loss: 0.626469, acc.: 70.31%] [G loss: 0.907385]\n",
      "epoch:6 step:6247 [D loss: 0.699903, acc.: 52.34%] [G loss: 0.888734]\n",
      "epoch:6 step:6248 [D loss: 0.664074, acc.: 56.25%] [G loss: 0.845164]\n",
      "epoch:6 step:6249 [D loss: 0.651850, acc.: 65.62%] [G loss: 0.861502]\n",
      "epoch:6 step:6250 [D loss: 0.678908, acc.: 60.16%] [G loss: 0.859550]\n",
      "epoch:6 step:6251 [D loss: 0.634681, acc.: 66.41%] [G loss: 0.902971]\n",
      "epoch:6 step:6252 [D loss: 0.655510, acc.: 61.72%] [G loss: 0.875291]\n",
      "epoch:6 step:6253 [D loss: 0.647067, acc.: 65.62%] [G loss: 0.874472]\n",
      "epoch:6 step:6254 [D loss: 0.649722, acc.: 61.72%] [G loss: 0.874343]\n",
      "epoch:6 step:6255 [D loss: 0.687668, acc.: 57.81%] [G loss: 0.900053]\n",
      "epoch:6 step:6256 [D loss: 0.621602, acc.: 67.19%] [G loss: 0.951398]\n",
      "epoch:6 step:6257 [D loss: 0.663032, acc.: 59.38%] [G loss: 0.943749]\n",
      "epoch:6 step:6258 [D loss: 0.685430, acc.: 53.12%] [G loss: 0.914212]\n",
      "epoch:6 step:6259 [D loss: 0.645399, acc.: 63.28%] [G loss: 0.910694]\n",
      "epoch:6 step:6260 [D loss: 0.638139, acc.: 64.84%] [G loss: 0.947895]\n",
      "epoch:6 step:6261 [D loss: 0.663549, acc.: 57.03%] [G loss: 0.892758]\n",
      "epoch:6 step:6262 [D loss: 0.602204, acc.: 68.75%] [G loss: 0.957895]\n",
      "epoch:6 step:6263 [D loss: 0.603794, acc.: 67.19%] [G loss: 0.984244]\n",
      "epoch:6 step:6264 [D loss: 0.555839, acc.: 75.78%] [G loss: 0.946968]\n",
      "epoch:6 step:6265 [D loss: 0.670859, acc.: 56.25%] [G loss: 1.012161]\n",
      "epoch:6 step:6266 [D loss: 0.706746, acc.: 54.69%] [G loss: 0.921433]\n",
      "epoch:6 step:6267 [D loss: 0.688188, acc.: 60.16%] [G loss: 0.866536]\n",
      "epoch:6 step:6268 [D loss: 0.658870, acc.: 66.41%] [G loss: 0.923583]\n",
      "epoch:6 step:6269 [D loss: 0.632754, acc.: 68.75%] [G loss: 0.914056]\n",
      "epoch:6 step:6270 [D loss: 0.565896, acc.: 71.88%] [G loss: 0.963151]\n",
      "epoch:6 step:6271 [D loss: 0.630460, acc.: 66.41%] [G loss: 0.964590]\n",
      "epoch:6 step:6272 [D loss: 0.604584, acc.: 67.97%] [G loss: 0.976490]\n",
      "epoch:6 step:6273 [D loss: 0.649067, acc.: 62.50%] [G loss: 0.881592]\n",
      "epoch:6 step:6274 [D loss: 0.681195, acc.: 57.03%] [G loss: 0.874386]\n",
      "epoch:6 step:6275 [D loss: 0.676854, acc.: 54.69%] [G loss: 0.895348]\n",
      "epoch:6 step:6276 [D loss: 0.625415, acc.: 62.50%] [G loss: 0.877558]\n",
      "epoch:6 step:6277 [D loss: 0.699207, acc.: 54.69%] [G loss: 0.862303]\n",
      "epoch:6 step:6278 [D loss: 0.643042, acc.: 58.59%] [G loss: 0.894181]\n",
      "epoch:6 step:6279 [D loss: 0.646705, acc.: 65.62%] [G loss: 0.907615]\n",
      "epoch:6 step:6280 [D loss: 0.681062, acc.: 60.16%] [G loss: 0.879518]\n",
      "epoch:6 step:6281 [D loss: 0.628420, acc.: 64.06%] [G loss: 0.920500]\n",
      "epoch:6 step:6282 [D loss: 0.611464, acc.: 62.50%] [G loss: 0.954295]\n",
      "epoch:6 step:6283 [D loss: 0.619094, acc.: 69.53%] [G loss: 0.881615]\n",
      "epoch:6 step:6284 [D loss: 0.683387, acc.: 64.06%] [G loss: 0.988843]\n",
      "epoch:6 step:6285 [D loss: 0.618060, acc.: 69.53%] [G loss: 0.944836]\n",
      "epoch:6 step:6286 [D loss: 0.627443, acc.: 59.38%] [G loss: 1.002907]\n",
      "epoch:6 step:6287 [D loss: 0.672583, acc.: 56.25%] [G loss: 0.964152]\n",
      "epoch:6 step:6288 [D loss: 0.653287, acc.: 62.50%] [G loss: 0.978976]\n",
      "epoch:6 step:6289 [D loss: 0.645435, acc.: 60.16%] [G loss: 0.860652]\n",
      "epoch:6 step:6290 [D loss: 0.668172, acc.: 60.94%] [G loss: 0.895018]\n",
      "epoch:6 step:6291 [D loss: 0.629560, acc.: 66.41%] [G loss: 0.873497]\n",
      "epoch:6 step:6292 [D loss: 0.698753, acc.: 50.00%] [G loss: 0.823646]\n",
      "epoch:6 step:6293 [D loss: 0.713008, acc.: 57.81%] [G loss: 0.847430]\n",
      "epoch:6 step:6294 [D loss: 0.689031, acc.: 55.47%] [G loss: 0.873254]\n",
      "epoch:6 step:6295 [D loss: 0.644151, acc.: 66.41%] [G loss: 0.879908]\n",
      "epoch:6 step:6296 [D loss: 0.693185, acc.: 62.50%] [G loss: 0.968442]\n",
      "epoch:6 step:6297 [D loss: 0.650901, acc.: 60.94%] [G loss: 0.938617]\n",
      "epoch:6 step:6298 [D loss: 0.671949, acc.: 62.50%] [G loss: 0.878354]\n",
      "epoch:6 step:6299 [D loss: 0.631313, acc.: 66.41%] [G loss: 0.915013]\n",
      "epoch:6 step:6300 [D loss: 0.678780, acc.: 59.38%] [G loss: 0.866046]\n",
      "epoch:6 step:6301 [D loss: 0.684566, acc.: 58.59%] [G loss: 0.846091]\n",
      "epoch:6 step:6302 [D loss: 0.643136, acc.: 66.41%] [G loss: 0.882112]\n",
      "epoch:6 step:6303 [D loss: 0.617023, acc.: 64.06%] [G loss: 0.904153]\n",
      "epoch:6 step:6304 [D loss: 0.661209, acc.: 62.50%] [G loss: 0.907087]\n",
      "epoch:6 step:6305 [D loss: 0.650923, acc.: 63.28%] [G loss: 0.854389]\n",
      "epoch:6 step:6306 [D loss: 0.637331, acc.: 67.19%] [G loss: 0.846203]\n",
      "epoch:6 step:6307 [D loss: 0.637847, acc.: 64.84%] [G loss: 0.924448]\n",
      "epoch:6 step:6308 [D loss: 0.679496, acc.: 58.59%] [G loss: 0.891983]\n",
      "epoch:6 step:6309 [D loss: 0.654037, acc.: 60.94%] [G loss: 0.878658]\n",
      "epoch:6 step:6310 [D loss: 0.657807, acc.: 55.47%] [G loss: 0.905302]\n",
      "epoch:6 step:6311 [D loss: 0.657995, acc.: 62.50%] [G loss: 0.886159]\n",
      "epoch:6 step:6312 [D loss: 0.648202, acc.: 63.28%] [G loss: 0.919898]\n",
      "epoch:6 step:6313 [D loss: 0.635718, acc.: 60.16%] [G loss: 0.949043]\n",
      "epoch:6 step:6314 [D loss: 0.603001, acc.: 65.62%] [G loss: 0.969195]\n",
      "epoch:6 step:6315 [D loss: 0.638077, acc.: 63.28%] [G loss: 0.919355]\n",
      "epoch:6 step:6316 [D loss: 0.607512, acc.: 65.62%] [G loss: 0.925589]\n",
      "epoch:6 step:6317 [D loss: 0.633954, acc.: 62.50%] [G loss: 0.925829]\n",
      "epoch:6 step:6318 [D loss: 0.709425, acc.: 50.78%] [G loss: 0.928987]\n",
      "epoch:6 step:6319 [D loss: 0.644433, acc.: 59.38%] [G loss: 0.906111]\n",
      "epoch:6 step:6320 [D loss: 0.688988, acc.: 53.91%] [G loss: 0.891755]\n",
      "epoch:6 step:6321 [D loss: 0.640222, acc.: 68.75%] [G loss: 0.907068]\n",
      "epoch:6 step:6322 [D loss: 0.644855, acc.: 67.19%] [G loss: 0.892469]\n",
      "epoch:6 step:6323 [D loss: 0.580508, acc.: 69.53%] [G loss: 0.938076]\n",
      "epoch:6 step:6324 [D loss: 0.682193, acc.: 60.16%] [G loss: 0.864129]\n",
      "epoch:6 step:6325 [D loss: 0.669587, acc.: 59.38%] [G loss: 0.907564]\n",
      "epoch:6 step:6326 [D loss: 0.704266, acc.: 56.25%] [G loss: 0.918113]\n",
      "epoch:6 step:6327 [D loss: 0.675560, acc.: 62.50%] [G loss: 0.940973]\n",
      "epoch:6 step:6328 [D loss: 0.635753, acc.: 62.50%] [G loss: 0.955742]\n",
      "epoch:6 step:6329 [D loss: 0.602835, acc.: 69.53%] [G loss: 0.973456]\n",
      "epoch:6 step:6330 [D loss: 0.595272, acc.: 70.31%] [G loss: 0.946455]\n",
      "epoch:6 step:6331 [D loss: 0.605773, acc.: 70.31%] [G loss: 1.004372]\n",
      "epoch:6 step:6332 [D loss: 0.713733, acc.: 57.03%] [G loss: 0.906500]\n",
      "epoch:6 step:6333 [D loss: 0.693038, acc.: 55.47%] [G loss: 0.870437]\n",
      "epoch:6 step:6334 [D loss: 0.640003, acc.: 58.59%] [G loss: 0.933833]\n",
      "epoch:6 step:6335 [D loss: 0.654055, acc.: 59.38%] [G loss: 0.873140]\n",
      "epoch:6 step:6336 [D loss: 0.662980, acc.: 57.81%] [G loss: 0.836972]\n",
      "epoch:6 step:6337 [D loss: 0.669793, acc.: 57.03%] [G loss: 0.795863]\n",
      "epoch:6 step:6338 [D loss: 0.694262, acc.: 55.47%] [G loss: 0.841410]\n",
      "epoch:6 step:6339 [D loss: 0.683789, acc.: 56.25%] [G loss: 0.875707]\n",
      "epoch:6 step:6340 [D loss: 0.680946, acc.: 56.25%] [G loss: 0.834959]\n",
      "epoch:6 step:6341 [D loss: 0.648674, acc.: 62.50%] [G loss: 0.888559]\n",
      "epoch:6 step:6342 [D loss: 0.681856, acc.: 62.50%] [G loss: 0.889055]\n",
      "epoch:6 step:6343 [D loss: 0.664811, acc.: 56.25%] [G loss: 0.903769]\n",
      "epoch:6 step:6344 [D loss: 0.767253, acc.: 50.78%] [G loss: 0.904828]\n",
      "epoch:6 step:6345 [D loss: 0.661473, acc.: 61.72%] [G loss: 0.878406]\n",
      "epoch:6 step:6346 [D loss: 0.635467, acc.: 70.31%] [G loss: 0.883301]\n",
      "epoch:6 step:6347 [D loss: 0.604890, acc.: 67.97%] [G loss: 0.905372]\n",
      "epoch:6 step:6348 [D loss: 0.618975, acc.: 64.84%] [G loss: 0.866980]\n",
      "epoch:6 step:6349 [D loss: 0.681708, acc.: 57.81%] [G loss: 0.868813]\n",
      "epoch:6 step:6350 [D loss: 0.654442, acc.: 60.16%] [G loss: 0.838891]\n",
      "epoch:6 step:6351 [D loss: 0.675975, acc.: 58.59%] [G loss: 0.811216]\n",
      "epoch:6 step:6352 [D loss: 0.632776, acc.: 64.84%] [G loss: 0.918372]\n",
      "epoch:6 step:6353 [D loss: 0.630098, acc.: 63.28%] [G loss: 0.901312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6354 [D loss: 0.616542, acc.: 64.06%] [G loss: 0.934429]\n",
      "epoch:6 step:6355 [D loss: 0.603397, acc.: 66.41%] [G loss: 0.889355]\n",
      "epoch:6 step:6356 [D loss: 0.633758, acc.: 67.19%] [G loss: 0.854437]\n",
      "epoch:6 step:6357 [D loss: 0.632465, acc.: 66.41%] [G loss: 0.878834]\n",
      "epoch:6 step:6358 [D loss: 0.647404, acc.: 63.28%] [G loss: 0.968811]\n",
      "epoch:6 step:6359 [D loss: 0.634638, acc.: 60.16%] [G loss: 0.924791]\n",
      "epoch:6 step:6360 [D loss: 0.664407, acc.: 59.38%] [G loss: 0.844513]\n",
      "epoch:6 step:6361 [D loss: 0.670854, acc.: 61.72%] [G loss: 0.923010]\n",
      "epoch:6 step:6362 [D loss: 0.668476, acc.: 58.59%] [G loss: 0.839988]\n",
      "epoch:6 step:6363 [D loss: 0.618510, acc.: 75.78%] [G loss: 0.848560]\n",
      "epoch:6 step:6364 [D loss: 0.664530, acc.: 59.38%] [G loss: 0.886529]\n",
      "epoch:6 step:6365 [D loss: 0.657875, acc.: 60.16%] [G loss: 0.953995]\n",
      "epoch:6 step:6366 [D loss: 0.694814, acc.: 56.25%] [G loss: 0.870036]\n",
      "epoch:6 step:6367 [D loss: 0.678283, acc.: 60.94%] [G loss: 0.861839]\n",
      "epoch:6 step:6368 [D loss: 0.622192, acc.: 64.84%] [G loss: 0.880127]\n",
      "epoch:6 step:6369 [D loss: 0.657151, acc.: 60.94%] [G loss: 0.891214]\n",
      "epoch:6 step:6370 [D loss: 0.641416, acc.: 62.50%] [G loss: 0.930228]\n",
      "epoch:6 step:6371 [D loss: 0.658990, acc.: 61.72%] [G loss: 0.904985]\n",
      "epoch:6 step:6372 [D loss: 0.663164, acc.: 64.06%] [G loss: 0.883887]\n",
      "epoch:6 step:6373 [D loss: 0.600729, acc.: 69.53%] [G loss: 0.874766]\n",
      "epoch:6 step:6374 [D loss: 0.670087, acc.: 54.69%] [G loss: 0.883497]\n",
      "epoch:6 step:6375 [D loss: 0.630826, acc.: 62.50%] [G loss: 0.875687]\n",
      "epoch:6 step:6376 [D loss: 0.599306, acc.: 64.84%] [G loss: 0.875455]\n",
      "epoch:6 step:6377 [D loss: 0.641916, acc.: 58.59%] [G loss: 0.898993]\n",
      "epoch:6 step:6378 [D loss: 0.630053, acc.: 65.62%] [G loss: 0.947461]\n",
      "epoch:6 step:6379 [D loss: 0.678651, acc.: 59.38%] [G loss: 0.919470]\n",
      "epoch:6 step:6380 [D loss: 0.711647, acc.: 56.25%] [G loss: 0.829606]\n",
      "epoch:6 step:6381 [D loss: 0.694020, acc.: 59.38%] [G loss: 0.841807]\n",
      "epoch:6 step:6382 [D loss: 0.643459, acc.: 62.50%] [G loss: 0.956082]\n",
      "epoch:6 step:6383 [D loss: 0.649586, acc.: 58.59%] [G loss: 0.935747]\n",
      "epoch:6 step:6384 [D loss: 0.672146, acc.: 57.03%] [G loss: 0.900418]\n",
      "epoch:6 step:6385 [D loss: 0.653809, acc.: 61.72%] [G loss: 0.885363]\n",
      "epoch:6 step:6386 [D loss: 0.712952, acc.: 50.78%] [G loss: 0.935989]\n",
      "epoch:6 step:6387 [D loss: 0.716400, acc.: 49.22%] [G loss: 0.834269]\n",
      "epoch:6 step:6388 [D loss: 0.683066, acc.: 57.03%] [G loss: 0.865595]\n",
      "epoch:6 step:6389 [D loss: 0.624297, acc.: 65.62%] [G loss: 0.873590]\n",
      "epoch:6 step:6390 [D loss: 0.678277, acc.: 63.28%] [G loss: 0.856969]\n",
      "epoch:6 step:6391 [D loss: 0.619252, acc.: 61.72%] [G loss: 0.916881]\n",
      "epoch:6 step:6392 [D loss: 0.684285, acc.: 51.56%] [G loss: 0.921619]\n",
      "epoch:6 step:6393 [D loss: 0.657493, acc.: 65.62%] [G loss: 0.917068]\n",
      "epoch:6 step:6394 [D loss: 0.679289, acc.: 61.72%] [G loss: 0.895022]\n",
      "epoch:6 step:6395 [D loss: 0.615365, acc.: 64.06%] [G loss: 0.870103]\n",
      "epoch:6 step:6396 [D loss: 0.674104, acc.: 64.06%] [G loss: 0.897584]\n",
      "epoch:6 step:6397 [D loss: 0.621018, acc.: 64.06%] [G loss: 0.967662]\n",
      "epoch:6 step:6398 [D loss: 0.619343, acc.: 64.06%] [G loss: 0.972540]\n",
      "epoch:6 step:6399 [D loss: 0.625013, acc.: 67.97%] [G loss: 0.931769]\n",
      "epoch:6 step:6400 [D loss: 0.653498, acc.: 60.16%] [G loss: 0.960177]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.397916\n",
      "FID: 17.378979\n",
      "0 = 12.11351954669954\n",
      "1 = 0.0643263060465714\n",
      "2 = 0.9459999799728394\n",
      "3 = 0.8999999761581421\n",
      "4 = 0.9919999837875366\n",
      "5 = 0.9911894202232361\n",
      "6 = 0.8999999761581421\n",
      "7 = 6.989962067306053\n",
      "8 = 0.09010872948767401\n",
      "9 = 0.7787500023841858\n",
      "10 = 0.7513999938964844\n",
      "11 = 0.8061000108718872\n",
      "12 = 0.7948799133300781\n",
      "13 = 0.7513999938964844\n",
      "14 = 7.397977352142334\n",
      "15 = 9.556865692138672\n",
      "16 = 0.1160655990242958\n",
      "17 = 7.397916316986084\n",
      "18 = 17.378978729248047\n",
      "epoch:6 step:6401 [D loss: 0.682472, acc.: 60.16%] [G loss: 0.891312]\n",
      "epoch:6 step:6402 [D loss: 0.657061, acc.: 63.28%] [G loss: 0.923868]\n",
      "epoch:6 step:6403 [D loss: 0.625324, acc.: 68.75%] [G loss: 1.015749]\n",
      "epoch:6 step:6404 [D loss: 0.582579, acc.: 73.44%] [G loss: 0.984769]\n",
      "epoch:6 step:6405 [D loss: 0.700117, acc.: 52.34%] [G loss: 0.962857]\n",
      "epoch:6 step:6406 [D loss: 0.745347, acc.: 47.66%] [G loss: 0.851367]\n",
      "epoch:6 step:6407 [D loss: 0.674149, acc.: 57.81%] [G loss: 0.866733]\n",
      "epoch:6 step:6408 [D loss: 0.647232, acc.: 60.94%] [G loss: 0.909539]\n",
      "epoch:6 step:6409 [D loss: 0.697746, acc.: 49.22%] [G loss: 0.909196]\n",
      "epoch:6 step:6410 [D loss: 0.681285, acc.: 57.81%] [G loss: 0.889019]\n",
      "epoch:6 step:6411 [D loss: 0.639428, acc.: 62.50%] [G loss: 0.886582]\n",
      "epoch:6 step:6412 [D loss: 0.659479, acc.: 61.72%] [G loss: 0.908670]\n",
      "epoch:6 step:6413 [D loss: 0.692278, acc.: 50.00%] [G loss: 0.870864]\n",
      "epoch:6 step:6414 [D loss: 0.617763, acc.: 67.97%] [G loss: 0.861913]\n",
      "epoch:6 step:6415 [D loss: 0.635523, acc.: 71.09%] [G loss: 0.909279]\n",
      "epoch:6 step:6416 [D loss: 0.693165, acc.: 55.47%] [G loss: 0.934864]\n",
      "epoch:6 step:6417 [D loss: 0.661718, acc.: 62.50%] [G loss: 0.958718]\n",
      "epoch:6 step:6418 [D loss: 0.601585, acc.: 70.31%] [G loss: 0.953433]\n",
      "epoch:6 step:6419 [D loss: 0.639414, acc.: 59.38%] [G loss: 0.966856]\n",
      "epoch:6 step:6420 [D loss: 0.691453, acc.: 60.94%] [G loss: 0.867143]\n",
      "epoch:6 step:6421 [D loss: 0.656725, acc.: 59.38%] [G loss: 0.871525]\n",
      "epoch:6 step:6422 [D loss: 0.677457, acc.: 53.91%] [G loss: 0.970054]\n",
      "epoch:6 step:6423 [D loss: 0.609785, acc.: 68.75%] [G loss: 0.939642]\n",
      "epoch:6 step:6424 [D loss: 0.636668, acc.: 63.28%] [G loss: 1.001474]\n",
      "epoch:6 step:6425 [D loss: 0.644160, acc.: 60.16%] [G loss: 1.004337]\n",
      "epoch:6 step:6426 [D loss: 0.686376, acc.: 57.03%] [G loss: 0.885562]\n",
      "epoch:6 step:6427 [D loss: 0.665655, acc.: 54.69%] [G loss: 0.925311]\n",
      "epoch:6 step:6428 [D loss: 0.628317, acc.: 64.06%] [G loss: 0.821330]\n",
      "epoch:6 step:6429 [D loss: 0.626499, acc.: 64.84%] [G loss: 0.956372]\n",
      "epoch:6 step:6430 [D loss: 0.659825, acc.: 60.16%] [G loss: 0.856961]\n",
      "epoch:6 step:6431 [D loss: 0.688187, acc.: 57.81%] [G loss: 0.857900]\n",
      "epoch:6 step:6432 [D loss: 0.670780, acc.: 57.81%] [G loss: 0.830705]\n",
      "epoch:6 step:6433 [D loss: 0.670036, acc.: 55.47%] [G loss: 0.859737]\n",
      "epoch:6 step:6434 [D loss: 0.692723, acc.: 51.56%] [G loss: 0.836928]\n",
      "epoch:6 step:6435 [D loss: 0.657731, acc.: 61.72%] [G loss: 0.864961]\n",
      "epoch:6 step:6436 [D loss: 0.655653, acc.: 64.06%] [G loss: 0.927583]\n",
      "epoch:6 step:6437 [D loss: 0.629701, acc.: 70.31%] [G loss: 0.958139]\n",
      "epoch:6 step:6438 [D loss: 0.691735, acc.: 59.38%] [G loss: 0.905782]\n",
      "epoch:6 step:6439 [D loss: 0.668122, acc.: 57.03%] [G loss: 0.922787]\n",
      "epoch:6 step:6440 [D loss: 0.695341, acc.: 56.25%] [G loss: 0.903510]\n",
      "epoch:6 step:6441 [D loss: 0.633523, acc.: 67.19%] [G loss: 0.880488]\n",
      "epoch:6 step:6442 [D loss: 0.721881, acc.: 48.44%] [G loss: 0.847762]\n",
      "epoch:6 step:6443 [D loss: 0.665738, acc.: 61.72%] [G loss: 0.865567]\n",
      "epoch:6 step:6444 [D loss: 0.653637, acc.: 59.38%] [G loss: 0.837016]\n",
      "epoch:6 step:6445 [D loss: 0.653683, acc.: 57.81%] [G loss: 0.886759]\n",
      "epoch:6 step:6446 [D loss: 0.702973, acc.: 55.47%] [G loss: 0.854712]\n",
      "epoch:6 step:6447 [D loss: 0.625131, acc.: 64.84%] [G loss: 0.847945]\n",
      "epoch:6 step:6448 [D loss: 0.648792, acc.: 60.16%] [G loss: 0.866665]\n",
      "epoch:6 step:6449 [D loss: 0.684203, acc.: 53.91%] [G loss: 0.909010]\n",
      "epoch:6 step:6450 [D loss: 0.680848, acc.: 52.34%] [G loss: 0.875859]\n",
      "epoch:6 step:6451 [D loss: 0.680080, acc.: 53.91%] [G loss: 0.933702]\n",
      "epoch:6 step:6452 [D loss: 0.703022, acc.: 52.34%] [G loss: 0.932131]\n",
      "epoch:6 step:6453 [D loss: 0.681587, acc.: 58.59%] [G loss: 0.852295]\n",
      "epoch:6 step:6454 [D loss: 0.638038, acc.: 68.75%] [G loss: 0.835608]\n",
      "epoch:6 step:6455 [D loss: 0.637735, acc.: 60.94%] [G loss: 0.907223]\n",
      "epoch:6 step:6456 [D loss: 0.679959, acc.: 54.69%] [G loss: 0.803228]\n",
      "epoch:6 step:6457 [D loss: 0.614153, acc.: 72.66%] [G loss: 0.900601]\n",
      "epoch:6 step:6458 [D loss: 0.678555, acc.: 58.59%] [G loss: 0.842127]\n",
      "epoch:6 step:6459 [D loss: 0.663183, acc.: 62.50%] [G loss: 0.888289]\n",
      "epoch:6 step:6460 [D loss: 0.687765, acc.: 50.78%] [G loss: 0.884853]\n",
      "epoch:6 step:6461 [D loss: 0.635758, acc.: 65.62%] [G loss: 0.884779]\n",
      "epoch:6 step:6462 [D loss: 0.663354, acc.: 59.38%] [G loss: 0.949292]\n",
      "epoch:6 step:6463 [D loss: 0.643543, acc.: 61.72%] [G loss: 0.840988]\n",
      "epoch:6 step:6464 [D loss: 0.624333, acc.: 61.72%] [G loss: 0.911490]\n",
      "epoch:6 step:6465 [D loss: 0.675503, acc.: 59.38%] [G loss: 0.887305]\n",
      "epoch:6 step:6466 [D loss: 0.676549, acc.: 59.38%] [G loss: 0.889422]\n",
      "epoch:6 step:6467 [D loss: 0.628404, acc.: 66.41%] [G loss: 0.868646]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6468 [D loss: 0.641082, acc.: 60.16%] [G loss: 0.949987]\n",
      "epoch:6 step:6469 [D loss: 0.677174, acc.: 57.81%] [G loss: 0.866160]\n",
      "epoch:6 step:6470 [D loss: 0.666603, acc.: 62.50%] [G loss: 0.847354]\n",
      "epoch:6 step:6471 [D loss: 0.670053, acc.: 55.47%] [G loss: 0.824945]\n",
      "epoch:6 step:6472 [D loss: 0.646521, acc.: 60.16%] [G loss: 0.865036]\n",
      "epoch:6 step:6473 [D loss: 0.631308, acc.: 65.62%] [G loss: 0.924475]\n",
      "epoch:6 step:6474 [D loss: 0.612336, acc.: 66.41%] [G loss: 0.859712]\n",
      "epoch:6 step:6475 [D loss: 0.586824, acc.: 72.66%] [G loss: 0.966328]\n",
      "epoch:6 step:6476 [D loss: 0.657450, acc.: 62.50%] [G loss: 0.942843]\n",
      "epoch:6 step:6477 [D loss: 0.595600, acc.: 67.19%] [G loss: 0.899406]\n",
      "epoch:6 step:6478 [D loss: 0.674478, acc.: 60.94%] [G loss: 0.869916]\n",
      "epoch:6 step:6479 [D loss: 0.630275, acc.: 67.19%] [G loss: 0.922899]\n",
      "epoch:6 step:6480 [D loss: 0.748172, acc.: 49.22%] [G loss: 0.907579]\n",
      "epoch:6 step:6481 [D loss: 0.683669, acc.: 57.03%] [G loss: 0.929947]\n",
      "epoch:6 step:6482 [D loss: 0.626984, acc.: 62.50%] [G loss: 0.989594]\n",
      "epoch:6 step:6483 [D loss: 0.665373, acc.: 60.16%] [G loss: 0.955638]\n",
      "epoch:6 step:6484 [D loss: 0.667232, acc.: 56.25%] [G loss: 0.848415]\n",
      "epoch:6 step:6485 [D loss: 0.663502, acc.: 55.47%] [G loss: 0.851030]\n",
      "epoch:6 step:6486 [D loss: 0.672822, acc.: 54.69%] [G loss: 0.861066]\n",
      "epoch:6 step:6487 [D loss: 0.679286, acc.: 60.94%] [G loss: 0.853207]\n",
      "epoch:6 step:6488 [D loss: 0.612634, acc.: 67.97%] [G loss: 0.861946]\n",
      "epoch:6 step:6489 [D loss: 0.714728, acc.: 53.91%] [G loss: 0.855791]\n",
      "epoch:6 step:6490 [D loss: 0.633085, acc.: 62.50%] [G loss: 0.886076]\n",
      "epoch:6 step:6491 [D loss: 0.683505, acc.: 56.25%] [G loss: 0.907592]\n",
      "epoch:6 step:6492 [D loss: 0.679305, acc.: 63.28%] [G loss: 0.870433]\n",
      "epoch:6 step:6493 [D loss: 0.658789, acc.: 62.50%] [G loss: 0.855513]\n",
      "epoch:6 step:6494 [D loss: 0.618124, acc.: 67.19%] [G loss: 0.894429]\n",
      "epoch:6 step:6495 [D loss: 0.641207, acc.: 66.41%] [G loss: 0.823056]\n",
      "epoch:6 step:6496 [D loss: 0.656521, acc.: 65.62%] [G loss: 0.802472]\n",
      "epoch:6 step:6497 [D loss: 0.583302, acc.: 69.53%] [G loss: 0.871083]\n",
      "epoch:6 step:6498 [D loss: 0.709536, acc.: 51.56%] [G loss: 0.845313]\n",
      "epoch:6 step:6499 [D loss: 0.675514, acc.: 59.38%] [G loss: 0.846106]\n",
      "epoch:6 step:6500 [D loss: 0.687813, acc.: 55.47%] [G loss: 0.851413]\n",
      "epoch:6 step:6501 [D loss: 0.654975, acc.: 61.72%] [G loss: 0.853421]\n",
      "epoch:6 step:6502 [D loss: 0.665637, acc.: 58.59%] [G loss: 0.880156]\n",
      "epoch:6 step:6503 [D loss: 0.631753, acc.: 64.84%] [G loss: 0.843132]\n",
      "epoch:6 step:6504 [D loss: 0.639145, acc.: 63.28%] [G loss: 0.929399]\n",
      "epoch:6 step:6505 [D loss: 0.628870, acc.: 70.31%] [G loss: 0.975452]\n",
      "epoch:6 step:6506 [D loss: 0.596160, acc.: 69.53%] [G loss: 0.979441]\n",
      "epoch:6 step:6507 [D loss: 0.658368, acc.: 62.50%] [G loss: 0.957697]\n",
      "epoch:6 step:6508 [D loss: 0.576362, acc.: 67.19%] [G loss: 0.965531]\n",
      "epoch:6 step:6509 [D loss: 0.665131, acc.: 60.94%] [G loss: 0.971287]\n",
      "epoch:6 step:6510 [D loss: 0.649187, acc.: 65.62%] [G loss: 0.928886]\n",
      "epoch:6 step:6511 [D loss: 0.612841, acc.: 63.28%] [G loss: 0.833714]\n",
      "epoch:6 step:6512 [D loss: 0.597576, acc.: 70.31%] [G loss: 0.909881]\n",
      "epoch:6 step:6513 [D loss: 0.744970, acc.: 52.34%] [G loss: 0.882770]\n",
      "epoch:6 step:6514 [D loss: 0.745964, acc.: 47.66%] [G loss: 0.867596]\n",
      "epoch:6 step:6515 [D loss: 0.671113, acc.: 57.03%] [G loss: 0.908353]\n",
      "epoch:6 step:6516 [D loss: 0.641348, acc.: 62.50%] [G loss: 0.987593]\n",
      "epoch:6 step:6517 [D loss: 0.618098, acc.: 67.97%] [G loss: 0.964430]\n",
      "epoch:6 step:6518 [D loss: 0.647462, acc.: 66.41%] [G loss: 0.987114]\n",
      "epoch:6 step:6519 [D loss: 0.626332, acc.: 64.06%] [G loss: 0.950269]\n",
      "epoch:6 step:6520 [D loss: 0.609722, acc.: 65.62%] [G loss: 0.959182]\n",
      "epoch:6 step:6521 [D loss: 0.587489, acc.: 71.09%] [G loss: 0.946721]\n",
      "epoch:6 step:6522 [D loss: 0.636834, acc.: 64.06%] [G loss: 0.940223]\n",
      "epoch:6 step:6523 [D loss: 0.675577, acc.: 60.16%] [G loss: 0.968147]\n",
      "epoch:6 step:6524 [D loss: 0.730124, acc.: 47.66%] [G loss: 0.891514]\n",
      "epoch:6 step:6525 [D loss: 0.624357, acc.: 64.84%] [G loss: 0.906914]\n",
      "epoch:6 step:6526 [D loss: 0.725828, acc.: 52.34%] [G loss: 0.870708]\n",
      "epoch:6 step:6527 [D loss: 0.668135, acc.: 57.03%] [G loss: 0.906841]\n",
      "epoch:6 step:6528 [D loss: 0.629280, acc.: 67.19%] [G loss: 0.906979]\n",
      "epoch:6 step:6529 [D loss: 0.675406, acc.: 61.72%] [G loss: 0.896972]\n",
      "epoch:6 step:6530 [D loss: 0.623340, acc.: 70.31%] [G loss: 0.906636]\n",
      "epoch:6 step:6531 [D loss: 0.645787, acc.: 62.50%] [G loss: 0.852809]\n",
      "epoch:6 step:6532 [D loss: 0.633546, acc.: 58.59%] [G loss: 0.856224]\n",
      "epoch:6 step:6533 [D loss: 0.720278, acc.: 49.22%] [G loss: 0.915974]\n",
      "epoch:6 step:6534 [D loss: 0.634290, acc.: 67.19%] [G loss: 0.909589]\n",
      "epoch:6 step:6535 [D loss: 0.680137, acc.: 50.00%] [G loss: 0.934291]\n",
      "epoch:6 step:6536 [D loss: 0.624172, acc.: 66.41%] [G loss: 0.976747]\n",
      "epoch:6 step:6537 [D loss: 0.687555, acc.: 60.16%] [G loss: 0.941520]\n",
      "epoch:6 step:6538 [D loss: 0.660142, acc.: 57.81%] [G loss: 0.879695]\n",
      "epoch:6 step:6539 [D loss: 0.683643, acc.: 58.59%] [G loss: 0.841737]\n",
      "epoch:6 step:6540 [D loss: 0.595504, acc.: 72.66%] [G loss: 0.907972]\n",
      "epoch:6 step:6541 [D loss: 0.641309, acc.: 60.94%] [G loss: 0.868120]\n",
      "epoch:6 step:6542 [D loss: 0.756261, acc.: 46.09%] [G loss: 0.916100]\n",
      "epoch:6 step:6543 [D loss: 0.654681, acc.: 64.06%] [G loss: 0.893673]\n",
      "epoch:6 step:6544 [D loss: 0.645669, acc.: 64.84%] [G loss: 0.911677]\n",
      "epoch:6 step:6545 [D loss: 0.621331, acc.: 67.97%] [G loss: 0.865129]\n",
      "epoch:6 step:6546 [D loss: 0.564638, acc.: 71.09%] [G loss: 0.877489]\n",
      "epoch:6 step:6547 [D loss: 0.581971, acc.: 70.31%] [G loss: 1.002324]\n",
      "epoch:6 step:6548 [D loss: 0.608552, acc.: 72.66%] [G loss: 1.008959]\n",
      "epoch:6 step:6549 [D loss: 0.597416, acc.: 67.97%] [G loss: 0.998326]\n",
      "epoch:6 step:6550 [D loss: 0.861647, acc.: 54.69%] [G loss: 1.036490]\n",
      "epoch:6 step:6551 [D loss: 0.608732, acc.: 66.41%] [G loss: 1.086526]\n",
      "epoch:6 step:6552 [D loss: 0.575855, acc.: 71.09%] [G loss: 1.050551]\n",
      "epoch:6 step:6553 [D loss: 0.692917, acc.: 59.38%] [G loss: 0.946485]\n",
      "epoch:6 step:6554 [D loss: 0.696200, acc.: 57.81%] [G loss: 0.960755]\n",
      "epoch:6 step:6555 [D loss: 0.675553, acc.: 57.03%] [G loss: 0.950258]\n",
      "epoch:6 step:6556 [D loss: 0.646907, acc.: 67.19%] [G loss: 0.898813]\n",
      "epoch:6 step:6557 [D loss: 0.662495, acc.: 62.50%] [G loss: 0.954921]\n",
      "epoch:6 step:6558 [D loss: 0.574253, acc.: 75.78%] [G loss: 0.971614]\n",
      "epoch:6 step:6559 [D loss: 0.606942, acc.: 67.97%] [G loss: 1.106433]\n",
      "epoch:7 step:6560 [D loss: 0.707521, acc.: 60.94%] [G loss: 0.996620]\n",
      "epoch:7 step:6561 [D loss: 0.743864, acc.: 50.78%] [G loss: 0.950979]\n",
      "epoch:7 step:6562 [D loss: 0.668883, acc.: 59.38%] [G loss: 0.939238]\n",
      "epoch:7 step:6563 [D loss: 0.704601, acc.: 53.91%] [G loss: 0.954138]\n",
      "epoch:7 step:6564 [D loss: 0.663546, acc.: 60.16%] [G loss: 0.940665]\n",
      "epoch:7 step:6565 [D loss: 0.654899, acc.: 57.81%] [G loss: 0.942121]\n",
      "epoch:7 step:6566 [D loss: 0.638097, acc.: 60.94%] [G loss: 0.955560]\n",
      "epoch:7 step:6567 [D loss: 0.694614, acc.: 53.91%] [G loss: 0.822095]\n",
      "epoch:7 step:6568 [D loss: 0.647225, acc.: 61.72%] [G loss: 0.884360]\n",
      "epoch:7 step:6569 [D loss: 0.664350, acc.: 58.59%] [G loss: 0.917813]\n",
      "epoch:7 step:6570 [D loss: 0.648143, acc.: 64.06%] [G loss: 0.929209]\n",
      "epoch:7 step:6571 [D loss: 0.663051, acc.: 55.47%] [G loss: 0.963727]\n",
      "epoch:7 step:6572 [D loss: 0.674428, acc.: 57.03%] [G loss: 0.940650]\n",
      "epoch:7 step:6573 [D loss: 0.648505, acc.: 60.94%] [G loss: 0.909153]\n",
      "epoch:7 step:6574 [D loss: 0.644685, acc.: 66.41%] [G loss: 1.003985]\n",
      "epoch:7 step:6575 [D loss: 0.615883, acc.: 70.31%] [G loss: 0.945414]\n",
      "epoch:7 step:6576 [D loss: 0.625192, acc.: 63.28%] [G loss: 0.955455]\n",
      "epoch:7 step:6577 [D loss: 0.676142, acc.: 57.03%] [G loss: 0.935228]\n",
      "epoch:7 step:6578 [D loss: 0.687810, acc.: 61.72%] [G loss: 0.980794]\n",
      "epoch:7 step:6579 [D loss: 0.720355, acc.: 49.22%] [G loss: 0.983695]\n",
      "epoch:7 step:6580 [D loss: 0.606372, acc.: 72.66%] [G loss: 1.010185]\n",
      "epoch:7 step:6581 [D loss: 0.584068, acc.: 69.53%] [G loss: 0.985924]\n",
      "epoch:7 step:6582 [D loss: 0.714173, acc.: 53.91%] [G loss: 0.961612]\n",
      "epoch:7 step:6583 [D loss: 0.669341, acc.: 57.03%] [G loss: 0.878201]\n",
      "epoch:7 step:6584 [D loss: 0.627497, acc.: 71.09%] [G loss: 0.844985]\n",
      "epoch:7 step:6585 [D loss: 0.664633, acc.: 60.16%] [G loss: 0.872515]\n",
      "epoch:7 step:6586 [D loss: 0.688814, acc.: 55.47%] [G loss: 0.831810]\n",
      "epoch:7 step:6587 [D loss: 0.635874, acc.: 63.28%] [G loss: 0.829568]\n",
      "epoch:7 step:6588 [D loss: 0.629760, acc.: 62.50%] [G loss: 0.849103]\n",
      "epoch:7 step:6589 [D loss: 0.640014, acc.: 64.06%] [G loss: 0.824720]\n",
      "epoch:7 step:6590 [D loss: 0.642324, acc.: 61.72%] [G loss: 0.899582]\n",
      "epoch:7 step:6591 [D loss: 0.613063, acc.: 69.53%] [G loss: 0.919677]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6592 [D loss: 0.654717, acc.: 57.81%] [G loss: 0.950055]\n",
      "epoch:7 step:6593 [D loss: 0.599126, acc.: 67.19%] [G loss: 0.871528]\n",
      "epoch:7 step:6594 [D loss: 0.626527, acc.: 64.06%] [G loss: 0.949852]\n",
      "epoch:7 step:6595 [D loss: 0.608717, acc.: 69.53%] [G loss: 0.943336]\n",
      "epoch:7 step:6596 [D loss: 0.726903, acc.: 52.34%] [G loss: 0.901723]\n",
      "epoch:7 step:6597 [D loss: 0.730940, acc.: 49.22%] [G loss: 0.877533]\n",
      "epoch:7 step:6598 [D loss: 0.622269, acc.: 67.19%] [G loss: 0.908384]\n",
      "epoch:7 step:6599 [D loss: 0.622730, acc.: 62.50%] [G loss: 0.917602]\n",
      "epoch:7 step:6600 [D loss: 0.653024, acc.: 64.84%] [G loss: 0.899146]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.686185\n",
      "FID: 12.007767\n",
      "0 = 11.97170469019407\n",
      "1 = 0.060162709867744246\n",
      "2 = 0.9416999816894531\n",
      "3 = 0.8932999968528748\n",
      "4 = 0.9901000261306763\n",
      "5 = 0.9890389442443848\n",
      "6 = 0.8932999968528748\n",
      "7 = 6.482208065629011\n",
      "8 = 0.07752685450771778\n",
      "9 = 0.746399998664856\n",
      "10 = 0.7142000198364258\n",
      "11 = 0.7785999774932861\n",
      "12 = 0.7633603811264038\n",
      "13 = 0.7142000198364258\n",
      "14 = 7.686249732971191\n",
      "15 = 9.586697578430176\n",
      "16 = 0.09946826100349426\n",
      "17 = 7.686185359954834\n",
      "18 = 12.007766723632812\n",
      "epoch:7 step:6601 [D loss: 0.640973, acc.: 61.72%] [G loss: 0.906494]\n",
      "epoch:7 step:6602 [D loss: 0.688551, acc.: 53.12%] [G loss: 0.864570]\n",
      "epoch:7 step:6603 [D loss: 0.694625, acc.: 50.78%] [G loss: 0.900675]\n",
      "epoch:7 step:6604 [D loss: 0.690302, acc.: 50.78%] [G loss: 0.890266]\n",
      "epoch:7 step:6605 [D loss: 0.645218, acc.: 62.50%] [G loss: 0.969065]\n",
      "epoch:7 step:6606 [D loss: 0.636267, acc.: 63.28%] [G loss: 0.914093]\n",
      "epoch:7 step:6607 [D loss: 0.639096, acc.: 66.41%] [G loss: 0.950719]\n",
      "epoch:7 step:6608 [D loss: 0.626671, acc.: 67.97%] [G loss: 0.935950]\n",
      "epoch:7 step:6609 [D loss: 0.629151, acc.: 66.41%] [G loss: 0.906991]\n",
      "epoch:7 step:6610 [D loss: 0.694646, acc.: 53.91%] [G loss: 0.851936]\n",
      "epoch:7 step:6611 [D loss: 0.624065, acc.: 65.62%] [G loss: 0.857155]\n",
      "epoch:7 step:6612 [D loss: 0.645158, acc.: 61.72%] [G loss: 0.872252]\n",
      "epoch:7 step:6613 [D loss: 0.613804, acc.: 67.97%] [G loss: 0.874815]\n",
      "epoch:7 step:6614 [D loss: 0.672532, acc.: 54.69%] [G loss: 0.916530]\n",
      "epoch:7 step:6615 [D loss: 0.681824, acc.: 56.25%] [G loss: 0.878617]\n",
      "epoch:7 step:6616 [D loss: 0.675742, acc.: 59.38%] [G loss: 0.922923]\n",
      "epoch:7 step:6617 [D loss: 0.667340, acc.: 61.72%] [G loss: 0.870598]\n",
      "epoch:7 step:6618 [D loss: 0.660405, acc.: 60.94%] [G loss: 0.897523]\n",
      "epoch:7 step:6619 [D loss: 0.672882, acc.: 59.38%] [G loss: 0.862516]\n",
      "epoch:7 step:6620 [D loss: 0.742033, acc.: 49.22%] [G loss: 0.830042]\n",
      "epoch:7 step:6621 [D loss: 0.678033, acc.: 57.03%] [G loss: 0.864660]\n",
      "epoch:7 step:6622 [D loss: 0.669060, acc.: 53.12%] [G loss: 0.894399]\n",
      "epoch:7 step:6623 [D loss: 0.690372, acc.: 55.47%] [G loss: 0.824924]\n",
      "epoch:7 step:6624 [D loss: 0.688062, acc.: 53.91%] [G loss: 0.839427]\n",
      "epoch:7 step:6625 [D loss: 0.648755, acc.: 63.28%] [G loss: 0.882032]\n",
      "epoch:7 step:6626 [D loss: 0.648735, acc.: 66.41%] [G loss: 0.861330]\n",
      "epoch:7 step:6627 [D loss: 0.657547, acc.: 63.28%] [G loss: 0.908124]\n",
      "epoch:7 step:6628 [D loss: 0.632195, acc.: 62.50%] [G loss: 0.908715]\n",
      "epoch:7 step:6629 [D loss: 0.625928, acc.: 64.84%] [G loss: 0.901583]\n",
      "epoch:7 step:6630 [D loss: 0.693888, acc.: 51.56%] [G loss: 0.895636]\n",
      "epoch:7 step:6631 [D loss: 0.651372, acc.: 64.06%] [G loss: 0.868754]\n",
      "epoch:7 step:6632 [D loss: 0.651595, acc.: 57.81%] [G loss: 0.899146]\n",
      "epoch:7 step:6633 [D loss: 0.620354, acc.: 67.19%] [G loss: 0.962932]\n",
      "epoch:7 step:6634 [D loss: 0.659208, acc.: 60.16%] [G loss: 0.908293]\n",
      "epoch:7 step:6635 [D loss: 0.584629, acc.: 68.75%] [G loss: 0.937939]\n",
      "epoch:7 step:6636 [D loss: 0.628423, acc.: 63.28%] [G loss: 0.919867]\n",
      "epoch:7 step:6637 [D loss: 0.673589, acc.: 55.47%] [G loss: 0.932344]\n",
      "epoch:7 step:6638 [D loss: 0.655886, acc.: 63.28%] [G loss: 0.867486]\n",
      "epoch:7 step:6639 [D loss: 0.686868, acc.: 57.03%] [G loss: 0.920467]\n",
      "epoch:7 step:6640 [D loss: 0.686772, acc.: 55.47%] [G loss: 0.890373]\n",
      "epoch:7 step:6641 [D loss: 0.637220, acc.: 60.94%] [G loss: 0.879314]\n",
      "epoch:7 step:6642 [D loss: 0.648415, acc.: 61.72%] [G loss: 0.886347]\n",
      "epoch:7 step:6643 [D loss: 0.658178, acc.: 63.28%] [G loss: 0.939039]\n",
      "epoch:7 step:6644 [D loss: 0.634547, acc.: 69.53%] [G loss: 0.905344]\n",
      "epoch:7 step:6645 [D loss: 0.644586, acc.: 62.50%] [G loss: 0.918716]\n",
      "epoch:7 step:6646 [D loss: 0.644292, acc.: 63.28%] [G loss: 0.873084]\n",
      "epoch:7 step:6647 [D loss: 0.623522, acc.: 70.31%] [G loss: 0.869978]\n",
      "epoch:7 step:6648 [D loss: 0.632312, acc.: 64.06%] [G loss: 0.877813]\n",
      "epoch:7 step:6649 [D loss: 0.628359, acc.: 62.50%] [G loss: 0.886001]\n",
      "epoch:7 step:6650 [D loss: 0.648323, acc.: 63.28%] [G loss: 0.878408]\n",
      "epoch:7 step:6651 [D loss: 0.634331, acc.: 67.19%] [G loss: 0.934788]\n",
      "epoch:7 step:6652 [D loss: 0.606590, acc.: 67.19%] [G loss: 0.890785]\n",
      "epoch:7 step:6653 [D loss: 0.600868, acc.: 70.31%] [G loss: 0.920112]\n",
      "epoch:7 step:6654 [D loss: 0.611609, acc.: 66.41%] [G loss: 0.852475]\n",
      "epoch:7 step:6655 [D loss: 0.653538, acc.: 60.94%] [G loss: 0.884100]\n",
      "epoch:7 step:6656 [D loss: 0.607828, acc.: 64.84%] [G loss: 0.894768]\n",
      "epoch:7 step:6657 [D loss: 0.625031, acc.: 67.97%] [G loss: 0.896641]\n",
      "epoch:7 step:6658 [D loss: 0.660838, acc.: 57.81%] [G loss: 0.932788]\n",
      "epoch:7 step:6659 [D loss: 0.548809, acc.: 72.66%] [G loss: 0.930177]\n",
      "epoch:7 step:6660 [D loss: 0.651592, acc.: 63.28%] [G loss: 0.907694]\n",
      "epoch:7 step:6661 [D loss: 0.749941, acc.: 52.34%] [G loss: 0.923119]\n",
      "epoch:7 step:6662 [D loss: 0.674176, acc.: 57.03%] [G loss: 0.859759]\n",
      "epoch:7 step:6663 [D loss: 0.675942, acc.: 58.59%] [G loss: 0.828741]\n",
      "epoch:7 step:6664 [D loss: 0.694741, acc.: 50.00%] [G loss: 0.889485]\n",
      "epoch:7 step:6665 [D loss: 0.634294, acc.: 62.50%] [G loss: 0.901125]\n",
      "epoch:7 step:6666 [D loss: 0.631610, acc.: 64.06%] [G loss: 0.985169]\n",
      "epoch:7 step:6667 [D loss: 0.714066, acc.: 50.78%] [G loss: 0.905687]\n",
      "epoch:7 step:6668 [D loss: 0.710503, acc.: 50.78%] [G loss: 0.901506]\n",
      "epoch:7 step:6669 [D loss: 0.646028, acc.: 61.72%] [G loss: 0.856073]\n",
      "epoch:7 step:6670 [D loss: 0.612476, acc.: 68.75%] [G loss: 0.863966]\n",
      "epoch:7 step:6671 [D loss: 0.643285, acc.: 60.94%] [G loss: 0.928854]\n",
      "epoch:7 step:6672 [D loss: 0.610536, acc.: 70.31%] [G loss: 0.943927]\n",
      "epoch:7 step:6673 [D loss: 0.628655, acc.: 66.41%] [G loss: 0.950020]\n",
      "epoch:7 step:6674 [D loss: 0.623612, acc.: 65.62%] [G loss: 1.065592]\n",
      "epoch:7 step:6675 [D loss: 0.605250, acc.: 68.75%] [G loss: 0.960541]\n",
      "epoch:7 step:6676 [D loss: 0.663097, acc.: 57.81%] [G loss: 0.961187]\n",
      "epoch:7 step:6677 [D loss: 0.662832, acc.: 55.47%] [G loss: 0.940528]\n",
      "epoch:7 step:6678 [D loss: 0.606127, acc.: 71.88%] [G loss: 0.948961]\n",
      "epoch:7 step:6679 [D loss: 0.692316, acc.: 50.78%] [G loss: 1.025735]\n",
      "epoch:7 step:6680 [D loss: 0.674927, acc.: 59.38%] [G loss: 0.928967]\n",
      "epoch:7 step:6681 [D loss: 0.635450, acc.: 64.84%] [G loss: 0.932804]\n",
      "epoch:7 step:6682 [D loss: 0.644588, acc.: 60.94%] [G loss: 0.948805]\n",
      "epoch:7 step:6683 [D loss: 0.725032, acc.: 52.34%] [G loss: 0.924884]\n",
      "epoch:7 step:6684 [D loss: 0.674484, acc.: 58.59%] [G loss: 0.906404]\n",
      "epoch:7 step:6685 [D loss: 0.631214, acc.: 67.19%] [G loss: 0.898125]\n",
      "epoch:7 step:6686 [D loss: 0.674388, acc.: 59.38%] [G loss: 0.889951]\n",
      "epoch:7 step:6687 [D loss: 0.637141, acc.: 64.06%] [G loss: 0.852690]\n",
      "epoch:7 step:6688 [D loss: 0.650475, acc.: 61.72%] [G loss: 0.887130]\n",
      "epoch:7 step:6689 [D loss: 0.665947, acc.: 55.47%] [G loss: 0.854021]\n",
      "epoch:7 step:6690 [D loss: 0.656438, acc.: 60.94%] [G loss: 0.880694]\n",
      "epoch:7 step:6691 [D loss: 0.654447, acc.: 57.03%] [G loss: 0.913812]\n",
      "epoch:7 step:6692 [D loss: 0.651307, acc.: 61.72%] [G loss: 0.861693]\n",
      "epoch:7 step:6693 [D loss: 0.638229, acc.: 62.50%] [G loss: 0.934127]\n",
      "epoch:7 step:6694 [D loss: 0.617376, acc.: 64.84%] [G loss: 0.948384]\n",
      "epoch:7 step:6695 [D loss: 0.640270, acc.: 65.62%] [G loss: 0.951984]\n",
      "epoch:7 step:6696 [D loss: 0.706958, acc.: 53.91%] [G loss: 0.895636]\n",
      "epoch:7 step:6697 [D loss: 0.702373, acc.: 49.22%] [G loss: 0.903496]\n",
      "epoch:7 step:6698 [D loss: 0.684294, acc.: 56.25%] [G loss: 0.910246]\n",
      "epoch:7 step:6699 [D loss: 0.654185, acc.: 64.06%] [G loss: 0.893652]\n",
      "epoch:7 step:6700 [D loss: 0.687617, acc.: 56.25%] [G loss: 0.850696]\n",
      "epoch:7 step:6701 [D loss: 0.687351, acc.: 54.69%] [G loss: 0.886018]\n",
      "epoch:7 step:6702 [D loss: 0.666253, acc.: 56.25%] [G loss: 0.850418]\n",
      "epoch:7 step:6703 [D loss: 0.676352, acc.: 60.16%] [G loss: 0.892125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6704 [D loss: 0.643498, acc.: 59.38%] [G loss: 0.918635]\n",
      "epoch:7 step:6705 [D loss: 0.678099, acc.: 58.59%] [G loss: 0.896480]\n",
      "epoch:7 step:6706 [D loss: 0.731493, acc.: 48.44%] [G loss: 0.877420]\n",
      "epoch:7 step:6707 [D loss: 0.687279, acc.: 53.91%] [G loss: 0.867278]\n",
      "epoch:7 step:6708 [D loss: 0.608601, acc.: 70.31%] [G loss: 0.890594]\n",
      "epoch:7 step:6709 [D loss: 0.627207, acc.: 71.09%] [G loss: 0.857970]\n",
      "epoch:7 step:6710 [D loss: 0.631127, acc.: 67.97%] [G loss: 0.852091]\n",
      "epoch:7 step:6711 [D loss: 0.620170, acc.: 71.09%] [G loss: 0.968580]\n",
      "epoch:7 step:6712 [D loss: 0.691126, acc.: 62.50%] [G loss: 0.843835]\n",
      "epoch:7 step:6713 [D loss: 0.658347, acc.: 57.03%] [G loss: 0.944364]\n",
      "epoch:7 step:6714 [D loss: 0.633300, acc.: 64.84%] [G loss: 0.928210]\n",
      "epoch:7 step:6715 [D loss: 0.647321, acc.: 62.50%] [G loss: 0.936884]\n",
      "epoch:7 step:6716 [D loss: 0.684919, acc.: 57.03%] [G loss: 0.867449]\n",
      "epoch:7 step:6717 [D loss: 0.646942, acc.: 60.94%] [G loss: 0.898396]\n",
      "epoch:7 step:6718 [D loss: 0.624191, acc.: 65.62%] [G loss: 0.863403]\n",
      "epoch:7 step:6719 [D loss: 0.736477, acc.: 55.47%] [G loss: 0.898688]\n",
      "epoch:7 step:6720 [D loss: 0.681423, acc.: 59.38%] [G loss: 0.981458]\n",
      "epoch:7 step:6721 [D loss: 0.712999, acc.: 55.47%] [G loss: 0.889738]\n",
      "epoch:7 step:6722 [D loss: 0.622125, acc.: 63.28%] [G loss: 0.902902]\n",
      "epoch:7 step:6723 [D loss: 0.631456, acc.: 64.06%] [G loss: 0.893989]\n",
      "epoch:7 step:6724 [D loss: 0.618533, acc.: 62.50%] [G loss: 0.910668]\n",
      "epoch:7 step:6725 [D loss: 0.624934, acc.: 70.31%] [G loss: 0.907259]\n",
      "epoch:7 step:6726 [D loss: 0.644228, acc.: 60.94%] [G loss: 0.847738]\n",
      "epoch:7 step:6727 [D loss: 0.640382, acc.: 62.50%] [G loss: 0.865909]\n",
      "epoch:7 step:6728 [D loss: 0.672144, acc.: 59.38%] [G loss: 0.826246]\n",
      "epoch:7 step:6729 [D loss: 0.632907, acc.: 62.50%] [G loss: 0.887138]\n",
      "epoch:7 step:6730 [D loss: 0.616598, acc.: 66.41%] [G loss: 0.875993]\n",
      "epoch:7 step:6731 [D loss: 0.631772, acc.: 63.28%] [G loss: 0.860184]\n",
      "epoch:7 step:6732 [D loss: 0.671832, acc.: 59.38%] [G loss: 0.856511]\n",
      "epoch:7 step:6733 [D loss: 0.683789, acc.: 58.59%] [G loss: 0.878206]\n",
      "epoch:7 step:6734 [D loss: 0.669404, acc.: 59.38%] [G loss: 0.866306]\n",
      "epoch:7 step:6735 [D loss: 0.643418, acc.: 65.62%] [G loss: 0.942768]\n",
      "epoch:7 step:6736 [D loss: 0.652958, acc.: 63.28%] [G loss: 0.898381]\n",
      "epoch:7 step:6737 [D loss: 0.649465, acc.: 58.59%] [G loss: 0.865574]\n",
      "epoch:7 step:6738 [D loss: 0.653466, acc.: 60.94%] [G loss: 0.850768]\n",
      "epoch:7 step:6739 [D loss: 0.683319, acc.: 56.25%] [G loss: 0.810673]\n",
      "epoch:7 step:6740 [D loss: 0.684363, acc.: 60.94%] [G loss: 0.825935]\n",
      "epoch:7 step:6741 [D loss: 0.719712, acc.: 44.53%] [G loss: 0.852504]\n",
      "epoch:7 step:6742 [D loss: 0.649070, acc.: 63.28%] [G loss: 0.863082]\n",
      "epoch:7 step:6743 [D loss: 0.681383, acc.: 63.28%] [G loss: 0.893770]\n",
      "epoch:7 step:6744 [D loss: 0.697719, acc.: 51.56%] [G loss: 0.884672]\n",
      "epoch:7 step:6745 [D loss: 0.683623, acc.: 60.94%] [G loss: 0.964482]\n",
      "epoch:7 step:6746 [D loss: 0.635039, acc.: 65.62%] [G loss: 0.894079]\n",
      "epoch:7 step:6747 [D loss: 0.722481, acc.: 53.91%] [G loss: 0.845572]\n",
      "epoch:7 step:6748 [D loss: 0.652853, acc.: 62.50%] [G loss: 0.829840]\n",
      "epoch:7 step:6749 [D loss: 0.642440, acc.: 64.84%] [G loss: 0.924271]\n",
      "epoch:7 step:6750 [D loss: 0.627055, acc.: 61.72%] [G loss: 0.894852]\n",
      "epoch:7 step:6751 [D loss: 0.635534, acc.: 64.84%] [G loss: 0.892746]\n",
      "epoch:7 step:6752 [D loss: 0.603082, acc.: 72.66%] [G loss: 0.900122]\n",
      "epoch:7 step:6753 [D loss: 0.586151, acc.: 69.53%] [G loss: 0.852271]\n",
      "epoch:7 step:6754 [D loss: 0.642063, acc.: 65.62%] [G loss: 0.894814]\n",
      "epoch:7 step:6755 [D loss: 0.697306, acc.: 57.81%] [G loss: 0.900500]\n",
      "epoch:7 step:6756 [D loss: 0.625459, acc.: 67.19%] [G loss: 0.955510]\n",
      "epoch:7 step:6757 [D loss: 0.597300, acc.: 67.19%] [G loss: 0.923609]\n",
      "epoch:7 step:6758 [D loss: 0.640973, acc.: 58.59%] [G loss: 0.932892]\n",
      "epoch:7 step:6759 [D loss: 0.716765, acc.: 54.69%] [G loss: 0.911700]\n",
      "epoch:7 step:6760 [D loss: 0.694050, acc.: 55.47%] [G loss: 0.892389]\n",
      "epoch:7 step:6761 [D loss: 0.631535, acc.: 59.38%] [G loss: 0.911765]\n",
      "epoch:7 step:6762 [D loss: 0.746620, acc.: 47.66%] [G loss: 0.813905]\n",
      "epoch:7 step:6763 [D loss: 0.639690, acc.: 60.94%] [G loss: 0.823215]\n",
      "epoch:7 step:6764 [D loss: 0.632833, acc.: 61.72%] [G loss: 0.855587]\n",
      "epoch:7 step:6765 [D loss: 0.622425, acc.: 63.28%] [G loss: 0.922151]\n",
      "epoch:7 step:6766 [D loss: 0.625183, acc.: 63.28%] [G loss: 0.920447]\n",
      "epoch:7 step:6767 [D loss: 0.599424, acc.: 60.16%] [G loss: 0.932639]\n",
      "epoch:7 step:6768 [D loss: 0.600272, acc.: 63.28%] [G loss: 0.925758]\n",
      "epoch:7 step:6769 [D loss: 0.749399, acc.: 47.66%] [G loss: 0.865472]\n",
      "epoch:7 step:6770 [D loss: 0.690185, acc.: 51.56%] [G loss: 0.843642]\n",
      "epoch:7 step:6771 [D loss: 0.648907, acc.: 64.06%] [G loss: 0.861178]\n",
      "epoch:7 step:6772 [D loss: 0.670493, acc.: 57.81%] [G loss: 0.892761]\n",
      "epoch:7 step:6773 [D loss: 0.684558, acc.: 55.47%] [G loss: 0.898569]\n",
      "epoch:7 step:6774 [D loss: 0.660961, acc.: 62.50%] [G loss: 0.887341]\n",
      "epoch:7 step:6775 [D loss: 0.622156, acc.: 62.50%] [G loss: 0.889583]\n",
      "epoch:7 step:6776 [D loss: 0.673218, acc.: 57.03%] [G loss: 0.875757]\n",
      "epoch:7 step:6777 [D loss: 0.634009, acc.: 64.06%] [G loss: 0.896907]\n",
      "epoch:7 step:6778 [D loss: 0.599769, acc.: 72.66%] [G loss: 0.916226]\n",
      "epoch:7 step:6779 [D loss: 0.713749, acc.: 50.00%] [G loss: 0.992669]\n",
      "epoch:7 step:6780 [D loss: 0.619971, acc.: 67.19%] [G loss: 0.938647]\n",
      "epoch:7 step:6781 [D loss: 0.590224, acc.: 67.97%] [G loss: 0.993151]\n",
      "epoch:7 step:6782 [D loss: 0.577576, acc.: 69.53%] [G loss: 0.948252]\n",
      "epoch:7 step:6783 [D loss: 0.751294, acc.: 50.00%] [G loss: 0.875845]\n",
      "epoch:7 step:6784 [D loss: 0.705147, acc.: 53.12%] [G loss: 0.853564]\n",
      "epoch:7 step:6785 [D loss: 0.701687, acc.: 57.03%] [G loss: 0.892290]\n",
      "epoch:7 step:6786 [D loss: 0.650949, acc.: 67.97%] [G loss: 0.914476]\n",
      "epoch:7 step:6787 [D loss: 0.690792, acc.: 49.22%] [G loss: 0.860876]\n",
      "epoch:7 step:6788 [D loss: 0.636441, acc.: 67.97%] [G loss: 0.887761]\n",
      "epoch:7 step:6789 [D loss: 0.594998, acc.: 72.66%] [G loss: 0.912552]\n",
      "epoch:7 step:6790 [D loss: 0.575826, acc.: 67.19%] [G loss: 1.025716]\n",
      "epoch:7 step:6791 [D loss: 0.579304, acc.: 66.41%] [G loss: 1.046574]\n",
      "epoch:7 step:6792 [D loss: 0.713869, acc.: 53.91%] [G loss: 0.951442]\n",
      "epoch:7 step:6793 [D loss: 0.705215, acc.: 53.91%] [G loss: 0.887274]\n",
      "epoch:7 step:6794 [D loss: 0.627275, acc.: 64.06%] [G loss: 1.001005]\n",
      "epoch:7 step:6795 [D loss: 0.604106, acc.: 72.66%] [G loss: 0.902368]\n",
      "epoch:7 step:6796 [D loss: 0.687711, acc.: 56.25%] [G loss: 0.957944]\n",
      "epoch:7 step:6797 [D loss: 0.641627, acc.: 64.06%] [G loss: 0.873022]\n",
      "epoch:7 step:6798 [D loss: 0.641122, acc.: 65.62%] [G loss: 0.904886]\n",
      "epoch:7 step:6799 [D loss: 0.646394, acc.: 63.28%] [G loss: 0.903929]\n",
      "epoch:7 step:6800 [D loss: 0.596748, acc.: 71.09%] [G loss: 0.884026]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.289628\n",
      "FID: 19.338543\n",
      "0 = 12.187382644224144\n",
      "1 = 0.06515765218346593\n",
      "2 = 0.947350025177002\n",
      "3 = 0.9034000039100647\n",
      "4 = 0.9912999868392944\n",
      "5 = 0.9904615879058838\n",
      "6 = 0.9034000039100647\n",
      "7 = 7.126691113764063\n",
      "8 = 0.09646799048794236\n",
      "9 = 0.7722499966621399\n",
      "10 = 0.7386999726295471\n",
      "11 = 0.8058000206947327\n",
      "12 = 0.791831910610199\n",
      "13 = 0.7386999726295471\n",
      "14 = 7.2896952629089355\n",
      "15 = 9.519255638122559\n",
      "16 = 0.12886331975460052\n",
      "17 = 7.289627552032471\n",
      "18 = 19.338542938232422\n",
      "epoch:7 step:6801 [D loss: 0.617065, acc.: 67.97%] [G loss: 0.946270]\n",
      "epoch:7 step:6802 [D loss: 0.650972, acc.: 60.94%] [G loss: 0.893373]\n",
      "epoch:7 step:6803 [D loss: 0.646872, acc.: 67.19%] [G loss: 0.858685]\n",
      "epoch:7 step:6804 [D loss: 0.686133, acc.: 54.69%] [G loss: 0.876561]\n",
      "epoch:7 step:6805 [D loss: 0.663258, acc.: 57.03%] [G loss: 0.931730]\n",
      "epoch:7 step:6806 [D loss: 0.720477, acc.: 52.34%] [G loss: 1.003604]\n",
      "epoch:7 step:6807 [D loss: 0.631023, acc.: 67.19%] [G loss: 1.010565]\n",
      "epoch:7 step:6808 [D loss: 0.727869, acc.: 50.00%] [G loss: 0.931345]\n",
      "epoch:7 step:6809 [D loss: 0.763212, acc.: 43.75%] [G loss: 0.858801]\n",
      "epoch:7 step:6810 [D loss: 0.725366, acc.: 47.66%] [G loss: 0.922038]\n",
      "epoch:7 step:6811 [D loss: 0.643932, acc.: 63.28%] [G loss: 0.872552]\n",
      "epoch:7 step:6812 [D loss: 0.650617, acc.: 63.28%] [G loss: 0.863148]\n",
      "epoch:7 step:6813 [D loss: 0.623193, acc.: 65.62%] [G loss: 0.879041]\n",
      "epoch:7 step:6814 [D loss: 0.659671, acc.: 63.28%] [G loss: 0.970092]\n",
      "epoch:7 step:6815 [D loss: 0.610797, acc.: 62.50%] [G loss: 0.947101]\n",
      "epoch:7 step:6816 [D loss: 0.643744, acc.: 66.41%] [G loss: 0.947269]\n",
      "epoch:7 step:6817 [D loss: 0.604809, acc.: 71.09%] [G loss: 0.910372]\n",
      "epoch:7 step:6818 [D loss: 0.628777, acc.: 62.50%] [G loss: 0.927876]\n",
      "epoch:7 step:6819 [D loss: 0.673137, acc.: 64.06%] [G loss: 0.881491]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6820 [D loss: 0.642242, acc.: 61.72%] [G loss: 0.899383]\n",
      "epoch:7 step:6821 [D loss: 0.608214, acc.: 66.41%] [G loss: 0.874389]\n",
      "epoch:7 step:6822 [D loss: 0.718145, acc.: 49.22%] [G loss: 0.848109]\n",
      "epoch:7 step:6823 [D loss: 0.623298, acc.: 63.28%] [G loss: 0.872514]\n",
      "epoch:7 step:6824 [D loss: 0.716348, acc.: 53.12%] [G loss: 0.886227]\n",
      "epoch:7 step:6825 [D loss: 0.651175, acc.: 61.72%] [G loss: 0.920749]\n",
      "epoch:7 step:6826 [D loss: 0.655941, acc.: 54.69%] [G loss: 0.893118]\n",
      "epoch:7 step:6827 [D loss: 0.657899, acc.: 57.81%] [G loss: 0.872628]\n",
      "epoch:7 step:6828 [D loss: 0.675755, acc.: 60.16%] [G loss: 0.917468]\n",
      "epoch:7 step:6829 [D loss: 0.635785, acc.: 65.62%] [G loss: 0.933706]\n",
      "epoch:7 step:6830 [D loss: 0.637821, acc.: 62.50%] [G loss: 0.914629]\n",
      "epoch:7 step:6831 [D loss: 0.657990, acc.: 60.94%] [G loss: 0.930151]\n",
      "epoch:7 step:6832 [D loss: 0.681972, acc.: 52.34%] [G loss: 0.895698]\n",
      "epoch:7 step:6833 [D loss: 0.631615, acc.: 65.62%] [G loss: 0.959509]\n",
      "epoch:7 step:6834 [D loss: 0.664647, acc.: 60.16%] [G loss: 0.874657]\n",
      "epoch:7 step:6835 [D loss: 0.662955, acc.: 57.81%] [G loss: 0.854789]\n",
      "epoch:7 step:6836 [D loss: 0.731022, acc.: 50.00%] [G loss: 0.841167]\n",
      "epoch:7 step:6837 [D loss: 0.713595, acc.: 49.22%] [G loss: 0.843940]\n",
      "epoch:7 step:6838 [D loss: 0.668575, acc.: 63.28%] [G loss: 0.962654]\n",
      "epoch:7 step:6839 [D loss: 0.614760, acc.: 71.88%] [G loss: 0.918882]\n",
      "epoch:7 step:6840 [D loss: 0.689207, acc.: 60.16%] [G loss: 0.917223]\n",
      "epoch:7 step:6841 [D loss: 0.673095, acc.: 57.81%] [G loss: 0.857381]\n",
      "epoch:7 step:6842 [D loss: 0.624071, acc.: 71.88%] [G loss: 0.889097]\n",
      "epoch:7 step:6843 [D loss: 0.628420, acc.: 65.62%] [G loss: 0.913373]\n",
      "epoch:7 step:6844 [D loss: 0.641354, acc.: 63.28%] [G loss: 0.871209]\n",
      "epoch:7 step:6845 [D loss: 0.625410, acc.: 69.53%] [G loss: 0.944055]\n",
      "epoch:7 step:6846 [D loss: 0.673680, acc.: 60.16%] [G loss: 0.895602]\n",
      "epoch:7 step:6847 [D loss: 0.651494, acc.: 60.16%] [G loss: 0.964885]\n",
      "epoch:7 step:6848 [D loss: 0.572307, acc.: 76.56%] [G loss: 0.978792]\n",
      "epoch:7 step:6849 [D loss: 0.652519, acc.: 60.16%] [G loss: 0.945811]\n",
      "epoch:7 step:6850 [D loss: 0.684755, acc.: 59.38%] [G loss: 0.887864]\n",
      "epoch:7 step:6851 [D loss: 0.639953, acc.: 63.28%] [G loss: 0.879089]\n",
      "epoch:7 step:6852 [D loss: 0.611221, acc.: 70.31%] [G loss: 0.862412]\n",
      "epoch:7 step:6853 [D loss: 0.713906, acc.: 56.25%] [G loss: 0.912062]\n",
      "epoch:7 step:6854 [D loss: 0.658188, acc.: 56.25%] [G loss: 0.807692]\n",
      "epoch:7 step:6855 [D loss: 0.670583, acc.: 55.47%] [G loss: 0.906743]\n",
      "epoch:7 step:6856 [D loss: 0.641840, acc.: 60.94%] [G loss: 0.933830]\n",
      "epoch:7 step:6857 [D loss: 0.584767, acc.: 71.88%] [G loss: 0.982054]\n",
      "epoch:7 step:6858 [D loss: 0.608718, acc.: 67.97%] [G loss: 0.923179]\n",
      "epoch:7 step:6859 [D loss: 0.619528, acc.: 68.75%] [G loss: 0.976324]\n",
      "epoch:7 step:6860 [D loss: 0.712890, acc.: 50.78%] [G loss: 0.942834]\n",
      "epoch:7 step:6861 [D loss: 0.627999, acc.: 63.28%] [G loss: 0.907064]\n",
      "epoch:7 step:6862 [D loss: 0.674826, acc.: 55.47%] [G loss: 0.940155]\n",
      "epoch:7 step:6863 [D loss: 0.639450, acc.: 61.72%] [G loss: 0.911635]\n",
      "epoch:7 step:6864 [D loss: 0.666626, acc.: 60.94%] [G loss: 0.886208]\n",
      "epoch:7 step:6865 [D loss: 0.613848, acc.: 64.06%] [G loss: 0.890074]\n",
      "epoch:7 step:6866 [D loss: 0.602235, acc.: 67.97%] [G loss: 0.887843]\n",
      "epoch:7 step:6867 [D loss: 0.664858, acc.: 63.28%] [G loss: 0.889483]\n",
      "epoch:7 step:6868 [D loss: 0.610910, acc.: 67.19%] [G loss: 0.937627]\n",
      "epoch:7 step:6869 [D loss: 0.659884, acc.: 62.50%] [G loss: 0.867545]\n",
      "epoch:7 step:6870 [D loss: 0.663141, acc.: 59.38%] [G loss: 0.867907]\n",
      "epoch:7 step:6871 [D loss: 0.568145, acc.: 74.22%] [G loss: 0.897384]\n",
      "epoch:7 step:6872 [D loss: 0.583817, acc.: 72.66%] [G loss: 0.904155]\n",
      "epoch:7 step:6873 [D loss: 0.614062, acc.: 62.50%] [G loss: 0.917930]\n",
      "epoch:7 step:6874 [D loss: 0.628462, acc.: 61.72%] [G loss: 0.923572]\n",
      "epoch:7 step:6875 [D loss: 0.772799, acc.: 52.34%] [G loss: 0.912390]\n",
      "epoch:7 step:6876 [D loss: 0.691018, acc.: 49.22%] [G loss: 0.907344]\n",
      "epoch:7 step:6877 [D loss: 0.658891, acc.: 64.06%] [G loss: 0.932016]\n",
      "epoch:7 step:6878 [D loss: 0.650325, acc.: 62.50%] [G loss: 0.917464]\n",
      "epoch:7 step:6879 [D loss: 0.621148, acc.: 60.94%] [G loss: 0.876682]\n",
      "epoch:7 step:6880 [D loss: 0.576432, acc.: 72.66%] [G loss: 0.943790]\n",
      "epoch:7 step:6881 [D loss: 0.632539, acc.: 63.28%] [G loss: 0.906801]\n",
      "epoch:7 step:6882 [D loss: 0.692005, acc.: 55.47%] [G loss: 0.879905]\n",
      "epoch:7 step:6883 [D loss: 0.653256, acc.: 67.19%] [G loss: 0.933994]\n",
      "epoch:7 step:6884 [D loss: 0.623641, acc.: 64.06%] [G loss: 0.866304]\n",
      "epoch:7 step:6885 [D loss: 0.639268, acc.: 64.84%] [G loss: 0.905967]\n",
      "epoch:7 step:6886 [D loss: 0.638901, acc.: 59.38%] [G loss: 0.929554]\n",
      "epoch:7 step:6887 [D loss: 0.631193, acc.: 66.41%] [G loss: 0.897882]\n",
      "epoch:7 step:6888 [D loss: 0.682940, acc.: 56.25%] [G loss: 0.931027]\n",
      "epoch:7 step:6889 [D loss: 0.653187, acc.: 60.94%] [G loss: 0.918987]\n",
      "epoch:7 step:6890 [D loss: 0.641480, acc.: 61.72%] [G loss: 0.924595]\n",
      "epoch:7 step:6891 [D loss: 0.643108, acc.: 58.59%] [G loss: 0.928098]\n",
      "epoch:7 step:6892 [D loss: 0.611144, acc.: 66.41%] [G loss: 0.960192]\n",
      "epoch:7 step:6893 [D loss: 0.675215, acc.: 61.72%] [G loss: 0.934289]\n",
      "epoch:7 step:6894 [D loss: 0.669466, acc.: 58.59%] [G loss: 0.991266]\n",
      "epoch:7 step:6895 [D loss: 0.619296, acc.: 67.19%] [G loss: 0.925008]\n",
      "epoch:7 step:6896 [D loss: 0.651327, acc.: 61.72%] [G loss: 0.990995]\n",
      "epoch:7 step:6897 [D loss: 0.638297, acc.: 64.06%] [G loss: 0.875882]\n",
      "epoch:7 step:6898 [D loss: 0.630099, acc.: 67.19%] [G loss: 0.901555]\n",
      "epoch:7 step:6899 [D loss: 0.671037, acc.: 60.16%] [G loss: 0.922891]\n",
      "epoch:7 step:6900 [D loss: 0.745817, acc.: 53.91%] [G loss: 0.948482]\n",
      "epoch:7 step:6901 [D loss: 0.695197, acc.: 53.91%] [G loss: 0.979174]\n",
      "epoch:7 step:6902 [D loss: 0.650332, acc.: 65.62%] [G loss: 0.972926]\n",
      "epoch:7 step:6903 [D loss: 0.637138, acc.: 65.62%] [G loss: 0.914019]\n",
      "epoch:7 step:6904 [D loss: 0.624935, acc.: 62.50%] [G loss: 0.976785]\n",
      "epoch:7 step:6905 [D loss: 0.607415, acc.: 70.31%] [G loss: 1.012642]\n",
      "epoch:7 step:6906 [D loss: 0.556596, acc.: 71.09%] [G loss: 1.047879]\n",
      "epoch:7 step:6907 [D loss: 0.729600, acc.: 54.69%] [G loss: 0.988072]\n",
      "epoch:7 step:6908 [D loss: 0.786515, acc.: 44.53%] [G loss: 0.833565]\n",
      "epoch:7 step:6909 [D loss: 0.667645, acc.: 55.47%] [G loss: 0.883367]\n",
      "epoch:7 step:6910 [D loss: 0.661511, acc.: 57.81%] [G loss: 0.915636]\n",
      "epoch:7 step:6911 [D loss: 0.649693, acc.: 58.59%] [G loss: 0.930509]\n",
      "epoch:7 step:6912 [D loss: 0.624639, acc.: 59.38%] [G loss: 0.973448]\n",
      "epoch:7 step:6913 [D loss: 0.613015, acc.: 65.62%] [G loss: 0.990556]\n",
      "epoch:7 step:6914 [D loss: 0.665958, acc.: 59.38%] [G loss: 0.936431]\n",
      "epoch:7 step:6915 [D loss: 0.636339, acc.: 68.75%] [G loss: 0.908551]\n",
      "epoch:7 step:6916 [D loss: 0.620008, acc.: 64.06%] [G loss: 0.858324]\n",
      "epoch:7 step:6917 [D loss: 0.619792, acc.: 69.53%] [G loss: 0.934778]\n",
      "epoch:7 step:6918 [D loss: 0.650914, acc.: 60.94%] [G loss: 0.914524]\n",
      "epoch:7 step:6919 [D loss: 0.625168, acc.: 67.97%] [G loss: 0.993308]\n",
      "epoch:7 step:6920 [D loss: 0.713069, acc.: 52.34%] [G loss: 0.964078]\n",
      "epoch:7 step:6921 [D loss: 0.704391, acc.: 52.34%] [G loss: 0.929009]\n",
      "epoch:7 step:6922 [D loss: 0.655528, acc.: 63.28%] [G loss: 0.883936]\n",
      "epoch:7 step:6923 [D loss: 0.622577, acc.: 64.84%] [G loss: 0.837960]\n",
      "epoch:7 step:6924 [D loss: 0.667442, acc.: 58.59%] [G loss: 0.869274]\n",
      "epoch:7 step:6925 [D loss: 0.641887, acc.: 67.19%] [G loss: 0.899247]\n",
      "epoch:7 step:6926 [D loss: 0.615797, acc.: 71.88%] [G loss: 0.857532]\n",
      "epoch:7 step:6927 [D loss: 0.651271, acc.: 65.62%] [G loss: 0.893615]\n",
      "epoch:7 step:6928 [D loss: 0.674026, acc.: 57.81%] [G loss: 0.868485]\n",
      "epoch:7 step:6929 [D loss: 0.625561, acc.: 64.84%] [G loss: 0.834004]\n",
      "epoch:7 step:6930 [D loss: 0.635245, acc.: 65.62%] [G loss: 0.851328]\n",
      "epoch:7 step:6931 [D loss: 0.676508, acc.: 60.16%] [G loss: 0.889740]\n",
      "epoch:7 step:6932 [D loss: 0.679785, acc.: 61.72%] [G loss: 0.885659]\n",
      "epoch:7 step:6933 [D loss: 0.613854, acc.: 68.75%] [G loss: 0.866267]\n",
      "epoch:7 step:6934 [D loss: 0.689139, acc.: 57.03%] [G loss: 0.921085]\n",
      "epoch:7 step:6935 [D loss: 0.739391, acc.: 48.44%] [G loss: 0.885084]\n",
      "epoch:7 step:6936 [D loss: 0.695053, acc.: 53.12%] [G loss: 0.896088]\n",
      "epoch:7 step:6937 [D loss: 0.667343, acc.: 56.25%] [G loss: 0.938849]\n",
      "epoch:7 step:6938 [D loss: 0.685499, acc.: 59.38%] [G loss: 0.883303]\n",
      "epoch:7 step:6939 [D loss: 0.684370, acc.: 57.03%] [G loss: 0.809627]\n",
      "epoch:7 step:6940 [D loss: 0.612777, acc.: 65.62%] [G loss: 0.851084]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6941 [D loss: 0.666780, acc.: 59.38%] [G loss: 0.960786]\n",
      "epoch:7 step:6942 [D loss: 0.646659, acc.: 64.06%] [G loss: 0.855533]\n",
      "epoch:7 step:6943 [D loss: 0.630205, acc.: 62.50%] [G loss: 0.871714]\n",
      "epoch:7 step:6944 [D loss: 0.636776, acc.: 64.06%] [G loss: 0.952728]\n",
      "epoch:7 step:6945 [D loss: 0.714621, acc.: 48.44%] [G loss: 0.905646]\n",
      "epoch:7 step:6946 [D loss: 0.656418, acc.: 61.72%] [G loss: 0.882259]\n",
      "epoch:7 step:6947 [D loss: 0.678896, acc.: 54.69%] [G loss: 0.928811]\n",
      "epoch:7 step:6948 [D loss: 0.650038, acc.: 63.28%] [G loss: 0.965540]\n",
      "epoch:7 step:6949 [D loss: 0.693620, acc.: 58.59%] [G loss: 0.900803]\n",
      "epoch:7 step:6950 [D loss: 0.630265, acc.: 64.84%] [G loss: 0.907074]\n",
      "epoch:7 step:6951 [D loss: 0.641961, acc.: 64.06%] [G loss: 0.903035]\n",
      "epoch:7 step:6952 [D loss: 0.663910, acc.: 55.47%] [G loss: 0.839389]\n",
      "epoch:7 step:6953 [D loss: 0.686639, acc.: 53.91%] [G loss: 0.812971]\n",
      "epoch:7 step:6954 [D loss: 0.648258, acc.: 59.38%] [G loss: 0.818449]\n",
      "epoch:7 step:6955 [D loss: 0.664997, acc.: 58.59%] [G loss: 0.836413]\n",
      "epoch:7 step:6956 [D loss: 0.587764, acc.: 70.31%] [G loss: 0.852481]\n",
      "epoch:7 step:6957 [D loss: 0.591822, acc.: 66.41%] [G loss: 0.956351]\n",
      "epoch:7 step:6958 [D loss: 0.582127, acc.: 71.88%] [G loss: 0.944353]\n",
      "epoch:7 step:6959 [D loss: 0.674365, acc.: 58.59%] [G loss: 0.873210]\n",
      "epoch:7 step:6960 [D loss: 0.645748, acc.: 64.06%] [G loss: 0.869118]\n",
      "epoch:7 step:6961 [D loss: 0.625939, acc.: 65.62%] [G loss: 0.834290]\n",
      "epoch:7 step:6962 [D loss: 0.670511, acc.: 58.59%] [G loss: 0.802256]\n",
      "epoch:7 step:6963 [D loss: 0.701114, acc.: 55.47%] [G loss: 0.813993]\n",
      "epoch:7 step:6964 [D loss: 0.630204, acc.: 65.62%] [G loss: 0.870649]\n",
      "epoch:7 step:6965 [D loss: 0.604908, acc.: 70.31%] [G loss: 0.954225]\n",
      "epoch:7 step:6966 [D loss: 0.633854, acc.: 64.84%] [G loss: 0.952244]\n",
      "epoch:7 step:6967 [D loss: 0.739769, acc.: 48.44%] [G loss: 0.846287]\n",
      "epoch:7 step:6968 [D loss: 0.667450, acc.: 59.38%] [G loss: 0.867523]\n",
      "epoch:7 step:6969 [D loss: 0.693864, acc.: 53.91%] [G loss: 0.897084]\n",
      "epoch:7 step:6970 [D loss: 0.677427, acc.: 57.81%] [G loss: 0.913430]\n",
      "epoch:7 step:6971 [D loss: 0.652199, acc.: 63.28%] [G loss: 0.904240]\n",
      "epoch:7 step:6972 [D loss: 0.651131, acc.: 59.38%] [G loss: 0.915524]\n",
      "epoch:7 step:6973 [D loss: 0.666926, acc.: 60.94%] [G loss: 0.903739]\n",
      "epoch:7 step:6974 [D loss: 0.638092, acc.: 64.06%] [G loss: 0.812253]\n",
      "epoch:7 step:6975 [D loss: 0.611488, acc.: 69.53%] [G loss: 0.866321]\n",
      "epoch:7 step:6976 [D loss: 0.687360, acc.: 53.91%] [G loss: 0.904968]\n",
      "epoch:7 step:6977 [D loss: 0.714455, acc.: 53.91%] [G loss: 0.868872]\n",
      "epoch:7 step:6978 [D loss: 0.683739, acc.: 56.25%] [G loss: 0.868896]\n",
      "epoch:7 step:6979 [D loss: 0.617825, acc.: 67.19%] [G loss: 0.929887]\n",
      "epoch:7 step:6980 [D loss: 0.714736, acc.: 50.78%] [G loss: 0.860438]\n",
      "epoch:7 step:6981 [D loss: 0.736008, acc.: 51.56%] [G loss: 0.813845]\n",
      "epoch:7 step:6982 [D loss: 0.686975, acc.: 55.47%] [G loss: 0.973766]\n",
      "epoch:7 step:6983 [D loss: 0.689779, acc.: 55.47%] [G loss: 0.934565]\n",
      "epoch:7 step:6984 [D loss: 0.696331, acc.: 57.81%] [G loss: 0.990297]\n",
      "epoch:7 step:6985 [D loss: 0.596379, acc.: 71.88%] [G loss: 0.934663]\n",
      "epoch:7 step:6986 [D loss: 0.586239, acc.: 71.88%] [G loss: 0.911483]\n",
      "epoch:7 step:6987 [D loss: 0.598291, acc.: 70.31%] [G loss: 0.889861]\n",
      "epoch:7 step:6988 [D loss: 0.629778, acc.: 68.75%] [G loss: 0.973926]\n",
      "epoch:7 step:6989 [D loss: 0.595651, acc.: 70.31%] [G loss: 0.974319]\n",
      "epoch:7 step:6990 [D loss: 0.662005, acc.: 60.16%] [G loss: 0.916636]\n",
      "epoch:7 step:6991 [D loss: 0.704173, acc.: 49.22%] [G loss: 0.969324]\n",
      "epoch:7 step:6992 [D loss: 0.721838, acc.: 50.00%] [G loss: 0.842991]\n",
      "epoch:7 step:6993 [D loss: 0.642695, acc.: 59.38%] [G loss: 0.901462]\n",
      "epoch:7 step:6994 [D loss: 0.642368, acc.: 64.06%] [G loss: 0.894972]\n",
      "epoch:7 step:6995 [D loss: 0.617568, acc.: 72.66%] [G loss: 0.928638]\n",
      "epoch:7 step:6996 [D loss: 0.765994, acc.: 47.66%] [G loss: 0.899038]\n",
      "epoch:7 step:6997 [D loss: 0.677457, acc.: 60.94%] [G loss: 0.864565]\n",
      "epoch:7 step:6998 [D loss: 0.671412, acc.: 60.94%] [G loss: 0.893524]\n",
      "epoch:7 step:6999 [D loss: 0.655429, acc.: 57.81%] [G loss: 0.901131]\n",
      "epoch:7 step:7000 [D loss: 0.672535, acc.: 58.59%] [G loss: 0.911235]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.491243\n",
      "FID: 15.345624\n",
      "0 = 11.948225234723088\n",
      "1 = 0.06041678943840795\n",
      "2 = 0.9419999718666077\n",
      "3 = 0.8932999968528748\n",
      "4 = 0.9907000064849854\n",
      "5 = 0.9896964430809021\n",
      "6 = 0.8932999968528748\n",
      "7 = 6.765514592939608\n",
      "8 = 0.08411415186595189\n",
      "9 = 0.7635499835014343\n",
      "10 = 0.7416999936103821\n",
      "11 = 0.7853999733924866\n",
      "12 = 0.7755934596061707\n",
      "13 = 0.7416999936103821\n",
      "14 = 7.491313457489014\n",
      "15 = 9.544340133666992\n",
      "16 = 0.12158801406621933\n",
      "17 = 7.491243362426758\n",
      "18 = 15.345623970031738\n",
      "epoch:7 step:7001 [D loss: 0.680514, acc.: 56.25%] [G loss: 0.877627]\n",
      "epoch:7 step:7002 [D loss: 0.633641, acc.: 64.06%] [G loss: 0.830935]\n",
      "epoch:7 step:7003 [D loss: 0.660396, acc.: 67.97%] [G loss: 0.852918]\n",
      "epoch:7 step:7004 [D loss: 0.598053, acc.: 72.66%] [G loss: 0.912606]\n",
      "epoch:7 step:7005 [D loss: 0.662960, acc.: 62.50%] [G loss: 0.910560]\n",
      "epoch:7 step:7006 [D loss: 0.643329, acc.: 60.16%] [G loss: 0.936851]\n",
      "epoch:7 step:7007 [D loss: 0.687057, acc.: 50.78%] [G loss: 0.949068]\n",
      "epoch:7 step:7008 [D loss: 0.673611, acc.: 58.59%] [G loss: 0.916011]\n",
      "epoch:7 step:7009 [D loss: 0.641087, acc.: 59.38%] [G loss: 0.924334]\n",
      "epoch:7 step:7010 [D loss: 0.620455, acc.: 64.06%] [G loss: 0.891595]\n",
      "epoch:7 step:7011 [D loss: 0.641056, acc.: 66.41%] [G loss: 0.886075]\n",
      "epoch:7 step:7012 [D loss: 0.628866, acc.: 59.38%] [G loss: 0.928451]\n",
      "epoch:7 step:7013 [D loss: 0.649273, acc.: 60.16%] [G loss: 0.924290]\n",
      "epoch:7 step:7014 [D loss: 0.709078, acc.: 55.47%] [G loss: 0.840686]\n",
      "epoch:7 step:7015 [D loss: 0.671168, acc.: 57.81%] [G loss: 0.874780]\n",
      "epoch:7 step:7016 [D loss: 0.637774, acc.: 62.50%] [G loss: 0.882782]\n",
      "epoch:7 step:7017 [D loss: 0.731396, acc.: 55.47%] [G loss: 0.828492]\n",
      "epoch:7 step:7018 [D loss: 0.672202, acc.: 60.16%] [G loss: 0.864778]\n",
      "epoch:7 step:7019 [D loss: 0.738455, acc.: 46.88%] [G loss: 0.908437]\n",
      "epoch:7 step:7020 [D loss: 0.699951, acc.: 53.12%] [G loss: 0.879698]\n",
      "epoch:7 step:7021 [D loss: 0.704741, acc.: 53.12%] [G loss: 0.866696]\n",
      "epoch:7 step:7022 [D loss: 0.700635, acc.: 56.25%] [G loss: 0.867502]\n",
      "epoch:7 step:7023 [D loss: 0.653093, acc.: 67.19%] [G loss: 0.859269]\n",
      "epoch:7 step:7024 [D loss: 0.656770, acc.: 60.94%] [G loss: 0.874327]\n",
      "epoch:7 step:7025 [D loss: 0.616752, acc.: 67.19%] [G loss: 0.852203]\n",
      "epoch:7 step:7026 [D loss: 0.637696, acc.: 62.50%] [G loss: 0.879712]\n",
      "epoch:7 step:7027 [D loss: 0.658604, acc.: 63.28%] [G loss: 0.907599]\n",
      "epoch:7 step:7028 [D loss: 0.630472, acc.: 64.06%] [G loss: 0.907710]\n",
      "epoch:7 step:7029 [D loss: 0.632150, acc.: 63.28%] [G loss: 0.923855]\n",
      "epoch:7 step:7030 [D loss: 0.596784, acc.: 67.19%] [G loss: 0.950222]\n",
      "epoch:7 step:7031 [D loss: 0.639098, acc.: 64.06%] [G loss: 0.976973]\n",
      "epoch:7 step:7032 [D loss: 0.754960, acc.: 50.00%] [G loss: 0.904153]\n",
      "epoch:7 step:7033 [D loss: 0.661018, acc.: 60.94%] [G loss: 0.904453]\n",
      "epoch:7 step:7034 [D loss: 0.629943, acc.: 60.94%] [G loss: 0.955990]\n",
      "epoch:7 step:7035 [D loss: 0.659706, acc.: 61.72%] [G loss: 0.976845]\n",
      "epoch:7 step:7036 [D loss: 0.740426, acc.: 50.78%] [G loss: 0.816083]\n",
      "epoch:7 step:7037 [D loss: 0.689659, acc.: 55.47%] [G loss: 0.850348]\n",
      "epoch:7 step:7038 [D loss: 0.643956, acc.: 66.41%] [G loss: 0.872489]\n",
      "epoch:7 step:7039 [D loss: 0.662611, acc.: 61.72%] [G loss: 0.877805]\n",
      "epoch:7 step:7040 [D loss: 0.620334, acc.: 67.19%] [G loss: 0.935063]\n",
      "epoch:7 step:7041 [D loss: 0.674768, acc.: 53.12%] [G loss: 0.894600]\n",
      "epoch:7 step:7042 [D loss: 0.678415, acc.: 59.38%] [G loss: 0.886228]\n",
      "epoch:7 step:7043 [D loss: 0.614934, acc.: 67.19%] [G loss: 0.893893]\n",
      "epoch:7 step:7044 [D loss: 0.662168, acc.: 66.41%] [G loss: 0.910859]\n",
      "epoch:7 step:7045 [D loss: 0.683993, acc.: 56.25%] [G loss: 0.946254]\n",
      "epoch:7 step:7046 [D loss: 0.681536, acc.: 54.69%] [G loss: 0.923509]\n",
      "epoch:7 step:7047 [D loss: 0.658840, acc.: 62.50%] [G loss: 0.933879]\n",
      "epoch:7 step:7048 [D loss: 0.680552, acc.: 58.59%] [G loss: 0.957159]\n",
      "epoch:7 step:7049 [D loss: 0.668743, acc.: 59.38%] [G loss: 0.971981]\n",
      "epoch:7 step:7050 [D loss: 0.651405, acc.: 63.28%] [G loss: 0.931747]\n",
      "epoch:7 step:7051 [D loss: 0.698283, acc.: 57.03%] [G loss: 0.944625]\n",
      "epoch:7 step:7052 [D loss: 0.656614, acc.: 59.38%] [G loss: 0.915614]\n",
      "epoch:7 step:7053 [D loss: 0.624670, acc.: 66.41%] [G loss: 0.875397]\n",
      "epoch:7 step:7054 [D loss: 0.606705, acc.: 65.62%] [G loss: 0.902332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7055 [D loss: 0.646433, acc.: 63.28%] [G loss: 0.890515]\n",
      "epoch:7 step:7056 [D loss: 0.671038, acc.: 61.72%] [G loss: 0.896385]\n",
      "epoch:7 step:7057 [D loss: 0.659632, acc.: 65.62%] [G loss: 0.865820]\n",
      "epoch:7 step:7058 [D loss: 0.632339, acc.: 67.19%] [G loss: 0.941248]\n",
      "epoch:7 step:7059 [D loss: 0.742694, acc.: 47.66%] [G loss: 0.945322]\n",
      "epoch:7 step:7060 [D loss: 0.733179, acc.: 50.78%] [G loss: 0.860360]\n",
      "epoch:7 step:7061 [D loss: 0.643167, acc.: 62.50%] [G loss: 0.899579]\n",
      "epoch:7 step:7062 [D loss: 0.636256, acc.: 65.62%] [G loss: 0.891824]\n",
      "epoch:7 step:7063 [D loss: 0.621946, acc.: 66.41%] [G loss: 0.956429]\n",
      "epoch:7 step:7064 [D loss: 0.631302, acc.: 62.50%] [G loss: 0.915650]\n",
      "epoch:7 step:7065 [D loss: 0.646574, acc.: 58.59%] [G loss: 0.999268]\n",
      "epoch:7 step:7066 [D loss: 0.618972, acc.: 67.19%] [G loss: 1.005403]\n",
      "epoch:7 step:7067 [D loss: 0.604103, acc.: 68.75%] [G loss: 1.043240]\n",
      "epoch:7 step:7068 [D loss: 0.697076, acc.: 55.47%] [G loss: 0.938190]\n",
      "epoch:7 step:7069 [D loss: 0.709135, acc.: 50.00%] [G loss: 0.870798]\n",
      "epoch:7 step:7070 [D loss: 0.732994, acc.: 51.56%] [G loss: 0.878133]\n",
      "epoch:7 step:7071 [D loss: 0.658288, acc.: 60.16%] [G loss: 0.926771]\n",
      "epoch:7 step:7072 [D loss: 0.660037, acc.: 61.72%] [G loss: 0.973970]\n",
      "epoch:7 step:7073 [D loss: 0.665336, acc.: 56.25%] [G loss: 0.901381]\n",
      "epoch:7 step:7074 [D loss: 0.619631, acc.: 72.66%] [G loss: 0.868011]\n",
      "epoch:7 step:7075 [D loss: 0.603424, acc.: 68.75%] [G loss: 0.887926]\n",
      "epoch:7 step:7076 [D loss: 0.693293, acc.: 57.81%] [G loss: 0.881714]\n",
      "epoch:7 step:7077 [D loss: 0.656242, acc.: 62.50%] [G loss: 0.901604]\n",
      "epoch:7 step:7078 [D loss: 0.582630, acc.: 75.00%] [G loss: 0.946178]\n",
      "epoch:7 step:7079 [D loss: 0.620624, acc.: 64.84%] [G loss: 0.915858]\n",
      "epoch:7 step:7080 [D loss: 0.649941, acc.: 64.06%] [G loss: 0.898221]\n",
      "epoch:7 step:7081 [D loss: 0.607079, acc.: 67.19%] [G loss: 0.883168]\n",
      "epoch:7 step:7082 [D loss: 0.631528, acc.: 67.19%] [G loss: 0.966192]\n",
      "epoch:7 step:7083 [D loss: 0.668485, acc.: 60.16%] [G loss: 0.877298]\n",
      "epoch:7 step:7084 [D loss: 0.719618, acc.: 49.22%] [G loss: 0.874938]\n",
      "epoch:7 step:7085 [D loss: 0.639080, acc.: 65.62%] [G loss: 0.923176]\n",
      "epoch:7 step:7086 [D loss: 0.658139, acc.: 68.75%] [G loss: 0.901170]\n",
      "epoch:7 step:7087 [D loss: 0.665873, acc.: 63.28%] [G loss: 0.909619]\n",
      "epoch:7 step:7088 [D loss: 0.695808, acc.: 51.56%] [G loss: 0.874492]\n",
      "epoch:7 step:7089 [D loss: 0.671068, acc.: 60.16%] [G loss: 0.888110]\n",
      "epoch:7 step:7090 [D loss: 0.660200, acc.: 60.94%] [G loss: 0.895893]\n",
      "epoch:7 step:7091 [D loss: 0.650365, acc.: 57.03%] [G loss: 0.857900]\n",
      "epoch:7 step:7092 [D loss: 0.687069, acc.: 53.91%] [G loss: 0.895085]\n",
      "epoch:7 step:7093 [D loss: 0.606216, acc.: 71.09%] [G loss: 0.902848]\n",
      "epoch:7 step:7094 [D loss: 0.677854, acc.: 57.81%] [G loss: 0.845101]\n",
      "epoch:7 step:7095 [D loss: 0.663533, acc.: 62.50%] [G loss: 0.911355]\n",
      "epoch:7 step:7096 [D loss: 0.661591, acc.: 61.72%] [G loss: 0.883188]\n",
      "epoch:7 step:7097 [D loss: 0.685834, acc.: 57.81%] [G loss: 0.851958]\n",
      "epoch:7 step:7098 [D loss: 0.670319, acc.: 56.25%] [G loss: 0.852274]\n",
      "epoch:7 step:7099 [D loss: 0.663515, acc.: 57.03%] [G loss: 0.915231]\n",
      "epoch:7 step:7100 [D loss: 0.658996, acc.: 60.94%] [G loss: 0.818429]\n",
      "epoch:7 step:7101 [D loss: 0.719278, acc.: 52.34%] [G loss: 0.881524]\n",
      "epoch:7 step:7102 [D loss: 0.693003, acc.: 53.91%] [G loss: 0.813866]\n",
      "epoch:7 step:7103 [D loss: 0.669957, acc.: 57.81%] [G loss: 0.884459]\n",
      "epoch:7 step:7104 [D loss: 0.634405, acc.: 66.41%] [G loss: 0.847187]\n",
      "epoch:7 step:7105 [D loss: 0.620256, acc.: 67.97%] [G loss: 0.894038]\n",
      "epoch:7 step:7106 [D loss: 0.623263, acc.: 65.62%] [G loss: 0.907920]\n",
      "epoch:7 step:7107 [D loss: 0.633583, acc.: 66.41%] [G loss: 0.901721]\n",
      "epoch:7 step:7108 [D loss: 0.621985, acc.: 66.41%] [G loss: 0.918351]\n",
      "epoch:7 step:7109 [D loss: 0.606888, acc.: 64.84%] [G loss: 0.952389]\n",
      "epoch:7 step:7110 [D loss: 0.615659, acc.: 67.97%] [G loss: 0.918374]\n",
      "epoch:7 step:7111 [D loss: 0.650581, acc.: 65.62%] [G loss: 0.913517]\n",
      "epoch:7 step:7112 [D loss: 0.701619, acc.: 52.34%] [G loss: 0.908610]\n",
      "epoch:7 step:7113 [D loss: 0.620423, acc.: 65.62%] [G loss: 0.852245]\n",
      "epoch:7 step:7114 [D loss: 0.644777, acc.: 57.03%] [G loss: 0.888492]\n",
      "epoch:7 step:7115 [D loss: 0.597871, acc.: 71.09%] [G loss: 0.904915]\n",
      "epoch:7 step:7116 [D loss: 0.577319, acc.: 71.09%] [G loss: 0.910681]\n",
      "epoch:7 step:7117 [D loss: 0.613453, acc.: 67.19%] [G loss: 0.901395]\n",
      "epoch:7 step:7118 [D loss: 0.749951, acc.: 49.22%] [G loss: 0.917286]\n",
      "epoch:7 step:7119 [D loss: 0.682405, acc.: 60.94%] [G loss: 0.878368]\n",
      "epoch:7 step:7120 [D loss: 0.625061, acc.: 60.94%] [G loss: 0.993016]\n",
      "epoch:7 step:7121 [D loss: 0.643353, acc.: 67.19%] [G loss: 0.947324]\n",
      "epoch:7 step:7122 [D loss: 0.650336, acc.: 58.59%] [G loss: 1.009728]\n",
      "epoch:7 step:7123 [D loss: 0.622138, acc.: 67.19%] [G loss: 1.106052]\n",
      "epoch:7 step:7124 [D loss: 0.682763, acc.: 57.81%] [G loss: 0.973239]\n",
      "epoch:7 step:7125 [D loss: 0.803822, acc.: 46.09%] [G loss: 0.869946]\n",
      "epoch:7 step:7126 [D loss: 0.632667, acc.: 63.28%] [G loss: 0.851961]\n",
      "epoch:7 step:7127 [D loss: 0.653630, acc.: 57.81%] [G loss: 0.892703]\n",
      "epoch:7 step:7128 [D loss: 0.711321, acc.: 51.56%] [G loss: 0.848392]\n",
      "epoch:7 step:7129 [D loss: 0.620713, acc.: 67.19%] [G loss: 0.896014]\n",
      "epoch:7 step:7130 [D loss: 0.609140, acc.: 67.19%] [G loss: 0.881679]\n",
      "epoch:7 step:7131 [D loss: 0.669654, acc.: 58.59%] [G loss: 0.927062]\n",
      "epoch:7 step:7132 [D loss: 0.694733, acc.: 61.72%] [G loss: 0.932766]\n",
      "epoch:7 step:7133 [D loss: 0.555536, acc.: 75.00%] [G loss: 0.983732]\n",
      "epoch:7 step:7134 [D loss: 0.624126, acc.: 61.72%] [G loss: 0.907497]\n",
      "epoch:7 step:7135 [D loss: 0.641113, acc.: 64.06%] [G loss: 0.926445]\n",
      "epoch:7 step:7136 [D loss: 0.677369, acc.: 59.38%] [G loss: 0.870437]\n",
      "epoch:7 step:7137 [D loss: 0.643352, acc.: 61.72%] [G loss: 0.863040]\n",
      "epoch:7 step:7138 [D loss: 0.682535, acc.: 53.91%] [G loss: 0.948101]\n",
      "epoch:7 step:7139 [D loss: 0.648863, acc.: 60.94%] [G loss: 0.849689]\n",
      "epoch:7 step:7140 [D loss: 0.632015, acc.: 59.38%] [G loss: 0.858973]\n",
      "epoch:7 step:7141 [D loss: 0.594348, acc.: 67.19%] [G loss: 0.887817]\n",
      "epoch:7 step:7142 [D loss: 0.693425, acc.: 55.47%] [G loss: 0.960431]\n",
      "epoch:7 step:7143 [D loss: 0.690353, acc.: 54.69%] [G loss: 0.924199]\n",
      "epoch:7 step:7144 [D loss: 0.676358, acc.: 56.25%] [G loss: 0.935370]\n",
      "epoch:7 step:7145 [D loss: 0.656263, acc.: 58.59%] [G loss: 0.889257]\n",
      "epoch:7 step:7146 [D loss: 0.664274, acc.: 60.16%] [G loss: 0.889545]\n",
      "epoch:7 step:7147 [D loss: 0.670922, acc.: 56.25%] [G loss: 0.857166]\n",
      "epoch:7 step:7148 [D loss: 0.651565, acc.: 64.84%] [G loss: 0.908607]\n",
      "epoch:7 step:7149 [D loss: 0.672075, acc.: 63.28%] [G loss: 0.834069]\n",
      "epoch:7 step:7150 [D loss: 0.680762, acc.: 58.59%] [G loss: 0.892952]\n",
      "epoch:7 step:7151 [D loss: 0.611061, acc.: 71.09%] [G loss: 0.953227]\n",
      "epoch:7 step:7152 [D loss: 0.680293, acc.: 59.38%] [G loss: 0.884813]\n",
      "epoch:7 step:7153 [D loss: 0.736395, acc.: 52.34%] [G loss: 0.835266]\n",
      "epoch:7 step:7154 [D loss: 0.664434, acc.: 59.38%] [G loss: 0.895242]\n",
      "epoch:7 step:7155 [D loss: 0.679634, acc.: 60.16%] [G loss: 0.882883]\n",
      "epoch:7 step:7156 [D loss: 0.634536, acc.: 63.28%] [G loss: 0.926933]\n",
      "epoch:7 step:7157 [D loss: 0.612320, acc.: 68.75%] [G loss: 0.863776]\n",
      "epoch:7 step:7158 [D loss: 0.652730, acc.: 60.94%] [G loss: 0.918036]\n",
      "epoch:7 step:7159 [D loss: 0.671295, acc.: 59.38%] [G loss: 0.840735]\n",
      "epoch:7 step:7160 [D loss: 0.669247, acc.: 60.94%] [G loss: 0.887351]\n",
      "epoch:7 step:7161 [D loss: 0.666848, acc.: 59.38%] [G loss: 0.937403]\n",
      "epoch:7 step:7162 [D loss: 0.661129, acc.: 57.03%] [G loss: 0.886605]\n",
      "epoch:7 step:7163 [D loss: 0.673239, acc.: 61.72%] [G loss: 0.848713]\n",
      "epoch:7 step:7164 [D loss: 0.661609, acc.: 62.50%] [G loss: 0.873265]\n",
      "epoch:7 step:7165 [D loss: 0.701164, acc.: 56.25%] [G loss: 0.901564]\n",
      "epoch:7 step:7166 [D loss: 0.651879, acc.: 61.72%] [G loss: 0.942293]\n",
      "epoch:7 step:7167 [D loss: 0.665769, acc.: 61.72%] [G loss: 0.877775]\n",
      "epoch:7 step:7168 [D loss: 0.650773, acc.: 63.28%] [G loss: 0.872090]\n",
      "epoch:7 step:7169 [D loss: 0.656132, acc.: 58.59%] [G loss: 0.865433]\n",
      "epoch:7 step:7170 [D loss: 0.672779, acc.: 61.72%] [G loss: 0.856248]\n",
      "epoch:7 step:7171 [D loss: 0.679267, acc.: 54.69%] [G loss: 0.891008]\n",
      "epoch:7 step:7172 [D loss: 0.635433, acc.: 61.72%] [G loss: 0.861309]\n",
      "epoch:7 step:7173 [D loss: 0.681053, acc.: 54.69%] [G loss: 0.778977]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7174 [D loss: 0.727234, acc.: 47.66%] [G loss: 0.820693]\n",
      "epoch:7 step:7175 [D loss: 0.660525, acc.: 57.81%] [G loss: 0.868924]\n",
      "epoch:7 step:7176 [D loss: 0.678615, acc.: 55.47%] [G loss: 0.906724]\n",
      "epoch:7 step:7177 [D loss: 0.621571, acc.: 63.28%] [G loss: 0.891263]\n",
      "epoch:7 step:7178 [D loss: 0.646706, acc.: 65.62%] [G loss: 0.932051]\n",
      "epoch:7 step:7179 [D loss: 0.654489, acc.: 62.50%] [G loss: 0.887612]\n",
      "epoch:7 step:7180 [D loss: 0.681506, acc.: 55.47%] [G loss: 0.866348]\n",
      "epoch:7 step:7181 [D loss: 0.694010, acc.: 56.25%] [G loss: 0.875828]\n",
      "epoch:7 step:7182 [D loss: 0.655203, acc.: 63.28%] [G loss: 0.912301]\n",
      "epoch:7 step:7183 [D loss: 0.634327, acc.: 66.41%] [G loss: 0.947296]\n",
      "epoch:7 step:7184 [D loss: 0.753886, acc.: 46.09%] [G loss: 0.859128]\n",
      "epoch:7 step:7185 [D loss: 0.650368, acc.: 58.59%] [G loss: 0.864965]\n",
      "epoch:7 step:7186 [D loss: 0.656807, acc.: 58.59%] [G loss: 0.895395]\n",
      "epoch:7 step:7187 [D loss: 0.660329, acc.: 62.50%] [G loss: 0.868786]\n",
      "epoch:7 step:7188 [D loss: 0.621007, acc.: 66.41%] [G loss: 0.895893]\n",
      "epoch:7 step:7189 [D loss: 0.687785, acc.: 57.03%] [G loss: 0.905893]\n",
      "epoch:7 step:7190 [D loss: 0.590325, acc.: 75.00%] [G loss: 0.930338]\n",
      "epoch:7 step:7191 [D loss: 0.633664, acc.: 63.28%] [G loss: 0.933819]\n",
      "epoch:7 step:7192 [D loss: 0.650322, acc.: 64.84%] [G loss: 0.886782]\n",
      "epoch:7 step:7193 [D loss: 0.618376, acc.: 69.53%] [G loss: 0.926294]\n",
      "epoch:7 step:7194 [D loss: 0.619509, acc.: 60.94%] [G loss: 0.953560]\n",
      "epoch:7 step:7195 [D loss: 0.670192, acc.: 59.38%] [G loss: 0.963503]\n",
      "epoch:7 step:7196 [D loss: 0.628329, acc.: 64.06%] [G loss: 0.875491]\n",
      "epoch:7 step:7197 [D loss: 0.673908, acc.: 56.25%] [G loss: 0.899441]\n",
      "epoch:7 step:7198 [D loss: 0.655595, acc.: 63.28%] [G loss: 0.901828]\n",
      "epoch:7 step:7199 [D loss: 0.605553, acc.: 67.97%] [G loss: 0.914827]\n",
      "epoch:7 step:7200 [D loss: 0.599475, acc.: 66.41%] [G loss: 0.893310]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.634193\n",
      "FID: 14.032739\n",
      "0 = 12.158462686681732\n",
      "1 = 0.06532119182081045\n",
      "2 = 0.9415500164031982\n",
      "3 = 0.8967000246047974\n",
      "4 = 0.9864000082015991\n",
      "5 = 0.9850598573684692\n",
      "6 = 0.8967000246047974\n",
      "7 = 6.692630757826566\n",
      "8 = 0.08256646802147061\n",
      "9 = 0.7455000281333923\n",
      "10 = 0.7175999879837036\n",
      "11 = 0.7734000086784363\n",
      "12 = 0.7600084543228149\n",
      "13 = 0.7175999879837036\n",
      "14 = 7.634261131286621\n",
      "15 = 9.59023666381836\n",
      "16 = 0.10499627143144608\n",
      "17 = 7.634192943572998\n",
      "18 = 14.03273868560791\n",
      "epoch:7 step:7201 [D loss: 0.598253, acc.: 67.19%] [G loss: 0.970996]\n",
      "epoch:7 step:7202 [D loss: 0.648516, acc.: 64.06%] [G loss: 0.922896]\n",
      "epoch:7 step:7203 [D loss: 0.684051, acc.: 57.81%] [G loss: 0.937500]\n",
      "epoch:7 step:7204 [D loss: 0.703416, acc.: 53.91%] [G loss: 0.923812]\n",
      "epoch:7 step:7205 [D loss: 0.615972, acc.: 63.28%] [G loss: 0.923567]\n",
      "epoch:7 step:7206 [D loss: 0.593377, acc.: 69.53%] [G loss: 0.944461]\n",
      "epoch:7 step:7207 [D loss: 0.624392, acc.: 64.06%] [G loss: 1.044128]\n",
      "epoch:7 step:7208 [D loss: 0.672819, acc.: 62.50%] [G loss: 0.922994]\n",
      "epoch:7 step:7209 [D loss: 0.597750, acc.: 74.22%] [G loss: 1.003781]\n",
      "epoch:7 step:7210 [D loss: 0.638149, acc.: 63.28%] [G loss: 0.928754]\n",
      "epoch:7 step:7211 [D loss: 0.694718, acc.: 52.34%] [G loss: 0.932912]\n",
      "epoch:7 step:7212 [D loss: 0.659217, acc.: 60.94%] [G loss: 0.901756]\n",
      "epoch:7 step:7213 [D loss: 0.633094, acc.: 65.62%] [G loss: 0.891752]\n",
      "epoch:7 step:7214 [D loss: 0.679684, acc.: 56.25%] [G loss: 0.852844]\n",
      "epoch:7 step:7215 [D loss: 0.635693, acc.: 63.28%] [G loss: 0.911553]\n",
      "epoch:7 step:7216 [D loss: 0.679948, acc.: 58.59%] [G loss: 0.879019]\n",
      "epoch:7 step:7217 [D loss: 0.658632, acc.: 60.16%] [G loss: 1.005448]\n",
      "epoch:7 step:7218 [D loss: 0.628330, acc.: 59.38%] [G loss: 0.970648]\n",
      "epoch:7 step:7219 [D loss: 0.636296, acc.: 57.03%] [G loss: 0.874169]\n",
      "epoch:7 step:7220 [D loss: 0.615977, acc.: 71.09%] [G loss: 0.865550]\n",
      "epoch:7 step:7221 [D loss: 0.675541, acc.: 64.06%] [G loss: 0.915980]\n",
      "epoch:7 step:7222 [D loss: 0.659991, acc.: 56.25%] [G loss: 0.899169]\n",
      "epoch:7 step:7223 [D loss: 0.673835, acc.: 55.47%] [G loss: 0.893952]\n",
      "epoch:7 step:7224 [D loss: 0.627946, acc.: 61.72%] [G loss: 0.908019]\n",
      "epoch:7 step:7225 [D loss: 0.681145, acc.: 61.72%] [G loss: 0.950784]\n",
      "epoch:7 step:7226 [D loss: 0.711640, acc.: 54.69%] [G loss: 0.964897]\n",
      "epoch:7 step:7227 [D loss: 0.682219, acc.: 57.81%] [G loss: 0.925866]\n",
      "epoch:7 step:7228 [D loss: 0.676923, acc.: 60.16%] [G loss: 0.949742]\n",
      "epoch:7 step:7229 [D loss: 0.687877, acc.: 54.69%] [G loss: 0.883682]\n",
      "epoch:7 step:7230 [D loss: 0.672053, acc.: 55.47%] [G loss: 0.875763]\n",
      "epoch:7 step:7231 [D loss: 0.700107, acc.: 58.59%] [G loss: 0.863649]\n",
      "epoch:7 step:7232 [D loss: 0.657647, acc.: 63.28%] [G loss: 0.895066]\n",
      "epoch:7 step:7233 [D loss: 0.645994, acc.: 62.50%] [G loss: 0.940040]\n",
      "epoch:7 step:7234 [D loss: 0.659837, acc.: 60.94%] [G loss: 0.861994]\n",
      "epoch:7 step:7235 [D loss: 0.656911, acc.: 55.47%] [G loss: 0.909682]\n",
      "epoch:7 step:7236 [D loss: 0.664663, acc.: 60.16%] [G loss: 0.890132]\n",
      "epoch:7 step:7237 [D loss: 0.681198, acc.: 54.69%] [G loss: 0.850017]\n",
      "epoch:7 step:7238 [D loss: 0.635204, acc.: 64.84%] [G loss: 0.887229]\n",
      "epoch:7 step:7239 [D loss: 0.627213, acc.: 62.50%] [G loss: 0.922070]\n",
      "epoch:7 step:7240 [D loss: 0.622546, acc.: 67.19%] [G loss: 0.893235]\n",
      "epoch:7 step:7241 [D loss: 0.618669, acc.: 64.06%] [G loss: 0.851311]\n",
      "epoch:7 step:7242 [D loss: 0.702150, acc.: 54.69%] [G loss: 0.948653]\n",
      "epoch:7 step:7243 [D loss: 0.625694, acc.: 68.75%] [G loss: 0.912456]\n",
      "epoch:7 step:7244 [D loss: 0.661649, acc.: 60.16%] [G loss: 0.884872]\n",
      "epoch:7 step:7245 [D loss: 0.648597, acc.: 64.06%] [G loss: 0.928113]\n",
      "epoch:7 step:7246 [D loss: 0.654541, acc.: 59.38%] [G loss: 0.899982]\n",
      "epoch:7 step:7247 [D loss: 0.650314, acc.: 59.38%] [G loss: 0.876164]\n",
      "epoch:7 step:7248 [D loss: 0.650465, acc.: 60.94%] [G loss: 0.937815]\n",
      "epoch:7 step:7249 [D loss: 0.632890, acc.: 65.62%] [G loss: 0.941164]\n",
      "epoch:7 step:7250 [D loss: 0.635538, acc.: 62.50%] [G loss: 0.915122]\n",
      "epoch:7 step:7251 [D loss: 0.599420, acc.: 73.44%] [G loss: 0.946097]\n",
      "epoch:7 step:7252 [D loss: 0.653619, acc.: 61.72%] [G loss: 0.920890]\n",
      "epoch:7 step:7253 [D loss: 0.633422, acc.: 60.94%] [G loss: 0.933576]\n",
      "epoch:7 step:7254 [D loss: 0.661822, acc.: 57.03%] [G loss: 0.970152]\n",
      "epoch:7 step:7255 [D loss: 0.703185, acc.: 48.44%] [G loss: 0.889355]\n",
      "epoch:7 step:7256 [D loss: 0.644159, acc.: 65.62%] [G loss: 0.905145]\n",
      "epoch:7 step:7257 [D loss: 0.638677, acc.: 64.84%] [G loss: 0.910990]\n",
      "epoch:7 step:7258 [D loss: 0.658319, acc.: 63.28%] [G loss: 0.859317]\n",
      "epoch:7 step:7259 [D loss: 0.667880, acc.: 60.94%] [G loss: 0.895049]\n",
      "epoch:7 step:7260 [D loss: 0.605886, acc.: 71.88%] [G loss: 0.965220]\n",
      "epoch:7 step:7261 [D loss: 0.666407, acc.: 60.94%] [G loss: 0.919115]\n",
      "epoch:7 step:7262 [D loss: 0.691657, acc.: 50.00%] [G loss: 0.917451]\n",
      "epoch:7 step:7263 [D loss: 0.692393, acc.: 59.38%] [G loss: 0.893868]\n",
      "epoch:7 step:7264 [D loss: 0.667072, acc.: 60.94%] [G loss: 0.860106]\n",
      "epoch:7 step:7265 [D loss: 0.676057, acc.: 54.69%] [G loss: 0.896183]\n",
      "epoch:7 step:7266 [D loss: 0.614575, acc.: 69.53%] [G loss: 0.943050]\n",
      "epoch:7 step:7267 [D loss: 0.591567, acc.: 73.44%] [G loss: 0.919955]\n",
      "epoch:7 step:7268 [D loss: 0.624222, acc.: 65.62%] [G loss: 0.910733]\n",
      "epoch:7 step:7269 [D loss: 0.689142, acc.: 58.59%] [G loss: 0.924726]\n",
      "epoch:7 step:7270 [D loss: 0.657497, acc.: 57.81%] [G loss: 0.880302]\n",
      "epoch:7 step:7271 [D loss: 0.634800, acc.: 62.50%] [G loss: 0.952905]\n",
      "epoch:7 step:7272 [D loss: 0.688221, acc.: 57.03%] [G loss: 0.860125]\n",
      "epoch:7 step:7273 [D loss: 0.687108, acc.: 54.69%] [G loss: 0.832766]\n",
      "epoch:7 step:7274 [D loss: 0.693545, acc.: 57.81%] [G loss: 0.875275]\n",
      "epoch:7 step:7275 [D loss: 0.712827, acc.: 52.34%] [G loss: 0.864771]\n",
      "epoch:7 step:7276 [D loss: 0.656680, acc.: 58.59%] [G loss: 0.867125]\n",
      "epoch:7 step:7277 [D loss: 0.707163, acc.: 54.69%] [G loss: 0.841195]\n",
      "epoch:7 step:7278 [D loss: 0.641683, acc.: 62.50%] [G loss: 0.879752]\n",
      "epoch:7 step:7279 [D loss: 0.665749, acc.: 64.84%] [G loss: 0.919473]\n",
      "epoch:7 step:7280 [D loss: 0.649234, acc.: 60.16%] [G loss: 0.881239]\n",
      "epoch:7 step:7281 [D loss: 0.703730, acc.: 55.47%] [G loss: 0.879941]\n",
      "epoch:7 step:7282 [D loss: 0.684075, acc.: 58.59%] [G loss: 0.944226]\n",
      "epoch:7 step:7283 [D loss: 0.639894, acc.: 64.84%] [G loss: 0.870879]\n",
      "epoch:7 step:7284 [D loss: 0.647263, acc.: 60.94%] [G loss: 0.912635]\n",
      "epoch:7 step:7285 [D loss: 0.628977, acc.: 63.28%] [G loss: 0.868361]\n",
      "epoch:7 step:7286 [D loss: 0.705874, acc.: 57.81%] [G loss: 0.848044]\n",
      "epoch:7 step:7287 [D loss: 0.690458, acc.: 56.25%] [G loss: 0.868332]\n",
      "epoch:7 step:7288 [D loss: 0.647666, acc.: 60.94%] [G loss: 0.810781]\n",
      "epoch:7 step:7289 [D loss: 0.654111, acc.: 58.59%] [G loss: 0.891204]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7290 [D loss: 0.629184, acc.: 65.62%] [G loss: 0.953692]\n",
      "epoch:7 step:7291 [D loss: 0.603046, acc.: 66.41%] [G loss: 0.920966]\n",
      "epoch:7 step:7292 [D loss: 0.601454, acc.: 68.75%] [G loss: 0.998707]\n",
      "epoch:7 step:7293 [D loss: 0.689262, acc.: 58.59%] [G loss: 0.918307]\n",
      "epoch:7 step:7294 [D loss: 0.682946, acc.: 56.25%] [G loss: 0.905275]\n",
      "epoch:7 step:7295 [D loss: 0.657034, acc.: 62.50%] [G loss: 0.937271]\n",
      "epoch:7 step:7296 [D loss: 0.664092, acc.: 60.16%] [G loss: 0.960825]\n",
      "epoch:7 step:7297 [D loss: 0.658063, acc.: 55.47%] [G loss: 0.899962]\n",
      "epoch:7 step:7298 [D loss: 0.711336, acc.: 54.69%] [G loss: 0.843283]\n",
      "epoch:7 step:7299 [D loss: 0.694760, acc.: 54.69%] [G loss: 0.857519]\n",
      "epoch:7 step:7300 [D loss: 0.674038, acc.: 57.03%] [G loss: 0.889990]\n",
      "epoch:7 step:7301 [D loss: 0.651025, acc.: 60.16%] [G loss: 0.896057]\n",
      "epoch:7 step:7302 [D loss: 0.627160, acc.: 67.19%] [G loss: 0.911988]\n",
      "epoch:7 step:7303 [D loss: 0.661372, acc.: 57.81%] [G loss: 0.891174]\n",
      "epoch:7 step:7304 [D loss: 0.712337, acc.: 51.56%] [G loss: 0.888270]\n",
      "epoch:7 step:7305 [D loss: 0.649686, acc.: 56.25%] [G loss: 0.884759]\n",
      "epoch:7 step:7306 [D loss: 0.654605, acc.: 58.59%] [G loss: 0.946154]\n",
      "epoch:7 step:7307 [D loss: 0.639310, acc.: 57.81%] [G loss: 0.881838]\n",
      "epoch:7 step:7308 [D loss: 0.683981, acc.: 59.38%] [G loss: 0.841761]\n",
      "epoch:7 step:7309 [D loss: 0.650615, acc.: 60.16%] [G loss: 0.854337]\n",
      "epoch:7 step:7310 [D loss: 0.652048, acc.: 64.06%] [G loss: 0.895943]\n",
      "epoch:7 step:7311 [D loss: 0.695126, acc.: 53.12%] [G loss: 0.876126]\n",
      "epoch:7 step:7312 [D loss: 0.645544, acc.: 60.94%] [G loss: 0.937756]\n",
      "epoch:7 step:7313 [D loss: 0.632611, acc.: 71.09%] [G loss: 0.929353]\n",
      "epoch:7 step:7314 [D loss: 0.636841, acc.: 64.84%] [G loss: 0.939519]\n",
      "epoch:7 step:7315 [D loss: 0.626166, acc.: 63.28%] [G loss: 1.022338]\n",
      "epoch:7 step:7316 [D loss: 0.721938, acc.: 50.78%] [G loss: 0.949354]\n",
      "epoch:7 step:7317 [D loss: 0.705014, acc.: 56.25%] [G loss: 0.906069]\n",
      "epoch:7 step:7318 [D loss: 0.659997, acc.: 58.59%] [G loss: 0.854327]\n",
      "epoch:7 step:7319 [D loss: 0.671452, acc.: 53.91%] [G loss: 0.941442]\n",
      "epoch:7 step:7320 [D loss: 0.684830, acc.: 63.28%] [G loss: 0.950595]\n",
      "epoch:7 step:7321 [D loss: 0.644595, acc.: 58.59%] [G loss: 0.850814]\n",
      "epoch:7 step:7322 [D loss: 0.658896, acc.: 63.28%] [G loss: 0.840236]\n",
      "epoch:7 step:7323 [D loss: 0.674618, acc.: 55.47%] [G loss: 0.915155]\n",
      "epoch:7 step:7324 [D loss: 0.719191, acc.: 51.56%] [G loss: 0.835642]\n",
      "epoch:7 step:7325 [D loss: 0.692502, acc.: 49.22%] [G loss: 0.843619]\n",
      "epoch:7 step:7326 [D loss: 0.625689, acc.: 64.84%] [G loss: 0.829068]\n",
      "epoch:7 step:7327 [D loss: 0.694927, acc.: 53.91%] [G loss: 0.892433]\n",
      "epoch:7 step:7328 [D loss: 0.654710, acc.: 65.62%] [G loss: 0.911667]\n",
      "epoch:7 step:7329 [D loss: 0.623653, acc.: 60.16%] [G loss: 0.976078]\n",
      "epoch:7 step:7330 [D loss: 0.613464, acc.: 66.41%] [G loss: 0.929357]\n",
      "epoch:7 step:7331 [D loss: 0.680631, acc.: 55.47%] [G loss: 0.961471]\n",
      "epoch:7 step:7332 [D loss: 0.608257, acc.: 67.19%] [G loss: 0.948489]\n",
      "epoch:7 step:7333 [D loss: 0.691237, acc.: 57.03%] [G loss: 0.870100]\n",
      "epoch:7 step:7334 [D loss: 0.668368, acc.: 60.16%] [G loss: 0.964398]\n",
      "epoch:7 step:7335 [D loss: 0.674588, acc.: 53.12%] [G loss: 0.938681]\n",
      "epoch:7 step:7336 [D loss: 0.654487, acc.: 62.50%] [G loss: 0.887753]\n",
      "epoch:7 step:7337 [D loss: 0.671311, acc.: 58.59%] [G loss: 0.938587]\n",
      "epoch:7 step:7338 [D loss: 0.649726, acc.: 63.28%] [G loss: 0.883402]\n",
      "epoch:7 step:7339 [D loss: 0.649596, acc.: 60.94%] [G loss: 0.927625]\n",
      "epoch:7 step:7340 [D loss: 0.589501, acc.: 70.31%] [G loss: 0.989596]\n",
      "epoch:7 step:7341 [D loss: 0.611699, acc.: 68.75%] [G loss: 1.050990]\n",
      "epoch:7 step:7342 [D loss: 0.743799, acc.: 53.91%] [G loss: 0.920384]\n",
      "epoch:7 step:7343 [D loss: 0.764060, acc.: 49.22%] [G loss: 0.873055]\n",
      "epoch:7 step:7344 [D loss: 0.686804, acc.: 57.81%] [G loss: 0.914452]\n",
      "epoch:7 step:7345 [D loss: 0.631246, acc.: 62.50%] [G loss: 0.868365]\n",
      "epoch:7 step:7346 [D loss: 0.679109, acc.: 60.94%] [G loss: 0.895793]\n",
      "epoch:7 step:7347 [D loss: 0.687423, acc.: 57.03%] [G loss: 0.935872]\n",
      "epoch:7 step:7348 [D loss: 0.630913, acc.: 64.84%] [G loss: 0.883996]\n",
      "epoch:7 step:7349 [D loss: 0.634923, acc.: 64.06%] [G loss: 0.876822]\n",
      "epoch:7 step:7350 [D loss: 0.686425, acc.: 54.69%] [G loss: 0.864588]\n",
      "epoch:7 step:7351 [D loss: 0.587118, acc.: 73.44%] [G loss: 0.909615]\n",
      "epoch:7 step:7352 [D loss: 0.632678, acc.: 61.72%] [G loss: 0.946890]\n",
      "epoch:7 step:7353 [D loss: 0.687061, acc.: 54.69%] [G loss: 0.921432]\n",
      "epoch:7 step:7354 [D loss: 0.663562, acc.: 56.25%] [G loss: 0.929005]\n",
      "epoch:7 step:7355 [D loss: 0.636270, acc.: 62.50%] [G loss: 0.960525]\n",
      "epoch:7 step:7356 [D loss: 0.715901, acc.: 50.00%] [G loss: 0.941970]\n",
      "epoch:7 step:7357 [D loss: 0.682426, acc.: 50.78%] [G loss: 0.851331]\n",
      "epoch:7 step:7358 [D loss: 0.636256, acc.: 66.41%] [G loss: 0.896276]\n",
      "epoch:7 step:7359 [D loss: 0.713649, acc.: 50.78%] [G loss: 0.973094]\n",
      "epoch:7 step:7360 [D loss: 0.587668, acc.: 71.88%] [G loss: 1.031182]\n",
      "epoch:7 step:7361 [D loss: 0.607255, acc.: 68.75%] [G loss: 0.998784]\n",
      "epoch:7 step:7362 [D loss: 0.621976, acc.: 67.97%] [G loss: 0.972816]\n",
      "epoch:7 step:7363 [D loss: 0.658997, acc.: 60.94%] [G loss: 0.968514]\n",
      "epoch:7 step:7364 [D loss: 0.648349, acc.: 62.50%] [G loss: 0.909994]\n",
      "epoch:7 step:7365 [D loss: 0.656307, acc.: 55.47%] [G loss: 0.878268]\n",
      "epoch:7 step:7366 [D loss: 0.592286, acc.: 69.53%] [G loss: 0.903449]\n",
      "epoch:7 step:7367 [D loss: 0.679818, acc.: 58.59%] [G loss: 0.912331]\n",
      "epoch:7 step:7368 [D loss: 0.685228, acc.: 57.81%] [G loss: 0.887753]\n",
      "epoch:7 step:7369 [D loss: 0.667295, acc.: 57.81%] [G loss: 0.890802]\n",
      "epoch:7 step:7370 [D loss: 0.672151, acc.: 56.25%] [G loss: 0.840483]\n",
      "epoch:7 step:7371 [D loss: 0.688788, acc.: 54.69%] [G loss: 0.861824]\n",
      "epoch:7 step:7372 [D loss: 0.657871, acc.: 58.59%] [G loss: 0.842130]\n",
      "epoch:7 step:7373 [D loss: 0.664267, acc.: 57.03%] [G loss: 0.892478]\n",
      "epoch:7 step:7374 [D loss: 0.642769, acc.: 67.97%] [G loss: 0.943144]\n",
      "epoch:7 step:7375 [D loss: 0.666355, acc.: 64.84%] [G loss: 0.886727]\n",
      "epoch:7 step:7376 [D loss: 0.677777, acc.: 60.94%] [G loss: 0.865735]\n",
      "epoch:7 step:7377 [D loss: 0.672856, acc.: 55.47%] [G loss: 0.824957]\n",
      "epoch:7 step:7378 [D loss: 0.629491, acc.: 67.97%] [G loss: 0.907694]\n",
      "epoch:7 step:7379 [D loss: 0.718712, acc.: 52.34%] [G loss: 0.929658]\n",
      "epoch:7 step:7380 [D loss: 0.644499, acc.: 64.84%] [G loss: 0.929039]\n",
      "epoch:7 step:7381 [D loss: 0.643620, acc.: 60.16%] [G loss: 0.838997]\n",
      "epoch:7 step:7382 [D loss: 0.654143, acc.: 56.25%] [G loss: 0.825889]\n",
      "epoch:7 step:7383 [D loss: 0.676354, acc.: 58.59%] [G loss: 0.844539]\n",
      "epoch:7 step:7384 [D loss: 0.621699, acc.: 61.72%] [G loss: 0.867478]\n",
      "epoch:7 step:7385 [D loss: 0.643640, acc.: 63.28%] [G loss: 0.834525]\n",
      "epoch:7 step:7386 [D loss: 0.683462, acc.: 57.03%] [G loss: 0.871738]\n",
      "epoch:7 step:7387 [D loss: 0.686847, acc.: 55.47%] [G loss: 0.884038]\n",
      "epoch:7 step:7388 [D loss: 0.654646, acc.: 64.84%] [G loss: 0.886434]\n",
      "epoch:7 step:7389 [D loss: 0.665678, acc.: 63.28%] [G loss: 0.862579]\n",
      "epoch:7 step:7390 [D loss: 0.643317, acc.: 57.81%] [G loss: 0.846658]\n",
      "epoch:7 step:7391 [D loss: 0.680543, acc.: 57.81%] [G loss: 0.874675]\n",
      "epoch:7 step:7392 [D loss: 0.653235, acc.: 60.94%] [G loss: 0.928837]\n",
      "epoch:7 step:7393 [D loss: 0.645662, acc.: 62.50%] [G loss: 0.851893]\n",
      "epoch:7 step:7394 [D loss: 0.646882, acc.: 57.03%] [G loss: 0.918830]\n",
      "epoch:7 step:7395 [D loss: 0.675042, acc.: 57.03%] [G loss: 0.928320]\n",
      "epoch:7 step:7396 [D loss: 0.631934, acc.: 62.50%] [G loss: 0.868838]\n",
      "epoch:7 step:7397 [D loss: 0.638817, acc.: 64.06%] [G loss: 0.864343]\n",
      "epoch:7 step:7398 [D loss: 0.676172, acc.: 58.59%] [G loss: 0.863690]\n",
      "epoch:7 step:7399 [D loss: 0.668565, acc.: 56.25%] [G loss: 0.898430]\n",
      "epoch:7 step:7400 [D loss: 0.658076, acc.: 64.06%] [G loss: 0.862025]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.734196\n",
      "FID: 12.119522\n",
      "0 = 12.05464608161453\n",
      "1 = 0.06298354966482397\n",
      "2 = 0.9433500170707703\n",
      "3 = 0.8991000056266785\n",
      "4 = 0.9876000285148621\n",
      "5 = 0.986396074295044\n",
      "6 = 0.8991000056266785\n",
      "7 = 6.460517273622779\n",
      "8 = 0.07339421071808833\n",
      "9 = 0.7500500082969666\n",
      "10 = 0.7250000238418579\n",
      "11 = 0.7750999927520752\n",
      "12 = 0.763238251209259\n",
      "13 = 0.7250000238418579\n",
      "14 = 7.734269142150879\n",
      "15 = 9.596006393432617\n",
      "16 = 0.10613945871591568\n",
      "17 = 7.734196186065674\n",
      "18 = 12.119522094726562\n",
      "epoch:7 step:7401 [D loss: 0.597199, acc.: 69.53%] [G loss: 0.870315]\n",
      "epoch:7 step:7402 [D loss: 0.653720, acc.: 64.84%] [G loss: 0.920281]\n",
      "epoch:7 step:7403 [D loss: 0.648291, acc.: 61.72%] [G loss: 0.949977]\n",
      "epoch:7 step:7404 [D loss: 0.649447, acc.: 58.59%] [G loss: 0.871223]\n",
      "epoch:7 step:7405 [D loss: 0.669588, acc.: 58.59%] [G loss: 0.907691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7406 [D loss: 0.698190, acc.: 51.56%] [G loss: 0.961978]\n",
      "epoch:7 step:7407 [D loss: 0.680988, acc.: 57.81%] [G loss: 0.857687]\n",
      "epoch:7 step:7408 [D loss: 0.637851, acc.: 64.06%] [G loss: 0.889222]\n",
      "epoch:7 step:7409 [D loss: 0.646249, acc.: 62.50%] [G loss: 0.884221]\n",
      "epoch:7 step:7410 [D loss: 0.680031, acc.: 60.16%] [G loss: 0.833598]\n",
      "epoch:7 step:7411 [D loss: 0.647329, acc.: 60.16%] [G loss: 0.918956]\n",
      "epoch:7 step:7412 [D loss: 0.652417, acc.: 59.38%] [G loss: 0.940743]\n",
      "epoch:7 step:7413 [D loss: 0.624364, acc.: 65.62%] [G loss: 0.878814]\n",
      "epoch:7 step:7414 [D loss: 0.629435, acc.: 64.06%] [G loss: 0.890125]\n",
      "epoch:7 step:7415 [D loss: 0.688954, acc.: 51.56%] [G loss: 0.929297]\n",
      "epoch:7 step:7416 [D loss: 0.650747, acc.: 63.28%] [G loss: 0.942736]\n",
      "epoch:7 step:7417 [D loss: 0.752142, acc.: 50.78%] [G loss: 0.926834]\n",
      "epoch:7 step:7418 [D loss: 0.677207, acc.: 55.47%] [G loss: 0.964098]\n",
      "epoch:7 step:7419 [D loss: 0.639066, acc.: 62.50%] [G loss: 0.941127]\n",
      "epoch:7 step:7420 [D loss: 0.703223, acc.: 53.91%] [G loss: 0.942051]\n",
      "epoch:7 step:7421 [D loss: 0.685507, acc.: 55.47%] [G loss: 0.887994]\n",
      "epoch:7 step:7422 [D loss: 0.665275, acc.: 57.03%] [G loss: 0.888189]\n",
      "epoch:7 step:7423 [D loss: 0.667778, acc.: 60.94%] [G loss: 0.889122]\n",
      "epoch:7 step:7424 [D loss: 0.678201, acc.: 60.16%] [G loss: 0.894379]\n",
      "epoch:7 step:7425 [D loss: 0.658689, acc.: 64.06%] [G loss: 0.865509]\n",
      "epoch:7 step:7426 [D loss: 0.708976, acc.: 51.56%] [G loss: 0.840787]\n",
      "epoch:7 step:7427 [D loss: 0.675020, acc.: 52.34%] [G loss: 0.915504]\n",
      "epoch:7 step:7428 [D loss: 0.645675, acc.: 66.41%] [G loss: 0.852606]\n",
      "epoch:7 step:7429 [D loss: 0.671326, acc.: 60.94%] [G loss: 0.878634]\n",
      "epoch:7 step:7430 [D loss: 0.612823, acc.: 70.31%] [G loss: 0.867145]\n",
      "epoch:7 step:7431 [D loss: 0.627807, acc.: 67.19%] [G loss: 0.916452]\n",
      "epoch:7 step:7432 [D loss: 0.674804, acc.: 56.25%] [G loss: 0.939495]\n",
      "epoch:7 step:7433 [D loss: 0.662212, acc.: 57.03%] [G loss: 0.923434]\n",
      "epoch:7 step:7434 [D loss: 0.627590, acc.: 68.75%] [G loss: 0.870444]\n",
      "epoch:7 step:7435 [D loss: 0.701595, acc.: 53.12%] [G loss: 0.886930]\n",
      "epoch:7 step:7436 [D loss: 0.669329, acc.: 54.69%] [G loss: 0.940815]\n",
      "epoch:7 step:7437 [D loss: 0.688690, acc.: 51.56%] [G loss: 0.855636]\n",
      "epoch:7 step:7438 [D loss: 0.684157, acc.: 56.25%] [G loss: 0.900883]\n",
      "epoch:7 step:7439 [D loss: 0.670067, acc.: 57.81%] [G loss: 0.871003]\n",
      "epoch:7 step:7440 [D loss: 0.652785, acc.: 66.41%] [G loss: 0.905593]\n",
      "epoch:7 step:7441 [D loss: 0.643624, acc.: 65.62%] [G loss: 0.888831]\n",
      "epoch:7 step:7442 [D loss: 0.647207, acc.: 64.06%] [G loss: 0.912559]\n",
      "epoch:7 step:7443 [D loss: 0.622275, acc.: 69.53%] [G loss: 0.860420]\n",
      "epoch:7 step:7444 [D loss: 0.620203, acc.: 67.19%] [G loss: 0.949210]\n",
      "epoch:7 step:7445 [D loss: 0.587444, acc.: 70.31%] [G loss: 0.928010]\n",
      "epoch:7 step:7446 [D loss: 0.676463, acc.: 57.81%] [G loss: 0.936728]\n",
      "epoch:7 step:7447 [D loss: 0.658071, acc.: 61.72%] [G loss: 0.894696]\n",
      "epoch:7 step:7448 [D loss: 0.622088, acc.: 67.97%] [G loss: 0.879754]\n",
      "epoch:7 step:7449 [D loss: 0.585043, acc.: 70.31%] [G loss: 0.947330]\n",
      "epoch:7 step:7450 [D loss: 0.667848, acc.: 59.38%] [G loss: 0.899094]\n",
      "epoch:7 step:7451 [D loss: 0.765554, acc.: 48.44%] [G loss: 0.901873]\n",
      "epoch:7 step:7452 [D loss: 0.625253, acc.: 64.06%] [G loss: 0.961586]\n",
      "epoch:7 step:7453 [D loss: 0.627649, acc.: 67.97%] [G loss: 0.945152]\n",
      "epoch:7 step:7454 [D loss: 0.641828, acc.: 58.59%] [G loss: 1.006114]\n",
      "epoch:7 step:7455 [D loss: 0.633206, acc.: 64.84%] [G loss: 0.931538]\n",
      "epoch:7 step:7456 [D loss: 0.610894, acc.: 69.53%] [G loss: 0.986349]\n",
      "epoch:7 step:7457 [D loss: 0.640992, acc.: 64.84%] [G loss: 0.905676]\n",
      "epoch:7 step:7458 [D loss: 0.643278, acc.: 60.94%] [G loss: 0.946299]\n",
      "epoch:7 step:7459 [D loss: 0.625532, acc.: 70.31%] [G loss: 0.953498]\n",
      "epoch:7 step:7460 [D loss: 0.661080, acc.: 56.25%] [G loss: 0.843118]\n",
      "epoch:7 step:7461 [D loss: 0.661629, acc.: 62.50%] [G loss: 0.883460]\n",
      "epoch:7 step:7462 [D loss: 0.660282, acc.: 62.50%] [G loss: 0.915843]\n",
      "epoch:7 step:7463 [D loss: 0.664757, acc.: 58.59%] [G loss: 0.872054]\n",
      "epoch:7 step:7464 [D loss: 0.624982, acc.: 64.06%] [G loss: 0.960282]\n",
      "epoch:7 step:7465 [D loss: 0.713347, acc.: 57.81%] [G loss: 0.957543]\n",
      "epoch:7 step:7466 [D loss: 0.669191, acc.: 60.94%] [G loss: 0.924634]\n",
      "epoch:7 step:7467 [D loss: 0.623854, acc.: 65.62%] [G loss: 0.933093]\n",
      "epoch:7 step:7468 [D loss: 0.660473, acc.: 60.16%] [G loss: 0.940485]\n",
      "epoch:7 step:7469 [D loss: 0.639071, acc.: 64.84%] [G loss: 0.898993]\n",
      "epoch:7 step:7470 [D loss: 0.679183, acc.: 58.59%] [G loss: 0.948583]\n",
      "epoch:7 step:7471 [D loss: 0.658554, acc.: 62.50%] [G loss: 0.909071]\n",
      "epoch:7 step:7472 [D loss: 0.682350, acc.: 51.56%] [G loss: 0.907072]\n",
      "epoch:7 step:7473 [D loss: 0.672933, acc.: 57.03%] [G loss: 0.945726]\n",
      "epoch:7 step:7474 [D loss: 0.678558, acc.: 59.38%] [G loss: 0.911331]\n",
      "epoch:7 step:7475 [D loss: 0.678300, acc.: 55.47%] [G loss: 0.932855]\n",
      "epoch:7 step:7476 [D loss: 0.650346, acc.: 59.38%] [G loss: 0.933298]\n",
      "epoch:7 step:7477 [D loss: 0.627984, acc.: 63.28%] [G loss: 0.984914]\n",
      "epoch:7 step:7478 [D loss: 0.585568, acc.: 74.22%] [G loss: 0.949888]\n",
      "epoch:7 step:7479 [D loss: 0.766786, acc.: 46.88%] [G loss: 0.881307]\n",
      "epoch:7 step:7480 [D loss: 0.614315, acc.: 67.19%] [G loss: 0.925925]\n",
      "epoch:7 step:7481 [D loss: 0.673386, acc.: 60.16%] [G loss: 0.927975]\n",
      "epoch:7 step:7482 [D loss: 0.642047, acc.: 62.50%] [G loss: 0.893746]\n",
      "epoch:7 step:7483 [D loss: 0.584637, acc.: 72.66%] [G loss: 0.936291]\n",
      "epoch:7 step:7484 [D loss: 0.602005, acc.: 71.09%] [G loss: 0.938568]\n",
      "epoch:7 step:7485 [D loss: 0.569966, acc.: 73.44%] [G loss: 1.012022]\n",
      "epoch:7 step:7486 [D loss: 0.606908, acc.: 67.97%] [G loss: 0.990968]\n",
      "epoch:7 step:7487 [D loss: 0.785128, acc.: 53.91%] [G loss: 0.985663]\n",
      "epoch:7 step:7488 [D loss: 0.576525, acc.: 70.31%] [G loss: 1.098228]\n",
      "epoch:7 step:7489 [D loss: 0.621273, acc.: 67.19%] [G loss: 1.048384]\n",
      "epoch:7 step:7490 [D loss: 0.749953, acc.: 50.78%] [G loss: 0.933348]\n",
      "epoch:7 step:7491 [D loss: 0.758314, acc.: 52.34%] [G loss: 0.800258]\n",
      "epoch:7 step:7492 [D loss: 0.670641, acc.: 64.06%] [G loss: 0.845443]\n",
      "epoch:7 step:7493 [D loss: 0.648721, acc.: 65.62%] [G loss: 0.872091]\n",
      "epoch:7 step:7494 [D loss: 0.590937, acc.: 72.66%] [G loss: 0.973152]\n",
      "epoch:7 step:7495 [D loss: 0.530652, acc.: 78.91%] [G loss: 0.973898]\n",
      "epoch:7 step:7496 [D loss: 0.560508, acc.: 75.78%] [G loss: 1.001776]\n",
      "epoch:8 step:7497 [D loss: 0.707928, acc.: 60.16%] [G loss: 1.061709]\n",
      "epoch:8 step:7498 [D loss: 0.702650, acc.: 57.81%] [G loss: 1.048580]\n",
      "epoch:8 step:7499 [D loss: 0.734840, acc.: 56.25%] [G loss: 0.951946]\n",
      "epoch:8 step:7500 [D loss: 0.679355, acc.: 57.81%] [G loss: 0.989508]\n",
      "epoch:8 step:7501 [D loss: 0.671496, acc.: 60.94%] [G loss: 0.910971]\n",
      "epoch:8 step:7502 [D loss: 0.693729, acc.: 53.12%] [G loss: 0.928568]\n",
      "epoch:8 step:7503 [D loss: 0.657031, acc.: 64.06%] [G loss: 0.997298]\n",
      "epoch:8 step:7504 [D loss: 0.710859, acc.: 54.69%] [G loss: 0.868959]\n",
      "epoch:8 step:7505 [D loss: 0.620067, acc.: 64.06%] [G loss: 0.910053]\n",
      "epoch:8 step:7506 [D loss: 0.639801, acc.: 61.72%] [G loss: 0.943623]\n",
      "epoch:8 step:7507 [D loss: 0.652638, acc.: 64.84%] [G loss: 0.938904]\n",
      "epoch:8 step:7508 [D loss: 0.642406, acc.: 58.59%] [G loss: 0.911427]\n",
      "epoch:8 step:7509 [D loss: 0.637204, acc.: 63.28%] [G loss: 0.946230]\n",
      "epoch:8 step:7510 [D loss: 0.603882, acc.: 67.19%] [G loss: 0.856943]\n",
      "epoch:8 step:7511 [D loss: 0.657620, acc.: 55.47%] [G loss: 0.973103]\n",
      "epoch:8 step:7512 [D loss: 0.618152, acc.: 70.31%] [G loss: 0.957419]\n",
      "epoch:8 step:7513 [D loss: 0.662560, acc.: 55.47%] [G loss: 0.951848]\n",
      "epoch:8 step:7514 [D loss: 0.647458, acc.: 57.03%] [G loss: 0.943913]\n",
      "epoch:8 step:7515 [D loss: 0.673546, acc.: 59.38%] [G loss: 0.922360]\n",
      "epoch:8 step:7516 [D loss: 0.690336, acc.: 52.34%] [G loss: 0.938470]\n",
      "epoch:8 step:7517 [D loss: 0.628894, acc.: 62.50%] [G loss: 0.983953]\n",
      "epoch:8 step:7518 [D loss: 0.631144, acc.: 66.41%] [G loss: 1.038881]\n",
      "epoch:8 step:7519 [D loss: 0.696183, acc.: 59.38%] [G loss: 0.972797]\n",
      "epoch:8 step:7520 [D loss: 0.675675, acc.: 58.59%] [G loss: 0.919437]\n",
      "epoch:8 step:7521 [D loss: 0.675119, acc.: 60.94%] [G loss: 0.898410]\n",
      "epoch:8 step:7522 [D loss: 0.671682, acc.: 58.59%] [G loss: 0.888440]\n",
      "epoch:8 step:7523 [D loss: 0.672966, acc.: 59.38%] [G loss: 0.849878]\n",
      "epoch:8 step:7524 [D loss: 0.658581, acc.: 60.94%] [G loss: 0.918319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7525 [D loss: 0.633404, acc.: 69.53%] [G loss: 0.895506]\n",
      "epoch:8 step:7526 [D loss: 0.634562, acc.: 64.06%] [G loss: 0.923213]\n",
      "epoch:8 step:7527 [D loss: 0.646044, acc.: 57.81%] [G loss: 0.944621]\n",
      "epoch:8 step:7528 [D loss: 0.661166, acc.: 59.38%] [G loss: 0.894877]\n",
      "epoch:8 step:7529 [D loss: 0.635718, acc.: 63.28%] [G loss: 0.844024]\n",
      "epoch:8 step:7530 [D loss: 0.670545, acc.: 54.69%] [G loss: 0.884849]\n",
      "epoch:8 step:7531 [D loss: 0.657645, acc.: 58.59%] [G loss: 0.913666]\n",
      "epoch:8 step:7532 [D loss: 0.615655, acc.: 62.50%] [G loss: 0.908314]\n",
      "epoch:8 step:7533 [D loss: 0.703819, acc.: 54.69%] [G loss: 0.869340]\n",
      "epoch:8 step:7534 [D loss: 0.734394, acc.: 57.03%] [G loss: 0.883340]\n",
      "epoch:8 step:7535 [D loss: 0.661679, acc.: 63.28%] [G loss: 0.942473]\n",
      "epoch:8 step:7536 [D loss: 0.614348, acc.: 64.84%] [G loss: 0.893651]\n",
      "epoch:8 step:7537 [D loss: 0.652470, acc.: 62.50%] [G loss: 0.923872]\n",
      "epoch:8 step:7538 [D loss: 0.648938, acc.: 60.94%] [G loss: 0.885344]\n",
      "epoch:8 step:7539 [D loss: 0.652708, acc.: 61.72%] [G loss: 0.912704]\n",
      "epoch:8 step:7540 [D loss: 0.712463, acc.: 53.91%] [G loss: 0.917427]\n",
      "epoch:8 step:7541 [D loss: 0.698584, acc.: 54.69%] [G loss: 0.852249]\n",
      "epoch:8 step:7542 [D loss: 0.651698, acc.: 65.62%] [G loss: 0.887820]\n",
      "epoch:8 step:7543 [D loss: 0.619725, acc.: 71.09%] [G loss: 0.903522]\n",
      "epoch:8 step:7544 [D loss: 0.667437, acc.: 60.16%] [G loss: 0.952258]\n",
      "epoch:8 step:7545 [D loss: 0.628774, acc.: 70.31%] [G loss: 0.949378]\n",
      "epoch:8 step:7546 [D loss: 0.653702, acc.: 64.84%] [G loss: 0.874440]\n",
      "epoch:8 step:7547 [D loss: 0.711464, acc.: 51.56%] [G loss: 0.802361]\n",
      "epoch:8 step:7548 [D loss: 0.676007, acc.: 55.47%] [G loss: 0.878458]\n",
      "epoch:8 step:7549 [D loss: 0.652444, acc.: 65.62%] [G loss: 0.912228]\n",
      "epoch:8 step:7550 [D loss: 0.615444, acc.: 71.09%] [G loss: 0.923461]\n",
      "epoch:8 step:7551 [D loss: 0.641234, acc.: 64.06%] [G loss: 0.958072]\n",
      "epoch:8 step:7552 [D loss: 0.693283, acc.: 60.16%] [G loss: 0.986381]\n",
      "epoch:8 step:7553 [D loss: 0.666393, acc.: 59.38%] [G loss: 0.950886]\n",
      "epoch:8 step:7554 [D loss: 0.669517, acc.: 60.16%] [G loss: 0.914165]\n",
      "epoch:8 step:7555 [D loss: 0.679503, acc.: 61.72%] [G loss: 0.868396]\n",
      "epoch:8 step:7556 [D loss: 0.702169, acc.: 54.69%] [G loss: 0.853071]\n",
      "epoch:8 step:7557 [D loss: 0.684991, acc.: 57.03%] [G loss: 0.900970]\n",
      "epoch:8 step:7558 [D loss: 0.653637, acc.: 62.50%] [G loss: 0.905872]\n",
      "epoch:8 step:7559 [D loss: 0.645228, acc.: 61.72%] [G loss: 0.906468]\n",
      "epoch:8 step:7560 [D loss: 0.670973, acc.: 57.81%] [G loss: 0.882044]\n",
      "epoch:8 step:7561 [D loss: 0.705663, acc.: 51.56%] [G loss: 0.869856]\n",
      "epoch:8 step:7562 [D loss: 0.632852, acc.: 61.72%] [G loss: 0.834776]\n",
      "epoch:8 step:7563 [D loss: 0.642096, acc.: 64.84%] [G loss: 0.882391]\n",
      "epoch:8 step:7564 [D loss: 0.636950, acc.: 64.84%] [G loss: 0.909810]\n",
      "epoch:8 step:7565 [D loss: 0.613746, acc.: 64.06%] [G loss: 0.903405]\n",
      "epoch:8 step:7566 [D loss: 0.648139, acc.: 64.06%] [G loss: 0.915323]\n",
      "epoch:8 step:7567 [D loss: 0.711726, acc.: 52.34%] [G loss: 0.831012]\n",
      "epoch:8 step:7568 [D loss: 0.655439, acc.: 63.28%] [G loss: 0.827197]\n",
      "epoch:8 step:7569 [D loss: 0.676552, acc.: 56.25%] [G loss: 0.882951]\n",
      "epoch:8 step:7570 [D loss: 0.609058, acc.: 73.44%] [G loss: 0.906457]\n",
      "epoch:8 step:7571 [D loss: 0.684636, acc.: 57.81%] [G loss: 0.888538]\n",
      "epoch:8 step:7572 [D loss: 0.650362, acc.: 61.72%] [G loss: 0.959831]\n",
      "epoch:8 step:7573 [D loss: 0.620079, acc.: 58.59%] [G loss: 0.936402]\n",
      "epoch:8 step:7574 [D loss: 0.709375, acc.: 53.12%] [G loss: 0.967010]\n",
      "epoch:8 step:7575 [D loss: 0.661369, acc.: 64.06%] [G loss: 0.881042]\n",
      "epoch:8 step:7576 [D loss: 0.715298, acc.: 53.91%] [G loss: 0.872976]\n",
      "epoch:8 step:7577 [D loss: 0.688501, acc.: 53.91%] [G loss: 0.878746]\n",
      "epoch:8 step:7578 [D loss: 0.646238, acc.: 56.25%] [G loss: 0.854827]\n",
      "epoch:8 step:7579 [D loss: 0.644557, acc.: 59.38%] [G loss: 0.948408]\n",
      "epoch:8 step:7580 [D loss: 0.630223, acc.: 67.97%] [G loss: 0.933368]\n",
      "epoch:8 step:7581 [D loss: 0.688152, acc.: 55.47%] [G loss: 0.947350]\n",
      "epoch:8 step:7582 [D loss: 0.655339, acc.: 60.16%] [G loss: 0.967250]\n",
      "epoch:8 step:7583 [D loss: 0.656738, acc.: 60.94%] [G loss: 0.886536]\n",
      "epoch:8 step:7584 [D loss: 0.660404, acc.: 62.50%] [G loss: 0.865443]\n",
      "epoch:8 step:7585 [D loss: 0.646817, acc.: 60.16%] [G loss: 0.866680]\n",
      "epoch:8 step:7586 [D loss: 0.653287, acc.: 60.16%] [G loss: 0.838237]\n",
      "epoch:8 step:7587 [D loss: 0.663855, acc.: 61.72%] [G loss: 0.880084]\n",
      "epoch:8 step:7588 [D loss: 0.608884, acc.: 68.75%] [G loss: 1.019900]\n",
      "epoch:8 step:7589 [D loss: 0.648774, acc.: 55.47%] [G loss: 0.948252]\n",
      "epoch:8 step:7590 [D loss: 0.621589, acc.: 66.41%] [G loss: 0.898126]\n",
      "epoch:8 step:7591 [D loss: 0.653864, acc.: 67.19%] [G loss: 0.902270]\n",
      "epoch:8 step:7592 [D loss: 0.619936, acc.: 62.50%] [G loss: 0.858475]\n",
      "epoch:8 step:7593 [D loss: 0.620301, acc.: 58.59%] [G loss: 0.911025]\n",
      "epoch:8 step:7594 [D loss: 0.687059, acc.: 57.81%] [G loss: 0.919177]\n",
      "epoch:8 step:7595 [D loss: 0.659406, acc.: 59.38%] [G loss: 0.917001]\n",
      "epoch:8 step:7596 [D loss: 0.584729, acc.: 67.19%] [G loss: 0.917895]\n",
      "epoch:8 step:7597 [D loss: 0.644532, acc.: 64.84%] [G loss: 0.896136]\n",
      "epoch:8 step:7598 [D loss: 0.685066, acc.: 58.59%] [G loss: 0.890430]\n",
      "epoch:8 step:7599 [D loss: 0.641758, acc.: 62.50%] [G loss: 0.902395]\n",
      "epoch:8 step:7600 [D loss: 0.659689, acc.: 54.69%] [G loss: 0.886680]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.715201\n",
      "FID: 11.063914\n",
      "0 = 11.89245603973871\n",
      "1 = 0.06057836882527665\n",
      "2 = 0.9394999742507935\n",
      "3 = 0.89410001039505\n",
      "4 = 0.9848999977111816\n",
      "5 = 0.9833920001983643\n",
      "6 = 0.89410001039505\n",
      "7 = 6.305473342984921\n",
      "8 = 0.06890304177356334\n",
      "9 = 0.7323499917984009\n",
      "10 = 0.7067000269889832\n",
      "11 = 0.7580000162124634\n",
      "12 = 0.7449141144752502\n",
      "13 = 0.7067000269889832\n",
      "14 = 7.715262413024902\n",
      "15 = 9.457504272460938\n",
      "16 = 0.13970743119716644\n",
      "17 = 7.715201377868652\n",
      "18 = 11.06391429901123\n",
      "epoch:8 step:7601 [D loss: 0.730834, acc.: 50.78%] [G loss: 0.900132]\n",
      "epoch:8 step:7602 [D loss: 0.634413, acc.: 66.41%] [G loss: 0.949871]\n",
      "epoch:8 step:7603 [D loss: 0.601869, acc.: 71.88%] [G loss: 1.027556]\n",
      "epoch:8 step:7604 [D loss: 0.763936, acc.: 46.09%] [G loss: 0.918349]\n",
      "epoch:8 step:7605 [D loss: 0.715042, acc.: 49.22%] [G loss: 0.909202]\n",
      "epoch:8 step:7606 [D loss: 0.677677, acc.: 56.25%] [G loss: 0.844138]\n",
      "epoch:8 step:7607 [D loss: 0.665578, acc.: 57.03%] [G loss: 0.884670]\n",
      "epoch:8 step:7608 [D loss: 0.637512, acc.: 62.50%] [G loss: 0.893111]\n",
      "epoch:8 step:7609 [D loss: 0.649348, acc.: 58.59%] [G loss: 0.904553]\n",
      "epoch:8 step:7610 [D loss: 0.656110, acc.: 65.62%] [G loss: 0.927104]\n",
      "epoch:8 step:7611 [D loss: 0.628329, acc.: 60.94%] [G loss: 0.967586]\n",
      "epoch:8 step:7612 [D loss: 0.624663, acc.: 62.50%] [G loss: 0.948341]\n",
      "epoch:8 step:7613 [D loss: 0.625458, acc.: 71.88%] [G loss: 0.906144]\n",
      "epoch:8 step:7614 [D loss: 0.695719, acc.: 55.47%] [G loss: 0.921396]\n",
      "epoch:8 step:7615 [D loss: 0.626370, acc.: 67.19%] [G loss: 0.964722]\n",
      "epoch:8 step:7616 [D loss: 0.713732, acc.: 55.47%] [G loss: 0.966309]\n",
      "epoch:8 step:7617 [D loss: 0.722210, acc.: 49.22%] [G loss: 0.859288]\n",
      "epoch:8 step:7618 [D loss: 0.644197, acc.: 66.41%] [G loss: 0.914264]\n",
      "epoch:8 step:7619 [D loss: 0.680642, acc.: 61.72%] [G loss: 0.944765]\n",
      "epoch:8 step:7620 [D loss: 0.703913, acc.: 53.91%] [G loss: 0.875835]\n",
      "epoch:8 step:7621 [D loss: 0.663189, acc.: 59.38%] [G loss: 0.874070]\n",
      "epoch:8 step:7622 [D loss: 0.620103, acc.: 67.97%] [G loss: 0.932823]\n",
      "epoch:8 step:7623 [D loss: 0.688810, acc.: 52.34%] [G loss: 0.893955]\n",
      "epoch:8 step:7624 [D loss: 0.679565, acc.: 57.81%] [G loss: 0.946512]\n",
      "epoch:8 step:7625 [D loss: 0.655864, acc.: 60.94%] [G loss: 0.921889]\n",
      "epoch:8 step:7626 [D loss: 0.611103, acc.: 74.22%] [G loss: 0.944431]\n",
      "epoch:8 step:7627 [D loss: 0.621545, acc.: 62.50%] [G loss: 0.871894]\n",
      "epoch:8 step:7628 [D loss: 0.644447, acc.: 62.50%] [G loss: 0.864517]\n",
      "epoch:8 step:7629 [D loss: 0.630743, acc.: 62.50%] [G loss: 0.885166]\n",
      "epoch:8 step:7630 [D loss: 0.649468, acc.: 61.72%] [G loss: 1.023646]\n",
      "epoch:8 step:7631 [D loss: 0.611067, acc.: 67.19%] [G loss: 0.979400]\n",
      "epoch:8 step:7632 [D loss: 0.635479, acc.: 63.28%] [G loss: 0.917949]\n",
      "epoch:8 step:7633 [D loss: 0.632173, acc.: 64.06%] [G loss: 0.862330]\n",
      "epoch:8 step:7634 [D loss: 0.628092, acc.: 64.06%] [G loss: 0.882138]\n",
      "epoch:8 step:7635 [D loss: 0.684501, acc.: 51.56%] [G loss: 0.921515]\n",
      "epoch:8 step:7636 [D loss: 0.668062, acc.: 57.03%] [G loss: 0.859792]\n",
      "epoch:8 step:7637 [D loss: 0.701272, acc.: 53.91%] [G loss: 0.910538]\n",
      "epoch:8 step:7638 [D loss: 0.702660, acc.: 50.78%] [G loss: 0.849843]\n",
      "epoch:8 step:7639 [D loss: 0.685406, acc.: 53.91%] [G loss: 0.892800]\n",
      "epoch:8 step:7640 [D loss: 0.669792, acc.: 60.16%] [G loss: 0.907307]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7641 [D loss: 0.653342, acc.: 62.50%] [G loss: 0.893085]\n",
      "epoch:8 step:7642 [D loss: 0.612471, acc.: 67.19%] [G loss: 0.843007]\n",
      "epoch:8 step:7643 [D loss: 0.690886, acc.: 60.16%] [G loss: 0.802836]\n",
      "epoch:8 step:7644 [D loss: 0.699850, acc.: 53.91%] [G loss: 0.881668]\n",
      "epoch:8 step:7645 [D loss: 0.653709, acc.: 59.38%] [G loss: 0.941269]\n",
      "epoch:8 step:7646 [D loss: 0.680145, acc.: 55.47%] [G loss: 0.882205]\n",
      "epoch:8 step:7647 [D loss: 0.653247, acc.: 66.41%] [G loss: 0.874349]\n",
      "epoch:8 step:7648 [D loss: 0.607176, acc.: 70.31%] [G loss: 0.957275]\n",
      "epoch:8 step:7649 [D loss: 0.702461, acc.: 54.69%] [G loss: 0.907560]\n",
      "epoch:8 step:7650 [D loss: 0.659672, acc.: 57.81%] [G loss: 0.907833]\n",
      "epoch:8 step:7651 [D loss: 0.632915, acc.: 59.38%] [G loss: 0.879706]\n",
      "epoch:8 step:7652 [D loss: 0.649173, acc.: 65.62%] [G loss: 0.929947]\n",
      "epoch:8 step:7653 [D loss: 0.681180, acc.: 60.94%] [G loss: 0.876018]\n",
      "epoch:8 step:7654 [D loss: 0.637327, acc.: 63.28%] [G loss: 0.925521]\n",
      "epoch:8 step:7655 [D loss: 0.659552, acc.: 64.84%] [G loss: 0.900651]\n",
      "epoch:8 step:7656 [D loss: 0.771184, acc.: 49.22%] [G loss: 0.931573]\n",
      "epoch:8 step:7657 [D loss: 0.656208, acc.: 57.03%] [G loss: 0.989236]\n",
      "epoch:8 step:7658 [D loss: 0.643211, acc.: 64.84%] [G loss: 0.934078]\n",
      "epoch:8 step:7659 [D loss: 0.619879, acc.: 64.06%] [G loss: 0.897451]\n",
      "epoch:8 step:7660 [D loss: 0.649746, acc.: 60.94%] [G loss: 0.947808]\n",
      "epoch:8 step:7661 [D loss: 0.689155, acc.: 58.59%] [G loss: 0.894554]\n",
      "epoch:8 step:7662 [D loss: 0.653546, acc.: 62.50%] [G loss: 0.855751]\n",
      "epoch:8 step:7663 [D loss: 0.661049, acc.: 60.16%] [G loss: 0.827238]\n",
      "epoch:8 step:7664 [D loss: 0.641529, acc.: 66.41%] [G loss: 0.870700]\n",
      "epoch:8 step:7665 [D loss: 0.650059, acc.: 65.62%] [G loss: 0.880805]\n",
      "epoch:8 step:7666 [D loss: 0.660150, acc.: 60.16%] [G loss: 0.853561]\n",
      "epoch:8 step:7667 [D loss: 0.644261, acc.: 62.50%] [G loss: 0.865109]\n",
      "epoch:8 step:7668 [D loss: 0.674148, acc.: 56.25%] [G loss: 0.852074]\n",
      "epoch:8 step:7669 [D loss: 0.632822, acc.: 65.62%] [G loss: 0.870609]\n",
      "epoch:8 step:7670 [D loss: 0.706103, acc.: 53.12%] [G loss: 0.843307]\n",
      "epoch:8 step:7671 [D loss: 0.678444, acc.: 62.50%] [G loss: 0.891306]\n",
      "epoch:8 step:7672 [D loss: 0.662675, acc.: 64.06%] [G loss: 0.849438]\n",
      "epoch:8 step:7673 [D loss: 0.686198, acc.: 58.59%] [G loss: 0.900617]\n",
      "epoch:8 step:7674 [D loss: 0.646073, acc.: 66.41%] [G loss: 0.943861]\n",
      "epoch:8 step:7675 [D loss: 0.673429, acc.: 58.59%] [G loss: 0.893116]\n",
      "epoch:8 step:7676 [D loss: 0.696936, acc.: 52.34%] [G loss: 0.886666]\n",
      "epoch:8 step:7677 [D loss: 0.699546, acc.: 55.47%] [G loss: 0.848346]\n",
      "epoch:8 step:7678 [D loss: 0.688497, acc.: 53.91%] [G loss: 0.912337]\n",
      "epoch:8 step:7679 [D loss: 0.640715, acc.: 65.62%] [G loss: 0.879617]\n",
      "epoch:8 step:7680 [D loss: 0.663288, acc.: 58.59%] [G loss: 0.930915]\n",
      "epoch:8 step:7681 [D loss: 0.680952, acc.: 60.16%] [G loss: 0.902299]\n",
      "epoch:8 step:7682 [D loss: 0.670641, acc.: 60.16%] [G loss: 0.870808]\n",
      "epoch:8 step:7683 [D loss: 0.656232, acc.: 64.84%] [G loss: 0.939539]\n",
      "epoch:8 step:7684 [D loss: 0.698205, acc.: 53.12%] [G loss: 0.841854]\n",
      "epoch:8 step:7685 [D loss: 0.688541, acc.: 56.25%] [G loss: 0.842078]\n",
      "epoch:8 step:7686 [D loss: 0.642568, acc.: 63.28%] [G loss: 0.880063]\n",
      "epoch:8 step:7687 [D loss: 0.647118, acc.: 64.06%] [G loss: 0.907999]\n",
      "epoch:8 step:7688 [D loss: 0.677987, acc.: 60.94%] [G loss: 0.882889]\n",
      "epoch:8 step:7689 [D loss: 0.665355, acc.: 57.03%] [G loss: 0.914749]\n",
      "epoch:8 step:7690 [D loss: 0.617664, acc.: 64.84%] [G loss: 0.960844]\n",
      "epoch:8 step:7691 [D loss: 0.640270, acc.: 61.72%] [G loss: 0.935530]\n",
      "epoch:8 step:7692 [D loss: 0.676087, acc.: 58.59%] [G loss: 0.882880]\n",
      "epoch:8 step:7693 [D loss: 0.609177, acc.: 66.41%] [G loss: 0.918322]\n",
      "epoch:8 step:7694 [D loss: 0.583399, acc.: 72.66%] [G loss: 0.885684]\n",
      "epoch:8 step:7695 [D loss: 0.634240, acc.: 65.62%] [G loss: 0.963564]\n",
      "epoch:8 step:7696 [D loss: 0.701645, acc.: 49.22%] [G loss: 0.854653]\n",
      "epoch:8 step:7697 [D loss: 0.662850, acc.: 58.59%] [G loss: 0.856543]\n",
      "epoch:8 step:7698 [D loss: 0.668193, acc.: 58.59%] [G loss: 0.877174]\n",
      "epoch:8 step:7699 [D loss: 0.708859, acc.: 47.66%] [G loss: 0.866627]\n",
      "epoch:8 step:7700 [D loss: 0.671158, acc.: 51.56%] [G loss: 0.861485]\n",
      "epoch:8 step:7701 [D loss: 0.674616, acc.: 57.03%] [G loss: 0.888439]\n",
      "epoch:8 step:7702 [D loss: 0.630762, acc.: 66.41%] [G loss: 0.921869]\n",
      "epoch:8 step:7703 [D loss: 0.649492, acc.: 60.16%] [G loss: 0.940155]\n",
      "epoch:8 step:7704 [D loss: 0.612097, acc.: 68.75%] [G loss: 0.929952]\n",
      "epoch:8 step:7705 [D loss: 0.581864, acc.: 68.75%] [G loss: 0.920682]\n",
      "epoch:8 step:7706 [D loss: 0.730324, acc.: 50.78%] [G loss: 0.928407]\n",
      "epoch:8 step:7707 [D loss: 0.660325, acc.: 60.16%] [G loss: 0.892096]\n",
      "epoch:8 step:7708 [D loss: 0.676588, acc.: 54.69%] [G loss: 0.878920]\n",
      "epoch:8 step:7709 [D loss: 0.627098, acc.: 66.41%] [G loss: 0.889522]\n",
      "epoch:8 step:7710 [D loss: 0.696146, acc.: 53.91%] [G loss: 0.916442]\n",
      "epoch:8 step:7711 [D loss: 0.716716, acc.: 53.12%] [G loss: 0.845790]\n",
      "epoch:8 step:7712 [D loss: 0.629467, acc.: 67.97%] [G loss: 0.921265]\n",
      "epoch:8 step:7713 [D loss: 0.629406, acc.: 61.72%] [G loss: 0.914211]\n",
      "epoch:8 step:7714 [D loss: 0.633482, acc.: 61.72%] [G loss: 0.826651]\n",
      "epoch:8 step:7715 [D loss: 0.603655, acc.: 64.84%] [G loss: 0.931267]\n",
      "epoch:8 step:7716 [D loss: 0.727461, acc.: 50.78%] [G loss: 0.904644]\n",
      "epoch:8 step:7717 [D loss: 0.613248, acc.: 67.97%] [G loss: 0.860598]\n",
      "epoch:8 step:7718 [D loss: 0.622114, acc.: 60.16%] [G loss: 0.934197]\n",
      "epoch:8 step:7719 [D loss: 0.586722, acc.: 66.41%] [G loss: 0.966214]\n",
      "epoch:8 step:7720 [D loss: 0.673360, acc.: 62.50%] [G loss: 0.882953]\n",
      "epoch:8 step:7721 [D loss: 0.718276, acc.: 49.22%] [G loss: 0.861143]\n",
      "epoch:8 step:7722 [D loss: 0.673988, acc.: 58.59%] [G loss: 0.843213]\n",
      "epoch:8 step:7723 [D loss: 0.659773, acc.: 58.59%] [G loss: 0.892765]\n",
      "epoch:8 step:7724 [D loss: 0.691681, acc.: 55.47%] [G loss: 0.865263]\n",
      "epoch:8 step:7725 [D loss: 0.617294, acc.: 71.09%] [G loss: 0.861953]\n",
      "epoch:8 step:7726 [D loss: 0.585562, acc.: 67.19%] [G loss: 0.932260]\n",
      "epoch:8 step:7727 [D loss: 0.580204, acc.: 64.06%] [G loss: 0.984169]\n",
      "epoch:8 step:7728 [D loss: 0.576478, acc.: 65.62%] [G loss: 1.074116]\n",
      "epoch:8 step:7729 [D loss: 0.733689, acc.: 52.34%] [G loss: 0.941909]\n",
      "epoch:8 step:7730 [D loss: 0.710027, acc.: 52.34%] [G loss: 0.942659]\n",
      "epoch:8 step:7731 [D loss: 0.647843, acc.: 60.16%] [G loss: 0.963046]\n",
      "epoch:8 step:7732 [D loss: 0.639116, acc.: 62.50%] [G loss: 0.967896]\n",
      "epoch:8 step:7733 [D loss: 0.675915, acc.: 53.12%] [G loss: 0.948410]\n",
      "epoch:8 step:7734 [D loss: 0.692706, acc.: 57.03%] [G loss: 0.903014]\n",
      "epoch:8 step:7735 [D loss: 0.675908, acc.: 52.34%] [G loss: 0.925194]\n",
      "epoch:8 step:7736 [D loss: 0.678590, acc.: 50.00%] [G loss: 0.916749]\n",
      "epoch:8 step:7737 [D loss: 0.632224, acc.: 64.84%] [G loss: 0.908102]\n",
      "epoch:8 step:7738 [D loss: 0.597504, acc.: 69.53%] [G loss: 0.901740]\n",
      "epoch:8 step:7739 [D loss: 0.636682, acc.: 58.59%] [G loss: 0.934575]\n",
      "epoch:8 step:7740 [D loss: 0.626977, acc.: 67.19%] [G loss: 0.914155]\n",
      "epoch:8 step:7741 [D loss: 0.665589, acc.: 60.16%] [G loss: 0.903463]\n",
      "epoch:8 step:7742 [D loss: 0.638877, acc.: 64.06%] [G loss: 0.871941]\n",
      "epoch:8 step:7743 [D loss: 0.586020, acc.: 69.53%] [G loss: 0.920407]\n",
      "epoch:8 step:7744 [D loss: 0.623389, acc.: 65.62%] [G loss: 0.939088]\n",
      "epoch:8 step:7745 [D loss: 0.702566, acc.: 60.94%] [G loss: 0.882619]\n",
      "epoch:8 step:7746 [D loss: 0.746246, acc.: 50.00%] [G loss: 0.821581]\n",
      "epoch:8 step:7747 [D loss: 0.693762, acc.: 60.16%] [G loss: 0.836930]\n",
      "epoch:8 step:7748 [D loss: 0.674529, acc.: 59.38%] [G loss: 0.874146]\n",
      "epoch:8 step:7749 [D loss: 0.634619, acc.: 64.06%] [G loss: 0.957514]\n",
      "epoch:8 step:7750 [D loss: 0.631772, acc.: 66.41%] [G loss: 0.961206]\n",
      "epoch:8 step:7751 [D loss: 0.632285, acc.: 64.06%] [G loss: 0.959961]\n",
      "epoch:8 step:7752 [D loss: 0.660742, acc.: 61.72%] [G loss: 0.979801]\n",
      "epoch:8 step:7753 [D loss: 0.645471, acc.: 64.06%] [G loss: 0.923235]\n",
      "epoch:8 step:7754 [D loss: 0.676460, acc.: 60.16%] [G loss: 0.912276]\n",
      "epoch:8 step:7755 [D loss: 0.680615, acc.: 61.72%] [G loss: 0.954646]\n",
      "epoch:8 step:7756 [D loss: 0.676960, acc.: 59.38%] [G loss: 0.864291]\n",
      "epoch:8 step:7757 [D loss: 0.666253, acc.: 54.69%] [G loss: 0.903983]\n",
      "epoch:8 step:7758 [D loss: 0.608324, acc.: 63.28%] [G loss: 0.882225]\n",
      "epoch:8 step:7759 [D loss: 0.728186, acc.: 50.78%] [G loss: 0.917359]\n",
      "epoch:8 step:7760 [D loss: 0.640439, acc.: 67.19%] [G loss: 0.900723]\n",
      "epoch:8 step:7761 [D loss: 0.720577, acc.: 50.00%] [G loss: 0.840905]\n",
      "epoch:8 step:7762 [D loss: 0.661410, acc.: 59.38%] [G loss: 0.796611]\n",
      "epoch:8 step:7763 [D loss: 0.660908, acc.: 60.94%] [G loss: 0.862722]\n",
      "epoch:8 step:7764 [D loss: 0.648253, acc.: 60.94%] [G loss: 0.903054]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7765 [D loss: 0.656738, acc.: 60.16%] [G loss: 0.952514]\n",
      "epoch:8 step:7766 [D loss: 0.653324, acc.: 63.28%] [G loss: 0.862302]\n",
      "epoch:8 step:7767 [D loss: 0.640003, acc.: 60.94%] [G loss: 0.946432]\n",
      "epoch:8 step:7768 [D loss: 0.632606, acc.: 61.72%] [G loss: 0.889228]\n",
      "epoch:8 step:7769 [D loss: 0.660575, acc.: 55.47%] [G loss: 0.856346]\n",
      "epoch:8 step:7770 [D loss: 0.639890, acc.: 64.84%] [G loss: 0.868606]\n",
      "epoch:8 step:7771 [D loss: 0.672706, acc.: 53.91%] [G loss: 0.922916]\n",
      "epoch:8 step:7772 [D loss: 0.643129, acc.: 64.06%] [G loss: 0.950759]\n",
      "epoch:8 step:7773 [D loss: 0.708722, acc.: 56.25%] [G loss: 0.900160]\n",
      "epoch:8 step:7774 [D loss: 0.642516, acc.: 64.84%] [G loss: 0.891321]\n",
      "epoch:8 step:7775 [D loss: 0.663509, acc.: 63.28%] [G loss: 0.959164]\n",
      "epoch:8 step:7776 [D loss: 0.601730, acc.: 67.97%] [G loss: 0.952646]\n",
      "epoch:8 step:7777 [D loss: 0.711565, acc.: 57.81%] [G loss: 0.921154]\n",
      "epoch:8 step:7778 [D loss: 0.706336, acc.: 55.47%] [G loss: 0.871204]\n",
      "epoch:8 step:7779 [D loss: 0.620461, acc.: 68.75%] [G loss: 0.895936]\n",
      "epoch:8 step:7780 [D loss: 0.650762, acc.: 65.62%] [G loss: 0.914970]\n",
      "epoch:8 step:7781 [D loss: 0.644629, acc.: 67.97%] [G loss: 0.891236]\n",
      "epoch:8 step:7782 [D loss: 0.614134, acc.: 68.75%] [G loss: 0.938307]\n",
      "epoch:8 step:7783 [D loss: 0.645055, acc.: 64.06%] [G loss: 0.907179]\n",
      "epoch:8 step:7784 [D loss: 0.679307, acc.: 54.69%] [G loss: 0.909771]\n",
      "epoch:8 step:7785 [D loss: 0.590574, acc.: 73.44%] [G loss: 0.886954]\n",
      "epoch:8 step:7786 [D loss: 0.637227, acc.: 62.50%] [G loss: 0.887561]\n",
      "epoch:8 step:7787 [D loss: 0.670703, acc.: 57.81%] [G loss: 0.910864]\n",
      "epoch:8 step:7788 [D loss: 0.642244, acc.: 65.62%] [G loss: 0.863541]\n",
      "epoch:8 step:7789 [D loss: 0.653911, acc.: 55.47%] [G loss: 0.917854]\n",
      "epoch:8 step:7790 [D loss: 0.718439, acc.: 53.91%] [G loss: 0.846312]\n",
      "epoch:8 step:7791 [D loss: 0.688330, acc.: 57.03%] [G loss: 0.901327]\n",
      "epoch:8 step:7792 [D loss: 0.632940, acc.: 65.62%] [G loss: 0.923272]\n",
      "epoch:8 step:7793 [D loss: 0.642167, acc.: 61.72%] [G loss: 0.902822]\n",
      "epoch:8 step:7794 [D loss: 0.650502, acc.: 64.06%] [G loss: 0.915025]\n",
      "epoch:8 step:7795 [D loss: 0.602804, acc.: 67.19%] [G loss: 0.924645]\n",
      "epoch:8 step:7796 [D loss: 0.628757, acc.: 65.62%] [G loss: 0.896261]\n",
      "epoch:8 step:7797 [D loss: 0.714770, acc.: 50.00%] [G loss: 0.875029]\n",
      "epoch:8 step:7798 [D loss: 0.628821, acc.: 68.75%] [G loss: 0.911685]\n",
      "epoch:8 step:7799 [D loss: 0.659091, acc.: 58.59%] [G loss: 0.901329]\n",
      "epoch:8 step:7800 [D loss: 0.596807, acc.: 72.66%] [G loss: 0.969542]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.648052\n",
      "FID: 14.932954\n",
      "0 = 11.860446057319677\n",
      "1 = 0.05838586167895564\n",
      "2 = 0.9312999844551086\n",
      "3 = 0.878600001335144\n",
      "4 = 0.984000027179718\n",
      "5 = 0.9821149110794067\n",
      "6 = 0.878600001335144\n",
      "7 = 6.592741923546802\n",
      "8 = 0.08450440267796969\n",
      "9 = 0.7385500073432922\n",
      "10 = 0.715399980545044\n",
      "11 = 0.7616999745368958\n",
      "12 = 0.7501310706138611\n",
      "13 = 0.715399980545044\n",
      "14 = 7.648121356964111\n",
      "15 = 9.570537567138672\n",
      "16 = 0.10467378050088882\n",
      "17 = 7.648051738739014\n",
      "18 = 14.932953834533691\n",
      "epoch:8 step:7801 [D loss: 0.634343, acc.: 61.72%] [G loss: 0.896966]\n",
      "epoch:8 step:7802 [D loss: 0.657851, acc.: 60.94%] [G loss: 0.947820]\n",
      "epoch:8 step:7803 [D loss: 0.630862, acc.: 68.75%] [G loss: 0.938384]\n",
      "epoch:8 step:7804 [D loss: 0.661425, acc.: 62.50%] [G loss: 0.937937]\n",
      "epoch:8 step:7805 [D loss: 0.638475, acc.: 63.28%] [G loss: 0.945517]\n",
      "epoch:8 step:7806 [D loss: 0.643567, acc.: 64.84%] [G loss: 0.872895]\n",
      "epoch:8 step:7807 [D loss: 0.636582, acc.: 64.06%] [G loss: 0.915813]\n",
      "epoch:8 step:7808 [D loss: 0.542044, acc.: 75.78%] [G loss: 0.920093]\n",
      "epoch:8 step:7809 [D loss: 0.600216, acc.: 64.84%] [G loss: 0.984323]\n",
      "epoch:8 step:7810 [D loss: 0.585628, acc.: 69.53%] [G loss: 1.048896]\n",
      "epoch:8 step:7811 [D loss: 0.586132, acc.: 70.31%] [G loss: 0.979092]\n",
      "epoch:8 step:7812 [D loss: 0.846469, acc.: 43.75%] [G loss: 0.935443]\n",
      "epoch:8 step:7813 [D loss: 0.661082, acc.: 56.25%] [G loss: 0.924478]\n",
      "epoch:8 step:7814 [D loss: 0.663843, acc.: 57.03%] [G loss: 0.892810]\n",
      "epoch:8 step:7815 [D loss: 0.644617, acc.: 63.28%] [G loss: 0.932825]\n",
      "epoch:8 step:7816 [D loss: 0.626395, acc.: 64.84%] [G loss: 0.918355]\n",
      "epoch:8 step:7817 [D loss: 0.590043, acc.: 71.09%] [G loss: 0.961947]\n",
      "epoch:8 step:7818 [D loss: 0.646356, acc.: 63.28%] [G loss: 0.920025]\n",
      "epoch:8 step:7819 [D loss: 0.651781, acc.: 58.59%] [G loss: 0.927783]\n",
      "epoch:8 step:7820 [D loss: 0.687461, acc.: 52.34%] [G loss: 0.859665]\n",
      "epoch:8 step:7821 [D loss: 0.694665, acc.: 56.25%] [G loss: 0.873077]\n",
      "epoch:8 step:7822 [D loss: 0.678735, acc.: 59.38%] [G loss: 0.917030]\n",
      "epoch:8 step:7823 [D loss: 0.666927, acc.: 59.38%] [G loss: 0.940117]\n",
      "epoch:8 step:7824 [D loss: 0.626687, acc.: 65.62%] [G loss: 0.941155]\n",
      "epoch:8 step:7825 [D loss: 0.692407, acc.: 56.25%] [G loss: 0.920179]\n",
      "epoch:8 step:7826 [D loss: 0.675148, acc.: 56.25%] [G loss: 0.859228]\n",
      "epoch:8 step:7827 [D loss: 0.664116, acc.: 66.41%] [G loss: 0.869222]\n",
      "epoch:8 step:7828 [D loss: 0.633099, acc.: 67.19%] [G loss: 0.906156]\n",
      "epoch:8 step:7829 [D loss: 0.617385, acc.: 67.97%] [G loss: 0.918112]\n",
      "epoch:8 step:7830 [D loss: 0.667368, acc.: 60.94%] [G loss: 0.905998]\n",
      "epoch:8 step:7831 [D loss: 0.668410, acc.: 56.25%] [G loss: 0.910645]\n",
      "epoch:8 step:7832 [D loss: 0.616570, acc.: 70.31%] [G loss: 0.964237]\n",
      "epoch:8 step:7833 [D loss: 0.649438, acc.: 64.06%] [G loss: 0.926946]\n",
      "epoch:8 step:7834 [D loss: 0.622892, acc.: 67.19%] [G loss: 0.874843]\n",
      "epoch:8 step:7835 [D loss: 0.670335, acc.: 60.94%] [G loss: 0.891455]\n",
      "epoch:8 step:7836 [D loss: 0.592547, acc.: 72.66%] [G loss: 0.832943]\n",
      "epoch:8 step:7837 [D loss: 0.751966, acc.: 45.31%] [G loss: 0.895484]\n",
      "epoch:8 step:7838 [D loss: 0.673438, acc.: 57.81%] [G loss: 0.911468]\n",
      "epoch:8 step:7839 [D loss: 0.587205, acc.: 69.53%] [G loss: 0.934540]\n",
      "epoch:8 step:7840 [D loss: 0.602357, acc.: 71.09%] [G loss: 0.939463]\n",
      "epoch:8 step:7841 [D loss: 0.605267, acc.: 73.44%] [G loss: 0.971849]\n",
      "epoch:8 step:7842 [D loss: 0.547102, acc.: 71.88%] [G loss: 0.964449]\n",
      "epoch:8 step:7843 [D loss: 0.550422, acc.: 71.88%] [G loss: 0.975225]\n",
      "epoch:8 step:7844 [D loss: 0.760176, acc.: 51.56%] [G loss: 0.901001]\n",
      "epoch:8 step:7845 [D loss: 0.746948, acc.: 46.88%] [G loss: 0.860548]\n",
      "epoch:8 step:7846 [D loss: 0.644649, acc.: 61.72%] [G loss: 0.909985]\n",
      "epoch:8 step:7847 [D loss: 0.686853, acc.: 58.59%] [G loss: 0.867110]\n",
      "epoch:8 step:7848 [D loss: 0.688543, acc.: 57.03%] [G loss: 0.947109]\n",
      "epoch:8 step:7849 [D loss: 0.608999, acc.: 71.09%] [G loss: 0.946456]\n",
      "epoch:8 step:7850 [D loss: 0.607230, acc.: 73.44%] [G loss: 0.968543]\n",
      "epoch:8 step:7851 [D loss: 0.649627, acc.: 60.94%] [G loss: 0.964972]\n",
      "epoch:8 step:7852 [D loss: 0.662966, acc.: 62.50%] [G loss: 0.879575]\n",
      "epoch:8 step:7853 [D loss: 0.662008, acc.: 57.03%] [G loss: 0.845469]\n",
      "epoch:8 step:7854 [D loss: 0.647088, acc.: 58.59%] [G loss: 0.967851]\n",
      "epoch:8 step:7855 [D loss: 0.627047, acc.: 65.62%] [G loss: 0.938340]\n",
      "epoch:8 step:7856 [D loss: 0.617994, acc.: 62.50%] [G loss: 0.970896]\n",
      "epoch:8 step:7857 [D loss: 0.641103, acc.: 67.19%] [G loss: 0.933216]\n",
      "epoch:8 step:7858 [D loss: 0.656770, acc.: 57.03%] [G loss: 0.937192]\n",
      "epoch:8 step:7859 [D loss: 0.646528, acc.: 63.28%] [G loss: 0.923484]\n",
      "epoch:8 step:7860 [D loss: 0.638776, acc.: 57.03%] [G loss: 0.929556]\n",
      "epoch:8 step:7861 [D loss: 0.628681, acc.: 62.50%] [G loss: 0.932055]\n",
      "epoch:8 step:7862 [D loss: 0.654332, acc.: 66.41%] [G loss: 0.916933]\n",
      "epoch:8 step:7863 [D loss: 0.598755, acc.: 69.53%] [G loss: 0.938015]\n",
      "epoch:8 step:7864 [D loss: 0.650218, acc.: 58.59%] [G loss: 0.887944]\n",
      "epoch:8 step:7865 [D loss: 0.720670, acc.: 52.34%] [G loss: 0.909700]\n",
      "epoch:8 step:7866 [D loss: 0.653901, acc.: 60.16%] [G loss: 0.904050]\n",
      "epoch:8 step:7867 [D loss: 0.613895, acc.: 72.66%] [G loss: 0.910777]\n",
      "epoch:8 step:7868 [D loss: 0.642247, acc.: 61.72%] [G loss: 0.947840]\n",
      "epoch:8 step:7869 [D loss: 0.696200, acc.: 57.03%] [G loss: 0.901401]\n",
      "epoch:8 step:7870 [D loss: 0.601947, acc.: 66.41%] [G loss: 0.899853]\n",
      "epoch:8 step:7871 [D loss: 0.658773, acc.: 59.38%] [G loss: 0.905108]\n",
      "epoch:8 step:7872 [D loss: 0.724687, acc.: 50.00%] [G loss: 0.868540]\n",
      "epoch:8 step:7873 [D loss: 0.696870, acc.: 57.03%] [G loss: 0.783283]\n",
      "epoch:8 step:7874 [D loss: 0.677155, acc.: 57.03%] [G loss: 0.851617]\n",
      "epoch:8 step:7875 [D loss: 0.681577, acc.: 57.81%] [G loss: 0.799595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7876 [D loss: 0.646127, acc.: 60.16%] [G loss: 0.845294]\n",
      "epoch:8 step:7877 [D loss: 0.627682, acc.: 61.72%] [G loss: 0.911227]\n",
      "epoch:8 step:7878 [D loss: 0.692341, acc.: 62.50%] [G loss: 0.926795]\n",
      "epoch:8 step:7879 [D loss: 0.674130, acc.: 60.94%] [G loss: 0.847956]\n",
      "epoch:8 step:7880 [D loss: 0.620779, acc.: 67.19%] [G loss: 0.965904]\n",
      "epoch:8 step:7881 [D loss: 0.655897, acc.: 60.94%] [G loss: 0.942609]\n",
      "epoch:8 step:7882 [D loss: 0.679441, acc.: 59.38%] [G loss: 0.921016]\n",
      "epoch:8 step:7883 [D loss: 0.642151, acc.: 67.97%] [G loss: 0.897843]\n",
      "epoch:8 step:7884 [D loss: 0.641483, acc.: 66.41%] [G loss: 0.873129]\n",
      "epoch:8 step:7885 [D loss: 0.638884, acc.: 65.62%] [G loss: 0.897557]\n",
      "epoch:8 step:7886 [D loss: 0.708523, acc.: 55.47%] [G loss: 0.876307]\n",
      "epoch:8 step:7887 [D loss: 0.642291, acc.: 63.28%] [G loss: 0.901400]\n",
      "epoch:8 step:7888 [D loss: 0.622908, acc.: 68.75%] [G loss: 0.874599]\n",
      "epoch:8 step:7889 [D loss: 0.711848, acc.: 52.34%] [G loss: 0.862626]\n",
      "epoch:8 step:7890 [D loss: 0.705345, acc.: 50.78%] [G loss: 0.896067]\n",
      "epoch:8 step:7891 [D loss: 0.678958, acc.: 54.69%] [G loss: 0.868272]\n",
      "epoch:8 step:7892 [D loss: 0.655809, acc.: 65.62%] [G loss: 0.941295]\n",
      "epoch:8 step:7893 [D loss: 0.620112, acc.: 68.75%] [G loss: 0.900961]\n",
      "epoch:8 step:7894 [D loss: 0.558847, acc.: 74.22%] [G loss: 0.914205]\n",
      "epoch:8 step:7895 [D loss: 0.587543, acc.: 70.31%] [G loss: 0.932248]\n",
      "epoch:8 step:7896 [D loss: 0.688692, acc.: 53.12%] [G loss: 0.831451]\n",
      "epoch:8 step:7897 [D loss: 0.701740, acc.: 50.78%] [G loss: 0.875529]\n",
      "epoch:8 step:7898 [D loss: 0.664093, acc.: 65.62%] [G loss: 0.888937]\n",
      "epoch:8 step:7899 [D loss: 0.678230, acc.: 60.16%] [G loss: 0.847248]\n",
      "epoch:8 step:7900 [D loss: 0.648410, acc.: 60.16%] [G loss: 0.877766]\n",
      "epoch:8 step:7901 [D loss: 0.626519, acc.: 66.41%] [G loss: 0.936154]\n",
      "epoch:8 step:7902 [D loss: 0.639053, acc.: 61.72%] [G loss: 0.970082]\n",
      "epoch:8 step:7903 [D loss: 0.682230, acc.: 57.03%] [G loss: 0.942330]\n",
      "epoch:8 step:7904 [D loss: 0.673474, acc.: 65.62%] [G loss: 0.861788]\n",
      "epoch:8 step:7905 [D loss: 0.666473, acc.: 60.16%] [G loss: 0.886313]\n",
      "epoch:8 step:7906 [D loss: 0.679384, acc.: 58.59%] [G loss: 0.843211]\n",
      "epoch:8 step:7907 [D loss: 0.639714, acc.: 61.72%] [G loss: 0.824826]\n",
      "epoch:8 step:7908 [D loss: 0.649053, acc.: 61.72%] [G loss: 0.906019]\n",
      "epoch:8 step:7909 [D loss: 0.674119, acc.: 59.38%] [G loss: 0.869632]\n",
      "epoch:8 step:7910 [D loss: 0.646612, acc.: 64.84%] [G loss: 0.880328]\n",
      "epoch:8 step:7911 [D loss: 0.647737, acc.: 58.59%] [G loss: 0.927364]\n",
      "epoch:8 step:7912 [D loss: 0.645182, acc.: 61.72%] [G loss: 1.011469]\n",
      "epoch:8 step:7913 [D loss: 0.705787, acc.: 58.59%] [G loss: 1.007751]\n",
      "epoch:8 step:7914 [D loss: 0.746438, acc.: 48.44%] [G loss: 0.895344]\n",
      "epoch:8 step:7915 [D loss: 0.685544, acc.: 57.03%] [G loss: 0.880535]\n",
      "epoch:8 step:7916 [D loss: 0.653893, acc.: 59.38%] [G loss: 0.984481]\n",
      "epoch:8 step:7917 [D loss: 0.679181, acc.: 60.16%] [G loss: 0.877285]\n",
      "epoch:8 step:7918 [D loss: 0.680657, acc.: 59.38%] [G loss: 0.908590]\n",
      "epoch:8 step:7919 [D loss: 0.655230, acc.: 64.84%] [G loss: 0.870843]\n",
      "epoch:8 step:7920 [D loss: 0.698880, acc.: 54.69%] [G loss: 0.910658]\n",
      "epoch:8 step:7921 [D loss: 0.638601, acc.: 64.06%] [G loss: 0.903626]\n",
      "epoch:8 step:7922 [D loss: 0.601156, acc.: 71.88%] [G loss: 0.928631]\n",
      "epoch:8 step:7923 [D loss: 0.650416, acc.: 64.84%] [G loss: 0.894122]\n",
      "epoch:8 step:7924 [D loss: 0.658380, acc.: 59.38%] [G loss: 0.866416]\n",
      "epoch:8 step:7925 [D loss: 0.625733, acc.: 66.41%] [G loss: 0.921421]\n",
      "epoch:8 step:7926 [D loss: 0.670905, acc.: 64.84%] [G loss: 0.986929]\n",
      "epoch:8 step:7927 [D loss: 0.652761, acc.: 60.16%] [G loss: 0.895740]\n",
      "epoch:8 step:7928 [D loss: 0.651526, acc.: 59.38%] [G loss: 0.890054]\n",
      "epoch:8 step:7929 [D loss: 0.705606, acc.: 49.22%] [G loss: 0.886283]\n",
      "epoch:8 step:7930 [D loss: 0.604918, acc.: 71.09%] [G loss: 0.883169]\n",
      "epoch:8 step:7931 [D loss: 0.655449, acc.: 66.41%] [G loss: 0.947817]\n",
      "epoch:8 step:7932 [D loss: 0.623196, acc.: 66.41%] [G loss: 0.962783]\n",
      "epoch:8 step:7933 [D loss: 0.760378, acc.: 51.56%] [G loss: 0.907095]\n",
      "epoch:8 step:7934 [D loss: 0.719828, acc.: 46.88%] [G loss: 0.921290]\n",
      "epoch:8 step:7935 [D loss: 0.639006, acc.: 64.06%] [G loss: 0.936552]\n",
      "epoch:8 step:7936 [D loss: 0.645259, acc.: 65.62%] [G loss: 0.922501]\n",
      "epoch:8 step:7937 [D loss: 0.653763, acc.: 60.94%] [G loss: 0.904870]\n",
      "epoch:8 step:7938 [D loss: 0.649858, acc.: 60.94%] [G loss: 0.961533]\n",
      "epoch:8 step:7939 [D loss: 0.666713, acc.: 58.59%] [G loss: 0.926342]\n",
      "epoch:8 step:7940 [D loss: 0.684222, acc.: 60.94%] [G loss: 0.870849]\n",
      "epoch:8 step:7941 [D loss: 0.594177, acc.: 71.09%] [G loss: 0.905257]\n",
      "epoch:8 step:7942 [D loss: 0.679948, acc.: 57.81%] [G loss: 0.948787]\n",
      "epoch:8 step:7943 [D loss: 0.630307, acc.: 64.84%] [G loss: 0.939534]\n",
      "epoch:8 step:7944 [D loss: 0.693049, acc.: 58.59%] [G loss: 0.907348]\n",
      "epoch:8 step:7945 [D loss: 0.669300, acc.: 54.69%] [G loss: 0.813532]\n",
      "epoch:8 step:7946 [D loss: 0.644068, acc.: 64.84%] [G loss: 0.843781]\n",
      "epoch:8 step:7947 [D loss: 0.651468, acc.: 61.72%] [G loss: 0.880779]\n",
      "epoch:8 step:7948 [D loss: 0.644851, acc.: 61.72%] [G loss: 0.887299]\n",
      "epoch:8 step:7949 [D loss: 0.619446, acc.: 60.16%] [G loss: 0.945935]\n",
      "epoch:8 step:7950 [D loss: 0.660836, acc.: 60.16%] [G loss: 0.876516]\n",
      "epoch:8 step:7951 [D loss: 0.697158, acc.: 51.56%] [G loss: 0.894147]\n",
      "epoch:8 step:7952 [D loss: 0.684560, acc.: 53.91%] [G loss: 0.878481]\n",
      "epoch:8 step:7953 [D loss: 0.644615, acc.: 62.50%] [G loss: 0.930197]\n",
      "epoch:8 step:7954 [D loss: 0.735668, acc.: 48.44%] [G loss: 0.891678]\n",
      "epoch:8 step:7955 [D loss: 0.667303, acc.: 55.47%] [G loss: 0.815163]\n",
      "epoch:8 step:7956 [D loss: 0.665233, acc.: 61.72%] [G loss: 0.931716]\n",
      "epoch:8 step:7957 [D loss: 0.688122, acc.: 59.38%] [G loss: 0.886905]\n",
      "epoch:8 step:7958 [D loss: 0.683130, acc.: 55.47%] [G loss: 0.870451]\n",
      "epoch:8 step:7959 [D loss: 0.659694, acc.: 63.28%] [G loss: 0.828630]\n",
      "epoch:8 step:7960 [D loss: 0.640843, acc.: 64.06%] [G loss: 0.864454]\n",
      "epoch:8 step:7961 [D loss: 0.690161, acc.: 56.25%] [G loss: 0.845493]\n",
      "epoch:8 step:7962 [D loss: 0.665260, acc.: 57.03%] [G loss: 0.899726]\n",
      "epoch:8 step:7963 [D loss: 0.648992, acc.: 57.81%] [G loss: 0.877492]\n",
      "epoch:8 step:7964 [D loss: 0.671307, acc.: 53.12%] [G loss: 0.968958]\n",
      "epoch:8 step:7965 [D loss: 0.599236, acc.: 64.06%] [G loss: 0.987066]\n",
      "epoch:8 step:7966 [D loss: 0.687110, acc.: 54.69%] [G loss: 0.983978]\n",
      "epoch:8 step:7967 [D loss: 0.628692, acc.: 62.50%] [G loss: 1.006634]\n",
      "epoch:8 step:7968 [D loss: 0.647439, acc.: 64.06%] [G loss: 1.036203]\n",
      "epoch:8 step:7969 [D loss: 0.731882, acc.: 49.22%] [G loss: 0.971062]\n",
      "epoch:8 step:7970 [D loss: 0.647214, acc.: 63.28%] [G loss: 0.940100]\n",
      "epoch:8 step:7971 [D loss: 0.584071, acc.: 70.31%] [G loss: 0.958322]\n",
      "epoch:8 step:7972 [D loss: 0.666919, acc.: 52.34%] [G loss: 0.907876]\n",
      "epoch:8 step:7973 [D loss: 0.720106, acc.: 48.44%] [G loss: 0.916620]\n",
      "epoch:8 step:7974 [D loss: 0.757480, acc.: 44.53%] [G loss: 0.899816]\n",
      "epoch:8 step:7975 [D loss: 0.642602, acc.: 65.62%] [G loss: 0.836738]\n",
      "epoch:8 step:7976 [D loss: 0.660162, acc.: 64.06%] [G loss: 0.909345]\n",
      "epoch:8 step:7977 [D loss: 0.656212, acc.: 60.16%] [G loss: 0.903954]\n",
      "epoch:8 step:7978 [D loss: 0.726524, acc.: 47.66%] [G loss: 0.908429]\n",
      "epoch:8 step:7979 [D loss: 0.718291, acc.: 51.56%] [G loss: 0.949953]\n",
      "epoch:8 step:7980 [D loss: 0.652172, acc.: 60.94%] [G loss: 0.934546]\n",
      "epoch:8 step:7981 [D loss: 0.615653, acc.: 64.84%] [G loss: 0.915949]\n",
      "epoch:8 step:7982 [D loss: 0.658122, acc.: 64.84%] [G loss: 0.876047]\n",
      "epoch:8 step:7983 [D loss: 0.680063, acc.: 56.25%] [G loss: 0.885929]\n",
      "epoch:8 step:7984 [D loss: 0.633894, acc.: 60.94%] [G loss: 0.887628]\n",
      "epoch:8 step:7985 [D loss: 0.651169, acc.: 65.62%] [G loss: 0.889743]\n",
      "epoch:8 step:7986 [D loss: 0.669420, acc.: 58.59%] [G loss: 0.878038]\n",
      "epoch:8 step:7987 [D loss: 0.677679, acc.: 54.69%] [G loss: 0.887469]\n",
      "epoch:8 step:7988 [D loss: 0.669443, acc.: 59.38%] [G loss: 0.870197]\n",
      "epoch:8 step:7989 [D loss: 0.653725, acc.: 62.50%] [G loss: 0.894056]\n",
      "epoch:8 step:7990 [D loss: 0.627037, acc.: 63.28%] [G loss: 0.933399]\n",
      "epoch:8 step:7991 [D loss: 0.648450, acc.: 63.28%] [G loss: 0.907013]\n",
      "epoch:8 step:7992 [D loss: 0.652082, acc.: 64.06%] [G loss: 0.872324]\n",
      "epoch:8 step:7993 [D loss: 0.636588, acc.: 64.06%] [G loss: 0.944770]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7994 [D loss: 0.605664, acc.: 67.19%] [G loss: 0.950054]\n",
      "epoch:8 step:7995 [D loss: 0.622344, acc.: 67.19%] [G loss: 0.941428]\n",
      "epoch:8 step:7996 [D loss: 0.692608, acc.: 53.91%] [G loss: 0.857541]\n",
      "epoch:8 step:7997 [D loss: 0.745291, acc.: 55.47%] [G loss: 0.878499]\n",
      "epoch:8 step:7998 [D loss: 0.708710, acc.: 50.78%] [G loss: 0.902005]\n",
      "epoch:8 step:7999 [D loss: 0.643383, acc.: 66.41%] [G loss: 0.892637]\n",
      "epoch:8 step:8000 [D loss: 0.609397, acc.: 72.66%] [G loss: 0.901570]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.443147\n",
      "FID: 15.897599\n",
      "0 = 12.029981474638008\n",
      "1 = 0.0606629274634238\n",
      "2 = 0.9394000172615051\n",
      "3 = 0.895799994468689\n",
      "4 = 0.9829999804496765\n",
      "5 = 0.9813759922981262\n",
      "6 = 0.895799994468689\n",
      "7 = 6.858098310244051\n",
      "8 = 0.08611625806405027\n",
      "9 = 0.7576500177383423\n",
      "10 = 0.7271999716758728\n",
      "11 = 0.788100004196167\n",
      "12 = 0.7743584513664246\n",
      "13 = 0.7271999716758728\n",
      "14 = 7.443213939666748\n",
      "15 = 9.531803131103516\n",
      "16 = 0.12024080753326416\n",
      "17 = 7.4431471824646\n",
      "18 = 15.897599220275879\n",
      "epoch:8 step:8001 [D loss: 0.636685, acc.: 63.28%] [G loss: 0.949750]\n",
      "epoch:8 step:8002 [D loss: 0.663695, acc.: 53.91%] [G loss: 0.977774]\n",
      "epoch:8 step:8003 [D loss: 0.582776, acc.: 70.31%] [G loss: 1.060050]\n",
      "epoch:8 step:8004 [D loss: 0.556004, acc.: 75.00%] [G loss: 1.021396]\n",
      "epoch:8 step:8005 [D loss: 0.677852, acc.: 61.72%] [G loss: 0.967143]\n",
      "epoch:8 step:8006 [D loss: 0.675377, acc.: 57.03%] [G loss: 0.911981]\n",
      "epoch:8 step:8007 [D loss: 0.718519, acc.: 53.12%] [G loss: 0.838639]\n",
      "epoch:8 step:8008 [D loss: 0.712770, acc.: 53.91%] [G loss: 0.809792]\n",
      "epoch:8 step:8009 [D loss: 0.659019, acc.: 57.03%] [G loss: 0.851265]\n",
      "epoch:8 step:8010 [D loss: 0.638247, acc.: 60.16%] [G loss: 0.820723]\n",
      "epoch:8 step:8011 [D loss: 0.587802, acc.: 69.53%] [G loss: 0.875083]\n",
      "epoch:8 step:8012 [D loss: 0.601509, acc.: 71.88%] [G loss: 0.902495]\n",
      "epoch:8 step:8013 [D loss: 0.716510, acc.: 56.25%] [G loss: 0.831017]\n",
      "epoch:8 step:8014 [D loss: 0.659832, acc.: 60.16%] [G loss: 0.855177]\n",
      "epoch:8 step:8015 [D loss: 0.608222, acc.: 68.75%] [G loss: 0.848628]\n",
      "epoch:8 step:8016 [D loss: 0.638727, acc.: 66.41%] [G loss: 0.908532]\n",
      "epoch:8 step:8017 [D loss: 0.635297, acc.: 67.97%] [G loss: 0.895689]\n",
      "epoch:8 step:8018 [D loss: 0.643846, acc.: 66.41%] [G loss: 0.860374]\n",
      "epoch:8 step:8019 [D loss: 0.631498, acc.: 67.97%] [G loss: 0.862483]\n",
      "epoch:8 step:8020 [D loss: 0.682440, acc.: 55.47%] [G loss: 0.852951]\n",
      "epoch:8 step:8021 [D loss: 0.652692, acc.: 58.59%] [G loss: 0.884687]\n",
      "epoch:8 step:8022 [D loss: 0.627978, acc.: 67.19%] [G loss: 0.923443]\n",
      "epoch:8 step:8023 [D loss: 0.694114, acc.: 58.59%] [G loss: 0.890603]\n",
      "epoch:8 step:8024 [D loss: 0.705220, acc.: 52.34%] [G loss: 0.894428]\n",
      "epoch:8 step:8025 [D loss: 0.701317, acc.: 54.69%] [G loss: 0.889109]\n",
      "epoch:8 step:8026 [D loss: 0.610482, acc.: 67.97%] [G loss: 0.914461]\n",
      "epoch:8 step:8027 [D loss: 0.712220, acc.: 53.12%] [G loss: 0.863481]\n",
      "epoch:8 step:8028 [D loss: 0.692258, acc.: 54.69%] [G loss: 0.871247]\n",
      "epoch:8 step:8029 [D loss: 0.658410, acc.: 61.72%] [G loss: 0.835313]\n",
      "epoch:8 step:8030 [D loss: 0.587838, acc.: 67.97%] [G loss: 0.856944]\n",
      "epoch:8 step:8031 [D loss: 0.701569, acc.: 54.69%] [G loss: 0.839968]\n",
      "epoch:8 step:8032 [D loss: 0.628985, acc.: 65.62%] [G loss: 0.877871]\n",
      "epoch:8 step:8033 [D loss: 0.706529, acc.: 51.56%] [G loss: 0.909950]\n",
      "epoch:8 step:8034 [D loss: 0.703757, acc.: 53.91%] [G loss: 0.850283]\n",
      "epoch:8 step:8035 [D loss: 0.644627, acc.: 62.50%] [G loss: 0.881541]\n",
      "epoch:8 step:8036 [D loss: 0.666176, acc.: 61.72%] [G loss: 0.911770]\n",
      "epoch:8 step:8037 [D loss: 0.656787, acc.: 64.84%] [G loss: 0.868878]\n",
      "epoch:8 step:8038 [D loss: 0.741271, acc.: 51.56%] [G loss: 0.850485]\n",
      "epoch:8 step:8039 [D loss: 0.710996, acc.: 48.44%] [G loss: 0.902942]\n",
      "epoch:8 step:8040 [D loss: 0.638901, acc.: 60.94%] [G loss: 0.893411]\n",
      "epoch:8 step:8041 [D loss: 0.654444, acc.: 60.16%] [G loss: 0.890435]\n",
      "epoch:8 step:8042 [D loss: 0.681012, acc.: 53.91%] [G loss: 0.901329]\n",
      "epoch:8 step:8043 [D loss: 0.617214, acc.: 65.62%] [G loss: 0.875353]\n",
      "epoch:8 step:8044 [D loss: 0.631661, acc.: 61.72%] [G loss: 0.963176]\n",
      "epoch:8 step:8045 [D loss: 0.611718, acc.: 67.19%] [G loss: 0.938233]\n",
      "epoch:8 step:8046 [D loss: 0.628372, acc.: 67.97%] [G loss: 0.934048]\n",
      "epoch:8 step:8047 [D loss: 0.639054, acc.: 63.28%] [G loss: 0.946477]\n",
      "epoch:8 step:8048 [D loss: 0.653623, acc.: 63.28%] [G loss: 0.912025]\n",
      "epoch:8 step:8049 [D loss: 0.634439, acc.: 64.06%] [G loss: 0.916369]\n",
      "epoch:8 step:8050 [D loss: 0.635147, acc.: 65.62%] [G loss: 0.890857]\n",
      "epoch:8 step:8051 [D loss: 0.610294, acc.: 69.53%] [G loss: 0.976786]\n",
      "epoch:8 step:8052 [D loss: 0.632015, acc.: 61.72%] [G loss: 0.856862]\n",
      "epoch:8 step:8053 [D loss: 0.638907, acc.: 64.06%] [G loss: 0.903055]\n",
      "epoch:8 step:8054 [D loss: 0.591869, acc.: 67.97%] [G loss: 0.862700]\n",
      "epoch:8 step:8055 [D loss: 0.709290, acc.: 56.25%] [G loss: 0.906907]\n",
      "epoch:8 step:8056 [D loss: 0.704603, acc.: 58.59%] [G loss: 0.882660]\n",
      "epoch:8 step:8057 [D loss: 0.584096, acc.: 72.66%] [G loss: 0.893563]\n",
      "epoch:8 step:8058 [D loss: 0.636529, acc.: 69.53%] [G loss: 0.918496]\n",
      "epoch:8 step:8059 [D loss: 0.663531, acc.: 65.62%] [G loss: 0.960533]\n",
      "epoch:8 step:8060 [D loss: 0.626099, acc.: 66.41%] [G loss: 1.020737]\n",
      "epoch:8 step:8061 [D loss: 0.661448, acc.: 57.81%] [G loss: 0.957349]\n",
      "epoch:8 step:8062 [D loss: 0.791374, acc.: 46.09%] [G loss: 0.869514]\n",
      "epoch:8 step:8063 [D loss: 0.644414, acc.: 60.94%] [G loss: 0.939515]\n",
      "epoch:8 step:8064 [D loss: 0.672691, acc.: 55.47%] [G loss: 0.929304]\n",
      "epoch:8 step:8065 [D loss: 0.723796, acc.: 52.34%] [G loss: 0.882922]\n",
      "epoch:8 step:8066 [D loss: 0.667140, acc.: 60.16%] [G loss: 0.839348]\n",
      "epoch:8 step:8067 [D loss: 0.610051, acc.: 65.62%] [G loss: 0.833066]\n",
      "epoch:8 step:8068 [D loss: 0.657668, acc.: 56.25%] [G loss: 0.940343]\n",
      "epoch:8 step:8069 [D loss: 0.654287, acc.: 63.28%] [G loss: 0.910840]\n",
      "epoch:8 step:8070 [D loss: 0.587439, acc.: 75.00%] [G loss: 0.937429]\n",
      "epoch:8 step:8071 [D loss: 0.605456, acc.: 69.53%] [G loss: 0.930867]\n",
      "epoch:8 step:8072 [D loss: 0.655154, acc.: 53.12%] [G loss: 0.888244]\n",
      "epoch:8 step:8073 [D loss: 0.685422, acc.: 55.47%] [G loss: 0.924432]\n",
      "epoch:8 step:8074 [D loss: 0.660356, acc.: 61.72%] [G loss: 0.916046]\n",
      "epoch:8 step:8075 [D loss: 0.674385, acc.: 59.38%] [G loss: 0.898312]\n",
      "epoch:8 step:8076 [D loss: 0.649039, acc.: 63.28%] [G loss: 0.885800]\n",
      "epoch:8 step:8077 [D loss: 0.598277, acc.: 67.97%] [G loss: 0.944769]\n",
      "epoch:8 step:8078 [D loss: 0.689918, acc.: 53.12%] [G loss: 0.879674]\n",
      "epoch:8 step:8079 [D loss: 0.652142, acc.: 61.72%] [G loss: 0.888015]\n",
      "epoch:8 step:8080 [D loss: 0.717746, acc.: 51.56%] [G loss: 0.889060]\n",
      "epoch:8 step:8081 [D loss: 0.670147, acc.: 60.16%] [G loss: 0.894305]\n",
      "epoch:8 step:8082 [D loss: 0.671901, acc.: 60.94%] [G loss: 0.887358]\n",
      "epoch:8 step:8083 [D loss: 0.722123, acc.: 53.12%] [G loss: 0.879357]\n",
      "epoch:8 step:8084 [D loss: 0.651781, acc.: 58.59%] [G loss: 0.971071]\n",
      "epoch:8 step:8085 [D loss: 0.617341, acc.: 65.62%] [G loss: 0.951076]\n",
      "epoch:8 step:8086 [D loss: 0.664111, acc.: 59.38%] [G loss: 0.869782]\n",
      "epoch:8 step:8087 [D loss: 0.714360, acc.: 53.12%] [G loss: 0.896218]\n",
      "epoch:8 step:8088 [D loss: 0.652048, acc.: 61.72%] [G loss: 0.890857]\n",
      "epoch:8 step:8089 [D loss: 0.663367, acc.: 57.81%] [G loss: 0.943509]\n",
      "epoch:8 step:8090 [D loss: 0.645370, acc.: 59.38%] [G loss: 0.880263]\n",
      "epoch:8 step:8091 [D loss: 0.616421, acc.: 64.06%] [G loss: 0.835068]\n",
      "epoch:8 step:8092 [D loss: 0.676992, acc.: 54.69%] [G loss: 0.824254]\n",
      "epoch:8 step:8093 [D loss: 0.740673, acc.: 50.00%] [G loss: 0.930997]\n",
      "epoch:8 step:8094 [D loss: 0.631493, acc.: 67.19%] [G loss: 0.893711]\n",
      "epoch:8 step:8095 [D loss: 0.662176, acc.: 55.47%] [G loss: 0.951173]\n",
      "epoch:8 step:8096 [D loss: 0.691993, acc.: 53.91%] [G loss: 0.903679]\n",
      "epoch:8 step:8097 [D loss: 0.675772, acc.: 62.50%] [G loss: 0.930051]\n",
      "epoch:8 step:8098 [D loss: 0.691789, acc.: 53.12%] [G loss: 0.846834]\n",
      "epoch:8 step:8099 [D loss: 0.667475, acc.: 64.06%] [G loss: 0.876864]\n",
      "epoch:8 step:8100 [D loss: 0.676002, acc.: 57.03%] [G loss: 0.874861]\n",
      "epoch:8 step:8101 [D loss: 0.648435, acc.: 62.50%] [G loss: 0.804909]\n",
      "epoch:8 step:8102 [D loss: 0.679014, acc.: 57.03%] [G loss: 0.882023]\n",
      "epoch:8 step:8103 [D loss: 0.609461, acc.: 74.22%] [G loss: 0.907626]\n",
      "epoch:8 step:8104 [D loss: 0.660478, acc.: 62.50%] [G loss: 0.843078]\n",
      "epoch:8 step:8105 [D loss: 0.645315, acc.: 60.94%] [G loss: 0.852526]\n",
      "epoch:8 step:8106 [D loss: 0.668548, acc.: 57.81%] [G loss: 0.886966]\n",
      "epoch:8 step:8107 [D loss: 0.606430, acc.: 66.41%] [G loss: 0.844695]\n",
      "epoch:8 step:8108 [D loss: 0.670837, acc.: 57.03%] [G loss: 0.861529]\n",
      "epoch:8 step:8109 [D loss: 0.675615, acc.: 59.38%] [G loss: 0.842524]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8110 [D loss: 0.708367, acc.: 54.69%] [G loss: 0.863994]\n",
      "epoch:8 step:8111 [D loss: 0.715171, acc.: 51.56%] [G loss: 0.915981]\n",
      "epoch:8 step:8112 [D loss: 0.703460, acc.: 53.12%] [G loss: 0.884345]\n",
      "epoch:8 step:8113 [D loss: 0.636108, acc.: 61.72%] [G loss: 0.929936]\n",
      "epoch:8 step:8114 [D loss: 0.666318, acc.: 58.59%] [G loss: 0.902344]\n",
      "epoch:8 step:8115 [D loss: 0.650992, acc.: 63.28%] [G loss: 0.948536]\n",
      "epoch:8 step:8116 [D loss: 0.673018, acc.: 59.38%] [G loss: 0.883494]\n",
      "epoch:8 step:8117 [D loss: 0.691441, acc.: 49.22%] [G loss: 0.866559]\n",
      "epoch:8 step:8118 [D loss: 0.650838, acc.: 61.72%] [G loss: 0.903296]\n",
      "epoch:8 step:8119 [D loss: 0.685424, acc.: 58.59%] [G loss: 0.916987]\n",
      "epoch:8 step:8120 [D loss: 0.627168, acc.: 67.19%] [G loss: 0.936189]\n",
      "epoch:8 step:8121 [D loss: 0.695426, acc.: 54.69%] [G loss: 0.921491]\n",
      "epoch:8 step:8122 [D loss: 0.698986, acc.: 58.59%] [G loss: 0.901509]\n",
      "epoch:8 step:8123 [D loss: 0.634257, acc.: 64.06%] [G loss: 0.903451]\n",
      "epoch:8 step:8124 [D loss: 0.671208, acc.: 63.28%] [G loss: 0.864208]\n",
      "epoch:8 step:8125 [D loss: 0.641330, acc.: 63.28%] [G loss: 0.941663]\n",
      "epoch:8 step:8126 [D loss: 0.612995, acc.: 67.19%] [G loss: 0.868369]\n",
      "epoch:8 step:8127 [D loss: 0.641588, acc.: 64.84%] [G loss: 0.865915]\n",
      "epoch:8 step:8128 [D loss: 0.636252, acc.: 61.72%] [G loss: 0.950485]\n",
      "epoch:8 step:8129 [D loss: 0.658469, acc.: 58.59%] [G loss: 0.899722]\n",
      "epoch:8 step:8130 [D loss: 0.616032, acc.: 64.84%] [G loss: 0.955158]\n",
      "epoch:8 step:8131 [D loss: 0.632145, acc.: 63.28%] [G loss: 0.899196]\n",
      "epoch:8 step:8132 [D loss: 0.665244, acc.: 57.03%] [G loss: 0.867230]\n",
      "epoch:8 step:8133 [D loss: 0.623892, acc.: 67.97%] [G loss: 0.903973]\n",
      "epoch:8 step:8134 [D loss: 0.623697, acc.: 61.72%] [G loss: 0.868900]\n",
      "epoch:8 step:8135 [D loss: 0.649970, acc.: 58.59%] [G loss: 0.924120]\n",
      "epoch:8 step:8136 [D loss: 0.643169, acc.: 58.59%] [G loss: 0.877699]\n",
      "epoch:8 step:8137 [D loss: 0.638667, acc.: 60.94%] [G loss: 0.937402]\n",
      "epoch:8 step:8138 [D loss: 0.600479, acc.: 66.41%] [G loss: 0.945571]\n",
      "epoch:8 step:8139 [D loss: 0.652901, acc.: 64.84%] [G loss: 0.927861]\n",
      "epoch:8 step:8140 [D loss: 0.722906, acc.: 50.00%] [G loss: 0.891629]\n",
      "epoch:8 step:8141 [D loss: 0.672879, acc.: 57.03%] [G loss: 0.903969]\n",
      "epoch:8 step:8142 [D loss: 0.660291, acc.: 58.59%] [G loss: 0.927117]\n",
      "epoch:8 step:8143 [D loss: 0.645157, acc.: 68.75%] [G loss: 0.920104]\n",
      "epoch:8 step:8144 [D loss: 0.617881, acc.: 65.62%] [G loss: 0.967716]\n",
      "epoch:8 step:8145 [D loss: 0.654262, acc.: 58.59%] [G loss: 0.977102]\n",
      "epoch:8 step:8146 [D loss: 0.592361, acc.: 68.75%] [G loss: 0.995289]\n",
      "epoch:8 step:8147 [D loss: 0.638879, acc.: 60.16%] [G loss: 0.961674]\n",
      "epoch:8 step:8148 [D loss: 0.689989, acc.: 55.47%] [G loss: 0.933270]\n",
      "epoch:8 step:8149 [D loss: 0.681360, acc.: 53.91%] [G loss: 0.886743]\n",
      "epoch:8 step:8150 [D loss: 0.630523, acc.: 63.28%] [G loss: 0.914078]\n",
      "epoch:8 step:8151 [D loss: 0.708224, acc.: 48.44%] [G loss: 0.856900]\n",
      "epoch:8 step:8152 [D loss: 0.662034, acc.: 62.50%] [G loss: 0.884383]\n",
      "epoch:8 step:8153 [D loss: 0.681344, acc.: 57.03%] [G loss: 0.859911]\n",
      "epoch:8 step:8154 [D loss: 0.662063, acc.: 60.16%] [G loss: 0.922192]\n",
      "epoch:8 step:8155 [D loss: 0.606822, acc.: 69.53%] [G loss: 0.864018]\n",
      "epoch:8 step:8156 [D loss: 0.631182, acc.: 63.28%] [G loss: 0.899551]\n",
      "epoch:8 step:8157 [D loss: 0.641485, acc.: 64.84%] [G loss: 0.942467]\n",
      "epoch:8 step:8158 [D loss: 0.700009, acc.: 57.81%] [G loss: 0.861614]\n",
      "epoch:8 step:8159 [D loss: 0.652819, acc.: 65.62%] [G loss: 0.826194]\n",
      "epoch:8 step:8160 [D loss: 0.694993, acc.: 57.03%] [G loss: 0.855687]\n",
      "epoch:8 step:8161 [D loss: 0.671890, acc.: 53.91%] [G loss: 0.916192]\n",
      "epoch:8 step:8162 [D loss: 0.659931, acc.: 57.81%] [G loss: 0.924844]\n",
      "epoch:8 step:8163 [D loss: 0.720404, acc.: 57.81%] [G loss: 0.895610]\n",
      "epoch:8 step:8164 [D loss: 0.695983, acc.: 55.47%] [G loss: 0.928773]\n",
      "epoch:8 step:8165 [D loss: 0.663578, acc.: 61.72%] [G loss: 0.930543]\n",
      "epoch:8 step:8166 [D loss: 0.665360, acc.: 62.50%] [G loss: 0.840313]\n",
      "epoch:8 step:8167 [D loss: 0.687093, acc.: 56.25%] [G loss: 0.913416]\n",
      "epoch:8 step:8168 [D loss: 0.706377, acc.: 57.03%] [G loss: 0.873166]\n",
      "epoch:8 step:8169 [D loss: 0.659568, acc.: 59.38%] [G loss: 0.883089]\n",
      "epoch:8 step:8170 [D loss: 0.636227, acc.: 67.97%] [G loss: 0.872805]\n",
      "epoch:8 step:8171 [D loss: 0.726083, acc.: 53.12%] [G loss: 0.916472]\n",
      "epoch:8 step:8172 [D loss: 0.665117, acc.: 60.94%] [G loss: 0.860949]\n",
      "epoch:8 step:8173 [D loss: 0.632795, acc.: 64.84%] [G loss: 0.854114]\n",
      "epoch:8 step:8174 [D loss: 0.640905, acc.: 66.41%] [G loss: 0.896020]\n",
      "epoch:8 step:8175 [D loss: 0.676419, acc.: 62.50%] [G loss: 0.892507]\n",
      "epoch:8 step:8176 [D loss: 0.653678, acc.: 60.16%] [G loss: 0.856360]\n",
      "epoch:8 step:8177 [D loss: 0.657062, acc.: 63.28%] [G loss: 0.877037]\n",
      "epoch:8 step:8178 [D loss: 0.655316, acc.: 61.72%] [G loss: 0.846055]\n",
      "epoch:8 step:8179 [D loss: 0.694199, acc.: 50.78%] [G loss: 0.856816]\n",
      "epoch:8 step:8180 [D loss: 0.638340, acc.: 65.62%] [G loss: 0.856579]\n",
      "epoch:8 step:8181 [D loss: 0.692322, acc.: 55.47%] [G loss: 0.889065]\n",
      "epoch:8 step:8182 [D loss: 0.671356, acc.: 58.59%] [G loss: 0.942564]\n",
      "epoch:8 step:8183 [D loss: 0.654053, acc.: 65.62%] [G loss: 0.909815]\n",
      "epoch:8 step:8184 [D loss: 0.645326, acc.: 63.28%] [G loss: 0.850629]\n",
      "epoch:8 step:8185 [D loss: 0.678056, acc.: 57.81%] [G loss: 0.912524]\n",
      "epoch:8 step:8186 [D loss: 0.632199, acc.: 62.50%] [G loss: 0.919793]\n",
      "epoch:8 step:8187 [D loss: 0.586925, acc.: 71.88%] [G loss: 0.891811]\n",
      "epoch:8 step:8188 [D loss: 0.617919, acc.: 71.09%] [G loss: 0.935605]\n",
      "epoch:8 step:8189 [D loss: 0.629854, acc.: 60.94%] [G loss: 0.895047]\n",
      "epoch:8 step:8190 [D loss: 0.622708, acc.: 67.19%] [G loss: 0.953234]\n",
      "epoch:8 step:8191 [D loss: 0.638513, acc.: 64.84%] [G loss: 0.926839]\n",
      "epoch:8 step:8192 [D loss: 0.664473, acc.: 55.47%] [G loss: 0.883680]\n",
      "epoch:8 step:8193 [D loss: 0.676080, acc.: 58.59%] [G loss: 0.815198]\n",
      "epoch:8 step:8194 [D loss: 0.689996, acc.: 56.25%] [G loss: 0.898963]\n",
      "epoch:8 step:8195 [D loss: 0.635328, acc.: 61.72%] [G loss: 0.919811]\n",
      "epoch:8 step:8196 [D loss: 0.621551, acc.: 66.41%] [G loss: 0.897909]\n",
      "epoch:8 step:8197 [D loss: 0.665419, acc.: 64.06%] [G loss: 0.926972]\n",
      "epoch:8 step:8198 [D loss: 0.664293, acc.: 59.38%] [G loss: 0.905670]\n",
      "epoch:8 step:8199 [D loss: 0.722725, acc.: 50.78%] [G loss: 0.885924]\n",
      "epoch:8 step:8200 [D loss: 0.726875, acc.: 50.78%] [G loss: 0.906806]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.742239\n",
      "FID: 10.760653\n",
      "0 = 11.976990325665458\n",
      "1 = 0.05484857000053434\n",
      "2 = 0.9350000023841858\n",
      "3 = 0.883899986743927\n",
      "4 = 0.9861000180244446\n",
      "5 = 0.9845176935195923\n",
      "6 = 0.883899986743927\n",
      "7 = 6.345258682829161\n",
      "8 = 0.07421875\n",
      "9 = 0.7458999752998352\n",
      "10 = 0.7168999910354614\n",
      "11 = 0.7749000191688538\n",
      "12 = 0.7610403299331665\n",
      "13 = 0.7168999910354614\n",
      "14 = 7.742303848266602\n",
      "15 = 9.60136604309082\n",
      "16 = 0.09448894113302231\n",
      "17 = 7.742238521575928\n",
      "18 = 10.760652542114258\n",
      "epoch:8 step:8201 [D loss: 0.651999, acc.: 64.06%] [G loss: 0.878850]\n",
      "epoch:8 step:8202 [D loss: 0.654443, acc.: 59.38%] [G loss: 0.883264]\n",
      "epoch:8 step:8203 [D loss: 0.616539, acc.: 69.53%] [G loss: 0.871370]\n",
      "epoch:8 step:8204 [D loss: 0.565036, acc.: 72.66%] [G loss: 0.945931]\n",
      "epoch:8 step:8205 [D loss: 0.629563, acc.: 66.41%] [G loss: 0.899651]\n",
      "epoch:8 step:8206 [D loss: 0.671025, acc.: 55.47%] [G loss: 0.890561]\n",
      "epoch:8 step:8207 [D loss: 0.666502, acc.: 56.25%] [G loss: 0.881842]\n",
      "epoch:8 step:8208 [D loss: 0.684329, acc.: 53.91%] [G loss: 0.902673]\n",
      "epoch:8 step:8209 [D loss: 0.718692, acc.: 50.78%] [G loss: 0.898487]\n",
      "epoch:8 step:8210 [D loss: 0.694222, acc.: 56.25%] [G loss: 0.914822]\n",
      "epoch:8 step:8211 [D loss: 0.671786, acc.: 60.16%] [G loss: 0.887629]\n",
      "epoch:8 step:8212 [D loss: 0.719895, acc.: 51.56%] [G loss: 0.876551]\n",
      "epoch:8 step:8213 [D loss: 0.644093, acc.: 64.84%] [G loss: 0.871722]\n",
      "epoch:8 step:8214 [D loss: 0.677466, acc.: 60.16%] [G loss: 0.909833]\n",
      "epoch:8 step:8215 [D loss: 0.632017, acc.: 64.84%] [G loss: 0.873022]\n",
      "epoch:8 step:8216 [D loss: 0.663855, acc.: 56.25%] [G loss: 0.906079]\n",
      "epoch:8 step:8217 [D loss: 0.670220, acc.: 57.03%] [G loss: 0.893907]\n",
      "epoch:8 step:8218 [D loss: 0.696396, acc.: 57.03%] [G loss: 0.917188]\n",
      "epoch:8 step:8219 [D loss: 0.636012, acc.: 64.84%] [G loss: 0.923756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8220 [D loss: 0.639221, acc.: 59.38%] [G loss: 0.861955]\n",
      "epoch:8 step:8221 [D loss: 0.660762, acc.: 59.38%] [G loss: 0.864723]\n",
      "epoch:8 step:8222 [D loss: 0.667420, acc.: 55.47%] [G loss: 0.915991]\n",
      "epoch:8 step:8223 [D loss: 0.677793, acc.: 50.00%] [G loss: 0.894438]\n",
      "epoch:8 step:8224 [D loss: 0.653286, acc.: 58.59%] [G loss: 0.917985]\n",
      "epoch:8 step:8225 [D loss: 0.650271, acc.: 64.06%] [G loss: 0.888398]\n",
      "epoch:8 step:8226 [D loss: 0.631561, acc.: 63.28%] [G loss: 0.937681]\n",
      "epoch:8 step:8227 [D loss: 0.688958, acc.: 57.03%] [G loss: 0.950789]\n",
      "epoch:8 step:8228 [D loss: 0.624387, acc.: 68.75%] [G loss: 0.974207]\n",
      "epoch:8 step:8229 [D loss: 0.619406, acc.: 68.75%] [G loss: 0.920620]\n",
      "epoch:8 step:8230 [D loss: 0.684394, acc.: 58.59%] [G loss: 0.935752]\n",
      "epoch:8 step:8231 [D loss: 0.673541, acc.: 60.16%] [G loss: 0.877719]\n",
      "epoch:8 step:8232 [D loss: 0.621166, acc.: 66.41%] [G loss: 0.885105]\n",
      "epoch:8 step:8233 [D loss: 0.640031, acc.: 63.28%] [G loss: 0.877009]\n",
      "epoch:8 step:8234 [D loss: 0.697262, acc.: 50.78%] [G loss: 0.829418]\n",
      "epoch:8 step:8235 [D loss: 0.726656, acc.: 46.09%] [G loss: 0.887740]\n",
      "epoch:8 step:8236 [D loss: 0.694337, acc.: 55.47%] [G loss: 0.817337]\n",
      "epoch:8 step:8237 [D loss: 0.682601, acc.: 56.25%] [G loss: 0.838597]\n",
      "epoch:8 step:8238 [D loss: 0.671640, acc.: 54.69%] [G loss: 0.933912]\n",
      "epoch:8 step:8239 [D loss: 0.636308, acc.: 64.06%] [G loss: 0.923331]\n",
      "epoch:8 step:8240 [D loss: 0.647875, acc.: 62.50%] [G loss: 0.915079]\n",
      "epoch:8 step:8241 [D loss: 0.699525, acc.: 54.69%] [G loss: 0.842841]\n",
      "epoch:8 step:8242 [D loss: 0.644637, acc.: 62.50%] [G loss: 0.873809]\n",
      "epoch:8 step:8243 [D loss: 0.640811, acc.: 62.50%] [G loss: 0.873110]\n",
      "epoch:8 step:8244 [D loss: 0.674389, acc.: 55.47%] [G loss: 0.813529]\n",
      "epoch:8 step:8245 [D loss: 0.679777, acc.: 60.94%] [G loss: 0.864052]\n",
      "epoch:8 step:8246 [D loss: 0.665220, acc.: 58.59%] [G loss: 0.906714]\n",
      "epoch:8 step:8247 [D loss: 0.587350, acc.: 70.31%] [G loss: 0.884543]\n",
      "epoch:8 step:8248 [D loss: 0.675053, acc.: 62.50%] [G loss: 0.858407]\n",
      "epoch:8 step:8249 [D loss: 0.666504, acc.: 59.38%] [G loss: 0.843234]\n",
      "epoch:8 step:8250 [D loss: 0.628199, acc.: 64.06%] [G loss: 0.880877]\n",
      "epoch:8 step:8251 [D loss: 0.653389, acc.: 57.03%] [G loss: 0.959083]\n",
      "epoch:8 step:8252 [D loss: 0.639177, acc.: 60.16%] [G loss: 0.969590]\n",
      "epoch:8 step:8253 [D loss: 0.707958, acc.: 54.69%] [G loss: 0.869320]\n",
      "epoch:8 step:8254 [D loss: 0.690036, acc.: 57.03%] [G loss: 0.921332]\n",
      "epoch:8 step:8255 [D loss: 0.700924, acc.: 48.44%] [G loss: 0.862731]\n",
      "epoch:8 step:8256 [D loss: 0.687539, acc.: 52.34%] [G loss: 0.935912]\n",
      "epoch:8 step:8257 [D loss: 0.668092, acc.: 56.25%] [G loss: 0.864702]\n",
      "epoch:8 step:8258 [D loss: 0.673767, acc.: 59.38%] [G loss: 0.902713]\n",
      "epoch:8 step:8259 [D loss: 0.681574, acc.: 53.12%] [G loss: 0.884347]\n",
      "epoch:8 step:8260 [D loss: 0.665307, acc.: 52.34%] [G loss: 0.895654]\n",
      "epoch:8 step:8261 [D loss: 0.716970, acc.: 49.22%] [G loss: 0.818175]\n",
      "epoch:8 step:8262 [D loss: 0.672116, acc.: 58.59%] [G loss: 0.851587]\n",
      "epoch:8 step:8263 [D loss: 0.630665, acc.: 67.19%] [G loss: 0.842355]\n",
      "epoch:8 step:8264 [D loss: 0.709692, acc.: 58.59%] [G loss: 0.901180]\n",
      "epoch:8 step:8265 [D loss: 0.642220, acc.: 62.50%] [G loss: 0.976925]\n",
      "epoch:8 step:8266 [D loss: 0.633875, acc.: 59.38%] [G loss: 0.917843]\n",
      "epoch:8 step:8267 [D loss: 0.695086, acc.: 54.69%] [G loss: 0.943345]\n",
      "epoch:8 step:8268 [D loss: 0.703553, acc.: 46.88%] [G loss: 0.888067]\n",
      "epoch:8 step:8269 [D loss: 0.650235, acc.: 60.16%] [G loss: 0.914636]\n",
      "epoch:8 step:8270 [D loss: 0.738190, acc.: 49.22%] [G loss: 0.903385]\n",
      "epoch:8 step:8271 [D loss: 0.611028, acc.: 69.53%] [G loss: 0.926665]\n",
      "epoch:8 step:8272 [D loss: 0.693150, acc.: 49.22%] [G loss: 0.912176]\n",
      "epoch:8 step:8273 [D loss: 0.631284, acc.: 65.62%] [G loss: 0.942814]\n",
      "epoch:8 step:8274 [D loss: 0.672493, acc.: 60.94%] [G loss: 0.896709]\n",
      "epoch:8 step:8275 [D loss: 0.710783, acc.: 52.34%] [G loss: 0.911644]\n",
      "epoch:8 step:8276 [D loss: 0.657792, acc.: 56.25%] [G loss: 0.877630]\n",
      "epoch:8 step:8277 [D loss: 0.638057, acc.: 66.41%] [G loss: 0.938053]\n",
      "epoch:8 step:8278 [D loss: 0.563040, acc.: 74.22%] [G loss: 0.940727]\n",
      "epoch:8 step:8279 [D loss: 0.684235, acc.: 55.47%] [G loss: 0.910769]\n",
      "epoch:8 step:8280 [D loss: 0.745288, acc.: 45.31%] [G loss: 0.835969]\n",
      "epoch:8 step:8281 [D loss: 0.662071, acc.: 63.28%] [G loss: 0.846709]\n",
      "epoch:8 step:8282 [D loss: 0.577138, acc.: 76.56%] [G loss: 0.884792]\n",
      "epoch:8 step:8283 [D loss: 0.700308, acc.: 53.91%] [G loss: 0.871437]\n",
      "epoch:8 step:8284 [D loss: 0.679106, acc.: 55.47%] [G loss: 0.886586]\n",
      "epoch:8 step:8285 [D loss: 0.659688, acc.: 60.94%] [G loss: 0.854211]\n",
      "epoch:8 step:8286 [D loss: 0.651198, acc.: 64.84%] [G loss: 0.906830]\n",
      "epoch:8 step:8287 [D loss: 0.731819, acc.: 47.66%] [G loss: 0.928700]\n",
      "epoch:8 step:8288 [D loss: 0.612368, acc.: 68.75%] [G loss: 0.932027]\n",
      "epoch:8 step:8289 [D loss: 0.597110, acc.: 67.19%] [G loss: 0.912037]\n",
      "epoch:8 step:8290 [D loss: 0.721189, acc.: 50.00%] [G loss: 0.929583]\n",
      "epoch:8 step:8291 [D loss: 0.664305, acc.: 62.50%] [G loss: 0.909906]\n",
      "epoch:8 step:8292 [D loss: 0.635455, acc.: 64.06%] [G loss: 0.903541]\n",
      "epoch:8 step:8293 [D loss: 0.658169, acc.: 59.38%] [G loss: 0.900488]\n",
      "epoch:8 step:8294 [D loss: 0.646230, acc.: 59.38%] [G loss: 0.871965]\n",
      "epoch:8 step:8295 [D loss: 0.627314, acc.: 66.41%] [G loss: 0.908982]\n",
      "epoch:8 step:8296 [D loss: 0.699692, acc.: 57.03%] [G loss: 0.948230]\n",
      "epoch:8 step:8297 [D loss: 0.655061, acc.: 60.16%] [G loss: 0.915062]\n",
      "epoch:8 step:8298 [D loss: 0.618153, acc.: 65.62%] [G loss: 0.969230]\n",
      "epoch:8 step:8299 [D loss: 0.688520, acc.: 56.25%] [G loss: 0.953640]\n",
      "epoch:8 step:8300 [D loss: 0.705596, acc.: 57.03%] [G loss: 0.948567]\n",
      "epoch:8 step:8301 [D loss: 0.651337, acc.: 63.28%] [G loss: 0.873897]\n",
      "epoch:8 step:8302 [D loss: 0.652814, acc.: 66.41%] [G loss: 0.866867]\n",
      "epoch:8 step:8303 [D loss: 0.620158, acc.: 67.97%] [G loss: 0.908012]\n",
      "epoch:8 step:8304 [D loss: 0.668323, acc.: 60.94%] [G loss: 0.860518]\n",
      "epoch:8 step:8305 [D loss: 0.713662, acc.: 49.22%] [G loss: 0.893460]\n",
      "epoch:8 step:8306 [D loss: 0.668105, acc.: 58.59%] [G loss: 0.868645]\n",
      "epoch:8 step:8307 [D loss: 0.710436, acc.: 53.12%] [G loss: 0.860909]\n",
      "epoch:8 step:8308 [D loss: 0.677705, acc.: 55.47%] [G loss: 0.872244]\n",
      "epoch:8 step:8309 [D loss: 0.655472, acc.: 56.25%] [G loss: 0.892534]\n",
      "epoch:8 step:8310 [D loss: 0.731043, acc.: 49.22%] [G loss: 0.890842]\n",
      "epoch:8 step:8311 [D loss: 0.652563, acc.: 60.94%] [G loss: 1.020788]\n",
      "epoch:8 step:8312 [D loss: 0.672621, acc.: 60.16%] [G loss: 0.963158]\n",
      "epoch:8 step:8313 [D loss: 0.659164, acc.: 58.59%] [G loss: 0.939232]\n",
      "epoch:8 step:8314 [D loss: 0.710538, acc.: 53.12%] [G loss: 0.924111]\n",
      "epoch:8 step:8315 [D loss: 0.675766, acc.: 64.06%] [G loss: 0.924791]\n",
      "epoch:8 step:8316 [D loss: 0.728265, acc.: 53.12%] [G loss: 0.869854]\n",
      "epoch:8 step:8317 [D loss: 0.667698, acc.: 62.50%] [G loss: 0.928403]\n",
      "epoch:8 step:8318 [D loss: 0.645382, acc.: 63.28%] [G loss: 0.866770]\n",
      "epoch:8 step:8319 [D loss: 0.671526, acc.: 60.16%] [G loss: 0.972001]\n",
      "epoch:8 step:8320 [D loss: 0.706008, acc.: 54.69%] [G loss: 0.848298]\n",
      "epoch:8 step:8321 [D loss: 0.640500, acc.: 62.50%] [G loss: 0.892404]\n",
      "epoch:8 step:8322 [D loss: 0.676568, acc.: 57.81%] [G loss: 0.931684]\n",
      "epoch:8 step:8323 [D loss: 0.701949, acc.: 55.47%] [G loss: 0.917961]\n",
      "epoch:8 step:8324 [D loss: 0.729505, acc.: 50.00%] [G loss: 0.913233]\n",
      "epoch:8 step:8325 [D loss: 0.696564, acc.: 54.69%] [G loss: 0.959797]\n",
      "epoch:8 step:8326 [D loss: 0.643705, acc.: 63.28%] [G loss: 0.896050]\n",
      "epoch:8 step:8327 [D loss: 0.675393, acc.: 55.47%] [G loss: 0.842145]\n",
      "epoch:8 step:8328 [D loss: 0.619371, acc.: 67.19%] [G loss: 0.897090]\n",
      "epoch:8 step:8329 [D loss: 0.635375, acc.: 67.19%] [G loss: 0.870718]\n",
      "epoch:8 step:8330 [D loss: 0.653855, acc.: 60.94%] [G loss: 0.854902]\n",
      "epoch:8 step:8331 [D loss: 0.658528, acc.: 64.06%] [G loss: 0.832184]\n",
      "epoch:8 step:8332 [D loss: 0.638030, acc.: 64.84%] [G loss: 0.866479]\n",
      "epoch:8 step:8333 [D loss: 0.621173, acc.: 64.84%] [G loss: 0.872984]\n",
      "epoch:8 step:8334 [D loss: 0.615395, acc.: 63.28%] [G loss: 0.947127]\n",
      "epoch:8 step:8335 [D loss: 0.702337, acc.: 54.69%] [G loss: 0.934077]\n",
      "epoch:8 step:8336 [D loss: 0.665566, acc.: 58.59%] [G loss: 0.924815]\n",
      "epoch:8 step:8337 [D loss: 0.653533, acc.: 59.38%] [G loss: 0.896026]\n",
      "epoch:8 step:8338 [D loss: 0.598697, acc.: 69.53%] [G loss: 0.879396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8339 [D loss: 0.672768, acc.: 60.94%] [G loss: 0.926316]\n",
      "epoch:8 step:8340 [D loss: 0.650166, acc.: 59.38%] [G loss: 0.951104]\n",
      "epoch:8 step:8341 [D loss: 0.633969, acc.: 60.94%] [G loss: 0.900279]\n",
      "epoch:8 step:8342 [D loss: 0.631534, acc.: 61.72%] [G loss: 0.835190]\n",
      "epoch:8 step:8343 [D loss: 0.699365, acc.: 49.22%] [G loss: 0.834252]\n",
      "epoch:8 step:8344 [D loss: 0.672905, acc.: 60.16%] [G loss: 0.851524]\n",
      "epoch:8 step:8345 [D loss: 0.636355, acc.: 66.41%] [G loss: 0.777238]\n",
      "epoch:8 step:8346 [D loss: 0.690054, acc.: 54.69%] [G loss: 0.850208]\n",
      "epoch:8 step:8347 [D loss: 0.719678, acc.: 50.00%] [G loss: 0.861634]\n",
      "epoch:8 step:8348 [D loss: 0.619254, acc.: 61.72%] [G loss: 0.946571]\n",
      "epoch:8 step:8349 [D loss: 0.676137, acc.: 55.47%] [G loss: 0.959267]\n",
      "epoch:8 step:8350 [D loss: 0.667015, acc.: 60.94%] [G loss: 0.905775]\n",
      "epoch:8 step:8351 [D loss: 0.658362, acc.: 64.06%] [G loss: 0.924255]\n",
      "epoch:8 step:8352 [D loss: 0.674011, acc.: 56.25%] [G loss: 0.991701]\n",
      "epoch:8 step:8353 [D loss: 0.620711, acc.: 67.19%] [G loss: 0.903943]\n",
      "epoch:8 step:8354 [D loss: 0.737869, acc.: 50.78%] [G loss: 0.949578]\n",
      "epoch:8 step:8355 [D loss: 0.668085, acc.: 52.34%] [G loss: 0.923582]\n",
      "epoch:8 step:8356 [D loss: 0.646161, acc.: 62.50%] [G loss: 0.893449]\n",
      "epoch:8 step:8357 [D loss: 0.694658, acc.: 49.22%] [G loss: 0.880524]\n",
      "epoch:8 step:8358 [D loss: 0.692219, acc.: 60.16%] [G loss: 0.868794]\n",
      "epoch:8 step:8359 [D loss: 0.635510, acc.: 59.38%] [G loss: 0.895001]\n",
      "epoch:8 step:8360 [D loss: 0.671373, acc.: 62.50%] [G loss: 0.846639]\n",
      "epoch:8 step:8361 [D loss: 0.708323, acc.: 51.56%] [G loss: 0.881650]\n",
      "epoch:8 step:8362 [D loss: 0.675782, acc.: 58.59%] [G loss: 0.810638]\n",
      "epoch:8 step:8363 [D loss: 0.691139, acc.: 56.25%] [G loss: 0.861516]\n",
      "epoch:8 step:8364 [D loss: 0.633237, acc.: 59.38%] [G loss: 0.846741]\n",
      "epoch:8 step:8365 [D loss: 0.670025, acc.: 60.16%] [G loss: 0.899167]\n",
      "epoch:8 step:8366 [D loss: 0.630800, acc.: 62.50%] [G loss: 0.904321]\n",
      "epoch:8 step:8367 [D loss: 0.622627, acc.: 63.28%] [G loss: 0.889819]\n",
      "epoch:8 step:8368 [D loss: 0.628562, acc.: 68.75%] [G loss: 0.891218]\n",
      "epoch:8 step:8369 [D loss: 0.639750, acc.: 68.75%] [G loss: 0.863349]\n",
      "epoch:8 step:8370 [D loss: 0.656665, acc.: 60.16%] [G loss: 0.902508]\n",
      "epoch:8 step:8371 [D loss: 0.604142, acc.: 69.53%] [G loss: 0.909578]\n",
      "epoch:8 step:8372 [D loss: 0.725397, acc.: 51.56%] [G loss: 0.849171]\n",
      "epoch:8 step:8373 [D loss: 0.721030, acc.: 54.69%] [G loss: 0.836601]\n",
      "epoch:8 step:8374 [D loss: 0.695493, acc.: 50.00%] [G loss: 0.880515]\n",
      "epoch:8 step:8375 [D loss: 0.665152, acc.: 55.47%] [G loss: 0.882514]\n",
      "epoch:8 step:8376 [D loss: 0.656566, acc.: 63.28%] [G loss: 0.865989]\n",
      "epoch:8 step:8377 [D loss: 0.664971, acc.: 55.47%] [G loss: 0.906551]\n",
      "epoch:8 step:8378 [D loss: 0.663451, acc.: 63.28%] [G loss: 0.872013]\n",
      "epoch:8 step:8379 [D loss: 0.639425, acc.: 67.97%] [G loss: 0.928384]\n",
      "epoch:8 step:8380 [D loss: 0.594901, acc.: 70.31%] [G loss: 0.944517]\n",
      "epoch:8 step:8381 [D loss: 0.598354, acc.: 71.88%] [G loss: 1.001110]\n",
      "epoch:8 step:8382 [D loss: 0.580012, acc.: 70.31%] [G loss: 0.984188]\n",
      "epoch:8 step:8383 [D loss: 0.660304, acc.: 57.81%] [G loss: 0.971721]\n",
      "epoch:8 step:8384 [D loss: 0.647351, acc.: 61.72%] [G loss: 0.890075]\n",
      "epoch:8 step:8385 [D loss: 0.627900, acc.: 60.16%] [G loss: 0.908703]\n",
      "epoch:8 step:8386 [D loss: 0.661402, acc.: 63.28%] [G loss: 0.965256]\n",
      "epoch:8 step:8387 [D loss: 0.710973, acc.: 59.38%] [G loss: 0.849481]\n",
      "epoch:8 step:8388 [D loss: 0.671190, acc.: 63.28%] [G loss: 0.898205]\n",
      "epoch:8 step:8389 [D loss: 0.659998, acc.: 60.16%] [G loss: 0.896166]\n",
      "epoch:8 step:8390 [D loss: 0.593879, acc.: 73.44%] [G loss: 0.898785]\n",
      "epoch:8 step:8391 [D loss: 0.647443, acc.: 60.16%] [G loss: 0.901933]\n",
      "epoch:8 step:8392 [D loss: 0.661140, acc.: 60.94%] [G loss: 0.977714]\n",
      "epoch:8 step:8393 [D loss: 0.609849, acc.: 71.88%] [G loss: 0.976334]\n",
      "epoch:8 step:8394 [D loss: 0.603143, acc.: 70.31%] [G loss: 0.881475]\n",
      "epoch:8 step:8395 [D loss: 0.642985, acc.: 60.16%] [G loss: 0.950903]\n",
      "epoch:8 step:8396 [D loss: 0.669075, acc.: 64.84%] [G loss: 0.966683]\n",
      "epoch:8 step:8397 [D loss: 0.658536, acc.: 64.06%] [G loss: 0.915277]\n",
      "epoch:8 step:8398 [D loss: 0.676564, acc.: 54.69%] [G loss: 0.870578]\n",
      "epoch:8 step:8399 [D loss: 0.677283, acc.: 54.69%] [G loss: 0.846052]\n",
      "epoch:8 step:8400 [D loss: 0.687506, acc.: 54.69%] [G loss: 0.951839]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.631983\n",
      "FID: 13.962054\n",
      "0 = 11.887706751060511\n",
      "1 = 0.06198191489743623\n",
      "2 = 0.9325000047683716\n",
      "3 = 0.8802000284194946\n",
      "4 = 0.9847999811172485\n",
      "5 = 0.9830243587493896\n",
      "6 = 0.8802000284194946\n",
      "7 = 6.582434171140179\n",
      "8 = 0.08126912992195429\n",
      "9 = 0.7498499751091003\n",
      "10 = 0.7232000231742859\n",
      "11 = 0.7764999866485596\n",
      "12 = 0.7639167904853821\n",
      "13 = 0.7232000231742859\n",
      "14 = 7.632057189941406\n",
      "15 = 9.560763359069824\n",
      "16 = 0.10889655351638794\n",
      "17 = 7.631983280181885\n",
      "18 = 13.962054252624512\n",
      "epoch:8 step:8401 [D loss: 0.625213, acc.: 64.84%] [G loss: 0.891583]\n",
      "epoch:8 step:8402 [D loss: 0.615556, acc.: 67.97%] [G loss: 0.948662]\n",
      "epoch:8 step:8403 [D loss: 0.658960, acc.: 54.69%] [G loss: 0.933701]\n",
      "epoch:8 step:8404 [D loss: 0.670682, acc.: 55.47%] [G loss: 0.898955]\n",
      "epoch:8 step:8405 [D loss: 0.605254, acc.: 73.44%] [G loss: 0.897466]\n",
      "epoch:8 step:8406 [D loss: 0.652669, acc.: 61.72%] [G loss: 0.836590]\n",
      "epoch:8 step:8407 [D loss: 0.684068, acc.: 61.72%] [G loss: 0.927230]\n",
      "epoch:8 step:8408 [D loss: 0.621060, acc.: 68.75%] [G loss: 0.871916]\n",
      "epoch:8 step:8409 [D loss: 0.664870, acc.: 60.94%] [G loss: 0.917082]\n",
      "epoch:8 step:8410 [D loss: 0.631794, acc.: 64.06%] [G loss: 0.887581]\n",
      "epoch:8 step:8411 [D loss: 0.694916, acc.: 48.44%] [G loss: 0.945807]\n",
      "epoch:8 step:8412 [D loss: 0.702745, acc.: 53.12%] [G loss: 0.932861]\n",
      "epoch:8 step:8413 [D loss: 0.691628, acc.: 56.25%] [G loss: 0.915951]\n",
      "epoch:8 step:8414 [D loss: 0.624147, acc.: 64.06%] [G loss: 0.942691]\n",
      "epoch:8 step:8415 [D loss: 0.594822, acc.: 69.53%] [G loss: 0.995817]\n",
      "epoch:8 step:8416 [D loss: 0.765213, acc.: 48.44%] [G loss: 0.932839]\n",
      "epoch:8 step:8417 [D loss: 0.650216, acc.: 57.81%] [G loss: 0.843698]\n",
      "epoch:8 step:8418 [D loss: 0.664474, acc.: 63.28%] [G loss: 0.888803]\n",
      "epoch:8 step:8419 [D loss: 0.623251, acc.: 67.97%] [G loss: 0.885524]\n",
      "epoch:8 step:8420 [D loss: 0.572046, acc.: 71.09%] [G loss: 0.889837]\n",
      "epoch:8 step:8421 [D loss: 0.583759, acc.: 73.44%] [G loss: 0.988896]\n",
      "epoch:8 step:8422 [D loss: 0.625935, acc.: 69.53%] [G loss: 0.981665]\n",
      "epoch:8 step:8423 [D loss: 0.600014, acc.: 70.31%] [G loss: 1.002917]\n",
      "epoch:8 step:8424 [D loss: 0.746334, acc.: 54.69%] [G loss: 0.998969]\n",
      "epoch:8 step:8425 [D loss: 0.541028, acc.: 78.91%] [G loss: 1.120497]\n",
      "epoch:8 step:8426 [D loss: 0.606347, acc.: 62.50%] [G loss: 1.017278]\n",
      "epoch:8 step:8427 [D loss: 0.708090, acc.: 54.69%] [G loss: 0.913963]\n",
      "epoch:8 step:8428 [D loss: 0.718285, acc.: 59.38%] [G loss: 0.984196]\n",
      "epoch:8 step:8429 [D loss: 0.605587, acc.: 71.09%] [G loss: 0.963810]\n",
      "epoch:8 step:8430 [D loss: 0.616253, acc.: 67.97%] [G loss: 0.960856]\n",
      "epoch:8 step:8431 [D loss: 0.597743, acc.: 69.53%] [G loss: 1.039878]\n",
      "epoch:8 step:8432 [D loss: 0.571631, acc.: 76.56%] [G loss: 0.981503]\n",
      "epoch:8 step:8433 [D loss: 0.629089, acc.: 63.28%] [G loss: 1.041375]\n",
      "epoch:9 step:8434 [D loss: 0.643846, acc.: 64.06%] [G loss: 1.035520]\n",
      "epoch:9 step:8435 [D loss: 0.695118, acc.: 60.94%] [G loss: 0.928324]\n",
      "epoch:9 step:8436 [D loss: 0.689060, acc.: 54.69%] [G loss: 0.951339]\n",
      "epoch:9 step:8437 [D loss: 0.695810, acc.: 57.03%] [G loss: 0.940554]\n",
      "epoch:9 step:8438 [D loss: 0.672333, acc.: 60.16%] [G loss: 0.844417]\n",
      "epoch:9 step:8439 [D loss: 0.677996, acc.: 56.25%] [G loss: 0.875206]\n",
      "epoch:9 step:8440 [D loss: 0.602316, acc.: 68.75%] [G loss: 0.896258]\n",
      "epoch:9 step:8441 [D loss: 0.672868, acc.: 56.25%] [G loss: 0.865104]\n",
      "epoch:9 step:8442 [D loss: 0.616485, acc.: 64.84%] [G loss: 0.861741]\n",
      "epoch:9 step:8443 [D loss: 0.626532, acc.: 65.62%] [G loss: 0.912884]\n",
      "epoch:9 step:8444 [D loss: 0.631259, acc.: 68.75%] [G loss: 0.929770]\n",
      "epoch:9 step:8445 [D loss: 0.661476, acc.: 58.59%] [G loss: 0.851738]\n",
      "epoch:9 step:8446 [D loss: 0.653281, acc.: 62.50%] [G loss: 0.910596]\n",
      "epoch:9 step:8447 [D loss: 0.631641, acc.: 61.72%] [G loss: 0.932483]\n",
      "epoch:9 step:8448 [D loss: 0.612192, acc.: 66.41%] [G loss: 0.925705]\n",
      "epoch:9 step:8449 [D loss: 0.629852, acc.: 64.06%] [G loss: 0.949459]\n",
      "epoch:9 step:8450 [D loss: 0.650050, acc.: 59.38%] [G loss: 0.926078]\n",
      "epoch:9 step:8451 [D loss: 0.656329, acc.: 62.50%] [G loss: 0.932136]\n",
      "epoch:9 step:8452 [D loss: 0.674134, acc.: 65.62%] [G loss: 0.979317]\n",
      "epoch:9 step:8453 [D loss: 0.760212, acc.: 47.66%] [G loss: 0.926142]\n",
      "epoch:9 step:8454 [D loss: 0.628765, acc.: 65.62%] [G loss: 0.941162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8455 [D loss: 0.585221, acc.: 67.19%] [G loss: 0.957883]\n",
      "epoch:9 step:8456 [D loss: 0.655970, acc.: 60.94%] [G loss: 0.904204]\n",
      "epoch:9 step:8457 [D loss: 0.646139, acc.: 63.28%] [G loss: 0.868088]\n",
      "epoch:9 step:8458 [D loss: 0.662254, acc.: 56.25%] [G loss: 0.925943]\n",
      "epoch:9 step:8459 [D loss: 0.689049, acc.: 57.81%] [G loss: 0.873985]\n",
      "epoch:9 step:8460 [D loss: 0.692588, acc.: 55.47%] [G loss: 0.888983]\n",
      "epoch:9 step:8461 [D loss: 0.650420, acc.: 62.50%] [G loss: 0.894487]\n",
      "epoch:9 step:8462 [D loss: 0.635774, acc.: 64.84%] [G loss: 0.887082]\n",
      "epoch:9 step:8463 [D loss: 0.660385, acc.: 62.50%] [G loss: 0.893729]\n",
      "epoch:9 step:8464 [D loss: 0.662617, acc.: 61.72%] [G loss: 0.855536]\n",
      "epoch:9 step:8465 [D loss: 0.662535, acc.: 59.38%] [G loss: 0.907790]\n",
      "epoch:9 step:8466 [D loss: 0.644312, acc.: 59.38%] [G loss: 0.934307]\n",
      "epoch:9 step:8467 [D loss: 0.653883, acc.: 55.47%] [G loss: 0.879571]\n",
      "epoch:9 step:8468 [D loss: 0.643418, acc.: 66.41%] [G loss: 0.919302]\n",
      "epoch:9 step:8469 [D loss: 0.565528, acc.: 75.78%] [G loss: 1.019948]\n",
      "epoch:9 step:8470 [D loss: 0.733601, acc.: 50.00%] [G loss: 0.915594]\n",
      "epoch:9 step:8471 [D loss: 0.768249, acc.: 46.88%] [G loss: 0.846828]\n",
      "epoch:9 step:8472 [D loss: 0.639432, acc.: 60.94%] [G loss: 0.836601]\n",
      "epoch:9 step:8473 [D loss: 0.639363, acc.: 63.28%] [G loss: 0.866341]\n",
      "epoch:9 step:8474 [D loss: 0.645982, acc.: 63.28%] [G loss: 0.876243]\n",
      "epoch:9 step:8475 [D loss: 0.634471, acc.: 66.41%] [G loss: 0.865112]\n",
      "epoch:9 step:8476 [D loss: 0.651624, acc.: 61.72%] [G loss: 0.918840]\n",
      "epoch:9 step:8477 [D loss: 0.680830, acc.: 53.91%] [G loss: 0.869971]\n",
      "epoch:9 step:8478 [D loss: 0.682736, acc.: 56.25%] [G loss: 0.910187]\n",
      "epoch:9 step:8479 [D loss: 0.647264, acc.: 61.72%] [G loss: 0.952759]\n",
      "epoch:9 step:8480 [D loss: 0.650725, acc.: 67.19%] [G loss: 0.893816]\n",
      "epoch:9 step:8481 [D loss: 0.609964, acc.: 64.06%] [G loss: 0.920433]\n",
      "epoch:9 step:8482 [D loss: 0.629415, acc.: 67.19%] [G loss: 0.930793]\n",
      "epoch:9 step:8483 [D loss: 0.705577, acc.: 48.44%] [G loss: 0.907997]\n",
      "epoch:9 step:8484 [D loss: 0.715357, acc.: 50.00%] [G loss: 0.870187]\n",
      "epoch:9 step:8485 [D loss: 0.633522, acc.: 64.84%] [G loss: 0.868605]\n",
      "epoch:9 step:8486 [D loss: 0.661371, acc.: 63.28%] [G loss: 0.961908]\n",
      "epoch:9 step:8487 [D loss: 0.637729, acc.: 64.84%] [G loss: 0.926592]\n",
      "epoch:9 step:8488 [D loss: 0.663760, acc.: 57.81%] [G loss: 0.879704]\n",
      "epoch:9 step:8489 [D loss: 0.638533, acc.: 66.41%] [G loss: 0.875823]\n",
      "epoch:9 step:8490 [D loss: 0.676049, acc.: 57.81%] [G loss: 0.897637]\n",
      "epoch:9 step:8491 [D loss: 0.721060, acc.: 51.56%] [G loss: 0.924944]\n",
      "epoch:9 step:8492 [D loss: 0.660061, acc.: 55.47%] [G loss: 0.917133]\n",
      "epoch:9 step:8493 [D loss: 0.710793, acc.: 53.12%] [G loss: 0.920117]\n",
      "epoch:9 step:8494 [D loss: 0.651814, acc.: 62.50%] [G loss: 0.846335]\n",
      "epoch:9 step:8495 [D loss: 0.668136, acc.: 53.91%] [G loss: 0.922126]\n",
      "epoch:9 step:8496 [D loss: 0.673096, acc.: 53.91%] [G loss: 0.910488]\n",
      "epoch:9 step:8497 [D loss: 0.669766, acc.: 61.72%] [G loss: 0.901789]\n",
      "epoch:9 step:8498 [D loss: 0.651525, acc.: 56.25%] [G loss: 0.923949]\n",
      "epoch:9 step:8499 [D loss: 0.644382, acc.: 60.94%] [G loss: 0.883309]\n",
      "epoch:9 step:8500 [D loss: 0.634189, acc.: 67.19%] [G loss: 0.834258]\n",
      "epoch:9 step:8501 [D loss: 0.668275, acc.: 59.38%] [G loss: 0.831094]\n",
      "epoch:9 step:8502 [D loss: 0.627228, acc.: 66.41%] [G loss: 0.945832]\n",
      "epoch:9 step:8503 [D loss: 0.645853, acc.: 66.41%] [G loss: 0.912520]\n",
      "epoch:9 step:8504 [D loss: 0.704225, acc.: 52.34%] [G loss: 0.900909]\n",
      "epoch:9 step:8505 [D loss: 0.656673, acc.: 64.06%] [G loss: 0.924519]\n",
      "epoch:9 step:8506 [D loss: 0.672931, acc.: 57.03%] [G loss: 0.901735]\n",
      "epoch:9 step:8507 [D loss: 0.623001, acc.: 67.97%] [G loss: 0.882246]\n",
      "epoch:9 step:8508 [D loss: 0.629391, acc.: 64.06%] [G loss: 0.900255]\n",
      "epoch:9 step:8509 [D loss: 0.611972, acc.: 65.62%] [G loss: 0.920611]\n",
      "epoch:9 step:8510 [D loss: 0.620236, acc.: 63.28%] [G loss: 0.944779]\n",
      "epoch:9 step:8511 [D loss: 0.712234, acc.: 53.91%] [G loss: 0.911054]\n",
      "epoch:9 step:8512 [D loss: 0.658433, acc.: 65.62%] [G loss: 0.891132]\n",
      "epoch:9 step:8513 [D loss: 0.638704, acc.: 61.72%] [G loss: 0.875741]\n",
      "epoch:9 step:8514 [D loss: 0.713101, acc.: 52.34%] [G loss: 0.863032]\n",
      "epoch:9 step:8515 [D loss: 0.627341, acc.: 64.84%] [G loss: 0.840903]\n",
      "epoch:9 step:8516 [D loss: 0.650448, acc.: 60.94%] [G loss: 0.965439]\n",
      "epoch:9 step:8517 [D loss: 0.610189, acc.: 67.19%] [G loss: 0.936452]\n",
      "epoch:9 step:8518 [D loss: 0.659079, acc.: 59.38%] [G loss: 0.901298]\n",
      "epoch:9 step:8519 [D loss: 0.686981, acc.: 60.94%] [G loss: 0.919217]\n",
      "epoch:9 step:8520 [D loss: 0.629139, acc.: 64.84%] [G loss: 0.860271]\n",
      "epoch:9 step:8521 [D loss: 0.613723, acc.: 67.97%] [G loss: 0.931533]\n",
      "epoch:9 step:8522 [D loss: 0.682353, acc.: 59.38%] [G loss: 0.878349]\n",
      "epoch:9 step:8523 [D loss: 0.620236, acc.: 64.06%] [G loss: 0.903730]\n",
      "epoch:9 step:8524 [D loss: 0.617814, acc.: 67.97%] [G loss: 0.914936]\n",
      "epoch:9 step:8525 [D loss: 0.649728, acc.: 60.94%] [G loss: 0.902582]\n",
      "epoch:9 step:8526 [D loss: 0.643746, acc.: 59.38%] [G loss: 0.869561]\n",
      "epoch:9 step:8527 [D loss: 0.698474, acc.: 59.38%] [G loss: 0.941389]\n",
      "epoch:9 step:8528 [D loss: 0.648649, acc.: 60.94%] [G loss: 0.939193]\n",
      "epoch:9 step:8529 [D loss: 0.622784, acc.: 64.84%] [G loss: 0.919994]\n",
      "epoch:9 step:8530 [D loss: 0.611946, acc.: 67.97%] [G loss: 0.870657]\n",
      "epoch:9 step:8531 [D loss: 0.637421, acc.: 64.06%] [G loss: 0.932546]\n",
      "epoch:9 step:8532 [D loss: 0.646750, acc.: 60.94%] [G loss: 0.871056]\n",
      "epoch:9 step:8533 [D loss: 0.602328, acc.: 68.75%] [G loss: 0.928811]\n",
      "epoch:9 step:8534 [D loss: 0.685280, acc.: 56.25%] [G loss: 0.935489]\n",
      "epoch:9 step:8535 [D loss: 0.701477, acc.: 57.03%] [G loss: 0.917163]\n",
      "epoch:9 step:8536 [D loss: 0.649694, acc.: 57.03%] [G loss: 0.860062]\n",
      "epoch:9 step:8537 [D loss: 0.689192, acc.: 55.47%] [G loss: 0.820348]\n",
      "epoch:9 step:8538 [D loss: 0.679590, acc.: 56.25%] [G loss: 0.882132]\n",
      "epoch:9 step:8539 [D loss: 0.621139, acc.: 71.88%] [G loss: 0.901670]\n",
      "epoch:9 step:8540 [D loss: 0.611258, acc.: 69.53%] [G loss: 0.931705]\n",
      "epoch:9 step:8541 [D loss: 0.694111, acc.: 58.59%] [G loss: 0.919551]\n",
      "epoch:9 step:8542 [D loss: 0.723090, acc.: 49.22%] [G loss: 0.893802]\n",
      "epoch:9 step:8543 [D loss: 0.711427, acc.: 48.44%] [G loss: 0.870261]\n",
      "epoch:9 step:8544 [D loss: 0.620666, acc.: 67.97%] [G loss: 0.860722]\n",
      "epoch:9 step:8545 [D loss: 0.632062, acc.: 60.94%] [G loss: 0.875532]\n",
      "epoch:9 step:8546 [D loss: 0.623819, acc.: 66.41%] [G loss: 0.971391]\n",
      "epoch:9 step:8547 [D loss: 0.630448, acc.: 71.09%] [G loss: 0.943266]\n",
      "epoch:9 step:8548 [D loss: 0.622386, acc.: 65.62%] [G loss: 0.958972]\n",
      "epoch:9 step:8549 [D loss: 0.581323, acc.: 68.75%] [G loss: 0.948040]\n",
      "epoch:9 step:8550 [D loss: 0.619180, acc.: 67.19%] [G loss: 0.952696]\n",
      "epoch:9 step:8551 [D loss: 0.700150, acc.: 53.12%] [G loss: 0.900840]\n",
      "epoch:9 step:8552 [D loss: 0.564856, acc.: 71.88%] [G loss: 0.979923]\n",
      "epoch:9 step:8553 [D loss: 0.716538, acc.: 52.34%] [G loss: 0.970870]\n",
      "epoch:9 step:8554 [D loss: 0.691378, acc.: 57.03%] [G loss: 0.898733]\n",
      "epoch:9 step:8555 [D loss: 0.617162, acc.: 71.09%] [G loss: 0.927247]\n",
      "epoch:9 step:8556 [D loss: 0.659211, acc.: 57.81%] [G loss: 0.988434]\n",
      "epoch:9 step:8557 [D loss: 0.664749, acc.: 62.50%] [G loss: 0.865514]\n",
      "epoch:9 step:8558 [D loss: 0.695355, acc.: 59.38%] [G loss: 0.848389]\n",
      "epoch:9 step:8559 [D loss: 0.611710, acc.: 67.97%] [G loss: 0.826611]\n",
      "epoch:9 step:8560 [D loss: 0.709462, acc.: 52.34%] [G loss: 0.971745]\n",
      "epoch:9 step:8561 [D loss: 0.674677, acc.: 57.81%] [G loss: 0.851510]\n",
      "epoch:9 step:8562 [D loss: 0.667098, acc.: 58.59%] [G loss: 0.880551]\n",
      "epoch:9 step:8563 [D loss: 0.645620, acc.: 62.50%] [G loss: 0.866308]\n",
      "epoch:9 step:8564 [D loss: 0.637650, acc.: 63.28%] [G loss: 0.851169]\n",
      "epoch:9 step:8565 [D loss: 0.703090, acc.: 53.12%] [G loss: 0.898483]\n",
      "epoch:9 step:8566 [D loss: 0.740652, acc.: 47.66%] [G loss: 0.912073]\n",
      "epoch:9 step:8567 [D loss: 0.696964, acc.: 54.69%] [G loss: 0.903719]\n",
      "epoch:9 step:8568 [D loss: 0.630351, acc.: 60.94%] [G loss: 0.941912]\n",
      "epoch:9 step:8569 [D loss: 0.682116, acc.: 56.25%] [G loss: 0.937198]\n",
      "epoch:9 step:8570 [D loss: 0.665092, acc.: 55.47%] [G loss: 0.831362]\n",
      "epoch:9 step:8571 [D loss: 0.660155, acc.: 63.28%] [G loss: 0.932050]\n",
      "epoch:9 step:8572 [D loss: 0.689710, acc.: 60.16%] [G loss: 0.813510]\n",
      "epoch:9 step:8573 [D loss: 0.691271, acc.: 58.59%] [G loss: 0.883762]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8574 [D loss: 0.655125, acc.: 65.62%] [G loss: 0.806632]\n",
      "epoch:9 step:8575 [D loss: 0.657158, acc.: 60.94%] [G loss: 0.847588]\n",
      "epoch:9 step:8576 [D loss: 0.678678, acc.: 53.12%] [G loss: 0.934325]\n",
      "epoch:9 step:8577 [D loss: 0.642597, acc.: 65.62%] [G loss: 0.889716]\n",
      "epoch:9 step:8578 [D loss: 0.626998, acc.: 63.28%] [G loss: 0.905849]\n",
      "epoch:9 step:8579 [D loss: 0.670825, acc.: 60.94%] [G loss: 0.836964]\n",
      "epoch:9 step:8580 [D loss: 0.708533, acc.: 53.12%] [G loss: 0.889883]\n",
      "epoch:9 step:8581 [D loss: 0.710982, acc.: 56.25%] [G loss: 0.884786]\n",
      "epoch:9 step:8582 [D loss: 0.651594, acc.: 61.72%] [G loss: 0.892713]\n",
      "epoch:9 step:8583 [D loss: 0.692097, acc.: 57.81%] [G loss: 0.924436]\n",
      "epoch:9 step:8584 [D loss: 0.592838, acc.: 73.44%] [G loss: 0.875139]\n",
      "epoch:9 step:8585 [D loss: 0.708169, acc.: 55.47%] [G loss: 0.945102]\n",
      "epoch:9 step:8586 [D loss: 0.681909, acc.: 59.38%] [G loss: 0.886493]\n",
      "epoch:9 step:8587 [D loss: 0.672291, acc.: 53.12%] [G loss: 0.887677]\n",
      "epoch:9 step:8588 [D loss: 0.632363, acc.: 66.41%] [G loss: 0.882476]\n",
      "epoch:9 step:8589 [D loss: 0.667647, acc.: 56.25%] [G loss: 0.830126]\n",
      "epoch:9 step:8590 [D loss: 0.642252, acc.: 63.28%] [G loss: 0.851243]\n",
      "epoch:9 step:8591 [D loss: 0.617373, acc.: 69.53%] [G loss: 0.889538]\n",
      "epoch:9 step:8592 [D loss: 0.631927, acc.: 61.72%] [G loss: 0.830857]\n",
      "epoch:9 step:8593 [D loss: 0.755032, acc.: 46.88%] [G loss: 0.811735]\n",
      "epoch:9 step:8594 [D loss: 0.641437, acc.: 61.72%] [G loss: 0.968220]\n",
      "epoch:9 step:8595 [D loss: 0.693331, acc.: 55.47%] [G loss: 0.922382]\n",
      "epoch:9 step:8596 [D loss: 0.638404, acc.: 64.06%] [G loss: 0.906819]\n",
      "epoch:9 step:8597 [D loss: 0.625515, acc.: 62.50%] [G loss: 0.907119]\n",
      "epoch:9 step:8598 [D loss: 0.662515, acc.: 54.69%] [G loss: 0.936164]\n",
      "epoch:9 step:8599 [D loss: 0.645236, acc.: 68.75%] [G loss: 0.947659]\n",
      "epoch:9 step:8600 [D loss: 0.686316, acc.: 53.12%] [G loss: 0.946838]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.991636\n",
      "FID: 7.571397\n",
      "0 = 11.779551507711437\n",
      "1 = 0.05623507831596863\n",
      "2 = 0.920199990272522\n",
      "3 = 0.8622000217437744\n",
      "4 = 0.9782000184059143\n",
      "5 = 0.9753393530845642\n",
      "6 = 0.8622000217437744\n",
      "7 = 5.923468390846266\n",
      "8 = 0.059844838423828345\n",
      "9 = 0.7207000255584717\n",
      "10 = 0.6876000165939331\n",
      "11 = 0.7537999749183655\n",
      "12 = 0.7363461256027222\n",
      "13 = 0.6876000165939331\n",
      "14 = 7.991705417633057\n",
      "15 = 9.60274887084961\n",
      "16 = 0.08993805199861526\n",
      "17 = 7.991636276245117\n",
      "18 = 7.571396827697754\n",
      "epoch:9 step:8601 [D loss: 0.649212, acc.: 62.50%] [G loss: 0.865324]\n",
      "epoch:9 step:8602 [D loss: 0.687518, acc.: 53.12%] [G loss: 0.850115]\n",
      "epoch:9 step:8603 [D loss: 0.680234, acc.: 62.50%] [G loss: 0.892340]\n",
      "epoch:9 step:8604 [D loss: 0.618909, acc.: 66.41%] [G loss: 0.893939]\n",
      "epoch:9 step:8605 [D loss: 0.653945, acc.: 58.59%] [G loss: 0.851427]\n",
      "epoch:9 step:8606 [D loss: 0.606809, acc.: 70.31%] [G loss: 0.902788]\n",
      "epoch:9 step:8607 [D loss: 0.694698, acc.: 55.47%] [G loss: 0.851330]\n",
      "epoch:9 step:8608 [D loss: 0.690002, acc.: 54.69%] [G loss: 0.863185]\n",
      "epoch:9 step:8609 [D loss: 0.661177, acc.: 60.94%] [G loss: 0.874355]\n",
      "epoch:9 step:8610 [D loss: 0.652121, acc.: 65.62%] [G loss: 0.858870]\n",
      "epoch:9 step:8611 [D loss: 0.674221, acc.: 63.28%] [G loss: 0.867254]\n",
      "epoch:9 step:8612 [D loss: 0.694591, acc.: 54.69%] [G loss: 0.849017]\n",
      "epoch:9 step:8613 [D loss: 0.700729, acc.: 50.78%] [G loss: 0.839145]\n",
      "epoch:9 step:8614 [D loss: 0.669759, acc.: 57.03%] [G loss: 0.891702]\n",
      "epoch:9 step:8615 [D loss: 0.682373, acc.: 57.81%] [G loss: 0.884087]\n",
      "epoch:9 step:8616 [D loss: 0.671395, acc.: 65.62%] [G loss: 0.927030]\n",
      "epoch:9 step:8617 [D loss: 0.662060, acc.: 62.50%] [G loss: 0.861816]\n",
      "epoch:9 step:8618 [D loss: 0.708738, acc.: 53.91%] [G loss: 0.894623]\n",
      "epoch:9 step:8619 [D loss: 0.679084, acc.: 58.59%] [G loss: 0.835737]\n",
      "epoch:9 step:8620 [D loss: 0.668631, acc.: 64.06%] [G loss: 0.877109]\n",
      "epoch:9 step:8621 [D loss: 0.700718, acc.: 57.81%] [G loss: 0.834073]\n",
      "epoch:9 step:8622 [D loss: 0.694800, acc.: 60.94%] [G loss: 0.859649]\n",
      "epoch:9 step:8623 [D loss: 0.637942, acc.: 65.62%] [G loss: 0.843549]\n",
      "epoch:9 step:8624 [D loss: 0.635903, acc.: 64.84%] [G loss: 0.855189]\n",
      "epoch:9 step:8625 [D loss: 0.609655, acc.: 70.31%] [G loss: 0.917534]\n",
      "epoch:9 step:8626 [D loss: 0.643859, acc.: 58.59%] [G loss: 0.925229]\n",
      "epoch:9 step:8627 [D loss: 0.647348, acc.: 61.72%] [G loss: 0.954548]\n",
      "epoch:9 step:8628 [D loss: 0.649685, acc.: 60.16%] [G loss: 0.918780]\n",
      "epoch:9 step:8629 [D loss: 0.673870, acc.: 57.03%] [G loss: 0.925102]\n",
      "epoch:9 step:8630 [D loss: 0.613285, acc.: 68.75%] [G loss: 0.873912]\n",
      "epoch:9 step:8631 [D loss: 0.585482, acc.: 70.31%] [G loss: 0.891802]\n",
      "epoch:9 step:8632 [D loss: 0.607933, acc.: 66.41%] [G loss: 0.900066]\n",
      "epoch:9 step:8633 [D loss: 0.724707, acc.: 47.66%] [G loss: 0.891436]\n",
      "epoch:9 step:8634 [D loss: 0.675927, acc.: 53.91%] [G loss: 0.905713]\n",
      "epoch:9 step:8635 [D loss: 0.680358, acc.: 60.16%] [G loss: 0.870045]\n",
      "epoch:9 step:8636 [D loss: 0.711554, acc.: 55.47%] [G loss: 0.886751]\n",
      "epoch:9 step:8637 [D loss: 0.657468, acc.: 60.94%] [G loss: 0.912043]\n",
      "epoch:9 step:8638 [D loss: 0.678412, acc.: 53.91%] [G loss: 0.920002]\n",
      "epoch:9 step:8639 [D loss: 0.622163, acc.: 67.19%] [G loss: 0.912797]\n",
      "epoch:9 step:8640 [D loss: 0.598176, acc.: 74.22%] [G loss: 0.906138]\n",
      "epoch:9 step:8641 [D loss: 0.586829, acc.: 69.53%] [G loss: 0.878902]\n",
      "epoch:9 step:8642 [D loss: 0.583236, acc.: 73.44%] [G loss: 0.967153]\n",
      "epoch:9 step:8643 [D loss: 0.718302, acc.: 50.00%] [G loss: 0.906067]\n",
      "epoch:9 step:8644 [D loss: 0.658840, acc.: 60.16%] [G loss: 0.879415]\n",
      "epoch:9 step:8645 [D loss: 0.682121, acc.: 58.59%] [G loss: 0.831655]\n",
      "epoch:9 step:8646 [D loss: 0.685823, acc.: 53.91%] [G loss: 0.801359]\n",
      "epoch:9 step:8647 [D loss: 0.699854, acc.: 52.34%] [G loss: 0.823016]\n",
      "epoch:9 step:8648 [D loss: 0.729110, acc.: 47.66%] [G loss: 0.847815]\n",
      "epoch:9 step:8649 [D loss: 0.664069, acc.: 57.81%] [G loss: 0.872678]\n",
      "epoch:9 step:8650 [D loss: 0.633411, acc.: 61.72%] [G loss: 0.835349]\n",
      "epoch:9 step:8651 [D loss: 0.635315, acc.: 64.06%] [G loss: 0.883961]\n",
      "epoch:9 step:8652 [D loss: 0.636588, acc.: 63.28%] [G loss: 0.844696]\n",
      "epoch:9 step:8653 [D loss: 0.724175, acc.: 47.66%] [G loss: 0.904372]\n",
      "epoch:9 step:8654 [D loss: 0.611625, acc.: 66.41%] [G loss: 0.914248]\n",
      "epoch:9 step:8655 [D loss: 0.598380, acc.: 65.62%] [G loss: 1.050794]\n",
      "epoch:9 step:8656 [D loss: 0.576702, acc.: 66.41%] [G loss: 0.969681]\n",
      "epoch:9 step:8657 [D loss: 0.730562, acc.: 50.78%] [G loss: 0.941158]\n",
      "epoch:9 step:8658 [D loss: 0.695495, acc.: 50.00%] [G loss: 0.921487]\n",
      "epoch:9 step:8659 [D loss: 0.701306, acc.: 56.25%] [G loss: 0.901771]\n",
      "epoch:9 step:8660 [D loss: 0.652124, acc.: 57.81%] [G loss: 0.849755]\n",
      "epoch:9 step:8661 [D loss: 0.712909, acc.: 50.00%] [G loss: 0.804435]\n",
      "epoch:9 step:8662 [D loss: 0.637317, acc.: 66.41%] [G loss: 0.875475]\n",
      "epoch:9 step:8663 [D loss: 0.616605, acc.: 67.97%] [G loss: 0.885812]\n",
      "epoch:9 step:8664 [D loss: 0.569479, acc.: 69.53%] [G loss: 0.930683]\n",
      "epoch:9 step:8665 [D loss: 0.540230, acc.: 75.78%] [G loss: 0.970564]\n",
      "epoch:9 step:8666 [D loss: 0.687219, acc.: 58.59%] [G loss: 0.892223]\n",
      "epoch:9 step:8667 [D loss: 0.711274, acc.: 57.03%] [G loss: 0.881341]\n",
      "epoch:9 step:8668 [D loss: 0.652688, acc.: 57.81%] [G loss: 0.885496]\n",
      "epoch:9 step:8669 [D loss: 0.634407, acc.: 64.84%] [G loss: 0.898157]\n",
      "epoch:9 step:8670 [D loss: 0.655750, acc.: 66.41%] [G loss: 0.870346]\n",
      "epoch:9 step:8671 [D loss: 0.624684, acc.: 64.06%] [G loss: 0.866950]\n",
      "epoch:9 step:8672 [D loss: 0.667523, acc.: 57.03%] [G loss: 0.882150]\n",
      "epoch:9 step:8673 [D loss: 0.685396, acc.: 58.59%] [G loss: 0.916185]\n",
      "epoch:9 step:8674 [D loss: 0.659413, acc.: 63.28%] [G loss: 0.981781]\n",
      "epoch:9 step:8675 [D loss: 0.593643, acc.: 71.88%] [G loss: 0.964127]\n",
      "epoch:9 step:8676 [D loss: 0.651583, acc.: 59.38%] [G loss: 0.914046]\n",
      "epoch:9 step:8677 [D loss: 0.663075, acc.: 64.06%] [G loss: 0.875506]\n",
      "epoch:9 step:8678 [D loss: 0.644749, acc.: 60.16%] [G loss: 0.893636]\n",
      "epoch:9 step:8679 [D loss: 0.679561, acc.: 53.91%] [G loss: 0.901664]\n",
      "epoch:9 step:8680 [D loss: 0.647587, acc.: 61.72%] [G loss: 0.861778]\n",
      "epoch:9 step:8681 [D loss: 0.622199, acc.: 63.28%] [G loss: 0.907989]\n",
      "epoch:9 step:8682 [D loss: 0.755391, acc.: 42.97%] [G loss: 0.863757]\n",
      "epoch:9 step:8683 [D loss: 0.725484, acc.: 46.88%] [G loss: 0.829551]\n",
      "epoch:9 step:8684 [D loss: 0.661454, acc.: 59.38%] [G loss: 0.888647]\n",
      "epoch:9 step:8685 [D loss: 0.714096, acc.: 53.12%] [G loss: 0.893341]\n",
      "epoch:9 step:8686 [D loss: 0.674489, acc.: 58.59%] [G loss: 0.934585]\n",
      "epoch:9 step:8687 [D loss: 0.629404, acc.: 65.62%] [G loss: 0.945812]\n",
      "epoch:9 step:8688 [D loss: 0.636812, acc.: 60.16%] [G loss: 0.912248]\n",
      "epoch:9 step:8689 [D loss: 0.637503, acc.: 63.28%] [G loss: 0.952972]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8690 [D loss: 0.657407, acc.: 60.94%] [G loss: 0.938078]\n",
      "epoch:9 step:8691 [D loss: 0.633546, acc.: 65.62%] [G loss: 0.933407]\n",
      "epoch:9 step:8692 [D loss: 0.637454, acc.: 63.28%] [G loss: 0.870431]\n",
      "epoch:9 step:8693 [D loss: 0.676101, acc.: 55.47%] [G loss: 0.901739]\n",
      "epoch:9 step:8694 [D loss: 0.648450, acc.: 64.84%] [G loss: 0.855642]\n",
      "epoch:9 step:8695 [D loss: 0.607502, acc.: 67.97%] [G loss: 0.940998]\n",
      "epoch:9 step:8696 [D loss: 0.702285, acc.: 56.25%] [G loss: 0.843283]\n",
      "epoch:9 step:8697 [D loss: 0.634617, acc.: 64.06%] [G loss: 0.911205]\n",
      "epoch:9 step:8698 [D loss: 0.763665, acc.: 40.62%] [G loss: 0.907180]\n",
      "epoch:9 step:8699 [D loss: 0.676845, acc.: 59.38%] [G loss: 0.895993]\n",
      "epoch:9 step:8700 [D loss: 0.655554, acc.: 62.50%] [G loss: 0.897546]\n",
      "epoch:9 step:8701 [D loss: 0.625876, acc.: 67.19%] [G loss: 0.905861]\n",
      "epoch:9 step:8702 [D loss: 0.694611, acc.: 60.16%] [G loss: 0.918561]\n",
      "epoch:9 step:8703 [D loss: 0.661556, acc.: 58.59%] [G loss: 0.873734]\n",
      "epoch:9 step:8704 [D loss: 0.629427, acc.: 67.19%] [G loss: 0.942916]\n",
      "epoch:9 step:8705 [D loss: 0.670732, acc.: 61.72%] [G loss: 0.866520]\n",
      "epoch:9 step:8706 [D loss: 0.639003, acc.: 65.62%] [G loss: 0.944602]\n",
      "epoch:9 step:8707 [D loss: 0.668003, acc.: 54.69%] [G loss: 0.940060]\n",
      "epoch:9 step:8708 [D loss: 0.674129, acc.: 59.38%] [G loss: 1.023410]\n",
      "epoch:9 step:8709 [D loss: 0.639146, acc.: 67.19%] [G loss: 0.948188]\n",
      "epoch:9 step:8710 [D loss: 0.752912, acc.: 52.34%] [G loss: 0.837274]\n",
      "epoch:9 step:8711 [D loss: 0.677314, acc.: 56.25%] [G loss: 0.839572]\n",
      "epoch:9 step:8712 [D loss: 0.642792, acc.: 61.72%] [G loss: 0.909086]\n",
      "epoch:9 step:8713 [D loss: 0.618691, acc.: 68.75%] [G loss: 0.934594]\n",
      "epoch:9 step:8714 [D loss: 0.730449, acc.: 53.12%] [G loss: 0.899134]\n",
      "epoch:9 step:8715 [D loss: 0.652163, acc.: 57.03%] [G loss: 0.933581]\n",
      "epoch:9 step:8716 [D loss: 0.648479, acc.: 64.06%] [G loss: 0.927609]\n",
      "epoch:9 step:8717 [D loss: 0.647393, acc.: 58.59%] [G loss: 0.986500]\n",
      "epoch:9 step:8718 [D loss: 0.628754, acc.: 60.16%] [G loss: 0.825837]\n",
      "epoch:9 step:8719 [D loss: 0.678101, acc.: 61.72%] [G loss: 0.882636]\n",
      "epoch:9 step:8720 [D loss: 0.702156, acc.: 57.03%] [G loss: 0.901398]\n",
      "epoch:9 step:8721 [D loss: 0.661228, acc.: 58.59%] [G loss: 0.893637]\n",
      "epoch:9 step:8722 [D loss: 0.649970, acc.: 60.94%] [G loss: 0.866433]\n",
      "epoch:9 step:8723 [D loss: 0.659937, acc.: 61.72%] [G loss: 0.867296]\n",
      "epoch:9 step:8724 [D loss: 0.703577, acc.: 52.34%] [G loss: 0.846556]\n",
      "epoch:9 step:8725 [D loss: 0.612672, acc.: 67.97%] [G loss: 0.830611]\n",
      "epoch:9 step:8726 [D loss: 0.661933, acc.: 57.03%] [G loss: 0.813565]\n",
      "epoch:9 step:8727 [D loss: 0.696519, acc.: 53.12%] [G loss: 0.828020]\n",
      "epoch:9 step:8728 [D loss: 0.713548, acc.: 50.78%] [G loss: 0.810456]\n",
      "epoch:9 step:8729 [D loss: 0.661287, acc.: 59.38%] [G loss: 0.874455]\n",
      "epoch:9 step:8730 [D loss: 0.654221, acc.: 61.72%] [G loss: 0.912825]\n",
      "epoch:9 step:8731 [D loss: 0.619472, acc.: 69.53%] [G loss: 0.917155]\n",
      "epoch:9 step:8732 [D loss: 0.617107, acc.: 68.75%] [G loss: 0.932376]\n",
      "epoch:9 step:8733 [D loss: 0.628409, acc.: 67.97%] [G loss: 0.923122]\n",
      "epoch:9 step:8734 [D loss: 0.669928, acc.: 56.25%] [G loss: 0.943695]\n",
      "epoch:9 step:8735 [D loss: 0.611937, acc.: 69.53%] [G loss: 0.887247]\n",
      "epoch:9 step:8736 [D loss: 0.687974, acc.: 55.47%] [G loss: 0.855022]\n",
      "epoch:9 step:8737 [D loss: 0.621879, acc.: 65.62%] [G loss: 0.898163]\n",
      "epoch:9 step:8738 [D loss: 0.637413, acc.: 64.06%] [G loss: 0.933044]\n",
      "epoch:9 step:8739 [D loss: 0.620369, acc.: 64.84%] [G loss: 0.916719]\n",
      "epoch:9 step:8740 [D loss: 0.664293, acc.: 63.28%] [G loss: 0.948290]\n",
      "epoch:9 step:8741 [D loss: 0.646993, acc.: 63.28%] [G loss: 0.933856]\n",
      "epoch:9 step:8742 [D loss: 0.639991, acc.: 64.06%] [G loss: 0.947413]\n",
      "epoch:9 step:8743 [D loss: 0.619969, acc.: 70.31%] [G loss: 0.911820]\n",
      "epoch:9 step:8744 [D loss: 0.625442, acc.: 63.28%] [G loss: 0.908826]\n",
      "epoch:9 step:8745 [D loss: 0.627954, acc.: 63.28%] [G loss: 0.959668]\n",
      "epoch:9 step:8746 [D loss: 0.610889, acc.: 67.97%] [G loss: 0.935961]\n",
      "epoch:9 step:8747 [D loss: 0.579857, acc.: 67.19%] [G loss: 0.956211]\n",
      "epoch:9 step:8748 [D loss: 0.641981, acc.: 58.59%] [G loss: 1.003748]\n",
      "epoch:9 step:8749 [D loss: 0.751695, acc.: 48.44%] [G loss: 0.880606]\n",
      "epoch:9 step:8750 [D loss: 0.705358, acc.: 49.22%] [G loss: 0.883700]\n",
      "epoch:9 step:8751 [D loss: 0.672634, acc.: 57.81%] [G loss: 0.901626]\n",
      "epoch:9 step:8752 [D loss: 0.666313, acc.: 60.94%] [G loss: 0.928242]\n",
      "epoch:9 step:8753 [D loss: 0.625505, acc.: 66.41%] [G loss: 0.836100]\n",
      "epoch:9 step:8754 [D loss: 0.631347, acc.: 70.31%] [G loss: 0.929257]\n",
      "epoch:9 step:8755 [D loss: 0.677793, acc.: 57.03%] [G loss: 0.889507]\n",
      "epoch:9 step:8756 [D loss: 0.734176, acc.: 49.22%] [G loss: 0.879567]\n",
      "epoch:9 step:8757 [D loss: 0.645001, acc.: 64.06%] [G loss: 0.944815]\n",
      "epoch:9 step:8758 [D loss: 0.654855, acc.: 61.72%] [G loss: 0.872216]\n",
      "epoch:9 step:8759 [D loss: 0.658911, acc.: 66.41%] [G loss: 0.918221]\n",
      "epoch:9 step:8760 [D loss: 0.639766, acc.: 61.72%] [G loss: 0.986225]\n",
      "epoch:9 step:8761 [D loss: 0.644510, acc.: 64.06%] [G loss: 0.948740]\n",
      "epoch:9 step:8762 [D loss: 0.684926, acc.: 53.91%] [G loss: 0.907635]\n",
      "epoch:9 step:8763 [D loss: 0.692595, acc.: 57.03%] [G loss: 0.930418]\n",
      "epoch:9 step:8764 [D loss: 0.624381, acc.: 61.72%] [G loss: 0.882871]\n",
      "epoch:9 step:8765 [D loss: 0.662835, acc.: 60.16%] [G loss: 0.887477]\n",
      "epoch:9 step:8766 [D loss: 0.616299, acc.: 65.62%] [G loss: 0.913658]\n",
      "epoch:9 step:8767 [D loss: 0.641399, acc.: 63.28%] [G loss: 0.879112]\n",
      "epoch:9 step:8768 [D loss: 0.619819, acc.: 67.19%] [G loss: 0.941531]\n",
      "epoch:9 step:8769 [D loss: 0.636813, acc.: 58.59%] [G loss: 0.947899]\n",
      "epoch:9 step:8770 [D loss: 0.645531, acc.: 64.06%] [G loss: 0.937092]\n",
      "epoch:9 step:8771 [D loss: 0.627606, acc.: 64.84%] [G loss: 0.883617]\n",
      "epoch:9 step:8772 [D loss: 0.668760, acc.: 64.06%] [G loss: 0.909629]\n",
      "epoch:9 step:8773 [D loss: 0.632550, acc.: 65.62%] [G loss: 0.861260]\n",
      "epoch:9 step:8774 [D loss: 0.694591, acc.: 57.81%] [G loss: 0.889368]\n",
      "epoch:9 step:8775 [D loss: 0.673922, acc.: 57.81%] [G loss: 0.878222]\n",
      "epoch:9 step:8776 [D loss: 0.618856, acc.: 63.28%] [G loss: 0.951106]\n",
      "epoch:9 step:8777 [D loss: 0.611105, acc.: 64.84%] [G loss: 0.944360]\n",
      "epoch:9 step:8778 [D loss: 0.619644, acc.: 63.28%] [G loss: 0.934065]\n",
      "epoch:9 step:8779 [D loss: 0.586552, acc.: 66.41%] [G loss: 0.925542]\n",
      "epoch:9 step:8780 [D loss: 0.610958, acc.: 63.28%] [G loss: 0.937407]\n",
      "epoch:9 step:8781 [D loss: 0.733152, acc.: 53.91%] [G loss: 0.937722]\n",
      "epoch:9 step:8782 [D loss: 0.731348, acc.: 48.44%] [G loss: 0.849619]\n",
      "epoch:9 step:8783 [D loss: 0.629894, acc.: 64.84%] [G loss: 0.901393]\n",
      "epoch:9 step:8784 [D loss: 0.670507, acc.: 60.16%] [G loss: 0.909525]\n",
      "epoch:9 step:8785 [D loss: 0.684762, acc.: 54.69%] [G loss: 0.898407]\n",
      "epoch:9 step:8786 [D loss: 0.647248, acc.: 62.50%] [G loss: 0.942757]\n",
      "epoch:9 step:8787 [D loss: 0.617248, acc.: 66.41%] [G loss: 0.908147]\n",
      "epoch:9 step:8788 [D loss: 0.659384, acc.: 57.03%] [G loss: 0.926876]\n",
      "epoch:9 step:8789 [D loss: 0.684499, acc.: 58.59%] [G loss: 0.953580]\n",
      "epoch:9 step:8790 [D loss: 0.633956, acc.: 64.84%] [G loss: 0.928963]\n",
      "epoch:9 step:8791 [D loss: 0.599071, acc.: 64.84%] [G loss: 0.920371]\n",
      "epoch:9 step:8792 [D loss: 0.618287, acc.: 67.19%] [G loss: 0.908117]\n",
      "epoch:9 step:8793 [D loss: 0.636602, acc.: 62.50%] [G loss: 0.961591]\n",
      "epoch:9 step:8794 [D loss: 0.644196, acc.: 65.62%] [G loss: 0.992613]\n",
      "epoch:9 step:8795 [D loss: 0.660913, acc.: 64.06%] [G loss: 0.916521]\n",
      "epoch:9 step:8796 [D loss: 0.630161, acc.: 67.19%] [G loss: 0.902158]\n",
      "epoch:9 step:8797 [D loss: 0.618734, acc.: 62.50%] [G loss: 0.888739]\n",
      "epoch:9 step:8798 [D loss: 0.674913, acc.: 59.38%] [G loss: 0.903036]\n",
      "epoch:9 step:8799 [D loss: 0.643839, acc.: 64.84%] [G loss: 0.910452]\n",
      "epoch:9 step:8800 [D loss: 0.656861, acc.: 62.50%] [G loss: 0.905061]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.943303\n",
      "FID: 10.209697\n",
      "0 = 11.933303487205615\n",
      "1 = 0.05666271962649862\n",
      "2 = 0.9372000098228455\n",
      "3 = 0.8928999900817871\n",
      "4 = 0.9815000295639038\n",
      "5 = 0.979701578617096\n",
      "6 = 0.8928999900817871\n",
      "7 = 6.12505630099773\n",
      "8 = 0.06624448933264834\n",
      "9 = 0.728950023651123\n",
      "10 = 0.699400007724762\n",
      "11 = 0.7584999799728394\n",
      "12 = 0.7433308362960815\n",
      "13 = 0.699400007724762\n",
      "14 = 7.943367958068848\n",
      "15 = 9.60667610168457\n",
      "16 = 0.08966872096061707\n",
      "17 = 7.943302631378174\n",
      "18 = 10.209696769714355\n",
      "epoch:9 step:8801 [D loss: 0.643618, acc.: 66.41%] [G loss: 0.866071]\n",
      "epoch:9 step:8802 [D loss: 0.708067, acc.: 53.91%] [G loss: 0.915099]\n",
      "epoch:9 step:8803 [D loss: 0.660654, acc.: 59.38%] [G loss: 0.894402]\n",
      "epoch:9 step:8804 [D loss: 0.605105, acc.: 64.84%] [G loss: 0.919899]\n",
      "epoch:9 step:8805 [D loss: 0.641222, acc.: 65.62%] [G loss: 0.917612]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8806 [D loss: 0.707615, acc.: 53.91%] [G loss: 0.946727]\n",
      "epoch:9 step:8807 [D loss: 0.581900, acc.: 69.53%] [G loss: 1.034058]\n",
      "epoch:9 step:8808 [D loss: 0.658210, acc.: 63.28%] [G loss: 0.976833]\n",
      "epoch:9 step:8809 [D loss: 0.731388, acc.: 46.09%] [G loss: 0.818374]\n",
      "epoch:9 step:8810 [D loss: 0.724906, acc.: 52.34%] [G loss: 0.914336]\n",
      "epoch:9 step:8811 [D loss: 0.709270, acc.: 50.78%] [G loss: 0.889525]\n",
      "epoch:9 step:8812 [D loss: 0.644135, acc.: 57.03%] [G loss: 0.901771]\n",
      "epoch:9 step:8813 [D loss: 0.669054, acc.: 60.94%] [G loss: 0.880063]\n",
      "epoch:9 step:8814 [D loss: 0.612519, acc.: 70.31%] [G loss: 0.924780]\n",
      "epoch:9 step:8815 [D loss: 0.663983, acc.: 64.06%] [G loss: 0.883448]\n",
      "epoch:9 step:8816 [D loss: 0.652798, acc.: 62.50%] [G loss: 0.858289]\n",
      "epoch:9 step:8817 [D loss: 0.667873, acc.: 59.38%] [G loss: 0.910917]\n",
      "epoch:9 step:8818 [D loss: 0.608592, acc.: 67.97%] [G loss: 0.924891]\n",
      "epoch:9 step:8819 [D loss: 0.673976, acc.: 60.16%] [G loss: 0.940758]\n",
      "epoch:9 step:8820 [D loss: 0.649227, acc.: 61.72%] [G loss: 0.930737]\n",
      "epoch:9 step:8821 [D loss: 0.644266, acc.: 59.38%] [G loss: 0.929236]\n",
      "epoch:9 step:8822 [D loss: 0.672147, acc.: 57.81%] [G loss: 0.935073]\n",
      "epoch:9 step:8823 [D loss: 0.704126, acc.: 53.12%] [G loss: 0.888095]\n",
      "epoch:9 step:8824 [D loss: 0.637230, acc.: 65.62%] [G loss: 0.892434]\n",
      "epoch:9 step:8825 [D loss: 0.656666, acc.: 63.28%] [G loss: 0.868378]\n",
      "epoch:9 step:8826 [D loss: 0.682371, acc.: 54.69%] [G loss: 0.893396]\n",
      "epoch:9 step:8827 [D loss: 0.671893, acc.: 58.59%] [G loss: 0.874207]\n",
      "epoch:9 step:8828 [D loss: 0.675178, acc.: 57.03%] [G loss: 0.880896]\n",
      "epoch:9 step:8829 [D loss: 0.723856, acc.: 50.00%] [G loss: 0.855919]\n",
      "epoch:9 step:8830 [D loss: 0.631419, acc.: 61.72%] [G loss: 0.862833]\n",
      "epoch:9 step:8831 [D loss: 0.637120, acc.: 63.28%] [G loss: 0.933821]\n",
      "epoch:9 step:8832 [D loss: 0.630329, acc.: 65.62%] [G loss: 0.972742]\n",
      "epoch:9 step:8833 [D loss: 0.698422, acc.: 51.56%] [G loss: 0.912135]\n",
      "epoch:9 step:8834 [D loss: 0.674804, acc.: 55.47%] [G loss: 0.876978]\n",
      "epoch:9 step:8835 [D loss: 0.662527, acc.: 62.50%] [G loss: 0.896078]\n",
      "epoch:9 step:8836 [D loss: 0.684969, acc.: 60.16%] [G loss: 0.920260]\n",
      "epoch:9 step:8837 [D loss: 0.641042, acc.: 69.53%] [G loss: 0.945075]\n",
      "epoch:9 step:8838 [D loss: 0.624714, acc.: 67.19%] [G loss: 0.896015]\n",
      "epoch:9 step:8839 [D loss: 0.660564, acc.: 61.72%] [G loss: 0.927328]\n",
      "epoch:9 step:8840 [D loss: 0.681931, acc.: 57.03%] [G loss: 0.928562]\n",
      "epoch:9 step:8841 [D loss: 0.689487, acc.: 53.91%] [G loss: 0.940294]\n",
      "epoch:9 step:8842 [D loss: 0.640748, acc.: 61.72%] [G loss: 0.829639]\n",
      "epoch:9 step:8843 [D loss: 0.667013, acc.: 59.38%] [G loss: 0.859063]\n",
      "epoch:9 step:8844 [D loss: 0.657200, acc.: 55.47%] [G loss: 0.937009]\n",
      "epoch:9 step:8845 [D loss: 0.673658, acc.: 60.94%] [G loss: 0.863098]\n",
      "epoch:9 step:8846 [D loss: 0.668382, acc.: 62.50%] [G loss: 0.906022]\n",
      "epoch:9 step:8847 [D loss: 0.644074, acc.: 63.28%] [G loss: 0.983210]\n",
      "epoch:9 step:8848 [D loss: 0.634554, acc.: 67.19%] [G loss: 0.930185]\n",
      "epoch:9 step:8849 [D loss: 0.596497, acc.: 66.41%] [G loss: 0.961962]\n",
      "epoch:9 step:8850 [D loss: 0.658300, acc.: 57.03%] [G loss: 0.968458]\n",
      "epoch:9 step:8851 [D loss: 0.671060, acc.: 60.16%] [G loss: 0.815198]\n",
      "epoch:9 step:8852 [D loss: 0.666630, acc.: 65.62%] [G loss: 0.827808]\n",
      "epoch:9 step:8853 [D loss: 0.632909, acc.: 60.16%] [G loss: 0.861243]\n",
      "epoch:9 step:8854 [D loss: 0.739343, acc.: 50.00%] [G loss: 0.895169]\n",
      "epoch:9 step:8855 [D loss: 0.726112, acc.: 51.56%] [G loss: 0.881291]\n",
      "epoch:9 step:8856 [D loss: 0.684660, acc.: 60.94%] [G loss: 0.918117]\n",
      "epoch:9 step:8857 [D loss: 0.671696, acc.: 57.03%] [G loss: 0.916812]\n",
      "epoch:9 step:8858 [D loss: 0.634263, acc.: 66.41%] [G loss: 0.961002]\n",
      "epoch:9 step:8859 [D loss: 0.604969, acc.: 70.31%] [G loss: 0.916058]\n",
      "epoch:9 step:8860 [D loss: 0.667334, acc.: 59.38%] [G loss: 0.994292]\n",
      "epoch:9 step:8861 [D loss: 0.587235, acc.: 65.62%] [G loss: 0.958021]\n",
      "epoch:9 step:8862 [D loss: 0.666031, acc.: 60.16%] [G loss: 0.919478]\n",
      "epoch:9 step:8863 [D loss: 0.633643, acc.: 61.72%] [G loss: 0.902326]\n",
      "epoch:9 step:8864 [D loss: 0.660124, acc.: 63.28%] [G loss: 0.943014]\n",
      "epoch:9 step:8865 [D loss: 0.670760, acc.: 53.12%] [G loss: 0.864842]\n",
      "epoch:9 step:8866 [D loss: 0.714262, acc.: 53.91%] [G loss: 0.888913]\n",
      "epoch:9 step:8867 [D loss: 0.638256, acc.: 62.50%] [G loss: 0.931247]\n",
      "epoch:9 step:8868 [D loss: 0.595662, acc.: 68.75%] [G loss: 0.945284]\n",
      "epoch:9 step:8869 [D loss: 0.622406, acc.: 67.97%] [G loss: 0.939767]\n",
      "epoch:9 step:8870 [D loss: 0.740461, acc.: 49.22%] [G loss: 0.871675]\n",
      "epoch:9 step:8871 [D loss: 0.701814, acc.: 50.78%] [G loss: 0.853745]\n",
      "epoch:9 step:8872 [D loss: 0.673696, acc.: 57.81%] [G loss: 0.888457]\n",
      "epoch:9 step:8873 [D loss: 0.620256, acc.: 71.09%] [G loss: 0.935582]\n",
      "epoch:9 step:8874 [D loss: 0.618169, acc.: 66.41%] [G loss: 0.899663]\n",
      "epoch:9 step:8875 [D loss: 0.696527, acc.: 53.12%] [G loss: 0.975882]\n",
      "epoch:9 step:8876 [D loss: 0.674841, acc.: 61.72%] [G loss: 0.909411]\n",
      "epoch:9 step:8877 [D loss: 0.645345, acc.: 63.28%] [G loss: 0.881711]\n",
      "epoch:9 step:8878 [D loss: 0.649219, acc.: 59.38%] [G loss: 0.962242]\n",
      "epoch:9 step:8879 [D loss: 0.644403, acc.: 60.94%] [G loss: 0.898580]\n",
      "epoch:9 step:8880 [D loss: 0.612519, acc.: 67.19%] [G loss: 0.902342]\n",
      "epoch:9 step:8881 [D loss: 0.670191, acc.: 60.94%] [G loss: 0.901814]\n",
      "epoch:9 step:8882 [D loss: 0.670898, acc.: 57.81%] [G loss: 0.789284]\n",
      "epoch:9 step:8883 [D loss: 0.628036, acc.: 62.50%] [G loss: 0.865694]\n",
      "epoch:9 step:8884 [D loss: 0.633977, acc.: 62.50%] [G loss: 0.896577]\n",
      "epoch:9 step:8885 [D loss: 0.703391, acc.: 58.59%] [G loss: 0.929373]\n",
      "epoch:9 step:8886 [D loss: 0.640794, acc.: 67.19%] [G loss: 1.004932]\n",
      "epoch:9 step:8887 [D loss: 0.648763, acc.: 63.28%] [G loss: 1.005081]\n",
      "epoch:9 step:8888 [D loss: 0.713018, acc.: 50.00%] [G loss: 0.921482]\n",
      "epoch:9 step:8889 [D loss: 0.680690, acc.: 55.47%] [G loss: 0.943498]\n",
      "epoch:9 step:8890 [D loss: 0.666233, acc.: 60.16%] [G loss: 0.939157]\n",
      "epoch:9 step:8891 [D loss: 0.751603, acc.: 47.66%] [G loss: 0.880806]\n",
      "epoch:9 step:8892 [D loss: 0.681768, acc.: 54.69%] [G loss: 0.843042]\n",
      "epoch:9 step:8893 [D loss: 0.665635, acc.: 57.03%] [G loss: 0.898048]\n",
      "epoch:9 step:8894 [D loss: 0.697172, acc.: 53.91%] [G loss: 0.871315]\n",
      "epoch:9 step:8895 [D loss: 0.680522, acc.: 57.81%] [G loss: 0.813045]\n",
      "epoch:9 step:8896 [D loss: 0.679348, acc.: 58.59%] [G loss: 0.862941]\n",
      "epoch:9 step:8897 [D loss: 0.663946, acc.: 61.72%] [G loss: 0.847537]\n",
      "epoch:9 step:8898 [D loss: 0.674160, acc.: 57.81%] [G loss: 0.832645]\n",
      "epoch:9 step:8899 [D loss: 0.665287, acc.: 57.81%] [G loss: 0.869473]\n",
      "epoch:9 step:8900 [D loss: 0.638056, acc.: 67.97%] [G loss: 0.885544]\n",
      "epoch:9 step:8901 [D loss: 0.598125, acc.: 70.31%] [G loss: 0.925783]\n",
      "epoch:9 step:8902 [D loss: 0.629679, acc.: 65.62%] [G loss: 0.949748]\n",
      "epoch:9 step:8903 [D loss: 0.637965, acc.: 60.16%] [G loss: 0.963304]\n",
      "epoch:9 step:8904 [D loss: 0.589138, acc.: 69.53%] [G loss: 1.014533]\n",
      "epoch:9 step:8905 [D loss: 0.649078, acc.: 58.59%] [G loss: 1.071933]\n",
      "epoch:9 step:8906 [D loss: 0.760834, acc.: 51.56%] [G loss: 0.962863]\n",
      "epoch:9 step:8907 [D loss: 0.646984, acc.: 63.28%] [G loss: 0.917938]\n",
      "epoch:9 step:8908 [D loss: 0.621592, acc.: 66.41%] [G loss: 0.974115]\n",
      "epoch:9 step:8909 [D loss: 0.697819, acc.: 57.81%] [G loss: 0.989476]\n",
      "epoch:9 step:8910 [D loss: 0.744309, acc.: 46.88%] [G loss: 0.837102]\n",
      "epoch:9 step:8911 [D loss: 0.709178, acc.: 50.00%] [G loss: 0.831040]\n",
      "epoch:9 step:8912 [D loss: 0.669020, acc.: 59.38%] [G loss: 0.844370]\n",
      "epoch:9 step:8913 [D loss: 0.670915, acc.: 53.91%] [G loss: 0.882403]\n",
      "epoch:9 step:8914 [D loss: 0.599097, acc.: 69.53%] [G loss: 0.893664]\n",
      "epoch:9 step:8915 [D loss: 0.706179, acc.: 46.88%] [G loss: 0.903527]\n",
      "epoch:9 step:8916 [D loss: 0.683270, acc.: 57.81%] [G loss: 0.884674]\n",
      "epoch:9 step:8917 [D loss: 0.638921, acc.: 67.19%] [G loss: 0.890628]\n",
      "epoch:9 step:8918 [D loss: 0.648301, acc.: 61.72%] [G loss: 0.964986]\n",
      "epoch:9 step:8919 [D loss: 0.684624, acc.: 60.16%] [G loss: 0.902980]\n",
      "epoch:9 step:8920 [D loss: 0.654958, acc.: 60.16%] [G loss: 0.961735]\n",
      "epoch:9 step:8921 [D loss: 0.625590, acc.: 64.84%] [G loss: 0.924722]\n",
      "epoch:9 step:8922 [D loss: 0.677067, acc.: 60.94%] [G loss: 0.891226]\n",
      "epoch:9 step:8923 [D loss: 0.652417, acc.: 67.19%] [G loss: 0.922981]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8924 [D loss: 0.678121, acc.: 57.81%] [G loss: 0.921580]\n",
      "epoch:9 step:8925 [D loss: 0.705837, acc.: 53.91%] [G loss: 0.928790]\n",
      "epoch:9 step:8926 [D loss: 0.661846, acc.: 57.03%] [G loss: 0.954409]\n",
      "epoch:9 step:8927 [D loss: 0.673700, acc.: 61.72%] [G loss: 0.882113]\n",
      "epoch:9 step:8928 [D loss: 0.624730, acc.: 63.28%] [G loss: 0.881302]\n",
      "epoch:9 step:8929 [D loss: 0.655485, acc.: 60.94%] [G loss: 0.875147]\n",
      "epoch:9 step:8930 [D loss: 0.680880, acc.: 58.59%] [G loss: 0.917951]\n",
      "epoch:9 step:8931 [D loss: 0.618386, acc.: 63.28%] [G loss: 0.954671]\n",
      "epoch:9 step:8932 [D loss: 0.588548, acc.: 74.22%] [G loss: 0.967126]\n",
      "epoch:9 step:8933 [D loss: 0.736288, acc.: 50.78%] [G loss: 0.930235]\n",
      "epoch:9 step:8934 [D loss: 0.750651, acc.: 49.22%] [G loss: 0.947992]\n",
      "epoch:9 step:8935 [D loss: 0.689190, acc.: 53.91%] [G loss: 0.904722]\n",
      "epoch:9 step:8936 [D loss: 0.657573, acc.: 60.16%] [G loss: 0.951289]\n",
      "epoch:9 step:8937 [D loss: 0.606760, acc.: 67.97%] [G loss: 0.940223]\n",
      "epoch:9 step:8938 [D loss: 0.626688, acc.: 60.16%] [G loss: 1.024403]\n",
      "epoch:9 step:8939 [D loss: 0.611941, acc.: 65.62%] [G loss: 1.043355]\n",
      "epoch:9 step:8940 [D loss: 0.627028, acc.: 66.41%] [G loss: 0.960567]\n",
      "epoch:9 step:8941 [D loss: 0.574167, acc.: 68.75%] [G loss: 1.063474]\n",
      "epoch:9 step:8942 [D loss: 0.706820, acc.: 54.69%] [G loss: 0.960729]\n",
      "epoch:9 step:8943 [D loss: 0.694580, acc.: 57.03%] [G loss: 0.882824]\n",
      "epoch:9 step:8944 [D loss: 0.728296, acc.: 46.09%] [G loss: 0.836008]\n",
      "epoch:9 step:8945 [D loss: 0.672606, acc.: 54.69%] [G loss: 0.859129]\n",
      "epoch:9 step:8946 [D loss: 0.641824, acc.: 66.41%] [G loss: 0.875548]\n",
      "epoch:9 step:8947 [D loss: 0.616947, acc.: 64.06%] [G loss: 0.894670]\n",
      "epoch:9 step:8948 [D loss: 0.601305, acc.: 73.44%] [G loss: 0.925272]\n",
      "epoch:9 step:8949 [D loss: 0.647153, acc.: 61.72%] [G loss: 0.936860]\n",
      "epoch:9 step:8950 [D loss: 0.669701, acc.: 57.81%] [G loss: 0.876823]\n",
      "epoch:9 step:8951 [D loss: 0.629803, acc.: 62.50%] [G loss: 0.862132]\n",
      "epoch:9 step:8952 [D loss: 0.631919, acc.: 64.06%] [G loss: 0.883232]\n",
      "epoch:9 step:8953 [D loss: 0.613961, acc.: 67.19%] [G loss: 0.877092]\n",
      "epoch:9 step:8954 [D loss: 0.645376, acc.: 65.62%] [G loss: 0.944893]\n",
      "epoch:9 step:8955 [D loss: 0.654074, acc.: 64.06%] [G loss: 0.901974]\n",
      "epoch:9 step:8956 [D loss: 0.657259, acc.: 60.16%] [G loss: 0.892867]\n",
      "epoch:9 step:8957 [D loss: 0.690239, acc.: 55.47%] [G loss: 0.850343]\n",
      "epoch:9 step:8958 [D loss: 0.711652, acc.: 53.91%] [G loss: 0.862579]\n",
      "epoch:9 step:8959 [D loss: 0.636814, acc.: 65.62%] [G loss: 0.897552]\n",
      "epoch:9 step:8960 [D loss: 0.705567, acc.: 50.78%] [G loss: 0.930080]\n",
      "epoch:9 step:8961 [D loss: 0.703204, acc.: 50.78%] [G loss: 0.883596]\n",
      "epoch:9 step:8962 [D loss: 0.701716, acc.: 48.44%] [G loss: 0.924184]\n",
      "epoch:9 step:8963 [D loss: 0.619081, acc.: 67.19%] [G loss: 0.914075]\n",
      "epoch:9 step:8964 [D loss: 0.696019, acc.: 55.47%] [G loss: 0.902067]\n",
      "epoch:9 step:8965 [D loss: 0.706471, acc.: 52.34%] [G loss: 0.842667]\n",
      "epoch:9 step:8966 [D loss: 0.666262, acc.: 60.94%] [G loss: 0.886155]\n",
      "epoch:9 step:8967 [D loss: 0.635312, acc.: 60.94%] [G loss: 0.921558]\n",
      "epoch:9 step:8968 [D loss: 0.677967, acc.: 55.47%] [G loss: 0.890584]\n",
      "epoch:9 step:8969 [D loss: 0.646729, acc.: 60.16%] [G loss: 0.939479]\n",
      "epoch:9 step:8970 [D loss: 0.672000, acc.: 55.47%] [G loss: 0.924889]\n",
      "epoch:9 step:8971 [D loss: 0.666970, acc.: 57.81%] [G loss: 0.936477]\n",
      "epoch:9 step:8972 [D loss: 0.665773, acc.: 56.25%] [G loss: 0.923395]\n",
      "epoch:9 step:8973 [D loss: 0.650134, acc.: 62.50%] [G loss: 0.944121]\n",
      "epoch:9 step:8974 [D loss: 0.674375, acc.: 56.25%] [G loss: 0.886069]\n",
      "epoch:9 step:8975 [D loss: 0.752658, acc.: 48.44%] [G loss: 0.907266]\n",
      "epoch:9 step:8976 [D loss: 0.672821, acc.: 53.91%] [G loss: 0.872340]\n",
      "epoch:9 step:8977 [D loss: 0.669766, acc.: 56.25%] [G loss: 0.906588]\n",
      "epoch:9 step:8978 [D loss: 0.648562, acc.: 64.06%] [G loss: 0.851891]\n",
      "epoch:9 step:8979 [D loss: 0.623377, acc.: 67.19%] [G loss: 0.916962]\n",
      "epoch:9 step:8980 [D loss: 0.648309, acc.: 65.62%] [G loss: 0.886710]\n",
      "epoch:9 step:8981 [D loss: 0.628854, acc.: 64.06%] [G loss: 0.922306]\n",
      "epoch:9 step:8982 [D loss: 0.614854, acc.: 70.31%] [G loss: 0.914914]\n",
      "epoch:9 step:8983 [D loss: 0.623379, acc.: 70.31%] [G loss: 0.953579]\n",
      "epoch:9 step:8984 [D loss: 0.625839, acc.: 64.84%] [G loss: 0.943802]\n",
      "epoch:9 step:8985 [D loss: 0.613223, acc.: 67.97%] [G loss: 0.879437]\n",
      "epoch:9 step:8986 [D loss: 0.704580, acc.: 57.03%] [G loss: 0.828267]\n",
      "epoch:9 step:8987 [D loss: 0.647099, acc.: 64.06%] [G loss: 0.884040]\n",
      "epoch:9 step:8988 [D loss: 0.642129, acc.: 65.62%] [G loss: 0.856352]\n",
      "epoch:9 step:8989 [D loss: 0.616485, acc.: 71.88%] [G loss: 0.943406]\n",
      "epoch:9 step:8990 [D loss: 0.619556, acc.: 60.94%] [G loss: 0.925382]\n",
      "epoch:9 step:8991 [D loss: 0.646080, acc.: 64.06%] [G loss: 0.874691]\n",
      "epoch:9 step:8992 [D loss: 0.672994, acc.: 56.25%] [G loss: 0.901272]\n",
      "epoch:9 step:8993 [D loss: 0.719319, acc.: 48.44%] [G loss: 0.892362]\n",
      "epoch:9 step:8994 [D loss: 0.624365, acc.: 63.28%] [G loss: 0.907194]\n",
      "epoch:9 step:8995 [D loss: 0.643434, acc.: 63.28%] [G loss: 0.960104]\n",
      "epoch:9 step:8996 [D loss: 0.621406, acc.: 66.41%] [G loss: 0.988236]\n",
      "epoch:9 step:8997 [D loss: 0.603361, acc.: 71.88%] [G loss: 1.004719]\n",
      "epoch:9 step:8998 [D loss: 0.687425, acc.: 60.16%] [G loss: 0.913353]\n",
      "epoch:9 step:8999 [D loss: 0.722066, acc.: 56.25%] [G loss: 0.889101]\n",
      "epoch:9 step:9000 [D loss: 0.630382, acc.: 64.06%] [G loss: 0.920323]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.540619\n",
      "FID: 17.304935\n",
      "0 = 11.930943466734895\n",
      "1 = 0.06375951060242498\n",
      "2 = 0.9328500032424927\n",
      "3 = 0.8830999732017517\n",
      "4 = 0.9825999736785889\n",
      "5 = 0.9806774258613586\n",
      "6 = 0.8830999732017517\n",
      "7 = 6.798907905590521\n",
      "8 = 0.09526115660521696\n",
      "9 = 0.7513499855995178\n",
      "10 = 0.7197999954223633\n",
      "11 = 0.7828999757766724\n",
      "12 = 0.7682783603668213\n",
      "13 = 0.7197999954223633\n",
      "14 = 7.540685176849365\n",
      "15 = 9.4901704788208\n",
      "16 = 0.12262440472841263\n",
      "17 = 7.540618896484375\n",
      "18 = 17.304935455322266\n",
      "epoch:9 step:9001 [D loss: 0.633565, acc.: 63.28%] [G loss: 0.883544]\n",
      "epoch:9 step:9002 [D loss: 0.698373, acc.: 54.69%] [G loss: 0.827209]\n",
      "epoch:9 step:9003 [D loss: 0.649583, acc.: 64.84%] [G loss: 0.835723]\n",
      "epoch:9 step:9004 [D loss: 0.653815, acc.: 59.38%] [G loss: 0.854551]\n",
      "epoch:9 step:9005 [D loss: 0.657086, acc.: 60.16%] [G loss: 0.957793]\n",
      "epoch:9 step:9006 [D loss: 0.643963, acc.: 61.72%] [G loss: 0.947474]\n",
      "epoch:9 step:9007 [D loss: 0.596689, acc.: 68.75%] [G loss: 0.952456]\n",
      "epoch:9 step:9008 [D loss: 0.606257, acc.: 64.84%] [G loss: 0.985700]\n",
      "epoch:9 step:9009 [D loss: 0.681053, acc.: 59.38%] [G loss: 0.959738]\n",
      "epoch:9 step:9010 [D loss: 0.648643, acc.: 66.41%] [G loss: 0.909467]\n",
      "epoch:9 step:9011 [D loss: 0.665226, acc.: 58.59%] [G loss: 0.866468]\n",
      "epoch:9 step:9012 [D loss: 0.651323, acc.: 64.06%] [G loss: 0.859979]\n",
      "epoch:9 step:9013 [D loss: 0.668286, acc.: 59.38%] [G loss: 0.906389]\n",
      "epoch:9 step:9014 [D loss: 0.605353, acc.: 64.84%] [G loss: 0.974171]\n",
      "epoch:9 step:9015 [D loss: 0.608378, acc.: 66.41%] [G loss: 0.972320]\n",
      "epoch:9 step:9016 [D loss: 0.670471, acc.: 64.06%] [G loss: 0.946444]\n",
      "epoch:9 step:9017 [D loss: 0.719235, acc.: 52.34%] [G loss: 0.934032]\n",
      "epoch:9 step:9018 [D loss: 0.674953, acc.: 56.25%] [G loss: 0.874870]\n",
      "epoch:9 step:9019 [D loss: 0.687381, acc.: 57.03%] [G loss: 0.862345]\n",
      "epoch:9 step:9020 [D loss: 0.738461, acc.: 42.19%] [G loss: 0.887881]\n",
      "epoch:9 step:9021 [D loss: 0.675075, acc.: 55.47%] [G loss: 0.937337]\n",
      "epoch:9 step:9022 [D loss: 0.622124, acc.: 64.06%] [G loss: 0.938500]\n",
      "epoch:9 step:9023 [D loss: 0.672708, acc.: 60.16%] [G loss: 0.957367]\n",
      "epoch:9 step:9024 [D loss: 0.710772, acc.: 48.44%] [G loss: 0.875526]\n",
      "epoch:9 step:9025 [D loss: 0.632905, acc.: 64.06%] [G loss: 0.905367]\n",
      "epoch:9 step:9026 [D loss: 0.666813, acc.: 58.59%] [G loss: 0.903189]\n",
      "epoch:9 step:9027 [D loss: 0.641970, acc.: 64.06%] [G loss: 0.863495]\n",
      "epoch:9 step:9028 [D loss: 0.670941, acc.: 58.59%] [G loss: 0.930889]\n",
      "epoch:9 step:9029 [D loss: 0.686381, acc.: 59.38%] [G loss: 0.899239]\n",
      "epoch:9 step:9030 [D loss: 0.679387, acc.: 59.38%] [G loss: 0.830682]\n",
      "epoch:9 step:9031 [D loss: 0.622288, acc.: 68.75%] [G loss: 0.836169]\n",
      "epoch:9 step:9032 [D loss: 0.644337, acc.: 66.41%] [G loss: 0.888308]\n",
      "epoch:9 step:9033 [D loss: 0.727921, acc.: 46.88%] [G loss: 0.851484]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9034 [D loss: 0.642187, acc.: 67.97%] [G loss: 0.905912]\n",
      "epoch:9 step:9035 [D loss: 0.692775, acc.: 53.91%] [G loss: 0.878901]\n",
      "epoch:9 step:9036 [D loss: 0.652318, acc.: 60.16%] [G loss: 0.870594]\n",
      "epoch:9 step:9037 [D loss: 0.670151, acc.: 57.81%] [G loss: 0.887374]\n",
      "epoch:9 step:9038 [D loss: 0.648165, acc.: 62.50%] [G loss: 0.926087]\n",
      "epoch:9 step:9039 [D loss: 0.676834, acc.: 53.91%] [G loss: 0.857135]\n",
      "epoch:9 step:9040 [D loss: 0.631807, acc.: 62.50%] [G loss: 0.840876]\n",
      "epoch:9 step:9041 [D loss: 0.648583, acc.: 64.84%] [G loss: 0.904871]\n",
      "epoch:9 step:9042 [D loss: 0.661314, acc.: 59.38%] [G loss: 0.944723]\n",
      "epoch:9 step:9043 [D loss: 0.661775, acc.: 57.03%] [G loss: 0.897664]\n",
      "epoch:9 step:9044 [D loss: 0.683765, acc.: 58.59%] [G loss: 0.874543]\n",
      "epoch:9 step:9045 [D loss: 0.677859, acc.: 55.47%] [G loss: 0.876381]\n",
      "epoch:9 step:9046 [D loss: 0.646146, acc.: 62.50%] [G loss: 0.874020]\n",
      "epoch:9 step:9047 [D loss: 0.687265, acc.: 52.34%] [G loss: 0.886207]\n",
      "epoch:9 step:9048 [D loss: 0.681113, acc.: 55.47%] [G loss: 0.858061]\n",
      "epoch:9 step:9049 [D loss: 0.699056, acc.: 56.25%] [G loss: 0.950292]\n",
      "epoch:9 step:9050 [D loss: 0.643695, acc.: 58.59%] [G loss: 0.950740]\n",
      "epoch:9 step:9051 [D loss: 0.631687, acc.: 69.53%] [G loss: 0.872237]\n",
      "epoch:9 step:9052 [D loss: 0.665596, acc.: 60.16%] [G loss: 0.886402]\n",
      "epoch:9 step:9053 [D loss: 0.641487, acc.: 60.94%] [G loss: 0.893481]\n",
      "epoch:9 step:9054 [D loss: 0.674119, acc.: 56.25%] [G loss: 0.838494]\n",
      "epoch:9 step:9055 [D loss: 0.689886, acc.: 55.47%] [G loss: 0.863210]\n",
      "epoch:9 step:9056 [D loss: 0.632261, acc.: 62.50%] [G loss: 0.847550]\n",
      "epoch:9 step:9057 [D loss: 0.617578, acc.: 69.53%] [G loss: 0.941525]\n",
      "epoch:9 step:9058 [D loss: 0.697791, acc.: 52.34%] [G loss: 0.896144]\n",
      "epoch:9 step:9059 [D loss: 0.737857, acc.: 46.09%] [G loss: 0.833748]\n",
      "epoch:9 step:9060 [D loss: 0.682229, acc.: 59.38%] [G loss: 0.900665]\n",
      "epoch:9 step:9061 [D loss: 0.712613, acc.: 53.91%] [G loss: 0.875261]\n",
      "epoch:9 step:9062 [D loss: 0.629130, acc.: 65.62%] [G loss: 0.844862]\n",
      "epoch:9 step:9063 [D loss: 0.638887, acc.: 67.19%] [G loss: 0.905928]\n",
      "epoch:9 step:9064 [D loss: 0.601366, acc.: 71.09%] [G loss: 0.931470]\n",
      "epoch:9 step:9065 [D loss: 0.650836, acc.: 64.06%] [G loss: 0.909890]\n",
      "epoch:9 step:9066 [D loss: 0.638923, acc.: 60.94%] [G loss: 0.964002]\n",
      "epoch:9 step:9067 [D loss: 0.613625, acc.: 70.31%] [G loss: 1.003096]\n",
      "epoch:9 step:9068 [D loss: 0.651421, acc.: 65.62%] [G loss: 0.997022]\n",
      "epoch:9 step:9069 [D loss: 0.704681, acc.: 50.00%] [G loss: 0.999318]\n",
      "epoch:9 step:9070 [D loss: 0.634245, acc.: 57.81%] [G loss: 0.945480]\n",
      "epoch:9 step:9071 [D loss: 0.652676, acc.: 60.94%] [G loss: 0.879617]\n",
      "epoch:9 step:9072 [D loss: 0.687096, acc.: 51.56%] [G loss: 0.903590]\n",
      "epoch:9 step:9073 [D loss: 0.653250, acc.: 59.38%] [G loss: 0.838355]\n",
      "epoch:9 step:9074 [D loss: 0.630446, acc.: 67.19%] [G loss: 0.934603]\n",
      "epoch:9 step:9075 [D loss: 0.631368, acc.: 60.16%] [G loss: 0.928422]\n",
      "epoch:9 step:9076 [D loss: 0.620858, acc.: 64.06%] [G loss: 0.917401]\n",
      "epoch:9 step:9077 [D loss: 0.640130, acc.: 61.72%] [G loss: 0.895207]\n",
      "epoch:9 step:9078 [D loss: 0.681757, acc.: 56.25%] [G loss: 0.897810]\n",
      "epoch:9 step:9079 [D loss: 0.652567, acc.: 61.72%] [G loss: 0.910108]\n",
      "epoch:9 step:9080 [D loss: 0.641380, acc.: 64.84%] [G loss: 0.951635]\n",
      "epoch:9 step:9081 [D loss: 0.571738, acc.: 69.53%] [G loss: 0.982439]\n",
      "epoch:9 step:9082 [D loss: 0.602601, acc.: 67.97%] [G loss: 0.947896]\n",
      "epoch:9 step:9083 [D loss: 0.605536, acc.: 70.31%] [G loss: 0.904962]\n",
      "epoch:9 step:9084 [D loss: 0.667584, acc.: 60.16%] [G loss: 0.955272]\n",
      "epoch:9 step:9085 [D loss: 0.660228, acc.: 62.50%] [G loss: 0.894541]\n",
      "epoch:9 step:9086 [D loss: 0.696046, acc.: 59.38%] [G loss: 0.938231]\n",
      "epoch:9 step:9087 [D loss: 0.669850, acc.: 57.81%] [G loss: 0.863201]\n",
      "epoch:9 step:9088 [D loss: 0.687619, acc.: 57.81%] [G loss: 0.883485]\n",
      "epoch:9 step:9089 [D loss: 0.674279, acc.: 56.25%] [G loss: 0.865173]\n",
      "epoch:9 step:9090 [D loss: 0.682608, acc.: 60.94%] [G loss: 0.917520]\n",
      "epoch:9 step:9091 [D loss: 0.639927, acc.: 61.72%] [G loss: 0.933491]\n",
      "epoch:9 step:9092 [D loss: 0.645303, acc.: 63.28%] [G loss: 0.969090]\n",
      "epoch:9 step:9093 [D loss: 0.616873, acc.: 69.53%] [G loss: 0.911336]\n",
      "epoch:9 step:9094 [D loss: 0.616349, acc.: 63.28%] [G loss: 0.890701]\n",
      "epoch:9 step:9095 [D loss: 0.658695, acc.: 58.59%] [G loss: 0.949205]\n",
      "epoch:9 step:9096 [D loss: 0.669313, acc.: 57.03%] [G loss: 0.892842]\n",
      "epoch:9 step:9097 [D loss: 0.694306, acc.: 57.81%] [G loss: 0.893789]\n",
      "epoch:9 step:9098 [D loss: 0.674535, acc.: 55.47%] [G loss: 0.973895]\n",
      "epoch:9 step:9099 [D loss: 0.622693, acc.: 61.72%] [G loss: 0.913442]\n",
      "epoch:9 step:9100 [D loss: 0.670419, acc.: 58.59%] [G loss: 0.901467]\n",
      "epoch:9 step:9101 [D loss: 0.629135, acc.: 61.72%] [G loss: 0.850871]\n",
      "epoch:9 step:9102 [D loss: 0.618987, acc.: 64.84%] [G loss: 0.783768]\n",
      "epoch:9 step:9103 [D loss: 0.672301, acc.: 57.81%] [G loss: 0.858354]\n",
      "epoch:9 step:9104 [D loss: 0.702939, acc.: 53.91%] [G loss: 0.835682]\n",
      "epoch:9 step:9105 [D loss: 0.690177, acc.: 53.91%] [G loss: 0.786089]\n",
      "epoch:9 step:9106 [D loss: 0.644708, acc.: 64.06%] [G loss: 0.920197]\n",
      "epoch:9 step:9107 [D loss: 0.623400, acc.: 66.41%] [G loss: 0.915112]\n",
      "epoch:9 step:9108 [D loss: 0.724319, acc.: 46.88%] [G loss: 0.866100]\n",
      "epoch:9 step:9109 [D loss: 0.663249, acc.: 53.91%] [G loss: 0.883616]\n",
      "epoch:9 step:9110 [D loss: 0.640916, acc.: 62.50%] [G loss: 0.930308]\n",
      "epoch:9 step:9111 [D loss: 0.676387, acc.: 58.59%] [G loss: 0.875323]\n",
      "epoch:9 step:9112 [D loss: 0.655915, acc.: 62.50%] [G loss: 0.875675]\n",
      "epoch:9 step:9113 [D loss: 0.666988, acc.: 59.38%] [G loss: 0.892404]\n",
      "epoch:9 step:9114 [D loss: 0.626842, acc.: 64.06%] [G loss: 0.895389]\n",
      "epoch:9 step:9115 [D loss: 0.679320, acc.: 54.69%] [G loss: 0.895296]\n",
      "epoch:9 step:9116 [D loss: 0.677415, acc.: 55.47%] [G loss: 0.858489]\n",
      "epoch:9 step:9117 [D loss: 0.683118, acc.: 58.59%] [G loss: 0.842835]\n",
      "epoch:9 step:9118 [D loss: 0.648677, acc.: 64.06%] [G loss: 0.857660]\n",
      "epoch:9 step:9119 [D loss: 0.636745, acc.: 66.41%] [G loss: 0.913147]\n",
      "epoch:9 step:9120 [D loss: 0.670955, acc.: 62.50%] [G loss: 0.841949]\n",
      "epoch:9 step:9121 [D loss: 0.656913, acc.: 60.16%] [G loss: 0.890048]\n",
      "epoch:9 step:9122 [D loss: 0.657216, acc.: 64.06%] [G loss: 0.922576]\n",
      "epoch:9 step:9123 [D loss: 0.652010, acc.: 60.16%] [G loss: 0.935309]\n",
      "epoch:9 step:9124 [D loss: 0.574538, acc.: 75.00%] [G loss: 0.961048]\n",
      "epoch:9 step:9125 [D loss: 0.610099, acc.: 64.06%] [G loss: 0.935345]\n",
      "epoch:9 step:9126 [D loss: 0.628689, acc.: 61.72%] [G loss: 0.883911]\n",
      "epoch:9 step:9127 [D loss: 0.621687, acc.: 68.75%] [G loss: 0.936743]\n",
      "epoch:9 step:9128 [D loss: 0.685496, acc.: 57.03%] [G loss: 0.951165]\n",
      "epoch:9 step:9129 [D loss: 0.671053, acc.: 56.25%] [G loss: 0.905958]\n",
      "epoch:9 step:9130 [D loss: 0.662480, acc.: 59.38%] [G loss: 0.878637]\n",
      "epoch:9 step:9131 [D loss: 0.658264, acc.: 60.16%] [G loss: 0.909428]\n",
      "epoch:9 step:9132 [D loss: 0.658143, acc.: 56.25%] [G loss: 0.865207]\n",
      "epoch:9 step:9133 [D loss: 0.644004, acc.: 61.72%] [G loss: 0.898070]\n",
      "epoch:9 step:9134 [D loss: 0.628292, acc.: 64.84%] [G loss: 0.890809]\n",
      "epoch:9 step:9135 [D loss: 0.662365, acc.: 56.25%] [G loss: 0.916546]\n",
      "epoch:9 step:9136 [D loss: 0.704187, acc.: 46.88%] [G loss: 0.899734]\n",
      "epoch:9 step:9137 [D loss: 0.679105, acc.: 57.03%] [G loss: 0.852106]\n",
      "epoch:9 step:9138 [D loss: 0.680776, acc.: 61.72%] [G loss: 0.790389]\n",
      "epoch:9 step:9139 [D loss: 0.648509, acc.: 61.72%] [G loss: 0.844091]\n",
      "epoch:9 step:9140 [D loss: 0.644552, acc.: 65.62%] [G loss: 0.868867]\n",
      "epoch:9 step:9141 [D loss: 0.638379, acc.: 65.62%] [G loss: 0.875975]\n",
      "epoch:9 step:9142 [D loss: 0.643103, acc.: 64.84%] [G loss: 0.936527]\n",
      "epoch:9 step:9143 [D loss: 0.673213, acc.: 58.59%] [G loss: 0.911977]\n",
      "epoch:9 step:9144 [D loss: 0.704852, acc.: 51.56%] [G loss: 0.876987]\n",
      "epoch:9 step:9145 [D loss: 0.603178, acc.: 65.62%] [G loss: 0.885545]\n",
      "epoch:9 step:9146 [D loss: 0.674556, acc.: 56.25%] [G loss: 0.843781]\n",
      "epoch:9 step:9147 [D loss: 0.626319, acc.: 67.19%] [G loss: 0.877173]\n",
      "epoch:9 step:9148 [D loss: 0.671129, acc.: 60.94%] [G loss: 0.855085]\n",
      "epoch:9 step:9149 [D loss: 0.759475, acc.: 44.53%] [G loss: 0.840227]\n",
      "epoch:9 step:9150 [D loss: 0.680623, acc.: 57.03%] [G loss: 0.929939]\n",
      "epoch:9 step:9151 [D loss: 0.654831, acc.: 63.28%] [G loss: 0.909771]\n",
      "epoch:9 step:9152 [D loss: 0.649164, acc.: 62.50%] [G loss: 0.937060]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9153 [D loss: 0.677369, acc.: 54.69%] [G loss: 0.999229]\n",
      "epoch:9 step:9154 [D loss: 0.658699, acc.: 60.94%] [G loss: 0.938233]\n",
      "epoch:9 step:9155 [D loss: 0.720341, acc.: 50.00%] [G loss: 0.894404]\n",
      "epoch:9 step:9156 [D loss: 0.698353, acc.: 55.47%] [G loss: 0.881597]\n",
      "epoch:9 step:9157 [D loss: 0.653935, acc.: 62.50%] [G loss: 0.908128]\n",
      "epoch:9 step:9158 [D loss: 0.620252, acc.: 67.19%] [G loss: 0.886919]\n",
      "epoch:9 step:9159 [D loss: 0.662107, acc.: 58.59%] [G loss: 0.832894]\n",
      "epoch:9 step:9160 [D loss: 0.658703, acc.: 58.59%] [G loss: 0.844720]\n",
      "epoch:9 step:9161 [D loss: 0.644946, acc.: 66.41%] [G loss: 0.933190]\n",
      "epoch:9 step:9162 [D loss: 0.725639, acc.: 50.00%] [G loss: 0.938713]\n",
      "epoch:9 step:9163 [D loss: 0.606315, acc.: 66.41%] [G loss: 0.891764]\n",
      "epoch:9 step:9164 [D loss: 0.674986, acc.: 60.94%] [G loss: 0.941687]\n",
      "epoch:9 step:9165 [D loss: 0.629807, acc.: 66.41%] [G loss: 0.925512]\n",
      "epoch:9 step:9166 [D loss: 0.630822, acc.: 63.28%] [G loss: 0.990200]\n",
      "epoch:9 step:9167 [D loss: 0.687062, acc.: 58.59%] [G loss: 0.949166]\n",
      "epoch:9 step:9168 [D loss: 0.667256, acc.: 58.59%] [G loss: 0.900226]\n",
      "epoch:9 step:9169 [D loss: 0.630825, acc.: 64.06%] [G loss: 0.916991]\n",
      "epoch:9 step:9170 [D loss: 0.681164, acc.: 53.12%] [G loss: 0.891279]\n",
      "epoch:9 step:9171 [D loss: 0.707057, acc.: 48.44%] [G loss: 0.915769]\n",
      "epoch:9 step:9172 [D loss: 0.684013, acc.: 58.59%] [G loss: 0.873363]\n",
      "epoch:9 step:9173 [D loss: 0.693503, acc.: 55.47%] [G loss: 0.886108]\n",
      "epoch:9 step:9174 [D loss: 0.661347, acc.: 58.59%] [G loss: 0.820344]\n",
      "epoch:9 step:9175 [D loss: 0.632696, acc.: 67.19%] [G loss: 0.853096]\n",
      "epoch:9 step:9176 [D loss: 0.615992, acc.: 61.72%] [G loss: 0.925048]\n",
      "epoch:9 step:9177 [D loss: 0.666243, acc.: 60.16%] [G loss: 0.935465]\n",
      "epoch:9 step:9178 [D loss: 0.709125, acc.: 54.69%] [G loss: 0.938685]\n",
      "epoch:9 step:9179 [D loss: 0.632249, acc.: 67.19%] [G loss: 0.907832]\n",
      "epoch:9 step:9180 [D loss: 0.640816, acc.: 61.72%] [G loss: 0.857306]\n",
      "epoch:9 step:9181 [D loss: 0.677120, acc.: 57.03%] [G loss: 0.899648]\n",
      "epoch:9 step:9182 [D loss: 0.701408, acc.: 53.12%] [G loss: 0.880235]\n",
      "epoch:9 step:9183 [D loss: 0.716693, acc.: 57.03%] [G loss: 0.899955]\n",
      "epoch:9 step:9184 [D loss: 0.621774, acc.: 66.41%] [G loss: 0.965027]\n",
      "epoch:9 step:9185 [D loss: 0.731204, acc.: 51.56%] [G loss: 0.938126]\n",
      "epoch:9 step:9186 [D loss: 0.622198, acc.: 67.19%] [G loss: 0.980586]\n",
      "epoch:9 step:9187 [D loss: 0.661352, acc.: 57.03%] [G loss: 0.877850]\n",
      "epoch:9 step:9188 [D loss: 0.641110, acc.: 62.50%] [G loss: 0.849481]\n",
      "epoch:9 step:9189 [D loss: 0.683020, acc.: 61.72%] [G loss: 0.883131]\n",
      "epoch:9 step:9190 [D loss: 0.708698, acc.: 53.91%] [G loss: 0.895896]\n",
      "epoch:9 step:9191 [D loss: 0.676257, acc.: 63.28%] [G loss: 0.844217]\n",
      "epoch:9 step:9192 [D loss: 0.678328, acc.: 57.03%] [G loss: 0.818276]\n",
      "epoch:9 step:9193 [D loss: 0.632709, acc.: 60.16%] [G loss: 0.863959]\n",
      "epoch:9 step:9194 [D loss: 0.664063, acc.: 53.12%] [G loss: 0.900281]\n",
      "epoch:9 step:9195 [D loss: 0.675275, acc.: 56.25%] [G loss: 0.932067]\n",
      "epoch:9 step:9196 [D loss: 0.672290, acc.: 56.25%] [G loss: 0.884374]\n",
      "epoch:9 step:9197 [D loss: 0.654827, acc.: 61.72%] [G loss: 0.903278]\n",
      "epoch:9 step:9198 [D loss: 0.776020, acc.: 42.97%] [G loss: 0.882577]\n",
      "epoch:9 step:9199 [D loss: 0.690602, acc.: 53.12%] [G loss: 0.941713]\n",
      "epoch:9 step:9200 [D loss: 0.645112, acc.: 61.72%] [G loss: 0.959229]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.974873\n",
      "FID: 8.950171\n",
      "0 = 11.875129820299215\n",
      "1 = 0.05829493303216088\n",
      "2 = 0.9315500259399414\n",
      "3 = 0.8853999972343445\n",
      "4 = 0.9776999950408936\n",
      "5 = 0.9754323959350586\n",
      "6 = 0.8853999972343445\n",
      "7 = 5.994505734771481\n",
      "8 = 0.06594328217668119\n",
      "9 = 0.7199500203132629\n",
      "10 = 0.6934000253677368\n",
      "11 = 0.7465000152587891\n",
      "12 = 0.7322843074798584\n",
      "13 = 0.6934000253677368\n",
      "14 = 7.974940776824951\n",
      "15 = 9.619603157043457\n",
      "16 = 0.09020059555768967\n",
      "17 = 7.974873065948486\n",
      "18 = 8.950170516967773\n",
      "epoch:9 step:9201 [D loss: 0.679065, acc.: 60.16%] [G loss: 0.979581]\n",
      "epoch:9 step:9202 [D loss: 0.690067, acc.: 58.59%] [G loss: 0.937381]\n",
      "epoch:9 step:9203 [D loss: 0.629758, acc.: 61.72%] [G loss: 0.950477]\n",
      "epoch:9 step:9204 [D loss: 0.678743, acc.: 57.81%] [G loss: 0.879736]\n",
      "epoch:9 step:9205 [D loss: 0.642052, acc.: 61.72%] [G loss: 0.865459]\n",
      "epoch:9 step:9206 [D loss: 0.643547, acc.: 63.28%] [G loss: 0.980664]\n",
      "epoch:9 step:9207 [D loss: 0.676661, acc.: 58.59%] [G loss: 0.907968]\n",
      "epoch:9 step:9208 [D loss: 0.607703, acc.: 68.75%] [G loss: 0.906351]\n",
      "epoch:9 step:9209 [D loss: 0.710344, acc.: 49.22%] [G loss: 0.916775]\n",
      "epoch:9 step:9210 [D loss: 0.659672, acc.: 60.16%] [G loss: 0.963570]\n",
      "epoch:9 step:9211 [D loss: 0.683138, acc.: 57.81%] [G loss: 0.948718]\n",
      "epoch:9 step:9212 [D loss: 0.633739, acc.: 67.97%] [G loss: 0.907792]\n",
      "epoch:9 step:9213 [D loss: 0.635790, acc.: 63.28%] [G loss: 0.863403]\n",
      "epoch:9 step:9214 [D loss: 0.616143, acc.: 72.66%] [G loss: 0.926475]\n",
      "epoch:9 step:9215 [D loss: 0.576439, acc.: 71.09%] [G loss: 0.964012]\n",
      "epoch:9 step:9216 [D loss: 0.763089, acc.: 50.00%] [G loss: 0.885082]\n",
      "epoch:9 step:9217 [D loss: 0.764272, acc.: 45.31%] [G loss: 0.833973]\n",
      "epoch:9 step:9218 [D loss: 0.671373, acc.: 58.59%] [G loss: 0.770501]\n",
      "epoch:9 step:9219 [D loss: 0.636039, acc.: 61.72%] [G loss: 0.910555]\n",
      "epoch:9 step:9220 [D loss: 0.699458, acc.: 57.03%] [G loss: 0.862657]\n",
      "epoch:9 step:9221 [D loss: 0.720854, acc.: 49.22%] [G loss: 0.868013]\n",
      "epoch:9 step:9222 [D loss: 0.641449, acc.: 62.50%] [G loss: 0.918459]\n",
      "epoch:9 step:9223 [D loss: 0.644999, acc.: 59.38%] [G loss: 0.910078]\n",
      "epoch:9 step:9224 [D loss: 0.700539, acc.: 56.25%] [G loss: 0.898286]\n",
      "epoch:9 step:9225 [D loss: 0.617598, acc.: 71.88%] [G loss: 0.929623]\n",
      "epoch:9 step:9226 [D loss: 0.668380, acc.: 57.81%] [G loss: 0.921966]\n",
      "epoch:9 step:9227 [D loss: 0.706891, acc.: 50.00%] [G loss: 0.951832]\n",
      "epoch:9 step:9228 [D loss: 0.656124, acc.: 61.72%] [G loss: 0.968305]\n",
      "epoch:9 step:9229 [D loss: 0.631756, acc.: 63.28%] [G loss: 0.914735]\n",
      "epoch:9 step:9230 [D loss: 0.719161, acc.: 47.66%] [G loss: 0.907544]\n",
      "epoch:9 step:9231 [D loss: 0.707047, acc.: 50.78%] [G loss: 0.791788]\n",
      "epoch:9 step:9232 [D loss: 0.630435, acc.: 68.75%] [G loss: 0.842972]\n",
      "epoch:9 step:9233 [D loss: 0.690306, acc.: 53.12%] [G loss: 0.896103]\n",
      "epoch:9 step:9234 [D loss: 0.633941, acc.: 64.06%] [G loss: 0.871191]\n",
      "epoch:9 step:9235 [D loss: 0.627294, acc.: 62.50%] [G loss: 0.938903]\n",
      "epoch:9 step:9236 [D loss: 0.670335, acc.: 64.06%] [G loss: 0.959331]\n",
      "epoch:9 step:9237 [D loss: 0.710227, acc.: 53.12%] [G loss: 0.962476]\n",
      "epoch:9 step:9238 [D loss: 0.650330, acc.: 59.38%] [G loss: 0.907091]\n",
      "epoch:9 step:9239 [D loss: 0.662637, acc.: 62.50%] [G loss: 0.934788]\n",
      "epoch:9 step:9240 [D loss: 0.613259, acc.: 69.53%] [G loss: 0.824061]\n",
      "epoch:9 step:9241 [D loss: 0.672753, acc.: 61.72%] [G loss: 0.863900]\n",
      "epoch:9 step:9242 [D loss: 0.661685, acc.: 62.50%] [G loss: 0.867806]\n",
      "epoch:9 step:9243 [D loss: 0.652145, acc.: 57.81%] [G loss: 0.814524]\n",
      "epoch:9 step:9244 [D loss: 0.685636, acc.: 55.47%] [G loss: 0.880965]\n",
      "epoch:9 step:9245 [D loss: 0.692939, acc.: 56.25%] [G loss: 0.832185]\n",
      "epoch:9 step:9246 [D loss: 0.670099, acc.: 59.38%] [G loss: 0.940295]\n",
      "epoch:9 step:9247 [D loss: 0.641974, acc.: 64.84%] [G loss: 0.884571]\n",
      "epoch:9 step:9248 [D loss: 0.637502, acc.: 64.06%] [G loss: 0.957042]\n",
      "epoch:9 step:9249 [D loss: 0.677682, acc.: 57.03%] [G loss: 0.896149]\n",
      "epoch:9 step:9250 [D loss: 0.649825, acc.: 64.84%] [G loss: 0.924613]\n",
      "epoch:9 step:9251 [D loss: 0.686491, acc.: 60.16%] [G loss: 0.924952]\n",
      "epoch:9 step:9252 [D loss: 0.630650, acc.: 69.53%] [G loss: 0.894798]\n",
      "epoch:9 step:9253 [D loss: 0.761067, acc.: 48.44%] [G loss: 0.891060]\n",
      "epoch:9 step:9254 [D loss: 0.692072, acc.: 55.47%] [G loss: 0.844844]\n",
      "epoch:9 step:9255 [D loss: 0.635039, acc.: 61.72%] [G loss: 0.886491]\n",
      "epoch:9 step:9256 [D loss: 0.660282, acc.: 60.94%] [G loss: 0.862183]\n",
      "epoch:9 step:9257 [D loss: 0.674561, acc.: 60.94%] [G loss: 0.866062]\n",
      "epoch:9 step:9258 [D loss: 0.678467, acc.: 59.38%] [G loss: 0.858401]\n",
      "epoch:9 step:9259 [D loss: 0.662239, acc.: 58.59%] [G loss: 0.912087]\n",
      "epoch:9 step:9260 [D loss: 0.698775, acc.: 53.12%] [G loss: 0.944846]\n",
      "epoch:9 step:9261 [D loss: 0.677844, acc.: 56.25%] [G loss: 0.902461]\n",
      "epoch:9 step:9262 [D loss: 0.640875, acc.: 61.72%] [G loss: 0.902948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9263 [D loss: 0.651442, acc.: 64.06%] [G loss: 0.862747]\n",
      "epoch:9 step:9264 [D loss: 0.679884, acc.: 54.69%] [G loss: 0.879652]\n",
      "epoch:9 step:9265 [D loss: 0.601626, acc.: 70.31%] [G loss: 0.868068]\n",
      "epoch:9 step:9266 [D loss: 0.639902, acc.: 64.06%] [G loss: 0.844030]\n",
      "epoch:9 step:9267 [D loss: 0.674801, acc.: 57.81%] [G loss: 0.875397]\n",
      "epoch:9 step:9268 [D loss: 0.633993, acc.: 71.88%] [G loss: 0.892319]\n",
      "epoch:9 step:9269 [D loss: 0.672286, acc.: 57.81%] [G loss: 0.891912]\n",
      "epoch:9 step:9270 [D loss: 0.668012, acc.: 58.59%] [G loss: 0.855456]\n",
      "epoch:9 step:9271 [D loss: 0.619065, acc.: 66.41%] [G loss: 0.923470]\n",
      "epoch:9 step:9272 [D loss: 0.688592, acc.: 53.12%] [G loss: 0.914470]\n",
      "epoch:9 step:9273 [D loss: 0.656959, acc.: 57.03%] [G loss: 0.917065]\n",
      "epoch:9 step:9274 [D loss: 0.668628, acc.: 62.50%] [G loss: 0.857697]\n",
      "epoch:9 step:9275 [D loss: 0.616135, acc.: 72.66%] [G loss: 0.933501]\n",
      "epoch:9 step:9276 [D loss: 0.668296, acc.: 54.69%] [G loss: 0.949944]\n",
      "epoch:9 step:9277 [D loss: 0.693945, acc.: 53.91%] [G loss: 0.916037]\n",
      "epoch:9 step:9278 [D loss: 0.650489, acc.: 57.03%] [G loss: 0.931870]\n",
      "epoch:9 step:9279 [D loss: 0.680691, acc.: 53.91%] [G loss: 0.883871]\n",
      "epoch:9 step:9280 [D loss: 0.702781, acc.: 53.91%] [G loss: 0.886451]\n",
      "epoch:9 step:9281 [D loss: 0.668768, acc.: 57.03%] [G loss: 0.866711]\n",
      "epoch:9 step:9282 [D loss: 0.637208, acc.: 67.19%] [G loss: 0.854305]\n",
      "epoch:9 step:9283 [D loss: 0.663120, acc.: 59.38%] [G loss: 0.879551]\n",
      "epoch:9 step:9284 [D loss: 0.716744, acc.: 53.91%] [G loss: 0.868641]\n",
      "epoch:9 step:9285 [D loss: 0.596666, acc.: 67.97%] [G loss: 0.877270]\n",
      "epoch:9 step:9286 [D loss: 0.633842, acc.: 61.72%] [G loss: 0.952844]\n",
      "epoch:9 step:9287 [D loss: 0.656459, acc.: 64.84%] [G loss: 0.860759]\n",
      "epoch:9 step:9288 [D loss: 0.641996, acc.: 66.41%] [G loss: 0.922509]\n",
      "epoch:9 step:9289 [D loss: 0.684782, acc.: 56.25%] [G loss: 0.863258]\n",
      "epoch:9 step:9290 [D loss: 0.625327, acc.: 67.97%] [G loss: 0.890922]\n",
      "epoch:9 step:9291 [D loss: 0.788200, acc.: 44.53%] [G loss: 0.896781]\n",
      "epoch:9 step:9292 [D loss: 0.680559, acc.: 56.25%] [G loss: 0.929064]\n",
      "epoch:9 step:9293 [D loss: 0.602581, acc.: 70.31%] [G loss: 0.975379]\n",
      "epoch:9 step:9294 [D loss: 0.672867, acc.: 60.16%] [G loss: 0.934468]\n",
      "epoch:9 step:9295 [D loss: 0.689204, acc.: 60.16%] [G loss: 0.857885]\n",
      "epoch:9 step:9296 [D loss: 0.666147, acc.: 57.03%] [G loss: 0.893496]\n",
      "epoch:9 step:9297 [D loss: 0.694729, acc.: 53.12%] [G loss: 0.871099]\n",
      "epoch:9 step:9298 [D loss: 0.699598, acc.: 53.91%] [G loss: 0.880489]\n",
      "epoch:9 step:9299 [D loss: 0.673506, acc.: 61.72%] [G loss: 0.860438]\n",
      "epoch:9 step:9300 [D loss: 0.690819, acc.: 54.69%] [G loss: 0.874113]\n",
      "epoch:9 step:9301 [D loss: 0.643644, acc.: 62.50%] [G loss: 0.879759]\n",
      "epoch:9 step:9302 [D loss: 0.682676, acc.: 60.16%] [G loss: 0.896559]\n",
      "epoch:9 step:9303 [D loss: 0.639402, acc.: 64.06%] [G loss: 0.890656]\n",
      "epoch:9 step:9304 [D loss: 0.665186, acc.: 56.25%] [G loss: 0.908226]\n",
      "epoch:9 step:9305 [D loss: 0.641650, acc.: 64.06%] [G loss: 0.912464]\n",
      "epoch:9 step:9306 [D loss: 0.678114, acc.: 60.94%] [G loss: 0.848132]\n",
      "epoch:9 step:9307 [D loss: 0.655562, acc.: 59.38%] [G loss: 0.894221]\n",
      "epoch:9 step:9308 [D loss: 0.597304, acc.: 72.66%] [G loss: 0.896672]\n",
      "epoch:9 step:9309 [D loss: 0.664152, acc.: 64.06%] [G loss: 0.832773]\n",
      "epoch:9 step:9310 [D loss: 0.655519, acc.: 61.72%] [G loss: 0.872459]\n",
      "epoch:9 step:9311 [D loss: 0.657592, acc.: 64.06%] [G loss: 0.873294]\n",
      "epoch:9 step:9312 [D loss: 0.682970, acc.: 56.25%] [G loss: 0.861283]\n",
      "epoch:9 step:9313 [D loss: 0.696781, acc.: 52.34%] [G loss: 0.882711]\n",
      "epoch:9 step:9314 [D loss: 0.672817, acc.: 53.91%] [G loss: 0.915977]\n",
      "epoch:9 step:9315 [D loss: 0.637423, acc.: 62.50%] [G loss: 0.856724]\n",
      "epoch:9 step:9316 [D loss: 0.678433, acc.: 56.25%] [G loss: 0.880397]\n",
      "epoch:9 step:9317 [D loss: 0.625496, acc.: 66.41%] [G loss: 0.901371]\n",
      "epoch:9 step:9318 [D loss: 0.705704, acc.: 53.12%] [G loss: 0.899046]\n",
      "epoch:9 step:9319 [D loss: 0.604842, acc.: 67.97%] [G loss: 0.965678]\n",
      "epoch:9 step:9320 [D loss: 0.653801, acc.: 61.72%] [G loss: 0.904286]\n",
      "epoch:9 step:9321 [D loss: 0.683631, acc.: 57.81%] [G loss: 0.889077]\n",
      "epoch:9 step:9322 [D loss: 0.640766, acc.: 62.50%] [G loss: 0.898978]\n",
      "epoch:9 step:9323 [D loss: 0.651108, acc.: 64.84%] [G loss: 0.905619]\n",
      "epoch:9 step:9324 [D loss: 0.720773, acc.: 50.78%] [G loss: 0.838324]\n",
      "epoch:9 step:9325 [D loss: 0.693532, acc.: 56.25%] [G loss: 0.829469]\n",
      "epoch:9 step:9326 [D loss: 0.637020, acc.: 64.06%] [G loss: 0.935996]\n",
      "epoch:9 step:9327 [D loss: 0.652142, acc.: 62.50%] [G loss: 0.947708]\n",
      "epoch:9 step:9328 [D loss: 0.631205, acc.: 63.28%] [G loss: 0.922121]\n",
      "epoch:9 step:9329 [D loss: 0.644556, acc.: 61.72%] [G loss: 0.939289]\n",
      "epoch:9 step:9330 [D loss: 0.639198, acc.: 63.28%] [G loss: 0.907118]\n",
      "epoch:9 step:9331 [D loss: 0.640212, acc.: 64.84%] [G loss: 0.932935]\n",
      "epoch:9 step:9332 [D loss: 0.614620, acc.: 64.84%] [G loss: 0.952094]\n",
      "epoch:9 step:9333 [D loss: 0.620938, acc.: 65.62%] [G loss: 0.937631]\n",
      "epoch:9 step:9334 [D loss: 0.662276, acc.: 61.72%] [G loss: 0.903920]\n",
      "epoch:9 step:9335 [D loss: 0.663752, acc.: 61.72%] [G loss: 0.856401]\n",
      "epoch:9 step:9336 [D loss: 0.662418, acc.: 60.94%] [G loss: 0.903324]\n",
      "epoch:9 step:9337 [D loss: 0.673952, acc.: 61.72%] [G loss: 0.847303]\n",
      "epoch:9 step:9338 [D loss: 0.677932, acc.: 57.81%] [G loss: 0.892729]\n",
      "epoch:9 step:9339 [D loss: 0.645550, acc.: 57.81%] [G loss: 0.911792]\n",
      "epoch:9 step:9340 [D loss: 0.653604, acc.: 63.28%] [G loss: 0.880081]\n",
      "epoch:9 step:9341 [D loss: 0.635836, acc.: 66.41%] [G loss: 0.963375]\n",
      "epoch:9 step:9342 [D loss: 0.603593, acc.: 70.31%] [G loss: 0.940101]\n",
      "epoch:9 step:9343 [D loss: 0.662513, acc.: 63.28%] [G loss: 0.861221]\n",
      "epoch:9 step:9344 [D loss: 0.687698, acc.: 56.25%] [G loss: 0.937427]\n",
      "epoch:9 step:9345 [D loss: 0.631353, acc.: 62.50%] [G loss: 0.915661]\n",
      "epoch:9 step:9346 [D loss: 0.646746, acc.: 59.38%] [G loss: 0.894548]\n",
      "epoch:9 step:9347 [D loss: 0.662627, acc.: 59.38%] [G loss: 0.995207]\n",
      "epoch:9 step:9348 [D loss: 0.709348, acc.: 53.91%] [G loss: 0.915446]\n",
      "epoch:9 step:9349 [D loss: 0.717595, acc.: 53.91%] [G loss: 0.899791]\n",
      "epoch:9 step:9350 [D loss: 0.672679, acc.: 59.38%] [G loss: 0.854190]\n",
      "epoch:9 step:9351 [D loss: 0.636194, acc.: 62.50%] [G loss: 0.884156]\n",
      "epoch:9 step:9352 [D loss: 0.590561, acc.: 69.53%] [G loss: 1.006901]\n",
      "epoch:9 step:9353 [D loss: 0.795603, acc.: 38.28%] [G loss: 0.902874]\n",
      "epoch:9 step:9354 [D loss: 0.603448, acc.: 75.00%] [G loss: 0.961624]\n",
      "epoch:9 step:9355 [D loss: 0.640263, acc.: 64.84%] [G loss: 0.895254]\n",
      "epoch:9 step:9356 [D loss: 0.607387, acc.: 73.44%] [G loss: 0.852818]\n",
      "epoch:9 step:9357 [D loss: 0.545165, acc.: 80.47%] [G loss: 0.864580]\n",
      "epoch:9 step:9358 [D loss: 0.563598, acc.: 76.56%] [G loss: 0.935896]\n",
      "epoch:9 step:9359 [D loss: 0.601305, acc.: 67.19%] [G loss: 0.969757]\n",
      "epoch:9 step:9360 [D loss: 0.656535, acc.: 60.94%] [G loss: 0.990636]\n",
      "epoch:9 step:9361 [D loss: 0.819114, acc.: 53.12%] [G loss: 1.017512]\n",
      "epoch:9 step:9362 [D loss: 0.603332, acc.: 71.88%] [G loss: 1.106609]\n",
      "epoch:9 step:9363 [D loss: 0.571399, acc.: 64.84%] [G loss: 1.128021]\n",
      "epoch:9 step:9364 [D loss: 0.671554, acc.: 56.25%] [G loss: 0.990600]\n",
      "epoch:9 step:9365 [D loss: 0.698466, acc.: 55.47%] [G loss: 0.928832]\n",
      "epoch:9 step:9366 [D loss: 0.683379, acc.: 57.81%] [G loss: 0.953625]\n",
      "epoch:9 step:9367 [D loss: 0.607942, acc.: 70.31%] [G loss: 0.934545]\n",
      "epoch:9 step:9368 [D loss: 0.595304, acc.: 66.41%] [G loss: 0.995754]\n",
      "epoch:9 step:9369 [D loss: 0.567558, acc.: 75.00%] [G loss: 0.983056]\n",
      "epoch:9 step:9370 [D loss: 0.615963, acc.: 67.19%] [G loss: 0.985771]\n",
      "epoch:10 step:9371 [D loss: 0.658358, acc.: 64.84%] [G loss: 0.942615]\n",
      "epoch:10 step:9372 [D loss: 0.735358, acc.: 54.69%] [G loss: 0.870252]\n",
      "epoch:10 step:9373 [D loss: 0.733566, acc.: 53.12%] [G loss: 0.920309]\n",
      "epoch:10 step:9374 [D loss: 0.661208, acc.: 57.81%] [G loss: 0.836215]\n",
      "epoch:10 step:9375 [D loss: 0.691478, acc.: 53.12%] [G loss: 0.915289]\n",
      "epoch:10 step:9376 [D loss: 0.647390, acc.: 61.72%] [G loss: 0.903363]\n",
      "epoch:10 step:9377 [D loss: 0.622391, acc.: 64.06%] [G loss: 0.867861]\n",
      "epoch:10 step:9378 [D loss: 0.688447, acc.: 62.50%] [G loss: 0.878802]\n",
      "epoch:10 step:9379 [D loss: 0.631644, acc.: 67.97%] [G loss: 0.858996]\n",
      "epoch:10 step:9380 [D loss: 0.676325, acc.: 53.91%] [G loss: 0.890026]\n",
      "epoch:10 step:9381 [D loss: 0.654216, acc.: 63.28%] [G loss: 0.913059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9382 [D loss: 0.646130, acc.: 61.72%] [G loss: 0.946359]\n",
      "epoch:10 step:9383 [D loss: 0.680373, acc.: 58.59%] [G loss: 0.936338]\n",
      "epoch:10 step:9384 [D loss: 0.613363, acc.: 65.62%] [G loss: 0.945530]\n",
      "epoch:10 step:9385 [D loss: 0.658680, acc.: 60.94%] [G loss: 0.966819]\n",
      "epoch:10 step:9386 [D loss: 0.593735, acc.: 67.97%] [G loss: 1.025352]\n",
      "epoch:10 step:9387 [D loss: 0.646418, acc.: 57.81%] [G loss: 1.022604]\n",
      "epoch:10 step:9388 [D loss: 0.630528, acc.: 66.41%] [G loss: 0.965355]\n",
      "epoch:10 step:9389 [D loss: 0.719170, acc.: 54.69%] [G loss: 0.946234]\n",
      "epoch:10 step:9390 [D loss: 0.723551, acc.: 50.00%] [G loss: 0.972337]\n",
      "epoch:10 step:9391 [D loss: 0.630694, acc.: 60.16%] [G loss: 1.007526]\n",
      "epoch:10 step:9392 [D loss: 0.626072, acc.: 67.19%] [G loss: 1.027133]\n",
      "epoch:10 step:9393 [D loss: 0.712797, acc.: 60.16%] [G loss: 0.875964]\n",
      "epoch:10 step:9394 [D loss: 0.659943, acc.: 60.94%] [G loss: 0.896769]\n",
      "epoch:10 step:9395 [D loss: 0.621346, acc.: 61.72%] [G loss: 0.853996]\n",
      "epoch:10 step:9396 [D loss: 0.688391, acc.: 55.47%] [G loss: 0.877705]\n",
      "epoch:10 step:9397 [D loss: 0.684928, acc.: 56.25%] [G loss: 0.882163]\n",
      "epoch:10 step:9398 [D loss: 0.663016, acc.: 60.94%] [G loss: 0.928984]\n",
      "epoch:10 step:9399 [D loss: 0.634314, acc.: 64.06%] [G loss: 0.910533]\n",
      "epoch:10 step:9400 [D loss: 0.689845, acc.: 50.00%] [G loss: 0.914910]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.884342\n",
      "FID: 9.481627\n",
      "0 = 11.96143736126417\n",
      "1 = 0.05546668680141768\n",
      "2 = 0.9296000003814697\n",
      "3 = 0.8794000148773193\n",
      "4 = 0.9797999858856201\n",
      "5 = 0.9775455594062805\n",
      "6 = 0.8794000148773193\n",
      "7 = 6.0550993382632745\n",
      "8 = 0.06580574938576172\n",
      "9 = 0.731249988079071\n",
      "10 = 0.7013000249862671\n",
      "11 = 0.7612000107765198\n",
      "12 = 0.7459844946861267\n",
      "13 = 0.7013000249862671\n",
      "14 = 7.88441276550293\n",
      "15 = 9.622748374938965\n",
      "16 = 0.08693963289260864\n",
      "17 = 7.884342193603516\n",
      "18 = 9.481626510620117\n",
      "epoch:10 step:9401 [D loss: 0.653983, acc.: 60.16%] [G loss: 0.948708]\n",
      "epoch:10 step:9402 [D loss: 0.638811, acc.: 61.72%] [G loss: 0.895620]\n",
      "epoch:10 step:9403 [D loss: 0.638893, acc.: 60.16%] [G loss: 0.944752]\n",
      "epoch:10 step:9404 [D loss: 0.676351, acc.: 57.81%] [G loss: 0.916339]\n",
      "epoch:10 step:9405 [D loss: 0.630818, acc.: 65.62%] [G loss: 0.904953]\n",
      "epoch:10 step:9406 [D loss: 0.637376, acc.: 71.88%] [G loss: 0.897759]\n",
      "epoch:10 step:9407 [D loss: 0.688228, acc.: 57.03%] [G loss: 0.845031]\n",
      "epoch:10 step:9408 [D loss: 0.730805, acc.: 50.78%] [G loss: 0.879416]\n",
      "epoch:10 step:9409 [D loss: 0.685694, acc.: 51.56%] [G loss: 0.872226]\n",
      "epoch:10 step:9410 [D loss: 0.614205, acc.: 69.53%] [G loss: 0.899074]\n",
      "epoch:10 step:9411 [D loss: 0.668365, acc.: 59.38%] [G loss: 0.917224]\n",
      "epoch:10 step:9412 [D loss: 0.671502, acc.: 62.50%] [G loss: 0.896203]\n",
      "epoch:10 step:9413 [D loss: 0.664410, acc.: 64.06%] [G loss: 0.916381]\n",
      "epoch:10 step:9414 [D loss: 0.686882, acc.: 53.91%] [G loss: 0.969686]\n",
      "epoch:10 step:9415 [D loss: 0.741036, acc.: 53.12%] [G loss: 0.874847]\n",
      "epoch:10 step:9416 [D loss: 0.669715, acc.: 58.59%] [G loss: 0.914661]\n",
      "epoch:10 step:9417 [D loss: 0.652849, acc.: 67.19%] [G loss: 0.938468]\n",
      "epoch:10 step:9418 [D loss: 0.654631, acc.: 60.16%] [G loss: 0.906284]\n",
      "epoch:10 step:9419 [D loss: 0.637298, acc.: 61.72%] [G loss: 0.943674]\n",
      "epoch:10 step:9420 [D loss: 0.651959, acc.: 60.94%] [G loss: 0.966981]\n",
      "epoch:10 step:9421 [D loss: 0.703670, acc.: 53.12%] [G loss: 0.893904]\n",
      "epoch:10 step:9422 [D loss: 0.636531, acc.: 68.75%] [G loss: 0.912639]\n",
      "epoch:10 step:9423 [D loss: 0.652198, acc.: 54.69%] [G loss: 0.942438]\n",
      "epoch:10 step:9424 [D loss: 0.622561, acc.: 67.19%] [G loss: 0.901707]\n",
      "epoch:10 step:9425 [D loss: 0.664959, acc.: 56.25%] [G loss: 1.001802]\n",
      "epoch:10 step:9426 [D loss: 0.665264, acc.: 60.94%] [G loss: 0.957613]\n",
      "epoch:10 step:9427 [D loss: 0.683549, acc.: 59.38%] [G loss: 0.914549]\n",
      "epoch:10 step:9428 [D loss: 0.653856, acc.: 54.69%] [G loss: 0.848066]\n",
      "epoch:10 step:9429 [D loss: 0.656342, acc.: 61.72%] [G loss: 0.859812]\n",
      "epoch:10 step:9430 [D loss: 0.661078, acc.: 61.72%] [G loss: 0.863810]\n",
      "epoch:10 step:9431 [D loss: 0.682732, acc.: 55.47%] [G loss: 0.820661]\n",
      "epoch:10 step:9432 [D loss: 0.671860, acc.: 58.59%] [G loss: 0.881508]\n",
      "epoch:10 step:9433 [D loss: 0.614898, acc.: 67.19%] [G loss: 0.898776]\n",
      "epoch:10 step:9434 [D loss: 0.685955, acc.: 52.34%] [G loss: 0.889769]\n",
      "epoch:10 step:9435 [D loss: 0.665551, acc.: 60.16%] [G loss: 0.898090]\n",
      "epoch:10 step:9436 [D loss: 0.659172, acc.: 61.72%] [G loss: 0.909651]\n",
      "epoch:10 step:9437 [D loss: 0.672407, acc.: 59.38%] [G loss: 0.866085]\n",
      "epoch:10 step:9438 [D loss: 0.642064, acc.: 61.72%] [G loss: 0.907587]\n",
      "epoch:10 step:9439 [D loss: 0.625264, acc.: 66.41%] [G loss: 0.890922]\n",
      "epoch:10 step:9440 [D loss: 0.636542, acc.: 65.62%] [G loss: 0.951067]\n",
      "epoch:10 step:9441 [D loss: 0.692350, acc.: 56.25%] [G loss: 0.912201]\n",
      "epoch:10 step:9442 [D loss: 0.692164, acc.: 53.12%] [G loss: 0.887916]\n",
      "epoch:10 step:9443 [D loss: 0.695009, acc.: 50.00%] [G loss: 0.912861]\n",
      "epoch:10 step:9444 [D loss: 0.611117, acc.: 64.84%] [G loss: 0.920131]\n",
      "epoch:10 step:9445 [D loss: 0.663031, acc.: 61.72%] [G loss: 0.959833]\n",
      "epoch:10 step:9446 [D loss: 0.580274, acc.: 65.62%] [G loss: 0.945321]\n",
      "epoch:10 step:9447 [D loss: 0.580276, acc.: 71.09%] [G loss: 0.938070]\n",
      "epoch:10 step:9448 [D loss: 0.706180, acc.: 59.38%] [G loss: 0.861629]\n",
      "epoch:10 step:9449 [D loss: 0.671663, acc.: 59.38%] [G loss: 0.912155]\n",
      "epoch:10 step:9450 [D loss: 0.674224, acc.: 54.69%] [G loss: 0.886373]\n",
      "epoch:10 step:9451 [D loss: 0.706395, acc.: 49.22%] [G loss: 0.885722]\n",
      "epoch:10 step:9452 [D loss: 0.667585, acc.: 56.25%] [G loss: 0.858305]\n",
      "epoch:10 step:9453 [D loss: 0.644388, acc.: 57.03%] [G loss: 0.913620]\n",
      "epoch:10 step:9454 [D loss: 0.655887, acc.: 59.38%] [G loss: 0.932199]\n",
      "epoch:10 step:9455 [D loss: 0.671703, acc.: 57.03%] [G loss: 0.898047]\n",
      "epoch:10 step:9456 [D loss: 0.646141, acc.: 64.84%] [G loss: 0.956417]\n",
      "epoch:10 step:9457 [D loss: 0.667005, acc.: 59.38%] [G loss: 0.898942]\n",
      "epoch:10 step:9458 [D loss: 0.657809, acc.: 60.16%] [G loss: 0.913999]\n",
      "epoch:10 step:9459 [D loss: 0.670304, acc.: 58.59%] [G loss: 0.935250]\n",
      "epoch:10 step:9460 [D loss: 0.630287, acc.: 67.19%] [G loss: 0.886662]\n",
      "epoch:10 step:9461 [D loss: 0.656557, acc.: 61.72%] [G loss: 0.893899]\n",
      "epoch:10 step:9462 [D loss: 0.613349, acc.: 66.41%] [G loss: 0.951558]\n",
      "epoch:10 step:9463 [D loss: 0.622791, acc.: 67.97%] [G loss: 0.941629]\n",
      "epoch:10 step:9464 [D loss: 0.650713, acc.: 60.94%] [G loss: 0.863977]\n",
      "epoch:10 step:9465 [D loss: 0.631822, acc.: 62.50%] [G loss: 0.888577]\n",
      "epoch:10 step:9466 [D loss: 0.646354, acc.: 60.16%] [G loss: 0.887698]\n",
      "epoch:10 step:9467 [D loss: 0.580984, acc.: 71.09%] [G loss: 0.931437]\n",
      "epoch:10 step:9468 [D loss: 0.629197, acc.: 60.16%] [G loss: 0.975935]\n",
      "epoch:10 step:9469 [D loss: 0.630707, acc.: 67.19%] [G loss: 0.949568]\n",
      "epoch:10 step:9470 [D loss: 0.565038, acc.: 72.66%] [G loss: 1.017901]\n",
      "epoch:10 step:9471 [D loss: 0.688453, acc.: 53.91%] [G loss: 0.907466]\n",
      "epoch:10 step:9472 [D loss: 0.713337, acc.: 53.91%] [G loss: 0.886976]\n",
      "epoch:10 step:9473 [D loss: 0.660718, acc.: 58.59%] [G loss: 0.870079]\n",
      "epoch:10 step:9474 [D loss: 0.673443, acc.: 64.84%] [G loss: 0.866028]\n",
      "epoch:10 step:9475 [D loss: 0.680226, acc.: 57.03%] [G loss: 0.827078]\n",
      "epoch:10 step:9476 [D loss: 0.630280, acc.: 64.06%] [G loss: 0.916518]\n",
      "epoch:10 step:9477 [D loss: 0.633875, acc.: 67.19%] [G loss: 0.993864]\n",
      "epoch:10 step:9478 [D loss: 0.710100, acc.: 50.78%] [G loss: 0.976858]\n",
      "epoch:10 step:9479 [D loss: 0.721106, acc.: 56.25%] [G loss: 0.888900]\n",
      "epoch:10 step:9480 [D loss: 0.662253, acc.: 60.16%] [G loss: 0.896587]\n",
      "epoch:10 step:9481 [D loss: 0.626893, acc.: 67.97%] [G loss: 0.870543]\n",
      "epoch:10 step:9482 [D loss: 0.627039, acc.: 67.97%] [G loss: 0.875901]\n",
      "epoch:10 step:9483 [D loss: 0.650923, acc.: 60.16%] [G loss: 0.909301]\n",
      "epoch:10 step:9484 [D loss: 0.638317, acc.: 62.50%] [G loss: 0.944450]\n",
      "epoch:10 step:9485 [D loss: 0.569441, acc.: 74.22%] [G loss: 0.984738]\n",
      "epoch:10 step:9486 [D loss: 0.592143, acc.: 72.66%] [G loss: 0.940384]\n",
      "epoch:10 step:9487 [D loss: 0.600472, acc.: 71.09%] [G loss: 0.944629]\n",
      "epoch:10 step:9488 [D loss: 0.633286, acc.: 64.84%] [G loss: 0.963717]\n",
      "epoch:10 step:9489 [D loss: 0.588562, acc.: 71.88%] [G loss: 1.004021]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9490 [D loss: 0.704825, acc.: 55.47%] [G loss: 0.950918]\n",
      "epoch:10 step:9491 [D loss: 0.748562, acc.: 54.69%] [G loss: 0.905179]\n",
      "epoch:10 step:9492 [D loss: 0.656691, acc.: 60.16%] [G loss: 1.028882]\n",
      "epoch:10 step:9493 [D loss: 0.651783, acc.: 61.72%] [G loss: 0.999454]\n",
      "epoch:10 step:9494 [D loss: 0.705237, acc.: 54.69%] [G loss: 0.994531]\n",
      "epoch:10 step:9495 [D loss: 0.672445, acc.: 57.03%] [G loss: 0.974252]\n",
      "epoch:10 step:9496 [D loss: 0.608866, acc.: 69.53%] [G loss: 0.924335]\n",
      "epoch:10 step:9497 [D loss: 0.645241, acc.: 63.28%] [G loss: 0.952381]\n",
      "epoch:10 step:9498 [D loss: 0.669559, acc.: 62.50%] [G loss: 0.889859]\n",
      "epoch:10 step:9499 [D loss: 0.655298, acc.: 62.50%] [G loss: 0.847814]\n",
      "epoch:10 step:9500 [D loss: 0.675495, acc.: 60.94%] [G loss: 0.888113]\n",
      "epoch:10 step:9501 [D loss: 0.608304, acc.: 70.31%] [G loss: 0.928515]\n",
      "epoch:10 step:9502 [D loss: 0.674327, acc.: 57.03%] [G loss: 0.893719]\n",
      "epoch:10 step:9503 [D loss: 0.622305, acc.: 67.19%] [G loss: 0.939520]\n",
      "epoch:10 step:9504 [D loss: 0.626268, acc.: 68.75%] [G loss: 1.023869]\n",
      "epoch:10 step:9505 [D loss: 0.608245, acc.: 61.72%] [G loss: 0.951091]\n",
      "epoch:10 step:9506 [D loss: 0.627041, acc.: 64.84%] [G loss: 0.936866]\n",
      "epoch:10 step:9507 [D loss: 0.715678, acc.: 53.91%] [G loss: 0.865126]\n",
      "epoch:10 step:9508 [D loss: 0.688319, acc.: 57.03%] [G loss: 0.888935]\n",
      "epoch:10 step:9509 [D loss: 0.729550, acc.: 47.66%] [G loss: 0.863964]\n",
      "epoch:10 step:9510 [D loss: 0.646873, acc.: 57.81%] [G loss: 0.859015]\n",
      "epoch:10 step:9511 [D loss: 0.702163, acc.: 57.81%] [G loss: 0.861945]\n",
      "epoch:10 step:9512 [D loss: 0.665727, acc.: 60.94%] [G loss: 0.872875]\n",
      "epoch:10 step:9513 [D loss: 0.675716, acc.: 57.81%] [G loss: 0.867742]\n",
      "epoch:10 step:9514 [D loss: 0.659819, acc.: 60.94%] [G loss: 0.869100]\n",
      "epoch:10 step:9515 [D loss: 0.665801, acc.: 57.81%] [G loss: 0.955817]\n",
      "epoch:10 step:9516 [D loss: 0.681767, acc.: 57.81%] [G loss: 0.905909]\n",
      "epoch:10 step:9517 [D loss: 0.671018, acc.: 55.47%] [G loss: 0.939211]\n",
      "epoch:10 step:9518 [D loss: 0.675055, acc.: 55.47%] [G loss: 0.897388]\n",
      "epoch:10 step:9519 [D loss: 0.635814, acc.: 64.06%] [G loss: 0.931252]\n",
      "epoch:10 step:9520 [D loss: 0.646776, acc.: 61.72%] [G loss: 0.878874]\n",
      "epoch:10 step:9521 [D loss: 0.658571, acc.: 63.28%] [G loss: 0.854219]\n",
      "epoch:10 step:9522 [D loss: 0.659749, acc.: 60.16%] [G loss: 0.883856]\n",
      "epoch:10 step:9523 [D loss: 0.690987, acc.: 52.34%] [G loss: 0.907242]\n",
      "epoch:10 step:9524 [D loss: 0.644609, acc.: 61.72%] [G loss: 0.891025]\n",
      "epoch:10 step:9525 [D loss: 0.647646, acc.: 60.94%] [G loss: 0.956238]\n",
      "epoch:10 step:9526 [D loss: 0.622243, acc.: 70.31%] [G loss: 0.926247]\n",
      "epoch:10 step:9527 [D loss: 0.696764, acc.: 55.47%] [G loss: 0.910351]\n",
      "epoch:10 step:9528 [D loss: 0.654447, acc.: 64.06%] [G loss: 0.848231]\n",
      "epoch:10 step:9529 [D loss: 0.674345, acc.: 57.03%] [G loss: 0.893258]\n",
      "epoch:10 step:9530 [D loss: 0.739632, acc.: 52.34%] [G loss: 0.873232]\n",
      "epoch:10 step:9531 [D loss: 0.662751, acc.: 60.16%] [G loss: 0.995306]\n",
      "epoch:10 step:9532 [D loss: 0.630832, acc.: 64.06%] [G loss: 0.923466]\n",
      "epoch:10 step:9533 [D loss: 0.662533, acc.: 61.72%] [G loss: 0.885073]\n",
      "epoch:10 step:9534 [D loss: 0.651096, acc.: 60.94%] [G loss: 0.930508]\n",
      "epoch:10 step:9535 [D loss: 0.643199, acc.: 62.50%] [G loss: 0.898488]\n",
      "epoch:10 step:9536 [D loss: 0.665675, acc.: 60.94%] [G loss: 0.896473]\n",
      "epoch:10 step:9537 [D loss: 0.667110, acc.: 60.94%] [G loss: 0.853706]\n",
      "epoch:10 step:9538 [D loss: 0.709667, acc.: 57.81%] [G loss: 0.809963]\n",
      "epoch:10 step:9539 [D loss: 0.666510, acc.: 61.72%] [G loss: 0.912441]\n",
      "epoch:10 step:9540 [D loss: 0.640236, acc.: 62.50%] [G loss: 0.883326]\n",
      "epoch:10 step:9541 [D loss: 0.683769, acc.: 54.69%] [G loss: 0.827359]\n",
      "epoch:10 step:9542 [D loss: 0.666703, acc.: 60.16%] [G loss: 0.861790]\n",
      "epoch:10 step:9543 [D loss: 0.628055, acc.: 68.75%] [G loss: 0.835016]\n",
      "epoch:10 step:9544 [D loss: 0.673858, acc.: 61.72%] [G loss: 0.874126]\n",
      "epoch:10 step:9545 [D loss: 0.650906, acc.: 64.06%] [G loss: 0.824191]\n",
      "epoch:10 step:9546 [D loss: 0.670040, acc.: 55.47%] [G loss: 0.866263]\n",
      "epoch:10 step:9547 [D loss: 0.679734, acc.: 56.25%] [G loss: 0.905188]\n",
      "epoch:10 step:9548 [D loss: 0.680230, acc.: 56.25%] [G loss: 0.884379]\n",
      "epoch:10 step:9549 [D loss: 0.678532, acc.: 60.16%] [G loss: 0.893076]\n",
      "epoch:10 step:9550 [D loss: 0.685545, acc.: 53.91%] [G loss: 0.844658]\n",
      "epoch:10 step:9551 [D loss: 0.700990, acc.: 46.88%] [G loss: 0.867557]\n",
      "epoch:10 step:9552 [D loss: 0.681746, acc.: 60.16%] [G loss: 0.919569]\n",
      "epoch:10 step:9553 [D loss: 0.669675, acc.: 60.16%] [G loss: 0.907426]\n",
      "epoch:10 step:9554 [D loss: 0.631497, acc.: 71.88%] [G loss: 0.908482]\n",
      "epoch:10 step:9555 [D loss: 0.691175, acc.: 55.47%] [G loss: 0.851446]\n",
      "epoch:10 step:9556 [D loss: 0.703412, acc.: 53.12%] [G loss: 0.941650]\n",
      "epoch:10 step:9557 [D loss: 0.649820, acc.: 63.28%] [G loss: 0.910241]\n",
      "epoch:10 step:9558 [D loss: 0.729115, acc.: 54.69%] [G loss: 0.885311]\n",
      "epoch:10 step:9559 [D loss: 0.722577, acc.: 51.56%] [G loss: 0.879830]\n",
      "epoch:10 step:9560 [D loss: 0.664723, acc.: 60.16%] [G loss: 0.814328]\n",
      "epoch:10 step:9561 [D loss: 0.612693, acc.: 68.75%] [G loss: 0.858213]\n",
      "epoch:10 step:9562 [D loss: 0.648888, acc.: 64.06%] [G loss: 0.873498]\n",
      "epoch:10 step:9563 [D loss: 0.673707, acc.: 61.72%] [G loss: 0.897266]\n",
      "epoch:10 step:9564 [D loss: 0.591010, acc.: 70.31%] [G loss: 0.896155]\n",
      "epoch:10 step:9565 [D loss: 0.606121, acc.: 67.97%] [G loss: 0.938218]\n",
      "epoch:10 step:9566 [D loss: 0.698158, acc.: 54.69%] [G loss: 0.921857]\n",
      "epoch:10 step:9567 [D loss: 0.647043, acc.: 63.28%] [G loss: 0.905896]\n",
      "epoch:10 step:9568 [D loss: 0.605347, acc.: 67.19%] [G loss: 0.927230]\n",
      "epoch:10 step:9569 [D loss: 0.650857, acc.: 57.81%] [G loss: 0.923099]\n",
      "epoch:10 step:9570 [D loss: 0.694399, acc.: 52.34%] [G loss: 0.910955]\n",
      "epoch:10 step:9571 [D loss: 0.665825, acc.: 58.59%] [G loss: 0.870835]\n",
      "epoch:10 step:9572 [D loss: 0.665393, acc.: 62.50%] [G loss: 0.914407]\n",
      "epoch:10 step:9573 [D loss: 0.716847, acc.: 53.12%] [G loss: 0.900512]\n",
      "epoch:10 step:9574 [D loss: 0.678401, acc.: 57.03%] [G loss: 0.865066]\n",
      "epoch:10 step:9575 [D loss: 0.670737, acc.: 60.94%] [G loss: 0.913866]\n",
      "epoch:10 step:9576 [D loss: 0.577237, acc.: 71.88%] [G loss: 0.948619]\n",
      "epoch:10 step:9577 [D loss: 0.669946, acc.: 60.16%] [G loss: 0.976856]\n",
      "epoch:10 step:9578 [D loss: 0.571341, acc.: 66.41%] [G loss: 0.892315]\n",
      "epoch:10 step:9579 [D loss: 0.616743, acc.: 66.41%] [G loss: 0.906408]\n",
      "epoch:10 step:9580 [D loss: 0.686805, acc.: 54.69%] [G loss: 0.868020]\n",
      "epoch:10 step:9581 [D loss: 0.691288, acc.: 55.47%] [G loss: 0.839583]\n",
      "epoch:10 step:9582 [D loss: 0.657212, acc.: 58.59%] [G loss: 0.919656]\n",
      "epoch:10 step:9583 [D loss: 0.707998, acc.: 50.00%] [G loss: 0.912955]\n",
      "epoch:10 step:9584 [D loss: 0.698363, acc.: 51.56%] [G loss: 0.856751]\n",
      "epoch:10 step:9585 [D loss: 0.705822, acc.: 53.91%] [G loss: 0.867742]\n",
      "epoch:10 step:9586 [D loss: 0.636315, acc.: 62.50%] [G loss: 0.881132]\n",
      "epoch:10 step:9587 [D loss: 0.667649, acc.: 55.47%] [G loss: 0.851066]\n",
      "epoch:10 step:9588 [D loss: 0.610913, acc.: 70.31%] [G loss: 0.848106]\n",
      "epoch:10 step:9589 [D loss: 0.592830, acc.: 70.31%] [G loss: 0.972022]\n",
      "epoch:10 step:9590 [D loss: 0.741008, acc.: 48.44%] [G loss: 0.942734]\n",
      "epoch:10 step:9591 [D loss: 0.624658, acc.: 66.41%] [G loss: 0.918564]\n",
      "epoch:10 step:9592 [D loss: 0.632698, acc.: 61.72%] [G loss: 0.928464]\n",
      "epoch:10 step:9593 [D loss: 0.603445, acc.: 63.28%] [G loss: 0.928343]\n",
      "epoch:10 step:9594 [D loss: 0.681615, acc.: 59.38%] [G loss: 0.927700]\n",
      "epoch:10 step:9595 [D loss: 0.674154, acc.: 55.47%] [G loss: 0.842815]\n",
      "epoch:10 step:9596 [D loss: 0.700394, acc.: 50.78%] [G loss: 0.860350]\n",
      "epoch:10 step:9597 [D loss: 0.666207, acc.: 57.03%] [G loss: 0.880900]\n",
      "epoch:10 step:9598 [D loss: 0.661054, acc.: 57.03%] [G loss: 0.927262]\n",
      "epoch:10 step:9599 [D loss: 0.596804, acc.: 69.53%] [G loss: 0.864716]\n",
      "epoch:10 step:9600 [D loss: 0.604188, acc.: 64.84%] [G loss: 1.021206]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.815265\n",
      "FID: 12.906065\n",
      "0 = 12.000962788248069\n",
      "1 = 0.05843076289707653\n",
      "2 = 0.9322999715805054\n",
      "3 = 0.8820000290870667\n",
      "4 = 0.9825999736785889\n",
      "5 = 0.9806537628173828\n",
      "6 = 0.8820000290870667\n",
      "7 = 6.476259056854235\n",
      "8 = 0.08051164095094125\n",
      "9 = 0.7386500239372253\n",
      "10 = 0.7099999785423279\n",
      "11 = 0.767300009727478\n",
      "12 = 0.7531558275222778\n",
      "13 = 0.7099999785423279\n",
      "14 = 7.815332412719727\n",
      "15 = 9.558171272277832\n",
      "16 = 0.10422182828187943\n",
      "17 = 7.815264701843262\n",
      "18 = 12.906064987182617\n",
      "epoch:10 step:9601 [D loss: 0.555906, acc.: 70.31%] [G loss: 1.036043]\n",
      "epoch:10 step:9602 [D loss: 0.542642, acc.: 75.78%] [G loss: 0.997461]\n",
      "epoch:10 step:9603 [D loss: 0.655752, acc.: 58.59%] [G loss: 0.938942]\n",
      "epoch:10 step:9604 [D loss: 0.712438, acc.: 52.34%] [G loss: 0.926479]\n",
      "epoch:10 step:9605 [D loss: 0.667526, acc.: 57.81%] [G loss: 0.888947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9606 [D loss: 0.668312, acc.: 60.16%] [G loss: 0.877498]\n",
      "epoch:10 step:9607 [D loss: 0.629922, acc.: 67.19%] [G loss: 0.911365]\n",
      "epoch:10 step:9608 [D loss: 0.662279, acc.: 59.38%] [G loss: 0.954169]\n",
      "epoch:10 step:9609 [D loss: 0.672267, acc.: 54.69%] [G loss: 0.910904]\n",
      "epoch:10 step:9610 [D loss: 0.645620, acc.: 63.28%] [G loss: 0.939795]\n",
      "epoch:10 step:9611 [D loss: 0.631596, acc.: 68.75%] [G loss: 0.958564]\n",
      "epoch:10 step:9612 [D loss: 0.621310, acc.: 66.41%] [G loss: 0.941351]\n",
      "epoch:10 step:9613 [D loss: 0.643662, acc.: 60.94%] [G loss: 0.967904]\n",
      "epoch:10 step:9614 [D loss: 0.664012, acc.: 60.16%] [G loss: 0.925350]\n",
      "epoch:10 step:9615 [D loss: 0.673357, acc.: 59.38%] [G loss: 0.936972]\n",
      "epoch:10 step:9616 [D loss: 0.677304, acc.: 59.38%] [G loss: 0.879079]\n",
      "epoch:10 step:9617 [D loss: 0.664681, acc.: 62.50%] [G loss: 0.903846]\n",
      "epoch:10 step:9618 [D loss: 0.648899, acc.: 62.50%] [G loss: 0.906481]\n",
      "epoch:10 step:9619 [D loss: 0.693612, acc.: 50.00%] [G loss: 0.895394]\n",
      "epoch:10 step:9620 [D loss: 0.710451, acc.: 46.88%] [G loss: 0.899179]\n",
      "epoch:10 step:9621 [D loss: 0.688299, acc.: 54.69%] [G loss: 0.945405]\n",
      "epoch:10 step:9622 [D loss: 0.666701, acc.: 60.16%] [G loss: 0.966447]\n",
      "epoch:10 step:9623 [D loss: 0.620913, acc.: 69.53%] [G loss: 0.920761]\n",
      "epoch:10 step:9624 [D loss: 0.659040, acc.: 66.41%] [G loss: 0.905483]\n",
      "epoch:10 step:9625 [D loss: 0.623201, acc.: 65.62%] [G loss: 0.900896]\n",
      "epoch:10 step:9626 [D loss: 0.623442, acc.: 68.75%] [G loss: 0.923582]\n",
      "epoch:10 step:9627 [D loss: 0.703974, acc.: 53.12%] [G loss: 0.941408]\n",
      "epoch:10 step:9628 [D loss: 0.636319, acc.: 64.06%] [G loss: 0.942775]\n",
      "epoch:10 step:9629 [D loss: 0.660330, acc.: 63.28%] [G loss: 0.930619]\n",
      "epoch:10 step:9630 [D loss: 0.694753, acc.: 53.12%] [G loss: 0.959490]\n",
      "epoch:10 step:9631 [D loss: 0.626092, acc.: 60.94%] [G loss: 0.953668]\n",
      "epoch:10 step:9632 [D loss: 0.615211, acc.: 65.62%] [G loss: 0.972481]\n",
      "epoch:10 step:9633 [D loss: 0.756592, acc.: 50.78%] [G loss: 0.878431]\n",
      "epoch:10 step:9634 [D loss: 0.664097, acc.: 58.59%] [G loss: 0.885255]\n",
      "epoch:10 step:9635 [D loss: 0.686767, acc.: 50.00%] [G loss: 0.882583]\n",
      "epoch:10 step:9636 [D loss: 0.647813, acc.: 64.06%] [G loss: 0.901392]\n",
      "epoch:10 step:9637 [D loss: 0.682822, acc.: 58.59%] [G loss: 0.923332]\n",
      "epoch:10 step:9638 [D loss: 0.640321, acc.: 63.28%] [G loss: 0.865845]\n",
      "epoch:10 step:9639 [D loss: 0.665225, acc.: 56.25%] [G loss: 0.967833]\n",
      "epoch:10 step:9640 [D loss: 0.646727, acc.: 59.38%] [G loss: 0.915044]\n",
      "epoch:10 step:9641 [D loss: 0.620755, acc.: 64.84%] [G loss: 0.985068]\n",
      "epoch:10 step:9642 [D loss: 0.660913, acc.: 60.94%] [G loss: 0.946336]\n",
      "epoch:10 step:9643 [D loss: 0.668476, acc.: 64.06%] [G loss: 0.879831]\n",
      "epoch:10 step:9644 [D loss: 0.655706, acc.: 58.59%] [G loss: 0.866452]\n",
      "epoch:10 step:9645 [D loss: 0.660442, acc.: 62.50%] [G loss: 0.882921]\n",
      "epoch:10 step:9646 [D loss: 0.651112, acc.: 58.59%] [G loss: 0.867124]\n",
      "epoch:10 step:9647 [D loss: 0.719203, acc.: 49.22%] [G loss: 0.845828]\n",
      "epoch:10 step:9648 [D loss: 0.680331, acc.: 57.81%] [G loss: 0.865303]\n",
      "epoch:10 step:9649 [D loss: 0.619824, acc.: 60.94%] [G loss: 0.958234]\n",
      "epoch:10 step:9650 [D loss: 0.679508, acc.: 59.38%] [G loss: 0.940829]\n",
      "epoch:10 step:9651 [D loss: 0.686557, acc.: 57.81%] [G loss: 0.898939]\n",
      "epoch:10 step:9652 [D loss: 0.668617, acc.: 53.91%] [G loss: 0.871470]\n",
      "epoch:10 step:9653 [D loss: 0.629630, acc.: 64.06%] [G loss: 0.892197]\n",
      "epoch:10 step:9654 [D loss: 0.639186, acc.: 67.19%] [G loss: 0.892351]\n",
      "epoch:10 step:9655 [D loss: 0.626834, acc.: 65.62%] [G loss: 0.953434]\n",
      "epoch:10 step:9656 [D loss: 0.596716, acc.: 70.31%] [G loss: 0.895762]\n",
      "epoch:10 step:9657 [D loss: 0.647772, acc.: 64.06%] [G loss: 0.942219]\n",
      "epoch:10 step:9658 [D loss: 0.644102, acc.: 63.28%] [G loss: 0.901980]\n",
      "epoch:10 step:9659 [D loss: 0.610089, acc.: 71.09%] [G loss: 0.950646]\n",
      "epoch:10 step:9660 [D loss: 0.648036, acc.: 61.72%] [G loss: 0.941713]\n",
      "epoch:10 step:9661 [D loss: 0.719562, acc.: 56.25%] [G loss: 0.872396]\n",
      "epoch:10 step:9662 [D loss: 0.664633, acc.: 59.38%] [G loss: 0.845020]\n",
      "epoch:10 step:9663 [D loss: 0.628955, acc.: 62.50%] [G loss: 0.883974]\n",
      "epoch:10 step:9664 [D loss: 0.689143, acc.: 56.25%] [G loss: 0.907561]\n",
      "epoch:10 step:9665 [D loss: 0.689501, acc.: 53.91%] [G loss: 0.875794]\n",
      "epoch:10 step:9666 [D loss: 0.642672, acc.: 63.28%] [G loss: 0.880780]\n",
      "epoch:10 step:9667 [D loss: 0.650335, acc.: 60.16%] [G loss: 0.943309]\n",
      "epoch:10 step:9668 [D loss: 0.630884, acc.: 63.28%] [G loss: 0.968716]\n",
      "epoch:10 step:9669 [D loss: 0.630350, acc.: 59.38%] [G loss: 0.954368]\n",
      "epoch:10 step:9670 [D loss: 0.612167, acc.: 69.53%] [G loss: 0.947339]\n",
      "epoch:10 step:9671 [D loss: 0.722321, acc.: 56.25%] [G loss: 0.886444]\n",
      "epoch:10 step:9672 [D loss: 0.635499, acc.: 63.28%] [G loss: 0.829315]\n",
      "epoch:10 step:9673 [D loss: 0.650345, acc.: 60.16%] [G loss: 0.878747]\n",
      "epoch:10 step:9674 [D loss: 0.616387, acc.: 60.94%] [G loss: 0.888939]\n",
      "epoch:10 step:9675 [D loss: 0.661084, acc.: 60.16%] [G loss: 0.910552]\n",
      "epoch:10 step:9676 [D loss: 0.663381, acc.: 59.38%] [G loss: 0.939016]\n",
      "epoch:10 step:9677 [D loss: 0.606007, acc.: 71.09%] [G loss: 0.895263]\n",
      "epoch:10 step:9678 [D loss: 0.669847, acc.: 58.59%] [G loss: 0.886605]\n",
      "epoch:10 step:9679 [D loss: 0.622692, acc.: 70.31%] [G loss: 0.908984]\n",
      "epoch:10 step:9680 [D loss: 0.665770, acc.: 57.81%] [G loss: 0.967442]\n",
      "epoch:10 step:9681 [D loss: 0.619712, acc.: 67.19%] [G loss: 0.944844]\n",
      "epoch:10 step:9682 [D loss: 0.595966, acc.: 70.31%] [G loss: 0.929349]\n",
      "epoch:10 step:9683 [D loss: 0.581326, acc.: 69.53%] [G loss: 0.990790]\n",
      "epoch:10 step:9684 [D loss: 0.601372, acc.: 71.88%] [G loss: 0.945233]\n",
      "epoch:10 step:9685 [D loss: 0.628032, acc.: 64.06%] [G loss: 0.965732]\n",
      "epoch:10 step:9686 [D loss: 0.779937, acc.: 49.22%] [G loss: 0.963442]\n",
      "epoch:10 step:9687 [D loss: 0.659737, acc.: 60.16%] [G loss: 0.914435]\n",
      "epoch:10 step:9688 [D loss: 0.649231, acc.: 62.50%] [G loss: 0.882236]\n",
      "epoch:10 step:9689 [D loss: 0.626215, acc.: 65.62%] [G loss: 0.881654]\n",
      "epoch:10 step:9690 [D loss: 0.619624, acc.: 65.62%] [G loss: 0.877551]\n",
      "epoch:10 step:9691 [D loss: 0.636419, acc.: 60.16%] [G loss: 0.856782]\n",
      "epoch:10 step:9692 [D loss: 0.633748, acc.: 63.28%] [G loss: 0.890281]\n",
      "epoch:10 step:9693 [D loss: 0.695676, acc.: 59.38%] [G loss: 0.855405]\n",
      "epoch:10 step:9694 [D loss: 0.644655, acc.: 62.50%] [G loss: 0.840608]\n",
      "epoch:10 step:9695 [D loss: 0.661208, acc.: 61.72%] [G loss: 0.849031]\n",
      "epoch:10 step:9696 [D loss: 0.678133, acc.: 60.16%] [G loss: 0.879269]\n",
      "epoch:10 step:9697 [D loss: 0.618905, acc.: 69.53%] [G loss: 0.880212]\n",
      "epoch:10 step:9698 [D loss: 0.660346, acc.: 64.84%] [G loss: 0.953913]\n",
      "epoch:10 step:9699 [D loss: 0.704538, acc.: 57.03%] [G loss: 0.910940]\n",
      "epoch:10 step:9700 [D loss: 0.637946, acc.: 67.19%] [G loss: 0.893619]\n",
      "epoch:10 step:9701 [D loss: 0.646862, acc.: 59.38%] [G loss: 0.854486]\n",
      "epoch:10 step:9702 [D loss: 0.615560, acc.: 70.31%] [G loss: 0.926942]\n",
      "epoch:10 step:9703 [D loss: 0.620986, acc.: 64.06%] [G loss: 0.938239]\n",
      "epoch:10 step:9704 [D loss: 0.657062, acc.: 62.50%] [G loss: 0.898765]\n",
      "epoch:10 step:9705 [D loss: 0.633804, acc.: 64.84%] [G loss: 0.905358]\n",
      "epoch:10 step:9706 [D loss: 0.635873, acc.: 64.06%] [G loss: 0.924951]\n",
      "epoch:10 step:9707 [D loss: 0.616713, acc.: 65.62%] [G loss: 0.882213]\n",
      "epoch:10 step:9708 [D loss: 0.630946, acc.: 60.16%] [G loss: 0.882479]\n",
      "epoch:10 step:9709 [D loss: 0.654726, acc.: 64.84%] [G loss: 0.941590]\n",
      "epoch:10 step:9710 [D loss: 0.629348, acc.: 64.84%] [G loss: 0.838465]\n",
      "epoch:10 step:9711 [D loss: 0.714531, acc.: 54.69%] [G loss: 0.885381]\n",
      "epoch:10 step:9712 [D loss: 0.752009, acc.: 40.62%] [G loss: 0.880912]\n",
      "epoch:10 step:9713 [D loss: 0.633662, acc.: 68.75%] [G loss: 0.959384]\n",
      "epoch:10 step:9714 [D loss: 0.651566, acc.: 61.72%] [G loss: 0.946964]\n",
      "epoch:10 step:9715 [D loss: 0.638312, acc.: 61.72%] [G loss: 1.035825]\n",
      "epoch:10 step:9716 [D loss: 0.610576, acc.: 67.97%] [G loss: 0.990015]\n",
      "epoch:10 step:9717 [D loss: 0.541336, acc.: 75.00%] [G loss: 0.957197]\n",
      "epoch:10 step:9718 [D loss: 0.779116, acc.: 50.78%] [G loss: 0.914279]\n",
      "epoch:10 step:9719 [D loss: 0.763077, acc.: 42.19%] [G loss: 0.861179]\n",
      "epoch:10 step:9720 [D loss: 0.639011, acc.: 69.53%] [G loss: 0.845913]\n",
      "epoch:10 step:9721 [D loss: 0.668002, acc.: 61.72%] [G loss: 0.876350]\n",
      "epoch:10 step:9722 [D loss: 0.664752, acc.: 60.94%] [G loss: 0.912119]\n",
      "epoch:10 step:9723 [D loss: 0.627974, acc.: 64.84%] [G loss: 0.859876]\n",
      "epoch:10 step:9724 [D loss: 0.587472, acc.: 73.44%] [G loss: 0.976612]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9725 [D loss: 0.628205, acc.: 66.41%] [G loss: 0.948790]\n",
      "epoch:10 step:9726 [D loss: 0.682479, acc.: 53.91%] [G loss: 0.955031]\n",
      "epoch:10 step:9727 [D loss: 0.614381, acc.: 62.50%] [G loss: 0.875588]\n",
      "epoch:10 step:9728 [D loss: 0.576983, acc.: 70.31%] [G loss: 0.882831]\n",
      "epoch:10 step:9729 [D loss: 0.648784, acc.: 61.72%] [G loss: 0.923597]\n",
      "epoch:10 step:9730 [D loss: 0.589247, acc.: 67.97%] [G loss: 0.934001]\n",
      "epoch:10 step:9731 [D loss: 0.619467, acc.: 65.62%] [G loss: 0.950182]\n",
      "epoch:10 step:9732 [D loss: 0.682080, acc.: 53.12%] [G loss: 0.925587]\n",
      "epoch:10 step:9733 [D loss: 0.651471, acc.: 64.06%] [G loss: 0.880151]\n",
      "epoch:10 step:9734 [D loss: 0.618447, acc.: 62.50%] [G loss: 0.916958]\n",
      "epoch:10 step:9735 [D loss: 0.649079, acc.: 57.81%] [G loss: 0.926725]\n",
      "epoch:10 step:9736 [D loss: 0.672226, acc.: 64.06%] [G loss: 0.916445]\n",
      "epoch:10 step:9737 [D loss: 0.647978, acc.: 60.94%] [G loss: 0.883361]\n",
      "epoch:10 step:9738 [D loss: 0.668082, acc.: 57.03%] [G loss: 0.910167]\n",
      "epoch:10 step:9739 [D loss: 0.695912, acc.: 51.56%] [G loss: 0.826173]\n",
      "epoch:10 step:9740 [D loss: 0.631704, acc.: 64.84%] [G loss: 0.894737]\n",
      "epoch:10 step:9741 [D loss: 0.643462, acc.: 61.72%] [G loss: 0.890792]\n",
      "epoch:10 step:9742 [D loss: 0.686048, acc.: 53.91%] [G loss: 0.922008]\n",
      "epoch:10 step:9743 [D loss: 0.708072, acc.: 58.59%] [G loss: 0.932036]\n",
      "epoch:10 step:9744 [D loss: 0.647652, acc.: 64.84%] [G loss: 0.939675]\n",
      "epoch:10 step:9745 [D loss: 0.659081, acc.: 60.94%] [G loss: 0.916928]\n",
      "epoch:10 step:9746 [D loss: 0.681032, acc.: 55.47%] [G loss: 0.915342]\n",
      "epoch:10 step:9747 [D loss: 0.694280, acc.: 62.50%] [G loss: 0.917426]\n",
      "epoch:10 step:9748 [D loss: 0.713442, acc.: 51.56%] [G loss: 0.883373]\n",
      "epoch:10 step:9749 [D loss: 0.666672, acc.: 60.94%] [G loss: 0.885271]\n",
      "epoch:10 step:9750 [D loss: 0.679274, acc.: 62.50%] [G loss: 0.886393]\n",
      "epoch:10 step:9751 [D loss: 0.656307, acc.: 60.16%] [G loss: 0.875137]\n",
      "epoch:10 step:9752 [D loss: 0.671733, acc.: 59.38%] [G loss: 0.892835]\n",
      "epoch:10 step:9753 [D loss: 0.643826, acc.: 64.06%] [G loss: 0.862695]\n",
      "epoch:10 step:9754 [D loss: 0.632101, acc.: 63.28%] [G loss: 0.946153]\n",
      "epoch:10 step:9755 [D loss: 0.625263, acc.: 65.62%] [G loss: 0.947943]\n",
      "epoch:10 step:9756 [D loss: 0.654472, acc.: 60.94%] [G loss: 0.912246]\n",
      "epoch:10 step:9757 [D loss: 0.666975, acc.: 60.16%] [G loss: 0.848274]\n",
      "epoch:10 step:9758 [D loss: 0.673244, acc.: 62.50%] [G loss: 0.920294]\n",
      "epoch:10 step:9759 [D loss: 0.585277, acc.: 68.75%] [G loss: 0.927249]\n",
      "epoch:10 step:9760 [D loss: 0.642699, acc.: 67.19%] [G loss: 0.877608]\n",
      "epoch:10 step:9761 [D loss: 0.651204, acc.: 67.19%] [G loss: 0.850665]\n",
      "epoch:10 step:9762 [D loss: 0.637424, acc.: 64.06%] [G loss: 0.859612]\n",
      "epoch:10 step:9763 [D loss: 0.680501, acc.: 54.69%] [G loss: 0.901497]\n",
      "epoch:10 step:9764 [D loss: 0.669055, acc.: 61.72%] [G loss: 0.872243]\n",
      "epoch:10 step:9765 [D loss: 0.647924, acc.: 60.94%] [G loss: 0.851823]\n",
      "epoch:10 step:9766 [D loss: 0.705184, acc.: 49.22%] [G loss: 0.864178]\n",
      "epoch:10 step:9767 [D loss: 0.642156, acc.: 67.19%] [G loss: 0.907189]\n",
      "epoch:10 step:9768 [D loss: 0.563190, acc.: 78.12%] [G loss: 0.903962]\n",
      "epoch:10 step:9769 [D loss: 0.589266, acc.: 71.88%] [G loss: 0.993517]\n",
      "epoch:10 step:9770 [D loss: 0.726458, acc.: 50.00%] [G loss: 0.898893]\n",
      "epoch:10 step:9771 [D loss: 0.705082, acc.: 52.34%] [G loss: 0.838334]\n",
      "epoch:10 step:9772 [D loss: 0.671844, acc.: 57.03%] [G loss: 0.877540]\n",
      "epoch:10 step:9773 [D loss: 0.689758, acc.: 57.81%] [G loss: 0.831997]\n",
      "epoch:10 step:9774 [D loss: 0.631390, acc.: 65.62%] [G loss: 0.871194]\n",
      "epoch:10 step:9775 [D loss: 0.640871, acc.: 62.50%] [G loss: 0.849456]\n",
      "epoch:10 step:9776 [D loss: 0.623705, acc.: 68.75%] [G loss: 0.899060]\n",
      "epoch:10 step:9777 [D loss: 0.683320, acc.: 57.03%] [G loss: 0.896530]\n",
      "epoch:10 step:9778 [D loss: 0.703953, acc.: 55.47%] [G loss: 0.946443]\n",
      "epoch:10 step:9779 [D loss: 0.684045, acc.: 57.03%] [G loss: 0.949299]\n",
      "epoch:10 step:9780 [D loss: 0.672902, acc.: 61.72%] [G loss: 0.853364]\n",
      "epoch:10 step:9781 [D loss: 0.671122, acc.: 58.59%] [G loss: 0.882277]\n",
      "epoch:10 step:9782 [D loss: 0.680200, acc.: 54.69%] [G loss: 0.866922]\n",
      "epoch:10 step:9783 [D loss: 0.684558, acc.: 60.94%] [G loss: 0.822446]\n",
      "epoch:10 step:9784 [D loss: 0.650044, acc.: 57.03%] [G loss: 0.923142]\n",
      "epoch:10 step:9785 [D loss: 0.656624, acc.: 65.62%] [G loss: 0.980485]\n",
      "epoch:10 step:9786 [D loss: 0.585704, acc.: 70.31%] [G loss: 0.950369]\n",
      "epoch:10 step:9787 [D loss: 0.671337, acc.: 57.03%] [G loss: 0.898011]\n",
      "epoch:10 step:9788 [D loss: 0.745084, acc.: 49.22%] [G loss: 0.856098]\n",
      "epoch:10 step:9789 [D loss: 0.678368, acc.: 61.72%] [G loss: 0.870901]\n",
      "epoch:10 step:9790 [D loss: 0.671741, acc.: 54.69%] [G loss: 0.863443]\n",
      "epoch:10 step:9791 [D loss: 0.704638, acc.: 53.12%] [G loss: 0.832270]\n",
      "epoch:10 step:9792 [D loss: 0.685043, acc.: 52.34%] [G loss: 0.819269]\n",
      "epoch:10 step:9793 [D loss: 0.678420, acc.: 61.72%] [G loss: 0.902201]\n",
      "epoch:10 step:9794 [D loss: 0.705013, acc.: 51.56%] [G loss: 0.936411]\n",
      "epoch:10 step:9795 [D loss: 0.667180, acc.: 62.50%] [G loss: 0.939689]\n",
      "epoch:10 step:9796 [D loss: 0.645737, acc.: 62.50%] [G loss: 0.987188]\n",
      "epoch:10 step:9797 [D loss: 0.600755, acc.: 64.84%] [G loss: 1.020266]\n",
      "epoch:10 step:9798 [D loss: 0.588918, acc.: 67.97%] [G loss: 0.898211]\n",
      "epoch:10 step:9799 [D loss: 0.679351, acc.: 57.81%] [G loss: 0.942208]\n",
      "epoch:10 step:9800 [D loss: 0.658660, acc.: 64.06%] [G loss: 0.899846]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.832070\n",
      "FID: 10.452115\n",
      "0 = 12.032462334489818\n",
      "1 = 0.06084246928273383\n",
      "2 = 0.9332000017166138\n",
      "3 = 0.8855000138282776\n",
      "4 = 0.98089998960495\n",
      "5 = 0.9788857102394104\n",
      "6 = 0.8855000138282776\n",
      "7 = 6.238133887767785\n",
      "8 = 0.07462321048297\n",
      "9 = 0.7372499704360962\n",
      "10 = 0.7106999754905701\n",
      "11 = 0.7638000249862671\n",
      "12 = 0.7505544424057007\n",
      "13 = 0.7106999754905701\n",
      "14 = 7.832139015197754\n",
      "15 = 9.613834381103516\n",
      "16 = 0.08761053532361984\n",
      "17 = 7.8320698738098145\n",
      "18 = 10.452115058898926\n",
      "epoch:10 step:9801 [D loss: 0.733025, acc.: 50.00%] [G loss: 0.897011]\n",
      "epoch:10 step:9802 [D loss: 0.693674, acc.: 53.12%] [G loss: 0.923430]\n",
      "epoch:10 step:9803 [D loss: 0.697259, acc.: 56.25%] [G loss: 0.929771]\n",
      "epoch:10 step:9804 [D loss: 0.620230, acc.: 69.53%] [G loss: 0.926782]\n",
      "epoch:10 step:9805 [D loss: 0.617192, acc.: 65.62%] [G loss: 0.941298]\n",
      "epoch:10 step:9806 [D loss: 0.589466, acc.: 69.53%] [G loss: 0.920366]\n",
      "epoch:10 step:9807 [D loss: 0.728746, acc.: 53.91%] [G loss: 0.869663]\n",
      "epoch:10 step:9808 [D loss: 0.672699, acc.: 59.38%] [G loss: 0.841662]\n",
      "epoch:10 step:9809 [D loss: 0.666675, acc.: 60.16%] [G loss: 0.884665]\n",
      "epoch:10 step:9810 [D loss: 0.639011, acc.: 61.72%] [G loss: 0.899540]\n",
      "epoch:10 step:9811 [D loss: 0.639566, acc.: 67.97%] [G loss: 0.927212]\n",
      "epoch:10 step:9812 [D loss: 0.651215, acc.: 54.69%] [G loss: 0.902866]\n",
      "epoch:10 step:9813 [D loss: 0.631066, acc.: 64.06%] [G loss: 0.947077]\n",
      "epoch:10 step:9814 [D loss: 0.660395, acc.: 60.16%] [G loss: 0.853127]\n",
      "epoch:10 step:9815 [D loss: 0.618896, acc.: 64.84%] [G loss: 0.902968]\n",
      "epoch:10 step:9816 [D loss: 0.669399, acc.: 61.72%] [G loss: 0.886036]\n",
      "epoch:10 step:9817 [D loss: 0.627958, acc.: 63.28%] [G loss: 0.892552]\n",
      "epoch:10 step:9818 [D loss: 0.686054, acc.: 55.47%] [G loss: 0.901749]\n",
      "epoch:10 step:9819 [D loss: 0.686084, acc.: 55.47%] [G loss: 0.901493]\n",
      "epoch:10 step:9820 [D loss: 0.633671, acc.: 65.62%] [G loss: 0.860829]\n",
      "epoch:10 step:9821 [D loss: 0.606832, acc.: 68.75%] [G loss: 0.925510]\n",
      "epoch:10 step:9822 [D loss: 0.642099, acc.: 66.41%] [G loss: 0.911677]\n",
      "epoch:10 step:9823 [D loss: 0.642962, acc.: 61.72%] [G loss: 0.935455]\n",
      "epoch:10 step:9824 [D loss: 0.666245, acc.: 60.94%] [G loss: 0.919481]\n",
      "epoch:10 step:9825 [D loss: 0.708840, acc.: 58.59%] [G loss: 0.966106]\n",
      "epoch:10 step:9826 [D loss: 0.653978, acc.: 60.94%] [G loss: 0.936952]\n",
      "epoch:10 step:9827 [D loss: 0.584534, acc.: 72.66%] [G loss: 0.974339]\n",
      "epoch:10 step:9828 [D loss: 0.745319, acc.: 50.78%] [G loss: 0.881844]\n",
      "epoch:10 step:9829 [D loss: 0.670089, acc.: 55.47%] [G loss: 0.868270]\n",
      "epoch:10 step:9830 [D loss: 0.718716, acc.: 48.44%] [G loss: 0.857645]\n",
      "epoch:10 step:9831 [D loss: 0.700905, acc.: 53.91%] [G loss: 0.852999]\n",
      "epoch:10 step:9832 [D loss: 0.666664, acc.: 60.94%] [G loss: 0.865022]\n",
      "epoch:10 step:9833 [D loss: 0.699454, acc.: 55.47%] [G loss: 0.870890]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9834 [D loss: 0.679142, acc.: 58.59%] [G loss: 0.820146]\n",
      "epoch:10 step:9835 [D loss: 0.630694, acc.: 66.41%] [G loss: 0.839895]\n",
      "epoch:10 step:9836 [D loss: 0.671362, acc.: 60.94%] [G loss: 0.797991]\n",
      "epoch:10 step:9837 [D loss: 0.651770, acc.: 58.59%] [G loss: 0.885559]\n",
      "epoch:10 step:9838 [D loss: 0.658331, acc.: 60.16%] [G loss: 0.895839]\n",
      "epoch:10 step:9839 [D loss: 0.640038, acc.: 62.50%] [G loss: 0.919667]\n",
      "epoch:10 step:9840 [D loss: 0.641835, acc.: 65.62%] [G loss: 0.934359]\n",
      "epoch:10 step:9841 [D loss: 0.572121, acc.: 74.22%] [G loss: 1.008491]\n",
      "epoch:10 step:9842 [D loss: 0.651684, acc.: 60.94%] [G loss: 0.954231]\n",
      "epoch:10 step:9843 [D loss: 0.744678, acc.: 50.00%] [G loss: 0.948951]\n",
      "epoch:10 step:9844 [D loss: 0.674320, acc.: 55.47%] [G loss: 0.926191]\n",
      "epoch:10 step:9845 [D loss: 0.639299, acc.: 63.28%] [G loss: 0.979655]\n",
      "epoch:10 step:9846 [D loss: 0.659616, acc.: 66.41%] [G loss: 0.948138]\n",
      "epoch:10 step:9847 [D loss: 0.726836, acc.: 52.34%] [G loss: 0.876425]\n",
      "epoch:10 step:9848 [D loss: 0.701766, acc.: 53.12%] [G loss: 0.833335]\n",
      "epoch:10 step:9849 [D loss: 0.651581, acc.: 67.97%] [G loss: 0.823959]\n",
      "epoch:10 step:9850 [D loss: 0.639222, acc.: 66.41%] [G loss: 0.852405]\n",
      "epoch:10 step:9851 [D loss: 0.640478, acc.: 65.62%] [G loss: 0.873772]\n",
      "epoch:10 step:9852 [D loss: 0.702299, acc.: 53.12%] [G loss: 0.917961]\n",
      "epoch:10 step:9853 [D loss: 0.672498, acc.: 59.38%] [G loss: 0.869120]\n",
      "epoch:10 step:9854 [D loss: 0.619832, acc.: 65.62%] [G loss: 0.926002]\n",
      "epoch:10 step:9855 [D loss: 0.653321, acc.: 60.16%] [G loss: 0.867765]\n",
      "epoch:10 step:9856 [D loss: 0.669430, acc.: 63.28%] [G loss: 0.907774]\n",
      "epoch:10 step:9857 [D loss: 0.669762, acc.: 58.59%] [G loss: 0.927819]\n",
      "epoch:10 step:9858 [D loss: 0.614697, acc.: 63.28%] [G loss: 0.926913]\n",
      "epoch:10 step:9859 [D loss: 0.706407, acc.: 56.25%] [G loss: 0.856299]\n",
      "epoch:10 step:9860 [D loss: 0.717647, acc.: 54.69%] [G loss: 0.895999]\n",
      "epoch:10 step:9861 [D loss: 0.652779, acc.: 61.72%] [G loss: 0.930639]\n",
      "epoch:10 step:9862 [D loss: 0.704166, acc.: 52.34%] [G loss: 0.944520]\n",
      "epoch:10 step:9863 [D loss: 0.681099, acc.: 56.25%] [G loss: 0.877200]\n",
      "epoch:10 step:9864 [D loss: 0.625241, acc.: 66.41%] [G loss: 0.857697]\n",
      "epoch:10 step:9865 [D loss: 0.608184, acc.: 66.41%] [G loss: 0.934162]\n",
      "epoch:10 step:9866 [D loss: 0.658069, acc.: 64.06%] [G loss: 0.917586]\n",
      "epoch:10 step:9867 [D loss: 0.658133, acc.: 61.72%] [G loss: 0.879813]\n",
      "epoch:10 step:9868 [D loss: 0.678849, acc.: 58.59%] [G loss: 0.932608]\n",
      "epoch:10 step:9869 [D loss: 0.584649, acc.: 73.44%] [G loss: 0.934967]\n",
      "epoch:10 step:9870 [D loss: 0.700338, acc.: 51.56%] [G loss: 0.897978]\n",
      "epoch:10 step:9871 [D loss: 0.718720, acc.: 53.91%] [G loss: 0.906142]\n",
      "epoch:10 step:9872 [D loss: 0.675874, acc.: 55.47%] [G loss: 0.880456]\n",
      "epoch:10 step:9873 [D loss: 0.664599, acc.: 58.59%] [G loss: 0.930242]\n",
      "epoch:10 step:9874 [D loss: 0.576708, acc.: 71.88%] [G loss: 0.922622]\n",
      "epoch:10 step:9875 [D loss: 0.667916, acc.: 58.59%] [G loss: 0.932898]\n",
      "epoch:10 step:9876 [D loss: 0.621961, acc.: 62.50%] [G loss: 0.983454]\n",
      "epoch:10 step:9877 [D loss: 0.634696, acc.: 67.19%] [G loss: 0.935815]\n",
      "epoch:10 step:9878 [D loss: 0.548071, acc.: 70.31%] [G loss: 1.019091]\n",
      "epoch:10 step:9879 [D loss: 0.697166, acc.: 57.03%] [G loss: 0.961532]\n",
      "epoch:10 step:9880 [D loss: 0.774566, acc.: 46.88%] [G loss: 0.910786]\n",
      "epoch:10 step:9881 [D loss: 0.680446, acc.: 56.25%] [G loss: 0.951173]\n",
      "epoch:10 step:9882 [D loss: 0.661705, acc.: 59.38%] [G loss: 0.912370]\n",
      "epoch:10 step:9883 [D loss: 0.599069, acc.: 71.88%] [G loss: 0.872840]\n",
      "epoch:10 step:9884 [D loss: 0.619818, acc.: 64.06%] [G loss: 0.895829]\n",
      "epoch:10 step:9885 [D loss: 0.631027, acc.: 64.84%] [G loss: 1.008344]\n",
      "epoch:10 step:9886 [D loss: 0.605307, acc.: 69.53%] [G loss: 0.953327]\n",
      "epoch:10 step:9887 [D loss: 0.721503, acc.: 51.56%] [G loss: 0.936306]\n",
      "epoch:10 step:9888 [D loss: 0.662795, acc.: 59.38%] [G loss: 0.883393]\n",
      "epoch:10 step:9889 [D loss: 0.651677, acc.: 61.72%] [G loss: 0.880327]\n",
      "epoch:10 step:9890 [D loss: 0.612158, acc.: 63.28%] [G loss: 0.917121]\n",
      "epoch:10 step:9891 [D loss: 0.660877, acc.: 55.47%] [G loss: 0.894846]\n",
      "epoch:10 step:9892 [D loss: 0.617336, acc.: 68.75%] [G loss: 0.934278]\n",
      "epoch:10 step:9893 [D loss: 0.599289, acc.: 72.66%] [G loss: 0.989258]\n",
      "epoch:10 step:9894 [D loss: 0.702647, acc.: 57.03%] [G loss: 0.935010]\n",
      "epoch:10 step:9895 [D loss: 0.643683, acc.: 59.38%] [G loss: 0.852502]\n",
      "epoch:10 step:9896 [D loss: 0.644648, acc.: 59.38%] [G loss: 0.868546]\n",
      "epoch:10 step:9897 [D loss: 0.701975, acc.: 58.59%] [G loss: 0.948014]\n",
      "epoch:10 step:9898 [D loss: 0.705374, acc.: 52.34%] [G loss: 0.912419]\n",
      "epoch:10 step:9899 [D loss: 0.700167, acc.: 53.91%] [G loss: 0.969348]\n",
      "epoch:10 step:9900 [D loss: 0.616160, acc.: 71.88%] [G loss: 0.924984]\n",
      "epoch:10 step:9901 [D loss: 0.680748, acc.: 53.91%] [G loss: 0.939301]\n",
      "epoch:10 step:9902 [D loss: 0.721444, acc.: 48.44%] [G loss: 0.857407]\n",
      "epoch:10 step:9903 [D loss: 0.678428, acc.: 57.03%] [G loss: 0.867196]\n",
      "epoch:10 step:9904 [D loss: 0.626422, acc.: 67.97%] [G loss: 0.916828]\n",
      "epoch:10 step:9905 [D loss: 0.696704, acc.: 51.56%] [G loss: 0.887666]\n",
      "epoch:10 step:9906 [D loss: 0.649813, acc.: 64.06%] [G loss: 0.841221]\n",
      "epoch:10 step:9907 [D loss: 0.655015, acc.: 60.94%] [G loss: 0.838325]\n",
      "epoch:10 step:9908 [D loss: 0.668339, acc.: 57.81%] [G loss: 0.875431]\n",
      "epoch:10 step:9909 [D loss: 0.631028, acc.: 67.19%] [G loss: 0.896046]\n",
      "epoch:10 step:9910 [D loss: 0.683750, acc.: 60.94%] [G loss: 0.922099]\n",
      "epoch:10 step:9911 [D loss: 0.654057, acc.: 64.06%] [G loss: 0.877303]\n",
      "epoch:10 step:9912 [D loss: 0.735978, acc.: 48.44%] [G loss: 0.874510]\n",
      "epoch:10 step:9913 [D loss: 0.677576, acc.: 55.47%] [G loss: 0.914700]\n",
      "epoch:10 step:9914 [D loss: 0.689631, acc.: 56.25%] [G loss: 0.894623]\n",
      "epoch:10 step:9915 [D loss: 0.650002, acc.: 61.72%] [G loss: 0.870988]\n",
      "epoch:10 step:9916 [D loss: 0.696046, acc.: 54.69%] [G loss: 0.944340]\n",
      "epoch:10 step:9917 [D loss: 0.616490, acc.: 67.19%] [G loss: 0.910544]\n",
      "epoch:10 step:9918 [D loss: 0.671730, acc.: 58.59%] [G loss: 0.881221]\n",
      "epoch:10 step:9919 [D loss: 0.607402, acc.: 71.09%] [G loss: 0.880969]\n",
      "epoch:10 step:9920 [D loss: 0.634668, acc.: 60.16%] [G loss: 0.883132]\n",
      "epoch:10 step:9921 [D loss: 0.615289, acc.: 63.28%] [G loss: 0.908522]\n",
      "epoch:10 step:9922 [D loss: 0.634709, acc.: 67.19%] [G loss: 0.910538]\n",
      "epoch:10 step:9923 [D loss: 0.700523, acc.: 56.25%] [G loss: 0.922663]\n",
      "epoch:10 step:9924 [D loss: 0.656703, acc.: 61.72%] [G loss: 0.870581]\n",
      "epoch:10 step:9925 [D loss: 0.654845, acc.: 59.38%] [G loss: 0.884540]\n",
      "epoch:10 step:9926 [D loss: 0.608418, acc.: 67.97%] [G loss: 0.899168]\n",
      "epoch:10 step:9927 [D loss: 0.635145, acc.: 70.31%] [G loss: 0.939455]\n",
      "epoch:10 step:9928 [D loss: 0.640111, acc.: 64.06%] [G loss: 0.934891]\n",
      "epoch:10 step:9929 [D loss: 0.701850, acc.: 56.25%] [G loss: 0.940110]\n",
      "epoch:10 step:9930 [D loss: 0.698918, acc.: 53.12%] [G loss: 0.879794]\n",
      "epoch:10 step:9931 [D loss: 0.614507, acc.: 66.41%] [G loss: 0.982708]\n",
      "epoch:10 step:9932 [D loss: 0.670480, acc.: 56.25%] [G loss: 0.901247]\n",
      "epoch:10 step:9933 [D loss: 0.668293, acc.: 60.16%] [G loss: 0.996956]\n",
      "epoch:10 step:9934 [D loss: 0.597761, acc.: 68.75%] [G loss: 1.051669]\n",
      "epoch:10 step:9935 [D loss: 0.719846, acc.: 54.69%] [G loss: 0.951220]\n",
      "epoch:10 step:9936 [D loss: 0.766665, acc.: 43.75%] [G loss: 0.919126]\n",
      "epoch:10 step:9937 [D loss: 0.638144, acc.: 63.28%] [G loss: 0.927526]\n",
      "epoch:10 step:9938 [D loss: 0.686984, acc.: 57.81%] [G loss: 0.869323]\n",
      "epoch:10 step:9939 [D loss: 0.735159, acc.: 51.56%] [G loss: 0.885629]\n",
      "epoch:10 step:9940 [D loss: 0.630212, acc.: 64.84%] [G loss: 0.875973]\n",
      "epoch:10 step:9941 [D loss: 0.636238, acc.: 65.62%] [G loss: 0.923518]\n",
      "epoch:10 step:9942 [D loss: 0.650391, acc.: 62.50%] [G loss: 0.967027]\n",
      "epoch:10 step:9943 [D loss: 0.614234, acc.: 67.97%] [G loss: 0.898285]\n",
      "epoch:10 step:9944 [D loss: 0.564685, acc.: 72.66%] [G loss: 0.949297]\n",
      "epoch:10 step:9945 [D loss: 0.581223, acc.: 71.09%] [G loss: 0.951743]\n",
      "epoch:10 step:9946 [D loss: 0.700417, acc.: 54.69%] [G loss: 0.980079]\n",
      "epoch:10 step:9947 [D loss: 0.678894, acc.: 60.16%] [G loss: 0.865589]\n",
      "epoch:10 step:9948 [D loss: 0.624354, acc.: 65.62%] [G loss: 0.855302]\n",
      "epoch:10 step:9949 [D loss: 0.648008, acc.: 63.28%] [G loss: 0.860647]\n",
      "epoch:10 step:9950 [D loss: 0.670778, acc.: 56.25%] [G loss: 0.880101]\n",
      "epoch:10 step:9951 [D loss: 0.611521, acc.: 67.97%] [G loss: 0.859906]\n",
      "epoch:10 step:9952 [D loss: 0.594046, acc.: 64.06%] [G loss: 0.915469]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9953 [D loss: 0.637300, acc.: 64.06%] [G loss: 0.907457]\n",
      "epoch:10 step:9954 [D loss: 0.738953, acc.: 52.34%] [G loss: 0.915721]\n",
      "epoch:10 step:9955 [D loss: 0.655369, acc.: 64.06%] [G loss: 0.879266]\n",
      "epoch:10 step:9956 [D loss: 0.684139, acc.: 54.69%] [G loss: 0.917103]\n",
      "epoch:10 step:9957 [D loss: 0.718381, acc.: 49.22%] [G loss: 0.908487]\n",
      "epoch:10 step:9958 [D loss: 0.677657, acc.: 54.69%] [G loss: 0.888978]\n",
      "epoch:10 step:9959 [D loss: 0.638960, acc.: 67.97%] [G loss: 0.905038]\n",
      "epoch:10 step:9960 [D loss: 0.677737, acc.: 56.25%] [G loss: 0.935114]\n",
      "epoch:10 step:9961 [D loss: 0.685379, acc.: 54.69%] [G loss: 0.898889]\n",
      "epoch:10 step:9962 [D loss: 0.621327, acc.: 64.06%] [G loss: 0.917156]\n",
      "epoch:10 step:9963 [D loss: 0.624605, acc.: 64.84%] [G loss: 0.931146]\n",
      "epoch:10 step:9964 [D loss: 0.704219, acc.: 51.56%] [G loss: 0.842858]\n",
      "epoch:10 step:9965 [D loss: 0.609583, acc.: 67.19%] [G loss: 0.873139]\n",
      "epoch:10 step:9966 [D loss: 0.659523, acc.: 62.50%] [G loss: 0.850560]\n",
      "epoch:10 step:9967 [D loss: 0.678198, acc.: 57.03%] [G loss: 0.846233]\n",
      "epoch:10 step:9968 [D loss: 0.636946, acc.: 67.19%] [G loss: 0.887781]\n",
      "epoch:10 step:9969 [D loss: 0.643978, acc.: 58.59%] [G loss: 0.910983]\n",
      "epoch:10 step:9970 [D loss: 0.702735, acc.: 52.34%] [G loss: 0.816418]\n",
      "epoch:10 step:9971 [D loss: 0.664914, acc.: 56.25%] [G loss: 0.829503]\n",
      "epoch:10 step:9972 [D loss: 0.649778, acc.: 60.16%] [G loss: 0.811386]\n",
      "epoch:10 step:9973 [D loss: 0.693855, acc.: 55.47%] [G loss: 0.873528]\n",
      "epoch:10 step:9974 [D loss: 0.661639, acc.: 57.81%] [G loss: 0.891034]\n",
      "epoch:10 step:9975 [D loss: 0.612560, acc.: 69.53%] [G loss: 0.815888]\n",
      "epoch:10 step:9976 [D loss: 0.653060, acc.: 62.50%] [G loss: 0.816503]\n",
      "epoch:10 step:9977 [D loss: 0.669780, acc.: 58.59%] [G loss: 0.866887]\n",
      "epoch:10 step:9978 [D loss: 0.635059, acc.: 62.50%] [G loss: 0.879991]\n",
      "epoch:10 step:9979 [D loss: 0.620784, acc.: 66.41%] [G loss: 0.942188]\n",
      "epoch:10 step:9980 [D loss: 0.648806, acc.: 58.59%] [G loss: 0.920370]\n",
      "epoch:10 step:9981 [D loss: 0.671633, acc.: 54.69%] [G loss: 0.952593]\n",
      "epoch:10 step:9982 [D loss: 0.724930, acc.: 49.22%] [G loss: 0.906649]\n",
      "epoch:10 step:9983 [D loss: 0.646936, acc.: 62.50%] [G loss: 0.860927]\n",
      "epoch:10 step:9984 [D loss: 0.700632, acc.: 50.78%] [G loss: 0.885992]\n",
      "epoch:10 step:9985 [D loss: 0.724505, acc.: 46.88%] [G loss: 0.899746]\n",
      "epoch:10 step:9986 [D loss: 0.658982, acc.: 61.72%] [G loss: 0.926961]\n",
      "epoch:10 step:9987 [D loss: 0.624682, acc.: 67.19%] [G loss: 0.901972]\n",
      "epoch:10 step:9988 [D loss: 0.622819, acc.: 67.97%] [G loss: 0.874442]\n",
      "epoch:10 step:9989 [D loss: 0.718240, acc.: 51.56%] [G loss: 0.873594]\n",
      "epoch:10 step:9990 [D loss: 0.627711, acc.: 65.62%] [G loss: 0.908124]\n",
      "epoch:10 step:9991 [D loss: 0.692593, acc.: 52.34%] [G loss: 0.848348]\n",
      "epoch:10 step:9992 [D loss: 0.686782, acc.: 50.78%] [G loss: 0.885764]\n",
      "epoch:10 step:9993 [D loss: 0.632102, acc.: 65.62%] [G loss: 0.896309]\n",
      "epoch:10 step:9994 [D loss: 0.641725, acc.: 63.28%] [G loss: 0.906827]\n",
      "epoch:10 step:9995 [D loss: 0.685643, acc.: 57.03%] [G loss: 0.877126]\n",
      "epoch:10 step:9996 [D loss: 0.687430, acc.: 57.03%] [G loss: 0.854255]\n",
      "epoch:10 step:9997 [D loss: 0.656822, acc.: 61.72%] [G loss: 0.860263]\n",
      "epoch:10 step:9998 [D loss: 0.658299, acc.: 60.94%] [G loss: 0.880093]\n",
      "epoch:10 step:9999 [D loss: 0.627703, acc.: 69.53%] [G loss: 0.876411]\n",
      "epoch:10 step:10000 [D loss: 0.689878, acc.: 58.59%] [G loss: 0.902077]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.760046\n",
      "FID: 9.913532\n",
      "0 = 11.898155139708493\n",
      "1 = 0.05495062605941164\n",
      "2 = 0.9284499883651733\n",
      "3 = 0.8806999921798706\n",
      "4 = 0.9761999845504761\n",
      "5 = 0.9736871123313904\n",
      "6 = 0.8806999921798706\n",
      "7 = 6.245233575594426\n",
      "8 = 0.06445959810061246\n",
      "9 = 0.7184500098228455\n",
      "10 = 0.6880000233650208\n",
      "11 = 0.7488999962806702\n",
      "12 = 0.7326163053512573\n",
      "13 = 0.6880000233650208\n",
      "14 = 7.760117053985596\n",
      "15 = 9.52968978881836\n",
      "16 = 0.11878134310245514\n",
      "17 = 7.760046482086182\n",
      "18 = 9.913532257080078\n",
      "epoch:10 step:10001 [D loss: 0.598147, acc.: 68.75%] [G loss: 0.881213]\n",
      "epoch:10 step:10002 [D loss: 0.642905, acc.: 63.28%] [G loss: 0.929978]\n",
      "epoch:10 step:10003 [D loss: 0.661410, acc.: 60.94%] [G loss: 0.956222]\n",
      "epoch:10 step:10004 [D loss: 0.627074, acc.: 66.41%] [G loss: 0.919388]\n",
      "epoch:10 step:10005 [D loss: 0.584654, acc.: 71.09%] [G loss: 0.920317]\n",
      "epoch:10 step:10006 [D loss: 0.683352, acc.: 55.47%] [G loss: 0.897176]\n",
      "epoch:10 step:10007 [D loss: 0.629776, acc.: 62.50%] [G loss: 0.847273]\n",
      "epoch:10 step:10008 [D loss: 0.707235, acc.: 53.12%] [G loss: 0.949782]\n",
      "epoch:10 step:10009 [D loss: 0.687176, acc.: 53.91%] [G loss: 0.889976]\n",
      "epoch:10 step:10010 [D loss: 0.680160, acc.: 57.81%] [G loss: 0.865749]\n",
      "epoch:10 step:10011 [D loss: 0.606551, acc.: 70.31%] [G loss: 0.864686]\n",
      "epoch:10 step:10012 [D loss: 0.600015, acc.: 69.53%] [G loss: 0.901986]\n",
      "epoch:10 step:10013 [D loss: 0.656566, acc.: 59.38%] [G loss: 0.889569]\n",
      "epoch:10 step:10014 [D loss: 0.677340, acc.: 55.47%] [G loss: 0.858515]\n",
      "epoch:10 step:10015 [D loss: 0.672121, acc.: 57.81%] [G loss: 0.881970]\n",
      "epoch:10 step:10016 [D loss: 0.653714, acc.: 61.72%] [G loss: 0.831572]\n",
      "epoch:10 step:10017 [D loss: 0.640524, acc.: 62.50%] [G loss: 0.927855]\n",
      "epoch:10 step:10018 [D loss: 0.579870, acc.: 65.62%] [G loss: 0.974085]\n",
      "epoch:10 step:10019 [D loss: 0.609526, acc.: 65.62%] [G loss: 0.962846]\n",
      "epoch:10 step:10020 [D loss: 0.567532, acc.: 72.66%] [G loss: 0.945077]\n",
      "epoch:10 step:10021 [D loss: 0.677544, acc.: 57.81%] [G loss: 0.911372]\n",
      "epoch:10 step:10022 [D loss: 0.652591, acc.: 59.38%] [G loss: 0.922559]\n",
      "epoch:10 step:10023 [D loss: 0.645831, acc.: 67.19%] [G loss: 0.897822]\n",
      "epoch:10 step:10024 [D loss: 0.660377, acc.: 62.50%] [G loss: 0.931222]\n",
      "epoch:10 step:10025 [D loss: 0.743876, acc.: 57.81%] [G loss: 0.844207]\n",
      "epoch:10 step:10026 [D loss: 0.702293, acc.: 54.69%] [G loss: 0.904764]\n",
      "epoch:10 step:10027 [D loss: 0.668527, acc.: 53.12%] [G loss: 0.866156]\n",
      "epoch:10 step:10028 [D loss: 0.633538, acc.: 64.84%] [G loss: 0.939105]\n",
      "epoch:10 step:10029 [D loss: 0.693363, acc.: 56.25%] [G loss: 0.982654]\n",
      "epoch:10 step:10030 [D loss: 0.626575, acc.: 61.72%] [G loss: 0.947241]\n",
      "epoch:10 step:10031 [D loss: 0.602901, acc.: 71.09%] [G loss: 0.972474]\n",
      "epoch:10 step:10032 [D loss: 0.673697, acc.: 60.16%] [G loss: 0.921555]\n",
      "epoch:10 step:10033 [D loss: 0.636372, acc.: 63.28%] [G loss: 0.899288]\n",
      "epoch:10 step:10034 [D loss: 0.648174, acc.: 60.94%] [G loss: 0.896819]\n",
      "epoch:10 step:10035 [D loss: 0.668943, acc.: 57.81%] [G loss: 1.001462]\n",
      "epoch:10 step:10036 [D loss: 0.648797, acc.: 62.50%] [G loss: 0.952746]\n",
      "epoch:10 step:10037 [D loss: 0.669873, acc.: 57.03%] [G loss: 0.969001]\n",
      "epoch:10 step:10038 [D loss: 0.701528, acc.: 53.12%] [G loss: 0.902866]\n",
      "epoch:10 step:10039 [D loss: 0.630145, acc.: 68.75%] [G loss: 0.923979]\n",
      "epoch:10 step:10040 [D loss: 0.695928, acc.: 53.91%] [G loss: 0.866342]\n",
      "epoch:10 step:10041 [D loss: 0.686008, acc.: 60.16%] [G loss: 0.870314]\n",
      "epoch:10 step:10042 [D loss: 0.697029, acc.: 53.91%] [G loss: 0.867735]\n",
      "epoch:10 step:10043 [D loss: 0.698050, acc.: 55.47%] [G loss: 0.852610]\n",
      "epoch:10 step:10044 [D loss: 0.708764, acc.: 55.47%] [G loss: 0.812235]\n",
      "epoch:10 step:10045 [D loss: 0.639458, acc.: 57.81%] [G loss: 0.907851]\n",
      "epoch:10 step:10046 [D loss: 0.662780, acc.: 60.16%] [G loss: 0.948009]\n",
      "epoch:10 step:10047 [D loss: 0.632539, acc.: 62.50%] [G loss: 0.923197]\n",
      "epoch:10 step:10048 [D loss: 0.691530, acc.: 57.03%] [G loss: 0.848629]\n",
      "epoch:10 step:10049 [D loss: 0.664941, acc.: 59.38%] [G loss: 0.847749]\n",
      "epoch:10 step:10050 [D loss: 0.671025, acc.: 56.25%] [G loss: 0.850069]\n",
      "epoch:10 step:10051 [D loss: 0.593809, acc.: 70.31%] [G loss: 0.883283]\n",
      "epoch:10 step:10052 [D loss: 0.695119, acc.: 57.03%] [G loss: 0.904961]\n",
      "epoch:10 step:10053 [D loss: 0.673219, acc.: 56.25%] [G loss: 0.875352]\n",
      "epoch:10 step:10054 [D loss: 0.642348, acc.: 63.28%] [G loss: 0.846374]\n",
      "epoch:10 step:10055 [D loss: 0.629272, acc.: 67.97%] [G loss: 0.926490]\n",
      "epoch:10 step:10056 [D loss: 0.643978, acc.: 64.84%] [G loss: 0.876310]\n",
      "epoch:10 step:10057 [D loss: 0.670763, acc.: 57.81%] [G loss: 0.857334]\n",
      "epoch:10 step:10058 [D loss: 0.625470, acc.: 64.84%] [G loss: 0.933151]\n",
      "epoch:10 step:10059 [D loss: 0.634936, acc.: 63.28%] [G loss: 0.910833]\n",
      "epoch:10 step:10060 [D loss: 0.627007, acc.: 65.62%] [G loss: 0.961487]\n",
      "epoch:10 step:10061 [D loss: 0.602973, acc.: 69.53%] [G loss: 0.942659]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10062 [D loss: 0.662053, acc.: 55.47%] [G loss: 0.973698]\n",
      "epoch:10 step:10063 [D loss: 0.627713, acc.: 60.16%] [G loss: 0.945820]\n",
      "epoch:10 step:10064 [D loss: 0.641399, acc.: 62.50%] [G loss: 0.983086]\n",
      "epoch:10 step:10065 [D loss: 0.609269, acc.: 62.50%] [G loss: 0.947736]\n",
      "epoch:10 step:10066 [D loss: 0.684496, acc.: 61.72%] [G loss: 0.884472]\n",
      "epoch:10 step:10067 [D loss: 0.637909, acc.: 64.84%] [G loss: 0.858070]\n",
      "epoch:10 step:10068 [D loss: 0.665347, acc.: 59.38%] [G loss: 0.878966]\n",
      "epoch:10 step:10069 [D loss: 0.629048, acc.: 65.62%] [G loss: 0.909911]\n",
      "epoch:10 step:10070 [D loss: 0.617575, acc.: 67.97%] [G loss: 0.892626]\n",
      "epoch:10 step:10071 [D loss: 0.619873, acc.: 64.84%] [G loss: 0.999655]\n",
      "epoch:10 step:10072 [D loss: 0.729890, acc.: 53.12%] [G loss: 0.985365]\n",
      "epoch:10 step:10073 [D loss: 0.738492, acc.: 47.66%] [G loss: 0.936265]\n",
      "epoch:10 step:10074 [D loss: 0.681845, acc.: 52.34%] [G loss: 0.867194]\n",
      "epoch:10 step:10075 [D loss: 0.645158, acc.: 64.84%] [G loss: 0.925174]\n",
      "epoch:10 step:10076 [D loss: 0.630193, acc.: 62.50%] [G loss: 0.940989]\n",
      "epoch:10 step:10077 [D loss: 0.634057, acc.: 65.62%] [G loss: 0.943583]\n",
      "epoch:10 step:10078 [D loss: 0.569042, acc.: 73.44%] [G loss: 0.928916]\n",
      "epoch:10 step:10079 [D loss: 0.606003, acc.: 68.75%] [G loss: 0.955224]\n",
      "epoch:10 step:10080 [D loss: 0.708154, acc.: 57.81%] [G loss: 0.978406]\n",
      "epoch:10 step:10081 [D loss: 0.697711, acc.: 56.25%] [G loss: 0.896360]\n",
      "epoch:10 step:10082 [D loss: 0.619686, acc.: 65.62%] [G loss: 0.870366]\n",
      "epoch:10 step:10083 [D loss: 0.665457, acc.: 58.59%] [G loss: 0.871570]\n",
      "epoch:10 step:10084 [D loss: 0.681932, acc.: 58.59%] [G loss: 0.884910]\n",
      "epoch:10 step:10085 [D loss: 0.675348, acc.: 61.72%] [G loss: 0.910383]\n",
      "epoch:10 step:10086 [D loss: 0.735158, acc.: 47.66%] [G loss: 0.855176]\n",
      "epoch:10 step:10087 [D loss: 0.657740, acc.: 60.16%] [G loss: 0.926950]\n",
      "epoch:10 step:10088 [D loss: 0.669592, acc.: 59.38%] [G loss: 0.899277]\n",
      "epoch:10 step:10089 [D loss: 0.657899, acc.: 64.84%] [G loss: 0.924802]\n",
      "epoch:10 step:10090 [D loss: 0.684891, acc.: 54.69%] [G loss: 0.902094]\n",
      "epoch:10 step:10091 [D loss: 0.681870, acc.: 57.03%] [G loss: 0.938766]\n",
      "epoch:10 step:10092 [D loss: 0.708083, acc.: 54.69%] [G loss: 0.877021]\n",
      "epoch:10 step:10093 [D loss: 0.656728, acc.: 60.16%] [G loss: 0.888374]\n",
      "epoch:10 step:10094 [D loss: 0.643884, acc.: 60.16%] [G loss: 0.904910]\n",
      "epoch:10 step:10095 [D loss: 0.613677, acc.: 70.31%] [G loss: 0.904305]\n",
      "epoch:10 step:10096 [D loss: 0.640245, acc.: 58.59%] [G loss: 0.946915]\n",
      "epoch:10 step:10097 [D loss: 0.721055, acc.: 51.56%] [G loss: 0.869359]\n",
      "epoch:10 step:10098 [D loss: 0.668409, acc.: 57.81%] [G loss: 0.820031]\n",
      "epoch:10 step:10099 [D loss: 0.704742, acc.: 54.69%] [G loss: 0.840010]\n",
      "epoch:10 step:10100 [D loss: 0.624633, acc.: 68.75%] [G loss: 0.857756]\n",
      "epoch:10 step:10101 [D loss: 0.669823, acc.: 57.03%] [G loss: 0.878766]\n",
      "epoch:10 step:10102 [D loss: 0.648300, acc.: 61.72%] [G loss: 0.892531]\n",
      "epoch:10 step:10103 [D loss: 0.631208, acc.: 69.53%] [G loss: 0.920546]\n",
      "epoch:10 step:10104 [D loss: 0.667083, acc.: 53.91%] [G loss: 0.938771]\n",
      "epoch:10 step:10105 [D loss: 0.682998, acc.: 57.03%] [G loss: 0.887505]\n",
      "epoch:10 step:10106 [D loss: 0.646678, acc.: 61.72%] [G loss: 0.836635]\n",
      "epoch:10 step:10107 [D loss: 0.657633, acc.: 55.47%] [G loss: 0.875293]\n",
      "epoch:10 step:10108 [D loss: 0.720444, acc.: 50.00%] [G loss: 0.854487]\n",
      "epoch:10 step:10109 [D loss: 0.669456, acc.: 60.94%] [G loss: 0.856727]\n",
      "epoch:10 step:10110 [D loss: 0.661966, acc.: 60.16%] [G loss: 0.863103]\n",
      "epoch:10 step:10111 [D loss: 0.673160, acc.: 60.94%] [G loss: 0.829593]\n",
      "epoch:10 step:10112 [D loss: 0.669940, acc.: 57.03%] [G loss: 0.970325]\n",
      "epoch:10 step:10113 [D loss: 0.641854, acc.: 64.06%] [G loss: 0.911387]\n",
      "epoch:10 step:10114 [D loss: 0.652536, acc.: 57.03%] [G loss: 0.911475]\n",
      "epoch:10 step:10115 [D loss: 0.710061, acc.: 49.22%] [G loss: 0.900023]\n",
      "epoch:10 step:10116 [D loss: 0.621064, acc.: 64.06%] [G loss: 0.828687]\n",
      "epoch:10 step:10117 [D loss: 0.632825, acc.: 60.16%] [G loss: 0.879931]\n",
      "epoch:10 step:10118 [D loss: 0.642043, acc.: 65.62%] [G loss: 0.818754]\n",
      "epoch:10 step:10119 [D loss: 0.645685, acc.: 63.28%] [G loss: 0.879053]\n",
      "epoch:10 step:10120 [D loss: 0.649904, acc.: 58.59%] [G loss: 0.880312]\n",
      "epoch:10 step:10121 [D loss: 0.611263, acc.: 71.09%] [G loss: 0.875492]\n",
      "epoch:10 step:10122 [D loss: 0.704589, acc.: 52.34%] [G loss: 0.849929]\n",
      "epoch:10 step:10123 [D loss: 0.673546, acc.: 57.81%] [G loss: 0.868461]\n",
      "epoch:10 step:10124 [D loss: 0.633983, acc.: 64.06%] [G loss: 0.901912]\n",
      "epoch:10 step:10125 [D loss: 0.651146, acc.: 63.28%] [G loss: 0.908168]\n",
      "epoch:10 step:10126 [D loss: 0.658147, acc.: 64.06%] [G loss: 0.937042]\n",
      "epoch:10 step:10127 [D loss: 0.688601, acc.: 57.03%] [G loss: 0.864993]\n",
      "epoch:10 step:10128 [D loss: 0.657524, acc.: 60.16%] [G loss: 0.937373]\n",
      "epoch:10 step:10129 [D loss: 0.687836, acc.: 53.91%] [G loss: 0.875845]\n",
      "epoch:10 step:10130 [D loss: 0.699134, acc.: 56.25%] [G loss: 0.839961]\n",
      "epoch:10 step:10131 [D loss: 0.631620, acc.: 64.06%] [G loss: 0.895372]\n",
      "epoch:10 step:10132 [D loss: 0.640652, acc.: 62.50%] [G loss: 0.907119]\n",
      "epoch:10 step:10133 [D loss: 0.626662, acc.: 64.84%] [G loss: 0.852739]\n",
      "epoch:10 step:10134 [D loss: 0.657906, acc.: 59.38%] [G loss: 0.919297]\n",
      "epoch:10 step:10135 [D loss: 0.751853, acc.: 53.12%] [G loss: 0.876817]\n",
      "epoch:10 step:10136 [D loss: 0.654097, acc.: 60.94%] [G loss: 0.861636]\n",
      "epoch:10 step:10137 [D loss: 0.655509, acc.: 58.59%] [G loss: 0.852821]\n",
      "epoch:10 step:10138 [D loss: 0.664098, acc.: 61.72%] [G loss: 0.878690]\n",
      "epoch:10 step:10139 [D loss: 0.644158, acc.: 66.41%] [G loss: 0.894297]\n",
      "epoch:10 step:10140 [D loss: 0.671448, acc.: 57.81%] [G loss: 0.900936]\n",
      "epoch:10 step:10141 [D loss: 0.672714, acc.: 57.03%] [G loss: 0.928810]\n",
      "epoch:10 step:10142 [D loss: 0.700542, acc.: 53.12%] [G loss: 0.887450]\n",
      "epoch:10 step:10143 [D loss: 0.652219, acc.: 61.72%] [G loss: 0.939888]\n",
      "epoch:10 step:10144 [D loss: 0.734620, acc.: 48.44%] [G loss: 0.962253]\n",
      "epoch:10 step:10145 [D loss: 0.612632, acc.: 69.53%] [G loss: 1.005733]\n",
      "epoch:10 step:10146 [D loss: 0.682911, acc.: 54.69%] [G loss: 0.936002]\n",
      "epoch:10 step:10147 [D loss: 0.651001, acc.: 64.84%] [G loss: 0.944558]\n",
      "epoch:10 step:10148 [D loss: 0.656770, acc.: 60.16%] [G loss: 0.923321]\n",
      "epoch:10 step:10149 [D loss: 0.673029, acc.: 61.72%] [G loss: 0.934510]\n",
      "epoch:10 step:10150 [D loss: 0.642446, acc.: 57.03%] [G loss: 0.915623]\n",
      "epoch:10 step:10151 [D loss: 0.598245, acc.: 69.53%] [G loss: 0.861614]\n",
      "epoch:10 step:10152 [D loss: 0.638018, acc.: 61.72%] [G loss: 1.033134]\n",
      "epoch:10 step:10153 [D loss: 0.697466, acc.: 55.47%] [G loss: 0.990010]\n",
      "epoch:10 step:10154 [D loss: 0.715198, acc.: 48.44%] [G loss: 0.877916]\n",
      "epoch:10 step:10155 [D loss: 0.679617, acc.: 57.03%] [G loss: 0.820557]\n",
      "epoch:10 step:10156 [D loss: 0.633459, acc.: 63.28%] [G loss: 0.991853]\n",
      "epoch:10 step:10157 [D loss: 0.721194, acc.: 56.25%] [G loss: 0.933174]\n",
      "epoch:10 step:10158 [D loss: 0.683739, acc.: 53.12%] [G loss: 0.919324]\n",
      "epoch:10 step:10159 [D loss: 0.652196, acc.: 62.50%] [G loss: 0.906591]\n",
      "epoch:10 step:10160 [D loss: 0.624582, acc.: 63.28%] [G loss: 0.834326]\n",
      "epoch:10 step:10161 [D loss: 0.689650, acc.: 56.25%] [G loss: 0.842844]\n",
      "epoch:10 step:10162 [D loss: 0.625780, acc.: 64.84%] [G loss: 0.879454]\n",
      "epoch:10 step:10163 [D loss: 0.646787, acc.: 60.16%] [G loss: 0.839433]\n",
      "epoch:10 step:10164 [D loss: 0.670943, acc.: 53.91%] [G loss: 0.921075]\n",
      "epoch:10 step:10165 [D loss: 0.652800, acc.: 60.94%] [G loss: 0.939549]\n",
      "epoch:10 step:10166 [D loss: 0.633451, acc.: 64.84%] [G loss: 0.953821]\n",
      "epoch:10 step:10167 [D loss: 0.648002, acc.: 61.72%] [G loss: 0.906853]\n",
      "epoch:10 step:10168 [D loss: 0.672666, acc.: 53.91%] [G loss: 0.885800]\n",
      "epoch:10 step:10169 [D loss: 0.667348, acc.: 56.25%] [G loss: 0.956510]\n",
      "epoch:10 step:10170 [D loss: 0.663922, acc.: 55.47%] [G loss: 0.944782]\n",
      "epoch:10 step:10171 [D loss: 0.618719, acc.: 64.84%] [G loss: 0.956054]\n",
      "epoch:10 step:10172 [D loss: 0.648746, acc.: 63.28%] [G loss: 0.989706]\n",
      "epoch:10 step:10173 [D loss: 0.594612, acc.: 70.31%] [G loss: 0.947102]\n",
      "epoch:10 step:10174 [D loss: 0.663888, acc.: 57.03%] [G loss: 0.867794]\n",
      "epoch:10 step:10175 [D loss: 0.711063, acc.: 50.78%] [G loss: 0.814046]\n",
      "epoch:10 step:10176 [D loss: 0.647041, acc.: 60.94%] [G loss: 0.822326]\n",
      "epoch:10 step:10177 [D loss: 0.609097, acc.: 67.19%] [G loss: 0.895364]\n",
      "epoch:10 step:10178 [D loss: 0.697202, acc.: 54.69%] [G loss: 0.912862]\n",
      "epoch:10 step:10179 [D loss: 0.673888, acc.: 58.59%] [G loss: 0.883513]\n",
      "epoch:10 step:10180 [D loss: 0.664533, acc.: 58.59%] [G loss: 0.880969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10181 [D loss: 0.640764, acc.: 64.84%] [G loss: 0.896550]\n",
      "epoch:10 step:10182 [D loss: 0.697882, acc.: 50.78%] [G loss: 0.845094]\n",
      "epoch:10 step:10183 [D loss: 0.646990, acc.: 61.72%] [G loss: 0.928169]\n",
      "epoch:10 step:10184 [D loss: 0.651111, acc.: 57.81%] [G loss: 0.925642]\n",
      "epoch:10 step:10185 [D loss: 0.652887, acc.: 62.50%] [G loss: 0.941035]\n",
      "epoch:10 step:10186 [D loss: 0.671237, acc.: 57.03%] [G loss: 0.907980]\n",
      "epoch:10 step:10187 [D loss: 0.700009, acc.: 55.47%] [G loss: 0.913919]\n",
      "epoch:10 step:10188 [D loss: 0.685090, acc.: 55.47%] [G loss: 0.931774]\n",
      "epoch:10 step:10189 [D loss: 0.656714, acc.: 64.84%] [G loss: 0.899641]\n",
      "epoch:10 step:10190 [D loss: 0.726241, acc.: 50.78%] [G loss: 0.904778]\n",
      "epoch:10 step:10191 [D loss: 0.657903, acc.: 60.16%] [G loss: 0.895091]\n",
      "epoch:10 step:10192 [D loss: 0.613280, acc.: 67.97%] [G loss: 0.878917]\n",
      "epoch:10 step:10193 [D loss: 0.631457, acc.: 62.50%] [G loss: 0.869737]\n",
      "epoch:10 step:10194 [D loss: 0.701086, acc.: 53.91%] [G loss: 0.866931]\n",
      "epoch:10 step:10195 [D loss: 0.620188, acc.: 68.75%] [G loss: 0.846759]\n",
      "epoch:10 step:10196 [D loss: 0.669099, acc.: 58.59%] [G loss: 0.879746]\n",
      "epoch:10 step:10197 [D loss: 0.668194, acc.: 56.25%] [G loss: 0.906034]\n",
      "epoch:10 step:10198 [D loss: 0.646638, acc.: 66.41%] [G loss: 0.856746]\n",
      "epoch:10 step:10199 [D loss: 0.672908, acc.: 56.25%] [G loss: 0.882280]\n",
      "epoch:10 step:10200 [D loss: 0.629397, acc.: 65.62%] [G loss: 0.892878]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.804535\n",
      "FID: 12.179613\n",
      "0 = 11.889158643913253\n",
      "1 = 0.05548602627633805\n",
      "2 = 0.9172999858856201\n",
      "3 = 0.8654999732971191\n",
      "4 = 0.9690999984741211\n",
      "5 = 0.9655287861824036\n",
      "6 = 0.8654999732971191\n",
      "7 = 6.4315077839553245\n",
      "8 = 0.0791678445293408\n",
      "9 = 0.7332000136375427\n",
      "10 = 0.7121999859809875\n",
      "11 = 0.7541999816894531\n",
      "12 = 0.7434238195419312\n",
      "13 = 0.7121999859809875\n",
      "14 = 7.804597854614258\n",
      "15 = 9.575328826904297\n",
      "16 = 0.10032087564468384\n",
      "17 = 7.804535388946533\n",
      "18 = 12.17961311340332\n",
      "epoch:10 step:10201 [D loss: 0.641929, acc.: 65.62%] [G loss: 0.906814]\n",
      "epoch:10 step:10202 [D loss: 0.618389, acc.: 61.72%] [G loss: 0.899425]\n",
      "epoch:10 step:10203 [D loss: 0.627934, acc.: 65.62%] [G loss: 0.844536]\n",
      "epoch:10 step:10204 [D loss: 0.660297, acc.: 64.06%] [G loss: 0.838859]\n",
      "epoch:10 step:10205 [D loss: 0.653166, acc.: 65.62%] [G loss: 0.873453]\n",
      "epoch:10 step:10206 [D loss: 0.646272, acc.: 62.50%] [G loss: 0.871017]\n",
      "epoch:10 step:10207 [D loss: 0.632949, acc.: 65.62%] [G loss: 0.909057]\n",
      "epoch:10 step:10208 [D loss: 0.638372, acc.: 66.41%] [G loss: 0.854936]\n",
      "epoch:10 step:10209 [D loss: 0.663115, acc.: 58.59%] [G loss: 0.838944]\n",
      "epoch:10 step:10210 [D loss: 0.667837, acc.: 61.72%] [G loss: 0.899370]\n",
      "epoch:10 step:10211 [D loss: 0.686887, acc.: 54.69%] [G loss: 0.929311]\n",
      "epoch:10 step:10212 [D loss: 0.631718, acc.: 63.28%] [G loss: 0.954053]\n",
      "epoch:10 step:10213 [D loss: 0.663137, acc.: 63.28%] [G loss: 0.954656]\n",
      "epoch:10 step:10214 [D loss: 0.655560, acc.: 61.72%] [G loss: 0.896694]\n",
      "epoch:10 step:10215 [D loss: 0.610664, acc.: 67.97%] [G loss: 0.955274]\n",
      "epoch:10 step:10216 [D loss: 0.689527, acc.: 50.78%] [G loss: 0.932872]\n",
      "epoch:10 step:10217 [D loss: 0.683325, acc.: 56.25%] [G loss: 0.868058]\n",
      "epoch:10 step:10218 [D loss: 0.668305, acc.: 63.28%] [G loss: 0.810539]\n",
      "epoch:10 step:10219 [D loss: 0.646708, acc.: 64.06%] [G loss: 0.830451]\n",
      "epoch:10 step:10220 [D loss: 0.706030, acc.: 60.16%] [G loss: 0.840181]\n",
      "epoch:10 step:10221 [D loss: 0.662990, acc.: 57.03%] [G loss: 0.892408]\n",
      "epoch:10 step:10222 [D loss: 0.590223, acc.: 69.53%] [G loss: 0.931645]\n",
      "epoch:10 step:10223 [D loss: 0.662589, acc.: 60.94%] [G loss: 0.896939]\n",
      "epoch:10 step:10224 [D loss: 0.634681, acc.: 62.50%] [G loss: 0.923363]\n",
      "epoch:10 step:10225 [D loss: 0.723132, acc.: 52.34%] [G loss: 0.920749]\n",
      "epoch:10 step:10226 [D loss: 0.673705, acc.: 56.25%] [G loss: 0.934602]\n",
      "epoch:10 step:10227 [D loss: 0.623458, acc.: 65.62%] [G loss: 0.947851]\n",
      "epoch:10 step:10228 [D loss: 0.744025, acc.: 50.78%] [G loss: 0.867137]\n",
      "epoch:10 step:10229 [D loss: 0.684968, acc.: 56.25%] [G loss: 0.875610]\n",
      "epoch:10 step:10230 [D loss: 0.599622, acc.: 71.09%] [G loss: 0.964934]\n",
      "epoch:10 step:10231 [D loss: 0.707035, acc.: 53.12%] [G loss: 0.876104]\n",
      "epoch:10 step:10232 [D loss: 0.691256, acc.: 53.12%] [G loss: 0.892162]\n",
      "epoch:10 step:10233 [D loss: 0.658592, acc.: 55.47%] [G loss: 0.887116]\n",
      "epoch:10 step:10234 [D loss: 0.720539, acc.: 52.34%] [G loss: 0.859182]\n",
      "epoch:10 step:10235 [D loss: 0.665006, acc.: 56.25%] [G loss: 0.848121]\n",
      "epoch:10 step:10236 [D loss: 0.656848, acc.: 60.16%] [G loss: 0.878942]\n",
      "epoch:10 step:10237 [D loss: 0.673681, acc.: 53.12%] [G loss: 0.834607]\n",
      "epoch:10 step:10238 [D loss: 0.631539, acc.: 64.84%] [G loss: 0.884360]\n",
      "epoch:10 step:10239 [D loss: 0.667656, acc.: 60.16%] [G loss: 0.918588]\n",
      "epoch:10 step:10240 [D loss: 0.628146, acc.: 64.84%] [G loss: 0.928886]\n",
      "epoch:10 step:10241 [D loss: 0.597890, acc.: 71.09%] [G loss: 0.886699]\n",
      "epoch:10 step:10242 [D loss: 0.609200, acc.: 70.31%] [G loss: 0.863965]\n",
      "epoch:10 step:10243 [D loss: 0.656699, acc.: 61.72%] [G loss: 0.889075]\n",
      "epoch:10 step:10244 [D loss: 0.666122, acc.: 60.16%] [G loss: 0.887940]\n",
      "epoch:10 step:10245 [D loss: 0.581096, acc.: 75.78%] [G loss: 0.913530]\n",
      "epoch:10 step:10246 [D loss: 0.629535, acc.: 64.06%] [G loss: 0.853974]\n",
      "epoch:10 step:10247 [D loss: 0.653409, acc.: 60.16%] [G loss: 0.866318]\n",
      "epoch:10 step:10248 [D loss: 0.674201, acc.: 57.03%] [G loss: 0.803639]\n",
      "epoch:10 step:10249 [D loss: 0.664062, acc.: 59.38%] [G loss: 0.860748]\n",
      "epoch:10 step:10250 [D loss: 0.685918, acc.: 61.72%] [G loss: 0.875819]\n",
      "epoch:10 step:10251 [D loss: 0.656002, acc.: 60.16%] [G loss: 0.837300]\n",
      "epoch:10 step:10252 [D loss: 0.688597, acc.: 55.47%] [G loss: 0.915397]\n",
      "epoch:10 step:10253 [D loss: 0.674464, acc.: 60.16%] [G loss: 0.970552]\n",
      "epoch:10 step:10254 [D loss: 0.633264, acc.: 62.50%] [G loss: 0.986968]\n",
      "epoch:10 step:10255 [D loss: 0.672999, acc.: 58.59%] [G loss: 0.981135]\n",
      "epoch:10 step:10256 [D loss: 0.615786, acc.: 71.88%] [G loss: 1.029623]\n",
      "epoch:10 step:10257 [D loss: 0.674641, acc.: 59.38%] [G loss: 0.939934]\n",
      "epoch:10 step:10258 [D loss: 0.678227, acc.: 58.59%] [G loss: 0.813582]\n",
      "epoch:10 step:10259 [D loss: 0.653239, acc.: 61.72%] [G loss: 0.880525]\n",
      "epoch:10 step:10260 [D loss: 0.591143, acc.: 71.09%] [G loss: 0.921752]\n",
      "epoch:10 step:10261 [D loss: 0.728031, acc.: 48.44%] [G loss: 0.907313]\n",
      "epoch:10 step:10262 [D loss: 0.741886, acc.: 49.22%] [G loss: 0.872947]\n",
      "epoch:10 step:10263 [D loss: 0.661237, acc.: 59.38%] [G loss: 0.888803]\n",
      "epoch:10 step:10264 [D loss: 0.633027, acc.: 64.84%] [G loss: 0.908085]\n",
      "epoch:10 step:10265 [D loss: 0.656067, acc.: 62.50%] [G loss: 0.958271]\n",
      "epoch:10 step:10266 [D loss: 0.625971, acc.: 66.41%] [G loss: 0.941920]\n",
      "epoch:10 step:10267 [D loss: 0.630062, acc.: 60.94%] [G loss: 0.954796]\n",
      "epoch:10 step:10268 [D loss: 0.586678, acc.: 71.09%] [G loss: 0.904417]\n",
      "epoch:10 step:10269 [D loss: 0.601889, acc.: 70.31%] [G loss: 0.919478]\n",
      "epoch:10 step:10270 [D loss: 0.610166, acc.: 65.62%] [G loss: 0.913088]\n",
      "epoch:10 step:10271 [D loss: 0.654041, acc.: 54.69%] [G loss: 0.905088]\n",
      "epoch:10 step:10272 [D loss: 0.673207, acc.: 57.03%] [G loss: 0.902924]\n",
      "epoch:10 step:10273 [D loss: 0.639967, acc.: 63.28%] [G loss: 0.980057]\n",
      "epoch:10 step:10274 [D loss: 0.673953, acc.: 60.94%] [G loss: 0.946434]\n",
      "epoch:10 step:10275 [D loss: 0.634115, acc.: 60.94%] [G loss: 0.971086]\n",
      "epoch:10 step:10276 [D loss: 0.667659, acc.: 59.38%] [G loss: 0.971772]\n",
      "epoch:10 step:10277 [D loss: 0.740256, acc.: 51.56%] [G loss: 0.873194]\n",
      "epoch:10 step:10278 [D loss: 0.629528, acc.: 65.62%] [G loss: 0.927821]\n",
      "epoch:10 step:10279 [D loss: 0.619242, acc.: 68.75%] [G loss: 0.940303]\n",
      "epoch:10 step:10280 [D loss: 0.661854, acc.: 57.03%] [G loss: 0.913524]\n",
      "epoch:10 step:10281 [D loss: 0.651049, acc.: 63.28%] [G loss: 0.884081]\n",
      "epoch:10 step:10282 [D loss: 0.582681, acc.: 71.09%] [G loss: 0.959201]\n",
      "epoch:10 step:10283 [D loss: 0.649566, acc.: 60.94%] [G loss: 0.894424]\n",
      "epoch:10 step:10284 [D loss: 0.680843, acc.: 57.03%] [G loss: 0.995629]\n",
      "epoch:10 step:10285 [D loss: 0.704832, acc.: 54.69%] [G loss: 0.972581]\n",
      "epoch:10 step:10286 [D loss: 0.730832, acc.: 49.22%] [G loss: 0.899495]\n",
      "epoch:10 step:10287 [D loss: 0.677277, acc.: 58.59%] [G loss: 0.926748]\n",
      "epoch:10 step:10288 [D loss: 0.560097, acc.: 72.66%] [G loss: 0.968731]\n",
      "epoch:10 step:10289 [D loss: 0.623133, acc.: 64.06%] [G loss: 1.012478]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10290 [D loss: 0.816585, acc.: 43.75%] [G loss: 0.983714]\n",
      "epoch:10 step:10291 [D loss: 0.620625, acc.: 67.97%] [G loss: 0.962356]\n",
      "epoch:10 step:10292 [D loss: 0.687815, acc.: 57.81%] [G loss: 0.949914]\n",
      "epoch:10 step:10293 [D loss: 0.623988, acc.: 67.97%] [G loss: 0.968214]\n",
      "epoch:10 step:10294 [D loss: 0.612429, acc.: 71.88%] [G loss: 0.938617]\n",
      "epoch:10 step:10295 [D loss: 0.593181, acc.: 73.44%] [G loss: 0.983267]\n",
      "epoch:10 step:10296 [D loss: 0.564651, acc.: 73.44%] [G loss: 0.981123]\n",
      "epoch:10 step:10297 [D loss: 0.603411, acc.: 67.19%] [G loss: 1.005908]\n",
      "epoch:10 step:10298 [D loss: 0.798040, acc.: 53.91%] [G loss: 1.038679]\n",
      "epoch:10 step:10299 [D loss: 0.598028, acc.: 69.53%] [G loss: 1.187584]\n",
      "epoch:10 step:10300 [D loss: 0.651821, acc.: 62.50%] [G loss: 1.091288]\n",
      "epoch:10 step:10301 [D loss: 0.697586, acc.: 53.91%] [G loss: 1.002877]\n",
      "epoch:10 step:10302 [D loss: 0.739615, acc.: 51.56%] [G loss: 0.912181]\n",
      "epoch:10 step:10303 [D loss: 0.628530, acc.: 66.41%] [G loss: 0.878216]\n",
      "epoch:10 step:10304 [D loss: 0.641653, acc.: 67.97%] [G loss: 0.916265]\n",
      "epoch:10 step:10305 [D loss: 0.586856, acc.: 66.41%] [G loss: 0.946593]\n",
      "epoch:10 step:10306 [D loss: 0.577100, acc.: 68.75%] [G loss: 1.061188]\n",
      "epoch:10 step:10307 [D loss: 0.610020, acc.: 67.19%] [G loss: 1.069313]\n",
      "epoch:11 step:10308 [D loss: 0.721875, acc.: 56.25%] [G loss: 1.002623]\n",
      "epoch:11 step:10309 [D loss: 0.706856, acc.: 52.34%] [G loss: 0.972769]\n",
      "epoch:11 step:10310 [D loss: 0.711079, acc.: 50.78%] [G loss: 0.918789]\n",
      "epoch:11 step:10311 [D loss: 0.694640, acc.: 53.91%] [G loss: 0.933878]\n",
      "epoch:11 step:10312 [D loss: 0.674824, acc.: 58.59%] [G loss: 0.979976]\n",
      "epoch:11 step:10313 [D loss: 0.662038, acc.: 64.06%] [G loss: 1.004401]\n",
      "epoch:11 step:10314 [D loss: 0.654225, acc.: 59.38%] [G loss: 1.021893]\n",
      "epoch:11 step:10315 [D loss: 0.658799, acc.: 58.59%] [G loss: 0.910852]\n",
      "epoch:11 step:10316 [D loss: 0.628289, acc.: 64.06%] [G loss: 0.890425]\n",
      "epoch:11 step:10317 [D loss: 0.596395, acc.: 67.97%] [G loss: 0.907661]\n",
      "epoch:11 step:10318 [D loss: 0.614815, acc.: 68.75%] [G loss: 0.912371]\n",
      "epoch:11 step:10319 [D loss: 0.669894, acc.: 58.59%] [G loss: 0.908764]\n",
      "epoch:11 step:10320 [D loss: 0.651245, acc.: 59.38%] [G loss: 0.945003]\n",
      "epoch:11 step:10321 [D loss: 0.641793, acc.: 59.38%] [G loss: 0.938579]\n",
      "epoch:11 step:10322 [D loss: 0.612615, acc.: 65.62%] [G loss: 0.996499]\n",
      "epoch:11 step:10323 [D loss: 0.640897, acc.: 58.59%] [G loss: 0.973233]\n",
      "epoch:11 step:10324 [D loss: 0.669337, acc.: 59.38%] [G loss: 0.924284]\n",
      "epoch:11 step:10325 [D loss: 0.670441, acc.: 59.38%] [G loss: 0.944831]\n",
      "epoch:11 step:10326 [D loss: 0.665692, acc.: 60.16%] [G loss: 0.911321]\n",
      "epoch:11 step:10327 [D loss: 0.696682, acc.: 56.25%] [G loss: 1.005610]\n",
      "epoch:11 step:10328 [D loss: 0.637754, acc.: 64.06%] [G loss: 0.985780]\n",
      "epoch:11 step:10329 [D loss: 0.572688, acc.: 69.53%] [G loss: 1.045425]\n",
      "epoch:11 step:10330 [D loss: 0.705791, acc.: 54.69%] [G loss: 0.942318]\n",
      "epoch:11 step:10331 [D loss: 0.698193, acc.: 55.47%] [G loss: 0.872495]\n",
      "epoch:11 step:10332 [D loss: 0.661227, acc.: 59.38%] [G loss: 0.876541]\n",
      "epoch:11 step:10333 [D loss: 0.705200, acc.: 55.47%] [G loss: 0.855251]\n",
      "epoch:11 step:10334 [D loss: 0.710467, acc.: 60.16%] [G loss: 0.938742]\n",
      "epoch:11 step:10335 [D loss: 0.653721, acc.: 64.06%] [G loss: 0.888641]\n",
      "epoch:11 step:10336 [D loss: 0.604942, acc.: 71.09%] [G loss: 0.910526]\n",
      "epoch:11 step:10337 [D loss: 0.634151, acc.: 60.16%] [G loss: 0.938606]\n",
      "epoch:11 step:10338 [D loss: 0.638567, acc.: 64.84%] [G loss: 0.816016]\n",
      "epoch:11 step:10339 [D loss: 0.701273, acc.: 59.38%] [G loss: 0.908309]\n",
      "epoch:11 step:10340 [D loss: 0.636193, acc.: 60.94%] [G loss: 0.922412]\n",
      "epoch:11 step:10341 [D loss: 0.672741, acc.: 58.59%] [G loss: 0.908417]\n",
      "epoch:11 step:10342 [D loss: 0.656956, acc.: 57.81%] [G loss: 0.862610]\n",
      "epoch:11 step:10343 [D loss: 0.641611, acc.: 61.72%] [G loss: 0.923723]\n",
      "epoch:11 step:10344 [D loss: 0.783880, acc.: 42.97%] [G loss: 0.913099]\n",
      "epoch:11 step:10345 [D loss: 0.718370, acc.: 52.34%] [G loss: 0.968403]\n",
      "epoch:11 step:10346 [D loss: 0.674699, acc.: 61.72%] [G loss: 0.848253]\n",
      "epoch:11 step:10347 [D loss: 0.617601, acc.: 65.62%] [G loss: 0.894630]\n",
      "epoch:11 step:10348 [D loss: 0.680171, acc.: 57.03%] [G loss: 0.892210]\n",
      "epoch:11 step:10349 [D loss: 0.689016, acc.: 60.16%] [G loss: 0.895271]\n",
      "epoch:11 step:10350 [D loss: 0.680267, acc.: 54.69%] [G loss: 0.837714]\n",
      "epoch:11 step:10351 [D loss: 0.668829, acc.: 60.16%] [G loss: 0.893230]\n",
      "epoch:11 step:10352 [D loss: 0.724592, acc.: 53.12%] [G loss: 0.909217]\n",
      "epoch:11 step:10353 [D loss: 0.650565, acc.: 57.03%] [G loss: 0.839151]\n",
      "epoch:11 step:10354 [D loss: 0.631272, acc.: 64.84%] [G loss: 0.875180]\n",
      "epoch:11 step:10355 [D loss: 0.620628, acc.: 70.31%] [G loss: 0.889115]\n",
      "epoch:11 step:10356 [D loss: 0.617383, acc.: 66.41%] [G loss: 0.879503]\n",
      "epoch:11 step:10357 [D loss: 0.627033, acc.: 65.62%] [G loss: 0.897515]\n",
      "epoch:11 step:10358 [D loss: 0.720682, acc.: 51.56%] [G loss: 0.899771]\n",
      "epoch:11 step:10359 [D loss: 0.665000, acc.: 62.50%] [G loss: 0.926342]\n",
      "epoch:11 step:10360 [D loss: 0.620539, acc.: 65.62%] [G loss: 0.869475]\n",
      "epoch:11 step:10361 [D loss: 0.602029, acc.: 68.75%] [G loss: 0.931187]\n",
      "epoch:11 step:10362 [D loss: 0.630483, acc.: 64.06%] [G loss: 0.976633]\n",
      "epoch:11 step:10363 [D loss: 0.672571, acc.: 59.38%] [G loss: 0.920173]\n",
      "epoch:11 step:10364 [D loss: 0.672995, acc.: 60.94%] [G loss: 0.885935]\n",
      "epoch:11 step:10365 [D loss: 0.694012, acc.: 58.59%] [G loss: 0.923695]\n",
      "epoch:11 step:10366 [D loss: 0.641019, acc.: 60.94%] [G loss: 0.954772]\n",
      "epoch:11 step:10367 [D loss: 0.655420, acc.: 57.81%] [G loss: 0.889358]\n",
      "epoch:11 step:10368 [D loss: 0.655156, acc.: 64.06%] [G loss: 0.909413]\n",
      "epoch:11 step:10369 [D loss: 0.683118, acc.: 60.94%] [G loss: 0.909320]\n",
      "epoch:11 step:10370 [D loss: 0.642232, acc.: 64.84%] [G loss: 0.872752]\n",
      "epoch:11 step:10371 [D loss: 0.724510, acc.: 48.44%] [G loss: 0.869871]\n",
      "epoch:11 step:10372 [D loss: 0.659009, acc.: 62.50%] [G loss: 0.950402]\n",
      "epoch:11 step:10373 [D loss: 0.634347, acc.: 60.94%] [G loss: 0.895149]\n",
      "epoch:11 step:10374 [D loss: 0.633777, acc.: 60.94%] [G loss: 0.849126]\n",
      "epoch:11 step:10375 [D loss: 0.682177, acc.: 59.38%] [G loss: 0.900847]\n",
      "epoch:11 step:10376 [D loss: 0.638021, acc.: 64.84%] [G loss: 0.898712]\n",
      "epoch:11 step:10377 [D loss: 0.611103, acc.: 71.09%] [G loss: 1.015390]\n",
      "epoch:11 step:10378 [D loss: 0.692465, acc.: 54.69%] [G loss: 0.893053]\n",
      "epoch:11 step:10379 [D loss: 0.678410, acc.: 57.81%] [G loss: 0.966881]\n",
      "epoch:11 step:10380 [D loss: 0.649549, acc.: 57.03%] [G loss: 0.928265]\n",
      "epoch:11 step:10381 [D loss: 0.611158, acc.: 64.06%] [G loss: 0.983975]\n",
      "epoch:11 step:10382 [D loss: 0.672437, acc.: 62.50%] [G loss: 0.975824]\n",
      "epoch:11 step:10383 [D loss: 0.591461, acc.: 71.09%] [G loss: 0.946148]\n",
      "epoch:11 step:10384 [D loss: 0.564278, acc.: 68.75%] [G loss: 0.939089]\n",
      "epoch:11 step:10385 [D loss: 0.752801, acc.: 53.12%] [G loss: 0.952231]\n",
      "epoch:11 step:10386 [D loss: 0.666903, acc.: 57.81%] [G loss: 0.884206]\n",
      "epoch:11 step:10387 [D loss: 0.670980, acc.: 63.28%] [G loss: 0.869420]\n",
      "epoch:11 step:10388 [D loss: 0.732414, acc.: 52.34%] [G loss: 0.901888]\n",
      "epoch:11 step:10389 [D loss: 0.617269, acc.: 67.19%] [G loss: 0.915713]\n",
      "epoch:11 step:10390 [D loss: 0.642442, acc.: 64.06%] [G loss: 0.914114]\n",
      "epoch:11 step:10391 [D loss: 0.622614, acc.: 64.06%] [G loss: 0.868999]\n",
      "epoch:11 step:10392 [D loss: 0.678948, acc.: 54.69%] [G loss: 0.945660]\n",
      "epoch:11 step:10393 [D loss: 0.658122, acc.: 61.72%] [G loss: 0.952353]\n",
      "epoch:11 step:10394 [D loss: 0.684561, acc.: 56.25%] [G loss: 0.916313]\n",
      "epoch:11 step:10395 [D loss: 0.621737, acc.: 68.75%] [G loss: 0.963565]\n",
      "epoch:11 step:10396 [D loss: 0.677373, acc.: 63.28%] [G loss: 0.852291]\n",
      "epoch:11 step:10397 [D loss: 0.621400, acc.: 65.62%] [G loss: 0.898263]\n",
      "epoch:11 step:10398 [D loss: 0.630722, acc.: 69.53%] [G loss: 0.922028]\n",
      "epoch:11 step:10399 [D loss: 0.594234, acc.: 67.97%] [G loss: 0.899810]\n",
      "epoch:11 step:10400 [D loss: 0.618214, acc.: 66.41%] [G loss: 0.965677]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.011244\n",
      "FID: 7.070572\n",
      "0 = 11.971533094048544\n",
      "1 = 0.059254292714867166\n",
      "2 = 0.933650016784668\n",
      "3 = 0.8913999795913696\n",
      "4 = 0.9758999943733215\n",
      "5 = 0.9736756086349487\n",
      "6 = 0.8913999795913696\n",
      "7 = 5.934222048360115\n",
      "8 = 0.051513093339464584\n",
      "9 = 0.7203999757766724\n",
      "10 = 0.6927000284194946\n",
      "11 = 0.7480999827384949\n",
      "12 = 0.733326256275177\n",
      "13 = 0.6927000284194946\n",
      "14 = 8.011314392089844\n",
      "15 = 9.520576477050781\n",
      "16 = 0.11586164683103561\n",
      "17 = 8.01124382019043\n",
      "18 = 7.070572376251221\n",
      "epoch:11 step:10401 [D loss: 0.644179, acc.: 60.16%] [G loss: 0.908046]\n",
      "epoch:11 step:10402 [D loss: 0.653761, acc.: 59.38%] [G loss: 0.992253]\n",
      "epoch:11 step:10403 [D loss: 0.646807, acc.: 68.75%] [G loss: 0.889250]\n",
      "epoch:11 step:10404 [D loss: 0.592637, acc.: 70.31%] [G loss: 0.966942]\n",
      "epoch:11 step:10405 [D loss: 0.622225, acc.: 64.06%] [G loss: 0.992053]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10406 [D loss: 0.639367, acc.: 62.50%] [G loss: 0.921156]\n",
      "epoch:11 step:10407 [D loss: 0.583011, acc.: 64.06%] [G loss: 0.960329]\n",
      "epoch:11 step:10408 [D loss: 0.638399, acc.: 62.50%] [G loss: 0.837090]\n",
      "epoch:11 step:10409 [D loss: 0.734919, acc.: 53.12%] [G loss: 0.866233]\n",
      "epoch:11 step:10410 [D loss: 0.664957, acc.: 60.16%] [G loss: 0.878140]\n",
      "epoch:11 step:10411 [D loss: 0.683213, acc.: 56.25%] [G loss: 0.872339]\n",
      "epoch:11 step:10412 [D loss: 0.707215, acc.: 54.69%] [G loss: 0.855908]\n",
      "epoch:11 step:10413 [D loss: 0.680963, acc.: 57.81%] [G loss: 0.936947]\n",
      "epoch:11 step:10414 [D loss: 0.615900, acc.: 64.84%] [G loss: 1.018406]\n",
      "epoch:11 step:10415 [D loss: 0.725601, acc.: 49.22%] [G loss: 0.967292]\n",
      "epoch:11 step:10416 [D loss: 0.681511, acc.: 53.12%] [G loss: 0.876568]\n",
      "epoch:11 step:10417 [D loss: 0.695023, acc.: 54.69%] [G loss: 0.905927]\n",
      "epoch:11 step:10418 [D loss: 0.658211, acc.: 58.59%] [G loss: 0.957691]\n",
      "epoch:11 step:10419 [D loss: 0.641955, acc.: 63.28%] [G loss: 0.870421]\n",
      "epoch:11 step:10420 [D loss: 0.576439, acc.: 74.22%] [G loss: 0.893523]\n",
      "epoch:11 step:10421 [D loss: 0.591602, acc.: 68.75%] [G loss: 0.972051]\n",
      "epoch:11 step:10422 [D loss: 0.601482, acc.: 67.19%] [G loss: 1.008505]\n",
      "epoch:11 step:10423 [D loss: 0.587728, acc.: 68.75%] [G loss: 1.010767]\n",
      "epoch:11 step:10424 [D loss: 0.652585, acc.: 62.50%] [G loss: 0.983953]\n",
      "epoch:11 step:10425 [D loss: 0.673739, acc.: 55.47%] [G loss: 0.978428]\n",
      "epoch:11 step:10426 [D loss: 0.650885, acc.: 60.16%] [G loss: 0.974289]\n",
      "epoch:11 step:10427 [D loss: 0.669971, acc.: 60.16%] [G loss: 0.949783]\n",
      "epoch:11 step:10428 [D loss: 0.699358, acc.: 54.69%] [G loss: 0.949486]\n",
      "epoch:11 step:10429 [D loss: 0.640359, acc.: 60.16%] [G loss: 0.923558]\n",
      "epoch:11 step:10430 [D loss: 0.636066, acc.: 62.50%] [G loss: 0.992195]\n",
      "epoch:11 step:10431 [D loss: 0.688306, acc.: 57.81%] [G loss: 0.960561]\n",
      "epoch:11 step:10432 [D loss: 0.620892, acc.: 65.62%] [G loss: 0.918831]\n",
      "epoch:11 step:10433 [D loss: 0.586726, acc.: 67.97%] [G loss: 0.972857]\n",
      "epoch:11 step:10434 [D loss: 0.631040, acc.: 64.06%] [G loss: 0.896733]\n",
      "epoch:11 step:10435 [D loss: 0.674835, acc.: 56.25%] [G loss: 0.864380]\n",
      "epoch:11 step:10436 [D loss: 0.663927, acc.: 60.16%] [G loss: 0.898647]\n",
      "epoch:11 step:10437 [D loss: 0.616525, acc.: 69.53%] [G loss: 0.852720]\n",
      "epoch:11 step:10438 [D loss: 0.631482, acc.: 66.41%] [G loss: 0.909431]\n",
      "epoch:11 step:10439 [D loss: 0.627782, acc.: 64.84%] [G loss: 0.912968]\n",
      "epoch:11 step:10440 [D loss: 0.676858, acc.: 60.16%] [G loss: 0.953579]\n",
      "epoch:11 step:10441 [D loss: 0.656232, acc.: 60.94%] [G loss: 0.980040]\n",
      "epoch:11 step:10442 [D loss: 0.638730, acc.: 61.72%] [G loss: 1.005434]\n",
      "epoch:11 step:10443 [D loss: 0.624640, acc.: 67.97%] [G loss: 0.875024]\n",
      "epoch:11 step:10444 [D loss: 0.680231, acc.: 57.03%] [G loss: 0.805469]\n",
      "epoch:11 step:10445 [D loss: 0.686271, acc.: 59.38%] [G loss: 0.905599]\n",
      "epoch:11 step:10446 [D loss: 0.671433, acc.: 58.59%] [G loss: 0.841983]\n",
      "epoch:11 step:10447 [D loss: 0.666714, acc.: 59.38%] [G loss: 0.800911]\n",
      "epoch:11 step:10448 [D loss: 0.696815, acc.: 50.78%] [G loss: 0.892893]\n",
      "epoch:11 step:10449 [D loss: 0.642638, acc.: 64.06%] [G loss: 0.866021]\n",
      "epoch:11 step:10450 [D loss: 0.679080, acc.: 59.38%] [G loss: 0.848270]\n",
      "epoch:11 step:10451 [D loss: 0.656692, acc.: 65.62%] [G loss: 0.828928]\n",
      "epoch:11 step:10452 [D loss: 0.694662, acc.: 54.69%] [G loss: 0.887713]\n",
      "epoch:11 step:10453 [D loss: 0.666033, acc.: 61.72%] [G loss: 0.872184]\n",
      "epoch:11 step:10454 [D loss: 0.684317, acc.: 53.91%] [G loss: 0.924497]\n",
      "epoch:11 step:10455 [D loss: 0.655968, acc.: 57.81%] [G loss: 0.930079]\n",
      "epoch:11 step:10456 [D loss: 0.659441, acc.: 60.94%] [G loss: 0.853449]\n",
      "epoch:11 step:10457 [D loss: 0.653768, acc.: 65.62%] [G loss: 0.818800]\n",
      "epoch:11 step:10458 [D loss: 0.656587, acc.: 63.28%] [G loss: 0.870622]\n",
      "epoch:11 step:10459 [D loss: 0.661725, acc.: 60.16%] [G loss: 0.873551]\n",
      "epoch:11 step:10460 [D loss: 0.655512, acc.: 62.50%] [G loss: 0.827599]\n",
      "epoch:11 step:10461 [D loss: 0.644185, acc.: 59.38%] [G loss: 0.851715]\n",
      "epoch:11 step:10462 [D loss: 0.589656, acc.: 72.66%] [G loss: 0.890594]\n",
      "epoch:11 step:10463 [D loss: 0.675590, acc.: 62.50%] [G loss: 0.900754]\n",
      "epoch:11 step:10464 [D loss: 0.702409, acc.: 52.34%] [G loss: 0.847920]\n",
      "epoch:11 step:10465 [D loss: 0.678736, acc.: 59.38%] [G loss: 0.948655]\n",
      "epoch:11 step:10466 [D loss: 0.647440, acc.: 64.84%] [G loss: 0.942239]\n",
      "epoch:11 step:10467 [D loss: 0.748580, acc.: 51.56%] [G loss: 0.943044]\n",
      "epoch:11 step:10468 [D loss: 0.659214, acc.: 57.03%] [G loss: 0.932857]\n",
      "epoch:11 step:10469 [D loss: 0.702599, acc.: 59.38%] [G loss: 0.964531]\n",
      "epoch:11 step:10470 [D loss: 0.663572, acc.: 56.25%] [G loss: 0.948207]\n",
      "epoch:11 step:10471 [D loss: 0.644069, acc.: 61.72%] [G loss: 0.852421]\n",
      "epoch:11 step:10472 [D loss: 0.654650, acc.: 58.59%] [G loss: 0.888625]\n",
      "epoch:11 step:10473 [D loss: 0.652308, acc.: 60.16%] [G loss: 0.869409]\n",
      "epoch:11 step:10474 [D loss: 0.684294, acc.: 52.34%] [G loss: 0.906971]\n",
      "epoch:11 step:10475 [D loss: 0.695783, acc.: 60.16%] [G loss: 0.969154]\n",
      "epoch:11 step:10476 [D loss: 0.663151, acc.: 56.25%] [G loss: 0.920272]\n",
      "epoch:11 step:10477 [D loss: 0.624666, acc.: 65.62%] [G loss: 0.856183]\n",
      "epoch:11 step:10478 [D loss: 0.646839, acc.: 60.94%] [G loss: 0.810170]\n",
      "epoch:11 step:10479 [D loss: 0.690463, acc.: 56.25%] [G loss: 0.825907]\n",
      "epoch:11 step:10480 [D loss: 0.681096, acc.: 61.72%] [G loss: 0.862581]\n",
      "epoch:11 step:10481 [D loss: 0.679631, acc.: 54.69%] [G loss: 0.899246]\n",
      "epoch:11 step:10482 [D loss: 0.641739, acc.: 60.94%] [G loss: 0.860294]\n",
      "epoch:11 step:10483 [D loss: 0.648589, acc.: 62.50%] [G loss: 0.883252]\n",
      "epoch:11 step:10484 [D loss: 0.645614, acc.: 62.50%] [G loss: 0.878386]\n",
      "epoch:11 step:10485 [D loss: 0.678337, acc.: 57.03%] [G loss: 0.869424]\n",
      "epoch:11 step:10486 [D loss: 0.659966, acc.: 63.28%] [G loss: 0.884836]\n",
      "epoch:11 step:10487 [D loss: 0.692440, acc.: 56.25%] [G loss: 0.914513]\n",
      "epoch:11 step:10488 [D loss: 0.711031, acc.: 50.78%] [G loss: 0.853319]\n",
      "epoch:11 step:10489 [D loss: 0.692867, acc.: 56.25%] [G loss: 0.826086]\n",
      "epoch:11 step:10490 [D loss: 0.648537, acc.: 61.72%] [G loss: 0.845878]\n",
      "epoch:11 step:10491 [D loss: 0.629624, acc.: 65.62%] [G loss: 0.859037]\n",
      "epoch:11 step:10492 [D loss: 0.704082, acc.: 52.34%] [G loss: 0.902948]\n",
      "epoch:11 step:10493 [D loss: 0.697050, acc.: 59.38%] [G loss: 0.857007]\n",
      "epoch:11 step:10494 [D loss: 0.683548, acc.: 54.69%] [G loss: 0.875022]\n",
      "epoch:11 step:10495 [D loss: 0.680368, acc.: 56.25%] [G loss: 0.818528]\n",
      "epoch:11 step:10496 [D loss: 0.704354, acc.: 52.34%] [G loss: 0.830189]\n",
      "epoch:11 step:10497 [D loss: 0.658801, acc.: 59.38%] [G loss: 0.809003]\n",
      "epoch:11 step:10498 [D loss: 0.624281, acc.: 62.50%] [G loss: 0.874469]\n",
      "epoch:11 step:10499 [D loss: 0.653369, acc.: 62.50%] [G loss: 0.881613]\n",
      "epoch:11 step:10500 [D loss: 0.637735, acc.: 60.94%] [G loss: 0.877360]\n",
      "epoch:11 step:10501 [D loss: 0.659008, acc.: 61.72%] [G loss: 0.896824]\n",
      "epoch:11 step:10502 [D loss: 0.659284, acc.: 62.50%] [G loss: 0.911995]\n",
      "epoch:11 step:10503 [D loss: 0.693463, acc.: 52.34%] [G loss: 0.867701]\n",
      "epoch:11 step:10504 [D loss: 0.613529, acc.: 68.75%] [G loss: 0.899615]\n",
      "epoch:11 step:10505 [D loss: 0.624510, acc.: 64.06%] [G loss: 0.904292]\n",
      "epoch:11 step:10506 [D loss: 0.629561, acc.: 61.72%] [G loss: 0.890434]\n",
      "epoch:11 step:10507 [D loss: 0.659658, acc.: 58.59%] [G loss: 0.879547]\n",
      "epoch:11 step:10508 [D loss: 0.697684, acc.: 53.91%] [G loss: 0.906643]\n",
      "epoch:11 step:10509 [D loss: 0.639535, acc.: 67.19%] [G loss: 0.888585]\n",
      "epoch:11 step:10510 [D loss: 0.718905, acc.: 51.56%] [G loss: 0.853915]\n",
      "epoch:11 step:10511 [D loss: 0.649506, acc.: 62.50%] [G loss: 0.815483]\n",
      "epoch:11 step:10512 [D loss: 0.681546, acc.: 57.03%] [G loss: 0.885586]\n",
      "epoch:11 step:10513 [D loss: 0.635527, acc.: 64.06%] [G loss: 0.871552]\n",
      "epoch:11 step:10514 [D loss: 0.610429, acc.: 64.06%] [G loss: 0.848715]\n",
      "epoch:11 step:10515 [D loss: 0.554102, acc.: 71.88%] [G loss: 0.889853]\n",
      "epoch:11 step:10516 [D loss: 0.665578, acc.: 63.28%] [G loss: 0.889563]\n",
      "epoch:11 step:10517 [D loss: 0.664040, acc.: 60.94%] [G loss: 0.876908]\n",
      "epoch:11 step:10518 [D loss: 0.681386, acc.: 57.03%] [G loss: 0.831286]\n",
      "epoch:11 step:10519 [D loss: 0.640168, acc.: 62.50%] [G loss: 0.886509]\n",
      "epoch:11 step:10520 [D loss: 0.672475, acc.: 57.03%] [G loss: 0.926871]\n",
      "epoch:11 step:10521 [D loss: 0.700347, acc.: 51.56%] [G loss: 0.918513]\n",
      "epoch:11 step:10522 [D loss: 0.713766, acc.: 53.12%] [G loss: 0.881553]\n",
      "epoch:11 step:10523 [D loss: 0.636302, acc.: 64.06%] [G loss: 0.874404]\n",
      "epoch:11 step:10524 [D loss: 0.625579, acc.: 64.06%] [G loss: 0.918411]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10525 [D loss: 0.618313, acc.: 65.62%] [G loss: 0.910147]\n",
      "epoch:11 step:10526 [D loss: 0.609101, acc.: 61.72%] [G loss: 0.901092]\n",
      "epoch:11 step:10527 [D loss: 0.755062, acc.: 47.66%] [G loss: 0.839863]\n",
      "epoch:11 step:10528 [D loss: 0.644569, acc.: 59.38%] [G loss: 0.934896]\n",
      "epoch:11 step:10529 [D loss: 0.630954, acc.: 64.84%] [G loss: 0.997866]\n",
      "epoch:11 step:10530 [D loss: 0.582973, acc.: 71.88%] [G loss: 0.958688]\n",
      "epoch:11 step:10531 [D loss: 0.713234, acc.: 56.25%] [G loss: 0.868598]\n",
      "epoch:11 step:10532 [D loss: 0.716317, acc.: 49.22%] [G loss: 0.773315]\n",
      "epoch:11 step:10533 [D loss: 0.660251, acc.: 53.91%] [G loss: 0.839585]\n",
      "epoch:11 step:10534 [D loss: 0.670044, acc.: 58.59%] [G loss: 0.855127]\n",
      "epoch:11 step:10535 [D loss: 0.670264, acc.: 58.59%] [G loss: 0.890696]\n",
      "epoch:11 step:10536 [D loss: 0.625857, acc.: 64.06%] [G loss: 0.865645]\n",
      "epoch:11 step:10537 [D loss: 0.614320, acc.: 69.53%] [G loss: 0.898569]\n",
      "epoch:11 step:10538 [D loss: 0.558049, acc.: 69.53%] [G loss: 0.933153]\n",
      "epoch:11 step:10539 [D loss: 0.576818, acc.: 70.31%] [G loss: 0.990437]\n",
      "epoch:11 step:10540 [D loss: 0.696373, acc.: 56.25%] [G loss: 0.965854]\n",
      "epoch:11 step:10541 [D loss: 0.687018, acc.: 57.03%] [G loss: 0.915881]\n",
      "epoch:11 step:10542 [D loss: 0.676828, acc.: 56.25%] [G loss: 0.962144]\n",
      "epoch:11 step:10543 [D loss: 0.653146, acc.: 60.16%] [G loss: 0.902876]\n",
      "epoch:11 step:10544 [D loss: 0.648598, acc.: 60.94%] [G loss: 0.937921]\n",
      "epoch:11 step:10545 [D loss: 0.670606, acc.: 56.25%] [G loss: 0.896499]\n",
      "epoch:11 step:10546 [D loss: 0.642896, acc.: 65.62%] [G loss: 0.968781]\n",
      "epoch:11 step:10547 [D loss: 0.677193, acc.: 57.81%] [G loss: 0.936284]\n",
      "epoch:11 step:10548 [D loss: 0.633923, acc.: 65.62%] [G loss: 0.963087]\n",
      "epoch:11 step:10549 [D loss: 0.620466, acc.: 67.97%] [G loss: 1.000286]\n",
      "epoch:11 step:10550 [D loss: 0.656119, acc.: 57.81%] [G loss: 0.902242]\n",
      "epoch:11 step:10551 [D loss: 0.662284, acc.: 61.72%] [G loss: 0.898754]\n",
      "epoch:11 step:10552 [D loss: 0.660052, acc.: 63.28%] [G loss: 0.917225]\n",
      "epoch:11 step:10553 [D loss: 0.679309, acc.: 57.03%] [G loss: 0.908483]\n",
      "epoch:11 step:10554 [D loss: 0.658693, acc.: 57.81%] [G loss: 0.942624]\n",
      "epoch:11 step:10555 [D loss: 0.618629, acc.: 61.72%] [G loss: 0.890800]\n",
      "epoch:11 step:10556 [D loss: 0.727002, acc.: 51.56%] [G loss: 0.766932]\n",
      "epoch:11 step:10557 [D loss: 0.766253, acc.: 44.53%] [G loss: 0.850692]\n",
      "epoch:11 step:10558 [D loss: 0.730765, acc.: 53.91%] [G loss: 0.856531]\n",
      "epoch:11 step:10559 [D loss: 0.658089, acc.: 60.16%] [G loss: 0.888941]\n",
      "epoch:11 step:10560 [D loss: 0.656897, acc.: 57.81%] [G loss: 0.932465]\n",
      "epoch:11 step:10561 [D loss: 0.636230, acc.: 67.19%] [G loss: 0.940881]\n",
      "epoch:11 step:10562 [D loss: 0.668326, acc.: 62.50%] [G loss: 0.922746]\n",
      "epoch:11 step:10563 [D loss: 0.617284, acc.: 67.97%] [G loss: 0.954693]\n",
      "epoch:11 step:10564 [D loss: 0.668411, acc.: 54.69%] [G loss: 0.900647]\n",
      "epoch:11 step:10565 [D loss: 0.646463, acc.: 58.59%] [G loss: 0.924445]\n",
      "epoch:11 step:10566 [D loss: 0.655768, acc.: 64.06%] [G loss: 0.877541]\n",
      "epoch:11 step:10567 [D loss: 0.657268, acc.: 58.59%] [G loss: 0.857624]\n",
      "epoch:11 step:10568 [D loss: 0.656590, acc.: 64.84%] [G loss: 0.868463]\n",
      "epoch:11 step:10569 [D loss: 0.675144, acc.: 53.91%] [G loss: 0.923483]\n",
      "epoch:11 step:10570 [D loss: 0.675260, acc.: 55.47%] [G loss: 0.876202]\n",
      "epoch:11 step:10571 [D loss: 0.583076, acc.: 69.53%] [G loss: 0.899174]\n",
      "epoch:11 step:10572 [D loss: 0.724202, acc.: 50.00%] [G loss: 0.909647]\n",
      "epoch:11 step:10573 [D loss: 0.654850, acc.: 60.16%] [G loss: 0.875297]\n",
      "epoch:11 step:10574 [D loss: 0.690032, acc.: 61.72%] [G loss: 0.887352]\n",
      "epoch:11 step:10575 [D loss: 0.635128, acc.: 65.62%] [G loss: 0.967541]\n",
      "epoch:11 step:10576 [D loss: 0.647862, acc.: 60.16%] [G loss: 0.912794]\n",
      "epoch:11 step:10577 [D loss: 0.626076, acc.: 69.53%] [G loss: 0.944938]\n",
      "epoch:11 step:10578 [D loss: 0.634092, acc.: 65.62%] [G loss: 0.935535]\n",
      "epoch:11 step:10579 [D loss: 0.672604, acc.: 56.25%] [G loss: 0.939468]\n",
      "epoch:11 step:10580 [D loss: 0.651055, acc.: 62.50%] [G loss: 0.909240]\n",
      "epoch:11 step:10581 [D loss: 0.633232, acc.: 68.75%] [G loss: 0.903971]\n",
      "epoch:11 step:10582 [D loss: 0.672766, acc.: 57.81%] [G loss: 0.867868]\n",
      "epoch:11 step:10583 [D loss: 0.626411, acc.: 62.50%] [G loss: 0.922263]\n",
      "epoch:11 step:10584 [D loss: 0.707270, acc.: 52.34%] [G loss: 0.896594]\n",
      "epoch:11 step:10585 [D loss: 0.652263, acc.: 65.62%] [G loss: 0.942717]\n",
      "epoch:11 step:10586 [D loss: 0.679436, acc.: 54.69%] [G loss: 0.869844]\n",
      "epoch:11 step:10587 [D loss: 0.599870, acc.: 67.19%] [G loss: 0.899794]\n",
      "epoch:11 step:10588 [D loss: 0.694619, acc.: 58.59%] [G loss: 0.910618]\n",
      "epoch:11 step:10589 [D loss: 0.675387, acc.: 58.59%] [G loss: 0.901691]\n",
      "epoch:11 step:10590 [D loss: 0.641081, acc.: 60.16%] [G loss: 0.965698]\n",
      "epoch:11 step:10591 [D loss: 0.625886, acc.: 68.75%] [G loss: 0.909059]\n",
      "epoch:11 step:10592 [D loss: 0.604174, acc.: 68.75%] [G loss: 0.877470]\n",
      "epoch:11 step:10593 [D loss: 0.631168, acc.: 67.97%] [G loss: 0.895789]\n",
      "epoch:11 step:10594 [D loss: 0.649683, acc.: 60.94%] [G loss: 0.929136]\n",
      "epoch:11 step:10595 [D loss: 0.677428, acc.: 63.28%] [G loss: 0.966901]\n",
      "epoch:11 step:10596 [D loss: 0.606758, acc.: 68.75%] [G loss: 0.962822]\n",
      "epoch:11 step:10597 [D loss: 0.699268, acc.: 58.59%] [G loss: 0.901099]\n",
      "epoch:11 step:10598 [D loss: 0.762011, acc.: 47.66%] [G loss: 0.874040]\n",
      "epoch:11 step:10599 [D loss: 0.664362, acc.: 59.38%] [G loss: 0.876545]\n",
      "epoch:11 step:10600 [D loss: 0.662428, acc.: 61.72%] [G loss: 0.885597]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.705604\n",
      "FID: 13.365192\n",
      "0 = 11.939320268034889\n",
      "1 = 0.05632827398992085\n",
      "2 = 0.9312499761581421\n",
      "3 = 0.8859999775886536\n",
      "4 = 0.9764999747276306\n",
      "5 = 0.9741616249084473\n",
      "6 = 0.8859999775886536\n",
      "7 = 6.501694552207009\n",
      "8 = 0.0778934863147498\n",
      "9 = 0.7311499714851379\n",
      "10 = 0.70660001039505\n",
      "11 = 0.7556999921798706\n",
      "12 = 0.743085503578186\n",
      "13 = 0.70660001039505\n",
      "14 = 7.705677509307861\n",
      "15 = 9.511655807495117\n",
      "16 = 0.11909512430429459\n",
      "17 = 7.705604076385498\n",
      "18 = 13.365192413330078\n",
      "epoch:11 step:10601 [D loss: 0.652057, acc.: 62.50%] [G loss: 0.855346]\n",
      "epoch:11 step:10602 [D loss: 0.650405, acc.: 60.16%] [G loss: 0.878086]\n",
      "epoch:11 step:10603 [D loss: 0.609995, acc.: 67.19%] [G loss: 0.895259]\n",
      "epoch:11 step:10604 [D loss: 0.672346, acc.: 60.16%] [G loss: 0.909511]\n",
      "epoch:11 step:10605 [D loss: 0.642991, acc.: 61.72%] [G loss: 0.907991]\n",
      "epoch:11 step:10606 [D loss: 0.668723, acc.: 58.59%] [G loss: 0.923492]\n",
      "epoch:11 step:10607 [D loss: 0.636190, acc.: 62.50%] [G loss: 0.903756]\n",
      "epoch:11 step:10608 [D loss: 0.687149, acc.: 56.25%] [G loss: 0.911676]\n",
      "epoch:11 step:10609 [D loss: 0.662783, acc.: 59.38%] [G loss: 0.941860]\n",
      "epoch:11 step:10610 [D loss: 0.675578, acc.: 60.94%] [G loss: 0.902889]\n",
      "epoch:11 step:10611 [D loss: 0.657240, acc.: 60.16%] [G loss: 0.884082]\n",
      "epoch:11 step:10612 [D loss: 0.644479, acc.: 60.94%] [G loss: 0.894215]\n",
      "epoch:11 step:10613 [D loss: 0.661042, acc.: 57.81%] [G loss: 0.913364]\n",
      "epoch:11 step:10614 [D loss: 0.617409, acc.: 66.41%] [G loss: 0.958110]\n",
      "epoch:11 step:10615 [D loss: 0.658941, acc.: 60.16%] [G loss: 0.887230]\n",
      "epoch:11 step:10616 [D loss: 0.634895, acc.: 68.75%] [G loss: 0.909467]\n",
      "epoch:11 step:10617 [D loss: 0.618160, acc.: 69.53%] [G loss: 0.941198]\n",
      "epoch:11 step:10618 [D loss: 0.642866, acc.: 65.62%] [G loss: 0.932527]\n",
      "epoch:11 step:10619 [D loss: 0.614282, acc.: 65.62%] [G loss: 0.986663]\n",
      "epoch:11 step:10620 [D loss: 0.599491, acc.: 72.66%] [G loss: 1.021628]\n",
      "epoch:11 step:10621 [D loss: 0.587431, acc.: 67.19%] [G loss: 0.986685]\n",
      "epoch:11 step:10622 [D loss: 0.648328, acc.: 64.06%] [G loss: 0.935374]\n",
      "epoch:11 step:10623 [D loss: 0.789515, acc.: 47.66%] [G loss: 0.909412]\n",
      "epoch:11 step:10624 [D loss: 0.663307, acc.: 58.59%] [G loss: 0.893575]\n",
      "epoch:11 step:10625 [D loss: 0.626746, acc.: 64.06%] [G loss: 0.894483]\n",
      "epoch:11 step:10626 [D loss: 0.640208, acc.: 61.72%] [G loss: 0.898580]\n",
      "epoch:11 step:10627 [D loss: 0.681765, acc.: 56.25%] [G loss: 0.884880]\n",
      "epoch:11 step:10628 [D loss: 0.651298, acc.: 57.81%] [G loss: 0.943063]\n",
      "epoch:11 step:10629 [D loss: 0.648562, acc.: 63.28%] [G loss: 0.904235]\n",
      "epoch:11 step:10630 [D loss: 0.711235, acc.: 53.91%] [G loss: 0.883516]\n",
      "epoch:11 step:10631 [D loss: 0.661552, acc.: 59.38%] [G loss: 0.817794]\n",
      "epoch:11 step:10632 [D loss: 0.613359, acc.: 65.62%] [G loss: 0.835801]\n",
      "epoch:11 step:10633 [D loss: 0.652705, acc.: 63.28%] [G loss: 0.849810]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10634 [D loss: 0.631527, acc.: 63.28%] [G loss: 0.912062]\n",
      "epoch:11 step:10635 [D loss: 0.650840, acc.: 57.03%] [G loss: 0.969428]\n",
      "epoch:11 step:10636 [D loss: 0.691642, acc.: 58.59%] [G loss: 0.927890]\n",
      "epoch:11 step:10637 [D loss: 0.687290, acc.: 57.81%] [G loss: 0.888722]\n",
      "epoch:11 step:10638 [D loss: 0.618283, acc.: 64.84%] [G loss: 0.793141]\n",
      "epoch:11 step:10639 [D loss: 0.617513, acc.: 66.41%] [G loss: 0.890801]\n",
      "epoch:11 step:10640 [D loss: 0.623932, acc.: 67.19%] [G loss: 0.868571]\n",
      "epoch:11 step:10641 [D loss: 0.639117, acc.: 64.84%] [G loss: 0.923789]\n",
      "epoch:11 step:10642 [D loss: 0.634105, acc.: 63.28%] [G loss: 0.932687]\n",
      "epoch:11 step:10643 [D loss: 0.632753, acc.: 63.28%] [G loss: 0.907619]\n",
      "epoch:11 step:10644 [D loss: 0.606663, acc.: 71.88%] [G loss: 0.907652]\n",
      "epoch:11 step:10645 [D loss: 0.660993, acc.: 62.50%] [G loss: 0.858187]\n",
      "epoch:11 step:10646 [D loss: 0.624480, acc.: 69.53%] [G loss: 0.861953]\n",
      "epoch:11 step:10647 [D loss: 0.631763, acc.: 63.28%] [G loss: 0.903433]\n",
      "epoch:11 step:10648 [D loss: 0.767367, acc.: 53.91%] [G loss: 0.887466]\n",
      "epoch:11 step:10649 [D loss: 0.712249, acc.: 50.00%] [G loss: 0.935300]\n",
      "epoch:11 step:10650 [D loss: 0.646090, acc.: 67.97%] [G loss: 0.946292]\n",
      "epoch:11 step:10651 [D loss: 0.645383, acc.: 60.94%] [G loss: 0.988016]\n",
      "epoch:11 step:10652 [D loss: 0.637990, acc.: 66.41%] [G loss: 0.923296]\n",
      "epoch:11 step:10653 [D loss: 0.587835, acc.: 71.09%] [G loss: 1.064427]\n",
      "epoch:11 step:10654 [D loss: 0.595747, acc.: 69.53%] [G loss: 1.050065]\n",
      "epoch:11 step:10655 [D loss: 0.830942, acc.: 51.56%] [G loss: 0.921186]\n",
      "epoch:11 step:10656 [D loss: 0.711310, acc.: 52.34%] [G loss: 0.787734]\n",
      "epoch:11 step:10657 [D loss: 0.662092, acc.: 58.59%] [G loss: 0.885682]\n",
      "epoch:11 step:10658 [D loss: 0.655320, acc.: 65.62%] [G loss: 0.890334]\n",
      "epoch:11 step:10659 [D loss: 0.661051, acc.: 58.59%] [G loss: 0.853595]\n",
      "epoch:11 step:10660 [D loss: 0.623039, acc.: 63.28%] [G loss: 0.939737]\n",
      "epoch:11 step:10661 [D loss: 0.632709, acc.: 62.50%] [G loss: 0.939190]\n",
      "epoch:11 step:10662 [D loss: 0.667893, acc.: 64.06%] [G loss: 0.955058]\n",
      "epoch:11 step:10663 [D loss: 0.692076, acc.: 53.91%] [G loss: 0.980687]\n",
      "epoch:11 step:10664 [D loss: 0.629294, acc.: 63.28%] [G loss: 0.918144]\n",
      "epoch:11 step:10665 [D loss: 0.602069, acc.: 67.19%] [G loss: 0.888918]\n",
      "epoch:11 step:10666 [D loss: 0.606912, acc.: 65.62%] [G loss: 0.900590]\n",
      "epoch:11 step:10667 [D loss: 0.617607, acc.: 63.28%] [G loss: 0.944681]\n",
      "epoch:11 step:10668 [D loss: 0.645509, acc.: 62.50%] [G loss: 0.986082]\n",
      "epoch:11 step:10669 [D loss: 0.662627, acc.: 53.12%] [G loss: 0.949903]\n",
      "epoch:11 step:10670 [D loss: 0.633077, acc.: 64.06%] [G loss: 0.892982]\n",
      "epoch:11 step:10671 [D loss: 0.596061, acc.: 71.09%] [G loss: 0.936329]\n",
      "epoch:11 step:10672 [D loss: 0.637392, acc.: 66.41%] [G loss: 0.952474]\n",
      "epoch:11 step:10673 [D loss: 0.691768, acc.: 55.47%] [G loss: 0.912874]\n",
      "epoch:11 step:10674 [D loss: 0.633291, acc.: 65.62%] [G loss: 0.968379]\n",
      "epoch:11 step:10675 [D loss: 0.658380, acc.: 59.38%] [G loss: 0.877566]\n",
      "epoch:11 step:10676 [D loss: 0.730849, acc.: 50.00%] [G loss: 0.811867]\n",
      "epoch:11 step:10677 [D loss: 0.650233, acc.: 66.41%] [G loss: 0.833564]\n",
      "epoch:11 step:10678 [D loss: 0.609915, acc.: 70.31%] [G loss: 0.956889]\n",
      "epoch:11 step:10679 [D loss: 0.678646, acc.: 59.38%] [G loss: 0.923515]\n",
      "epoch:11 step:10680 [D loss: 0.680073, acc.: 59.38%] [G loss: 0.926235]\n",
      "epoch:11 step:10681 [D loss: 0.620025, acc.: 68.75%] [G loss: 0.952646]\n",
      "epoch:11 step:10682 [D loss: 0.677113, acc.: 55.47%] [G loss: 0.943955]\n",
      "epoch:11 step:10683 [D loss: 0.694409, acc.: 55.47%] [G loss: 0.903751]\n",
      "epoch:11 step:10684 [D loss: 0.722880, acc.: 51.56%] [G loss: 0.851017]\n",
      "epoch:11 step:10685 [D loss: 0.699666, acc.: 56.25%] [G loss: 0.831123]\n",
      "epoch:11 step:10686 [D loss: 0.627038, acc.: 68.75%] [G loss: 0.900386]\n",
      "epoch:11 step:10687 [D loss: 0.669829, acc.: 57.81%] [G loss: 0.825733]\n",
      "epoch:11 step:10688 [D loss: 0.622422, acc.: 64.06%] [G loss: 0.861159]\n",
      "epoch:11 step:10689 [D loss: 0.664672, acc.: 62.50%] [G loss: 0.888151]\n",
      "epoch:11 step:10690 [D loss: 0.627098, acc.: 61.72%] [G loss: 0.828621]\n",
      "epoch:11 step:10691 [D loss: 0.624743, acc.: 69.53%] [G loss: 0.894838]\n",
      "epoch:11 step:10692 [D loss: 0.647707, acc.: 56.25%] [G loss: 0.902358]\n",
      "epoch:11 step:10693 [D loss: 0.698664, acc.: 58.59%] [G loss: 0.867363]\n",
      "epoch:11 step:10694 [D loss: 0.669682, acc.: 57.81%] [G loss: 0.927242]\n",
      "epoch:11 step:10695 [D loss: 0.679515, acc.: 57.81%] [G loss: 0.923006]\n",
      "epoch:11 step:10696 [D loss: 0.684805, acc.: 57.03%] [G loss: 0.879561]\n",
      "epoch:11 step:10697 [D loss: 0.668425, acc.: 60.16%] [G loss: 0.836034]\n",
      "epoch:11 step:10698 [D loss: 0.641607, acc.: 67.97%] [G loss: 0.910219]\n",
      "epoch:11 step:10699 [D loss: 0.652665, acc.: 64.84%] [G loss: 0.926929]\n",
      "epoch:11 step:10700 [D loss: 0.658768, acc.: 60.94%] [G loss: 0.857964]\n",
      "epoch:11 step:10701 [D loss: 0.650186, acc.: 59.38%] [G loss: 0.847039]\n",
      "epoch:11 step:10702 [D loss: 0.701418, acc.: 53.12%] [G loss: 0.969632]\n",
      "epoch:11 step:10703 [D loss: 0.670708, acc.: 63.28%] [G loss: 0.889300]\n",
      "epoch:11 step:10704 [D loss: 0.663627, acc.: 62.50%] [G loss: 0.957758]\n",
      "epoch:11 step:10705 [D loss: 0.600699, acc.: 65.62%] [G loss: 1.022298]\n",
      "epoch:11 step:10706 [D loss: 0.607549, acc.: 67.19%] [G loss: 0.933718]\n",
      "epoch:11 step:10707 [D loss: 0.716159, acc.: 50.78%] [G loss: 0.900025]\n",
      "epoch:11 step:10708 [D loss: 0.703588, acc.: 54.69%] [G loss: 0.842192]\n",
      "epoch:11 step:10709 [D loss: 0.642143, acc.: 64.06%] [G loss: 0.921572]\n",
      "epoch:11 step:10710 [D loss: 0.672004, acc.: 54.69%] [G loss: 0.933586]\n",
      "epoch:11 step:10711 [D loss: 0.675810, acc.: 57.81%] [G loss: 0.873778]\n",
      "epoch:11 step:10712 [D loss: 0.651312, acc.: 60.16%] [G loss: 0.951104]\n",
      "epoch:11 step:10713 [D loss: 0.632551, acc.: 66.41%] [G loss: 0.974203]\n",
      "epoch:11 step:10714 [D loss: 0.662478, acc.: 58.59%] [G loss: 0.932512]\n",
      "epoch:11 step:10715 [D loss: 0.739034, acc.: 46.88%] [G loss: 0.916028]\n",
      "epoch:11 step:10716 [D loss: 0.684087, acc.: 53.12%] [G loss: 0.879420]\n",
      "epoch:11 step:10717 [D loss: 0.649505, acc.: 64.06%] [G loss: 0.890231]\n",
      "epoch:11 step:10718 [D loss: 0.690651, acc.: 53.12%] [G loss: 0.855100]\n",
      "epoch:11 step:10719 [D loss: 0.700125, acc.: 55.47%] [G loss: 0.823661]\n",
      "epoch:11 step:10720 [D loss: 0.638270, acc.: 62.50%] [G loss: 0.900118]\n",
      "epoch:11 step:10721 [D loss: 0.646994, acc.: 61.72%] [G loss: 0.988745]\n",
      "epoch:11 step:10722 [D loss: 0.667180, acc.: 60.94%] [G loss: 0.947174]\n",
      "epoch:11 step:10723 [D loss: 0.639762, acc.: 68.75%] [G loss: 1.020112]\n",
      "epoch:11 step:10724 [D loss: 0.676749, acc.: 60.16%] [G loss: 0.967133]\n",
      "epoch:11 step:10725 [D loss: 0.702862, acc.: 55.47%] [G loss: 0.944268]\n",
      "epoch:11 step:10726 [D loss: 0.657229, acc.: 61.72%] [G loss: 0.901918]\n",
      "epoch:11 step:10727 [D loss: 0.658741, acc.: 59.38%] [G loss: 0.861564]\n",
      "epoch:11 step:10728 [D loss: 0.681942, acc.: 57.81%] [G loss: 0.810927]\n",
      "epoch:11 step:10729 [D loss: 0.664430, acc.: 55.47%] [G loss: 0.860295]\n",
      "epoch:11 step:10730 [D loss: 0.706759, acc.: 53.12%] [G loss: 0.909481]\n",
      "epoch:11 step:10731 [D loss: 0.717367, acc.: 52.34%] [G loss: 0.863426]\n",
      "epoch:11 step:10732 [D loss: 0.671263, acc.: 56.25%] [G loss: 0.970064]\n",
      "epoch:11 step:10733 [D loss: 0.611394, acc.: 64.84%] [G loss: 0.888849]\n",
      "epoch:11 step:10734 [D loss: 0.621782, acc.: 67.19%] [G loss: 0.885523]\n",
      "epoch:11 step:10735 [D loss: 0.625271, acc.: 61.72%] [G loss: 0.971516]\n",
      "epoch:11 step:10736 [D loss: 0.634848, acc.: 65.62%] [G loss: 0.956787]\n",
      "epoch:11 step:10737 [D loss: 0.589428, acc.: 69.53%] [G loss: 0.935552]\n",
      "epoch:11 step:10738 [D loss: 0.638125, acc.: 64.06%] [G loss: 0.871110]\n",
      "epoch:11 step:10739 [D loss: 0.653362, acc.: 66.41%] [G loss: 0.855851]\n",
      "epoch:11 step:10740 [D loss: 0.679983, acc.: 54.69%] [G loss: 0.851171]\n",
      "epoch:11 step:10741 [D loss: 0.663157, acc.: 55.47%] [G loss: 0.882775]\n",
      "epoch:11 step:10742 [D loss: 0.664508, acc.: 59.38%] [G loss: 0.902195]\n",
      "epoch:11 step:10743 [D loss: 0.627005, acc.: 61.72%] [G loss: 0.986704]\n",
      "epoch:11 step:10744 [D loss: 0.716983, acc.: 57.81%] [G loss: 0.970045]\n",
      "epoch:11 step:10745 [D loss: 0.685237, acc.: 57.03%] [G loss: 0.959326]\n",
      "epoch:11 step:10746 [D loss: 0.647501, acc.: 59.38%] [G loss: 0.984064]\n",
      "epoch:11 step:10747 [D loss: 0.668476, acc.: 57.81%] [G loss: 0.954454]\n",
      "epoch:11 step:10748 [D loss: 0.656185, acc.: 59.38%] [G loss: 0.896262]\n",
      "epoch:11 step:10749 [D loss: 0.661007, acc.: 54.69%] [G loss: 0.941062]\n",
      "epoch:11 step:10750 [D loss: 0.657464, acc.: 60.94%] [G loss: 0.922205]\n",
      "epoch:11 step:10751 [D loss: 0.623839, acc.: 67.97%] [G loss: 0.910646]\n",
      "epoch:11 step:10752 [D loss: 0.604840, acc.: 63.28%] [G loss: 0.900644]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10753 [D loss: 0.657078, acc.: 63.28%] [G loss: 0.911197]\n",
      "epoch:11 step:10754 [D loss: 0.598813, acc.: 70.31%] [G loss: 0.873305]\n",
      "epoch:11 step:10755 [D loss: 0.698028, acc.: 53.91%] [G loss: 0.875320]\n",
      "epoch:11 step:10756 [D loss: 0.727636, acc.: 49.22%] [G loss: 0.873199]\n",
      "epoch:11 step:10757 [D loss: 0.649421, acc.: 62.50%] [G loss: 0.853931]\n",
      "epoch:11 step:10758 [D loss: 0.638159, acc.: 64.84%] [G loss: 0.833142]\n",
      "epoch:11 step:10759 [D loss: 0.639491, acc.: 68.75%] [G loss: 0.888069]\n",
      "epoch:11 step:10760 [D loss: 0.673192, acc.: 55.47%] [G loss: 0.933629]\n",
      "epoch:11 step:10761 [D loss: 0.683445, acc.: 57.03%] [G loss: 0.944753]\n",
      "epoch:11 step:10762 [D loss: 0.679667, acc.: 57.81%] [G loss: 0.890644]\n",
      "epoch:11 step:10763 [D loss: 0.655280, acc.: 60.94%] [G loss: 0.957307]\n",
      "epoch:11 step:10764 [D loss: 0.634404, acc.: 62.50%] [G loss: 0.933871]\n",
      "epoch:11 step:10765 [D loss: 0.747679, acc.: 49.22%] [G loss: 0.858075]\n",
      "epoch:11 step:10766 [D loss: 0.694478, acc.: 57.03%] [G loss: 0.902046]\n",
      "epoch:11 step:10767 [D loss: 0.715090, acc.: 53.12%] [G loss: 0.873998]\n",
      "epoch:11 step:10768 [D loss: 0.721948, acc.: 50.78%] [G loss: 0.841616]\n",
      "epoch:11 step:10769 [D loss: 0.663786, acc.: 64.06%] [G loss: 0.874988]\n",
      "epoch:11 step:10770 [D loss: 0.647599, acc.: 64.84%] [G loss: 0.939035]\n",
      "epoch:11 step:10771 [D loss: 0.666051, acc.: 57.81%] [G loss: 0.882185]\n",
      "epoch:11 step:10772 [D loss: 0.710896, acc.: 46.09%] [G loss: 0.888599]\n",
      "epoch:11 step:10773 [D loss: 0.696659, acc.: 56.25%] [G loss: 0.825955]\n",
      "epoch:11 step:10774 [D loss: 0.664563, acc.: 60.16%] [G loss: 0.865580]\n",
      "epoch:11 step:10775 [D loss: 0.643696, acc.: 64.06%] [G loss: 0.922174]\n",
      "epoch:11 step:10776 [D loss: 0.628826, acc.: 64.06%] [G loss: 0.975669]\n",
      "epoch:11 step:10777 [D loss: 0.650152, acc.: 58.59%] [G loss: 0.913503]\n",
      "epoch:11 step:10778 [D loss: 0.606418, acc.: 67.97%] [G loss: 0.921453]\n",
      "epoch:11 step:10779 [D loss: 0.644709, acc.: 64.06%] [G loss: 0.894326]\n",
      "epoch:11 step:10780 [D loss: 0.713969, acc.: 53.91%] [G loss: 0.911134]\n",
      "epoch:11 step:10781 [D loss: 0.652806, acc.: 63.28%] [G loss: 0.939856]\n",
      "epoch:11 step:10782 [D loss: 0.646247, acc.: 60.94%] [G loss: 0.874672]\n",
      "epoch:11 step:10783 [D loss: 0.672928, acc.: 57.03%] [G loss: 0.932364]\n",
      "epoch:11 step:10784 [D loss: 0.757676, acc.: 42.19%] [G loss: 0.922652]\n",
      "epoch:11 step:10785 [D loss: 0.663027, acc.: 57.03%] [G loss: 0.884874]\n",
      "epoch:11 step:10786 [D loss: 0.630209, acc.: 68.75%] [G loss: 0.874812]\n",
      "epoch:11 step:10787 [D loss: 0.624107, acc.: 67.19%] [G loss: 0.858193]\n",
      "epoch:11 step:10788 [D loss: 0.617942, acc.: 65.62%] [G loss: 0.898959]\n",
      "epoch:11 step:10789 [D loss: 0.734761, acc.: 48.44%] [G loss: 0.907483]\n",
      "epoch:11 step:10790 [D loss: 0.690599, acc.: 59.38%] [G loss: 0.893038]\n",
      "epoch:11 step:10791 [D loss: 0.630578, acc.: 63.28%] [G loss: 0.882474]\n",
      "epoch:11 step:10792 [D loss: 0.675363, acc.: 54.69%] [G loss: 0.948472]\n",
      "epoch:11 step:10793 [D loss: 0.680398, acc.: 57.81%] [G loss: 0.900654]\n",
      "epoch:11 step:10794 [D loss: 0.675729, acc.: 60.16%] [G loss: 0.915021]\n",
      "epoch:11 step:10795 [D loss: 0.623470, acc.: 63.28%] [G loss: 0.924847]\n",
      "epoch:11 step:10796 [D loss: 0.713840, acc.: 55.47%] [G loss: 0.918932]\n",
      "epoch:11 step:10797 [D loss: 0.659446, acc.: 61.72%] [G loss: 0.912487]\n",
      "epoch:11 step:10798 [D loss: 0.695645, acc.: 55.47%] [G loss: 0.880151]\n",
      "epoch:11 step:10799 [D loss: 0.690865, acc.: 56.25%] [G loss: 0.874021]\n",
      "epoch:11 step:10800 [D loss: 0.654252, acc.: 61.72%] [G loss: 0.908709]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.740518\n",
      "FID: 11.762122\n",
      "0 = 11.830700804829574\n",
      "1 = 0.05444171714871854\n",
      "2 = 0.9242500066757202\n",
      "3 = 0.8755000233650208\n",
      "4 = 0.9729999899864197\n",
      "5 = 0.9700831174850464\n",
      "6 = 0.8755000233650208\n",
      "7 = 6.272479464703802\n",
      "8 = 0.07625790164216566\n",
      "9 = 0.728950023651123\n",
      "10 = 0.7002999782562256\n",
      "11 = 0.7576000094413757\n",
      "12 = 0.7428662180900574\n",
      "13 = 0.7002999782562256\n",
      "14 = 7.740581512451172\n",
      "15 = 9.484942436218262\n",
      "16 = 0.1285475790500641\n",
      "17 = 7.740517616271973\n",
      "18 = 11.76212215423584\n",
      "epoch:11 step:10801 [D loss: 0.653335, acc.: 60.16%] [G loss: 0.900751]\n",
      "epoch:11 step:10802 [D loss: 0.614685, acc.: 64.84%] [G loss: 0.882418]\n",
      "epoch:11 step:10803 [D loss: 0.622671, acc.: 68.75%] [G loss: 0.913980]\n",
      "epoch:11 step:10804 [D loss: 0.677834, acc.: 57.81%] [G loss: 0.915130]\n",
      "epoch:11 step:10805 [D loss: 0.638739, acc.: 62.50%] [G loss: 0.928875]\n",
      "epoch:11 step:10806 [D loss: 0.615395, acc.: 72.66%] [G loss: 0.914992]\n",
      "epoch:11 step:10807 [D loss: 0.688932, acc.: 57.81%] [G loss: 0.854735]\n",
      "epoch:11 step:10808 [D loss: 0.717359, acc.: 55.47%] [G loss: 0.846792]\n",
      "epoch:11 step:10809 [D loss: 0.683697, acc.: 58.59%] [G loss: 0.846500]\n",
      "epoch:11 step:10810 [D loss: 0.637347, acc.: 60.94%] [G loss: 0.930621]\n",
      "epoch:11 step:10811 [D loss: 0.595857, acc.: 71.88%] [G loss: 0.897420]\n",
      "epoch:11 step:10812 [D loss: 0.612202, acc.: 63.28%] [G loss: 0.902371]\n",
      "epoch:11 step:10813 [D loss: 0.638311, acc.: 61.72%] [G loss: 0.952736]\n",
      "epoch:11 step:10814 [D loss: 0.604132, acc.: 64.06%] [G loss: 1.059389]\n",
      "epoch:11 step:10815 [D loss: 0.553422, acc.: 70.31%] [G loss: 1.115016]\n",
      "epoch:11 step:10816 [D loss: 0.715250, acc.: 52.34%] [G loss: 0.959915]\n",
      "epoch:11 step:10817 [D loss: 0.718007, acc.: 49.22%] [G loss: 0.904698]\n",
      "epoch:11 step:10818 [D loss: 0.764773, acc.: 43.75%] [G loss: 0.849838]\n",
      "epoch:11 step:10819 [D loss: 0.650150, acc.: 57.03%] [G loss: 0.862554]\n",
      "epoch:11 step:10820 [D loss: 0.643659, acc.: 63.28%] [G loss: 0.914663]\n",
      "epoch:11 step:10821 [D loss: 0.656882, acc.: 57.81%] [G loss: 0.871361]\n",
      "epoch:11 step:10822 [D loss: 0.645699, acc.: 61.72%] [G loss: 0.953883]\n",
      "epoch:11 step:10823 [D loss: 0.636244, acc.: 70.31%] [G loss: 0.914122]\n",
      "epoch:11 step:10824 [D loss: 0.674475, acc.: 59.38%] [G loss: 0.911272]\n",
      "epoch:11 step:10825 [D loss: 0.618209, acc.: 67.19%] [G loss: 0.903387]\n",
      "epoch:11 step:10826 [D loss: 0.624081, acc.: 65.62%] [G loss: 0.923680]\n",
      "epoch:11 step:10827 [D loss: 0.649652, acc.: 57.03%] [G loss: 0.879573]\n",
      "epoch:11 step:10828 [D loss: 0.636258, acc.: 63.28%] [G loss: 0.934566]\n",
      "epoch:11 step:10829 [D loss: 0.657376, acc.: 60.16%] [G loss: 0.897924]\n",
      "epoch:11 step:10830 [D loss: 0.635883, acc.: 65.62%] [G loss: 0.909282]\n",
      "epoch:11 step:10831 [D loss: 0.682929, acc.: 58.59%] [G loss: 0.889267]\n",
      "epoch:11 step:10832 [D loss: 0.699221, acc.: 55.47%] [G loss: 0.899626]\n",
      "epoch:11 step:10833 [D loss: 0.648540, acc.: 57.81%] [G loss: 0.993489]\n",
      "epoch:11 step:10834 [D loss: 0.695522, acc.: 56.25%] [G loss: 0.956317]\n",
      "epoch:11 step:10835 [D loss: 0.700344, acc.: 53.91%] [G loss: 0.887282]\n",
      "epoch:11 step:10836 [D loss: 0.698600, acc.: 51.56%] [G loss: 0.909994]\n",
      "epoch:11 step:10837 [D loss: 0.647702, acc.: 64.06%] [G loss: 0.906978]\n",
      "epoch:11 step:10838 [D loss: 0.717621, acc.: 56.25%] [G loss: 0.864961]\n",
      "epoch:11 step:10839 [D loss: 0.676575, acc.: 56.25%] [G loss: 0.883571]\n",
      "epoch:11 step:10840 [D loss: 0.675231, acc.: 57.03%] [G loss: 0.921355]\n",
      "epoch:11 step:10841 [D loss: 0.631719, acc.: 64.06%] [G loss: 0.985658]\n",
      "epoch:11 step:10842 [D loss: 0.677629, acc.: 59.38%] [G loss: 0.904150]\n",
      "epoch:11 step:10843 [D loss: 0.640027, acc.: 60.94%] [G loss: 0.919742]\n",
      "epoch:11 step:10844 [D loss: 0.688988, acc.: 53.91%] [G loss: 0.973836]\n",
      "epoch:11 step:10845 [D loss: 0.675169, acc.: 53.91%] [G loss: 0.936346]\n",
      "epoch:11 step:10846 [D loss: 0.618561, acc.: 65.62%] [G loss: 0.929927]\n",
      "epoch:11 step:10847 [D loss: 0.660174, acc.: 58.59%] [G loss: 0.938069]\n",
      "epoch:11 step:10848 [D loss: 0.660753, acc.: 59.38%] [G loss: 0.887461]\n",
      "epoch:11 step:10849 [D loss: 0.758556, acc.: 51.56%] [G loss: 0.831622]\n",
      "epoch:11 step:10850 [D loss: 0.688013, acc.: 55.47%] [G loss: 0.827259]\n",
      "epoch:11 step:10851 [D loss: 0.617619, acc.: 65.62%] [G loss: 0.876615]\n",
      "epoch:11 step:10852 [D loss: 0.691273, acc.: 56.25%] [G loss: 0.887852]\n",
      "epoch:11 step:10853 [D loss: 0.670611, acc.: 51.56%] [G loss: 0.943400]\n",
      "epoch:11 step:10854 [D loss: 0.621825, acc.: 64.06%] [G loss: 0.901348]\n",
      "epoch:11 step:10855 [D loss: 0.642156, acc.: 60.94%] [G loss: 0.875200]\n",
      "epoch:11 step:10856 [D loss: 0.630799, acc.: 62.50%] [G loss: 0.927698]\n",
      "epoch:11 step:10857 [D loss: 0.659384, acc.: 65.62%] [G loss: 0.916732]\n",
      "epoch:11 step:10858 [D loss: 0.599268, acc.: 65.62%] [G loss: 0.918965]\n",
      "epoch:11 step:10859 [D loss: 0.669125, acc.: 61.72%] [G loss: 0.923789]\n",
      "epoch:11 step:10860 [D loss: 0.712714, acc.: 50.78%] [G loss: 0.859321]\n",
      "epoch:11 step:10861 [D loss: 0.655959, acc.: 58.59%] [G loss: 0.913129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10862 [D loss: 0.620664, acc.: 69.53%] [G loss: 0.907980]\n",
      "epoch:11 step:10863 [D loss: 0.620324, acc.: 66.41%] [G loss: 0.874122]\n",
      "epoch:11 step:10864 [D loss: 0.611678, acc.: 67.19%] [G loss: 0.884401]\n",
      "epoch:11 step:10865 [D loss: 0.622488, acc.: 64.06%] [G loss: 0.960703]\n",
      "epoch:11 step:10866 [D loss: 0.709673, acc.: 51.56%] [G loss: 0.904903]\n",
      "epoch:11 step:10867 [D loss: 0.700898, acc.: 54.69%] [G loss: 0.857226]\n",
      "epoch:11 step:10868 [D loss: 0.668434, acc.: 55.47%] [G loss: 0.876600]\n",
      "epoch:11 step:10869 [D loss: 0.660666, acc.: 59.38%] [G loss: 0.893465]\n",
      "epoch:11 step:10870 [D loss: 0.612319, acc.: 67.97%] [G loss: 0.915131]\n",
      "epoch:11 step:10871 [D loss: 0.632445, acc.: 62.50%] [G loss: 0.968970]\n",
      "epoch:11 step:10872 [D loss: 0.669365, acc.: 60.16%] [G loss: 0.910387]\n",
      "epoch:11 step:10873 [D loss: 0.729215, acc.: 48.44%] [G loss: 0.884001]\n",
      "epoch:11 step:10874 [D loss: 0.674397, acc.: 59.38%] [G loss: 0.921252]\n",
      "epoch:11 step:10875 [D loss: 0.663648, acc.: 59.38%] [G loss: 0.960255]\n",
      "epoch:11 step:10876 [D loss: 0.724000, acc.: 52.34%] [G loss: 0.906769]\n",
      "epoch:11 step:10877 [D loss: 0.663125, acc.: 63.28%] [G loss: 0.861875]\n",
      "epoch:11 step:10878 [D loss: 0.674716, acc.: 61.72%] [G loss: 0.887415]\n",
      "epoch:11 step:10879 [D loss: 0.659068, acc.: 61.72%] [G loss: 0.951619]\n",
      "epoch:11 step:10880 [D loss: 0.612716, acc.: 65.62%] [G loss: 0.930457]\n",
      "epoch:11 step:10881 [D loss: 0.584461, acc.: 67.19%] [G loss: 1.015100]\n",
      "epoch:11 step:10882 [D loss: 0.626571, acc.: 67.19%] [G loss: 0.960892]\n",
      "epoch:11 step:10883 [D loss: 0.686530, acc.: 60.94%] [G loss: 0.930035]\n",
      "epoch:11 step:10884 [D loss: 0.688679, acc.: 50.78%] [G loss: 0.958787]\n",
      "epoch:11 step:10885 [D loss: 0.641946, acc.: 66.41%] [G loss: 0.905680]\n",
      "epoch:11 step:10886 [D loss: 0.690386, acc.: 56.25%] [G loss: 0.824479]\n",
      "epoch:11 step:10887 [D loss: 0.676425, acc.: 61.72%] [G loss: 0.879594]\n",
      "epoch:11 step:10888 [D loss: 0.607730, acc.: 72.66%] [G loss: 0.954180]\n",
      "epoch:11 step:10889 [D loss: 0.615903, acc.: 67.19%] [G loss: 0.916483]\n",
      "epoch:11 step:10890 [D loss: 0.638948, acc.: 67.97%] [G loss: 0.919132]\n",
      "epoch:11 step:10891 [D loss: 0.704212, acc.: 56.25%] [G loss: 0.953501]\n",
      "epoch:11 step:10892 [D loss: 0.658163, acc.: 57.03%] [G loss: 0.888551]\n",
      "epoch:11 step:10893 [D loss: 0.682373, acc.: 58.59%] [G loss: 0.863254]\n",
      "epoch:11 step:10894 [D loss: 0.711400, acc.: 50.00%] [G loss: 0.881470]\n",
      "epoch:11 step:10895 [D loss: 0.646409, acc.: 58.59%] [G loss: 0.971505]\n",
      "epoch:11 step:10896 [D loss: 0.610834, acc.: 66.41%] [G loss: 0.915255]\n",
      "epoch:11 step:10897 [D loss: 0.713449, acc.: 58.59%] [G loss: 0.925538]\n",
      "epoch:11 step:10898 [D loss: 0.698994, acc.: 55.47%] [G loss: 0.866216]\n",
      "epoch:11 step:10899 [D loss: 0.680933, acc.: 58.59%] [G loss: 0.933797]\n",
      "epoch:11 step:10900 [D loss: 0.641627, acc.: 64.06%] [G loss: 0.931607]\n",
      "epoch:11 step:10901 [D loss: 0.708158, acc.: 54.69%] [G loss: 0.888999]\n",
      "epoch:11 step:10902 [D loss: 0.651464, acc.: 59.38%] [G loss: 0.870379]\n",
      "epoch:11 step:10903 [D loss: 0.681505, acc.: 54.69%] [G loss: 0.883249]\n",
      "epoch:11 step:10904 [D loss: 0.706510, acc.: 49.22%] [G loss: 0.850530]\n",
      "epoch:11 step:10905 [D loss: 0.652351, acc.: 60.94%] [G loss: 0.841146]\n",
      "epoch:11 step:10906 [D loss: 0.635867, acc.: 67.97%] [G loss: 0.917902]\n",
      "epoch:11 step:10907 [D loss: 0.690470, acc.: 56.25%] [G loss: 0.850808]\n",
      "epoch:11 step:10908 [D loss: 0.687274, acc.: 59.38%] [G loss: 0.865311]\n",
      "epoch:11 step:10909 [D loss: 0.668894, acc.: 59.38%] [G loss: 0.868422]\n",
      "epoch:11 step:10910 [D loss: 0.642814, acc.: 67.19%] [G loss: 0.916103]\n",
      "epoch:11 step:10911 [D loss: 0.669181, acc.: 57.81%] [G loss: 0.929521]\n",
      "epoch:11 step:10912 [D loss: 0.627343, acc.: 61.72%] [G loss: 0.923772]\n",
      "epoch:11 step:10913 [D loss: 0.701941, acc.: 55.47%] [G loss: 0.936711]\n",
      "epoch:11 step:10914 [D loss: 0.651390, acc.: 60.16%] [G loss: 0.875566]\n",
      "epoch:11 step:10915 [D loss: 0.624276, acc.: 66.41%] [G loss: 0.885568]\n",
      "epoch:11 step:10916 [D loss: 0.663123, acc.: 62.50%] [G loss: 0.853339]\n",
      "epoch:11 step:10917 [D loss: 0.665655, acc.: 57.03%] [G loss: 0.923133]\n",
      "epoch:11 step:10918 [D loss: 0.695880, acc.: 50.00%] [G loss: 0.891245]\n",
      "epoch:11 step:10919 [D loss: 0.684324, acc.: 55.47%] [G loss: 0.885870]\n",
      "epoch:11 step:10920 [D loss: 0.630707, acc.: 65.62%] [G loss: 0.892968]\n",
      "epoch:11 step:10921 [D loss: 0.680908, acc.: 60.16%] [G loss: 0.812243]\n",
      "epoch:11 step:10922 [D loss: 0.734368, acc.: 50.00%] [G loss: 0.858425]\n",
      "epoch:11 step:10923 [D loss: 0.657043, acc.: 60.16%] [G loss: 0.905123]\n",
      "epoch:11 step:10924 [D loss: 0.683418, acc.: 58.59%] [G loss: 0.866690]\n",
      "epoch:11 step:10925 [D loss: 0.614993, acc.: 65.62%] [G loss: 0.936571]\n",
      "epoch:11 step:10926 [D loss: 0.685309, acc.: 57.81%] [G loss: 0.917378]\n",
      "epoch:11 step:10927 [D loss: 0.613169, acc.: 64.06%] [G loss: 0.910925]\n",
      "epoch:11 step:10928 [D loss: 0.683155, acc.: 56.25%] [G loss: 0.867604]\n",
      "epoch:11 step:10929 [D loss: 0.627139, acc.: 60.94%] [G loss: 0.906136]\n",
      "epoch:11 step:10930 [D loss: 0.651612, acc.: 66.41%] [G loss: 0.894966]\n",
      "epoch:11 step:10931 [D loss: 0.640792, acc.: 64.84%] [G loss: 0.943068]\n",
      "epoch:11 step:10932 [D loss: 0.676545, acc.: 52.34%] [G loss: 0.950560]\n",
      "epoch:11 step:10933 [D loss: 0.663984, acc.: 60.94%] [G loss: 0.957653]\n",
      "epoch:11 step:10934 [D loss: 0.638227, acc.: 65.62%] [G loss: 0.922112]\n",
      "epoch:11 step:10935 [D loss: 0.682861, acc.: 60.16%] [G loss: 0.861775]\n",
      "epoch:11 step:10936 [D loss: 0.635486, acc.: 59.38%] [G loss: 0.910548]\n",
      "epoch:11 step:10937 [D loss: 0.694179, acc.: 56.25%] [G loss: 0.925878]\n",
      "epoch:11 step:10938 [D loss: 0.640167, acc.: 61.72%] [G loss: 0.855279]\n",
      "epoch:11 step:10939 [D loss: 0.629328, acc.: 67.19%] [G loss: 0.972705]\n",
      "epoch:11 step:10940 [D loss: 0.666311, acc.: 60.16%] [G loss: 0.900529]\n",
      "epoch:11 step:10941 [D loss: 0.645110, acc.: 64.06%] [G loss: 0.953906]\n",
      "epoch:11 step:10942 [D loss: 0.626527, acc.: 64.84%] [G loss: 0.922221]\n",
      "epoch:11 step:10943 [D loss: 0.674078, acc.: 60.16%] [G loss: 0.901994]\n",
      "epoch:11 step:10944 [D loss: 0.684508, acc.: 53.12%] [G loss: 0.912080]\n",
      "epoch:11 step:10945 [D loss: 0.666337, acc.: 57.81%] [G loss: 0.846042]\n",
      "epoch:11 step:10946 [D loss: 0.663532, acc.: 60.94%] [G loss: 0.874352]\n",
      "epoch:11 step:10947 [D loss: 0.624991, acc.: 64.06%] [G loss: 0.895187]\n",
      "epoch:11 step:10948 [D loss: 0.668806, acc.: 55.47%] [G loss: 0.926059]\n",
      "epoch:11 step:10949 [D loss: 0.630451, acc.: 62.50%] [G loss: 0.975530]\n",
      "epoch:11 step:10950 [D loss: 0.669399, acc.: 57.81%] [G loss: 0.973745]\n",
      "epoch:11 step:10951 [D loss: 0.679662, acc.: 60.16%] [G loss: 0.892766]\n",
      "epoch:11 step:10952 [D loss: 0.688404, acc.: 51.56%] [G loss: 0.803578]\n",
      "epoch:11 step:10953 [D loss: 0.636448, acc.: 66.41%] [G loss: 0.925224]\n",
      "epoch:11 step:10954 [D loss: 0.619064, acc.: 71.88%] [G loss: 0.878300]\n",
      "epoch:11 step:10955 [D loss: 0.602965, acc.: 71.88%] [G loss: 0.926502]\n",
      "epoch:11 step:10956 [D loss: 0.599613, acc.: 68.75%] [G loss: 0.961432]\n",
      "epoch:11 step:10957 [D loss: 0.609092, acc.: 68.75%] [G loss: 0.986340]\n",
      "epoch:11 step:10958 [D loss: 0.629382, acc.: 60.16%] [G loss: 0.985301]\n",
      "epoch:11 step:10959 [D loss: 0.690488, acc.: 60.16%] [G loss: 0.920656]\n",
      "epoch:11 step:10960 [D loss: 0.635654, acc.: 62.50%] [G loss: 0.913977]\n",
      "epoch:11 step:10961 [D loss: 0.638662, acc.: 63.28%] [G loss: 0.866709]\n",
      "epoch:11 step:10962 [D loss: 0.725062, acc.: 53.91%] [G loss: 0.846842]\n",
      "epoch:11 step:10963 [D loss: 0.639029, acc.: 59.38%] [G loss: 0.812868]\n",
      "epoch:11 step:10964 [D loss: 0.719692, acc.: 54.69%] [G loss: 0.865400]\n",
      "epoch:11 step:10965 [D loss: 0.681718, acc.: 56.25%] [G loss: 0.881979]\n",
      "epoch:11 step:10966 [D loss: 0.654584, acc.: 62.50%] [G loss: 0.852921]\n",
      "epoch:11 step:10967 [D loss: 0.653801, acc.: 55.47%] [G loss: 0.912611]\n",
      "epoch:11 step:10968 [D loss: 0.620383, acc.: 60.16%] [G loss: 0.874838]\n",
      "epoch:11 step:10969 [D loss: 0.657679, acc.: 64.06%] [G loss: 0.908401]\n",
      "epoch:11 step:10970 [D loss: 0.678973, acc.: 53.91%] [G loss: 0.910510]\n",
      "epoch:11 step:10971 [D loss: 0.616724, acc.: 65.62%] [G loss: 0.905477]\n",
      "epoch:11 step:10972 [D loss: 0.662311, acc.: 61.72%] [G loss: 0.960157]\n",
      "epoch:11 step:10973 [D loss: 0.657678, acc.: 66.41%] [G loss: 0.953472]\n",
      "epoch:11 step:10974 [D loss: 0.668313, acc.: 59.38%] [G loss: 0.909897]\n",
      "epoch:11 step:10975 [D loss: 0.675147, acc.: 52.34%] [G loss: 0.913365]\n",
      "epoch:11 step:10976 [D loss: 0.641108, acc.: 60.16%] [G loss: 1.002070]\n",
      "epoch:11 step:10977 [D loss: 0.685957, acc.: 53.12%] [G loss: 0.853710]\n",
      "epoch:11 step:10978 [D loss: 0.717511, acc.: 53.91%] [G loss: 0.878353]\n",
      "epoch:11 step:10979 [D loss: 0.682324, acc.: 54.69%] [G loss: 0.862281]\n",
      "epoch:11 step:10980 [D loss: 0.694403, acc.: 57.03%] [G loss: 0.937109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10981 [D loss: 0.652954, acc.: 62.50%] [G loss: 0.943452]\n",
      "epoch:11 step:10982 [D loss: 0.673032, acc.: 63.28%] [G loss: 0.888658]\n",
      "epoch:11 step:10983 [D loss: 0.672208, acc.: 58.59%] [G loss: 0.872449]\n",
      "epoch:11 step:10984 [D loss: 0.625282, acc.: 65.62%] [G loss: 0.906556]\n",
      "epoch:11 step:10985 [D loss: 0.670444, acc.: 60.94%] [G loss: 0.903619]\n",
      "epoch:11 step:10986 [D loss: 0.632195, acc.: 67.97%] [G loss: 0.862539]\n",
      "epoch:11 step:10987 [D loss: 0.625970, acc.: 65.62%] [G loss: 0.942961]\n",
      "epoch:11 step:10988 [D loss: 0.620187, acc.: 67.97%] [G loss: 0.886934]\n",
      "epoch:11 step:10989 [D loss: 0.650102, acc.: 58.59%] [G loss: 0.942176]\n",
      "epoch:11 step:10990 [D loss: 0.659843, acc.: 64.06%] [G loss: 0.911462]\n",
      "epoch:11 step:10991 [D loss: 0.667763, acc.: 58.59%] [G loss: 0.962170]\n",
      "epoch:11 step:10992 [D loss: 0.661681, acc.: 65.62%] [G loss: 0.866816]\n",
      "epoch:11 step:10993 [D loss: 0.637741, acc.: 57.81%] [G loss: 0.888809]\n",
      "epoch:11 step:10994 [D loss: 0.651209, acc.: 64.84%] [G loss: 0.826306]\n",
      "epoch:11 step:10995 [D loss: 0.681840, acc.: 58.59%] [G loss: 0.869564]\n",
      "epoch:11 step:10996 [D loss: 0.644697, acc.: 64.06%] [G loss: 0.933015]\n",
      "epoch:11 step:10997 [D loss: 0.634191, acc.: 60.94%] [G loss: 0.966914]\n",
      "epoch:11 step:10998 [D loss: 0.644165, acc.: 64.84%] [G loss: 0.923710]\n",
      "epoch:11 step:10999 [D loss: 0.614584, acc.: 66.41%] [G loss: 0.948333]\n",
      "epoch:11 step:11000 [D loss: 0.603942, acc.: 66.41%] [G loss: 0.923860]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.920190\n",
      "FID: 8.682579\n",
      "0 = 11.906737906432163\n",
      "1 = 0.05308360562736265\n",
      "2 = 0.9248999953269958\n",
      "3 = 0.878600001335144\n",
      "4 = 0.9711999893188477\n",
      "5 = 0.9682609438896179\n",
      "6 = 0.878600001335144\n",
      "7 = 6.015634537637213\n",
      "8 = 0.06535859302159659\n",
      "9 = 0.7113000154495239\n",
      "10 = 0.6883999705314636\n",
      "11 = 0.7342000007629395\n",
      "12 = 0.7214420437812805\n",
      "13 = 0.6883999705314636\n",
      "14 = 7.920257091522217\n",
      "15 = 9.556204795837402\n",
      "16 = 0.1047232523560524\n",
      "17 = 7.920190334320068\n",
      "18 = 8.682579040527344\n",
      "epoch:11 step:11001 [D loss: 0.574163, acc.: 69.53%] [G loss: 0.941066]\n",
      "epoch:11 step:11002 [D loss: 0.683488, acc.: 60.16%] [G loss: 0.962480]\n",
      "epoch:11 step:11003 [D loss: 0.695264, acc.: 51.56%] [G loss: 0.873595]\n",
      "epoch:11 step:11004 [D loss: 0.621511, acc.: 65.62%] [G loss: 0.863359]\n",
      "epoch:11 step:11005 [D loss: 0.663432, acc.: 59.38%] [G loss: 0.934273]\n",
      "epoch:11 step:11006 [D loss: 0.610535, acc.: 68.75%] [G loss: 0.852649]\n",
      "epoch:11 step:11007 [D loss: 0.616989, acc.: 64.06%] [G loss: 0.934647]\n",
      "epoch:11 step:11008 [D loss: 0.601692, acc.: 64.84%] [G loss: 0.983193]\n",
      "epoch:11 step:11009 [D loss: 0.623598, acc.: 65.62%] [G loss: 1.019883]\n",
      "epoch:11 step:11010 [D loss: 0.750779, acc.: 44.53%] [G loss: 0.990836]\n",
      "epoch:11 step:11011 [D loss: 0.716617, acc.: 56.25%] [G loss: 0.919544]\n",
      "epoch:11 step:11012 [D loss: 0.624603, acc.: 65.62%] [G loss: 0.905568]\n",
      "epoch:11 step:11013 [D loss: 0.636218, acc.: 68.75%] [G loss: 0.859882]\n",
      "epoch:11 step:11014 [D loss: 0.655450, acc.: 64.06%] [G loss: 0.913164]\n",
      "epoch:11 step:11015 [D loss: 0.603342, acc.: 67.97%] [G loss: 0.982284]\n",
      "epoch:11 step:11016 [D loss: 0.598170, acc.: 69.53%] [G loss: 0.939861]\n",
      "epoch:11 step:11017 [D loss: 0.693712, acc.: 60.16%] [G loss: 0.887287]\n",
      "epoch:11 step:11018 [D loss: 0.713163, acc.: 49.22%] [G loss: 0.852428]\n",
      "epoch:11 step:11019 [D loss: 0.651165, acc.: 59.38%] [G loss: 0.842834]\n",
      "epoch:11 step:11020 [D loss: 0.675595, acc.: 60.16%] [G loss: 0.856681]\n",
      "epoch:11 step:11021 [D loss: 0.698726, acc.: 60.94%] [G loss: 0.877544]\n",
      "epoch:11 step:11022 [D loss: 0.630073, acc.: 63.28%] [G loss: 0.910682]\n",
      "epoch:11 step:11023 [D loss: 0.713174, acc.: 51.56%] [G loss: 0.904717]\n",
      "epoch:11 step:11024 [D loss: 0.685019, acc.: 57.81%] [G loss: 0.960694]\n",
      "epoch:11 step:11025 [D loss: 0.673760, acc.: 63.28%] [G loss: 0.934660]\n",
      "epoch:11 step:11026 [D loss: 0.647598, acc.: 60.94%] [G loss: 0.913038]\n",
      "epoch:11 step:11027 [D loss: 0.648705, acc.: 63.28%] [G loss: 0.938731]\n",
      "epoch:11 step:11028 [D loss: 0.657711, acc.: 60.94%] [G loss: 0.914847]\n",
      "epoch:11 step:11029 [D loss: 0.718766, acc.: 51.56%] [G loss: 0.842834]\n",
      "epoch:11 step:11030 [D loss: 0.669326, acc.: 63.28%] [G loss: 0.914197]\n",
      "epoch:11 step:11031 [D loss: 0.634890, acc.: 64.84%] [G loss: 0.876274]\n",
      "epoch:11 step:11032 [D loss: 0.645758, acc.: 62.50%] [G loss: 0.925381]\n",
      "epoch:11 step:11033 [D loss: 0.639548, acc.: 60.94%] [G loss: 0.908914]\n",
      "epoch:11 step:11034 [D loss: 0.695210, acc.: 59.38%] [G loss: 0.840017]\n",
      "epoch:11 step:11035 [D loss: 0.661316, acc.: 60.16%] [G loss: 0.798905]\n",
      "epoch:11 step:11036 [D loss: 0.714690, acc.: 45.31%] [G loss: 0.875866]\n",
      "epoch:11 step:11037 [D loss: 0.641633, acc.: 61.72%] [G loss: 0.794338]\n",
      "epoch:11 step:11038 [D loss: 0.658381, acc.: 57.03%] [G loss: 0.829708]\n",
      "epoch:11 step:11039 [D loss: 0.585084, acc.: 70.31%] [G loss: 0.916856]\n",
      "epoch:11 step:11040 [D loss: 0.664268, acc.: 59.38%] [G loss: 0.907917]\n",
      "epoch:11 step:11041 [D loss: 0.665320, acc.: 58.59%] [G loss: 0.907476]\n",
      "epoch:11 step:11042 [D loss: 0.670309, acc.: 56.25%] [G loss: 0.870933]\n",
      "epoch:11 step:11043 [D loss: 0.643772, acc.: 60.94%] [G loss: 0.870104]\n",
      "epoch:11 step:11044 [D loss: 0.631081, acc.: 64.06%] [G loss: 0.865940]\n",
      "epoch:11 step:11045 [D loss: 0.683922, acc.: 52.34%] [G loss: 0.797748]\n",
      "epoch:11 step:11046 [D loss: 0.669060, acc.: 59.38%] [G loss: 0.880573]\n",
      "epoch:11 step:11047 [D loss: 0.716070, acc.: 43.75%] [G loss: 0.842782]\n",
      "epoch:11 step:11048 [D loss: 0.680667, acc.: 58.59%] [G loss: 0.936850]\n",
      "epoch:11 step:11049 [D loss: 0.673547, acc.: 56.25%] [G loss: 0.952830]\n",
      "epoch:11 step:11050 [D loss: 0.627123, acc.: 68.75%] [G loss: 0.965083]\n",
      "epoch:11 step:11051 [D loss: 0.663688, acc.: 62.50%] [G loss: 0.878061]\n",
      "epoch:11 step:11052 [D loss: 0.656778, acc.: 56.25%] [G loss: 0.914845]\n",
      "epoch:11 step:11053 [D loss: 0.615700, acc.: 67.97%] [G loss: 0.964544]\n",
      "epoch:11 step:11054 [D loss: 0.595387, acc.: 67.97%] [G loss: 0.939840]\n",
      "epoch:11 step:11055 [D loss: 0.652028, acc.: 57.81%] [G loss: 0.861128]\n",
      "epoch:11 step:11056 [D loss: 0.677257, acc.: 60.94%] [G loss: 0.858035]\n",
      "epoch:11 step:11057 [D loss: 0.654377, acc.: 64.84%] [G loss: 0.927120]\n",
      "epoch:11 step:11058 [D loss: 0.606484, acc.: 67.19%] [G loss: 0.922173]\n",
      "epoch:11 step:11059 [D loss: 0.675734, acc.: 54.69%] [G loss: 0.925490]\n",
      "epoch:11 step:11060 [D loss: 0.647531, acc.: 59.38%] [G loss: 0.909653]\n",
      "epoch:11 step:11061 [D loss: 0.658308, acc.: 60.94%] [G loss: 0.877195]\n",
      "epoch:11 step:11062 [D loss: 0.635170, acc.: 64.06%] [G loss: 0.941689]\n",
      "epoch:11 step:11063 [D loss: 0.664763, acc.: 58.59%] [G loss: 0.938190]\n",
      "epoch:11 step:11064 [D loss: 0.693249, acc.: 51.56%] [G loss: 0.851889]\n",
      "epoch:11 step:11065 [D loss: 0.682979, acc.: 56.25%] [G loss: 0.920482]\n",
      "epoch:11 step:11066 [D loss: 0.681764, acc.: 56.25%] [G loss: 0.924890]\n",
      "epoch:11 step:11067 [D loss: 0.643282, acc.: 63.28%] [G loss: 0.916368]\n",
      "epoch:11 step:11068 [D loss: 0.671283, acc.: 58.59%] [G loss: 0.864349]\n",
      "epoch:11 step:11069 [D loss: 0.655436, acc.: 61.72%] [G loss: 0.912472]\n",
      "epoch:11 step:11070 [D loss: 0.642915, acc.: 65.62%] [G loss: 0.895887]\n",
      "epoch:11 step:11071 [D loss: 0.668728, acc.: 53.12%] [G loss: 0.926818]\n",
      "epoch:11 step:11072 [D loss: 0.762890, acc.: 43.75%] [G loss: 0.844193]\n",
      "epoch:11 step:11073 [D loss: 0.692194, acc.: 53.12%] [G loss: 0.875834]\n",
      "epoch:11 step:11074 [D loss: 0.663425, acc.: 60.94%] [G loss: 0.898547]\n",
      "epoch:11 step:11075 [D loss: 0.679642, acc.: 55.47%] [G loss: 0.882570]\n",
      "epoch:11 step:11076 [D loss: 0.647492, acc.: 58.59%] [G loss: 0.879490]\n",
      "epoch:11 step:11077 [D loss: 0.630987, acc.: 61.72%] [G loss: 0.956697]\n",
      "epoch:11 step:11078 [D loss: 0.643238, acc.: 62.50%] [G loss: 0.981707]\n",
      "epoch:11 step:11079 [D loss: 0.695449, acc.: 56.25%] [G loss: 0.909644]\n",
      "epoch:11 step:11080 [D loss: 0.630488, acc.: 67.97%] [G loss: 0.989730]\n",
      "epoch:11 step:11081 [D loss: 0.676887, acc.: 61.72%] [G loss: 0.877301]\n",
      "epoch:11 step:11082 [D loss: 0.621336, acc.: 68.75%] [G loss: 0.911936]\n",
      "epoch:11 step:11083 [D loss: 0.618666, acc.: 67.97%] [G loss: 0.950846]\n",
      "epoch:11 step:11084 [D loss: 0.650384, acc.: 62.50%] [G loss: 0.917336]\n",
      "epoch:11 step:11085 [D loss: 0.686435, acc.: 52.34%] [G loss: 0.903834]\n",
      "epoch:11 step:11086 [D loss: 0.638808, acc.: 62.50%] [G loss: 0.911534]\n",
      "epoch:11 step:11087 [D loss: 0.644384, acc.: 64.06%] [G loss: 0.941483]\n",
      "epoch:11 step:11088 [D loss: 0.611081, acc.: 66.41%] [G loss: 0.952274]\n",
      "epoch:11 step:11089 [D loss: 0.598167, acc.: 67.97%] [G loss: 0.962296]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11090 [D loss: 0.731468, acc.: 46.88%] [G loss: 0.960391]\n",
      "epoch:11 step:11091 [D loss: 0.750994, acc.: 47.66%] [G loss: 0.857828]\n",
      "epoch:11 step:11092 [D loss: 0.675394, acc.: 62.50%] [G loss: 0.862936]\n",
      "epoch:11 step:11093 [D loss: 0.578890, acc.: 74.22%] [G loss: 0.868080]\n",
      "epoch:11 step:11094 [D loss: 0.690566, acc.: 59.38%] [G loss: 0.880190]\n",
      "epoch:11 step:11095 [D loss: 0.696618, acc.: 51.56%] [G loss: 0.865403]\n",
      "epoch:11 step:11096 [D loss: 0.641655, acc.: 66.41%] [G loss: 0.902800]\n",
      "epoch:11 step:11097 [D loss: 0.650117, acc.: 60.94%] [G loss: 0.896814]\n",
      "epoch:11 step:11098 [D loss: 0.700985, acc.: 51.56%] [G loss: 0.893739]\n",
      "epoch:11 step:11099 [D loss: 0.628518, acc.: 63.28%] [G loss: 0.878911]\n",
      "epoch:11 step:11100 [D loss: 0.643443, acc.: 59.38%] [G loss: 0.910859]\n",
      "epoch:11 step:11101 [D loss: 0.715926, acc.: 48.44%] [G loss: 0.851635]\n",
      "epoch:11 step:11102 [D loss: 0.631495, acc.: 64.06%] [G loss: 0.883093]\n",
      "epoch:11 step:11103 [D loss: 0.656072, acc.: 63.28%] [G loss: 0.956416]\n",
      "epoch:11 step:11104 [D loss: 0.709580, acc.: 50.00%] [G loss: 0.914757]\n",
      "epoch:11 step:11105 [D loss: 0.655079, acc.: 60.16%] [G loss: 0.840133]\n",
      "epoch:11 step:11106 [D loss: 0.632159, acc.: 64.84%] [G loss: 0.958409]\n",
      "epoch:11 step:11107 [D loss: 0.687764, acc.: 53.12%] [G loss: 0.945544]\n",
      "epoch:11 step:11108 [D loss: 0.643060, acc.: 64.84%] [G loss: 0.995025]\n",
      "epoch:11 step:11109 [D loss: 0.630602, acc.: 64.06%] [G loss: 0.989989]\n",
      "epoch:11 step:11110 [D loss: 0.635858, acc.: 62.50%] [G loss: 0.954360]\n",
      "epoch:11 step:11111 [D loss: 0.681373, acc.: 59.38%] [G loss: 0.916674]\n",
      "epoch:11 step:11112 [D loss: 0.685120, acc.: 54.69%] [G loss: 0.808513]\n",
      "epoch:11 step:11113 [D loss: 0.689942, acc.: 54.69%] [G loss: 0.885596]\n",
      "epoch:11 step:11114 [D loss: 0.614141, acc.: 66.41%] [G loss: 0.837740]\n",
      "epoch:11 step:11115 [D loss: 0.715734, acc.: 54.69%] [G loss: 0.846830]\n",
      "epoch:11 step:11116 [D loss: 0.668882, acc.: 59.38%] [G loss: 0.890000]\n",
      "epoch:11 step:11117 [D loss: 0.677858, acc.: 56.25%] [G loss: 0.859137]\n",
      "epoch:11 step:11118 [D loss: 0.668011, acc.: 60.16%] [G loss: 0.882587]\n",
      "epoch:11 step:11119 [D loss: 0.672042, acc.: 54.69%] [G loss: 0.865489]\n",
      "epoch:11 step:11120 [D loss: 0.675979, acc.: 57.03%] [G loss: 0.879225]\n",
      "epoch:11 step:11121 [D loss: 0.669760, acc.: 57.03%] [G loss: 0.887784]\n",
      "epoch:11 step:11122 [D loss: 0.639754, acc.: 65.62%] [G loss: 0.897553]\n",
      "epoch:11 step:11123 [D loss: 0.660716, acc.: 60.16%] [G loss: 0.964844]\n",
      "epoch:11 step:11124 [D loss: 0.654409, acc.: 64.06%] [G loss: 0.880720]\n",
      "epoch:11 step:11125 [D loss: 0.693158, acc.: 55.47%] [G loss: 0.898565]\n",
      "epoch:11 step:11126 [D loss: 0.683071, acc.: 61.72%] [G loss: 0.869962]\n",
      "epoch:11 step:11127 [D loss: 0.761826, acc.: 47.66%] [G loss: 0.862880]\n",
      "epoch:11 step:11128 [D loss: 0.658350, acc.: 58.59%] [G loss: 0.918001]\n",
      "epoch:11 step:11129 [D loss: 0.646248, acc.: 62.50%] [G loss: 0.870607]\n",
      "epoch:11 step:11130 [D loss: 0.633862, acc.: 68.75%] [G loss: 0.858942]\n",
      "epoch:11 step:11131 [D loss: 0.699067, acc.: 53.91%] [G loss: 0.849164]\n",
      "epoch:11 step:11132 [D loss: 0.616306, acc.: 71.09%] [G loss: 0.893763]\n",
      "epoch:11 step:11133 [D loss: 0.630466, acc.: 67.19%] [G loss: 0.922730]\n",
      "epoch:11 step:11134 [D loss: 0.714765, acc.: 55.47%] [G loss: 0.853113]\n",
      "epoch:11 step:11135 [D loss: 0.695751, acc.: 58.59%] [G loss: 0.880660]\n",
      "epoch:11 step:11136 [D loss: 0.698804, acc.: 52.34%] [G loss: 0.814870]\n",
      "epoch:11 step:11137 [D loss: 0.653427, acc.: 61.72%] [G loss: 0.861236]\n",
      "epoch:11 step:11138 [D loss: 0.652705, acc.: 60.16%] [G loss: 0.892564]\n",
      "epoch:11 step:11139 [D loss: 0.647795, acc.: 64.84%] [G loss: 0.871751]\n",
      "epoch:11 step:11140 [D loss: 0.640818, acc.: 62.50%] [G loss: 0.863346]\n",
      "epoch:11 step:11141 [D loss: 0.719102, acc.: 53.12%] [G loss: 0.927663]\n",
      "epoch:11 step:11142 [D loss: 0.649062, acc.: 64.06%] [G loss: 0.825542]\n",
      "epoch:11 step:11143 [D loss: 0.651625, acc.: 59.38%] [G loss: 0.917342]\n",
      "epoch:11 step:11144 [D loss: 0.653294, acc.: 60.16%] [G loss: 0.967457]\n",
      "epoch:11 step:11145 [D loss: 0.631608, acc.: 66.41%] [G loss: 0.943720]\n",
      "epoch:11 step:11146 [D loss: 0.679058, acc.: 60.94%] [G loss: 0.926004]\n",
      "epoch:11 step:11147 [D loss: 0.670704, acc.: 62.50%] [G loss: 0.915350]\n",
      "epoch:11 step:11148 [D loss: 0.660743, acc.: 63.28%] [G loss: 0.909037]\n",
      "epoch:11 step:11149 [D loss: 0.629567, acc.: 64.84%] [G loss: 0.901074]\n",
      "epoch:11 step:11150 [D loss: 0.680881, acc.: 55.47%] [G loss: 0.931446]\n",
      "epoch:11 step:11151 [D loss: 0.673781, acc.: 57.03%] [G loss: 0.915532]\n",
      "epoch:11 step:11152 [D loss: 0.646164, acc.: 57.81%] [G loss: 0.935309]\n",
      "epoch:11 step:11153 [D loss: 0.655870, acc.: 61.72%] [G loss: 0.878207]\n",
      "epoch:11 step:11154 [D loss: 0.678794, acc.: 56.25%] [G loss: 0.862357]\n",
      "epoch:11 step:11155 [D loss: 0.660378, acc.: 64.06%] [G loss: 0.850679]\n",
      "epoch:11 step:11156 [D loss: 0.672237, acc.: 58.59%] [G loss: 0.854445]\n",
      "epoch:11 step:11157 [D loss: 0.664162, acc.: 60.94%] [G loss: 0.832913]\n",
      "epoch:11 step:11158 [D loss: 0.695807, acc.: 56.25%] [G loss: 0.900205]\n",
      "epoch:11 step:11159 [D loss: 0.636530, acc.: 65.62%] [G loss: 0.866279]\n",
      "epoch:11 step:11160 [D loss: 0.634653, acc.: 61.72%] [G loss: 0.918612]\n",
      "epoch:11 step:11161 [D loss: 0.646922, acc.: 63.28%] [G loss: 0.927541]\n",
      "epoch:11 step:11162 [D loss: 0.637045, acc.: 64.06%] [G loss: 0.894814]\n",
      "epoch:11 step:11163 [D loss: 0.693139, acc.: 52.34%] [G loss: 0.944083]\n",
      "epoch:11 step:11164 [D loss: 0.597422, acc.: 73.44%] [G loss: 0.889663]\n",
      "epoch:11 step:11165 [D loss: 0.755455, acc.: 45.31%] [G loss: 0.878687]\n",
      "epoch:11 step:11166 [D loss: 0.718193, acc.: 47.66%] [G loss: 0.919831]\n",
      "epoch:11 step:11167 [D loss: 0.623545, acc.: 64.84%] [G loss: 0.956266]\n",
      "epoch:11 step:11168 [D loss: 0.709301, acc.: 50.00%] [G loss: 0.897510]\n",
      "epoch:11 step:11169 [D loss: 0.697516, acc.: 55.47%] [G loss: 0.912209]\n",
      "epoch:11 step:11170 [D loss: 0.651387, acc.: 56.25%] [G loss: 0.872179]\n",
      "epoch:11 step:11171 [D loss: 0.633815, acc.: 66.41%] [G loss: 0.817884]\n",
      "epoch:11 step:11172 [D loss: 0.703260, acc.: 55.47%] [G loss: 0.732987]\n",
      "epoch:11 step:11173 [D loss: 0.682700, acc.: 54.69%] [G loss: 0.826368]\n",
      "epoch:11 step:11174 [D loss: 0.717591, acc.: 48.44%] [G loss: 0.832200]\n",
      "epoch:11 step:11175 [D loss: 0.613591, acc.: 67.19%] [G loss: 0.881030]\n",
      "epoch:11 step:11176 [D loss: 0.692254, acc.: 48.44%] [G loss: 0.883486]\n",
      "epoch:11 step:11177 [D loss: 0.684425, acc.: 57.03%] [G loss: 0.856764]\n",
      "epoch:11 step:11178 [D loss: 0.624680, acc.: 65.62%] [G loss: 0.890914]\n",
      "epoch:11 step:11179 [D loss: 0.617946, acc.: 64.06%] [G loss: 0.908242]\n",
      "epoch:11 step:11180 [D loss: 0.672936, acc.: 53.91%] [G loss: 0.897744]\n",
      "epoch:11 step:11181 [D loss: 0.653432, acc.: 60.94%] [G loss: 0.934272]\n",
      "epoch:11 step:11182 [D loss: 0.646999, acc.: 64.06%] [G loss: 0.954619]\n",
      "epoch:11 step:11183 [D loss: 0.677028, acc.: 57.03%] [G loss: 0.887272]\n",
      "epoch:11 step:11184 [D loss: 0.714101, acc.: 49.22%] [G loss: 0.814487]\n",
      "epoch:11 step:11185 [D loss: 0.684699, acc.: 56.25%] [G loss: 0.899982]\n",
      "epoch:11 step:11186 [D loss: 0.651026, acc.: 57.81%] [G loss: 0.817899]\n",
      "epoch:11 step:11187 [D loss: 0.679324, acc.: 55.47%] [G loss: 0.879520]\n",
      "epoch:11 step:11188 [D loss: 0.640485, acc.: 60.94%] [G loss: 0.914884]\n",
      "epoch:11 step:11189 [D loss: 0.662537, acc.: 58.59%] [G loss: 0.903050]\n",
      "epoch:11 step:11190 [D loss: 0.673604, acc.: 59.38%] [G loss: 0.896532]\n",
      "epoch:11 step:11191 [D loss: 0.625614, acc.: 61.72%] [G loss: 0.898414]\n",
      "epoch:11 step:11192 [D loss: 0.644381, acc.: 68.75%] [G loss: 0.955420]\n",
      "epoch:11 step:11193 [D loss: 0.591504, acc.: 67.19%] [G loss: 0.982298]\n",
      "epoch:11 step:11194 [D loss: 0.674257, acc.: 58.59%] [G loss: 0.993160]\n",
      "epoch:11 step:11195 [D loss: 0.659355, acc.: 58.59%] [G loss: 0.900290]\n",
      "epoch:11 step:11196 [D loss: 0.615077, acc.: 68.75%] [G loss: 0.938015]\n",
      "epoch:11 step:11197 [D loss: 0.638426, acc.: 66.41%] [G loss: 0.913386]\n",
      "epoch:11 step:11198 [D loss: 0.676299, acc.: 57.03%] [G loss: 0.873467]\n",
      "epoch:11 step:11199 [D loss: 0.705819, acc.: 50.78%] [G loss: 0.814067]\n",
      "epoch:11 step:11200 [D loss: 0.626468, acc.: 65.62%] [G loss: 0.878785]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.862236\n",
      "FID: 12.843956\n",
      "0 = 11.88072977368835\n",
      "1 = 0.061399304334445896\n",
      "2 = 0.9136499762535095\n",
      "3 = 0.8526999950408936\n",
      "4 = 0.9746000170707703\n",
      "5 = 0.9710739254951477\n",
      "6 = 0.8526999950408936\n",
      "7 = 6.425953598594675\n",
      "8 = 0.083466106182975\n",
      "9 = 0.7321000099182129\n",
      "10 = 0.7026000022888184\n",
      "11 = 0.7616000175476074\n",
      "12 = 0.7466524839401245\n",
      "13 = 0.7026000022888184\n",
      "14 = 7.862301826477051\n",
      "15 = 9.535676002502441\n",
      "16 = 0.11267658323049545\n",
      "17 = 7.8622355461120605\n",
      "18 = 12.843955993652344\n",
      "epoch:11 step:11201 [D loss: 0.613774, acc.: 73.44%] [G loss: 0.899591]\n",
      "epoch:11 step:11202 [D loss: 0.640877, acc.: 60.94%] [G loss: 0.915410]\n",
      "epoch:11 step:11203 [D loss: 0.655619, acc.: 63.28%] [G loss: 0.948423]\n",
      "epoch:11 step:11204 [D loss: 0.611187, acc.: 67.97%] [G loss: 0.963603]\n",
      "epoch:11 step:11205 [D loss: 0.625207, acc.: 67.19%] [G loss: 0.996230]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11206 [D loss: 0.602719, acc.: 71.09%] [G loss: 0.974412]\n",
      "epoch:11 step:11207 [D loss: 0.637383, acc.: 67.19%] [G loss: 0.973541]\n",
      "epoch:11 step:11208 [D loss: 0.670489, acc.: 60.94%] [G loss: 0.946468]\n",
      "epoch:11 step:11209 [D loss: 0.668524, acc.: 57.81%] [G loss: 0.959350]\n",
      "epoch:11 step:11210 [D loss: 0.688038, acc.: 57.81%] [G loss: 0.926694]\n",
      "epoch:11 step:11211 [D loss: 0.709133, acc.: 48.44%] [G loss: 0.907221]\n",
      "epoch:11 step:11212 [D loss: 0.627870, acc.: 64.84%] [G loss: 0.909127]\n",
      "epoch:11 step:11213 [D loss: 0.657376, acc.: 60.94%] [G loss: 0.877726]\n",
      "epoch:11 step:11214 [D loss: 0.668646, acc.: 58.59%] [G loss: 0.889399]\n",
      "epoch:11 step:11215 [D loss: 0.641835, acc.: 66.41%] [G loss: 0.915220]\n",
      "epoch:11 step:11216 [D loss: 0.619410, acc.: 65.62%] [G loss: 0.948387]\n",
      "epoch:11 step:11217 [D loss: 0.666827, acc.: 52.34%] [G loss: 0.970113]\n",
      "epoch:11 step:11218 [D loss: 0.667011, acc.: 62.50%] [G loss: 0.955292]\n",
      "epoch:11 step:11219 [D loss: 0.632319, acc.: 62.50%] [G loss: 0.983587]\n",
      "epoch:11 step:11220 [D loss: 0.648809, acc.: 64.84%] [G loss: 0.919122]\n",
      "epoch:11 step:11221 [D loss: 0.668067, acc.: 61.72%] [G loss: 0.947312]\n",
      "epoch:11 step:11222 [D loss: 0.651654, acc.: 58.59%] [G loss: 0.906768]\n",
      "epoch:11 step:11223 [D loss: 0.683310, acc.: 60.16%] [G loss: 0.871421]\n",
      "epoch:11 step:11224 [D loss: 0.662061, acc.: 60.16%] [G loss: 0.901827]\n",
      "epoch:11 step:11225 [D loss: 0.597515, acc.: 75.00%] [G loss: 0.923584]\n",
      "epoch:11 step:11226 [D loss: 0.633718, acc.: 64.84%] [G loss: 0.933924]\n",
      "epoch:11 step:11227 [D loss: 0.803346, acc.: 41.41%] [G loss: 0.936367]\n",
      "epoch:11 step:11228 [D loss: 0.666451, acc.: 58.59%] [G loss: 0.957590]\n",
      "epoch:11 step:11229 [D loss: 0.658911, acc.: 62.50%] [G loss: 0.902733]\n",
      "epoch:11 step:11230 [D loss: 0.635099, acc.: 63.28%] [G loss: 0.870678]\n",
      "epoch:11 step:11231 [D loss: 0.580258, acc.: 71.88%] [G loss: 0.960670]\n",
      "epoch:11 step:11232 [D loss: 0.603552, acc.: 71.88%] [G loss: 0.977028]\n",
      "epoch:11 step:11233 [D loss: 0.584025, acc.: 73.44%] [G loss: 1.004899]\n",
      "epoch:11 step:11234 [D loss: 0.698393, acc.: 48.44%] [G loss: 1.071095]\n",
      "epoch:11 step:11235 [D loss: 0.792056, acc.: 53.91%] [G loss: 1.058991]\n",
      "epoch:11 step:11236 [D loss: 0.571470, acc.: 73.44%] [G loss: 1.171696]\n",
      "epoch:11 step:11237 [D loss: 0.679229, acc.: 64.06%] [G loss: 1.035548]\n",
      "epoch:11 step:11238 [D loss: 0.735606, acc.: 52.34%] [G loss: 0.906447]\n",
      "epoch:11 step:11239 [D loss: 0.719652, acc.: 51.56%] [G loss: 0.839013]\n",
      "epoch:11 step:11240 [D loss: 0.652170, acc.: 63.28%] [G loss: 0.924191]\n",
      "epoch:11 step:11241 [D loss: 0.664333, acc.: 64.06%] [G loss: 0.930177]\n",
      "epoch:11 step:11242 [D loss: 0.567202, acc.: 72.66%] [G loss: 0.971089]\n",
      "epoch:11 step:11243 [D loss: 0.558456, acc.: 71.09%] [G loss: 0.979547]\n",
      "epoch:11 step:11244 [D loss: 0.596743, acc.: 68.75%] [G loss: 1.077262]\n",
      "epoch:12 step:11245 [D loss: 0.657977, acc.: 58.59%] [G loss: 1.008565]\n",
      "epoch:12 step:11246 [D loss: 0.740012, acc.: 58.59%] [G loss: 0.914317]\n",
      "epoch:12 step:11247 [D loss: 0.744182, acc.: 50.00%] [G loss: 0.908633]\n",
      "epoch:12 step:11248 [D loss: 0.706722, acc.: 53.91%] [G loss: 0.843108]\n",
      "epoch:12 step:11249 [D loss: 0.693966, acc.: 58.59%] [G loss: 0.898292]\n",
      "epoch:12 step:11250 [D loss: 0.626717, acc.: 59.38%] [G loss: 0.862566]\n",
      "epoch:12 step:11251 [D loss: 0.645446, acc.: 64.06%] [G loss: 0.906417]\n",
      "epoch:12 step:11252 [D loss: 0.648348, acc.: 59.38%] [G loss: 0.927063]\n",
      "epoch:12 step:11253 [D loss: 0.624656, acc.: 64.84%] [G loss: 0.921699]\n",
      "epoch:12 step:11254 [D loss: 0.647298, acc.: 61.72%] [G loss: 0.908942]\n",
      "epoch:12 step:11255 [D loss: 0.663866, acc.: 59.38%] [G loss: 0.881841]\n",
      "epoch:12 step:11256 [D loss: 0.672690, acc.: 60.16%] [G loss: 0.952136]\n",
      "epoch:12 step:11257 [D loss: 0.642720, acc.: 64.84%] [G loss: 0.911055]\n",
      "epoch:12 step:11258 [D loss: 0.677287, acc.: 53.91%] [G loss: 0.911554]\n",
      "epoch:12 step:11259 [D loss: 0.583413, acc.: 71.09%] [G loss: 0.938242]\n",
      "epoch:12 step:11260 [D loss: 0.638020, acc.: 62.50%] [G loss: 0.976691]\n",
      "epoch:12 step:11261 [D loss: 0.666115, acc.: 61.72%] [G loss: 0.924774]\n",
      "epoch:12 step:11262 [D loss: 0.667008, acc.: 60.16%] [G loss: 0.919847]\n",
      "epoch:12 step:11263 [D loss: 0.701629, acc.: 53.12%] [G loss: 0.900456]\n",
      "epoch:12 step:11264 [D loss: 0.677516, acc.: 57.81%] [G loss: 1.033797]\n",
      "epoch:12 step:11265 [D loss: 0.604011, acc.: 69.53%] [G loss: 1.013510]\n",
      "epoch:12 step:11266 [D loss: 0.583895, acc.: 70.31%] [G loss: 1.015120]\n",
      "epoch:12 step:11267 [D loss: 0.732702, acc.: 51.56%] [G loss: 0.917710]\n",
      "epoch:12 step:11268 [D loss: 0.673897, acc.: 58.59%] [G loss: 0.835134]\n",
      "epoch:12 step:11269 [D loss: 0.632643, acc.: 62.50%] [G loss: 0.858904]\n",
      "epoch:12 step:11270 [D loss: 0.652253, acc.: 60.94%] [G loss: 0.826093]\n",
      "epoch:12 step:11271 [D loss: 0.674392, acc.: 61.72%] [G loss: 0.902103]\n",
      "epoch:12 step:11272 [D loss: 0.630479, acc.: 67.19%] [G loss: 0.847607]\n",
      "epoch:12 step:11273 [D loss: 0.685837, acc.: 57.81%] [G loss: 0.815646]\n",
      "epoch:12 step:11274 [D loss: 0.658929, acc.: 59.38%] [G loss: 0.877192]\n",
      "epoch:12 step:11275 [D loss: 0.672012, acc.: 57.03%] [G loss: 0.926513]\n",
      "epoch:12 step:11276 [D loss: 0.638406, acc.: 60.94%] [G loss: 0.935236]\n",
      "epoch:12 step:11277 [D loss: 0.679127, acc.: 53.91%] [G loss: 0.892722]\n",
      "epoch:12 step:11278 [D loss: 0.675832, acc.: 57.03%] [G loss: 0.937499]\n",
      "epoch:12 step:11279 [D loss: 0.658235, acc.: 63.28%] [G loss: 0.940827]\n",
      "epoch:12 step:11280 [D loss: 0.629236, acc.: 70.31%] [G loss: 0.890419]\n",
      "epoch:12 step:11281 [D loss: 0.666098, acc.: 64.06%] [G loss: 0.895825]\n",
      "epoch:12 step:11282 [D loss: 0.723647, acc.: 53.12%] [G loss: 0.875700]\n",
      "epoch:12 step:11283 [D loss: 0.646112, acc.: 59.38%] [G loss: 0.903774]\n",
      "epoch:12 step:11284 [D loss: 0.645883, acc.: 62.50%] [G loss: 0.927453]\n",
      "epoch:12 step:11285 [D loss: 0.682832, acc.: 57.81%] [G loss: 0.929345]\n",
      "epoch:12 step:11286 [D loss: 0.655334, acc.: 62.50%] [G loss: 0.846118]\n",
      "epoch:12 step:11287 [D loss: 0.690164, acc.: 55.47%] [G loss: 0.860951]\n",
      "epoch:12 step:11288 [D loss: 0.701308, acc.: 50.78%] [G loss: 0.881970]\n",
      "epoch:12 step:11289 [D loss: 0.677858, acc.: 58.59%] [G loss: 0.883388]\n",
      "epoch:12 step:11290 [D loss: 0.667280, acc.: 60.16%] [G loss: 0.882020]\n",
      "epoch:12 step:11291 [D loss: 0.659860, acc.: 60.16%] [G loss: 0.893955]\n",
      "epoch:12 step:11292 [D loss: 0.647001, acc.: 62.50%] [G loss: 0.908513]\n",
      "epoch:12 step:11293 [D loss: 0.633355, acc.: 67.19%] [G loss: 0.940254]\n",
      "epoch:12 step:11294 [D loss: 0.660015, acc.: 58.59%] [G loss: 0.975270]\n",
      "epoch:12 step:11295 [D loss: 0.728508, acc.: 45.31%] [G loss: 0.836427]\n",
      "epoch:12 step:11296 [D loss: 0.660433, acc.: 63.28%] [G loss: 0.876154]\n",
      "epoch:12 step:11297 [D loss: 0.631014, acc.: 63.28%] [G loss: 0.909197]\n",
      "epoch:12 step:11298 [D loss: 0.638793, acc.: 67.19%] [G loss: 0.962386]\n",
      "epoch:12 step:11299 [D loss: 0.634028, acc.: 62.50%] [G loss: 0.976058]\n",
      "epoch:12 step:11300 [D loss: 0.648210, acc.: 68.75%] [G loss: 0.986565]\n",
      "epoch:12 step:11301 [D loss: 0.650358, acc.: 58.59%] [G loss: 0.924215]\n",
      "epoch:12 step:11302 [D loss: 0.676397, acc.: 57.81%] [G loss: 0.912441]\n",
      "epoch:12 step:11303 [D loss: 0.654026, acc.: 62.50%] [G loss: 0.921631]\n",
      "epoch:12 step:11304 [D loss: 0.680825, acc.: 58.59%] [G loss: 0.875525]\n",
      "epoch:12 step:11305 [D loss: 0.719562, acc.: 51.56%] [G loss: 0.901069]\n",
      "epoch:12 step:11306 [D loss: 0.649657, acc.: 63.28%] [G loss: 0.886263]\n",
      "epoch:12 step:11307 [D loss: 0.641263, acc.: 60.16%] [G loss: 0.810315]\n",
      "epoch:12 step:11308 [D loss: 0.686852, acc.: 60.94%] [G loss: 0.903141]\n",
      "epoch:12 step:11309 [D loss: 0.693212, acc.: 57.03%] [G loss: 0.855220]\n",
      "epoch:12 step:11310 [D loss: 0.658300, acc.: 61.72%] [G loss: 0.871621]\n",
      "epoch:12 step:11311 [D loss: 0.641681, acc.: 63.28%] [G loss: 0.893955]\n",
      "epoch:12 step:11312 [D loss: 0.637817, acc.: 62.50%] [G loss: 0.850885]\n",
      "epoch:12 step:11313 [D loss: 0.640658, acc.: 62.50%] [G loss: 0.858846]\n",
      "epoch:12 step:11314 [D loss: 0.631844, acc.: 62.50%] [G loss: 0.891682]\n",
      "epoch:12 step:11315 [D loss: 0.666162, acc.: 64.06%] [G loss: 0.880370]\n",
      "epoch:12 step:11316 [D loss: 0.695405, acc.: 54.69%] [G loss: 0.886738]\n",
      "epoch:12 step:11317 [D loss: 0.686571, acc.: 57.81%] [G loss: 0.961519]\n",
      "epoch:12 step:11318 [D loss: 0.595012, acc.: 66.41%] [G loss: 0.975437]\n",
      "epoch:12 step:11319 [D loss: 0.643902, acc.: 57.81%] [G loss: 0.967989]\n",
      "epoch:12 step:11320 [D loss: 0.586275, acc.: 65.62%] [G loss: 0.986976]\n",
      "epoch:12 step:11321 [D loss: 0.601012, acc.: 68.75%] [G loss: 0.976710]\n",
      "epoch:12 step:11322 [D loss: 0.726335, acc.: 53.12%] [G loss: 0.851877]\n",
      "epoch:12 step:11323 [D loss: 0.687541, acc.: 56.25%] [G loss: 0.862736]\n",
      "epoch:12 step:11324 [D loss: 0.664090, acc.: 55.47%] [G loss: 0.837690]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11325 [D loss: 0.715908, acc.: 52.34%] [G loss: 0.868570]\n",
      "epoch:12 step:11326 [D loss: 0.636841, acc.: 60.94%] [G loss: 0.887254]\n",
      "epoch:12 step:11327 [D loss: 0.616586, acc.: 64.84%] [G loss: 0.939931]\n",
      "epoch:12 step:11328 [D loss: 0.621489, acc.: 64.06%] [G loss: 0.962176]\n",
      "epoch:12 step:11329 [D loss: 0.621993, acc.: 65.62%] [G loss: 0.907009]\n",
      "epoch:12 step:11330 [D loss: 0.628990, acc.: 64.84%] [G loss: 0.944408]\n",
      "epoch:12 step:11331 [D loss: 0.619102, acc.: 71.09%] [G loss: 0.935855]\n",
      "epoch:12 step:11332 [D loss: 0.657640, acc.: 60.94%] [G loss: 0.893068]\n",
      "epoch:12 step:11333 [D loss: 0.663974, acc.: 64.84%] [G loss: 0.925265]\n",
      "epoch:12 step:11334 [D loss: 0.645525, acc.: 58.59%] [G loss: 0.922495]\n",
      "epoch:12 step:11335 [D loss: 0.661808, acc.: 58.59%] [G loss: 0.921965]\n",
      "epoch:12 step:11336 [D loss: 0.627371, acc.: 67.19%] [G loss: 0.879999]\n",
      "epoch:12 step:11337 [D loss: 0.613103, acc.: 68.75%] [G loss: 0.871919]\n",
      "epoch:12 step:11338 [D loss: 0.673325, acc.: 65.62%] [G loss: 0.933610]\n",
      "epoch:12 step:11339 [D loss: 0.637849, acc.: 67.19%] [G loss: 0.902812]\n",
      "epoch:12 step:11340 [D loss: 0.634742, acc.: 65.62%] [G loss: 0.912887]\n",
      "epoch:12 step:11341 [D loss: 0.610781, acc.: 68.75%] [G loss: 0.950035]\n",
      "epoch:12 step:11342 [D loss: 0.626814, acc.: 66.41%] [G loss: 0.979137]\n",
      "epoch:12 step:11343 [D loss: 0.688958, acc.: 57.81%] [G loss: 0.941842]\n",
      "epoch:12 step:11344 [D loss: 0.614723, acc.: 65.62%] [G loss: 0.935957]\n",
      "epoch:12 step:11345 [D loss: 0.613568, acc.: 67.97%] [G loss: 0.915491]\n",
      "epoch:12 step:11346 [D loss: 0.655816, acc.: 61.72%] [G loss: 0.872744]\n",
      "epoch:12 step:11347 [D loss: 0.649190, acc.: 60.16%] [G loss: 0.881802]\n",
      "epoch:12 step:11348 [D loss: 0.706766, acc.: 56.25%] [G loss: 0.883148]\n",
      "epoch:12 step:11349 [D loss: 0.656995, acc.: 54.69%] [G loss: 0.859029]\n",
      "epoch:12 step:11350 [D loss: 0.608500, acc.: 64.84%] [G loss: 0.931658]\n",
      "epoch:12 step:11351 [D loss: 0.618798, acc.: 70.31%] [G loss: 0.927513]\n",
      "epoch:12 step:11352 [D loss: 0.712579, acc.: 53.91%] [G loss: 0.959065]\n",
      "epoch:12 step:11353 [D loss: 0.753571, acc.: 47.66%] [G loss: 0.932568]\n",
      "epoch:12 step:11354 [D loss: 0.677508, acc.: 53.12%] [G loss: 0.895596]\n",
      "epoch:12 step:11355 [D loss: 0.619771, acc.: 68.75%] [G loss: 0.935312]\n",
      "epoch:12 step:11356 [D loss: 0.610047, acc.: 71.09%] [G loss: 0.916207]\n",
      "epoch:12 step:11357 [D loss: 0.631419, acc.: 60.94%] [G loss: 0.974124]\n",
      "epoch:12 step:11358 [D loss: 0.621080, acc.: 67.97%] [G loss: 0.998573]\n",
      "epoch:12 step:11359 [D loss: 0.574294, acc.: 70.31%] [G loss: 1.042363]\n",
      "epoch:12 step:11360 [D loss: 0.649761, acc.: 65.62%] [G loss: 0.973507]\n",
      "epoch:12 step:11361 [D loss: 0.622421, acc.: 64.84%] [G loss: 0.905629]\n",
      "epoch:12 step:11362 [D loss: 0.700099, acc.: 60.16%] [G loss: 0.948752]\n",
      "epoch:12 step:11363 [D loss: 0.613833, acc.: 71.88%] [G loss: 0.946300]\n",
      "epoch:12 step:11364 [D loss: 0.689581, acc.: 56.25%] [G loss: 0.965558]\n",
      "epoch:12 step:11365 [D loss: 0.724629, acc.: 50.78%] [G loss: 0.861633]\n",
      "epoch:12 step:11366 [D loss: 0.650767, acc.: 63.28%] [G loss: 0.927021]\n",
      "epoch:12 step:11367 [D loss: 0.648065, acc.: 64.84%] [G loss: 0.912760]\n",
      "epoch:12 step:11368 [D loss: 0.710643, acc.: 48.44%] [G loss: 0.886957]\n",
      "epoch:12 step:11369 [D loss: 0.712353, acc.: 54.69%] [G loss: 0.892296]\n",
      "epoch:12 step:11370 [D loss: 0.616722, acc.: 64.84%] [G loss: 0.922086]\n",
      "epoch:12 step:11371 [D loss: 0.650202, acc.: 65.62%] [G loss: 0.927785]\n",
      "epoch:12 step:11372 [D loss: 0.686758, acc.: 56.25%] [G loss: 0.861208]\n",
      "epoch:12 step:11373 [D loss: 0.656968, acc.: 57.81%] [G loss: 0.869617]\n",
      "epoch:12 step:11374 [D loss: 0.626295, acc.: 64.84%] [G loss: 0.859140]\n",
      "epoch:12 step:11375 [D loss: 0.612405, acc.: 69.53%] [G loss: 0.913407]\n",
      "epoch:12 step:11376 [D loss: 0.653870, acc.: 62.50%] [G loss: 0.956874]\n",
      "epoch:12 step:11377 [D loss: 0.611841, acc.: 71.88%] [G loss: 0.956028]\n",
      "epoch:12 step:11378 [D loss: 0.639239, acc.: 60.94%] [G loss: 1.020610]\n",
      "epoch:12 step:11379 [D loss: 0.610704, acc.: 66.41%] [G loss: 0.987416]\n",
      "epoch:12 step:11380 [D loss: 0.616883, acc.: 65.62%] [G loss: 0.915788]\n",
      "epoch:12 step:11381 [D loss: 0.646801, acc.: 58.59%] [G loss: 0.855006]\n",
      "epoch:12 step:11382 [D loss: 0.648346, acc.: 60.16%] [G loss: 0.864612]\n",
      "epoch:12 step:11383 [D loss: 0.734511, acc.: 46.88%] [G loss: 0.922720]\n",
      "epoch:12 step:11384 [D loss: 0.725906, acc.: 50.78%] [G loss: 0.862412]\n",
      "epoch:12 step:11385 [D loss: 0.675377, acc.: 59.38%] [G loss: 0.890454]\n",
      "epoch:12 step:11386 [D loss: 0.655993, acc.: 60.94%] [G loss: 0.805238]\n",
      "epoch:12 step:11387 [D loss: 0.731644, acc.: 50.00%] [G loss: 0.860653]\n",
      "epoch:12 step:11388 [D loss: 0.622681, acc.: 69.53%] [G loss: 0.932395]\n",
      "epoch:12 step:11389 [D loss: 0.629144, acc.: 61.72%] [G loss: 0.872619]\n",
      "epoch:12 step:11390 [D loss: 0.652924, acc.: 64.06%] [G loss: 0.884835]\n",
      "epoch:12 step:11391 [D loss: 0.704940, acc.: 56.25%] [G loss: 0.905719]\n",
      "epoch:12 step:11392 [D loss: 0.709970, acc.: 50.00%] [G loss: 0.904734]\n",
      "epoch:12 step:11393 [D loss: 0.675595, acc.: 58.59%] [G loss: 0.923911]\n",
      "epoch:12 step:11394 [D loss: 0.685776, acc.: 53.91%] [G loss: 0.926254]\n",
      "epoch:12 step:11395 [D loss: 0.636019, acc.: 63.28%] [G loss: 0.912944]\n",
      "epoch:12 step:11396 [D loss: 0.668594, acc.: 53.91%] [G loss: 0.917295]\n",
      "epoch:12 step:11397 [D loss: 0.661474, acc.: 57.03%] [G loss: 0.903783]\n",
      "epoch:12 step:11398 [D loss: 0.675650, acc.: 57.81%] [G loss: 0.859553]\n",
      "epoch:12 step:11399 [D loss: 0.608197, acc.: 67.19%] [G loss: 0.849297]\n",
      "epoch:12 step:11400 [D loss: 0.666367, acc.: 63.28%] [G loss: 0.907810]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.844219\n",
      "FID: 10.392071\n",
      "0 = 11.897634300065059\n",
      "1 = 0.05153969925271255\n",
      "2 = 0.9225500226020813\n",
      "3 = 0.8762000203132629\n",
      "4 = 0.9689000248908997\n",
      "5 = 0.9657225012779236\n",
      "6 = 0.8762000203132629\n",
      "7 = 6.077891505879176\n",
      "8 = 0.06424378586935198\n",
      "9 = 0.7118499875068665\n",
      "10 = 0.6854000091552734\n",
      "11 = 0.7383000254631042\n",
      "12 = 0.7236828207969666\n",
      "13 = 0.6854000091552734\n",
      "14 = 7.844289779663086\n",
      "15 = 9.467934608459473\n",
      "16 = 0.13410459458827972\n",
      "17 = 7.844219207763672\n",
      "18 = 10.392070770263672\n",
      "epoch:12 step:11401 [D loss: 0.684422, acc.: 62.50%] [G loss: 0.902481]\n",
      "epoch:12 step:11402 [D loss: 0.661930, acc.: 58.59%] [G loss: 0.907887]\n",
      "epoch:12 step:11403 [D loss: 0.660329, acc.: 58.59%] [G loss: 0.919665]\n",
      "epoch:12 step:11404 [D loss: 0.746460, acc.: 53.91%] [G loss: 0.900087]\n",
      "epoch:12 step:11405 [D loss: 0.615615, acc.: 68.75%] [G loss: 0.979571]\n",
      "epoch:12 step:11406 [D loss: 0.666630, acc.: 60.16%] [G loss: 1.013091]\n",
      "epoch:12 step:11407 [D loss: 0.679521, acc.: 57.03%] [G loss: 0.939056]\n",
      "epoch:12 step:11408 [D loss: 0.643520, acc.: 64.84%] [G loss: 0.875038]\n",
      "epoch:12 step:11409 [D loss: 0.676693, acc.: 57.81%] [G loss: 0.847463]\n",
      "epoch:12 step:11410 [D loss: 0.679927, acc.: 59.38%] [G loss: 0.882287]\n",
      "epoch:12 step:11411 [D loss: 0.693331, acc.: 56.25%] [G loss: 0.873052]\n",
      "epoch:12 step:11412 [D loss: 0.647110, acc.: 60.16%] [G loss: 0.806458]\n",
      "epoch:12 step:11413 [D loss: 0.665067, acc.: 60.16%] [G loss: 0.869124]\n",
      "epoch:12 step:11414 [D loss: 0.652397, acc.: 57.03%] [G loss: 0.938986]\n",
      "epoch:12 step:11415 [D loss: 0.668005, acc.: 57.03%] [G loss: 0.872762]\n",
      "epoch:12 step:11416 [D loss: 0.680220, acc.: 59.38%] [G loss: 0.871225]\n",
      "epoch:12 step:11417 [D loss: 0.616277, acc.: 66.41%] [G loss: 0.858804]\n",
      "epoch:12 step:11418 [D loss: 0.690506, acc.: 50.00%] [G loss: 0.900149]\n",
      "epoch:12 step:11419 [D loss: 0.694775, acc.: 54.69%] [G loss: 0.843150]\n",
      "epoch:12 step:11420 [D loss: 0.664743, acc.: 56.25%] [G loss: 0.885263]\n",
      "epoch:12 step:11421 [D loss: 0.612953, acc.: 72.66%] [G loss: 0.892214]\n",
      "epoch:12 step:11422 [D loss: 0.662911, acc.: 61.72%] [G loss: 0.852585]\n",
      "epoch:12 step:11423 [D loss: 0.651319, acc.: 60.94%] [G loss: 0.934373]\n",
      "epoch:12 step:11424 [D loss: 0.677063, acc.: 55.47%] [G loss: 0.974457]\n",
      "epoch:12 step:11425 [D loss: 0.697924, acc.: 53.12%] [G loss: 0.868705]\n",
      "epoch:12 step:11426 [D loss: 0.677531, acc.: 53.91%] [G loss: 0.897671]\n",
      "epoch:12 step:11427 [D loss: 0.630013, acc.: 64.84%] [G loss: 0.806117]\n",
      "epoch:12 step:11428 [D loss: 0.691185, acc.: 51.56%] [G loss: 0.867454]\n",
      "epoch:12 step:11429 [D loss: 0.626583, acc.: 67.19%] [G loss: 0.895249]\n",
      "epoch:12 step:11430 [D loss: 0.705193, acc.: 56.25%] [G loss: 0.914127]\n",
      "epoch:12 step:11431 [D loss: 0.698230, acc.: 55.47%] [G loss: 0.929710]\n",
      "epoch:12 step:11432 [D loss: 0.649450, acc.: 68.75%] [G loss: 0.929552]\n",
      "epoch:12 step:11433 [D loss: 0.684879, acc.: 60.16%] [G loss: 0.848314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11434 [D loss: 0.675675, acc.: 50.78%] [G loss: 0.851052]\n",
      "epoch:12 step:11435 [D loss: 0.633365, acc.: 64.84%] [G loss: 0.848300]\n",
      "epoch:12 step:11436 [D loss: 0.660028, acc.: 62.50%] [G loss: 0.904921]\n",
      "epoch:12 step:11437 [D loss: 0.665090, acc.: 64.06%] [G loss: 0.880598]\n",
      "epoch:12 step:11438 [D loss: 0.619856, acc.: 65.62%] [G loss: 0.929073]\n",
      "epoch:12 step:11439 [D loss: 0.644197, acc.: 64.06%] [G loss: 0.891740]\n",
      "epoch:12 step:11440 [D loss: 0.713643, acc.: 50.00%] [G loss: 0.893211]\n",
      "epoch:12 step:11441 [D loss: 0.612970, acc.: 69.53%] [G loss: 0.951164]\n",
      "epoch:12 step:11442 [D loss: 0.611820, acc.: 65.62%] [G loss: 0.972718]\n",
      "epoch:12 step:11443 [D loss: 0.680884, acc.: 57.03%] [G loss: 0.888186]\n",
      "epoch:12 step:11444 [D loss: 0.700409, acc.: 54.69%] [G loss: 0.918761]\n",
      "epoch:12 step:11445 [D loss: 0.674533, acc.: 58.59%] [G loss: 0.878031]\n",
      "epoch:12 step:11446 [D loss: 0.658309, acc.: 56.25%] [G loss: 0.930865]\n",
      "epoch:12 step:11447 [D loss: 0.738036, acc.: 48.44%] [G loss: 0.904373]\n",
      "epoch:12 step:11448 [D loss: 0.645531, acc.: 60.16%] [G loss: 0.901037]\n",
      "epoch:12 step:11449 [D loss: 0.674979, acc.: 65.62%] [G loss: 0.883600]\n",
      "epoch:12 step:11450 [D loss: 0.611522, acc.: 66.41%] [G loss: 0.921860]\n",
      "epoch:12 step:11451 [D loss: 0.641739, acc.: 62.50%] [G loss: 0.893880]\n",
      "epoch:12 step:11452 [D loss: 0.600950, acc.: 65.62%] [G loss: 0.894894]\n",
      "epoch:12 step:11453 [D loss: 0.613551, acc.: 61.72%] [G loss: 0.920503]\n",
      "epoch:12 step:11454 [D loss: 0.725374, acc.: 50.78%] [G loss: 0.919149]\n",
      "epoch:12 step:11455 [D loss: 0.688920, acc.: 53.91%] [G loss: 0.850710]\n",
      "epoch:12 step:11456 [D loss: 0.667659, acc.: 63.28%] [G loss: 0.843970]\n",
      "epoch:12 step:11457 [D loss: 0.683691, acc.: 51.56%] [G loss: 0.854428]\n",
      "epoch:12 step:11458 [D loss: 0.702924, acc.: 50.78%] [G loss: 0.904193]\n",
      "epoch:12 step:11459 [D loss: 0.693810, acc.: 57.03%] [G loss: 0.864097]\n",
      "epoch:12 step:11460 [D loss: 0.652816, acc.: 67.97%] [G loss: 0.903624]\n",
      "epoch:12 step:11461 [D loss: 0.676612, acc.: 58.59%] [G loss: 0.863069]\n",
      "epoch:12 step:11462 [D loss: 0.638879, acc.: 66.41%] [G loss: 0.885096]\n",
      "epoch:12 step:11463 [D loss: 0.609548, acc.: 65.62%] [G loss: 0.936500]\n",
      "epoch:12 step:11464 [D loss: 0.785198, acc.: 47.66%] [G loss: 0.830848]\n",
      "epoch:12 step:11465 [D loss: 0.633788, acc.: 64.84%] [G loss: 0.906350]\n",
      "epoch:12 step:11466 [D loss: 0.611208, acc.: 67.19%] [G loss: 0.899986]\n",
      "epoch:12 step:11467 [D loss: 0.636251, acc.: 64.06%] [G loss: 0.944035]\n",
      "epoch:12 step:11468 [D loss: 0.648207, acc.: 63.28%] [G loss: 0.923691]\n",
      "epoch:12 step:11469 [D loss: 0.685760, acc.: 58.59%] [G loss: 0.918865]\n",
      "epoch:12 step:11470 [D loss: 0.700540, acc.: 52.34%] [G loss: 0.831656]\n",
      "epoch:12 step:11471 [D loss: 0.656297, acc.: 60.16%] [G loss: 0.846172]\n",
      "epoch:12 step:11472 [D loss: 0.672808, acc.: 62.50%] [G loss: 0.903728]\n",
      "epoch:12 step:11473 [D loss: 0.625468, acc.: 68.75%] [G loss: 0.973569]\n",
      "epoch:12 step:11474 [D loss: 0.622455, acc.: 68.75%] [G loss: 0.965160]\n",
      "epoch:12 step:11475 [D loss: 0.570637, acc.: 68.75%] [G loss: 1.027452]\n",
      "epoch:12 step:11476 [D loss: 0.600409, acc.: 67.97%] [G loss: 1.146697]\n",
      "epoch:12 step:11477 [D loss: 0.690620, acc.: 56.25%] [G loss: 0.947931]\n",
      "epoch:12 step:11478 [D loss: 0.655882, acc.: 60.94%] [G loss: 0.922441]\n",
      "epoch:12 step:11479 [D loss: 0.668249, acc.: 60.94%] [G loss: 0.937514]\n",
      "epoch:12 step:11480 [D loss: 0.653435, acc.: 58.59%] [G loss: 0.941585]\n",
      "epoch:12 step:11481 [D loss: 0.674854, acc.: 59.38%] [G loss: 0.934143]\n",
      "epoch:12 step:11482 [D loss: 0.684905, acc.: 60.16%] [G loss: 0.858685]\n",
      "epoch:12 step:11483 [D loss: 0.685916, acc.: 61.72%] [G loss: 0.891236]\n",
      "epoch:12 step:11484 [D loss: 0.626478, acc.: 67.19%] [G loss: 0.861723]\n",
      "epoch:12 step:11485 [D loss: 0.628097, acc.: 66.41%] [G loss: 0.924373]\n",
      "epoch:12 step:11486 [D loss: 0.598867, acc.: 71.09%] [G loss: 0.953189]\n",
      "epoch:12 step:11487 [D loss: 0.620136, acc.: 63.28%] [G loss: 0.974394]\n",
      "epoch:12 step:11488 [D loss: 0.630588, acc.: 64.84%] [G loss: 0.914811]\n",
      "epoch:12 step:11489 [D loss: 0.685128, acc.: 60.16%] [G loss: 0.981632]\n",
      "epoch:12 step:11490 [D loss: 0.670264, acc.: 59.38%] [G loss: 0.893328]\n",
      "epoch:12 step:11491 [D loss: 0.651655, acc.: 61.72%] [G loss: 0.913725]\n",
      "epoch:12 step:11492 [D loss: 0.627252, acc.: 62.50%] [G loss: 0.911471]\n",
      "epoch:12 step:11493 [D loss: 0.736098, acc.: 50.78%] [G loss: 0.913323]\n",
      "epoch:12 step:11494 [D loss: 0.748015, acc.: 46.88%] [G loss: 0.901256]\n",
      "epoch:12 step:11495 [D loss: 0.718331, acc.: 58.59%] [G loss: 0.886883]\n",
      "epoch:12 step:11496 [D loss: 0.702301, acc.: 53.91%] [G loss: 0.910696]\n",
      "epoch:12 step:11497 [D loss: 0.685718, acc.: 56.25%] [G loss: 0.903211]\n",
      "epoch:12 step:11498 [D loss: 0.649997, acc.: 60.94%] [G loss: 0.857657]\n",
      "epoch:12 step:11499 [D loss: 0.654436, acc.: 60.16%] [G loss: 0.915989]\n",
      "epoch:12 step:11500 [D loss: 0.657678, acc.: 57.81%] [G loss: 0.889525]\n",
      "epoch:12 step:11501 [D loss: 0.639067, acc.: 62.50%] [G loss: 0.926283]\n",
      "epoch:12 step:11502 [D loss: 0.642024, acc.: 60.94%] [G loss: 0.860861]\n",
      "epoch:12 step:11503 [D loss: 0.611364, acc.: 71.09%] [G loss: 0.899421]\n",
      "epoch:12 step:11504 [D loss: 0.691930, acc.: 53.12%] [G loss: 0.864873]\n",
      "epoch:12 step:11505 [D loss: 0.637791, acc.: 60.94%] [G loss: 0.847983]\n",
      "epoch:12 step:11506 [D loss: 0.658224, acc.: 59.38%] [G loss: 0.913012]\n",
      "epoch:12 step:11507 [D loss: 0.683150, acc.: 58.59%] [G loss: 0.883203]\n",
      "epoch:12 step:11508 [D loss: 0.621425, acc.: 64.84%] [G loss: 0.974301]\n",
      "epoch:12 step:11509 [D loss: 0.660713, acc.: 60.94%] [G loss: 0.901238]\n",
      "epoch:12 step:11510 [D loss: 0.684062, acc.: 57.03%] [G loss: 0.892421]\n",
      "epoch:12 step:11511 [D loss: 0.674671, acc.: 56.25%] [G loss: 0.901322]\n",
      "epoch:12 step:11512 [D loss: 0.661803, acc.: 58.59%] [G loss: 0.873038]\n",
      "epoch:12 step:11513 [D loss: 0.676505, acc.: 50.78%] [G loss: 0.887278]\n",
      "epoch:12 step:11514 [D loss: 0.664355, acc.: 59.38%] [G loss: 0.923477]\n",
      "epoch:12 step:11515 [D loss: 0.648327, acc.: 60.94%] [G loss: 0.934667]\n",
      "epoch:12 step:11516 [D loss: 0.650024, acc.: 59.38%] [G loss: 0.957644]\n",
      "epoch:12 step:11517 [D loss: 0.610190, acc.: 66.41%] [G loss: 0.930544]\n",
      "epoch:12 step:11518 [D loss: 0.628117, acc.: 65.62%] [G loss: 0.930502]\n",
      "epoch:12 step:11519 [D loss: 0.671258, acc.: 57.81%] [G loss: 0.955967]\n",
      "epoch:12 step:11520 [D loss: 0.637265, acc.: 62.50%] [G loss: 0.880157]\n",
      "epoch:12 step:11521 [D loss: 0.719568, acc.: 53.91%] [G loss: 0.907447]\n",
      "epoch:12 step:11522 [D loss: 0.706530, acc.: 51.56%] [G loss: 0.871498]\n",
      "epoch:12 step:11523 [D loss: 0.662045, acc.: 57.81%] [G loss: 0.960156]\n",
      "epoch:12 step:11524 [D loss: 0.661076, acc.: 57.03%] [G loss: 0.875714]\n",
      "epoch:12 step:11525 [D loss: 0.706759, acc.: 53.12%] [G loss: 0.942365]\n",
      "epoch:12 step:11526 [D loss: 0.653772, acc.: 62.50%] [G loss: 0.871843]\n",
      "epoch:12 step:11527 [D loss: 0.599823, acc.: 71.88%] [G loss: 0.908031]\n",
      "epoch:12 step:11528 [D loss: 0.647403, acc.: 66.41%] [G loss: 0.880323]\n",
      "epoch:12 step:11529 [D loss: 0.679061, acc.: 53.91%] [G loss: 0.890578]\n",
      "epoch:12 step:11530 [D loss: 0.643082, acc.: 66.41%] [G loss: 0.976636]\n",
      "epoch:12 step:11531 [D loss: 0.660860, acc.: 59.38%] [G loss: 0.926304]\n",
      "epoch:12 step:11532 [D loss: 0.662263, acc.: 58.59%] [G loss: 0.934260]\n",
      "epoch:12 step:11533 [D loss: 0.608579, acc.: 63.28%] [G loss: 0.957673]\n",
      "epoch:12 step:11534 [D loss: 0.667760, acc.: 55.47%] [G loss: 0.972321]\n",
      "epoch:12 step:11535 [D loss: 0.688341, acc.: 53.12%] [G loss: 0.841403]\n",
      "epoch:12 step:11536 [D loss: 0.666597, acc.: 60.94%] [G loss: 0.912331]\n",
      "epoch:12 step:11537 [D loss: 0.652873, acc.: 61.72%] [G loss: 0.911259]\n",
      "epoch:12 step:11538 [D loss: 0.673706, acc.: 53.12%] [G loss: 0.905327]\n",
      "epoch:12 step:11539 [D loss: 0.682232, acc.: 57.81%] [G loss: 0.866693]\n",
      "epoch:12 step:11540 [D loss: 0.649058, acc.: 61.72%] [G loss: 0.905946]\n",
      "epoch:12 step:11541 [D loss: 0.674885, acc.: 55.47%] [G loss: 0.912267]\n",
      "epoch:12 step:11542 [D loss: 0.653733, acc.: 65.62%] [G loss: 0.932110]\n",
      "epoch:12 step:11543 [D loss: 0.648367, acc.: 62.50%] [G loss: 0.924724]\n",
      "epoch:12 step:11544 [D loss: 0.670868, acc.: 57.03%] [G loss: 0.920756]\n",
      "epoch:12 step:11545 [D loss: 0.663144, acc.: 61.72%] [G loss: 0.913259]\n",
      "epoch:12 step:11546 [D loss: 0.662018, acc.: 60.16%] [G loss: 0.909424]\n",
      "epoch:12 step:11547 [D loss: 0.630203, acc.: 67.19%] [G loss: 0.944654]\n",
      "epoch:12 step:11548 [D loss: 0.623701, acc.: 64.06%] [G loss: 0.900528]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11549 [D loss: 0.640582, acc.: 63.28%] [G loss: 0.914711]\n",
      "epoch:12 step:11550 [D loss: 0.637662, acc.: 60.16%] [G loss: 0.886634]\n",
      "epoch:12 step:11551 [D loss: 0.631771, acc.: 62.50%] [G loss: 0.888182]\n",
      "epoch:12 step:11552 [D loss: 0.649021, acc.: 60.94%] [G loss: 0.893442]\n",
      "epoch:12 step:11553 [D loss: 0.605227, acc.: 70.31%] [G loss: 0.873544]\n",
      "epoch:12 step:11554 [D loss: 0.645846, acc.: 61.72%] [G loss: 0.941655]\n",
      "epoch:12 step:11555 [D loss: 0.640321, acc.: 61.72%] [G loss: 0.906404]\n",
      "epoch:12 step:11556 [D loss: 0.621125, acc.: 71.09%] [G loss: 0.903366]\n",
      "epoch:12 step:11557 [D loss: 0.659801, acc.: 60.94%] [G loss: 1.012382]\n",
      "epoch:12 step:11558 [D loss: 0.624682, acc.: 64.84%] [G loss: 0.999787]\n",
      "epoch:12 step:11559 [D loss: 0.592557, acc.: 66.41%] [G loss: 0.964253]\n",
      "epoch:12 step:11560 [D loss: 0.736287, acc.: 48.44%] [G loss: 0.862111]\n",
      "epoch:12 step:11561 [D loss: 0.669416, acc.: 59.38%] [G loss: 0.896846]\n",
      "epoch:12 step:11562 [D loss: 0.651885, acc.: 60.94%] [G loss: 0.871627]\n",
      "epoch:12 step:11563 [D loss: 0.675257, acc.: 56.25%] [G loss: 0.902747]\n",
      "epoch:12 step:11564 [D loss: 0.658598, acc.: 58.59%] [G loss: 0.865409]\n",
      "epoch:12 step:11565 [D loss: 0.653010, acc.: 60.94%] [G loss: 0.938268]\n",
      "epoch:12 step:11566 [D loss: 0.654701, acc.: 60.94%] [G loss: 0.974179]\n",
      "epoch:12 step:11567 [D loss: 0.702850, acc.: 52.34%] [G loss: 0.944008]\n",
      "epoch:12 step:11568 [D loss: 0.666944, acc.: 59.38%] [G loss: 0.887083]\n",
      "epoch:12 step:11569 [D loss: 0.683594, acc.: 53.91%] [G loss: 0.898231]\n",
      "epoch:12 step:11570 [D loss: 0.641510, acc.: 66.41%] [G loss: 0.888237]\n",
      "epoch:12 step:11571 [D loss: 0.658116, acc.: 62.50%] [G loss: 0.959470]\n",
      "epoch:12 step:11572 [D loss: 0.608917, acc.: 64.84%] [G loss: 1.009323]\n",
      "epoch:12 step:11573 [D loss: 0.726787, acc.: 54.69%] [G loss: 0.947460]\n",
      "epoch:12 step:11574 [D loss: 0.659786, acc.: 57.81%] [G loss: 0.894357]\n",
      "epoch:12 step:11575 [D loss: 0.654626, acc.: 58.59%] [G loss: 0.894471]\n",
      "epoch:12 step:11576 [D loss: 0.623652, acc.: 66.41%] [G loss: 0.893739]\n",
      "epoch:12 step:11577 [D loss: 0.636788, acc.: 67.19%] [G loss: 0.911183]\n",
      "epoch:12 step:11578 [D loss: 0.633824, acc.: 65.62%] [G loss: 0.894105]\n",
      "epoch:12 step:11579 [D loss: 0.595205, acc.: 70.31%] [G loss: 0.937405]\n",
      "epoch:12 step:11580 [D loss: 0.660454, acc.: 67.19%] [G loss: 0.908390]\n",
      "epoch:12 step:11581 [D loss: 0.632361, acc.: 67.97%] [G loss: 0.940667]\n",
      "epoch:12 step:11582 [D loss: 0.641988, acc.: 64.06%] [G loss: 0.938232]\n",
      "epoch:12 step:11583 [D loss: 0.620880, acc.: 70.31%] [G loss: 0.877548]\n",
      "epoch:12 step:11584 [D loss: 0.638608, acc.: 61.72%] [G loss: 0.882155]\n",
      "epoch:12 step:11585 [D loss: 0.727794, acc.: 53.12%] [G loss: 0.861795]\n",
      "epoch:12 step:11586 [D loss: 0.700597, acc.: 51.56%] [G loss: 0.901462]\n",
      "epoch:12 step:11587 [D loss: 0.616889, acc.: 70.31%] [G loss: 0.920062]\n",
      "epoch:12 step:11588 [D loss: 0.630305, acc.: 60.16%] [G loss: 0.956299]\n",
      "epoch:12 step:11589 [D loss: 0.607019, acc.: 66.41%] [G loss: 0.960485]\n",
      "epoch:12 step:11590 [D loss: 0.597332, acc.: 68.75%] [G loss: 0.864775]\n",
      "epoch:12 step:11591 [D loss: 0.557296, acc.: 70.31%] [G loss: 1.020388]\n",
      "epoch:12 step:11592 [D loss: 0.732763, acc.: 56.25%] [G loss: 0.927571]\n",
      "epoch:12 step:11593 [D loss: 0.758431, acc.: 46.88%] [G loss: 0.886690]\n",
      "epoch:12 step:11594 [D loss: 0.645673, acc.: 60.94%] [G loss: 0.885360]\n",
      "epoch:12 step:11595 [D loss: 0.679391, acc.: 60.16%] [G loss: 0.908160]\n",
      "epoch:12 step:11596 [D loss: 0.654801, acc.: 59.38%] [G loss: 0.867649]\n",
      "epoch:12 step:11597 [D loss: 0.622325, acc.: 64.06%] [G loss: 0.943550]\n",
      "epoch:12 step:11598 [D loss: 0.628538, acc.: 63.28%] [G loss: 0.964350]\n",
      "epoch:12 step:11599 [D loss: 0.649535, acc.: 58.59%] [G loss: 0.943824]\n",
      "epoch:12 step:11600 [D loss: 0.665279, acc.: 59.38%] [G loss: 0.902140]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.076698\n",
      "FID: 6.974741\n",
      "0 = 11.792438302111586\n",
      "1 = 0.053802966258019835\n",
      "2 = 0.9214000105857849\n",
      "3 = 0.8712999820709229\n",
      "4 = 0.9714999794960022\n",
      "5 = 0.9683262705802917\n",
      "6 = 0.8712999820709229\n",
      "7 = 5.707944771867994\n",
      "8 = 0.05479420741853993\n",
      "9 = 0.7120500206947327\n",
      "10 = 0.6870999932289124\n",
      "11 = 0.7369999885559082\n",
      "12 = 0.7231870293617249\n",
      "13 = 0.6870999932289124\n",
      "14 = 8.076763153076172\n",
      "15 = 9.623941421508789\n",
      "16 = 0.08474323898553848\n",
      "17 = 8.076698303222656\n",
      "18 = 6.974740505218506\n",
      "epoch:12 step:11601 [D loss: 0.630989, acc.: 60.16%] [G loss: 0.898644]\n",
      "epoch:12 step:11602 [D loss: 0.630726, acc.: 64.84%] [G loss: 0.937722]\n",
      "epoch:12 step:11603 [D loss: 0.635947, acc.: 65.62%] [G loss: 0.945717]\n",
      "epoch:12 step:11604 [D loss: 0.649315, acc.: 61.72%] [G loss: 0.955516]\n",
      "epoch:12 step:11605 [D loss: 0.645955, acc.: 64.06%] [G loss: 0.961089]\n",
      "epoch:12 step:11606 [D loss: 0.680577, acc.: 53.91%] [G loss: 0.907421]\n",
      "epoch:12 step:11607 [D loss: 0.674777, acc.: 63.28%] [G loss: 0.908254]\n",
      "epoch:12 step:11608 [D loss: 0.667333, acc.: 58.59%] [G loss: 0.961113]\n",
      "epoch:12 step:11609 [D loss: 0.621833, acc.: 70.31%] [G loss: 0.881063]\n",
      "epoch:12 step:11610 [D loss: 0.641361, acc.: 60.94%] [G loss: 0.883157]\n",
      "epoch:12 step:11611 [D loss: 0.623556, acc.: 67.19%] [G loss: 0.933656]\n",
      "epoch:12 step:11612 [D loss: 0.662311, acc.: 60.94%] [G loss: 0.849440]\n",
      "epoch:12 step:11613 [D loss: 0.694581, acc.: 57.81%] [G loss: 0.838063]\n",
      "epoch:12 step:11614 [D loss: 0.634381, acc.: 64.84%] [G loss: 0.863743]\n",
      "epoch:12 step:11615 [D loss: 0.560772, acc.: 75.78%] [G loss: 0.998572]\n",
      "epoch:12 step:11616 [D loss: 0.661600, acc.: 66.41%] [G loss: 0.954960]\n",
      "epoch:12 step:11617 [D loss: 0.720042, acc.: 50.00%] [G loss: 0.892669]\n",
      "epoch:12 step:11618 [D loss: 0.593990, acc.: 74.22%] [G loss: 0.904750]\n",
      "epoch:12 step:11619 [D loss: 0.672681, acc.: 60.94%] [G loss: 0.937205]\n",
      "epoch:12 step:11620 [D loss: 0.723074, acc.: 48.44%] [G loss: 0.891947]\n",
      "epoch:12 step:11621 [D loss: 0.733225, acc.: 49.22%] [G loss: 0.858796]\n",
      "epoch:12 step:11622 [D loss: 0.728764, acc.: 46.88%] [G loss: 0.847854]\n",
      "epoch:12 step:11623 [D loss: 0.640333, acc.: 62.50%] [G loss: 0.851242]\n",
      "epoch:12 step:11624 [D loss: 0.669457, acc.: 60.16%] [G loss: 0.880486]\n",
      "epoch:12 step:11625 [D loss: 0.638883, acc.: 63.28%] [G loss: 0.901220]\n",
      "epoch:12 step:11626 [D loss: 0.649514, acc.: 60.16%] [G loss: 0.906193]\n",
      "epoch:12 step:11627 [D loss: 0.687113, acc.: 54.69%] [G loss: 0.878569]\n",
      "epoch:12 step:11628 [D loss: 0.658127, acc.: 56.25%] [G loss: 0.888682]\n",
      "epoch:12 step:11629 [D loss: 0.633542, acc.: 61.72%] [G loss: 0.886638]\n",
      "epoch:12 step:11630 [D loss: 0.681239, acc.: 55.47%] [G loss: 0.919852]\n",
      "epoch:12 step:11631 [D loss: 0.629175, acc.: 60.16%] [G loss: 0.883874]\n",
      "epoch:12 step:11632 [D loss: 0.669759, acc.: 56.25%] [G loss: 0.850180]\n",
      "epoch:12 step:11633 [D loss: 0.646751, acc.: 62.50%] [G loss: 0.938580]\n",
      "epoch:12 step:11634 [D loss: 0.663591, acc.: 61.72%] [G loss: 0.865878]\n",
      "epoch:12 step:11635 [D loss: 0.639717, acc.: 60.94%] [G loss: 0.913240]\n",
      "epoch:12 step:11636 [D loss: 0.635197, acc.: 66.41%] [G loss: 0.868601]\n",
      "epoch:12 step:11637 [D loss: 0.709940, acc.: 52.34%] [G loss: 0.881182]\n",
      "epoch:12 step:11638 [D loss: 0.705963, acc.: 50.00%] [G loss: 0.915432]\n",
      "epoch:12 step:11639 [D loss: 0.650007, acc.: 57.03%] [G loss: 0.911998]\n",
      "epoch:12 step:11640 [D loss: 0.684119, acc.: 50.78%] [G loss: 0.998576]\n",
      "epoch:12 step:11641 [D loss: 0.680103, acc.: 55.47%] [G loss: 0.941317]\n",
      "epoch:12 step:11642 [D loss: 0.628743, acc.: 61.72%] [G loss: 1.011637]\n",
      "epoch:12 step:11643 [D loss: 0.645290, acc.: 66.41%] [G loss: 0.974260]\n",
      "epoch:12 step:11644 [D loss: 0.685157, acc.: 57.81%] [G loss: 0.861495]\n",
      "epoch:12 step:11645 [D loss: 0.698075, acc.: 51.56%] [G loss: 0.905200]\n",
      "epoch:12 step:11646 [D loss: 0.663952, acc.: 59.38%] [G loss: 0.960457]\n",
      "epoch:12 step:11647 [D loss: 0.651713, acc.: 62.50%] [G loss: 0.942926]\n",
      "epoch:12 step:11648 [D loss: 0.647180, acc.: 67.19%] [G loss: 0.961565]\n",
      "epoch:12 step:11649 [D loss: 0.630003, acc.: 70.31%] [G loss: 0.848696]\n",
      "epoch:12 step:11650 [D loss: 0.621549, acc.: 67.19%] [G loss: 0.955958]\n",
      "epoch:12 step:11651 [D loss: 0.682082, acc.: 58.59%] [G loss: 0.941856]\n",
      "epoch:12 step:11652 [D loss: 0.674951, acc.: 55.47%] [G loss: 0.935558]\n",
      "epoch:12 step:11653 [D loss: 0.633832, acc.: 62.50%] [G loss: 0.884199]\n",
      "epoch:12 step:11654 [D loss: 0.679328, acc.: 57.81%] [G loss: 0.904754]\n",
      "epoch:12 step:11655 [D loss: 0.718827, acc.: 52.34%] [G loss: 0.849231]\n",
      "epoch:12 step:11656 [D loss: 0.653970, acc.: 57.81%] [G loss: 0.845762]\n",
      "epoch:12 step:11657 [D loss: 0.680170, acc.: 54.69%] [G loss: 0.881446]\n",
      "epoch:12 step:11658 [D loss: 0.647091, acc.: 58.59%] [G loss: 0.867595]\n",
      "epoch:12 step:11659 [D loss: 0.634851, acc.: 68.75%] [G loss: 0.955174]\n",
      "epoch:12 step:11660 [D loss: 0.610762, acc.: 71.09%] [G loss: 0.959369]\n",
      "epoch:12 step:11661 [D loss: 0.670808, acc.: 64.06%] [G loss: 0.921352]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11662 [D loss: 0.693485, acc.: 56.25%] [G loss: 0.917128]\n",
      "epoch:12 step:11663 [D loss: 0.672530, acc.: 57.81%] [G loss: 0.891312]\n",
      "epoch:12 step:11664 [D loss: 0.628600, acc.: 62.50%] [G loss: 0.937220]\n",
      "epoch:12 step:11665 [D loss: 0.721945, acc.: 50.78%] [G loss: 0.895648]\n",
      "epoch:12 step:11666 [D loss: 0.689100, acc.: 56.25%] [G loss: 0.863233]\n",
      "epoch:12 step:11667 [D loss: 0.703464, acc.: 55.47%] [G loss: 0.897213]\n",
      "epoch:12 step:11668 [D loss: 0.705393, acc.: 51.56%] [G loss: 0.901712]\n",
      "epoch:12 step:11669 [D loss: 0.647533, acc.: 60.16%] [G loss: 0.874174]\n",
      "epoch:12 step:11670 [D loss: 0.664354, acc.: 60.94%] [G loss: 0.903488]\n",
      "epoch:12 step:11671 [D loss: 0.581877, acc.: 71.09%] [G loss: 0.927966]\n",
      "epoch:12 step:11672 [D loss: 0.720618, acc.: 56.25%] [G loss: 0.833522]\n",
      "epoch:12 step:11673 [D loss: 0.669247, acc.: 58.59%] [G loss: 0.897433]\n",
      "epoch:12 step:11674 [D loss: 0.583349, acc.: 67.97%] [G loss: 0.899563]\n",
      "epoch:12 step:11675 [D loss: 0.717667, acc.: 52.34%] [G loss: 0.879044]\n",
      "epoch:12 step:11676 [D loss: 0.611700, acc.: 70.31%] [G loss: 0.888933]\n",
      "epoch:12 step:11677 [D loss: 0.640016, acc.: 60.94%] [G loss: 0.805540]\n",
      "epoch:12 step:11678 [D loss: 0.628469, acc.: 68.75%] [G loss: 0.885897]\n",
      "epoch:12 step:11679 [D loss: 0.689443, acc.: 53.91%] [G loss: 0.931734]\n",
      "epoch:12 step:11680 [D loss: 0.626106, acc.: 69.53%] [G loss: 0.977697]\n",
      "epoch:12 step:11681 [D loss: 0.756913, acc.: 50.00%] [G loss: 0.933115]\n",
      "epoch:12 step:11682 [D loss: 0.696476, acc.: 51.56%] [G loss: 0.933471]\n",
      "epoch:12 step:11683 [D loss: 0.638842, acc.: 68.75%] [G loss: 0.913789]\n",
      "epoch:12 step:11684 [D loss: 0.630092, acc.: 65.62%] [G loss: 0.935922]\n",
      "epoch:12 step:11685 [D loss: 0.592579, acc.: 71.09%] [G loss: 1.011675]\n",
      "epoch:12 step:11686 [D loss: 0.652051, acc.: 63.28%] [G loss: 0.951073]\n",
      "epoch:12 step:11687 [D loss: 0.662921, acc.: 57.03%] [G loss: 0.907101]\n",
      "epoch:12 step:11688 [D loss: 0.651289, acc.: 61.72%] [G loss: 0.991467]\n",
      "epoch:12 step:11689 [D loss: 0.593581, acc.: 67.19%] [G loss: 0.918491]\n",
      "epoch:12 step:11690 [D loss: 0.641729, acc.: 64.84%] [G loss: 0.945744]\n",
      "epoch:12 step:11691 [D loss: 0.605800, acc.: 65.62%] [G loss: 0.923756]\n",
      "epoch:12 step:11692 [D loss: 0.702840, acc.: 53.91%] [G loss: 0.855804]\n",
      "epoch:12 step:11693 [D loss: 0.670525, acc.: 62.50%] [G loss: 0.812375]\n",
      "epoch:12 step:11694 [D loss: 0.661895, acc.: 64.06%] [G loss: 0.844780]\n",
      "epoch:12 step:11695 [D loss: 0.644338, acc.: 62.50%] [G loss: 0.961809]\n",
      "epoch:12 step:11696 [D loss: 0.603480, acc.: 69.53%] [G loss: 0.936977]\n",
      "epoch:12 step:11697 [D loss: 0.630730, acc.: 67.97%] [G loss: 0.882652]\n",
      "epoch:12 step:11698 [D loss: 0.646340, acc.: 64.06%] [G loss: 0.899056]\n",
      "epoch:12 step:11699 [D loss: 0.696741, acc.: 55.47%] [G loss: 0.935483]\n",
      "epoch:12 step:11700 [D loss: 0.694001, acc.: 53.91%] [G loss: 0.920033]\n",
      "epoch:12 step:11701 [D loss: 0.637346, acc.: 66.41%] [G loss: 0.965166]\n",
      "epoch:12 step:11702 [D loss: 0.740229, acc.: 53.12%] [G loss: 0.909940]\n",
      "epoch:12 step:11703 [D loss: 0.668470, acc.: 59.38%] [G loss: 0.861089]\n",
      "epoch:12 step:11704 [D loss: 0.674219, acc.: 55.47%] [G loss: 0.895714]\n",
      "epoch:12 step:11705 [D loss: 0.686947, acc.: 57.81%] [G loss: 0.888723]\n",
      "epoch:12 step:11706 [D loss: 0.690913, acc.: 53.91%] [G loss: 0.867412]\n",
      "epoch:12 step:11707 [D loss: 0.658754, acc.: 62.50%] [G loss: 0.884453]\n",
      "epoch:12 step:11708 [D loss: 0.690200, acc.: 54.69%] [G loss: 0.897648]\n",
      "epoch:12 step:11709 [D loss: 0.651069, acc.: 63.28%] [G loss: 0.855273]\n",
      "epoch:12 step:11710 [D loss: 0.666587, acc.: 60.16%] [G loss: 0.818687]\n",
      "epoch:12 step:11711 [D loss: 0.604342, acc.: 65.62%] [G loss: 0.850085]\n",
      "epoch:12 step:11712 [D loss: 0.676409, acc.: 58.59%] [G loss: 0.938746]\n",
      "epoch:12 step:11713 [D loss: 0.651944, acc.: 61.72%] [G loss: 1.007871]\n",
      "epoch:12 step:11714 [D loss: 0.651406, acc.: 64.06%] [G loss: 1.035571]\n",
      "epoch:12 step:11715 [D loss: 0.570159, acc.: 71.88%] [G loss: 1.023376]\n",
      "epoch:12 step:11716 [D loss: 0.617180, acc.: 71.88%] [G loss: 0.988173]\n",
      "epoch:12 step:11717 [D loss: 0.695952, acc.: 59.38%] [G loss: 0.972551]\n",
      "epoch:12 step:11718 [D loss: 0.644647, acc.: 64.84%] [G loss: 0.991461]\n",
      "epoch:12 step:11719 [D loss: 0.631603, acc.: 60.16%] [G loss: 0.993534]\n",
      "epoch:12 step:11720 [D loss: 0.685824, acc.: 57.81%] [G loss: 0.968208]\n",
      "epoch:12 step:11721 [D loss: 0.732718, acc.: 47.66%] [G loss: 0.847060]\n",
      "epoch:12 step:11722 [D loss: 0.701681, acc.: 53.91%] [G loss: 0.840415]\n",
      "epoch:12 step:11723 [D loss: 0.660222, acc.: 64.06%] [G loss: 0.902887]\n",
      "epoch:12 step:11724 [D loss: 0.641878, acc.: 65.62%] [G loss: 0.815507]\n",
      "epoch:12 step:11725 [D loss: 0.619720, acc.: 68.75%] [G loss: 0.898871]\n",
      "epoch:12 step:11726 [D loss: 0.701238, acc.: 52.34%] [G loss: 0.846529]\n",
      "epoch:12 step:11727 [D loss: 0.663602, acc.: 57.03%] [G loss: 0.832328]\n",
      "epoch:12 step:11728 [D loss: 0.614041, acc.: 67.19%] [G loss: 0.895707]\n",
      "epoch:12 step:11729 [D loss: 0.680363, acc.: 56.25%] [G loss: 0.903381]\n",
      "epoch:12 step:11730 [D loss: 0.686595, acc.: 58.59%] [G loss: 0.909149]\n",
      "epoch:12 step:11731 [D loss: 0.682372, acc.: 57.81%] [G loss: 0.914707]\n",
      "epoch:12 step:11732 [D loss: 0.649001, acc.: 57.03%] [G loss: 0.946953]\n",
      "epoch:12 step:11733 [D loss: 0.662297, acc.: 67.97%] [G loss: 0.977929]\n",
      "epoch:12 step:11734 [D loss: 0.652849, acc.: 64.06%] [G loss: 0.871320]\n",
      "epoch:12 step:11735 [D loss: 0.676812, acc.: 55.47%] [G loss: 0.895908]\n",
      "epoch:12 step:11736 [D loss: 0.689803, acc.: 54.69%] [G loss: 0.867434]\n",
      "epoch:12 step:11737 [D loss: 0.648875, acc.: 68.75%] [G loss: 0.888154]\n",
      "epoch:12 step:11738 [D loss: 0.662808, acc.: 60.94%] [G loss: 0.905320]\n",
      "epoch:12 step:11739 [D loss: 0.652124, acc.: 65.62%] [G loss: 0.933822]\n",
      "epoch:12 step:11740 [D loss: 0.683626, acc.: 60.16%] [G loss: 0.971466]\n",
      "epoch:12 step:11741 [D loss: 0.633072, acc.: 67.19%] [G loss: 0.881475]\n",
      "epoch:12 step:11742 [D loss: 0.613290, acc.: 67.19%] [G loss: 0.932180]\n",
      "epoch:12 step:11743 [D loss: 0.581120, acc.: 77.34%] [G loss: 0.945513]\n",
      "epoch:12 step:11744 [D loss: 0.711448, acc.: 55.47%] [G loss: 0.937453]\n",
      "epoch:12 step:11745 [D loss: 0.720549, acc.: 56.25%] [G loss: 0.861400]\n",
      "epoch:12 step:11746 [D loss: 0.688690, acc.: 53.91%] [G loss: 0.865339]\n",
      "epoch:12 step:11747 [D loss: 0.675307, acc.: 54.69%] [G loss: 0.840967]\n",
      "epoch:12 step:11748 [D loss: 0.600771, acc.: 70.31%] [G loss: 0.894028]\n",
      "epoch:12 step:11749 [D loss: 0.568235, acc.: 71.88%] [G loss: 0.937581]\n",
      "epoch:12 step:11750 [D loss: 0.640948, acc.: 60.16%] [G loss: 0.972888]\n",
      "epoch:12 step:11751 [D loss: 0.623782, acc.: 63.28%] [G loss: 0.978468]\n",
      "epoch:12 step:11752 [D loss: 0.556865, acc.: 75.78%] [G loss: 1.053821]\n",
      "epoch:12 step:11753 [D loss: 0.739968, acc.: 46.88%] [G loss: 1.096588]\n",
      "epoch:12 step:11754 [D loss: 0.696235, acc.: 51.56%] [G loss: 0.900867]\n",
      "epoch:12 step:11755 [D loss: 0.712501, acc.: 50.00%] [G loss: 0.902181]\n",
      "epoch:12 step:11756 [D loss: 0.667007, acc.: 58.59%] [G loss: 0.865064]\n",
      "epoch:12 step:11757 [D loss: 0.641889, acc.: 62.50%] [G loss: 0.843185]\n",
      "epoch:12 step:11758 [D loss: 0.621689, acc.: 62.50%] [G loss: 0.842363]\n",
      "epoch:12 step:11759 [D loss: 0.584599, acc.: 71.88%] [G loss: 0.889446]\n",
      "epoch:12 step:11760 [D loss: 0.617696, acc.: 66.41%] [G loss: 0.892621]\n",
      "epoch:12 step:11761 [D loss: 0.732962, acc.: 51.56%] [G loss: 0.870504]\n",
      "epoch:12 step:11762 [D loss: 0.682999, acc.: 57.03%] [G loss: 0.820204]\n",
      "epoch:12 step:11763 [D loss: 0.625954, acc.: 64.84%] [G loss: 0.906898]\n",
      "epoch:12 step:11764 [D loss: 0.607924, acc.: 67.97%] [G loss: 0.968463]\n",
      "epoch:12 step:11765 [D loss: 0.661506, acc.: 60.94%] [G loss: 0.959702]\n",
      "epoch:12 step:11766 [D loss: 0.627015, acc.: 64.06%] [G loss: 0.839977]\n",
      "epoch:12 step:11767 [D loss: 0.603115, acc.: 64.06%] [G loss: 0.963945]\n",
      "epoch:12 step:11768 [D loss: 0.680773, acc.: 60.94%] [G loss: 0.880406]\n",
      "epoch:12 step:11769 [D loss: 0.724070, acc.: 56.25%] [G loss: 0.889584]\n",
      "epoch:12 step:11770 [D loss: 0.621422, acc.: 66.41%] [G loss: 0.952592]\n",
      "epoch:12 step:11771 [D loss: 0.704505, acc.: 55.47%] [G loss: 0.896284]\n",
      "epoch:12 step:11772 [D loss: 0.704274, acc.: 53.91%] [G loss: 0.882606]\n",
      "epoch:12 step:11773 [D loss: 0.667708, acc.: 57.03%] [G loss: 0.911931]\n",
      "epoch:12 step:11774 [D loss: 0.644314, acc.: 63.28%] [G loss: 0.914740]\n",
      "epoch:12 step:11775 [D loss: 0.705687, acc.: 52.34%] [G loss: 0.845271]\n",
      "epoch:12 step:11776 [D loss: 0.713718, acc.: 53.91%] [G loss: 0.836571]\n",
      "epoch:12 step:11777 [D loss: 0.713185, acc.: 53.12%] [G loss: 0.874648]\n",
      "epoch:12 step:11778 [D loss: 0.569420, acc.: 77.34%] [G loss: 0.908953]\n",
      "epoch:12 step:11779 [D loss: 0.681725, acc.: 56.25%] [G loss: 0.894004]\n",
      "epoch:12 step:11780 [D loss: 0.641365, acc.: 67.97%] [G loss: 0.838434]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11781 [D loss: 0.682025, acc.: 62.50%] [G loss: 0.878140]\n",
      "epoch:12 step:11782 [D loss: 0.677560, acc.: 57.03%] [G loss: 0.931266]\n",
      "epoch:12 step:11783 [D loss: 0.669647, acc.: 53.91%] [G loss: 0.863064]\n",
      "epoch:12 step:11784 [D loss: 0.693579, acc.: 57.03%] [G loss: 0.920469]\n",
      "epoch:12 step:11785 [D loss: 0.616463, acc.: 68.75%] [G loss: 0.872442]\n",
      "epoch:12 step:11786 [D loss: 0.766694, acc.: 40.62%] [G loss: 0.925048]\n",
      "epoch:12 step:11787 [D loss: 0.699272, acc.: 51.56%] [G loss: 0.877163]\n",
      "epoch:12 step:11788 [D loss: 0.657464, acc.: 60.94%] [G loss: 0.898386]\n",
      "epoch:12 step:11789 [D loss: 0.638113, acc.: 64.06%] [G loss: 0.893757]\n",
      "epoch:12 step:11790 [D loss: 0.670498, acc.: 57.03%] [G loss: 0.894338]\n",
      "epoch:12 step:11791 [D loss: 0.638190, acc.: 63.28%] [G loss: 0.942745]\n",
      "epoch:12 step:11792 [D loss: 0.636505, acc.: 59.38%] [G loss: 0.931495]\n",
      "epoch:12 step:11793 [D loss: 0.629283, acc.: 64.84%] [G loss: 0.881449]\n",
      "epoch:12 step:11794 [D loss: 0.678454, acc.: 60.94%] [G loss: 0.926578]\n",
      "epoch:12 step:11795 [D loss: 0.610224, acc.: 66.41%] [G loss: 0.889033]\n",
      "epoch:12 step:11796 [D loss: 0.642071, acc.: 64.06%] [G loss: 0.884197]\n",
      "epoch:12 step:11797 [D loss: 0.672094, acc.: 60.16%] [G loss: 0.871254]\n",
      "epoch:12 step:11798 [D loss: 0.614528, acc.: 71.09%] [G loss: 0.890944]\n",
      "epoch:12 step:11799 [D loss: 0.640460, acc.: 60.16%] [G loss: 0.882229]\n",
      "epoch:12 step:11800 [D loss: 0.639936, acc.: 64.06%] [G loss: 0.880533]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.998057\n",
      "FID: 8.409129\n",
      "0 = 11.863513076806083\n",
      "1 = 0.054462515022743296\n",
      "2 = 0.9247999787330627\n",
      "3 = 0.880299985408783\n",
      "4 = 0.9692999720573425\n",
      "5 = 0.9663007855415344\n",
      "6 = 0.880299985408783\n",
      "7 = 5.994447498393047\n",
      "8 = 0.06383051854925355\n",
      "9 = 0.7124000191688538\n",
      "10 = 0.6884999871253967\n",
      "11 = 0.736299991607666\n",
      "12 = 0.7230623960494995\n",
      "13 = 0.6884999871253967\n",
      "14 = 7.9981255531311035\n",
      "15 = 9.603459358215332\n",
      "16 = 0.0872824639081955\n",
      "17 = 7.9980573654174805\n",
      "18 = 8.40912914276123\n",
      "epoch:12 step:11801 [D loss: 0.625556, acc.: 66.41%] [G loss: 0.918033]\n",
      "epoch:12 step:11802 [D loss: 0.706869, acc.: 53.91%] [G loss: 0.907285]\n",
      "epoch:12 step:11803 [D loss: 0.706965, acc.: 52.34%] [G loss: 0.895864]\n",
      "epoch:12 step:11804 [D loss: 0.698533, acc.: 53.12%] [G loss: 0.915991]\n",
      "epoch:12 step:11805 [D loss: 0.617216, acc.: 70.31%] [G loss: 0.880931]\n",
      "epoch:12 step:11806 [D loss: 0.628093, acc.: 64.06%] [G loss: 0.854611]\n",
      "epoch:12 step:11807 [D loss: 0.598752, acc.: 71.09%] [G loss: 0.956098]\n",
      "epoch:12 step:11808 [D loss: 0.585804, acc.: 73.44%] [G loss: 1.035673]\n",
      "epoch:12 step:11809 [D loss: 0.754314, acc.: 46.09%] [G loss: 0.934358]\n",
      "epoch:12 step:11810 [D loss: 0.752517, acc.: 46.88%] [G loss: 0.926024]\n",
      "epoch:12 step:11811 [D loss: 0.634043, acc.: 66.41%] [G loss: 0.970822]\n",
      "epoch:12 step:11812 [D loss: 0.637027, acc.: 62.50%] [G loss: 0.959083]\n",
      "epoch:12 step:11813 [D loss: 0.715063, acc.: 52.34%] [G loss: 0.905301]\n",
      "epoch:12 step:11814 [D loss: 0.655942, acc.: 59.38%] [G loss: 0.886941]\n",
      "epoch:12 step:11815 [D loss: 0.632639, acc.: 65.62%] [G loss: 0.832055]\n",
      "epoch:12 step:11816 [D loss: 0.649049, acc.: 66.41%] [G loss: 0.936727]\n",
      "epoch:12 step:11817 [D loss: 0.655343, acc.: 57.03%] [G loss: 0.905674]\n",
      "epoch:12 step:11818 [D loss: 0.567352, acc.: 72.66%] [G loss: 0.968168]\n",
      "epoch:12 step:11819 [D loss: 0.607358, acc.: 64.84%] [G loss: 1.004464]\n",
      "epoch:12 step:11820 [D loss: 0.700290, acc.: 50.78%] [G loss: 0.960178]\n",
      "epoch:12 step:11821 [D loss: 0.687632, acc.: 53.91%] [G loss: 0.926365]\n",
      "epoch:12 step:11822 [D loss: 0.665563, acc.: 60.16%] [G loss: 0.928384]\n",
      "epoch:12 step:11823 [D loss: 0.662525, acc.: 59.38%] [G loss: 0.852644]\n",
      "epoch:12 step:11824 [D loss: 0.683469, acc.: 56.25%] [G loss: 0.887795]\n",
      "epoch:12 step:11825 [D loss: 0.623318, acc.: 60.16%] [G loss: 0.923514]\n",
      "epoch:12 step:11826 [D loss: 0.644817, acc.: 60.94%] [G loss: 0.968954]\n",
      "epoch:12 step:11827 [D loss: 0.633830, acc.: 60.16%] [G loss: 0.939124]\n",
      "epoch:12 step:11828 [D loss: 0.670499, acc.: 58.59%] [G loss: 0.941726]\n",
      "epoch:12 step:11829 [D loss: 0.652018, acc.: 61.72%] [G loss: 0.899280]\n",
      "epoch:12 step:11830 [D loss: 0.659557, acc.: 58.59%] [G loss: 0.895110]\n",
      "epoch:12 step:11831 [D loss: 0.683664, acc.: 55.47%] [G loss: 0.838616]\n",
      "epoch:12 step:11832 [D loss: 0.666468, acc.: 57.03%] [G loss: 0.855302]\n",
      "epoch:12 step:11833 [D loss: 0.609885, acc.: 68.75%] [G loss: 0.960192]\n",
      "epoch:12 step:11834 [D loss: 0.699157, acc.: 59.38%] [G loss: 0.897157]\n",
      "epoch:12 step:11835 [D loss: 0.698778, acc.: 54.69%] [G loss: 0.865512]\n",
      "epoch:12 step:11836 [D loss: 0.620039, acc.: 67.97%] [G loss: 0.847432]\n",
      "epoch:12 step:11837 [D loss: 0.600939, acc.: 69.53%] [G loss: 0.876435]\n",
      "epoch:12 step:11838 [D loss: 0.704490, acc.: 51.56%] [G loss: 0.888258]\n",
      "epoch:12 step:11839 [D loss: 0.630677, acc.: 64.06%] [G loss: 0.874243]\n",
      "epoch:12 step:11840 [D loss: 0.680245, acc.: 57.81%] [G loss: 0.856718]\n",
      "epoch:12 step:11841 [D loss: 0.653647, acc.: 67.97%] [G loss: 0.853145]\n",
      "epoch:12 step:11842 [D loss: 0.640229, acc.: 66.41%] [G loss: 0.929634]\n",
      "epoch:12 step:11843 [D loss: 0.678981, acc.: 57.03%] [G loss: 0.904823]\n",
      "epoch:12 step:11844 [D loss: 0.672802, acc.: 57.03%] [G loss: 0.899124]\n",
      "epoch:12 step:11845 [D loss: 0.664189, acc.: 56.25%] [G loss: 0.916720]\n",
      "epoch:12 step:11846 [D loss: 0.654571, acc.: 53.12%] [G loss: 0.877000]\n",
      "epoch:12 step:11847 [D loss: 0.679614, acc.: 60.94%] [G loss: 0.873318]\n",
      "epoch:12 step:11848 [D loss: 0.659729, acc.: 59.38%] [G loss: 0.909971]\n",
      "epoch:12 step:11849 [D loss: 0.651075, acc.: 62.50%] [G loss: 0.930137]\n",
      "epoch:12 step:11850 [D loss: 0.624872, acc.: 61.72%] [G loss: 0.896791]\n",
      "epoch:12 step:11851 [D loss: 0.673420, acc.: 59.38%] [G loss: 0.860877]\n",
      "epoch:12 step:11852 [D loss: 0.655818, acc.: 60.94%] [G loss: 0.895926]\n",
      "epoch:12 step:11853 [D loss: 0.632552, acc.: 69.53%] [G loss: 0.860113]\n",
      "epoch:12 step:11854 [D loss: 0.646912, acc.: 57.03%] [G loss: 0.886679]\n",
      "epoch:12 step:11855 [D loss: 0.643013, acc.: 63.28%] [G loss: 0.935114]\n",
      "epoch:12 step:11856 [D loss: 0.649395, acc.: 60.94%] [G loss: 0.865353]\n",
      "epoch:12 step:11857 [D loss: 0.632752, acc.: 69.53%] [G loss: 0.911410]\n",
      "epoch:12 step:11858 [D loss: 0.704803, acc.: 52.34%] [G loss: 0.858202]\n",
      "epoch:12 step:11859 [D loss: 0.720050, acc.: 50.78%] [G loss: 0.889035]\n",
      "epoch:12 step:11860 [D loss: 0.681766, acc.: 53.12%] [G loss: 0.928044]\n",
      "epoch:12 step:11861 [D loss: 0.641916, acc.: 64.84%] [G loss: 0.952359]\n",
      "epoch:12 step:11862 [D loss: 0.658452, acc.: 60.16%] [G loss: 0.951688]\n",
      "epoch:12 step:11863 [D loss: 0.669479, acc.: 62.50%] [G loss: 0.910127]\n",
      "epoch:12 step:11864 [D loss: 0.638807, acc.: 64.84%] [G loss: 0.938823]\n",
      "epoch:12 step:11865 [D loss: 0.708843, acc.: 53.12%] [G loss: 0.874588]\n",
      "epoch:12 step:11866 [D loss: 0.673062, acc.: 55.47%] [G loss: 0.904040]\n",
      "epoch:12 step:11867 [D loss: 0.685504, acc.: 55.47%] [G loss: 0.869893]\n",
      "epoch:12 step:11868 [D loss: 0.639975, acc.: 64.06%] [G loss: 0.949722]\n",
      "epoch:12 step:11869 [D loss: 0.670629, acc.: 64.06%] [G loss: 0.909084]\n",
      "epoch:12 step:11870 [D loss: 0.665842, acc.: 60.16%] [G loss: 0.900591]\n",
      "epoch:12 step:11871 [D loss: 0.620867, acc.: 67.19%] [G loss: 0.881943]\n",
      "epoch:12 step:11872 [D loss: 0.711920, acc.: 54.69%] [G loss: 0.812449]\n",
      "epoch:12 step:11873 [D loss: 0.648644, acc.: 61.72%] [G loss: 0.853264]\n",
      "epoch:12 step:11874 [D loss: 0.673043, acc.: 60.16%] [G loss: 0.908064]\n",
      "epoch:12 step:11875 [D loss: 0.630823, acc.: 64.84%] [G loss: 0.875926]\n",
      "epoch:12 step:11876 [D loss: 0.645466, acc.: 66.41%] [G loss: 0.975425]\n",
      "epoch:12 step:11877 [D loss: 0.652499, acc.: 62.50%] [G loss: 0.954004]\n",
      "epoch:12 step:11878 [D loss: 0.583701, acc.: 73.44%] [G loss: 0.929381]\n",
      "epoch:12 step:11879 [D loss: 0.652744, acc.: 63.28%] [G loss: 0.980392]\n",
      "epoch:12 step:11880 [D loss: 0.671140, acc.: 60.94%] [G loss: 0.948638]\n",
      "epoch:12 step:11881 [D loss: 0.663273, acc.: 60.94%] [G loss: 0.902452]\n",
      "epoch:12 step:11882 [D loss: 0.674914, acc.: 60.16%] [G loss: 0.915159]\n",
      "epoch:12 step:11883 [D loss: 0.658182, acc.: 60.94%] [G loss: 0.862423]\n",
      "epoch:12 step:11884 [D loss: 0.633715, acc.: 64.06%] [G loss: 0.943156]\n",
      "epoch:12 step:11885 [D loss: 0.644600, acc.: 66.41%] [G loss: 0.939949]\n",
      "epoch:12 step:11886 [D loss: 0.616523, acc.: 64.84%] [G loss: 0.983168]\n",
      "epoch:12 step:11887 [D loss: 0.640718, acc.: 60.16%] [G loss: 0.970778]\n",
      "epoch:12 step:11888 [D loss: 0.685025, acc.: 58.59%] [G loss: 0.916903]\n",
      "epoch:12 step:11889 [D loss: 0.675411, acc.: 56.25%] [G loss: 0.810812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11890 [D loss: 0.653871, acc.: 64.06%] [G loss: 0.866031]\n",
      "epoch:12 step:11891 [D loss: 0.612981, acc.: 68.75%] [G loss: 0.858408]\n",
      "epoch:12 step:11892 [D loss: 0.573178, acc.: 68.75%] [G loss: 0.961772]\n",
      "epoch:12 step:11893 [D loss: 0.608607, acc.: 67.97%] [G loss: 0.920294]\n",
      "epoch:12 step:11894 [D loss: 0.622556, acc.: 65.62%] [G loss: 0.918194]\n",
      "epoch:12 step:11895 [D loss: 0.637848, acc.: 59.38%] [G loss: 0.993094]\n",
      "epoch:12 step:11896 [D loss: 0.662180, acc.: 57.03%] [G loss: 0.927296]\n",
      "epoch:12 step:11897 [D loss: 0.675292, acc.: 56.25%] [G loss: 0.981552]\n",
      "epoch:12 step:11898 [D loss: 0.660831, acc.: 60.16%] [G loss: 0.940265]\n",
      "epoch:12 step:11899 [D loss: 0.688605, acc.: 56.25%] [G loss: 0.932459]\n",
      "epoch:12 step:11900 [D loss: 0.675774, acc.: 60.94%] [G loss: 0.851331]\n",
      "epoch:12 step:11901 [D loss: 0.704755, acc.: 53.12%] [G loss: 0.954637]\n",
      "epoch:12 step:11902 [D loss: 0.624384, acc.: 64.84%] [G loss: 1.010267]\n",
      "epoch:12 step:11903 [D loss: 0.654154, acc.: 56.25%] [G loss: 0.975208]\n",
      "epoch:12 step:11904 [D loss: 0.628720, acc.: 64.06%] [G loss: 0.929072]\n",
      "epoch:12 step:11905 [D loss: 0.619592, acc.: 68.75%] [G loss: 0.962718]\n",
      "epoch:12 step:11906 [D loss: 0.659767, acc.: 58.59%] [G loss: 0.919609]\n",
      "epoch:12 step:11907 [D loss: 0.729752, acc.: 57.03%] [G loss: 0.925043]\n",
      "epoch:12 step:11908 [D loss: 0.648581, acc.: 60.94%] [G loss: 0.932159]\n",
      "epoch:12 step:11909 [D loss: 0.636057, acc.: 64.06%] [G loss: 0.908912]\n",
      "epoch:12 step:11910 [D loss: 0.631636, acc.: 64.84%] [G loss: 1.012834]\n",
      "epoch:12 step:11911 [D loss: 0.685362, acc.: 60.94%] [G loss: 0.895275]\n",
      "epoch:12 step:11912 [D loss: 0.641929, acc.: 61.72%] [G loss: 0.924287]\n",
      "epoch:12 step:11913 [D loss: 0.623453, acc.: 68.75%] [G loss: 0.938361]\n",
      "epoch:12 step:11914 [D loss: 0.668147, acc.: 62.50%] [G loss: 0.872235]\n",
      "epoch:12 step:11915 [D loss: 0.653205, acc.: 63.28%] [G loss: 0.821120]\n",
      "epoch:12 step:11916 [D loss: 0.714279, acc.: 53.91%] [G loss: 0.851401]\n",
      "epoch:12 step:11917 [D loss: 0.678004, acc.: 60.16%] [G loss: 0.870220]\n",
      "epoch:12 step:11918 [D loss: 0.631303, acc.: 71.09%] [G loss: 0.973140]\n",
      "epoch:12 step:11919 [D loss: 0.686111, acc.: 57.03%] [G loss: 0.863998]\n",
      "epoch:12 step:11920 [D loss: 0.650800, acc.: 62.50%] [G loss: 0.872735]\n",
      "epoch:12 step:11921 [D loss: 0.611707, acc.: 70.31%] [G loss: 0.934933]\n",
      "epoch:12 step:11922 [D loss: 0.638942, acc.: 65.62%] [G loss: 0.855614]\n",
      "epoch:12 step:11923 [D loss: 0.668026, acc.: 63.28%] [G loss: 0.869970]\n",
      "epoch:12 step:11924 [D loss: 0.645381, acc.: 58.59%] [G loss: 0.905182]\n",
      "epoch:12 step:11925 [D loss: 0.610645, acc.: 72.66%] [G loss: 0.954739]\n",
      "epoch:12 step:11926 [D loss: 0.697515, acc.: 53.91%] [G loss: 0.954720]\n",
      "epoch:12 step:11927 [D loss: 0.676613, acc.: 60.94%] [G loss: 0.932912]\n",
      "epoch:12 step:11928 [D loss: 0.686534, acc.: 58.59%] [G loss: 0.898436]\n",
      "epoch:12 step:11929 [D loss: 0.650709, acc.: 64.06%] [G loss: 0.896838]\n",
      "epoch:12 step:11930 [D loss: 0.668819, acc.: 66.41%] [G loss: 0.902362]\n",
      "epoch:12 step:11931 [D loss: 0.660925, acc.: 58.59%] [G loss: 0.895987]\n",
      "epoch:12 step:11932 [D loss: 0.596862, acc.: 70.31%] [G loss: 0.906027]\n",
      "epoch:12 step:11933 [D loss: 0.645137, acc.: 60.16%] [G loss: 0.929252]\n",
      "epoch:12 step:11934 [D loss: 0.627074, acc.: 60.94%] [G loss: 0.917084]\n",
      "epoch:12 step:11935 [D loss: 0.633817, acc.: 60.94%] [G loss: 0.986666]\n",
      "epoch:12 step:11936 [D loss: 0.665779, acc.: 60.16%] [G loss: 0.986607]\n",
      "epoch:12 step:11937 [D loss: 0.663609, acc.: 59.38%] [G loss: 0.917822]\n",
      "epoch:12 step:11938 [D loss: 0.599851, acc.: 64.84%] [G loss: 0.950142]\n",
      "epoch:12 step:11939 [D loss: 0.635599, acc.: 64.06%] [G loss: 0.918982]\n",
      "epoch:12 step:11940 [D loss: 0.672318, acc.: 59.38%] [G loss: 0.897902]\n",
      "epoch:12 step:11941 [D loss: 0.640861, acc.: 64.06%] [G loss: 0.908602]\n",
      "epoch:12 step:11942 [D loss: 0.704306, acc.: 59.38%] [G loss: 0.943649]\n",
      "epoch:12 step:11943 [D loss: 0.612642, acc.: 68.75%] [G loss: 0.938370]\n",
      "epoch:12 step:11944 [D loss: 0.581625, acc.: 68.75%] [G loss: 0.959857]\n",
      "epoch:12 step:11945 [D loss: 0.617785, acc.: 63.28%] [G loss: 0.931686]\n",
      "epoch:12 step:11946 [D loss: 0.666432, acc.: 64.84%] [G loss: 0.932237]\n",
      "epoch:12 step:11947 [D loss: 0.727668, acc.: 49.22%] [G loss: 0.901983]\n",
      "epoch:12 step:11948 [D loss: 0.674635, acc.: 57.03%] [G loss: 0.830850]\n",
      "epoch:12 step:11949 [D loss: 0.666948, acc.: 64.06%] [G loss: 0.887129]\n",
      "epoch:12 step:11950 [D loss: 0.645446, acc.: 64.84%] [G loss: 0.908017]\n",
      "epoch:12 step:11951 [D loss: 0.639832, acc.: 64.84%] [G loss: 0.933976]\n",
      "epoch:12 step:11952 [D loss: 0.606351, acc.: 67.97%] [G loss: 0.993731]\n",
      "epoch:12 step:11953 [D loss: 0.594407, acc.: 74.22%] [G loss: 0.971388]\n",
      "epoch:12 step:11954 [D loss: 0.684065, acc.: 56.25%] [G loss: 0.907043]\n",
      "epoch:12 step:11955 [D loss: 0.705862, acc.: 47.66%] [G loss: 0.805567]\n",
      "epoch:12 step:11956 [D loss: 0.650524, acc.: 55.47%] [G loss: 0.865542]\n",
      "epoch:12 step:11957 [D loss: 0.689374, acc.: 58.59%] [G loss: 0.919650]\n",
      "epoch:12 step:11958 [D loss: 0.639265, acc.: 65.62%] [G loss: 0.895172]\n",
      "epoch:12 step:11959 [D loss: 0.695519, acc.: 55.47%] [G loss: 0.890093]\n",
      "epoch:12 step:11960 [D loss: 0.696022, acc.: 59.38%] [G loss: 0.846492]\n",
      "epoch:12 step:11961 [D loss: 0.659882, acc.: 65.62%] [G loss: 0.826553]\n",
      "epoch:12 step:11962 [D loss: 0.654032, acc.: 59.38%] [G loss: 0.843585]\n",
      "epoch:12 step:11963 [D loss: 0.669734, acc.: 57.81%] [G loss: 0.907025]\n",
      "epoch:12 step:11964 [D loss: 0.685003, acc.: 58.59%] [G loss: 0.876367]\n",
      "epoch:12 step:11965 [D loss: 0.655801, acc.: 60.94%] [G loss: 0.981989]\n",
      "epoch:12 step:11966 [D loss: 0.725778, acc.: 50.00%] [G loss: 0.956791]\n",
      "epoch:12 step:11967 [D loss: 0.654569, acc.: 63.28%] [G loss: 0.909105]\n",
      "epoch:12 step:11968 [D loss: 0.633626, acc.: 65.62%] [G loss: 0.834180]\n",
      "epoch:12 step:11969 [D loss: 0.671456, acc.: 61.72%] [G loss: 0.914758]\n",
      "epoch:12 step:11970 [D loss: 0.660337, acc.: 57.03%] [G loss: 0.917877]\n",
      "epoch:12 step:11971 [D loss: 0.692017, acc.: 58.59%] [G loss: 0.884955]\n",
      "epoch:12 step:11972 [D loss: 0.717171, acc.: 51.56%] [G loss: 0.861290]\n",
      "epoch:12 step:11973 [D loss: 0.670537, acc.: 56.25%] [G loss: 0.844578]\n",
      "epoch:12 step:11974 [D loss: 0.640308, acc.: 66.41%] [G loss: 0.860354]\n",
      "epoch:12 step:11975 [D loss: 0.628582, acc.: 62.50%] [G loss: 0.889793]\n",
      "epoch:12 step:11976 [D loss: 0.652276, acc.: 60.94%] [G loss: 0.953318]\n",
      "epoch:12 step:11977 [D loss: 0.611294, acc.: 71.88%] [G loss: 0.925127]\n",
      "epoch:12 step:11978 [D loss: 0.649697, acc.: 60.94%] [G loss: 0.945569]\n",
      "epoch:12 step:11979 [D loss: 0.702291, acc.: 48.44%] [G loss: 0.853302]\n",
      "epoch:12 step:11980 [D loss: 0.668901, acc.: 62.50%] [G loss: 0.862626]\n",
      "epoch:12 step:11981 [D loss: 0.657330, acc.: 62.50%] [G loss: 0.879306]\n",
      "epoch:12 step:11982 [D loss: 0.691471, acc.: 54.69%] [G loss: 0.900843]\n",
      "epoch:12 step:11983 [D loss: 0.716175, acc.: 56.25%] [G loss: 0.877790]\n",
      "epoch:12 step:11984 [D loss: 0.678711, acc.: 62.50%] [G loss: 0.911982]\n",
      "epoch:12 step:11985 [D loss: 0.671161, acc.: 63.28%] [G loss: 0.870325]\n",
      "epoch:12 step:11986 [D loss: 0.650668, acc.: 58.59%] [G loss: 0.869477]\n",
      "epoch:12 step:11987 [D loss: 0.626464, acc.: 69.53%] [G loss: 0.936912]\n",
      "epoch:12 step:11988 [D loss: 0.664869, acc.: 62.50%] [G loss: 0.961967]\n",
      "epoch:12 step:11989 [D loss: 0.695258, acc.: 57.81%] [G loss: 0.895245]\n",
      "epoch:12 step:11990 [D loss: 0.669381, acc.: 63.28%] [G loss: 0.896149]\n",
      "epoch:12 step:11991 [D loss: 0.636354, acc.: 58.59%] [G loss: 0.934129]\n",
      "epoch:12 step:11992 [D loss: 0.651487, acc.: 57.81%] [G loss: 0.897547]\n",
      "epoch:12 step:11993 [D loss: 0.626560, acc.: 65.62%] [G loss: 0.942450]\n",
      "epoch:12 step:11994 [D loss: 0.657747, acc.: 64.06%] [G loss: 0.892594]\n",
      "epoch:12 step:11995 [D loss: 0.628997, acc.: 60.94%] [G loss: 0.905868]\n",
      "epoch:12 step:11996 [D loss: 0.691471, acc.: 55.47%] [G loss: 0.926874]\n",
      "epoch:12 step:11997 [D loss: 0.610750, acc.: 65.62%] [G loss: 0.926593]\n",
      "epoch:12 step:11998 [D loss: 0.614453, acc.: 67.19%] [G loss: 0.982764]\n",
      "epoch:12 step:11999 [D loss: 0.662594, acc.: 58.59%] [G loss: 0.910636]\n",
      "epoch:12 step:12000 [D loss: 0.613262, acc.: 67.19%] [G loss: 0.928456]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.115467\n",
      "FID: 6.155631\n",
      "0 = 11.703842882061036\n",
      "1 = 0.04921841091463057\n",
      "2 = 0.9161499738693237\n",
      "3 = 0.8672000169754028\n",
      "4 = 0.9650999903678894\n",
      "5 = 0.961312472820282\n",
      "6 = 0.8672000169754028\n",
      "7 = 5.618582173180586\n",
      "8 = 0.052290567738611037\n",
      "9 = 0.7045000195503235\n",
      "10 = 0.6858999729156494\n",
      "11 = 0.7231000065803528\n",
      "12 = 0.7124013304710388\n",
      "13 = 0.6858999729156494\n",
      "14 = 8.115544319152832\n",
      "15 = 9.610591888427734\n",
      "16 = 0.08784737437963486\n",
      "17 = 8.115467071533203\n",
      "18 = 6.155631065368652\n",
      "epoch:12 step:12001 [D loss: 0.706204, acc.: 50.78%] [G loss: 0.861973]\n",
      "epoch:12 step:12002 [D loss: 0.674303, acc.: 57.03%] [G loss: 0.871318]\n",
      "epoch:12 step:12003 [D loss: 0.710585, acc.: 52.34%] [G loss: 0.882520]\n",
      "epoch:12 step:12004 [D loss: 0.662005, acc.: 60.94%] [G loss: 0.858665]\n",
      "epoch:12 step:12005 [D loss: 0.647086, acc.: 62.50%] [G loss: 0.870730]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:12006 [D loss: 0.651518, acc.: 60.16%] [G loss: 0.830849]\n",
      "epoch:12 step:12007 [D loss: 0.646861, acc.: 64.84%] [G loss: 0.893705]\n",
      "epoch:12 step:12008 [D loss: 0.673902, acc.: 55.47%] [G loss: 0.894910]\n",
      "epoch:12 step:12009 [D loss: 0.736578, acc.: 46.09%] [G loss: 0.847488]\n",
      "epoch:12 step:12010 [D loss: 0.706743, acc.: 51.56%] [G loss: 0.885037]\n",
      "epoch:12 step:12011 [D loss: 0.629827, acc.: 67.19%] [G loss: 0.933720]\n",
      "epoch:12 step:12012 [D loss: 0.699852, acc.: 57.81%] [G loss: 1.002952]\n",
      "epoch:12 step:12013 [D loss: 0.653248, acc.: 63.28%] [G loss: 0.962195]\n",
      "epoch:12 step:12014 [D loss: 0.625110, acc.: 65.62%] [G loss: 0.939512]\n",
      "epoch:12 step:12015 [D loss: 0.683591, acc.: 55.47%] [G loss: 0.953452]\n",
      "epoch:12 step:12016 [D loss: 0.686143, acc.: 60.94%] [G loss: 0.870665]\n",
      "epoch:12 step:12017 [D loss: 0.662781, acc.: 61.72%] [G loss: 0.885282]\n",
      "epoch:12 step:12018 [D loss: 0.661401, acc.: 57.81%] [G loss: 0.890622]\n",
      "epoch:12 step:12019 [D loss: 0.609313, acc.: 68.75%] [G loss: 0.953830]\n",
      "epoch:12 step:12020 [D loss: 0.684267, acc.: 58.59%] [G loss: 0.976162]\n",
      "epoch:12 step:12021 [D loss: 0.658285, acc.: 60.94%] [G loss: 0.955301]\n",
      "epoch:12 step:12022 [D loss: 0.668619, acc.: 52.34%] [G loss: 0.932066]\n",
      "epoch:12 step:12023 [D loss: 0.685670, acc.: 57.03%] [G loss: 1.002996]\n",
      "epoch:12 step:12024 [D loss: 0.663842, acc.: 56.25%] [G loss: 0.849270]\n",
      "epoch:12 step:12025 [D loss: 0.593037, acc.: 70.31%] [G loss: 0.924221]\n",
      "epoch:12 step:12026 [D loss: 0.605527, acc.: 71.88%] [G loss: 0.971378]\n",
      "epoch:12 step:12027 [D loss: 0.715027, acc.: 57.81%] [G loss: 0.867973]\n",
      "epoch:12 step:12028 [D loss: 0.779251, acc.: 48.44%] [G loss: 0.888891]\n",
      "epoch:12 step:12029 [D loss: 0.676951, acc.: 57.81%] [G loss: 0.806252]\n",
      "epoch:12 step:12030 [D loss: 0.615959, acc.: 69.53%] [G loss: 0.887970]\n",
      "epoch:12 step:12031 [D loss: 0.675164, acc.: 60.16%] [G loss: 0.910961]\n",
      "epoch:12 step:12032 [D loss: 0.703812, acc.: 50.78%] [G loss: 0.836135]\n",
      "epoch:12 step:12033 [D loss: 0.612104, acc.: 68.75%] [G loss: 0.897690]\n",
      "epoch:12 step:12034 [D loss: 0.635894, acc.: 64.06%] [G loss: 0.881060]\n",
      "epoch:12 step:12035 [D loss: 0.750849, acc.: 45.31%] [G loss: 0.887226]\n",
      "epoch:12 step:12036 [D loss: 0.615773, acc.: 67.97%] [G loss: 0.868020]\n",
      "epoch:12 step:12037 [D loss: 0.625549, acc.: 60.94%] [G loss: 0.894626]\n",
      "epoch:12 step:12038 [D loss: 0.703720, acc.: 51.56%] [G loss: 0.890711]\n",
      "epoch:12 step:12039 [D loss: 0.668137, acc.: 56.25%] [G loss: 0.960930]\n",
      "epoch:12 step:12040 [D loss: 0.614068, acc.: 69.53%] [G loss: 0.940761]\n",
      "epoch:12 step:12041 [D loss: 0.685108, acc.: 55.47%] [G loss: 0.890717]\n",
      "epoch:12 step:12042 [D loss: 0.671031, acc.: 54.69%] [G loss: 0.847544]\n",
      "epoch:12 step:12043 [D loss: 0.643214, acc.: 62.50%] [G loss: 0.844410]\n",
      "epoch:12 step:12044 [D loss: 0.706490, acc.: 51.56%] [G loss: 0.882431]\n",
      "epoch:12 step:12045 [D loss: 0.589637, acc.: 70.31%] [G loss: 0.891870]\n",
      "epoch:12 step:12046 [D loss: 0.608464, acc.: 71.09%] [G loss: 0.897597]\n",
      "epoch:12 step:12047 [D loss: 0.615186, acc.: 67.19%] [G loss: 0.880805]\n",
      "epoch:12 step:12048 [D loss: 0.708141, acc.: 50.78%] [G loss: 0.857316]\n",
      "epoch:12 step:12049 [D loss: 0.685249, acc.: 56.25%] [G loss: 0.783323]\n",
      "epoch:12 step:12050 [D loss: 0.658517, acc.: 62.50%] [G loss: 0.842479]\n",
      "epoch:12 step:12051 [D loss: 0.634839, acc.: 64.84%] [G loss: 0.798485]\n",
      "epoch:12 step:12052 [D loss: 0.709477, acc.: 55.47%] [G loss: 0.847644]\n",
      "epoch:12 step:12053 [D loss: 0.691070, acc.: 54.69%] [G loss: 0.849364]\n",
      "epoch:12 step:12054 [D loss: 0.645950, acc.: 64.06%] [G loss: 0.879516]\n",
      "epoch:12 step:12055 [D loss: 0.703360, acc.: 53.91%] [G loss: 0.896273]\n",
      "epoch:12 step:12056 [D loss: 0.692184, acc.: 60.16%] [G loss: 0.900857]\n",
      "epoch:12 step:12057 [D loss: 0.688670, acc.: 59.38%] [G loss: 0.870038]\n",
      "epoch:12 step:12058 [D loss: 0.676688, acc.: 57.81%] [G loss: 0.977624]\n",
      "epoch:12 step:12059 [D loss: 0.662730, acc.: 60.16%] [G loss: 0.960822]\n",
      "epoch:12 step:12060 [D loss: 0.642607, acc.: 63.28%] [G loss: 0.964136]\n",
      "epoch:12 step:12061 [D loss: 0.719630, acc.: 55.47%] [G loss: 0.931069]\n",
      "epoch:12 step:12062 [D loss: 0.695924, acc.: 54.69%] [G loss: 0.938921]\n",
      "epoch:12 step:12063 [D loss: 0.652306, acc.: 61.72%] [G loss: 0.901303]\n",
      "epoch:12 step:12064 [D loss: 0.724524, acc.: 52.34%] [G loss: 0.866199]\n",
      "epoch:12 step:12065 [D loss: 0.698043, acc.: 53.12%] [G loss: 0.835871]\n",
      "epoch:12 step:12066 [D loss: 0.660207, acc.: 60.16%] [G loss: 0.834414]\n",
      "epoch:12 step:12067 [D loss: 0.647531, acc.: 60.94%] [G loss: 0.899719]\n",
      "epoch:12 step:12068 [D loss: 0.673471, acc.: 60.94%] [G loss: 0.901303]\n",
      "epoch:12 step:12069 [D loss: 0.656267, acc.: 60.16%] [G loss: 0.839797]\n",
      "epoch:12 step:12070 [D loss: 0.680881, acc.: 53.91%] [G loss: 0.883644]\n",
      "epoch:12 step:12071 [D loss: 0.682576, acc.: 56.25%] [G loss: 0.867086]\n",
      "epoch:12 step:12072 [D loss: 0.708368, acc.: 53.12%] [G loss: 0.888445]\n",
      "epoch:12 step:12073 [D loss: 0.671152, acc.: 63.28%] [G loss: 0.899830]\n",
      "epoch:12 step:12074 [D loss: 0.637415, acc.: 69.53%] [G loss: 0.886706]\n",
      "epoch:12 step:12075 [D loss: 0.698453, acc.: 55.47%] [G loss: 0.878912]\n",
      "epoch:12 step:12076 [D loss: 0.647309, acc.: 63.28%] [G loss: 0.848926]\n",
      "epoch:12 step:12077 [D loss: 0.679425, acc.: 56.25%] [G loss: 0.846123]\n",
      "epoch:12 step:12078 [D loss: 0.666560, acc.: 57.81%] [G loss: 0.847862]\n",
      "epoch:12 step:12079 [D loss: 0.641873, acc.: 61.72%] [G loss: 0.873538]\n",
      "epoch:12 step:12080 [D loss: 0.643904, acc.: 66.41%] [G loss: 0.868690]\n",
      "epoch:12 step:12081 [D loss: 0.631974, acc.: 64.84%] [G loss: 0.893848]\n",
      "epoch:12 step:12082 [D loss: 0.643628, acc.: 60.94%] [G loss: 0.873076]\n",
      "epoch:12 step:12083 [D loss: 0.685663, acc.: 53.12%] [G loss: 0.818372]\n",
      "epoch:12 step:12084 [D loss: 0.674130, acc.: 57.81%] [G loss: 0.964834]\n",
      "epoch:12 step:12085 [D loss: 0.680097, acc.: 54.69%] [G loss: 0.929880]\n",
      "epoch:12 step:12086 [D loss: 0.623822, acc.: 70.31%] [G loss: 0.953837]\n",
      "epoch:12 step:12087 [D loss: 0.662191, acc.: 61.72%] [G loss: 0.915306]\n",
      "epoch:12 step:12088 [D loss: 0.699520, acc.: 56.25%] [G loss: 0.922249]\n",
      "epoch:12 step:12089 [D loss: 0.644614, acc.: 60.16%] [G loss: 0.923432]\n",
      "epoch:12 step:12090 [D loss: 0.670977, acc.: 57.03%] [G loss: 0.913475]\n",
      "epoch:12 step:12091 [D loss: 0.652475, acc.: 60.94%] [G loss: 0.841315]\n",
      "epoch:12 step:12092 [D loss: 0.683515, acc.: 59.38%] [G loss: 0.875008]\n",
      "epoch:12 step:12093 [D loss: 0.633250, acc.: 63.28%] [G loss: 0.939241]\n",
      "epoch:12 step:12094 [D loss: 0.686886, acc.: 56.25%] [G loss: 0.882475]\n",
      "epoch:12 step:12095 [D loss: 0.675069, acc.: 58.59%] [G loss: 0.904186]\n",
      "epoch:12 step:12096 [D loss: 0.623237, acc.: 64.06%] [G loss: 0.840535]\n",
      "epoch:12 step:12097 [D loss: 0.619865, acc.: 64.84%] [G loss: 0.865028]\n",
      "epoch:12 step:12098 [D loss: 0.631021, acc.: 67.97%] [G loss: 0.889848]\n",
      "epoch:12 step:12099 [D loss: 0.658831, acc.: 58.59%] [G loss: 0.918983]\n",
      "epoch:12 step:12100 [D loss: 0.645422, acc.: 67.19%] [G loss: 0.922141]\n",
      "epoch:12 step:12101 [D loss: 0.640775, acc.: 64.84%] [G loss: 0.940354]\n",
      "epoch:12 step:12102 [D loss: 0.748519, acc.: 45.31%] [G loss: 0.855598]\n",
      "epoch:12 step:12103 [D loss: 0.706746, acc.: 53.91%] [G loss: 0.824024]\n",
      "epoch:12 step:12104 [D loss: 0.647959, acc.: 63.28%] [G loss: 0.898041]\n",
      "epoch:12 step:12105 [D loss: 0.713162, acc.: 51.56%] [G loss: 0.843488]\n",
      "epoch:12 step:12106 [D loss: 0.676966, acc.: 57.03%] [G loss: 0.828866]\n",
      "epoch:12 step:12107 [D loss: 0.632552, acc.: 63.28%] [G loss: 0.882833]\n",
      "epoch:12 step:12108 [D loss: 0.655986, acc.: 61.72%] [G loss: 0.830807]\n",
      "epoch:12 step:12109 [D loss: 0.690134, acc.: 58.59%] [G loss: 0.838174]\n",
      "epoch:12 step:12110 [D loss: 0.652021, acc.: 62.50%] [G loss: 0.857005]\n",
      "epoch:12 step:12111 [D loss: 0.661315, acc.: 56.25%] [G loss: 0.854615]\n",
      "epoch:12 step:12112 [D loss: 0.629835, acc.: 64.06%] [G loss: 0.940895]\n",
      "epoch:12 step:12113 [D loss: 0.642303, acc.: 59.38%] [G loss: 0.954336]\n",
      "epoch:12 step:12114 [D loss: 0.644979, acc.: 61.72%] [G loss: 0.929294]\n",
      "epoch:12 step:12115 [D loss: 0.629008, acc.: 67.97%] [G loss: 0.868922]\n",
      "epoch:12 step:12116 [D loss: 0.629900, acc.: 67.97%] [G loss: 0.849681]\n",
      "epoch:12 step:12117 [D loss: 0.665984, acc.: 63.28%] [G loss: 0.943437]\n",
      "epoch:12 step:12118 [D loss: 0.691106, acc.: 56.25%] [G loss: 0.902482]\n",
      "epoch:12 step:12119 [D loss: 0.627093, acc.: 71.88%] [G loss: 0.897891]\n",
      "epoch:12 step:12120 [D loss: 0.635538, acc.: 61.72%] [G loss: 0.926288]\n",
      "epoch:12 step:12121 [D loss: 0.695319, acc.: 60.16%] [G loss: 0.863835]\n",
      "epoch:12 step:12122 [D loss: 0.666996, acc.: 54.69%] [G loss: 0.862871]\n",
      "epoch:12 step:12123 [D loss: 0.675907, acc.: 60.16%] [G loss: 0.843843]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:12124 [D loss: 0.637386, acc.: 61.72%] [G loss: 0.867061]\n",
      "epoch:12 step:12125 [D loss: 0.646119, acc.: 57.81%] [G loss: 0.896948]\n",
      "epoch:12 step:12126 [D loss: 0.653589, acc.: 60.16%] [G loss: 0.908514]\n",
      "epoch:12 step:12127 [D loss: 0.666381, acc.: 64.06%] [G loss: 0.946092]\n",
      "epoch:12 step:12128 [D loss: 0.636547, acc.: 65.62%] [G loss: 0.871714]\n",
      "epoch:12 step:12129 [D loss: 0.649980, acc.: 61.72%] [G loss: 0.984949]\n",
      "epoch:12 step:12130 [D loss: 0.630283, acc.: 68.75%] [G loss: 0.963766]\n",
      "epoch:12 step:12131 [D loss: 0.659452, acc.: 63.28%] [G loss: 0.921125]\n",
      "epoch:12 step:12132 [D loss: 0.664413, acc.: 56.25%] [G loss: 0.921112]\n",
      "epoch:12 step:12133 [D loss: 0.636354, acc.: 65.62%] [G loss: 0.922049]\n",
      "epoch:12 step:12134 [D loss: 0.652126, acc.: 57.81%] [G loss: 0.940376]\n",
      "epoch:12 step:12135 [D loss: 0.748523, acc.: 46.09%] [G loss: 0.915449]\n",
      "epoch:12 step:12136 [D loss: 0.721398, acc.: 55.47%] [G loss: 0.975608]\n",
      "epoch:12 step:12137 [D loss: 0.633841, acc.: 64.06%] [G loss: 0.989311]\n",
      "epoch:12 step:12138 [D loss: 0.637012, acc.: 66.41%] [G loss: 0.970019]\n",
      "epoch:12 step:12139 [D loss: 0.679001, acc.: 56.25%] [G loss: 0.958372]\n",
      "epoch:12 step:12140 [D loss: 0.641193, acc.: 60.94%] [G loss: 0.989791]\n",
      "epoch:12 step:12141 [D loss: 0.632022, acc.: 62.50%] [G loss: 0.956278]\n",
      "epoch:12 step:12142 [D loss: 0.641955, acc.: 64.06%] [G loss: 0.966741]\n",
      "epoch:12 step:12143 [D loss: 0.633106, acc.: 64.84%] [G loss: 1.054377]\n",
      "epoch:12 step:12144 [D loss: 0.637472, acc.: 62.50%] [G loss: 0.974319]\n",
      "epoch:12 step:12145 [D loss: 0.632595, acc.: 66.41%] [G loss: 0.918562]\n",
      "epoch:12 step:12146 [D loss: 0.700203, acc.: 56.25%] [G loss: 0.897392]\n",
      "epoch:12 step:12147 [D loss: 0.628703, acc.: 68.75%] [G loss: 0.938925]\n",
      "epoch:12 step:12148 [D loss: 0.697440, acc.: 52.34%] [G loss: 0.839636]\n",
      "epoch:12 step:12149 [D loss: 0.679393, acc.: 56.25%] [G loss: 0.857357]\n",
      "epoch:12 step:12150 [D loss: 0.634647, acc.: 65.62%] [G loss: 0.870090]\n",
      "epoch:12 step:12151 [D loss: 0.682129, acc.: 54.69%] [G loss: 0.914480]\n",
      "epoch:12 step:12152 [D loss: 0.607200, acc.: 69.53%] [G loss: 0.953972]\n",
      "epoch:12 step:12153 [D loss: 0.623500, acc.: 64.06%] [G loss: 0.887903]\n",
      "epoch:12 step:12154 [D loss: 0.650303, acc.: 60.16%] [G loss: 0.881589]\n",
      "epoch:12 step:12155 [D loss: 0.664482, acc.: 60.94%] [G loss: 0.879107]\n",
      "epoch:12 step:12156 [D loss: 0.646906, acc.: 66.41%] [G loss: 0.980431]\n",
      "epoch:12 step:12157 [D loss: 0.673179, acc.: 59.38%] [G loss: 0.917364]\n",
      "epoch:12 step:12158 [D loss: 0.623929, acc.: 63.28%] [G loss: 0.902464]\n",
      "epoch:12 step:12159 [D loss: 0.684934, acc.: 54.69%] [G loss: 0.863437]\n",
      "epoch:12 step:12160 [D loss: 0.658307, acc.: 57.03%] [G loss: 0.886216]\n",
      "epoch:12 step:12161 [D loss: 0.620771, acc.: 65.62%] [G loss: 0.838719]\n",
      "epoch:12 step:12162 [D loss: 0.607637, acc.: 71.09%] [G loss: 0.911985]\n",
      "epoch:12 step:12163 [D loss: 0.588740, acc.: 68.75%] [G loss: 1.055158]\n",
      "epoch:12 step:12164 [D loss: 0.803932, acc.: 42.97%] [G loss: 0.939230]\n",
      "epoch:12 step:12165 [D loss: 0.642870, acc.: 65.62%] [G loss: 1.009540]\n",
      "epoch:12 step:12166 [D loss: 0.649300, acc.: 64.06%] [G loss: 0.923662]\n",
      "epoch:12 step:12167 [D loss: 0.610338, acc.: 70.31%] [G loss: 0.939425]\n",
      "epoch:12 step:12168 [D loss: 0.624040, acc.: 62.50%] [G loss: 0.943953]\n",
      "epoch:12 step:12169 [D loss: 0.571326, acc.: 75.78%] [G loss: 1.024823]\n",
      "epoch:12 step:12170 [D loss: 0.609049, acc.: 64.84%] [G loss: 0.991136]\n",
      "epoch:12 step:12171 [D loss: 0.650295, acc.: 67.19%] [G loss: 1.034352]\n",
      "epoch:12 step:12172 [D loss: 0.780865, acc.: 53.12%] [G loss: 1.081160]\n",
      "epoch:12 step:12173 [D loss: 0.580537, acc.: 71.88%] [G loss: 1.134226]\n",
      "epoch:12 step:12174 [D loss: 0.622243, acc.: 67.19%] [G loss: 1.062415]\n",
      "epoch:12 step:12175 [D loss: 0.683551, acc.: 57.81%] [G loss: 0.921156]\n",
      "epoch:12 step:12176 [D loss: 0.713953, acc.: 53.12%] [G loss: 0.797319]\n",
      "epoch:12 step:12177 [D loss: 0.631699, acc.: 65.62%] [G loss: 0.897696]\n",
      "epoch:12 step:12178 [D loss: 0.635768, acc.: 67.19%] [G loss: 0.922573]\n",
      "epoch:12 step:12179 [D loss: 0.566594, acc.: 74.22%] [G loss: 0.996131]\n",
      "epoch:12 step:12180 [D loss: 0.518846, acc.: 78.91%] [G loss: 1.020152]\n",
      "epoch:12 step:12181 [D loss: 0.649459, acc.: 64.06%] [G loss: 1.096122]\n",
      "epoch:13 step:12182 [D loss: 0.664724, acc.: 58.59%] [G loss: 1.043030]\n",
      "epoch:13 step:12183 [D loss: 0.749922, acc.: 54.69%] [G loss: 0.935265]\n",
      "epoch:13 step:12184 [D loss: 0.722523, acc.: 53.91%] [G loss: 0.948151]\n",
      "epoch:13 step:12185 [D loss: 0.687175, acc.: 52.34%] [G loss: 0.846366]\n",
      "epoch:13 step:12186 [D loss: 0.709483, acc.: 53.91%] [G loss: 0.821064]\n",
      "epoch:13 step:12187 [D loss: 0.701339, acc.: 56.25%] [G loss: 0.935946]\n",
      "epoch:13 step:12188 [D loss: 0.639236, acc.: 59.38%] [G loss: 0.913734]\n",
      "epoch:13 step:12189 [D loss: 0.649715, acc.: 56.25%] [G loss: 0.886568]\n",
      "epoch:13 step:12190 [D loss: 0.652218, acc.: 64.06%] [G loss: 0.851972]\n",
      "epoch:13 step:12191 [D loss: 0.651372, acc.: 60.94%] [G loss: 0.894374]\n",
      "epoch:13 step:12192 [D loss: 0.657776, acc.: 60.16%] [G loss: 0.923137]\n",
      "epoch:13 step:12193 [D loss: 0.647905, acc.: 61.72%] [G loss: 0.943520]\n",
      "epoch:13 step:12194 [D loss: 0.650445, acc.: 60.94%] [G loss: 0.891252]\n",
      "epoch:13 step:12195 [D loss: 0.684524, acc.: 60.94%] [G loss: 0.970789]\n",
      "epoch:13 step:12196 [D loss: 0.565955, acc.: 74.22%] [G loss: 0.995586]\n",
      "epoch:13 step:12197 [D loss: 0.614805, acc.: 72.66%] [G loss: 0.970490]\n",
      "epoch:13 step:12198 [D loss: 0.653113, acc.: 60.16%] [G loss: 0.886865]\n",
      "epoch:13 step:12199 [D loss: 0.669819, acc.: 57.81%] [G loss: 0.913630]\n",
      "epoch:13 step:12200 [D loss: 0.702049, acc.: 57.03%] [G loss: 0.959917]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.025087\n",
      "FID: 9.061894\n",
      "0 = 11.9591301135302\n",
      "1 = 0.058611040743061914\n",
      "2 = 0.9284499883651733\n",
      "3 = 0.885200023651123\n",
      "4 = 0.9717000126838684\n",
      "5 = 0.9690202474594116\n",
      "6 = 0.885200023651123\n",
      "7 = 6.029786833196843\n",
      "8 = 0.06544426143658792\n",
      "9 = 0.71875\n",
      "10 = 0.6953999996185303\n",
      "11 = 0.7421000003814697\n",
      "12 = 0.7294660806655884\n",
      "13 = 0.6953999996185303\n",
      "14 = 8.025158882141113\n",
      "15 = 9.574477195739746\n",
      "16 = 0.09721583127975464\n",
      "17 = 8.025087356567383\n",
      "18 = 9.061894416809082\n",
      "epoch:13 step:12201 [D loss: 0.728637, acc.: 49.22%] [G loss: 1.022531]\n",
      "epoch:13 step:12202 [D loss: 0.637998, acc.: 62.50%] [G loss: 1.032026]\n",
      "epoch:13 step:12203 [D loss: 0.579991, acc.: 74.22%] [G loss: 1.126088]\n",
      "epoch:13 step:12204 [D loss: 0.779920, acc.: 45.31%] [G loss: 0.905851]\n",
      "epoch:13 step:12205 [D loss: 0.657062, acc.: 60.94%] [G loss: 0.839415]\n",
      "epoch:13 step:12206 [D loss: 0.640055, acc.: 64.06%] [G loss: 0.860025]\n",
      "epoch:13 step:12207 [D loss: 0.675173, acc.: 55.47%] [G loss: 0.935025]\n",
      "epoch:13 step:12208 [D loss: 0.669632, acc.: 59.38%] [G loss: 0.884787]\n",
      "epoch:13 step:12209 [D loss: 0.648834, acc.: 60.16%] [G loss: 0.904190]\n",
      "epoch:13 step:12210 [D loss: 0.612204, acc.: 67.19%] [G loss: 0.901512]\n",
      "epoch:13 step:12211 [D loss: 0.712555, acc.: 53.91%] [G loss: 0.868958]\n",
      "epoch:13 step:12212 [D loss: 0.651834, acc.: 61.72%] [G loss: 0.903000]\n",
      "epoch:13 step:12213 [D loss: 0.670573, acc.: 58.59%] [G loss: 0.962333]\n",
      "epoch:13 step:12214 [D loss: 0.682302, acc.: 54.69%] [G loss: 0.947930]\n",
      "epoch:13 step:12215 [D loss: 0.655330, acc.: 64.06%] [G loss: 0.896691]\n",
      "epoch:13 step:12216 [D loss: 0.649634, acc.: 64.06%] [G loss: 0.911873]\n",
      "epoch:13 step:12217 [D loss: 0.638641, acc.: 63.28%] [G loss: 0.926891]\n",
      "epoch:13 step:12218 [D loss: 0.682390, acc.: 56.25%] [G loss: 0.926470]\n",
      "epoch:13 step:12219 [D loss: 0.747319, acc.: 49.22%] [G loss: 0.867125]\n",
      "epoch:13 step:12220 [D loss: 0.645363, acc.: 60.94%] [G loss: 0.863161]\n",
      "epoch:13 step:12221 [D loss: 0.643665, acc.: 59.38%] [G loss: 0.940460]\n",
      "epoch:13 step:12222 [D loss: 0.682030, acc.: 61.72%] [G loss: 0.839479]\n",
      "epoch:13 step:12223 [D loss: 0.658865, acc.: 63.28%] [G loss: 0.834719]\n",
      "epoch:13 step:12224 [D loss: 0.652916, acc.: 62.50%] [G loss: 0.845748]\n",
      "epoch:13 step:12225 [D loss: 0.674949, acc.: 60.16%] [G loss: 0.895729]\n",
      "epoch:13 step:12226 [D loss: 0.672625, acc.: 55.47%] [G loss: 0.960403]\n",
      "epoch:13 step:12227 [D loss: 0.646578, acc.: 60.16%] [G loss: 0.954042]\n",
      "epoch:13 step:12228 [D loss: 0.651265, acc.: 57.03%] [G loss: 0.914183]\n",
      "epoch:13 step:12229 [D loss: 0.625957, acc.: 66.41%] [G loss: 0.870015]\n",
      "epoch:13 step:12230 [D loss: 0.640471, acc.: 61.72%] [G loss: 0.935487]\n",
      "epoch:13 step:12231 [D loss: 0.627488, acc.: 62.50%] [G loss: 0.929560]\n",
      "epoch:13 step:12232 [D loss: 0.722413, acc.: 53.12%] [G loss: 0.933161]\n",
      "epoch:13 step:12233 [D loss: 0.667475, acc.: 56.25%] [G loss: 0.917943]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12234 [D loss: 0.614499, acc.: 72.66%] [G loss: 0.913026]\n",
      "epoch:13 step:12235 [D loss: 0.677089, acc.: 59.38%] [G loss: 0.932829]\n",
      "epoch:13 step:12236 [D loss: 0.661302, acc.: 59.38%] [G loss: 0.884953]\n",
      "epoch:13 step:12237 [D loss: 0.657249, acc.: 61.72%] [G loss: 0.944043]\n",
      "epoch:13 step:12238 [D loss: 0.676996, acc.: 56.25%] [G loss: 0.861559]\n",
      "epoch:13 step:12239 [D loss: 0.636298, acc.: 59.38%] [G loss: 0.913594]\n",
      "epoch:13 step:12240 [D loss: 0.662993, acc.: 60.94%] [G loss: 0.952262]\n",
      "epoch:13 step:12241 [D loss: 0.661110, acc.: 61.72%] [G loss: 0.920182]\n",
      "epoch:13 step:12242 [D loss: 0.722005, acc.: 56.25%] [G loss: 0.891202]\n",
      "epoch:13 step:12243 [D loss: 0.701697, acc.: 53.91%] [G loss: 0.880051]\n",
      "epoch:13 step:12244 [D loss: 0.653567, acc.: 60.94%] [G loss: 0.919951]\n",
      "epoch:13 step:12245 [D loss: 0.693467, acc.: 51.56%] [G loss: 0.899273]\n",
      "epoch:13 step:12246 [D loss: 0.662892, acc.: 60.94%] [G loss: 0.918460]\n",
      "epoch:13 step:12247 [D loss: 0.691337, acc.: 53.91%] [G loss: 0.904348]\n",
      "epoch:13 step:12248 [D loss: 0.622840, acc.: 64.84%] [G loss: 0.907200]\n",
      "epoch:13 step:12249 [D loss: 0.665914, acc.: 64.06%] [G loss: 0.839109]\n",
      "epoch:13 step:12250 [D loss: 0.620393, acc.: 65.62%] [G loss: 0.909518]\n",
      "epoch:13 step:12251 [D loss: 0.646595, acc.: 60.16%] [G loss: 0.969816]\n",
      "epoch:13 step:12252 [D loss: 0.694233, acc.: 56.25%] [G loss: 0.970430]\n",
      "epoch:13 step:12253 [D loss: 0.658533, acc.: 62.50%] [G loss: 0.961285]\n",
      "epoch:13 step:12254 [D loss: 0.666312, acc.: 59.38%] [G loss: 0.880636]\n",
      "epoch:13 step:12255 [D loss: 0.588238, acc.: 72.66%] [G loss: 0.955464]\n",
      "epoch:13 step:12256 [D loss: 0.647687, acc.: 66.41%] [G loss: 0.960679]\n",
      "epoch:13 step:12257 [D loss: 0.611069, acc.: 60.16%] [G loss: 0.908565]\n",
      "epoch:13 step:12258 [D loss: 0.642864, acc.: 60.16%] [G loss: 0.983356]\n",
      "epoch:13 step:12259 [D loss: 0.756800, acc.: 47.66%] [G loss: 0.983745]\n",
      "epoch:13 step:12260 [D loss: 0.653693, acc.: 60.94%] [G loss: 0.975274]\n",
      "epoch:13 step:12261 [D loss: 0.662240, acc.: 59.38%] [G loss: 0.929762]\n",
      "epoch:13 step:12262 [D loss: 0.719802, acc.: 50.78%] [G loss: 0.882322]\n",
      "epoch:13 step:12263 [D loss: 0.644119, acc.: 63.28%] [G loss: 0.844565]\n",
      "epoch:13 step:12264 [D loss: 0.616944, acc.: 64.06%] [G loss: 0.860847]\n",
      "epoch:13 step:12265 [D loss: 0.684298, acc.: 60.94%] [G loss: 0.883335]\n",
      "epoch:13 step:12266 [D loss: 0.654014, acc.: 60.94%] [G loss: 0.951651]\n",
      "epoch:13 step:12267 [D loss: 0.668657, acc.: 63.28%] [G loss: 0.926767]\n",
      "epoch:13 step:12268 [D loss: 0.665867, acc.: 60.94%] [G loss: 0.860736]\n",
      "epoch:13 step:12269 [D loss: 0.671107, acc.: 62.50%] [G loss: 0.866780]\n",
      "epoch:13 step:12270 [D loss: 0.619861, acc.: 70.31%] [G loss: 0.906404]\n",
      "epoch:13 step:12271 [D loss: 0.642798, acc.: 59.38%] [G loss: 0.914511]\n",
      "epoch:13 step:12272 [D loss: 0.634875, acc.: 63.28%] [G loss: 0.884820]\n",
      "epoch:13 step:12273 [D loss: 0.615279, acc.: 71.09%] [G loss: 0.919252]\n",
      "epoch:13 step:12274 [D loss: 0.594566, acc.: 67.19%] [G loss: 0.991173]\n",
      "epoch:13 step:12275 [D loss: 0.648122, acc.: 60.94%] [G loss: 0.914261]\n",
      "epoch:13 step:12276 [D loss: 0.623681, acc.: 64.06%] [G loss: 0.951978]\n",
      "epoch:13 step:12277 [D loss: 0.628568, acc.: 62.50%] [G loss: 0.908919]\n",
      "epoch:13 step:12278 [D loss: 0.611500, acc.: 64.84%] [G loss: 0.849509]\n",
      "epoch:13 step:12279 [D loss: 0.603628, acc.: 67.19%] [G loss: 0.968637]\n",
      "epoch:13 step:12280 [D loss: 0.673900, acc.: 59.38%] [G loss: 1.033873]\n",
      "epoch:13 step:12281 [D loss: 0.591429, acc.: 67.97%] [G loss: 0.953907]\n",
      "epoch:13 step:12282 [D loss: 0.638122, acc.: 64.06%] [G loss: 0.862736]\n",
      "epoch:13 step:12283 [D loss: 0.701086, acc.: 57.81%] [G loss: 0.829016]\n",
      "epoch:13 step:12284 [D loss: 0.642649, acc.: 60.94%] [G loss: 0.889645]\n",
      "epoch:13 step:12285 [D loss: 0.706034, acc.: 59.38%] [G loss: 0.872124]\n",
      "epoch:13 step:12286 [D loss: 0.698289, acc.: 53.12%] [G loss: 0.862085]\n",
      "epoch:13 step:12287 [D loss: 0.651742, acc.: 65.62%] [G loss: 0.899624]\n",
      "epoch:13 step:12288 [D loss: 0.644839, acc.: 63.28%] [G loss: 0.894483]\n",
      "epoch:13 step:12289 [D loss: 0.698736, acc.: 50.78%] [G loss: 0.898227]\n",
      "epoch:13 step:12290 [D loss: 0.638583, acc.: 67.19%] [G loss: 0.865347]\n",
      "epoch:13 step:12291 [D loss: 0.623013, acc.: 65.62%] [G loss: 0.851798]\n",
      "epoch:13 step:12292 [D loss: 0.671604, acc.: 61.72%] [G loss: 0.866674]\n",
      "epoch:13 step:12293 [D loss: 0.622763, acc.: 63.28%] [G loss: 0.841401]\n",
      "epoch:13 step:12294 [D loss: 0.650512, acc.: 57.03%] [G loss: 0.886782]\n",
      "epoch:13 step:12295 [D loss: 0.641230, acc.: 69.53%] [G loss: 0.959828]\n",
      "epoch:13 step:12296 [D loss: 0.591409, acc.: 71.09%] [G loss: 1.013845]\n",
      "epoch:13 step:12297 [D loss: 0.614407, acc.: 66.41%] [G loss: 0.996106]\n",
      "epoch:13 step:12298 [D loss: 0.591010, acc.: 66.41%] [G loss: 0.974398]\n",
      "epoch:13 step:12299 [D loss: 0.644017, acc.: 65.62%] [G loss: 0.988278]\n",
      "epoch:13 step:12300 [D loss: 0.609493, acc.: 68.75%] [G loss: 1.005410]\n",
      "epoch:13 step:12301 [D loss: 0.720571, acc.: 53.12%] [G loss: 0.921591]\n",
      "epoch:13 step:12302 [D loss: 0.722255, acc.: 50.78%] [G loss: 0.993537]\n",
      "epoch:13 step:12303 [D loss: 0.648965, acc.: 64.84%] [G loss: 0.949223]\n",
      "epoch:13 step:12304 [D loss: 0.723000, acc.: 51.56%] [G loss: 0.950775]\n",
      "epoch:13 step:12305 [D loss: 0.700325, acc.: 50.78%] [G loss: 0.919084]\n",
      "epoch:13 step:12306 [D loss: 0.741755, acc.: 51.56%] [G loss: 0.946897]\n",
      "epoch:13 step:12307 [D loss: 0.602587, acc.: 67.19%] [G loss: 0.958086]\n",
      "epoch:13 step:12308 [D loss: 0.666689, acc.: 60.94%] [G loss: 0.915920]\n",
      "epoch:13 step:12309 [D loss: 0.657750, acc.: 60.16%] [G loss: 0.876149]\n",
      "epoch:13 step:12310 [D loss: 0.635389, acc.: 65.62%] [G loss: 0.938998]\n",
      "epoch:13 step:12311 [D loss: 0.663303, acc.: 64.84%] [G loss: 0.922808]\n",
      "epoch:13 step:12312 [D loss: 0.625060, acc.: 64.06%] [G loss: 0.897993]\n",
      "epoch:13 step:12313 [D loss: 0.639892, acc.: 64.06%] [G loss: 0.877432]\n",
      "epoch:13 step:12314 [D loss: 0.689241, acc.: 60.16%] [G loss: 0.885550]\n",
      "epoch:13 step:12315 [D loss: 0.646648, acc.: 62.50%] [G loss: 0.939314]\n",
      "epoch:13 step:12316 [D loss: 0.649972, acc.: 62.50%] [G loss: 0.974037]\n",
      "epoch:13 step:12317 [D loss: 0.613991, acc.: 67.19%] [G loss: 0.924406]\n",
      "epoch:13 step:12318 [D loss: 0.726180, acc.: 52.34%] [G loss: 0.873632]\n",
      "epoch:13 step:12319 [D loss: 0.684027, acc.: 60.94%] [G loss: 0.902370]\n",
      "epoch:13 step:12320 [D loss: 0.717337, acc.: 53.12%] [G loss: 0.882705]\n",
      "epoch:13 step:12321 [D loss: 0.679158, acc.: 54.69%] [G loss: 0.871883]\n",
      "epoch:13 step:12322 [D loss: 0.662264, acc.: 60.94%] [G loss: 0.863781]\n",
      "epoch:13 step:12323 [D loss: 0.673555, acc.: 57.81%] [G loss: 0.812638]\n",
      "epoch:13 step:12324 [D loss: 0.706334, acc.: 52.34%] [G loss: 0.845363]\n",
      "epoch:13 step:12325 [D loss: 0.644657, acc.: 64.84%] [G loss: 0.876571]\n",
      "epoch:13 step:12326 [D loss: 0.676671, acc.: 57.03%] [G loss: 0.872930]\n",
      "epoch:13 step:12327 [D loss: 0.638402, acc.: 61.72%] [G loss: 0.871007]\n",
      "epoch:13 step:12328 [D loss: 0.636735, acc.: 64.06%] [G loss: 0.878389]\n",
      "epoch:13 step:12329 [D loss: 0.673447, acc.: 58.59%] [G loss: 0.928992]\n",
      "epoch:13 step:12330 [D loss: 0.665130, acc.: 60.16%] [G loss: 0.888739]\n",
      "epoch:13 step:12331 [D loss: 0.707720, acc.: 53.12%] [G loss: 0.869926]\n",
      "epoch:13 step:12332 [D loss: 0.597219, acc.: 71.88%] [G loss: 0.890028]\n",
      "epoch:13 step:12333 [D loss: 0.676798, acc.: 57.81%] [G loss: 0.872453]\n",
      "epoch:13 step:12334 [D loss: 0.720059, acc.: 50.00%] [G loss: 0.835078]\n",
      "epoch:13 step:12335 [D loss: 0.674203, acc.: 58.59%] [G loss: 0.866818]\n",
      "epoch:13 step:12336 [D loss: 0.629485, acc.: 69.53%] [G loss: 0.884087]\n",
      "epoch:13 step:12337 [D loss: 0.670112, acc.: 58.59%] [G loss: 0.837249]\n",
      "epoch:13 step:12338 [D loss: 0.710301, acc.: 53.91%] [G loss: 0.908352]\n",
      "epoch:13 step:12339 [D loss: 0.640226, acc.: 63.28%] [G loss: 0.898515]\n",
      "epoch:13 step:12340 [D loss: 0.692828, acc.: 53.91%] [G loss: 0.824427]\n",
      "epoch:13 step:12341 [D loss: 0.739904, acc.: 53.12%] [G loss: 0.824022]\n",
      "epoch:13 step:12342 [D loss: 0.645843, acc.: 64.06%] [G loss: 1.001646]\n",
      "epoch:13 step:12343 [D loss: 0.652802, acc.: 62.50%] [G loss: 0.988095]\n",
      "epoch:13 step:12344 [D loss: 0.634415, acc.: 66.41%] [G loss: 0.982329]\n",
      "epoch:13 step:12345 [D loss: 0.635229, acc.: 64.06%] [G loss: 1.001438]\n",
      "epoch:13 step:12346 [D loss: 0.641499, acc.: 62.50%] [G loss: 0.933520]\n",
      "epoch:13 step:12347 [D loss: 0.701339, acc.: 54.69%] [G loss: 0.801628]\n",
      "epoch:13 step:12348 [D loss: 0.681244, acc.: 59.38%] [G loss: 0.823563]\n",
      "epoch:13 step:12349 [D loss: 0.656040, acc.: 54.69%] [G loss: 0.782400]\n",
      "epoch:13 step:12350 [D loss: 0.637806, acc.: 63.28%] [G loss: 0.875744]\n",
      "epoch:13 step:12351 [D loss: 0.657849, acc.: 62.50%] [G loss: 0.895101]\n",
      "epoch:13 step:12352 [D loss: 0.669337, acc.: 56.25%] [G loss: 0.847200]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12353 [D loss: 0.653523, acc.: 61.72%] [G loss: 0.882258]\n",
      "epoch:13 step:12354 [D loss: 0.645700, acc.: 67.19%] [G loss: 0.890195]\n",
      "epoch:13 step:12355 [D loss: 0.664546, acc.: 54.69%] [G loss: 0.831627]\n",
      "epoch:13 step:12356 [D loss: 0.683783, acc.: 57.81%] [G loss: 0.869426]\n",
      "epoch:13 step:12357 [D loss: 0.653008, acc.: 64.06%] [G loss: 0.981424]\n",
      "epoch:13 step:12358 [D loss: 0.660544, acc.: 57.81%] [G loss: 0.891043]\n",
      "epoch:13 step:12359 [D loss: 0.640548, acc.: 64.84%] [G loss: 0.857497]\n",
      "epoch:13 step:12360 [D loss: 0.671252, acc.: 60.16%] [G loss: 0.865331]\n",
      "epoch:13 step:12361 [D loss: 0.654282, acc.: 64.06%] [G loss: 0.907149]\n",
      "epoch:13 step:12362 [D loss: 0.679606, acc.: 59.38%] [G loss: 0.887374]\n",
      "epoch:13 step:12363 [D loss: 0.675852, acc.: 60.16%] [G loss: 0.838938]\n",
      "epoch:13 step:12364 [D loss: 0.649791, acc.: 61.72%] [G loss: 0.912943]\n",
      "epoch:13 step:12365 [D loss: 0.633671, acc.: 66.41%] [G loss: 0.917733]\n",
      "epoch:13 step:12366 [D loss: 0.684373, acc.: 56.25%] [G loss: 0.838694]\n",
      "epoch:13 step:12367 [D loss: 0.701378, acc.: 59.38%] [G loss: 0.879746]\n",
      "epoch:13 step:12368 [D loss: 0.667008, acc.: 57.03%] [G loss: 0.895654]\n",
      "epoch:13 step:12369 [D loss: 0.725185, acc.: 53.91%] [G loss: 0.850449]\n",
      "epoch:13 step:12370 [D loss: 0.654635, acc.: 58.59%] [G loss: 0.852754]\n",
      "epoch:13 step:12371 [D loss: 0.668796, acc.: 58.59%] [G loss: 0.839665]\n",
      "epoch:13 step:12372 [D loss: 0.638278, acc.: 61.72%] [G loss: 0.887118]\n",
      "epoch:13 step:12373 [D loss: 0.655793, acc.: 54.69%] [G loss: 0.948413]\n",
      "epoch:13 step:12374 [D loss: 0.654850, acc.: 53.91%] [G loss: 0.932062]\n",
      "epoch:13 step:12375 [D loss: 0.609123, acc.: 67.97%] [G loss: 0.996034]\n",
      "epoch:13 step:12376 [D loss: 0.665655, acc.: 59.38%] [G loss: 0.939024]\n",
      "epoch:13 step:12377 [D loss: 0.748634, acc.: 50.00%] [G loss: 0.925024]\n",
      "epoch:13 step:12378 [D loss: 0.671869, acc.: 57.81%] [G loss: 0.925527]\n",
      "epoch:13 step:12379 [D loss: 0.618498, acc.: 64.84%] [G loss: 0.913851]\n",
      "epoch:13 step:12380 [D loss: 0.653780, acc.: 58.59%] [G loss: 0.972088]\n",
      "epoch:13 step:12381 [D loss: 0.719210, acc.: 50.78%] [G loss: 0.883888]\n",
      "epoch:13 step:12382 [D loss: 0.707363, acc.: 54.69%] [G loss: 0.959740]\n",
      "epoch:13 step:12383 [D loss: 0.671927, acc.: 60.94%] [G loss: 0.898602]\n",
      "epoch:13 step:12384 [D loss: 0.741620, acc.: 47.66%] [G loss: 0.942762]\n",
      "epoch:13 step:12385 [D loss: 0.664294, acc.: 62.50%] [G loss: 0.878242]\n",
      "epoch:13 step:12386 [D loss: 0.657525, acc.: 62.50%] [G loss: 0.966227]\n",
      "epoch:13 step:12387 [D loss: 0.641625, acc.: 62.50%] [G loss: 0.974421]\n",
      "epoch:13 step:12388 [D loss: 0.623426, acc.: 64.84%] [G loss: 0.905944]\n",
      "epoch:13 step:12389 [D loss: 0.607758, acc.: 65.62%] [G loss: 0.926331]\n",
      "epoch:13 step:12390 [D loss: 0.601628, acc.: 69.53%] [G loss: 0.929235]\n",
      "epoch:13 step:12391 [D loss: 0.743942, acc.: 48.44%] [G loss: 0.888301]\n",
      "epoch:13 step:12392 [D loss: 0.694406, acc.: 54.69%] [G loss: 0.854562]\n",
      "epoch:13 step:12393 [D loss: 0.663136, acc.: 60.16%] [G loss: 0.874489]\n",
      "epoch:13 step:12394 [D loss: 0.693608, acc.: 54.69%] [G loss: 0.842686]\n",
      "epoch:13 step:12395 [D loss: 0.713642, acc.: 57.03%] [G loss: 0.933634]\n",
      "epoch:13 step:12396 [D loss: 0.700203, acc.: 50.00%] [G loss: 0.887155]\n",
      "epoch:13 step:12397 [D loss: 0.641471, acc.: 63.28%] [G loss: 0.865325]\n",
      "epoch:13 step:12398 [D loss: 0.625517, acc.: 64.06%] [G loss: 0.863938]\n",
      "epoch:13 step:12399 [D loss: 0.589147, acc.: 71.88%] [G loss: 0.913826]\n",
      "epoch:13 step:12400 [D loss: 0.581635, acc.: 70.31%] [G loss: 0.929400]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.086032\n",
      "FID: 6.690776\n",
      "0 = 11.90769129943848\n",
      "1 = 0.05550535901289524\n",
      "2 = 0.9171500205993652\n",
      "3 = 0.8766999840736389\n",
      "4 = 0.9575999975204468\n",
      "5 = 0.9538679122924805\n",
      "6 = 0.8766999840736389\n",
      "7 = 5.73892194629904\n",
      "8 = 0.05506223625267157\n",
      "9 = 0.7106999754905701\n",
      "10 = 0.6883000135421753\n",
      "11 = 0.7330999970436096\n",
      "12 = 0.7205820679664612\n",
      "13 = 0.6883000135421753\n",
      "14 = 8.086099624633789\n",
      "15 = 9.606316566467285\n",
      "16 = 0.088066466152668\n",
      "17 = 8.086031913757324\n",
      "18 = 6.6907758712768555\n",
      "epoch:13 step:12401 [D loss: 0.745686, acc.: 47.66%] [G loss: 0.903127]\n",
      "epoch:13 step:12402 [D loss: 0.648758, acc.: 63.28%] [G loss: 0.975079]\n",
      "epoch:13 step:12403 [D loss: 0.667722, acc.: 60.16%] [G loss: 1.005088]\n",
      "epoch:13 step:12404 [D loss: 0.626915, acc.: 63.28%] [G loss: 0.980450]\n",
      "epoch:13 step:12405 [D loss: 0.737881, acc.: 54.69%] [G loss: 0.913704]\n",
      "epoch:13 step:12406 [D loss: 0.688168, acc.: 53.12%] [G loss: 0.890104]\n",
      "epoch:13 step:12407 [D loss: 0.711512, acc.: 49.22%] [G loss: 0.825127]\n",
      "epoch:13 step:12408 [D loss: 0.663016, acc.: 57.81%] [G loss: 0.835001]\n",
      "epoch:13 step:12409 [D loss: 0.684271, acc.: 54.69%] [G loss: 0.899584]\n",
      "epoch:13 step:12410 [D loss: 0.643523, acc.: 61.72%] [G loss: 0.901180]\n",
      "epoch:13 step:12411 [D loss: 0.612611, acc.: 70.31%] [G loss: 0.916697]\n",
      "epoch:13 step:12412 [D loss: 0.553214, acc.: 72.66%] [G loss: 0.995569]\n",
      "epoch:13 step:12413 [D loss: 0.495890, acc.: 81.25%] [G loss: 1.022840]\n",
      "epoch:13 step:12414 [D loss: 0.700206, acc.: 55.47%] [G loss: 0.876384]\n",
      "epoch:13 step:12415 [D loss: 0.717468, acc.: 57.03%] [G loss: 0.899335]\n",
      "epoch:13 step:12416 [D loss: 0.649068, acc.: 64.06%] [G loss: 0.855535]\n",
      "epoch:13 step:12417 [D loss: 0.667818, acc.: 60.94%] [G loss: 0.900401]\n",
      "epoch:13 step:12418 [D loss: 0.690653, acc.: 52.34%] [G loss: 0.824338]\n",
      "epoch:13 step:12419 [D loss: 0.648814, acc.: 62.50%] [G loss: 0.904925]\n",
      "epoch:13 step:12420 [D loss: 0.654838, acc.: 55.47%] [G loss: 0.899779]\n",
      "epoch:13 step:12421 [D loss: 0.662288, acc.: 60.16%] [G loss: 0.851074]\n",
      "epoch:13 step:12422 [D loss: 0.617578, acc.: 69.53%] [G loss: 0.925274]\n",
      "epoch:13 step:12423 [D loss: 0.611053, acc.: 68.75%] [G loss: 0.832499]\n",
      "epoch:13 step:12424 [D loss: 0.640421, acc.: 64.06%] [G loss: 0.951882]\n",
      "epoch:13 step:12425 [D loss: 0.666263, acc.: 61.72%] [G loss: 0.908820]\n",
      "epoch:13 step:12426 [D loss: 0.646238, acc.: 60.94%] [G loss: 0.934366]\n",
      "epoch:13 step:12427 [D loss: 0.663904, acc.: 58.59%] [G loss: 0.928772]\n",
      "epoch:13 step:12428 [D loss: 0.642865, acc.: 63.28%] [G loss: 0.924085]\n",
      "epoch:13 step:12429 [D loss: 0.609034, acc.: 66.41%] [G loss: 0.994066]\n",
      "epoch:13 step:12430 [D loss: 0.747381, acc.: 53.12%] [G loss: 0.853234]\n",
      "epoch:13 step:12431 [D loss: 0.748468, acc.: 44.53%] [G loss: 0.842384]\n",
      "epoch:13 step:12432 [D loss: 0.690108, acc.: 54.69%] [G loss: 0.830634]\n",
      "epoch:13 step:12433 [D loss: 0.660001, acc.: 63.28%] [G loss: 0.809183]\n",
      "epoch:13 step:12434 [D loss: 0.661774, acc.: 61.72%] [G loss: 0.890915]\n",
      "epoch:13 step:12435 [D loss: 0.608992, acc.: 72.66%] [G loss: 0.907473]\n",
      "epoch:13 step:12436 [D loss: 0.647770, acc.: 60.94%] [G loss: 0.870020]\n",
      "epoch:13 step:12437 [D loss: 0.631205, acc.: 66.41%] [G loss: 0.866153]\n",
      "epoch:13 step:12438 [D loss: 0.630489, acc.: 68.75%] [G loss: 0.878554]\n",
      "epoch:13 step:12439 [D loss: 0.643205, acc.: 60.16%] [G loss: 0.943441]\n",
      "epoch:13 step:12440 [D loss: 0.614302, acc.: 65.62%] [G loss: 0.922179]\n",
      "epoch:13 step:12441 [D loss: 0.671778, acc.: 58.59%] [G loss: 0.855849]\n",
      "epoch:13 step:12442 [D loss: 0.639170, acc.: 67.97%] [G loss: 0.898514]\n",
      "epoch:13 step:12443 [D loss: 0.641297, acc.: 64.84%] [G loss: 0.951498]\n",
      "epoch:13 step:12444 [D loss: 0.732891, acc.: 51.56%] [G loss: 0.858167]\n",
      "epoch:13 step:12445 [D loss: 0.690440, acc.: 56.25%] [G loss: 0.861550]\n",
      "epoch:13 step:12446 [D loss: 0.697068, acc.: 53.91%] [G loss: 0.880631]\n",
      "epoch:13 step:12447 [D loss: 0.668458, acc.: 56.25%] [G loss: 0.875856]\n",
      "epoch:13 step:12448 [D loss: 0.672443, acc.: 58.59%] [G loss: 0.950723]\n",
      "epoch:13 step:12449 [D loss: 0.655415, acc.: 58.59%] [G loss: 0.987765]\n",
      "epoch:13 step:12450 [D loss: 0.670891, acc.: 60.16%] [G loss: 0.947891]\n",
      "epoch:13 step:12451 [D loss: 0.606570, acc.: 68.75%] [G loss: 0.922608]\n",
      "epoch:13 step:12452 [D loss: 0.637550, acc.: 62.50%] [G loss: 0.889493]\n",
      "epoch:13 step:12453 [D loss: 0.635462, acc.: 62.50%] [G loss: 0.898994]\n",
      "epoch:13 step:12454 [D loss: 0.644835, acc.: 66.41%] [G loss: 0.896182]\n",
      "epoch:13 step:12455 [D loss: 0.627658, acc.: 64.84%] [G loss: 0.899745]\n",
      "epoch:13 step:12456 [D loss: 0.659139, acc.: 61.72%] [G loss: 0.906771]\n",
      "epoch:13 step:12457 [D loss: 0.669825, acc.: 58.59%] [G loss: 0.907982]\n",
      "epoch:13 step:12458 [D loss: 0.696353, acc.: 54.69%] [G loss: 0.873498]\n",
      "epoch:13 step:12459 [D loss: 0.704325, acc.: 54.69%] [G loss: 0.888325]\n",
      "epoch:13 step:12460 [D loss: 0.640596, acc.: 60.94%] [G loss: 0.896453]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12461 [D loss: 0.640722, acc.: 60.16%] [G loss: 0.886415]\n",
      "epoch:13 step:12462 [D loss: 0.684519, acc.: 59.38%] [G loss: 0.872138]\n",
      "epoch:13 step:12463 [D loss: 0.711053, acc.: 50.78%] [G loss: 0.878705]\n",
      "epoch:13 step:12464 [D loss: 0.651644, acc.: 62.50%] [G loss: 0.898667]\n",
      "epoch:13 step:12465 [D loss: 0.655338, acc.: 66.41%] [G loss: 0.902293]\n",
      "epoch:13 step:12466 [D loss: 0.668029, acc.: 63.28%] [G loss: 0.907870]\n",
      "epoch:13 step:12467 [D loss: 0.671474, acc.: 59.38%] [G loss: 0.987081]\n",
      "epoch:13 step:12468 [D loss: 0.648353, acc.: 60.94%] [G loss: 0.928189]\n",
      "epoch:13 step:12469 [D loss: 0.648321, acc.: 60.16%] [G loss: 0.972111]\n",
      "epoch:13 step:12470 [D loss: 0.596089, acc.: 68.75%] [G loss: 1.018420]\n",
      "epoch:13 step:12471 [D loss: 0.688914, acc.: 57.81%] [G loss: 0.950472]\n",
      "epoch:13 step:12472 [D loss: 0.692373, acc.: 52.34%] [G loss: 0.926026]\n",
      "epoch:13 step:12473 [D loss: 0.650730, acc.: 63.28%] [G loss: 0.852307]\n",
      "epoch:13 step:12474 [D loss: 0.644525, acc.: 64.06%] [G loss: 0.922344]\n",
      "epoch:13 step:12475 [D loss: 0.679056, acc.: 56.25%] [G loss: 0.852351]\n",
      "epoch:13 step:12476 [D loss: 0.696138, acc.: 54.69%] [G loss: 0.847753]\n",
      "epoch:13 step:12477 [D loss: 0.610304, acc.: 73.44%] [G loss: 0.867112]\n",
      "epoch:13 step:12478 [D loss: 0.623944, acc.: 64.06%] [G loss: 0.851983]\n",
      "epoch:13 step:12479 [D loss: 0.622537, acc.: 65.62%] [G loss: 0.898271]\n",
      "epoch:13 step:12480 [D loss: 0.619445, acc.: 67.19%] [G loss: 0.905557]\n",
      "epoch:13 step:12481 [D loss: 0.626631, acc.: 70.31%] [G loss: 0.936726]\n",
      "epoch:13 step:12482 [D loss: 0.719586, acc.: 53.91%] [G loss: 0.886448]\n",
      "epoch:13 step:12483 [D loss: 0.628492, acc.: 63.28%] [G loss: 0.969549]\n",
      "epoch:13 step:12484 [D loss: 0.702487, acc.: 53.91%] [G loss: 0.945376]\n",
      "epoch:13 step:12485 [D loss: 0.657758, acc.: 62.50%] [G loss: 0.933834]\n",
      "epoch:13 step:12486 [D loss: 0.645436, acc.: 64.06%] [G loss: 0.923353]\n",
      "epoch:13 step:12487 [D loss: 0.628711, acc.: 64.06%] [G loss: 0.967139]\n",
      "epoch:13 step:12488 [D loss: 0.629335, acc.: 63.28%] [G loss: 1.010419]\n",
      "epoch:13 step:12489 [D loss: 0.649637, acc.: 60.94%] [G loss: 0.932230]\n",
      "epoch:13 step:12490 [D loss: 0.642752, acc.: 62.50%] [G loss: 0.988501]\n",
      "epoch:13 step:12491 [D loss: 0.623076, acc.: 67.19%] [G loss: 0.984383]\n",
      "epoch:13 step:12492 [D loss: 0.628097, acc.: 67.19%] [G loss: 0.968085]\n",
      "epoch:13 step:12493 [D loss: 0.596832, acc.: 67.19%] [G loss: 0.951608]\n",
      "epoch:13 step:12494 [D loss: 0.579414, acc.: 70.31%] [G loss: 1.005971]\n",
      "epoch:13 step:12495 [D loss: 0.566393, acc.: 69.53%] [G loss: 0.926564]\n",
      "epoch:13 step:12496 [D loss: 0.584223, acc.: 67.19%] [G loss: 1.014866]\n",
      "epoch:13 step:12497 [D loss: 0.772601, acc.: 49.22%] [G loss: 0.870018]\n",
      "epoch:13 step:12498 [D loss: 0.658704, acc.: 57.81%] [G loss: 0.853881]\n",
      "epoch:13 step:12499 [D loss: 0.630906, acc.: 63.28%] [G loss: 0.875804]\n",
      "epoch:13 step:12500 [D loss: 0.658169, acc.: 59.38%] [G loss: 0.870629]\n",
      "epoch:13 step:12501 [D loss: 0.681747, acc.: 58.59%] [G loss: 0.892432]\n",
      "epoch:13 step:12502 [D loss: 0.617680, acc.: 64.06%] [G loss: 0.948573]\n",
      "epoch:13 step:12503 [D loss: 0.677448, acc.: 60.16%] [G loss: 0.900563]\n",
      "epoch:13 step:12504 [D loss: 0.718609, acc.: 56.25%] [G loss: 0.958622]\n",
      "epoch:13 step:12505 [D loss: 0.658416, acc.: 61.72%] [G loss: 0.916465]\n",
      "epoch:13 step:12506 [D loss: 0.659397, acc.: 54.69%] [G loss: 0.872093]\n",
      "epoch:13 step:12507 [D loss: 0.657663, acc.: 66.41%] [G loss: 0.917167]\n",
      "epoch:13 step:12508 [D loss: 0.655371, acc.: 60.16%] [G loss: 0.962874]\n",
      "epoch:13 step:12509 [D loss: 0.666457, acc.: 59.38%] [G loss: 0.955974]\n",
      "epoch:13 step:12510 [D loss: 0.701819, acc.: 57.03%] [G loss: 0.890200]\n",
      "epoch:13 step:12511 [D loss: 0.679531, acc.: 53.91%] [G loss: 0.879769]\n",
      "epoch:13 step:12512 [D loss: 0.643792, acc.: 64.06%] [G loss: 0.868129]\n",
      "epoch:13 step:12513 [D loss: 0.595184, acc.: 71.88%] [G loss: 0.842697]\n",
      "epoch:13 step:12514 [D loss: 0.634526, acc.: 67.19%] [G loss: 0.925678]\n",
      "epoch:13 step:12515 [D loss: 0.665571, acc.: 60.94%] [G loss: 0.936472]\n",
      "epoch:13 step:12516 [D loss: 0.639015, acc.: 60.94%] [G loss: 0.894495]\n",
      "epoch:13 step:12517 [D loss: 0.664058, acc.: 61.72%] [G loss: 0.936996]\n",
      "epoch:13 step:12518 [D loss: 0.649120, acc.: 62.50%] [G loss: 0.928694]\n",
      "epoch:13 step:12519 [D loss: 0.633902, acc.: 66.41%] [G loss: 0.935295]\n",
      "epoch:13 step:12520 [D loss: 0.635602, acc.: 64.06%] [G loss: 0.922226]\n",
      "epoch:13 step:12521 [D loss: 0.641346, acc.: 60.94%] [G loss: 0.965630]\n",
      "epoch:13 step:12522 [D loss: 0.690628, acc.: 54.69%] [G loss: 0.975950]\n",
      "epoch:13 step:12523 [D loss: 0.672919, acc.: 57.81%] [G loss: 0.917617]\n",
      "epoch:13 step:12524 [D loss: 0.679384, acc.: 60.16%] [G loss: 0.988612]\n",
      "epoch:13 step:12525 [D loss: 0.623235, acc.: 66.41%] [G loss: 0.973953]\n",
      "epoch:13 step:12526 [D loss: 0.640576, acc.: 64.06%] [G loss: 0.954477]\n",
      "epoch:13 step:12527 [D loss: 0.600778, acc.: 64.84%] [G loss: 0.942972]\n",
      "epoch:13 step:12528 [D loss: 0.569044, acc.: 75.00%] [G loss: 1.094031]\n",
      "epoch:13 step:12529 [D loss: 0.758824, acc.: 54.69%] [G loss: 0.899581]\n",
      "epoch:13 step:12530 [D loss: 0.777988, acc.: 42.97%] [G loss: 0.839802]\n",
      "epoch:13 step:12531 [D loss: 0.669256, acc.: 58.59%] [G loss: 0.860718]\n",
      "epoch:13 step:12532 [D loss: 0.736210, acc.: 46.09%] [G loss: 0.911016]\n",
      "epoch:13 step:12533 [D loss: 0.656314, acc.: 56.25%] [G loss: 0.901667]\n",
      "epoch:13 step:12534 [D loss: 0.624654, acc.: 62.50%] [G loss: 1.022615]\n",
      "epoch:13 step:12535 [D loss: 0.579846, acc.: 71.88%] [G loss: 1.010488]\n",
      "epoch:13 step:12536 [D loss: 0.658404, acc.: 60.16%] [G loss: 0.946373]\n",
      "epoch:13 step:12537 [D loss: 0.656435, acc.: 65.62%] [G loss: 0.860920]\n",
      "epoch:13 step:12538 [D loss: 0.650581, acc.: 61.72%] [G loss: 0.869062]\n",
      "epoch:13 step:12539 [D loss: 0.588239, acc.: 71.09%] [G loss: 0.942632]\n",
      "epoch:13 step:12540 [D loss: 0.614798, acc.: 64.06%] [G loss: 0.928239]\n",
      "epoch:13 step:12541 [D loss: 0.607638, acc.: 65.62%] [G loss: 0.918894]\n",
      "epoch:13 step:12542 [D loss: 0.641240, acc.: 62.50%] [G loss: 1.023005]\n",
      "epoch:13 step:12543 [D loss: 0.693404, acc.: 54.69%] [G loss: 0.947186]\n",
      "epoch:13 step:12544 [D loss: 0.693986, acc.: 56.25%] [G loss: 0.928416]\n",
      "epoch:13 step:12545 [D loss: 0.632644, acc.: 63.28%] [G loss: 0.915130]\n",
      "epoch:13 step:12546 [D loss: 0.675226, acc.: 54.69%] [G loss: 0.913779]\n",
      "epoch:13 step:12547 [D loss: 0.658035, acc.: 61.72%] [G loss: 0.937020]\n",
      "epoch:13 step:12548 [D loss: 0.638175, acc.: 67.97%] [G loss: 0.944067]\n",
      "epoch:13 step:12549 [D loss: 0.670252, acc.: 58.59%] [G loss: 0.953088]\n",
      "epoch:13 step:12550 [D loss: 0.693349, acc.: 52.34%] [G loss: 0.952861]\n",
      "epoch:13 step:12551 [D loss: 0.634884, acc.: 61.72%] [G loss: 0.848884]\n",
      "epoch:13 step:12552 [D loss: 0.584087, acc.: 73.44%] [G loss: 0.931759]\n",
      "epoch:13 step:12553 [D loss: 0.689923, acc.: 53.91%] [G loss: 0.899107]\n",
      "epoch:13 step:12554 [D loss: 0.682127, acc.: 57.81%] [G loss: 0.844481]\n",
      "epoch:13 step:12555 [D loss: 0.622219, acc.: 62.50%] [G loss: 0.896858]\n",
      "epoch:13 step:12556 [D loss: 0.677140, acc.: 56.25%] [G loss: 0.914576]\n",
      "epoch:13 step:12557 [D loss: 0.709199, acc.: 51.56%] [G loss: 0.906466]\n",
      "epoch:13 step:12558 [D loss: 0.714277, acc.: 50.78%] [G loss: 0.848672]\n",
      "epoch:13 step:12559 [D loss: 0.661208, acc.: 66.41%] [G loss: 0.879729]\n",
      "epoch:13 step:12560 [D loss: 0.624083, acc.: 68.75%] [G loss: 0.898237]\n",
      "epoch:13 step:12561 [D loss: 0.660460, acc.: 59.38%] [G loss: 0.852023]\n",
      "epoch:13 step:12562 [D loss: 0.628545, acc.: 64.06%] [G loss: 0.922101]\n",
      "epoch:13 step:12563 [D loss: 0.657740, acc.: 60.16%] [G loss: 0.936190]\n",
      "epoch:13 step:12564 [D loss: 0.624358, acc.: 67.19%] [G loss: 0.904451]\n",
      "epoch:13 step:12565 [D loss: 0.602676, acc.: 69.53%] [G loss: 0.882178]\n",
      "epoch:13 step:12566 [D loss: 0.669311, acc.: 60.16%] [G loss: 0.953797]\n",
      "epoch:13 step:12567 [D loss: 0.669903, acc.: 62.50%] [G loss: 0.926083]\n",
      "epoch:13 step:12568 [D loss: 0.655038, acc.: 59.38%] [G loss: 0.928053]\n",
      "epoch:13 step:12569 [D loss: 0.670281, acc.: 59.38%] [G loss: 0.922430]\n",
      "epoch:13 step:12570 [D loss: 0.645424, acc.: 64.06%] [G loss: 0.914943]\n",
      "epoch:13 step:12571 [D loss: 0.657399, acc.: 57.81%] [G loss: 0.944277]\n",
      "epoch:13 step:12572 [D loss: 0.646736, acc.: 62.50%] [G loss: 0.877534]\n",
      "epoch:13 step:12573 [D loss: 0.658383, acc.: 64.06%] [G loss: 0.877496]\n",
      "epoch:13 step:12574 [D loss: 0.679918, acc.: 57.81%] [G loss: 0.850363]\n",
      "epoch:13 step:12575 [D loss: 0.650137, acc.: 63.28%] [G loss: 0.822506]\n",
      "epoch:13 step:12576 [D loss: 0.631626, acc.: 69.53%] [G loss: 0.859437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12577 [D loss: 0.685990, acc.: 52.34%] [G loss: 0.910200]\n",
      "epoch:13 step:12578 [D loss: 0.590426, acc.: 75.00%] [G loss: 0.924490]\n",
      "epoch:13 step:12579 [D loss: 0.608511, acc.: 67.19%] [G loss: 0.954281]\n",
      "epoch:13 step:12580 [D loss: 0.633248, acc.: 62.50%] [G loss: 0.982919]\n",
      "epoch:13 step:12581 [D loss: 0.746255, acc.: 48.44%] [G loss: 0.927717]\n",
      "epoch:13 step:12582 [D loss: 0.663327, acc.: 57.81%] [G loss: 0.875275]\n",
      "epoch:13 step:12583 [D loss: 0.658535, acc.: 58.59%] [G loss: 0.870521]\n",
      "epoch:13 step:12584 [D loss: 0.641156, acc.: 60.16%] [G loss: 0.905247]\n",
      "epoch:13 step:12585 [D loss: 0.689229, acc.: 53.12%] [G loss: 0.920696]\n",
      "epoch:13 step:12586 [D loss: 0.651795, acc.: 64.06%] [G loss: 0.910343]\n",
      "epoch:13 step:12587 [D loss: 0.628575, acc.: 63.28%] [G loss: 0.970243]\n",
      "epoch:13 step:12588 [D loss: 0.679690, acc.: 56.25%] [G loss: 0.920810]\n",
      "epoch:13 step:12589 [D loss: 0.664289, acc.: 60.16%] [G loss: 0.885899]\n",
      "epoch:13 step:12590 [D loss: 0.669335, acc.: 57.81%] [G loss: 0.856489]\n",
      "epoch:13 step:12591 [D loss: 0.658212, acc.: 60.94%] [G loss: 0.951935]\n",
      "epoch:13 step:12592 [D loss: 0.705817, acc.: 57.03%] [G loss: 0.861678]\n",
      "epoch:13 step:12593 [D loss: 0.673356, acc.: 58.59%] [G loss: 0.916347]\n",
      "epoch:13 step:12594 [D loss: 0.652424, acc.: 64.06%] [G loss: 0.871796]\n",
      "epoch:13 step:12595 [D loss: 0.650173, acc.: 58.59%] [G loss: 0.822566]\n",
      "epoch:13 step:12596 [D loss: 0.656296, acc.: 60.16%] [G loss: 0.885077]\n",
      "epoch:13 step:12597 [D loss: 0.608096, acc.: 71.09%] [G loss: 0.889852]\n",
      "epoch:13 step:12598 [D loss: 0.702460, acc.: 54.69%] [G loss: 0.970001]\n",
      "epoch:13 step:12599 [D loss: 0.720141, acc.: 49.22%] [G loss: 0.917056]\n",
      "epoch:13 step:12600 [D loss: 0.671514, acc.: 64.84%] [G loss: 0.940101]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.993074\n",
      "FID: 8.928078\n",
      "0 = 11.72964505143168\n",
      "1 = 0.048656926438879346\n",
      "2 = 0.9143499732017517\n",
      "3 = 0.8634999990463257\n",
      "4 = 0.9652000069618225\n",
      "5 = 0.9612601399421692\n",
      "6 = 0.8634999990463257\n",
      "7 = 5.877221390277127\n",
      "8 = 0.06667319106918937\n",
      "9 = 0.7080000042915344\n",
      "10 = 0.6753000020980835\n",
      "11 = 0.7407000064849854\n",
      "12 = 0.7225551009178162\n",
      "13 = 0.6753000020980835\n",
      "14 = 7.9931440353393555\n",
      "15 = 9.5974760055542\n",
      "16 = 0.09136613458395004\n",
      "17 = 7.993074417114258\n",
      "18 = 8.928077697753906\n",
      "epoch:13 step:12601 [D loss: 0.614471, acc.: 67.19%] [G loss: 0.948105]\n",
      "epoch:13 step:12602 [D loss: 0.707362, acc.: 57.81%] [G loss: 0.842304]\n",
      "epoch:13 step:12603 [D loss: 0.674018, acc.: 57.81%] [G loss: 0.816501]\n",
      "epoch:13 step:12604 [D loss: 0.662534, acc.: 56.25%] [G loss: 0.944165]\n",
      "epoch:13 step:12605 [D loss: 0.673291, acc.: 59.38%] [G loss: 0.927040]\n",
      "epoch:13 step:12606 [D loss: 0.674166, acc.: 56.25%] [G loss: 0.914542]\n",
      "epoch:13 step:12607 [D loss: 0.585381, acc.: 71.09%] [G loss: 0.927550]\n",
      "epoch:13 step:12608 [D loss: 0.634526, acc.: 64.06%] [G loss: 0.951905]\n",
      "epoch:13 step:12609 [D loss: 0.603431, acc.: 71.88%] [G loss: 0.977518]\n",
      "epoch:13 step:12610 [D loss: 0.649631, acc.: 62.50%] [G loss: 0.884793]\n",
      "epoch:13 step:12611 [D loss: 0.637650, acc.: 64.84%] [G loss: 0.935726]\n",
      "epoch:13 step:12612 [D loss: 0.685866, acc.: 53.12%] [G loss: 0.922190]\n",
      "epoch:13 step:12613 [D loss: 0.688624, acc.: 52.34%] [G loss: 0.945335]\n",
      "epoch:13 step:12614 [D loss: 0.668581, acc.: 57.81%] [G loss: 0.867189]\n",
      "epoch:13 step:12615 [D loss: 0.608482, acc.: 68.75%] [G loss: 0.867077]\n",
      "epoch:13 step:12616 [D loss: 0.640334, acc.: 61.72%] [G loss: 0.908973]\n",
      "epoch:13 step:12617 [D loss: 0.629115, acc.: 67.19%] [G loss: 1.005417]\n",
      "epoch:13 step:12618 [D loss: 0.774931, acc.: 48.44%] [G loss: 0.943805]\n",
      "epoch:13 step:12619 [D loss: 0.674582, acc.: 62.50%] [G loss: 0.924098]\n",
      "epoch:13 step:12620 [D loss: 0.688631, acc.: 51.56%] [G loss: 0.890633]\n",
      "epoch:13 step:12621 [D loss: 0.660992, acc.: 57.03%] [G loss: 0.946068]\n",
      "epoch:13 step:12622 [D loss: 0.632073, acc.: 64.06%] [G loss: 1.007458]\n",
      "epoch:13 step:12623 [D loss: 0.666805, acc.: 60.16%] [G loss: 0.989480]\n",
      "epoch:13 step:12624 [D loss: 0.652946, acc.: 58.59%] [G loss: 0.931957]\n",
      "epoch:13 step:12625 [D loss: 0.667416, acc.: 61.72%] [G loss: 0.955100]\n",
      "epoch:13 step:12626 [D loss: 0.610000, acc.: 62.50%] [G loss: 0.992569]\n",
      "epoch:13 step:12627 [D loss: 0.615206, acc.: 69.53%] [G loss: 0.928505]\n",
      "epoch:13 step:12628 [D loss: 0.652065, acc.: 63.28%] [G loss: 0.937997]\n",
      "epoch:13 step:12629 [D loss: 0.739358, acc.: 50.78%] [G loss: 0.885084]\n",
      "epoch:13 step:12630 [D loss: 0.639043, acc.: 63.28%] [G loss: 0.959131]\n",
      "epoch:13 step:12631 [D loss: 0.630834, acc.: 61.72%] [G loss: 0.925862]\n",
      "epoch:13 step:12632 [D loss: 0.613950, acc.: 64.06%] [G loss: 0.882308]\n",
      "epoch:13 step:12633 [D loss: 0.593950, acc.: 67.97%] [G loss: 0.943172]\n",
      "epoch:13 step:12634 [D loss: 0.637224, acc.: 65.62%] [G loss: 0.936992]\n",
      "epoch:13 step:12635 [D loss: 0.632276, acc.: 64.06%] [G loss: 0.937100]\n",
      "epoch:13 step:12636 [D loss: 0.682168, acc.: 58.59%] [G loss: 0.919536]\n",
      "epoch:13 step:12637 [D loss: 0.675079, acc.: 59.38%] [G loss: 0.921756]\n",
      "epoch:13 step:12638 [D loss: 0.658328, acc.: 62.50%] [G loss: 0.903737]\n",
      "epoch:13 step:12639 [D loss: 0.741781, acc.: 50.00%] [G loss: 0.951943]\n",
      "epoch:13 step:12640 [D loss: 0.627444, acc.: 70.31%] [G loss: 0.902459]\n",
      "epoch:13 step:12641 [D loss: 0.665116, acc.: 56.25%] [G loss: 0.910204]\n",
      "epoch:13 step:12642 [D loss: 0.667164, acc.: 60.94%] [G loss: 0.917683]\n",
      "epoch:13 step:12643 [D loss: 0.682560, acc.: 55.47%] [G loss: 0.928058]\n",
      "epoch:13 step:12644 [D loss: 0.653544, acc.: 65.62%] [G loss: 0.856960]\n",
      "epoch:13 step:12645 [D loss: 0.731955, acc.: 53.12%] [G loss: 0.857859]\n",
      "epoch:13 step:12646 [D loss: 0.671047, acc.: 56.25%] [G loss: 0.920222]\n",
      "epoch:13 step:12647 [D loss: 0.703053, acc.: 53.91%] [G loss: 0.839858]\n",
      "epoch:13 step:12648 [D loss: 0.656593, acc.: 60.16%] [G loss: 0.906506]\n",
      "epoch:13 step:12649 [D loss: 0.672904, acc.: 61.72%] [G loss: 0.900847]\n",
      "epoch:13 step:12650 [D loss: 0.619002, acc.: 61.72%] [G loss: 0.970918]\n",
      "epoch:13 step:12651 [D loss: 0.675119, acc.: 55.47%] [G loss: 0.980418]\n",
      "epoch:13 step:12652 [D loss: 0.620067, acc.: 68.75%] [G loss: 0.969762]\n",
      "epoch:13 step:12653 [D loss: 0.642148, acc.: 69.53%] [G loss: 0.967010]\n",
      "epoch:13 step:12654 [D loss: 0.731691, acc.: 50.00%] [G loss: 0.931723]\n",
      "epoch:13 step:12655 [D loss: 0.653750, acc.: 64.06%] [G loss: 0.913165]\n",
      "epoch:13 step:12656 [D loss: 0.639929, acc.: 63.28%] [G loss: 0.958193]\n",
      "epoch:13 step:12657 [D loss: 0.663516, acc.: 56.25%] [G loss: 0.918824]\n",
      "epoch:13 step:12658 [D loss: 0.716304, acc.: 47.66%] [G loss: 0.884661]\n",
      "epoch:13 step:12659 [D loss: 0.692060, acc.: 51.56%] [G loss: 0.834152]\n",
      "epoch:13 step:12660 [D loss: 0.626493, acc.: 67.19%] [G loss: 0.826849]\n",
      "epoch:13 step:12661 [D loss: 0.619082, acc.: 64.84%] [G loss: 0.894664]\n",
      "epoch:13 step:12662 [D loss: 0.594741, acc.: 69.53%] [G loss: 0.908328]\n",
      "epoch:13 step:12663 [D loss: 0.717921, acc.: 46.88%] [G loss: 0.874028]\n",
      "epoch:13 step:12664 [D loss: 0.692257, acc.: 52.34%] [G loss: 0.890803]\n",
      "epoch:13 step:12665 [D loss: 0.612900, acc.: 67.19%] [G loss: 0.893804]\n",
      "epoch:13 step:12666 [D loss: 0.635524, acc.: 68.75%] [G loss: 0.967845]\n",
      "epoch:13 step:12667 [D loss: 0.704904, acc.: 57.81%] [G loss: 0.938075]\n",
      "epoch:13 step:12668 [D loss: 0.675880, acc.: 57.03%] [G loss: 0.889639]\n",
      "epoch:13 step:12669 [D loss: 0.642730, acc.: 61.72%] [G loss: 0.948890]\n",
      "epoch:13 step:12670 [D loss: 0.681108, acc.: 56.25%] [G loss: 0.916989]\n",
      "epoch:13 step:12671 [D loss: 0.675325, acc.: 59.38%] [G loss: 0.911561]\n",
      "epoch:13 step:12672 [D loss: 0.641334, acc.: 61.72%] [G loss: 0.911668]\n",
      "epoch:13 step:12673 [D loss: 0.693014, acc.: 60.16%] [G loss: 0.847845]\n",
      "epoch:13 step:12674 [D loss: 0.697990, acc.: 56.25%] [G loss: 0.885722]\n",
      "epoch:13 step:12675 [D loss: 0.634269, acc.: 66.41%] [G loss: 0.825840]\n",
      "epoch:13 step:12676 [D loss: 0.611908, acc.: 70.31%] [G loss: 0.873413]\n",
      "epoch:13 step:12677 [D loss: 0.670367, acc.: 57.03%] [G loss: 0.900997]\n",
      "epoch:13 step:12678 [D loss: 0.672975, acc.: 57.03%] [G loss: 0.906135]\n",
      "epoch:13 step:12679 [D loss: 0.614495, acc.: 73.44%] [G loss: 0.964400]\n",
      "epoch:13 step:12680 [D loss: 0.623844, acc.: 71.88%] [G loss: 0.972130]\n",
      "epoch:13 step:12681 [D loss: 0.735762, acc.: 50.00%] [G loss: 0.930752]\n",
      "epoch:13 step:12682 [D loss: 0.717391, acc.: 50.78%] [G loss: 0.890867]\n",
      "epoch:13 step:12683 [D loss: 0.708432, acc.: 53.91%] [G loss: 0.897486]\n",
      "epoch:13 step:12684 [D loss: 0.657668, acc.: 63.28%] [G loss: 0.906167]\n",
      "epoch:13 step:12685 [D loss: 0.583525, acc.: 74.22%] [G loss: 0.880053]\n",
      "epoch:13 step:12686 [D loss: 0.592726, acc.: 68.75%] [G loss: 0.975005]\n",
      "epoch:13 step:12687 [D loss: 0.662491, acc.: 60.94%] [G loss: 0.957171]\n",
      "epoch:13 step:12688 [D loss: 0.622174, acc.: 67.97%] [G loss: 1.016273]\n",
      "epoch:13 step:12689 [D loss: 0.587454, acc.: 71.88%] [G loss: 1.135723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12690 [D loss: 0.741435, acc.: 52.34%] [G loss: 0.955412]\n",
      "epoch:13 step:12691 [D loss: 0.694713, acc.: 57.81%] [G loss: 0.901351]\n",
      "epoch:13 step:12692 [D loss: 0.713999, acc.: 50.78%] [G loss: 0.860227]\n",
      "epoch:13 step:12693 [D loss: 0.643725, acc.: 61.72%] [G loss: 0.827800]\n",
      "epoch:13 step:12694 [D loss: 0.619135, acc.: 66.41%] [G loss: 0.939326]\n",
      "epoch:13 step:12695 [D loss: 0.641715, acc.: 60.16%] [G loss: 0.907178]\n",
      "epoch:13 step:12696 [D loss: 0.596961, acc.: 68.75%] [G loss: 0.951834]\n",
      "epoch:13 step:12697 [D loss: 0.614212, acc.: 67.19%] [G loss: 0.888730]\n",
      "epoch:13 step:12698 [D loss: 0.713723, acc.: 58.59%] [G loss: 0.881307]\n",
      "epoch:13 step:12699 [D loss: 0.657841, acc.: 64.84%] [G loss: 0.912048]\n",
      "epoch:13 step:12700 [D loss: 0.631086, acc.: 64.06%] [G loss: 0.945720]\n",
      "epoch:13 step:12701 [D loss: 0.640922, acc.: 65.62%] [G loss: 0.991597]\n",
      "epoch:13 step:12702 [D loss: 0.631347, acc.: 60.94%] [G loss: 0.964124]\n",
      "epoch:13 step:12703 [D loss: 0.656214, acc.: 60.16%] [G loss: 0.951312]\n",
      "epoch:13 step:12704 [D loss: 0.606495, acc.: 69.53%] [G loss: 0.943607]\n",
      "epoch:13 step:12705 [D loss: 0.688133, acc.: 55.47%] [G loss: 0.903095]\n",
      "epoch:13 step:12706 [D loss: 0.717150, acc.: 60.16%] [G loss: 0.896398]\n",
      "epoch:13 step:12707 [D loss: 0.624745, acc.: 67.19%] [G loss: 0.958542]\n",
      "epoch:13 step:12708 [D loss: 0.656355, acc.: 60.16%] [G loss: 0.910757]\n",
      "epoch:13 step:12709 [D loss: 0.669577, acc.: 59.38%] [G loss: 0.953155]\n",
      "epoch:13 step:12710 [D loss: 0.706188, acc.: 57.03%] [G loss: 0.906631]\n",
      "epoch:13 step:12711 [D loss: 0.639780, acc.: 63.28%] [G loss: 0.968365]\n",
      "epoch:13 step:12712 [D loss: 0.722366, acc.: 49.22%] [G loss: 0.829443]\n",
      "epoch:13 step:12713 [D loss: 0.626294, acc.: 68.75%] [G loss: 0.876115]\n",
      "epoch:13 step:12714 [D loss: 0.696585, acc.: 57.03%] [G loss: 0.894743]\n",
      "epoch:13 step:12715 [D loss: 0.616173, acc.: 64.84%] [G loss: 0.910201]\n",
      "epoch:13 step:12716 [D loss: 0.663457, acc.: 60.94%] [G loss: 0.903654]\n",
      "epoch:13 step:12717 [D loss: 0.671649, acc.: 58.59%] [G loss: 0.940830]\n",
      "epoch:13 step:12718 [D loss: 0.661500, acc.: 60.94%] [G loss: 0.924751]\n",
      "epoch:13 step:12719 [D loss: 0.658504, acc.: 61.72%] [G loss: 0.867822]\n",
      "epoch:13 step:12720 [D loss: 0.639395, acc.: 62.50%] [G loss: 0.918880]\n",
      "epoch:13 step:12721 [D loss: 0.658912, acc.: 58.59%] [G loss: 0.885656]\n",
      "epoch:13 step:12722 [D loss: 0.670897, acc.: 60.16%] [G loss: 0.867598]\n",
      "epoch:13 step:12723 [D loss: 0.752290, acc.: 46.88%] [G loss: 0.872506]\n",
      "epoch:13 step:12724 [D loss: 0.736568, acc.: 50.00%] [G loss: 0.930716]\n",
      "epoch:13 step:12725 [D loss: 0.646819, acc.: 60.94%] [G loss: 0.876932]\n",
      "epoch:13 step:12726 [D loss: 0.645010, acc.: 64.06%] [G loss: 0.928814]\n",
      "epoch:13 step:12727 [D loss: 0.659883, acc.: 61.72%] [G loss: 0.900381]\n",
      "epoch:13 step:12728 [D loss: 0.602996, acc.: 67.19%] [G loss: 0.924376]\n",
      "epoch:13 step:12729 [D loss: 0.646709, acc.: 60.94%] [G loss: 0.907215]\n",
      "epoch:13 step:12730 [D loss: 0.668389, acc.: 57.81%] [G loss: 0.934921]\n",
      "epoch:13 step:12731 [D loss: 0.620680, acc.: 67.97%] [G loss: 0.910714]\n",
      "epoch:13 step:12732 [D loss: 0.599358, acc.: 64.84%] [G loss: 0.916887]\n",
      "epoch:13 step:12733 [D loss: 0.641049, acc.: 64.84%] [G loss: 0.937901]\n",
      "epoch:13 step:12734 [D loss: 0.667094, acc.: 63.28%] [G loss: 0.935077]\n",
      "epoch:13 step:12735 [D loss: 0.687020, acc.: 60.16%] [G loss: 0.894883]\n",
      "epoch:13 step:12736 [D loss: 0.632840, acc.: 64.84%] [G loss: 0.925533]\n",
      "epoch:13 step:12737 [D loss: 0.643970, acc.: 69.53%] [G loss: 0.930938]\n",
      "epoch:13 step:12738 [D loss: 0.619762, acc.: 64.84%] [G loss: 0.902670]\n",
      "epoch:13 step:12739 [D loss: 0.637998, acc.: 64.84%] [G loss: 0.938066]\n",
      "epoch:13 step:12740 [D loss: 0.708413, acc.: 52.34%] [G loss: 0.908720]\n",
      "epoch:13 step:12741 [D loss: 0.668461, acc.: 55.47%] [G loss: 0.881400]\n",
      "epoch:13 step:12742 [D loss: 0.608551, acc.: 67.97%] [G loss: 0.907945]\n",
      "epoch:13 step:12743 [D loss: 0.614228, acc.: 67.19%] [G loss: 0.925634]\n",
      "epoch:13 step:12744 [D loss: 0.609693, acc.: 67.97%] [G loss: 0.943834]\n",
      "epoch:13 step:12745 [D loss: 0.552085, acc.: 75.78%] [G loss: 1.026077]\n",
      "epoch:13 step:12746 [D loss: 0.683926, acc.: 58.59%] [G loss: 0.954616]\n",
      "epoch:13 step:12747 [D loss: 0.757168, acc.: 48.44%] [G loss: 0.963486]\n",
      "epoch:13 step:12748 [D loss: 0.603921, acc.: 68.75%] [G loss: 0.932324]\n",
      "epoch:13 step:12749 [D loss: 0.647128, acc.: 64.84%] [G loss: 0.906284]\n",
      "epoch:13 step:12750 [D loss: 0.720312, acc.: 51.56%] [G loss: 0.889630]\n",
      "epoch:13 step:12751 [D loss: 0.670345, acc.: 60.16%] [G loss: 0.939503]\n",
      "epoch:13 step:12752 [D loss: 0.608583, acc.: 67.19%] [G loss: 0.943157]\n",
      "epoch:13 step:12753 [D loss: 0.682510, acc.: 59.38%] [G loss: 0.888763]\n",
      "epoch:13 step:12754 [D loss: 0.692231, acc.: 52.34%] [G loss: 0.934108]\n",
      "epoch:13 step:12755 [D loss: 0.615411, acc.: 64.84%] [G loss: 0.993540]\n",
      "epoch:13 step:12756 [D loss: 0.577470, acc.: 67.19%] [G loss: 1.055930]\n",
      "epoch:13 step:12757 [D loss: 0.690851, acc.: 60.16%] [G loss: 0.948108]\n",
      "epoch:13 step:12758 [D loss: 0.675004, acc.: 60.94%] [G loss: 0.942840]\n",
      "epoch:13 step:12759 [D loss: 0.670735, acc.: 61.72%] [G loss: 0.844001]\n",
      "epoch:13 step:12760 [D loss: 0.691801, acc.: 56.25%] [G loss: 0.938421]\n",
      "epoch:13 step:12761 [D loss: 0.648535, acc.: 60.94%] [G loss: 0.904241]\n",
      "epoch:13 step:12762 [D loss: 0.579395, acc.: 68.75%] [G loss: 0.914472]\n",
      "epoch:13 step:12763 [D loss: 0.586833, acc.: 68.75%] [G loss: 0.952796]\n",
      "epoch:13 step:12764 [D loss: 0.667278, acc.: 56.25%] [G loss: 0.942523]\n",
      "epoch:13 step:12765 [D loss: 0.666389, acc.: 60.16%] [G loss: 0.847689]\n",
      "epoch:13 step:12766 [D loss: 0.620332, acc.: 65.62%] [G loss: 0.860865]\n",
      "epoch:13 step:12767 [D loss: 0.699635, acc.: 56.25%] [G loss: 0.883627]\n",
      "epoch:13 step:12768 [D loss: 0.689133, acc.: 55.47%] [G loss: 0.900291]\n",
      "epoch:13 step:12769 [D loss: 0.677012, acc.: 60.16%] [G loss: 0.874973]\n",
      "epoch:13 step:12770 [D loss: 0.666318, acc.: 55.47%] [G loss: 0.909449]\n",
      "epoch:13 step:12771 [D loss: 0.670329, acc.: 60.94%] [G loss: 0.965146]\n",
      "epoch:13 step:12772 [D loss: 0.655321, acc.: 53.91%] [G loss: 0.901261]\n",
      "epoch:13 step:12773 [D loss: 0.614357, acc.: 66.41%] [G loss: 0.926458]\n",
      "epoch:13 step:12774 [D loss: 0.579149, acc.: 72.66%] [G loss: 0.857614]\n",
      "epoch:13 step:12775 [D loss: 0.697570, acc.: 54.69%] [G loss: 0.864189]\n",
      "epoch:13 step:12776 [D loss: 0.616163, acc.: 66.41%] [G loss: 0.882400]\n",
      "epoch:13 step:12777 [D loss: 0.675453, acc.: 61.72%] [G loss: 0.890998]\n",
      "epoch:13 step:12778 [D loss: 0.676483, acc.: 56.25%] [G loss: 0.912196]\n",
      "epoch:13 step:12779 [D loss: 0.664980, acc.: 61.72%] [G loss: 0.878836]\n",
      "epoch:13 step:12780 [D loss: 0.653875, acc.: 60.94%] [G loss: 0.897547]\n",
      "epoch:13 step:12781 [D loss: 0.729228, acc.: 53.91%] [G loss: 0.906401]\n",
      "epoch:13 step:12782 [D loss: 0.679849, acc.: 62.50%] [G loss: 0.876616]\n",
      "epoch:13 step:12783 [D loss: 0.673166, acc.: 56.25%] [G loss: 0.928285]\n",
      "epoch:13 step:12784 [D loss: 0.691581, acc.: 58.59%] [G loss: 0.906086]\n",
      "epoch:13 step:12785 [D loss: 0.682995, acc.: 60.94%] [G loss: 0.973680]\n",
      "epoch:13 step:12786 [D loss: 0.642953, acc.: 64.06%] [G loss: 0.926271]\n",
      "epoch:13 step:12787 [D loss: 0.676732, acc.: 59.38%] [G loss: 0.895663]\n",
      "epoch:13 step:12788 [D loss: 0.662810, acc.: 54.69%] [G loss: 0.913268]\n",
      "epoch:13 step:12789 [D loss: 0.651066, acc.: 63.28%] [G loss: 0.831983]\n",
      "epoch:13 step:12790 [D loss: 0.658747, acc.: 55.47%] [G loss: 0.890492]\n",
      "epoch:13 step:12791 [D loss: 0.647587, acc.: 59.38%] [G loss: 0.874817]\n",
      "epoch:13 step:12792 [D loss: 0.680965, acc.: 54.69%] [G loss: 0.850861]\n",
      "epoch:13 step:12793 [D loss: 0.645549, acc.: 64.06%] [G loss: 0.914767]\n",
      "epoch:13 step:12794 [D loss: 0.661069, acc.: 63.28%] [G loss: 0.925816]\n",
      "epoch:13 step:12795 [D loss: 0.645065, acc.: 60.16%] [G loss: 0.921040]\n",
      "epoch:13 step:12796 [D loss: 0.703307, acc.: 54.69%] [G loss: 0.889270]\n",
      "epoch:13 step:12797 [D loss: 0.661884, acc.: 58.59%] [G loss: 0.909247]\n",
      "epoch:13 step:12798 [D loss: 0.656577, acc.: 57.81%] [G loss: 0.877710]\n",
      "epoch:13 step:12799 [D loss: 0.598139, acc.: 67.19%] [G loss: 0.912617]\n",
      "epoch:13 step:12800 [D loss: 0.663382, acc.: 58.59%] [G loss: 0.862798]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.097649\n",
      "FID: 6.261251\n",
      "0 = 11.776482323217436\n",
      "1 = 0.04689025630634375\n",
      "2 = 0.918749988079071\n",
      "3 = 0.8798999786376953\n",
      "4 = 0.9575999975204468\n",
      "5 = 0.9540279507637024\n",
      "6 = 0.8798999786376953\n",
      "7 = 5.641988468533777\n",
      "8 = 0.04985970842566162\n",
      "9 = 0.6941499710083008\n",
      "10 = 0.6721000075340271\n",
      "11 = 0.7161999940872192\n",
      "12 = 0.7031069993972778\n",
      "13 = 0.6721000075340271\n",
      "14 = 8.097716331481934\n",
      "15 = 9.561214447021484\n",
      "16 = 0.10561555624008179\n",
      "17 = 8.097648620605469\n",
      "18 = 6.261251449584961\n",
      "epoch:13 step:12801 [D loss: 0.615117, acc.: 68.75%] [G loss: 0.925646]\n",
      "epoch:13 step:12802 [D loss: 0.688686, acc.: 50.78%] [G loss: 0.906845]\n",
      "epoch:13 step:12803 [D loss: 0.740046, acc.: 48.44%] [G loss: 0.891013]\n",
      "epoch:13 step:12804 [D loss: 0.676856, acc.: 54.69%] [G loss: 0.862401]\n",
      "epoch:13 step:12805 [D loss: 0.599104, acc.: 68.75%] [G loss: 0.838309]\n",
      "epoch:13 step:12806 [D loss: 0.669908, acc.: 60.94%] [G loss: 0.873953]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12807 [D loss: 0.684969, acc.: 56.25%] [G loss: 0.872530]\n",
      "epoch:13 step:12808 [D loss: 0.645054, acc.: 63.28%] [G loss: 0.908852]\n",
      "epoch:13 step:12809 [D loss: 0.682546, acc.: 61.72%] [G loss: 0.888659]\n",
      "epoch:13 step:12810 [D loss: 0.635151, acc.: 64.84%] [G loss: 0.872047]\n",
      "epoch:13 step:12811 [D loss: 0.670888, acc.: 57.81%] [G loss: 0.852615]\n",
      "epoch:13 step:12812 [D loss: 0.638188, acc.: 70.31%] [G loss: 0.907722]\n",
      "epoch:13 step:12813 [D loss: 0.659116, acc.: 60.94%] [G loss: 0.914014]\n",
      "epoch:13 step:12814 [D loss: 0.659637, acc.: 62.50%] [G loss: 0.947179]\n",
      "epoch:13 step:12815 [D loss: 0.671482, acc.: 60.16%] [G loss: 0.979665]\n",
      "epoch:13 step:12816 [D loss: 0.628724, acc.: 66.41%] [G loss: 0.969193]\n",
      "epoch:13 step:12817 [D loss: 0.683546, acc.: 54.69%] [G loss: 0.908408]\n",
      "epoch:13 step:12818 [D loss: 0.640657, acc.: 65.62%] [G loss: 0.881652]\n",
      "epoch:13 step:12819 [D loss: 0.677843, acc.: 58.59%] [G loss: 0.895046]\n",
      "epoch:13 step:12820 [D loss: 0.673831, acc.: 57.03%] [G loss: 0.954215]\n",
      "epoch:13 step:12821 [D loss: 0.623668, acc.: 64.06%] [G loss: 0.864608]\n",
      "epoch:13 step:12822 [D loss: 0.667385, acc.: 61.72%] [G loss: 0.894730]\n",
      "epoch:13 step:12823 [D loss: 0.605984, acc.: 74.22%] [G loss: 0.911080]\n",
      "epoch:13 step:12824 [D loss: 0.626776, acc.: 59.38%] [G loss: 0.950065]\n",
      "epoch:13 step:12825 [D loss: 0.718752, acc.: 46.09%] [G loss: 0.903398]\n",
      "epoch:13 step:12826 [D loss: 0.662208, acc.: 59.38%] [G loss: 0.899857]\n",
      "epoch:13 step:12827 [D loss: 0.672923, acc.: 55.47%] [G loss: 0.891230]\n",
      "epoch:13 step:12828 [D loss: 0.650684, acc.: 62.50%] [G loss: 0.844708]\n",
      "epoch:13 step:12829 [D loss: 0.578591, acc.: 79.69%] [G loss: 0.945921]\n",
      "epoch:13 step:12830 [D loss: 0.586575, acc.: 69.53%] [G loss: 0.892041]\n",
      "epoch:13 step:12831 [D loss: 0.611045, acc.: 66.41%] [G loss: 0.974590]\n",
      "epoch:13 step:12832 [D loss: 0.644865, acc.: 60.16%] [G loss: 0.924774]\n",
      "epoch:13 step:12833 [D loss: 0.676029, acc.: 58.59%] [G loss: 0.905034]\n",
      "epoch:13 step:12834 [D loss: 0.667719, acc.: 58.59%] [G loss: 0.862749]\n",
      "epoch:13 step:12835 [D loss: 0.657646, acc.: 57.03%] [G loss: 0.871952]\n",
      "epoch:13 step:12836 [D loss: 0.729859, acc.: 51.56%] [G loss: 0.872199]\n",
      "epoch:13 step:12837 [D loss: 0.665025, acc.: 61.72%] [G loss: 0.926298]\n",
      "epoch:13 step:12838 [D loss: 0.697352, acc.: 53.91%] [G loss: 0.918501]\n",
      "epoch:13 step:12839 [D loss: 0.657760, acc.: 60.16%] [G loss: 0.954136]\n",
      "epoch:13 step:12840 [D loss: 0.612513, acc.: 67.97%] [G loss: 0.988057]\n",
      "epoch:13 step:12841 [D loss: 0.630070, acc.: 64.06%] [G loss: 0.962714]\n",
      "epoch:13 step:12842 [D loss: 0.629092, acc.: 64.84%] [G loss: 0.998673]\n",
      "epoch:13 step:12843 [D loss: 0.690395, acc.: 58.59%] [G loss: 0.941343]\n",
      "epoch:13 step:12844 [D loss: 0.700339, acc.: 50.00%] [G loss: 0.872520]\n",
      "epoch:13 step:12845 [D loss: 0.695648, acc.: 53.91%] [G loss: 0.882036]\n",
      "epoch:13 step:12846 [D loss: 0.680494, acc.: 53.91%] [G loss: 0.936779]\n",
      "epoch:13 step:12847 [D loss: 0.622094, acc.: 65.62%] [G loss: 0.909006]\n",
      "epoch:13 step:12848 [D loss: 0.663193, acc.: 59.38%] [G loss: 0.980127]\n",
      "epoch:13 step:12849 [D loss: 0.642760, acc.: 62.50%] [G loss: 0.990844]\n",
      "epoch:13 step:12850 [D loss: 0.626226, acc.: 67.19%] [G loss: 0.922699]\n",
      "epoch:13 step:12851 [D loss: 0.680231, acc.: 56.25%] [G loss: 0.872238]\n",
      "epoch:13 step:12852 [D loss: 0.664828, acc.: 62.50%] [G loss: 0.878355]\n",
      "epoch:13 step:12853 [D loss: 0.678563, acc.: 55.47%] [G loss: 0.853626]\n",
      "epoch:13 step:12854 [D loss: 0.685187, acc.: 60.16%] [G loss: 0.826736]\n",
      "epoch:13 step:12855 [D loss: 0.644043, acc.: 60.94%] [G loss: 0.905955]\n",
      "epoch:13 step:12856 [D loss: 0.735022, acc.: 44.53%] [G loss: 0.925399]\n",
      "epoch:13 step:12857 [D loss: 0.623170, acc.: 66.41%] [G loss: 0.844971]\n",
      "epoch:13 step:12858 [D loss: 0.665419, acc.: 62.50%] [G loss: 0.921184]\n",
      "epoch:13 step:12859 [D loss: 0.713396, acc.: 55.47%] [G loss: 0.925614]\n",
      "epoch:13 step:12860 [D loss: 0.617275, acc.: 67.19%] [G loss: 0.941530]\n",
      "epoch:13 step:12861 [D loss: 0.651063, acc.: 61.72%] [G loss: 0.909040]\n",
      "epoch:13 step:12862 [D loss: 0.621618, acc.: 67.19%] [G loss: 0.894132]\n",
      "epoch:13 step:12863 [D loss: 0.685677, acc.: 57.81%] [G loss: 0.932851]\n",
      "epoch:13 step:12864 [D loss: 0.663279, acc.: 53.91%] [G loss: 0.873084]\n",
      "epoch:13 step:12865 [D loss: 0.651654, acc.: 66.41%] [G loss: 0.886635]\n",
      "epoch:13 step:12866 [D loss: 0.644507, acc.: 62.50%] [G loss: 0.898529]\n",
      "epoch:13 step:12867 [D loss: 0.656093, acc.: 57.03%] [G loss: 0.882067]\n",
      "epoch:13 step:12868 [D loss: 0.707325, acc.: 54.69%] [G loss: 0.904630]\n",
      "epoch:13 step:12869 [D loss: 0.640836, acc.: 65.62%] [G loss: 0.864886]\n",
      "epoch:13 step:12870 [D loss: 0.641499, acc.: 64.84%] [G loss: 0.922213]\n",
      "epoch:13 step:12871 [D loss: 0.650634, acc.: 62.50%] [G loss: 0.917640]\n",
      "epoch:13 step:12872 [D loss: 0.600215, acc.: 65.62%] [G loss: 0.903947]\n",
      "epoch:13 step:12873 [D loss: 0.618431, acc.: 61.72%] [G loss: 0.949093]\n",
      "epoch:13 step:12874 [D loss: 0.635360, acc.: 63.28%] [G loss: 0.942765]\n",
      "epoch:13 step:12875 [D loss: 0.606144, acc.: 66.41%] [G loss: 0.932092]\n",
      "epoch:13 step:12876 [D loss: 0.668608, acc.: 58.59%] [G loss: 0.968565]\n",
      "epoch:13 step:12877 [D loss: 0.662683, acc.: 60.16%] [G loss: 0.929316]\n",
      "epoch:13 step:12878 [D loss: 0.637403, acc.: 65.62%] [G loss: 0.916882]\n",
      "epoch:13 step:12879 [D loss: 0.696661, acc.: 55.47%] [G loss: 0.902139]\n",
      "epoch:13 step:12880 [D loss: 0.603226, acc.: 70.31%] [G loss: 0.917095]\n",
      "epoch:13 step:12881 [D loss: 0.603609, acc.: 67.97%] [G loss: 0.937459]\n",
      "epoch:13 step:12882 [D loss: 0.650431, acc.: 59.38%] [G loss: 0.921626]\n",
      "epoch:13 step:12883 [D loss: 0.617842, acc.: 64.06%] [G loss: 0.968396]\n",
      "epoch:13 step:12884 [D loss: 0.697543, acc.: 55.47%] [G loss: 0.930983]\n",
      "epoch:13 step:12885 [D loss: 0.705352, acc.: 53.12%] [G loss: 0.916436]\n",
      "epoch:13 step:12886 [D loss: 0.659554, acc.: 66.41%] [G loss: 0.853820]\n",
      "epoch:13 step:12887 [D loss: 0.621995, acc.: 66.41%] [G loss: 0.897248]\n",
      "epoch:13 step:12888 [D loss: 0.603095, acc.: 68.75%] [G loss: 0.857205]\n",
      "epoch:13 step:12889 [D loss: 0.612429, acc.: 66.41%] [G loss: 0.973871]\n",
      "epoch:13 step:12890 [D loss: 0.609470, acc.: 71.88%] [G loss: 0.893643]\n",
      "epoch:13 step:12891 [D loss: 0.697859, acc.: 54.69%] [G loss: 0.854834]\n",
      "epoch:13 step:12892 [D loss: 0.719027, acc.: 53.91%] [G loss: 0.859515]\n",
      "epoch:13 step:12893 [D loss: 0.641336, acc.: 63.28%] [G loss: 0.896645]\n",
      "epoch:13 step:12894 [D loss: 0.650077, acc.: 60.94%] [G loss: 0.897318]\n",
      "epoch:13 step:12895 [D loss: 0.671225, acc.: 60.16%] [G loss: 0.889938]\n",
      "epoch:13 step:12896 [D loss: 0.687085, acc.: 56.25%] [G loss: 0.903754]\n",
      "epoch:13 step:12897 [D loss: 0.705850, acc.: 53.12%] [G loss: 0.866495]\n",
      "epoch:13 step:12898 [D loss: 0.680286, acc.: 54.69%] [G loss: 0.890608]\n",
      "epoch:13 step:12899 [D loss: 0.666339, acc.: 57.03%] [G loss: 0.895305]\n",
      "epoch:13 step:12900 [D loss: 0.610963, acc.: 66.41%] [G loss: 0.949049]\n",
      "epoch:13 step:12901 [D loss: 0.657020, acc.: 59.38%] [G loss: 0.942175]\n",
      "epoch:13 step:12902 [D loss: 0.690139, acc.: 53.91%] [G loss: 0.904747]\n",
      "epoch:13 step:12903 [D loss: 0.741719, acc.: 50.00%] [G loss: 0.891959]\n",
      "epoch:13 step:12904 [D loss: 0.668985, acc.: 55.47%] [G loss: 0.870696]\n",
      "epoch:13 step:12905 [D loss: 0.651309, acc.: 60.94%] [G loss: 0.906462]\n",
      "epoch:13 step:12906 [D loss: 0.636795, acc.: 65.62%] [G loss: 0.953387]\n",
      "epoch:13 step:12907 [D loss: 0.638669, acc.: 67.19%] [G loss: 0.918034]\n",
      "epoch:13 step:12908 [D loss: 0.705641, acc.: 60.94%] [G loss: 0.915425]\n",
      "epoch:13 step:12909 [D loss: 0.693917, acc.: 57.81%] [G loss: 0.888348]\n",
      "epoch:13 step:12910 [D loss: 0.701682, acc.: 51.56%] [G loss: 0.881946]\n",
      "epoch:13 step:12911 [D loss: 0.633966, acc.: 63.28%] [G loss: 0.922441]\n",
      "epoch:13 step:12912 [D loss: 0.638324, acc.: 62.50%] [G loss: 0.956797]\n",
      "epoch:13 step:12913 [D loss: 0.626248, acc.: 61.72%] [G loss: 0.971676]\n",
      "epoch:13 step:12914 [D loss: 0.608609, acc.: 68.75%] [G loss: 0.929045]\n",
      "epoch:13 step:12915 [D loss: 0.688304, acc.: 54.69%] [G loss: 0.972072]\n",
      "epoch:13 step:12916 [D loss: 0.651623, acc.: 62.50%] [G loss: 0.969046]\n",
      "epoch:13 step:12917 [D loss: 0.611991, acc.: 60.94%] [G loss: 0.819610]\n",
      "epoch:13 step:12918 [D loss: 0.618231, acc.: 62.50%] [G loss: 0.892999]\n",
      "epoch:13 step:12919 [D loss: 0.683281, acc.: 60.16%] [G loss: 0.881298]\n",
      "epoch:13 step:12920 [D loss: 0.699678, acc.: 53.91%] [G loss: 0.877960]\n",
      "epoch:13 step:12921 [D loss: 0.673848, acc.: 53.91%] [G loss: 0.832714]\n",
      "epoch:13 step:12922 [D loss: 0.701516, acc.: 57.03%] [G loss: 0.857212]\n",
      "epoch:13 step:12923 [D loss: 0.670651, acc.: 55.47%] [G loss: 0.886828]\n",
      "epoch:13 step:12924 [D loss: 0.615431, acc.: 70.31%] [G loss: 0.945708]\n",
      "epoch:13 step:12925 [D loss: 0.655211, acc.: 63.28%] [G loss: 0.943887]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12926 [D loss: 0.678336, acc.: 55.47%] [G loss: 0.968301]\n",
      "epoch:13 step:12927 [D loss: 0.601435, acc.: 67.19%] [G loss: 0.940031]\n",
      "epoch:13 step:12928 [D loss: 0.627622, acc.: 65.62%] [G loss: 0.927510]\n",
      "epoch:13 step:12929 [D loss: 0.660125, acc.: 62.50%] [G loss: 0.939622]\n",
      "epoch:13 step:12930 [D loss: 0.666619, acc.: 59.38%] [G loss: 0.931149]\n",
      "epoch:13 step:12931 [D loss: 0.637324, acc.: 64.06%] [G loss: 0.953106]\n",
      "epoch:13 step:12932 [D loss: 0.630795, acc.: 62.50%] [G loss: 0.900038]\n",
      "epoch:13 step:12933 [D loss: 0.721116, acc.: 51.56%] [G loss: 0.903684]\n",
      "epoch:13 step:12934 [D loss: 0.659033, acc.: 63.28%] [G loss: 0.898640]\n",
      "epoch:13 step:12935 [D loss: 0.623092, acc.: 65.62%] [G loss: 0.953636]\n",
      "epoch:13 step:12936 [D loss: 0.637411, acc.: 62.50%] [G loss: 0.950537]\n",
      "epoch:13 step:12937 [D loss: 0.627688, acc.: 67.19%] [G loss: 0.914819]\n",
      "epoch:13 step:12938 [D loss: 0.720979, acc.: 51.56%] [G loss: 0.820289]\n",
      "epoch:13 step:12939 [D loss: 0.650819, acc.: 58.59%] [G loss: 0.838800]\n",
      "epoch:13 step:12940 [D loss: 0.700596, acc.: 55.47%] [G loss: 0.840441]\n",
      "epoch:13 step:12941 [D loss: 0.660359, acc.: 60.94%] [G loss: 0.878662]\n",
      "epoch:13 step:12942 [D loss: 0.703680, acc.: 48.44%] [G loss: 0.961623]\n",
      "epoch:13 step:12943 [D loss: 0.701291, acc.: 55.47%] [G loss: 0.890014]\n",
      "epoch:13 step:12944 [D loss: 0.673928, acc.: 57.03%] [G loss: 0.879292]\n",
      "epoch:13 step:12945 [D loss: 0.679347, acc.: 52.34%] [G loss: 0.888946]\n",
      "epoch:13 step:12946 [D loss: 0.727545, acc.: 51.56%] [G loss: 0.893849]\n",
      "epoch:13 step:12947 [D loss: 0.713329, acc.: 47.66%] [G loss: 0.896129]\n",
      "epoch:13 step:12948 [D loss: 0.625110, acc.: 64.84%] [G loss: 0.890062]\n",
      "epoch:13 step:12949 [D loss: 0.665011, acc.: 64.06%] [G loss: 0.891734]\n",
      "epoch:13 step:12950 [D loss: 0.620438, acc.: 65.62%] [G loss: 0.945265]\n",
      "epoch:13 step:12951 [D loss: 0.644396, acc.: 64.06%] [G loss: 1.001954]\n",
      "epoch:13 step:12952 [D loss: 0.681774, acc.: 59.38%] [G loss: 0.894188]\n",
      "epoch:13 step:12953 [D loss: 0.715235, acc.: 54.69%] [G loss: 0.930619]\n",
      "epoch:13 step:12954 [D loss: 0.626629, acc.: 67.19%] [G loss: 0.940055]\n",
      "epoch:13 step:12955 [D loss: 0.679092, acc.: 62.50%] [G loss: 0.900931]\n",
      "epoch:13 step:12956 [D loss: 0.646708, acc.: 58.59%] [G loss: 0.948146]\n",
      "epoch:13 step:12957 [D loss: 0.668232, acc.: 62.50%] [G loss: 1.003697]\n",
      "epoch:13 step:12958 [D loss: 0.646425, acc.: 63.28%] [G loss: 0.934262]\n",
      "epoch:13 step:12959 [D loss: 0.646293, acc.: 65.62%] [G loss: 0.963711]\n",
      "epoch:13 step:12960 [D loss: 0.627632, acc.: 64.84%] [G loss: 0.917250]\n",
      "epoch:13 step:12961 [D loss: 0.634187, acc.: 64.06%] [G loss: 0.925408]\n",
      "epoch:13 step:12962 [D loss: 0.592071, acc.: 67.97%] [G loss: 1.013443]\n",
      "epoch:13 step:12963 [D loss: 0.625223, acc.: 60.94%] [G loss: 1.047626]\n",
      "epoch:13 step:12964 [D loss: 0.717643, acc.: 57.81%] [G loss: 0.969253]\n",
      "epoch:13 step:12965 [D loss: 0.754778, acc.: 45.31%] [G loss: 0.843033]\n",
      "epoch:13 step:12966 [D loss: 0.640197, acc.: 66.41%] [G loss: 0.867306]\n",
      "epoch:13 step:12967 [D loss: 0.628040, acc.: 60.94%] [G loss: 0.858090]\n",
      "epoch:13 step:12968 [D loss: 0.701065, acc.: 55.47%] [G loss: 0.907432]\n",
      "epoch:13 step:12969 [D loss: 0.748440, acc.: 45.31%] [G loss: 0.969392]\n",
      "epoch:13 step:12970 [D loss: 0.661259, acc.: 57.03%] [G loss: 0.921740]\n",
      "epoch:13 step:12971 [D loss: 0.679477, acc.: 58.59%] [G loss: 0.879629]\n",
      "epoch:13 step:12972 [D loss: 0.670997, acc.: 57.81%] [G loss: 0.868114]\n",
      "epoch:13 step:12973 [D loss: 0.615001, acc.: 72.66%] [G loss: 0.924210]\n",
      "epoch:13 step:12974 [D loss: 0.638063, acc.: 61.72%] [G loss: 0.973156]\n",
      "epoch:13 step:12975 [D loss: 0.746593, acc.: 47.66%] [G loss: 0.888071]\n",
      "epoch:13 step:12976 [D loss: 0.697229, acc.: 47.66%] [G loss: 0.962990]\n",
      "epoch:13 step:12977 [D loss: 0.604456, acc.: 64.84%] [G loss: 0.927839]\n",
      "epoch:13 step:12978 [D loss: 0.653254, acc.: 62.50%] [G loss: 0.940669]\n",
      "epoch:13 step:12979 [D loss: 0.710335, acc.: 47.66%] [G loss: 0.907668]\n",
      "epoch:13 step:12980 [D loss: 0.627650, acc.: 70.31%] [G loss: 0.910524]\n",
      "epoch:13 step:12981 [D loss: 0.667686, acc.: 60.94%] [G loss: 0.909640]\n",
      "epoch:13 step:12982 [D loss: 0.596249, acc.: 67.97%] [G loss: 0.943433]\n",
      "epoch:13 step:12983 [D loss: 0.606341, acc.: 71.09%] [G loss: 0.946096]\n",
      "epoch:13 step:12984 [D loss: 0.644165, acc.: 58.59%] [G loss: 0.970199]\n",
      "epoch:13 step:12985 [D loss: 0.703173, acc.: 57.03%] [G loss: 0.900038]\n",
      "epoch:13 step:12986 [D loss: 0.706975, acc.: 55.47%] [G loss: 0.933872]\n",
      "epoch:13 step:12987 [D loss: 0.634449, acc.: 63.28%] [G loss: 0.831765]\n",
      "epoch:13 step:12988 [D loss: 0.612514, acc.: 64.84%] [G loss: 0.913466]\n",
      "epoch:13 step:12989 [D loss: 0.688880, acc.: 54.69%] [G loss: 0.903478]\n",
      "epoch:13 step:12990 [D loss: 0.709506, acc.: 51.56%] [G loss: 0.845135]\n",
      "epoch:13 step:12991 [D loss: 0.661341, acc.: 58.59%] [G loss: 0.840632]\n",
      "epoch:13 step:12992 [D loss: 0.657486, acc.: 63.28%] [G loss: 0.900642]\n",
      "epoch:13 step:12993 [D loss: 0.663764, acc.: 64.06%] [G loss: 0.841742]\n",
      "epoch:13 step:12994 [D loss: 0.668577, acc.: 58.59%] [G loss: 0.851383]\n",
      "epoch:13 step:12995 [D loss: 0.666571, acc.: 58.59%] [G loss: 0.873049]\n",
      "epoch:13 step:12996 [D loss: 0.601340, acc.: 65.62%] [G loss: 0.934592]\n",
      "epoch:13 step:12997 [D loss: 0.663648, acc.: 64.06%] [G loss: 0.948384]\n",
      "epoch:13 step:12998 [D loss: 0.679479, acc.: 60.16%] [G loss: 0.920879]\n",
      "epoch:13 step:12999 [D loss: 0.685275, acc.: 53.91%] [G loss: 0.904487]\n",
      "epoch:13 step:13000 [D loss: 0.624721, acc.: 70.31%] [G loss: 0.902335]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.078903\n",
      "FID: 7.797370\n",
      "0 = 11.772123636102618\n",
      "1 = 0.049282553356209305\n",
      "2 = 0.9186000227928162\n",
      "3 = 0.8695999979972839\n",
      "4 = 0.9675999879837036\n",
      "5 = 0.9640797972679138\n",
      "6 = 0.8695999979972839\n",
      "7 = 5.822213386458168\n",
      "8 = 0.061700475377457174\n",
      "9 = 0.7128000259399414\n",
      "10 = 0.6887000203132629\n",
      "11 = 0.7368999719619751\n",
      "12 = 0.7235763669013977\n",
      "13 = 0.6887000203132629\n",
      "14 = 8.078975677490234\n",
      "15 = 9.61483383178711\n",
      "16 = 0.08183757960796356\n",
      "17 = 8.078903198242188\n",
      "18 = 7.797370433807373\n",
      "epoch:13 step:13001 [D loss: 0.753233, acc.: 52.34%] [G loss: 0.869576]\n",
      "epoch:13 step:13002 [D loss: 0.703031, acc.: 56.25%] [G loss: 0.890760]\n",
      "epoch:13 step:13003 [D loss: 0.638089, acc.: 60.16%] [G loss: 0.830320]\n",
      "epoch:13 step:13004 [D loss: 0.648490, acc.: 65.62%] [G loss: 0.837182]\n",
      "epoch:13 step:13005 [D loss: 0.649942, acc.: 58.59%] [G loss: 0.854707]\n",
      "epoch:13 step:13006 [D loss: 0.611140, acc.: 64.84%] [G loss: 0.939697]\n",
      "epoch:13 step:13007 [D loss: 0.668547, acc.: 59.38%] [G loss: 0.888149]\n",
      "epoch:13 step:13008 [D loss: 0.675426, acc.: 56.25%] [G loss: 0.850929]\n",
      "epoch:13 step:13009 [D loss: 0.669586, acc.: 61.72%] [G loss: 0.880761]\n",
      "epoch:13 step:13010 [D loss: 0.691368, acc.: 55.47%] [G loss: 0.888416]\n",
      "epoch:13 step:13011 [D loss: 0.662755, acc.: 53.91%] [G loss: 0.843987]\n",
      "epoch:13 step:13012 [D loss: 0.654898, acc.: 59.38%] [G loss: 0.829373]\n",
      "epoch:13 step:13013 [D loss: 0.640779, acc.: 66.41%] [G loss: 0.805195]\n",
      "epoch:13 step:13014 [D loss: 0.620014, acc.: 67.97%] [G loss: 0.857445]\n",
      "epoch:13 step:13015 [D loss: 0.654394, acc.: 60.94%] [G loss: 0.915452]\n",
      "epoch:13 step:13016 [D loss: 0.633613, acc.: 69.53%] [G loss: 0.871686]\n",
      "epoch:13 step:13017 [D loss: 0.689534, acc.: 57.03%] [G loss: 0.887306]\n",
      "epoch:13 step:13018 [D loss: 0.632726, acc.: 64.84%] [G loss: 0.869089]\n",
      "epoch:13 step:13019 [D loss: 0.634527, acc.: 65.62%] [G loss: 0.880335]\n",
      "epoch:13 step:13020 [D loss: 0.673868, acc.: 53.91%] [G loss: 0.915762]\n",
      "epoch:13 step:13021 [D loss: 0.633996, acc.: 67.19%] [G loss: 0.908614]\n",
      "epoch:13 step:13022 [D loss: 0.663077, acc.: 59.38%] [G loss: 0.879149]\n",
      "epoch:13 step:13023 [D loss: 0.635313, acc.: 62.50%] [G loss: 0.823975]\n",
      "epoch:13 step:13024 [D loss: 0.694295, acc.: 56.25%] [G loss: 0.882470]\n",
      "epoch:13 step:13025 [D loss: 0.643307, acc.: 63.28%] [G loss: 0.861989]\n",
      "epoch:13 step:13026 [D loss: 0.661183, acc.: 62.50%] [G loss: 0.907763]\n",
      "epoch:13 step:13027 [D loss: 0.650574, acc.: 57.03%] [G loss: 0.853273]\n",
      "epoch:13 step:13028 [D loss: 0.690175, acc.: 60.16%] [G loss: 0.891167]\n",
      "epoch:13 step:13029 [D loss: 0.670645, acc.: 60.94%] [G loss: 0.859237]\n",
      "epoch:13 step:13030 [D loss: 0.624403, acc.: 66.41%] [G loss: 0.922002]\n",
      "epoch:13 step:13031 [D loss: 0.675472, acc.: 62.50%] [G loss: 0.894586]\n",
      "epoch:13 step:13032 [D loss: 0.687499, acc.: 54.69%] [G loss: 0.895617]\n",
      "epoch:13 step:13033 [D loss: 0.636027, acc.: 57.81%] [G loss: 0.889121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:13034 [D loss: 0.665806, acc.: 61.72%] [G loss: 0.920808]\n",
      "epoch:13 step:13035 [D loss: 0.626278, acc.: 69.53%] [G loss: 0.933607]\n",
      "epoch:13 step:13036 [D loss: 0.678024, acc.: 57.81%] [G loss: 0.929002]\n",
      "epoch:13 step:13037 [D loss: 0.705449, acc.: 50.00%] [G loss: 0.940845]\n",
      "epoch:13 step:13038 [D loss: 0.645656, acc.: 60.94%] [G loss: 0.940758]\n",
      "epoch:13 step:13039 [D loss: 0.720524, acc.: 54.69%] [G loss: 0.909829]\n",
      "epoch:13 step:13040 [D loss: 0.695141, acc.: 54.69%] [G loss: 0.897257]\n",
      "epoch:13 step:13041 [D loss: 0.644987, acc.: 63.28%] [G loss: 0.995127]\n",
      "epoch:13 step:13042 [D loss: 0.713960, acc.: 54.69%] [G loss: 0.883814]\n",
      "epoch:13 step:13043 [D loss: 0.677459, acc.: 53.12%] [G loss: 0.836711]\n",
      "epoch:13 step:13044 [D loss: 0.646327, acc.: 63.28%] [G loss: 0.831920]\n",
      "epoch:13 step:13045 [D loss: 0.686906, acc.: 53.91%] [G loss: 0.842187]\n",
      "epoch:13 step:13046 [D loss: 0.714017, acc.: 51.56%] [G loss: 0.811107]\n",
      "epoch:13 step:13047 [D loss: 0.635520, acc.: 62.50%] [G loss: 0.832457]\n",
      "epoch:13 step:13048 [D loss: 0.699614, acc.: 54.69%] [G loss: 0.887175]\n",
      "epoch:13 step:13049 [D loss: 0.613045, acc.: 70.31%] [G loss: 0.847678]\n",
      "epoch:13 step:13050 [D loss: 0.669820, acc.: 51.56%] [G loss: 0.852371]\n",
      "epoch:13 step:13051 [D loss: 0.643732, acc.: 63.28%] [G loss: 0.879183]\n",
      "epoch:13 step:13052 [D loss: 0.611860, acc.: 67.19%] [G loss: 0.888464]\n",
      "epoch:13 step:13053 [D loss: 0.592831, acc.: 71.09%] [G loss: 0.938801]\n",
      "epoch:13 step:13054 [D loss: 0.608595, acc.: 66.41%] [G loss: 0.838038]\n",
      "epoch:13 step:13055 [D loss: 0.666897, acc.: 57.81%] [G loss: 0.880142]\n",
      "epoch:13 step:13056 [D loss: 0.646144, acc.: 64.06%] [G loss: 0.896457]\n",
      "epoch:13 step:13057 [D loss: 0.659832, acc.: 56.25%] [G loss: 0.918404]\n",
      "epoch:13 step:13058 [D loss: 0.643493, acc.: 64.84%] [G loss: 0.876009]\n",
      "epoch:13 step:13059 [D loss: 0.685306, acc.: 57.03%] [G loss: 0.821354]\n",
      "epoch:13 step:13060 [D loss: 0.671911, acc.: 57.81%] [G loss: 0.879908]\n",
      "epoch:13 step:13061 [D loss: 0.676864, acc.: 56.25%] [G loss: 0.893748]\n",
      "epoch:13 step:13062 [D loss: 0.669577, acc.: 61.72%] [G loss: 0.878016]\n",
      "epoch:13 step:13063 [D loss: 0.675636, acc.: 57.03%] [G loss: 0.901276]\n",
      "epoch:13 step:13064 [D loss: 0.706447, acc.: 53.91%] [G loss: 0.889023]\n",
      "epoch:13 step:13065 [D loss: 0.619819, acc.: 66.41%] [G loss: 0.874253]\n",
      "epoch:13 step:13066 [D loss: 0.636139, acc.: 64.84%] [G loss: 0.911241]\n",
      "epoch:13 step:13067 [D loss: 0.609669, acc.: 66.41%] [G loss: 0.924698]\n",
      "epoch:13 step:13068 [D loss: 0.678430, acc.: 60.16%] [G loss: 0.917264]\n",
      "epoch:13 step:13069 [D loss: 0.704790, acc.: 55.47%] [G loss: 0.889853]\n",
      "epoch:13 step:13070 [D loss: 0.620957, acc.: 63.28%] [G loss: 0.945649]\n",
      "epoch:13 step:13071 [D loss: 0.644693, acc.: 64.84%] [G loss: 0.887895]\n",
      "epoch:13 step:13072 [D loss: 0.682406, acc.: 56.25%] [G loss: 0.922727]\n",
      "epoch:13 step:13073 [D loss: 0.680158, acc.: 67.19%] [G loss: 0.891270]\n",
      "epoch:13 step:13074 [D loss: 0.647572, acc.: 58.59%] [G loss: 0.831569]\n",
      "epoch:13 step:13075 [D loss: 0.664361, acc.: 63.28%] [G loss: 0.963562]\n",
      "epoch:13 step:13076 [D loss: 0.650326, acc.: 59.38%] [G loss: 0.888810]\n",
      "epoch:13 step:13077 [D loss: 0.650629, acc.: 59.38%] [G loss: 0.955295]\n",
      "epoch:13 step:13078 [D loss: 0.608156, acc.: 67.19%] [G loss: 0.942135]\n",
      "epoch:13 step:13079 [D loss: 0.633578, acc.: 66.41%] [G loss: 0.908774]\n",
      "epoch:13 step:13080 [D loss: 0.653084, acc.: 65.62%] [G loss: 0.943235]\n",
      "epoch:13 step:13081 [D loss: 0.619563, acc.: 67.97%] [G loss: 0.896510]\n",
      "epoch:13 step:13082 [D loss: 0.648320, acc.: 65.62%] [G loss: 0.926142]\n",
      "epoch:13 step:13083 [D loss: 0.685321, acc.: 55.47%] [G loss: 0.946821]\n",
      "epoch:13 step:13084 [D loss: 0.643934, acc.: 64.84%] [G loss: 0.919281]\n",
      "epoch:13 step:13085 [D loss: 0.677396, acc.: 57.03%] [G loss: 0.850624]\n",
      "epoch:13 step:13086 [D loss: 0.654405, acc.: 61.72%] [G loss: 0.927452]\n",
      "epoch:13 step:13087 [D loss: 0.634358, acc.: 61.72%] [G loss: 0.957253]\n",
      "epoch:13 step:13088 [D loss: 0.688422, acc.: 57.03%] [G loss: 0.977499]\n",
      "epoch:13 step:13089 [D loss: 0.608582, acc.: 63.28%] [G loss: 0.943160]\n",
      "epoch:13 step:13090 [D loss: 0.615884, acc.: 68.75%] [G loss: 0.958388]\n",
      "epoch:13 step:13091 [D loss: 0.641510, acc.: 64.84%] [G loss: 0.860421]\n",
      "epoch:13 step:13092 [D loss: 0.702347, acc.: 49.22%] [G loss: 0.906380]\n",
      "epoch:13 step:13093 [D loss: 0.628162, acc.: 67.19%] [G loss: 0.900181]\n",
      "epoch:13 step:13094 [D loss: 0.625924, acc.: 61.72%] [G loss: 0.978418]\n",
      "epoch:13 step:13095 [D loss: 0.610801, acc.: 67.97%] [G loss: 0.982155]\n",
      "epoch:13 step:13096 [D loss: 0.724894, acc.: 56.25%] [G loss: 0.891180]\n",
      "epoch:13 step:13097 [D loss: 0.664712, acc.: 60.94%] [G loss: 0.884174]\n",
      "epoch:13 step:13098 [D loss: 0.668880, acc.: 59.38%] [G loss: 0.906052]\n",
      "epoch:13 step:13099 [D loss: 0.608391, acc.: 71.88%] [G loss: 0.933176]\n",
      "epoch:13 step:13100 [D loss: 0.566355, acc.: 72.66%] [G loss: 1.000502]\n",
      "epoch:13 step:13101 [D loss: 0.806143, acc.: 43.75%] [G loss: 0.870789]\n",
      "epoch:13 step:13102 [D loss: 0.631104, acc.: 62.50%] [G loss: 0.911023]\n",
      "epoch:13 step:13103 [D loss: 0.619615, acc.: 67.19%] [G loss: 0.865035]\n",
      "epoch:13 step:13104 [D loss: 0.621197, acc.: 67.19%] [G loss: 0.891293]\n",
      "epoch:13 step:13105 [D loss: 0.607103, acc.: 70.31%] [G loss: 0.942703]\n",
      "epoch:13 step:13106 [D loss: 0.625561, acc.: 64.06%] [G loss: 1.054414]\n",
      "epoch:13 step:13107 [D loss: 0.545291, acc.: 79.69%] [G loss: 1.022142]\n",
      "epoch:13 step:13108 [D loss: 0.698737, acc.: 55.47%] [G loss: 1.051377]\n",
      "epoch:13 step:13109 [D loss: 0.850925, acc.: 51.56%] [G loss: 1.080170]\n",
      "epoch:13 step:13110 [D loss: 0.610629, acc.: 71.09%] [G loss: 1.244609]\n",
      "epoch:13 step:13111 [D loss: 0.600974, acc.: 67.97%] [G loss: 1.140601]\n",
      "epoch:13 step:13112 [D loss: 0.709747, acc.: 54.69%] [G loss: 1.030528]\n",
      "epoch:13 step:13113 [D loss: 0.776444, acc.: 45.31%] [G loss: 0.968709]\n",
      "epoch:13 step:13114 [D loss: 0.617682, acc.: 67.19%] [G loss: 0.899046]\n",
      "epoch:13 step:13115 [D loss: 0.710588, acc.: 57.81%] [G loss: 0.905394]\n",
      "epoch:13 step:13116 [D loss: 0.593135, acc.: 72.66%] [G loss: 1.010773]\n",
      "epoch:13 step:13117 [D loss: 0.577733, acc.: 71.88%] [G loss: 0.958520]\n",
      "epoch:13 step:13118 [D loss: 0.640080, acc.: 64.06%] [G loss: 1.004838]\n",
      "epoch:14 step:13119 [D loss: 0.671064, acc.: 60.94%] [G loss: 0.952600]\n",
      "epoch:14 step:13120 [D loss: 0.747188, acc.: 55.47%] [G loss: 0.990138]\n",
      "epoch:14 step:13121 [D loss: 0.706395, acc.: 48.44%] [G loss: 0.935272]\n",
      "epoch:14 step:13122 [D loss: 0.696875, acc.: 51.56%] [G loss: 0.883688]\n",
      "epoch:14 step:13123 [D loss: 0.690381, acc.: 57.03%] [G loss: 0.838546]\n",
      "epoch:14 step:13124 [D loss: 0.637614, acc.: 60.16%] [G loss: 0.891825]\n",
      "epoch:14 step:13125 [D loss: 0.640752, acc.: 56.25%] [G loss: 0.857149]\n",
      "epoch:14 step:13126 [D loss: 0.663711, acc.: 60.94%] [G loss: 0.869895]\n",
      "epoch:14 step:13127 [D loss: 0.646756, acc.: 59.38%] [G loss: 0.917537]\n",
      "epoch:14 step:13128 [D loss: 0.628686, acc.: 64.06%] [G loss: 0.899861]\n",
      "epoch:14 step:13129 [D loss: 0.649815, acc.: 64.06%] [G loss: 0.933259]\n",
      "epoch:14 step:13130 [D loss: 0.664123, acc.: 63.28%] [G loss: 0.914762]\n",
      "epoch:14 step:13131 [D loss: 0.671197, acc.: 56.25%] [G loss: 0.904165]\n",
      "epoch:14 step:13132 [D loss: 0.614907, acc.: 64.06%] [G loss: 0.908211]\n",
      "epoch:14 step:13133 [D loss: 0.562878, acc.: 71.88%] [G loss: 0.976560]\n",
      "epoch:14 step:13134 [D loss: 0.605029, acc.: 65.62%] [G loss: 0.946844]\n",
      "epoch:14 step:13135 [D loss: 0.746453, acc.: 48.44%] [G loss: 0.967776]\n",
      "epoch:14 step:13136 [D loss: 0.676101, acc.: 58.59%] [G loss: 0.944740]\n",
      "epoch:14 step:13137 [D loss: 0.694099, acc.: 63.28%] [G loss: 0.947680]\n",
      "epoch:14 step:13138 [D loss: 0.684836, acc.: 57.81%] [G loss: 0.975888]\n",
      "epoch:14 step:13139 [D loss: 0.670264, acc.: 57.81%] [G loss: 1.005987]\n",
      "epoch:14 step:13140 [D loss: 0.580718, acc.: 70.31%] [G loss: 1.089554]\n",
      "epoch:14 step:13141 [D loss: 0.730802, acc.: 45.31%] [G loss: 0.948369]\n",
      "epoch:14 step:13142 [D loss: 0.661830, acc.: 60.94%] [G loss: 0.909613]\n",
      "epoch:14 step:13143 [D loss: 0.624518, acc.: 65.62%] [G loss: 0.972662]\n",
      "epoch:14 step:13144 [D loss: 0.675111, acc.: 60.16%] [G loss: 0.907974]\n",
      "epoch:14 step:13145 [D loss: 0.664262, acc.: 57.81%] [G loss: 0.908483]\n",
      "epoch:14 step:13146 [D loss: 0.651709, acc.: 62.50%] [G loss: 0.867179]\n",
      "epoch:14 step:13147 [D loss: 0.628000, acc.: 63.28%] [G loss: 0.855614]\n",
      "epoch:14 step:13148 [D loss: 0.676605, acc.: 57.81%] [G loss: 0.942430]\n",
      "epoch:14 step:13149 [D loss: 0.666701, acc.: 58.59%] [G loss: 0.968174]\n",
      "epoch:14 step:13150 [D loss: 0.678645, acc.: 57.81%] [G loss: 0.930713]\n",
      "epoch:14 step:13151 [D loss: 0.676355, acc.: 53.91%] [G loss: 0.939738]\n",
      "epoch:14 step:13152 [D loss: 0.678955, acc.: 57.03%] [G loss: 0.864696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13153 [D loss: 0.622808, acc.: 65.62%] [G loss: 0.926429]\n",
      "epoch:14 step:13154 [D loss: 0.643043, acc.: 63.28%] [G loss: 0.985729]\n",
      "epoch:14 step:13155 [D loss: 0.695122, acc.: 57.03%] [G loss: 0.897430]\n",
      "epoch:14 step:13156 [D loss: 0.710427, acc.: 51.56%] [G loss: 0.812472]\n",
      "epoch:14 step:13157 [D loss: 0.663637, acc.: 58.59%] [G loss: 0.863239]\n",
      "epoch:14 step:13158 [D loss: 0.620100, acc.: 62.50%] [G loss: 0.876760]\n",
      "epoch:14 step:13159 [D loss: 0.677129, acc.: 60.94%] [G loss: 0.916105]\n",
      "epoch:14 step:13160 [D loss: 0.667258, acc.: 62.50%] [G loss: 0.861998]\n",
      "epoch:14 step:13161 [D loss: 0.664200, acc.: 53.91%] [G loss: 0.877592]\n",
      "epoch:14 step:13162 [D loss: 0.657502, acc.: 59.38%] [G loss: 0.936309]\n",
      "epoch:14 step:13163 [D loss: 0.671387, acc.: 59.38%] [G loss: 0.931621]\n",
      "epoch:14 step:13164 [D loss: 0.615019, acc.: 67.97%] [G loss: 0.944254]\n",
      "epoch:14 step:13165 [D loss: 0.683956, acc.: 53.12%] [G loss: 0.913672]\n",
      "epoch:14 step:13166 [D loss: 0.646704, acc.: 66.41%] [G loss: 0.922757]\n",
      "epoch:14 step:13167 [D loss: 0.630827, acc.: 67.19%] [G loss: 0.945577]\n",
      "epoch:14 step:13168 [D loss: 0.636702, acc.: 64.06%] [G loss: 0.930532]\n",
      "epoch:14 step:13169 [D loss: 0.740514, acc.: 46.88%] [G loss: 0.853678]\n",
      "epoch:14 step:13170 [D loss: 0.673255, acc.: 58.59%] [G loss: 0.918660]\n",
      "epoch:14 step:13171 [D loss: 0.632913, acc.: 65.62%] [G loss: 0.978356]\n",
      "epoch:14 step:13172 [D loss: 0.639764, acc.: 61.72%] [G loss: 0.919466]\n",
      "epoch:14 step:13173 [D loss: 0.633573, acc.: 60.16%] [G loss: 1.006917]\n",
      "epoch:14 step:13174 [D loss: 0.715194, acc.: 53.91%] [G loss: 0.997352]\n",
      "epoch:14 step:13175 [D loss: 0.670280, acc.: 61.72%] [G loss: 0.963176]\n",
      "epoch:14 step:13176 [D loss: 0.725791, acc.: 48.44%] [G loss: 0.925677]\n",
      "epoch:14 step:13177 [D loss: 0.668485, acc.: 60.94%] [G loss: 0.912788]\n",
      "epoch:14 step:13178 [D loss: 0.694692, acc.: 52.34%] [G loss: 0.948975]\n",
      "epoch:14 step:13179 [D loss: 0.670372, acc.: 55.47%] [G loss: 0.874569]\n",
      "epoch:14 step:13180 [D loss: 0.654208, acc.: 61.72%] [G loss: 0.819607]\n",
      "epoch:14 step:13181 [D loss: 0.611087, acc.: 67.97%] [G loss: 0.891661]\n",
      "epoch:14 step:13182 [D loss: 0.662317, acc.: 63.28%] [G loss: 0.861372]\n",
      "epoch:14 step:13183 [D loss: 0.705937, acc.: 55.47%] [G loss: 0.918322]\n",
      "epoch:14 step:13184 [D loss: 0.651650, acc.: 60.16%] [G loss: 0.844575]\n",
      "epoch:14 step:13185 [D loss: 0.619850, acc.: 67.19%] [G loss: 0.945455]\n",
      "epoch:14 step:13186 [D loss: 0.636630, acc.: 64.84%] [G loss: 0.833081]\n",
      "epoch:14 step:13187 [D loss: 0.651490, acc.: 59.38%] [G loss: 0.909752]\n",
      "epoch:14 step:13188 [D loss: 0.623058, acc.: 70.31%] [G loss: 0.896617]\n",
      "epoch:14 step:13189 [D loss: 0.685950, acc.: 60.16%] [G loss: 0.920223]\n",
      "epoch:14 step:13190 [D loss: 0.679964, acc.: 60.16%] [G loss: 0.879936]\n",
      "epoch:14 step:13191 [D loss: 0.706011, acc.: 50.00%] [G loss: 0.914173]\n",
      "epoch:14 step:13192 [D loss: 0.621585, acc.: 67.19%] [G loss: 0.906364]\n",
      "epoch:14 step:13193 [D loss: 0.680468, acc.: 57.81%] [G loss: 0.898537]\n",
      "epoch:14 step:13194 [D loss: 0.628136, acc.: 64.06%] [G loss: 0.978350]\n",
      "epoch:14 step:13195 [D loss: 0.606132, acc.: 67.97%] [G loss: 1.028006]\n",
      "epoch:14 step:13196 [D loss: 0.705984, acc.: 50.78%] [G loss: 0.949316]\n",
      "epoch:14 step:13197 [D loss: 0.707896, acc.: 56.25%] [G loss: 0.939229]\n",
      "epoch:14 step:13198 [D loss: 0.661234, acc.: 56.25%] [G loss: 0.899338]\n",
      "epoch:14 step:13199 [D loss: 0.697329, acc.: 57.03%] [G loss: 0.872075]\n",
      "epoch:14 step:13200 [D loss: 0.656683, acc.: 64.06%] [G loss: 0.912302]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.045357\n",
      "FID: 8.131948\n",
      "0 = 11.816582408809685\n",
      "1 = 0.05286870730495657\n",
      "2 = 0.9243500232696533\n",
      "3 = 0.8820000290870667\n",
      "4 = 0.96670001745224\n",
      "5 = 0.9636184573173523\n",
      "6 = 0.8820000290870667\n",
      "7 = 5.868936085411895\n",
      "8 = 0.06231088637364217\n",
      "9 = 0.7026500105857849\n",
      "10 = 0.6797000169754028\n",
      "11 = 0.725600004196167\n",
      "12 = 0.7123991250991821\n",
      "13 = 0.6797000169754028\n",
      "14 = 8.045418739318848\n",
      "15 = 9.562634468078613\n",
      "16 = 0.10142087191343307\n",
      "17 = 8.045356750488281\n",
      "18 = 8.131948471069336\n",
      "epoch:14 step:13201 [D loss: 0.637671, acc.: 63.28%] [G loss: 0.874415]\n",
      "epoch:14 step:13202 [D loss: 0.643771, acc.: 62.50%] [G loss: 0.984164]\n",
      "epoch:14 step:13203 [D loss: 0.646777, acc.: 61.72%] [G loss: 0.959535]\n",
      "epoch:14 step:13204 [D loss: 0.684710, acc.: 59.38%] [G loss: 0.903870]\n",
      "epoch:14 step:13205 [D loss: 0.651832, acc.: 62.50%] [G loss: 0.889933]\n",
      "epoch:14 step:13206 [D loss: 0.616672, acc.: 67.97%] [G loss: 0.948949]\n",
      "epoch:14 step:13207 [D loss: 0.632717, acc.: 67.19%] [G loss: 0.896366]\n",
      "epoch:14 step:13208 [D loss: 0.600398, acc.: 69.53%] [G loss: 0.926060]\n",
      "epoch:14 step:13209 [D loss: 0.643403, acc.: 60.16%] [G loss: 0.900355]\n",
      "epoch:14 step:13210 [D loss: 0.639202, acc.: 63.28%] [G loss: 0.894403]\n",
      "epoch:14 step:13211 [D loss: 0.665212, acc.: 56.25%] [G loss: 0.924547]\n",
      "epoch:14 step:13212 [D loss: 0.664792, acc.: 60.94%] [G loss: 0.918380]\n",
      "epoch:14 step:13213 [D loss: 0.621172, acc.: 65.62%] [G loss: 0.878971]\n",
      "epoch:14 step:13214 [D loss: 0.612083, acc.: 65.62%] [G loss: 0.928000]\n",
      "epoch:14 step:13215 [D loss: 0.619825, acc.: 71.09%] [G loss: 0.933683]\n",
      "epoch:14 step:13216 [D loss: 0.628172, acc.: 63.28%] [G loss: 0.952452]\n",
      "epoch:14 step:13217 [D loss: 0.708472, acc.: 58.59%] [G loss: 0.912668]\n",
      "epoch:14 step:13218 [D loss: 0.651478, acc.: 61.72%] [G loss: 0.877643]\n",
      "epoch:14 step:13219 [D loss: 0.643833, acc.: 61.72%] [G loss: 0.936832]\n",
      "epoch:14 step:13220 [D loss: 0.713879, acc.: 55.47%] [G loss: 0.878838]\n",
      "epoch:14 step:13221 [D loss: 0.678316, acc.: 57.03%] [G loss: 0.891130]\n",
      "epoch:14 step:13222 [D loss: 0.707764, acc.: 51.56%] [G loss: 0.887003]\n",
      "epoch:14 step:13223 [D loss: 0.660160, acc.: 61.72%] [G loss: 0.932901]\n",
      "epoch:14 step:13224 [D loss: 0.630284, acc.: 65.62%] [G loss: 0.868393]\n",
      "epoch:14 step:13225 [D loss: 0.624762, acc.: 64.84%] [G loss: 0.936867]\n",
      "epoch:14 step:13226 [D loss: 0.737230, acc.: 52.34%] [G loss: 1.026104]\n",
      "epoch:14 step:13227 [D loss: 0.710179, acc.: 52.34%] [G loss: 0.927487]\n",
      "epoch:14 step:13228 [D loss: 0.640394, acc.: 65.62%] [G loss: 0.930432]\n",
      "epoch:14 step:13229 [D loss: 0.621564, acc.: 67.19%] [G loss: 0.907981]\n",
      "epoch:14 step:13230 [D loss: 0.593873, acc.: 70.31%] [G loss: 0.905230]\n",
      "epoch:14 step:13231 [D loss: 0.620862, acc.: 67.97%] [G loss: 0.963196]\n",
      "epoch:14 step:13232 [D loss: 0.667209, acc.: 64.06%] [G loss: 0.888141]\n",
      "epoch:14 step:13233 [D loss: 0.642718, acc.: 69.53%] [G loss: 0.988010]\n",
      "epoch:14 step:13234 [D loss: 0.633089, acc.: 69.53%] [G loss: 0.967688]\n",
      "epoch:14 step:13235 [D loss: 0.626483, acc.: 66.41%] [G loss: 0.918896]\n",
      "epoch:14 step:13236 [D loss: 0.688676, acc.: 55.47%] [G loss: 0.915781]\n",
      "epoch:14 step:13237 [D loss: 0.616503, acc.: 70.31%] [G loss: 0.995374]\n",
      "epoch:14 step:13238 [D loss: 0.695820, acc.: 59.38%] [G loss: 0.940085]\n",
      "epoch:14 step:13239 [D loss: 0.698960, acc.: 54.69%] [G loss: 0.870279]\n",
      "epoch:14 step:13240 [D loss: 0.642241, acc.: 65.62%] [G loss: 0.900616]\n",
      "epoch:14 step:13241 [D loss: 0.642297, acc.: 69.53%] [G loss: 0.942436]\n",
      "epoch:14 step:13242 [D loss: 0.659904, acc.: 60.94%] [G loss: 0.885460]\n",
      "epoch:14 step:13243 [D loss: 0.661181, acc.: 55.47%] [G loss: 0.938892]\n",
      "epoch:14 step:13244 [D loss: 0.653465, acc.: 62.50%] [G loss: 0.973919]\n",
      "epoch:14 step:13245 [D loss: 0.632380, acc.: 65.62%] [G loss: 0.999628]\n",
      "epoch:14 step:13246 [D loss: 0.709295, acc.: 52.34%] [G loss: 0.844076]\n",
      "epoch:14 step:13247 [D loss: 0.650638, acc.: 60.94%] [G loss: 0.846130]\n",
      "epoch:14 step:13248 [D loss: 0.636812, acc.: 62.50%] [G loss: 0.882296]\n",
      "epoch:14 step:13249 [D loss: 0.654604, acc.: 56.25%] [G loss: 0.907033]\n",
      "epoch:14 step:13250 [D loss: 0.696091, acc.: 51.56%] [G loss: 0.870230]\n",
      "epoch:14 step:13251 [D loss: 0.625299, acc.: 66.41%] [G loss: 0.942421]\n",
      "epoch:14 step:13252 [D loss: 0.661518, acc.: 63.28%] [G loss: 0.985536]\n",
      "epoch:14 step:13253 [D loss: 0.619553, acc.: 64.84%] [G loss: 0.923813]\n",
      "epoch:14 step:13254 [D loss: 0.683593, acc.: 60.94%] [G loss: 0.972537]\n",
      "epoch:14 step:13255 [D loss: 0.679713, acc.: 53.91%] [G loss: 0.944404]\n",
      "epoch:14 step:13256 [D loss: 0.693455, acc.: 53.91%] [G loss: 0.881637]\n",
      "epoch:14 step:13257 [D loss: 0.729600, acc.: 50.00%] [G loss: 0.883018]\n",
      "epoch:14 step:13258 [D loss: 0.665174, acc.: 58.59%] [G loss: 0.891784]\n",
      "epoch:14 step:13259 [D loss: 0.734990, acc.: 50.00%] [G loss: 0.827117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13260 [D loss: 0.665745, acc.: 60.16%] [G loss: 0.799381]\n",
      "epoch:14 step:13261 [D loss: 0.674055, acc.: 56.25%] [G loss: 0.826203]\n",
      "epoch:14 step:13262 [D loss: 0.665783, acc.: 60.94%] [G loss: 0.846238]\n",
      "epoch:14 step:13263 [D loss: 0.690641, acc.: 53.12%] [G loss: 0.920354]\n",
      "epoch:14 step:13264 [D loss: 0.644249, acc.: 64.84%] [G loss: 0.912017]\n",
      "epoch:14 step:13265 [D loss: 0.696252, acc.: 58.59%] [G loss: 0.896728]\n",
      "epoch:14 step:13266 [D loss: 0.672142, acc.: 60.94%] [G loss: 0.941987]\n",
      "epoch:14 step:13267 [D loss: 0.678553, acc.: 54.69%] [G loss: 0.908206]\n",
      "epoch:14 step:13268 [D loss: 0.714468, acc.: 47.66%] [G loss: 0.857561]\n",
      "epoch:14 step:13269 [D loss: 0.690764, acc.: 57.03%] [G loss: 0.822719]\n",
      "epoch:14 step:13270 [D loss: 0.656970, acc.: 63.28%] [G loss: 0.970713]\n",
      "epoch:14 step:13271 [D loss: 0.682779, acc.: 56.25%] [G loss: 0.908274]\n",
      "epoch:14 step:13272 [D loss: 0.648485, acc.: 64.06%] [G loss: 0.900686]\n",
      "epoch:14 step:13273 [D loss: 0.608823, acc.: 69.53%] [G loss: 0.902192]\n",
      "epoch:14 step:13274 [D loss: 0.611591, acc.: 66.41%] [G loss: 0.892542]\n",
      "epoch:14 step:13275 [D loss: 0.659116, acc.: 60.94%] [G loss: 0.891470]\n",
      "epoch:14 step:13276 [D loss: 0.650771, acc.: 64.84%] [G loss: 0.888984]\n",
      "epoch:14 step:13277 [D loss: 0.647364, acc.: 66.41%] [G loss: 0.861150]\n",
      "epoch:14 step:13278 [D loss: 0.725667, acc.: 50.78%] [G loss: 0.894723]\n",
      "epoch:14 step:13279 [D loss: 0.665980, acc.: 56.25%] [G loss: 1.017673]\n",
      "epoch:14 step:13280 [D loss: 0.699935, acc.: 57.03%] [G loss: 0.926328]\n",
      "epoch:14 step:13281 [D loss: 0.648695, acc.: 62.50%] [G loss: 0.906625]\n",
      "epoch:14 step:13282 [D loss: 0.626843, acc.: 64.06%] [G loss: 0.969333]\n",
      "epoch:14 step:13283 [D loss: 0.633422, acc.: 64.84%] [G loss: 0.909367]\n",
      "epoch:14 step:13284 [D loss: 0.658636, acc.: 60.94%] [G loss: 0.878379]\n",
      "epoch:14 step:13285 [D loss: 0.684235, acc.: 55.47%] [G loss: 0.866530]\n",
      "epoch:14 step:13286 [D loss: 0.641971, acc.: 64.84%] [G loss: 0.877093]\n",
      "epoch:14 step:13287 [D loss: 0.673224, acc.: 54.69%] [G loss: 0.874384]\n",
      "epoch:14 step:13288 [D loss: 0.634284, acc.: 61.72%] [G loss: 0.863996]\n",
      "epoch:14 step:13289 [D loss: 0.638027, acc.: 64.84%] [G loss: 0.893455]\n",
      "epoch:14 step:13290 [D loss: 0.659664, acc.: 57.81%] [G loss: 0.888106]\n",
      "epoch:14 step:13291 [D loss: 0.621804, acc.: 66.41%] [G loss: 0.864340]\n",
      "epoch:14 step:13292 [D loss: 0.673071, acc.: 55.47%] [G loss: 0.886091]\n",
      "epoch:14 step:13293 [D loss: 0.684244, acc.: 54.69%] [G loss: 0.865229]\n",
      "epoch:14 step:13294 [D loss: 0.666446, acc.: 59.38%] [G loss: 0.858441]\n",
      "epoch:14 step:13295 [D loss: 0.664565, acc.: 56.25%] [G loss: 0.859139]\n",
      "epoch:14 step:13296 [D loss: 0.682915, acc.: 58.59%] [G loss: 0.860420]\n",
      "epoch:14 step:13297 [D loss: 0.661962, acc.: 60.94%] [G loss: 0.957492]\n",
      "epoch:14 step:13298 [D loss: 0.662058, acc.: 62.50%] [G loss: 0.861222]\n",
      "epoch:14 step:13299 [D loss: 0.702814, acc.: 50.78%] [G loss: 0.871961]\n",
      "epoch:14 step:13300 [D loss: 0.664248, acc.: 60.16%] [G loss: 0.913095]\n",
      "epoch:14 step:13301 [D loss: 0.657232, acc.: 65.62%] [G loss: 0.915919]\n",
      "epoch:14 step:13302 [D loss: 0.649155, acc.: 64.84%] [G loss: 0.899998]\n",
      "epoch:14 step:13303 [D loss: 0.671044, acc.: 61.72%] [G loss: 0.890875]\n",
      "epoch:14 step:13304 [D loss: 0.728169, acc.: 54.69%] [G loss: 0.917875]\n",
      "epoch:14 step:13305 [D loss: 0.649313, acc.: 61.72%] [G loss: 0.874704]\n",
      "epoch:14 step:13306 [D loss: 0.688566, acc.: 54.69%] [G loss: 0.864066]\n",
      "epoch:14 step:13307 [D loss: 0.706808, acc.: 51.56%] [G loss: 0.873963]\n",
      "epoch:14 step:13308 [D loss: 0.616109, acc.: 65.62%] [G loss: 0.900094]\n",
      "epoch:14 step:13309 [D loss: 0.615373, acc.: 62.50%] [G loss: 0.866353]\n",
      "epoch:14 step:13310 [D loss: 0.605791, acc.: 64.06%] [G loss: 0.841761]\n",
      "epoch:14 step:13311 [D loss: 0.688756, acc.: 51.56%] [G loss: 0.937343]\n",
      "epoch:14 step:13312 [D loss: 0.636793, acc.: 64.84%] [G loss: 0.936090]\n",
      "epoch:14 step:13313 [D loss: 0.630674, acc.: 60.16%] [G loss: 0.947618]\n",
      "epoch:14 step:13314 [D loss: 0.666886, acc.: 57.81%] [G loss: 0.903740]\n",
      "epoch:14 step:13315 [D loss: 0.622147, acc.: 66.41%] [G loss: 0.929601]\n",
      "epoch:14 step:13316 [D loss: 0.609082, acc.: 71.09%] [G loss: 0.851002]\n",
      "epoch:14 step:13317 [D loss: 0.637339, acc.: 61.72%] [G loss: 0.860390]\n",
      "epoch:14 step:13318 [D loss: 0.687032, acc.: 56.25%] [G loss: 0.913356]\n",
      "epoch:14 step:13319 [D loss: 0.678929, acc.: 57.03%] [G loss: 0.904772]\n",
      "epoch:14 step:13320 [D loss: 0.676668, acc.: 57.81%] [G loss: 0.949999]\n",
      "epoch:14 step:13321 [D loss: 0.760331, acc.: 46.88%] [G loss: 0.923587]\n",
      "epoch:14 step:13322 [D loss: 0.695041, acc.: 50.00%] [G loss: 0.850844]\n",
      "epoch:14 step:13323 [D loss: 0.674902, acc.: 57.81%] [G loss: 0.903246]\n",
      "epoch:14 step:13324 [D loss: 0.623216, acc.: 64.06%] [G loss: 0.892345]\n",
      "epoch:14 step:13325 [D loss: 0.632076, acc.: 61.72%] [G loss: 0.921922]\n",
      "epoch:14 step:13326 [D loss: 0.601480, acc.: 68.75%] [G loss: 0.877315]\n",
      "epoch:14 step:13327 [D loss: 0.598258, acc.: 65.62%] [G loss: 0.945244]\n",
      "epoch:14 step:13328 [D loss: 0.700501, acc.: 53.12%] [G loss: 0.915684]\n",
      "epoch:14 step:13329 [D loss: 0.638744, acc.: 61.72%] [G loss: 0.909811]\n",
      "epoch:14 step:13330 [D loss: 0.671461, acc.: 62.50%] [G loss: 0.922340]\n",
      "epoch:14 step:13331 [D loss: 0.636594, acc.: 64.84%] [G loss: 0.890201]\n",
      "epoch:14 step:13332 [D loss: 0.726982, acc.: 49.22%] [G loss: 0.872088]\n",
      "epoch:14 step:13333 [D loss: 0.688704, acc.: 55.47%] [G loss: 0.870703]\n",
      "epoch:14 step:13334 [D loss: 0.655755, acc.: 61.72%] [G loss: 0.894651]\n",
      "epoch:14 step:13335 [D loss: 0.681560, acc.: 57.81%] [G loss: 0.882068]\n",
      "epoch:14 step:13336 [D loss: 0.630812, acc.: 64.84%] [G loss: 0.874667]\n",
      "epoch:14 step:13337 [D loss: 0.566119, acc.: 72.66%] [G loss: 0.874709]\n",
      "epoch:14 step:13338 [D loss: 0.772447, acc.: 48.44%] [G loss: 0.889203]\n",
      "epoch:14 step:13339 [D loss: 0.653121, acc.: 62.50%] [G loss: 0.935824]\n",
      "epoch:14 step:13340 [D loss: 0.629607, acc.: 61.72%] [G loss: 0.996649]\n",
      "epoch:14 step:13341 [D loss: 0.608335, acc.: 68.75%] [G loss: 0.950238]\n",
      "epoch:14 step:13342 [D loss: 0.720081, acc.: 53.12%] [G loss: 0.858633]\n",
      "epoch:14 step:13343 [D loss: 0.675096, acc.: 59.38%] [G loss: 0.845972]\n",
      "epoch:14 step:13344 [D loss: 0.667172, acc.: 59.38%] [G loss: 0.807798]\n",
      "epoch:14 step:13345 [D loss: 0.696495, acc.: 57.81%] [G loss: 0.861232]\n",
      "epoch:14 step:13346 [D loss: 0.690649, acc.: 53.12%] [G loss: 0.865054]\n",
      "epoch:14 step:13347 [D loss: 0.643296, acc.: 58.59%] [G loss: 0.924093]\n",
      "epoch:14 step:13348 [D loss: 0.622493, acc.: 61.72%] [G loss: 0.938806]\n",
      "epoch:14 step:13349 [D loss: 0.565789, acc.: 70.31%] [G loss: 1.027316]\n",
      "epoch:14 step:13350 [D loss: 0.558880, acc.: 72.66%] [G loss: 0.996980]\n",
      "epoch:14 step:13351 [D loss: 0.698218, acc.: 59.38%] [G loss: 0.982847]\n",
      "epoch:14 step:13352 [D loss: 0.716408, acc.: 53.91%] [G loss: 0.959389]\n",
      "epoch:14 step:13353 [D loss: 0.678248, acc.: 60.16%] [G loss: 0.901622]\n",
      "epoch:14 step:13354 [D loss: 0.660026, acc.: 58.59%] [G loss: 0.931631]\n",
      "epoch:14 step:13355 [D loss: 0.663382, acc.: 60.16%] [G loss: 0.869715]\n",
      "epoch:14 step:13356 [D loss: 0.654259, acc.: 62.50%] [G loss: 0.888978]\n",
      "epoch:14 step:13357 [D loss: 0.690209, acc.: 57.03%] [G loss: 0.850088]\n",
      "epoch:14 step:13358 [D loss: 0.658150, acc.: 59.38%] [G loss: 0.878876]\n",
      "epoch:14 step:13359 [D loss: 0.599954, acc.: 71.09%] [G loss: 0.912734]\n",
      "epoch:14 step:13360 [D loss: 0.606816, acc.: 70.31%] [G loss: 0.890859]\n",
      "epoch:14 step:13361 [D loss: 0.654075, acc.: 63.28%] [G loss: 0.926187]\n",
      "epoch:14 step:13362 [D loss: 0.644885, acc.: 65.62%] [G loss: 0.968877]\n",
      "epoch:14 step:13363 [D loss: 0.681334, acc.: 57.81%] [G loss: 0.902737]\n",
      "epoch:14 step:13364 [D loss: 0.605815, acc.: 64.84%] [G loss: 1.019941]\n",
      "epoch:14 step:13365 [D loss: 0.624381, acc.: 66.41%] [G loss: 0.972799]\n",
      "epoch:14 step:13366 [D loss: 0.597646, acc.: 63.28%] [G loss: 0.905611]\n",
      "epoch:14 step:13367 [D loss: 0.744609, acc.: 53.91%] [G loss: 0.917518]\n",
      "epoch:14 step:13368 [D loss: 0.761560, acc.: 46.88%] [G loss: 0.866905]\n",
      "epoch:14 step:13369 [D loss: 0.711393, acc.: 49.22%] [G loss: 0.888941]\n",
      "epoch:14 step:13370 [D loss: 0.692777, acc.: 56.25%] [G loss: 0.908727]\n",
      "epoch:14 step:13371 [D loss: 0.667013, acc.: 60.94%] [G loss: 0.908330]\n",
      "epoch:14 step:13372 [D loss: 0.637712, acc.: 64.06%] [G loss: 0.868988]\n",
      "epoch:14 step:13373 [D loss: 0.664671, acc.: 61.72%] [G loss: 0.930030]\n",
      "epoch:14 step:13374 [D loss: 0.625491, acc.: 68.75%] [G loss: 0.880982]\n",
      "epoch:14 step:13375 [D loss: 0.643776, acc.: 68.75%] [G loss: 0.924746]\n",
      "epoch:14 step:13376 [D loss: 0.627672, acc.: 60.94%] [G loss: 0.932230]\n",
      "epoch:14 step:13377 [D loss: 0.633221, acc.: 61.72%] [G loss: 0.913414]\n",
      "epoch:14 step:13378 [D loss: 0.674582, acc.: 55.47%] [G loss: 0.898408]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13379 [D loss: 0.600813, acc.: 67.97%] [G loss: 0.890272]\n",
      "epoch:14 step:13380 [D loss: 0.635012, acc.: 64.06%] [G loss: 0.908738]\n",
      "epoch:14 step:13381 [D loss: 0.710193, acc.: 53.12%] [G loss: 0.876351]\n",
      "epoch:14 step:13382 [D loss: 0.620791, acc.: 64.84%] [G loss: 0.895900]\n",
      "epoch:14 step:13383 [D loss: 0.681802, acc.: 54.69%] [G loss: 0.901130]\n",
      "epoch:14 step:13384 [D loss: 0.650810, acc.: 58.59%] [G loss: 0.872595]\n",
      "epoch:14 step:13385 [D loss: 0.646724, acc.: 65.62%] [G loss: 0.906057]\n",
      "epoch:14 step:13386 [D loss: 0.660529, acc.: 59.38%] [G loss: 0.929582]\n",
      "epoch:14 step:13387 [D loss: 0.652484, acc.: 64.06%] [G loss: 0.924341]\n",
      "epoch:14 step:13388 [D loss: 0.667539, acc.: 61.72%] [G loss: 1.010109]\n",
      "epoch:14 step:13389 [D loss: 0.613326, acc.: 68.75%] [G loss: 0.891849]\n",
      "epoch:14 step:13390 [D loss: 0.672774, acc.: 61.72%] [G loss: 0.892061]\n",
      "epoch:14 step:13391 [D loss: 0.655243, acc.: 60.94%] [G loss: 0.901396]\n",
      "epoch:14 step:13392 [D loss: 0.648522, acc.: 65.62%] [G loss: 0.951964]\n",
      "epoch:14 step:13393 [D loss: 0.727265, acc.: 52.34%] [G loss: 0.911541]\n",
      "epoch:14 step:13394 [D loss: 0.617045, acc.: 66.41%] [G loss: 0.911964]\n",
      "epoch:14 step:13395 [D loss: 0.653139, acc.: 63.28%] [G loss: 0.898292]\n",
      "epoch:14 step:13396 [D loss: 0.688965, acc.: 57.81%] [G loss: 0.825034]\n",
      "epoch:14 step:13397 [D loss: 0.662276, acc.: 60.94%] [G loss: 0.919545]\n",
      "epoch:14 step:13398 [D loss: 0.624325, acc.: 67.19%] [G loss: 0.977699]\n",
      "epoch:14 step:13399 [D loss: 0.706799, acc.: 57.03%] [G loss: 0.896679]\n",
      "epoch:14 step:13400 [D loss: 0.709202, acc.: 51.56%] [G loss: 0.885488]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.012914\n",
      "FID: 10.156830\n",
      "0 = 11.894423022961622\n",
      "1 = 0.05428932192294831\n",
      "2 = 0.9187999963760376\n",
      "3 = 0.8726999759674072\n",
      "4 = 0.964900016784668\n",
      "5 = 0.9613351225852966\n",
      "6 = 0.8726999759674072\n",
      "7 = 6.031078561294047\n",
      "8 = 0.07009174873668653\n",
      "9 = 0.714900016784668\n",
      "10 = 0.689300000667572\n",
      "11 = 0.7404999732971191\n",
      "12 = 0.7264966368675232\n",
      "13 = 0.689300000667572\n",
      "14 = 8.012984275817871\n",
      "15 = 9.565325736999512\n",
      "16 = 0.09751681983470917\n",
      "17 = 8.012913703918457\n",
      "18 = 10.156829833984375\n",
      "epoch:14 step:13401 [D loss: 0.589944, acc.: 71.09%] [G loss: 0.912757]\n",
      "epoch:14 step:13402 [D loss: 0.690524, acc.: 57.81%] [G loss: 0.915464]\n",
      "epoch:14 step:13403 [D loss: 0.631569, acc.: 62.50%] [G loss: 0.861565]\n",
      "epoch:14 step:13404 [D loss: 0.644855, acc.: 66.41%] [G loss: 0.915233]\n",
      "epoch:14 step:13405 [D loss: 0.667727, acc.: 52.34%] [G loss: 0.899916]\n",
      "epoch:14 step:13406 [D loss: 0.686256, acc.: 55.47%] [G loss: 0.916253]\n",
      "epoch:14 step:13407 [D loss: 0.600129, acc.: 74.22%] [G loss: 0.983317]\n",
      "epoch:14 step:13408 [D loss: 0.679524, acc.: 51.56%] [G loss: 0.975848]\n",
      "epoch:14 step:13409 [D loss: 0.664308, acc.: 61.72%] [G loss: 0.893999]\n",
      "epoch:14 step:13410 [D loss: 0.666140, acc.: 54.69%] [G loss: 0.969858]\n",
      "epoch:14 step:13411 [D loss: 0.619496, acc.: 69.53%] [G loss: 0.871017]\n",
      "epoch:14 step:13412 [D loss: 0.643769, acc.: 65.62%] [G loss: 0.838962]\n",
      "epoch:14 step:13413 [D loss: 0.687511, acc.: 53.91%] [G loss: 0.888401]\n",
      "epoch:14 step:13414 [D loss: 0.643321, acc.: 61.72%] [G loss: 0.905926]\n",
      "epoch:14 step:13415 [D loss: 0.648430, acc.: 67.19%] [G loss: 0.898838]\n",
      "epoch:14 step:13416 [D loss: 0.647740, acc.: 66.41%] [G loss: 0.911333]\n",
      "epoch:14 step:13417 [D loss: 0.641902, acc.: 60.16%] [G loss: 0.917730]\n",
      "epoch:14 step:13418 [D loss: 0.623320, acc.: 70.31%] [G loss: 0.914726]\n",
      "epoch:14 step:13419 [D loss: 0.695408, acc.: 54.69%] [G loss: 0.948254]\n",
      "epoch:14 step:13420 [D loss: 0.618663, acc.: 66.41%] [G loss: 0.870942]\n",
      "epoch:14 step:13421 [D loss: 0.641854, acc.: 64.06%] [G loss: 0.906834]\n",
      "epoch:14 step:13422 [D loss: 0.637604, acc.: 65.62%] [G loss: 0.906516]\n",
      "epoch:14 step:13423 [D loss: 0.603993, acc.: 71.88%] [G loss: 0.885593]\n",
      "epoch:14 step:13424 [D loss: 0.630291, acc.: 62.50%] [G loss: 0.957345]\n",
      "epoch:14 step:13425 [D loss: 0.621552, acc.: 64.06%] [G loss: 0.907648]\n",
      "epoch:14 step:13426 [D loss: 0.691731, acc.: 53.12%] [G loss: 0.907267]\n",
      "epoch:14 step:13427 [D loss: 0.612520, acc.: 67.97%] [G loss: 0.891618]\n",
      "epoch:14 step:13428 [D loss: 0.674387, acc.: 57.81%] [G loss: 0.894693]\n",
      "epoch:14 step:13429 [D loss: 0.685483, acc.: 58.59%] [G loss: 0.893863]\n",
      "epoch:14 step:13430 [D loss: 0.606377, acc.: 73.44%] [G loss: 0.983983]\n",
      "epoch:14 step:13431 [D loss: 0.596935, acc.: 71.88%] [G loss: 0.998659]\n",
      "epoch:14 step:13432 [D loss: 0.603137, acc.: 70.31%] [G loss: 0.981613]\n",
      "epoch:14 step:13433 [D loss: 0.625296, acc.: 64.84%] [G loss: 1.018828]\n",
      "epoch:14 step:13434 [D loss: 0.756220, acc.: 50.78%] [G loss: 0.929018]\n",
      "epoch:14 step:13435 [D loss: 0.728341, acc.: 53.12%] [G loss: 0.916717]\n",
      "epoch:14 step:13436 [D loss: 0.680739, acc.: 56.25%] [G loss: 0.926452]\n",
      "epoch:14 step:13437 [D loss: 0.667534, acc.: 56.25%] [G loss: 0.861370]\n",
      "epoch:14 step:13438 [D loss: 0.644912, acc.: 60.94%] [G loss: 0.886023]\n",
      "epoch:14 step:13439 [D loss: 0.618783, acc.: 67.19%] [G loss: 0.959170]\n",
      "epoch:14 step:13440 [D loss: 0.610833, acc.: 66.41%] [G loss: 1.007115]\n",
      "epoch:14 step:13441 [D loss: 0.665227, acc.: 60.94%] [G loss: 0.939051]\n",
      "epoch:14 step:13442 [D loss: 0.668531, acc.: 60.16%] [G loss: 0.956151]\n",
      "epoch:14 step:13443 [D loss: 0.683408, acc.: 56.25%] [G loss: 0.904960]\n",
      "epoch:14 step:13444 [D loss: 0.641626, acc.: 60.94%] [G loss: 0.919863]\n",
      "epoch:14 step:13445 [D loss: 0.657933, acc.: 58.59%] [G loss: 0.842133]\n",
      "epoch:14 step:13446 [D loss: 0.657724, acc.: 58.59%] [G loss: 0.953671]\n",
      "epoch:14 step:13447 [D loss: 0.652486, acc.: 60.16%] [G loss: 0.931680]\n",
      "epoch:14 step:13448 [D loss: 0.690285, acc.: 60.94%] [G loss: 0.929329]\n",
      "epoch:14 step:13449 [D loss: 0.592626, acc.: 68.75%] [G loss: 0.938197]\n",
      "epoch:14 step:13450 [D loss: 0.636970, acc.: 60.16%] [G loss: 0.945748]\n",
      "epoch:14 step:13451 [D loss: 0.614933, acc.: 66.41%] [G loss: 0.895811]\n",
      "epoch:14 step:13452 [D loss: 0.657133, acc.: 58.59%] [G loss: 0.927166]\n",
      "epoch:14 step:13453 [D loss: 0.676481, acc.: 58.59%] [G loss: 0.895336]\n",
      "epoch:14 step:13454 [D loss: 0.645673, acc.: 62.50%] [G loss: 0.975073]\n",
      "epoch:14 step:13455 [D loss: 0.654531, acc.: 61.72%] [G loss: 0.903744]\n",
      "epoch:14 step:13456 [D loss: 0.660943, acc.: 64.06%] [G loss: 0.901892]\n",
      "epoch:14 step:13457 [D loss: 0.668319, acc.: 64.06%] [G loss: 0.921283]\n",
      "epoch:14 step:13458 [D loss: 0.613677, acc.: 67.97%] [G loss: 0.886073]\n",
      "epoch:14 step:13459 [D loss: 0.671916, acc.: 59.38%] [G loss: 0.926709]\n",
      "epoch:14 step:13460 [D loss: 0.710095, acc.: 57.03%] [G loss: 0.942752]\n",
      "epoch:14 step:13461 [D loss: 0.658953, acc.: 66.41%] [G loss: 0.972971]\n",
      "epoch:14 step:13462 [D loss: 0.650203, acc.: 64.06%] [G loss: 0.974994]\n",
      "epoch:14 step:13463 [D loss: 0.633307, acc.: 60.94%] [G loss: 0.992833]\n",
      "epoch:14 step:13464 [D loss: 0.602341, acc.: 69.53%] [G loss: 0.893221]\n",
      "epoch:14 step:13465 [D loss: 0.586764, acc.: 67.97%] [G loss: 1.005390]\n",
      "epoch:14 step:13466 [D loss: 0.775552, acc.: 51.56%] [G loss: 0.886187]\n",
      "epoch:14 step:13467 [D loss: 0.784014, acc.: 39.84%] [G loss: 0.866925]\n",
      "epoch:14 step:13468 [D loss: 0.665083, acc.: 60.16%] [G loss: 0.900635]\n",
      "epoch:14 step:13469 [D loss: 0.627942, acc.: 66.41%] [G loss: 0.898108]\n",
      "epoch:14 step:13470 [D loss: 0.694340, acc.: 55.47%] [G loss: 0.916725]\n",
      "epoch:14 step:13471 [D loss: 0.623286, acc.: 63.28%] [G loss: 0.975846]\n",
      "epoch:14 step:13472 [D loss: 0.578211, acc.: 74.22%] [G loss: 0.962164]\n",
      "epoch:14 step:13473 [D loss: 0.664552, acc.: 60.94%] [G loss: 0.974183]\n",
      "epoch:14 step:13474 [D loss: 0.669373, acc.: 62.50%] [G loss: 0.919937]\n",
      "epoch:14 step:13475 [D loss: 0.640281, acc.: 56.25%] [G loss: 0.948635]\n",
      "epoch:14 step:13476 [D loss: 0.635970, acc.: 60.16%] [G loss: 0.954680]\n",
      "epoch:14 step:13477 [D loss: 0.606363, acc.: 64.84%] [G loss: 0.959013]\n",
      "epoch:14 step:13478 [D loss: 0.607959, acc.: 68.75%] [G loss: 0.934851]\n",
      "epoch:14 step:13479 [D loss: 0.645376, acc.: 64.84%] [G loss: 0.949996]\n",
      "epoch:14 step:13480 [D loss: 0.643870, acc.: 63.28%] [G loss: 0.930163]\n",
      "epoch:14 step:13481 [D loss: 0.631034, acc.: 64.06%] [G loss: 0.888917]\n",
      "epoch:14 step:13482 [D loss: 0.628479, acc.: 60.16%] [G loss: 0.978558]\n",
      "epoch:14 step:13483 [D loss: 0.649457, acc.: 60.94%] [G loss: 0.928761]\n",
      "epoch:14 step:13484 [D loss: 0.638046, acc.: 62.50%] [G loss: 0.942062]\n",
      "epoch:14 step:13485 [D loss: 0.601320, acc.: 71.09%] [G loss: 0.957598]\n",
      "epoch:14 step:13486 [D loss: 0.700718, acc.: 52.34%] [G loss: 0.893727]\n",
      "epoch:14 step:13487 [D loss: 0.689598, acc.: 56.25%] [G loss: 0.862144]\n",
      "epoch:14 step:13488 [D loss: 0.635906, acc.: 66.41%] [G loss: 0.869728]\n",
      "epoch:14 step:13489 [D loss: 0.620185, acc.: 64.84%] [G loss: 0.937001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13490 [D loss: 0.688841, acc.: 58.59%] [G loss: 0.984739]\n",
      "epoch:14 step:13491 [D loss: 0.701761, acc.: 61.72%] [G loss: 0.907981]\n",
      "epoch:14 step:13492 [D loss: 0.614365, acc.: 64.06%] [G loss: 0.921140]\n",
      "epoch:14 step:13493 [D loss: 0.701538, acc.: 53.91%] [G loss: 0.956570]\n",
      "epoch:14 step:13494 [D loss: 0.703015, acc.: 53.12%] [G loss: 0.887220]\n",
      "epoch:14 step:13495 [D loss: 0.736678, acc.: 46.88%] [G loss: 0.860820]\n",
      "epoch:14 step:13496 [D loss: 0.729657, acc.: 50.78%] [G loss: 0.909409]\n",
      "epoch:14 step:13497 [D loss: 0.661497, acc.: 58.59%] [G loss: 0.904666]\n",
      "epoch:14 step:13498 [D loss: 0.633535, acc.: 65.62%] [G loss: 0.872562]\n",
      "epoch:14 step:13499 [D loss: 0.645981, acc.: 63.28%] [G loss: 0.866820]\n",
      "epoch:14 step:13500 [D loss: 0.659083, acc.: 63.28%] [G loss: 0.902797]\n",
      "epoch:14 step:13501 [D loss: 0.698276, acc.: 53.12%] [G loss: 0.896445]\n",
      "epoch:14 step:13502 [D loss: 0.629413, acc.: 67.19%] [G loss: 0.898815]\n",
      "epoch:14 step:13503 [D loss: 0.626089, acc.: 64.84%] [G loss: 0.919938]\n",
      "epoch:14 step:13504 [D loss: 0.680378, acc.: 55.47%] [G loss: 0.918388]\n",
      "epoch:14 step:13505 [D loss: 0.645016, acc.: 61.72%] [G loss: 0.918559]\n",
      "epoch:14 step:13506 [D loss: 0.671036, acc.: 56.25%] [G loss: 0.924608]\n",
      "epoch:14 step:13507 [D loss: 0.682203, acc.: 54.69%] [G loss: 0.877231]\n",
      "epoch:14 step:13508 [D loss: 0.722410, acc.: 47.66%] [G loss: 0.862564]\n",
      "epoch:14 step:13509 [D loss: 0.649856, acc.: 66.41%] [G loss: 0.923261]\n",
      "epoch:14 step:13510 [D loss: 0.639958, acc.: 66.41%] [G loss: 0.899311]\n",
      "epoch:14 step:13511 [D loss: 0.646345, acc.: 65.62%] [G loss: 0.898705]\n",
      "epoch:14 step:13512 [D loss: 0.672841, acc.: 58.59%] [G loss: 0.840156]\n",
      "epoch:14 step:13513 [D loss: 0.662186, acc.: 64.84%] [G loss: 0.907200]\n",
      "epoch:14 step:13514 [D loss: 0.678853, acc.: 57.03%] [G loss: 0.865117]\n",
      "epoch:14 step:13515 [D loss: 0.643499, acc.: 63.28%] [G loss: 0.937981]\n",
      "epoch:14 step:13516 [D loss: 0.555702, acc.: 74.22%] [G loss: 1.054785]\n",
      "epoch:14 step:13517 [D loss: 0.614167, acc.: 67.97%] [G loss: 1.027627]\n",
      "epoch:14 step:13518 [D loss: 0.699471, acc.: 52.34%] [G loss: 1.000610]\n",
      "epoch:14 step:13519 [D loss: 0.654013, acc.: 62.50%] [G loss: 0.915406]\n",
      "epoch:14 step:13520 [D loss: 0.661779, acc.: 57.81%] [G loss: 0.887725]\n",
      "epoch:14 step:13521 [D loss: 0.667128, acc.: 57.03%] [G loss: 0.898505]\n",
      "epoch:14 step:13522 [D loss: 0.672817, acc.: 53.91%] [G loss: 0.916571]\n",
      "epoch:14 step:13523 [D loss: 0.669153, acc.: 60.16%] [G loss: 0.976914]\n",
      "epoch:14 step:13524 [D loss: 0.628668, acc.: 67.97%] [G loss: 0.960092]\n",
      "epoch:14 step:13525 [D loss: 0.621264, acc.: 62.50%] [G loss: 0.984029]\n",
      "epoch:14 step:13526 [D loss: 0.712901, acc.: 53.12%] [G loss: 0.902633]\n",
      "epoch:14 step:13527 [D loss: 0.624047, acc.: 65.62%] [G loss: 0.911113]\n",
      "epoch:14 step:13528 [D loss: 0.662944, acc.: 60.16%] [G loss: 0.863206]\n",
      "epoch:14 step:13529 [D loss: 0.750334, acc.: 50.00%] [G loss: 0.820555]\n",
      "epoch:14 step:13530 [D loss: 0.686039, acc.: 56.25%] [G loss: 0.950167]\n",
      "epoch:14 step:13531 [D loss: 0.697352, acc.: 58.59%] [G loss: 0.917955]\n",
      "epoch:14 step:13532 [D loss: 0.646161, acc.: 64.84%] [G loss: 0.918091]\n",
      "epoch:14 step:13533 [D loss: 0.682192, acc.: 60.16%] [G loss: 0.981841]\n",
      "epoch:14 step:13534 [D loss: 0.652215, acc.: 62.50%] [G loss: 1.024740]\n",
      "epoch:14 step:13535 [D loss: 0.678771, acc.: 57.03%] [G loss: 0.993504]\n",
      "epoch:14 step:13536 [D loss: 0.693276, acc.: 52.34%] [G loss: 0.926352]\n",
      "epoch:14 step:13537 [D loss: 0.665039, acc.: 62.50%] [G loss: 0.961385]\n",
      "epoch:14 step:13538 [D loss: 0.667050, acc.: 62.50%] [G loss: 0.969064]\n",
      "epoch:14 step:13539 [D loss: 0.733230, acc.: 51.56%] [G loss: 0.853287]\n",
      "epoch:14 step:13540 [D loss: 0.676935, acc.: 60.94%] [G loss: 0.908012]\n",
      "epoch:14 step:13541 [D loss: 0.665382, acc.: 61.72%] [G loss: 0.959024]\n",
      "epoch:14 step:13542 [D loss: 0.689821, acc.: 58.59%] [G loss: 0.897642]\n",
      "epoch:14 step:13543 [D loss: 0.636080, acc.: 65.62%] [G loss: 0.941735]\n",
      "epoch:14 step:13544 [D loss: 0.654894, acc.: 64.06%] [G loss: 0.922526]\n",
      "epoch:14 step:13545 [D loss: 0.596059, acc.: 69.53%] [G loss: 0.997842]\n",
      "epoch:14 step:13546 [D loss: 0.592679, acc.: 68.75%] [G loss: 0.907516]\n",
      "epoch:14 step:13547 [D loss: 0.631557, acc.: 64.84%] [G loss: 0.947692]\n",
      "epoch:14 step:13548 [D loss: 0.585229, acc.: 66.41%] [G loss: 0.934362]\n",
      "epoch:14 step:13549 [D loss: 0.709686, acc.: 56.25%] [G loss: 0.875596]\n",
      "epoch:14 step:13550 [D loss: 0.718487, acc.: 48.44%] [G loss: 0.973346]\n",
      "epoch:14 step:13551 [D loss: 0.694771, acc.: 51.56%] [G loss: 0.856041]\n",
      "epoch:14 step:13552 [D loss: 0.631887, acc.: 64.84%] [G loss: 0.910733]\n",
      "epoch:14 step:13553 [D loss: 0.648990, acc.: 58.59%] [G loss: 0.939856]\n",
      "epoch:14 step:13554 [D loss: 0.645940, acc.: 63.28%] [G loss: 1.002337]\n",
      "epoch:14 step:13555 [D loss: 0.736815, acc.: 46.88%] [G loss: 0.994355]\n",
      "epoch:14 step:13556 [D loss: 0.662229, acc.: 57.81%] [G loss: 0.950559]\n",
      "epoch:14 step:13557 [D loss: 0.637447, acc.: 66.41%] [G loss: 0.997679]\n",
      "epoch:14 step:13558 [D loss: 0.644870, acc.: 67.19%] [G loss: 1.020024]\n",
      "epoch:14 step:13559 [D loss: 0.615972, acc.: 70.31%] [G loss: 1.023939]\n",
      "epoch:14 step:13560 [D loss: 0.657476, acc.: 61.72%] [G loss: 0.880269]\n",
      "epoch:14 step:13561 [D loss: 0.624231, acc.: 62.50%] [G loss: 0.887845]\n",
      "epoch:14 step:13562 [D loss: 0.647190, acc.: 60.16%] [G loss: 0.893672]\n",
      "epoch:14 step:13563 [D loss: 0.644861, acc.: 58.59%] [G loss: 0.947724]\n",
      "epoch:14 step:13564 [D loss: 0.627023, acc.: 61.72%] [G loss: 0.890078]\n",
      "epoch:14 step:13565 [D loss: 0.615354, acc.: 70.31%] [G loss: 0.956880]\n",
      "epoch:14 step:13566 [D loss: 0.653014, acc.: 58.59%] [G loss: 0.866580]\n",
      "epoch:14 step:13567 [D loss: 0.717911, acc.: 52.34%] [G loss: 0.901889]\n",
      "epoch:14 step:13568 [D loss: 0.635053, acc.: 64.84%] [G loss: 0.954618]\n",
      "epoch:14 step:13569 [D loss: 0.612074, acc.: 70.31%] [G loss: 0.917041]\n",
      "epoch:14 step:13570 [D loss: 0.619937, acc.: 67.97%] [G loss: 0.941351]\n",
      "epoch:14 step:13571 [D loss: 0.626546, acc.: 67.97%] [G loss: 0.981688]\n",
      "epoch:14 step:13572 [D loss: 0.654647, acc.: 66.41%] [G loss: 1.040825]\n",
      "epoch:14 step:13573 [D loss: 0.673878, acc.: 60.16%] [G loss: 0.838668]\n",
      "epoch:14 step:13574 [D loss: 0.608571, acc.: 67.97%] [G loss: 0.898151]\n",
      "epoch:14 step:13575 [D loss: 0.615912, acc.: 65.62%] [G loss: 0.936079]\n",
      "epoch:14 step:13576 [D loss: 0.799875, acc.: 46.88%] [G loss: 0.848678]\n",
      "epoch:14 step:13577 [D loss: 0.701575, acc.: 55.47%] [G loss: 0.882948]\n",
      "epoch:14 step:13578 [D loss: 0.685001, acc.: 54.69%] [G loss: 0.912045]\n",
      "epoch:14 step:13579 [D loss: 0.666770, acc.: 64.06%] [G loss: 0.916437]\n",
      "epoch:14 step:13580 [D loss: 0.656906, acc.: 60.16%] [G loss: 0.882812]\n",
      "epoch:14 step:13581 [D loss: 0.661650, acc.: 59.38%] [G loss: 0.930013]\n",
      "epoch:14 step:13582 [D loss: 0.671921, acc.: 60.94%] [G loss: 0.853048]\n",
      "epoch:14 step:13583 [D loss: 0.658504, acc.: 66.41%] [G loss: 0.849771]\n",
      "epoch:14 step:13584 [D loss: 0.681727, acc.: 57.81%] [G loss: 0.869622]\n",
      "epoch:14 step:13585 [D loss: 0.641882, acc.: 60.94%] [G loss: 0.897221]\n",
      "epoch:14 step:13586 [D loss: 0.667752, acc.: 59.38%] [G loss: 0.911792]\n",
      "epoch:14 step:13587 [D loss: 0.633168, acc.: 63.28%] [G loss: 1.057246]\n",
      "epoch:14 step:13588 [D loss: 0.635918, acc.: 65.62%] [G loss: 0.943389]\n",
      "epoch:14 step:13589 [D loss: 0.616096, acc.: 65.62%] [G loss: 0.998362]\n",
      "epoch:14 step:13590 [D loss: 0.606000, acc.: 71.09%] [G loss: 1.018920]\n",
      "epoch:14 step:13591 [D loss: 0.706708, acc.: 55.47%] [G loss: 0.964821]\n",
      "epoch:14 step:13592 [D loss: 0.649454, acc.: 69.53%] [G loss: 0.958959]\n",
      "epoch:14 step:13593 [D loss: 0.655750, acc.: 58.59%] [G loss: 0.937003]\n",
      "epoch:14 step:13594 [D loss: 0.702233, acc.: 57.81%] [G loss: 0.960737]\n",
      "epoch:14 step:13595 [D loss: 0.722318, acc.: 48.44%] [G loss: 0.871042]\n",
      "epoch:14 step:13596 [D loss: 0.691555, acc.: 57.03%] [G loss: 0.846017]\n",
      "epoch:14 step:13597 [D loss: 0.601621, acc.: 67.19%] [G loss: 0.873357]\n",
      "epoch:14 step:13598 [D loss: 0.617384, acc.: 66.41%] [G loss: 0.925108]\n",
      "epoch:14 step:13599 [D loss: 0.600472, acc.: 64.84%] [G loss: 0.887057]\n",
      "epoch:14 step:13600 [D loss: 0.698623, acc.: 51.56%] [G loss: 0.914553]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.936111\n",
      "FID: 10.051355\n",
      "0 = 11.83459381120212\n",
      "1 = 0.05359873756800879\n",
      "2 = 0.9135000109672546\n",
      "3 = 0.8676999807357788\n",
      "4 = 0.9592999815940857\n",
      "5 = 0.955195963382721\n",
      "6 = 0.8676999807357788\n",
      "7 = 6.0325807158172\n",
      "8 = 0.0645058156430102\n",
      "9 = 0.7117000222206116\n",
      "10 = 0.6901999711990356\n",
      "11 = 0.7332000136375427\n",
      "12 = 0.7212121486663818\n",
      "13 = 0.6901999711990356\n",
      "14 = 7.9361748695373535\n",
      "15 = 9.586756706237793\n",
      "16 = 0.10040108859539032\n",
      "17 = 7.936110973358154\n",
      "18 = 10.051355361938477\n",
      "epoch:14 step:13601 [D loss: 0.677364, acc.: 59.38%] [G loss: 0.899151]\n",
      "epoch:14 step:13602 [D loss: 0.622018, acc.: 68.75%] [G loss: 0.985804]\n",
      "epoch:14 step:13603 [D loss: 0.621117, acc.: 71.88%] [G loss: 1.008533]\n",
      "epoch:14 step:13604 [D loss: 0.716723, acc.: 50.00%] [G loss: 0.895599]\n",
      "epoch:14 step:13605 [D loss: 0.704585, acc.: 56.25%] [G loss: 0.872909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13606 [D loss: 0.656410, acc.: 60.94%] [G loss: 0.918461]\n",
      "epoch:14 step:13607 [D loss: 0.666569, acc.: 62.50%] [G loss: 0.886247]\n",
      "epoch:14 step:13608 [D loss: 0.669780, acc.: 64.84%] [G loss: 0.951646]\n",
      "epoch:14 step:13609 [D loss: 0.663837, acc.: 60.94%] [G loss: 0.907856]\n",
      "epoch:14 step:13610 [D loss: 0.734922, acc.: 51.56%] [G loss: 0.923753]\n",
      "epoch:14 step:13611 [D loss: 0.661595, acc.: 57.03%] [G loss: 0.875819]\n",
      "epoch:14 step:13612 [D loss: 0.672917, acc.: 56.25%] [G loss: 0.859144]\n",
      "epoch:14 step:13613 [D loss: 0.631881, acc.: 64.84%] [G loss: 0.903862]\n",
      "epoch:14 step:13614 [D loss: 0.669527, acc.: 55.47%] [G loss: 0.892520]\n",
      "epoch:14 step:13615 [D loss: 0.647303, acc.: 62.50%] [G loss: 0.918568]\n",
      "epoch:14 step:13616 [D loss: 0.618510, acc.: 70.31%] [G loss: 0.966400]\n",
      "epoch:14 step:13617 [D loss: 0.591428, acc.: 75.00%] [G loss: 1.016918]\n",
      "epoch:14 step:13618 [D loss: 0.705155, acc.: 53.91%] [G loss: 0.947179]\n",
      "epoch:14 step:13619 [D loss: 0.691801, acc.: 59.38%] [G loss: 0.941609]\n",
      "epoch:14 step:13620 [D loss: 0.667762, acc.: 58.59%] [G loss: 0.924871]\n",
      "epoch:14 step:13621 [D loss: 0.689884, acc.: 53.91%] [G loss: 0.895782]\n",
      "epoch:14 step:13622 [D loss: 0.634062, acc.: 64.06%] [G loss: 0.835464]\n",
      "epoch:14 step:13623 [D loss: 0.624200, acc.: 61.72%] [G loss: 0.936880]\n",
      "epoch:14 step:13624 [D loss: 0.636141, acc.: 61.72%] [G loss: 0.952534]\n",
      "epoch:14 step:13625 [D loss: 0.629953, acc.: 60.94%] [G loss: 1.013853]\n",
      "epoch:14 step:13626 [D loss: 0.574977, acc.: 67.97%] [G loss: 1.011882]\n",
      "epoch:14 step:13627 [D loss: 0.734426, acc.: 49.22%] [G loss: 0.929950]\n",
      "epoch:14 step:13628 [D loss: 0.715814, acc.: 51.56%] [G loss: 0.890408]\n",
      "epoch:14 step:13629 [D loss: 0.731508, acc.: 48.44%] [G loss: 0.874302]\n",
      "epoch:14 step:13630 [D loss: 0.696612, acc.: 51.56%] [G loss: 0.825538]\n",
      "epoch:14 step:13631 [D loss: 0.661109, acc.: 57.81%] [G loss: 0.870541]\n",
      "epoch:14 step:13632 [D loss: 0.665347, acc.: 58.59%] [G loss: 0.899641]\n",
      "epoch:14 step:13633 [D loss: 0.684781, acc.: 56.25%] [G loss: 0.894907]\n",
      "epoch:14 step:13634 [D loss: 0.614631, acc.: 69.53%] [G loss: 0.921593]\n",
      "epoch:14 step:13635 [D loss: 0.684129, acc.: 58.59%] [G loss: 0.899588]\n",
      "epoch:14 step:13636 [D loss: 0.643912, acc.: 65.62%] [G loss: 0.915898]\n",
      "epoch:14 step:13637 [D loss: 0.616755, acc.: 67.97%] [G loss: 0.896227]\n",
      "epoch:14 step:13638 [D loss: 0.641716, acc.: 65.62%] [G loss: 0.946451]\n",
      "epoch:14 step:13639 [D loss: 0.617630, acc.: 66.41%] [G loss: 0.872656]\n",
      "epoch:14 step:13640 [D loss: 0.662182, acc.: 58.59%] [G loss: 0.884995]\n",
      "epoch:14 step:13641 [D loss: 0.621637, acc.: 67.19%] [G loss: 0.981564]\n",
      "epoch:14 step:13642 [D loss: 0.720546, acc.: 52.34%] [G loss: 0.901475]\n",
      "epoch:14 step:13643 [D loss: 0.676214, acc.: 56.25%] [G loss: 0.907790]\n",
      "epoch:14 step:13644 [D loss: 0.657614, acc.: 57.81%] [G loss: 0.941203]\n",
      "epoch:14 step:13645 [D loss: 0.683172, acc.: 60.94%] [G loss: 0.933157]\n",
      "epoch:14 step:13646 [D loss: 0.689711, acc.: 57.81%] [G loss: 0.924636]\n",
      "epoch:14 step:13647 [D loss: 0.707520, acc.: 53.91%] [G loss: 0.859699]\n",
      "epoch:14 step:13648 [D loss: 0.653387, acc.: 61.72%] [G loss: 0.863968]\n",
      "epoch:14 step:13649 [D loss: 0.705740, acc.: 53.91%] [G loss: 0.880778]\n",
      "epoch:14 step:13650 [D loss: 0.682125, acc.: 60.16%] [G loss: 0.866320]\n",
      "epoch:14 step:13651 [D loss: 0.701457, acc.: 54.69%] [G loss: 0.871798]\n",
      "epoch:14 step:13652 [D loss: 0.621769, acc.: 64.06%] [G loss: 0.824243]\n",
      "epoch:14 step:13653 [D loss: 0.678803, acc.: 59.38%] [G loss: 0.823473]\n",
      "epoch:14 step:13654 [D loss: 0.634564, acc.: 64.84%] [G loss: 0.871742]\n",
      "epoch:14 step:13655 [D loss: 0.670640, acc.: 57.03%] [G loss: 0.890670]\n",
      "epoch:14 step:13656 [D loss: 0.687190, acc.: 60.94%] [G loss: 0.875277]\n",
      "epoch:14 step:13657 [D loss: 0.656453, acc.: 58.59%] [G loss: 0.887791]\n",
      "epoch:14 step:13658 [D loss: 0.644331, acc.: 65.62%] [G loss: 0.890249]\n",
      "epoch:14 step:13659 [D loss: 0.632850, acc.: 69.53%] [G loss: 0.831517]\n",
      "epoch:14 step:13660 [D loss: 0.774111, acc.: 46.09%] [G loss: 0.780796]\n",
      "epoch:14 step:13661 [D loss: 0.697768, acc.: 53.12%] [G loss: 0.918208]\n",
      "epoch:14 step:13662 [D loss: 0.665825, acc.: 60.94%] [G loss: 0.843038]\n",
      "epoch:14 step:13663 [D loss: 0.634432, acc.: 62.50%] [G loss: 0.928695]\n",
      "epoch:14 step:13664 [D loss: 0.625396, acc.: 64.84%] [G loss: 0.864033]\n",
      "epoch:14 step:13665 [D loss: 0.635729, acc.: 63.28%] [G loss: 0.928745]\n",
      "epoch:14 step:13666 [D loss: 0.643770, acc.: 57.03%] [G loss: 0.867656]\n",
      "epoch:14 step:13667 [D loss: 0.633307, acc.: 67.97%] [G loss: 0.919739]\n",
      "epoch:14 step:13668 [D loss: 0.635163, acc.: 59.38%] [G loss: 0.971309]\n",
      "epoch:14 step:13669 [D loss: 0.637383, acc.: 66.41%] [G loss: 0.987474]\n",
      "epoch:14 step:13670 [D loss: 0.616398, acc.: 67.19%] [G loss: 0.955975]\n",
      "epoch:14 step:13671 [D loss: 0.699258, acc.: 59.38%] [G loss: 0.874554]\n",
      "epoch:14 step:13672 [D loss: 0.609687, acc.: 67.97%] [G loss: 0.879610]\n",
      "epoch:14 step:13673 [D loss: 0.636787, acc.: 67.19%] [G loss: 0.897208]\n",
      "epoch:14 step:13674 [D loss: 0.621557, acc.: 65.62%] [G loss: 0.864720]\n",
      "epoch:14 step:13675 [D loss: 0.597201, acc.: 67.97%] [G loss: 0.905560]\n",
      "epoch:14 step:13676 [D loss: 0.651781, acc.: 60.16%] [G loss: 0.859833]\n",
      "epoch:14 step:13677 [D loss: 0.702736, acc.: 51.56%] [G loss: 0.932449]\n",
      "epoch:14 step:13678 [D loss: 0.695892, acc.: 57.03%] [G loss: 0.906955]\n",
      "epoch:14 step:13679 [D loss: 0.638514, acc.: 62.50%] [G loss: 0.886031]\n",
      "epoch:14 step:13680 [D loss: 0.663584, acc.: 60.94%] [G loss: 0.880795]\n",
      "epoch:14 step:13681 [D loss: 0.604687, acc.: 63.28%] [G loss: 0.966002]\n",
      "epoch:14 step:13682 [D loss: 0.562250, acc.: 76.56%] [G loss: 0.980137]\n",
      "epoch:14 step:13683 [D loss: 0.699083, acc.: 51.56%] [G loss: 0.922000]\n",
      "epoch:14 step:13684 [D loss: 0.706547, acc.: 51.56%] [G loss: 0.917176]\n",
      "epoch:14 step:13685 [D loss: 0.618819, acc.: 62.50%] [G loss: 0.896878]\n",
      "epoch:14 step:13686 [D loss: 0.623216, acc.: 65.62%] [G loss: 0.921176]\n",
      "epoch:14 step:13687 [D loss: 0.726439, acc.: 53.12%] [G loss: 0.871533]\n",
      "epoch:14 step:13688 [D loss: 0.663584, acc.: 59.38%] [G loss: 0.846749]\n",
      "epoch:14 step:13689 [D loss: 0.636439, acc.: 59.38%] [G loss: 0.865598]\n",
      "epoch:14 step:13690 [D loss: 0.712251, acc.: 53.12%] [G loss: 0.901383]\n",
      "epoch:14 step:13691 [D loss: 0.646501, acc.: 61.72%] [G loss: 0.950996]\n",
      "epoch:14 step:13692 [D loss: 0.563919, acc.: 74.22%] [G loss: 1.014669]\n",
      "epoch:14 step:13693 [D loss: 0.590097, acc.: 70.31%] [G loss: 1.018907]\n",
      "epoch:14 step:13694 [D loss: 0.669020, acc.: 61.72%] [G loss: 0.911453]\n",
      "epoch:14 step:13695 [D loss: 0.681576, acc.: 58.59%] [G loss: 0.857947]\n",
      "epoch:14 step:13696 [D loss: 0.645185, acc.: 58.59%] [G loss: 0.839772]\n",
      "epoch:14 step:13697 [D loss: 0.658339, acc.: 57.81%] [G loss: 0.869016]\n",
      "epoch:14 step:13698 [D loss: 0.701884, acc.: 58.59%] [G loss: 0.874079]\n",
      "epoch:14 step:13699 [D loss: 0.638353, acc.: 63.28%] [G loss: 0.953370]\n",
      "epoch:14 step:13700 [D loss: 0.609406, acc.: 65.62%] [G loss: 0.966872]\n",
      "epoch:14 step:13701 [D loss: 0.664485, acc.: 63.28%] [G loss: 1.003092]\n",
      "epoch:14 step:13702 [D loss: 0.712071, acc.: 55.47%] [G loss: 0.954133]\n",
      "epoch:14 step:13703 [D loss: 0.654562, acc.: 58.59%] [G loss: 0.904802]\n",
      "epoch:14 step:13704 [D loss: 0.686910, acc.: 51.56%] [G loss: 0.892340]\n",
      "epoch:14 step:13705 [D loss: 0.718254, acc.: 50.00%] [G loss: 0.888271]\n",
      "epoch:14 step:13706 [D loss: 0.652682, acc.: 61.72%] [G loss: 0.927475]\n",
      "epoch:14 step:13707 [D loss: 0.617288, acc.: 62.50%] [G loss: 0.880245]\n",
      "epoch:14 step:13708 [D loss: 0.702747, acc.: 50.78%] [G loss: 0.862943]\n",
      "epoch:14 step:13709 [D loss: 0.711959, acc.: 51.56%] [G loss: 0.838071]\n",
      "epoch:14 step:13710 [D loss: 0.670423, acc.: 60.16%] [G loss: 0.870356]\n",
      "epoch:14 step:13711 [D loss: 0.640751, acc.: 64.06%] [G loss: 0.970054]\n",
      "epoch:14 step:13712 [D loss: 0.694310, acc.: 53.12%] [G loss: 0.874893]\n",
      "epoch:14 step:13713 [D loss: 0.612304, acc.: 65.62%] [G loss: 0.936611]\n",
      "epoch:14 step:13714 [D loss: 0.672556, acc.: 59.38%] [G loss: 0.924708]\n",
      "epoch:14 step:13715 [D loss: 0.704162, acc.: 54.69%] [G loss: 0.826134]\n",
      "epoch:14 step:13716 [D loss: 0.669188, acc.: 62.50%] [G loss: 0.904571]\n",
      "epoch:14 step:13717 [D loss: 0.628284, acc.: 63.28%] [G loss: 0.923279]\n",
      "epoch:14 step:13718 [D loss: 0.730530, acc.: 46.09%] [G loss: 0.846357]\n",
      "epoch:14 step:13719 [D loss: 0.666312, acc.: 56.25%] [G loss: 0.839482]\n",
      "epoch:14 step:13720 [D loss: 0.664834, acc.: 60.16%] [G loss: 0.840049]\n",
      "epoch:14 step:13721 [D loss: 0.660412, acc.: 61.72%] [G loss: 0.884626]\n",
      "epoch:14 step:13722 [D loss: 0.676827, acc.: 54.69%] [G loss: 0.838933]\n",
      "epoch:14 step:13723 [D loss: 0.659862, acc.: 64.84%] [G loss: 0.847254]\n",
      "epoch:14 step:13724 [D loss: 0.683722, acc.: 53.12%] [G loss: 0.900384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13725 [D loss: 0.638538, acc.: 68.75%] [G loss: 0.960460]\n",
      "epoch:14 step:13726 [D loss: 0.629362, acc.: 70.31%] [G loss: 0.879952]\n",
      "epoch:14 step:13727 [D loss: 0.641794, acc.: 66.41%] [G loss: 0.860968]\n",
      "epoch:14 step:13728 [D loss: 0.666404, acc.: 57.03%] [G loss: 0.955016]\n",
      "epoch:14 step:13729 [D loss: 0.632687, acc.: 64.84%] [G loss: 0.847511]\n",
      "epoch:14 step:13730 [D loss: 0.634591, acc.: 65.62%] [G loss: 0.865684]\n",
      "epoch:14 step:13731 [D loss: 0.632792, acc.: 61.72%] [G loss: 0.891861]\n",
      "epoch:14 step:13732 [D loss: 0.708110, acc.: 53.12%] [G loss: 0.865425]\n",
      "epoch:14 step:13733 [D loss: 0.710885, acc.: 53.91%] [G loss: 0.827752]\n",
      "epoch:14 step:13734 [D loss: 0.664854, acc.: 57.81%] [G loss: 0.884441]\n",
      "epoch:14 step:13735 [D loss: 0.654664, acc.: 64.84%] [G loss: 0.873329]\n",
      "epoch:14 step:13736 [D loss: 0.696797, acc.: 58.59%] [G loss: 0.946351]\n",
      "epoch:14 step:13737 [D loss: 0.665907, acc.: 62.50%] [G loss: 0.969590]\n",
      "epoch:14 step:13738 [D loss: 0.678535, acc.: 56.25%] [G loss: 0.914326]\n",
      "epoch:14 step:13739 [D loss: 0.688457, acc.: 52.34%] [G loss: 0.884689]\n",
      "epoch:14 step:13740 [D loss: 0.651202, acc.: 64.06%] [G loss: 0.902167]\n",
      "epoch:14 step:13741 [D loss: 0.658013, acc.: 61.72%] [G loss: 0.886480]\n",
      "epoch:14 step:13742 [D loss: 0.589817, acc.: 68.75%] [G loss: 0.981771]\n",
      "epoch:14 step:13743 [D loss: 0.671773, acc.: 59.38%] [G loss: 0.978179]\n",
      "epoch:14 step:13744 [D loss: 0.691142, acc.: 52.34%] [G loss: 0.891128]\n",
      "epoch:14 step:13745 [D loss: 0.655857, acc.: 57.81%] [G loss: 0.927945]\n",
      "epoch:14 step:13746 [D loss: 0.664843, acc.: 63.28%] [G loss: 0.904563]\n",
      "epoch:14 step:13747 [D loss: 0.597695, acc.: 71.88%] [G loss: 0.970014]\n",
      "epoch:14 step:13748 [D loss: 0.669901, acc.: 59.38%] [G loss: 0.912058]\n",
      "epoch:14 step:13749 [D loss: 0.591511, acc.: 72.66%] [G loss: 0.939388]\n",
      "epoch:14 step:13750 [D loss: 0.614917, acc.: 65.62%] [G loss: 0.990386]\n",
      "epoch:14 step:13751 [D loss: 0.612213, acc.: 66.41%] [G loss: 0.924800]\n",
      "epoch:14 step:13752 [D loss: 0.588524, acc.: 68.75%] [G loss: 0.872658]\n",
      "epoch:14 step:13753 [D loss: 0.631612, acc.: 62.50%] [G loss: 0.900175]\n",
      "epoch:14 step:13754 [D loss: 0.641616, acc.: 60.94%] [G loss: 0.875022]\n",
      "epoch:14 step:13755 [D loss: 0.622557, acc.: 65.62%] [G loss: 0.902145]\n",
      "epoch:14 step:13756 [D loss: 0.649058, acc.: 62.50%] [G loss: 0.920932]\n",
      "epoch:14 step:13757 [D loss: 0.672954, acc.: 57.03%] [G loss: 0.927248]\n",
      "epoch:14 step:13758 [D loss: 0.622879, acc.: 66.41%] [G loss: 0.908359]\n",
      "epoch:14 step:13759 [D loss: 0.588325, acc.: 72.66%] [G loss: 0.952380]\n",
      "epoch:14 step:13760 [D loss: 0.566779, acc.: 67.97%] [G loss: 0.963936]\n",
      "epoch:14 step:13761 [D loss: 0.642974, acc.: 64.84%] [G loss: 0.982023]\n",
      "epoch:14 step:13762 [D loss: 0.754427, acc.: 46.88%] [G loss: 0.871635]\n",
      "epoch:14 step:13763 [D loss: 0.657447, acc.: 59.38%] [G loss: 0.899924]\n",
      "epoch:14 step:13764 [D loss: 0.638399, acc.: 60.94%] [G loss: 0.890901]\n",
      "epoch:14 step:13765 [D loss: 0.641942, acc.: 64.06%] [G loss: 0.940630]\n",
      "epoch:14 step:13766 [D loss: 0.598729, acc.: 69.53%] [G loss: 1.020661]\n",
      "epoch:14 step:13767 [D loss: 0.637743, acc.: 63.28%] [G loss: 0.989607]\n",
      "epoch:14 step:13768 [D loss: 0.601096, acc.: 68.75%] [G loss: 1.049300]\n",
      "epoch:14 step:13769 [D loss: 0.691364, acc.: 57.81%] [G loss: 0.969513]\n",
      "epoch:14 step:13770 [D loss: 0.715647, acc.: 51.56%] [G loss: 0.915997]\n",
      "epoch:14 step:13771 [D loss: 0.688174, acc.: 53.91%] [G loss: 0.891162]\n",
      "epoch:14 step:13772 [D loss: 0.636448, acc.: 66.41%] [G loss: 0.943807]\n",
      "epoch:14 step:13773 [D loss: 0.728345, acc.: 57.81%] [G loss: 0.895970]\n",
      "epoch:14 step:13774 [D loss: 0.654452, acc.: 60.16%] [G loss: 0.883895]\n",
      "epoch:14 step:13775 [D loss: 0.652311, acc.: 60.94%] [G loss: 0.911413]\n",
      "epoch:14 step:13776 [D loss: 0.629520, acc.: 62.50%] [G loss: 0.943815]\n",
      "epoch:14 step:13777 [D loss: 0.660777, acc.: 62.50%] [G loss: 0.972144]\n",
      "epoch:14 step:13778 [D loss: 0.613948, acc.: 64.06%] [G loss: 0.987988]\n",
      "epoch:14 step:13779 [D loss: 0.628593, acc.: 60.16%] [G loss: 0.920449]\n",
      "epoch:14 step:13780 [D loss: 0.685653, acc.: 58.59%] [G loss: 0.906071]\n",
      "epoch:14 step:13781 [D loss: 0.677461, acc.: 59.38%] [G loss: 0.873386]\n",
      "epoch:14 step:13782 [D loss: 0.660094, acc.: 61.72%] [G loss: 0.847157]\n",
      "epoch:14 step:13783 [D loss: 0.659966, acc.: 59.38%] [G loss: 0.874650]\n",
      "epoch:14 step:13784 [D loss: 0.593818, acc.: 75.00%] [G loss: 0.885766]\n",
      "epoch:14 step:13785 [D loss: 0.652162, acc.: 61.72%] [G loss: 0.901505]\n",
      "epoch:14 step:13786 [D loss: 0.644570, acc.: 60.16%] [G loss: 0.947294]\n",
      "epoch:14 step:13787 [D loss: 0.603148, acc.: 67.97%] [G loss: 0.939904]\n",
      "epoch:14 step:13788 [D loss: 0.703840, acc.: 50.78%] [G loss: 0.898555]\n",
      "epoch:14 step:13789 [D loss: 0.731212, acc.: 54.69%] [G loss: 0.933115]\n",
      "epoch:14 step:13790 [D loss: 0.715462, acc.: 54.69%] [G loss: 0.888323]\n",
      "epoch:14 step:13791 [D loss: 0.683144, acc.: 59.38%] [G loss: 0.864445]\n",
      "epoch:14 step:13792 [D loss: 0.631370, acc.: 66.41%] [G loss: 0.882779]\n",
      "epoch:14 step:13793 [D loss: 0.707785, acc.: 54.69%] [G loss: 0.884640]\n",
      "epoch:14 step:13794 [D loss: 0.657440, acc.: 62.50%] [G loss: 0.900407]\n",
      "epoch:14 step:13795 [D loss: 0.652996, acc.: 60.16%] [G loss: 0.934897]\n",
      "epoch:14 step:13796 [D loss: 0.648993, acc.: 62.50%] [G loss: 0.927008]\n",
      "epoch:14 step:13797 [D loss: 0.659477, acc.: 64.06%] [G loss: 0.866136]\n",
      "epoch:14 step:13798 [D loss: 0.633971, acc.: 66.41%] [G loss: 0.932996]\n",
      "epoch:14 step:13799 [D loss: 0.595595, acc.: 65.62%] [G loss: 0.900744]\n",
      "epoch:14 step:13800 [D loss: 0.680457, acc.: 54.69%] [G loss: 0.846829]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.137628\n",
      "FID: 5.782161\n",
      "0 = 11.719091603684388\n",
      "1 = 0.04764934552314627\n",
      "2 = 0.9063500165939331\n",
      "3 = 0.8600999712944031\n",
      "4 = 0.9526000022888184\n",
      "5 = 0.9477685689926147\n",
      "6 = 0.8600999712944031\n",
      "7 = 5.557904887270911\n",
      "8 = 0.05201971619302372\n",
      "9 = 0.6954500079154968\n",
      "10 = 0.6834999918937683\n",
      "11 = 0.7074000239372253\n",
      "12 = 0.7002356052398682\n",
      "13 = 0.6834999918937683\n",
      "14 = 8.137700080871582\n",
      "15 = 9.593092918395996\n",
      "16 = 0.08917587995529175\n",
      "17 = 8.137627601623535\n",
      "18 = 5.782161235809326\n",
      "epoch:14 step:13801 [D loss: 0.660554, acc.: 53.12%] [G loss: 0.919460]\n",
      "epoch:14 step:13802 [D loss: 0.728455, acc.: 52.34%] [G loss: 0.857522]\n",
      "epoch:14 step:13803 [D loss: 0.672113, acc.: 57.81%] [G loss: 0.901708]\n",
      "epoch:14 step:13804 [D loss: 0.628977, acc.: 68.75%] [G loss: 0.858713]\n",
      "epoch:14 step:13805 [D loss: 0.685617, acc.: 54.69%] [G loss: 0.836095]\n",
      "epoch:14 step:13806 [D loss: 0.636922, acc.: 69.53%] [G loss: 0.919264]\n",
      "epoch:14 step:13807 [D loss: 0.649267, acc.: 64.06%] [G loss: 0.884433]\n",
      "epoch:14 step:13808 [D loss: 0.663611, acc.: 64.06%] [G loss: 0.919049]\n",
      "epoch:14 step:13809 [D loss: 0.625868, acc.: 69.53%] [G loss: 0.924505]\n",
      "epoch:14 step:13810 [D loss: 0.619865, acc.: 64.06%] [G loss: 0.858798]\n",
      "epoch:14 step:13811 [D loss: 0.661591, acc.: 60.94%] [G loss: 0.948615]\n",
      "epoch:14 step:13812 [D loss: 0.575615, acc.: 72.66%] [G loss: 0.930112]\n",
      "epoch:14 step:13813 [D loss: 0.630901, acc.: 67.19%] [G loss: 0.958557]\n",
      "epoch:14 step:13814 [D loss: 0.688783, acc.: 57.81%] [G loss: 0.897097]\n",
      "epoch:14 step:13815 [D loss: 0.668460, acc.: 58.59%] [G loss: 0.831309]\n",
      "epoch:14 step:13816 [D loss: 0.653247, acc.: 60.94%] [G loss: 0.848384]\n",
      "epoch:14 step:13817 [D loss: 0.656122, acc.: 61.72%] [G loss: 0.912882]\n",
      "epoch:14 step:13818 [D loss: 0.636017, acc.: 57.81%] [G loss: 0.908257]\n",
      "epoch:14 step:13819 [D loss: 0.637822, acc.: 64.06%] [G loss: 0.937168]\n",
      "epoch:14 step:13820 [D loss: 0.662841, acc.: 61.72%] [G loss: 0.912927]\n",
      "epoch:14 step:13821 [D loss: 0.724895, acc.: 53.12%] [G loss: 0.866030]\n",
      "epoch:14 step:13822 [D loss: 0.698753, acc.: 52.34%] [G loss: 0.920853]\n",
      "epoch:14 step:13823 [D loss: 0.673355, acc.: 61.72%] [G loss: 0.911662]\n",
      "epoch:14 step:13824 [D loss: 0.663346, acc.: 57.81%] [G loss: 0.829851]\n",
      "epoch:14 step:13825 [D loss: 0.631041, acc.: 64.06%] [G loss: 0.904111]\n",
      "epoch:14 step:13826 [D loss: 0.558624, acc.: 76.56%] [G loss: 0.935013]\n",
      "epoch:14 step:13827 [D loss: 0.625402, acc.: 67.19%] [G loss: 0.958725]\n",
      "epoch:14 step:13828 [D loss: 0.698126, acc.: 57.81%] [G loss: 0.900661]\n",
      "epoch:14 step:13829 [D loss: 0.670564, acc.: 58.59%] [G loss: 0.855333]\n",
      "epoch:14 step:13830 [D loss: 0.619726, acc.: 69.53%] [G loss: 0.986371]\n",
      "epoch:14 step:13831 [D loss: 0.652955, acc.: 60.94%] [G loss: 0.915856]\n",
      "epoch:14 step:13832 [D loss: 0.679829, acc.: 52.34%] [G loss: 1.018669]\n",
      "epoch:14 step:13833 [D loss: 0.666813, acc.: 60.94%] [G loss: 0.941106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13834 [D loss: 0.756229, acc.: 42.19%] [G loss: 0.890303]\n",
      "epoch:14 step:13835 [D loss: 0.667208, acc.: 52.34%] [G loss: 0.919741]\n",
      "epoch:14 step:13836 [D loss: 0.701112, acc.: 51.56%] [G loss: 0.886383]\n",
      "epoch:14 step:13837 [D loss: 0.644702, acc.: 68.75%] [G loss: 0.828834]\n",
      "epoch:14 step:13838 [D loss: 0.667731, acc.: 58.59%] [G loss: 0.884082]\n",
      "epoch:14 step:13839 [D loss: 0.677044, acc.: 55.47%] [G loss: 0.915407]\n",
      "epoch:14 step:13840 [D loss: 0.694433, acc.: 53.91%] [G loss: 0.849178]\n",
      "epoch:14 step:13841 [D loss: 0.647164, acc.: 61.72%] [G loss: 0.881185]\n",
      "epoch:14 step:13842 [D loss: 0.646082, acc.: 58.59%] [G loss: 0.962936]\n",
      "epoch:14 step:13843 [D loss: 0.657358, acc.: 59.38%] [G loss: 1.002770]\n",
      "epoch:14 step:13844 [D loss: 0.655237, acc.: 57.81%] [G loss: 0.928002]\n",
      "epoch:14 step:13845 [D loss: 0.713304, acc.: 54.69%] [G loss: 0.875705]\n",
      "epoch:14 step:13846 [D loss: 0.705585, acc.: 53.12%] [G loss: 0.788132]\n",
      "epoch:14 step:13847 [D loss: 0.676831, acc.: 53.91%] [G loss: 0.845880]\n",
      "epoch:14 step:13848 [D loss: 0.634222, acc.: 61.72%] [G loss: 0.886765]\n",
      "epoch:14 step:13849 [D loss: 0.643615, acc.: 63.28%] [G loss: 0.958591]\n",
      "epoch:14 step:13850 [D loss: 0.620050, acc.: 67.97%] [G loss: 0.904151]\n",
      "epoch:14 step:13851 [D loss: 0.588430, acc.: 71.09%] [G loss: 0.915456]\n",
      "epoch:14 step:13852 [D loss: 0.687544, acc.: 55.47%] [G loss: 0.903620]\n",
      "epoch:14 step:13853 [D loss: 0.676739, acc.: 57.81%] [G loss: 0.934413]\n",
      "epoch:14 step:13854 [D loss: 0.616259, acc.: 67.97%] [G loss: 0.949349]\n",
      "epoch:14 step:13855 [D loss: 0.633158, acc.: 62.50%] [G loss: 0.913384]\n",
      "epoch:14 step:13856 [D loss: 0.657872, acc.: 59.38%] [G loss: 0.928980]\n",
      "epoch:14 step:13857 [D loss: 0.711239, acc.: 54.69%] [G loss: 0.907583]\n",
      "epoch:14 step:13858 [D loss: 0.672118, acc.: 58.59%] [G loss: 0.836497]\n",
      "epoch:14 step:13859 [D loss: 0.626233, acc.: 66.41%] [G loss: 0.882030]\n",
      "epoch:14 step:13860 [D loss: 0.636756, acc.: 60.94%] [G loss: 0.906125]\n",
      "epoch:14 step:13861 [D loss: 0.669017, acc.: 64.06%] [G loss: 0.888378]\n",
      "epoch:14 step:13862 [D loss: 0.637755, acc.: 62.50%] [G loss: 0.906199]\n",
      "epoch:14 step:13863 [D loss: 0.692469, acc.: 50.78%] [G loss: 0.884239]\n",
      "epoch:14 step:13864 [D loss: 0.614332, acc.: 66.41%] [G loss: 0.874432]\n",
      "epoch:14 step:13865 [D loss: 0.621324, acc.: 66.41%] [G loss: 0.917386]\n",
      "epoch:14 step:13866 [D loss: 0.706033, acc.: 55.47%] [G loss: 0.911426]\n",
      "epoch:14 step:13867 [D loss: 0.639540, acc.: 59.38%] [G loss: 0.870898]\n",
      "epoch:14 step:13868 [D loss: 0.636179, acc.: 63.28%] [G loss: 0.891661]\n",
      "epoch:14 step:13869 [D loss: 0.648811, acc.: 62.50%] [G loss: 0.867857]\n",
      "epoch:14 step:13870 [D loss: 0.729674, acc.: 53.91%] [G loss: 0.846598]\n",
      "epoch:14 step:13871 [D loss: 0.635814, acc.: 66.41%] [G loss: 0.915930]\n",
      "epoch:14 step:13872 [D loss: 0.612620, acc.: 61.72%] [G loss: 0.910911]\n",
      "epoch:14 step:13873 [D loss: 0.627959, acc.: 65.62%] [G loss: 1.055953]\n",
      "epoch:14 step:13874 [D loss: 0.689106, acc.: 59.38%] [G loss: 0.916269]\n",
      "epoch:14 step:13875 [D loss: 0.718843, acc.: 53.91%] [G loss: 0.971392]\n",
      "epoch:14 step:13876 [D loss: 0.712751, acc.: 54.69%] [G loss: 0.876054]\n",
      "epoch:14 step:13877 [D loss: 0.762667, acc.: 46.09%] [G loss: 0.903207]\n",
      "epoch:14 step:13878 [D loss: 0.670226, acc.: 58.59%] [G loss: 0.918339]\n",
      "epoch:14 step:13879 [D loss: 0.611415, acc.: 68.75%] [G loss: 0.936447]\n",
      "epoch:14 step:13880 [D loss: 0.656228, acc.: 61.72%] [G loss: 0.862423]\n",
      "epoch:14 step:13881 [D loss: 0.655703, acc.: 63.28%] [G loss: 0.920174]\n",
      "epoch:14 step:13882 [D loss: 0.670492, acc.: 58.59%] [G loss: 0.886583]\n",
      "epoch:14 step:13883 [D loss: 0.720207, acc.: 50.00%] [G loss: 0.846825]\n",
      "epoch:14 step:13884 [D loss: 0.670671, acc.: 58.59%] [G loss: 0.927658]\n",
      "epoch:14 step:13885 [D loss: 0.638388, acc.: 61.72%] [G loss: 0.870401]\n",
      "epoch:14 step:13886 [D loss: 0.696544, acc.: 64.06%] [G loss: 0.930244]\n",
      "epoch:14 step:13887 [D loss: 0.661390, acc.: 63.28%] [G loss: 0.921279]\n",
      "epoch:14 step:13888 [D loss: 0.650801, acc.: 57.03%] [G loss: 0.934992]\n",
      "epoch:14 step:13889 [D loss: 0.665630, acc.: 62.50%] [G loss: 0.916508]\n",
      "epoch:14 step:13890 [D loss: 0.698530, acc.: 52.34%] [G loss: 0.901774]\n",
      "epoch:14 step:13891 [D loss: 0.615405, acc.: 66.41%] [G loss: 0.942840]\n",
      "epoch:14 step:13892 [D loss: 0.671465, acc.: 63.28%] [G loss: 0.919976]\n",
      "epoch:14 step:13893 [D loss: 0.618318, acc.: 63.28%] [G loss: 0.915576]\n",
      "epoch:14 step:13894 [D loss: 0.702375, acc.: 54.69%] [G loss: 1.000656]\n",
      "epoch:14 step:13895 [D loss: 0.643186, acc.: 61.72%] [G loss: 0.955882]\n",
      "epoch:14 step:13896 [D loss: 0.642748, acc.: 63.28%] [G loss: 0.983696]\n",
      "epoch:14 step:13897 [D loss: 0.621135, acc.: 65.62%] [G loss: 0.884437]\n",
      "epoch:14 step:13898 [D loss: 0.677295, acc.: 55.47%] [G loss: 0.835108]\n",
      "epoch:14 step:13899 [D loss: 0.591077, acc.: 70.31%] [G loss: 0.887540]\n",
      "epoch:14 step:13900 [D loss: 0.560192, acc.: 72.66%] [G loss: 0.930360]\n",
      "epoch:14 step:13901 [D loss: 0.663398, acc.: 58.59%] [G loss: 0.890081]\n",
      "epoch:14 step:13902 [D loss: 0.714735, acc.: 57.81%] [G loss: 0.831151]\n",
      "epoch:14 step:13903 [D loss: 0.691942, acc.: 63.28%] [G loss: 0.908800]\n",
      "epoch:14 step:13904 [D loss: 0.589626, acc.: 71.09%] [G loss: 0.944628]\n",
      "epoch:14 step:13905 [D loss: 0.698933, acc.: 53.91%] [G loss: 0.916242]\n",
      "epoch:14 step:13906 [D loss: 0.684636, acc.: 53.12%] [G loss: 0.930342]\n",
      "epoch:14 step:13907 [D loss: 0.634941, acc.: 60.16%] [G loss: 0.895645]\n",
      "epoch:14 step:13908 [D loss: 0.644268, acc.: 60.94%] [G loss: 0.912062]\n",
      "epoch:14 step:13909 [D loss: 0.656431, acc.: 58.59%] [G loss: 0.885876]\n",
      "epoch:14 step:13910 [D loss: 0.626637, acc.: 67.97%] [G loss: 0.864102]\n",
      "epoch:14 step:13911 [D loss: 0.660191, acc.: 62.50%] [G loss: 0.915213]\n",
      "epoch:14 step:13912 [D loss: 0.732841, acc.: 51.56%] [G loss: 0.878310]\n",
      "epoch:14 step:13913 [D loss: 0.672603, acc.: 59.38%] [G loss: 0.949899]\n",
      "epoch:14 step:13914 [D loss: 0.621827, acc.: 71.09%] [G loss: 1.010341]\n",
      "epoch:14 step:13915 [D loss: 0.668758, acc.: 60.94%] [G loss: 0.937915]\n",
      "epoch:14 step:13916 [D loss: 0.727386, acc.: 46.09%] [G loss: 0.893667]\n",
      "epoch:14 step:13917 [D loss: 0.627229, acc.: 67.19%] [G loss: 0.883062]\n",
      "epoch:14 step:13918 [D loss: 0.685204, acc.: 56.25%] [G loss: 0.962258]\n",
      "epoch:14 step:13919 [D loss: 0.591833, acc.: 71.88%] [G loss: 0.890377]\n",
      "epoch:14 step:13920 [D loss: 0.639159, acc.: 64.06%] [G loss: 0.993891]\n",
      "epoch:14 step:13921 [D loss: 0.609204, acc.: 67.19%] [G loss: 0.913956]\n",
      "epoch:14 step:13922 [D loss: 0.677248, acc.: 58.59%] [G loss: 0.922261]\n",
      "epoch:14 step:13923 [D loss: 0.656676, acc.: 58.59%] [G loss: 0.867587]\n",
      "epoch:14 step:13924 [D loss: 0.692862, acc.: 64.06%] [G loss: 0.795829]\n",
      "epoch:14 step:13925 [D loss: 0.647501, acc.: 61.72%] [G loss: 0.855466]\n",
      "epoch:14 step:13926 [D loss: 0.698129, acc.: 53.12%] [G loss: 0.882882]\n",
      "epoch:14 step:13927 [D loss: 0.669287, acc.: 56.25%] [G loss: 0.887661]\n",
      "epoch:14 step:13928 [D loss: 0.670771, acc.: 61.72%] [G loss: 0.862487]\n",
      "epoch:14 step:13929 [D loss: 0.657858, acc.: 60.16%] [G loss: 0.906396]\n",
      "epoch:14 step:13930 [D loss: 0.720196, acc.: 49.22%] [G loss: 0.898056]\n",
      "epoch:14 step:13931 [D loss: 0.690083, acc.: 57.81%] [G loss: 0.886341]\n",
      "epoch:14 step:13932 [D loss: 0.656157, acc.: 61.72%] [G loss: 0.879529]\n",
      "epoch:14 step:13933 [D loss: 0.625490, acc.: 65.62%] [G loss: 0.923432]\n",
      "epoch:14 step:13934 [D loss: 0.670200, acc.: 58.59%] [G loss: 0.890957]\n",
      "epoch:14 step:13935 [D loss: 0.648014, acc.: 64.06%] [G loss: 0.889518]\n",
      "epoch:14 step:13936 [D loss: 0.689358, acc.: 50.00%] [G loss: 0.938144]\n",
      "epoch:14 step:13937 [D loss: 0.653135, acc.: 60.94%] [G loss: 0.843898]\n",
      "epoch:14 step:13938 [D loss: 0.740397, acc.: 46.88%] [G loss: 0.880191]\n",
      "epoch:14 step:13939 [D loss: 0.698676, acc.: 60.16%] [G loss: 0.779825]\n",
      "epoch:14 step:13940 [D loss: 0.663331, acc.: 63.28%] [G loss: 0.884591]\n",
      "epoch:14 step:13941 [D loss: 0.660561, acc.: 56.25%] [G loss: 0.854758]\n",
      "epoch:14 step:13942 [D loss: 0.682945, acc.: 57.03%] [G loss: 0.864767]\n",
      "epoch:14 step:13943 [D loss: 0.658504, acc.: 63.28%] [G loss: 0.866132]\n",
      "epoch:14 step:13944 [D loss: 0.619395, acc.: 65.62%] [G loss: 0.925658]\n",
      "epoch:14 step:13945 [D loss: 0.663651, acc.: 56.25%] [G loss: 0.922268]\n",
      "epoch:14 step:13946 [D loss: 0.717413, acc.: 51.56%] [G loss: 0.881612]\n",
      "epoch:14 step:13947 [D loss: 0.669221, acc.: 58.59%] [G loss: 0.917977]\n",
      "epoch:14 step:13948 [D loss: 0.648098, acc.: 65.62%] [G loss: 0.881349]\n",
      "epoch:14 step:13949 [D loss: 0.655706, acc.: 59.38%] [G loss: 0.900047]\n",
      "epoch:14 step:13950 [D loss: 0.622847, acc.: 64.06%] [G loss: 0.871788]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13951 [D loss: 0.649853, acc.: 60.94%] [G loss: 0.900818]\n",
      "epoch:14 step:13952 [D loss: 0.640188, acc.: 64.06%] [G loss: 0.912029]\n",
      "epoch:14 step:13953 [D loss: 0.656339, acc.: 62.50%] [G loss: 0.864298]\n",
      "epoch:14 step:13954 [D loss: 0.633428, acc.: 66.41%] [G loss: 0.916169]\n",
      "epoch:14 step:13955 [D loss: 0.651485, acc.: 59.38%] [G loss: 0.950397]\n",
      "epoch:14 step:13956 [D loss: 0.604867, acc.: 69.53%] [G loss: 0.900715]\n",
      "epoch:14 step:13957 [D loss: 0.653915, acc.: 57.81%] [G loss: 0.878316]\n",
      "epoch:14 step:13958 [D loss: 0.673288, acc.: 63.28%] [G loss: 0.893260]\n",
      "epoch:14 step:13959 [D loss: 0.660706, acc.: 64.84%] [G loss: 0.897555]\n",
      "epoch:14 step:13960 [D loss: 0.607453, acc.: 67.19%] [G loss: 0.915221]\n",
      "epoch:14 step:13961 [D loss: 0.650602, acc.: 65.62%] [G loss: 0.896904]\n",
      "epoch:14 step:13962 [D loss: 0.661966, acc.: 60.16%] [G loss: 0.887712]\n",
      "epoch:14 step:13963 [D loss: 0.664048, acc.: 61.72%] [G loss: 0.969207]\n",
      "epoch:14 step:13964 [D loss: 0.684432, acc.: 52.34%] [G loss: 0.945586]\n",
      "epoch:14 step:13965 [D loss: 0.702808, acc.: 50.00%] [G loss: 0.886846]\n",
      "epoch:14 step:13966 [D loss: 0.714956, acc.: 51.56%] [G loss: 0.891020]\n",
      "epoch:14 step:13967 [D loss: 0.667548, acc.: 63.28%] [G loss: 0.833142]\n",
      "epoch:14 step:13968 [D loss: 0.675848, acc.: 57.81%] [G loss: 0.850944]\n",
      "epoch:14 step:13969 [D loss: 0.650956, acc.: 60.16%] [G loss: 0.902262]\n",
      "epoch:14 step:13970 [D loss: 0.627233, acc.: 61.72%] [G loss: 0.945544]\n",
      "epoch:14 step:13971 [D loss: 0.632138, acc.: 64.84%] [G loss: 0.920944]\n",
      "epoch:14 step:13972 [D loss: 0.612489, acc.: 66.41%] [G loss: 0.964687]\n",
      "epoch:14 step:13973 [D loss: 0.699831, acc.: 55.47%] [G loss: 0.925361]\n",
      "epoch:14 step:13974 [D loss: 0.666256, acc.: 60.16%] [G loss: 0.915026]\n",
      "epoch:14 step:13975 [D loss: 0.613538, acc.: 61.72%] [G loss: 0.906649]\n",
      "epoch:14 step:13976 [D loss: 0.755834, acc.: 48.44%] [G loss: 0.888461]\n",
      "epoch:14 step:13977 [D loss: 0.703220, acc.: 54.69%] [G loss: 0.872601]\n",
      "epoch:14 step:13978 [D loss: 0.684183, acc.: 57.03%] [G loss: 0.901229]\n",
      "epoch:14 step:13979 [D loss: 0.711478, acc.: 47.66%] [G loss: 0.914654]\n",
      "epoch:14 step:13980 [D loss: 0.667055, acc.: 58.59%] [G loss: 0.882795]\n",
      "epoch:14 step:13981 [D loss: 0.668596, acc.: 59.38%] [G loss: 0.853616]\n",
      "epoch:14 step:13982 [D loss: 0.658817, acc.: 60.16%] [G loss: 0.890811]\n",
      "epoch:14 step:13983 [D loss: 0.713152, acc.: 51.56%] [G loss: 0.914568]\n",
      "epoch:14 step:13984 [D loss: 0.659723, acc.: 60.94%] [G loss: 0.898495]\n",
      "epoch:14 step:13985 [D loss: 0.700360, acc.: 50.00%] [G loss: 0.884206]\n",
      "epoch:14 step:13986 [D loss: 0.641469, acc.: 61.72%] [G loss: 0.948934]\n",
      "epoch:14 step:13987 [D loss: 0.643993, acc.: 63.28%] [G loss: 0.855668]\n",
      "epoch:14 step:13988 [D loss: 0.665510, acc.: 60.94%] [G loss: 0.846460]\n",
      "epoch:14 step:13989 [D loss: 0.622313, acc.: 66.41%] [G loss: 0.905640]\n",
      "epoch:14 step:13990 [D loss: 0.623180, acc.: 70.31%] [G loss: 0.927957]\n",
      "epoch:14 step:13991 [D loss: 0.634965, acc.: 67.19%] [G loss: 1.013764]\n",
      "epoch:14 step:13992 [D loss: 0.653239, acc.: 59.38%] [G loss: 0.915451]\n",
      "epoch:14 step:13993 [D loss: 0.608829, acc.: 68.75%] [G loss: 0.928530]\n",
      "epoch:14 step:13994 [D loss: 0.664384, acc.: 57.81%] [G loss: 0.913656]\n",
      "epoch:14 step:13995 [D loss: 0.699338, acc.: 52.34%] [G loss: 0.883521]\n",
      "epoch:14 step:13996 [D loss: 0.687539, acc.: 53.91%] [G loss: 0.869451]\n",
      "epoch:14 step:13997 [D loss: 0.656840, acc.: 59.38%] [G loss: 0.888911]\n",
      "epoch:14 step:13998 [D loss: 0.654322, acc.: 59.38%] [G loss: 0.897207]\n",
      "epoch:14 step:13999 [D loss: 0.658205, acc.: 60.94%] [G loss: 0.856772]\n",
      "epoch:14 step:14000 [D loss: 0.658543, acc.: 62.50%] [G loss: 0.921637]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.275430\n",
      "FID: 4.543975\n",
      "0 = 11.610980710530214\n",
      "1 = 0.047485194659525484\n",
      "2 = 0.9059000015258789\n",
      "3 = 0.8501999974250793\n",
      "4 = 0.9616000056266785\n",
      "5 = 0.9567859768867493\n",
      "6 = 0.8501999974250793\n",
      "7 = 5.429745667368173\n",
      "8 = 0.0463571554641992\n",
      "9 = 0.7007499933242798\n",
      "10 = 0.6808000206947327\n",
      "11 = 0.7207000255584717\n",
      "12 = 0.7090927958488464\n",
      "13 = 0.6808000206947327\n",
      "14 = 8.27548885345459\n",
      "15 = 9.615833282470703\n",
      "16 = 0.07974350452423096\n",
      "17 = 8.275429725646973\n",
      "18 = 4.543974876403809\n",
      "epoch:14 step:14001 [D loss: 0.697848, acc.: 57.03%] [G loss: 0.893132]\n",
      "epoch:14 step:14002 [D loss: 0.619675, acc.: 67.19%] [G loss: 0.990698]\n",
      "epoch:14 step:14003 [D loss: 0.598763, acc.: 69.53%] [G loss: 1.014880]\n",
      "epoch:14 step:14004 [D loss: 0.631268, acc.: 64.06%] [G loss: 0.951491]\n",
      "epoch:14 step:14005 [D loss: 0.719716, acc.: 55.47%] [G loss: 0.961026]\n",
      "epoch:14 step:14006 [D loss: 0.676927, acc.: 55.47%] [G loss: 0.967651]\n",
      "epoch:14 step:14007 [D loss: 0.598727, acc.: 75.00%] [G loss: 0.957048]\n",
      "epoch:14 step:14008 [D loss: 0.574614, acc.: 72.66%] [G loss: 0.968422]\n",
      "epoch:14 step:14009 [D loss: 0.729240, acc.: 47.66%] [G loss: 0.927824]\n",
      "epoch:14 step:14010 [D loss: 0.751460, acc.: 46.88%] [G loss: 0.855704]\n",
      "epoch:14 step:14011 [D loss: 0.700762, acc.: 57.03%] [G loss: 0.885635]\n",
      "epoch:14 step:14012 [D loss: 0.651931, acc.: 62.50%] [G loss: 0.947823]\n",
      "epoch:14 step:14013 [D loss: 0.626723, acc.: 64.84%] [G loss: 0.965074]\n",
      "epoch:14 step:14014 [D loss: 0.626341, acc.: 65.62%] [G loss: 0.941408]\n",
      "epoch:14 step:14015 [D loss: 0.659589, acc.: 58.59%] [G loss: 0.958377]\n",
      "epoch:14 step:14016 [D loss: 0.594718, acc.: 69.53%] [G loss: 0.979805]\n",
      "epoch:14 step:14017 [D loss: 0.618302, acc.: 72.66%] [G loss: 0.959835]\n",
      "epoch:14 step:14018 [D loss: 0.625228, acc.: 64.84%] [G loss: 0.967223]\n",
      "epoch:14 step:14019 [D loss: 0.651544, acc.: 61.72%] [G loss: 0.940175]\n",
      "epoch:14 step:14020 [D loss: 0.654139, acc.: 60.94%] [G loss: 0.931707]\n",
      "epoch:14 step:14021 [D loss: 0.650069, acc.: 64.84%] [G loss: 0.854378]\n",
      "epoch:14 step:14022 [D loss: 0.661655, acc.: 61.72%] [G loss: 0.885623]\n",
      "epoch:14 step:14023 [D loss: 0.665156, acc.: 57.03%] [G loss: 0.899978]\n",
      "epoch:14 step:14024 [D loss: 0.633337, acc.: 60.16%] [G loss: 0.968258]\n",
      "epoch:14 step:14025 [D loss: 0.679013, acc.: 53.12%] [G loss: 0.944247]\n",
      "epoch:14 step:14026 [D loss: 0.610852, acc.: 67.19%] [G loss: 0.928453]\n",
      "epoch:14 step:14027 [D loss: 0.624169, acc.: 69.53%] [G loss: 0.960239]\n",
      "epoch:14 step:14028 [D loss: 0.651591, acc.: 64.06%] [G loss: 0.898677]\n",
      "epoch:14 step:14029 [D loss: 0.657003, acc.: 56.25%] [G loss: 0.892449]\n",
      "epoch:14 step:14030 [D loss: 0.615359, acc.: 64.06%] [G loss: 0.940553]\n",
      "epoch:14 step:14031 [D loss: 0.646075, acc.: 64.84%] [G loss: 0.926554]\n",
      "epoch:14 step:14032 [D loss: 0.583254, acc.: 67.19%] [G loss: 0.927467]\n",
      "epoch:14 step:14033 [D loss: 0.738198, acc.: 53.12%] [G loss: 0.894585]\n",
      "epoch:14 step:14034 [D loss: 0.696208, acc.: 60.16%] [G loss: 0.860462]\n",
      "epoch:14 step:14035 [D loss: 0.654817, acc.: 59.38%] [G loss: 0.914853]\n",
      "epoch:14 step:14036 [D loss: 0.565635, acc.: 74.22%] [G loss: 0.952741]\n",
      "epoch:14 step:14037 [D loss: 0.588192, acc.: 69.53%] [G loss: 0.964977]\n",
      "epoch:14 step:14038 [D loss: 0.830998, acc.: 36.72%] [G loss: 0.921901]\n",
      "epoch:14 step:14039 [D loss: 0.671436, acc.: 57.81%] [G loss: 0.932006]\n",
      "epoch:14 step:14040 [D loss: 0.653186, acc.: 64.06%] [G loss: 0.842490]\n",
      "epoch:14 step:14041 [D loss: 0.608753, acc.: 71.88%] [G loss: 0.883646]\n",
      "epoch:14 step:14042 [D loss: 0.560693, acc.: 78.12%] [G loss: 0.907206]\n",
      "epoch:14 step:14043 [D loss: 0.554318, acc.: 78.91%] [G loss: 0.995621]\n",
      "epoch:14 step:14044 [D loss: 0.562359, acc.: 73.44%] [G loss: 0.985722]\n",
      "epoch:14 step:14045 [D loss: 0.643862, acc.: 59.38%] [G loss: 0.998303]\n",
      "epoch:14 step:14046 [D loss: 0.858572, acc.: 53.12%] [G loss: 1.073427]\n",
      "epoch:14 step:14047 [D loss: 0.588999, acc.: 70.31%] [G loss: 1.108091]\n",
      "epoch:14 step:14048 [D loss: 0.612488, acc.: 64.06%] [G loss: 1.174625]\n",
      "epoch:14 step:14049 [D loss: 0.656045, acc.: 64.06%] [G loss: 0.986759]\n",
      "epoch:14 step:14050 [D loss: 0.730105, acc.: 52.34%] [G loss: 0.882378]\n",
      "epoch:14 step:14051 [D loss: 0.690004, acc.: 60.16%] [G loss: 0.940703]\n",
      "epoch:14 step:14052 [D loss: 0.732081, acc.: 51.56%] [G loss: 1.016384]\n",
      "epoch:14 step:14053 [D loss: 0.619647, acc.: 64.06%] [G loss: 0.966106]\n",
      "epoch:14 step:14054 [D loss: 0.568414, acc.: 73.44%] [G loss: 1.041334]\n",
      "epoch:14 step:14055 [D loss: 0.638847, acc.: 60.94%] [G loss: 1.149708]\n",
      "epoch:15 step:14056 [D loss: 0.648428, acc.: 62.50%] [G loss: 1.060559]\n",
      "epoch:15 step:14057 [D loss: 0.786798, acc.: 54.69%] [G loss: 0.935333]\n",
      "epoch:15 step:14058 [D loss: 0.697842, acc.: 57.03%] [G loss: 0.911782]\n",
      "epoch:15 step:14059 [D loss: 0.704222, acc.: 52.34%] [G loss: 0.922526]\n",
      "epoch:15 step:14060 [D loss: 0.733854, acc.: 50.00%] [G loss: 0.894037]\n",
      "epoch:15 step:14061 [D loss: 0.654083, acc.: 59.38%] [G loss: 0.851280]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14062 [D loss: 0.642182, acc.: 60.94%] [G loss: 0.910629]\n",
      "epoch:15 step:14063 [D loss: 0.637417, acc.: 63.28%] [G loss: 0.902555]\n",
      "epoch:15 step:14064 [D loss: 0.619839, acc.: 68.75%] [G loss: 0.855064]\n",
      "epoch:15 step:14065 [D loss: 0.607924, acc.: 66.41%] [G loss: 0.908672]\n",
      "epoch:15 step:14066 [D loss: 0.640915, acc.: 63.28%] [G loss: 0.933258]\n",
      "epoch:15 step:14067 [D loss: 0.672064, acc.: 54.69%] [G loss: 0.945243]\n",
      "epoch:15 step:14068 [D loss: 0.648598, acc.: 59.38%] [G loss: 0.901482]\n",
      "epoch:15 step:14069 [D loss: 0.619435, acc.: 63.28%] [G loss: 0.890890]\n",
      "epoch:15 step:14070 [D loss: 0.636864, acc.: 60.94%] [G loss: 0.915562]\n",
      "epoch:15 step:14071 [D loss: 0.613938, acc.: 64.84%] [G loss: 0.934607]\n",
      "epoch:15 step:14072 [D loss: 0.666629, acc.: 58.59%] [G loss: 0.996590]\n",
      "epoch:15 step:14073 [D loss: 0.642993, acc.: 64.06%] [G loss: 0.972016]\n",
      "epoch:15 step:14074 [D loss: 0.712042, acc.: 53.91%] [G loss: 0.932537]\n",
      "epoch:15 step:14075 [D loss: 0.725614, acc.: 54.69%] [G loss: 0.988621]\n",
      "epoch:15 step:14076 [D loss: 0.644629, acc.: 65.62%] [G loss: 1.023273]\n",
      "epoch:15 step:14077 [D loss: 0.567819, acc.: 69.53%] [G loss: 1.075820]\n",
      "epoch:15 step:14078 [D loss: 0.754375, acc.: 49.22%] [G loss: 0.910910]\n",
      "epoch:15 step:14079 [D loss: 0.688601, acc.: 59.38%] [G loss: 0.913078]\n",
      "epoch:15 step:14080 [D loss: 0.649505, acc.: 67.19%] [G loss: 0.922916]\n",
      "epoch:15 step:14081 [D loss: 0.662554, acc.: 61.72%] [G loss: 0.957477]\n",
      "epoch:15 step:14082 [D loss: 0.650469, acc.: 64.06%] [G loss: 0.877800]\n",
      "epoch:15 step:14083 [D loss: 0.638421, acc.: 59.38%] [G loss: 0.917304]\n",
      "epoch:15 step:14084 [D loss: 0.650566, acc.: 62.50%] [G loss: 0.846617]\n",
      "epoch:15 step:14085 [D loss: 0.652374, acc.: 58.59%] [G loss: 0.904480]\n",
      "epoch:15 step:14086 [D loss: 0.667649, acc.: 61.72%] [G loss: 0.941014]\n",
      "epoch:15 step:14087 [D loss: 0.681315, acc.: 60.16%] [G loss: 0.958132]\n",
      "epoch:15 step:14088 [D loss: 0.661549, acc.: 60.94%] [G loss: 0.922969]\n",
      "epoch:15 step:14089 [D loss: 0.673331, acc.: 57.81%] [G loss: 0.903634]\n",
      "epoch:15 step:14090 [D loss: 0.678416, acc.: 56.25%] [G loss: 0.932082]\n",
      "epoch:15 step:14091 [D loss: 0.681885, acc.: 59.38%] [G loss: 0.904326]\n",
      "epoch:15 step:14092 [D loss: 0.647972, acc.: 62.50%] [G loss: 0.895867]\n",
      "epoch:15 step:14093 [D loss: 0.696640, acc.: 55.47%] [G loss: 0.854768]\n",
      "epoch:15 step:14094 [D loss: 0.683827, acc.: 59.38%] [G loss: 0.920156]\n",
      "epoch:15 step:14095 [D loss: 0.613136, acc.: 60.16%] [G loss: 0.960680]\n",
      "epoch:15 step:14096 [D loss: 0.687457, acc.: 60.94%] [G loss: 0.895799]\n",
      "epoch:15 step:14097 [D loss: 0.652867, acc.: 63.28%] [G loss: 0.899420]\n",
      "epoch:15 step:14098 [D loss: 0.674610, acc.: 59.38%] [G loss: 0.884418]\n",
      "epoch:15 step:14099 [D loss: 0.684872, acc.: 58.59%] [G loss: 0.855674]\n",
      "epoch:15 step:14100 [D loss: 0.691939, acc.: 60.16%] [G loss: 0.894113]\n",
      "epoch:15 step:14101 [D loss: 0.638127, acc.: 60.16%] [G loss: 0.919197]\n",
      "epoch:15 step:14102 [D loss: 0.654193, acc.: 60.16%] [G loss: 0.890398]\n",
      "epoch:15 step:14103 [D loss: 0.627590, acc.: 61.72%] [G loss: 0.936155]\n",
      "epoch:15 step:14104 [D loss: 0.625565, acc.: 64.84%] [G loss: 0.884276]\n",
      "epoch:15 step:14105 [D loss: 0.646173, acc.: 67.19%] [G loss: 0.937272]\n",
      "epoch:15 step:14106 [D loss: 0.749917, acc.: 47.66%] [G loss: 0.873609]\n",
      "epoch:15 step:14107 [D loss: 0.649888, acc.: 59.38%] [G loss: 0.868685]\n",
      "epoch:15 step:14108 [D loss: 0.619656, acc.: 70.31%] [G loss: 0.853264]\n",
      "epoch:15 step:14109 [D loss: 0.636706, acc.: 67.97%] [G loss: 0.901441]\n",
      "epoch:15 step:14110 [D loss: 0.649776, acc.: 57.81%] [G loss: 0.990852]\n",
      "epoch:15 step:14111 [D loss: 0.637469, acc.: 64.84%] [G loss: 0.945332]\n",
      "epoch:15 step:14112 [D loss: 0.670831, acc.: 57.81%] [G loss: 0.934198]\n",
      "epoch:15 step:14113 [D loss: 0.711763, acc.: 54.69%] [G loss: 0.873762]\n",
      "epoch:15 step:14114 [D loss: 0.665354, acc.: 60.16%] [G loss: 0.841854]\n",
      "epoch:15 step:14115 [D loss: 0.650018, acc.: 65.62%] [G loss: 0.889350]\n",
      "epoch:15 step:14116 [D loss: 0.689046, acc.: 59.38%] [G loss: 0.837239]\n",
      "epoch:15 step:14117 [D loss: 0.699625, acc.: 58.59%] [G loss: 0.849796]\n",
      "epoch:15 step:14118 [D loss: 0.663585, acc.: 55.47%] [G loss: 0.899398]\n",
      "epoch:15 step:14119 [D loss: 0.659225, acc.: 57.81%] [G loss: 0.931726]\n",
      "epoch:15 step:14120 [D loss: 0.680225, acc.: 60.16%] [G loss: 0.848889]\n",
      "epoch:15 step:14121 [D loss: 0.662661, acc.: 59.38%] [G loss: 0.860334]\n",
      "epoch:15 step:14122 [D loss: 0.658125, acc.: 53.91%] [G loss: 0.911350]\n",
      "epoch:15 step:14123 [D loss: 0.660503, acc.: 62.50%] [G loss: 0.853211]\n",
      "epoch:15 step:14124 [D loss: 0.643195, acc.: 57.03%] [G loss: 0.929646]\n",
      "epoch:15 step:14125 [D loss: 0.655288, acc.: 63.28%] [G loss: 0.894821]\n",
      "epoch:15 step:14126 [D loss: 0.685591, acc.: 57.03%] [G loss: 0.937367]\n",
      "epoch:15 step:14127 [D loss: 0.679141, acc.: 60.16%] [G loss: 0.942888]\n",
      "epoch:15 step:14128 [D loss: 0.641100, acc.: 65.62%] [G loss: 0.950853]\n",
      "epoch:15 step:14129 [D loss: 0.592715, acc.: 67.97%] [G loss: 0.959325]\n",
      "epoch:15 step:14130 [D loss: 0.712841, acc.: 55.47%] [G loss: 0.926667]\n",
      "epoch:15 step:14131 [D loss: 0.583926, acc.: 74.22%] [G loss: 0.952088]\n",
      "epoch:15 step:14132 [D loss: 0.605513, acc.: 67.19%] [G loss: 0.953358]\n",
      "epoch:15 step:14133 [D loss: 0.726607, acc.: 50.00%] [G loss: 0.929690]\n",
      "epoch:15 step:14134 [D loss: 0.662655, acc.: 59.38%] [G loss: 0.912601]\n",
      "epoch:15 step:14135 [D loss: 0.663604, acc.: 62.50%] [G loss: 0.910241]\n",
      "epoch:15 step:14136 [D loss: 0.717942, acc.: 52.34%] [G loss: 0.894463]\n",
      "epoch:15 step:14137 [D loss: 0.608448, acc.: 68.75%] [G loss: 0.884224]\n",
      "epoch:15 step:14138 [D loss: 0.620736, acc.: 64.84%] [G loss: 0.905571]\n",
      "epoch:15 step:14139 [D loss: 0.623316, acc.: 62.50%] [G loss: 0.928362]\n",
      "epoch:15 step:14140 [D loss: 0.636124, acc.: 69.53%] [G loss: 0.902052]\n",
      "epoch:15 step:14141 [D loss: 0.685271, acc.: 53.91%] [G loss: 0.926816]\n",
      "epoch:15 step:14142 [D loss: 0.643482, acc.: 60.94%] [G loss: 0.914390]\n",
      "epoch:15 step:14143 [D loss: 0.662597, acc.: 55.47%] [G loss: 0.853869]\n",
      "epoch:15 step:14144 [D loss: 0.641217, acc.: 63.28%] [G loss: 0.928193]\n",
      "epoch:15 step:14145 [D loss: 0.638366, acc.: 63.28%] [G loss: 0.887295]\n",
      "epoch:15 step:14146 [D loss: 0.644692, acc.: 66.41%] [G loss: 0.901647]\n",
      "epoch:15 step:14147 [D loss: 0.624122, acc.: 63.28%] [G loss: 0.917868]\n",
      "epoch:15 step:14148 [D loss: 0.594219, acc.: 66.41%] [G loss: 0.908769]\n",
      "epoch:15 step:14149 [D loss: 0.665209, acc.: 60.94%] [G loss: 0.986689]\n",
      "epoch:15 step:14150 [D loss: 0.650390, acc.: 61.72%] [G loss: 0.897619]\n",
      "epoch:15 step:14151 [D loss: 0.608948, acc.: 67.19%] [G loss: 0.972673]\n",
      "epoch:15 step:14152 [D loss: 0.602197, acc.: 70.31%] [G loss: 0.968196]\n",
      "epoch:15 step:14153 [D loss: 0.626357, acc.: 65.62%] [G loss: 1.005171]\n",
      "epoch:15 step:14154 [D loss: 0.632918, acc.: 65.62%] [G loss: 0.999522]\n",
      "epoch:15 step:14155 [D loss: 0.612260, acc.: 66.41%] [G loss: 0.924100]\n",
      "epoch:15 step:14156 [D loss: 0.647646, acc.: 56.25%] [G loss: 0.931427]\n",
      "epoch:15 step:14157 [D loss: 0.710639, acc.: 48.44%] [G loss: 0.940015]\n",
      "epoch:15 step:14158 [D loss: 0.760897, acc.: 40.62%] [G loss: 0.839806]\n",
      "epoch:15 step:14159 [D loss: 0.650942, acc.: 65.62%] [G loss: 0.864011]\n",
      "epoch:15 step:14160 [D loss: 0.654155, acc.: 61.72%] [G loss: 0.840548]\n",
      "epoch:15 step:14161 [D loss: 0.605504, acc.: 69.53%] [G loss: 0.874586]\n",
      "epoch:15 step:14162 [D loss: 0.635190, acc.: 62.50%] [G loss: 0.918108]\n",
      "epoch:15 step:14163 [D loss: 0.708873, acc.: 58.59%] [G loss: 0.873587]\n",
      "epoch:15 step:14164 [D loss: 0.710585, acc.: 54.69%] [G loss: 0.857661]\n",
      "epoch:15 step:14165 [D loss: 0.674298, acc.: 63.28%] [G loss: 0.866592]\n",
      "epoch:15 step:14166 [D loss: 0.599488, acc.: 70.31%] [G loss: 0.895793]\n",
      "epoch:15 step:14167 [D loss: 0.640861, acc.: 63.28%] [G loss: 0.899884]\n",
      "epoch:15 step:14168 [D loss: 0.634344, acc.: 62.50%] [G loss: 0.917344]\n",
      "epoch:15 step:14169 [D loss: 0.634620, acc.: 67.97%] [G loss: 0.944377]\n",
      "epoch:15 step:14170 [D loss: 0.599895, acc.: 67.97%] [G loss: 1.052757]\n",
      "epoch:15 step:14171 [D loss: 0.634674, acc.: 66.41%] [G loss: 1.001854]\n",
      "epoch:15 step:14172 [D loss: 0.608069, acc.: 68.75%] [G loss: 1.000303]\n",
      "epoch:15 step:14173 [D loss: 0.657415, acc.: 64.84%] [G loss: 0.978091]\n",
      "epoch:15 step:14174 [D loss: 0.589539, acc.: 71.88%] [G loss: 0.977093]\n",
      "epoch:15 step:14175 [D loss: 0.709087, acc.: 52.34%] [G loss: 0.958622]\n",
      "epoch:15 step:14176 [D loss: 0.693218, acc.: 53.12%] [G loss: 0.928285]\n",
      "epoch:15 step:14177 [D loss: 0.625782, acc.: 68.75%] [G loss: 0.953657]\n",
      "epoch:15 step:14178 [D loss: 0.640766, acc.: 65.62%] [G loss: 0.911793]\n",
      "epoch:15 step:14179 [D loss: 0.675618, acc.: 60.16%] [G loss: 0.983308]\n",
      "epoch:15 step:14180 [D loss: 0.676775, acc.: 55.47%] [G loss: 0.925510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14181 [D loss: 0.569411, acc.: 75.00%] [G loss: 0.925709]\n",
      "epoch:15 step:14182 [D loss: 0.635669, acc.: 63.28%] [G loss: 0.884709]\n",
      "epoch:15 step:14183 [D loss: 0.686678, acc.: 57.81%] [G loss: 0.836428]\n",
      "epoch:15 step:14184 [D loss: 0.641335, acc.: 63.28%] [G loss: 0.906754]\n",
      "epoch:15 step:14185 [D loss: 0.603693, acc.: 70.31%] [G loss: 0.884595]\n",
      "epoch:15 step:14186 [D loss: 0.613696, acc.: 64.84%] [G loss: 0.914708]\n",
      "epoch:15 step:14187 [D loss: 0.697799, acc.: 60.16%] [G loss: 0.916118]\n",
      "epoch:15 step:14188 [D loss: 0.622297, acc.: 67.19%] [G loss: 0.998720]\n",
      "epoch:15 step:14189 [D loss: 0.673899, acc.: 50.00%] [G loss: 0.880043]\n",
      "epoch:15 step:14190 [D loss: 0.667284, acc.: 62.50%] [G loss: 0.937192]\n",
      "epoch:15 step:14191 [D loss: 0.682995, acc.: 59.38%] [G loss: 1.008265]\n",
      "epoch:15 step:14192 [D loss: 0.708773, acc.: 54.69%] [G loss: 0.971811]\n",
      "epoch:15 step:14193 [D loss: 0.666988, acc.: 60.16%] [G loss: 0.927821]\n",
      "epoch:15 step:14194 [D loss: 0.653977, acc.: 60.94%] [G loss: 0.865499]\n",
      "epoch:15 step:14195 [D loss: 0.688422, acc.: 52.34%] [G loss: 0.924973]\n",
      "epoch:15 step:14196 [D loss: 0.673976, acc.: 56.25%] [G loss: 0.914799]\n",
      "epoch:15 step:14197 [D loss: 0.696441, acc.: 57.03%] [G loss: 0.912863]\n",
      "epoch:15 step:14198 [D loss: 0.659410, acc.: 59.38%] [G loss: 0.900435]\n",
      "epoch:15 step:14199 [D loss: 0.702808, acc.: 57.81%] [G loss: 0.851857]\n",
      "epoch:15 step:14200 [D loss: 0.654748, acc.: 59.38%] [G loss: 0.919845]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.133669\n",
      "FID: 6.989893\n",
      "0 = 11.769233241558034\n",
      "1 = 0.05194518523387835\n",
      "2 = 0.9077500104904175\n",
      "3 = 0.8600000143051147\n",
      "4 = 0.9555000066757202\n",
      "5 = 0.9508015513420105\n",
      "6 = 0.8600000143051147\n",
      "7 = 5.745415629202157\n",
      "8 = 0.054888763648099186\n",
      "9 = 0.6972000002861023\n",
      "10 = 0.6710000038146973\n",
      "11 = 0.7233999967575073\n",
      "12 = 0.70810467004776\n",
      "13 = 0.6710000038146973\n",
      "14 = 8.133732795715332\n",
      "15 = 9.583292007446289\n",
      "16 = 0.0975264385342598\n",
      "17 = 8.133668899536133\n",
      "18 = 6.989893436431885\n",
      "epoch:15 step:14201 [D loss: 0.659640, acc.: 60.94%] [G loss: 0.891554]\n",
      "epoch:15 step:14202 [D loss: 0.676388, acc.: 53.91%] [G loss: 0.897687]\n",
      "epoch:15 step:14203 [D loss: 0.681078, acc.: 60.94%] [G loss: 0.780518]\n",
      "epoch:15 step:14204 [D loss: 0.628475, acc.: 66.41%] [G loss: 0.860292]\n",
      "epoch:15 step:14205 [D loss: 0.685515, acc.: 59.38%] [G loss: 0.819100]\n",
      "epoch:15 step:14206 [D loss: 0.638734, acc.: 64.06%] [G loss: 0.854786]\n",
      "epoch:15 step:14207 [D loss: 0.646476, acc.: 61.72%] [G loss: 0.836094]\n",
      "epoch:15 step:14208 [D loss: 0.691855, acc.: 50.78%] [G loss: 0.817388]\n",
      "epoch:15 step:14209 [D loss: 0.703622, acc.: 50.78%] [G loss: 0.886518]\n",
      "epoch:15 step:14210 [D loss: 0.644280, acc.: 63.28%] [G loss: 0.897999]\n",
      "epoch:15 step:14211 [D loss: 0.660971, acc.: 54.69%] [G loss: 0.988960]\n",
      "epoch:15 step:14212 [D loss: 0.655054, acc.: 65.62%] [G loss: 0.922702]\n",
      "epoch:15 step:14213 [D loss: 0.689827, acc.: 49.22%] [G loss: 0.891897]\n",
      "epoch:15 step:14214 [D loss: 0.628929, acc.: 63.28%] [G loss: 0.885969]\n",
      "epoch:15 step:14215 [D loss: 0.754948, acc.: 48.44%] [G loss: 0.874765]\n",
      "epoch:15 step:14216 [D loss: 0.631913, acc.: 64.84%] [G loss: 0.961086]\n",
      "epoch:15 step:14217 [D loss: 0.705896, acc.: 56.25%] [G loss: 0.975238]\n",
      "epoch:15 step:14218 [D loss: 0.703857, acc.: 51.56%] [G loss: 0.884389]\n",
      "epoch:15 step:14219 [D loss: 0.634676, acc.: 62.50%] [G loss: 0.942573]\n",
      "epoch:15 step:14220 [D loss: 0.652971, acc.: 60.16%] [G loss: 0.944655]\n",
      "epoch:15 step:14221 [D loss: 0.593864, acc.: 71.88%] [G loss: 0.948261]\n",
      "epoch:15 step:14222 [D loss: 0.641318, acc.: 64.84%] [G loss: 0.908354]\n",
      "epoch:15 step:14223 [D loss: 0.631656, acc.: 68.75%] [G loss: 0.854690]\n",
      "epoch:15 step:14224 [D loss: 0.640290, acc.: 65.62%] [G loss: 0.864328]\n",
      "epoch:15 step:14225 [D loss: 0.682228, acc.: 55.47%] [G loss: 0.907912]\n",
      "epoch:15 step:14226 [D loss: 0.681292, acc.: 58.59%] [G loss: 0.868846]\n",
      "epoch:15 step:14227 [D loss: 0.714489, acc.: 55.47%] [G loss: 0.856818]\n",
      "epoch:15 step:14228 [D loss: 0.639636, acc.: 57.03%] [G loss: 0.919562]\n",
      "epoch:15 step:14229 [D loss: 0.713794, acc.: 54.69%] [G loss: 0.898156]\n",
      "epoch:15 step:14230 [D loss: 0.670023, acc.: 58.59%] [G loss: 0.918540]\n",
      "epoch:15 step:14231 [D loss: 0.663140, acc.: 58.59%] [G loss: 0.878201]\n",
      "epoch:15 step:14232 [D loss: 0.706291, acc.: 52.34%] [G loss: 0.938112]\n",
      "epoch:15 step:14233 [D loss: 0.661805, acc.: 58.59%] [G loss: 0.837610]\n",
      "epoch:15 step:14234 [D loss: 0.626684, acc.: 69.53%] [G loss: 0.978340]\n",
      "epoch:15 step:14235 [D loss: 0.660120, acc.: 64.06%] [G loss: 0.920955]\n",
      "epoch:15 step:14236 [D loss: 0.702102, acc.: 53.91%] [G loss: 0.916322]\n",
      "epoch:15 step:14237 [D loss: 0.704059, acc.: 58.59%] [G loss: 0.921113]\n",
      "epoch:15 step:14238 [D loss: 0.664848, acc.: 63.28%] [G loss: 0.905315]\n",
      "epoch:15 step:14239 [D loss: 0.654081, acc.: 63.28%] [G loss: 0.942611]\n",
      "epoch:15 step:14240 [D loss: 0.634271, acc.: 62.50%] [G loss: 0.973526]\n",
      "epoch:15 step:14241 [D loss: 0.698600, acc.: 56.25%] [G loss: 0.946495]\n",
      "epoch:15 step:14242 [D loss: 0.636556, acc.: 63.28%] [G loss: 0.926460]\n",
      "epoch:15 step:14243 [D loss: 0.707205, acc.: 60.16%] [G loss: 0.859926]\n",
      "epoch:15 step:14244 [D loss: 0.649839, acc.: 61.72%] [G loss: 0.843915]\n",
      "epoch:15 step:14245 [D loss: 0.630843, acc.: 61.72%] [G loss: 0.889433]\n",
      "epoch:15 step:14246 [D loss: 0.630174, acc.: 70.31%] [G loss: 0.903567]\n",
      "epoch:15 step:14247 [D loss: 0.639398, acc.: 63.28%] [G loss: 0.937307]\n",
      "epoch:15 step:14248 [D loss: 0.645270, acc.: 63.28%] [G loss: 0.885072]\n",
      "epoch:15 step:14249 [D loss: 0.583123, acc.: 73.44%] [G loss: 0.940071]\n",
      "epoch:15 step:14250 [D loss: 0.639453, acc.: 63.28%] [G loss: 0.905231]\n",
      "epoch:15 step:14251 [D loss: 0.710976, acc.: 53.91%] [G loss: 0.913952]\n",
      "epoch:15 step:14252 [D loss: 0.624402, acc.: 64.84%] [G loss: 0.939709]\n",
      "epoch:15 step:14253 [D loss: 0.605802, acc.: 71.09%] [G loss: 0.978073]\n",
      "epoch:15 step:14254 [D loss: 0.601721, acc.: 67.19%] [G loss: 0.990871]\n",
      "epoch:15 step:14255 [D loss: 0.694066, acc.: 51.56%] [G loss: 0.883648]\n",
      "epoch:15 step:14256 [D loss: 0.695307, acc.: 60.94%] [G loss: 0.977465]\n",
      "epoch:15 step:14257 [D loss: 0.663699, acc.: 60.94%] [G loss: 0.862059]\n",
      "epoch:15 step:14258 [D loss: 0.703692, acc.: 56.25%] [G loss: 0.826319]\n",
      "epoch:15 step:14259 [D loss: 0.666055, acc.: 60.16%] [G loss: 0.848060]\n",
      "epoch:15 step:14260 [D loss: 0.643313, acc.: 62.50%] [G loss: 0.910515]\n",
      "epoch:15 step:14261 [D loss: 0.651899, acc.: 64.84%] [G loss: 0.914178]\n",
      "epoch:15 step:14262 [D loss: 0.615158, acc.: 64.84%] [G loss: 0.902878]\n",
      "epoch:15 step:14263 [D loss: 0.575043, acc.: 69.53%] [G loss: 1.019377]\n",
      "epoch:15 step:14264 [D loss: 0.668808, acc.: 57.81%] [G loss: 0.935782]\n",
      "epoch:15 step:14265 [D loss: 0.701887, acc.: 53.91%] [G loss: 0.878476]\n",
      "epoch:15 step:14266 [D loss: 0.685704, acc.: 57.03%] [G loss: 0.861028]\n",
      "epoch:15 step:14267 [D loss: 0.686490, acc.: 59.38%] [G loss: 0.956840]\n",
      "epoch:15 step:14268 [D loss: 0.652330, acc.: 60.16%] [G loss: 0.904363]\n",
      "epoch:15 step:14269 [D loss: 0.724368, acc.: 53.12%] [G loss: 0.891356]\n",
      "epoch:15 step:14270 [D loss: 0.706674, acc.: 53.91%] [G loss: 0.909046]\n",
      "epoch:15 step:14271 [D loss: 0.683458, acc.: 58.59%] [G loss: 0.945707]\n",
      "epoch:15 step:14272 [D loss: 0.652260, acc.: 61.72%] [G loss: 0.948747]\n",
      "epoch:15 step:14273 [D loss: 0.661233, acc.: 60.16%] [G loss: 0.916929]\n",
      "epoch:15 step:14274 [D loss: 0.620141, acc.: 62.50%] [G loss: 0.938063]\n",
      "epoch:15 step:14275 [D loss: 0.729023, acc.: 53.91%] [G loss: 0.932949]\n",
      "epoch:15 step:14276 [D loss: 0.657541, acc.: 64.06%] [G loss: 1.001275]\n",
      "epoch:15 step:14277 [D loss: 0.623506, acc.: 65.62%] [G loss: 1.022528]\n",
      "epoch:15 step:14278 [D loss: 0.610665, acc.: 65.62%] [G loss: 1.033970]\n",
      "epoch:15 step:14279 [D loss: 0.764010, acc.: 52.34%] [G loss: 0.883765]\n",
      "epoch:15 step:14280 [D loss: 0.706649, acc.: 51.56%] [G loss: 0.901479]\n",
      "epoch:15 step:14281 [D loss: 0.648203, acc.: 63.28%] [G loss: 0.888694]\n",
      "epoch:15 step:14282 [D loss: 0.630174, acc.: 70.31%] [G loss: 0.837787]\n",
      "epoch:15 step:14283 [D loss: 0.657384, acc.: 59.38%] [G loss: 0.913297]\n",
      "epoch:15 step:14284 [D loss: 0.642594, acc.: 59.38%] [G loss: 0.856493]\n",
      "epoch:15 step:14285 [D loss: 0.641335, acc.: 61.72%] [G loss: 0.907093]\n",
      "epoch:15 step:14286 [D loss: 0.606563, acc.: 64.84%] [G loss: 1.012405]\n",
      "epoch:15 step:14287 [D loss: 0.650393, acc.: 61.72%] [G loss: 0.947152]\n",
      "epoch:15 step:14288 [D loss: 0.699283, acc.: 58.59%] [G loss: 0.920983]\n",
      "epoch:15 step:14289 [D loss: 0.679136, acc.: 59.38%] [G loss: 0.903513]\n",
      "epoch:15 step:14290 [D loss: 0.651473, acc.: 66.41%] [G loss: 0.955250]\n",
      "epoch:15 step:14291 [D loss: 0.649756, acc.: 60.94%] [G loss: 0.965591]\n",
      "epoch:15 step:14292 [D loss: 0.630126, acc.: 64.84%] [G loss: 0.869542]\n",
      "epoch:15 step:14293 [D loss: 0.677662, acc.: 63.28%] [G loss: 0.869230]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14294 [D loss: 0.637500, acc.: 63.28%] [G loss: 0.866382]\n",
      "epoch:15 step:14295 [D loss: 0.664265, acc.: 60.94%] [G loss: 0.900262]\n",
      "epoch:15 step:14296 [D loss: 0.640810, acc.: 60.16%] [G loss: 0.942476]\n",
      "epoch:15 step:14297 [D loss: 0.608287, acc.: 65.62%] [G loss: 0.938369]\n",
      "epoch:15 step:14298 [D loss: 0.621784, acc.: 64.84%] [G loss: 0.912546]\n",
      "epoch:15 step:14299 [D loss: 0.663560, acc.: 60.94%] [G loss: 0.868883]\n",
      "epoch:15 step:14300 [D loss: 0.659312, acc.: 60.16%] [G loss: 0.877810]\n",
      "epoch:15 step:14301 [D loss: 0.666208, acc.: 60.16%] [G loss: 0.938133]\n",
      "epoch:15 step:14302 [D loss: 0.680385, acc.: 62.50%] [G loss: 0.937267]\n",
      "epoch:15 step:14303 [D loss: 0.597558, acc.: 67.19%] [G loss: 0.933500]\n",
      "epoch:15 step:14304 [D loss: 0.726373, acc.: 50.78%] [G loss: 0.948405]\n",
      "epoch:15 step:14305 [D loss: 0.716934, acc.: 55.47%] [G loss: 0.914405]\n",
      "epoch:15 step:14306 [D loss: 0.684209, acc.: 62.50%] [G loss: 0.971883]\n",
      "epoch:15 step:14307 [D loss: 0.655824, acc.: 59.38%] [G loss: 0.965381]\n",
      "epoch:15 step:14308 [D loss: 0.652713, acc.: 58.59%] [G loss: 0.926459]\n",
      "epoch:15 step:14309 [D loss: 0.636415, acc.: 70.31%] [G loss: 0.892980]\n",
      "epoch:15 step:14310 [D loss: 0.625820, acc.: 62.50%] [G loss: 0.836650]\n",
      "epoch:15 step:14311 [D loss: 0.635665, acc.: 64.84%] [G loss: 0.885134]\n",
      "epoch:15 step:14312 [D loss: 0.703505, acc.: 54.69%] [G loss: 0.866260]\n",
      "epoch:15 step:14313 [D loss: 0.609651, acc.: 72.66%] [G loss: 0.902537]\n",
      "epoch:15 step:14314 [D loss: 0.634166, acc.: 62.50%] [G loss: 0.868781]\n",
      "epoch:15 step:14315 [D loss: 0.677606, acc.: 56.25%] [G loss: 0.878965]\n",
      "epoch:15 step:14316 [D loss: 0.674059, acc.: 61.72%] [G loss: 0.836884]\n",
      "epoch:15 step:14317 [D loss: 0.653438, acc.: 64.84%] [G loss: 0.959006]\n",
      "epoch:15 step:14318 [D loss: 0.720901, acc.: 50.00%] [G loss: 0.881293]\n",
      "epoch:15 step:14319 [D loss: 0.628440, acc.: 67.19%] [G loss: 0.906977]\n",
      "epoch:15 step:14320 [D loss: 0.708389, acc.: 50.78%] [G loss: 0.921636]\n",
      "epoch:15 step:14321 [D loss: 0.676849, acc.: 53.12%] [G loss: 0.872746]\n",
      "epoch:15 step:14322 [D loss: 0.653119, acc.: 60.16%] [G loss: 0.908976]\n",
      "epoch:15 step:14323 [D loss: 0.629521, acc.: 64.06%] [G loss: 0.920014]\n",
      "epoch:15 step:14324 [D loss: 0.644704, acc.: 59.38%] [G loss: 0.934101]\n",
      "epoch:15 step:14325 [D loss: 0.648188, acc.: 63.28%] [G loss: 0.923357]\n",
      "epoch:15 step:14326 [D loss: 0.634022, acc.: 65.62%] [G loss: 0.902763]\n",
      "epoch:15 step:14327 [D loss: 0.625247, acc.: 64.06%] [G loss: 0.876354]\n",
      "epoch:15 step:14328 [D loss: 0.646321, acc.: 64.84%] [G loss: 0.847528]\n",
      "epoch:15 step:14329 [D loss: 0.627938, acc.: 64.84%] [G loss: 0.879546]\n",
      "epoch:15 step:14330 [D loss: 0.683345, acc.: 51.56%] [G loss: 0.842207]\n",
      "epoch:15 step:14331 [D loss: 0.697592, acc.: 59.38%] [G loss: 0.957812]\n",
      "epoch:15 step:14332 [D loss: 0.642786, acc.: 59.38%] [G loss: 0.936911]\n",
      "epoch:15 step:14333 [D loss: 0.674692, acc.: 59.38%] [G loss: 0.870587]\n",
      "epoch:15 step:14334 [D loss: 0.653531, acc.: 63.28%] [G loss: 0.976162]\n",
      "epoch:15 step:14335 [D loss: 0.635406, acc.: 60.94%] [G loss: 0.961640]\n",
      "epoch:15 step:14336 [D loss: 0.701581, acc.: 53.12%] [G loss: 0.935393]\n",
      "epoch:15 step:14337 [D loss: 0.718111, acc.: 53.91%] [G loss: 0.913404]\n",
      "epoch:15 step:14338 [D loss: 0.601039, acc.: 68.75%] [G loss: 0.949192]\n",
      "epoch:15 step:14339 [D loss: 0.645296, acc.: 59.38%] [G loss: 0.968564]\n",
      "epoch:15 step:14340 [D loss: 0.635962, acc.: 63.28%] [G loss: 0.883723]\n",
      "epoch:15 step:14341 [D loss: 0.626337, acc.: 71.09%] [G loss: 0.962885]\n",
      "epoch:15 step:14342 [D loss: 0.661168, acc.: 59.38%] [G loss: 0.998650]\n",
      "epoch:15 step:14343 [D loss: 0.650145, acc.: 57.03%] [G loss: 0.974760]\n",
      "epoch:15 step:14344 [D loss: 0.597971, acc.: 73.44%] [G loss: 1.000220]\n",
      "epoch:15 step:14345 [D loss: 0.649956, acc.: 62.50%] [G loss: 1.005637]\n",
      "epoch:15 step:14346 [D loss: 0.710842, acc.: 56.25%] [G loss: 0.849702]\n",
      "epoch:15 step:14347 [D loss: 0.629109, acc.: 65.62%] [G loss: 0.905426]\n",
      "epoch:15 step:14348 [D loss: 0.691853, acc.: 55.47%] [G loss: 0.870402]\n",
      "epoch:15 step:14349 [D loss: 0.652480, acc.: 64.06%] [G loss: 0.810137]\n",
      "epoch:15 step:14350 [D loss: 0.672223, acc.: 57.81%] [G loss: 0.817157]\n",
      "epoch:15 step:14351 [D loss: 0.626148, acc.: 60.94%] [G loss: 0.896883]\n",
      "epoch:15 step:14352 [D loss: 0.655925, acc.: 60.94%] [G loss: 0.938023]\n",
      "epoch:15 step:14353 [D loss: 0.605466, acc.: 73.44%] [G loss: 0.878176]\n",
      "epoch:15 step:14354 [D loss: 0.613235, acc.: 67.19%] [G loss: 0.946719]\n",
      "epoch:15 step:14355 [D loss: 0.629761, acc.: 64.84%] [G loss: 0.895615]\n",
      "epoch:15 step:14356 [D loss: 0.729099, acc.: 50.00%] [G loss: 0.930782]\n",
      "epoch:15 step:14357 [D loss: 0.616312, acc.: 66.41%] [G loss: 0.974790]\n",
      "epoch:15 step:14358 [D loss: 0.688432, acc.: 63.28%] [G loss: 0.914937]\n",
      "epoch:15 step:14359 [D loss: 0.634094, acc.: 64.06%] [G loss: 0.951992]\n",
      "epoch:15 step:14360 [D loss: 0.648569, acc.: 61.72%] [G loss: 0.977452]\n",
      "epoch:15 step:14361 [D loss: 0.616611, acc.: 66.41%] [G loss: 0.993093]\n",
      "epoch:15 step:14362 [D loss: 0.608561, acc.: 66.41%] [G loss: 0.966978]\n",
      "epoch:15 step:14363 [D loss: 0.618724, acc.: 64.84%] [G loss: 0.902918]\n",
      "epoch:15 step:14364 [D loss: 0.585900, acc.: 71.88%] [G loss: 0.950920]\n",
      "epoch:15 step:14365 [D loss: 0.600532, acc.: 64.06%] [G loss: 0.895692]\n",
      "epoch:15 step:14366 [D loss: 0.621254, acc.: 68.75%] [G loss: 0.934487]\n",
      "epoch:15 step:14367 [D loss: 0.592185, acc.: 72.66%] [G loss: 0.955229]\n",
      "epoch:15 step:14368 [D loss: 0.568900, acc.: 71.88%] [G loss: 1.018619]\n",
      "epoch:15 step:14369 [D loss: 0.583539, acc.: 70.31%] [G loss: 1.003901]\n",
      "epoch:15 step:14370 [D loss: 0.580262, acc.: 68.75%] [G loss: 1.076291]\n",
      "epoch:15 step:14371 [D loss: 0.787662, acc.: 50.00%] [G loss: 0.921826]\n",
      "epoch:15 step:14372 [D loss: 0.685337, acc.: 50.78%] [G loss: 0.889260]\n",
      "epoch:15 step:14373 [D loss: 0.689435, acc.: 53.12%] [G loss: 0.860945]\n",
      "epoch:15 step:14374 [D loss: 0.635367, acc.: 62.50%] [G loss: 0.848976]\n",
      "epoch:15 step:14375 [D loss: 0.667178, acc.: 54.69%] [G loss: 0.894394]\n",
      "epoch:15 step:14376 [D loss: 0.573928, acc.: 69.53%] [G loss: 0.849844]\n",
      "epoch:15 step:14377 [D loss: 0.617863, acc.: 63.28%] [G loss: 0.920596]\n",
      "epoch:15 step:14378 [D loss: 0.658534, acc.: 55.47%] [G loss: 0.882990]\n",
      "epoch:15 step:14379 [D loss: 0.710734, acc.: 57.03%] [G loss: 0.914644]\n",
      "epoch:15 step:14380 [D loss: 0.664812, acc.: 53.91%] [G loss: 0.901472]\n",
      "epoch:15 step:14381 [D loss: 0.654566, acc.: 64.84%] [G loss: 0.899878]\n",
      "epoch:15 step:14382 [D loss: 0.623465, acc.: 67.97%] [G loss: 0.984079]\n",
      "epoch:15 step:14383 [D loss: 0.610683, acc.: 67.19%] [G loss: 1.057866]\n",
      "epoch:15 step:14384 [D loss: 0.661251, acc.: 63.28%] [G loss: 1.018695]\n",
      "epoch:15 step:14385 [D loss: 0.688680, acc.: 60.94%] [G loss: 0.824625]\n",
      "epoch:15 step:14386 [D loss: 0.678133, acc.: 57.03%] [G loss: 0.895888]\n",
      "epoch:15 step:14387 [D loss: 0.634814, acc.: 64.06%] [G loss: 0.940680]\n",
      "epoch:15 step:14388 [D loss: 0.648471, acc.: 63.28%] [G loss: 0.902859]\n",
      "epoch:15 step:14389 [D loss: 0.641331, acc.: 61.72%] [G loss: 0.924907]\n",
      "epoch:15 step:14390 [D loss: 0.653684, acc.: 64.06%] [G loss: 0.971016]\n",
      "epoch:15 step:14391 [D loss: 0.626399, acc.: 63.28%] [G loss: 0.969820]\n",
      "epoch:15 step:14392 [D loss: 0.628699, acc.: 69.53%] [G loss: 0.933649]\n",
      "epoch:15 step:14393 [D loss: 0.698271, acc.: 57.03%] [G loss: 0.894186]\n",
      "epoch:15 step:14394 [D loss: 0.643625, acc.: 63.28%] [G loss: 0.896701]\n",
      "epoch:15 step:14395 [D loss: 0.626656, acc.: 64.84%] [G loss: 0.926383]\n",
      "epoch:15 step:14396 [D loss: 0.726236, acc.: 54.69%] [G loss: 0.958220]\n",
      "epoch:15 step:14397 [D loss: 0.698794, acc.: 52.34%] [G loss: 0.943699]\n",
      "epoch:15 step:14398 [D loss: 0.664105, acc.: 60.94%] [G loss: 0.908215]\n",
      "epoch:15 step:14399 [D loss: 0.637019, acc.: 68.75%] [G loss: 0.938289]\n",
      "epoch:15 step:14400 [D loss: 0.642343, acc.: 65.62%] [G loss: 0.964944]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.201494\n",
      "FID: 6.772248\n",
      "0 = 11.802599737596458\n",
      "1 = 0.049286181564169376\n",
      "2 = 0.9154999852180481\n",
      "3 = 0.8755999803543091\n",
      "4 = 0.9553999900817871\n",
      "5 = 0.9515323042869568\n",
      "6 = 0.8755999803543091\n",
      "7 = 5.694638056483856\n",
      "8 = 0.05840729611165635\n",
      "9 = 0.7083500027656555\n",
      "10 = 0.6868000030517578\n",
      "11 = 0.7299000024795532\n",
      "12 = 0.7177343368530273\n",
      "13 = 0.6868000030517578\n",
      "14 = 8.201558113098145\n",
      "15 = 9.63642406463623\n",
      "16 = 0.07184002548456192\n",
      "17 = 8.201494216918945\n",
      "18 = 6.772248268127441\n",
      "epoch:15 step:14401 [D loss: 0.598883, acc.: 71.09%] [G loss: 0.988132]\n",
      "epoch:15 step:14402 [D loss: 0.568529, acc.: 71.88%] [G loss: 1.002354]\n",
      "epoch:15 step:14403 [D loss: 0.762352, acc.: 52.34%] [G loss: 0.917101]\n",
      "epoch:15 step:14404 [D loss: 0.780912, acc.: 44.53%] [G loss: 0.887176]\n",
      "epoch:15 step:14405 [D loss: 0.691800, acc.: 58.59%] [G loss: 0.821348]\n",
      "epoch:15 step:14406 [D loss: 0.691026, acc.: 53.12%] [G loss: 0.905688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14407 [D loss: 0.655119, acc.: 58.59%] [G loss: 0.928415]\n",
      "epoch:15 step:14408 [D loss: 0.622695, acc.: 67.19%] [G loss: 1.009890]\n",
      "epoch:15 step:14409 [D loss: 0.574543, acc.: 76.56%] [G loss: 0.940401]\n",
      "epoch:15 step:14410 [D loss: 0.686636, acc.: 57.81%] [G loss: 0.924520]\n",
      "epoch:15 step:14411 [D loss: 0.656671, acc.: 60.16%] [G loss: 0.978864]\n",
      "epoch:15 step:14412 [D loss: 0.636704, acc.: 64.06%] [G loss: 0.936130]\n",
      "epoch:15 step:14413 [D loss: 0.651517, acc.: 58.59%] [G loss: 0.864931]\n",
      "epoch:15 step:14414 [D loss: 0.613793, acc.: 70.31%] [G loss: 0.929152]\n",
      "epoch:15 step:14415 [D loss: 0.558699, acc.: 72.66%] [G loss: 0.972451]\n",
      "epoch:15 step:14416 [D loss: 0.662970, acc.: 63.28%] [G loss: 0.976472]\n",
      "epoch:15 step:14417 [D loss: 0.672056, acc.: 55.47%] [G loss: 0.943831]\n",
      "epoch:15 step:14418 [D loss: 0.637907, acc.: 59.38%] [G loss: 0.956036]\n",
      "epoch:15 step:14419 [D loss: 0.648929, acc.: 56.25%] [G loss: 0.876506]\n",
      "epoch:15 step:14420 [D loss: 0.671178, acc.: 57.03%] [G loss: 0.945647]\n",
      "epoch:15 step:14421 [D loss: 0.623169, acc.: 67.19%] [G loss: 0.923570]\n",
      "epoch:15 step:14422 [D loss: 0.606476, acc.: 66.41%] [G loss: 0.907201]\n",
      "epoch:15 step:14423 [D loss: 0.672279, acc.: 59.38%] [G loss: 0.862909]\n",
      "epoch:15 step:14424 [D loss: 0.646756, acc.: 56.25%] [G loss: 0.883971]\n",
      "epoch:15 step:14425 [D loss: 0.628214, acc.: 64.84%] [G loss: 0.881092]\n",
      "epoch:15 step:14426 [D loss: 0.598291, acc.: 67.97%] [G loss: 0.975543]\n",
      "epoch:15 step:14427 [D loss: 0.676434, acc.: 57.81%] [G loss: 0.950222]\n",
      "epoch:15 step:14428 [D loss: 0.642653, acc.: 62.50%] [G loss: 1.004316]\n",
      "epoch:15 step:14429 [D loss: 0.616632, acc.: 67.19%] [G loss: 1.014204]\n",
      "epoch:15 step:14430 [D loss: 0.682545, acc.: 54.69%] [G loss: 0.931026]\n",
      "epoch:15 step:14431 [D loss: 0.702205, acc.: 56.25%] [G loss: 0.877615]\n",
      "epoch:15 step:14432 [D loss: 0.708814, acc.: 50.78%] [G loss: 0.839877]\n",
      "epoch:15 step:14433 [D loss: 0.638861, acc.: 61.72%] [G loss: 0.905663]\n",
      "epoch:15 step:14434 [D loss: 0.680144, acc.: 62.50%] [G loss: 0.925528]\n",
      "epoch:15 step:14435 [D loss: 0.741775, acc.: 51.56%] [G loss: 0.774497]\n",
      "epoch:15 step:14436 [D loss: 0.630258, acc.: 64.06%] [G loss: 0.895873]\n",
      "epoch:15 step:14437 [D loss: 0.671206, acc.: 57.81%] [G loss: 0.806752]\n",
      "epoch:15 step:14438 [D loss: 0.646714, acc.: 59.38%] [G loss: 0.911789]\n",
      "epoch:15 step:14439 [D loss: 0.624100, acc.: 63.28%] [G loss: 0.896525]\n",
      "epoch:15 step:14440 [D loss: 0.616907, acc.: 67.19%] [G loss: 0.877025]\n",
      "epoch:15 step:14441 [D loss: 0.729798, acc.: 51.56%] [G loss: 0.918581]\n",
      "epoch:15 step:14442 [D loss: 0.695115, acc.: 52.34%] [G loss: 0.912145]\n",
      "epoch:15 step:14443 [D loss: 0.676703, acc.: 60.16%] [G loss: 0.880031]\n",
      "epoch:15 step:14444 [D loss: 0.672750, acc.: 59.38%] [G loss: 0.933964]\n",
      "epoch:15 step:14445 [D loss: 0.683856, acc.: 58.59%] [G loss: 0.823304]\n",
      "epoch:15 step:14446 [D loss: 0.672302, acc.: 61.72%] [G loss: 0.882295]\n",
      "epoch:15 step:14447 [D loss: 0.652170, acc.: 60.16%] [G loss: 0.870459]\n",
      "epoch:15 step:14448 [D loss: 0.659849, acc.: 60.16%] [G loss: 0.862719]\n",
      "epoch:15 step:14449 [D loss: 0.688046, acc.: 54.69%] [G loss: 0.868238]\n",
      "epoch:15 step:14450 [D loss: 0.655684, acc.: 61.72%] [G loss: 0.875596]\n",
      "epoch:15 step:14451 [D loss: 0.704914, acc.: 56.25%] [G loss: 0.869229]\n",
      "epoch:15 step:14452 [D loss: 0.656700, acc.: 62.50%] [G loss: 0.938877]\n",
      "epoch:15 step:14453 [D loss: 0.596663, acc.: 67.19%] [G loss: 1.012954]\n",
      "epoch:15 step:14454 [D loss: 0.594204, acc.: 69.53%] [G loss: 1.054070]\n",
      "epoch:15 step:14455 [D loss: 0.687192, acc.: 52.34%] [G loss: 0.916464]\n",
      "epoch:15 step:14456 [D loss: 0.652407, acc.: 64.84%] [G loss: 0.890382]\n",
      "epoch:15 step:14457 [D loss: 0.634932, acc.: 68.75%] [G loss: 0.963488]\n",
      "epoch:15 step:14458 [D loss: 0.628812, acc.: 67.19%] [G loss: 0.952996]\n",
      "epoch:15 step:14459 [D loss: 0.687272, acc.: 56.25%] [G loss: 0.930871]\n",
      "epoch:15 step:14460 [D loss: 0.612217, acc.: 65.62%] [G loss: 0.914974]\n",
      "epoch:15 step:14461 [D loss: 0.626360, acc.: 65.62%] [G loss: 1.023290]\n",
      "epoch:15 step:14462 [D loss: 0.651470, acc.: 64.84%] [G loss: 0.975504]\n",
      "epoch:15 step:14463 [D loss: 0.686119, acc.: 53.91%] [G loss: 0.889872]\n",
      "epoch:15 step:14464 [D loss: 0.666738, acc.: 57.03%] [G loss: 0.929625]\n",
      "epoch:15 step:14465 [D loss: 0.677465, acc.: 62.50%] [G loss: 0.931778]\n",
      "epoch:15 step:14466 [D loss: 0.720809, acc.: 48.44%] [G loss: 0.825691]\n",
      "epoch:15 step:14467 [D loss: 0.683917, acc.: 60.16%] [G loss: 0.890909]\n",
      "epoch:15 step:14468 [D loss: 0.702392, acc.: 55.47%] [G loss: 0.916651]\n",
      "epoch:15 step:14469 [D loss: 0.682413, acc.: 59.38%] [G loss: 0.914722]\n",
      "epoch:15 step:14470 [D loss: 0.682755, acc.: 57.03%] [G loss: 0.952692]\n",
      "epoch:15 step:14471 [D loss: 0.568110, acc.: 77.34%] [G loss: 1.015062]\n",
      "epoch:15 step:14472 [D loss: 0.677826, acc.: 63.28%] [G loss: 1.029084]\n",
      "epoch:15 step:14473 [D loss: 0.751366, acc.: 45.31%] [G loss: 0.880277]\n",
      "epoch:15 step:14474 [D loss: 0.689959, acc.: 59.38%] [G loss: 0.825185]\n",
      "epoch:15 step:14475 [D loss: 0.678176, acc.: 60.94%] [G loss: 0.830043]\n",
      "epoch:15 step:14476 [D loss: 0.675725, acc.: 58.59%] [G loss: 0.857196]\n",
      "epoch:15 step:14477 [D loss: 0.664814, acc.: 62.50%] [G loss: 0.880680]\n",
      "epoch:15 step:14478 [D loss: 0.663429, acc.: 56.25%] [G loss: 0.914386]\n",
      "epoch:15 step:14479 [D loss: 0.710337, acc.: 53.12%] [G loss: 0.884816]\n",
      "epoch:15 step:14480 [D loss: 0.658716, acc.: 60.16%] [G loss: 0.968662]\n",
      "epoch:15 step:14481 [D loss: 0.659621, acc.: 61.72%] [G loss: 0.959955]\n",
      "epoch:15 step:14482 [D loss: 0.637511, acc.: 64.84%] [G loss: 1.000721]\n",
      "epoch:15 step:14483 [D loss: 0.622562, acc.: 68.75%] [G loss: 0.999539]\n",
      "epoch:15 step:14484 [D loss: 0.628332, acc.: 67.19%] [G loss: 0.931049]\n",
      "epoch:15 step:14485 [D loss: 0.593770, acc.: 73.44%] [G loss: 0.932454]\n",
      "epoch:15 step:14486 [D loss: 0.701908, acc.: 56.25%] [G loss: 0.933837]\n",
      "epoch:15 step:14487 [D loss: 0.691391, acc.: 52.34%] [G loss: 0.925577]\n",
      "epoch:15 step:14488 [D loss: 0.651339, acc.: 62.50%] [G loss: 0.905946]\n",
      "epoch:15 step:14489 [D loss: 0.600867, acc.: 67.97%] [G loss: 0.919430]\n",
      "epoch:15 step:14490 [D loss: 0.606475, acc.: 71.09%] [G loss: 0.906475]\n",
      "epoch:15 step:14491 [D loss: 0.594546, acc.: 70.31%] [G loss: 0.968406]\n",
      "epoch:15 step:14492 [D loss: 0.762430, acc.: 49.22%] [G loss: 0.957988]\n",
      "epoch:15 step:14493 [D loss: 0.671565, acc.: 57.81%] [G loss: 0.913709]\n",
      "epoch:15 step:14494 [D loss: 0.703308, acc.: 54.69%] [G loss: 0.903878]\n",
      "epoch:15 step:14495 [D loss: 0.629457, acc.: 67.97%] [G loss: 0.917891]\n",
      "epoch:15 step:14496 [D loss: 0.659115, acc.: 61.72%] [G loss: 0.972706]\n",
      "epoch:15 step:14497 [D loss: 0.696702, acc.: 55.47%] [G loss: 0.975297]\n",
      "epoch:15 step:14498 [D loss: 0.646182, acc.: 58.59%] [G loss: 0.981836]\n",
      "epoch:15 step:14499 [D loss: 0.654480, acc.: 57.03%] [G loss: 0.932095]\n",
      "epoch:15 step:14500 [D loss: 0.590620, acc.: 67.97%] [G loss: 0.916967]\n",
      "epoch:15 step:14501 [D loss: 0.651204, acc.: 62.50%] [G loss: 0.957612]\n",
      "epoch:15 step:14502 [D loss: 0.633960, acc.: 65.62%] [G loss: 0.887305]\n",
      "epoch:15 step:14503 [D loss: 0.708582, acc.: 55.47%] [G loss: 0.892368]\n",
      "epoch:15 step:14504 [D loss: 0.752493, acc.: 51.56%] [G loss: 0.893248]\n",
      "epoch:15 step:14505 [D loss: 0.628512, acc.: 67.97%] [G loss: 0.889116]\n",
      "epoch:15 step:14506 [D loss: 0.636870, acc.: 61.72%] [G loss: 0.909479]\n",
      "epoch:15 step:14507 [D loss: 0.649010, acc.: 60.16%] [G loss: 0.893028]\n",
      "epoch:15 step:14508 [D loss: 0.578101, acc.: 71.88%] [G loss: 0.871427]\n",
      "epoch:15 step:14509 [D loss: 0.666430, acc.: 62.50%] [G loss: 0.914338]\n",
      "epoch:15 step:14510 [D loss: 0.668959, acc.: 60.16%] [G loss: 0.881518]\n",
      "epoch:15 step:14511 [D loss: 0.686369, acc.: 53.91%] [G loss: 0.948685]\n",
      "epoch:15 step:14512 [D loss: 0.600893, acc.: 70.31%] [G loss: 0.924347]\n",
      "epoch:15 step:14513 [D loss: 0.771043, acc.: 48.44%] [G loss: 0.911335]\n",
      "epoch:15 step:14514 [D loss: 0.703247, acc.: 50.78%] [G loss: 0.792410]\n",
      "epoch:15 step:14515 [D loss: 0.720225, acc.: 46.09%] [G loss: 0.863876]\n",
      "epoch:15 step:14516 [D loss: 0.649749, acc.: 57.81%] [G loss: 0.821180]\n",
      "epoch:15 step:14517 [D loss: 0.687932, acc.: 58.59%] [G loss: 0.874982]\n",
      "epoch:15 step:14518 [D loss: 0.660414, acc.: 61.72%] [G loss: 0.879618]\n",
      "epoch:15 step:14519 [D loss: 0.648083, acc.: 65.62%] [G loss: 0.832121]\n",
      "epoch:15 step:14520 [D loss: 0.683338, acc.: 60.16%] [G loss: 0.857217]\n",
      "epoch:15 step:14521 [D loss: 0.687435, acc.: 55.47%] [G loss: 0.823736]\n",
      "epoch:15 step:14522 [D loss: 0.688742, acc.: 56.25%] [G loss: 0.860760]\n",
      "epoch:15 step:14523 [D loss: 0.624511, acc.: 64.06%] [G loss: 0.887983]\n",
      "epoch:15 step:14524 [D loss: 0.624667, acc.: 65.62%] [G loss: 0.903929]\n",
      "epoch:15 step:14525 [D loss: 0.652003, acc.: 64.06%] [G loss: 0.903427]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14526 [D loss: 0.614157, acc.: 64.84%] [G loss: 0.951847]\n",
      "epoch:15 step:14527 [D loss: 0.644360, acc.: 62.50%] [G loss: 0.916171]\n",
      "epoch:15 step:14528 [D loss: 0.732089, acc.: 52.34%] [G loss: 0.964860]\n",
      "epoch:15 step:14529 [D loss: 0.670914, acc.: 60.16%] [G loss: 0.926521]\n",
      "epoch:15 step:14530 [D loss: 0.641447, acc.: 64.84%] [G loss: 0.898879]\n",
      "epoch:15 step:14531 [D loss: 0.625499, acc.: 64.84%] [G loss: 0.880593]\n",
      "epoch:15 step:14532 [D loss: 0.696476, acc.: 56.25%] [G loss: 0.873771]\n",
      "epoch:15 step:14533 [D loss: 0.676269, acc.: 57.03%] [G loss: 0.850759]\n",
      "epoch:15 step:14534 [D loss: 0.626222, acc.: 65.62%] [G loss: 0.855407]\n",
      "epoch:15 step:14535 [D loss: 0.654189, acc.: 58.59%] [G loss: 0.840716]\n",
      "epoch:15 step:14536 [D loss: 0.649566, acc.: 64.84%] [G loss: 0.907023]\n",
      "epoch:15 step:14537 [D loss: 0.683157, acc.: 58.59%] [G loss: 0.880933]\n",
      "epoch:15 step:14538 [D loss: 0.677235, acc.: 53.12%] [G loss: 0.913582]\n",
      "epoch:15 step:14539 [D loss: 0.632382, acc.: 66.41%] [G loss: 0.892952]\n",
      "epoch:15 step:14540 [D loss: 0.647942, acc.: 61.72%] [G loss: 0.931810]\n",
      "epoch:15 step:14541 [D loss: 0.655765, acc.: 60.16%] [G loss: 0.901321]\n",
      "epoch:15 step:14542 [D loss: 0.622883, acc.: 67.19%] [G loss: 0.901236]\n",
      "epoch:15 step:14543 [D loss: 0.612117, acc.: 65.62%] [G loss: 0.866958]\n",
      "epoch:15 step:14544 [D loss: 0.676653, acc.: 58.59%] [G loss: 0.929519]\n",
      "epoch:15 step:14545 [D loss: 0.667132, acc.: 63.28%] [G loss: 0.934714]\n",
      "epoch:15 step:14546 [D loss: 0.720007, acc.: 55.47%] [G loss: 0.927692]\n",
      "epoch:15 step:14547 [D loss: 0.668656, acc.: 58.59%] [G loss: 0.933303]\n",
      "epoch:15 step:14548 [D loss: 0.631381, acc.: 64.84%] [G loss: 0.891852]\n",
      "epoch:15 step:14549 [D loss: 0.652815, acc.: 60.16%] [G loss: 0.887695]\n",
      "epoch:15 step:14550 [D loss: 0.608024, acc.: 66.41%] [G loss: 0.890522]\n",
      "epoch:15 step:14551 [D loss: 0.610580, acc.: 68.75%] [G loss: 0.927343]\n",
      "epoch:15 step:14552 [D loss: 0.616716, acc.: 67.97%] [G loss: 0.901190]\n",
      "epoch:15 step:14553 [D loss: 0.676031, acc.: 58.59%] [G loss: 0.966966]\n",
      "epoch:15 step:14554 [D loss: 0.606081, acc.: 76.56%] [G loss: 0.985152]\n",
      "epoch:15 step:14555 [D loss: 0.712795, acc.: 56.25%] [G loss: 0.893829]\n",
      "epoch:15 step:14556 [D loss: 0.735283, acc.: 53.91%] [G loss: 0.877197]\n",
      "epoch:15 step:14557 [D loss: 0.717203, acc.: 52.34%] [G loss: 0.902927]\n",
      "epoch:15 step:14558 [D loss: 0.691725, acc.: 56.25%] [G loss: 0.931918]\n",
      "epoch:15 step:14559 [D loss: 0.645993, acc.: 60.16%] [G loss: 0.948631]\n",
      "epoch:15 step:14560 [D loss: 0.624836, acc.: 62.50%] [G loss: 0.930737]\n",
      "epoch:15 step:14561 [D loss: 0.630936, acc.: 57.03%] [G loss: 0.945428]\n",
      "epoch:15 step:14562 [D loss: 0.616012, acc.: 65.62%] [G loss: 0.953239]\n",
      "epoch:15 step:14563 [D loss: 0.527384, acc.: 75.78%] [G loss: 1.010379]\n",
      "epoch:15 step:14564 [D loss: 0.713266, acc.: 56.25%] [G loss: 0.954888]\n",
      "epoch:15 step:14565 [D loss: 0.670673, acc.: 56.25%] [G loss: 0.887159]\n",
      "epoch:15 step:14566 [D loss: 0.717508, acc.: 46.09%] [G loss: 0.883670]\n",
      "epoch:15 step:14567 [D loss: 0.695843, acc.: 56.25%] [G loss: 0.868538]\n",
      "epoch:15 step:14568 [D loss: 0.666993, acc.: 57.81%] [G loss: 0.908103]\n",
      "epoch:15 step:14569 [D loss: 0.642257, acc.: 61.72%] [G loss: 0.867092]\n",
      "epoch:15 step:14570 [D loss: 0.621973, acc.: 70.31%] [G loss: 0.832618]\n",
      "epoch:15 step:14571 [D loss: 0.608230, acc.: 69.53%] [G loss: 0.967130]\n",
      "epoch:15 step:14572 [D loss: 0.692230, acc.: 53.91%] [G loss: 0.917462]\n",
      "epoch:15 step:14573 [D loss: 0.668593, acc.: 60.16%] [G loss: 0.903839]\n",
      "epoch:15 step:14574 [D loss: 0.643047, acc.: 61.72%] [G loss: 0.936620]\n",
      "epoch:15 step:14575 [D loss: 0.616511, acc.: 66.41%] [G loss: 0.943906]\n",
      "epoch:15 step:14576 [D loss: 0.626129, acc.: 67.19%] [G loss: 0.937904]\n",
      "epoch:15 step:14577 [D loss: 0.627863, acc.: 64.06%] [G loss: 0.915917]\n",
      "epoch:15 step:14578 [D loss: 0.665608, acc.: 59.38%] [G loss: 0.948082]\n",
      "epoch:15 step:14579 [D loss: 0.653302, acc.: 63.28%] [G loss: 0.871310]\n",
      "epoch:15 step:14580 [D loss: 0.677397, acc.: 59.38%] [G loss: 0.869145]\n",
      "epoch:15 step:14581 [D loss: 0.621242, acc.: 65.62%] [G loss: 0.919712]\n",
      "epoch:15 step:14582 [D loss: 0.677435, acc.: 54.69%] [G loss: 0.895563]\n",
      "epoch:15 step:14583 [D loss: 0.749884, acc.: 44.53%] [G loss: 0.866515]\n",
      "epoch:15 step:14584 [D loss: 0.696749, acc.: 50.78%] [G loss: 0.903461]\n",
      "epoch:15 step:14585 [D loss: 0.627819, acc.: 64.06%] [G loss: 0.925262]\n",
      "epoch:15 step:14586 [D loss: 0.686588, acc.: 58.59%] [G loss: 0.915593]\n",
      "epoch:15 step:14587 [D loss: 0.693507, acc.: 50.00%] [G loss: 0.866586]\n",
      "epoch:15 step:14588 [D loss: 0.678315, acc.: 57.81%] [G loss: 0.906411]\n",
      "epoch:15 step:14589 [D loss: 0.586996, acc.: 74.22%] [G loss: 0.880783]\n",
      "epoch:15 step:14590 [D loss: 0.707416, acc.: 49.22%] [G loss: 0.902890]\n",
      "epoch:15 step:14591 [D loss: 0.673077, acc.: 57.81%] [G loss: 0.825425]\n",
      "epoch:15 step:14592 [D loss: 0.656653, acc.: 61.72%] [G loss: 0.874193]\n",
      "epoch:15 step:14593 [D loss: 0.658896, acc.: 59.38%] [G loss: 0.888045]\n",
      "epoch:15 step:14594 [D loss: 0.652557, acc.: 60.94%] [G loss: 0.906677]\n",
      "epoch:15 step:14595 [D loss: 0.650554, acc.: 61.72%] [G loss: 0.899934]\n",
      "epoch:15 step:14596 [D loss: 0.647966, acc.: 60.94%] [G loss: 0.894935]\n",
      "epoch:15 step:14597 [D loss: 0.779088, acc.: 45.31%] [G loss: 0.875700]\n",
      "epoch:15 step:14598 [D loss: 0.680100, acc.: 57.03%] [G loss: 0.833090]\n",
      "epoch:15 step:14599 [D loss: 0.664506, acc.: 57.03%] [G loss: 0.872522]\n",
      "epoch:15 step:14600 [D loss: 0.684882, acc.: 57.03%] [G loss: 0.909000]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.125988\n",
      "FID: 6.247191\n",
      "0 = 11.776645573472962\n",
      "1 = 0.049253518070878945\n",
      "2 = 0.9178000092506409\n",
      "3 = 0.8754000067710876\n",
      "4 = 0.9602000117301941\n",
      "5 = 0.9565122127532959\n",
      "6 = 0.8754000067710876\n",
      "7 = 5.597791604769249\n",
      "8 = 0.05363320013629945\n",
      "9 = 0.7006999850273132\n",
      "10 = 0.6765999794006348\n",
      "11 = 0.7247999906539917\n",
      "12 = 0.7108636498451233\n",
      "13 = 0.6765999794006348\n",
      "14 = 8.126059532165527\n",
      "15 = 9.628214836120605\n",
      "16 = 0.0776689425110817\n",
      "17 = 8.125988006591797\n",
      "18 = 6.247190952301025\n",
      "epoch:15 step:14601 [D loss: 0.649445, acc.: 61.72%] [G loss: 0.897861]\n",
      "epoch:15 step:14602 [D loss: 0.619357, acc.: 65.62%] [G loss: 0.905209]\n",
      "epoch:15 step:14603 [D loss: 0.637808, acc.: 57.81%] [G loss: 0.920193]\n",
      "epoch:15 step:14604 [D loss: 0.629086, acc.: 67.97%] [G loss: 0.897936]\n",
      "epoch:15 step:14605 [D loss: 0.643948, acc.: 60.94%] [G loss: 0.889814]\n",
      "epoch:15 step:14606 [D loss: 0.626605, acc.: 67.97%] [G loss: 0.919634]\n",
      "epoch:15 step:14607 [D loss: 0.642745, acc.: 62.50%] [G loss: 0.894834]\n",
      "epoch:15 step:14608 [D loss: 0.683144, acc.: 61.72%] [G loss: 0.908716]\n",
      "epoch:15 step:14609 [D loss: 0.648488, acc.: 60.16%] [G loss: 0.874597]\n",
      "epoch:15 step:14610 [D loss: 0.610853, acc.: 67.97%] [G loss: 0.912942]\n",
      "epoch:15 step:14611 [D loss: 0.593351, acc.: 70.31%] [G loss: 0.955735]\n",
      "epoch:15 step:14612 [D loss: 0.597147, acc.: 71.09%] [G loss: 0.917051]\n",
      "epoch:15 step:14613 [D loss: 0.628453, acc.: 61.72%] [G loss: 0.940434]\n",
      "epoch:15 step:14614 [D loss: 0.711695, acc.: 50.00%] [G loss: 0.951962]\n",
      "epoch:15 step:14615 [D loss: 0.736741, acc.: 53.12%] [G loss: 0.905515]\n",
      "epoch:15 step:14616 [D loss: 0.687654, acc.: 57.03%] [G loss: 0.905674]\n",
      "epoch:15 step:14617 [D loss: 0.658486, acc.: 57.03%] [G loss: 0.907800]\n",
      "epoch:15 step:14618 [D loss: 0.614469, acc.: 70.31%] [G loss: 0.980714]\n",
      "epoch:15 step:14619 [D loss: 0.609510, acc.: 64.06%] [G loss: 0.977774]\n",
      "epoch:15 step:14620 [D loss: 0.644406, acc.: 60.94%] [G loss: 0.976937]\n",
      "epoch:15 step:14621 [D loss: 0.749094, acc.: 51.56%] [G loss: 0.901021]\n",
      "epoch:15 step:14622 [D loss: 0.635631, acc.: 65.62%] [G loss: 0.928689]\n",
      "epoch:15 step:14623 [D loss: 0.661640, acc.: 62.50%] [G loss: 0.901149]\n",
      "epoch:15 step:14624 [D loss: 0.683616, acc.: 59.38%] [G loss: 0.881367]\n",
      "epoch:15 step:14625 [D loss: 0.640949, acc.: 60.16%] [G loss: 0.868500]\n",
      "epoch:15 step:14626 [D loss: 0.622608, acc.: 68.75%] [G loss: 0.887260]\n",
      "epoch:15 step:14627 [D loss: 0.698265, acc.: 57.81%] [G loss: 0.871875]\n",
      "epoch:15 step:14628 [D loss: 0.631933, acc.: 62.50%] [G loss: 0.909207]\n",
      "epoch:15 step:14629 [D loss: 0.605155, acc.: 67.19%] [G loss: 1.046196]\n",
      "epoch:15 step:14630 [D loss: 0.626278, acc.: 64.84%] [G loss: 1.044241]\n",
      "epoch:15 step:14631 [D loss: 0.645546, acc.: 61.72%] [G loss: 0.993604]\n",
      "epoch:15 step:14632 [D loss: 0.726097, acc.: 60.16%] [G loss: 0.897583]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14633 [D loss: 0.658654, acc.: 60.94%] [G loss: 0.865251]\n",
      "epoch:15 step:14634 [D loss: 0.672957, acc.: 57.81%] [G loss: 0.907313]\n",
      "epoch:15 step:14635 [D loss: 0.677183, acc.: 62.50%] [G loss: 0.962222]\n",
      "epoch:15 step:14636 [D loss: 0.560086, acc.: 71.09%] [G loss: 0.974152]\n",
      "epoch:15 step:14637 [D loss: 0.611648, acc.: 67.19%] [G loss: 0.985422]\n",
      "epoch:15 step:14638 [D loss: 0.677160, acc.: 60.16%] [G loss: 0.989267]\n",
      "epoch:15 step:14639 [D loss: 0.705692, acc.: 59.38%] [G loss: 0.870805]\n",
      "epoch:15 step:14640 [D loss: 0.627935, acc.: 66.41%] [G loss: 0.862639]\n",
      "epoch:15 step:14641 [D loss: 0.709293, acc.: 53.12%] [G loss: 0.918469]\n",
      "epoch:15 step:14642 [D loss: 0.750067, acc.: 42.19%] [G loss: 0.883216]\n",
      "epoch:15 step:14643 [D loss: 0.642141, acc.: 58.59%] [G loss: 0.958879]\n",
      "epoch:15 step:14644 [D loss: 0.625333, acc.: 65.62%] [G loss: 0.896518]\n",
      "epoch:15 step:14645 [D loss: 0.663518, acc.: 59.38%] [G loss: 0.931631]\n",
      "epoch:15 step:14646 [D loss: 0.715961, acc.: 52.34%] [G loss: 0.902842]\n",
      "epoch:15 step:14647 [D loss: 0.652372, acc.: 59.38%] [G loss: 0.941899]\n",
      "epoch:15 step:14648 [D loss: 0.615591, acc.: 68.75%] [G loss: 0.921720]\n",
      "epoch:15 step:14649 [D loss: 0.639591, acc.: 60.94%] [G loss: 0.938908]\n",
      "epoch:15 step:14650 [D loss: 0.591217, acc.: 66.41%] [G loss: 0.923644]\n",
      "epoch:15 step:14651 [D loss: 0.695642, acc.: 57.81%] [G loss: 0.960104]\n",
      "epoch:15 step:14652 [D loss: 0.700535, acc.: 52.34%] [G loss: 0.813103]\n",
      "epoch:15 step:14653 [D loss: 0.663961, acc.: 56.25%] [G loss: 0.834933]\n",
      "epoch:15 step:14654 [D loss: 0.704820, acc.: 53.12%] [G loss: 0.862361]\n",
      "epoch:15 step:14655 [D loss: 0.726269, acc.: 49.22%] [G loss: 0.895199]\n",
      "epoch:15 step:14656 [D loss: 0.657022, acc.: 63.28%] [G loss: 0.888270]\n",
      "epoch:15 step:14657 [D loss: 0.645988, acc.: 62.50%] [G loss: 0.828011]\n",
      "epoch:15 step:14658 [D loss: 0.669358, acc.: 62.50%] [G loss: 0.870556]\n",
      "epoch:15 step:14659 [D loss: 0.658863, acc.: 59.38%] [G loss: 0.877570]\n",
      "epoch:15 step:14660 [D loss: 0.609734, acc.: 67.97%] [G loss: 0.902935]\n",
      "epoch:15 step:14661 [D loss: 0.659441, acc.: 61.72%] [G loss: 0.917169]\n",
      "epoch:15 step:14662 [D loss: 0.675250, acc.: 50.00%] [G loss: 0.898507]\n",
      "epoch:15 step:14663 [D loss: 0.645252, acc.: 61.72%] [G loss: 0.879886]\n",
      "epoch:15 step:14664 [D loss: 0.646935, acc.: 58.59%] [G loss: 0.917651]\n",
      "epoch:15 step:14665 [D loss: 0.674148, acc.: 59.38%] [G loss: 0.905899]\n",
      "epoch:15 step:14666 [D loss: 0.646868, acc.: 60.94%] [G loss: 0.870870]\n",
      "epoch:15 step:14667 [D loss: 0.687951, acc.: 57.03%] [G loss: 0.862067]\n",
      "epoch:15 step:14668 [D loss: 0.672635, acc.: 60.94%] [G loss: 0.878756]\n",
      "epoch:15 step:14669 [D loss: 0.736817, acc.: 52.34%] [G loss: 0.877916]\n",
      "epoch:15 step:14670 [D loss: 0.695889, acc.: 56.25%] [G loss: 0.896302]\n",
      "epoch:15 step:14671 [D loss: 0.674791, acc.: 54.69%] [G loss: 0.939332]\n",
      "epoch:15 step:14672 [D loss: 0.674592, acc.: 58.59%] [G loss: 0.916439]\n",
      "epoch:15 step:14673 [D loss: 0.640472, acc.: 64.84%] [G loss: 0.850825]\n",
      "epoch:15 step:14674 [D loss: 0.636554, acc.: 61.72%] [G loss: 0.839821]\n",
      "epoch:15 step:14675 [D loss: 0.654102, acc.: 60.94%] [G loss: 0.806642]\n",
      "epoch:15 step:14676 [D loss: 0.660443, acc.: 57.81%] [G loss: 0.857857]\n",
      "epoch:15 step:14677 [D loss: 0.673604, acc.: 53.91%] [G loss: 0.872254]\n",
      "epoch:15 step:14678 [D loss: 0.631429, acc.: 66.41%] [G loss: 0.904583]\n",
      "epoch:15 step:14679 [D loss: 0.618129, acc.: 63.28%] [G loss: 0.959685]\n",
      "epoch:15 step:14680 [D loss: 0.697116, acc.: 50.78%] [G loss: 0.913664]\n",
      "epoch:15 step:14681 [D loss: 0.677189, acc.: 60.94%] [G loss: 0.951866]\n",
      "epoch:15 step:14682 [D loss: 0.604141, acc.: 67.19%] [G loss: 0.886466]\n",
      "epoch:15 step:14683 [D loss: 0.684203, acc.: 58.59%] [G loss: 0.844618]\n",
      "epoch:15 step:14684 [D loss: 0.626218, acc.: 62.50%] [G loss: 0.881566]\n",
      "epoch:15 step:14685 [D loss: 0.640619, acc.: 67.97%] [G loss: 0.935850]\n",
      "epoch:15 step:14686 [D loss: 0.623070, acc.: 65.62%] [G loss: 0.928260]\n",
      "epoch:15 step:14687 [D loss: 0.648984, acc.: 59.38%] [G loss: 1.004275]\n",
      "epoch:15 step:14688 [D loss: 0.623885, acc.: 68.75%] [G loss: 1.005365]\n",
      "epoch:15 step:14689 [D loss: 0.639025, acc.: 60.16%] [G loss: 0.994075]\n",
      "epoch:15 step:14690 [D loss: 0.612296, acc.: 68.75%] [G loss: 1.016313]\n",
      "epoch:15 step:14691 [D loss: 0.653561, acc.: 58.59%] [G loss: 0.944271]\n",
      "epoch:15 step:14692 [D loss: 0.619112, acc.: 66.41%] [G loss: 0.906433]\n",
      "epoch:15 step:14693 [D loss: 0.606606, acc.: 67.19%] [G loss: 0.888296]\n",
      "epoch:15 step:14694 [D loss: 0.679501, acc.: 53.91%] [G loss: 0.878304]\n",
      "epoch:15 step:14695 [D loss: 0.661864, acc.: 60.94%] [G loss: 0.978132]\n",
      "epoch:15 step:14696 [D loss: 0.669950, acc.: 57.03%] [G loss: 0.965208]\n",
      "epoch:15 step:14697 [D loss: 0.610552, acc.: 70.31%] [G loss: 1.032152]\n",
      "epoch:15 step:14698 [D loss: 0.625806, acc.: 64.06%] [G loss: 0.944556]\n",
      "epoch:15 step:14699 [D loss: 0.694349, acc.: 54.69%] [G loss: 0.956530]\n",
      "epoch:15 step:14700 [D loss: 0.668936, acc.: 58.59%] [G loss: 0.948990]\n",
      "epoch:15 step:14701 [D loss: 0.716397, acc.: 53.12%] [G loss: 0.876759]\n",
      "epoch:15 step:14702 [D loss: 0.587705, acc.: 72.66%] [G loss: 0.973868]\n",
      "epoch:15 step:14703 [D loss: 0.587328, acc.: 67.19%] [G loss: 0.951066]\n",
      "epoch:15 step:14704 [D loss: 0.630286, acc.: 65.62%] [G loss: 0.992632]\n",
      "epoch:15 step:14705 [D loss: 0.633319, acc.: 65.62%] [G loss: 0.962378]\n",
      "epoch:15 step:14706 [D loss: 0.646374, acc.: 62.50%] [G loss: 0.978638]\n",
      "epoch:15 step:14707 [D loss: 0.682807, acc.: 58.59%] [G loss: 0.972452]\n",
      "epoch:15 step:14708 [D loss: 0.691053, acc.: 57.81%] [G loss: 0.980968]\n",
      "epoch:15 step:14709 [D loss: 0.630747, acc.: 67.19%] [G loss: 0.947116]\n",
      "epoch:15 step:14710 [D loss: 0.711968, acc.: 53.91%] [G loss: 0.959089]\n",
      "epoch:15 step:14711 [D loss: 0.657584, acc.: 64.06%] [G loss: 0.914603]\n",
      "epoch:15 step:14712 [D loss: 0.640794, acc.: 61.72%] [G loss: 0.931098]\n",
      "epoch:15 step:14713 [D loss: 0.644584, acc.: 67.19%] [G loss: 0.918221]\n",
      "epoch:15 step:14714 [D loss: 0.677913, acc.: 60.94%] [G loss: 0.897232]\n",
      "epoch:15 step:14715 [D loss: 0.583265, acc.: 70.31%] [G loss: 0.903953]\n",
      "epoch:15 step:14716 [D loss: 0.604307, acc.: 69.53%] [G loss: 0.987499]\n",
      "epoch:15 step:14717 [D loss: 0.718616, acc.: 46.09%] [G loss: 0.866771]\n",
      "epoch:15 step:14718 [D loss: 0.657582, acc.: 63.28%] [G loss: 0.916463]\n",
      "epoch:15 step:14719 [D loss: 0.633952, acc.: 63.28%] [G loss: 0.926774]\n",
      "epoch:15 step:14720 [D loss: 0.683912, acc.: 49.22%] [G loss: 0.912862]\n",
      "epoch:15 step:14721 [D loss: 0.642765, acc.: 63.28%] [G loss: 0.958563]\n",
      "epoch:15 step:14722 [D loss: 0.648391, acc.: 63.28%] [G loss: 1.031523]\n",
      "epoch:15 step:14723 [D loss: 0.676848, acc.: 56.25%] [G loss: 0.896528]\n",
      "epoch:15 step:14724 [D loss: 0.629092, acc.: 61.72%] [G loss: 0.877461]\n",
      "epoch:15 step:14725 [D loss: 0.699787, acc.: 57.03%] [G loss: 0.899045]\n",
      "epoch:15 step:14726 [D loss: 0.697133, acc.: 55.47%] [G loss: 0.859112]\n",
      "epoch:15 step:14727 [D loss: 0.669075, acc.: 61.72%] [G loss: 0.960701]\n",
      "epoch:15 step:14728 [D loss: 0.697875, acc.: 51.56%] [G loss: 0.890731]\n",
      "epoch:15 step:14729 [D loss: 0.678688, acc.: 54.69%] [G loss: 0.907742]\n",
      "epoch:15 step:14730 [D loss: 0.716786, acc.: 56.25%] [G loss: 0.847295]\n",
      "epoch:15 step:14731 [D loss: 0.630331, acc.: 69.53%] [G loss: 0.864481]\n",
      "epoch:15 step:14732 [D loss: 0.639834, acc.: 60.16%] [G loss: 0.970685]\n",
      "epoch:15 step:14733 [D loss: 0.664461, acc.: 60.94%] [G loss: 0.910326]\n",
      "epoch:15 step:14734 [D loss: 0.653632, acc.: 61.72%] [G loss: 0.923940]\n",
      "epoch:15 step:14735 [D loss: 0.634159, acc.: 66.41%] [G loss: 0.880481]\n",
      "epoch:15 step:14736 [D loss: 0.616900, acc.: 64.84%] [G loss: 0.906784]\n",
      "epoch:15 step:14737 [D loss: 0.661797, acc.: 57.03%] [G loss: 0.870071]\n",
      "epoch:15 step:14738 [D loss: 0.671882, acc.: 60.16%] [G loss: 0.857505]\n",
      "epoch:15 step:14739 [D loss: 0.691730, acc.: 57.81%] [G loss: 0.908082]\n",
      "epoch:15 step:14740 [D loss: 0.660804, acc.: 60.16%] [G loss: 0.900389]\n",
      "epoch:15 step:14741 [D loss: 0.669687, acc.: 54.69%] [G loss: 0.924772]\n",
      "epoch:15 step:14742 [D loss: 0.655082, acc.: 59.38%] [G loss: 0.890219]\n",
      "epoch:15 step:14743 [D loss: 0.626846, acc.: 68.75%] [G loss: 0.943443]\n",
      "epoch:15 step:14744 [D loss: 0.646048, acc.: 67.19%] [G loss: 0.872474]\n",
      "epoch:15 step:14745 [D loss: 0.615473, acc.: 67.97%] [G loss: 0.865221]\n",
      "epoch:15 step:14746 [D loss: 0.615982, acc.: 70.31%] [G loss: 0.957820]\n",
      "epoch:15 step:14747 [D loss: 0.600077, acc.: 69.53%] [G loss: 0.925583]\n",
      "epoch:15 step:14748 [D loss: 0.645458, acc.: 62.50%] [G loss: 0.973059]\n",
      "epoch:15 step:14749 [D loss: 0.582723, acc.: 67.19%] [G loss: 0.925512]\n",
      "epoch:15 step:14750 [D loss: 0.653328, acc.: 62.50%] [G loss: 0.986066]\n",
      "epoch:15 step:14751 [D loss: 0.781638, acc.: 48.44%] [G loss: 0.922545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14752 [D loss: 0.671499, acc.: 60.94%] [G loss: 0.903988]\n",
      "epoch:15 step:14753 [D loss: 0.642947, acc.: 57.81%] [G loss: 0.914287]\n",
      "epoch:15 step:14754 [D loss: 0.647364, acc.: 60.16%] [G loss: 0.892637]\n",
      "epoch:15 step:14755 [D loss: 0.600515, acc.: 66.41%] [G loss: 0.846692]\n",
      "epoch:15 step:14756 [D loss: 0.650933, acc.: 59.38%] [G loss: 0.873626]\n",
      "epoch:15 step:14757 [D loss: 0.628686, acc.: 66.41%] [G loss: 0.927983]\n",
      "epoch:15 step:14758 [D loss: 0.664210, acc.: 60.94%] [G loss: 0.879059]\n",
      "epoch:15 step:14759 [D loss: 0.717319, acc.: 53.91%] [G loss: 0.843639]\n",
      "epoch:15 step:14760 [D loss: 0.692116, acc.: 52.34%] [G loss: 0.834381]\n",
      "epoch:15 step:14761 [D loss: 0.678658, acc.: 58.59%] [G loss: 0.899633]\n",
      "epoch:15 step:14762 [D loss: 0.655173, acc.: 61.72%] [G loss: 0.917900]\n",
      "epoch:15 step:14763 [D loss: 0.626038, acc.: 69.53%] [G loss: 0.926594]\n",
      "epoch:15 step:14764 [D loss: 0.639095, acc.: 62.50%] [G loss: 0.956030]\n",
      "epoch:15 step:14765 [D loss: 0.654742, acc.: 64.84%] [G loss: 0.909867]\n",
      "epoch:15 step:14766 [D loss: 0.662512, acc.: 60.94%] [G loss: 0.943326]\n",
      "epoch:15 step:14767 [D loss: 0.649998, acc.: 64.84%] [G loss: 1.008614]\n",
      "epoch:15 step:14768 [D loss: 0.653950, acc.: 61.72%] [G loss: 0.961632]\n",
      "epoch:15 step:14769 [D loss: 0.691428, acc.: 57.03%] [G loss: 0.946433]\n",
      "epoch:15 step:14770 [D loss: 0.695634, acc.: 57.81%] [G loss: 0.932771]\n",
      "epoch:15 step:14771 [D loss: 0.727395, acc.: 50.78%] [G loss: 0.904193]\n",
      "epoch:15 step:14772 [D loss: 0.663132, acc.: 58.59%] [G loss: 0.864123]\n",
      "epoch:15 step:14773 [D loss: 0.677424, acc.: 58.59%] [G loss: 0.877063]\n",
      "epoch:15 step:14774 [D loss: 0.617409, acc.: 66.41%] [G loss: 1.001563]\n",
      "epoch:15 step:14775 [D loss: 0.667512, acc.: 61.72%] [G loss: 0.874759]\n",
      "epoch:15 step:14776 [D loss: 0.648665, acc.: 57.81%] [G loss: 0.922698]\n",
      "epoch:15 step:14777 [D loss: 0.679216, acc.: 58.59%] [G loss: 0.872307]\n",
      "epoch:15 step:14778 [D loss: 0.672988, acc.: 62.50%] [G loss: 0.919908]\n",
      "epoch:15 step:14779 [D loss: 0.629472, acc.: 64.84%] [G loss: 0.866162]\n",
      "epoch:15 step:14780 [D loss: 0.650972, acc.: 57.03%] [G loss: 0.912327]\n",
      "epoch:15 step:14781 [D loss: 0.681737, acc.: 54.69%] [G loss: 0.922947]\n",
      "epoch:15 step:14782 [D loss: 0.656923, acc.: 61.72%] [G loss: 0.866066]\n",
      "epoch:15 step:14783 [D loss: 0.682760, acc.: 59.38%] [G loss: 0.901821]\n",
      "epoch:15 step:14784 [D loss: 0.635863, acc.: 63.28%] [G loss: 0.883275]\n",
      "epoch:15 step:14785 [D loss: 0.627111, acc.: 66.41%] [G loss: 0.921357]\n",
      "epoch:15 step:14786 [D loss: 0.665183, acc.: 60.16%] [G loss: 0.889308]\n",
      "epoch:15 step:14787 [D loss: 0.600443, acc.: 67.97%] [G loss: 0.931378]\n",
      "epoch:15 step:14788 [D loss: 0.620839, acc.: 63.28%] [G loss: 0.963017]\n",
      "epoch:15 step:14789 [D loss: 0.701883, acc.: 56.25%] [G loss: 0.900599]\n",
      "epoch:15 step:14790 [D loss: 0.680807, acc.: 53.91%] [G loss: 0.945285]\n",
      "epoch:15 step:14791 [D loss: 0.654309, acc.: 65.62%] [G loss: 0.929652]\n",
      "epoch:15 step:14792 [D loss: 0.667555, acc.: 55.47%] [G loss: 0.939110]\n",
      "epoch:15 step:14793 [D loss: 0.690371, acc.: 53.91%] [G loss: 0.886585]\n",
      "epoch:15 step:14794 [D loss: 0.666916, acc.: 58.59%] [G loss: 0.913104]\n",
      "epoch:15 step:14795 [D loss: 0.649547, acc.: 59.38%] [G loss: 0.875591]\n",
      "epoch:15 step:14796 [D loss: 0.690535, acc.: 56.25%] [G loss: 0.912894]\n",
      "epoch:15 step:14797 [D loss: 0.647485, acc.: 61.72%] [G loss: 0.943241]\n",
      "epoch:15 step:14798 [D loss: 0.628835, acc.: 60.94%] [G loss: 0.894245]\n",
      "epoch:15 step:14799 [D loss: 0.727392, acc.: 50.00%] [G loss: 0.871043]\n",
      "epoch:15 step:14800 [D loss: 0.669770, acc.: 57.81%] [G loss: 0.875169]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.106891\n",
      "FID: 6.690484\n",
      "0 = 11.700355148410823\n",
      "1 = 0.05002559960199928\n",
      "2 = 0.9114999771118164\n",
      "3 = 0.8639000058174133\n",
      "4 = 0.9591000080108643\n",
      "5 = 0.9547966122627258\n",
      "6 = 0.8639000058174133\n",
      "7 = 5.738033695369974\n",
      "8 = 0.051654063912973835\n",
      "9 = 0.7049499750137329\n",
      "10 = 0.6870999932289124\n",
      "11 = 0.7228000164031982\n",
      "12 = 0.7125375866889954\n",
      "13 = 0.6870999932289124\n",
      "14 = 8.106963157653809\n",
      "15 = 9.587535858154297\n",
      "16 = 0.09708860516548157\n",
      "17 = 8.106890678405762\n",
      "18 = 6.690483570098877\n",
      "epoch:15 step:14801 [D loss: 0.598724, acc.: 71.88%] [G loss: 0.941240]\n",
      "epoch:15 step:14802 [D loss: 0.670212, acc.: 60.16%] [G loss: 0.907446]\n",
      "epoch:15 step:14803 [D loss: 0.618690, acc.: 64.84%] [G loss: 0.908635]\n",
      "epoch:15 step:14804 [D loss: 0.671414, acc.: 57.03%] [G loss: 0.932669]\n",
      "epoch:15 step:14805 [D loss: 0.678047, acc.: 60.16%] [G loss: 0.852988]\n",
      "epoch:15 step:14806 [D loss: 0.616457, acc.: 64.84%] [G loss: 0.857015]\n",
      "epoch:15 step:14807 [D loss: 0.667208, acc.: 60.16%] [G loss: 0.928306]\n",
      "epoch:15 step:14808 [D loss: 0.661537, acc.: 63.28%] [G loss: 0.961262]\n",
      "epoch:15 step:14809 [D loss: 0.609322, acc.: 67.19%] [G loss: 0.947546]\n",
      "epoch:15 step:14810 [D loss: 0.657172, acc.: 62.50%] [G loss: 0.904595]\n",
      "epoch:15 step:14811 [D loss: 0.648245, acc.: 62.50%] [G loss: 0.926520]\n",
      "epoch:15 step:14812 [D loss: 0.692228, acc.: 53.12%] [G loss: 0.861314]\n",
      "epoch:15 step:14813 [D loss: 0.677617, acc.: 58.59%] [G loss: 0.885241]\n",
      "epoch:15 step:14814 [D loss: 0.682654, acc.: 60.94%] [G loss: 0.928686]\n",
      "epoch:15 step:14815 [D loss: 0.655415, acc.: 60.16%] [G loss: 0.905266]\n",
      "epoch:15 step:14816 [D loss: 0.690112, acc.: 56.25%] [G loss: 0.837078]\n",
      "epoch:15 step:14817 [D loss: 0.644295, acc.: 63.28%] [G loss: 0.876251]\n",
      "epoch:15 step:14818 [D loss: 0.677532, acc.: 60.94%] [G loss: 0.894637]\n",
      "epoch:15 step:14819 [D loss: 0.662428, acc.: 59.38%] [G loss: 0.910408]\n",
      "epoch:15 step:14820 [D loss: 0.716375, acc.: 53.91%] [G loss: 0.917762]\n",
      "epoch:15 step:14821 [D loss: 0.665261, acc.: 60.94%] [G loss: 0.862214]\n",
      "epoch:15 step:14822 [D loss: 0.644186, acc.: 65.62%] [G loss: 0.949343]\n",
      "epoch:15 step:14823 [D loss: 0.710351, acc.: 56.25%] [G loss: 0.929233]\n",
      "epoch:15 step:14824 [D loss: 0.650824, acc.: 62.50%] [G loss: 0.884541]\n",
      "epoch:15 step:14825 [D loss: 0.650740, acc.: 58.59%] [G loss: 0.983634]\n",
      "epoch:15 step:14826 [D loss: 0.633639, acc.: 67.19%] [G loss: 0.907959]\n",
      "epoch:15 step:14827 [D loss: 0.674235, acc.: 58.59%] [G loss: 0.946146]\n",
      "epoch:15 step:14828 [D loss: 0.663260, acc.: 56.25%] [G loss: 0.979416]\n",
      "epoch:15 step:14829 [D loss: 0.674721, acc.: 60.16%] [G loss: 0.931430]\n",
      "epoch:15 step:14830 [D loss: 0.572638, acc.: 72.66%] [G loss: 0.980911]\n",
      "epoch:15 step:14831 [D loss: 0.656763, acc.: 58.59%] [G loss: 0.973659]\n",
      "epoch:15 step:14832 [D loss: 0.682559, acc.: 55.47%] [G loss: 0.984885]\n",
      "epoch:15 step:14833 [D loss: 0.658009, acc.: 61.72%] [G loss: 0.986236]\n",
      "epoch:15 step:14834 [D loss: 0.645098, acc.: 61.72%] [G loss: 0.972447]\n",
      "epoch:15 step:14835 [D loss: 0.675629, acc.: 53.91%] [G loss: 0.921490]\n",
      "epoch:15 step:14836 [D loss: 0.659320, acc.: 62.50%] [G loss: 1.049746]\n",
      "epoch:15 step:14837 [D loss: 0.597359, acc.: 66.41%] [G loss: 1.018575]\n",
      "epoch:15 step:14838 [D loss: 0.699363, acc.: 52.34%] [G loss: 1.049334]\n",
      "epoch:15 step:14839 [D loss: 0.758476, acc.: 48.44%] [G loss: 0.964048]\n",
      "epoch:15 step:14840 [D loss: 0.638201, acc.: 63.28%] [G loss: 0.948216]\n",
      "epoch:15 step:14841 [D loss: 0.605716, acc.: 67.19%] [G loss: 0.917280]\n",
      "epoch:15 step:14842 [D loss: 0.679765, acc.: 50.00%] [G loss: 0.851749]\n",
      "epoch:15 step:14843 [D loss: 0.679568, acc.: 57.81%] [G loss: 0.872572]\n",
      "epoch:15 step:14844 [D loss: 0.654769, acc.: 59.38%] [G loss: 0.890565]\n",
      "epoch:15 step:14845 [D loss: 0.642564, acc.: 64.84%] [G loss: 0.909044]\n",
      "epoch:15 step:14846 [D loss: 0.680557, acc.: 58.59%] [G loss: 0.902596]\n",
      "epoch:15 step:14847 [D loss: 0.643107, acc.: 66.41%] [G loss: 0.928050]\n",
      "epoch:15 step:14848 [D loss: 0.631811, acc.: 62.50%] [G loss: 0.917603]\n",
      "epoch:15 step:14849 [D loss: 0.742149, acc.: 43.75%] [G loss: 0.929950]\n",
      "epoch:15 step:14850 [D loss: 0.642900, acc.: 60.94%] [G loss: 0.960738]\n",
      "epoch:15 step:14851 [D loss: 0.635538, acc.: 61.72%] [G loss: 0.950437]\n",
      "epoch:15 step:14852 [D loss: 0.698650, acc.: 55.47%] [G loss: 0.928646]\n",
      "epoch:15 step:14853 [D loss: 0.755301, acc.: 43.75%] [G loss: 0.853391]\n",
      "epoch:15 step:14854 [D loss: 0.647790, acc.: 65.62%] [G loss: 0.897630]\n",
      "epoch:15 step:14855 [D loss: 0.705075, acc.: 50.00%] [G loss: 0.997781]\n",
      "epoch:15 step:14856 [D loss: 0.616993, acc.: 69.53%] [G loss: 0.917610]\n",
      "epoch:15 step:14857 [D loss: 0.627034, acc.: 66.41%] [G loss: 0.983675]\n",
      "epoch:15 step:14858 [D loss: 0.623959, acc.: 66.41%] [G loss: 1.031126]\n",
      "epoch:15 step:14859 [D loss: 0.666756, acc.: 61.72%] [G loss: 0.922380]\n",
      "epoch:15 step:14860 [D loss: 0.660825, acc.: 61.72%] [G loss: 0.925008]\n",
      "epoch:15 step:14861 [D loss: 0.700250, acc.: 52.34%] [G loss: 0.853979]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14862 [D loss: 0.650073, acc.: 62.50%] [G loss: 0.844202]\n",
      "epoch:15 step:14863 [D loss: 0.696048, acc.: 51.56%] [G loss: 0.919522]\n",
      "epoch:15 step:14864 [D loss: 0.679064, acc.: 61.72%] [G loss: 0.836723]\n",
      "epoch:15 step:14865 [D loss: 0.663566, acc.: 59.38%] [G loss: 0.880166]\n",
      "epoch:15 step:14866 [D loss: 0.668857, acc.: 64.84%] [G loss: 0.851175]\n",
      "epoch:15 step:14867 [D loss: 0.694738, acc.: 57.81%] [G loss: 0.859011]\n",
      "epoch:15 step:14868 [D loss: 0.643926, acc.: 65.62%] [G loss: 0.874384]\n",
      "epoch:15 step:14869 [D loss: 0.648824, acc.: 58.59%] [G loss: 0.890480]\n",
      "epoch:15 step:14870 [D loss: 0.643608, acc.: 64.06%] [G loss: 0.900874]\n",
      "epoch:15 step:14871 [D loss: 0.615407, acc.: 69.53%] [G loss: 0.896926]\n",
      "epoch:15 step:14872 [D loss: 0.659631, acc.: 59.38%] [G loss: 0.896623]\n",
      "epoch:15 step:14873 [D loss: 0.711970, acc.: 51.56%] [G loss: 0.931096]\n",
      "epoch:15 step:14874 [D loss: 0.682649, acc.: 57.81%] [G loss: 0.960699]\n",
      "epoch:15 step:14875 [D loss: 0.731820, acc.: 48.44%] [G loss: 0.940764]\n",
      "epoch:15 step:14876 [D loss: 0.709591, acc.: 57.03%] [G loss: 0.868943]\n",
      "epoch:15 step:14877 [D loss: 0.615624, acc.: 67.97%] [G loss: 0.862491]\n",
      "epoch:15 step:14878 [D loss: 0.651436, acc.: 61.72%] [G loss: 0.841933]\n",
      "epoch:15 step:14879 [D loss: 0.665893, acc.: 60.16%] [G loss: 0.890681]\n",
      "epoch:15 step:14880 [D loss: 0.649068, acc.: 62.50%] [G loss: 0.883155]\n",
      "epoch:15 step:14881 [D loss: 0.628409, acc.: 60.94%] [G loss: 0.910687]\n",
      "epoch:15 step:14882 [D loss: 0.668512, acc.: 63.28%] [G loss: 0.895403]\n",
      "epoch:15 step:14883 [D loss: 0.689494, acc.: 53.12%] [G loss: 0.929618]\n",
      "epoch:15 step:14884 [D loss: 0.656189, acc.: 66.41%] [G loss: 0.925611]\n",
      "epoch:15 step:14885 [D loss: 0.663315, acc.: 62.50%] [G loss: 0.868921]\n",
      "epoch:15 step:14886 [D loss: 0.680209, acc.: 54.69%] [G loss: 0.906501]\n",
      "epoch:15 step:14887 [D loss: 0.669531, acc.: 57.03%] [G loss: 0.875846]\n",
      "epoch:15 step:14888 [D loss: 0.673267, acc.: 57.03%] [G loss: 0.902163]\n",
      "epoch:15 step:14889 [D loss: 0.670373, acc.: 54.69%] [G loss: 0.896083]\n",
      "epoch:15 step:14890 [D loss: 0.632547, acc.: 68.75%] [G loss: 0.888891]\n",
      "epoch:15 step:14891 [D loss: 0.665775, acc.: 64.06%] [G loss: 0.949564]\n",
      "epoch:15 step:14892 [D loss: 0.650132, acc.: 58.59%] [G loss: 0.854347]\n",
      "epoch:15 step:14893 [D loss: 0.633333, acc.: 59.38%] [G loss: 0.903663]\n",
      "epoch:15 step:14894 [D loss: 0.659289, acc.: 57.81%] [G loss: 0.875537]\n",
      "epoch:15 step:14895 [D loss: 0.642955, acc.: 65.62%] [G loss: 0.828594]\n",
      "epoch:15 step:14896 [D loss: 0.651602, acc.: 63.28%] [G loss: 0.864541]\n",
      "epoch:15 step:14897 [D loss: 0.614227, acc.: 67.97%] [G loss: 0.878413]\n",
      "epoch:15 step:14898 [D loss: 0.663273, acc.: 60.94%] [G loss: 0.910869]\n",
      "epoch:15 step:14899 [D loss: 0.659296, acc.: 57.81%] [G loss: 0.930639]\n",
      "epoch:15 step:14900 [D loss: 0.665145, acc.: 61.72%] [G loss: 0.914801]\n",
      "epoch:15 step:14901 [D loss: 0.703997, acc.: 55.47%] [G loss: 0.932568]\n",
      "epoch:15 step:14902 [D loss: 0.720788, acc.: 52.34%] [G loss: 0.865394]\n",
      "epoch:15 step:14903 [D loss: 0.707290, acc.: 50.00%] [G loss: 0.893807]\n",
      "epoch:15 step:14904 [D loss: 0.647651, acc.: 60.16%] [G loss: 0.871858]\n",
      "epoch:15 step:14905 [D loss: 0.706228, acc.: 57.03%] [G loss: 0.910075]\n",
      "epoch:15 step:14906 [D loss: 0.655783, acc.: 62.50%] [G loss: 0.881887]\n",
      "epoch:15 step:14907 [D loss: 0.663819, acc.: 60.16%] [G loss: 0.881573]\n",
      "epoch:15 step:14908 [D loss: 0.628473, acc.: 65.62%] [G loss: 0.924181]\n",
      "epoch:15 step:14909 [D loss: 0.601040, acc.: 68.75%] [G loss: 0.875530]\n",
      "epoch:15 step:14910 [D loss: 0.650130, acc.: 62.50%] [G loss: 0.929815]\n",
      "epoch:15 step:14911 [D loss: 0.657156, acc.: 60.16%] [G loss: 0.897450]\n",
      "epoch:15 step:14912 [D loss: 0.642346, acc.: 61.72%] [G loss: 0.925549]\n",
      "epoch:15 step:14913 [D loss: 0.790113, acc.: 36.72%] [G loss: 0.890151]\n",
      "epoch:15 step:14914 [D loss: 0.704001, acc.: 57.81%] [G loss: 0.866157]\n",
      "epoch:15 step:14915 [D loss: 0.660469, acc.: 59.38%] [G loss: 0.905155]\n",
      "epoch:15 step:14916 [D loss: 0.783666, acc.: 41.41%] [G loss: 0.874881]\n",
      "epoch:15 step:14917 [D loss: 0.660265, acc.: 57.03%] [G loss: 0.897885]\n",
      "epoch:15 step:14918 [D loss: 0.663985, acc.: 59.38%] [G loss: 0.906145]\n",
      "epoch:15 step:14919 [D loss: 0.681779, acc.: 55.47%] [G loss: 0.841426]\n",
      "epoch:15 step:14920 [D loss: 0.675849, acc.: 63.28%] [G loss: 0.853590]\n",
      "epoch:15 step:14921 [D loss: 0.665729, acc.: 63.28%] [G loss: 0.870928]\n",
      "epoch:15 step:14922 [D loss: 0.687194, acc.: 54.69%] [G loss: 0.835247]\n",
      "epoch:15 step:14923 [D loss: 0.638593, acc.: 60.94%] [G loss: 0.939345]\n",
      "epoch:15 step:14924 [D loss: 0.639481, acc.: 58.59%] [G loss: 0.925360]\n",
      "epoch:15 step:14925 [D loss: 0.603035, acc.: 72.66%] [G loss: 0.983280]\n",
      "epoch:15 step:14926 [D loss: 0.606015, acc.: 64.06%] [G loss: 0.906042]\n",
      "epoch:15 step:14927 [D loss: 0.598607, acc.: 71.09%] [G loss: 0.913396]\n",
      "epoch:15 step:14928 [D loss: 0.649382, acc.: 60.94%] [G loss: 0.931821]\n",
      "epoch:15 step:14929 [D loss: 0.654905, acc.: 57.81%] [G loss: 0.905819]\n",
      "epoch:15 step:14930 [D loss: 0.633311, acc.: 65.62%] [G loss: 0.930584]\n",
      "epoch:15 step:14931 [D loss: 0.651435, acc.: 67.19%] [G loss: 0.854439]\n",
      "epoch:15 step:14932 [D loss: 0.679928, acc.: 62.50%] [G loss: 0.816986]\n",
      "epoch:15 step:14933 [D loss: 0.691324, acc.: 53.12%] [G loss: 0.827716]\n",
      "epoch:15 step:14934 [D loss: 0.633038, acc.: 62.50%] [G loss: 0.842801]\n",
      "epoch:15 step:14935 [D loss: 0.648025, acc.: 59.38%] [G loss: 0.857505]\n",
      "epoch:15 step:14936 [D loss: 0.654101, acc.: 60.94%] [G loss: 0.866697]\n",
      "epoch:15 step:14937 [D loss: 0.707842, acc.: 51.56%] [G loss: 0.799814]\n",
      "epoch:15 step:14938 [D loss: 0.713286, acc.: 52.34%] [G loss: 0.857915]\n",
      "epoch:15 step:14939 [D loss: 0.641062, acc.: 64.84%] [G loss: 0.892176]\n",
      "epoch:15 step:14940 [D loss: 0.666569, acc.: 57.03%] [G loss: 0.912018]\n",
      "epoch:15 step:14941 [D loss: 0.625434, acc.: 74.22%] [G loss: 0.959343]\n",
      "epoch:15 step:14942 [D loss: 0.667014, acc.: 56.25%] [G loss: 0.893897]\n",
      "epoch:15 step:14943 [D loss: 0.681695, acc.: 60.16%] [G loss: 0.895405]\n",
      "epoch:15 step:14944 [D loss: 0.649148, acc.: 60.16%] [G loss: 0.852537]\n",
      "epoch:15 step:14945 [D loss: 0.604713, acc.: 68.75%] [G loss: 0.899702]\n",
      "epoch:15 step:14946 [D loss: 0.682191, acc.: 56.25%] [G loss: 0.860195]\n",
      "epoch:15 step:14947 [D loss: 0.734661, acc.: 48.44%] [G loss: 0.837337]\n",
      "epoch:15 step:14948 [D loss: 0.693334, acc.: 57.03%] [G loss: 0.876428]\n",
      "epoch:15 step:14949 [D loss: 0.651779, acc.: 61.72%] [G loss: 0.916734]\n",
      "epoch:15 step:14950 [D loss: 0.648921, acc.: 63.28%] [G loss: 0.922917]\n",
      "epoch:15 step:14951 [D loss: 0.662246, acc.: 61.72%] [G loss: 0.962309]\n",
      "epoch:15 step:14952 [D loss: 0.638646, acc.: 61.72%] [G loss: 0.995664]\n",
      "epoch:15 step:14953 [D loss: 0.606573, acc.: 67.97%] [G loss: 0.977630]\n",
      "epoch:15 step:14954 [D loss: 0.594213, acc.: 67.19%] [G loss: 0.991735]\n",
      "epoch:15 step:14955 [D loss: 0.614446, acc.: 65.62%] [G loss: 1.031581]\n",
      "epoch:15 step:14956 [D loss: 0.669461, acc.: 59.38%] [G loss: 0.920803]\n",
      "epoch:15 step:14957 [D loss: 0.688284, acc.: 57.81%] [G loss: 0.932492]\n",
      "epoch:15 step:14958 [D loss: 0.653494, acc.: 60.16%] [G loss: 0.937423]\n",
      "epoch:15 step:14959 [D loss: 0.701153, acc.: 50.78%] [G loss: 0.889507]\n",
      "epoch:15 step:14960 [D loss: 0.673205, acc.: 54.69%] [G loss: 0.946603]\n",
      "epoch:15 step:14961 [D loss: 0.642017, acc.: 60.94%] [G loss: 0.954888]\n",
      "epoch:15 step:14962 [D loss: 0.712792, acc.: 54.69%] [G loss: 0.946690]\n",
      "epoch:15 step:14963 [D loss: 0.582583, acc.: 71.88%] [G loss: 0.908377]\n",
      "epoch:15 step:14964 [D loss: 0.603110, acc.: 64.06%] [G loss: 0.938342]\n",
      "epoch:15 step:14965 [D loss: 0.608249, acc.: 62.50%] [G loss: 0.931517]\n",
      "epoch:15 step:14966 [D loss: 0.646880, acc.: 66.41%] [G loss: 0.933089]\n",
      "epoch:15 step:14967 [D loss: 0.635655, acc.: 60.94%] [G loss: 0.945034]\n",
      "epoch:15 step:14968 [D loss: 0.673456, acc.: 60.16%] [G loss: 1.010908]\n",
      "epoch:15 step:14969 [D loss: 0.602819, acc.: 67.19%] [G loss: 1.009063]\n",
      "epoch:15 step:14970 [D loss: 0.756124, acc.: 50.00%] [G loss: 0.820801]\n",
      "epoch:15 step:14971 [D loss: 0.647221, acc.: 57.81%] [G loss: 0.853320]\n",
      "epoch:15 step:14972 [D loss: 0.672552, acc.: 61.72%] [G loss: 0.888103]\n",
      "epoch:15 step:14973 [D loss: 0.569378, acc.: 69.53%] [G loss: 0.943540]\n",
      "epoch:15 step:14974 [D loss: 0.590337, acc.: 69.53%] [G loss: 0.967231]\n",
      "epoch:15 step:14975 [D loss: 0.740719, acc.: 50.00%] [G loss: 0.953467]\n",
      "epoch:15 step:14976 [D loss: 0.621371, acc.: 67.97%] [G loss: 0.937461]\n",
      "epoch:15 step:14977 [D loss: 0.679373, acc.: 56.25%] [G loss: 0.835215]\n",
      "epoch:15 step:14978 [D loss: 0.620031, acc.: 67.19%] [G loss: 0.902570]\n",
      "epoch:15 step:14979 [D loss: 0.566383, acc.: 80.47%] [G loss: 0.959025]\n",
      "epoch:15 step:14980 [D loss: 0.590942, acc.: 72.66%] [G loss: 0.993218]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14981 [D loss: 0.595453, acc.: 68.75%] [G loss: 1.078483]\n",
      "epoch:15 step:14982 [D loss: 0.614536, acc.: 64.84%] [G loss: 1.071638]\n",
      "epoch:15 step:14983 [D loss: 0.768554, acc.: 55.47%] [G loss: 1.046731]\n",
      "epoch:15 step:14984 [D loss: 0.654358, acc.: 66.41%] [G loss: 1.238057]\n",
      "epoch:15 step:14985 [D loss: 0.609358, acc.: 66.41%] [G loss: 1.090847]\n",
      "epoch:15 step:14986 [D loss: 0.671381, acc.: 60.94%] [G loss: 0.921220]\n",
      "epoch:15 step:14987 [D loss: 0.764717, acc.: 49.22%] [G loss: 0.943551]\n",
      "epoch:15 step:14988 [D loss: 0.604724, acc.: 68.75%] [G loss: 0.959746]\n",
      "epoch:15 step:14989 [D loss: 0.678908, acc.: 57.81%] [G loss: 0.898636]\n",
      "epoch:15 step:14990 [D loss: 0.613170, acc.: 72.66%] [G loss: 0.975090]\n",
      "epoch:15 step:14991 [D loss: 0.513032, acc.: 77.34%] [G loss: 1.071458]\n",
      "epoch:15 step:14992 [D loss: 0.672660, acc.: 57.03%] [G loss: 1.084658]\n",
      "epoch:16 step:14993 [D loss: 0.729956, acc.: 58.59%] [G loss: 1.004717]\n",
      "epoch:16 step:14994 [D loss: 0.786384, acc.: 56.25%] [G loss: 0.956144]\n",
      "epoch:16 step:14995 [D loss: 0.739484, acc.: 48.44%] [G loss: 0.997762]\n",
      "epoch:16 step:14996 [D loss: 0.744146, acc.: 53.12%] [G loss: 0.966917]\n",
      "epoch:16 step:14997 [D loss: 0.745367, acc.: 47.66%] [G loss: 0.947659]\n",
      "epoch:16 step:14998 [D loss: 0.682082, acc.: 59.38%] [G loss: 0.946345]\n",
      "epoch:16 step:14999 [D loss: 0.687393, acc.: 57.81%] [G loss: 0.942926]\n",
      "epoch:16 step:15000 [D loss: 0.620516, acc.: 68.75%] [G loss: 0.914321]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.293879\n",
      "FID: 5.312006\n",
      "0 = 11.93731313645837\n",
      "1 = 0.05574645252658968\n",
      "2 = 0.9262999892234802\n",
      "3 = 0.890999972820282\n",
      "4 = 0.9616000056266785\n",
      "5 = 0.9586830139160156\n",
      "6 = 0.890999972820282\n",
      "7 = 5.61344235429166\n",
      "8 = 0.05199220951117115\n",
      "9 = 0.7025499939918518\n",
      "10 = 0.6818000078201294\n",
      "11 = 0.7232999801635742\n",
      "12 = 0.7113197445869446\n",
      "13 = 0.6818000078201294\n",
      "14 = 8.293949127197266\n",
      "15 = 9.565690040588379\n",
      "16 = 0.09651688486337662\n",
      "17 = 8.293878555297852\n",
      "18 = 5.31200647354126\n",
      "epoch:16 step:15001 [D loss: 0.642764, acc.: 61.72%] [G loss: 0.887130]\n",
      "epoch:16 step:15002 [D loss: 0.657405, acc.: 60.16%] [G loss: 0.975876]\n",
      "epoch:16 step:15003 [D loss: 0.655545, acc.: 59.38%] [G loss: 0.933057]\n",
      "epoch:16 step:15004 [D loss: 0.626652, acc.: 64.06%] [G loss: 0.956433]\n",
      "epoch:16 step:15005 [D loss: 0.613721, acc.: 67.19%] [G loss: 0.936847]\n",
      "epoch:16 step:15006 [D loss: 0.652990, acc.: 62.50%] [G loss: 0.889972]\n",
      "epoch:16 step:15007 [D loss: 0.615997, acc.: 62.50%] [G loss: 0.944054]\n",
      "epoch:16 step:15008 [D loss: 0.601553, acc.: 69.53%] [G loss: 1.014991]\n",
      "epoch:16 step:15009 [D loss: 0.657292, acc.: 60.94%] [G loss: 0.963693]\n",
      "epoch:16 step:15010 [D loss: 0.654952, acc.: 63.28%] [G loss: 1.006920]\n",
      "epoch:16 step:15011 [D loss: 0.713407, acc.: 57.81%] [G loss: 0.936403]\n",
      "epoch:16 step:15012 [D loss: 0.711745, acc.: 50.00%] [G loss: 0.959095]\n",
      "epoch:16 step:15013 [D loss: 0.669588, acc.: 61.72%] [G loss: 0.947281]\n",
      "epoch:16 step:15014 [D loss: 0.642925, acc.: 64.06%] [G loss: 0.956773]\n",
      "epoch:16 step:15015 [D loss: 0.716934, acc.: 51.56%] [G loss: 0.903170]\n",
      "epoch:16 step:15016 [D loss: 0.657941, acc.: 63.28%] [G loss: 0.878928]\n",
      "epoch:16 step:15017 [D loss: 0.672768, acc.: 57.81%] [G loss: 0.906272]\n",
      "epoch:16 step:15018 [D loss: 0.645636, acc.: 63.28%] [G loss: 0.912479]\n",
      "epoch:16 step:15019 [D loss: 0.646972, acc.: 60.94%] [G loss: 0.921808]\n",
      "epoch:16 step:15020 [D loss: 0.643714, acc.: 57.81%] [G loss: 0.927986]\n",
      "epoch:16 step:15021 [D loss: 0.632332, acc.: 67.19%] [G loss: 0.942603]\n",
      "epoch:16 step:15022 [D loss: 0.627035, acc.: 64.06%] [G loss: 0.916640]\n",
      "epoch:16 step:15023 [D loss: 0.697149, acc.: 57.03%] [G loss: 0.873672]\n",
      "epoch:16 step:15024 [D loss: 0.679698, acc.: 54.69%] [G loss: 0.894711]\n",
      "epoch:16 step:15025 [D loss: 0.626739, acc.: 60.94%] [G loss: 0.927070]\n",
      "epoch:16 step:15026 [D loss: 0.669003, acc.: 64.06%] [G loss: 0.865327]\n",
      "epoch:16 step:15027 [D loss: 0.668129, acc.: 58.59%] [G loss: 0.875759]\n",
      "epoch:16 step:15028 [D loss: 0.649926, acc.: 65.62%] [G loss: 0.906900]\n",
      "epoch:16 step:15029 [D loss: 0.702387, acc.: 53.12%] [G loss: 0.851127]\n",
      "epoch:16 step:15030 [D loss: 0.691038, acc.: 54.69%] [G loss: 0.850073]\n",
      "epoch:16 step:15031 [D loss: 0.712239, acc.: 56.25%] [G loss: 0.866680]\n",
      "epoch:16 step:15032 [D loss: 0.598425, acc.: 72.66%] [G loss: 0.894527]\n",
      "epoch:16 step:15033 [D loss: 0.660691, acc.: 62.50%] [G loss: 0.894971]\n",
      "epoch:16 step:15034 [D loss: 0.661919, acc.: 61.72%] [G loss: 0.929609]\n",
      "epoch:16 step:15035 [D loss: 0.644821, acc.: 64.06%] [G loss: 0.848568]\n",
      "epoch:16 step:15036 [D loss: 0.682819, acc.: 58.59%] [G loss: 0.851008]\n",
      "epoch:16 step:15037 [D loss: 0.703887, acc.: 57.81%] [G loss: 0.902111]\n",
      "epoch:16 step:15038 [D loss: 0.643362, acc.: 61.72%] [G loss: 0.879419]\n",
      "epoch:16 step:15039 [D loss: 0.678442, acc.: 59.38%] [G loss: 0.895276]\n",
      "epoch:16 step:15040 [D loss: 0.618870, acc.: 71.09%] [G loss: 0.860196]\n",
      "epoch:16 step:15041 [D loss: 0.622555, acc.: 64.06%] [G loss: 0.903339]\n",
      "epoch:16 step:15042 [D loss: 0.630159, acc.: 67.19%] [G loss: 0.966855]\n",
      "epoch:16 step:15043 [D loss: 0.745025, acc.: 42.97%] [G loss: 0.857935]\n",
      "epoch:16 step:15044 [D loss: 0.644470, acc.: 61.72%] [G loss: 0.864660]\n",
      "epoch:16 step:15045 [D loss: 0.644680, acc.: 64.84%] [G loss: 0.894633]\n",
      "epoch:16 step:15046 [D loss: 0.636064, acc.: 62.50%] [G loss: 0.920297]\n",
      "epoch:16 step:15047 [D loss: 0.664260, acc.: 64.84%] [G loss: 0.938588]\n",
      "epoch:16 step:15048 [D loss: 0.696384, acc.: 53.91%] [G loss: 0.882417]\n",
      "epoch:16 step:15049 [D loss: 0.676323, acc.: 53.12%] [G loss: 0.950830]\n",
      "epoch:16 step:15050 [D loss: 0.639793, acc.: 64.06%] [G loss: 0.890747]\n",
      "epoch:16 step:15051 [D loss: 0.666454, acc.: 56.25%] [G loss: 0.948774]\n",
      "epoch:16 step:15052 [D loss: 0.656119, acc.: 62.50%] [G loss: 0.911284]\n",
      "epoch:16 step:15053 [D loss: 0.703673, acc.: 52.34%] [G loss: 0.866202]\n",
      "epoch:16 step:15054 [D loss: 0.654016, acc.: 62.50%] [G loss: 0.852773]\n",
      "epoch:16 step:15055 [D loss: 0.618395, acc.: 66.41%] [G loss: 0.929769]\n",
      "epoch:16 step:15056 [D loss: 0.711058, acc.: 53.91%] [G loss: 0.967178]\n",
      "epoch:16 step:15057 [D loss: 0.672605, acc.: 60.16%] [G loss: 0.897641]\n",
      "epoch:16 step:15058 [D loss: 0.646717, acc.: 67.19%] [G loss: 0.875468]\n",
      "epoch:16 step:15059 [D loss: 0.673956, acc.: 56.25%] [G loss: 0.887306]\n",
      "epoch:16 step:15060 [D loss: 0.657944, acc.: 61.72%] [G loss: 0.922219]\n",
      "epoch:16 step:15061 [D loss: 0.651736, acc.: 61.72%] [G loss: 0.879858]\n",
      "epoch:16 step:15062 [D loss: 0.646258, acc.: 60.94%] [G loss: 0.912209]\n",
      "epoch:16 step:15063 [D loss: 0.667224, acc.: 57.81%] [G loss: 0.925618]\n",
      "epoch:16 step:15064 [D loss: 0.658441, acc.: 66.41%] [G loss: 0.915816]\n",
      "epoch:16 step:15065 [D loss: 0.667895, acc.: 59.38%] [G loss: 0.883476]\n",
      "epoch:16 step:15066 [D loss: 0.599898, acc.: 66.41%] [G loss: 0.913400]\n",
      "epoch:16 step:15067 [D loss: 0.665595, acc.: 60.16%] [G loss: 0.978859]\n",
      "epoch:16 step:15068 [D loss: 0.571664, acc.: 71.88%] [G loss: 0.937897]\n",
      "epoch:16 step:15069 [D loss: 0.601613, acc.: 67.97%] [G loss: 1.034706]\n",
      "epoch:16 step:15070 [D loss: 0.711363, acc.: 53.91%] [G loss: 0.871673]\n",
      "epoch:16 step:15071 [D loss: 0.679275, acc.: 57.03%] [G loss: 0.842839]\n",
      "epoch:16 step:15072 [D loss: 0.675330, acc.: 60.16%] [G loss: 0.872690]\n",
      "epoch:16 step:15073 [D loss: 0.681927, acc.: 55.47%] [G loss: 0.895692]\n",
      "epoch:16 step:15074 [D loss: 0.642577, acc.: 63.28%] [G loss: 0.872017]\n",
      "epoch:16 step:15075 [D loss: 0.655048, acc.: 67.97%] [G loss: 0.848055]\n",
      "epoch:16 step:15076 [D loss: 0.629941, acc.: 62.50%] [G loss: 0.929276]\n",
      "epoch:16 step:15077 [D loss: 0.667354, acc.: 64.06%] [G loss: 0.983467]\n",
      "epoch:16 step:15078 [D loss: 0.618056, acc.: 67.19%] [G loss: 0.959628]\n",
      "epoch:16 step:15079 [D loss: 0.639973, acc.: 60.94%] [G loss: 0.896564]\n",
      "epoch:16 step:15080 [D loss: 0.643634, acc.: 64.06%] [G loss: 0.972871]\n",
      "epoch:16 step:15081 [D loss: 0.699029, acc.: 60.16%] [G loss: 0.970616]\n",
      "epoch:16 step:15082 [D loss: 0.594058, acc.: 67.97%] [G loss: 0.900550]\n",
      "epoch:16 step:15083 [D loss: 0.644682, acc.: 66.41%] [G loss: 0.905845]\n",
      "epoch:16 step:15084 [D loss: 0.662330, acc.: 60.94%] [G loss: 0.913698]\n",
      "epoch:16 step:15085 [D loss: 0.594569, acc.: 67.19%] [G loss: 0.918392]\n",
      "epoch:16 step:15086 [D loss: 0.648040, acc.: 60.94%] [G loss: 0.969041]\n",
      "epoch:16 step:15087 [D loss: 0.641338, acc.: 60.16%] [G loss: 0.979613]\n",
      "epoch:16 step:15088 [D loss: 0.657987, acc.: 58.59%] [G loss: 0.878852]\n",
      "epoch:16 step:15089 [D loss: 0.612632, acc.: 64.06%] [G loss: 0.885633]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15090 [D loss: 0.680337, acc.: 62.50%] [G loss: 0.905456]\n",
      "epoch:16 step:15091 [D loss: 0.637539, acc.: 61.72%] [G loss: 0.912542]\n",
      "epoch:16 step:15092 [D loss: 0.595680, acc.: 69.53%] [G loss: 0.977629]\n",
      "epoch:16 step:15093 [D loss: 0.687278, acc.: 56.25%] [G loss: 0.947888]\n",
      "epoch:16 step:15094 [D loss: 0.740623, acc.: 49.22%] [G loss: 0.823384]\n",
      "epoch:16 step:15095 [D loss: 0.662315, acc.: 57.03%] [G loss: 0.916953]\n",
      "epoch:16 step:15096 [D loss: 0.671351, acc.: 60.16%] [G loss: 0.946425]\n",
      "epoch:16 step:15097 [D loss: 0.695860, acc.: 57.03%] [G loss: 0.883956]\n",
      "epoch:16 step:15098 [D loss: 0.647174, acc.: 62.50%] [G loss: 0.866429]\n",
      "epoch:16 step:15099 [D loss: 0.599996, acc.: 71.88%] [G loss: 0.951373]\n",
      "epoch:16 step:15100 [D loss: 0.685844, acc.: 55.47%] [G loss: 0.963794]\n",
      "epoch:16 step:15101 [D loss: 0.733866, acc.: 47.66%] [G loss: 0.885541]\n",
      "epoch:16 step:15102 [D loss: 0.695561, acc.: 54.69%] [G loss: 0.888365]\n",
      "epoch:16 step:15103 [D loss: 0.660743, acc.: 64.06%] [G loss: 0.852902]\n",
      "epoch:16 step:15104 [D loss: 0.605931, acc.: 65.62%] [G loss: 0.975765]\n",
      "epoch:16 step:15105 [D loss: 0.619540, acc.: 64.84%] [G loss: 0.949536]\n",
      "epoch:16 step:15106 [D loss: 0.629466, acc.: 65.62%] [G loss: 0.986758]\n",
      "epoch:16 step:15107 [D loss: 0.636853, acc.: 60.94%] [G loss: 1.039582]\n",
      "epoch:16 step:15108 [D loss: 0.614394, acc.: 66.41%] [G loss: 0.998008]\n",
      "epoch:16 step:15109 [D loss: 0.599180, acc.: 67.97%] [G loss: 1.007674]\n",
      "epoch:16 step:15110 [D loss: 0.596980, acc.: 70.31%] [G loss: 1.005876]\n",
      "epoch:16 step:15111 [D loss: 0.546501, acc.: 74.22%] [G loss: 1.012030]\n",
      "epoch:16 step:15112 [D loss: 0.682896, acc.: 52.34%] [G loss: 0.949514]\n",
      "epoch:16 step:15113 [D loss: 0.675961, acc.: 57.03%] [G loss: 0.890000]\n",
      "epoch:16 step:15114 [D loss: 0.651750, acc.: 60.94%] [G loss: 0.944670]\n",
      "epoch:16 step:15115 [D loss: 0.709427, acc.: 53.12%] [G loss: 0.993477]\n",
      "epoch:16 step:15116 [D loss: 0.689014, acc.: 51.56%] [G loss: 0.965745]\n",
      "epoch:16 step:15117 [D loss: 0.713962, acc.: 50.78%] [G loss: 0.940855]\n",
      "epoch:16 step:15118 [D loss: 0.643178, acc.: 60.16%] [G loss: 0.929656]\n",
      "epoch:16 step:15119 [D loss: 0.619971, acc.: 67.97%] [G loss: 1.005014]\n",
      "epoch:16 step:15120 [D loss: 0.679305, acc.: 55.47%] [G loss: 0.894782]\n",
      "epoch:16 step:15121 [D loss: 0.674140, acc.: 52.34%] [G loss: 0.896822]\n",
      "epoch:16 step:15122 [D loss: 0.685428, acc.: 53.91%] [G loss: 0.820660]\n",
      "epoch:16 step:15123 [D loss: 0.621677, acc.: 70.31%] [G loss: 0.895064]\n",
      "epoch:16 step:15124 [D loss: 0.664881, acc.: 59.38%] [G loss: 0.936447]\n",
      "epoch:16 step:15125 [D loss: 0.643202, acc.: 64.06%] [G loss: 0.968190]\n",
      "epoch:16 step:15126 [D loss: 0.596532, acc.: 67.97%] [G loss: 0.958649]\n",
      "epoch:16 step:15127 [D loss: 0.645555, acc.: 65.62%] [G loss: 0.952230]\n",
      "epoch:16 step:15128 [D loss: 0.626357, acc.: 62.50%] [G loss: 0.962805]\n",
      "epoch:16 step:15129 [D loss: 0.694516, acc.: 54.69%] [G loss: 0.855534]\n",
      "epoch:16 step:15130 [D loss: 0.672701, acc.: 57.03%] [G loss: 0.896951]\n",
      "epoch:16 step:15131 [D loss: 0.704053, acc.: 55.47%] [G loss: 0.841200]\n",
      "epoch:16 step:15132 [D loss: 0.743334, acc.: 47.66%] [G loss: 0.870258]\n",
      "epoch:16 step:15133 [D loss: 0.649293, acc.: 59.38%] [G loss: 0.878495]\n",
      "epoch:16 step:15134 [D loss: 0.684519, acc.: 57.03%] [G loss: 0.882354]\n",
      "epoch:16 step:15135 [D loss: 0.706240, acc.: 51.56%] [G loss: 0.904520]\n",
      "epoch:16 step:15136 [D loss: 0.644947, acc.: 64.06%] [G loss: 0.885434]\n",
      "epoch:16 step:15137 [D loss: 0.673787, acc.: 60.16%] [G loss: 0.903437]\n",
      "epoch:16 step:15138 [D loss: 0.600933, acc.: 68.75%] [G loss: 0.930194]\n",
      "epoch:16 step:15139 [D loss: 0.676896, acc.: 63.28%] [G loss: 0.907755]\n",
      "epoch:16 step:15140 [D loss: 0.702886, acc.: 55.47%] [G loss: 0.878874]\n",
      "epoch:16 step:15141 [D loss: 0.658600, acc.: 58.59%] [G loss: 0.897106]\n",
      "epoch:16 step:15142 [D loss: 0.675232, acc.: 59.38%] [G loss: 0.880170]\n",
      "epoch:16 step:15143 [D loss: 0.665118, acc.: 58.59%] [G loss: 0.845083]\n",
      "epoch:16 step:15144 [D loss: 0.682845, acc.: 63.28%] [G loss: 0.882641]\n",
      "epoch:16 step:15145 [D loss: 0.690482, acc.: 54.69%] [G loss: 0.862677]\n",
      "epoch:16 step:15146 [D loss: 0.624215, acc.: 64.06%] [G loss: 0.896330]\n",
      "epoch:16 step:15147 [D loss: 0.667138, acc.: 61.72%] [G loss: 0.888951]\n",
      "epoch:16 step:15148 [D loss: 0.646594, acc.: 67.97%] [G loss: 0.890236]\n",
      "epoch:16 step:15149 [D loss: 0.659920, acc.: 63.28%] [G loss: 0.967174]\n",
      "epoch:16 step:15150 [D loss: 0.656451, acc.: 60.16%] [G loss: 0.935982]\n",
      "epoch:16 step:15151 [D loss: 0.590642, acc.: 73.44%] [G loss: 0.945407]\n",
      "epoch:16 step:15152 [D loss: 0.740591, acc.: 54.69%] [G loss: 0.893471]\n",
      "epoch:16 step:15153 [D loss: 0.673799, acc.: 57.81%] [G loss: 0.960836]\n",
      "epoch:16 step:15154 [D loss: 0.638541, acc.: 67.97%] [G loss: 0.914841]\n",
      "epoch:16 step:15155 [D loss: 0.693675, acc.: 57.03%] [G loss: 0.892227]\n",
      "epoch:16 step:15156 [D loss: 0.629839, acc.: 64.84%] [G loss: 0.952276]\n",
      "epoch:16 step:15157 [D loss: 0.656380, acc.: 64.84%] [G loss: 0.844203]\n",
      "epoch:16 step:15158 [D loss: 0.660730, acc.: 56.25%] [G loss: 0.882222]\n",
      "epoch:16 step:15159 [D loss: 0.696182, acc.: 48.44%] [G loss: 0.850025]\n",
      "epoch:16 step:15160 [D loss: 0.654454, acc.: 61.72%] [G loss: 0.905435]\n",
      "epoch:16 step:15161 [D loss: 0.671658, acc.: 53.91%] [G loss: 0.883407]\n",
      "epoch:16 step:15162 [D loss: 0.630552, acc.: 60.94%] [G loss: 0.852856]\n",
      "epoch:16 step:15163 [D loss: 0.620886, acc.: 64.06%] [G loss: 0.897489]\n",
      "epoch:16 step:15164 [D loss: 0.641806, acc.: 61.72%] [G loss: 0.859510]\n",
      "epoch:16 step:15165 [D loss: 0.617480, acc.: 67.97%] [G loss: 0.949955]\n",
      "epoch:16 step:15166 [D loss: 0.689460, acc.: 53.91%] [G loss: 0.887504]\n",
      "epoch:16 step:15167 [D loss: 0.709423, acc.: 50.78%] [G loss: 0.859021]\n",
      "epoch:16 step:15168 [D loss: 0.671271, acc.: 56.25%] [G loss: 0.842583]\n",
      "epoch:16 step:15169 [D loss: 0.675106, acc.: 58.59%] [G loss: 0.840659]\n",
      "epoch:16 step:15170 [D loss: 0.667960, acc.: 53.12%] [G loss: 0.929584]\n",
      "epoch:16 step:15171 [D loss: 0.649235, acc.: 66.41%] [G loss: 0.918430]\n",
      "epoch:16 step:15172 [D loss: 0.659239, acc.: 56.25%] [G loss: 0.975029]\n",
      "epoch:16 step:15173 [D loss: 0.727492, acc.: 49.22%] [G loss: 0.925812]\n",
      "epoch:16 step:15174 [D loss: 0.677918, acc.: 57.81%] [G loss: 0.871118]\n",
      "epoch:16 step:15175 [D loss: 0.655982, acc.: 63.28%] [G loss: 0.906205]\n",
      "epoch:16 step:15176 [D loss: 0.647391, acc.: 62.50%] [G loss: 0.894956]\n",
      "epoch:16 step:15177 [D loss: 0.668187, acc.: 57.81%] [G loss: 0.901432]\n",
      "epoch:16 step:15178 [D loss: 0.707214, acc.: 56.25%] [G loss: 0.889426]\n",
      "epoch:16 step:15179 [D loss: 0.645695, acc.: 54.69%] [G loss: 0.919646]\n",
      "epoch:16 step:15180 [D loss: 0.722340, acc.: 53.12%] [G loss: 0.908040]\n",
      "epoch:16 step:15181 [D loss: 0.687592, acc.: 53.91%] [G loss: 0.824721]\n",
      "epoch:16 step:15182 [D loss: 0.635571, acc.: 69.53%] [G loss: 0.845499]\n",
      "epoch:16 step:15183 [D loss: 0.636652, acc.: 63.28%] [G loss: 0.868295]\n",
      "epoch:16 step:15184 [D loss: 0.611332, acc.: 67.97%] [G loss: 0.844609]\n",
      "epoch:16 step:15185 [D loss: 0.703152, acc.: 48.44%] [G loss: 0.911522]\n",
      "epoch:16 step:15186 [D loss: 0.623684, acc.: 64.84%] [G loss: 0.872048]\n",
      "epoch:16 step:15187 [D loss: 0.635471, acc.: 64.84%] [G loss: 0.899113]\n",
      "epoch:16 step:15188 [D loss: 0.691973, acc.: 57.03%] [G loss: 0.904937]\n",
      "epoch:16 step:15189 [D loss: 0.638104, acc.: 64.84%] [G loss: 0.894790]\n",
      "epoch:16 step:15190 [D loss: 0.635268, acc.: 71.09%] [G loss: 0.944004]\n",
      "epoch:16 step:15191 [D loss: 0.625484, acc.: 62.50%] [G loss: 0.976253]\n",
      "epoch:16 step:15192 [D loss: 0.654501, acc.: 62.50%] [G loss: 0.918912]\n",
      "epoch:16 step:15193 [D loss: 0.658523, acc.: 64.06%] [G loss: 0.913901]\n",
      "epoch:16 step:15194 [D loss: 0.653186, acc.: 64.06%] [G loss: 0.939135]\n",
      "epoch:16 step:15195 [D loss: 0.720301, acc.: 47.66%] [G loss: 0.869797]\n",
      "epoch:16 step:15196 [D loss: 0.672497, acc.: 62.50%] [G loss: 0.942061]\n",
      "epoch:16 step:15197 [D loss: 0.643488, acc.: 62.50%] [G loss: 1.051416]\n",
      "epoch:16 step:15198 [D loss: 0.604171, acc.: 68.75%] [G loss: 0.941920]\n",
      "epoch:16 step:15199 [D loss: 0.656976, acc.: 62.50%] [G loss: 0.869534]\n",
      "epoch:16 step:15200 [D loss: 0.586856, acc.: 66.41%] [G loss: 0.916632]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.128294\n",
      "FID: 6.622422\n",
      "0 = 11.734371562194804\n",
      "1 = 0.04943109151052972\n",
      "2 = 0.9077500104904175\n",
      "3 = 0.8626999855041504\n",
      "4 = 0.9527999758720398\n",
      "5 = 0.9481261968612671\n",
      "6 = 0.8626999855041504\n",
      "7 = 5.565186491844063\n",
      "8 = 0.05395010670677005\n",
      "9 = 0.7049000263214111\n",
      "10 = 0.6836000084877014\n",
      "11 = 0.7261999845504761\n",
      "12 = 0.7140171527862549\n",
      "13 = 0.6836000084877014\n",
      "14 = 8.128362655639648\n",
      "15 = 9.60007095336914\n",
      "16 = 0.08710822463035583\n",
      "17 = 8.128293991088867\n",
      "18 = 6.622422218322754\n",
      "epoch:16 step:15201 [D loss: 0.622463, acc.: 60.16%] [G loss: 0.927902]\n",
      "epoch:16 step:15202 [D loss: 0.741516, acc.: 49.22%] [G loss: 0.941865]\n",
      "epoch:16 step:15203 [D loss: 0.699309, acc.: 50.78%] [G loss: 0.834170]\n",
      "epoch:16 step:15204 [D loss: 0.658676, acc.: 67.97%] [G loss: 0.815324]\n",
      "epoch:16 step:15205 [D loss: 0.671019, acc.: 65.62%] [G loss: 0.921747]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15206 [D loss: 0.707922, acc.: 51.56%] [G loss: 0.874349]\n",
      "epoch:16 step:15207 [D loss: 0.688319, acc.: 54.69%] [G loss: 0.845695]\n",
      "epoch:16 step:15208 [D loss: 0.635548, acc.: 65.62%] [G loss: 0.838104]\n",
      "epoch:16 step:15209 [D loss: 0.635166, acc.: 70.31%] [G loss: 0.869185]\n",
      "epoch:16 step:15210 [D loss: 0.625494, acc.: 64.84%] [G loss: 0.895319]\n",
      "epoch:16 step:15211 [D loss: 0.631574, acc.: 64.06%] [G loss: 0.911425]\n",
      "epoch:16 step:15212 [D loss: 0.725635, acc.: 53.12%] [G loss: 0.953799]\n",
      "epoch:16 step:15213 [D loss: 0.632990, acc.: 61.72%] [G loss: 0.941398]\n",
      "epoch:16 step:15214 [D loss: 0.615823, acc.: 65.62%] [G loss: 1.005421]\n",
      "epoch:16 step:15215 [D loss: 0.623342, acc.: 62.50%] [G loss: 0.937114]\n",
      "epoch:16 step:15216 [D loss: 0.718814, acc.: 53.91%] [G loss: 0.960157]\n",
      "epoch:16 step:15217 [D loss: 0.677169, acc.: 55.47%] [G loss: 0.884093]\n",
      "epoch:16 step:15218 [D loss: 0.718308, acc.: 53.12%] [G loss: 0.836909]\n",
      "epoch:16 step:15219 [D loss: 0.690784, acc.: 58.59%] [G loss: 0.847795]\n",
      "epoch:16 step:15220 [D loss: 0.665900, acc.: 57.81%] [G loss: 0.905869]\n",
      "epoch:16 step:15221 [D loss: 0.608384, acc.: 69.53%] [G loss: 0.878487]\n",
      "epoch:16 step:15222 [D loss: 0.642560, acc.: 60.94%] [G loss: 0.938532]\n",
      "epoch:16 step:15223 [D loss: 0.549222, acc.: 75.78%] [G loss: 0.980660]\n",
      "epoch:16 step:15224 [D loss: 0.528810, acc.: 76.56%] [G loss: 1.068105]\n",
      "epoch:16 step:15225 [D loss: 0.744661, acc.: 57.81%] [G loss: 0.895076]\n",
      "epoch:16 step:15226 [D loss: 0.686408, acc.: 58.59%] [G loss: 0.911157]\n",
      "epoch:16 step:15227 [D loss: 0.659197, acc.: 63.28%] [G loss: 0.917570]\n",
      "epoch:16 step:15228 [D loss: 0.658076, acc.: 60.94%] [G loss: 0.913064]\n",
      "epoch:16 step:15229 [D loss: 0.662446, acc.: 61.72%] [G loss: 0.927711]\n",
      "epoch:16 step:15230 [D loss: 0.677361, acc.: 58.59%] [G loss: 0.877702]\n",
      "epoch:16 step:15231 [D loss: 0.638901, acc.: 63.28%] [G loss: 0.904430]\n",
      "epoch:16 step:15232 [D loss: 0.631799, acc.: 64.06%] [G loss: 0.942993]\n",
      "epoch:16 step:15233 [D loss: 0.637728, acc.: 63.28%] [G loss: 0.927310]\n",
      "epoch:16 step:15234 [D loss: 0.584295, acc.: 71.09%] [G loss: 0.940182]\n",
      "epoch:16 step:15235 [D loss: 0.632664, acc.: 62.50%] [G loss: 0.977111]\n",
      "epoch:16 step:15236 [D loss: 0.667165, acc.: 61.72%] [G loss: 0.874410]\n",
      "epoch:16 step:15237 [D loss: 0.611339, acc.: 67.19%] [G loss: 0.946581]\n",
      "epoch:16 step:15238 [D loss: 0.657997, acc.: 57.03%] [G loss: 0.915783]\n",
      "epoch:16 step:15239 [D loss: 0.659348, acc.: 56.25%] [G loss: 0.962956]\n",
      "epoch:16 step:15240 [D loss: 0.611336, acc.: 67.97%] [G loss: 0.960631]\n",
      "epoch:16 step:15241 [D loss: 0.755147, acc.: 50.00%] [G loss: 0.956411]\n",
      "epoch:16 step:15242 [D loss: 0.743656, acc.: 49.22%] [G loss: 0.917780]\n",
      "epoch:16 step:15243 [D loss: 0.696527, acc.: 53.12%] [G loss: 0.890163]\n",
      "epoch:16 step:15244 [D loss: 0.663042, acc.: 59.38%] [G loss: 0.925698]\n",
      "epoch:16 step:15245 [D loss: 0.646810, acc.: 60.16%] [G loss: 0.936421]\n",
      "epoch:16 step:15246 [D loss: 0.625869, acc.: 70.31%] [G loss: 0.930640]\n",
      "epoch:16 step:15247 [D loss: 0.651368, acc.: 59.38%] [G loss: 0.878553]\n",
      "epoch:16 step:15248 [D loss: 0.660962, acc.: 60.94%] [G loss: 0.876117]\n",
      "epoch:16 step:15249 [D loss: 0.635733, acc.: 64.06%] [G loss: 0.860264]\n",
      "epoch:16 step:15250 [D loss: 0.624441, acc.: 64.84%] [G loss: 0.923711]\n",
      "epoch:16 step:15251 [D loss: 0.628834, acc.: 64.06%] [G loss: 0.850477]\n",
      "epoch:16 step:15252 [D loss: 0.661828, acc.: 60.16%] [G loss: 0.900798]\n",
      "epoch:16 step:15253 [D loss: 0.618872, acc.: 68.75%] [G loss: 0.963848]\n",
      "epoch:16 step:15254 [D loss: 0.638645, acc.: 60.16%] [G loss: 0.905400]\n",
      "epoch:16 step:15255 [D loss: 0.749536, acc.: 48.44%] [G loss: 0.835524]\n",
      "epoch:16 step:15256 [D loss: 0.662088, acc.: 59.38%] [G loss: 0.858537]\n",
      "epoch:16 step:15257 [D loss: 0.689494, acc.: 53.12%] [G loss: 0.895227]\n",
      "epoch:16 step:15258 [D loss: 0.655811, acc.: 56.25%] [G loss: 0.863538]\n",
      "epoch:16 step:15259 [D loss: 0.681922, acc.: 58.59%] [G loss: 0.893236]\n",
      "epoch:16 step:15260 [D loss: 0.627146, acc.: 65.62%] [G loss: 0.910404]\n",
      "epoch:16 step:15261 [D loss: 0.659989, acc.: 56.25%] [G loss: 0.915672]\n",
      "epoch:16 step:15262 [D loss: 0.646274, acc.: 58.59%] [G loss: 0.890910]\n",
      "epoch:16 step:15263 [D loss: 0.663471, acc.: 60.16%] [G loss: 0.917415]\n",
      "epoch:16 step:15264 [D loss: 0.609563, acc.: 70.31%] [G loss: 0.951390]\n",
      "epoch:16 step:15265 [D loss: 0.654790, acc.: 59.38%] [G loss: 0.933507]\n",
      "epoch:16 step:15266 [D loss: 0.662642, acc.: 63.28%] [G loss: 0.898364]\n",
      "epoch:16 step:15267 [D loss: 0.681633, acc.: 55.47%] [G loss: 0.917838]\n",
      "epoch:16 step:15268 [D loss: 0.634062, acc.: 67.19%] [G loss: 0.906249]\n",
      "epoch:16 step:15269 [D loss: 0.700199, acc.: 53.91%] [G loss: 0.903458]\n",
      "epoch:16 step:15270 [D loss: 0.693547, acc.: 53.12%] [G loss: 0.883417]\n",
      "epoch:16 step:15271 [D loss: 0.633638, acc.: 70.31%] [G loss: 0.972293]\n",
      "epoch:16 step:15272 [D loss: 0.612495, acc.: 64.84%] [G loss: 0.918384]\n",
      "epoch:16 step:15273 [D loss: 0.695312, acc.: 60.16%] [G loss: 0.892834]\n",
      "epoch:16 step:15274 [D loss: 0.665956, acc.: 60.94%] [G loss: 0.868355]\n",
      "epoch:16 step:15275 [D loss: 0.613182, acc.: 67.19%] [G loss: 0.877537]\n",
      "epoch:16 step:15276 [D loss: 0.667781, acc.: 58.59%] [G loss: 0.984063]\n",
      "epoch:16 step:15277 [D loss: 0.673049, acc.: 60.16%] [G loss: 0.930323]\n",
      "epoch:16 step:15278 [D loss: 0.615541, acc.: 66.41%] [G loss: 0.943912]\n",
      "epoch:16 step:15279 [D loss: 0.667573, acc.: 63.28%] [G loss: 0.886928]\n",
      "epoch:16 step:15280 [D loss: 0.675428, acc.: 54.69%] [G loss: 0.904952]\n",
      "epoch:16 step:15281 [D loss: 0.591414, acc.: 67.19%] [G loss: 0.989259]\n",
      "epoch:16 step:15282 [D loss: 0.677905, acc.: 57.03%] [G loss: 0.863926]\n",
      "epoch:16 step:15283 [D loss: 0.733997, acc.: 48.44%] [G loss: 0.864936]\n",
      "epoch:16 step:15284 [D loss: 0.654916, acc.: 58.59%] [G loss: 0.908866]\n",
      "epoch:16 step:15285 [D loss: 0.644773, acc.: 58.59%] [G loss: 0.925217]\n",
      "epoch:16 step:15286 [D loss: 0.685945, acc.: 59.38%] [G loss: 0.838261]\n",
      "epoch:16 step:15287 [D loss: 0.656253, acc.: 63.28%] [G loss: 0.876753]\n",
      "epoch:16 step:15288 [D loss: 0.640533, acc.: 65.62%] [G loss: 0.950008]\n",
      "epoch:16 step:15289 [D loss: 0.651294, acc.: 59.38%] [G loss: 0.863163]\n",
      "epoch:16 step:15290 [D loss: 0.645275, acc.: 64.84%] [G loss: 0.929359]\n",
      "epoch:16 step:15291 [D loss: 0.621272, acc.: 63.28%] [G loss: 0.868812]\n",
      "epoch:16 step:15292 [D loss: 0.612743, acc.: 67.97%] [G loss: 0.909855]\n",
      "epoch:16 step:15293 [D loss: 0.707980, acc.: 57.81%] [G loss: 0.876232]\n",
      "epoch:16 step:15294 [D loss: 0.659825, acc.: 58.59%] [G loss: 0.919358]\n",
      "epoch:16 step:15295 [D loss: 0.663983, acc.: 61.72%] [G loss: 0.901772]\n",
      "epoch:16 step:15296 [D loss: 0.629295, acc.: 62.50%] [G loss: 0.887638]\n",
      "epoch:16 step:15297 [D loss: 0.631368, acc.: 64.84%] [G loss: 0.971685]\n",
      "epoch:16 step:15298 [D loss: 0.682082, acc.: 56.25%] [G loss: 0.962782]\n",
      "epoch:16 step:15299 [D loss: 0.623550, acc.: 68.75%] [G loss: 1.008998]\n",
      "epoch:16 step:15300 [D loss: 0.682502, acc.: 60.94%] [G loss: 0.920428]\n",
      "epoch:16 step:15301 [D loss: 0.608392, acc.: 67.97%] [G loss: 0.857715]\n",
      "epoch:16 step:15302 [D loss: 0.642342, acc.: 65.62%] [G loss: 0.915952]\n",
      "epoch:16 step:15303 [D loss: 0.629991, acc.: 68.75%] [G loss: 0.899352]\n",
      "epoch:16 step:15304 [D loss: 0.601387, acc.: 66.41%] [G loss: 0.915474]\n",
      "epoch:16 step:15305 [D loss: 0.612894, acc.: 66.41%] [G loss: 0.991933]\n",
      "epoch:16 step:15306 [D loss: 0.606076, acc.: 63.28%] [G loss: 0.976918]\n",
      "epoch:16 step:15307 [D loss: 0.610100, acc.: 64.84%] [G loss: 0.918162]\n",
      "epoch:16 step:15308 [D loss: 0.770486, acc.: 48.44%] [G loss: 0.898565]\n",
      "epoch:16 step:15309 [D loss: 0.720531, acc.: 52.34%] [G loss: 0.864413]\n",
      "epoch:16 step:15310 [D loss: 0.656739, acc.: 57.81%] [G loss: 0.854469]\n",
      "epoch:16 step:15311 [D loss: 0.659586, acc.: 64.06%] [G loss: 0.821111]\n",
      "epoch:16 step:15312 [D loss: 0.637254, acc.: 60.94%] [G loss: 0.882591]\n",
      "epoch:16 step:15313 [D loss: 0.695679, acc.: 58.59%] [G loss: 0.950247]\n",
      "epoch:16 step:15314 [D loss: 0.646887, acc.: 60.94%] [G loss: 0.889320]\n",
      "epoch:16 step:15315 [D loss: 0.703562, acc.: 49.22%] [G loss: 0.851931]\n",
      "epoch:16 step:15316 [D loss: 0.698180, acc.: 56.25%] [G loss: 0.937404]\n",
      "epoch:16 step:15317 [D loss: 0.665065, acc.: 61.72%] [G loss: 0.834938]\n",
      "epoch:16 step:15318 [D loss: 0.642339, acc.: 57.03%] [G loss: 0.866424]\n",
      "epoch:16 step:15319 [D loss: 0.670625, acc.: 59.38%] [G loss: 0.928682]\n",
      "epoch:16 step:15320 [D loss: 0.627316, acc.: 62.50%] [G loss: 0.926240]\n",
      "epoch:16 step:15321 [D loss: 0.655145, acc.: 58.59%] [G loss: 0.909917]\n",
      "epoch:16 step:15322 [D loss: 0.676339, acc.: 55.47%] [G loss: 0.878982]\n",
      "epoch:16 step:15323 [D loss: 0.634285, acc.: 61.72%] [G loss: 0.884013]\n",
      "epoch:16 step:15324 [D loss: 0.654456, acc.: 61.72%] [G loss: 0.937853]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15325 [D loss: 0.686955, acc.: 54.69%] [G loss: 0.851561]\n",
      "epoch:16 step:15326 [D loss: 0.661987, acc.: 60.94%] [G loss: 0.896615]\n",
      "epoch:16 step:15327 [D loss: 0.715443, acc.: 49.22%] [G loss: 0.937456]\n",
      "epoch:16 step:15328 [D loss: 0.605024, acc.: 67.97%] [G loss: 0.973947]\n",
      "epoch:16 step:15329 [D loss: 0.633358, acc.: 62.50%] [G loss: 0.943089]\n",
      "epoch:16 step:15330 [D loss: 0.674838, acc.: 53.91%] [G loss: 0.953979]\n",
      "epoch:16 step:15331 [D loss: 0.636939, acc.: 65.62%] [G loss: 0.909692]\n",
      "epoch:16 step:15332 [D loss: 0.689736, acc.: 59.38%] [G loss: 0.936458]\n",
      "epoch:16 step:15333 [D loss: 0.675409, acc.: 62.50%] [G loss: 0.906077]\n",
      "epoch:16 step:15334 [D loss: 0.663212, acc.: 51.56%] [G loss: 0.984265]\n",
      "epoch:16 step:15335 [D loss: 0.637925, acc.: 68.75%] [G loss: 0.967169]\n",
      "epoch:16 step:15336 [D loss: 0.609603, acc.: 70.31%] [G loss: 0.954349]\n",
      "epoch:16 step:15337 [D loss: 0.659390, acc.: 59.38%] [G loss: 0.964539]\n",
      "epoch:16 step:15338 [D loss: 0.638613, acc.: 63.28%] [G loss: 0.949074]\n",
      "epoch:16 step:15339 [D loss: 0.585121, acc.: 69.53%] [G loss: 1.056354]\n",
      "epoch:16 step:15340 [D loss: 0.788226, acc.: 49.22%] [G loss: 0.983173]\n",
      "epoch:16 step:15341 [D loss: 0.755892, acc.: 45.31%] [G loss: 0.905353]\n",
      "epoch:16 step:15342 [D loss: 0.687455, acc.: 51.56%] [G loss: 0.886780]\n",
      "epoch:16 step:15343 [D loss: 0.664347, acc.: 61.72%] [G loss: 0.870250]\n",
      "epoch:16 step:15344 [D loss: 0.675233, acc.: 53.12%] [G loss: 0.888530]\n",
      "epoch:16 step:15345 [D loss: 0.606719, acc.: 67.97%] [G loss: 0.926363]\n",
      "epoch:16 step:15346 [D loss: 0.630040, acc.: 67.97%] [G loss: 0.938973]\n",
      "epoch:16 step:15347 [D loss: 0.663941, acc.: 60.94%] [G loss: 0.975413]\n",
      "epoch:16 step:15348 [D loss: 0.688577, acc.: 57.81%] [G loss: 0.932929]\n",
      "epoch:16 step:15349 [D loss: 0.648987, acc.: 64.84%] [G loss: 0.913629]\n",
      "epoch:16 step:15350 [D loss: 0.585468, acc.: 72.66%] [G loss: 0.885347]\n",
      "epoch:16 step:15351 [D loss: 0.615650, acc.: 64.06%] [G loss: 0.927066]\n",
      "epoch:16 step:15352 [D loss: 0.619473, acc.: 61.72%] [G loss: 0.911346]\n",
      "epoch:16 step:15353 [D loss: 0.625475, acc.: 62.50%] [G loss: 0.913157]\n",
      "epoch:16 step:15354 [D loss: 0.675192, acc.: 59.38%] [G loss: 0.911309]\n",
      "epoch:16 step:15355 [D loss: 0.655709, acc.: 61.72%] [G loss: 0.922128]\n",
      "epoch:16 step:15356 [D loss: 0.647078, acc.: 57.81%] [G loss: 0.971028]\n",
      "epoch:16 step:15357 [D loss: 0.652915, acc.: 58.59%] [G loss: 0.890405]\n",
      "epoch:16 step:15358 [D loss: 0.679618, acc.: 60.16%] [G loss: 0.894094]\n",
      "epoch:16 step:15359 [D loss: 0.659892, acc.: 59.38%] [G loss: 0.885747]\n",
      "epoch:16 step:15360 [D loss: 0.674090, acc.: 58.59%] [G loss: 0.929428]\n",
      "epoch:16 step:15361 [D loss: 0.669681, acc.: 57.81%] [G loss: 0.924442]\n",
      "epoch:16 step:15362 [D loss: 0.650031, acc.: 59.38%] [G loss: 0.936820]\n",
      "epoch:16 step:15363 [D loss: 0.602978, acc.: 74.22%] [G loss: 0.952809]\n",
      "epoch:16 step:15364 [D loss: 0.675377, acc.: 59.38%] [G loss: 0.946331]\n",
      "epoch:16 step:15365 [D loss: 0.718655, acc.: 48.44%] [G loss: 0.941020]\n",
      "epoch:16 step:15366 [D loss: 0.628647, acc.: 66.41%] [G loss: 0.927873]\n",
      "epoch:16 step:15367 [D loss: 0.680353, acc.: 64.06%] [G loss: 0.903543]\n",
      "epoch:16 step:15368 [D loss: 0.667343, acc.: 57.03%] [G loss: 0.912536]\n",
      "epoch:16 step:15369 [D loss: 0.696775, acc.: 58.59%] [G loss: 0.918225]\n",
      "epoch:16 step:15370 [D loss: 0.661392, acc.: 60.94%] [G loss: 0.915963]\n",
      "epoch:16 step:15371 [D loss: 0.647214, acc.: 60.16%] [G loss: 0.897739]\n",
      "epoch:16 step:15372 [D loss: 0.649392, acc.: 61.72%] [G loss: 0.861968]\n",
      "epoch:16 step:15373 [D loss: 0.622386, acc.: 64.84%] [G loss: 0.917431]\n",
      "epoch:16 step:15374 [D loss: 0.628388, acc.: 65.62%] [G loss: 0.910743]\n",
      "epoch:16 step:15375 [D loss: 0.681638, acc.: 49.22%] [G loss: 0.865142]\n",
      "epoch:16 step:15376 [D loss: 0.637070, acc.: 66.41%] [G loss: 0.871702]\n",
      "epoch:16 step:15377 [D loss: 0.629502, acc.: 63.28%] [G loss: 0.870492]\n",
      "epoch:16 step:15378 [D loss: 0.628880, acc.: 67.19%] [G loss: 0.954016]\n",
      "epoch:16 step:15379 [D loss: 0.644373, acc.: 63.28%] [G loss: 0.960712]\n",
      "epoch:16 step:15380 [D loss: 0.656847, acc.: 61.72%] [G loss: 0.901947]\n",
      "epoch:16 step:15381 [D loss: 0.665811, acc.: 56.25%] [G loss: 0.911091]\n",
      "epoch:16 step:15382 [D loss: 0.688147, acc.: 56.25%] [G loss: 0.889548]\n",
      "epoch:16 step:15383 [D loss: 0.629100, acc.: 65.62%] [G loss: 0.860243]\n",
      "epoch:16 step:15384 [D loss: 0.663749, acc.: 60.16%] [G loss: 0.899775]\n",
      "epoch:16 step:15385 [D loss: 0.681862, acc.: 53.12%] [G loss: 0.892578]\n",
      "epoch:16 step:15386 [D loss: 0.667859, acc.: 60.94%] [G loss: 0.913099]\n",
      "epoch:16 step:15387 [D loss: 0.677628, acc.: 57.03%] [G loss: 0.914601]\n",
      "epoch:16 step:15388 [D loss: 0.685282, acc.: 49.22%] [G loss: 0.938190]\n",
      "epoch:16 step:15389 [D loss: 0.619495, acc.: 66.41%] [G loss: 0.971288]\n",
      "epoch:16 step:15390 [D loss: 0.575531, acc.: 72.66%] [G loss: 0.979631]\n",
      "epoch:16 step:15391 [D loss: 0.624344, acc.: 72.66%] [G loss: 0.989973]\n",
      "epoch:16 step:15392 [D loss: 0.681418, acc.: 53.12%] [G loss: 0.930703]\n",
      "epoch:16 step:15393 [D loss: 0.658332, acc.: 60.94%] [G loss: 0.899790]\n",
      "epoch:16 step:15394 [D loss: 0.634748, acc.: 64.06%] [G loss: 0.893834]\n",
      "epoch:16 step:15395 [D loss: 0.700304, acc.: 53.12%] [G loss: 0.886410]\n",
      "epoch:16 step:15396 [D loss: 0.628536, acc.: 66.41%] [G loss: 0.906506]\n",
      "epoch:16 step:15397 [D loss: 0.607899, acc.: 69.53%] [G loss: 0.919650]\n",
      "epoch:16 step:15398 [D loss: 0.608054, acc.: 67.19%] [G loss: 1.031648]\n",
      "epoch:16 step:15399 [D loss: 0.703418, acc.: 57.03%] [G loss: 0.949215]\n",
      "epoch:16 step:15400 [D loss: 0.666860, acc.: 60.94%] [G loss: 1.001610]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.172094\n",
      "FID: 8.309459\n",
      "0 = 11.816792479109782\n",
      "1 = 0.051043493536609294\n",
      "2 = 0.911050021648407\n",
      "3 = 0.864799976348877\n",
      "4 = 0.9573000073432922\n",
      "5 = 0.9529476761817932\n",
      "6 = 0.864799976348877\n",
      "7 = 5.806947131431107\n",
      "8 = 0.06599117029254437\n",
      "9 = 0.697350025177002\n",
      "10 = 0.6769000291824341\n",
      "11 = 0.7178000211715698\n",
      "12 = 0.7057658433914185\n",
      "13 = 0.6769000291824341\n",
      "14 = 8.172160148620605\n",
      "15 = 9.595283508300781\n",
      "16 = 0.08603044599294662\n",
      "17 = 8.172094345092773\n",
      "18 = 8.30945873260498\n",
      "epoch:16 step:15401 [D loss: 0.649176, acc.: 62.50%] [G loss: 0.861192]\n",
      "epoch:16 step:15402 [D loss: 0.714194, acc.: 54.69%] [G loss: 0.923639]\n",
      "epoch:16 step:15403 [D loss: 0.719110, acc.: 57.03%] [G loss: 0.851161]\n",
      "epoch:16 step:15404 [D loss: 0.656582, acc.: 63.28%] [G loss: 0.922024]\n",
      "epoch:16 step:15405 [D loss: 0.664425, acc.: 63.28%] [G loss: 1.004374]\n",
      "epoch:16 step:15406 [D loss: 0.671975, acc.: 57.03%] [G loss: 0.980612]\n",
      "epoch:16 step:15407 [D loss: 0.678370, acc.: 57.81%] [G loss: 0.997544]\n",
      "epoch:16 step:15408 [D loss: 0.593398, acc.: 72.66%] [G loss: 1.024322]\n",
      "epoch:16 step:15409 [D loss: 0.699342, acc.: 54.69%] [G loss: 0.933126]\n",
      "epoch:16 step:15410 [D loss: 0.720569, acc.: 47.66%] [G loss: 0.890540]\n",
      "epoch:16 step:15411 [D loss: 0.677340, acc.: 59.38%] [G loss: 0.875734]\n",
      "epoch:16 step:15412 [D loss: 0.629992, acc.: 67.19%] [G loss: 0.959118]\n",
      "epoch:16 step:15413 [D loss: 0.656609, acc.: 58.59%] [G loss: 0.904078]\n",
      "epoch:16 step:15414 [D loss: 0.668712, acc.: 55.47%] [G loss: 0.883550]\n",
      "epoch:16 step:15415 [D loss: 0.700161, acc.: 54.69%] [G loss: 0.865775]\n",
      "epoch:16 step:15416 [D loss: 0.705528, acc.: 57.03%] [G loss: 0.978258]\n",
      "epoch:16 step:15417 [D loss: 0.632550, acc.: 66.41%] [G loss: 0.960549]\n",
      "epoch:16 step:15418 [D loss: 0.627363, acc.: 65.62%] [G loss: 0.956629]\n",
      "epoch:16 step:15419 [D loss: 0.617380, acc.: 64.84%] [G loss: 0.931942]\n",
      "epoch:16 step:15420 [D loss: 0.666135, acc.: 56.25%] [G loss: 0.969631]\n",
      "epoch:16 step:15421 [D loss: 0.619627, acc.: 69.53%] [G loss: 0.970291]\n",
      "epoch:16 step:15422 [D loss: 0.575916, acc.: 68.75%] [G loss: 0.902024]\n",
      "epoch:16 step:15423 [D loss: 0.688446, acc.: 59.38%] [G loss: 0.901324]\n",
      "epoch:16 step:15424 [D loss: 0.679410, acc.: 60.16%] [G loss: 0.932852]\n",
      "epoch:16 step:15425 [D loss: 0.663379, acc.: 54.69%] [G loss: 0.878609]\n",
      "epoch:16 step:15426 [D loss: 0.671420, acc.: 59.38%] [G loss: 0.877507]\n",
      "epoch:16 step:15427 [D loss: 0.658561, acc.: 61.72%] [G loss: 0.952861]\n",
      "epoch:16 step:15428 [D loss: 0.639460, acc.: 64.84%] [G loss: 0.960443]\n",
      "epoch:16 step:15429 [D loss: 0.792586, acc.: 41.41%] [G loss: 0.912967]\n",
      "epoch:16 step:15430 [D loss: 0.665732, acc.: 57.81%] [G loss: 0.917200]\n",
      "epoch:16 step:15431 [D loss: 0.693766, acc.: 60.16%] [G loss: 1.014843]\n",
      "epoch:16 step:15432 [D loss: 0.636298, acc.: 63.28%] [G loss: 0.948091]\n",
      "epoch:16 step:15433 [D loss: 0.638111, acc.: 65.62%] [G loss: 0.953091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15434 [D loss: 0.644418, acc.: 61.72%] [G loss: 0.986626]\n",
      "epoch:16 step:15435 [D loss: 0.662171, acc.: 63.28%] [G loss: 0.929229]\n",
      "epoch:16 step:15436 [D loss: 0.640686, acc.: 69.53%] [G loss: 0.918707]\n",
      "epoch:16 step:15437 [D loss: 0.632593, acc.: 61.72%] [G loss: 0.991928]\n",
      "epoch:16 step:15438 [D loss: 0.641940, acc.: 63.28%] [G loss: 0.941079]\n",
      "epoch:16 step:15439 [D loss: 0.610681, acc.: 65.62%] [G loss: 0.943809]\n",
      "epoch:16 step:15440 [D loss: 0.729317, acc.: 54.69%] [G loss: 0.928849]\n",
      "epoch:16 step:15441 [D loss: 0.659402, acc.: 61.72%] [G loss: 0.907223]\n",
      "epoch:16 step:15442 [D loss: 0.654320, acc.: 61.72%] [G loss: 0.912320]\n",
      "epoch:16 step:15443 [D loss: 0.638745, acc.: 60.94%] [G loss: 0.838009]\n",
      "epoch:16 step:15444 [D loss: 0.624093, acc.: 67.19%] [G loss: 0.865947]\n",
      "epoch:16 step:15445 [D loss: 0.606383, acc.: 71.88%] [G loss: 0.918649]\n",
      "epoch:16 step:15446 [D loss: 0.677614, acc.: 61.72%] [G loss: 0.902027]\n",
      "epoch:16 step:15447 [D loss: 0.705638, acc.: 50.00%] [G loss: 0.908288]\n",
      "epoch:16 step:15448 [D loss: 0.669824, acc.: 55.47%] [G loss: 0.920689]\n",
      "epoch:16 step:15449 [D loss: 0.629698, acc.: 61.72%] [G loss: 0.883155]\n",
      "epoch:16 step:15450 [D loss: 0.694504, acc.: 55.47%] [G loss: 0.930397]\n",
      "epoch:16 step:15451 [D loss: 0.646706, acc.: 64.06%] [G loss: 0.940731]\n",
      "epoch:16 step:15452 [D loss: 0.698632, acc.: 52.34%] [G loss: 0.895446]\n",
      "epoch:16 step:15453 [D loss: 0.656987, acc.: 61.72%] [G loss: 0.918378]\n",
      "epoch:16 step:15454 [D loss: 0.644596, acc.: 57.03%] [G loss: 0.905152]\n",
      "epoch:16 step:15455 [D loss: 0.733738, acc.: 53.12%] [G loss: 0.938108]\n",
      "epoch:16 step:15456 [D loss: 0.651183, acc.: 59.38%] [G loss: 0.943716]\n",
      "epoch:16 step:15457 [D loss: 0.641402, acc.: 62.50%] [G loss: 0.948778]\n",
      "epoch:16 step:15458 [D loss: 0.637596, acc.: 71.88%] [G loss: 0.937169]\n",
      "epoch:16 step:15459 [D loss: 0.628546, acc.: 65.62%] [G loss: 0.927412]\n",
      "epoch:16 step:15460 [D loss: 0.635747, acc.: 66.41%] [G loss: 0.889150]\n",
      "epoch:16 step:15461 [D loss: 0.651140, acc.: 59.38%] [G loss: 0.935767]\n",
      "epoch:16 step:15462 [D loss: 0.655823, acc.: 64.06%] [G loss: 0.997887]\n",
      "epoch:16 step:15463 [D loss: 0.599217, acc.: 70.31%] [G loss: 0.999140]\n",
      "epoch:16 step:15464 [D loss: 0.608884, acc.: 66.41%] [G loss: 0.997937]\n",
      "epoch:16 step:15465 [D loss: 0.700851, acc.: 54.69%] [G loss: 0.905915]\n",
      "epoch:16 step:15466 [D loss: 0.635677, acc.: 70.31%] [G loss: 0.920131]\n",
      "epoch:16 step:15467 [D loss: 0.632368, acc.: 65.62%] [G loss: 0.975479]\n",
      "epoch:16 step:15468 [D loss: 0.649164, acc.: 61.72%] [G loss: 0.940715]\n",
      "epoch:16 step:15469 [D loss: 0.729444, acc.: 50.00%] [G loss: 0.933970]\n",
      "epoch:16 step:15470 [D loss: 0.705482, acc.: 50.00%] [G loss: 0.896571]\n",
      "epoch:16 step:15471 [D loss: 0.649073, acc.: 60.94%] [G loss: 0.880420]\n",
      "epoch:16 step:15472 [D loss: 0.666701, acc.: 61.72%] [G loss: 0.903790]\n",
      "epoch:16 step:15473 [D loss: 0.629878, acc.: 63.28%] [G loss: 0.930742]\n",
      "epoch:16 step:15474 [D loss: 0.707314, acc.: 47.66%] [G loss: 0.874267]\n",
      "epoch:16 step:15475 [D loss: 0.682066, acc.: 51.56%] [G loss: 0.892684]\n",
      "epoch:16 step:15476 [D loss: 0.623924, acc.: 66.41%] [G loss: 0.937736]\n",
      "epoch:16 step:15477 [D loss: 0.681840, acc.: 59.38%] [G loss: 0.890845]\n",
      "epoch:16 step:15478 [D loss: 0.695388, acc.: 53.91%] [G loss: 0.901549]\n",
      "epoch:16 step:15479 [D loss: 0.689445, acc.: 56.25%] [G loss: 0.886015]\n",
      "epoch:16 step:15480 [D loss: 0.648803, acc.: 57.03%] [G loss: 0.887916]\n",
      "epoch:16 step:15481 [D loss: 0.674236, acc.: 57.03%] [G loss: 0.891721]\n",
      "epoch:16 step:15482 [D loss: 0.648581, acc.: 64.06%] [G loss: 0.906268]\n",
      "epoch:16 step:15483 [D loss: 0.679850, acc.: 57.03%] [G loss: 0.951757]\n",
      "epoch:16 step:15484 [D loss: 0.674620, acc.: 60.16%] [G loss: 0.927835]\n",
      "epoch:16 step:15485 [D loss: 0.641985, acc.: 66.41%] [G loss: 0.955213]\n",
      "epoch:16 step:15486 [D loss: 0.668711, acc.: 57.81%] [G loss: 0.830247]\n",
      "epoch:16 step:15487 [D loss: 0.607792, acc.: 67.19%] [G loss: 0.839092]\n",
      "epoch:16 step:15488 [D loss: 0.631526, acc.: 66.41%] [G loss: 0.881395]\n",
      "epoch:16 step:15489 [D loss: 0.682779, acc.: 52.34%] [G loss: 0.953001]\n",
      "epoch:16 step:15490 [D loss: 0.650081, acc.: 67.97%] [G loss: 0.954491]\n",
      "epoch:16 step:15491 [D loss: 0.627053, acc.: 65.62%] [G loss: 0.919659]\n",
      "epoch:16 step:15492 [D loss: 0.698612, acc.: 57.81%] [G loss: 0.967085]\n",
      "epoch:16 step:15493 [D loss: 0.763234, acc.: 49.22%] [G loss: 0.895111]\n",
      "epoch:16 step:15494 [D loss: 0.701243, acc.: 51.56%] [G loss: 0.879310]\n",
      "epoch:16 step:15495 [D loss: 0.648455, acc.: 64.84%] [G loss: 0.898991]\n",
      "epoch:16 step:15496 [D loss: 0.628538, acc.: 66.41%] [G loss: 0.861731]\n",
      "epoch:16 step:15497 [D loss: 0.618133, acc.: 64.06%] [G loss: 0.939144]\n",
      "epoch:16 step:15498 [D loss: 0.644837, acc.: 64.06%] [G loss: 0.953149]\n",
      "epoch:16 step:15499 [D loss: 0.617371, acc.: 60.16%] [G loss: 0.987194]\n",
      "epoch:16 step:15500 [D loss: 0.586754, acc.: 66.41%] [G loss: 1.031885]\n",
      "epoch:16 step:15501 [D loss: 0.714471, acc.: 57.81%] [G loss: 0.945172]\n",
      "epoch:16 step:15502 [D loss: 0.685647, acc.: 55.47%] [G loss: 0.930936]\n",
      "epoch:16 step:15503 [D loss: 0.726108, acc.: 47.66%] [G loss: 0.886588]\n",
      "epoch:16 step:15504 [D loss: 0.668949, acc.: 60.94%] [G loss: 0.924120]\n",
      "epoch:16 step:15505 [D loss: 0.639038, acc.: 64.84%] [G loss: 0.979235]\n",
      "epoch:16 step:15506 [D loss: 0.671987, acc.: 59.38%] [G loss: 0.970761]\n",
      "epoch:16 step:15507 [D loss: 0.587455, acc.: 73.44%] [G loss: 0.899501]\n",
      "epoch:16 step:15508 [D loss: 0.645837, acc.: 61.72%] [G loss: 0.860156]\n",
      "epoch:16 step:15509 [D loss: 0.717319, acc.: 51.56%] [G loss: 0.882995]\n",
      "epoch:16 step:15510 [D loss: 0.647661, acc.: 60.16%] [G loss: 0.841845]\n",
      "epoch:16 step:15511 [D loss: 0.654267, acc.: 63.28%] [G loss: 0.888079]\n",
      "epoch:16 step:15512 [D loss: 0.608328, acc.: 68.75%] [G loss: 0.938299]\n",
      "epoch:16 step:15513 [D loss: 0.654643, acc.: 62.50%] [G loss: 0.943982]\n",
      "epoch:16 step:15514 [D loss: 0.643053, acc.: 64.84%] [G loss: 0.977776]\n",
      "epoch:16 step:15515 [D loss: 0.657825, acc.: 63.28%] [G loss: 0.916557]\n",
      "epoch:16 step:15516 [D loss: 0.664202, acc.: 64.06%] [G loss: 0.975925]\n",
      "epoch:16 step:15517 [D loss: 0.663748, acc.: 55.47%] [G loss: 0.850606]\n",
      "epoch:16 step:15518 [D loss: 0.629819, acc.: 60.16%] [G loss: 0.959596]\n",
      "epoch:16 step:15519 [D loss: 0.696877, acc.: 53.12%] [G loss: 0.909915]\n",
      "epoch:16 step:15520 [D loss: 0.718349, acc.: 53.12%] [G loss: 0.841660]\n",
      "epoch:16 step:15521 [D loss: 0.700047, acc.: 53.91%] [G loss: 0.908946]\n",
      "epoch:16 step:15522 [D loss: 0.639966, acc.: 65.62%] [G loss: 0.904446]\n",
      "epoch:16 step:15523 [D loss: 0.680805, acc.: 56.25%] [G loss: 0.854780]\n",
      "epoch:16 step:15524 [D loss: 0.671068, acc.: 63.28%] [G loss: 0.861697]\n",
      "epoch:16 step:15525 [D loss: 0.667210, acc.: 60.16%] [G loss: 0.919509]\n",
      "epoch:16 step:15526 [D loss: 0.638204, acc.: 64.84%] [G loss: 0.909559]\n",
      "epoch:16 step:15527 [D loss: 0.689646, acc.: 52.34%] [G loss: 0.888616]\n",
      "epoch:16 step:15528 [D loss: 0.651180, acc.: 62.50%] [G loss: 0.878997]\n",
      "epoch:16 step:15529 [D loss: 0.675639, acc.: 53.12%] [G loss: 0.943131]\n",
      "epoch:16 step:15530 [D loss: 0.630458, acc.: 66.41%] [G loss: 0.926005]\n",
      "epoch:16 step:15531 [D loss: 0.639384, acc.: 63.28%] [G loss: 0.886958]\n",
      "epoch:16 step:15532 [D loss: 0.679701, acc.: 54.69%] [G loss: 0.894863]\n",
      "epoch:16 step:15533 [D loss: 0.628698, acc.: 64.84%] [G loss: 0.921736]\n",
      "epoch:16 step:15534 [D loss: 0.761637, acc.: 42.19%] [G loss: 0.835750]\n",
      "epoch:16 step:15535 [D loss: 0.662301, acc.: 58.59%] [G loss: 0.857345]\n",
      "epoch:16 step:15536 [D loss: 0.647494, acc.: 65.62%] [G loss: 0.816669]\n",
      "epoch:16 step:15537 [D loss: 0.678425, acc.: 62.50%] [G loss: 0.893589]\n",
      "epoch:16 step:15538 [D loss: 0.614371, acc.: 66.41%] [G loss: 0.857340]\n",
      "epoch:16 step:15539 [D loss: 0.643797, acc.: 61.72%] [G loss: 0.893436]\n",
      "epoch:16 step:15540 [D loss: 0.651582, acc.: 58.59%] [G loss: 0.924862]\n",
      "epoch:16 step:15541 [D loss: 0.633544, acc.: 63.28%] [G loss: 0.910632]\n",
      "epoch:16 step:15542 [D loss: 0.607957, acc.: 69.53%] [G loss: 0.915146]\n",
      "epoch:16 step:15543 [D loss: 0.600146, acc.: 66.41%] [G loss: 0.941231]\n",
      "epoch:16 step:15544 [D loss: 0.628727, acc.: 67.97%] [G loss: 0.937994]\n",
      "epoch:16 step:15545 [D loss: 0.723240, acc.: 53.12%] [G loss: 0.921637]\n",
      "epoch:16 step:15546 [D loss: 0.637527, acc.: 60.16%] [G loss: 0.914988]\n",
      "epoch:16 step:15547 [D loss: 0.602281, acc.: 67.97%] [G loss: 0.870293]\n",
      "epoch:16 step:15548 [D loss: 0.613728, acc.: 66.41%] [G loss: 0.963443]\n",
      "epoch:16 step:15549 [D loss: 0.632326, acc.: 64.84%] [G loss: 0.899320]\n",
      "epoch:16 step:15550 [D loss: 0.614573, acc.: 64.06%] [G loss: 0.930625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15551 [D loss: 0.700709, acc.: 55.47%] [G loss: 0.964649]\n",
      "epoch:16 step:15552 [D loss: 0.744353, acc.: 42.97%] [G loss: 0.889750]\n",
      "epoch:16 step:15553 [D loss: 0.653675, acc.: 60.16%] [G loss: 0.899354]\n",
      "epoch:16 step:15554 [D loss: 0.650765, acc.: 63.28%] [G loss: 0.925161]\n",
      "epoch:16 step:15555 [D loss: 0.617627, acc.: 65.62%] [G loss: 0.987543]\n",
      "epoch:16 step:15556 [D loss: 0.607820, acc.: 66.41%] [G loss: 1.028482]\n",
      "epoch:16 step:15557 [D loss: 0.688826, acc.: 59.38%] [G loss: 0.951314]\n",
      "epoch:16 step:15558 [D loss: 0.734445, acc.: 43.75%] [G loss: 0.920928]\n",
      "epoch:16 step:15559 [D loss: 0.638917, acc.: 66.41%] [G loss: 0.946498]\n",
      "epoch:16 step:15560 [D loss: 0.664184, acc.: 60.94%] [G loss: 0.931143]\n",
      "epoch:16 step:15561 [D loss: 0.709384, acc.: 60.16%] [G loss: 0.840118]\n",
      "epoch:16 step:15562 [D loss: 0.652051, acc.: 57.03%] [G loss: 0.831327]\n",
      "epoch:16 step:15563 [D loss: 0.610367, acc.: 64.06%] [G loss: 0.916171]\n",
      "epoch:16 step:15564 [D loss: 0.636822, acc.: 64.06%] [G loss: 0.904989]\n",
      "epoch:16 step:15565 [D loss: 0.613190, acc.: 67.19%] [G loss: 0.954082]\n",
      "epoch:16 step:15566 [D loss: 0.558103, acc.: 67.97%] [G loss: 1.053365]\n",
      "epoch:16 step:15567 [D loss: 0.631436, acc.: 62.50%] [G loss: 1.060878]\n",
      "epoch:16 step:15568 [D loss: 0.703326, acc.: 56.25%] [G loss: 0.962994]\n",
      "epoch:16 step:15569 [D loss: 0.664508, acc.: 57.03%] [G loss: 0.927386]\n",
      "epoch:16 step:15570 [D loss: 0.663524, acc.: 60.94%] [G loss: 0.935992]\n",
      "epoch:16 step:15571 [D loss: 0.672188, acc.: 58.59%] [G loss: 0.917492]\n",
      "epoch:16 step:15572 [D loss: 0.653766, acc.: 60.94%] [G loss: 0.892334]\n",
      "epoch:16 step:15573 [D loss: 0.613962, acc.: 65.62%] [G loss: 0.935027]\n",
      "epoch:16 step:15574 [D loss: 0.589425, acc.: 67.97%] [G loss: 0.956730]\n",
      "epoch:16 step:15575 [D loss: 0.600619, acc.: 67.97%] [G loss: 0.982519]\n",
      "epoch:16 step:15576 [D loss: 0.709110, acc.: 50.00%] [G loss: 0.904934]\n",
      "epoch:16 step:15577 [D loss: 0.663805, acc.: 56.25%] [G loss: 0.913660]\n",
      "epoch:16 step:15578 [D loss: 0.669072, acc.: 60.94%] [G loss: 0.915828]\n",
      "epoch:16 step:15579 [D loss: 0.703823, acc.: 54.69%] [G loss: 0.925196]\n",
      "epoch:16 step:15580 [D loss: 0.641347, acc.: 60.94%] [G loss: 0.878172]\n",
      "epoch:16 step:15581 [D loss: 0.664670, acc.: 56.25%] [G loss: 0.859969]\n",
      "epoch:16 step:15582 [D loss: 0.667059, acc.: 60.16%] [G loss: 0.899630]\n",
      "epoch:16 step:15583 [D loss: 0.665503, acc.: 60.16%] [G loss: 0.865672]\n",
      "epoch:16 step:15584 [D loss: 0.616994, acc.: 65.62%] [G loss: 0.908559]\n",
      "epoch:16 step:15585 [D loss: 0.608404, acc.: 69.53%] [G loss: 0.874193]\n",
      "epoch:16 step:15586 [D loss: 0.647060, acc.: 63.28%] [G loss: 0.885539]\n",
      "epoch:16 step:15587 [D loss: 0.612153, acc.: 70.31%] [G loss: 0.961465]\n",
      "epoch:16 step:15588 [D loss: 0.703151, acc.: 52.34%] [G loss: 0.911382]\n",
      "epoch:16 step:15589 [D loss: 0.701126, acc.: 53.12%] [G loss: 0.879319]\n",
      "epoch:16 step:15590 [D loss: 0.672105, acc.: 63.28%] [G loss: 0.852195]\n",
      "epoch:16 step:15591 [D loss: 0.676710, acc.: 58.59%] [G loss: 0.885358]\n",
      "epoch:16 step:15592 [D loss: 0.672550, acc.: 60.94%] [G loss: 0.879811]\n",
      "epoch:16 step:15593 [D loss: 0.620482, acc.: 66.41%] [G loss: 0.869746]\n",
      "epoch:16 step:15594 [D loss: 0.655798, acc.: 62.50%] [G loss: 0.866479]\n",
      "epoch:16 step:15595 [D loss: 0.628058, acc.: 65.62%] [G loss: 0.877026]\n",
      "epoch:16 step:15596 [D loss: 0.670377, acc.: 59.38%] [G loss: 0.912814]\n",
      "epoch:16 step:15597 [D loss: 0.649852, acc.: 59.38%] [G loss: 0.977903]\n",
      "epoch:16 step:15598 [D loss: 0.664215, acc.: 60.16%] [G loss: 0.833620]\n",
      "epoch:16 step:15599 [D loss: 0.640465, acc.: 57.81%] [G loss: 0.918446]\n",
      "epoch:16 step:15600 [D loss: 0.638190, acc.: 65.62%] [G loss: 0.918426]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 7.970426\n",
      "FID: 7.965346\n",
      "0 = 11.842452248644767\n",
      "1 = 0.05035692611075679\n",
      "2 = 0.9095500111579895\n",
      "3 = 0.8720999956130981\n",
      "4 = 0.9470000267028809\n",
      "5 = 0.9427089095115662\n",
      "6 = 0.8720999956130981\n",
      "7 = 5.869011636728082\n",
      "8 = 0.06286514429465266\n",
      "9 = 0.7042499780654907\n",
      "10 = 0.6863999962806702\n",
      "11 = 0.722100019454956\n",
      "12 = 0.7118116617202759\n",
      "13 = 0.6863999962806702\n",
      "14 = 7.97049617767334\n",
      "15 = 9.643413543701172\n",
      "16 = 0.07375998049974442\n",
      "17 = 7.970426082611084\n",
      "18 = 7.965346336364746\n",
      "epoch:16 step:15601 [D loss: 0.655015, acc.: 64.06%] [G loss: 0.930429]\n",
      "epoch:16 step:15602 [D loss: 0.654203, acc.: 57.03%] [G loss: 0.908372]\n",
      "epoch:16 step:15603 [D loss: 0.664344, acc.: 57.81%] [G loss: 0.951940]\n",
      "epoch:16 step:15604 [D loss: 0.649188, acc.: 57.03%] [G loss: 0.868891]\n",
      "epoch:16 step:15605 [D loss: 0.638197, acc.: 62.50%] [G loss: 0.892415]\n",
      "epoch:16 step:15606 [D loss: 0.691753, acc.: 57.81%] [G loss: 0.881846]\n",
      "epoch:16 step:15607 [D loss: 0.712715, acc.: 50.00%] [G loss: 0.881017]\n",
      "epoch:16 step:15608 [D loss: 0.692515, acc.: 55.47%] [G loss: 0.812899]\n",
      "epoch:16 step:15609 [D loss: 0.615716, acc.: 67.97%] [G loss: 0.895262]\n",
      "epoch:16 step:15610 [D loss: 0.598821, acc.: 65.62%] [G loss: 0.930565]\n",
      "epoch:16 step:15611 [D loss: 0.648861, acc.: 62.50%] [G loss: 0.834512]\n",
      "epoch:16 step:15612 [D loss: 0.616992, acc.: 67.19%] [G loss: 0.903897]\n",
      "epoch:16 step:15613 [D loss: 0.684163, acc.: 58.59%] [G loss: 0.843083]\n",
      "epoch:16 step:15614 [D loss: 0.688617, acc.: 56.25%] [G loss: 0.871581]\n",
      "epoch:16 step:15615 [D loss: 0.657771, acc.: 57.03%] [G loss: 0.919070]\n",
      "epoch:16 step:15616 [D loss: 0.593368, acc.: 75.78%] [G loss: 0.908555]\n",
      "epoch:16 step:15617 [D loss: 0.662872, acc.: 60.94%] [G loss: 0.946053]\n",
      "epoch:16 step:15618 [D loss: 0.699068, acc.: 57.03%] [G loss: 0.970348]\n",
      "epoch:16 step:15619 [D loss: 0.688181, acc.: 53.91%] [G loss: 0.837400]\n",
      "epoch:16 step:15620 [D loss: 0.698573, acc.: 56.25%] [G loss: 0.942335]\n",
      "epoch:16 step:15621 [D loss: 0.611781, acc.: 66.41%] [G loss: 0.918800]\n",
      "epoch:16 step:15622 [D loss: 0.667701, acc.: 64.06%] [G loss: 0.933452]\n",
      "epoch:16 step:15623 [D loss: 0.593424, acc.: 71.88%] [G loss: 0.919733]\n",
      "epoch:16 step:15624 [D loss: 0.634352, acc.: 61.72%] [G loss: 0.920645]\n",
      "epoch:16 step:15625 [D loss: 0.660123, acc.: 62.50%] [G loss: 0.949673]\n",
      "epoch:16 step:15626 [D loss: 0.574363, acc.: 70.31%] [G loss: 0.887096]\n",
      "epoch:16 step:15627 [D loss: 0.635499, acc.: 61.72%] [G loss: 0.905593]\n",
      "epoch:16 step:15628 [D loss: 0.667508, acc.: 60.94%] [G loss: 0.927473]\n",
      "epoch:16 step:15629 [D loss: 0.654580, acc.: 57.03%] [G loss: 0.931600]\n",
      "epoch:16 step:15630 [D loss: 0.637485, acc.: 60.94%] [G loss: 0.864562]\n",
      "epoch:16 step:15631 [D loss: 0.677561, acc.: 57.03%] [G loss: 0.932117]\n",
      "epoch:16 step:15632 [D loss: 0.707800, acc.: 51.56%] [G loss: 0.858546]\n",
      "epoch:16 step:15633 [D loss: 0.675682, acc.: 60.94%] [G loss: 0.914322]\n",
      "epoch:16 step:15634 [D loss: 0.660711, acc.: 60.94%] [G loss: 0.981717]\n",
      "epoch:16 step:15635 [D loss: 0.631362, acc.: 64.84%] [G loss: 0.981477]\n",
      "epoch:16 step:15636 [D loss: 0.723593, acc.: 47.66%] [G loss: 0.937532]\n",
      "epoch:16 step:15637 [D loss: 0.663963, acc.: 58.59%] [G loss: 0.923931]\n",
      "epoch:16 step:15638 [D loss: 0.602823, acc.: 70.31%] [G loss: 0.905624]\n",
      "epoch:16 step:15639 [D loss: 0.604006, acc.: 68.75%] [G loss: 0.938491]\n",
      "epoch:16 step:15640 [D loss: 0.583902, acc.: 67.97%] [G loss: 1.050339]\n",
      "epoch:16 step:15641 [D loss: 0.663156, acc.: 56.25%] [G loss: 1.058780]\n",
      "epoch:16 step:15642 [D loss: 0.615122, acc.: 67.97%] [G loss: 0.986919]\n",
      "epoch:16 step:15643 [D loss: 0.648364, acc.: 62.50%] [G loss: 0.954046]\n",
      "epoch:16 step:15644 [D loss: 0.669019, acc.: 55.47%] [G loss: 0.891720]\n",
      "epoch:16 step:15645 [D loss: 0.618795, acc.: 67.97%] [G loss: 0.882442]\n",
      "epoch:16 step:15646 [D loss: 0.645258, acc.: 60.16%] [G loss: 0.887623]\n",
      "epoch:16 step:15647 [D loss: 0.691986, acc.: 58.59%] [G loss: 0.916580]\n",
      "epoch:16 step:15648 [D loss: 0.671133, acc.: 57.81%] [G loss: 0.918743]\n",
      "epoch:16 step:15649 [D loss: 0.676091, acc.: 60.16%] [G loss: 0.889548]\n",
      "epoch:16 step:15650 [D loss: 0.626518, acc.: 67.97%] [G loss: 0.949484]\n",
      "epoch:16 step:15651 [D loss: 0.650639, acc.: 61.72%] [G loss: 0.957439]\n",
      "epoch:16 step:15652 [D loss: 0.649299, acc.: 61.72%] [G loss: 0.980103]\n",
      "epoch:16 step:15653 [D loss: 0.573773, acc.: 76.56%] [G loss: 0.912730]\n",
      "epoch:16 step:15654 [D loss: 0.679049, acc.: 59.38%] [G loss: 0.877207]\n",
      "epoch:16 step:15655 [D loss: 0.710100, acc.: 50.78%] [G loss: 0.883839]\n",
      "epoch:16 step:15656 [D loss: 0.625140, acc.: 65.62%] [G loss: 0.882368]\n",
      "epoch:16 step:15657 [D loss: 0.638910, acc.: 61.72%] [G loss: 0.920305]\n",
      "epoch:16 step:15658 [D loss: 0.637489, acc.: 60.16%] [G loss: 0.956749]\n",
      "epoch:16 step:15659 [D loss: 0.673798, acc.: 57.03%] [G loss: 0.911763]\n",
      "epoch:16 step:15660 [D loss: 0.630692, acc.: 65.62%] [G loss: 0.909648]\n",
      "epoch:16 step:15661 [D loss: 0.638050, acc.: 64.84%] [G loss: 0.901410]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15662 [D loss: 0.692248, acc.: 60.16%] [G loss: 0.835397]\n",
      "epoch:16 step:15663 [D loss: 0.711024, acc.: 53.12%] [G loss: 0.871353]\n",
      "epoch:16 step:15664 [D loss: 0.701884, acc.: 54.69%] [G loss: 0.895365]\n",
      "epoch:16 step:15665 [D loss: 0.684685, acc.: 56.25%] [G loss: 0.933168]\n",
      "epoch:16 step:15666 [D loss: 0.647516, acc.: 58.59%] [G loss: 1.015674]\n",
      "epoch:16 step:15667 [D loss: 0.687786, acc.: 61.72%] [G loss: 0.887531]\n",
      "epoch:16 step:15668 [D loss: 0.656551, acc.: 63.28%] [G loss: 0.867466]\n",
      "epoch:16 step:15669 [D loss: 0.631291, acc.: 65.62%] [G loss: 0.883379]\n",
      "epoch:16 step:15670 [D loss: 0.701466, acc.: 53.12%] [G loss: 0.949645]\n",
      "epoch:16 step:15671 [D loss: 0.624435, acc.: 65.62%] [G loss: 0.899904]\n",
      "epoch:16 step:15672 [D loss: 0.688153, acc.: 56.25%] [G loss: 0.900442]\n",
      "epoch:16 step:15673 [D loss: 0.580456, acc.: 76.56%] [G loss: 0.964323]\n",
      "epoch:16 step:15674 [D loss: 0.672521, acc.: 60.94%] [G loss: 0.924743]\n",
      "epoch:16 step:15675 [D loss: 0.689177, acc.: 52.34%] [G loss: 0.835306]\n",
      "epoch:16 step:15676 [D loss: 0.677567, acc.: 56.25%] [G loss: 0.941976]\n",
      "epoch:16 step:15677 [D loss: 0.638310, acc.: 61.72%] [G loss: 0.893093]\n",
      "epoch:16 step:15678 [D loss: 0.665909, acc.: 62.50%] [G loss: 0.845407]\n",
      "epoch:16 step:15679 [D loss: 0.657400, acc.: 60.94%] [G loss: 0.836729]\n",
      "epoch:16 step:15680 [D loss: 0.626203, acc.: 67.97%] [G loss: 0.987286]\n",
      "epoch:16 step:15681 [D loss: 0.649044, acc.: 60.16%] [G loss: 0.900641]\n",
      "epoch:16 step:15682 [D loss: 0.711994, acc.: 54.69%] [G loss: 0.933981]\n",
      "epoch:16 step:15683 [D loss: 0.607011, acc.: 68.75%] [G loss: 0.967281]\n",
      "epoch:16 step:15684 [D loss: 0.635545, acc.: 57.81%] [G loss: 0.954818]\n",
      "epoch:16 step:15685 [D loss: 0.655065, acc.: 59.38%] [G loss: 0.878108]\n",
      "epoch:16 step:15686 [D loss: 0.615561, acc.: 59.38%] [G loss: 0.917857]\n",
      "epoch:16 step:15687 [D loss: 0.669040, acc.: 56.25%] [G loss: 0.907882]\n",
      "epoch:16 step:15688 [D loss: 0.672855, acc.: 54.69%] [G loss: 0.933208]\n",
      "epoch:16 step:15689 [D loss: 0.682077, acc.: 56.25%] [G loss: 0.926022]\n",
      "epoch:16 step:15690 [D loss: 0.685888, acc.: 53.91%] [G loss: 0.871015]\n",
      "epoch:16 step:15691 [D loss: 0.661742, acc.: 66.41%] [G loss: 0.907052]\n",
      "epoch:16 step:15692 [D loss: 0.629868, acc.: 65.62%] [G loss: 0.965310]\n",
      "epoch:16 step:15693 [D loss: 0.674639, acc.: 60.16%] [G loss: 1.005754]\n",
      "epoch:16 step:15694 [D loss: 0.690328, acc.: 57.03%] [G loss: 1.023359]\n",
      "epoch:16 step:15695 [D loss: 0.705036, acc.: 50.78%] [G loss: 0.950175]\n",
      "epoch:16 step:15696 [D loss: 0.680829, acc.: 50.78%] [G loss: 0.879456]\n",
      "epoch:16 step:15697 [D loss: 0.650293, acc.: 62.50%] [G loss: 0.872217]\n",
      "epoch:16 step:15698 [D loss: 0.616803, acc.: 64.06%] [G loss: 0.861684]\n",
      "epoch:16 step:15699 [D loss: 0.627458, acc.: 67.19%] [G loss: 0.881287]\n",
      "epoch:16 step:15700 [D loss: 0.548113, acc.: 71.88%] [G loss: 0.939518]\n",
      "epoch:16 step:15701 [D loss: 0.636312, acc.: 62.50%] [G loss: 0.991351]\n",
      "epoch:16 step:15702 [D loss: 0.767412, acc.: 46.88%] [G loss: 0.886996]\n",
      "epoch:16 step:15703 [D loss: 0.728732, acc.: 51.56%] [G loss: 0.827802]\n",
      "epoch:16 step:15704 [D loss: 0.638704, acc.: 60.94%] [G loss: 0.944661]\n",
      "epoch:16 step:15705 [D loss: 0.677768, acc.: 63.28%] [G loss: 0.887766]\n",
      "epoch:16 step:15706 [D loss: 0.697787, acc.: 57.81%] [G loss: 0.888139]\n",
      "epoch:16 step:15707 [D loss: 0.646620, acc.: 61.72%] [G loss: 0.877658]\n",
      "epoch:16 step:15708 [D loss: 0.694589, acc.: 52.34%] [G loss: 0.789828]\n",
      "epoch:16 step:15709 [D loss: 0.731676, acc.: 51.56%] [G loss: 0.867791]\n",
      "epoch:16 step:15710 [D loss: 0.681683, acc.: 56.25%] [G loss: 0.879222]\n",
      "epoch:16 step:15711 [D loss: 0.638838, acc.: 66.41%] [G loss: 0.901927]\n",
      "epoch:16 step:15712 [D loss: 0.643058, acc.: 65.62%] [G loss: 0.882918]\n",
      "epoch:16 step:15713 [D loss: 0.704814, acc.: 51.56%] [G loss: 0.939163]\n",
      "epoch:16 step:15714 [D loss: 0.659074, acc.: 62.50%] [G loss: 0.882536]\n",
      "epoch:16 step:15715 [D loss: 0.661746, acc.: 59.38%] [G loss: 0.948423]\n",
      "epoch:16 step:15716 [D loss: 0.648690, acc.: 58.59%] [G loss: 0.995120]\n",
      "epoch:16 step:15717 [D loss: 0.648747, acc.: 60.94%] [G loss: 0.952782]\n",
      "epoch:16 step:15718 [D loss: 0.643984, acc.: 61.72%] [G loss: 1.033199]\n",
      "epoch:16 step:15719 [D loss: 0.688234, acc.: 60.16%] [G loss: 0.873368]\n",
      "epoch:16 step:15720 [D loss: 0.719751, acc.: 50.78%] [G loss: 0.885474]\n",
      "epoch:16 step:15721 [D loss: 0.642369, acc.: 64.06%] [G loss: 0.932896]\n",
      "epoch:16 step:15722 [D loss: 0.614795, acc.: 67.19%] [G loss: 0.896606]\n",
      "epoch:16 step:15723 [D loss: 0.678945, acc.: 57.81%] [G loss: 0.852178]\n",
      "epoch:16 step:15724 [D loss: 0.619461, acc.: 63.28%] [G loss: 0.926447]\n",
      "epoch:16 step:15725 [D loss: 0.579166, acc.: 72.66%] [G loss: 1.002922]\n",
      "epoch:16 step:15726 [D loss: 0.667553, acc.: 59.38%] [G loss: 0.954931]\n",
      "epoch:16 step:15727 [D loss: 0.695526, acc.: 53.91%] [G loss: 0.950869]\n",
      "epoch:16 step:15728 [D loss: 0.623483, acc.: 64.84%] [G loss: 0.887759]\n",
      "epoch:16 step:15729 [D loss: 0.642689, acc.: 58.59%] [G loss: 0.855812]\n",
      "epoch:16 step:15730 [D loss: 0.678111, acc.: 54.69%] [G loss: 0.870847]\n",
      "epoch:16 step:15731 [D loss: 0.685863, acc.: 60.16%] [G loss: 0.908713]\n",
      "epoch:16 step:15732 [D loss: 0.670628, acc.: 54.69%] [G loss: 0.808621]\n",
      "epoch:16 step:15733 [D loss: 0.689415, acc.: 58.59%] [G loss: 0.887622]\n",
      "epoch:16 step:15734 [D loss: 0.674318, acc.: 59.38%] [G loss: 0.896205]\n",
      "epoch:16 step:15735 [D loss: 0.637203, acc.: 63.28%] [G loss: 0.891061]\n",
      "epoch:16 step:15736 [D loss: 0.626904, acc.: 67.97%] [G loss: 0.955432]\n",
      "epoch:16 step:15737 [D loss: 0.665722, acc.: 60.16%] [G loss: 0.893088]\n",
      "epoch:16 step:15738 [D loss: 0.630440, acc.: 66.41%] [G loss: 0.864680]\n",
      "epoch:16 step:15739 [D loss: 0.632310, acc.: 67.19%] [G loss: 0.914165]\n",
      "epoch:16 step:15740 [D loss: 0.676904, acc.: 60.94%] [G loss: 0.880588]\n",
      "epoch:16 step:15741 [D loss: 0.666697, acc.: 59.38%] [G loss: 0.932731]\n",
      "epoch:16 step:15742 [D loss: 0.639657, acc.: 63.28%] [G loss: 0.861540]\n",
      "epoch:16 step:15743 [D loss: 0.627944, acc.: 59.38%] [G loss: 0.924576]\n",
      "epoch:16 step:15744 [D loss: 0.681457, acc.: 59.38%] [G loss: 0.869311]\n",
      "epoch:16 step:15745 [D loss: 0.634162, acc.: 64.06%] [G loss: 0.894099]\n",
      "epoch:16 step:15746 [D loss: 0.616685, acc.: 62.50%] [G loss: 0.864372]\n",
      "epoch:16 step:15747 [D loss: 0.651329, acc.: 61.72%] [G loss: 0.924613]\n",
      "epoch:16 step:15748 [D loss: 0.623817, acc.: 68.75%] [G loss: 0.980125]\n",
      "epoch:16 step:15749 [D loss: 0.672632, acc.: 60.94%] [G loss: 0.943571]\n",
      "epoch:16 step:15750 [D loss: 0.654626, acc.: 63.28%] [G loss: 0.874661]\n",
      "epoch:16 step:15751 [D loss: 0.659481, acc.: 57.81%] [G loss: 0.841776]\n",
      "epoch:16 step:15752 [D loss: 0.656048, acc.: 55.47%] [G loss: 0.872239]\n",
      "epoch:16 step:15753 [D loss: 0.685668, acc.: 54.69%] [G loss: 0.888526]\n",
      "epoch:16 step:15754 [D loss: 0.672769, acc.: 55.47%] [G loss: 0.828038]\n",
      "epoch:16 step:15755 [D loss: 0.614034, acc.: 65.62%] [G loss: 0.874835]\n",
      "epoch:16 step:15756 [D loss: 0.679763, acc.: 55.47%] [G loss: 0.944074]\n",
      "epoch:16 step:15757 [D loss: 0.741792, acc.: 43.75%] [G loss: 0.886256]\n",
      "epoch:16 step:15758 [D loss: 0.689005, acc.: 52.34%] [G loss: 0.891905]\n",
      "epoch:16 step:15759 [D loss: 0.636992, acc.: 64.06%] [G loss: 0.932224]\n",
      "epoch:16 step:15760 [D loss: 0.713155, acc.: 56.25%] [G loss: 0.980777]\n",
      "epoch:16 step:15761 [D loss: 0.687622, acc.: 55.47%] [G loss: 1.040800]\n",
      "epoch:16 step:15762 [D loss: 0.651339, acc.: 57.81%] [G loss: 1.039449]\n",
      "epoch:16 step:15763 [D loss: 0.674231, acc.: 62.50%] [G loss: 0.953852]\n",
      "epoch:16 step:15764 [D loss: 0.661984, acc.: 60.94%] [G loss: 0.855303]\n",
      "epoch:16 step:15765 [D loss: 0.636982, acc.: 66.41%] [G loss: 0.932386]\n",
      "epoch:16 step:15766 [D loss: 0.677974, acc.: 57.03%] [G loss: 0.916780]\n",
      "epoch:16 step:15767 [D loss: 0.605386, acc.: 65.62%] [G loss: 0.967750]\n",
      "epoch:16 step:15768 [D loss: 0.648148, acc.: 59.38%] [G loss: 0.974122]\n",
      "epoch:16 step:15769 [D loss: 0.620164, acc.: 64.06%] [G loss: 0.985220]\n",
      "epoch:16 step:15770 [D loss: 0.666688, acc.: 58.59%] [G loss: 0.912681]\n",
      "epoch:16 step:15771 [D loss: 0.698025, acc.: 57.03%] [G loss: 0.858449]\n",
      "epoch:16 step:15772 [D loss: 0.649175, acc.: 60.94%] [G loss: 0.858734]\n",
      "epoch:16 step:15773 [D loss: 0.606387, acc.: 68.75%] [G loss: 0.948608]\n",
      "epoch:16 step:15774 [D loss: 0.541996, acc.: 75.00%] [G loss: 0.964508]\n",
      "epoch:16 step:15775 [D loss: 0.727604, acc.: 53.91%] [G loss: 0.910530]\n",
      "epoch:16 step:15776 [D loss: 0.747076, acc.: 46.09%] [G loss: 0.830569]\n",
      "epoch:16 step:15777 [D loss: 0.632046, acc.: 65.62%] [G loss: 0.921186]\n",
      "epoch:16 step:15778 [D loss: 0.636063, acc.: 66.41%] [G loss: 0.974033]\n",
      "epoch:16 step:15779 [D loss: 0.715809, acc.: 50.00%] [G loss: 0.855378]\n",
      "epoch:16 step:15780 [D loss: 0.722831, acc.: 47.66%] [G loss: 0.950803]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15781 [D loss: 0.640181, acc.: 59.38%] [G loss: 0.915990]\n",
      "epoch:16 step:15782 [D loss: 0.649124, acc.: 64.84%] [G loss: 0.881426]\n",
      "epoch:16 step:15783 [D loss: 0.726484, acc.: 53.12%] [G loss: 0.909627]\n",
      "epoch:16 step:15784 [D loss: 0.624518, acc.: 65.62%] [G loss: 0.898076]\n",
      "epoch:16 step:15785 [D loss: 0.646914, acc.: 64.06%] [G loss: 0.949892]\n",
      "epoch:16 step:15786 [D loss: 0.641858, acc.: 65.62%] [G loss: 0.910732]\n",
      "epoch:16 step:15787 [D loss: 0.673470, acc.: 55.47%] [G loss: 0.939799]\n",
      "epoch:16 step:15788 [D loss: 0.652608, acc.: 60.94%] [G loss: 0.910951]\n",
      "epoch:16 step:15789 [D loss: 0.707323, acc.: 57.81%] [G loss: 0.920963]\n",
      "epoch:16 step:15790 [D loss: 0.642930, acc.: 63.28%] [G loss: 0.885447]\n",
      "epoch:16 step:15791 [D loss: 0.613581, acc.: 70.31%] [G loss: 0.906917]\n",
      "epoch:16 step:15792 [D loss: 0.697271, acc.: 55.47%] [G loss: 0.872651]\n",
      "epoch:16 step:15793 [D loss: 0.630244, acc.: 60.94%] [G loss: 0.942524]\n",
      "epoch:16 step:15794 [D loss: 0.623037, acc.: 66.41%] [G loss: 0.938609]\n",
      "epoch:16 step:15795 [D loss: 0.626207, acc.: 65.62%] [G loss: 1.017390]\n",
      "epoch:16 step:15796 [D loss: 0.650321, acc.: 61.72%] [G loss: 0.943750]\n",
      "epoch:16 step:15797 [D loss: 0.662008, acc.: 56.25%] [G loss: 0.830775]\n",
      "epoch:16 step:15798 [D loss: 0.658569, acc.: 57.81%] [G loss: 0.890409]\n",
      "epoch:16 step:15799 [D loss: 0.622440, acc.: 69.53%] [G loss: 0.886699]\n",
      "epoch:16 step:15800 [D loss: 0.716730, acc.: 50.00%] [G loss: 0.903228]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.145056\n",
      "FID: 7.407126\n",
      "0 = 11.711305456399902\n",
      "1 = 0.047117243120796015\n",
      "2 = 0.900950014591217\n",
      "3 = 0.8500999808311462\n",
      "4 = 0.9517999887466431\n",
      "5 = 0.9463430643081665\n",
      "6 = 0.8500999808311462\n",
      "7 = 5.7467311679512365\n",
      "8 = 0.05315654042751623\n",
      "9 = 0.6988499760627747\n",
      "10 = 0.6758999824523926\n",
      "11 = 0.7218000292778015\n",
      "12 = 0.7084162831306458\n",
      "13 = 0.6758999824523926\n",
      "14 = 8.145124435424805\n",
      "15 = 9.479114532470703\n",
      "16 = 0.12573102116584778\n",
      "17 = 8.145055770874023\n",
      "18 = 7.407126426696777\n",
      "epoch:16 step:15801 [D loss: 0.682552, acc.: 57.03%] [G loss: 0.860401]\n",
      "epoch:16 step:15802 [D loss: 0.653358, acc.: 63.28%] [G loss: 0.949246]\n",
      "epoch:16 step:15803 [D loss: 0.651121, acc.: 60.16%] [G loss: 0.896145]\n",
      "epoch:16 step:15804 [D loss: 0.670647, acc.: 60.94%] [G loss: 0.876789]\n",
      "epoch:16 step:15805 [D loss: 0.687525, acc.: 55.47%] [G loss: 0.907819]\n",
      "epoch:16 step:15806 [D loss: 0.655616, acc.: 65.62%] [G loss: 0.922207]\n",
      "epoch:16 step:15807 [D loss: 0.685214, acc.: 56.25%] [G loss: 0.961237]\n",
      "epoch:16 step:15808 [D loss: 0.635104, acc.: 64.84%] [G loss: 0.940708]\n",
      "epoch:16 step:15809 [D loss: 0.689628, acc.: 54.69%] [G loss: 0.907470]\n",
      "epoch:16 step:15810 [D loss: 0.674311, acc.: 54.69%] [G loss: 0.887031]\n",
      "epoch:16 step:15811 [D loss: 0.652726, acc.: 66.41%] [G loss: 0.912658]\n",
      "epoch:16 step:15812 [D loss: 0.787148, acc.: 42.19%] [G loss: 0.862417]\n",
      "epoch:16 step:15813 [D loss: 0.686155, acc.: 59.38%] [G loss: 0.884685]\n",
      "epoch:16 step:15814 [D loss: 0.635830, acc.: 60.94%] [G loss: 0.865813]\n",
      "epoch:16 step:15815 [D loss: 0.611830, acc.: 67.19%] [G loss: 0.868394]\n",
      "epoch:16 step:15816 [D loss: 0.671885, acc.: 60.16%] [G loss: 0.881500]\n",
      "epoch:16 step:15817 [D loss: 0.600433, acc.: 71.09%] [G loss: 0.889324]\n",
      "epoch:16 step:15818 [D loss: 0.620147, acc.: 64.06%] [G loss: 0.909000]\n",
      "epoch:16 step:15819 [D loss: 0.720535, acc.: 47.66%] [G loss: 0.858304]\n",
      "epoch:16 step:15820 [D loss: 0.695566, acc.: 53.12%] [G loss: 0.894851]\n",
      "epoch:16 step:15821 [D loss: 0.647345, acc.: 64.84%] [G loss: 0.893730]\n",
      "epoch:16 step:15822 [D loss: 0.635467, acc.: 66.41%] [G loss: 0.912173]\n",
      "epoch:16 step:15823 [D loss: 0.692880, acc.: 58.59%] [G loss: 0.893575]\n",
      "epoch:16 step:15824 [D loss: 0.637753, acc.: 63.28%] [G loss: 0.898729]\n",
      "epoch:16 step:15825 [D loss: 0.633255, acc.: 62.50%] [G loss: 0.899775]\n",
      "epoch:16 step:15826 [D loss: 0.685117, acc.: 55.47%] [G loss: 0.855291]\n",
      "epoch:16 step:15827 [D loss: 0.653964, acc.: 56.25%] [G loss: 0.887885]\n",
      "epoch:16 step:15828 [D loss: 0.632096, acc.: 69.53%] [G loss: 0.905892]\n",
      "epoch:16 step:15829 [D loss: 0.654794, acc.: 64.06%] [G loss: 0.874854]\n",
      "epoch:16 step:15830 [D loss: 0.622773, acc.: 68.75%] [G loss: 0.861468]\n",
      "epoch:16 step:15831 [D loss: 0.630518, acc.: 64.06%] [G loss: 0.875234]\n",
      "epoch:16 step:15832 [D loss: 0.668065, acc.: 58.59%] [G loss: 0.915416]\n",
      "epoch:16 step:15833 [D loss: 0.666049, acc.: 64.06%] [G loss: 0.948952]\n",
      "epoch:16 step:15834 [D loss: 0.600706, acc.: 70.31%] [G loss: 0.839335]\n",
      "epoch:16 step:15835 [D loss: 0.660078, acc.: 63.28%] [G loss: 0.883252]\n",
      "epoch:16 step:15836 [D loss: 0.641657, acc.: 62.50%] [G loss: 0.918640]\n",
      "epoch:16 step:15837 [D loss: 0.659257, acc.: 58.59%] [G loss: 0.891878]\n",
      "epoch:16 step:15838 [D loss: 0.684604, acc.: 60.94%] [G loss: 0.841522]\n",
      "epoch:16 step:15839 [D loss: 0.659490, acc.: 60.16%] [G loss: 0.833748]\n",
      "epoch:16 step:15840 [D loss: 0.692353, acc.: 57.03%] [G loss: 0.836269]\n",
      "epoch:16 step:15841 [D loss: 0.645478, acc.: 64.06%] [G loss: 0.832324]\n",
      "epoch:16 step:15842 [D loss: 0.680182, acc.: 54.69%] [G loss: 0.910624]\n",
      "epoch:16 step:15843 [D loss: 0.724179, acc.: 49.22%] [G loss: 0.876466]\n",
      "epoch:16 step:15844 [D loss: 0.624622, acc.: 65.62%] [G loss: 0.885639]\n",
      "epoch:16 step:15845 [D loss: 0.628997, acc.: 62.50%] [G loss: 0.927308]\n",
      "epoch:16 step:15846 [D loss: 0.654792, acc.: 62.50%] [G loss: 0.911679]\n",
      "epoch:16 step:15847 [D loss: 0.685206, acc.: 57.81%] [G loss: 0.950239]\n",
      "epoch:16 step:15848 [D loss: 0.660030, acc.: 59.38%] [G loss: 0.921190]\n",
      "epoch:16 step:15849 [D loss: 0.620342, acc.: 67.97%] [G loss: 0.968336]\n",
      "epoch:16 step:15850 [D loss: 0.752722, acc.: 39.06%] [G loss: 0.879730]\n",
      "epoch:16 step:15851 [D loss: 0.710712, acc.: 54.69%] [G loss: 0.935932]\n",
      "epoch:16 step:15852 [D loss: 0.645525, acc.: 64.06%] [G loss: 0.938465]\n",
      "epoch:16 step:15853 [D loss: 0.701197, acc.: 54.69%] [G loss: 0.857440]\n",
      "epoch:16 step:15854 [D loss: 0.653041, acc.: 60.16%] [G loss: 0.884378]\n",
      "epoch:16 step:15855 [D loss: 0.635743, acc.: 63.28%] [G loss: 0.906715]\n",
      "epoch:16 step:15856 [D loss: 0.695377, acc.: 53.91%] [G loss: 0.904349]\n",
      "epoch:16 step:15857 [D loss: 0.697436, acc.: 57.81%] [G loss: 0.836548]\n",
      "epoch:16 step:15858 [D loss: 0.650801, acc.: 61.72%] [G loss: 0.888264]\n",
      "epoch:16 step:15859 [D loss: 0.680758, acc.: 58.59%] [G loss: 0.888674]\n",
      "epoch:16 step:15860 [D loss: 0.622664, acc.: 61.72%] [G loss: 0.873972]\n",
      "epoch:16 step:15861 [D loss: 0.648197, acc.: 64.06%] [G loss: 0.935119]\n",
      "epoch:16 step:15862 [D loss: 0.621898, acc.: 66.41%] [G loss: 0.925481]\n",
      "epoch:16 step:15863 [D loss: 0.607885, acc.: 67.97%] [G loss: 0.921988]\n",
      "epoch:16 step:15864 [D loss: 0.638908, acc.: 63.28%] [G loss: 0.893706]\n",
      "epoch:16 step:15865 [D loss: 0.625836, acc.: 65.62%] [G loss: 0.931128]\n",
      "epoch:16 step:15866 [D loss: 0.674877, acc.: 58.59%] [G loss: 0.924219]\n",
      "epoch:16 step:15867 [D loss: 0.640728, acc.: 64.06%] [G loss: 0.885406]\n",
      "epoch:16 step:15868 [D loss: 0.651038, acc.: 61.72%] [G loss: 0.839730]\n",
      "epoch:16 step:15869 [D loss: 0.657016, acc.: 60.16%] [G loss: 0.845809]\n",
      "epoch:16 step:15870 [D loss: 0.704686, acc.: 52.34%] [G loss: 0.844205]\n",
      "epoch:16 step:15871 [D loss: 0.673153, acc.: 61.72%] [G loss: 0.887341]\n",
      "epoch:16 step:15872 [D loss: 0.712707, acc.: 55.47%] [G loss: 0.890209]\n",
      "epoch:16 step:15873 [D loss: 0.671068, acc.: 60.16%] [G loss: 0.873626]\n",
      "epoch:16 step:15874 [D loss: 0.687932, acc.: 56.25%] [G loss: 0.874743]\n",
      "epoch:16 step:15875 [D loss: 0.705263, acc.: 51.56%] [G loss: 0.896428]\n",
      "epoch:16 step:15876 [D loss: 0.612743, acc.: 69.53%] [G loss: 0.909364]\n",
      "epoch:16 step:15877 [D loss: 0.650144, acc.: 60.94%] [G loss: 0.931970]\n",
      "epoch:16 step:15878 [D loss: 0.654747, acc.: 56.25%] [G loss: 0.987852]\n",
      "epoch:16 step:15879 [D loss: 0.683966, acc.: 56.25%] [G loss: 0.921448]\n",
      "epoch:16 step:15880 [D loss: 0.668212, acc.: 60.16%] [G loss: 0.925418]\n",
      "epoch:16 step:15881 [D loss: 0.633486, acc.: 63.28%] [G loss: 0.976175]\n",
      "epoch:16 step:15882 [D loss: 0.632180, acc.: 61.72%] [G loss: 1.000070]\n",
      "epoch:16 step:15883 [D loss: 0.721722, acc.: 50.78%] [G loss: 0.875771]\n",
      "epoch:16 step:15884 [D loss: 0.761159, acc.: 45.31%] [G loss: 0.912414]\n",
      "epoch:16 step:15885 [D loss: 0.653041, acc.: 57.81%] [G loss: 0.864361]\n",
      "epoch:16 step:15886 [D loss: 0.626909, acc.: 61.72%] [G loss: 0.863419]\n",
      "epoch:16 step:15887 [D loss: 0.635464, acc.: 61.72%] [G loss: 0.872008]\n",
      "epoch:16 step:15888 [D loss: 0.649578, acc.: 60.16%] [G loss: 0.877727]\n",
      "epoch:16 step:15889 [D loss: 0.608265, acc.: 65.62%] [G loss: 0.941587]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15890 [D loss: 0.593578, acc.: 71.09%] [G loss: 0.912321]\n",
      "epoch:16 step:15891 [D loss: 0.615786, acc.: 64.84%] [G loss: 0.938916]\n",
      "epoch:16 step:15892 [D loss: 0.618190, acc.: 70.31%] [G loss: 0.967409]\n",
      "epoch:16 step:15893 [D loss: 0.668840, acc.: 63.28%] [G loss: 0.953889]\n",
      "epoch:16 step:15894 [D loss: 0.658462, acc.: 57.81%] [G loss: 0.973541]\n",
      "epoch:16 step:15895 [D loss: 0.635443, acc.: 69.53%] [G loss: 0.961230]\n",
      "epoch:16 step:15896 [D loss: 0.711833, acc.: 49.22%] [G loss: 1.014367]\n",
      "epoch:16 step:15897 [D loss: 0.629562, acc.: 63.28%] [G loss: 0.943319]\n",
      "epoch:16 step:15898 [D loss: 0.589795, acc.: 69.53%] [G loss: 0.993683]\n",
      "epoch:16 step:15899 [D loss: 0.676116, acc.: 57.81%] [G loss: 0.888547]\n",
      "epoch:16 step:15900 [D loss: 0.620721, acc.: 64.06%] [G loss: 0.978204]\n",
      "epoch:16 step:15901 [D loss: 0.580364, acc.: 67.19%] [G loss: 0.987636]\n",
      "epoch:16 step:15902 [D loss: 0.669293, acc.: 64.06%] [G loss: 0.898634]\n",
      "epoch:16 step:15903 [D loss: 0.692000, acc.: 57.03%] [G loss: 0.883331]\n",
      "epoch:16 step:15904 [D loss: 0.647093, acc.: 58.59%] [G loss: 0.836072]\n",
      "epoch:16 step:15905 [D loss: 0.652225, acc.: 62.50%] [G loss: 0.927958]\n",
      "epoch:16 step:15906 [D loss: 0.621021, acc.: 67.19%] [G loss: 0.881137]\n",
      "epoch:16 step:15907 [D loss: 0.756011, acc.: 52.34%] [G loss: 0.940239]\n",
      "epoch:16 step:15908 [D loss: 0.636107, acc.: 55.47%] [G loss: 0.861115]\n",
      "epoch:16 step:15909 [D loss: 0.662805, acc.: 63.28%] [G loss: 0.929719]\n",
      "epoch:16 step:15910 [D loss: 0.580731, acc.: 71.09%] [G loss: 0.958307]\n",
      "epoch:16 step:15911 [D loss: 0.599231, acc.: 67.19%] [G loss: 1.011055]\n",
      "epoch:16 step:15912 [D loss: 0.778393, acc.: 38.28%] [G loss: 0.962093]\n",
      "epoch:16 step:15913 [D loss: 0.623069, acc.: 67.19%] [G loss: 1.001490]\n",
      "epoch:16 step:15914 [D loss: 0.714291, acc.: 53.91%] [G loss: 0.930274]\n",
      "epoch:16 step:15915 [D loss: 0.642288, acc.: 61.72%] [G loss: 0.945214]\n",
      "epoch:16 step:15916 [D loss: 0.616257, acc.: 68.75%] [G loss: 0.924449]\n",
      "epoch:16 step:15917 [D loss: 0.606707, acc.: 67.97%] [G loss: 0.951257]\n",
      "epoch:16 step:15918 [D loss: 0.595756, acc.: 70.31%] [G loss: 1.015057]\n",
      "epoch:16 step:15919 [D loss: 0.630914, acc.: 67.19%] [G loss: 1.054299]\n",
      "epoch:16 step:15920 [D loss: 0.784829, acc.: 58.59%] [G loss: 1.123770]\n",
      "epoch:16 step:15921 [D loss: 0.594561, acc.: 66.41%] [G loss: 1.188392]\n",
      "epoch:16 step:15922 [D loss: 0.584433, acc.: 65.62%] [G loss: 1.134059]\n",
      "epoch:16 step:15923 [D loss: 0.684077, acc.: 57.03%] [G loss: 0.968012]\n",
      "epoch:16 step:15924 [D loss: 0.679771, acc.: 56.25%] [G loss: 0.905006]\n",
      "epoch:16 step:15925 [D loss: 0.632996, acc.: 64.06%] [G loss: 0.899140]\n",
      "epoch:16 step:15926 [D loss: 0.700212, acc.: 54.69%] [G loss: 0.967655]\n",
      "epoch:16 step:15927 [D loss: 0.591665, acc.: 69.53%] [G loss: 1.062067]\n",
      "epoch:16 step:15928 [D loss: 0.623603, acc.: 64.84%] [G loss: 1.098094]\n",
      "epoch:16 step:15929 [D loss: 0.586727, acc.: 71.09%] [G loss: 1.092999]\n",
      "epoch:17 step:15930 [D loss: 0.678221, acc.: 61.72%] [G loss: 0.991382]\n",
      "epoch:17 step:15931 [D loss: 0.770042, acc.: 52.34%] [G loss: 0.934766]\n",
      "epoch:17 step:15932 [D loss: 0.669798, acc.: 57.81%] [G loss: 0.957382]\n",
      "epoch:17 step:15933 [D loss: 0.678477, acc.: 54.69%] [G loss: 0.893294]\n",
      "epoch:17 step:15934 [D loss: 0.713225, acc.: 54.69%] [G loss: 0.850107]\n",
      "epoch:17 step:15935 [D loss: 0.639781, acc.: 58.59%] [G loss: 0.926910]\n",
      "epoch:17 step:15936 [D loss: 0.653433, acc.: 59.38%] [G loss: 0.903753]\n",
      "epoch:17 step:15937 [D loss: 0.682472, acc.: 56.25%] [G loss: 0.888176]\n",
      "epoch:17 step:15938 [D loss: 0.616961, acc.: 67.19%] [G loss: 0.917942]\n",
      "epoch:17 step:15939 [D loss: 0.651495, acc.: 60.16%] [G loss: 0.952599]\n",
      "epoch:17 step:15940 [D loss: 0.634178, acc.: 62.50%] [G loss: 0.946852]\n",
      "epoch:17 step:15941 [D loss: 0.667125, acc.: 63.28%] [G loss: 0.931614]\n",
      "epoch:17 step:15942 [D loss: 0.647249, acc.: 60.94%] [G loss: 0.931817]\n",
      "epoch:17 step:15943 [D loss: 0.614476, acc.: 66.41%] [G loss: 0.957247]\n",
      "epoch:17 step:15944 [D loss: 0.599148, acc.: 66.41%] [G loss: 0.919821]\n",
      "epoch:17 step:15945 [D loss: 0.568044, acc.: 73.44%] [G loss: 0.973704]\n",
      "epoch:17 step:15946 [D loss: 0.686164, acc.: 57.81%] [G loss: 0.964928]\n",
      "epoch:17 step:15947 [D loss: 0.686472, acc.: 58.59%] [G loss: 0.960604]\n",
      "epoch:17 step:15948 [D loss: 0.712556, acc.: 50.78%] [G loss: 1.041214]\n",
      "epoch:17 step:15949 [D loss: 0.734765, acc.: 50.78%] [G loss: 1.101539]\n",
      "epoch:17 step:15950 [D loss: 0.691669, acc.: 56.25%] [G loss: 1.079352]\n",
      "epoch:17 step:15951 [D loss: 0.566548, acc.: 73.44%] [G loss: 1.069948]\n",
      "epoch:17 step:15952 [D loss: 0.729463, acc.: 50.78%] [G loss: 0.908039]\n",
      "epoch:17 step:15953 [D loss: 0.638835, acc.: 64.06%] [G loss: 0.883209]\n",
      "epoch:17 step:15954 [D loss: 0.619714, acc.: 64.84%] [G loss: 0.909513]\n",
      "epoch:17 step:15955 [D loss: 0.682315, acc.: 55.47%] [G loss: 0.900395]\n",
      "epoch:17 step:15956 [D loss: 0.679145, acc.: 57.03%] [G loss: 0.909426]\n",
      "epoch:17 step:15957 [D loss: 0.663792, acc.: 60.94%] [G loss: 0.938188]\n",
      "epoch:17 step:15958 [D loss: 0.650889, acc.: 59.38%] [G loss: 0.948116]\n",
      "epoch:17 step:15959 [D loss: 0.652682, acc.: 56.25%] [G loss: 0.918321]\n",
      "epoch:17 step:15960 [D loss: 0.660467, acc.: 61.72%] [G loss: 0.931484]\n",
      "epoch:17 step:15961 [D loss: 0.644761, acc.: 61.72%] [G loss: 1.007519]\n",
      "epoch:17 step:15962 [D loss: 0.641424, acc.: 65.62%] [G loss: 0.968856]\n",
      "epoch:17 step:15963 [D loss: 0.655718, acc.: 61.72%] [G loss: 0.925975]\n",
      "epoch:17 step:15964 [D loss: 0.640201, acc.: 53.12%] [G loss: 0.851993]\n",
      "epoch:17 step:15965 [D loss: 0.631793, acc.: 71.09%] [G loss: 0.902274]\n",
      "epoch:17 step:15966 [D loss: 0.716799, acc.: 50.00%] [G loss: 0.937941]\n",
      "epoch:17 step:15967 [D loss: 0.709716, acc.: 49.22%] [G loss: 0.903166]\n",
      "epoch:17 step:15968 [D loss: 0.674506, acc.: 57.03%] [G loss: 0.861884]\n",
      "epoch:17 step:15969 [D loss: 0.595732, acc.: 67.97%] [G loss: 0.875694]\n",
      "epoch:17 step:15970 [D loss: 0.698010, acc.: 53.91%] [G loss: 0.975607]\n",
      "epoch:17 step:15971 [D loss: 0.672845, acc.: 62.50%] [G loss: 0.921892]\n",
      "epoch:17 step:15972 [D loss: 0.668000, acc.: 57.03%] [G loss: 0.885890]\n",
      "epoch:17 step:15973 [D loss: 0.700063, acc.: 53.12%] [G loss: 0.895778]\n",
      "epoch:17 step:15974 [D loss: 0.654670, acc.: 58.59%] [G loss: 0.913812]\n",
      "epoch:17 step:15975 [D loss: 0.633057, acc.: 61.72%] [G loss: 0.986972]\n",
      "epoch:17 step:15976 [D loss: 0.656629, acc.: 64.06%] [G loss: 0.863926]\n",
      "epoch:17 step:15977 [D loss: 0.652883, acc.: 57.03%] [G loss: 0.902586]\n",
      "epoch:17 step:15978 [D loss: 0.617174, acc.: 67.97%] [G loss: 0.938364]\n",
      "epoch:17 step:15979 [D loss: 0.636521, acc.: 67.19%] [G loss: 0.972692]\n",
      "epoch:17 step:15980 [D loss: 0.616850, acc.: 67.19%] [G loss: 0.916582]\n",
      "epoch:17 step:15981 [D loss: 0.654524, acc.: 67.19%] [G loss: 0.900716]\n",
      "epoch:17 step:15982 [D loss: 0.641361, acc.: 61.72%] [G loss: 0.976820]\n",
      "epoch:17 step:15983 [D loss: 0.640399, acc.: 65.62%] [G loss: 0.874943]\n",
      "epoch:17 step:15984 [D loss: 0.621908, acc.: 67.19%] [G loss: 0.934676]\n",
      "epoch:17 step:15985 [D loss: 0.678803, acc.: 55.47%] [G loss: 0.895306]\n",
      "epoch:17 step:15986 [D loss: 0.698684, acc.: 55.47%] [G loss: 0.868764]\n",
      "epoch:17 step:15987 [D loss: 0.738827, acc.: 50.00%] [G loss: 0.868694]\n",
      "epoch:17 step:15988 [D loss: 0.659432, acc.: 61.72%] [G loss: 0.842120]\n",
      "epoch:17 step:15989 [D loss: 0.670952, acc.: 61.72%] [G loss: 0.852655]\n",
      "epoch:17 step:15990 [D loss: 0.689204, acc.: 56.25%] [G loss: 0.833084]\n",
      "epoch:17 step:15991 [D loss: 0.647279, acc.: 64.84%] [G loss: 0.882974]\n",
      "epoch:17 step:15992 [D loss: 0.654859, acc.: 55.47%] [G loss: 0.886224]\n",
      "epoch:17 step:15993 [D loss: 0.655189, acc.: 64.06%] [G loss: 0.822154]\n",
      "epoch:17 step:15994 [D loss: 0.632305, acc.: 60.16%] [G loss: 0.861001]\n",
      "epoch:17 step:15995 [D loss: 0.679062, acc.: 61.72%] [G loss: 0.817768]\n",
      "epoch:17 step:15996 [D loss: 0.636119, acc.: 67.19%] [G loss: 0.874098]\n",
      "epoch:17 step:15997 [D loss: 0.661287, acc.: 58.59%] [G loss: 0.849741]\n",
      "epoch:17 step:15998 [D loss: 0.642838, acc.: 62.50%] [G loss: 0.912419]\n",
      "epoch:17 step:15999 [D loss: 0.650863, acc.: 67.19%] [G loss: 0.975385]\n",
      "epoch:17 step:16000 [D loss: 0.688464, acc.: 57.03%] [G loss: 0.901785]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.097082\n",
      "FID: 8.237429\n",
      "0 = 11.9093496747971\n",
      "1 = 0.05656796760898893\n",
      "2 = 0.9101999998092651\n",
      "3 = 0.8687000274658203\n",
      "4 = 0.95169997215271\n",
      "5 = 0.9473282694816589\n",
      "6 = 0.8687000274658203\n",
      "7 = 5.923459838250276\n",
      "8 = 0.06504687013243511\n",
      "9 = 0.705049991607666\n",
      "10 = 0.6807000041007996\n",
      "11 = 0.7293999791145325\n",
      "12 = 0.7155471444129944\n",
      "13 = 0.6807000041007996\n",
      "14 = 8.097150802612305\n",
      "15 = 9.497127532958984\n",
      "16 = 0.11752042174339294\n",
      "17 = 8.097082138061523\n",
      "18 = 8.237428665161133\n",
      "epoch:17 step:16001 [D loss: 0.678484, acc.: 64.06%] [G loss: 0.948937]\n",
      "epoch:17 step:16002 [D loss: 0.652611, acc.: 60.94%] [G loss: 0.927085]\n",
      "epoch:17 step:16003 [D loss: 0.628739, acc.: 67.19%] [G loss: 0.884563]\n",
      "epoch:17 step:16004 [D loss: 0.646915, acc.: 68.75%] [G loss: 1.030182]\n",
      "epoch:17 step:16005 [D loss: 0.616966, acc.: 65.62%] [G loss: 0.949035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16006 [D loss: 0.577528, acc.: 67.97%] [G loss: 0.996800]\n",
      "epoch:17 step:16007 [D loss: 0.728727, acc.: 56.25%] [G loss: 0.868412]\n",
      "epoch:17 step:16008 [D loss: 0.631408, acc.: 61.72%] [G loss: 0.938902]\n",
      "epoch:17 step:16009 [D loss: 0.622945, acc.: 65.62%] [G loss: 0.866060]\n",
      "epoch:17 step:16010 [D loss: 0.645885, acc.: 63.28%] [G loss: 0.842729]\n",
      "epoch:17 step:16011 [D loss: 0.615203, acc.: 67.19%] [G loss: 0.845249]\n",
      "epoch:17 step:16012 [D loss: 0.678225, acc.: 60.16%] [G loss: 0.851488]\n",
      "epoch:17 step:16013 [D loss: 0.629391, acc.: 63.28%] [G loss: 0.844403]\n",
      "epoch:17 step:16014 [D loss: 0.653847, acc.: 61.72%] [G loss: 0.921051]\n",
      "epoch:17 step:16015 [D loss: 0.674958, acc.: 58.59%] [G loss: 0.972873]\n",
      "epoch:17 step:16016 [D loss: 0.695026, acc.: 54.69%] [G loss: 0.939741]\n",
      "epoch:17 step:16017 [D loss: 0.663570, acc.: 60.16%] [G loss: 0.931099]\n",
      "epoch:17 step:16018 [D loss: 0.682598, acc.: 57.81%] [G loss: 0.877251]\n",
      "epoch:17 step:16019 [D loss: 0.622180, acc.: 65.62%] [G loss: 0.862420]\n",
      "epoch:17 step:16020 [D loss: 0.668682, acc.: 62.50%] [G loss: 0.912738]\n",
      "epoch:17 step:16021 [D loss: 0.614983, acc.: 61.72%] [G loss: 0.935477]\n",
      "epoch:17 step:16022 [D loss: 0.629753, acc.: 67.19%] [G loss: 0.976125]\n",
      "epoch:17 step:16023 [D loss: 0.663438, acc.: 58.59%] [G loss: 0.914430]\n",
      "epoch:17 step:16024 [D loss: 0.623774, acc.: 61.72%] [G loss: 0.949778]\n",
      "epoch:17 step:16025 [D loss: 0.608185, acc.: 66.41%] [G loss: 0.962062]\n",
      "epoch:17 step:16026 [D loss: 0.637481, acc.: 66.41%] [G loss: 1.018498]\n",
      "epoch:17 step:16027 [D loss: 0.666233, acc.: 60.94%] [G loss: 1.068350]\n",
      "epoch:17 step:16028 [D loss: 0.689665, acc.: 59.38%] [G loss: 0.992389]\n",
      "epoch:17 step:16029 [D loss: 0.642525, acc.: 62.50%] [G loss: 0.995129]\n",
      "epoch:17 step:16030 [D loss: 0.669989, acc.: 57.81%] [G loss: 0.907913]\n",
      "epoch:17 step:16031 [D loss: 0.714554, acc.: 56.25%] [G loss: 0.949414]\n",
      "epoch:17 step:16032 [D loss: 0.651662, acc.: 61.72%] [G loss: 0.873488]\n",
      "epoch:17 step:16033 [D loss: 0.658609, acc.: 64.84%] [G loss: 0.894035]\n",
      "epoch:17 step:16034 [D loss: 0.663465, acc.: 58.59%] [G loss: 0.918512]\n",
      "epoch:17 step:16035 [D loss: 0.644333, acc.: 64.06%] [G loss: 0.866094]\n",
      "epoch:17 step:16036 [D loss: 0.606360, acc.: 64.06%] [G loss: 0.987529]\n",
      "epoch:17 step:16037 [D loss: 0.735113, acc.: 53.91%] [G loss: 0.982465]\n",
      "epoch:17 step:16038 [D loss: 0.695244, acc.: 59.38%] [G loss: 0.896213]\n",
      "epoch:17 step:16039 [D loss: 0.664953, acc.: 56.25%] [G loss: 0.892491]\n",
      "epoch:17 step:16040 [D loss: 0.614114, acc.: 65.62%] [G loss: 0.883953]\n",
      "epoch:17 step:16041 [D loss: 0.612517, acc.: 69.53%] [G loss: 0.911454]\n",
      "epoch:17 step:16042 [D loss: 0.626010, acc.: 67.97%] [G loss: 0.960111]\n",
      "epoch:17 step:16043 [D loss: 0.622330, acc.: 64.84%] [G loss: 0.967263]\n",
      "epoch:17 step:16044 [D loss: 0.593497, acc.: 71.88%] [G loss: 1.009200]\n",
      "epoch:17 step:16045 [D loss: 0.594416, acc.: 66.41%] [G loss: 0.989331]\n",
      "epoch:17 step:16046 [D loss: 0.647477, acc.: 58.59%] [G loss: 0.986921]\n",
      "epoch:17 step:16047 [D loss: 0.667185, acc.: 58.59%] [G loss: 0.969993]\n",
      "epoch:17 step:16048 [D loss: 0.541446, acc.: 75.00%] [G loss: 1.067283]\n",
      "epoch:17 step:16049 [D loss: 0.692077, acc.: 57.03%] [G loss: 0.993172]\n",
      "epoch:17 step:16050 [D loss: 0.730324, acc.: 54.69%] [G loss: 0.913526]\n",
      "epoch:17 step:16051 [D loss: 0.640219, acc.: 63.28%] [G loss: 0.946438]\n",
      "epoch:17 step:16052 [D loss: 0.674410, acc.: 59.38%] [G loss: 0.930320]\n",
      "epoch:17 step:16053 [D loss: 0.692803, acc.: 57.03%] [G loss: 0.976629]\n",
      "epoch:17 step:16054 [D loss: 0.677180, acc.: 56.25%] [G loss: 0.918076]\n",
      "epoch:17 step:16055 [D loss: 0.609885, acc.: 66.41%] [G loss: 0.872662]\n",
      "epoch:17 step:16056 [D loss: 0.631471, acc.: 66.41%] [G loss: 0.898290]\n",
      "epoch:17 step:16057 [D loss: 0.683696, acc.: 54.69%] [G loss: 0.895614]\n",
      "epoch:17 step:16058 [D loss: 0.669711, acc.: 58.59%] [G loss: 0.890031]\n",
      "epoch:17 step:16059 [D loss: 0.630636, acc.: 60.16%] [G loss: 0.889163]\n",
      "epoch:17 step:16060 [D loss: 0.657345, acc.: 63.28%] [G loss: 0.904172]\n",
      "epoch:17 step:16061 [D loss: 0.631263, acc.: 64.84%] [G loss: 0.934794]\n",
      "epoch:17 step:16062 [D loss: 0.638986, acc.: 59.38%] [G loss: 1.008558]\n",
      "epoch:17 step:16063 [D loss: 0.611204, acc.: 65.62%] [G loss: 0.957590]\n",
      "epoch:17 step:16064 [D loss: 0.592260, acc.: 68.75%] [G loss: 0.964336]\n",
      "epoch:17 step:16065 [D loss: 0.621417, acc.: 69.53%] [G loss: 1.006772]\n",
      "epoch:17 step:16066 [D loss: 0.719612, acc.: 57.81%] [G loss: 0.934522]\n",
      "epoch:17 step:16067 [D loss: 0.674351, acc.: 57.03%] [G loss: 0.910844]\n",
      "epoch:17 step:16068 [D loss: 0.743093, acc.: 53.91%] [G loss: 0.900797]\n",
      "epoch:17 step:16069 [D loss: 0.679490, acc.: 56.25%] [G loss: 0.943406]\n",
      "epoch:17 step:16070 [D loss: 0.669591, acc.: 57.81%] [G loss: 0.936382]\n",
      "epoch:17 step:16071 [D loss: 0.676804, acc.: 56.25%] [G loss: 0.834331]\n",
      "epoch:17 step:16072 [D loss: 0.662934, acc.: 59.38%] [G loss: 0.856764]\n",
      "epoch:17 step:16073 [D loss: 0.650571, acc.: 65.62%] [G loss: 0.949386]\n",
      "epoch:17 step:16074 [D loss: 0.636781, acc.: 64.84%] [G loss: 0.957611]\n",
      "epoch:17 step:16075 [D loss: 0.674143, acc.: 56.25%] [G loss: 0.915761]\n",
      "epoch:17 step:16076 [D loss: 0.682447, acc.: 57.81%] [G loss: 0.933198]\n",
      "epoch:17 step:16077 [D loss: 0.692976, acc.: 54.69%] [G loss: 0.962809]\n",
      "epoch:17 step:16078 [D loss: 0.653646, acc.: 57.03%] [G loss: 0.908195]\n",
      "epoch:17 step:16079 [D loss: 0.683717, acc.: 57.81%] [G loss: 0.945493]\n",
      "epoch:17 step:16080 [D loss: 0.623600, acc.: 65.62%] [G loss: 0.946368]\n",
      "epoch:17 step:16081 [D loss: 0.664718, acc.: 60.94%] [G loss: 0.946113]\n",
      "epoch:17 step:16082 [D loss: 0.680969, acc.: 54.69%] [G loss: 0.864273]\n",
      "epoch:17 step:16083 [D loss: 0.636336, acc.: 65.62%] [G loss: 0.939586]\n",
      "epoch:17 step:16084 [D loss: 0.665553, acc.: 60.94%] [G loss: 0.877049]\n",
      "epoch:17 step:16085 [D loss: 0.633012, acc.: 62.50%] [G loss: 0.924997]\n",
      "epoch:17 step:16086 [D loss: 0.677724, acc.: 60.94%] [G loss: 0.912563]\n",
      "epoch:17 step:16087 [D loss: 0.663266, acc.: 58.59%] [G loss: 0.877856]\n",
      "epoch:17 step:16088 [D loss: 0.643932, acc.: 62.50%] [G loss: 0.910486]\n",
      "epoch:17 step:16089 [D loss: 0.771057, acc.: 50.00%] [G loss: 0.989030]\n",
      "epoch:17 step:16090 [D loss: 0.696618, acc.: 53.91%] [G loss: 1.001424]\n",
      "epoch:17 step:16091 [D loss: 0.718390, acc.: 46.09%] [G loss: 0.874741]\n",
      "epoch:17 step:16092 [D loss: 0.674786, acc.: 60.94%] [G loss: 0.854212]\n",
      "epoch:17 step:16093 [D loss: 0.657072, acc.: 60.94%] [G loss: 0.935953]\n",
      "epoch:17 step:16094 [D loss: 0.620194, acc.: 64.84%] [G loss: 0.913821]\n",
      "epoch:17 step:16095 [D loss: 0.654884, acc.: 59.38%] [G loss: 0.891023]\n",
      "epoch:17 step:16096 [D loss: 0.652538, acc.: 60.16%] [G loss: 0.908635]\n",
      "epoch:17 step:16097 [D loss: 0.648114, acc.: 61.72%] [G loss: 0.860895]\n",
      "epoch:17 step:16098 [D loss: 0.634165, acc.: 64.06%] [G loss: 0.891970]\n",
      "epoch:17 step:16099 [D loss: 0.647673, acc.: 65.62%] [G loss: 0.849895]\n",
      "epoch:17 step:16100 [D loss: 0.664308, acc.: 57.81%] [G loss: 0.860834]\n",
      "epoch:17 step:16101 [D loss: 0.688870, acc.: 53.12%] [G loss: 0.802503]\n",
      "epoch:17 step:16102 [D loss: 0.658402, acc.: 60.94%] [G loss: 0.900635]\n",
      "epoch:17 step:16103 [D loss: 0.676985, acc.: 61.72%] [G loss: 0.810630]\n",
      "epoch:17 step:16104 [D loss: 0.666526, acc.: 63.28%] [G loss: 0.902859]\n",
      "epoch:17 step:16105 [D loss: 0.636369, acc.: 61.72%] [G loss: 0.835479]\n",
      "epoch:17 step:16106 [D loss: 0.665173, acc.: 56.25%] [G loss: 0.841430]\n",
      "epoch:17 step:16107 [D loss: 0.687687, acc.: 54.69%] [G loss: 0.886045]\n",
      "epoch:17 step:16108 [D loss: 0.641223, acc.: 63.28%] [G loss: 0.912868]\n",
      "epoch:17 step:16109 [D loss: 0.663904, acc.: 60.94%] [G loss: 0.860670]\n",
      "epoch:17 step:16110 [D loss: 0.663377, acc.: 61.72%] [G loss: 0.854078]\n",
      "epoch:17 step:16111 [D loss: 0.678250, acc.: 56.25%] [G loss: 0.901507]\n",
      "epoch:17 step:16112 [D loss: 0.659187, acc.: 64.84%] [G loss: 0.933616]\n",
      "epoch:17 step:16113 [D loss: 0.625874, acc.: 66.41%] [G loss: 0.910255]\n",
      "epoch:17 step:16114 [D loss: 0.667361, acc.: 59.38%] [G loss: 0.846170]\n",
      "epoch:17 step:16115 [D loss: 0.703498, acc.: 58.59%] [G loss: 0.898453]\n",
      "epoch:17 step:16116 [D loss: 0.647508, acc.: 59.38%] [G loss: 0.902357]\n",
      "epoch:17 step:16117 [D loss: 0.686324, acc.: 53.91%] [G loss: 0.934693]\n",
      "epoch:17 step:16118 [D loss: 0.683179, acc.: 57.03%] [G loss: 0.914890]\n",
      "epoch:17 step:16119 [D loss: 0.640859, acc.: 57.81%] [G loss: 0.831587]\n",
      "epoch:17 step:16120 [D loss: 0.610103, acc.: 61.72%] [G loss: 0.887073]\n",
      "epoch:17 step:16121 [D loss: 0.671283, acc.: 56.25%] [G loss: 0.908875]\n",
      "epoch:17 step:16122 [D loss: 0.686650, acc.: 55.47%] [G loss: 0.861336]\n",
      "epoch:17 step:16123 [D loss: 0.629593, acc.: 64.84%] [G loss: 0.943182]\n",
      "epoch:17 step:16124 [D loss: 0.650557, acc.: 60.94%] [G loss: 0.921326]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16125 [D loss: 0.679675, acc.: 56.25%] [G loss: 0.917972]\n",
      "epoch:17 step:16126 [D loss: 0.625618, acc.: 60.94%] [G loss: 0.950519]\n",
      "epoch:17 step:16127 [D loss: 0.639262, acc.: 61.72%] [G loss: 0.987944]\n",
      "epoch:17 step:16128 [D loss: 0.669710, acc.: 57.81%] [G loss: 0.951285]\n",
      "epoch:17 step:16129 [D loss: 0.742650, acc.: 46.88%] [G loss: 0.951812]\n",
      "epoch:17 step:16130 [D loss: 0.627697, acc.: 64.06%] [G loss: 0.957452]\n",
      "epoch:17 step:16131 [D loss: 0.680647, acc.: 58.59%] [G loss: 0.892659]\n",
      "epoch:17 step:16132 [D loss: 0.701570, acc.: 54.69%] [G loss: 0.893557]\n",
      "epoch:17 step:16133 [D loss: 0.672644, acc.: 59.38%] [G loss: 0.905758]\n",
      "epoch:17 step:16134 [D loss: 0.636530, acc.: 64.84%] [G loss: 0.917279]\n",
      "epoch:17 step:16135 [D loss: 0.612050, acc.: 67.97%] [G loss: 0.924458]\n",
      "epoch:17 step:16136 [D loss: 0.602323, acc.: 66.41%] [G loss: 0.906445]\n",
      "epoch:17 step:16137 [D loss: 0.596247, acc.: 67.97%] [G loss: 0.897003]\n",
      "epoch:17 step:16138 [D loss: 0.558502, acc.: 70.31%] [G loss: 0.893455]\n",
      "epoch:17 step:16139 [D loss: 0.749712, acc.: 49.22%] [G loss: 0.898800]\n",
      "epoch:17 step:16140 [D loss: 0.667590, acc.: 59.38%] [G loss: 0.918824]\n",
      "epoch:17 step:16141 [D loss: 0.656350, acc.: 64.84%] [G loss: 0.861351]\n",
      "epoch:17 step:16142 [D loss: 0.653858, acc.: 59.38%] [G loss: 0.859888]\n",
      "epoch:17 step:16143 [D loss: 0.735627, acc.: 49.22%] [G loss: 0.919048]\n",
      "epoch:17 step:16144 [D loss: 0.669909, acc.: 58.59%] [G loss: 0.885086]\n",
      "epoch:17 step:16145 [D loss: 0.601599, acc.: 67.97%] [G loss: 0.867060]\n",
      "epoch:17 step:16146 [D loss: 0.654930, acc.: 57.81%] [G loss: 0.914481]\n",
      "epoch:17 step:16147 [D loss: 0.597089, acc.: 67.19%] [G loss: 0.909495]\n",
      "epoch:17 step:16148 [D loss: 0.588176, acc.: 67.19%] [G loss: 0.955198]\n",
      "epoch:17 step:16149 [D loss: 0.778921, acc.: 47.66%] [G loss: 0.924660]\n",
      "epoch:17 step:16150 [D loss: 0.644598, acc.: 67.19%] [G loss: 0.896535]\n",
      "epoch:17 step:16151 [D loss: 0.620385, acc.: 66.41%] [G loss: 0.941695]\n",
      "epoch:17 step:16152 [D loss: 0.659149, acc.: 59.38%] [G loss: 0.882776]\n",
      "epoch:17 step:16153 [D loss: 0.669162, acc.: 56.25%] [G loss: 0.895157]\n",
      "epoch:17 step:16154 [D loss: 0.659136, acc.: 62.50%] [G loss: 0.837039]\n",
      "epoch:17 step:16155 [D loss: 0.682186, acc.: 50.78%] [G loss: 0.831037]\n",
      "epoch:17 step:16156 [D loss: 0.665333, acc.: 59.38%] [G loss: 0.863292]\n",
      "epoch:17 step:16157 [D loss: 0.649169, acc.: 57.81%] [G loss: 0.831876]\n",
      "epoch:17 step:16158 [D loss: 0.654526, acc.: 64.06%] [G loss: 0.853638]\n",
      "epoch:17 step:16159 [D loss: 0.598280, acc.: 68.75%] [G loss: 0.971994]\n",
      "epoch:17 step:16160 [D loss: 0.579807, acc.: 70.31%] [G loss: 1.030606]\n",
      "epoch:17 step:16161 [D loss: 0.584224, acc.: 70.31%] [G loss: 1.080533]\n",
      "epoch:17 step:16162 [D loss: 0.702212, acc.: 57.81%] [G loss: 0.891689]\n",
      "epoch:17 step:16163 [D loss: 0.707633, acc.: 53.91%] [G loss: 0.959014]\n",
      "epoch:17 step:16164 [D loss: 0.703339, acc.: 53.12%] [G loss: 0.921874]\n",
      "epoch:17 step:16165 [D loss: 0.645000, acc.: 60.94%] [G loss: 0.945122]\n",
      "epoch:17 step:16166 [D loss: 0.714536, acc.: 48.44%] [G loss: 0.910667]\n",
      "epoch:17 step:16167 [D loss: 0.653214, acc.: 64.84%] [G loss: 0.980368]\n",
      "epoch:17 step:16168 [D loss: 0.609125, acc.: 66.41%] [G loss: 0.902090]\n",
      "epoch:17 step:16169 [D loss: 0.728773, acc.: 51.56%] [G loss: 0.922325]\n",
      "epoch:17 step:16170 [D loss: 0.654191, acc.: 55.47%] [G loss: 0.921263]\n",
      "epoch:17 step:16171 [D loss: 0.586179, acc.: 70.31%] [G loss: 0.964940]\n",
      "epoch:17 step:16172 [D loss: 0.631170, acc.: 64.06%] [G loss: 0.889109]\n",
      "epoch:17 step:16173 [D loss: 0.627264, acc.: 64.84%] [G loss: 0.918507]\n",
      "epoch:17 step:16174 [D loss: 0.636446, acc.: 63.28%] [G loss: 0.916897]\n",
      "epoch:17 step:16175 [D loss: 0.631906, acc.: 59.38%] [G loss: 0.934878]\n",
      "epoch:17 step:16176 [D loss: 0.660812, acc.: 57.03%] [G loss: 0.965514]\n",
      "epoch:17 step:16177 [D loss: 0.613040, acc.: 66.41%] [G loss: 0.927545]\n",
      "epoch:17 step:16178 [D loss: 0.717609, acc.: 45.31%] [G loss: 0.933801]\n",
      "epoch:17 step:16179 [D loss: 0.741317, acc.: 47.66%] [G loss: 0.877265]\n",
      "epoch:17 step:16180 [D loss: 0.718166, acc.: 53.91%] [G loss: 0.938314]\n",
      "epoch:17 step:16181 [D loss: 0.643421, acc.: 58.59%] [G loss: 0.929067]\n",
      "epoch:17 step:16182 [D loss: 0.672634, acc.: 60.94%] [G loss: 0.865254]\n",
      "epoch:17 step:16183 [D loss: 0.668364, acc.: 60.94%] [G loss: 0.893810]\n",
      "epoch:17 step:16184 [D loss: 0.621800, acc.: 65.62%] [G loss: 0.852106]\n",
      "epoch:17 step:16185 [D loss: 0.630507, acc.: 61.72%] [G loss: 0.935961]\n",
      "epoch:17 step:16186 [D loss: 0.671937, acc.: 59.38%] [G loss: 0.936783]\n",
      "epoch:17 step:16187 [D loss: 0.605321, acc.: 68.75%] [G loss: 0.876655]\n",
      "epoch:17 step:16188 [D loss: 0.655245, acc.: 57.81%] [G loss: 0.931177]\n",
      "epoch:17 step:16189 [D loss: 0.653585, acc.: 62.50%] [G loss: 0.901060]\n",
      "epoch:17 step:16190 [D loss: 0.658207, acc.: 60.94%] [G loss: 0.994997]\n",
      "epoch:17 step:16191 [D loss: 0.653538, acc.: 59.38%] [G loss: 0.934024]\n",
      "epoch:17 step:16192 [D loss: 0.742924, acc.: 46.09%] [G loss: 0.894020]\n",
      "epoch:17 step:16193 [D loss: 0.595062, acc.: 75.00%] [G loss: 0.920223]\n",
      "epoch:17 step:16194 [D loss: 0.671650, acc.: 57.03%] [G loss: 0.881486]\n",
      "epoch:17 step:16195 [D loss: 0.644194, acc.: 59.38%] [G loss: 0.907018]\n",
      "epoch:17 step:16196 [D loss: 0.682107, acc.: 56.25%] [G loss: 0.846264]\n",
      "epoch:17 step:16197 [D loss: 0.659479, acc.: 61.72%] [G loss: 0.938210]\n",
      "epoch:17 step:16198 [D loss: 0.642888, acc.: 60.16%] [G loss: 0.924198]\n",
      "epoch:17 step:16199 [D loss: 0.643496, acc.: 63.28%] [G loss: 0.938962]\n",
      "epoch:17 step:16200 [D loss: 0.628256, acc.: 60.94%] [G loss: 0.908491]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.286363\n",
      "FID: 5.554096\n",
      "0 = 11.575166582465176\n",
      "1 = 0.041368690585888934\n",
      "2 = 0.8979499936103821\n",
      "3 = 0.8460000157356262\n",
      "4 = 0.9498999714851379\n",
      "5 = 0.9440910816192627\n",
      "6 = 0.8460000157356262\n",
      "7 = 5.389902086770521\n",
      "8 = 0.04939973042835399\n",
      "9 = 0.6845499873161316\n",
      "10 = 0.659600019454956\n",
      "11 = 0.7095000147819519\n",
      "12 = 0.6942427158355713\n",
      "13 = 0.659600019454956\n",
      "14 = 8.286430358886719\n",
      "15 = 9.645349502563477\n",
      "16 = 0.06808136403560638\n",
      "17 = 8.286362648010254\n",
      "18 = 5.55409574508667\n",
      "epoch:17 step:16201 [D loss: 0.653813, acc.: 62.50%] [G loss: 0.958506]\n",
      "epoch:17 step:16202 [D loss: 0.666952, acc.: 63.28%] [G loss: 0.900162]\n",
      "epoch:17 step:16203 [D loss: 0.640811, acc.: 64.06%] [G loss: 0.883389]\n",
      "epoch:17 step:16204 [D loss: 0.659923, acc.: 60.94%] [G loss: 0.872874]\n",
      "epoch:17 step:16205 [D loss: 0.638110, acc.: 63.28%] [G loss: 0.862933]\n",
      "epoch:17 step:16206 [D loss: 0.707260, acc.: 52.34%] [G loss: 0.858811]\n",
      "epoch:17 step:16207 [D loss: 0.716555, acc.: 50.00%] [G loss: 0.842115]\n",
      "epoch:17 step:16208 [D loss: 0.665079, acc.: 60.16%] [G loss: 0.915811]\n",
      "epoch:17 step:16209 [D loss: 0.628852, acc.: 63.28%] [G loss: 0.968673]\n",
      "epoch:17 step:16210 [D loss: 0.677253, acc.: 60.16%] [G loss: 0.858705]\n",
      "epoch:17 step:16211 [D loss: 0.680561, acc.: 53.91%] [G loss: 0.868238]\n",
      "epoch:17 step:16212 [D loss: 0.614172, acc.: 65.62%] [G loss: 0.980052]\n",
      "epoch:17 step:16213 [D loss: 0.670054, acc.: 57.03%] [G loss: 0.858274]\n",
      "epoch:17 step:16214 [D loss: 0.668920, acc.: 57.81%] [G loss: 0.910375]\n",
      "epoch:17 step:16215 [D loss: 0.598613, acc.: 71.88%] [G loss: 0.921313]\n",
      "epoch:17 step:16216 [D loss: 0.647371, acc.: 64.06%] [G loss: 0.871827]\n",
      "epoch:17 step:16217 [D loss: 0.659629, acc.: 57.81%] [G loss: 0.931902]\n",
      "epoch:17 step:16218 [D loss: 0.587585, acc.: 74.22%] [G loss: 1.039679]\n",
      "epoch:17 step:16219 [D loss: 0.667480, acc.: 60.94%] [G loss: 0.961455]\n",
      "epoch:17 step:16220 [D loss: 0.717674, acc.: 50.00%] [G loss: 0.916590]\n",
      "epoch:17 step:16221 [D loss: 0.691332, acc.: 54.69%] [G loss: 0.886104]\n",
      "epoch:17 step:16222 [D loss: 0.632446, acc.: 64.06%] [G loss: 0.907344]\n",
      "epoch:17 step:16223 [D loss: 0.692074, acc.: 53.12%] [G loss: 0.884908]\n",
      "epoch:17 step:16224 [D loss: 0.642190, acc.: 57.03%] [G loss: 0.911114]\n",
      "epoch:17 step:16225 [D loss: 0.606344, acc.: 70.31%] [G loss: 0.921287]\n",
      "epoch:17 step:16226 [D loss: 0.659387, acc.: 61.72%] [G loss: 0.910899]\n",
      "epoch:17 step:16227 [D loss: 0.623624, acc.: 68.75%] [G loss: 0.909023]\n",
      "epoch:17 step:16228 [D loss: 0.613750, acc.: 64.84%] [G loss: 0.897133]\n",
      "epoch:17 step:16229 [D loss: 0.662877, acc.: 61.72%] [G loss: 0.919619]\n",
      "epoch:17 step:16230 [D loss: 0.724149, acc.: 53.12%] [G loss: 0.967176]\n",
      "epoch:17 step:16231 [D loss: 0.657545, acc.: 61.72%] [G loss: 0.913442]\n",
      "epoch:17 step:16232 [D loss: 0.691106, acc.: 57.81%] [G loss: 0.886351]\n",
      "epoch:17 step:16233 [D loss: 0.622945, acc.: 63.28%] [G loss: 0.878263]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16234 [D loss: 0.630776, acc.: 64.06%] [G loss: 0.914284]\n",
      "epoch:17 step:16235 [D loss: 0.590968, acc.: 67.97%] [G loss: 0.992685]\n",
      "epoch:17 step:16236 [D loss: 0.634028, acc.: 65.62%] [G loss: 0.956809]\n",
      "epoch:17 step:16237 [D loss: 0.673105, acc.: 60.94%] [G loss: 0.926635]\n",
      "epoch:17 step:16238 [D loss: 0.612437, acc.: 70.31%] [G loss: 0.918196]\n",
      "epoch:17 step:16239 [D loss: 0.626356, acc.: 61.72%] [G loss: 0.920051]\n",
      "epoch:17 step:16240 [D loss: 0.652898, acc.: 62.50%] [G loss: 0.829557]\n",
      "epoch:17 step:16241 [D loss: 0.655887, acc.: 60.94%] [G loss: 0.969910]\n",
      "epoch:17 step:16242 [D loss: 0.593964, acc.: 67.97%] [G loss: 0.989549]\n",
      "epoch:17 step:16243 [D loss: 0.581576, acc.: 66.41%] [G loss: 0.996163]\n",
      "epoch:17 step:16244 [D loss: 0.598587, acc.: 62.50%] [G loss: 0.977391]\n",
      "epoch:17 step:16245 [D loss: 0.744362, acc.: 52.34%] [G loss: 0.897956]\n",
      "epoch:17 step:16246 [D loss: 0.734332, acc.: 53.91%] [G loss: 0.896821]\n",
      "epoch:17 step:16247 [D loss: 0.684390, acc.: 56.25%] [G loss: 0.867708]\n",
      "epoch:17 step:16248 [D loss: 0.657900, acc.: 61.72%] [G loss: 0.841400]\n",
      "epoch:17 step:16249 [D loss: 0.677808, acc.: 57.81%] [G loss: 0.956993]\n",
      "epoch:17 step:16250 [D loss: 0.659479, acc.: 58.59%] [G loss: 0.901823]\n",
      "epoch:17 step:16251 [D loss: 0.625349, acc.: 65.62%] [G loss: 0.849462]\n",
      "epoch:17 step:16252 [D loss: 0.682255, acc.: 58.59%] [G loss: 0.932318]\n",
      "epoch:17 step:16253 [D loss: 0.669080, acc.: 57.81%] [G loss: 0.871949]\n",
      "epoch:17 step:16254 [D loss: 0.636974, acc.: 62.50%] [G loss: 0.886561]\n",
      "epoch:17 step:16255 [D loss: 0.640221, acc.: 66.41%] [G loss: 0.938249]\n",
      "epoch:17 step:16256 [D loss: 0.643046, acc.: 60.94%] [G loss: 0.958954]\n",
      "epoch:17 step:16257 [D loss: 0.617056, acc.: 66.41%] [G loss: 0.993934]\n",
      "epoch:17 step:16258 [D loss: 0.676006, acc.: 60.94%] [G loss: 0.967589]\n",
      "epoch:17 step:16259 [D loss: 0.706041, acc.: 56.25%] [G loss: 0.895882]\n",
      "epoch:17 step:16260 [D loss: 0.602307, acc.: 67.97%] [G loss: 0.935129]\n",
      "epoch:17 step:16261 [D loss: 0.613506, acc.: 67.19%] [G loss: 0.866212]\n",
      "epoch:17 step:16262 [D loss: 0.664506, acc.: 59.38%] [G loss: 0.909794]\n",
      "epoch:17 step:16263 [D loss: 0.672640, acc.: 64.06%] [G loss: 0.968096]\n",
      "epoch:17 step:16264 [D loss: 0.638992, acc.: 59.38%] [G loss: 0.999162]\n",
      "epoch:17 step:16265 [D loss: 0.644299, acc.: 64.06%] [G loss: 0.908411]\n",
      "epoch:17 step:16266 [D loss: 0.670964, acc.: 57.81%] [G loss: 0.895234]\n",
      "epoch:17 step:16267 [D loss: 0.650529, acc.: 64.06%] [G loss: 0.912887]\n",
      "epoch:17 step:16268 [D loss: 0.693247, acc.: 59.38%] [G loss: 0.901731]\n",
      "epoch:17 step:16269 [D loss: 0.610804, acc.: 67.97%] [G loss: 0.905357]\n",
      "epoch:17 step:16270 [D loss: 0.689720, acc.: 56.25%] [G loss: 0.944381]\n",
      "epoch:17 step:16271 [D loss: 0.699701, acc.: 51.56%] [G loss: 0.940427]\n",
      "epoch:17 step:16272 [D loss: 0.641192, acc.: 67.19%] [G loss: 0.957653]\n",
      "epoch:17 step:16273 [D loss: 0.626568, acc.: 68.75%] [G loss: 0.911556]\n",
      "epoch:17 step:16274 [D loss: 0.619154, acc.: 65.62%] [G loss: 0.926015]\n",
      "epoch:17 step:16275 [D loss: 0.653248, acc.: 65.62%] [G loss: 0.936462]\n",
      "epoch:17 step:16276 [D loss: 0.609228, acc.: 67.97%] [G loss: 0.999579]\n",
      "epoch:17 step:16277 [D loss: 0.721291, acc.: 55.47%] [G loss: 0.902470]\n",
      "epoch:17 step:16278 [D loss: 0.725926, acc.: 50.00%] [G loss: 0.895426]\n",
      "epoch:17 step:16279 [D loss: 0.660431, acc.: 61.72%] [G loss: 0.844655]\n",
      "epoch:17 step:16280 [D loss: 0.700113, acc.: 50.78%] [G loss: 0.873927]\n",
      "epoch:17 step:16281 [D loss: 0.676203, acc.: 58.59%] [G loss: 0.895219]\n",
      "epoch:17 step:16282 [D loss: 0.624724, acc.: 64.06%] [G loss: 0.909276]\n",
      "epoch:17 step:16283 [D loss: 0.560783, acc.: 75.78%] [G loss: 0.958251]\n",
      "epoch:17 step:16284 [D loss: 0.677230, acc.: 60.94%] [G loss: 1.006781]\n",
      "epoch:17 step:16285 [D loss: 0.659743, acc.: 56.25%] [G loss: 0.928632]\n",
      "epoch:17 step:16286 [D loss: 0.647047, acc.: 66.41%] [G loss: 0.895036]\n",
      "epoch:17 step:16287 [D loss: 0.663783, acc.: 60.16%] [G loss: 0.976246]\n",
      "epoch:17 step:16288 [D loss: 0.597653, acc.: 67.19%] [G loss: 0.995925]\n",
      "epoch:17 step:16289 [D loss: 0.630447, acc.: 68.75%] [G loss: 0.947738]\n",
      "epoch:17 step:16290 [D loss: 0.635736, acc.: 65.62%] [G loss: 0.953969]\n",
      "epoch:17 step:16291 [D loss: 0.655711, acc.: 55.47%] [G loss: 0.922286]\n",
      "epoch:17 step:16292 [D loss: 0.668761, acc.: 55.47%] [G loss: 0.920530]\n",
      "epoch:17 step:16293 [D loss: 0.622288, acc.: 63.28%] [G loss: 0.911649]\n",
      "epoch:17 step:16294 [D loss: 0.632832, acc.: 60.94%] [G loss: 0.929770]\n",
      "epoch:17 step:16295 [D loss: 0.618727, acc.: 65.62%] [G loss: 0.908970]\n",
      "epoch:17 step:16296 [D loss: 0.650996, acc.: 56.25%] [G loss: 0.967306]\n",
      "epoch:17 step:16297 [D loss: 0.629576, acc.: 62.50%] [G loss: 0.896141]\n",
      "epoch:17 step:16298 [D loss: 0.653164, acc.: 63.28%] [G loss: 0.886179]\n",
      "epoch:17 step:16299 [D loss: 0.653363, acc.: 66.41%] [G loss: 0.943277]\n",
      "epoch:17 step:16300 [D loss: 0.634750, acc.: 67.97%] [G loss: 0.923752]\n",
      "epoch:17 step:16301 [D loss: 0.689533, acc.: 57.81%] [G loss: 0.984120]\n",
      "epoch:17 step:16302 [D loss: 0.707828, acc.: 49.22%] [G loss: 0.897758]\n",
      "epoch:17 step:16303 [D loss: 0.656192, acc.: 57.81%] [G loss: 0.907627]\n",
      "epoch:17 step:16304 [D loss: 0.643712, acc.: 64.06%] [G loss: 0.968634]\n",
      "epoch:17 step:16305 [D loss: 0.688559, acc.: 50.00%] [G loss: 0.951262]\n",
      "epoch:17 step:16306 [D loss: 0.702903, acc.: 53.12%] [G loss: 0.890900]\n",
      "epoch:17 step:16307 [D loss: 0.674026, acc.: 54.69%] [G loss: 0.935650]\n",
      "epoch:17 step:16308 [D loss: 0.646132, acc.: 59.38%] [G loss: 0.976204]\n",
      "epoch:17 step:16309 [D loss: 0.669054, acc.: 54.69%] [G loss: 0.872626]\n",
      "epoch:17 step:16310 [D loss: 0.607132, acc.: 67.97%] [G loss: 0.886397]\n",
      "epoch:17 step:16311 [D loss: 0.710780, acc.: 53.91%] [G loss: 0.923201]\n",
      "epoch:17 step:16312 [D loss: 0.670518, acc.: 58.59%] [G loss: 0.855871]\n",
      "epoch:17 step:16313 [D loss: 0.639149, acc.: 58.59%] [G loss: 0.859294]\n",
      "epoch:17 step:16314 [D loss: 0.625082, acc.: 64.84%] [G loss: 0.956455]\n",
      "epoch:17 step:16315 [D loss: 0.681037, acc.: 60.16%] [G loss: 0.955240]\n",
      "epoch:17 step:16316 [D loss: 0.612559, acc.: 61.72%] [G loss: 0.967294]\n",
      "epoch:17 step:16317 [D loss: 0.631132, acc.: 63.28%] [G loss: 0.961503]\n",
      "epoch:17 step:16318 [D loss: 0.723072, acc.: 56.25%] [G loss: 0.911071]\n",
      "epoch:17 step:16319 [D loss: 0.671093, acc.: 62.50%] [G loss: 0.899400]\n",
      "epoch:17 step:16320 [D loss: 0.644841, acc.: 63.28%] [G loss: 0.980598]\n",
      "epoch:17 step:16321 [D loss: 0.649414, acc.: 62.50%] [G loss: 0.947066]\n",
      "epoch:17 step:16322 [D loss: 0.624250, acc.: 62.50%] [G loss: 0.888767]\n",
      "epoch:17 step:16323 [D loss: 0.669739, acc.: 57.81%] [G loss: 0.825132]\n",
      "epoch:17 step:16324 [D loss: 0.650138, acc.: 55.47%] [G loss: 0.888498]\n",
      "epoch:17 step:16325 [D loss: 0.718722, acc.: 50.00%] [G loss: 0.843508]\n",
      "epoch:17 step:16326 [D loss: 0.654092, acc.: 62.50%] [G loss: 0.950462]\n",
      "epoch:17 step:16327 [D loss: 0.623691, acc.: 63.28%] [G loss: 1.004573]\n",
      "epoch:17 step:16328 [D loss: 0.614874, acc.: 64.84%] [G loss: 0.989217]\n",
      "epoch:17 step:16329 [D loss: 0.745682, acc.: 46.09%] [G loss: 0.936427]\n",
      "epoch:17 step:16330 [D loss: 0.673929, acc.: 56.25%] [G loss: 0.944391]\n",
      "epoch:17 step:16331 [D loss: 0.616857, acc.: 65.62%] [G loss: 0.974278]\n",
      "epoch:17 step:16332 [D loss: 0.670088, acc.: 60.16%] [G loss: 0.878581]\n",
      "epoch:17 step:16333 [D loss: 0.634181, acc.: 62.50%] [G loss: 0.962560]\n",
      "epoch:17 step:16334 [D loss: 0.636272, acc.: 61.72%] [G loss: 0.994834]\n",
      "epoch:17 step:16335 [D loss: 0.631154, acc.: 64.84%] [G loss: 1.012153]\n",
      "epoch:17 step:16336 [D loss: 0.663971, acc.: 64.06%] [G loss: 1.043709]\n",
      "epoch:17 step:16337 [D loss: 0.693513, acc.: 57.81%] [G loss: 0.886520]\n",
      "epoch:17 step:16338 [D loss: 0.645137, acc.: 63.28%] [G loss: 0.907607]\n",
      "epoch:17 step:16339 [D loss: 0.663138, acc.: 58.59%] [G loss: 0.881469]\n",
      "epoch:17 step:16340 [D loss: 0.705913, acc.: 53.91%] [G loss: 0.882863]\n",
      "epoch:17 step:16341 [D loss: 0.661309, acc.: 60.16%] [G loss: 0.880197]\n",
      "epoch:17 step:16342 [D loss: 0.642980, acc.: 66.41%] [G loss: 0.956473]\n",
      "epoch:17 step:16343 [D loss: 0.680454, acc.: 57.81%] [G loss: 0.917670]\n",
      "epoch:17 step:16344 [D loss: 0.659111, acc.: 59.38%] [G loss: 0.896122]\n",
      "epoch:17 step:16345 [D loss: 0.599624, acc.: 70.31%] [G loss: 0.947329]\n",
      "epoch:17 step:16346 [D loss: 0.688626, acc.: 58.59%] [G loss: 0.935516]\n",
      "epoch:17 step:16347 [D loss: 0.699829, acc.: 50.78%] [G loss: 0.905845]\n",
      "epoch:17 step:16348 [D loss: 0.674942, acc.: 56.25%] [G loss: 0.920867]\n",
      "epoch:17 step:16349 [D loss: 0.601809, acc.: 67.19%] [G loss: 0.950336]\n",
      "epoch:17 step:16350 [D loss: 0.793620, acc.: 46.88%] [G loss: 0.850942]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16351 [D loss: 0.684597, acc.: 55.47%] [G loss: 0.860154]\n",
      "epoch:17 step:16352 [D loss: 0.661214, acc.: 62.50%] [G loss: 0.880399]\n",
      "epoch:17 step:16353 [D loss: 0.675231, acc.: 59.38%] [G loss: 0.940107]\n",
      "epoch:17 step:16354 [D loss: 0.658858, acc.: 57.03%] [G loss: 0.897370]\n",
      "epoch:17 step:16355 [D loss: 0.616688, acc.: 67.19%] [G loss: 0.885339]\n",
      "epoch:17 step:16356 [D loss: 0.665274, acc.: 53.91%] [G loss: 0.887264]\n",
      "epoch:17 step:16357 [D loss: 0.617731, acc.: 64.06%] [G loss: 0.944312]\n",
      "epoch:17 step:16358 [D loss: 0.616423, acc.: 66.41%] [G loss: 0.917004]\n",
      "epoch:17 step:16359 [D loss: 0.591654, acc.: 68.75%] [G loss: 0.952303]\n",
      "epoch:17 step:16360 [D loss: 0.641946, acc.: 64.06%] [G loss: 0.974858]\n",
      "epoch:17 step:16361 [D loss: 0.675730, acc.: 58.59%] [G loss: 0.935042]\n",
      "epoch:17 step:16362 [D loss: 0.683121, acc.: 51.56%] [G loss: 0.807537]\n",
      "epoch:17 step:16363 [D loss: 0.621316, acc.: 66.41%] [G loss: 0.925894]\n",
      "epoch:17 step:16364 [D loss: 0.687879, acc.: 53.91%] [G loss: 0.944287]\n",
      "epoch:17 step:16365 [D loss: 0.586677, acc.: 69.53%] [G loss: 0.955835]\n",
      "epoch:17 step:16366 [D loss: 0.768314, acc.: 48.44%] [G loss: 0.865500]\n",
      "epoch:17 step:16367 [D loss: 0.690041, acc.: 57.81%] [G loss: 0.870494]\n",
      "epoch:17 step:16368 [D loss: 0.694107, acc.: 55.47%] [G loss: 0.848538]\n",
      "epoch:17 step:16369 [D loss: 0.635218, acc.: 67.97%] [G loss: 0.918472]\n",
      "epoch:17 step:16370 [D loss: 0.664311, acc.: 60.94%] [G loss: 0.973820]\n",
      "epoch:17 step:16371 [D loss: 0.648937, acc.: 62.50%] [G loss: 0.973087]\n",
      "epoch:17 step:16372 [D loss: 0.629629, acc.: 67.97%] [G loss: 0.962200]\n",
      "epoch:17 step:16373 [D loss: 0.658040, acc.: 57.03%] [G loss: 0.977990]\n",
      "epoch:17 step:16374 [D loss: 0.621798, acc.: 66.41%] [G loss: 0.923435]\n",
      "epoch:17 step:16375 [D loss: 0.603651, acc.: 67.97%] [G loss: 0.942006]\n",
      "epoch:17 step:16376 [D loss: 0.597025, acc.: 69.53%] [G loss: 0.991552]\n",
      "epoch:17 step:16377 [D loss: 0.709551, acc.: 55.47%] [G loss: 0.982013]\n",
      "epoch:17 step:16378 [D loss: 0.659473, acc.: 63.28%] [G loss: 0.927196]\n",
      "epoch:17 step:16379 [D loss: 0.611502, acc.: 67.19%] [G loss: 0.904073]\n",
      "epoch:17 step:16380 [D loss: 0.629175, acc.: 67.19%] [G loss: 0.927330]\n",
      "epoch:17 step:16381 [D loss: 0.621934, acc.: 64.06%] [G loss: 0.910557]\n",
      "epoch:17 step:16382 [D loss: 0.616786, acc.: 68.75%] [G loss: 0.947881]\n",
      "epoch:17 step:16383 [D loss: 0.624879, acc.: 64.06%] [G loss: 0.934976]\n",
      "epoch:17 step:16384 [D loss: 0.716684, acc.: 53.12%] [G loss: 0.939856]\n",
      "epoch:17 step:16385 [D loss: 0.653812, acc.: 60.16%] [G loss: 0.921626]\n",
      "epoch:17 step:16386 [D loss: 0.641576, acc.: 62.50%] [G loss: 0.937921]\n",
      "epoch:17 step:16387 [D loss: 0.716425, acc.: 52.34%] [G loss: 0.921379]\n",
      "epoch:17 step:16388 [D loss: 0.623724, acc.: 67.19%] [G loss: 0.897789]\n",
      "epoch:17 step:16389 [D loss: 0.669554, acc.: 57.81%] [G loss: 0.875943]\n",
      "epoch:17 step:16390 [D loss: 0.641008, acc.: 64.84%] [G loss: 0.849333]\n",
      "epoch:17 step:16391 [D loss: 0.694703, acc.: 48.44%] [G loss: 0.883065]\n",
      "epoch:17 step:16392 [D loss: 0.685585, acc.: 53.12%] [G loss: 0.910330]\n",
      "epoch:17 step:16393 [D loss: 0.668366, acc.: 59.38%] [G loss: 0.854913]\n",
      "epoch:17 step:16394 [D loss: 0.685305, acc.: 60.16%] [G loss: 0.861804]\n",
      "epoch:17 step:16395 [D loss: 0.658651, acc.: 64.84%] [G loss: 0.901820]\n",
      "epoch:17 step:16396 [D loss: 0.637163, acc.: 67.19%] [G loss: 0.836827]\n",
      "epoch:17 step:16397 [D loss: 0.627480, acc.: 64.84%] [G loss: 0.877224]\n",
      "epoch:17 step:16398 [D loss: 0.551290, acc.: 74.22%] [G loss: 0.964493]\n",
      "epoch:17 step:16399 [D loss: 0.674396, acc.: 57.81%] [G loss: 0.989017]\n",
      "epoch:17 step:16400 [D loss: 0.611125, acc.: 71.88%] [G loss: 0.980137]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.205842\n",
      "FID: 5.212328\n",
      "0 = 11.929027722454078\n",
      "1 = 0.05100844982682136\n",
      "2 = 0.9164999723434448\n",
      "3 = 0.8823999762535095\n",
      "4 = 0.9506000280380249\n",
      "5 = 0.9469843506813049\n",
      "6 = 0.8823999762535095\n",
      "7 = 5.542990771093966\n",
      "8 = 0.04812977160293597\n",
      "9 = 0.6963000297546387\n",
      "10 = 0.6794999837875366\n",
      "11 = 0.713100016117096\n",
      "12 = 0.703125\n",
      "13 = 0.6794999837875366\n",
      "14 = 8.205909729003906\n",
      "15 = 9.637724876403809\n",
      "16 = 0.06770573556423187\n",
      "17 = 8.205842018127441\n",
      "18 = 5.2123284339904785\n",
      "epoch:17 step:16401 [D loss: 0.634261, acc.: 64.84%] [G loss: 1.013157]\n",
      "epoch:17 step:16402 [D loss: 0.750738, acc.: 46.88%] [G loss: 1.003881]\n",
      "epoch:17 step:16403 [D loss: 0.650944, acc.: 59.38%] [G loss: 0.952040]\n",
      "epoch:17 step:16404 [D loss: 0.652555, acc.: 60.16%] [G loss: 0.884335]\n",
      "epoch:17 step:16405 [D loss: 0.682018, acc.: 56.25%] [G loss: 0.962628]\n",
      "epoch:17 step:16406 [D loss: 0.715155, acc.: 52.34%] [G loss: 0.946959]\n",
      "epoch:17 step:16407 [D loss: 0.680811, acc.: 59.38%] [G loss: 0.959192]\n",
      "epoch:17 step:16408 [D loss: 0.643366, acc.: 71.09%] [G loss: 0.868183]\n",
      "epoch:17 step:16409 [D loss: 0.613315, acc.: 70.31%] [G loss: 0.915936]\n",
      "epoch:17 step:16410 [D loss: 0.617752, acc.: 67.97%] [G loss: 0.878753]\n",
      "epoch:17 step:16411 [D loss: 0.708114, acc.: 52.34%] [G loss: 0.878206]\n",
      "epoch:17 step:16412 [D loss: 0.673885, acc.: 56.25%] [G loss: 0.888939]\n",
      "epoch:17 step:16413 [D loss: 0.627303, acc.: 64.06%] [G loss: 0.881171]\n",
      "epoch:17 step:16414 [D loss: 0.621244, acc.: 64.06%] [G loss: 0.940587]\n",
      "epoch:17 step:16415 [D loss: 0.674238, acc.: 55.47%] [G loss: 0.859264]\n",
      "epoch:17 step:16416 [D loss: 0.666683, acc.: 62.50%] [G loss: 0.895812]\n",
      "epoch:17 step:16417 [D loss: 0.600729, acc.: 70.31%] [G loss: 0.940779]\n",
      "epoch:17 step:16418 [D loss: 0.636219, acc.: 65.62%] [G loss: 0.843814]\n",
      "epoch:17 step:16419 [D loss: 0.675929, acc.: 59.38%] [G loss: 0.943423]\n",
      "epoch:17 step:16420 [D loss: 0.666629, acc.: 57.03%] [G loss: 0.921875]\n",
      "epoch:17 step:16421 [D loss: 0.658391, acc.: 60.16%] [G loss: 0.952497]\n",
      "epoch:17 step:16422 [D loss: 0.659987, acc.: 62.50%] [G loss: 0.918090]\n",
      "epoch:17 step:16423 [D loss: 0.661192, acc.: 64.06%] [G loss: 0.858456]\n",
      "epoch:17 step:16424 [D loss: 0.621181, acc.: 67.19%] [G loss: 0.920899]\n",
      "epoch:17 step:16425 [D loss: 0.634821, acc.: 65.62%] [G loss: 0.948057]\n",
      "epoch:17 step:16426 [D loss: 0.601078, acc.: 67.97%] [G loss: 0.896004]\n",
      "epoch:17 step:16427 [D loss: 0.607453, acc.: 67.97%] [G loss: 0.964024]\n",
      "epoch:17 step:16428 [D loss: 0.590486, acc.: 67.97%] [G loss: 0.947748]\n",
      "epoch:17 step:16429 [D loss: 0.670156, acc.: 60.16%] [G loss: 0.981162]\n",
      "epoch:17 step:16430 [D loss: 0.698188, acc.: 53.12%] [G loss: 0.883739]\n",
      "epoch:17 step:16431 [D loss: 0.683114, acc.: 57.03%] [G loss: 0.925521]\n",
      "epoch:17 step:16432 [D loss: 0.646933, acc.: 57.03%] [G loss: 0.936036]\n",
      "epoch:17 step:16433 [D loss: 0.623230, acc.: 63.28%] [G loss: 0.933163]\n",
      "epoch:17 step:16434 [D loss: 0.591452, acc.: 67.97%] [G loss: 0.962054]\n",
      "epoch:17 step:16435 [D loss: 0.616228, acc.: 64.06%] [G loss: 1.010851]\n",
      "epoch:17 step:16436 [D loss: 0.601399, acc.: 65.62%] [G loss: 1.106340]\n",
      "epoch:17 step:16437 [D loss: 0.533748, acc.: 75.78%] [G loss: 1.101658]\n",
      "epoch:17 step:16438 [D loss: 0.755478, acc.: 52.34%] [G loss: 0.949142]\n",
      "epoch:17 step:16439 [D loss: 0.731364, acc.: 49.22%] [G loss: 0.848002]\n",
      "epoch:17 step:16440 [D loss: 0.685885, acc.: 51.56%] [G loss: 0.963687]\n",
      "epoch:17 step:16441 [D loss: 0.639953, acc.: 60.94%] [G loss: 0.905570]\n",
      "epoch:17 step:16442 [D loss: 0.624400, acc.: 64.06%] [G loss: 0.949778]\n",
      "epoch:17 step:16443 [D loss: 0.634024, acc.: 60.94%] [G loss: 0.915833]\n",
      "epoch:17 step:16444 [D loss: 0.636803, acc.: 63.28%] [G loss: 0.957304]\n",
      "epoch:17 step:16445 [D loss: 0.637430, acc.: 63.28%] [G loss: 0.893618]\n",
      "epoch:17 step:16446 [D loss: 0.696429, acc.: 55.47%] [G loss: 0.869300]\n",
      "epoch:17 step:16447 [D loss: 0.653132, acc.: 65.62%] [G loss: 0.893403]\n",
      "epoch:17 step:16448 [D loss: 0.651733, acc.: 62.50%] [G loss: 0.899835]\n",
      "epoch:17 step:16449 [D loss: 0.613448, acc.: 64.06%] [G loss: 0.960652]\n",
      "epoch:17 step:16450 [D loss: 0.657035, acc.: 60.16%] [G loss: 0.926484]\n",
      "epoch:17 step:16451 [D loss: 0.633090, acc.: 63.28%] [G loss: 0.972987]\n",
      "epoch:17 step:16452 [D loss: 0.603198, acc.: 67.19%] [G loss: 0.942191]\n",
      "epoch:17 step:16453 [D loss: 0.676359, acc.: 61.72%] [G loss: 0.896992]\n",
      "epoch:17 step:16454 [D loss: 0.665907, acc.: 63.28%] [G loss: 0.849583]\n",
      "epoch:17 step:16455 [D loss: 0.664146, acc.: 60.16%] [G loss: 0.996676]\n",
      "epoch:17 step:16456 [D loss: 0.688198, acc.: 53.91%] [G loss: 0.907466]\n",
      "epoch:17 step:16457 [D loss: 0.705347, acc.: 48.44%] [G loss: 0.926727]\n",
      "epoch:17 step:16458 [D loss: 0.723150, acc.: 47.66%] [G loss: 0.923935]\n",
      "epoch:17 step:16459 [D loss: 0.611379, acc.: 67.97%] [G loss: 0.940851]\n",
      "epoch:17 step:16460 [D loss: 0.700312, acc.: 52.34%] [G loss: 0.969577]\n",
      "epoch:17 step:16461 [D loss: 0.718106, acc.: 54.69%] [G loss: 0.832579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16462 [D loss: 0.690619, acc.: 58.59%] [G loss: 0.906407]\n",
      "epoch:17 step:16463 [D loss: 0.629153, acc.: 67.97%] [G loss: 0.955844]\n",
      "epoch:17 step:16464 [D loss: 0.674231, acc.: 57.03%] [G loss: 0.926153]\n",
      "epoch:17 step:16465 [D loss: 0.691082, acc.: 57.81%] [G loss: 0.865928]\n",
      "epoch:17 step:16466 [D loss: 0.686004, acc.: 54.69%] [G loss: 0.918479]\n",
      "epoch:17 step:16467 [D loss: 0.646560, acc.: 56.25%] [G loss: 0.917407]\n",
      "epoch:17 step:16468 [D loss: 0.657245, acc.: 61.72%] [G loss: 0.906602]\n",
      "epoch:17 step:16469 [D loss: 0.666511, acc.: 55.47%] [G loss: 0.960526]\n",
      "epoch:17 step:16470 [D loss: 0.646189, acc.: 61.72%] [G loss: 0.894141]\n",
      "epoch:17 step:16471 [D loss: 0.775888, acc.: 42.19%] [G loss: 0.895389]\n",
      "epoch:17 step:16472 [D loss: 0.711592, acc.: 55.47%] [G loss: 0.867570]\n",
      "epoch:17 step:16473 [D loss: 0.668901, acc.: 61.72%] [G loss: 0.913220]\n",
      "epoch:17 step:16474 [D loss: 0.623025, acc.: 64.06%] [G loss: 0.882373]\n",
      "epoch:17 step:16475 [D loss: 0.633968, acc.: 65.62%] [G loss: 0.935790]\n",
      "epoch:17 step:16476 [D loss: 0.685552, acc.: 55.47%] [G loss: 0.890692]\n",
      "epoch:17 step:16477 [D loss: 0.649928, acc.: 57.81%] [G loss: 0.935536]\n",
      "epoch:17 step:16478 [D loss: 0.617933, acc.: 67.19%] [G loss: 0.886200]\n",
      "epoch:17 step:16479 [D loss: 0.600567, acc.: 67.97%] [G loss: 0.938911]\n",
      "epoch:17 step:16480 [D loss: 0.595288, acc.: 71.88%] [G loss: 0.953439]\n",
      "epoch:17 step:16481 [D loss: 0.625342, acc.: 67.19%] [G loss: 0.846762]\n",
      "epoch:17 step:16482 [D loss: 0.660247, acc.: 57.81%] [G loss: 0.894932]\n",
      "epoch:17 step:16483 [D loss: 0.624882, acc.: 66.41%] [G loss: 0.943178]\n",
      "epoch:17 step:16484 [D loss: 0.619232, acc.: 66.41%] [G loss: 0.944500]\n",
      "epoch:17 step:16485 [D loss: 0.628563, acc.: 63.28%] [G loss: 0.993653]\n",
      "epoch:17 step:16486 [D loss: 0.606087, acc.: 71.09%] [G loss: 0.953105]\n",
      "epoch:17 step:16487 [D loss: 0.615988, acc.: 66.41%] [G loss: 0.947619]\n",
      "epoch:17 step:16488 [D loss: 0.727683, acc.: 54.69%] [G loss: 0.916210]\n",
      "epoch:17 step:16489 [D loss: 0.695357, acc.: 58.59%] [G loss: 0.862979]\n",
      "epoch:17 step:16490 [D loss: 0.677128, acc.: 57.81%] [G loss: 0.863128]\n",
      "epoch:17 step:16491 [D loss: 0.641942, acc.: 65.62%] [G loss: 0.881578]\n",
      "epoch:17 step:16492 [D loss: 0.633225, acc.: 60.94%] [G loss: 0.939354]\n",
      "epoch:17 step:16493 [D loss: 0.600706, acc.: 71.88%] [G loss: 0.999262]\n",
      "epoch:17 step:16494 [D loss: 0.701971, acc.: 57.81%] [G loss: 0.988438]\n",
      "epoch:17 step:16495 [D loss: 0.749361, acc.: 50.00%] [G loss: 0.947697]\n",
      "epoch:17 step:16496 [D loss: 0.620862, acc.: 67.19%] [G loss: 0.976854]\n",
      "epoch:17 step:16497 [D loss: 0.574248, acc.: 71.09%] [G loss: 0.974518]\n",
      "epoch:17 step:16498 [D loss: 0.714940, acc.: 60.16%] [G loss: 0.888385]\n",
      "epoch:17 step:16499 [D loss: 0.656349, acc.: 62.50%] [G loss: 0.859716]\n",
      "epoch:17 step:16500 [D loss: 0.661018, acc.: 60.16%] [G loss: 0.963618]\n",
      "epoch:17 step:16501 [D loss: 0.649161, acc.: 59.38%] [G loss: 0.894523]\n",
      "epoch:17 step:16502 [D loss: 0.683069, acc.: 60.94%] [G loss: 0.899831]\n",
      "epoch:17 step:16503 [D loss: 0.571030, acc.: 71.88%] [G loss: 1.029767]\n",
      "epoch:17 step:16504 [D loss: 0.604830, acc.: 69.53%] [G loss: 0.951712]\n",
      "epoch:17 step:16505 [D loss: 0.638043, acc.: 62.50%] [G loss: 0.962073]\n",
      "epoch:17 step:16506 [D loss: 0.664648, acc.: 56.25%] [G loss: 0.947032]\n",
      "epoch:17 step:16507 [D loss: 0.650211, acc.: 57.81%] [G loss: 0.889385]\n",
      "epoch:17 step:16508 [D loss: 0.670451, acc.: 57.81%] [G loss: 0.869469]\n",
      "epoch:17 step:16509 [D loss: 0.649976, acc.: 59.38%] [G loss: 0.906310]\n",
      "epoch:17 step:16510 [D loss: 0.600333, acc.: 67.97%] [G loss: 0.883368]\n",
      "epoch:17 step:16511 [D loss: 0.590026, acc.: 67.19%] [G loss: 0.936546]\n",
      "epoch:17 step:16512 [D loss: 0.667951, acc.: 57.81%] [G loss: 0.995291]\n",
      "epoch:17 step:16513 [D loss: 0.701500, acc.: 53.91%] [G loss: 0.857228]\n",
      "epoch:17 step:16514 [D loss: 0.652786, acc.: 62.50%] [G loss: 0.942825]\n",
      "epoch:17 step:16515 [D loss: 0.664261, acc.: 57.81%] [G loss: 0.884658]\n",
      "epoch:17 step:16516 [D loss: 0.730055, acc.: 50.78%] [G loss: 0.868807]\n",
      "epoch:17 step:16517 [D loss: 0.648081, acc.: 59.38%] [G loss: 0.863073]\n",
      "epoch:17 step:16518 [D loss: 0.641982, acc.: 60.94%] [G loss: 0.943816]\n",
      "epoch:17 step:16519 [D loss: 0.681883, acc.: 57.03%] [G loss: 0.960084]\n",
      "epoch:17 step:16520 [D loss: 0.718188, acc.: 53.91%] [G loss: 0.995300]\n",
      "epoch:17 step:16521 [D loss: 0.622441, acc.: 64.84%] [G loss: 0.933450]\n",
      "epoch:17 step:16522 [D loss: 0.622791, acc.: 67.19%] [G loss: 0.957223]\n",
      "epoch:17 step:16523 [D loss: 0.718372, acc.: 53.91%] [G loss: 0.987264]\n",
      "epoch:17 step:16524 [D loss: 0.611412, acc.: 67.97%] [G loss: 0.872762]\n",
      "epoch:17 step:16525 [D loss: 0.628909, acc.: 61.72%] [G loss: 0.773258]\n",
      "epoch:17 step:16526 [D loss: 0.713984, acc.: 51.56%] [G loss: 0.822791]\n",
      "epoch:17 step:16527 [D loss: 0.648153, acc.: 67.19%] [G loss: 0.874450]\n",
      "epoch:17 step:16528 [D loss: 0.653039, acc.: 64.84%] [G loss: 0.884346]\n",
      "epoch:17 step:16529 [D loss: 0.713028, acc.: 48.44%] [G loss: 0.900334]\n",
      "epoch:17 step:16530 [D loss: 0.663625, acc.: 64.84%] [G loss: 0.861441]\n",
      "epoch:17 step:16531 [D loss: 0.638924, acc.: 64.06%] [G loss: 0.865134]\n",
      "epoch:17 step:16532 [D loss: 0.663222, acc.: 63.28%] [G loss: 0.858209]\n",
      "epoch:17 step:16533 [D loss: 0.667023, acc.: 64.84%] [G loss: 0.880262]\n",
      "epoch:17 step:16534 [D loss: 0.635165, acc.: 64.06%] [G loss: 0.922551]\n",
      "epoch:17 step:16535 [D loss: 0.672338, acc.: 58.59%] [G loss: 0.885878]\n",
      "epoch:17 step:16536 [D loss: 0.668038, acc.: 64.06%] [G loss: 0.862481]\n",
      "epoch:17 step:16537 [D loss: 0.650019, acc.: 63.28%] [G loss: 0.930358]\n",
      "epoch:17 step:16538 [D loss: 0.636528, acc.: 64.06%] [G loss: 0.852842]\n",
      "epoch:17 step:16539 [D loss: 0.655031, acc.: 59.38%] [G loss: 0.882906]\n",
      "epoch:17 step:16540 [D loss: 0.651519, acc.: 62.50%] [G loss: 0.899929]\n",
      "epoch:17 step:16541 [D loss: 0.664589, acc.: 57.03%] [G loss: 0.883834]\n",
      "epoch:17 step:16542 [D loss: 0.659039, acc.: 60.16%] [G loss: 0.876317]\n",
      "epoch:17 step:16543 [D loss: 0.657489, acc.: 65.62%] [G loss: 0.915525]\n",
      "epoch:17 step:16544 [D loss: 0.679098, acc.: 57.03%] [G loss: 0.833480]\n",
      "epoch:17 step:16545 [D loss: 0.685745, acc.: 55.47%] [G loss: 0.858936]\n",
      "epoch:17 step:16546 [D loss: 0.659705, acc.: 58.59%] [G loss: 0.917449]\n",
      "epoch:17 step:16547 [D loss: 0.642411, acc.: 60.94%] [G loss: 0.926998]\n",
      "epoch:17 step:16548 [D loss: 0.676496, acc.: 57.03%] [G loss: 0.884681]\n",
      "epoch:17 step:16549 [D loss: 0.651645, acc.: 62.50%] [G loss: 0.915770]\n",
      "epoch:17 step:16550 [D loss: 0.691911, acc.: 52.34%] [G loss: 0.867483]\n",
      "epoch:17 step:16551 [D loss: 0.672340, acc.: 57.03%] [G loss: 0.886222]\n",
      "epoch:17 step:16552 [D loss: 0.636627, acc.: 67.97%] [G loss: 0.898999]\n",
      "epoch:17 step:16553 [D loss: 0.605641, acc.: 71.09%] [G loss: 0.876767]\n",
      "epoch:17 step:16554 [D loss: 0.665018, acc.: 52.34%] [G loss: 0.861177]\n",
      "epoch:17 step:16555 [D loss: 0.678715, acc.: 60.16%] [G loss: 0.878129]\n",
      "epoch:17 step:16556 [D loss: 0.651202, acc.: 60.16%] [G loss: 0.925390]\n",
      "epoch:17 step:16557 [D loss: 0.640093, acc.: 67.19%] [G loss: 0.932311]\n",
      "epoch:17 step:16558 [D loss: 0.613206, acc.: 69.53%] [G loss: 0.916504]\n",
      "epoch:17 step:16559 [D loss: 0.676136, acc.: 65.62%] [G loss: 0.944669]\n",
      "epoch:17 step:16560 [D loss: 0.624027, acc.: 67.19%] [G loss: 0.935554]\n",
      "epoch:17 step:16561 [D loss: 0.624985, acc.: 66.41%] [G loss: 0.870302]\n",
      "epoch:17 step:16562 [D loss: 0.677340, acc.: 58.59%] [G loss: 0.995821]\n",
      "epoch:17 step:16563 [D loss: 0.621184, acc.: 64.06%] [G loss: 0.899661]\n",
      "epoch:17 step:16564 [D loss: 0.639527, acc.: 57.81%] [G loss: 0.919427]\n",
      "epoch:17 step:16565 [D loss: 0.653244, acc.: 57.81%] [G loss: 0.942886]\n",
      "epoch:17 step:16566 [D loss: 0.604730, acc.: 67.97%] [G loss: 0.953763]\n",
      "epoch:17 step:16567 [D loss: 0.638509, acc.: 61.72%] [G loss: 0.942676]\n",
      "epoch:17 step:16568 [D loss: 0.709999, acc.: 46.88%] [G loss: 0.912825]\n",
      "epoch:17 step:16569 [D loss: 0.738525, acc.: 46.09%] [G loss: 0.952787]\n",
      "epoch:17 step:16570 [D loss: 0.605617, acc.: 70.31%] [G loss: 0.957135]\n",
      "epoch:17 step:16571 [D loss: 0.590460, acc.: 74.22%] [G loss: 0.975194]\n",
      "epoch:17 step:16572 [D loss: 0.603198, acc.: 67.19%] [G loss: 0.954361]\n",
      "epoch:17 step:16573 [D loss: 0.644767, acc.: 66.41%] [G loss: 0.854926]\n",
      "epoch:17 step:16574 [D loss: 0.673881, acc.: 57.03%] [G loss: 0.890411]\n",
      "epoch:17 step:16575 [D loss: 0.629169, acc.: 67.97%] [G loss: 0.859271]\n",
      "epoch:17 step:16576 [D loss: 0.619961, acc.: 67.19%] [G loss: 0.981290]\n",
      "epoch:17 step:16577 [D loss: 0.564023, acc.: 72.66%] [G loss: 1.012857]\n",
      "epoch:17 step:16578 [D loss: 0.628882, acc.: 64.06%] [G loss: 0.988671]\n",
      "epoch:17 step:16579 [D loss: 0.620708, acc.: 71.09%] [G loss: 0.974218]\n",
      "epoch:17 step:16580 [D loss: 0.628650, acc.: 65.62%] [G loss: 0.946516]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16581 [D loss: 0.668517, acc.: 60.94%] [G loss: 0.933489]\n",
      "epoch:17 step:16582 [D loss: 0.663069, acc.: 60.94%] [G loss: 0.949977]\n",
      "epoch:17 step:16583 [D loss: 0.646295, acc.: 62.50%] [G loss: 0.932718]\n",
      "epoch:17 step:16584 [D loss: 0.710003, acc.: 56.25%] [G loss: 0.899014]\n",
      "epoch:17 step:16585 [D loss: 0.658446, acc.: 60.94%] [G loss: 0.955539]\n",
      "epoch:17 step:16586 [D loss: 0.666774, acc.: 60.94%] [G loss: 0.897996]\n",
      "epoch:17 step:16587 [D loss: 0.674415, acc.: 63.28%] [G loss: 0.922083]\n",
      "epoch:17 step:16588 [D loss: 0.639404, acc.: 63.28%] [G loss: 0.933766]\n",
      "epoch:17 step:16589 [D loss: 0.612409, acc.: 68.75%] [G loss: 0.934430]\n",
      "epoch:17 step:16590 [D loss: 0.592174, acc.: 71.88%] [G loss: 0.942926]\n",
      "epoch:17 step:16591 [D loss: 0.712678, acc.: 49.22%] [G loss: 0.908222]\n",
      "epoch:17 step:16592 [D loss: 0.705967, acc.: 50.78%] [G loss: 0.875861]\n",
      "epoch:17 step:16593 [D loss: 0.656038, acc.: 60.16%] [G loss: 0.929301]\n",
      "epoch:17 step:16594 [D loss: 0.641321, acc.: 58.59%] [G loss: 0.904349]\n",
      "epoch:17 step:16595 [D loss: 0.644568, acc.: 62.50%] [G loss: 0.919628]\n",
      "epoch:17 step:16596 [D loss: 0.664219, acc.: 61.72%] [G loss: 0.932562]\n",
      "epoch:17 step:16597 [D loss: 0.687379, acc.: 56.25%] [G loss: 0.911766]\n",
      "epoch:17 step:16598 [D loss: 0.631618, acc.: 64.84%] [G loss: 0.861323]\n",
      "epoch:17 step:16599 [D loss: 0.695566, acc.: 52.34%] [G loss: 0.898210]\n",
      "epoch:17 step:16600 [D loss: 0.666103, acc.: 57.81%] [G loss: 0.904041]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.334852\n",
      "FID: 5.095265\n",
      "0 = 11.6404281092405\n",
      "1 = 0.04424539470953932\n",
      "2 = 0.8972499966621399\n",
      "3 = 0.8511000275611877\n",
      "4 = 0.9434000253677368\n",
      "5 = 0.9376446008682251\n",
      "6 = 0.8511000275611877\n",
      "7 = 5.3766769979000175\n",
      "8 = 0.05060134711903657\n",
      "9 = 0.6782000064849854\n",
      "10 = 0.6563000082969666\n",
      "11 = 0.7001000046730042\n",
      "12 = 0.6863626837730408\n",
      "13 = 0.6563000082969666\n",
      "14 = 8.33491325378418\n",
      "15 = 9.619165420532227\n",
      "16 = 0.07536114752292633\n",
      "17 = 8.33485221862793\n",
      "18 = 5.095264911651611\n",
      "epoch:17 step:16601 [D loss: 0.667546, acc.: 58.59%] [G loss: 0.855219]\n",
      "epoch:17 step:16602 [D loss: 0.667625, acc.: 59.38%] [G loss: 0.988822]\n",
      "epoch:17 step:16603 [D loss: 0.663627, acc.: 59.38%] [G loss: 0.936573]\n",
      "epoch:17 step:16604 [D loss: 0.696925, acc.: 52.34%] [G loss: 0.918120]\n",
      "epoch:17 step:16605 [D loss: 0.630546, acc.: 63.28%] [G loss: 0.973776]\n",
      "epoch:17 step:16606 [D loss: 0.648470, acc.: 64.06%] [G loss: 0.917501]\n",
      "epoch:17 step:16607 [D loss: 0.690341, acc.: 57.81%] [G loss: 0.883767]\n",
      "epoch:17 step:16608 [D loss: 0.654305, acc.: 60.16%] [G loss: 0.877863]\n",
      "epoch:17 step:16609 [D loss: 0.688076, acc.: 51.56%] [G loss: 0.877484]\n",
      "epoch:17 step:16610 [D loss: 0.595231, acc.: 71.09%] [G loss: 0.923386]\n",
      "epoch:17 step:16611 [D loss: 0.661648, acc.: 61.72%] [G loss: 0.897321]\n",
      "epoch:17 step:16612 [D loss: 0.633883, acc.: 62.50%] [G loss: 0.840047]\n",
      "epoch:17 step:16613 [D loss: 0.668593, acc.: 53.12%] [G loss: 0.897107]\n",
      "epoch:17 step:16614 [D loss: 0.675660, acc.: 55.47%] [G loss: 0.882967]\n",
      "epoch:17 step:16615 [D loss: 0.633696, acc.: 62.50%] [G loss: 0.902540]\n",
      "epoch:17 step:16616 [D loss: 0.657920, acc.: 60.16%] [G loss: 0.858330]\n",
      "epoch:17 step:16617 [D loss: 0.655194, acc.: 57.03%] [G loss: 0.892678]\n",
      "epoch:17 step:16618 [D loss: 0.644722, acc.: 61.72%] [G loss: 0.902727]\n",
      "epoch:17 step:16619 [D loss: 0.661831, acc.: 59.38%] [G loss: 0.884182]\n",
      "epoch:17 step:16620 [D loss: 0.630346, acc.: 64.84%] [G loss: 0.960852]\n",
      "epoch:17 step:16621 [D loss: 0.657017, acc.: 61.72%] [G loss: 0.997487]\n",
      "epoch:17 step:16622 [D loss: 0.637904, acc.: 64.84%] [G loss: 0.983266]\n",
      "epoch:17 step:16623 [D loss: 0.609509, acc.: 65.62%] [G loss: 0.950964]\n",
      "epoch:17 step:16624 [D loss: 0.641502, acc.: 67.19%] [G loss: 0.934844]\n",
      "epoch:17 step:16625 [D loss: 0.669486, acc.: 57.03%] [G loss: 0.935919]\n",
      "epoch:17 step:16626 [D loss: 0.670640, acc.: 55.47%] [G loss: 0.834013]\n",
      "epoch:17 step:16627 [D loss: 0.656443, acc.: 60.94%] [G loss: 0.886460]\n",
      "epoch:17 step:16628 [D loss: 0.649016, acc.: 64.84%] [G loss: 0.844642]\n",
      "epoch:17 step:16629 [D loss: 0.671351, acc.: 62.50%] [G loss: 0.951403]\n",
      "epoch:17 step:16630 [D loss: 0.646155, acc.: 64.06%] [G loss: 0.898345]\n",
      "epoch:17 step:16631 [D loss: 0.699215, acc.: 51.56%] [G loss: 0.946665]\n",
      "epoch:17 step:16632 [D loss: 0.718877, acc.: 53.12%] [G loss: 0.913611]\n",
      "epoch:17 step:16633 [D loss: 0.676868, acc.: 58.59%] [G loss: 0.906391]\n",
      "epoch:17 step:16634 [D loss: 0.717473, acc.: 57.03%] [G loss: 0.893989]\n",
      "epoch:17 step:16635 [D loss: 0.639326, acc.: 66.41%] [G loss: 0.958950]\n",
      "epoch:17 step:16636 [D loss: 0.616565, acc.: 69.53%] [G loss: 0.893019]\n",
      "epoch:17 step:16637 [D loss: 0.593707, acc.: 69.53%] [G loss: 0.910116]\n",
      "epoch:17 step:16638 [D loss: 0.596867, acc.: 69.53%] [G loss: 0.911816]\n",
      "epoch:17 step:16639 [D loss: 0.701269, acc.: 57.03%] [G loss: 0.889444]\n",
      "epoch:17 step:16640 [D loss: 0.682182, acc.: 56.25%] [G loss: 0.886708]\n",
      "epoch:17 step:16641 [D loss: 0.618626, acc.: 66.41%] [G loss: 0.919485]\n",
      "epoch:17 step:16642 [D loss: 0.652505, acc.: 64.06%] [G loss: 0.894030]\n",
      "epoch:17 step:16643 [D loss: 0.685601, acc.: 56.25%] [G loss: 0.918409]\n",
      "epoch:17 step:16644 [D loss: 0.670119, acc.: 58.59%] [G loss: 0.871750]\n",
      "epoch:17 step:16645 [D loss: 0.731893, acc.: 49.22%] [G loss: 0.938604]\n",
      "epoch:17 step:16646 [D loss: 0.648346, acc.: 63.28%] [G loss: 0.854659]\n",
      "epoch:17 step:16647 [D loss: 0.690510, acc.: 53.91%] [G loss: 0.912129]\n",
      "epoch:17 step:16648 [D loss: 0.641576, acc.: 68.75%] [G loss: 0.966402]\n",
      "epoch:17 step:16649 [D loss: 0.638785, acc.: 67.97%] [G loss: 0.998106]\n",
      "epoch:17 step:16650 [D loss: 0.673031, acc.: 53.91%] [G loss: 0.921500]\n",
      "epoch:17 step:16651 [D loss: 0.723120, acc.: 51.56%] [G loss: 0.801772]\n",
      "epoch:17 step:16652 [D loss: 0.640660, acc.: 66.41%] [G loss: 0.930043]\n",
      "epoch:17 step:16653 [D loss: 0.643600, acc.: 64.06%] [G loss: 0.893208]\n",
      "epoch:17 step:16654 [D loss: 0.675998, acc.: 57.81%] [G loss: 0.917739]\n",
      "epoch:17 step:16655 [D loss: 0.627576, acc.: 64.84%] [G loss: 0.914152]\n",
      "epoch:17 step:16656 [D loss: 0.714882, acc.: 58.59%] [G loss: 0.910814]\n",
      "epoch:17 step:16657 [D loss: 0.681566, acc.: 58.59%] [G loss: 0.845174]\n",
      "epoch:17 step:16658 [D loss: 0.659362, acc.: 60.94%] [G loss: 0.893890]\n",
      "epoch:17 step:16659 [D loss: 0.624761, acc.: 66.41%] [G loss: 0.905681]\n",
      "epoch:17 step:16660 [D loss: 0.640580, acc.: 65.62%] [G loss: 0.918637]\n",
      "epoch:17 step:16661 [D loss: 0.647862, acc.: 60.94%] [G loss: 0.925639]\n",
      "epoch:17 step:16662 [D loss: 0.606152, acc.: 67.97%] [G loss: 0.997807]\n",
      "epoch:17 step:16663 [D loss: 0.693340, acc.: 58.59%] [G loss: 0.907022]\n",
      "epoch:17 step:16664 [D loss: 0.686015, acc.: 50.78%] [G loss: 0.864225]\n",
      "epoch:17 step:16665 [D loss: 0.638960, acc.: 65.62%] [G loss: 0.906560]\n",
      "epoch:17 step:16666 [D loss: 0.636428, acc.: 65.62%] [G loss: 0.887155]\n",
      "epoch:17 step:16667 [D loss: 0.646681, acc.: 65.62%] [G loss: 0.912678]\n",
      "epoch:17 step:16668 [D loss: 0.688903, acc.: 60.16%] [G loss: 0.834032]\n",
      "epoch:17 step:16669 [D loss: 0.683795, acc.: 51.56%] [G loss: 0.791919]\n",
      "epoch:17 step:16670 [D loss: 0.649991, acc.: 67.19%] [G loss: 0.875670]\n",
      "epoch:17 step:16671 [D loss: 0.627241, acc.: 64.84%] [G loss: 0.916679]\n",
      "epoch:17 step:16672 [D loss: 0.654403, acc.: 63.28%] [G loss: 0.871280]\n",
      "epoch:17 step:16673 [D loss: 0.589326, acc.: 69.53%] [G loss: 0.860502]\n",
      "epoch:17 step:16674 [D loss: 0.694520, acc.: 61.72%] [G loss: 0.894728]\n",
      "epoch:17 step:16675 [D loss: 0.598262, acc.: 65.62%] [G loss: 0.885493]\n",
      "epoch:17 step:16676 [D loss: 0.659238, acc.: 64.06%] [G loss: 0.990607]\n",
      "epoch:17 step:16677 [D loss: 0.733540, acc.: 52.34%] [G loss: 0.890799]\n",
      "epoch:17 step:16678 [D loss: 0.655134, acc.: 64.84%] [G loss: 0.866404]\n",
      "epoch:17 step:16679 [D loss: 0.664633, acc.: 58.59%] [G loss: 0.877548]\n",
      "epoch:17 step:16680 [D loss: 0.611044, acc.: 64.06%] [G loss: 0.928887]\n",
      "epoch:17 step:16681 [D loss: 0.708070, acc.: 52.34%] [G loss: 0.891343]\n",
      "epoch:17 step:16682 [D loss: 0.676549, acc.: 60.16%] [G loss: 0.901468]\n",
      "epoch:17 step:16683 [D loss: 0.647869, acc.: 61.72%] [G loss: 0.898660]\n",
      "epoch:17 step:16684 [D loss: 0.675261, acc.: 59.38%] [G loss: 0.966762]\n",
      "epoch:17 step:16685 [D loss: 0.653349, acc.: 62.50%] [G loss: 0.949645]\n",
      "epoch:17 step:16686 [D loss: 0.706809, acc.: 53.12%] [G loss: 0.874448]\n",
      "epoch:17 step:16687 [D loss: 0.679535, acc.: 54.69%] [G loss: 0.855770]\n",
      "epoch:17 step:16688 [D loss: 0.676006, acc.: 55.47%] [G loss: 0.936572]\n",
      "epoch:17 step:16689 [D loss: 0.650930, acc.: 61.72%] [G loss: 0.901830]\n",
      "epoch:17 step:16690 [D loss: 0.677844, acc.: 48.44%] [G loss: 0.971708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16691 [D loss: 0.688916, acc.: 56.25%] [G loss: 0.957725]\n",
      "epoch:17 step:16692 [D loss: 0.621826, acc.: 68.75%] [G loss: 0.887310]\n",
      "epoch:17 step:16693 [D loss: 0.648075, acc.: 63.28%] [G loss: 0.883609]\n",
      "epoch:17 step:16694 [D loss: 0.735704, acc.: 46.88%] [G loss: 0.887869]\n",
      "epoch:17 step:16695 [D loss: 0.687510, acc.: 51.56%] [G loss: 0.899179]\n",
      "epoch:17 step:16696 [D loss: 0.643803, acc.: 64.06%] [G loss: 0.935258]\n",
      "epoch:17 step:16697 [D loss: 0.666443, acc.: 60.94%] [G loss: 0.979120]\n",
      "epoch:17 step:16698 [D loss: 0.606079, acc.: 69.53%] [G loss: 1.011682]\n",
      "epoch:17 step:16699 [D loss: 0.616134, acc.: 62.50%] [G loss: 0.991345]\n",
      "epoch:17 step:16700 [D loss: 0.697639, acc.: 56.25%] [G loss: 0.960669]\n",
      "epoch:17 step:16701 [D loss: 0.654886, acc.: 58.59%] [G loss: 0.924093]\n",
      "epoch:17 step:16702 [D loss: 0.649145, acc.: 63.28%] [G loss: 0.898710]\n",
      "epoch:17 step:16703 [D loss: 0.669625, acc.: 58.59%] [G loss: 0.957538]\n",
      "epoch:17 step:16704 [D loss: 0.604092, acc.: 67.97%] [G loss: 1.012406]\n",
      "epoch:17 step:16705 [D loss: 0.672325, acc.: 57.03%] [G loss: 0.926664]\n",
      "epoch:17 step:16706 [D loss: 0.657301, acc.: 57.03%] [G loss: 0.931039]\n",
      "epoch:17 step:16707 [D loss: 0.674740, acc.: 56.25%] [G loss: 0.910641]\n",
      "epoch:17 step:16708 [D loss: 0.655492, acc.: 60.16%] [G loss: 0.883571]\n",
      "epoch:17 step:16709 [D loss: 0.682159, acc.: 51.56%] [G loss: 0.936468]\n",
      "epoch:17 step:16710 [D loss: 0.582379, acc.: 70.31%] [G loss: 0.965489]\n",
      "epoch:17 step:16711 [D loss: 0.584256, acc.: 68.75%] [G loss: 1.040363]\n",
      "epoch:17 step:16712 [D loss: 0.707258, acc.: 53.91%] [G loss: 0.902866]\n",
      "epoch:17 step:16713 [D loss: 0.745284, acc.: 51.56%] [G loss: 0.806849]\n",
      "epoch:17 step:16714 [D loss: 0.709749, acc.: 53.91%] [G loss: 0.864792]\n",
      "epoch:17 step:16715 [D loss: 0.615296, acc.: 67.97%] [G loss: 0.868510]\n",
      "epoch:17 step:16716 [D loss: 0.674373, acc.: 54.69%] [G loss: 0.921371]\n",
      "epoch:17 step:16717 [D loss: 0.694928, acc.: 55.47%] [G loss: 0.900932]\n",
      "epoch:17 step:16718 [D loss: 0.678179, acc.: 59.38%] [G loss: 0.944252]\n",
      "epoch:17 step:16719 [D loss: 0.644363, acc.: 64.84%] [G loss: 0.948262]\n",
      "epoch:17 step:16720 [D loss: 0.666141, acc.: 59.38%] [G loss: 0.836614]\n",
      "epoch:17 step:16721 [D loss: 0.659807, acc.: 61.72%] [G loss: 0.909229]\n",
      "epoch:17 step:16722 [D loss: 0.653515, acc.: 60.16%] [G loss: 0.917644]\n",
      "epoch:17 step:16723 [D loss: 0.689331, acc.: 50.78%] [G loss: 0.918830]\n",
      "epoch:17 step:16724 [D loss: 0.648017, acc.: 58.59%] [G loss: 0.948739]\n",
      "epoch:17 step:16725 [D loss: 0.645590, acc.: 67.19%] [G loss: 0.946090]\n",
      "epoch:17 step:16726 [D loss: 0.683500, acc.: 56.25%] [G loss: 0.910769]\n",
      "epoch:17 step:16727 [D loss: 0.662106, acc.: 63.28%] [G loss: 0.886446]\n",
      "epoch:17 step:16728 [D loss: 0.651955, acc.: 65.62%] [G loss: 0.941642]\n",
      "epoch:17 step:16729 [D loss: 0.707280, acc.: 48.44%] [G loss: 0.947776]\n",
      "epoch:17 step:16730 [D loss: 0.635170, acc.: 64.84%] [G loss: 0.972441]\n",
      "epoch:17 step:16731 [D loss: 0.593234, acc.: 68.75%] [G loss: 0.979208]\n",
      "epoch:17 step:16732 [D loss: 0.616028, acc.: 68.75%] [G loss: 1.003280]\n",
      "epoch:17 step:16733 [D loss: 0.666966, acc.: 62.50%] [G loss: 0.918260]\n",
      "epoch:17 step:16734 [D loss: 0.657375, acc.: 59.38%] [G loss: 0.898724]\n",
      "epoch:17 step:16735 [D loss: 0.680172, acc.: 58.59%] [G loss: 0.839377]\n",
      "epoch:17 step:16736 [D loss: 0.620605, acc.: 65.62%] [G loss: 0.924072]\n",
      "epoch:17 step:16737 [D loss: 0.681276, acc.: 55.47%] [G loss: 0.921707]\n",
      "epoch:17 step:16738 [D loss: 0.730122, acc.: 50.00%] [G loss: 0.835597]\n",
      "epoch:17 step:16739 [D loss: 0.676220, acc.: 56.25%] [G loss: 0.870242]\n",
      "epoch:17 step:16740 [D loss: 0.692836, acc.: 56.25%] [G loss: 0.881789]\n",
      "epoch:17 step:16741 [D loss: 0.675731, acc.: 57.03%] [G loss: 0.884865]\n",
      "epoch:17 step:16742 [D loss: 0.700165, acc.: 54.69%] [G loss: 0.935987]\n",
      "epoch:17 step:16743 [D loss: 0.667983, acc.: 57.81%] [G loss: 0.959545]\n",
      "epoch:17 step:16744 [D loss: 0.685833, acc.: 57.03%] [G loss: 1.030473]\n",
      "epoch:17 step:16745 [D loss: 0.667609, acc.: 58.59%] [G loss: 0.979305]\n",
      "epoch:17 step:16746 [D loss: 0.680361, acc.: 57.81%] [G loss: 0.983644]\n",
      "epoch:17 step:16747 [D loss: 0.707306, acc.: 57.81%] [G loss: 0.959637]\n",
      "epoch:17 step:16748 [D loss: 0.657551, acc.: 60.94%] [G loss: 0.883650]\n",
      "epoch:17 step:16749 [D loss: 0.747801, acc.: 53.91%] [G loss: 0.881959]\n",
      "epoch:17 step:16750 [D loss: 0.669580, acc.: 59.38%] [G loss: 0.871003]\n",
      "epoch:17 step:16751 [D loss: 0.605040, acc.: 67.97%] [G loss: 0.890442]\n",
      "epoch:17 step:16752 [D loss: 0.631500, acc.: 64.06%] [G loss: 0.885764]\n",
      "epoch:17 step:16753 [D loss: 0.662889, acc.: 60.16%] [G loss: 0.850498]\n",
      "epoch:17 step:16754 [D loss: 0.663923, acc.: 64.06%] [G loss: 0.927885]\n",
      "epoch:17 step:16755 [D loss: 0.640706, acc.: 64.06%] [G loss: 0.904797]\n",
      "epoch:17 step:16756 [D loss: 0.655583, acc.: 61.72%] [G loss: 0.912724]\n",
      "epoch:17 step:16757 [D loss: 0.701799, acc.: 48.44%] [G loss: 0.935803]\n",
      "epoch:17 step:16758 [D loss: 0.636824, acc.: 67.19%] [G loss: 0.855507]\n",
      "epoch:17 step:16759 [D loss: 0.645087, acc.: 62.50%] [G loss: 0.912479]\n",
      "epoch:17 step:16760 [D loss: 0.682171, acc.: 63.28%] [G loss: 0.893694]\n",
      "epoch:17 step:16761 [D loss: 0.622960, acc.: 69.53%] [G loss: 0.837861]\n",
      "epoch:17 step:16762 [D loss: 0.662619, acc.: 59.38%] [G loss: 0.878248]\n",
      "epoch:17 step:16763 [D loss: 0.707422, acc.: 50.00%] [G loss: 0.886587]\n",
      "epoch:17 step:16764 [D loss: 0.653224, acc.: 62.50%] [G loss: 0.836253]\n",
      "epoch:17 step:16765 [D loss: 0.666453, acc.: 61.72%] [G loss: 0.861390]\n",
      "epoch:17 step:16766 [D loss: 0.661156, acc.: 55.47%] [G loss: 0.893963]\n",
      "epoch:17 step:16767 [D loss: 0.602593, acc.: 67.97%] [G loss: 0.865677]\n",
      "epoch:17 step:16768 [D loss: 0.659897, acc.: 58.59%] [G loss: 0.860789]\n",
      "epoch:17 step:16769 [D loss: 0.633510, acc.: 63.28%] [G loss: 0.856034]\n",
      "epoch:17 step:16770 [D loss: 0.634797, acc.: 63.28%] [G loss: 0.888197]\n",
      "epoch:17 step:16771 [D loss: 0.591753, acc.: 71.09%] [G loss: 0.879048]\n",
      "epoch:17 step:16772 [D loss: 0.700350, acc.: 53.91%] [G loss: 0.824074]\n",
      "epoch:17 step:16773 [D loss: 0.667075, acc.: 57.03%] [G loss: 0.868168]\n",
      "epoch:17 step:16774 [D loss: 0.629880, acc.: 64.06%] [G loss: 0.920687]\n",
      "epoch:17 step:16775 [D loss: 0.694474, acc.: 53.91%] [G loss: 0.849334]\n",
      "epoch:17 step:16776 [D loss: 0.692610, acc.: 56.25%] [G loss: 0.876486]\n",
      "epoch:17 step:16777 [D loss: 0.686621, acc.: 54.69%] [G loss: 0.928800]\n",
      "epoch:17 step:16778 [D loss: 0.636350, acc.: 61.72%] [G loss: 0.870605]\n",
      "epoch:17 step:16779 [D loss: 0.676762, acc.: 60.94%] [G loss: 0.960994]\n",
      "epoch:17 step:16780 [D loss: 0.691749, acc.: 54.69%] [G loss: 0.883942]\n",
      "epoch:17 step:16781 [D loss: 0.637402, acc.: 65.62%] [G loss: 0.847131]\n",
      "epoch:17 step:16782 [D loss: 0.645607, acc.: 57.03%] [G loss: 0.920118]\n",
      "epoch:17 step:16783 [D loss: 0.632442, acc.: 67.97%] [G loss: 0.892433]\n",
      "epoch:17 step:16784 [D loss: 0.706471, acc.: 52.34%] [G loss: 0.927115]\n",
      "epoch:17 step:16785 [D loss: 0.715055, acc.: 46.88%] [G loss: 0.979401]\n",
      "epoch:17 step:16786 [D loss: 0.646853, acc.: 61.72%] [G loss: 0.889889]\n",
      "epoch:17 step:16787 [D loss: 0.715225, acc.: 55.47%] [G loss: 0.917259]\n",
      "epoch:17 step:16788 [D loss: 0.671700, acc.: 57.81%] [G loss: 0.911958]\n",
      "epoch:17 step:16789 [D loss: 0.629297, acc.: 61.72%] [G loss: 0.943595]\n",
      "epoch:17 step:16790 [D loss: 0.733312, acc.: 51.56%] [G loss: 0.918137]\n",
      "epoch:17 step:16791 [D loss: 0.665734, acc.: 61.72%] [G loss: 0.846636]\n",
      "epoch:17 step:16792 [D loss: 0.669636, acc.: 64.84%] [G loss: 0.946681]\n",
      "epoch:17 step:16793 [D loss: 0.666071, acc.: 57.81%] [G loss: 0.889832]\n",
      "epoch:17 step:16794 [D loss: 0.680570, acc.: 64.06%] [G loss: 0.925964]\n",
      "epoch:17 step:16795 [D loss: 0.665012, acc.: 60.16%] [G loss: 0.896717]\n",
      "epoch:17 step:16796 [D loss: 0.658877, acc.: 59.38%] [G loss: 0.877029]\n",
      "epoch:17 step:16797 [D loss: 0.694208, acc.: 48.44%] [G loss: 0.867971]\n",
      "epoch:17 step:16798 [D loss: 0.671618, acc.: 55.47%] [G loss: 0.911720]\n",
      "epoch:17 step:16799 [D loss: 0.621714, acc.: 67.97%] [G loss: 0.952259]\n",
      "epoch:17 step:16800 [D loss: 0.613523, acc.: 65.62%] [G loss: 0.904023]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.323447\n",
      "FID: 3.946815\n",
      "0 = 11.535068241333947\n",
      "1 = 0.04344194128809644\n",
      "2 = 0.8956000208854675\n",
      "3 = 0.8483999967575073\n",
      "4 = 0.942799985408783\n",
      "5 = 0.9368374347686768\n",
      "6 = 0.8483999967575073\n",
      "7 = 5.192307798093533\n",
      "8 = 0.04205743023954854\n",
      "9 = 0.6822500228881836\n",
      "10 = 0.6593000292778015\n",
      "11 = 0.7052000164985657\n",
      "12 = 0.6910176873207092\n",
      "13 = 0.6593000292778015\n",
      "14 = 8.323518753051758\n",
      "15 = 9.639669418334961\n",
      "16 = 0.06943071633577347\n",
      "17 = 8.323447227478027\n",
      "18 = 3.9468154907226562\n",
      "epoch:17 step:16801 [D loss: 0.666416, acc.: 62.50%] [G loss: 0.968055]\n",
      "epoch:17 step:16802 [D loss: 0.617896, acc.: 64.84%] [G loss: 0.958195]\n",
      "epoch:17 step:16803 [D loss: 0.630361, acc.: 71.09%] [G loss: 0.937663]\n",
      "epoch:17 step:16804 [D loss: 0.595697, acc.: 71.88%] [G loss: 0.943261]\n",
      "epoch:17 step:16805 [D loss: 0.712797, acc.: 47.66%] [G loss: 0.932022]\n",
      "epoch:17 step:16806 [D loss: 0.664283, acc.: 63.28%] [G loss: 0.870595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16807 [D loss: 0.701129, acc.: 51.56%] [G loss: 0.850789]\n",
      "epoch:17 step:16808 [D loss: 0.665522, acc.: 58.59%] [G loss: 0.935825]\n",
      "epoch:17 step:16809 [D loss: 0.689990, acc.: 55.47%] [G loss: 0.906712]\n",
      "epoch:17 step:16810 [D loss: 0.655803, acc.: 60.94%] [G loss: 0.910728]\n",
      "epoch:17 step:16811 [D loss: 0.669158, acc.: 64.06%] [G loss: 0.823873]\n",
      "epoch:17 step:16812 [D loss: 0.671873, acc.: 60.94%] [G loss: 0.891112]\n",
      "epoch:17 step:16813 [D loss: 0.616518, acc.: 67.19%] [G loss: 0.913310]\n",
      "epoch:17 step:16814 [D loss: 0.629758, acc.: 66.41%] [G loss: 0.937510]\n",
      "epoch:17 step:16815 [D loss: 0.639877, acc.: 63.28%] [G loss: 0.957353]\n",
      "epoch:17 step:16816 [D loss: 0.673512, acc.: 58.59%] [G loss: 0.922596]\n",
      "epoch:17 step:16817 [D loss: 0.687436, acc.: 61.72%] [G loss: 0.904932]\n",
      "epoch:17 step:16818 [D loss: 0.611864, acc.: 69.53%] [G loss: 0.885693]\n",
      "epoch:17 step:16819 [D loss: 0.615844, acc.: 61.72%] [G loss: 0.940033]\n",
      "epoch:17 step:16820 [D loss: 0.734035, acc.: 54.69%] [G loss: 0.957737]\n",
      "epoch:17 step:16821 [D loss: 0.724805, acc.: 53.12%] [G loss: 0.858694]\n",
      "epoch:17 step:16822 [D loss: 0.707892, acc.: 56.25%] [G loss: 0.924910]\n",
      "epoch:17 step:16823 [D loss: 0.637243, acc.: 64.06%] [G loss: 0.913124]\n",
      "epoch:17 step:16824 [D loss: 0.606044, acc.: 67.19%] [G loss: 0.947840]\n",
      "epoch:17 step:16825 [D loss: 0.611239, acc.: 67.19%] [G loss: 0.944602]\n",
      "epoch:17 step:16826 [D loss: 0.626537, acc.: 65.62%] [G loss: 0.949583]\n",
      "epoch:17 step:16827 [D loss: 0.614101, acc.: 67.19%] [G loss: 0.913478]\n",
      "epoch:17 step:16828 [D loss: 0.585367, acc.: 70.31%] [G loss: 0.984322]\n",
      "epoch:17 step:16829 [D loss: 0.583720, acc.: 70.31%] [G loss: 0.981380]\n",
      "epoch:17 step:16830 [D loss: 0.677653, acc.: 58.59%] [G loss: 0.872869]\n",
      "epoch:17 step:16831 [D loss: 0.675862, acc.: 60.16%] [G loss: 0.879794]\n",
      "epoch:17 step:16832 [D loss: 0.696333, acc.: 58.59%] [G loss: 0.900416]\n",
      "epoch:17 step:16833 [D loss: 0.690555, acc.: 53.91%] [G loss: 0.848926]\n",
      "epoch:17 step:16834 [D loss: 0.683211, acc.: 57.03%] [G loss: 0.920948]\n",
      "epoch:17 step:16835 [D loss: 0.668343, acc.: 55.47%] [G loss: 0.943364]\n",
      "epoch:17 step:16836 [D loss: 0.665735, acc.: 62.50%] [G loss: 0.928330]\n",
      "epoch:17 step:16837 [D loss: 0.644111, acc.: 67.19%] [G loss: 0.980449]\n",
      "epoch:17 step:16838 [D loss: 0.575108, acc.: 73.44%] [G loss: 0.977966]\n",
      "epoch:17 step:16839 [D loss: 0.687718, acc.: 58.59%] [G loss: 0.928369]\n",
      "epoch:17 step:16840 [D loss: 0.709882, acc.: 54.69%] [G loss: 0.928429]\n",
      "epoch:17 step:16841 [D loss: 0.681163, acc.: 57.03%] [G loss: 0.987157]\n",
      "epoch:17 step:16842 [D loss: 0.621031, acc.: 64.06%] [G loss: 0.991826]\n",
      "epoch:17 step:16843 [D loss: 0.642522, acc.: 62.50%] [G loss: 0.982312]\n",
      "epoch:17 step:16844 [D loss: 0.708992, acc.: 55.47%] [G loss: 0.903392]\n",
      "epoch:17 step:16845 [D loss: 0.655671, acc.: 64.06%] [G loss: 0.895052]\n",
      "epoch:17 step:16846 [D loss: 0.662942, acc.: 55.47%] [G loss: 0.961535]\n",
      "epoch:17 step:16847 [D loss: 0.544869, acc.: 75.78%] [G loss: 0.969844]\n",
      "epoch:17 step:16848 [D loss: 0.609262, acc.: 62.50%] [G loss: 0.960410]\n",
      "epoch:17 step:16849 [D loss: 0.738537, acc.: 51.56%] [G loss: 0.977345]\n",
      "epoch:17 step:16850 [D loss: 0.654880, acc.: 60.94%] [G loss: 0.947183]\n",
      "epoch:17 step:16851 [D loss: 0.722656, acc.: 52.34%] [G loss: 0.838771]\n",
      "epoch:17 step:16852 [D loss: 0.595166, acc.: 68.75%] [G loss: 0.870395]\n",
      "epoch:17 step:16853 [D loss: 0.558605, acc.: 77.34%] [G loss: 0.933895]\n",
      "epoch:17 step:16854 [D loss: 0.594672, acc.: 71.88%] [G loss: 0.950505]\n",
      "epoch:17 step:16855 [D loss: 0.597795, acc.: 68.75%] [G loss: 1.035226]\n",
      "epoch:17 step:16856 [D loss: 0.703456, acc.: 59.38%] [G loss: 1.085860]\n",
      "epoch:17 step:16857 [D loss: 0.840014, acc.: 54.69%] [G loss: 1.076393]\n",
      "epoch:17 step:16858 [D loss: 0.609690, acc.: 64.06%] [G loss: 1.210105]\n",
      "epoch:17 step:16859 [D loss: 0.572290, acc.: 71.88%] [G loss: 1.109124]\n",
      "epoch:17 step:16860 [D loss: 0.713893, acc.: 56.25%] [G loss: 1.016895]\n",
      "epoch:17 step:16861 [D loss: 0.785142, acc.: 46.09%] [G loss: 0.864830]\n",
      "epoch:17 step:16862 [D loss: 0.679835, acc.: 63.28%] [G loss: 0.902325]\n",
      "epoch:17 step:16863 [D loss: 0.635961, acc.: 59.38%] [G loss: 0.989138]\n",
      "epoch:17 step:16864 [D loss: 0.558398, acc.: 73.44%] [G loss: 0.984781]\n",
      "epoch:17 step:16865 [D loss: 0.486653, acc.: 80.47%] [G loss: 1.027192]\n",
      "epoch:17 step:16866 [D loss: 0.602753, acc.: 70.31%] [G loss: 0.971900]\n",
      "epoch:18 step:16867 [D loss: 0.642679, acc.: 60.94%] [G loss: 1.018275]\n",
      "epoch:18 step:16868 [D loss: 0.737330, acc.: 58.59%] [G loss: 1.020466]\n",
      "epoch:18 step:16869 [D loss: 0.708648, acc.: 54.69%] [G loss: 0.916865]\n",
      "epoch:18 step:16870 [D loss: 0.696259, acc.: 56.25%] [G loss: 0.945786]\n",
      "epoch:18 step:16871 [D loss: 0.668046, acc.: 61.72%] [G loss: 0.913743]\n",
      "epoch:18 step:16872 [D loss: 0.635034, acc.: 60.16%] [G loss: 0.910539]\n",
      "epoch:18 step:16873 [D loss: 0.664962, acc.: 54.69%] [G loss: 0.918706]\n",
      "epoch:18 step:16874 [D loss: 0.625419, acc.: 62.50%] [G loss: 0.878389]\n",
      "epoch:18 step:16875 [D loss: 0.653981, acc.: 60.94%] [G loss: 0.919485]\n",
      "epoch:18 step:16876 [D loss: 0.684041, acc.: 57.81%] [G loss: 0.927122]\n",
      "epoch:18 step:16877 [D loss: 0.630660, acc.: 60.94%] [G loss: 1.001667]\n",
      "epoch:18 step:16878 [D loss: 0.655675, acc.: 62.50%] [G loss: 1.033407]\n",
      "epoch:18 step:16879 [D loss: 0.638547, acc.: 61.72%] [G loss: 0.975082]\n",
      "epoch:18 step:16880 [D loss: 0.585967, acc.: 70.31%] [G loss: 0.944106]\n",
      "epoch:18 step:16881 [D loss: 0.575850, acc.: 68.75%] [G loss: 0.990757]\n",
      "epoch:18 step:16882 [D loss: 0.562023, acc.: 72.66%] [G loss: 0.936945]\n",
      "epoch:18 step:16883 [D loss: 0.668515, acc.: 57.81%] [G loss: 0.943593]\n",
      "epoch:18 step:16884 [D loss: 0.673441, acc.: 59.38%] [G loss: 1.009382]\n",
      "epoch:18 step:16885 [D loss: 0.714716, acc.: 50.78%] [G loss: 0.984521]\n",
      "epoch:18 step:16886 [D loss: 0.664632, acc.: 63.28%] [G loss: 1.039025]\n",
      "epoch:18 step:16887 [D loss: 0.633284, acc.: 67.97%] [G loss: 1.005163]\n",
      "epoch:18 step:16888 [D loss: 0.611119, acc.: 67.97%] [G loss: 1.120108]\n",
      "epoch:18 step:16889 [D loss: 0.701504, acc.: 57.03%] [G loss: 0.936000]\n",
      "epoch:18 step:16890 [D loss: 0.689209, acc.: 53.91%] [G loss: 0.882363]\n",
      "epoch:18 step:16891 [D loss: 0.619877, acc.: 67.19%] [G loss: 0.910553]\n",
      "epoch:18 step:16892 [D loss: 0.665490, acc.: 60.16%] [G loss: 0.873172]\n",
      "epoch:18 step:16893 [D loss: 0.667668, acc.: 65.62%] [G loss: 0.925339]\n",
      "epoch:18 step:16894 [D loss: 0.683183, acc.: 57.81%] [G loss: 0.905690]\n",
      "epoch:18 step:16895 [D loss: 0.608888, acc.: 67.97%] [G loss: 0.917779]\n",
      "epoch:18 step:16896 [D loss: 0.657062, acc.: 60.16%] [G loss: 0.900274]\n",
      "epoch:18 step:16897 [D loss: 0.675439, acc.: 57.81%] [G loss: 0.929888]\n",
      "epoch:18 step:16898 [D loss: 0.643077, acc.: 64.84%] [G loss: 0.913324]\n",
      "epoch:18 step:16899 [D loss: 0.652938, acc.: 60.16%] [G loss: 0.983108]\n",
      "epoch:18 step:16900 [D loss: 0.660632, acc.: 63.28%] [G loss: 0.911841]\n",
      "epoch:18 step:16901 [D loss: 0.668233, acc.: 57.81%] [G loss: 0.889564]\n",
      "epoch:18 step:16902 [D loss: 0.621498, acc.: 71.88%] [G loss: 0.961507]\n",
      "epoch:18 step:16903 [D loss: 0.682989, acc.: 57.81%] [G loss: 0.890147]\n",
      "epoch:18 step:16904 [D loss: 0.736823, acc.: 46.88%] [G loss: 0.861730]\n",
      "epoch:18 step:16905 [D loss: 0.660248, acc.: 64.84%] [G loss: 0.872198]\n",
      "epoch:18 step:16906 [D loss: 0.652835, acc.: 62.50%] [G loss: 0.867733]\n",
      "epoch:18 step:16907 [D loss: 0.681417, acc.: 57.81%] [G loss: 0.895111]\n",
      "epoch:18 step:16908 [D loss: 0.642271, acc.: 67.97%] [G loss: 0.818174]\n",
      "epoch:18 step:16909 [D loss: 0.637176, acc.: 64.84%] [G loss: 0.904341]\n",
      "epoch:18 step:16910 [D loss: 0.691637, acc.: 58.59%] [G loss: 0.868045]\n",
      "epoch:18 step:16911 [D loss: 0.675401, acc.: 57.81%] [G loss: 0.966614]\n",
      "epoch:18 step:16912 [D loss: 0.651222, acc.: 57.81%] [G loss: 0.909592]\n",
      "epoch:18 step:16913 [D loss: 0.655793, acc.: 63.28%] [G loss: 0.914554]\n",
      "epoch:18 step:16914 [D loss: 0.636716, acc.: 64.06%] [G loss: 0.893791]\n",
      "epoch:18 step:16915 [D loss: 0.620953, acc.: 64.84%] [G loss: 0.899518]\n",
      "epoch:18 step:16916 [D loss: 0.646394, acc.: 60.94%] [G loss: 0.836633]\n",
      "epoch:18 step:16917 [D loss: 0.688601, acc.: 54.69%] [G loss: 0.862616]\n",
      "epoch:18 step:16918 [D loss: 0.670708, acc.: 59.38%] [G loss: 0.894289]\n",
      "epoch:18 step:16919 [D loss: 0.648366, acc.: 60.94%] [G loss: 0.923726]\n",
      "epoch:18 step:16920 [D loss: 0.603556, acc.: 63.28%] [G loss: 0.892966]\n",
      "epoch:18 step:16921 [D loss: 0.628737, acc.: 63.28%] [G loss: 0.908111]\n",
      "epoch:18 step:16922 [D loss: 0.643686, acc.: 64.84%] [G loss: 0.868684]\n",
      "epoch:18 step:16923 [D loss: 0.661518, acc.: 59.38%] [G loss: 0.804904]\n",
      "epoch:18 step:16924 [D loss: 0.691174, acc.: 56.25%] [G loss: 0.875121]\n",
      "epoch:18 step:16925 [D loss: 0.621714, acc.: 71.09%] [G loss: 0.995451]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:16926 [D loss: 0.667991, acc.: 59.38%] [G loss: 0.941468]\n",
      "epoch:18 step:16927 [D loss: 0.697202, acc.: 52.34%] [G loss: 0.863376]\n",
      "epoch:18 step:16928 [D loss: 0.711798, acc.: 53.91%] [G loss: 0.957299]\n",
      "epoch:18 step:16929 [D loss: 0.597921, acc.: 68.75%] [G loss: 0.961391]\n",
      "epoch:18 step:16930 [D loss: 0.699574, acc.: 55.47%] [G loss: 0.935585]\n",
      "epoch:18 step:16931 [D loss: 0.636608, acc.: 63.28%] [G loss: 0.931554]\n",
      "epoch:18 step:16932 [D loss: 0.666252, acc.: 59.38%] [G loss: 0.950184]\n",
      "epoch:18 step:16933 [D loss: 0.652448, acc.: 57.81%] [G loss: 0.850812]\n",
      "epoch:18 step:16934 [D loss: 0.657940, acc.: 62.50%] [G loss: 0.872051]\n",
      "epoch:18 step:16935 [D loss: 0.616689, acc.: 68.75%] [G loss: 0.864424]\n",
      "epoch:18 step:16936 [D loss: 0.638816, acc.: 60.94%] [G loss: 0.980562]\n",
      "epoch:18 step:16937 [D loss: 0.709353, acc.: 54.69%] [G loss: 0.919761]\n",
      "epoch:18 step:16938 [D loss: 0.696922, acc.: 57.03%] [G loss: 0.882507]\n",
      "epoch:18 step:16939 [D loss: 0.672213, acc.: 57.03%] [G loss: 0.868407]\n",
      "epoch:18 step:16940 [D loss: 0.625758, acc.: 62.50%] [G loss: 0.912550]\n",
      "epoch:18 step:16941 [D loss: 0.648999, acc.: 64.84%] [G loss: 0.952067]\n",
      "epoch:18 step:16942 [D loss: 0.574920, acc.: 70.31%] [G loss: 0.915618]\n",
      "epoch:18 step:16943 [D loss: 0.592763, acc.: 65.62%] [G loss: 0.974419]\n",
      "epoch:18 step:16944 [D loss: 0.750930, acc.: 51.56%] [G loss: 0.912174]\n",
      "epoch:18 step:16945 [D loss: 0.674949, acc.: 60.16%] [G loss: 0.898490]\n",
      "epoch:18 step:16946 [D loss: 0.640687, acc.: 63.28%] [G loss: 0.897952]\n",
      "epoch:18 step:16947 [D loss: 0.656970, acc.: 62.50%] [G loss: 0.824994]\n",
      "epoch:18 step:16948 [D loss: 0.632078, acc.: 59.38%] [G loss: 0.875095]\n",
      "epoch:18 step:16949 [D loss: 0.640000, acc.: 60.16%] [G loss: 0.862175]\n",
      "epoch:18 step:16950 [D loss: 0.629930, acc.: 67.19%] [G loss: 0.930367]\n",
      "epoch:18 step:16951 [D loss: 0.712282, acc.: 60.16%] [G loss: 0.948544]\n",
      "epoch:18 step:16952 [D loss: 0.679430, acc.: 59.38%] [G loss: 0.934917]\n",
      "epoch:18 step:16953 [D loss: 0.644185, acc.: 56.25%] [G loss: 0.892793]\n",
      "epoch:18 step:16954 [D loss: 0.609144, acc.: 68.75%] [G loss: 0.918903]\n",
      "epoch:18 step:16955 [D loss: 0.650632, acc.: 60.94%] [G loss: 0.948837]\n",
      "epoch:18 step:16956 [D loss: 0.645467, acc.: 64.84%] [G loss: 0.925446]\n",
      "epoch:18 step:16957 [D loss: 0.640111, acc.: 64.84%] [G loss: 0.916137]\n",
      "epoch:18 step:16958 [D loss: 0.601398, acc.: 70.31%] [G loss: 0.973699]\n",
      "epoch:18 step:16959 [D loss: 0.563449, acc.: 71.88%] [G loss: 0.915214]\n",
      "epoch:18 step:16960 [D loss: 0.668974, acc.: 60.94%] [G loss: 0.959489]\n",
      "epoch:18 step:16961 [D loss: 0.679894, acc.: 55.47%] [G loss: 0.897859]\n",
      "epoch:18 step:16962 [D loss: 0.655057, acc.: 62.50%] [G loss: 0.960721]\n",
      "epoch:18 step:16963 [D loss: 0.615060, acc.: 67.19%] [G loss: 0.968380]\n",
      "epoch:18 step:16964 [D loss: 0.659677, acc.: 60.16%] [G loss: 0.958730]\n",
      "epoch:18 step:16965 [D loss: 0.641950, acc.: 64.06%] [G loss: 0.916561]\n",
      "epoch:18 step:16966 [D loss: 0.609257, acc.: 67.97%] [G loss: 0.897766]\n",
      "epoch:18 step:16967 [D loss: 0.666364, acc.: 61.72%] [G loss: 0.931057]\n",
      "epoch:18 step:16968 [D loss: 0.730694, acc.: 49.22%] [G loss: 0.829538]\n",
      "epoch:18 step:16969 [D loss: 0.672318, acc.: 57.03%] [G loss: 0.855103]\n",
      "epoch:18 step:16970 [D loss: 0.694921, acc.: 54.69%] [G loss: 0.898420]\n",
      "epoch:18 step:16971 [D loss: 0.692855, acc.: 52.34%] [G loss: 0.843101]\n",
      "epoch:18 step:16972 [D loss: 0.645140, acc.: 65.62%] [G loss: 0.869892]\n",
      "epoch:18 step:16973 [D loss: 0.622018, acc.: 66.41%] [G loss: 0.946167]\n",
      "epoch:18 step:16974 [D loss: 0.722865, acc.: 51.56%] [G loss: 0.978941]\n",
      "epoch:18 step:16975 [D loss: 0.705495, acc.: 52.34%] [G loss: 0.907034]\n",
      "epoch:18 step:16976 [D loss: 0.690585, acc.: 57.81%] [G loss: 0.827687]\n",
      "epoch:18 step:16977 [D loss: 0.664686, acc.: 57.03%] [G loss: 0.930440]\n",
      "epoch:18 step:16978 [D loss: 0.620383, acc.: 67.97%] [G loss: 0.905547]\n",
      "epoch:18 step:16979 [D loss: 0.619724, acc.: 67.19%] [G loss: 0.930199]\n",
      "epoch:18 step:16980 [D loss: 0.627122, acc.: 64.84%] [G loss: 0.890900]\n",
      "epoch:18 step:16981 [D loss: 0.572852, acc.: 70.31%] [G loss: 1.014131]\n",
      "epoch:18 step:16982 [D loss: 0.640182, acc.: 66.41%] [G loss: 1.046564]\n",
      "epoch:18 step:16983 [D loss: 0.661823, acc.: 60.16%] [G loss: 0.981559]\n",
      "epoch:18 step:16984 [D loss: 0.640147, acc.: 64.06%] [G loss: 1.062804]\n",
      "epoch:18 step:16985 [D loss: 0.558159, acc.: 73.44%] [G loss: 1.037707]\n",
      "epoch:18 step:16986 [D loss: 0.739372, acc.: 53.91%] [G loss: 1.033848]\n",
      "epoch:18 step:16987 [D loss: 0.665595, acc.: 59.38%] [G loss: 1.001590]\n",
      "epoch:18 step:16988 [D loss: 0.587017, acc.: 71.09%] [G loss: 0.960770]\n",
      "epoch:18 step:16989 [D loss: 0.665398, acc.: 57.81%] [G loss: 0.956044]\n",
      "epoch:18 step:16990 [D loss: 0.696076, acc.: 57.03%] [G loss: 0.954483]\n",
      "epoch:18 step:16991 [D loss: 0.710447, acc.: 56.25%] [G loss: 0.893598]\n",
      "epoch:18 step:16992 [D loss: 0.627787, acc.: 64.06%] [G loss: 0.913426]\n",
      "epoch:18 step:16993 [D loss: 0.641210, acc.: 62.50%] [G loss: 0.930038]\n",
      "epoch:18 step:16994 [D loss: 0.631425, acc.: 60.16%] [G loss: 0.883785]\n",
      "epoch:18 step:16995 [D loss: 0.651078, acc.: 62.50%] [G loss: 0.837134]\n",
      "epoch:18 step:16996 [D loss: 0.634493, acc.: 66.41%] [G loss: 0.848588]\n",
      "epoch:18 step:16997 [D loss: 0.614979, acc.: 66.41%] [G loss: 0.829360]\n",
      "epoch:18 step:16998 [D loss: 0.683019, acc.: 61.72%] [G loss: 0.927240]\n",
      "epoch:18 step:16999 [D loss: 0.683553, acc.: 59.38%] [G loss: 0.923774]\n",
      "epoch:18 step:17000 [D loss: 0.644581, acc.: 60.16%] [G loss: 0.967771]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.108435\n",
      "FID: 8.869603\n",
      "0 = 11.812538429188738\n",
      "1 = 0.05189007827208874\n",
      "2 = 0.9128999710083008\n",
      "3 = 0.8723999857902527\n",
      "4 = 0.9534000158309937\n",
      "5 = 0.9492927193641663\n",
      "6 = 0.8723999857902527\n",
      "7 = 5.837300787532332\n",
      "8 = 0.062525743904554\n",
      "9 = 0.6941999793052673\n",
      "10 = 0.6753000020980835\n",
      "11 = 0.713100016117096\n",
      "12 = 0.7018291354179382\n",
      "13 = 0.6753000020980835\n",
      "14 = 8.108500480651855\n",
      "15 = 9.538216590881348\n",
      "16 = 0.1118110716342926\n",
      "17 = 8.108434677124023\n",
      "18 = 8.869603157043457\n",
      "epoch:18 step:17001 [D loss: 0.614618, acc.: 65.62%] [G loss: 1.003359]\n",
      "epoch:18 step:17002 [D loss: 0.628684, acc.: 56.25%] [G loss: 0.965039]\n",
      "epoch:18 step:17003 [D loss: 0.652363, acc.: 64.84%] [G loss: 1.024904]\n",
      "epoch:18 step:17004 [D loss: 0.710230, acc.: 52.34%] [G loss: 0.932533]\n",
      "epoch:18 step:17005 [D loss: 0.651198, acc.: 61.72%] [G loss: 0.929565]\n",
      "epoch:18 step:17006 [D loss: 0.628949, acc.: 67.97%] [G loss: 0.837235]\n",
      "epoch:18 step:17007 [D loss: 0.686748, acc.: 52.34%] [G loss: 0.867106]\n",
      "epoch:18 step:17008 [D loss: 0.667438, acc.: 62.50%] [G loss: 0.887188]\n",
      "epoch:18 step:17009 [D loss: 0.705561, acc.: 53.91%] [G loss: 0.874171]\n",
      "epoch:18 step:17010 [D loss: 0.666246, acc.: 64.06%] [G loss: 0.923233]\n",
      "epoch:18 step:17011 [D loss: 0.656504, acc.: 61.72%] [G loss: 0.919986]\n",
      "epoch:18 step:17012 [D loss: 0.634953, acc.: 62.50%] [G loss: 0.974357]\n",
      "epoch:18 step:17013 [D loss: 0.711392, acc.: 50.00%] [G loss: 0.851189]\n",
      "epoch:18 step:17014 [D loss: 0.667280, acc.: 61.72%] [G loss: 0.843759]\n",
      "epoch:18 step:17015 [D loss: 0.646034, acc.: 61.72%] [G loss: 0.858823]\n",
      "epoch:18 step:17016 [D loss: 0.697598, acc.: 51.56%] [G loss: 0.879527]\n",
      "epoch:18 step:17017 [D loss: 0.640490, acc.: 64.84%] [G loss: 0.859170]\n",
      "epoch:18 step:17018 [D loss: 0.640321, acc.: 63.28%] [G loss: 0.870029]\n",
      "epoch:18 step:17019 [D loss: 0.712083, acc.: 49.22%] [G loss: 0.900938]\n",
      "epoch:18 step:17020 [D loss: 0.664970, acc.: 57.03%] [G loss: 0.942806]\n",
      "epoch:18 step:17021 [D loss: 0.633560, acc.: 62.50%] [G loss: 0.895119]\n",
      "epoch:18 step:17022 [D loss: 0.670253, acc.: 59.38%] [G loss: 0.903864]\n",
      "epoch:18 step:17023 [D loss: 0.670941, acc.: 62.50%] [G loss: 0.948694]\n",
      "epoch:18 step:17024 [D loss: 0.662477, acc.: 57.03%] [G loss: 0.865935]\n",
      "epoch:18 step:17025 [D loss: 0.641808, acc.: 65.62%] [G loss: 0.996473]\n",
      "epoch:18 step:17026 [D loss: 0.733515, acc.: 56.25%] [G loss: 0.875138]\n",
      "epoch:18 step:17027 [D loss: 0.679257, acc.: 58.59%] [G loss: 0.936451]\n",
      "epoch:18 step:17028 [D loss: 0.681637, acc.: 60.94%] [G loss: 0.896925]\n",
      "epoch:18 step:17029 [D loss: 0.694974, acc.: 50.78%] [G loss: 0.850652]\n",
      "epoch:18 step:17030 [D loss: 0.636521, acc.: 60.16%] [G loss: 0.968039]\n",
      "epoch:18 step:17031 [D loss: 0.674787, acc.: 57.03%] [G loss: 0.921986]\n",
      "epoch:18 step:17032 [D loss: 0.666655, acc.: 56.25%] [G loss: 0.925943]\n",
      "epoch:18 step:17033 [D loss: 0.672261, acc.: 61.72%] [G loss: 0.843253]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17034 [D loss: 0.633533, acc.: 65.62%] [G loss: 0.894131]\n",
      "epoch:18 step:17035 [D loss: 0.653555, acc.: 59.38%] [G loss: 0.970468]\n",
      "epoch:18 step:17036 [D loss: 0.647743, acc.: 66.41%] [G loss: 0.916323]\n",
      "epoch:18 step:17037 [D loss: 0.626623, acc.: 60.16%] [G loss: 0.852030]\n",
      "epoch:18 step:17038 [D loss: 0.698265, acc.: 54.69%] [G loss: 0.870630]\n",
      "epoch:18 step:17039 [D loss: 0.635502, acc.: 64.06%] [G loss: 0.919800]\n",
      "epoch:18 step:17040 [D loss: 0.663866, acc.: 58.59%] [G loss: 0.937122]\n",
      "epoch:18 step:17041 [D loss: 0.712966, acc.: 51.56%] [G loss: 0.862799]\n",
      "epoch:18 step:17042 [D loss: 0.641559, acc.: 65.62%] [G loss: 0.935870]\n",
      "epoch:18 step:17043 [D loss: 0.646982, acc.: 60.16%] [G loss: 0.893408]\n",
      "epoch:18 step:17044 [D loss: 0.663043, acc.: 59.38%] [G loss: 0.897965]\n",
      "epoch:18 step:17045 [D loss: 0.641207, acc.: 67.19%] [G loss: 0.946015]\n",
      "epoch:18 step:17046 [D loss: 0.673386, acc.: 59.38%] [G loss: 0.943770]\n",
      "epoch:18 step:17047 [D loss: 0.703704, acc.: 51.56%] [G loss: 0.832941]\n",
      "epoch:18 step:17048 [D loss: 0.656947, acc.: 63.28%] [G loss: 0.906589]\n",
      "epoch:18 step:17049 [D loss: 0.676056, acc.: 60.16%] [G loss: 0.890011]\n",
      "epoch:18 step:17050 [D loss: 0.599835, acc.: 67.19%] [G loss: 0.941669]\n",
      "epoch:18 step:17051 [D loss: 0.656714, acc.: 64.06%] [G loss: 0.912911]\n",
      "epoch:18 step:17052 [D loss: 0.674733, acc.: 56.25%] [G loss: 0.920651]\n",
      "epoch:18 step:17053 [D loss: 0.627733, acc.: 65.62%] [G loss: 0.852451]\n",
      "epoch:18 step:17054 [D loss: 0.700320, acc.: 53.91%] [G loss: 0.869984]\n",
      "epoch:18 step:17055 [D loss: 0.688734, acc.: 56.25%] [G loss: 0.912438]\n",
      "epoch:18 step:17056 [D loss: 0.656226, acc.: 58.59%] [G loss: 0.907640]\n",
      "epoch:18 step:17057 [D loss: 0.635677, acc.: 64.84%] [G loss: 0.975359]\n",
      "epoch:18 step:17058 [D loss: 0.656791, acc.: 58.59%] [G loss: 0.921267]\n",
      "epoch:18 step:17059 [D loss: 0.698814, acc.: 57.81%] [G loss: 0.881889]\n",
      "epoch:18 step:17060 [D loss: 0.651751, acc.: 61.72%] [G loss: 0.893356]\n",
      "epoch:18 step:17061 [D loss: 0.658564, acc.: 58.59%] [G loss: 0.908803]\n",
      "epoch:18 step:17062 [D loss: 0.673039, acc.: 60.94%] [G loss: 0.941685]\n",
      "epoch:18 step:17063 [D loss: 0.614281, acc.: 63.28%] [G loss: 0.916208]\n",
      "epoch:18 step:17064 [D loss: 0.656253, acc.: 60.94%] [G loss: 0.929220]\n",
      "epoch:18 step:17065 [D loss: 0.649319, acc.: 60.94%] [G loss: 0.869849]\n",
      "epoch:18 step:17066 [D loss: 0.730313, acc.: 50.78%] [G loss: 0.901461]\n",
      "epoch:18 step:17067 [D loss: 0.653312, acc.: 54.69%] [G loss: 0.918437]\n",
      "epoch:18 step:17068 [D loss: 0.708101, acc.: 53.91%] [G loss: 0.851874]\n",
      "epoch:18 step:17069 [D loss: 0.716338, acc.: 50.00%] [G loss: 0.902792]\n",
      "epoch:18 step:17070 [D loss: 0.690478, acc.: 50.00%] [G loss: 0.913629]\n",
      "epoch:18 step:17071 [D loss: 0.632043, acc.: 64.84%] [G loss: 0.939679]\n",
      "epoch:18 step:17072 [D loss: 0.617665, acc.: 65.62%] [G loss: 0.927725]\n",
      "epoch:18 step:17073 [D loss: 0.627119, acc.: 66.41%] [G loss: 0.941421]\n",
      "epoch:18 step:17074 [D loss: 0.621607, acc.: 60.16%] [G loss: 0.983836]\n",
      "epoch:18 step:17075 [D loss: 0.615658, acc.: 70.31%] [G loss: 0.920748]\n",
      "epoch:18 step:17076 [D loss: 0.705229, acc.: 53.12%] [G loss: 0.884795]\n",
      "epoch:18 step:17077 [D loss: 0.706449, acc.: 51.56%] [G loss: 0.873103]\n",
      "epoch:18 step:17078 [D loss: 0.654510, acc.: 67.19%] [G loss: 0.862908]\n",
      "epoch:18 step:17079 [D loss: 0.649493, acc.: 60.94%] [G loss: 0.886239]\n",
      "epoch:18 step:17080 [D loss: 0.698214, acc.: 58.59%] [G loss: 0.885543]\n",
      "epoch:18 step:17081 [D loss: 0.715572, acc.: 59.38%] [G loss: 0.868538]\n",
      "epoch:18 step:17082 [D loss: 0.629685, acc.: 62.50%] [G loss: 0.847156]\n",
      "epoch:18 step:17083 [D loss: 0.664718, acc.: 58.59%] [G loss: 0.885513]\n",
      "epoch:18 step:17084 [D loss: 0.653003, acc.: 59.38%] [G loss: 0.875963]\n",
      "epoch:18 step:17085 [D loss: 0.604157, acc.: 67.97%] [G loss: 0.942303]\n",
      "epoch:18 step:17086 [D loss: 0.732267, acc.: 54.69%] [G loss: 0.956869]\n",
      "epoch:18 step:17087 [D loss: 0.633399, acc.: 64.06%] [G loss: 0.955362]\n",
      "epoch:18 step:17088 [D loss: 0.580080, acc.: 70.31%] [G loss: 0.947219]\n",
      "epoch:18 step:17089 [D loss: 0.576118, acc.: 73.44%] [G loss: 0.980293]\n",
      "epoch:18 step:17090 [D loss: 0.703743, acc.: 55.47%] [G loss: 0.842224]\n",
      "epoch:18 step:17091 [D loss: 0.658547, acc.: 58.59%] [G loss: 0.920535]\n",
      "epoch:18 step:17092 [D loss: 0.688003, acc.: 54.69%] [G loss: 0.917664]\n",
      "epoch:18 step:17093 [D loss: 0.651843, acc.: 67.97%] [G loss: 0.894619]\n",
      "epoch:18 step:17094 [D loss: 0.674092, acc.: 58.59%] [G loss: 0.899501]\n",
      "epoch:18 step:17095 [D loss: 0.593679, acc.: 72.66%] [G loss: 0.863796]\n",
      "epoch:18 step:17096 [D loss: 0.591828, acc.: 67.97%] [G loss: 0.940722]\n",
      "epoch:18 step:17097 [D loss: 0.584478, acc.: 64.84%] [G loss: 0.958325]\n",
      "epoch:18 step:17098 [D loss: 0.554186, acc.: 73.44%] [G loss: 1.076939]\n",
      "epoch:18 step:17099 [D loss: 0.675420, acc.: 63.28%] [G loss: 0.978094]\n",
      "epoch:18 step:17100 [D loss: 0.721867, acc.: 57.03%] [G loss: 0.981313]\n",
      "epoch:18 step:17101 [D loss: 0.667151, acc.: 60.16%] [G loss: 0.905464]\n",
      "epoch:18 step:17102 [D loss: 0.657258, acc.: 60.94%] [G loss: 0.930667]\n",
      "epoch:18 step:17103 [D loss: 0.643640, acc.: 64.84%] [G loss: 0.963745]\n",
      "epoch:18 step:17104 [D loss: 0.609653, acc.: 69.53%] [G loss: 0.946395]\n",
      "epoch:18 step:17105 [D loss: 0.632071, acc.: 61.72%] [G loss: 0.887860]\n",
      "epoch:18 step:17106 [D loss: 0.634516, acc.: 65.62%] [G loss: 0.921130]\n",
      "epoch:18 step:17107 [D loss: 0.558558, acc.: 73.44%] [G loss: 0.965434]\n",
      "epoch:18 step:17108 [D loss: 0.629679, acc.: 66.41%] [G loss: 0.982624]\n",
      "epoch:18 step:17109 [D loss: 0.627501, acc.: 67.19%] [G loss: 0.995927]\n",
      "epoch:18 step:17110 [D loss: 0.687377, acc.: 56.25%] [G loss: 0.974045]\n",
      "epoch:18 step:17111 [D loss: 0.625606, acc.: 67.97%] [G loss: 0.993115]\n",
      "epoch:18 step:17112 [D loss: 0.650101, acc.: 64.06%] [G loss: 0.962247]\n",
      "epoch:18 step:17113 [D loss: 0.657652, acc.: 60.94%] [G loss: 0.927535]\n",
      "epoch:18 step:17114 [D loss: 0.622091, acc.: 66.41%] [G loss: 0.993853]\n",
      "epoch:18 step:17115 [D loss: 0.788269, acc.: 44.53%] [G loss: 0.971184]\n",
      "epoch:18 step:17116 [D loss: 0.731884, acc.: 50.78%] [G loss: 0.911785]\n",
      "epoch:18 step:17117 [D loss: 0.692062, acc.: 57.03%] [G loss: 0.856756]\n",
      "epoch:18 step:17118 [D loss: 0.649515, acc.: 60.94%] [G loss: 0.827902]\n",
      "epoch:18 step:17119 [D loss: 0.694362, acc.: 50.78%] [G loss: 0.907717]\n",
      "epoch:18 step:17120 [D loss: 0.666476, acc.: 61.72%] [G loss: 0.939495]\n",
      "epoch:18 step:17121 [D loss: 0.649411, acc.: 57.81%] [G loss: 0.962901]\n",
      "epoch:18 step:17122 [D loss: 0.699523, acc.: 54.69%] [G loss: 0.982133]\n",
      "epoch:18 step:17123 [D loss: 0.656177, acc.: 59.38%] [G loss: 0.942457]\n",
      "epoch:18 step:17124 [D loss: 0.631616, acc.: 60.16%] [G loss: 0.921210]\n",
      "epoch:18 step:17125 [D loss: 0.631186, acc.: 62.50%] [G loss: 0.892365]\n",
      "epoch:18 step:17126 [D loss: 0.676304, acc.: 50.00%] [G loss: 0.864618]\n",
      "epoch:18 step:17127 [D loss: 0.632908, acc.: 59.38%] [G loss: 0.891810]\n",
      "epoch:18 step:17128 [D loss: 0.632762, acc.: 63.28%] [G loss: 0.861322]\n",
      "epoch:18 step:17129 [D loss: 0.719467, acc.: 55.47%] [G loss: 0.875556]\n",
      "epoch:18 step:17130 [D loss: 0.640186, acc.: 67.97%] [G loss: 0.893675]\n",
      "epoch:18 step:17131 [D loss: 0.694120, acc.: 50.78%] [G loss: 0.894763]\n",
      "epoch:18 step:17132 [D loss: 0.645788, acc.: 65.62%] [G loss: 0.848473]\n",
      "epoch:18 step:17133 [D loss: 0.669374, acc.: 57.03%] [G loss: 0.920012]\n",
      "epoch:18 step:17134 [D loss: 0.615845, acc.: 64.06%] [G loss: 0.968489]\n",
      "epoch:18 step:17135 [D loss: 0.676492, acc.: 59.38%] [G loss: 0.917872]\n",
      "epoch:18 step:17136 [D loss: 0.650699, acc.: 61.72%] [G loss: 0.952405]\n",
      "epoch:18 step:17137 [D loss: 0.643585, acc.: 59.38%] [G loss: 0.935192]\n",
      "epoch:18 step:17138 [D loss: 0.631490, acc.: 66.41%] [G loss: 0.892145]\n",
      "epoch:18 step:17139 [D loss: 0.713186, acc.: 56.25%] [G loss: 0.933323]\n",
      "epoch:18 step:17140 [D loss: 0.624259, acc.: 68.75%] [G loss: 0.936180]\n",
      "epoch:18 step:17141 [D loss: 0.698692, acc.: 58.59%] [G loss: 0.863510]\n",
      "epoch:18 step:17142 [D loss: 0.610943, acc.: 66.41%] [G loss: 0.937738]\n",
      "epoch:18 step:17143 [D loss: 0.734034, acc.: 42.97%] [G loss: 0.858780]\n",
      "epoch:18 step:17144 [D loss: 0.731939, acc.: 49.22%] [G loss: 0.797205]\n",
      "epoch:18 step:17145 [D loss: 0.672137, acc.: 64.06%] [G loss: 0.861387]\n",
      "epoch:18 step:17146 [D loss: 0.616493, acc.: 67.97%] [G loss: 0.856215]\n",
      "epoch:18 step:17147 [D loss: 0.669560, acc.: 58.59%] [G loss: 0.882133]\n",
      "epoch:18 step:17148 [D loss: 0.662655, acc.: 58.59%] [G loss: 0.827448]\n",
      "epoch:18 step:17149 [D loss: 0.596246, acc.: 72.66%] [G loss: 0.864400]\n",
      "epoch:18 step:17150 [D loss: 0.683396, acc.: 53.12%] [G loss: 0.872694]\n",
      "epoch:18 step:17151 [D loss: 0.658076, acc.: 57.03%] [G loss: 0.861233]\n",
      "epoch:18 step:17152 [D loss: 0.684089, acc.: 57.81%] [G loss: 0.955860]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17153 [D loss: 0.649782, acc.: 65.62%] [G loss: 0.909619]\n",
      "epoch:18 step:17154 [D loss: 0.612600, acc.: 70.31%] [G loss: 0.975639]\n",
      "epoch:18 step:17155 [D loss: 0.592166, acc.: 65.62%] [G loss: 1.014497]\n",
      "epoch:18 step:17156 [D loss: 0.641750, acc.: 68.75%] [G loss: 0.934917]\n",
      "epoch:18 step:17157 [D loss: 0.716558, acc.: 52.34%] [G loss: 0.843790]\n",
      "epoch:18 step:17158 [D loss: 0.653922, acc.: 63.28%] [G loss: 0.927654]\n",
      "epoch:18 step:17159 [D loss: 0.617454, acc.: 67.19%] [G loss: 0.908543]\n",
      "epoch:18 step:17160 [D loss: 0.660383, acc.: 60.16%] [G loss: 0.897151]\n",
      "epoch:18 step:17161 [D loss: 0.651330, acc.: 62.50%] [G loss: 0.880404]\n",
      "epoch:18 step:17162 [D loss: 0.616715, acc.: 67.97%] [G loss: 0.897220]\n",
      "epoch:18 step:17163 [D loss: 0.660404, acc.: 60.16%] [G loss: 0.952881]\n",
      "epoch:18 step:17164 [D loss: 0.623858, acc.: 64.06%] [G loss: 0.916064]\n",
      "epoch:18 step:17165 [D loss: 0.625866, acc.: 65.62%] [G loss: 0.893784]\n",
      "epoch:18 step:17166 [D loss: 0.651537, acc.: 64.06%] [G loss: 0.877761]\n",
      "epoch:18 step:17167 [D loss: 0.692635, acc.: 53.12%] [G loss: 0.926119]\n",
      "epoch:18 step:17168 [D loss: 0.673384, acc.: 57.03%] [G loss: 0.974680]\n",
      "epoch:18 step:17169 [D loss: 0.677071, acc.: 60.16%] [G loss: 0.870888]\n",
      "epoch:18 step:17170 [D loss: 0.645048, acc.: 62.50%] [G loss: 0.874723]\n",
      "epoch:18 step:17171 [D loss: 0.638791, acc.: 61.72%] [G loss: 0.884279]\n",
      "epoch:18 step:17172 [D loss: 0.614449, acc.: 66.41%] [G loss: 0.879236]\n",
      "epoch:18 step:17173 [D loss: 0.643070, acc.: 60.16%] [G loss: 0.906935]\n",
      "epoch:18 step:17174 [D loss: 0.728569, acc.: 53.12%] [G loss: 0.936711]\n",
      "epoch:18 step:17175 [D loss: 0.621771, acc.: 67.19%] [G loss: 0.871075]\n",
      "epoch:18 step:17176 [D loss: 0.632093, acc.: 64.84%] [G loss: 0.878340]\n",
      "epoch:18 step:17177 [D loss: 0.619005, acc.: 71.09%] [G loss: 0.932873]\n",
      "epoch:18 step:17178 [D loss: 0.649125, acc.: 64.84%] [G loss: 0.905568]\n",
      "epoch:18 step:17179 [D loss: 0.659811, acc.: 57.81%] [G loss: 0.941086]\n",
      "epoch:18 step:17180 [D loss: 0.607506, acc.: 63.28%] [G loss: 0.929704]\n",
      "epoch:18 step:17181 [D loss: 0.613919, acc.: 67.97%] [G loss: 1.040062]\n",
      "epoch:18 step:17182 [D loss: 0.779745, acc.: 46.09%] [G loss: 0.890333]\n",
      "epoch:18 step:17183 [D loss: 0.653897, acc.: 58.59%] [G loss: 0.936047]\n",
      "epoch:18 step:17184 [D loss: 0.632434, acc.: 63.28%] [G loss: 0.855928]\n",
      "epoch:18 step:17185 [D loss: 0.658341, acc.: 62.50%] [G loss: 0.871606]\n",
      "epoch:18 step:17186 [D loss: 0.685272, acc.: 57.03%] [G loss: 0.892742]\n",
      "epoch:18 step:17187 [D loss: 0.629411, acc.: 66.41%] [G loss: 0.939572]\n",
      "epoch:18 step:17188 [D loss: 0.658159, acc.: 59.38%] [G loss: 0.986153]\n",
      "epoch:18 step:17189 [D loss: 0.651289, acc.: 58.59%] [G loss: 0.891292]\n",
      "epoch:18 step:17190 [D loss: 0.650901, acc.: 60.16%] [G loss: 0.951607]\n",
      "epoch:18 step:17191 [D loss: 0.680579, acc.: 57.81%] [G loss: 0.862718]\n",
      "epoch:18 step:17192 [D loss: 0.634814, acc.: 66.41%] [G loss: 0.891430]\n",
      "epoch:18 step:17193 [D loss: 0.656628, acc.: 60.16%] [G loss: 0.963133]\n",
      "epoch:18 step:17194 [D loss: 0.605051, acc.: 67.19%] [G loss: 0.977155]\n",
      "epoch:18 step:17195 [D loss: 0.690820, acc.: 50.00%] [G loss: 0.926638]\n",
      "epoch:18 step:17196 [D loss: 0.686669, acc.: 53.12%] [G loss: 0.870827]\n",
      "epoch:18 step:17197 [D loss: 0.635269, acc.: 63.28%] [G loss: 0.907359]\n",
      "epoch:18 step:17198 [D loss: 0.628081, acc.: 62.50%] [G loss: 0.921175]\n",
      "epoch:18 step:17199 [D loss: 0.653524, acc.: 63.28%] [G loss: 0.925882]\n",
      "epoch:18 step:17200 [D loss: 0.603856, acc.: 70.31%] [G loss: 0.917083]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.320139\n",
      "FID: 5.133807\n",
      "0 = 11.68505147118569\n",
      "1 = 0.04712103805279391\n",
      "2 = 0.8986499905586243\n",
      "3 = 0.8562999963760376\n",
      "4 = 0.9409999847412109\n",
      "5 = 0.9355402588844299\n",
      "6 = 0.8562999963760376\n",
      "7 = 5.465673538213973\n",
      "8 = 0.050212313967781086\n",
      "9 = 0.690850019454956\n",
      "10 = 0.6780999898910522\n",
      "11 = 0.7035999894142151\n",
      "12 = 0.6958439946174622\n",
      "13 = 0.6780999898910522\n",
      "14 = 8.320211410522461\n",
      "15 = 9.630751609802246\n",
      "16 = 0.06896989792585373\n",
      "17 = 8.320138931274414\n",
      "18 = 5.133807182312012\n",
      "epoch:18 step:17201 [D loss: 0.622212, acc.: 64.06%] [G loss: 1.021294]\n",
      "epoch:18 step:17202 [D loss: 0.665485, acc.: 61.72%] [G loss: 0.945839]\n",
      "epoch:18 step:17203 [D loss: 0.643988, acc.: 64.84%] [G loss: 0.942884]\n",
      "epoch:18 step:17204 [D loss: 0.635795, acc.: 66.41%] [G loss: 0.887924]\n",
      "epoch:18 step:17205 [D loss: 0.628889, acc.: 66.41%] [G loss: 0.950049]\n",
      "epoch:18 step:17206 [D loss: 0.631870, acc.: 60.94%] [G loss: 0.894906]\n",
      "epoch:18 step:17207 [D loss: 0.715438, acc.: 46.88%] [G loss: 0.967244]\n",
      "epoch:18 step:17208 [D loss: 0.668192, acc.: 54.69%] [G loss: 0.944369]\n",
      "epoch:18 step:17209 [D loss: 0.657857, acc.: 60.16%] [G loss: 1.053271]\n",
      "epoch:18 step:17210 [D loss: 0.620980, acc.: 70.31%] [G loss: 0.986195]\n",
      "epoch:18 step:17211 [D loss: 0.626089, acc.: 62.50%] [G loss: 0.914744]\n",
      "epoch:18 step:17212 [D loss: 0.596099, acc.: 68.75%] [G loss: 0.966601]\n",
      "epoch:18 step:17213 [D loss: 0.579323, acc.: 67.97%] [G loss: 1.003405]\n",
      "epoch:18 step:17214 [D loss: 0.774471, acc.: 53.12%] [G loss: 0.925498]\n",
      "epoch:18 step:17215 [D loss: 0.774153, acc.: 46.09%] [G loss: 0.907202]\n",
      "epoch:18 step:17216 [D loss: 0.673033, acc.: 57.03%] [G loss: 0.876675]\n",
      "epoch:18 step:17217 [D loss: 0.699862, acc.: 53.91%] [G loss: 0.909866]\n",
      "epoch:18 step:17218 [D loss: 0.697152, acc.: 54.69%] [G loss: 0.991606]\n",
      "epoch:18 step:17219 [D loss: 0.618552, acc.: 64.84%] [G loss: 1.016873]\n",
      "epoch:18 step:17220 [D loss: 0.553719, acc.: 73.44%] [G loss: 0.950799]\n",
      "epoch:18 step:17221 [D loss: 0.666337, acc.: 61.72%] [G loss: 0.970313]\n",
      "epoch:18 step:17222 [D loss: 0.677276, acc.: 60.16%] [G loss: 0.882247]\n",
      "epoch:18 step:17223 [D loss: 0.667455, acc.: 62.50%] [G loss: 0.900872]\n",
      "epoch:18 step:17224 [D loss: 0.595411, acc.: 69.53%] [G loss: 0.910019]\n",
      "epoch:18 step:17225 [D loss: 0.668483, acc.: 57.03%] [G loss: 0.926866]\n",
      "epoch:18 step:17226 [D loss: 0.596288, acc.: 66.41%] [G loss: 0.990500]\n",
      "epoch:18 step:17227 [D loss: 0.616575, acc.: 66.41%] [G loss: 1.025903]\n",
      "epoch:18 step:17228 [D loss: 0.644286, acc.: 60.16%] [G loss: 0.974222]\n",
      "epoch:18 step:17229 [D loss: 0.665665, acc.: 57.03%] [G loss: 0.978712]\n",
      "epoch:18 step:17230 [D loss: 0.566365, acc.: 71.09%] [G loss: 0.892121]\n",
      "epoch:18 step:17231 [D loss: 0.602867, acc.: 65.62%] [G loss: 0.906440]\n",
      "epoch:18 step:17232 [D loss: 0.648502, acc.: 61.72%] [G loss: 0.938588]\n",
      "epoch:18 step:17233 [D loss: 0.599253, acc.: 68.75%] [G loss: 0.978226]\n",
      "epoch:18 step:17234 [D loss: 0.654807, acc.: 58.59%] [G loss: 0.988569]\n",
      "epoch:18 step:17235 [D loss: 0.694483, acc.: 54.69%] [G loss: 0.945672]\n",
      "epoch:18 step:17236 [D loss: 0.634953, acc.: 64.84%] [G loss: 0.899835]\n",
      "epoch:18 step:17237 [D loss: 0.606335, acc.: 71.88%] [G loss: 0.908979]\n",
      "epoch:18 step:17238 [D loss: 0.623506, acc.: 65.62%] [G loss: 0.970975]\n",
      "epoch:18 step:17239 [D loss: 0.671357, acc.: 61.72%] [G loss: 0.922073]\n",
      "epoch:18 step:17240 [D loss: 0.611605, acc.: 71.09%] [G loss: 0.952289]\n",
      "epoch:18 step:17241 [D loss: 0.651583, acc.: 60.16%] [G loss: 0.962052]\n",
      "epoch:18 step:17242 [D loss: 0.687057, acc.: 54.69%] [G loss: 0.949920]\n",
      "epoch:18 step:17243 [D loss: 0.787175, acc.: 44.53%] [G loss: 0.947510]\n",
      "epoch:18 step:17244 [D loss: 0.655330, acc.: 57.81%] [G loss: 0.933795]\n",
      "epoch:18 step:17245 [D loss: 0.718892, acc.: 51.56%] [G loss: 0.946089]\n",
      "epoch:18 step:17246 [D loss: 0.673987, acc.: 57.81%] [G loss: 0.904141]\n",
      "epoch:18 step:17247 [D loss: 0.652091, acc.: 60.16%] [G loss: 0.905325]\n",
      "epoch:18 step:17248 [D loss: 0.668933, acc.: 62.50%] [G loss: 0.838835]\n",
      "epoch:18 step:17249 [D loss: 0.672016, acc.: 52.34%] [G loss: 0.894869]\n",
      "epoch:18 step:17250 [D loss: 0.636347, acc.: 66.41%] [G loss: 0.812971]\n",
      "epoch:18 step:17251 [D loss: 0.634968, acc.: 67.19%] [G loss: 0.859135]\n",
      "epoch:18 step:17252 [D loss: 0.685208, acc.: 55.47%] [G loss: 0.889633]\n",
      "epoch:18 step:17253 [D loss: 0.643294, acc.: 60.94%] [G loss: 0.857674]\n",
      "epoch:18 step:17254 [D loss: 0.626982, acc.: 69.53%] [G loss: 0.893071]\n",
      "epoch:18 step:17255 [D loss: 0.680474, acc.: 60.16%] [G loss: 0.872339]\n",
      "epoch:18 step:17256 [D loss: 0.654712, acc.: 62.50%] [G loss: 0.860133]\n",
      "epoch:18 step:17257 [D loss: 0.666099, acc.: 59.38%] [G loss: 0.875273]\n",
      "epoch:18 step:17258 [D loss: 0.631735, acc.: 61.72%] [G loss: 0.897266]\n",
      "epoch:18 step:17259 [D loss: 0.631497, acc.: 65.62%] [G loss: 0.909912]\n",
      "epoch:18 step:17260 [D loss: 0.677215, acc.: 60.94%] [G loss: 0.871199]\n",
      "epoch:18 step:17261 [D loss: 0.691238, acc.: 52.34%] [G loss: 0.920068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17262 [D loss: 0.731471, acc.: 53.91%] [G loss: 0.918801]\n",
      "epoch:18 step:17263 [D loss: 0.645673, acc.: 63.28%] [G loss: 0.966401]\n",
      "epoch:18 step:17264 [D loss: 0.624822, acc.: 67.19%] [G loss: 1.015370]\n",
      "epoch:18 step:17265 [D loss: 0.591609, acc.: 68.75%] [G loss: 0.972134]\n",
      "epoch:18 step:17266 [D loss: 0.715042, acc.: 50.78%] [G loss: 0.868393]\n",
      "epoch:18 step:17267 [D loss: 0.659103, acc.: 53.91%] [G loss: 0.886535]\n",
      "epoch:18 step:17268 [D loss: 0.596613, acc.: 71.09%] [G loss: 0.972728]\n",
      "epoch:18 step:17269 [D loss: 0.682770, acc.: 57.81%] [G loss: 0.873206]\n",
      "epoch:18 step:17270 [D loss: 0.679176, acc.: 57.81%] [G loss: 0.943744]\n",
      "epoch:18 step:17271 [D loss: 0.609146, acc.: 73.44%] [G loss: 0.933270]\n",
      "epoch:18 step:17272 [D loss: 0.629273, acc.: 59.38%] [G loss: 0.993708]\n",
      "epoch:18 step:17273 [D loss: 0.675741, acc.: 60.94%] [G loss: 1.025723]\n",
      "epoch:18 step:17274 [D loss: 0.657783, acc.: 60.94%] [G loss: 0.974450]\n",
      "epoch:18 step:17275 [D loss: 0.651876, acc.: 58.59%] [G loss: 0.953265]\n",
      "epoch:18 step:17276 [D loss: 0.707019, acc.: 58.59%] [G loss: 0.914253]\n",
      "epoch:18 step:17277 [D loss: 0.690593, acc.: 56.25%] [G loss: 0.930772]\n",
      "epoch:18 step:17278 [D loss: 0.651686, acc.: 60.94%] [G loss: 0.893391]\n",
      "epoch:18 step:17279 [D loss: 0.689182, acc.: 59.38%] [G loss: 0.855868]\n",
      "epoch:18 step:17280 [D loss: 0.625045, acc.: 65.62%] [G loss: 0.945006]\n",
      "epoch:18 step:17281 [D loss: 0.625184, acc.: 64.84%] [G loss: 0.964924]\n",
      "epoch:18 step:17282 [D loss: 0.638129, acc.: 69.53%] [G loss: 1.057465]\n",
      "epoch:18 step:17283 [D loss: 0.669283, acc.: 60.16%] [G loss: 1.022727]\n",
      "epoch:18 step:17284 [D loss: 0.711282, acc.: 50.78%] [G loss: 0.907585]\n",
      "epoch:18 step:17285 [D loss: 0.655790, acc.: 65.62%] [G loss: 0.868119]\n",
      "epoch:18 step:17286 [D loss: 0.688994, acc.: 57.03%] [G loss: 0.868165]\n",
      "epoch:18 step:17287 [D loss: 0.694581, acc.: 57.03%] [G loss: 0.865726]\n",
      "epoch:18 step:17288 [D loss: 0.708400, acc.: 50.00%] [G loss: 0.861474]\n",
      "epoch:18 step:17289 [D loss: 0.681999, acc.: 56.25%] [G loss: 0.898042]\n",
      "epoch:18 step:17290 [D loss: 0.712687, acc.: 52.34%] [G loss: 0.927557]\n",
      "epoch:18 step:17291 [D loss: 0.712154, acc.: 55.47%] [G loss: 0.957705]\n",
      "epoch:18 step:17292 [D loss: 0.641852, acc.: 65.62%] [G loss: 0.941586]\n",
      "epoch:18 step:17293 [D loss: 0.648839, acc.: 63.28%] [G loss: 1.013367]\n",
      "epoch:18 step:17294 [D loss: 0.593471, acc.: 65.62%] [G loss: 0.935153]\n",
      "epoch:18 step:17295 [D loss: 0.626774, acc.: 62.50%] [G loss: 0.995248]\n",
      "epoch:18 step:17296 [D loss: 0.642882, acc.: 62.50%] [G loss: 0.871812]\n",
      "epoch:18 step:17297 [D loss: 0.680465, acc.: 60.94%] [G loss: 0.847685]\n",
      "epoch:18 step:17298 [D loss: 0.635860, acc.: 64.84%] [G loss: 0.871127]\n",
      "epoch:18 step:17299 [D loss: 0.694025, acc.: 54.69%] [G loss: 0.902364]\n",
      "epoch:18 step:17300 [D loss: 0.607625, acc.: 61.72%] [G loss: 0.849848]\n",
      "epoch:18 step:17301 [D loss: 0.644078, acc.: 64.84%] [G loss: 0.959449]\n",
      "epoch:18 step:17302 [D loss: 0.625043, acc.: 66.41%] [G loss: 0.969602]\n",
      "epoch:18 step:17303 [D loss: 0.776951, acc.: 44.53%] [G loss: 0.929485]\n",
      "epoch:18 step:17304 [D loss: 0.657490, acc.: 60.16%] [G loss: 0.914486]\n",
      "epoch:18 step:17305 [D loss: 0.701272, acc.: 56.25%] [G loss: 0.959275]\n",
      "epoch:18 step:17306 [D loss: 0.608167, acc.: 66.41%] [G loss: 0.977913]\n",
      "epoch:18 step:17307 [D loss: 0.659471, acc.: 63.28%] [G loss: 0.896076]\n",
      "epoch:18 step:17308 [D loss: 0.647428, acc.: 59.38%] [G loss: 0.907138]\n",
      "epoch:18 step:17309 [D loss: 0.616190, acc.: 68.75%] [G loss: 0.837559]\n",
      "epoch:18 step:17310 [D loss: 0.647517, acc.: 59.38%] [G loss: 0.928440]\n",
      "epoch:18 step:17311 [D loss: 0.665934, acc.: 60.16%] [G loss: 0.942822]\n",
      "epoch:18 step:17312 [D loss: 0.642590, acc.: 61.72%] [G loss: 1.038633]\n",
      "epoch:18 step:17313 [D loss: 0.601255, acc.: 65.62%] [G loss: 0.924320]\n",
      "epoch:18 step:17314 [D loss: 0.710520, acc.: 57.81%] [G loss: 0.940979]\n",
      "epoch:18 step:17315 [D loss: 0.687894, acc.: 57.03%] [G loss: 0.879938]\n",
      "epoch:18 step:17316 [D loss: 0.621081, acc.: 64.06%] [G loss: 0.880925]\n",
      "epoch:18 step:17317 [D loss: 0.613268, acc.: 64.06%] [G loss: 0.865144]\n",
      "epoch:18 step:17318 [D loss: 0.643414, acc.: 63.28%] [G loss: 0.921003]\n",
      "epoch:18 step:17319 [D loss: 0.656075, acc.: 66.41%] [G loss: 0.898355]\n",
      "epoch:18 step:17320 [D loss: 0.619917, acc.: 64.84%] [G loss: 0.877215]\n",
      "epoch:18 step:17321 [D loss: 0.738014, acc.: 52.34%] [G loss: 0.869682]\n",
      "epoch:18 step:17322 [D loss: 0.657019, acc.: 63.28%] [G loss: 0.863289]\n",
      "epoch:18 step:17323 [D loss: 0.655353, acc.: 62.50%] [G loss: 0.907628]\n",
      "epoch:18 step:17324 [D loss: 0.682799, acc.: 57.03%] [G loss: 0.871844]\n",
      "epoch:18 step:17325 [D loss: 0.637079, acc.: 67.97%] [G loss: 0.915984]\n",
      "epoch:18 step:17326 [D loss: 0.691937, acc.: 57.03%] [G loss: 0.961595]\n",
      "epoch:18 step:17327 [D loss: 0.674219, acc.: 58.59%] [G loss: 0.839405]\n",
      "epoch:18 step:17328 [D loss: 0.706821, acc.: 53.91%] [G loss: 0.910972]\n",
      "epoch:18 step:17329 [D loss: 0.704606, acc.: 53.91%] [G loss: 0.922847]\n",
      "epoch:18 step:17330 [D loss: 0.672075, acc.: 54.69%] [G loss: 0.843906]\n",
      "epoch:18 step:17331 [D loss: 0.659886, acc.: 59.38%] [G loss: 0.891725]\n",
      "epoch:18 step:17332 [D loss: 0.655720, acc.: 61.72%] [G loss: 0.878716]\n",
      "epoch:18 step:17333 [D loss: 0.644536, acc.: 61.72%] [G loss: 0.933043]\n",
      "epoch:18 step:17334 [D loss: 0.647399, acc.: 64.84%] [G loss: 0.957463]\n",
      "epoch:18 step:17335 [D loss: 0.604601, acc.: 70.31%] [G loss: 1.011547]\n",
      "epoch:18 step:17336 [D loss: 0.615507, acc.: 67.19%] [G loss: 0.950764]\n",
      "epoch:18 step:17337 [D loss: 0.588612, acc.: 72.66%] [G loss: 0.953676]\n",
      "epoch:18 step:17338 [D loss: 0.673426, acc.: 61.72%] [G loss: 0.982136]\n",
      "epoch:18 step:17339 [D loss: 0.718189, acc.: 53.91%] [G loss: 0.915931]\n",
      "epoch:18 step:17340 [D loss: 0.694424, acc.: 55.47%] [G loss: 0.982406]\n",
      "epoch:18 step:17341 [D loss: 0.669700, acc.: 57.81%] [G loss: 0.957322]\n",
      "epoch:18 step:17342 [D loss: 0.696816, acc.: 59.38%] [G loss: 0.921887]\n",
      "epoch:18 step:17343 [D loss: 0.725291, acc.: 52.34%] [G loss: 0.963494]\n",
      "epoch:18 step:17344 [D loss: 0.667250, acc.: 57.03%] [G loss: 0.876051]\n",
      "epoch:18 step:17345 [D loss: 0.599010, acc.: 75.78%] [G loss: 0.855454]\n",
      "epoch:18 step:17346 [D loss: 0.607929, acc.: 71.88%] [G loss: 0.846786]\n",
      "epoch:18 step:17347 [D loss: 0.615176, acc.: 71.88%] [G loss: 0.893800]\n",
      "epoch:18 step:17348 [D loss: 0.749809, acc.: 46.09%] [G loss: 0.887556]\n",
      "epoch:18 step:17349 [D loss: 0.665283, acc.: 57.03%] [G loss: 0.923219]\n",
      "epoch:18 step:17350 [D loss: 0.658875, acc.: 64.84%] [G loss: 0.993082]\n",
      "epoch:18 step:17351 [D loss: 0.651704, acc.: 61.72%] [G loss: 0.934937]\n",
      "epoch:18 step:17352 [D loss: 0.670940, acc.: 60.16%] [G loss: 0.888632]\n",
      "epoch:18 step:17353 [D loss: 0.652517, acc.: 57.03%] [G loss: 0.992021]\n",
      "epoch:18 step:17354 [D loss: 0.628572, acc.: 61.72%] [G loss: 0.945284]\n",
      "epoch:18 step:17355 [D loss: 0.649870, acc.: 62.50%] [G loss: 0.868604]\n",
      "epoch:18 step:17356 [D loss: 0.677574, acc.: 58.59%] [G loss: 0.921564]\n",
      "epoch:18 step:17357 [D loss: 0.632187, acc.: 61.72%] [G loss: 0.944292]\n",
      "epoch:18 step:17358 [D loss: 0.668440, acc.: 58.59%] [G loss: 0.888988]\n",
      "epoch:18 step:17359 [D loss: 0.667642, acc.: 63.28%] [G loss: 0.872393]\n",
      "epoch:18 step:17360 [D loss: 0.692787, acc.: 58.59%] [G loss: 0.891660]\n",
      "epoch:18 step:17361 [D loss: 0.618620, acc.: 64.06%] [G loss: 0.883592]\n",
      "epoch:18 step:17362 [D loss: 0.635004, acc.: 66.41%] [G loss: 0.929251]\n",
      "epoch:18 step:17363 [D loss: 0.672605, acc.: 64.06%] [G loss: 0.860800]\n",
      "epoch:18 step:17364 [D loss: 0.639826, acc.: 64.06%] [G loss: 0.955927]\n",
      "epoch:18 step:17365 [D loss: 0.610178, acc.: 66.41%] [G loss: 1.004828]\n",
      "epoch:18 step:17366 [D loss: 0.712810, acc.: 57.03%] [G loss: 0.935810]\n",
      "epoch:18 step:17367 [D loss: 0.693405, acc.: 60.94%] [G loss: 0.943354]\n",
      "epoch:18 step:17368 [D loss: 0.702486, acc.: 51.56%] [G loss: 0.931314]\n",
      "epoch:18 step:17369 [D loss: 0.661366, acc.: 63.28%] [G loss: 0.899477]\n",
      "epoch:18 step:17370 [D loss: 0.617832, acc.: 67.19%] [G loss: 0.966437]\n",
      "epoch:18 step:17371 [D loss: 0.631030, acc.: 62.50%] [G loss: 1.018029]\n",
      "epoch:18 step:17372 [D loss: 0.633918, acc.: 62.50%] [G loss: 1.005205]\n",
      "epoch:18 step:17373 [D loss: 0.595565, acc.: 61.72%] [G loss: 1.031136]\n",
      "epoch:18 step:17374 [D loss: 0.523923, acc.: 75.78%] [G loss: 1.052574]\n",
      "epoch:18 step:17375 [D loss: 0.730886, acc.: 57.03%] [G loss: 0.881936]\n",
      "epoch:18 step:17376 [D loss: 0.717590, acc.: 52.34%] [G loss: 0.894000]\n",
      "epoch:18 step:17377 [D loss: 0.728524, acc.: 45.31%] [G loss: 0.892562]\n",
      "epoch:18 step:17378 [D loss: 0.679363, acc.: 61.72%] [G loss: 0.915947]\n",
      "epoch:18 step:17379 [D loss: 0.635569, acc.: 60.94%] [G loss: 0.910291]\n",
      "epoch:18 step:17380 [D loss: 0.659996, acc.: 60.94%] [G loss: 0.928059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17381 [D loss: 0.608179, acc.: 67.97%] [G loss: 0.941294]\n",
      "epoch:18 step:17382 [D loss: 0.618205, acc.: 70.31%] [G loss: 0.907405]\n",
      "epoch:18 step:17383 [D loss: 0.704203, acc.: 54.69%] [G loss: 0.861986]\n",
      "epoch:18 step:17384 [D loss: 0.644898, acc.: 70.31%] [G loss: 0.957221]\n",
      "epoch:18 step:17385 [D loss: 0.670629, acc.: 57.03%] [G loss: 0.902337]\n",
      "epoch:18 step:17386 [D loss: 0.650219, acc.: 62.50%] [G loss: 0.950925]\n",
      "epoch:18 step:17387 [D loss: 0.630972, acc.: 65.62%] [G loss: 0.958111]\n",
      "epoch:18 step:17388 [D loss: 0.657750, acc.: 60.94%] [G loss: 0.877835]\n",
      "epoch:18 step:17389 [D loss: 0.617806, acc.: 64.06%] [G loss: 0.949934]\n",
      "epoch:18 step:17390 [D loss: 0.661348, acc.: 60.16%] [G loss: 0.950044]\n",
      "epoch:18 step:17391 [D loss: 0.665421, acc.: 60.16%] [G loss: 0.923586]\n",
      "epoch:18 step:17392 [D loss: 0.671873, acc.: 60.16%] [G loss: 0.955571]\n",
      "epoch:18 step:17393 [D loss: 0.684669, acc.: 61.72%] [G loss: 0.947742]\n",
      "epoch:18 step:17394 [D loss: 0.708215, acc.: 54.69%] [G loss: 0.902073]\n",
      "epoch:18 step:17395 [D loss: 0.726225, acc.: 50.00%] [G loss: 0.872822]\n",
      "epoch:18 step:17396 [D loss: 0.674861, acc.: 59.38%] [G loss: 0.956523]\n",
      "epoch:18 step:17397 [D loss: 0.677361, acc.: 58.59%] [G loss: 0.833014]\n",
      "epoch:18 step:17398 [D loss: 0.700663, acc.: 60.94%] [G loss: 0.789109]\n",
      "epoch:18 step:17399 [D loss: 0.696762, acc.: 50.78%] [G loss: 0.903390]\n",
      "epoch:18 step:17400 [D loss: 0.619303, acc.: 63.28%] [G loss: 0.888226]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.263990\n",
      "FID: 6.130342\n",
      "0 = 11.673198644900292\n",
      "1 = 0.04585556300369924\n",
      "2 = 0.9051499962806702\n",
      "3 = 0.8651000261306763\n",
      "4 = 0.9452000260353088\n",
      "5 = 0.9404283165931702\n",
      "6 = 0.8651000261306763\n",
      "7 = 5.540601798343651\n",
      "8 = 0.05475829854981618\n",
      "9 = 0.6830999851226807\n",
      "10 = 0.661899983882904\n",
      "11 = 0.7042999863624573\n",
      "12 = 0.6912071704864502\n",
      "13 = 0.661899983882904\n",
      "14 = 8.264062881469727\n",
      "15 = 9.620213508605957\n",
      "16 = 0.07659042626619339\n",
      "17 = 8.26399040222168\n",
      "18 = 6.130341529846191\n",
      "epoch:18 step:17401 [D loss: 0.683946, acc.: 61.72%] [G loss: 0.864552]\n",
      "epoch:18 step:17402 [D loss: 0.627443, acc.: 68.75%] [G loss: 0.911768]\n",
      "epoch:18 step:17403 [D loss: 0.658737, acc.: 61.72%] [G loss: 1.017557]\n",
      "epoch:18 step:17404 [D loss: 0.660035, acc.: 60.94%] [G loss: 0.881572]\n",
      "epoch:18 step:17405 [D loss: 0.676902, acc.: 60.94%] [G loss: 0.921035]\n",
      "epoch:18 step:17406 [D loss: 0.636428, acc.: 59.38%] [G loss: 0.926684]\n",
      "epoch:18 step:17407 [D loss: 0.681069, acc.: 58.59%] [G loss: 0.876468]\n",
      "epoch:18 step:17408 [D loss: 0.743638, acc.: 46.09%] [G loss: 0.888564]\n",
      "epoch:18 step:17409 [D loss: 0.639209, acc.: 66.41%] [G loss: 0.956244]\n",
      "epoch:18 step:17410 [D loss: 0.638430, acc.: 58.59%] [G loss: 0.926870]\n",
      "epoch:18 step:17411 [D loss: 0.635979, acc.: 59.38%] [G loss: 0.954074]\n",
      "epoch:18 step:17412 [D loss: 0.616247, acc.: 65.62%] [G loss: 0.923862]\n",
      "epoch:18 step:17413 [D loss: 0.672551, acc.: 57.03%] [G loss: 0.933656]\n",
      "epoch:18 step:17414 [D loss: 0.622539, acc.: 64.06%] [G loss: 0.915976]\n",
      "epoch:18 step:17415 [D loss: 0.635302, acc.: 64.84%] [G loss: 0.913381]\n",
      "epoch:18 step:17416 [D loss: 0.647880, acc.: 63.28%] [G loss: 0.915597]\n",
      "epoch:18 step:17417 [D loss: 0.577334, acc.: 69.53%] [G loss: 0.925763]\n",
      "epoch:18 step:17418 [D loss: 0.604758, acc.: 64.84%] [G loss: 0.927900]\n",
      "epoch:18 step:17419 [D loss: 0.678277, acc.: 61.72%] [G loss: 0.905437]\n",
      "epoch:18 step:17420 [D loss: 0.639449, acc.: 65.62%] [G loss: 0.936172]\n",
      "epoch:18 step:17421 [D loss: 0.643723, acc.: 63.28%] [G loss: 0.908852]\n",
      "epoch:18 step:17422 [D loss: 0.644113, acc.: 63.28%] [G loss: 0.965564]\n",
      "epoch:18 step:17423 [D loss: 0.562718, acc.: 70.31%] [G loss: 0.923226]\n",
      "epoch:18 step:17424 [D loss: 0.604225, acc.: 67.97%] [G loss: 0.979762]\n",
      "epoch:18 step:17425 [D loss: 0.722283, acc.: 51.56%] [G loss: 0.930327]\n",
      "epoch:18 step:17426 [D loss: 0.739867, acc.: 52.34%] [G loss: 0.894201]\n",
      "epoch:18 step:17427 [D loss: 0.688288, acc.: 57.03%] [G loss: 0.945381]\n",
      "epoch:18 step:17428 [D loss: 0.699004, acc.: 53.91%] [G loss: 0.912819]\n",
      "epoch:18 step:17429 [D loss: 0.604646, acc.: 72.66%] [G loss: 0.932711]\n",
      "epoch:18 step:17430 [D loss: 0.589212, acc.: 69.53%] [G loss: 0.994572]\n",
      "epoch:18 step:17431 [D loss: 0.667487, acc.: 60.16%] [G loss: 1.016467]\n",
      "epoch:18 step:17432 [D loss: 0.770132, acc.: 48.44%] [G loss: 0.965686]\n",
      "epoch:18 step:17433 [D loss: 0.628710, acc.: 64.84%] [G loss: 0.984242]\n",
      "epoch:18 step:17434 [D loss: 0.658458, acc.: 60.94%] [G loss: 0.990620]\n",
      "epoch:18 step:17435 [D loss: 0.721491, acc.: 57.81%] [G loss: 0.891178]\n",
      "epoch:18 step:17436 [D loss: 0.645803, acc.: 64.84%] [G loss: 0.869578]\n",
      "epoch:18 step:17437 [D loss: 0.634807, acc.: 63.28%] [G loss: 0.893684]\n",
      "epoch:18 step:17438 [D loss: 0.682939, acc.: 60.94%] [G loss: 0.879162]\n",
      "epoch:18 step:17439 [D loss: 0.685532, acc.: 56.25%] [G loss: 0.900606]\n",
      "epoch:18 step:17440 [D loss: 0.619856, acc.: 67.19%] [G loss: 0.967088]\n",
      "epoch:18 step:17441 [D loss: 0.577808, acc.: 71.88%] [G loss: 0.999395]\n",
      "epoch:18 step:17442 [D loss: 0.708644, acc.: 52.34%] [G loss: 0.947374]\n",
      "epoch:18 step:17443 [D loss: 0.667312, acc.: 60.94%] [G loss: 0.909371]\n",
      "epoch:18 step:17444 [D loss: 0.658645, acc.: 59.38%] [G loss: 0.870873]\n",
      "epoch:18 step:17445 [D loss: 0.650303, acc.: 66.41%] [G loss: 0.921788]\n",
      "epoch:18 step:17446 [D loss: 0.605329, acc.: 66.41%] [G loss: 0.880285]\n",
      "epoch:18 step:17447 [D loss: 0.576049, acc.: 71.88%] [G loss: 0.972761]\n",
      "epoch:18 step:17448 [D loss: 0.593260, acc.: 70.31%] [G loss: 0.908425]\n",
      "epoch:18 step:17449 [D loss: 0.658217, acc.: 59.38%] [G loss: 0.943231]\n",
      "epoch:18 step:17450 [D loss: 0.696470, acc.: 53.12%] [G loss: 0.955218]\n",
      "epoch:18 step:17451 [D loss: 0.644314, acc.: 55.47%] [G loss: 0.892046]\n",
      "epoch:18 step:17452 [D loss: 0.636208, acc.: 63.28%] [G loss: 0.927246]\n",
      "epoch:18 step:17453 [D loss: 0.715043, acc.: 49.22%] [G loss: 0.898879]\n",
      "epoch:18 step:17454 [D loss: 0.655839, acc.: 57.81%] [G loss: 0.883571]\n",
      "epoch:18 step:17455 [D loss: 0.646054, acc.: 60.94%] [G loss: 0.937349]\n",
      "epoch:18 step:17456 [D loss: 0.679510, acc.: 56.25%] [G loss: 0.888528]\n",
      "epoch:18 step:17457 [D loss: 0.672158, acc.: 63.28%] [G loss: 0.918652]\n",
      "epoch:18 step:17458 [D loss: 0.599608, acc.: 71.09%] [G loss: 0.861167]\n",
      "epoch:18 step:17459 [D loss: 0.606769, acc.: 69.53%] [G loss: 0.929387]\n",
      "epoch:18 step:17460 [D loss: 0.682322, acc.: 54.69%] [G loss: 0.906195]\n",
      "epoch:18 step:17461 [D loss: 0.621582, acc.: 69.53%] [G loss: 0.892614]\n",
      "epoch:18 step:17462 [D loss: 0.678656, acc.: 57.81%] [G loss: 0.908480]\n",
      "epoch:18 step:17463 [D loss: 0.710704, acc.: 51.56%] [G loss: 0.898430]\n",
      "epoch:18 step:17464 [D loss: 0.662016, acc.: 57.03%] [G loss: 0.928967]\n",
      "epoch:18 step:17465 [D loss: 0.692693, acc.: 53.91%] [G loss: 0.933499]\n",
      "epoch:18 step:17466 [D loss: 0.721373, acc.: 57.03%] [G loss: 0.888357]\n",
      "epoch:18 step:17467 [D loss: 0.633003, acc.: 68.75%] [G loss: 0.901563]\n",
      "epoch:18 step:17468 [D loss: 0.651607, acc.: 62.50%] [G loss: 0.855097]\n",
      "epoch:18 step:17469 [D loss: 0.671158, acc.: 58.59%] [G loss: 0.927354]\n",
      "epoch:18 step:17470 [D loss: 0.680487, acc.: 55.47%] [G loss: 0.885423]\n",
      "epoch:18 step:17471 [D loss: 0.651999, acc.: 64.06%] [G loss: 0.846415]\n",
      "epoch:18 step:17472 [D loss: 0.640772, acc.: 60.94%] [G loss: 0.875241]\n",
      "epoch:18 step:17473 [D loss: 0.629717, acc.: 60.94%] [G loss: 0.922969]\n",
      "epoch:18 step:17474 [D loss: 0.623942, acc.: 64.06%] [G loss: 0.905789]\n",
      "epoch:18 step:17475 [D loss: 0.658088, acc.: 64.06%] [G loss: 0.926013]\n",
      "epoch:18 step:17476 [D loss: 0.648434, acc.: 63.28%] [G loss: 0.848295]\n",
      "epoch:18 step:17477 [D loss: 0.684317, acc.: 55.47%] [G loss: 0.858961]\n",
      "epoch:18 step:17478 [D loss: 0.664700, acc.: 57.03%] [G loss: 0.941555]\n",
      "epoch:18 step:17479 [D loss: 0.652824, acc.: 61.72%] [G loss: 0.943195]\n",
      "epoch:18 step:17480 [D loss: 0.709858, acc.: 50.00%] [G loss: 0.885141]\n",
      "epoch:18 step:17481 [D loss: 0.706252, acc.: 50.00%] [G loss: 0.859352]\n",
      "epoch:18 step:17482 [D loss: 0.646698, acc.: 64.84%] [G loss: 0.899433]\n",
      "epoch:18 step:17483 [D loss: 0.683109, acc.: 57.03%] [G loss: 0.939337]\n",
      "epoch:18 step:17484 [D loss: 0.628968, acc.: 65.62%] [G loss: 0.984868]\n",
      "epoch:18 step:17485 [D loss: 0.632246, acc.: 63.28%] [G loss: 0.923608]\n",
      "epoch:18 step:17486 [D loss: 0.617804, acc.: 64.06%] [G loss: 0.929940]\n",
      "epoch:18 step:17487 [D loss: 0.704168, acc.: 52.34%] [G loss: 0.804216]\n",
      "epoch:18 step:17488 [D loss: 0.701589, acc.: 50.78%] [G loss: 0.836134]\n",
      "epoch:18 step:17489 [D loss: 0.696145, acc.: 49.22%] [G loss: 0.826796]\n",
      "epoch:18 step:17490 [D loss: 0.610689, acc.: 67.19%] [G loss: 0.897651]\n",
      "epoch:18 step:17491 [D loss: 0.681856, acc.: 57.03%] [G loss: 0.903200]\n",
      "epoch:18 step:17492 [D loss: 0.651859, acc.: 62.50%] [G loss: 0.853948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17493 [D loss: 0.628285, acc.: 63.28%] [G loss: 0.949120]\n",
      "epoch:18 step:17494 [D loss: 0.668103, acc.: 62.50%] [G loss: 0.898727]\n",
      "epoch:18 step:17495 [D loss: 0.694649, acc.: 54.69%] [G loss: 0.886146]\n",
      "epoch:18 step:17496 [D loss: 0.719215, acc.: 51.56%] [G loss: 0.877930]\n",
      "epoch:18 step:17497 [D loss: 0.625153, acc.: 67.97%] [G loss: 0.901817]\n",
      "epoch:18 step:17498 [D loss: 0.616110, acc.: 67.19%] [G loss: 0.929693]\n",
      "epoch:18 step:17499 [D loss: 0.613843, acc.: 71.09%] [G loss: 0.895039]\n",
      "epoch:18 step:17500 [D loss: 0.606989, acc.: 68.75%] [G loss: 0.972561]\n",
      "epoch:18 step:17501 [D loss: 0.624121, acc.: 71.09%] [G loss: 0.956740]\n",
      "epoch:18 step:17502 [D loss: 0.674129, acc.: 57.03%] [G loss: 0.956447]\n",
      "epoch:18 step:17503 [D loss: 0.656123, acc.: 60.94%] [G loss: 0.983628]\n",
      "epoch:18 step:17504 [D loss: 0.637582, acc.: 64.06%] [G loss: 0.933520]\n",
      "epoch:18 step:17505 [D loss: 0.643112, acc.: 60.94%] [G loss: 0.932087]\n",
      "epoch:18 step:17506 [D loss: 0.688159, acc.: 55.47%] [G loss: 0.922841]\n",
      "epoch:18 step:17507 [D loss: 0.592576, acc.: 74.22%] [G loss: 0.924689]\n",
      "epoch:18 step:17508 [D loss: 0.616375, acc.: 63.28%] [G loss: 0.963997]\n",
      "epoch:18 step:17509 [D loss: 0.659215, acc.: 58.59%] [G loss: 0.998055]\n",
      "epoch:18 step:17510 [D loss: 0.688015, acc.: 54.69%] [G loss: 0.932632]\n",
      "epoch:18 step:17511 [D loss: 0.661311, acc.: 57.03%] [G loss: 0.897031]\n",
      "epoch:18 step:17512 [D loss: 0.632796, acc.: 64.84%] [G loss: 0.944697]\n",
      "epoch:18 step:17513 [D loss: 0.598635, acc.: 67.19%] [G loss: 0.952352]\n",
      "epoch:18 step:17514 [D loss: 0.545011, acc.: 71.88%] [G loss: 1.045664]\n",
      "epoch:18 step:17515 [D loss: 0.686795, acc.: 53.12%] [G loss: 0.978822]\n",
      "epoch:18 step:17516 [D loss: 0.585360, acc.: 66.41%] [G loss: 0.980254]\n",
      "epoch:18 step:17517 [D loss: 0.631875, acc.: 63.28%] [G loss: 1.014506]\n",
      "epoch:18 step:17518 [D loss: 0.699576, acc.: 58.59%] [G loss: 0.898663]\n",
      "epoch:18 step:17519 [D loss: 0.647405, acc.: 64.06%] [G loss: 0.917027]\n",
      "epoch:18 step:17520 [D loss: 0.631028, acc.: 60.16%] [G loss: 0.957042]\n",
      "epoch:18 step:17521 [D loss: 0.731099, acc.: 52.34%] [G loss: 0.944698]\n",
      "epoch:18 step:17522 [D loss: 0.677567, acc.: 57.03%] [G loss: 0.866459]\n",
      "epoch:18 step:17523 [D loss: 0.700669, acc.: 53.91%] [G loss: 0.897153]\n",
      "epoch:18 step:17524 [D loss: 0.657889, acc.: 61.72%] [G loss: 0.881416]\n",
      "epoch:18 step:17525 [D loss: 0.650799, acc.: 62.50%] [G loss: 0.909329]\n",
      "epoch:18 step:17526 [D loss: 0.648586, acc.: 57.81%] [G loss: 0.926365]\n",
      "epoch:18 step:17527 [D loss: 0.620306, acc.: 67.19%] [G loss: 0.940395]\n",
      "epoch:18 step:17528 [D loss: 0.658331, acc.: 56.25%] [G loss: 0.940344]\n",
      "epoch:18 step:17529 [D loss: 0.682490, acc.: 58.59%] [G loss: 0.948040]\n",
      "epoch:18 step:17530 [D loss: 0.641621, acc.: 62.50%] [G loss: 0.941335]\n",
      "epoch:18 step:17531 [D loss: 0.664686, acc.: 57.81%] [G loss: 0.903733]\n",
      "epoch:18 step:17532 [D loss: 0.605913, acc.: 69.53%] [G loss: 0.940736]\n",
      "epoch:18 step:17533 [D loss: 0.651502, acc.: 62.50%] [G loss: 1.005868]\n",
      "epoch:18 step:17534 [D loss: 0.676639, acc.: 59.38%] [G loss: 0.841951]\n",
      "epoch:18 step:17535 [D loss: 0.605519, acc.: 66.41%] [G loss: 0.819624]\n",
      "epoch:18 step:17536 [D loss: 0.687063, acc.: 59.38%] [G loss: 0.839597]\n",
      "epoch:18 step:17537 [D loss: 0.683004, acc.: 51.56%] [G loss: 0.842422]\n",
      "epoch:18 step:17538 [D loss: 0.686973, acc.: 56.25%] [G loss: 0.887049]\n",
      "epoch:18 step:17539 [D loss: 0.655132, acc.: 61.72%] [G loss: 0.913521]\n",
      "epoch:18 step:17540 [D loss: 0.622469, acc.: 69.53%] [G loss: 0.934496]\n",
      "epoch:18 step:17541 [D loss: 0.701560, acc.: 55.47%] [G loss: 0.868839]\n",
      "epoch:18 step:17542 [D loss: 0.675861, acc.: 61.72%] [G loss: 0.943552]\n",
      "epoch:18 step:17543 [D loss: 0.634036, acc.: 64.84%] [G loss: 0.916954]\n",
      "epoch:18 step:17544 [D loss: 0.654896, acc.: 62.50%] [G loss: 0.956024]\n",
      "epoch:18 step:17545 [D loss: 0.627485, acc.: 60.16%] [G loss: 0.865969]\n",
      "epoch:18 step:17546 [D loss: 0.670481, acc.: 58.59%] [G loss: 1.032812]\n",
      "epoch:18 step:17547 [D loss: 0.628858, acc.: 67.19%] [G loss: 0.976894]\n",
      "epoch:18 step:17548 [D loss: 0.690047, acc.: 53.91%] [G loss: 0.950219]\n",
      "epoch:18 step:17549 [D loss: 0.659467, acc.: 61.72%] [G loss: 0.894665]\n",
      "epoch:18 step:17550 [D loss: 0.633922, acc.: 60.94%] [G loss: 0.950139]\n",
      "epoch:18 step:17551 [D loss: 0.656778, acc.: 64.06%] [G loss: 0.826463]\n",
      "epoch:18 step:17552 [D loss: 0.639345, acc.: 62.50%] [G loss: 0.789079]\n",
      "epoch:18 step:17553 [D loss: 0.652718, acc.: 63.28%] [G loss: 0.873222]\n",
      "epoch:18 step:17554 [D loss: 0.647506, acc.: 62.50%] [G loss: 0.886209]\n",
      "epoch:18 step:17555 [D loss: 0.658078, acc.: 61.72%] [G loss: 0.874841]\n",
      "epoch:18 step:17556 [D loss: 0.628347, acc.: 67.19%] [G loss: 0.927994]\n",
      "epoch:18 step:17557 [D loss: 0.620666, acc.: 64.84%] [G loss: 0.979579]\n",
      "epoch:18 step:17558 [D loss: 0.626745, acc.: 61.72%] [G loss: 1.033860]\n",
      "epoch:18 step:17559 [D loss: 0.668996, acc.: 60.16%] [G loss: 0.898321]\n",
      "epoch:18 step:17560 [D loss: 0.618683, acc.: 61.72%] [G loss: 0.904710]\n",
      "epoch:18 step:17561 [D loss: 0.660421, acc.: 60.16%] [G loss: 0.907314]\n",
      "epoch:18 step:17562 [D loss: 0.667548, acc.: 52.34%] [G loss: 0.899638]\n",
      "epoch:18 step:17563 [D loss: 0.665368, acc.: 61.72%] [G loss: 0.919011]\n",
      "epoch:18 step:17564 [D loss: 0.708859, acc.: 53.91%] [G loss: 0.911961]\n",
      "epoch:18 step:17565 [D loss: 0.645062, acc.: 63.28%] [G loss: 0.909926]\n",
      "epoch:18 step:17566 [D loss: 0.662417, acc.: 59.38%] [G loss: 0.888111]\n",
      "epoch:18 step:17567 [D loss: 0.619903, acc.: 68.75%] [G loss: 0.946279]\n",
      "epoch:18 step:17568 [D loss: 0.651401, acc.: 64.06%] [G loss: 0.947354]\n",
      "epoch:18 step:17569 [D loss: 0.705765, acc.: 51.56%] [G loss: 0.903447]\n",
      "epoch:18 step:17570 [D loss: 0.710034, acc.: 51.56%] [G loss: 0.934142]\n",
      "epoch:18 step:17571 [D loss: 0.676030, acc.: 53.12%] [G loss: 0.918594]\n",
      "epoch:18 step:17572 [D loss: 0.641262, acc.: 64.06%] [G loss: 1.041611]\n",
      "epoch:18 step:17573 [D loss: 0.624416, acc.: 67.19%] [G loss: 0.966093]\n",
      "epoch:18 step:17574 [D loss: 0.582924, acc.: 70.31%] [G loss: 0.911308]\n",
      "epoch:18 step:17575 [D loss: 0.614933, acc.: 64.84%] [G loss: 0.906818]\n",
      "epoch:18 step:17576 [D loss: 0.655854, acc.: 63.28%] [G loss: 0.858318]\n",
      "epoch:18 step:17577 [D loss: 0.677711, acc.: 60.94%] [G loss: 0.845951]\n",
      "epoch:18 step:17578 [D loss: 0.641330, acc.: 61.72%] [G loss: 0.950764]\n",
      "epoch:18 step:17579 [D loss: 0.657635, acc.: 58.59%] [G loss: 0.984865]\n",
      "epoch:18 step:17580 [D loss: 0.627763, acc.: 69.53%] [G loss: 0.925666]\n",
      "epoch:18 step:17581 [D loss: 0.681023, acc.: 57.03%] [G loss: 0.896714]\n",
      "epoch:18 step:17582 [D loss: 0.704286, acc.: 51.56%] [G loss: 0.850040]\n",
      "epoch:18 step:17583 [D loss: 0.671814, acc.: 59.38%] [G loss: 0.850562]\n",
      "epoch:18 step:17584 [D loss: 0.681645, acc.: 57.03%] [G loss: 0.914181]\n",
      "epoch:18 step:17585 [D loss: 0.612576, acc.: 66.41%] [G loss: 0.912171]\n",
      "epoch:18 step:17586 [D loss: 0.658010, acc.: 59.38%] [G loss: 0.963222]\n",
      "epoch:18 step:17587 [D loss: 0.700111, acc.: 57.81%] [G loss: 0.931332]\n",
      "epoch:18 step:17588 [D loss: 0.737123, acc.: 52.34%] [G loss: 0.937809]\n",
      "epoch:18 step:17589 [D loss: 0.669862, acc.: 58.59%] [G loss: 0.876603]\n",
      "epoch:18 step:17590 [D loss: 0.660069, acc.: 57.03%] [G loss: 0.883772]\n",
      "epoch:18 step:17591 [D loss: 0.660921, acc.: 59.38%] [G loss: 0.941947]\n",
      "epoch:18 step:17592 [D loss: 0.645286, acc.: 62.50%] [G loss: 0.962194]\n",
      "epoch:18 step:17593 [D loss: 0.684000, acc.: 59.38%] [G loss: 0.985432]\n",
      "epoch:18 step:17594 [D loss: 0.693897, acc.: 57.03%] [G loss: 0.891519]\n",
      "epoch:18 step:17595 [D loss: 0.639858, acc.: 62.50%] [G loss: 0.946897]\n",
      "epoch:18 step:17596 [D loss: 0.594602, acc.: 73.44%] [G loss: 0.981525]\n",
      "epoch:18 step:17597 [D loss: 0.630360, acc.: 67.19%] [G loss: 0.916395]\n",
      "epoch:18 step:17598 [D loss: 0.575901, acc.: 71.09%] [G loss: 0.956671]\n",
      "epoch:18 step:17599 [D loss: 0.573907, acc.: 73.44%] [G loss: 0.938609]\n",
      "epoch:18 step:17600 [D loss: 0.702402, acc.: 53.12%] [G loss: 0.891240]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.133502\n",
      "FID: 7.403004\n",
      "0 = 11.720069231224024\n",
      "1 = 0.05302068903915266\n",
      "2 = 0.8981000185012817\n",
      "3 = 0.8518000245094299\n",
      "4 = 0.9444000124931335\n",
      "5 = 0.938726007938385\n",
      "6 = 0.8518000245094299\n",
      "7 = 5.714031389409309\n",
      "8 = 0.06237016543685846\n",
      "9 = 0.6934499740600586\n",
      "10 = 0.6718000173568726\n",
      "11 = 0.7150999903678894\n",
      "12 = 0.70220547914505\n",
      "13 = 0.6718000173568726\n",
      "14 = 8.133573532104492\n",
      "15 = 9.65338134765625\n",
      "16 = 0.06301307678222656\n",
      "17 = 8.133502006530762\n",
      "18 = 7.403003692626953\n",
      "epoch:18 step:17601 [D loss: 0.678484, acc.: 61.72%] [G loss: 0.844442]\n",
      "epoch:18 step:17602 [D loss: 0.644676, acc.: 60.16%] [G loss: 0.828558]\n",
      "epoch:18 step:17603 [D loss: 0.640925, acc.: 62.50%] [G loss: 0.923614]\n",
      "epoch:18 step:17604 [D loss: 0.687233, acc.: 53.91%] [G loss: 0.828247]\n",
      "epoch:18 step:17605 [D loss: 0.704972, acc.: 52.34%] [G loss: 0.856960]\n",
      "epoch:18 step:17606 [D loss: 0.687640, acc.: 57.81%] [G loss: 0.826371]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17607 [D loss: 0.657581, acc.: 63.28%] [G loss: 0.921389]\n",
      "epoch:18 step:17608 [D loss: 0.646118, acc.: 64.84%] [G loss: 0.882504]\n",
      "epoch:18 step:17609 [D loss: 0.640987, acc.: 59.38%] [G loss: 0.961792]\n",
      "epoch:18 step:17610 [D loss: 0.631811, acc.: 64.84%] [G loss: 0.949045]\n",
      "epoch:18 step:17611 [D loss: 0.699905, acc.: 55.47%] [G loss: 0.881354]\n",
      "epoch:18 step:17612 [D loss: 0.701755, acc.: 54.69%] [G loss: 0.909154]\n",
      "epoch:18 step:17613 [D loss: 0.634524, acc.: 62.50%] [G loss: 0.862217]\n",
      "epoch:18 step:17614 [D loss: 0.719031, acc.: 56.25%] [G loss: 0.878344]\n",
      "epoch:18 step:17615 [D loss: 0.644698, acc.: 64.84%] [G loss: 0.942494]\n",
      "epoch:18 step:17616 [D loss: 0.666780, acc.: 57.81%] [G loss: 0.912365]\n",
      "epoch:18 step:17617 [D loss: 0.626340, acc.: 67.19%] [G loss: 0.961818]\n",
      "epoch:18 step:17618 [D loss: 0.675338, acc.: 59.38%] [G loss: 0.916013]\n",
      "epoch:18 step:17619 [D loss: 0.651381, acc.: 65.62%] [G loss: 0.900772]\n",
      "epoch:18 step:17620 [D loss: 0.627412, acc.: 64.84%] [G loss: 0.893345]\n",
      "epoch:18 step:17621 [D loss: 0.659296, acc.: 60.16%] [G loss: 0.915207]\n",
      "epoch:18 step:17622 [D loss: 0.653342, acc.: 63.28%] [G loss: 0.893112]\n",
      "epoch:18 step:17623 [D loss: 0.640000, acc.: 61.72%] [G loss: 0.938423]\n",
      "epoch:18 step:17624 [D loss: 0.645495, acc.: 60.94%] [G loss: 0.892000]\n",
      "epoch:18 step:17625 [D loss: 0.716468, acc.: 55.47%] [G loss: 0.820201]\n",
      "epoch:18 step:17626 [D loss: 0.669683, acc.: 61.72%] [G loss: 0.900254]\n",
      "epoch:18 step:17627 [D loss: 0.676853, acc.: 62.50%] [G loss: 0.918780]\n",
      "epoch:18 step:17628 [D loss: 0.675554, acc.: 56.25%] [G loss: 0.887920]\n",
      "epoch:18 step:17629 [D loss: 0.636803, acc.: 68.75%] [G loss: 0.920201]\n",
      "epoch:18 step:17630 [D loss: 0.670195, acc.: 60.94%] [G loss: 0.897027]\n",
      "epoch:18 step:17631 [D loss: 0.790162, acc.: 45.31%] [G loss: 0.908421]\n",
      "epoch:18 step:17632 [D loss: 0.695610, acc.: 57.03%] [G loss: 0.893217]\n",
      "epoch:18 step:17633 [D loss: 0.618088, acc.: 67.97%] [G loss: 0.953548]\n",
      "epoch:18 step:17634 [D loss: 0.661956, acc.: 60.16%] [G loss: 0.894654]\n",
      "epoch:18 step:17635 [D loss: 0.650564, acc.: 66.41%] [G loss: 0.882215]\n",
      "epoch:18 step:17636 [D loss: 0.689956, acc.: 54.69%] [G loss: 0.895235]\n",
      "epoch:18 step:17637 [D loss: 0.660262, acc.: 60.16%] [G loss: 0.868752]\n",
      "epoch:18 step:17638 [D loss: 0.691986, acc.: 60.16%] [G loss: 0.868490]\n",
      "epoch:18 step:17639 [D loss: 0.655715, acc.: 60.16%] [G loss: 0.908401]\n",
      "epoch:18 step:17640 [D loss: 0.654011, acc.: 59.38%] [G loss: 0.920316]\n",
      "epoch:18 step:17641 [D loss: 0.590130, acc.: 67.97%] [G loss: 0.965553]\n",
      "epoch:18 step:17642 [D loss: 0.659121, acc.: 57.81%] [G loss: 0.974231]\n",
      "epoch:18 step:17643 [D loss: 0.624935, acc.: 65.62%] [G loss: 0.925657]\n",
      "epoch:18 step:17644 [D loss: 0.647725, acc.: 60.94%] [G loss: 0.960305]\n",
      "epoch:18 step:17645 [D loss: 0.613272, acc.: 64.84%] [G loss: 0.824979]\n",
      "epoch:18 step:17646 [D loss: 0.692244, acc.: 51.56%] [G loss: 0.962512]\n",
      "epoch:18 step:17647 [D loss: 0.607602, acc.: 66.41%] [G loss: 0.963952]\n",
      "epoch:18 step:17648 [D loss: 0.587662, acc.: 67.19%] [G loss: 1.040688]\n",
      "epoch:18 step:17649 [D loss: 0.726571, acc.: 53.12%] [G loss: 0.920570]\n",
      "epoch:18 step:17650 [D loss: 0.750055, acc.: 46.09%] [G loss: 0.859031]\n",
      "epoch:18 step:17651 [D loss: 0.657424, acc.: 60.94%] [G loss: 0.900281]\n",
      "epoch:18 step:17652 [D loss: 0.634968, acc.: 66.41%] [G loss: 0.917326]\n",
      "epoch:18 step:17653 [D loss: 0.681417, acc.: 58.59%] [G loss: 0.931796]\n",
      "epoch:18 step:17654 [D loss: 0.736575, acc.: 46.88%] [G loss: 0.835611]\n",
      "epoch:18 step:17655 [D loss: 0.654687, acc.: 60.94%] [G loss: 0.914532]\n",
      "epoch:18 step:17656 [D loss: 0.645962, acc.: 59.38%] [G loss: 0.904530]\n",
      "epoch:18 step:17657 [D loss: 0.686271, acc.: 59.38%] [G loss: 0.912594]\n",
      "epoch:18 step:17658 [D loss: 0.599495, acc.: 69.53%] [G loss: 0.878447]\n",
      "epoch:18 step:17659 [D loss: 0.654648, acc.: 56.25%] [G loss: 0.845304]\n",
      "epoch:18 step:17660 [D loss: 0.683991, acc.: 59.38%] [G loss: 0.925537]\n",
      "epoch:18 step:17661 [D loss: 0.713735, acc.: 52.34%] [G loss: 0.929608]\n",
      "epoch:18 step:17662 [D loss: 0.639521, acc.: 64.84%] [G loss: 0.924817]\n",
      "epoch:18 step:17663 [D loss: 0.680710, acc.: 58.59%] [G loss: 0.874943]\n",
      "epoch:18 step:17664 [D loss: 0.678495, acc.: 57.03%] [G loss: 0.925244]\n",
      "epoch:18 step:17665 [D loss: 0.650468, acc.: 67.97%] [G loss: 0.942492]\n",
      "epoch:18 step:17666 [D loss: 0.647469, acc.: 64.84%] [G loss: 0.914267]\n",
      "epoch:18 step:17667 [D loss: 0.621160, acc.: 65.62%] [G loss: 0.923223]\n",
      "epoch:18 step:17668 [D loss: 0.633184, acc.: 67.97%] [G loss: 0.984579]\n",
      "epoch:18 step:17669 [D loss: 0.672550, acc.: 62.50%] [G loss: 0.949123]\n",
      "epoch:18 step:17670 [D loss: 0.688323, acc.: 56.25%] [G loss: 0.954079]\n",
      "epoch:18 step:17671 [D loss: 0.674641, acc.: 53.91%] [G loss: 0.882082]\n",
      "epoch:18 step:17672 [D loss: 0.641381, acc.: 60.94%] [G loss: 0.881897]\n",
      "epoch:18 step:17673 [D loss: 0.645111, acc.: 65.62%] [G loss: 0.881730]\n",
      "epoch:18 step:17674 [D loss: 0.698408, acc.: 52.34%] [G loss: 0.858185]\n",
      "epoch:18 step:17675 [D loss: 0.683958, acc.: 60.94%] [G loss: 0.936716]\n",
      "epoch:18 step:17676 [D loss: 0.676330, acc.: 60.16%] [G loss: 0.892766]\n",
      "epoch:18 step:17677 [D loss: 0.677855, acc.: 58.59%] [G loss: 0.910147]\n",
      "epoch:18 step:17678 [D loss: 0.651928, acc.: 61.72%] [G loss: 0.882476]\n",
      "epoch:18 step:17679 [D loss: 0.657089, acc.: 55.47%] [G loss: 0.931927]\n",
      "epoch:18 step:17680 [D loss: 0.644570, acc.: 59.38%] [G loss: 1.000294]\n",
      "epoch:18 step:17681 [D loss: 0.647847, acc.: 60.16%] [G loss: 1.063940]\n",
      "epoch:18 step:17682 [D loss: 0.653725, acc.: 63.28%] [G loss: 0.923920]\n",
      "epoch:18 step:17683 [D loss: 0.663358, acc.: 62.50%] [G loss: 0.915670]\n",
      "epoch:18 step:17684 [D loss: 0.659868, acc.: 58.59%] [G loss: 0.988438]\n",
      "epoch:18 step:17685 [D loss: 0.686782, acc.: 60.16%] [G loss: 0.853192]\n",
      "epoch:18 step:17686 [D loss: 0.715795, acc.: 51.56%] [G loss: 0.806341]\n",
      "epoch:18 step:17687 [D loss: 0.639488, acc.: 61.72%] [G loss: 0.862903]\n",
      "epoch:18 step:17688 [D loss: 0.641570, acc.: 65.62%] [G loss: 0.881602]\n",
      "epoch:18 step:17689 [D loss: 0.646102, acc.: 60.94%] [G loss: 0.873272]\n",
      "epoch:18 step:17690 [D loss: 0.606945, acc.: 64.84%] [G loss: 0.884172]\n",
      "epoch:18 step:17691 [D loss: 0.651416, acc.: 63.28%] [G loss: 0.878585]\n",
      "epoch:18 step:17692 [D loss: 0.685164, acc.: 55.47%] [G loss: 0.944389]\n",
      "epoch:18 step:17693 [D loss: 0.729648, acc.: 52.34%] [G loss: 0.934791]\n",
      "epoch:18 step:17694 [D loss: 0.687335, acc.: 59.38%] [G loss: 0.867161]\n",
      "epoch:18 step:17695 [D loss: 0.621688, acc.: 68.75%] [G loss: 0.926885]\n",
      "epoch:18 step:17696 [D loss: 0.648454, acc.: 67.97%] [G loss: 0.944353]\n",
      "epoch:18 step:17697 [D loss: 0.674290, acc.: 54.69%] [G loss: 0.835291]\n",
      "epoch:18 step:17698 [D loss: 0.637973, acc.: 64.84%] [G loss: 0.870203]\n",
      "epoch:18 step:17699 [D loss: 0.608965, acc.: 68.75%] [G loss: 0.907823]\n",
      "epoch:18 step:17700 [D loss: 0.692303, acc.: 57.03%] [G loss: 0.871598]\n",
      "epoch:18 step:17701 [D loss: 0.665597, acc.: 61.72%] [G loss: 0.858352]\n",
      "epoch:18 step:17702 [D loss: 0.664253, acc.: 60.16%] [G loss: 0.831800]\n",
      "epoch:18 step:17703 [D loss: 0.614834, acc.: 67.97%] [G loss: 0.890772]\n",
      "epoch:18 step:17704 [D loss: 0.671177, acc.: 59.38%] [G loss: 0.958656]\n",
      "epoch:18 step:17705 [D loss: 0.684339, acc.: 58.59%] [G loss: 0.877443]\n",
      "epoch:18 step:17706 [D loss: 0.660286, acc.: 60.94%] [G loss: 0.887480]\n",
      "epoch:18 step:17707 [D loss: 0.646060, acc.: 64.84%] [G loss: 0.878009]\n",
      "epoch:18 step:17708 [D loss: 0.613928, acc.: 67.19%] [G loss: 0.875436]\n",
      "epoch:18 step:17709 [D loss: 0.702217, acc.: 57.81%] [G loss: 0.827625]\n",
      "epoch:18 step:17710 [D loss: 0.688543, acc.: 55.47%] [G loss: 0.939357]\n",
      "epoch:18 step:17711 [D loss: 0.634791, acc.: 64.06%] [G loss: 0.920770]\n",
      "epoch:18 step:17712 [D loss: 0.697477, acc.: 52.34%] [G loss: 0.892091]\n",
      "epoch:18 step:17713 [D loss: 0.669660, acc.: 52.34%] [G loss: 0.903555]\n",
      "epoch:18 step:17714 [D loss: 0.673787, acc.: 60.16%] [G loss: 0.891513]\n",
      "epoch:18 step:17715 [D loss: 0.640595, acc.: 62.50%] [G loss: 0.862471]\n",
      "epoch:18 step:17716 [D loss: 0.680109, acc.: 53.91%] [G loss: 0.893676]\n",
      "epoch:18 step:17717 [D loss: 0.653256, acc.: 57.81%] [G loss: 0.900064]\n",
      "epoch:18 step:17718 [D loss: 0.654273, acc.: 60.94%] [G loss: 0.951084]\n",
      "epoch:18 step:17719 [D loss: 0.615398, acc.: 71.09%] [G loss: 0.902694]\n",
      "epoch:18 step:17720 [D loss: 0.632223, acc.: 65.62%] [G loss: 0.916310]\n",
      "epoch:18 step:17721 [D loss: 0.666168, acc.: 62.50%] [G loss: 0.953981]\n",
      "epoch:18 step:17722 [D loss: 0.681113, acc.: 57.03%] [G loss: 0.996833]\n",
      "epoch:18 step:17723 [D loss: 0.657385, acc.: 64.84%] [G loss: 0.897238]\n",
      "epoch:18 step:17724 [D loss: 0.706498, acc.: 46.88%] [G loss: 0.875056]\n",
      "epoch:18 step:17725 [D loss: 0.672666, acc.: 59.38%] [G loss: 0.895157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17726 [D loss: 0.664400, acc.: 62.50%] [G loss: 0.848991]\n",
      "epoch:18 step:17727 [D loss: 0.719880, acc.: 53.12%] [G loss: 0.899320]\n",
      "epoch:18 step:17728 [D loss: 0.661857, acc.: 59.38%] [G loss: 0.872410]\n",
      "epoch:18 step:17729 [D loss: 0.656821, acc.: 62.50%] [G loss: 0.871048]\n",
      "epoch:18 step:17730 [D loss: 0.702437, acc.: 56.25%] [G loss: 0.863985]\n",
      "epoch:18 step:17731 [D loss: 0.707745, acc.: 57.81%] [G loss: 0.821873]\n",
      "epoch:18 step:17732 [D loss: 0.677376, acc.: 60.16%] [G loss: 0.873815]\n",
      "epoch:18 step:17733 [D loss: 0.673208, acc.: 60.94%] [G loss: 0.900685]\n",
      "epoch:18 step:17734 [D loss: 0.626902, acc.: 68.75%] [G loss: 0.861791]\n",
      "epoch:18 step:17735 [D loss: 0.661938, acc.: 59.38%] [G loss: 0.869467]\n",
      "epoch:18 step:17736 [D loss: 0.666768, acc.: 63.28%] [G loss: 0.982514]\n",
      "epoch:18 step:17737 [D loss: 0.632684, acc.: 67.19%] [G loss: 0.935987]\n",
      "epoch:18 step:17738 [D loss: 0.661095, acc.: 65.62%] [G loss: 0.907855]\n",
      "epoch:18 step:17739 [D loss: 0.629852, acc.: 67.19%] [G loss: 0.938544]\n",
      "epoch:18 step:17740 [D loss: 0.637461, acc.: 61.72%] [G loss: 0.898963]\n",
      "epoch:18 step:17741 [D loss: 0.663757, acc.: 57.03%] [G loss: 0.968756]\n",
      "epoch:18 step:17742 [D loss: 0.695940, acc.: 56.25%] [G loss: 0.917434]\n",
      "epoch:18 step:17743 [D loss: 0.678938, acc.: 55.47%] [G loss: 0.861718]\n",
      "epoch:18 step:17744 [D loss: 0.701679, acc.: 49.22%] [G loss: 0.857346]\n",
      "epoch:18 step:17745 [D loss: 0.660254, acc.: 61.72%] [G loss: 0.914856]\n",
      "epoch:18 step:17746 [D loss: 0.660104, acc.: 59.38%] [G loss: 0.827586]\n",
      "epoch:18 step:17747 [D loss: 0.657440, acc.: 58.59%] [G loss: 0.842988]\n",
      "epoch:18 step:17748 [D loss: 0.662852, acc.: 59.38%] [G loss: 0.879888]\n",
      "epoch:18 step:17749 [D loss: 0.680945, acc.: 62.50%] [G loss: 0.893635]\n",
      "epoch:18 step:17750 [D loss: 0.648234, acc.: 59.38%] [G loss: 0.942956]\n",
      "epoch:18 step:17751 [D loss: 0.602362, acc.: 70.31%] [G loss: 0.960538]\n",
      "epoch:18 step:17752 [D loss: 0.624982, acc.: 67.19%] [G loss: 0.957127]\n",
      "epoch:18 step:17753 [D loss: 0.658617, acc.: 61.72%] [G loss: 1.039925]\n",
      "epoch:18 step:17754 [D loss: 0.681846, acc.: 55.47%] [G loss: 0.918924]\n",
      "epoch:18 step:17755 [D loss: 0.636163, acc.: 63.28%] [G loss: 0.908597]\n",
      "epoch:18 step:17756 [D loss: 0.640336, acc.: 61.72%] [G loss: 0.915452]\n",
      "epoch:18 step:17757 [D loss: 0.730145, acc.: 52.34%] [G loss: 0.876084]\n",
      "epoch:18 step:17758 [D loss: 0.733620, acc.: 49.22%] [G loss: 0.874105]\n",
      "epoch:18 step:17759 [D loss: 0.671831, acc.: 58.59%] [G loss: 0.835770]\n",
      "epoch:18 step:17760 [D loss: 0.613761, acc.: 67.19%] [G loss: 0.906079]\n",
      "epoch:18 step:17761 [D loss: 0.613289, acc.: 67.97%] [G loss: 0.952377]\n",
      "epoch:18 step:17762 [D loss: 0.630667, acc.: 63.28%] [G loss: 0.921584]\n",
      "epoch:18 step:17763 [D loss: 0.589565, acc.: 69.53%] [G loss: 0.978901]\n",
      "epoch:18 step:17764 [D loss: 0.643567, acc.: 60.94%] [G loss: 1.019695]\n",
      "epoch:18 step:17765 [D loss: 0.569064, acc.: 71.88%] [G loss: 1.006617]\n",
      "epoch:18 step:17766 [D loss: 0.636029, acc.: 67.97%] [G loss: 0.950589]\n",
      "epoch:18 step:17767 [D loss: 0.627514, acc.: 61.72%] [G loss: 0.897032]\n",
      "epoch:18 step:17768 [D loss: 0.646707, acc.: 61.72%] [G loss: 0.886855]\n",
      "epoch:18 step:17769 [D loss: 0.666449, acc.: 58.59%] [G loss: 0.888525]\n",
      "epoch:18 step:17770 [D loss: 0.678203, acc.: 60.16%] [G loss: 0.861754]\n",
      "epoch:18 step:17771 [D loss: 0.625095, acc.: 66.41%] [G loss: 0.938701]\n",
      "epoch:18 step:17772 [D loss: 0.689293, acc.: 54.69%] [G loss: 0.932407]\n",
      "epoch:18 step:17773 [D loss: 0.635399, acc.: 61.72%] [G loss: 0.888542]\n",
      "epoch:18 step:17774 [D loss: 0.603103, acc.: 67.19%] [G loss: 0.987307]\n",
      "epoch:18 step:17775 [D loss: 0.555880, acc.: 75.78%] [G loss: 0.899492]\n",
      "epoch:18 step:17776 [D loss: 0.669361, acc.: 57.03%] [G loss: 0.960857]\n",
      "epoch:18 step:17777 [D loss: 0.660138, acc.: 61.72%] [G loss: 0.858558]\n",
      "epoch:18 step:17778 [D loss: 0.691274, acc.: 57.03%] [G loss: 0.887100]\n",
      "epoch:18 step:17779 [D loss: 0.632041, acc.: 62.50%] [G loss: 0.894525]\n",
      "epoch:18 step:17780 [D loss: 0.645719, acc.: 67.19%] [G loss: 0.925406]\n",
      "epoch:18 step:17781 [D loss: 0.703239, acc.: 57.03%] [G loss: 0.969666]\n",
      "epoch:18 step:17782 [D loss: 0.628322, acc.: 63.28%] [G loss: 0.903034]\n",
      "epoch:18 step:17783 [D loss: 0.677017, acc.: 57.03%] [G loss: 0.968718]\n",
      "epoch:18 step:17784 [D loss: 0.581464, acc.: 74.22%] [G loss: 1.025524]\n",
      "epoch:18 step:17785 [D loss: 0.612979, acc.: 66.41%] [G loss: 0.879231]\n",
      "epoch:18 step:17786 [D loss: 0.720716, acc.: 54.69%] [G loss: 0.905587]\n",
      "epoch:18 step:17787 [D loss: 0.647903, acc.: 59.38%] [G loss: 0.958180]\n",
      "epoch:18 step:17788 [D loss: 0.684829, acc.: 54.69%] [G loss: 0.908308]\n",
      "epoch:18 step:17789 [D loss: 0.591565, acc.: 69.53%] [G loss: 0.892621]\n",
      "epoch:18 step:17790 [D loss: 0.589410, acc.: 73.44%] [G loss: 1.031540]\n",
      "epoch:18 step:17791 [D loss: 0.592913, acc.: 73.44%] [G loss: 1.025580]\n",
      "epoch:18 step:17792 [D loss: 0.560602, acc.: 75.78%] [G loss: 1.077885]\n",
      "epoch:18 step:17793 [D loss: 0.681244, acc.: 57.03%] [G loss: 1.071454]\n",
      "epoch:18 step:17794 [D loss: 0.800605, acc.: 60.94%] [G loss: 1.027821]\n",
      "epoch:18 step:17795 [D loss: 0.655126, acc.: 60.16%] [G loss: 1.162467]\n",
      "epoch:18 step:17796 [D loss: 0.587692, acc.: 67.97%] [G loss: 1.115175]\n",
      "epoch:18 step:17797 [D loss: 0.717851, acc.: 54.69%] [G loss: 1.037754]\n",
      "epoch:18 step:17798 [D loss: 0.728483, acc.: 53.12%] [G loss: 0.839479]\n",
      "epoch:18 step:17799 [D loss: 0.627341, acc.: 60.94%] [G loss: 0.879390]\n",
      "epoch:18 step:17800 [D loss: 0.667357, acc.: 64.06%] [G loss: 0.892870]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.372362\n",
      "FID: 3.389057\n",
      "0 = 11.831469573855378\n",
      "1 = 0.05186365210264148\n",
      "2 = 0.9043499827384949\n",
      "3 = 0.8662999868392944\n",
      "4 = 0.9423999786376953\n",
      "5 = 0.9376555681228638\n",
      "6 = 0.8662999868392944\n",
      "7 = 5.246431695592398\n",
      "8 = 0.03840852715466864\n",
      "9 = 0.6858000159263611\n",
      "10 = 0.6689000129699707\n",
      "11 = 0.7027000188827515\n",
      "12 = 0.6922997236251831\n",
      "13 = 0.6689000129699707\n",
      "14 = 8.372422218322754\n",
      "15 = 9.60383415222168\n",
      "16 = 0.08126844465732574\n",
      "17 = 8.37236213684082\n",
      "18 = 3.38905668258667\n",
      "epoch:18 step:17801 [D loss: 0.546203, acc.: 78.12%] [G loss: 0.918910]\n",
      "epoch:18 step:17802 [D loss: 0.572843, acc.: 70.31%] [G loss: 1.041649]\n",
      "epoch:18 step:17803 [D loss: 0.608464, acc.: 64.84%] [G loss: 1.089987]\n",
      "epoch:19 step:17804 [D loss: 0.674476, acc.: 60.16%] [G loss: 1.043088]\n",
      "epoch:19 step:17805 [D loss: 0.675028, acc.: 60.94%] [G loss: 1.004756]\n",
      "epoch:19 step:17806 [D loss: 0.688632, acc.: 58.59%] [G loss: 0.867541]\n",
      "epoch:19 step:17807 [D loss: 0.705076, acc.: 57.03%] [G loss: 0.957426]\n",
      "epoch:19 step:17808 [D loss: 0.688744, acc.: 60.16%] [G loss: 0.888982]\n",
      "epoch:19 step:17809 [D loss: 0.661430, acc.: 57.81%] [G loss: 0.970322]\n",
      "epoch:19 step:17810 [D loss: 0.645255, acc.: 60.94%] [G loss: 0.956625]\n",
      "epoch:19 step:17811 [D loss: 0.669945, acc.: 59.38%] [G loss: 0.874436]\n",
      "epoch:19 step:17812 [D loss: 0.643673, acc.: 60.16%] [G loss: 0.954959]\n",
      "epoch:19 step:17813 [D loss: 0.658913, acc.: 66.41%] [G loss: 1.011855]\n",
      "epoch:19 step:17814 [D loss: 0.643697, acc.: 66.41%] [G loss: 0.996338]\n",
      "epoch:19 step:17815 [D loss: 0.654111, acc.: 61.72%] [G loss: 0.970293]\n",
      "epoch:19 step:17816 [D loss: 0.670638, acc.: 54.69%] [G loss: 0.898339]\n",
      "epoch:19 step:17817 [D loss: 0.608224, acc.: 68.75%] [G loss: 0.917189]\n",
      "epoch:19 step:17818 [D loss: 0.560041, acc.: 70.31%] [G loss: 0.960021]\n",
      "epoch:19 step:17819 [D loss: 0.562207, acc.: 72.66%] [G loss: 0.939157]\n",
      "epoch:19 step:17820 [D loss: 0.663554, acc.: 55.47%] [G loss: 0.856038]\n",
      "epoch:19 step:17821 [D loss: 0.662820, acc.: 59.38%] [G loss: 0.888411]\n",
      "epoch:19 step:17822 [D loss: 0.705285, acc.: 57.81%] [G loss: 0.977443]\n",
      "epoch:19 step:17823 [D loss: 0.710339, acc.: 53.91%] [G loss: 1.022098]\n",
      "epoch:19 step:17824 [D loss: 0.648691, acc.: 59.38%] [G loss: 1.079583]\n",
      "epoch:19 step:17825 [D loss: 0.556472, acc.: 71.09%] [G loss: 1.185205]\n",
      "epoch:19 step:17826 [D loss: 0.704472, acc.: 52.34%] [G loss: 0.880746]\n",
      "epoch:19 step:17827 [D loss: 0.698016, acc.: 57.81%] [G loss: 0.899428]\n",
      "epoch:19 step:17828 [D loss: 0.633870, acc.: 64.84%] [G loss: 0.899799]\n",
      "epoch:19 step:17829 [D loss: 0.741164, acc.: 50.00%] [G loss: 0.920332]\n",
      "epoch:19 step:17830 [D loss: 0.658951, acc.: 60.16%] [G loss: 0.896648]\n",
      "epoch:19 step:17831 [D loss: 0.705550, acc.: 54.69%] [G loss: 0.924821]\n",
      "epoch:19 step:17832 [D loss: 0.645438, acc.: 64.06%] [G loss: 0.984907]\n",
      "epoch:19 step:17833 [D loss: 0.657983, acc.: 59.38%] [G loss: 0.934043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:17834 [D loss: 0.671331, acc.: 57.81%] [G loss: 0.980914]\n",
      "epoch:19 step:17835 [D loss: 0.637801, acc.: 64.06%] [G loss: 0.965292]\n",
      "epoch:19 step:17836 [D loss: 0.629715, acc.: 71.88%] [G loss: 0.887978]\n",
      "epoch:19 step:17837 [D loss: 0.673875, acc.: 57.81%] [G loss: 0.899102]\n",
      "epoch:19 step:17838 [D loss: 0.637749, acc.: 61.72%] [G loss: 0.865969]\n",
      "epoch:19 step:17839 [D loss: 0.651943, acc.: 58.59%] [G loss: 0.957552]\n",
      "epoch:19 step:17840 [D loss: 0.678302, acc.: 57.03%] [G loss: 0.936821]\n",
      "epoch:19 step:17841 [D loss: 0.724111, acc.: 55.47%] [G loss: 0.808991]\n",
      "epoch:19 step:17842 [D loss: 0.686573, acc.: 47.66%] [G loss: 0.842971]\n",
      "epoch:19 step:17843 [D loss: 0.660392, acc.: 64.06%] [G loss: 0.944261]\n",
      "epoch:19 step:17844 [D loss: 0.640835, acc.: 62.50%] [G loss: 0.934387]\n",
      "epoch:19 step:17845 [D loss: 0.679248, acc.: 59.38%] [G loss: 0.880009]\n",
      "epoch:19 step:17846 [D loss: 0.676875, acc.: 56.25%] [G loss: 0.938585]\n",
      "epoch:19 step:17847 [D loss: 0.694411, acc.: 52.34%] [G loss: 0.857028]\n",
      "epoch:19 step:17848 [D loss: 0.654154, acc.: 61.72%] [G loss: 0.905007]\n",
      "epoch:19 step:17849 [D loss: 0.665907, acc.: 54.69%] [G loss: 0.961750]\n",
      "epoch:19 step:17850 [D loss: 0.630179, acc.: 64.06%] [G loss: 0.878553]\n",
      "epoch:19 step:17851 [D loss: 0.628388, acc.: 61.72%] [G loss: 0.883404]\n",
      "epoch:19 step:17852 [D loss: 0.652886, acc.: 64.84%] [G loss: 0.873600]\n",
      "epoch:19 step:17853 [D loss: 0.614251, acc.: 70.31%] [G loss: 0.949012]\n",
      "epoch:19 step:17854 [D loss: 0.721336, acc.: 54.69%] [G loss: 0.874159]\n",
      "epoch:19 step:17855 [D loss: 0.671799, acc.: 60.16%] [G loss: 0.919939]\n",
      "epoch:19 step:17856 [D loss: 0.652467, acc.: 60.94%] [G loss: 0.979571]\n",
      "epoch:19 step:17857 [D loss: 0.583272, acc.: 69.53%] [G loss: 0.887932]\n",
      "epoch:19 step:17858 [D loss: 0.647467, acc.: 62.50%] [G loss: 0.941746]\n",
      "epoch:19 step:17859 [D loss: 0.674304, acc.: 60.94%] [G loss: 0.911208]\n",
      "epoch:19 step:17860 [D loss: 0.629934, acc.: 63.28%] [G loss: 0.923019]\n",
      "epoch:19 step:17861 [D loss: 0.666203, acc.: 60.16%] [G loss: 0.906472]\n",
      "epoch:19 step:17862 [D loss: 0.693213, acc.: 57.03%] [G loss: 0.908932]\n",
      "epoch:19 step:17863 [D loss: 0.655338, acc.: 59.38%] [G loss: 0.883509]\n",
      "epoch:19 step:17864 [D loss: 0.673409, acc.: 56.25%] [G loss: 0.856372]\n",
      "epoch:19 step:17865 [D loss: 0.663880, acc.: 60.16%] [G loss: 0.880631]\n",
      "epoch:19 step:17866 [D loss: 0.624868, acc.: 64.06%] [G loss: 0.913485]\n",
      "epoch:19 step:17867 [D loss: 0.664003, acc.: 57.03%] [G loss: 0.937596]\n",
      "epoch:19 step:17868 [D loss: 0.648647, acc.: 57.03%] [G loss: 0.914500]\n",
      "epoch:19 step:17869 [D loss: 0.664679, acc.: 60.94%] [G loss: 0.885431]\n",
      "epoch:19 step:17870 [D loss: 0.622710, acc.: 67.19%] [G loss: 0.916753]\n",
      "epoch:19 step:17871 [D loss: 0.642323, acc.: 66.41%] [G loss: 0.870157]\n",
      "epoch:19 step:17872 [D loss: 0.623361, acc.: 67.19%] [G loss: 0.905607]\n",
      "epoch:19 step:17873 [D loss: 0.656921, acc.: 60.94%] [G loss: 0.915622]\n",
      "epoch:19 step:17874 [D loss: 0.738054, acc.: 50.78%] [G loss: 0.914293]\n",
      "epoch:19 step:17875 [D loss: 0.680282, acc.: 53.12%] [G loss: 0.926264]\n",
      "epoch:19 step:17876 [D loss: 0.699263, acc.: 50.78%] [G loss: 0.965498]\n",
      "epoch:19 step:17877 [D loss: 0.646704, acc.: 63.28%] [G loss: 0.993206]\n",
      "epoch:19 step:17878 [D loss: 0.702085, acc.: 50.78%] [G loss: 0.919454]\n",
      "epoch:19 step:17879 [D loss: 0.589826, acc.: 67.19%] [G loss: 0.941682]\n",
      "epoch:19 step:17880 [D loss: 0.556588, acc.: 71.09%] [G loss: 1.003023]\n",
      "epoch:19 step:17881 [D loss: 0.731106, acc.: 54.69%] [G loss: 0.963110]\n",
      "epoch:19 step:17882 [D loss: 0.648266, acc.: 59.38%] [G loss: 0.921179]\n",
      "epoch:19 step:17883 [D loss: 0.673411, acc.: 58.59%] [G loss: 0.904926]\n",
      "epoch:19 step:17884 [D loss: 0.670897, acc.: 57.03%] [G loss: 0.821604]\n",
      "epoch:19 step:17885 [D loss: 0.639900, acc.: 58.59%] [G loss: 0.917245]\n",
      "epoch:19 step:17886 [D loss: 0.666321, acc.: 61.72%] [G loss: 0.861602]\n",
      "epoch:19 step:17887 [D loss: 0.643598, acc.: 64.06%] [G loss: 0.897961]\n",
      "epoch:19 step:17888 [D loss: 0.654017, acc.: 57.03%] [G loss: 0.910392]\n",
      "epoch:19 step:17889 [D loss: 0.668716, acc.: 59.38%] [G loss: 0.951754]\n",
      "epoch:19 step:17890 [D loss: 0.657446, acc.: 59.38%] [G loss: 0.953665]\n",
      "epoch:19 step:17891 [D loss: 0.658173, acc.: 62.50%] [G loss: 0.954884]\n",
      "epoch:19 step:17892 [D loss: 0.633758, acc.: 62.50%] [G loss: 0.965951]\n",
      "epoch:19 step:17893 [D loss: 0.659360, acc.: 58.59%] [G loss: 0.909635]\n",
      "epoch:19 step:17894 [D loss: 0.626763, acc.: 66.41%] [G loss: 0.926313]\n",
      "epoch:19 step:17895 [D loss: 0.580398, acc.: 69.53%] [G loss: 0.901097]\n",
      "epoch:19 step:17896 [D loss: 0.618566, acc.: 65.62%] [G loss: 0.952791]\n",
      "epoch:19 step:17897 [D loss: 0.641084, acc.: 62.50%] [G loss: 0.988308]\n",
      "epoch:19 step:17898 [D loss: 0.654535, acc.: 67.19%] [G loss: 0.983302]\n",
      "epoch:19 step:17899 [D loss: 0.684586, acc.: 55.47%] [G loss: 1.052067]\n",
      "epoch:19 step:17900 [D loss: 0.622270, acc.: 60.94%] [G loss: 1.041773]\n",
      "epoch:19 step:17901 [D loss: 0.657583, acc.: 61.72%] [G loss: 1.047781]\n",
      "epoch:19 step:17902 [D loss: 0.636311, acc.: 64.06%] [G loss: 0.920028]\n",
      "epoch:19 step:17903 [D loss: 0.615098, acc.: 66.41%] [G loss: 0.949771]\n",
      "epoch:19 step:17904 [D loss: 0.673445, acc.: 54.69%] [G loss: 0.928134]\n",
      "epoch:19 step:17905 [D loss: 0.726686, acc.: 52.34%] [G loss: 0.822630]\n",
      "epoch:19 step:17906 [D loss: 0.695022, acc.: 57.03%] [G loss: 0.801322]\n",
      "epoch:19 step:17907 [D loss: 0.664445, acc.: 54.69%] [G loss: 0.846069]\n",
      "epoch:19 step:17908 [D loss: 0.718072, acc.: 50.00%] [G loss: 0.841471]\n",
      "epoch:19 step:17909 [D loss: 0.672595, acc.: 60.16%] [G loss: 0.914952]\n",
      "epoch:19 step:17910 [D loss: 0.624986, acc.: 67.97%] [G loss: 0.984112]\n",
      "epoch:19 step:17911 [D loss: 0.714227, acc.: 51.56%] [G loss: 0.916806]\n",
      "epoch:19 step:17912 [D loss: 0.735149, acc.: 47.66%] [G loss: 0.948893]\n",
      "epoch:19 step:17913 [D loss: 0.693184, acc.: 49.22%] [G loss: 0.913979]\n",
      "epoch:19 step:17914 [D loss: 0.656867, acc.: 60.16%] [G loss: 0.858514]\n",
      "epoch:19 step:17915 [D loss: 0.604814, acc.: 73.44%] [G loss: 0.890894]\n",
      "epoch:19 step:17916 [D loss: 0.646727, acc.: 65.62%] [G loss: 0.920750]\n",
      "epoch:19 step:17917 [D loss: 0.641035, acc.: 58.59%] [G loss: 0.915402]\n",
      "epoch:19 step:17918 [D loss: 0.604437, acc.: 62.50%] [G loss: 0.950118]\n",
      "epoch:19 step:17919 [D loss: 0.598899, acc.: 69.53%] [G loss: 1.026103]\n",
      "epoch:19 step:17920 [D loss: 0.606537, acc.: 68.75%] [G loss: 0.960742]\n",
      "epoch:19 step:17921 [D loss: 0.636204, acc.: 64.84%] [G loss: 1.052726]\n",
      "epoch:19 step:17922 [D loss: 0.575111, acc.: 70.31%] [G loss: 1.025588]\n",
      "epoch:19 step:17923 [D loss: 0.691358, acc.: 53.12%] [G loss: 0.924087]\n",
      "epoch:19 step:17924 [D loss: 0.684845, acc.: 54.69%] [G loss: 0.884415]\n",
      "epoch:19 step:17925 [D loss: 0.617077, acc.: 65.62%] [G loss: 0.936643]\n",
      "epoch:19 step:17926 [D loss: 0.688904, acc.: 58.59%] [G loss: 0.912556]\n",
      "epoch:19 step:17927 [D loss: 0.732423, acc.: 51.56%] [G loss: 0.971028]\n",
      "epoch:19 step:17928 [D loss: 0.700178, acc.: 57.03%] [G loss: 0.919068]\n",
      "epoch:19 step:17929 [D loss: 0.608352, acc.: 64.06%] [G loss: 0.991004]\n",
      "epoch:19 step:17930 [D loss: 0.625498, acc.: 64.84%] [G loss: 0.869914]\n",
      "epoch:19 step:17931 [D loss: 0.702249, acc.: 50.00%] [G loss: 0.890685]\n",
      "epoch:19 step:17932 [D loss: 0.673360, acc.: 55.47%] [G loss: 0.894622]\n",
      "epoch:19 step:17933 [D loss: 0.598803, acc.: 67.97%] [G loss: 0.885919]\n",
      "epoch:19 step:17934 [D loss: 0.626990, acc.: 66.41%] [G loss: 0.869110]\n",
      "epoch:19 step:17935 [D loss: 0.645219, acc.: 69.53%] [G loss: 0.928622]\n",
      "epoch:19 step:17936 [D loss: 0.651678, acc.: 62.50%] [G loss: 0.946116]\n",
      "epoch:19 step:17937 [D loss: 0.614137, acc.: 61.72%] [G loss: 1.003801]\n",
      "epoch:19 step:17938 [D loss: 0.669235, acc.: 60.16%] [G loss: 0.942596]\n",
      "epoch:19 step:17939 [D loss: 0.601844, acc.: 72.66%] [G loss: 1.025172]\n",
      "epoch:19 step:17940 [D loss: 0.709259, acc.: 56.25%] [G loss: 0.912863]\n",
      "epoch:19 step:17941 [D loss: 0.682264, acc.: 57.81%] [G loss: 0.834356]\n",
      "epoch:19 step:17942 [D loss: 0.707512, acc.: 57.03%] [G loss: 0.873982]\n",
      "epoch:19 step:17943 [D loss: 0.693455, acc.: 53.12%] [G loss: 0.898565]\n",
      "epoch:19 step:17944 [D loss: 0.695138, acc.: 51.56%] [G loss: 0.936332]\n",
      "epoch:19 step:17945 [D loss: 0.661866, acc.: 60.16%] [G loss: 0.872390]\n",
      "epoch:19 step:17946 [D loss: 0.698502, acc.: 52.34%] [G loss: 0.929372]\n",
      "epoch:19 step:17947 [D loss: 0.608652, acc.: 69.53%] [G loss: 0.840513]\n",
      "epoch:19 step:17948 [D loss: 0.650569, acc.: 60.94%] [G loss: 0.928296]\n",
      "epoch:19 step:17949 [D loss: 0.620704, acc.: 61.72%] [G loss: 0.896672]\n",
      "epoch:19 step:17950 [D loss: 0.678271, acc.: 60.94%] [G loss: 0.917239]\n",
      "epoch:19 step:17951 [D loss: 0.698923, acc.: 57.03%] [G loss: 0.918483]\n",
      "epoch:19 step:17952 [D loss: 0.688613, acc.: 55.47%] [G loss: 0.937995]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:17953 [D loss: 0.676715, acc.: 57.03%] [G loss: 0.885641]\n",
      "epoch:19 step:17954 [D loss: 0.640567, acc.: 64.06%] [G loss: 0.959527]\n",
      "epoch:19 step:17955 [D loss: 0.631003, acc.: 63.28%] [G loss: 0.931966]\n",
      "epoch:19 step:17956 [D loss: 0.691162, acc.: 52.34%] [G loss: 0.867392]\n",
      "epoch:19 step:17957 [D loss: 0.627468, acc.: 64.06%] [G loss: 0.857475]\n",
      "epoch:19 step:17958 [D loss: 0.632099, acc.: 62.50%] [G loss: 0.909654]\n",
      "epoch:19 step:17959 [D loss: 0.691298, acc.: 57.03%] [G loss: 0.947012]\n",
      "epoch:19 step:17960 [D loss: 0.708685, acc.: 55.47%] [G loss: 0.924351]\n",
      "epoch:19 step:17961 [D loss: 0.702444, acc.: 55.47%] [G loss: 0.825669]\n",
      "epoch:19 step:17962 [D loss: 0.641101, acc.: 60.94%] [G loss: 0.917588]\n",
      "epoch:19 step:17963 [D loss: 0.732362, acc.: 54.69%] [G loss: 0.889662]\n",
      "epoch:19 step:17964 [D loss: 0.688503, acc.: 53.12%] [G loss: 0.931116]\n",
      "epoch:19 step:17965 [D loss: 0.677630, acc.: 56.25%] [G loss: 0.860421]\n",
      "epoch:19 step:17966 [D loss: 0.689236, acc.: 58.59%] [G loss: 0.931145]\n",
      "epoch:19 step:17967 [D loss: 0.579495, acc.: 72.66%] [G loss: 0.959417]\n",
      "epoch:19 step:17968 [D loss: 0.650960, acc.: 59.38%] [G loss: 0.923080]\n",
      "epoch:19 step:17969 [D loss: 0.657094, acc.: 62.50%] [G loss: 0.896322]\n",
      "epoch:19 step:17970 [D loss: 0.624828, acc.: 67.97%] [G loss: 0.927243]\n",
      "epoch:19 step:17971 [D loss: 0.620918, acc.: 67.19%] [G loss: 0.914408]\n",
      "epoch:19 step:17972 [D loss: 0.653939, acc.: 60.94%] [G loss: 0.965441]\n",
      "epoch:19 step:17973 [D loss: 0.675125, acc.: 57.81%] [G loss: 0.795737]\n",
      "epoch:19 step:17974 [D loss: 0.616916, acc.: 68.75%] [G loss: 0.841500]\n",
      "epoch:19 step:17975 [D loss: 0.649081, acc.: 65.62%] [G loss: 0.858460]\n",
      "epoch:19 step:17976 [D loss: 0.625005, acc.: 71.09%] [G loss: 0.924646]\n",
      "epoch:19 step:17977 [D loss: 0.697845, acc.: 55.47%] [G loss: 0.907352]\n",
      "epoch:19 step:17978 [D loss: 0.688882, acc.: 55.47%] [G loss: 0.909059]\n",
      "epoch:19 step:17979 [D loss: 0.638127, acc.: 64.06%] [G loss: 0.837181]\n",
      "epoch:19 step:17980 [D loss: 0.696791, acc.: 51.56%] [G loss: 0.906564]\n",
      "epoch:19 step:17981 [D loss: 0.696760, acc.: 53.91%] [G loss: 0.930753]\n",
      "epoch:19 step:17982 [D loss: 0.679286, acc.: 59.38%] [G loss: 0.915896]\n",
      "epoch:19 step:17983 [D loss: 0.737589, acc.: 46.09%] [G loss: 0.944840]\n",
      "epoch:19 step:17984 [D loss: 0.659732, acc.: 60.94%] [G loss: 0.936651]\n",
      "epoch:19 step:17985 [D loss: 0.682680, acc.: 56.25%] [G loss: 0.927814]\n",
      "epoch:19 step:17986 [D loss: 0.666973, acc.: 57.03%] [G loss: 0.930391]\n",
      "epoch:19 step:17987 [D loss: 0.597947, acc.: 68.75%] [G loss: 1.000755]\n",
      "epoch:19 step:17988 [D loss: 0.637797, acc.: 59.38%] [G loss: 0.858765]\n",
      "epoch:19 step:17989 [D loss: 0.693046, acc.: 60.94%] [G loss: 0.914931]\n",
      "epoch:19 step:17990 [D loss: 0.679991, acc.: 59.38%] [G loss: 0.919076]\n",
      "epoch:19 step:17991 [D loss: 0.648187, acc.: 64.06%] [G loss: 0.951426]\n",
      "epoch:19 step:17992 [D loss: 0.659734, acc.: 53.12%] [G loss: 0.890523]\n",
      "epoch:19 step:17993 [D loss: 0.694771, acc.: 56.25%] [G loss: 0.919250]\n",
      "epoch:19 step:17994 [D loss: 0.629992, acc.: 67.97%] [G loss: 0.855993]\n",
      "epoch:19 step:17995 [D loss: 0.604082, acc.: 65.62%] [G loss: 0.909234]\n",
      "epoch:19 step:17996 [D loss: 0.666435, acc.: 57.81%] [G loss: 0.893212]\n",
      "epoch:19 step:17997 [D loss: 0.627001, acc.: 67.19%] [G loss: 0.939088]\n",
      "epoch:19 step:17998 [D loss: 0.617423, acc.: 60.94%] [G loss: 0.933901]\n",
      "epoch:19 step:17999 [D loss: 0.680475, acc.: 56.25%] [G loss: 0.892609]\n",
      "epoch:19 step:18000 [D loss: 0.643777, acc.: 64.84%] [G loss: 0.926933]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.264040\n",
      "FID: 6.358953\n",
      "0 = 11.792804721784616\n",
      "1 = 0.05381515102967453\n",
      "2 = 0.9122499823570251\n",
      "3 = 0.8822000026702881\n",
      "4 = 0.942300021648407\n",
      "5 = 0.9386104941368103\n",
      "6 = 0.8822000026702881\n",
      "7 = 5.545471428930774\n",
      "8 = 0.057146640209584085\n",
      "9 = 0.6820499897003174\n",
      "10 = 0.659500002861023\n",
      "11 = 0.7045999765396118\n",
      "12 = 0.6906482577323914\n",
      "13 = 0.659500002861023\n",
      "14 = 8.264107704162598\n",
      "15 = 9.603145599365234\n",
      "16 = 0.08529724925756454\n",
      "17 = 8.264039993286133\n",
      "18 = 6.358952522277832\n",
      "epoch:19 step:18001 [D loss: 0.625263, acc.: 64.84%] [G loss: 0.907094]\n",
      "epoch:19 step:18002 [D loss: 0.624249, acc.: 69.53%] [G loss: 0.873059]\n",
      "epoch:19 step:18003 [D loss: 0.705862, acc.: 52.34%] [G loss: 0.897448]\n",
      "epoch:19 step:18004 [D loss: 0.676889, acc.: 55.47%] [G loss: 0.936193]\n",
      "epoch:19 step:18005 [D loss: 0.670655, acc.: 58.59%] [G loss: 0.888290]\n",
      "epoch:19 step:18006 [D loss: 0.723398, acc.: 47.66%] [G loss: 0.897877]\n",
      "epoch:19 step:18007 [D loss: 0.630430, acc.: 57.81%] [G loss: 0.919659]\n",
      "epoch:19 step:18008 [D loss: 0.632689, acc.: 66.41%] [G loss: 0.950940]\n",
      "epoch:19 step:18009 [D loss: 0.606421, acc.: 66.41%] [G loss: 0.924115]\n",
      "epoch:19 step:18010 [D loss: 0.674792, acc.: 57.03%] [G loss: 0.942331]\n",
      "epoch:19 step:18011 [D loss: 0.614827, acc.: 64.84%] [G loss: 0.892644]\n",
      "epoch:19 step:18012 [D loss: 0.592469, acc.: 67.19%] [G loss: 0.949249]\n",
      "epoch:19 step:18013 [D loss: 0.734621, acc.: 50.00%] [G loss: 0.952423]\n",
      "epoch:19 step:18014 [D loss: 0.685665, acc.: 58.59%] [G loss: 0.805683]\n",
      "epoch:19 step:18015 [D loss: 0.712130, acc.: 55.47%] [G loss: 0.833112]\n",
      "epoch:19 step:18016 [D loss: 0.690781, acc.: 53.91%] [G loss: 0.938223]\n",
      "epoch:19 step:18017 [D loss: 0.714680, acc.: 52.34%] [G loss: 0.893321]\n",
      "epoch:19 step:18018 [D loss: 0.685623, acc.: 52.34%] [G loss: 0.859933]\n",
      "epoch:19 step:18019 [D loss: 0.652412, acc.: 60.16%] [G loss: 0.938366]\n",
      "epoch:19 step:18020 [D loss: 0.646020, acc.: 60.16%] [G loss: 0.894275]\n",
      "epoch:19 step:18021 [D loss: 0.609524, acc.: 63.28%] [G loss: 0.887395]\n",
      "epoch:19 step:18022 [D loss: 0.611644, acc.: 67.19%] [G loss: 0.882826]\n",
      "epoch:19 step:18023 [D loss: 0.728520, acc.: 50.00%] [G loss: 0.929652]\n",
      "epoch:19 step:18024 [D loss: 0.642585, acc.: 61.72%] [G loss: 0.977684]\n",
      "epoch:19 step:18025 [D loss: 0.604051, acc.: 64.84%] [G loss: 0.981636]\n",
      "epoch:19 step:18026 [D loss: 0.591867, acc.: 71.09%] [G loss: 1.009486]\n",
      "epoch:19 step:18027 [D loss: 0.674637, acc.: 57.81%] [G loss: 0.831878]\n",
      "epoch:19 step:18028 [D loss: 0.689434, acc.: 52.34%] [G loss: 0.862857]\n",
      "epoch:19 step:18029 [D loss: 0.661983, acc.: 57.81%] [G loss: 0.862096]\n",
      "epoch:19 step:18030 [D loss: 0.658546, acc.: 61.72%] [G loss: 0.844530]\n",
      "epoch:19 step:18031 [D loss: 0.633871, acc.: 63.28%] [G loss: 0.869298]\n",
      "epoch:19 step:18032 [D loss: 0.610090, acc.: 67.19%] [G loss: 0.907982]\n",
      "epoch:19 step:18033 [D loss: 0.614132, acc.: 59.38%] [G loss: 0.934173]\n",
      "epoch:19 step:18034 [D loss: 0.580271, acc.: 66.41%] [G loss: 0.977878]\n",
      "epoch:19 step:18035 [D loss: 0.533012, acc.: 75.00%] [G loss: 1.066639]\n",
      "epoch:19 step:18036 [D loss: 0.679384, acc.: 58.59%] [G loss: 0.978773]\n",
      "epoch:19 step:18037 [D loss: 0.741230, acc.: 54.69%] [G loss: 0.870521]\n",
      "epoch:19 step:18038 [D loss: 0.674335, acc.: 62.50%] [G loss: 0.935328]\n",
      "epoch:19 step:18039 [D loss: 0.636967, acc.: 66.41%] [G loss: 0.908929]\n",
      "epoch:19 step:18040 [D loss: 0.632038, acc.: 68.75%] [G loss: 0.910752]\n",
      "epoch:19 step:18041 [D loss: 0.652432, acc.: 58.59%] [G loss: 0.867544]\n",
      "epoch:19 step:18042 [D loss: 0.650838, acc.: 59.38%] [G loss: 0.939744]\n",
      "epoch:19 step:18043 [D loss: 0.682090, acc.: 54.69%] [G loss: 0.878911]\n",
      "epoch:19 step:18044 [D loss: 0.651981, acc.: 64.06%] [G loss: 0.935990]\n",
      "epoch:19 step:18045 [D loss: 0.606376, acc.: 70.31%] [G loss: 1.009750]\n",
      "epoch:19 step:18046 [D loss: 0.629035, acc.: 63.28%] [G loss: 1.027577]\n",
      "epoch:19 step:18047 [D loss: 0.645657, acc.: 59.38%] [G loss: 1.019146]\n",
      "epoch:19 step:18048 [D loss: 0.637377, acc.: 64.84%] [G loss: 0.991786]\n",
      "epoch:19 step:18049 [D loss: 0.646102, acc.: 60.16%] [G loss: 0.984174]\n",
      "epoch:19 step:18050 [D loss: 0.648884, acc.: 62.50%] [G loss: 0.999227]\n",
      "epoch:19 step:18051 [D loss: 0.615861, acc.: 63.28%] [G loss: 0.971154]\n",
      "epoch:19 step:18052 [D loss: 0.754581, acc.: 50.00%] [G loss: 0.935172]\n",
      "epoch:19 step:18053 [D loss: 0.754359, acc.: 43.75%] [G loss: 0.858461]\n",
      "epoch:19 step:18054 [D loss: 0.693879, acc.: 51.56%] [G loss: 0.890677]\n",
      "epoch:19 step:18055 [D loss: 0.671362, acc.: 60.16%] [G loss: 0.877602]\n",
      "epoch:19 step:18056 [D loss: 0.655262, acc.: 60.94%] [G loss: 0.956506]\n",
      "epoch:19 step:18057 [D loss: 0.648421, acc.: 64.84%] [G loss: 0.895185]\n",
      "epoch:19 step:18058 [D loss: 0.633911, acc.: 61.72%] [G loss: 0.897783]\n",
      "epoch:19 step:18059 [D loss: 0.610899, acc.: 72.66%] [G loss: 0.899296]\n",
      "epoch:19 step:18060 [D loss: 0.642888, acc.: 60.94%] [G loss: 0.915109]\n",
      "epoch:19 step:18061 [D loss: 0.642045, acc.: 64.06%] [G loss: 0.873675]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18062 [D loss: 0.649460, acc.: 59.38%] [G loss: 0.919790]\n",
      "epoch:19 step:18063 [D loss: 0.691789, acc.: 57.03%] [G loss: 0.848809]\n",
      "epoch:19 step:18064 [D loss: 0.603132, acc.: 66.41%] [G loss: 0.926338]\n",
      "epoch:19 step:18065 [D loss: 0.595069, acc.: 63.28%] [G loss: 0.924784]\n",
      "epoch:19 step:18066 [D loss: 0.697251, acc.: 60.94%] [G loss: 0.897124]\n",
      "epoch:19 step:18067 [D loss: 0.615586, acc.: 64.84%] [G loss: 0.844976]\n",
      "epoch:19 step:18068 [D loss: 0.638357, acc.: 69.53%] [G loss: 0.825194]\n",
      "epoch:19 step:18069 [D loss: 0.690309, acc.: 51.56%] [G loss: 0.946542]\n",
      "epoch:19 step:18070 [D loss: 0.641467, acc.: 64.84%] [G loss: 0.915589]\n",
      "epoch:19 step:18071 [D loss: 0.680305, acc.: 60.16%] [G loss: 0.897983]\n",
      "epoch:19 step:18072 [D loss: 0.657020, acc.: 56.25%] [G loss: 0.898213]\n",
      "epoch:19 step:18073 [D loss: 0.662441, acc.: 60.16%] [G loss: 0.952744]\n",
      "epoch:19 step:18074 [D loss: 0.625254, acc.: 67.97%] [G loss: 0.954722]\n",
      "epoch:19 step:18075 [D loss: 0.637152, acc.: 64.84%] [G loss: 0.981334]\n",
      "epoch:19 step:18076 [D loss: 0.665999, acc.: 62.50%] [G loss: 0.877292]\n",
      "epoch:19 step:18077 [D loss: 0.654954, acc.: 60.94%] [G loss: 0.947977]\n",
      "epoch:19 step:18078 [D loss: 0.670846, acc.: 58.59%] [G loss: 0.924781]\n",
      "epoch:19 step:18079 [D loss: 0.619746, acc.: 65.62%] [G loss: 0.891018]\n",
      "epoch:19 step:18080 [D loss: 0.681703, acc.: 55.47%] [G loss: 0.870876]\n",
      "epoch:19 step:18081 [D loss: 0.732652, acc.: 44.53%] [G loss: 0.878193]\n",
      "epoch:19 step:18082 [D loss: 0.677987, acc.: 57.81%] [G loss: 0.939205]\n",
      "epoch:19 step:18083 [D loss: 0.640618, acc.: 61.72%] [G loss: 0.929161]\n",
      "epoch:19 step:18084 [D loss: 0.687599, acc.: 56.25%] [G loss: 0.903578]\n",
      "epoch:19 step:18085 [D loss: 0.644006, acc.: 64.06%] [G loss: 0.829587]\n",
      "epoch:19 step:18086 [D loss: 0.606269, acc.: 68.75%] [G loss: 0.879235]\n",
      "epoch:19 step:18087 [D loss: 0.629204, acc.: 64.84%] [G loss: 0.933035]\n",
      "epoch:19 step:18088 [D loss: 0.645494, acc.: 63.28%] [G loss: 0.835424]\n",
      "epoch:19 step:18089 [D loss: 0.613654, acc.: 68.75%] [G loss: 0.933156]\n",
      "epoch:19 step:18090 [D loss: 0.658743, acc.: 63.28%] [G loss: 0.944335]\n",
      "epoch:19 step:18091 [D loss: 0.660115, acc.: 63.28%] [G loss: 0.918858]\n",
      "epoch:19 step:18092 [D loss: 0.625174, acc.: 67.19%] [G loss: 0.964814]\n",
      "epoch:19 step:18093 [D loss: 0.700291, acc.: 54.69%] [G loss: 0.996989]\n",
      "epoch:19 step:18094 [D loss: 0.672189, acc.: 60.16%] [G loss: 0.938096]\n",
      "epoch:19 step:18095 [D loss: 0.649893, acc.: 61.72%] [G loss: 0.888582]\n",
      "epoch:19 step:18096 [D loss: 0.634098, acc.: 66.41%] [G loss: 0.848125]\n",
      "epoch:19 step:18097 [D loss: 0.723846, acc.: 49.22%] [G loss: 0.861616]\n",
      "epoch:19 step:18098 [D loss: 0.650071, acc.: 60.16%] [G loss: 0.870718]\n",
      "epoch:19 step:18099 [D loss: 0.646473, acc.: 62.50%] [G loss: 0.890681]\n",
      "epoch:19 step:18100 [D loss: 0.660043, acc.: 59.38%] [G loss: 0.930665]\n",
      "epoch:19 step:18101 [D loss: 0.635614, acc.: 65.62%] [G loss: 0.895732]\n",
      "epoch:19 step:18102 [D loss: 0.631887, acc.: 65.62%] [G loss: 0.984359]\n",
      "epoch:19 step:18103 [D loss: 0.624441, acc.: 69.53%] [G loss: 1.004217]\n",
      "epoch:19 step:18104 [D loss: 0.695525, acc.: 56.25%] [G loss: 0.885670]\n",
      "epoch:19 step:18105 [D loss: 0.644636, acc.: 62.50%] [G loss: 0.908061]\n",
      "epoch:19 step:18106 [D loss: 0.673441, acc.: 57.81%] [G loss: 0.863506]\n",
      "epoch:19 step:18107 [D loss: 0.664520, acc.: 59.38%] [G loss: 0.936218]\n",
      "epoch:19 step:18108 [D loss: 0.630459, acc.: 67.19%] [G loss: 0.985732]\n",
      "epoch:19 step:18109 [D loss: 0.642698, acc.: 60.94%] [G loss: 0.948944]\n",
      "epoch:19 step:18110 [D loss: 0.621283, acc.: 65.62%] [G loss: 0.977399]\n",
      "epoch:19 step:18111 [D loss: 0.684579, acc.: 53.91%] [G loss: 0.838267]\n",
      "epoch:19 step:18112 [D loss: 0.609219, acc.: 70.31%] [G loss: 0.904616]\n",
      "epoch:19 step:18113 [D loss: 0.652479, acc.: 64.06%] [G loss: 0.851356]\n",
      "epoch:19 step:18114 [D loss: 0.651515, acc.: 64.06%] [G loss: 0.933677]\n",
      "epoch:19 step:18115 [D loss: 0.612121, acc.: 63.28%] [G loss: 1.042040]\n",
      "epoch:19 step:18116 [D loss: 0.604336, acc.: 67.19%] [G loss: 0.992975]\n",
      "epoch:19 step:18117 [D loss: 0.596455, acc.: 64.06%] [G loss: 1.060407]\n",
      "epoch:19 step:18118 [D loss: 0.587801, acc.: 65.62%] [G loss: 1.016911]\n",
      "epoch:19 step:18119 [D loss: 0.795542, acc.: 51.56%] [G loss: 0.948984]\n",
      "epoch:19 step:18120 [D loss: 0.729810, acc.: 46.88%] [G loss: 0.921579]\n",
      "epoch:19 step:18121 [D loss: 0.637389, acc.: 60.16%] [G loss: 0.889238]\n",
      "epoch:19 step:18122 [D loss: 0.638946, acc.: 61.72%] [G loss: 0.936162]\n",
      "epoch:19 step:18123 [D loss: 0.658375, acc.: 59.38%] [G loss: 0.907173]\n",
      "epoch:19 step:18124 [D loss: 0.681976, acc.: 57.81%] [G loss: 0.902339]\n",
      "epoch:19 step:18125 [D loss: 0.628293, acc.: 66.41%] [G loss: 0.904217]\n",
      "epoch:19 step:18126 [D loss: 0.687483, acc.: 51.56%] [G loss: 0.947142]\n",
      "epoch:19 step:18127 [D loss: 0.706014, acc.: 55.47%] [G loss: 0.873818]\n",
      "epoch:19 step:18128 [D loss: 0.665381, acc.: 58.59%] [G loss: 0.900006]\n",
      "epoch:19 step:18129 [D loss: 0.642795, acc.: 62.50%] [G loss: 0.942395]\n",
      "epoch:19 step:18130 [D loss: 0.674286, acc.: 57.03%] [G loss: 0.949533]\n",
      "epoch:19 step:18131 [D loss: 0.619023, acc.: 63.28%] [G loss: 0.955954]\n",
      "epoch:19 step:18132 [D loss: 0.668689, acc.: 62.50%] [G loss: 0.868572]\n",
      "epoch:19 step:18133 [D loss: 0.619594, acc.: 65.62%] [G loss: 0.862913]\n",
      "epoch:19 step:18134 [D loss: 0.639785, acc.: 64.84%] [G loss: 0.956938]\n",
      "epoch:19 step:18135 [D loss: 0.645124, acc.: 58.59%] [G loss: 0.930563]\n",
      "epoch:19 step:18136 [D loss: 0.631273, acc.: 63.28%] [G loss: 0.894558]\n",
      "epoch:19 step:18137 [D loss: 0.650102, acc.: 59.38%] [G loss: 0.923945]\n",
      "epoch:19 step:18138 [D loss: 0.641809, acc.: 60.16%] [G loss: 0.964550]\n",
      "epoch:19 step:18139 [D loss: 0.664021, acc.: 68.75%] [G loss: 0.921298]\n",
      "epoch:19 step:18140 [D loss: 0.640856, acc.: 67.97%] [G loss: 0.879224]\n",
      "epoch:19 step:18141 [D loss: 0.660986, acc.: 62.50%] [G loss: 0.911399]\n",
      "epoch:19 step:18142 [D loss: 0.619300, acc.: 69.53%] [G loss: 0.895646]\n",
      "epoch:19 step:18143 [D loss: 0.672952, acc.: 62.50%] [G loss: 0.942541]\n",
      "epoch:19 step:18144 [D loss: 0.715911, acc.: 53.91%] [G loss: 0.936939]\n",
      "epoch:19 step:18145 [D loss: 0.656605, acc.: 57.03%] [G loss: 1.021628]\n",
      "epoch:19 step:18146 [D loss: 0.609114, acc.: 68.75%] [G loss: 0.923262]\n",
      "epoch:19 step:18147 [D loss: 0.609076, acc.: 65.62%] [G loss: 0.935976]\n",
      "epoch:19 step:18148 [D loss: 0.655110, acc.: 57.03%] [G loss: 0.934810]\n",
      "epoch:19 step:18149 [D loss: 0.627437, acc.: 65.62%] [G loss: 0.967089]\n",
      "epoch:19 step:18150 [D loss: 0.573727, acc.: 71.88%] [G loss: 0.982335]\n",
      "epoch:19 step:18151 [D loss: 0.724781, acc.: 53.91%] [G loss: 0.879285]\n",
      "epoch:19 step:18152 [D loss: 0.757102, acc.: 49.22%] [G loss: 0.885786]\n",
      "epoch:19 step:18153 [D loss: 0.639850, acc.: 57.81%] [G loss: 0.862794]\n",
      "epoch:19 step:18154 [D loss: 0.690602, acc.: 51.56%] [G loss: 0.822476]\n",
      "epoch:19 step:18155 [D loss: 0.636458, acc.: 64.84%] [G loss: 0.886377]\n",
      "epoch:19 step:18156 [D loss: 0.603529, acc.: 68.75%] [G loss: 0.876332]\n",
      "epoch:19 step:18157 [D loss: 0.603410, acc.: 71.09%] [G loss: 0.942295]\n",
      "epoch:19 step:18158 [D loss: 0.683860, acc.: 55.47%] [G loss: 0.972729]\n",
      "epoch:19 step:18159 [D loss: 0.672178, acc.: 57.81%] [G loss: 0.992343]\n",
      "epoch:19 step:18160 [D loss: 0.683802, acc.: 57.03%] [G loss: 0.911224]\n",
      "epoch:19 step:18161 [D loss: 0.601700, acc.: 65.62%] [G loss: 0.934786]\n",
      "epoch:19 step:18162 [D loss: 0.648727, acc.: 62.50%] [G loss: 0.955541]\n",
      "epoch:19 step:18163 [D loss: 0.633469, acc.: 60.94%] [G loss: 0.972081]\n",
      "epoch:19 step:18164 [D loss: 0.656765, acc.: 64.84%] [G loss: 0.895491]\n",
      "epoch:19 step:18165 [D loss: 0.686632, acc.: 54.69%] [G loss: 0.923185]\n",
      "epoch:19 step:18166 [D loss: 0.634994, acc.: 64.84%] [G loss: 0.944769]\n",
      "epoch:19 step:18167 [D loss: 0.638097, acc.: 61.72%] [G loss: 0.988693]\n",
      "epoch:19 step:18168 [D loss: 0.666462, acc.: 60.16%] [G loss: 0.923214]\n",
      "epoch:19 step:18169 [D loss: 0.648941, acc.: 62.50%] [G loss: 0.900510]\n",
      "epoch:19 step:18170 [D loss: 0.615628, acc.: 70.31%] [G loss: 0.910176]\n",
      "epoch:19 step:18171 [D loss: 0.634911, acc.: 67.19%] [G loss: 0.910382]\n",
      "epoch:19 step:18172 [D loss: 0.660658, acc.: 57.03%] [G loss: 0.928814]\n",
      "epoch:19 step:18173 [D loss: 0.601673, acc.: 70.31%] [G loss: 0.918424]\n",
      "epoch:19 step:18174 [D loss: 0.609972, acc.: 67.97%] [G loss: 0.909027]\n",
      "epoch:19 step:18175 [D loss: 0.669085, acc.: 54.69%] [G loss: 0.929648]\n",
      "epoch:19 step:18176 [D loss: 0.684925, acc.: 59.38%] [G loss: 0.894601]\n",
      "epoch:19 step:18177 [D loss: 0.627002, acc.: 60.94%] [G loss: 0.998475]\n",
      "epoch:19 step:18178 [D loss: 0.678554, acc.: 62.50%] [G loss: 0.909465]\n",
      "epoch:19 step:18179 [D loss: 0.713529, acc.: 50.78%] [G loss: 0.989570]\n",
      "epoch:19 step:18180 [D loss: 0.684717, acc.: 60.16%] [G loss: 0.891816]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18181 [D loss: 0.715871, acc.: 53.91%] [G loss: 0.914339]\n",
      "epoch:19 step:18182 [D loss: 0.653595, acc.: 64.84%] [G loss: 0.965320]\n",
      "epoch:19 step:18183 [D loss: 0.662527, acc.: 60.16%] [G loss: 0.880960]\n",
      "epoch:19 step:18184 [D loss: 0.649249, acc.: 61.72%] [G loss: 0.933631]\n",
      "epoch:19 step:18185 [D loss: 0.668430, acc.: 64.06%] [G loss: 0.880711]\n",
      "epoch:19 step:18186 [D loss: 0.659674, acc.: 59.38%] [G loss: 0.869520]\n",
      "epoch:19 step:18187 [D loss: 0.650016, acc.: 60.16%] [G loss: 0.919112]\n",
      "epoch:19 step:18188 [D loss: 0.638174, acc.: 63.28%] [G loss: 0.945873]\n",
      "epoch:19 step:18189 [D loss: 0.667789, acc.: 61.72%] [G loss: 0.906370]\n",
      "epoch:19 step:18190 [D loss: 0.649600, acc.: 60.94%] [G loss: 0.880760]\n",
      "epoch:19 step:18191 [D loss: 0.651915, acc.: 62.50%] [G loss: 0.957267]\n",
      "epoch:19 step:18192 [D loss: 0.684994, acc.: 58.59%] [G loss: 0.925621]\n",
      "epoch:19 step:18193 [D loss: 0.656333, acc.: 60.16%] [G loss: 0.851353]\n",
      "epoch:19 step:18194 [D loss: 0.670434, acc.: 60.94%] [G loss: 0.903821]\n",
      "epoch:19 step:18195 [D loss: 0.632501, acc.: 66.41%] [G loss: 0.900423]\n",
      "epoch:19 step:18196 [D loss: 0.692449, acc.: 55.47%] [G loss: 0.837007]\n",
      "epoch:19 step:18197 [D loss: 0.643730, acc.: 65.62%] [G loss: 0.843480]\n",
      "epoch:19 step:18198 [D loss: 0.650333, acc.: 65.62%] [G loss: 0.891665]\n",
      "epoch:19 step:18199 [D loss: 0.676177, acc.: 57.03%] [G loss: 0.931034]\n",
      "epoch:19 step:18200 [D loss: 0.637028, acc.: 64.06%] [G loss: 0.958207]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.078315\n",
      "FID: 9.391243\n",
      "0 = 11.640595833134697\n",
      "1 = 0.047785499279019934\n",
      "2 = 0.894599974155426\n",
      "3 = 0.8458999991416931\n",
      "4 = 0.9433000087738037\n",
      "5 = 0.9371814727783203\n",
      "6 = 0.8458999991416931\n",
      "7 = 5.824653918999438\n",
      "8 = 0.06264669369241141\n",
      "9 = 0.6988999843597412\n",
      "10 = 0.680899977684021\n",
      "11 = 0.7168999910354614\n",
      "12 = 0.7063277959823608\n",
      "13 = 0.680899977684021\n",
      "14 = 8.078384399414062\n",
      "15 = 9.516294479370117\n",
      "16 = 0.11541841179132462\n",
      "17 = 8.078314781188965\n",
      "18 = 9.391242980957031\n",
      "epoch:19 step:18201 [D loss: 0.615446, acc.: 68.75%] [G loss: 0.943762]\n",
      "epoch:19 step:18202 [D loss: 0.633001, acc.: 66.41%] [G loss: 1.019480]\n",
      "epoch:19 step:18203 [D loss: 0.711331, acc.: 53.12%] [G loss: 0.846795]\n",
      "epoch:19 step:18204 [D loss: 0.679381, acc.: 57.81%] [G loss: 0.832068]\n",
      "epoch:19 step:18205 [D loss: 0.623560, acc.: 68.75%] [G loss: 0.880099]\n",
      "epoch:19 step:18206 [D loss: 0.611997, acc.: 69.53%] [G loss: 0.819852]\n",
      "epoch:19 step:18207 [D loss: 0.645584, acc.: 60.94%] [G loss: 0.879216]\n",
      "epoch:19 step:18208 [D loss: 0.685362, acc.: 56.25%] [G loss: 1.023026]\n",
      "epoch:19 step:18209 [D loss: 0.608553, acc.: 65.62%] [G loss: 1.011619]\n",
      "epoch:19 step:18210 [D loss: 0.646813, acc.: 62.50%] [G loss: 0.950114]\n",
      "epoch:19 step:18211 [D loss: 0.708804, acc.: 56.25%] [G loss: 0.914472]\n",
      "epoch:19 step:18212 [D loss: 0.661965, acc.: 60.16%] [G loss: 0.890086]\n",
      "epoch:19 step:18213 [D loss: 0.705092, acc.: 49.22%] [G loss: 0.886803]\n",
      "epoch:19 step:18214 [D loss: 0.719608, acc.: 47.66%] [G loss: 0.883012]\n",
      "epoch:19 step:18215 [D loss: 0.721150, acc.: 49.22%] [G loss: 0.926121]\n",
      "epoch:19 step:18216 [D loss: 0.691450, acc.: 61.72%] [G loss: 0.831136]\n",
      "epoch:19 step:18217 [D loss: 0.626956, acc.: 64.06%] [G loss: 0.901615]\n",
      "epoch:19 step:18218 [D loss: 0.596938, acc.: 66.41%] [G loss: 0.935490]\n",
      "epoch:19 step:18219 [D loss: 0.641736, acc.: 60.16%] [G loss: 0.955151]\n",
      "epoch:19 step:18220 [D loss: 0.688215, acc.: 58.59%] [G loss: 0.935515]\n",
      "epoch:19 step:18221 [D loss: 0.648180, acc.: 66.41%] [G loss: 0.913023]\n",
      "epoch:19 step:18222 [D loss: 0.709066, acc.: 55.47%] [G loss: 0.906810]\n",
      "epoch:19 step:18223 [D loss: 0.618295, acc.: 63.28%] [G loss: 0.915939]\n",
      "epoch:19 step:18224 [D loss: 0.663304, acc.: 61.72%] [G loss: 0.928711]\n",
      "epoch:19 step:18225 [D loss: 0.710351, acc.: 50.00%] [G loss: 0.970958]\n",
      "epoch:19 step:18226 [D loss: 0.666625, acc.: 64.06%] [G loss: 0.919351]\n",
      "epoch:19 step:18227 [D loss: 0.682792, acc.: 59.38%] [G loss: 0.923009]\n",
      "epoch:19 step:18228 [D loss: 0.699445, acc.: 56.25%] [G loss: 0.853510]\n",
      "epoch:19 step:18229 [D loss: 0.643358, acc.: 65.62%] [G loss: 0.814689]\n",
      "epoch:19 step:18230 [D loss: 0.705763, acc.: 55.47%] [G loss: 0.898058]\n",
      "epoch:19 step:18231 [D loss: 0.622495, acc.: 64.06%] [G loss: 0.852250]\n",
      "epoch:19 step:18232 [D loss: 0.636722, acc.: 67.19%] [G loss: 0.886486]\n",
      "epoch:19 step:18233 [D loss: 0.628359, acc.: 62.50%] [G loss: 0.953345]\n",
      "epoch:19 step:18234 [D loss: 0.661030, acc.: 62.50%] [G loss: 0.923789]\n",
      "epoch:19 step:18235 [D loss: 0.667835, acc.: 60.94%] [G loss: 0.981553]\n",
      "epoch:19 step:18236 [D loss: 0.639783, acc.: 62.50%] [G loss: 0.923165]\n",
      "epoch:19 step:18237 [D loss: 0.641773, acc.: 60.16%] [G loss: 0.894794]\n",
      "epoch:19 step:18238 [D loss: 0.644987, acc.: 59.38%] [G loss: 0.920230]\n",
      "epoch:19 step:18239 [D loss: 0.644559, acc.: 65.62%] [G loss: 0.945801]\n",
      "epoch:19 step:18240 [D loss: 0.762542, acc.: 47.66%] [G loss: 0.918317]\n",
      "epoch:19 step:18241 [D loss: 0.678296, acc.: 50.78%] [G loss: 0.945685]\n",
      "epoch:19 step:18242 [D loss: 0.677059, acc.: 54.69%] [G loss: 0.966574]\n",
      "epoch:19 step:18243 [D loss: 0.643047, acc.: 66.41%] [G loss: 0.963838]\n",
      "epoch:19 step:18244 [D loss: 0.678949, acc.: 57.81%] [G loss: 0.988770]\n",
      "epoch:19 step:18245 [D loss: 0.660458, acc.: 60.16%] [G loss: 0.952614]\n",
      "epoch:19 step:18246 [D loss: 0.613680, acc.: 72.66%] [G loss: 0.902756]\n",
      "epoch:19 step:18247 [D loss: 0.662739, acc.: 58.59%] [G loss: 0.933155]\n",
      "epoch:19 step:18248 [D loss: 0.585603, acc.: 69.53%] [G loss: 0.876971]\n",
      "epoch:19 step:18249 [D loss: 0.622554, acc.: 67.19%] [G loss: 0.965590]\n",
      "epoch:19 step:18250 [D loss: 0.603610, acc.: 67.97%] [G loss: 0.919713]\n",
      "epoch:19 step:18251 [D loss: 0.689763, acc.: 58.59%] [G loss: 0.945669]\n",
      "epoch:19 step:18252 [D loss: 0.655516, acc.: 60.16%] [G loss: 0.937135]\n",
      "epoch:19 step:18253 [D loss: 0.636640, acc.: 67.19%] [G loss: 0.843530]\n",
      "epoch:19 step:18254 [D loss: 0.633205, acc.: 64.06%] [G loss: 0.865556]\n",
      "epoch:19 step:18255 [D loss: 0.616846, acc.: 72.66%] [G loss: 0.959751]\n",
      "epoch:19 step:18256 [D loss: 0.643621, acc.: 60.16%] [G loss: 0.908663]\n",
      "epoch:19 step:18257 [D loss: 0.625121, acc.: 64.06%] [G loss: 0.902047]\n",
      "epoch:19 step:18258 [D loss: 0.737325, acc.: 47.66%] [G loss: 0.863685]\n",
      "epoch:19 step:18259 [D loss: 0.654817, acc.: 61.72%] [G loss: 0.938996]\n",
      "epoch:19 step:18260 [D loss: 0.645073, acc.: 64.06%] [G loss: 0.962322]\n",
      "epoch:19 step:18261 [D loss: 0.740784, acc.: 49.22%] [G loss: 0.915320]\n",
      "epoch:19 step:18262 [D loss: 0.702931, acc.: 51.56%] [G loss: 1.009646]\n",
      "epoch:19 step:18263 [D loss: 0.672312, acc.: 54.69%] [G loss: 0.892771]\n",
      "epoch:19 step:18264 [D loss: 0.658366, acc.: 62.50%] [G loss: 0.914388]\n",
      "epoch:19 step:18265 [D loss: 0.693562, acc.: 51.56%] [G loss: 0.892156]\n",
      "epoch:19 step:18266 [D loss: 0.682285, acc.: 54.69%] [G loss: 0.882186]\n",
      "epoch:19 step:18267 [D loss: 0.642960, acc.: 57.03%] [G loss: 0.875553]\n",
      "epoch:19 step:18268 [D loss: 0.704416, acc.: 55.47%] [G loss: 0.920917]\n",
      "epoch:19 step:18269 [D loss: 0.643495, acc.: 59.38%] [G loss: 0.971376]\n",
      "epoch:19 step:18270 [D loss: 0.640759, acc.: 63.28%] [G loss: 0.928937]\n",
      "epoch:19 step:18271 [D loss: 0.657516, acc.: 63.28%] [G loss: 0.887913]\n",
      "epoch:19 step:18272 [D loss: 0.651103, acc.: 63.28%] [G loss: 0.998405]\n",
      "epoch:19 step:18273 [D loss: 0.675783, acc.: 56.25%] [G loss: 0.968063]\n",
      "epoch:19 step:18274 [D loss: 0.628178, acc.: 63.28%] [G loss: 0.980877]\n",
      "epoch:19 step:18275 [D loss: 0.648729, acc.: 61.72%] [G loss: 0.970578]\n",
      "epoch:19 step:18276 [D loss: 0.655270, acc.: 59.38%] [G loss: 0.920904]\n",
      "epoch:19 step:18277 [D loss: 0.639328, acc.: 61.72%] [G loss: 0.887290]\n",
      "epoch:19 step:18278 [D loss: 0.709522, acc.: 56.25%] [G loss: 0.901864]\n",
      "epoch:19 step:18279 [D loss: 0.691340, acc.: 55.47%] [G loss: 0.942121]\n",
      "epoch:19 step:18280 [D loss: 0.721333, acc.: 55.47%] [G loss: 0.877344]\n",
      "epoch:19 step:18281 [D loss: 0.657889, acc.: 61.72%] [G loss: 0.894557]\n",
      "epoch:19 step:18282 [D loss: 0.625388, acc.: 71.09%] [G loss: 0.881436]\n",
      "epoch:19 step:18283 [D loss: 0.616158, acc.: 64.06%] [G loss: 0.912731]\n",
      "epoch:19 step:18284 [D loss: 0.597171, acc.: 73.44%] [G loss: 0.879675]\n",
      "epoch:19 step:18285 [D loss: 0.741929, acc.: 46.88%] [G loss: 0.899989]\n",
      "epoch:19 step:18286 [D loss: 0.681713, acc.: 57.03%] [G loss: 0.884047]\n",
      "epoch:19 step:18287 [D loss: 0.653051, acc.: 63.28%] [G loss: 0.952574]\n",
      "epoch:19 step:18288 [D loss: 0.608193, acc.: 69.53%] [G loss: 0.906841]\n",
      "epoch:19 step:18289 [D loss: 0.644088, acc.: 60.94%] [G loss: 0.914066]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18290 [D loss: 0.664693, acc.: 54.69%] [G loss: 0.861961]\n",
      "epoch:19 step:18291 [D loss: 0.592868, acc.: 70.31%] [G loss: 0.869020]\n",
      "epoch:19 step:18292 [D loss: 0.698652, acc.: 57.81%] [G loss: 0.890754]\n",
      "epoch:19 step:18293 [D loss: 0.680103, acc.: 59.38%] [G loss: 0.915453]\n",
      "epoch:19 step:18294 [D loss: 0.647978, acc.: 60.16%] [G loss: 0.926543]\n",
      "epoch:19 step:18295 [D loss: 0.681359, acc.: 55.47%] [G loss: 0.892470]\n",
      "epoch:19 step:18296 [D loss: 0.644094, acc.: 62.50%] [G loss: 0.885034]\n",
      "epoch:19 step:18297 [D loss: 0.641925, acc.: 64.06%] [G loss: 0.878724]\n",
      "epoch:19 step:18298 [D loss: 0.621112, acc.: 66.41%] [G loss: 0.869895]\n",
      "epoch:19 step:18299 [D loss: 0.614570, acc.: 69.53%] [G loss: 0.970269]\n",
      "epoch:19 step:18300 [D loss: 0.641743, acc.: 54.69%] [G loss: 0.894080]\n",
      "epoch:19 step:18301 [D loss: 0.642817, acc.: 57.81%] [G loss: 0.904516]\n",
      "epoch:19 step:18302 [D loss: 0.584276, acc.: 72.66%] [G loss: 0.915371]\n",
      "epoch:19 step:18303 [D loss: 0.727413, acc.: 59.38%] [G loss: 0.936864]\n",
      "epoch:19 step:18304 [D loss: 0.753030, acc.: 52.34%] [G loss: 0.923062]\n",
      "epoch:19 step:18305 [D loss: 0.652310, acc.: 61.72%] [G loss: 0.982075]\n",
      "epoch:19 step:18306 [D loss: 0.665563, acc.: 60.94%] [G loss: 0.966331]\n",
      "epoch:19 step:18307 [D loss: 0.616776, acc.: 67.97%] [G loss: 0.958165]\n",
      "epoch:19 step:18308 [D loss: 0.627029, acc.: 60.16%] [G loss: 1.033404]\n",
      "epoch:19 step:18309 [D loss: 0.646232, acc.: 62.50%] [G loss: 0.983039]\n",
      "epoch:19 step:18310 [D loss: 0.615577, acc.: 67.19%] [G loss: 0.933368]\n",
      "epoch:19 step:18311 [D loss: 0.576074, acc.: 68.75%] [G loss: 1.082569]\n",
      "epoch:19 step:18312 [D loss: 0.677141, acc.: 60.94%] [G loss: 0.906023]\n",
      "epoch:19 step:18313 [D loss: 0.709888, acc.: 53.12%] [G loss: 0.898058]\n",
      "epoch:19 step:18314 [D loss: 0.688299, acc.: 54.69%] [G loss: 0.860922]\n",
      "epoch:19 step:18315 [D loss: 0.670615, acc.: 57.81%] [G loss: 0.868029]\n",
      "epoch:19 step:18316 [D loss: 0.647658, acc.: 63.28%] [G loss: 0.904452]\n",
      "epoch:19 step:18317 [D loss: 0.625034, acc.: 61.72%] [G loss: 0.876796]\n",
      "epoch:19 step:18318 [D loss: 0.648970, acc.: 60.94%] [G loss: 0.944319]\n",
      "epoch:19 step:18319 [D loss: 0.591606, acc.: 69.53%] [G loss: 0.897553]\n",
      "epoch:19 step:18320 [D loss: 0.688907, acc.: 59.38%] [G loss: 0.975509]\n",
      "epoch:19 step:18321 [D loss: 0.656218, acc.: 65.62%] [G loss: 0.886503]\n",
      "epoch:19 step:18322 [D loss: 0.592420, acc.: 66.41%] [G loss: 0.952602]\n",
      "epoch:19 step:18323 [D loss: 0.634497, acc.: 62.50%] [G loss: 0.923222]\n",
      "epoch:19 step:18324 [D loss: 0.606152, acc.: 67.97%] [G loss: 0.885550]\n",
      "epoch:19 step:18325 [D loss: 0.641513, acc.: 64.84%] [G loss: 0.961312]\n",
      "epoch:19 step:18326 [D loss: 0.619919, acc.: 65.62%] [G loss: 0.933390]\n",
      "epoch:19 step:18327 [D loss: 0.656091, acc.: 60.16%] [G loss: 0.898448]\n",
      "epoch:19 step:18328 [D loss: 0.654319, acc.: 63.28%] [G loss: 0.825157]\n",
      "epoch:19 step:18329 [D loss: 0.682558, acc.: 60.94%] [G loss: 0.950193]\n",
      "epoch:19 step:18330 [D loss: 0.702676, acc.: 54.69%] [G loss: 0.953040]\n",
      "epoch:19 step:18331 [D loss: 0.754413, acc.: 45.31%] [G loss: 0.829312]\n",
      "epoch:19 step:18332 [D loss: 0.701065, acc.: 55.47%] [G loss: 0.843830]\n",
      "epoch:19 step:18333 [D loss: 0.660047, acc.: 64.06%] [G loss: 0.928416]\n",
      "epoch:19 step:18334 [D loss: 0.682152, acc.: 55.47%] [G loss: 0.854105]\n",
      "epoch:19 step:18335 [D loss: 0.705137, acc.: 53.12%] [G loss: 0.817218]\n",
      "epoch:19 step:18336 [D loss: 0.641123, acc.: 64.06%] [G loss: 0.841748]\n",
      "epoch:19 step:18337 [D loss: 0.639039, acc.: 60.16%] [G loss: 0.940373]\n",
      "epoch:19 step:18338 [D loss: 0.657478, acc.: 57.03%] [G loss: 0.898605]\n",
      "epoch:19 step:18339 [D loss: 0.658554, acc.: 65.62%] [G loss: 0.934123]\n",
      "epoch:19 step:18340 [D loss: 0.695531, acc.: 50.78%] [G loss: 0.867937]\n",
      "epoch:19 step:18341 [D loss: 0.677650, acc.: 54.69%] [G loss: 0.850428]\n",
      "epoch:19 step:18342 [D loss: 0.652588, acc.: 58.59%] [G loss: 0.876722]\n",
      "epoch:19 step:18343 [D loss: 0.660060, acc.: 65.62%] [G loss: 0.918636]\n",
      "epoch:19 step:18344 [D loss: 0.641864, acc.: 60.94%] [G loss: 0.898139]\n",
      "epoch:19 step:18345 [D loss: 0.730906, acc.: 49.22%] [G loss: 0.833439]\n",
      "epoch:19 step:18346 [D loss: 0.674752, acc.: 57.81%] [G loss: 0.843102]\n",
      "epoch:19 step:18347 [D loss: 0.671907, acc.: 56.25%] [G loss: 0.932423]\n",
      "epoch:19 step:18348 [D loss: 0.670191, acc.: 58.59%] [G loss: 0.902882]\n",
      "epoch:19 step:18349 [D loss: 0.610654, acc.: 66.41%] [G loss: 0.921399]\n",
      "epoch:19 step:18350 [D loss: 0.625876, acc.: 62.50%] [G loss: 0.923939]\n",
      "epoch:19 step:18351 [D loss: 0.621836, acc.: 65.62%] [G loss: 0.911098]\n",
      "epoch:19 step:18352 [D loss: 0.630196, acc.: 69.53%] [G loss: 0.869609]\n",
      "epoch:19 step:18353 [D loss: 0.617481, acc.: 67.97%] [G loss: 0.911310]\n",
      "epoch:19 step:18354 [D loss: 0.606493, acc.: 67.19%] [G loss: 0.927435]\n",
      "epoch:19 step:18355 [D loss: 0.657269, acc.: 61.72%] [G loss: 0.900847]\n",
      "epoch:19 step:18356 [D loss: 0.667942, acc.: 60.16%] [G loss: 0.906049]\n",
      "epoch:19 step:18357 [D loss: 0.678480, acc.: 58.59%] [G loss: 0.924757]\n",
      "epoch:19 step:18358 [D loss: 0.625807, acc.: 61.72%] [G loss: 0.864341]\n",
      "epoch:19 step:18359 [D loss: 0.636168, acc.: 63.28%] [G loss: 0.898614]\n",
      "epoch:19 step:18360 [D loss: 0.644956, acc.: 62.50%] [G loss: 0.946841]\n",
      "epoch:19 step:18361 [D loss: 0.656411, acc.: 62.50%] [G loss: 0.920034]\n",
      "epoch:19 step:18362 [D loss: 0.675030, acc.: 60.16%] [G loss: 0.988426]\n",
      "epoch:19 step:18363 [D loss: 0.700484, acc.: 51.56%] [G loss: 0.913010]\n",
      "epoch:19 step:18364 [D loss: 0.671319, acc.: 56.25%] [G loss: 0.881554]\n",
      "epoch:19 step:18365 [D loss: 0.633368, acc.: 64.84%] [G loss: 0.943506]\n",
      "epoch:19 step:18366 [D loss: 0.623169, acc.: 66.41%] [G loss: 1.010128]\n",
      "epoch:19 step:18367 [D loss: 0.625399, acc.: 66.41%] [G loss: 1.040349]\n",
      "epoch:19 step:18368 [D loss: 0.671159, acc.: 60.94%] [G loss: 0.987587]\n",
      "epoch:19 step:18369 [D loss: 0.658212, acc.: 58.59%] [G loss: 1.027266]\n",
      "epoch:19 step:18370 [D loss: 0.617158, acc.: 69.53%] [G loss: 0.965843]\n",
      "epoch:19 step:18371 [D loss: 0.672538, acc.: 61.72%] [G loss: 0.941635]\n",
      "epoch:19 step:18372 [D loss: 0.703919, acc.: 57.03%] [G loss: 0.894029]\n",
      "epoch:19 step:18373 [D loss: 0.636131, acc.: 61.72%] [G loss: 0.883394]\n",
      "epoch:19 step:18374 [D loss: 0.617059, acc.: 66.41%] [G loss: 0.903637]\n",
      "epoch:19 step:18375 [D loss: 0.678762, acc.: 60.16%] [G loss: 0.891176]\n",
      "epoch:19 step:18376 [D loss: 0.618404, acc.: 64.84%] [G loss: 1.001586]\n",
      "epoch:19 step:18377 [D loss: 0.575080, acc.: 71.09%] [G loss: 1.002340]\n",
      "epoch:19 step:18378 [D loss: 0.610977, acc.: 64.06%] [G loss: 0.989518]\n",
      "epoch:19 step:18379 [D loss: 0.719013, acc.: 50.00%] [G loss: 0.992990]\n",
      "epoch:19 step:18380 [D loss: 0.650321, acc.: 67.19%] [G loss: 0.919245]\n",
      "epoch:19 step:18381 [D loss: 0.651529, acc.: 60.94%] [G loss: 0.926462]\n",
      "epoch:19 step:18382 [D loss: 0.686043, acc.: 55.47%] [G loss: 0.912120]\n",
      "epoch:19 step:18383 [D loss: 0.665908, acc.: 57.81%] [G loss: 0.835676]\n",
      "epoch:19 step:18384 [D loss: 0.568666, acc.: 76.56%] [G loss: 0.900935]\n",
      "epoch:19 step:18385 [D loss: 0.625081, acc.: 63.28%] [G loss: 0.952627]\n",
      "epoch:19 step:18386 [D loss: 0.653432, acc.: 62.50%] [G loss: 0.988498]\n",
      "epoch:19 step:18387 [D loss: 0.696468, acc.: 54.69%] [G loss: 0.957257]\n",
      "epoch:19 step:18388 [D loss: 0.598964, acc.: 67.19%] [G loss: 0.923345]\n",
      "epoch:19 step:18389 [D loss: 0.666391, acc.: 58.59%] [G loss: 0.916962]\n",
      "epoch:19 step:18390 [D loss: 0.667563, acc.: 61.72%] [G loss: 0.927167]\n",
      "epoch:19 step:18391 [D loss: 0.669891, acc.: 56.25%] [G loss: 0.948148]\n",
      "epoch:19 step:18392 [D loss: 0.645545, acc.: 59.38%] [G loss: 0.955654]\n",
      "epoch:19 step:18393 [D loss: 0.757577, acc.: 47.66%] [G loss: 0.890703]\n",
      "epoch:19 step:18394 [D loss: 0.659448, acc.: 59.38%] [G loss: 0.947116]\n",
      "epoch:19 step:18395 [D loss: 0.605096, acc.: 67.97%] [G loss: 0.961357]\n",
      "epoch:19 step:18396 [D loss: 0.646385, acc.: 62.50%] [G loss: 0.898574]\n",
      "epoch:19 step:18397 [D loss: 0.668331, acc.: 60.16%] [G loss: 0.901493]\n",
      "epoch:19 step:18398 [D loss: 0.621167, acc.: 67.19%] [G loss: 0.864868]\n",
      "epoch:19 step:18399 [D loss: 0.679769, acc.: 60.16%] [G loss: 0.925469]\n",
      "epoch:19 step:18400 [D loss: 0.731196, acc.: 48.44%] [G loss: 0.863445]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.286562\n",
      "FID: 4.810498\n",
      "0 = 11.716844733786548\n",
      "1 = 0.04632242666262274\n",
      "2 = 0.9009000062942505\n",
      "3 = 0.8579999804496765\n",
      "4 = 0.9437999725341797\n",
      "5 = 0.9385254979133606\n",
      "6 = 0.8579999804496765\n",
      "7 = 5.464324414354551\n",
      "8 = 0.04887083093369605\n",
      "9 = 0.6916499733924866\n",
      "10 = 0.6708999872207642\n",
      "11 = 0.7124000191688538\n",
      "12 = 0.6999478340148926\n",
      "13 = 0.6708999872207642\n",
      "14 = 8.286625862121582\n",
      "15 = 9.63024616241455\n",
      "16 = 0.0754188597202301\n",
      "17 = 8.286561965942383\n",
      "18 = 4.810498237609863\n",
      "epoch:19 step:18401 [D loss: 0.666019, acc.: 64.84%] [G loss: 0.857648]\n",
      "epoch:19 step:18402 [D loss: 0.694436, acc.: 54.69%] [G loss: 0.950637]\n",
      "epoch:19 step:18403 [D loss: 0.674658, acc.: 53.12%] [G loss: 0.829707]\n",
      "epoch:19 step:18404 [D loss: 0.678970, acc.: 56.25%] [G loss: 0.877411]\n",
      "epoch:19 step:18405 [D loss: 0.628142, acc.: 62.50%] [G loss: 0.877454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18406 [D loss: 0.656379, acc.: 61.72%] [G loss: 0.879160]\n",
      "epoch:19 step:18407 [D loss: 0.648182, acc.: 65.62%] [G loss: 0.908048]\n",
      "epoch:19 step:18408 [D loss: 0.664513, acc.: 60.94%] [G loss: 0.886731]\n",
      "epoch:19 step:18409 [D loss: 0.670410, acc.: 58.59%] [G loss: 0.891863]\n",
      "epoch:19 step:18410 [D loss: 0.648430, acc.: 60.16%] [G loss: 0.885573]\n",
      "epoch:19 step:18411 [D loss: 0.642674, acc.: 64.06%] [G loss: 0.844198]\n",
      "epoch:19 step:18412 [D loss: 0.642382, acc.: 61.72%] [G loss: 0.905230]\n",
      "epoch:19 step:18413 [D loss: 0.647092, acc.: 64.84%] [G loss: 0.860071]\n",
      "epoch:19 step:18414 [D loss: 0.619331, acc.: 66.41%] [G loss: 0.873756]\n",
      "epoch:19 step:18415 [D loss: 0.657196, acc.: 57.81%] [G loss: 0.884250]\n",
      "epoch:19 step:18416 [D loss: 0.686591, acc.: 53.12%] [G loss: 0.950293]\n",
      "epoch:19 step:18417 [D loss: 0.728812, acc.: 46.88%] [G loss: 0.880640]\n",
      "epoch:19 step:18418 [D loss: 0.729831, acc.: 50.78%] [G loss: 0.845906]\n",
      "epoch:19 step:18419 [D loss: 0.651343, acc.: 60.94%] [G loss: 0.874201]\n",
      "epoch:19 step:18420 [D loss: 0.615762, acc.: 66.41%] [G loss: 0.901145]\n",
      "epoch:19 step:18421 [D loss: 0.640349, acc.: 60.16%] [G loss: 0.927433]\n",
      "epoch:19 step:18422 [D loss: 0.709950, acc.: 57.81%] [G loss: 0.912318]\n",
      "epoch:19 step:18423 [D loss: 0.615691, acc.: 66.41%] [G loss: 0.923883]\n",
      "epoch:19 step:18424 [D loss: 0.659049, acc.: 58.59%] [G loss: 0.898654]\n",
      "epoch:19 step:18425 [D loss: 0.718230, acc.: 56.25%] [G loss: 0.812224]\n",
      "epoch:19 step:18426 [D loss: 0.664944, acc.: 60.16%] [G loss: 0.898021]\n",
      "epoch:19 step:18427 [D loss: 0.647645, acc.: 64.06%] [G loss: 0.875335]\n",
      "epoch:19 step:18428 [D loss: 0.672842, acc.: 57.03%] [G loss: 0.888294]\n",
      "epoch:19 step:18429 [D loss: 0.668713, acc.: 61.72%] [G loss: 0.872393]\n",
      "epoch:19 step:18430 [D loss: 0.618256, acc.: 67.19%] [G loss: 0.943381]\n",
      "epoch:19 step:18431 [D loss: 0.647117, acc.: 66.41%] [G loss: 0.898319]\n",
      "epoch:19 step:18432 [D loss: 0.634468, acc.: 63.28%] [G loss: 0.924106]\n",
      "epoch:19 step:18433 [D loss: 0.639410, acc.: 66.41%] [G loss: 0.942652]\n",
      "epoch:19 step:18434 [D loss: 0.641448, acc.: 64.06%] [G loss: 0.904286]\n",
      "epoch:19 step:18435 [D loss: 0.634982, acc.: 60.94%] [G loss: 0.923959]\n",
      "epoch:19 step:18436 [D loss: 0.710400, acc.: 56.25%] [G loss: 0.950177]\n",
      "epoch:19 step:18437 [D loss: 0.650378, acc.: 63.28%] [G loss: 0.928421]\n",
      "epoch:19 step:18438 [D loss: 0.617432, acc.: 64.84%] [G loss: 0.897471]\n",
      "epoch:19 step:18439 [D loss: 0.613943, acc.: 64.84%] [G loss: 0.945090]\n",
      "epoch:19 step:18440 [D loss: 0.648103, acc.: 63.28%] [G loss: 0.933692]\n",
      "epoch:19 step:18441 [D loss: 0.657454, acc.: 56.25%] [G loss: 0.865990]\n",
      "epoch:19 step:18442 [D loss: 0.635266, acc.: 64.84%] [G loss: 0.829684]\n",
      "epoch:19 step:18443 [D loss: 0.683899, acc.: 55.47%] [G loss: 0.898776]\n",
      "epoch:19 step:18444 [D loss: 0.634305, acc.: 64.84%] [G loss: 0.940944]\n",
      "epoch:19 step:18445 [D loss: 0.613136, acc.: 71.88%] [G loss: 0.962960]\n",
      "epoch:19 step:18446 [D loss: 0.623019, acc.: 63.28%] [G loss: 0.993185]\n",
      "epoch:19 step:18447 [D loss: 0.723455, acc.: 49.22%] [G loss: 0.898405]\n",
      "epoch:19 step:18448 [D loss: 0.662431, acc.: 57.81%] [G loss: 0.919814]\n",
      "epoch:19 step:18449 [D loss: 0.647926, acc.: 60.94%] [G loss: 0.939707]\n",
      "epoch:19 step:18450 [D loss: 0.605439, acc.: 66.41%] [G loss: 0.942431]\n",
      "epoch:19 step:18451 [D loss: 0.591675, acc.: 68.75%] [G loss: 0.947327]\n",
      "epoch:19 step:18452 [D loss: 0.672845, acc.: 62.50%] [G loss: 1.025236]\n",
      "epoch:19 step:18453 [D loss: 0.634465, acc.: 64.06%] [G loss: 1.008832]\n",
      "epoch:19 step:18454 [D loss: 0.630253, acc.: 65.62%] [G loss: 0.956877]\n",
      "epoch:19 step:18455 [D loss: 0.693919, acc.: 57.03%] [G loss: 0.907572]\n",
      "epoch:19 step:18456 [D loss: 0.655708, acc.: 61.72%] [G loss: 0.981536]\n",
      "epoch:19 step:18457 [D loss: 0.611988, acc.: 69.53%] [G loss: 1.000130]\n",
      "epoch:19 step:18458 [D loss: 0.673352, acc.: 60.16%] [G loss: 0.923932]\n",
      "epoch:19 step:18459 [D loss: 0.684500, acc.: 60.94%] [G loss: 0.984480]\n",
      "epoch:19 step:18460 [D loss: 0.664287, acc.: 60.16%] [G loss: 0.915305]\n",
      "epoch:19 step:18461 [D loss: 0.668752, acc.: 61.72%] [G loss: 0.918181]\n",
      "epoch:19 step:18462 [D loss: 0.615767, acc.: 65.62%] [G loss: 0.971677]\n",
      "epoch:19 step:18463 [D loss: 0.634094, acc.: 62.50%] [G loss: 0.938931]\n",
      "epoch:19 step:18464 [D loss: 0.589024, acc.: 70.31%] [G loss: 1.037634]\n",
      "epoch:19 step:18465 [D loss: 0.698198, acc.: 57.81%] [G loss: 0.956063]\n",
      "epoch:19 step:18466 [D loss: 0.701977, acc.: 50.78%] [G loss: 0.843649]\n",
      "epoch:19 step:18467 [D loss: 0.633328, acc.: 64.06%] [G loss: 0.872028]\n",
      "epoch:19 step:18468 [D loss: 0.676651, acc.: 56.25%] [G loss: 0.921005]\n",
      "epoch:19 step:18469 [D loss: 0.658050, acc.: 60.16%] [G loss: 0.914906]\n",
      "epoch:19 step:18470 [D loss: 0.641809, acc.: 62.50%] [G loss: 0.898430]\n",
      "epoch:19 step:18471 [D loss: 0.634180, acc.: 61.72%] [G loss: 0.921839]\n",
      "epoch:19 step:18472 [D loss: 0.672628, acc.: 60.16%] [G loss: 0.861451]\n",
      "epoch:19 step:18473 [D loss: 0.698982, acc.: 53.12%] [G loss: 0.878889]\n",
      "epoch:19 step:18474 [D loss: 0.705930, acc.: 50.78%] [G loss: 0.881676]\n",
      "epoch:19 step:18475 [D loss: 0.639271, acc.: 63.28%] [G loss: 0.932915]\n",
      "epoch:19 step:18476 [D loss: 0.674794, acc.: 57.81%] [G loss: 0.853790]\n",
      "epoch:19 step:18477 [D loss: 0.619987, acc.: 69.53%] [G loss: 0.934519]\n",
      "epoch:19 step:18478 [D loss: 0.680650, acc.: 57.03%] [G loss: 0.939962]\n",
      "epoch:19 step:18479 [D loss: 0.645835, acc.: 64.84%] [G loss: 0.865967]\n",
      "epoch:19 step:18480 [D loss: 0.596822, acc.: 67.19%] [G loss: 0.908826]\n",
      "epoch:19 step:18481 [D loss: 0.673123, acc.: 59.38%] [G loss: 0.892101]\n",
      "epoch:19 step:18482 [D loss: 0.657045, acc.: 63.28%] [G loss: 0.925175]\n",
      "epoch:19 step:18483 [D loss: 0.675795, acc.: 53.91%] [G loss: 0.934798]\n",
      "epoch:19 step:18484 [D loss: 0.617819, acc.: 66.41%] [G loss: 0.889308]\n",
      "epoch:19 step:18485 [D loss: 0.700924, acc.: 57.81%] [G loss: 0.899592]\n",
      "epoch:19 step:18486 [D loss: 0.671271, acc.: 58.59%] [G loss: 0.891747]\n",
      "epoch:19 step:18487 [D loss: 0.656564, acc.: 63.28%] [G loss: 0.965673]\n",
      "epoch:19 step:18488 [D loss: 0.684938, acc.: 59.38%] [G loss: 0.976032]\n",
      "epoch:19 step:18489 [D loss: 0.675928, acc.: 53.12%] [G loss: 0.893498]\n",
      "epoch:19 step:18490 [D loss: 0.629446, acc.: 64.84%] [G loss: 0.929257]\n",
      "epoch:19 step:18491 [D loss: 0.668014, acc.: 53.91%] [G loss: 0.902298]\n",
      "epoch:19 step:18492 [D loss: 0.710676, acc.: 53.12%] [G loss: 0.901164]\n",
      "epoch:19 step:18493 [D loss: 0.652105, acc.: 63.28%] [G loss: 0.918985]\n",
      "epoch:19 step:18494 [D loss: 0.601076, acc.: 67.19%] [G loss: 0.974978]\n",
      "epoch:19 step:18495 [D loss: 0.645818, acc.: 60.16%] [G loss: 1.060955]\n",
      "epoch:19 step:18496 [D loss: 0.668604, acc.: 60.16%] [G loss: 0.962787]\n",
      "epoch:19 step:18497 [D loss: 0.618505, acc.: 65.62%] [G loss: 1.052775]\n",
      "epoch:19 step:18498 [D loss: 0.647020, acc.: 65.62%] [G loss: 0.932678]\n",
      "epoch:19 step:18499 [D loss: 0.692919, acc.: 47.66%] [G loss: 0.919573]\n",
      "epoch:19 step:18500 [D loss: 0.669680, acc.: 61.72%] [G loss: 0.852406]\n",
      "epoch:19 step:18501 [D loss: 0.659021, acc.: 60.16%] [G loss: 0.876437]\n",
      "epoch:19 step:18502 [D loss: 0.671820, acc.: 56.25%] [G loss: 0.952943]\n",
      "epoch:19 step:18503 [D loss: 0.636456, acc.: 62.50%] [G loss: 0.937822]\n",
      "epoch:19 step:18504 [D loss: 0.603901, acc.: 67.97%] [G loss: 0.971814]\n",
      "epoch:19 step:18505 [D loss: 0.685820, acc.: 56.25%] [G loss: 1.003682]\n",
      "epoch:19 step:18506 [D loss: 0.697428, acc.: 57.81%] [G loss: 0.934873]\n",
      "epoch:19 step:18507 [D loss: 0.684613, acc.: 57.81%] [G loss: 0.899811]\n",
      "epoch:19 step:18508 [D loss: 0.672835, acc.: 57.03%] [G loss: 0.873325]\n",
      "epoch:19 step:18509 [D loss: 0.593675, acc.: 70.31%] [G loss: 0.981629]\n",
      "epoch:19 step:18510 [D loss: 0.624985, acc.: 64.06%] [G loss: 0.974212]\n",
      "epoch:19 step:18511 [D loss: 0.575969, acc.: 72.66%] [G loss: 0.884135]\n",
      "epoch:19 step:18512 [D loss: 0.601599, acc.: 70.31%] [G loss: 0.945496]\n",
      "epoch:19 step:18513 [D loss: 0.676337, acc.: 57.03%] [G loss: 0.972578]\n",
      "epoch:19 step:18514 [D loss: 0.662979, acc.: 55.47%] [G loss: 0.870544]\n",
      "epoch:19 step:18515 [D loss: 0.596916, acc.: 71.88%] [G loss: 0.938397]\n",
      "epoch:19 step:18516 [D loss: 0.670194, acc.: 57.81%] [G loss: 0.919273]\n",
      "epoch:19 step:18517 [D loss: 0.667801, acc.: 62.50%] [G loss: 0.993927]\n",
      "epoch:19 step:18518 [D loss: 0.688334, acc.: 53.12%] [G loss: 0.923302]\n",
      "epoch:19 step:18519 [D loss: 0.706836, acc.: 53.12%] [G loss: 0.875744]\n",
      "epoch:19 step:18520 [D loss: 0.661389, acc.: 60.16%] [G loss: 0.905938]\n",
      "epoch:19 step:18521 [D loss: 0.631151, acc.: 67.97%] [G loss: 0.891061]\n",
      "epoch:19 step:18522 [D loss: 0.607858, acc.: 62.50%] [G loss: 0.881549]\n",
      "epoch:19 step:18523 [D loss: 0.656559, acc.: 58.59%] [G loss: 0.996020]\n",
      "epoch:19 step:18524 [D loss: 0.688801, acc.: 53.12%] [G loss: 0.910336]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18525 [D loss: 0.751190, acc.: 48.44%] [G loss: 0.917001]\n",
      "epoch:19 step:18526 [D loss: 0.657644, acc.: 60.16%] [G loss: 0.939120]\n",
      "epoch:19 step:18527 [D loss: 0.601552, acc.: 71.88%] [G loss: 0.920728]\n",
      "epoch:19 step:18528 [D loss: 0.610502, acc.: 64.84%] [G loss: 1.060206]\n",
      "epoch:19 step:18529 [D loss: 0.695673, acc.: 53.12%] [G loss: 0.986731]\n",
      "epoch:19 step:18530 [D loss: 0.708396, acc.: 50.00%] [G loss: 0.920811]\n",
      "epoch:19 step:18531 [D loss: 0.645092, acc.: 67.97%] [G loss: 0.922431]\n",
      "epoch:19 step:18532 [D loss: 0.646653, acc.: 62.50%] [G loss: 0.909575]\n",
      "epoch:19 step:18533 [D loss: 0.589139, acc.: 71.09%] [G loss: 0.941995]\n",
      "epoch:19 step:18534 [D loss: 0.603018, acc.: 66.41%] [G loss: 0.895473]\n",
      "epoch:19 step:18535 [D loss: 0.596611, acc.: 66.41%] [G loss: 0.905955]\n",
      "epoch:19 step:18536 [D loss: 0.569382, acc.: 69.53%] [G loss: 0.921258]\n",
      "epoch:19 step:18537 [D loss: 0.676405, acc.: 63.28%] [G loss: 0.902134]\n",
      "epoch:19 step:18538 [D loss: 0.682078, acc.: 56.25%] [G loss: 0.863152]\n",
      "epoch:19 step:18539 [D loss: 0.654505, acc.: 60.94%] [G loss: 0.877471]\n",
      "epoch:19 step:18540 [D loss: 0.632462, acc.: 58.59%] [G loss: 0.825811]\n",
      "epoch:19 step:18541 [D loss: 0.695759, acc.: 57.03%] [G loss: 0.827810]\n",
      "epoch:19 step:18542 [D loss: 0.679724, acc.: 55.47%] [G loss: 0.824289]\n",
      "epoch:19 step:18543 [D loss: 0.671129, acc.: 55.47%] [G loss: 0.868257]\n",
      "epoch:19 step:18544 [D loss: 0.671582, acc.: 60.16%] [G loss: 0.892191]\n",
      "epoch:19 step:18545 [D loss: 0.653597, acc.: 64.84%] [G loss: 0.902137]\n",
      "epoch:19 step:18546 [D loss: 0.600564, acc.: 64.06%] [G loss: 0.925362]\n",
      "epoch:19 step:18547 [D loss: 0.697157, acc.: 61.72%] [G loss: 0.979978]\n",
      "epoch:19 step:18548 [D loss: 0.689110, acc.: 57.81%] [G loss: 0.924345]\n",
      "epoch:19 step:18549 [D loss: 0.630814, acc.: 62.50%] [G loss: 0.971172]\n",
      "epoch:19 step:18550 [D loss: 0.654804, acc.: 58.59%] [G loss: 0.986260]\n",
      "epoch:19 step:18551 [D loss: 0.649706, acc.: 62.50%] [G loss: 0.945538]\n",
      "epoch:19 step:18552 [D loss: 0.644661, acc.: 64.06%] [G loss: 0.916601]\n",
      "epoch:19 step:18553 [D loss: 0.636036, acc.: 66.41%] [G loss: 0.929093]\n",
      "epoch:19 step:18554 [D loss: 0.641197, acc.: 59.38%] [G loss: 0.998895]\n",
      "epoch:19 step:18555 [D loss: 0.665896, acc.: 58.59%] [G loss: 0.973755]\n",
      "epoch:19 step:18556 [D loss: 0.635294, acc.: 64.84%] [G loss: 0.906815]\n",
      "epoch:19 step:18557 [D loss: 0.640056, acc.: 65.62%] [G loss: 0.857535]\n",
      "epoch:19 step:18558 [D loss: 0.694215, acc.: 55.47%] [G loss: 0.890136]\n",
      "epoch:19 step:18559 [D loss: 0.646046, acc.: 57.81%] [G loss: 0.918092]\n",
      "epoch:19 step:18560 [D loss: 0.677738, acc.: 57.81%] [G loss: 0.984117]\n",
      "epoch:19 step:18561 [D loss: 0.681340, acc.: 57.81%] [G loss: 0.906649]\n",
      "epoch:19 step:18562 [D loss: 0.680415, acc.: 57.81%] [G loss: 0.923762]\n",
      "epoch:19 step:18563 [D loss: 0.670993, acc.: 58.59%] [G loss: 0.939144]\n",
      "epoch:19 step:18564 [D loss: 0.644903, acc.: 61.72%] [G loss: 0.931702]\n",
      "epoch:19 step:18565 [D loss: 0.685132, acc.: 53.91%] [G loss: 0.872638]\n",
      "epoch:19 step:18566 [D loss: 0.652605, acc.: 59.38%] [G loss: 0.900058]\n",
      "epoch:19 step:18567 [D loss: 0.727648, acc.: 50.00%] [G loss: 0.893616]\n",
      "epoch:19 step:18568 [D loss: 0.723705, acc.: 52.34%] [G loss: 0.886552]\n",
      "epoch:19 step:18569 [D loss: 0.694623, acc.: 53.12%] [G loss: 0.906722]\n",
      "epoch:19 step:18570 [D loss: 0.647332, acc.: 64.06%] [G loss: 0.937057]\n",
      "epoch:19 step:18571 [D loss: 0.684551, acc.: 57.81%] [G loss: 0.922582]\n",
      "epoch:19 step:18572 [D loss: 0.663622, acc.: 60.94%] [G loss: 0.919591]\n",
      "epoch:19 step:18573 [D loss: 0.639995, acc.: 60.94%] [G loss: 0.931350]\n",
      "epoch:19 step:18574 [D loss: 0.650626, acc.: 57.81%] [G loss: 0.973137]\n",
      "epoch:19 step:18575 [D loss: 0.695358, acc.: 56.25%] [G loss: 0.960520]\n",
      "epoch:19 step:18576 [D loss: 0.673670, acc.: 60.16%] [G loss: 1.017873]\n",
      "epoch:19 step:18577 [D loss: 0.710515, acc.: 55.47%] [G loss: 0.957083]\n",
      "epoch:19 step:18578 [D loss: 0.616231, acc.: 64.06%] [G loss: 0.996491]\n",
      "epoch:19 step:18579 [D loss: 0.637007, acc.: 63.28%] [G loss: 0.937036]\n",
      "epoch:19 step:18580 [D loss: 0.640146, acc.: 60.16%] [G loss: 0.901858]\n",
      "epoch:19 step:18581 [D loss: 0.650925, acc.: 62.50%] [G loss: 0.934632]\n",
      "epoch:19 step:18582 [D loss: 0.663476, acc.: 55.47%] [G loss: 0.896968]\n",
      "epoch:19 step:18583 [D loss: 0.694908, acc.: 56.25%] [G loss: 0.876046]\n",
      "epoch:19 step:18584 [D loss: 0.636101, acc.: 63.28%] [G loss: 0.923810]\n",
      "epoch:19 step:18585 [D loss: 0.611436, acc.: 66.41%] [G loss: 0.947304]\n",
      "epoch:19 step:18586 [D loss: 0.721937, acc.: 57.81%] [G loss: 0.925150]\n",
      "epoch:19 step:18587 [D loss: 0.714730, acc.: 50.00%] [G loss: 0.891835]\n",
      "epoch:19 step:18588 [D loss: 0.632895, acc.: 63.28%] [G loss: 0.892268]\n",
      "epoch:19 step:18589 [D loss: 0.626554, acc.: 64.06%] [G loss: 0.857034]\n",
      "epoch:19 step:18590 [D loss: 0.660873, acc.: 57.81%] [G loss: 0.856046]\n",
      "epoch:19 step:18591 [D loss: 0.695549, acc.: 57.03%] [G loss: 0.800923]\n",
      "epoch:19 step:18592 [D loss: 0.641164, acc.: 62.50%] [G loss: 0.886081]\n",
      "epoch:19 step:18593 [D loss: 0.668627, acc.: 60.16%] [G loss: 0.945784]\n",
      "epoch:19 step:18594 [D loss: 0.660134, acc.: 63.28%] [G loss: 0.952448]\n",
      "epoch:19 step:18595 [D loss: 0.594454, acc.: 71.09%] [G loss: 0.927705]\n",
      "epoch:19 step:18596 [D loss: 0.642241, acc.: 59.38%] [G loss: 1.039651]\n",
      "epoch:19 step:18597 [D loss: 0.763153, acc.: 45.31%] [G loss: 1.008711]\n",
      "epoch:19 step:18598 [D loss: 0.676057, acc.: 55.47%] [G loss: 1.067950]\n",
      "epoch:19 step:18599 [D loss: 0.663410, acc.: 57.03%] [G loss: 0.973440]\n",
      "epoch:19 step:18600 [D loss: 0.705809, acc.: 50.00%] [G loss: 0.896278]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 8.178617\n",
      "FID: 7.340221\n",
      "0 = 11.805628705692325\n",
      "1 = 0.05107151119137845\n",
      "2 = 0.9103500247001648\n",
      "3 = 0.867900013923645\n",
      "4 = 0.9527999758720398\n",
      "5 = 0.9484209418296814\n",
      "6 = 0.867900013923645\n",
      "7 = 5.6262568984270205\n",
      "8 = 0.05915966135739273\n",
      "9 = 0.69964998960495\n",
      "10 = 0.6766999959945679\n",
      "11 = 0.722599983215332\n",
      "12 = 0.709254801273346\n",
      "13 = 0.6766999959945679\n",
      "14 = 8.178686141967773\n",
      "15 = 9.633095741271973\n",
      "16 = 0.0763542503118515\n",
      "17 = 8.178616523742676\n",
      "18 = 7.340221405029297\n",
      "epoch:19 step:18601 [D loss: 0.648023, acc.: 60.16%] [G loss: 0.804193]\n",
      "epoch:19 step:18602 [D loss: 0.622657, acc.: 65.62%] [G loss: 0.895591]\n",
      "epoch:19 step:18603 [D loss: 0.690069, acc.: 54.69%] [G loss: 0.925774]\n",
      "epoch:19 step:18604 [D loss: 0.586600, acc.: 67.19%] [G loss: 0.930215]\n",
      "epoch:19 step:18605 [D loss: 0.607212, acc.: 67.19%] [G loss: 0.955921]\n",
      "epoch:19 step:18606 [D loss: 0.629054, acc.: 63.28%] [G loss: 0.935308]\n",
      "epoch:19 step:18607 [D loss: 0.648080, acc.: 59.38%] [G loss: 0.941117]\n",
      "epoch:19 step:18608 [D loss: 0.643808, acc.: 62.50%] [G loss: 0.919994]\n",
      "epoch:19 step:18609 [D loss: 0.681048, acc.: 53.12%] [G loss: 0.897635]\n",
      "epoch:19 step:18610 [D loss: 0.628443, acc.: 65.62%] [G loss: 0.913490]\n",
      "epoch:19 step:18611 [D loss: 0.696268, acc.: 53.12%] [G loss: 0.865131]\n",
      "epoch:19 step:18612 [D loss: 0.713739, acc.: 54.69%] [G loss: 0.849662]\n",
      "epoch:19 step:18613 [D loss: 0.665414, acc.: 59.38%] [G loss: 0.835585]\n",
      "epoch:19 step:18614 [D loss: 0.674050, acc.: 59.38%] [G loss: 0.874609]\n",
      "epoch:19 step:18615 [D loss: 0.668978, acc.: 64.84%] [G loss: 0.868731]\n",
      "epoch:19 step:18616 [D loss: 0.690033, acc.: 55.47%] [G loss: 0.955728]\n",
      "epoch:19 step:18617 [D loss: 0.644737, acc.: 64.06%] [G loss: 0.913618]\n",
      "epoch:19 step:18618 [D loss: 0.618864, acc.: 63.28%] [G loss: 0.961020]\n",
      "epoch:19 step:18619 [D loss: 0.654482, acc.: 58.59%] [G loss: 0.918939]\n",
      "epoch:19 step:18620 [D loss: 0.661131, acc.: 60.16%] [G loss: 0.941146]\n",
      "epoch:19 step:18621 [D loss: 0.660408, acc.: 60.94%] [G loss: 0.864432]\n",
      "epoch:19 step:18622 [D loss: 0.695579, acc.: 57.03%] [G loss: 0.908066]\n",
      "epoch:19 step:18623 [D loss: 0.718604, acc.: 49.22%] [G loss: 0.898306]\n",
      "epoch:19 step:18624 [D loss: 0.653457, acc.: 59.38%] [G loss: 0.872030]\n",
      "epoch:19 step:18625 [D loss: 0.657357, acc.: 60.94%] [G loss: 0.933382]\n",
      "epoch:19 step:18626 [D loss: 0.659390, acc.: 58.59%] [G loss: 0.833669]\n",
      "epoch:19 step:18627 [D loss: 0.653962, acc.: 60.94%] [G loss: 0.829989]\n",
      "epoch:19 step:18628 [D loss: 0.648486, acc.: 57.81%] [G loss: 0.894060]\n",
      "epoch:19 step:18629 [D loss: 0.629291, acc.: 64.84%] [G loss: 0.921681]\n",
      "epoch:19 step:18630 [D loss: 0.717849, acc.: 50.00%] [G loss: 1.002982]\n",
      "epoch:19 step:18631 [D loss: 0.710211, acc.: 50.78%] [G loss: 0.872395]\n",
      "epoch:19 step:18632 [D loss: 0.662864, acc.: 59.38%] [G loss: 0.872996]\n",
      "epoch:19 step:18633 [D loss: 0.648433, acc.: 64.06%] [G loss: 0.816465]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18634 [D loss: 0.687423, acc.: 60.16%] [G loss: 0.870255]\n",
      "epoch:19 step:18635 [D loss: 0.646304, acc.: 64.84%] [G loss: 0.931730]\n",
      "epoch:19 step:18636 [D loss: 0.663010, acc.: 57.81%] [G loss: 0.923999]\n",
      "epoch:19 step:18637 [D loss: 0.656579, acc.: 63.28%] [G loss: 0.879631]\n",
      "epoch:19 step:18638 [D loss: 0.658579, acc.: 56.25%] [G loss: 0.858545]\n",
      "epoch:19 step:18639 [D loss: 0.656564, acc.: 60.16%] [G loss: 0.901670]\n",
      "epoch:19 step:18640 [D loss: 0.606147, acc.: 69.53%] [G loss: 0.913368]\n",
      "epoch:19 step:18641 [D loss: 0.606538, acc.: 72.66%] [G loss: 0.925228]\n",
      "epoch:19 step:18642 [D loss: 0.630057, acc.: 62.50%] [G loss: 0.908547]\n",
      "epoch:19 step:18643 [D loss: 0.659614, acc.: 62.50%] [G loss: 0.978200]\n",
      "epoch:19 step:18644 [D loss: 0.623565, acc.: 69.53%] [G loss: 0.950634]\n",
      "epoch:19 step:18645 [D loss: 0.617345, acc.: 64.06%] [G loss: 0.880303]\n",
      "epoch:19 step:18646 [D loss: 0.678343, acc.: 55.47%] [G loss: 0.886904]\n",
      "epoch:19 step:18647 [D loss: 0.613024, acc.: 67.97%] [G loss: 0.918370]\n",
      "epoch:19 step:18648 [D loss: 0.667371, acc.: 60.94%] [G loss: 0.928883]\n",
      "epoch:19 step:18649 [D loss: 0.687399, acc.: 54.69%] [G loss: 0.906455]\n",
      "epoch:19 step:18650 [D loss: 0.630779, acc.: 63.28%] [G loss: 0.904577]\n",
      "epoch:19 step:18651 [D loss: 0.685086, acc.: 55.47%] [G loss: 0.889244]\n",
      "epoch:19 step:18652 [D loss: 0.619569, acc.: 65.62%] [G loss: 0.846205]\n",
      "epoch:19 step:18653 [D loss: 0.708211, acc.: 47.66%] [G loss: 0.837059]\n",
      "epoch:19 step:18654 [D loss: 0.711073, acc.: 48.44%] [G loss: 0.886420]\n",
      "epoch:19 step:18655 [D loss: 0.614102, acc.: 66.41%] [G loss: 0.925944]\n",
      "epoch:19 step:18656 [D loss: 0.642934, acc.: 57.81%] [G loss: 0.916525]\n",
      "epoch:19 step:18657 [D loss: 0.659743, acc.: 64.84%] [G loss: 0.889786]\n",
      "epoch:19 step:18658 [D loss: 0.677770, acc.: 55.47%] [G loss: 0.949345]\n",
      "epoch:19 step:18659 [D loss: 0.661481, acc.: 62.50%] [G loss: 0.882429]\n",
      "epoch:19 step:18660 [D loss: 0.647139, acc.: 58.59%] [G loss: 0.875087]\n",
      "epoch:19 step:18661 [D loss: 0.749890, acc.: 46.09%] [G loss: 0.807826]\n",
      "epoch:19 step:18662 [D loss: 0.678736, acc.: 54.69%] [G loss: 0.807051]\n",
      "epoch:19 step:18663 [D loss: 0.648742, acc.: 64.84%] [G loss: 0.860770]\n",
      "epoch:19 step:18664 [D loss: 0.673180, acc.: 58.59%] [G loss: 0.926187]\n",
      "epoch:19 step:18665 [D loss: 0.669302, acc.: 63.28%] [G loss: 0.884342]\n",
      "epoch:19 step:18666 [D loss: 0.686497, acc.: 57.81%] [G loss: 0.905690]\n",
      "epoch:19 step:18667 [D loss: 0.681212, acc.: 58.59%] [G loss: 0.890455]\n",
      "epoch:19 step:18668 [D loss: 0.678346, acc.: 58.59%] [G loss: 0.814833]\n",
      "epoch:19 step:18669 [D loss: 0.652963, acc.: 57.81%] [G loss: 0.884133]\n",
      "epoch:19 step:18670 [D loss: 0.699013, acc.: 51.56%] [G loss: 0.911875]\n",
      "epoch:19 step:18671 [D loss: 0.612542, acc.: 66.41%] [G loss: 0.886364]\n",
      "epoch:19 step:18672 [D loss: 0.677071, acc.: 55.47%] [G loss: 0.884480]\n",
      "epoch:19 step:18673 [D loss: 0.666959, acc.: 60.16%] [G loss: 0.856874]\n",
      "epoch:19 step:18674 [D loss: 0.635975, acc.: 61.72%] [G loss: 0.970537]\n",
      "epoch:19 step:18675 [D loss: 0.661744, acc.: 61.72%] [G loss: 0.896690]\n",
      "epoch:19 step:18676 [D loss: 0.664371, acc.: 57.03%] [G loss: 0.900301]\n",
      "epoch:19 step:18677 [D loss: 0.689021, acc.: 57.81%] [G loss: 0.908642]\n",
      "epoch:19 step:18678 [D loss: 0.597688, acc.: 69.53%] [G loss: 0.937082]\n",
      "epoch:19 step:18679 [D loss: 0.691386, acc.: 56.25%] [G loss: 0.923475]\n",
      "epoch:19 step:18680 [D loss: 0.660310, acc.: 56.25%] [G loss: 0.849571]\n",
      "epoch:19 step:18681 [D loss: 0.661238, acc.: 59.38%] [G loss: 0.902386]\n",
      "epoch:19 step:18682 [D loss: 0.653146, acc.: 61.72%] [G loss: 0.848155]\n",
      "epoch:19 step:18683 [D loss: 0.664115, acc.: 64.06%] [G loss: 0.852790]\n",
      "epoch:19 step:18684 [D loss: 0.691174, acc.: 55.47%] [G loss: 0.855089]\n",
      "epoch:19 step:18685 [D loss: 0.707646, acc.: 50.78%] [G loss: 0.889578]\n",
      "epoch:19 step:18686 [D loss: 0.664903, acc.: 63.28%] [G loss: 0.892871]\n",
      "epoch:19 step:18687 [D loss: 0.632596, acc.: 66.41%] [G loss: 0.855192]\n",
      "epoch:19 step:18688 [D loss: 0.630729, acc.: 69.53%] [G loss: 0.939219]\n",
      "epoch:19 step:18689 [D loss: 0.639420, acc.: 65.62%] [G loss: 0.958672]\n",
      "epoch:19 step:18690 [D loss: 0.680424, acc.: 57.81%] [G loss: 0.953152]\n",
      "epoch:19 step:18691 [D loss: 0.664183, acc.: 60.16%] [G loss: 0.890459]\n",
      "epoch:19 step:18692 [D loss: 0.655745, acc.: 60.16%] [G loss: 0.921841]\n",
      "epoch:19 step:18693 [D loss: 0.646964, acc.: 65.62%] [G loss: 0.888469]\n",
      "epoch:19 step:18694 [D loss: 0.723921, acc.: 50.78%] [G loss: 0.839439]\n",
      "epoch:19 step:18695 [D loss: 0.714102, acc.: 58.59%] [G loss: 0.848667]\n",
      "epoch:19 step:18696 [D loss: 0.717338, acc.: 50.78%] [G loss: 0.890225]\n",
      "epoch:19 step:18697 [D loss: 0.611852, acc.: 65.62%] [G loss: 0.906651]\n",
      "epoch:19 step:18698 [D loss: 0.643149, acc.: 62.50%] [G loss: 0.962140]\n",
      "epoch:19 step:18699 [D loss: 0.656903, acc.: 58.59%] [G loss: 0.969428]\n",
      "epoch:19 step:18700 [D loss: 0.659485, acc.: 64.84%] [G loss: 1.010002]\n",
      "epoch:19 step:18701 [D loss: 0.620913, acc.: 62.50%] [G loss: 0.981808]\n",
      "epoch:19 step:18702 [D loss: 0.590859, acc.: 71.09%] [G loss: 0.986564]\n",
      "epoch:19 step:18703 [D loss: 0.616814, acc.: 64.06%] [G loss: 0.974116]\n",
      "epoch:19 step:18704 [D loss: 0.645952, acc.: 60.94%] [G loss: 0.946993]\n",
      "epoch:19 step:18705 [D loss: 0.684864, acc.: 53.91%] [G loss: 0.914409]\n",
      "epoch:19 step:18706 [D loss: 0.681121, acc.: 59.38%] [G loss: 0.872031]\n",
      "epoch:19 step:18707 [D loss: 0.670361, acc.: 53.12%] [G loss: 0.910760]\n",
      "epoch:19 step:18708 [D loss: 0.617495, acc.: 67.19%] [G loss: 0.932814]\n",
      "epoch:19 step:18709 [D loss: 0.672383, acc.: 58.59%] [G loss: 0.946682]\n",
      "epoch:19 step:18710 [D loss: 0.667571, acc.: 54.69%] [G loss: 0.894881]\n",
      "epoch:19 step:18711 [D loss: 0.588377, acc.: 71.88%] [G loss: 0.955101]\n",
      "epoch:19 step:18712 [D loss: 0.650417, acc.: 62.50%] [G loss: 0.927779]\n",
      "epoch:19 step:18713 [D loss: 0.674162, acc.: 56.25%] [G loss: 0.903066]\n",
      "epoch:19 step:18714 [D loss: 0.664741, acc.: 57.81%] [G loss: 0.942255]\n",
      "epoch:19 step:18715 [D loss: 0.628785, acc.: 67.97%] [G loss: 0.983867]\n",
      "epoch:19 step:18716 [D loss: 0.665329, acc.: 59.38%] [G loss: 0.933679]\n",
      "epoch:19 step:18717 [D loss: 0.623370, acc.: 66.41%] [G loss: 0.947480]\n",
      "epoch:19 step:18718 [D loss: 0.696200, acc.: 57.03%] [G loss: 0.839280]\n",
      "epoch:19 step:18719 [D loss: 0.667102, acc.: 60.16%] [G loss: 0.880060]\n",
      "epoch:19 step:18720 [D loss: 0.653119, acc.: 62.50%] [G loss: 0.871804]\n",
      "epoch:19 step:18721 [D loss: 0.595493, acc.: 68.75%] [G loss: 1.011352]\n",
      "epoch:19 step:18722 [D loss: 0.586029, acc.: 73.44%] [G loss: 1.040716]\n",
      "epoch:19 step:18723 [D loss: 0.806272, acc.: 42.97%] [G loss: 0.949518]\n",
      "epoch:19 step:18724 [D loss: 0.700698, acc.: 61.72%] [G loss: 0.822412]\n",
      "epoch:19 step:18725 [D loss: 0.665005, acc.: 63.28%] [G loss: 0.873474]\n",
      "epoch:19 step:18726 [D loss: 0.598791, acc.: 70.31%] [G loss: 0.970685]\n",
      "epoch:19 step:18727 [D loss: 0.570472, acc.: 76.56%] [G loss: 0.923215]\n",
      "epoch:19 step:18728 [D loss: 0.584774, acc.: 67.97%] [G loss: 0.954937]\n",
      "epoch:19 step:18729 [D loss: 0.609524, acc.: 64.84%] [G loss: 1.016385]\n",
      "epoch:19 step:18730 [D loss: 0.626169, acc.: 64.84%] [G loss: 0.988899]\n",
      "epoch:19 step:18731 [D loss: 0.813132, acc.: 56.25%] [G loss: 1.022827]\n",
      "epoch:19 step:18732 [D loss: 0.661984, acc.: 63.28%] [G loss: 1.258436]\n",
      "epoch:19 step:18733 [D loss: 0.588305, acc.: 71.09%] [G loss: 1.157062]\n",
      "epoch:19 step:18734 [D loss: 0.638377, acc.: 63.28%] [G loss: 0.953725]\n",
      "epoch:19 step:18735 [D loss: 0.675314, acc.: 63.28%] [G loss: 0.830440]\n",
      "epoch:19 step:18736 [D loss: 0.690823, acc.: 57.81%] [G loss: 0.946556]\n",
      "epoch:19 step:18737 [D loss: 0.649525, acc.: 61.72%] [G loss: 0.930588]\n",
      "epoch:19 step:18738 [D loss: 0.580290, acc.: 71.88%] [G loss: 0.919936]\n",
      "epoch:19 step:18739 [D loss: 0.549714, acc.: 71.09%] [G loss: 1.070943]\n",
      "epoch:19 step:18740 [D loss: 0.659995, acc.: 62.50%] [G loss: 1.101205]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xd8XNWZ+P/PM6NR79Wqlmy5ycbYxtiAqSYhQAgtFch3w4aEhIQkuwu7Szb5JvmySyrsZpMlybL5EQIpQNjNQkILYAjBNMu4gKtkW7bVey8jzZzfH/fOaKRRGUmj/rxfL78Y3bkzc0Y2zz33Oec8R4wxKKWUWhwcs90ApZRSM0eDvlJKLSIa9JVSahHRoK+UUouIBn2llFpENOgrpdQiokFfKaUWEQ36Sim1iGjQV0qpRSRithswXHp6uiksLJztZiil1Lyye/fuRmNMxnjnzbmgX1hYSGlp6Ww3Qyml5hURORnKeZreUUqpRUSDvlJKLSIa9JVSahHRoK+UUouIBn2llFpExg36IvKgiNSLyHujPC8i8iMRKReR/SKyKeC5T4lImf3nU+FsuFJKqYkLpaf/EHD5GM9fAayw/9wK/BRARFKBbwJbgS3AN0UkZSqNVUopNTXjztM3xrwqIoVjnHIN8LCx9l18U0SSRSQbuBh4wRjTDCAiL2BdPH471UaPpG/Aw7+/WEZqXCQpsZGkxkVSkpNIVmL0kPOMMRyu7WBlVgJOh0xHU5RSas4Kx+KsXOB0wM+V9rHRjgcRkVux7hIoKCiYVCPauvt54NXjDHgH9/x1OYVrNuTy+YuWsTQtjj/ur+Y//3ycw7UdbCtO40ef2EhafNSkPk8ppeajObEi1xjzAPAAwObNmye1U3tmYjRl91xBR98ALV1uGjv7eGpvNY+VnuaJ3ZWkxUXS1OVmRWY8n79oOb/YeYKrfvwa99+0iU0FmnVSSi0O4Qj6VUB+wM959rEqrBRP4PFXwvB5oxIREqNdJEa7WJoWx1lLU/nypSv45RsnOVzTzsc257N9dSYOh3DV+mxu+/VuPv6fb/Dt687go5vzh7yXe8DLCwfruGR1BrGRc+LaqJRSUxaOaPYUcLuIPIo1aNtmjKkRkeeBbwcM3l4GfDUMnzchafFR/N37VwYdX5ebxB9vv4Av/uYd/vG/95McG8n7S7IAGPB4+fJv9/DcgVpKshP5r09tJjc5ZqabrpRSYRfKlM3fAm8Aq0SkUkRuEZHPi8jn7VOeAY4D5cB/AV8AsAdw/xnYZf+52zeoO1ckxbp44K/O4ozcJL7023fYfbIFr9dw5+/28dyBWm7aWsDplm6u/vFrvHW8ababq5RSUybWpJu5Y/PmzWamq2w2dvbx4Z++TntPP9uK0/nj/hr+/gOr+OIlxRxr6OSzvyzlVHM3/3HjRi5flz2jbVNKqVCIyG5jzObxztMVuUB6fBS//OstOET44/4avnjJcr54STEAyzPi+f0Xt7EyK4F/efoQ/R7vLLdWKaUmT4O+rTA9jt/eeg4/+Mh67rxs1ZDnkmJc3HHZSipbenhqb/UstVAppaZOg36AlVkJfHRzPiLBi7a2r85k9ZIEfvJKOV7v3EqJKaVUqDToh0hE+MIlxRxr6OJPB2tnuzlKKTUpGvQn4INnZFOYFsv9Lx9jrg2AK6VUKDToT4DTIdx28XLerWrj1bLG2W6OUkpNmAb9CbpuYx7ZSdH89JXy2W6KUkpNmAb9CYqMcHDDlgLePN5MQ0ffbDdHKaUmRIP+JFy6JhOAl4/Uz3JLlFJqYjToT0JJdiJLEqPZcUiDvlJqftGgPwkiwvY1mfylrIG+Ac9sN0cppUKmQX+SLl2dSZfbw9sn5lQNOaWUGpMG/Uk6b3k6UREOdhzWFI9Sav7QoD9JMZFOzluexkuH6nWhllJq3tCgPwXb12RxqrmbYw1ds90UpZQKiQb9Kdi+2pq6ueNw3Sy3RCmlQhNS0BeRy0XkiIiUi8hdIzy/VEReEpH9IvKKiOQFPPd9ETkgIodE5EcyUgnLeSo3OYbVSxJ4SaduKqXmiVC2S3QC9wNXACXADSJSMuy0e4GHjTHrgbuB79ivPQ/YBqwH1gFnAxeFrfVzwKVrMik92UJLl3u2m6KUUuMKpae/BSg3xhw3xriBR4Frhp1TAuywH78c8LwBooFIIApwAQsqF3LV+hy8xvDjHVqLRyk194US9HOB0wE/V9rHAu0DrrcfXwckiEiaMeYNrItAjf3neWPMoak1eW5Zk53IJ84u4JdvVHC4tn22m6OUUmMK10DuncBFIrIHK31TBXhEpBhYA+RhXSi2i8gFw18sIreKSKmIlDY0NISpSTPnHz6wioToCL7x5AGdvqmUmtNCCfpVQH7Az3n2MT9jTLUx5npjzEbga/axVqxe/5vGmE5jTCfwLHDu8A8wxjxgjNlsjNmckZExya8ye1LiIvmHD6zm7RPNPKl76Cql5rBQgv4uYIWIFIlIJPAJ4KnAE0QkXUR87/VV4EH78SmsO4AIEXFh3QUsqPSOz8fPzufMvCTueeYQHb39s90cpZQa0bhB3xgzANwOPI8VsB83xhwQkbtF5Gr7tIuBIyJyFMgC7rGPPwEcA97FyvvvM8b8IbxfYW5wOoS7r1lHY2cf/99rJ2a7OUopNSKZaznozZs3m9LS0tluxqTd8MCb1LT18PKdF7OAliQopeY4EdltjNk83nm6IjfMrtmQQ0VTN+9WtQ053tU3wPMHamepVUopZdGgH2ZXrMvG5RSeGjage9+fjvK5R3ZzpLZjllqmlFIa9MMuKdbFRSsz+MP+ajxeK3XW2NnHb94+CcCeUy2z2Tyl1CKnQX8afOjMHOra+/wbrPz8LydwD3iJjXSy51TrLLdOKbWYRcx2Axai95dkEeNy8tS+alYvSeCRNyq4an0O7b397D2tQV8pNXs06E+D2MgI3l+SxbPv1ZAc66LL7eGLlxTz7Hs1/PloGR29/SREu2a7mUqpRUjTO9Pk6jNzaO3u52d/Psbla5ewakkCGwtSMAberWwb/w2UUmoaaNCfJheuzCApxoUxcPv2YgA25CUDsEdTPEqpWaLpnWkSGeHgi5csp7q1l3W5SYA1s2dZRpwO5iqlZo0G/Wl064XLg45tyE/m1aMNGGN0xa5SasZpemeGbSxIobHTTWVLz2w3RSm1CGnQn2Eb8628vk7dVErNBg36M2zVkgSiXQ7N6yulZoUG/Rnmcjo4IzeJvae1HINSauZp0J8FGwtSeK+6HfeAd7abopRaZDToz4IN+cm4B7wcqtGN1JVSM0uD/izYWGAN5pae1BSPUmpmhRT0ReRyETkiIuUictcIzy8VkZdEZL+IvCIieQHPFYjIn0TkkIgcFJHC8DV/fspOimF5RhyvHKmf7aYopRaZcYO+iDiB+4ErgBLgBhEpGXbavcDDxpj1wN3AdwKeexj4gTFmDbAF0EgHXLIqk7eON9PtHpjtpiilFpFQevpbgHJjzHFjjBt4FLhm2DklwA778cu+5+2LQ4Qx5gUAY0ynMaY7LC2f57avzsTt8fJ6edNsN0UptYiEEvRzgdMBP1faxwLtA663H18HJIhIGrASaBWR/xGRPSLyA/vOYdHbXJhKXKSTlzXFo5SaQeEayL0TuEhE9gAXAVWAB6u2zwX282cDy4Cbh79YRG4VkVIRKW1oaAhTk+a2yAgH569I55UjVh0epZSaCaEE/SogP+DnPPuYnzGm2hhzvTFmI/A1+1gr1l3BXjs1NAD8L7Bp+AcYYx4wxmw2xmzOyMiY5FeZfy5ZlUlVaw9l9Z2z3RSl1CIRStDfBawQkSIRiQQ+ATwVeIKIpIuI772+CjwY8NpkEfFF8u3Awak3e2G4eFUmADsOa4pHKTUzxg36dg/9duB54BDwuDHmgIjcLSJX26ddDBwRkaNAFnCP/VoPVmrnJRF5FxDgv8L+LeapJUnRlGQn8rIGfaXUDAmpnr4x5hngmWHHvhHw+AngiVFe+wKwfgptXNAuWZ3Bz/58nPbefhJ131yl1DTTFbmz7JJVmXi8htfKGme7KUqpRUCD/izbkJ9MUoyLFw7WzXZTlFKLgAb9WRbhdHDthhye2lfN4VotwKaUml4a9OeAv33/ShKjI/jG/x4Yc87+0/tr2K1F2pRSU6BBfw5Ijo3kHy9fzdsVzfzv3qoRzznW0MmXH93Dj3eUzXDrlFILiQb9OeJjm/M5Mz+Ze54+THtvf9Dz33/uMB6v4WSTli5SSk2eBv05wuEQ/vmatTR19fHDF4b25ksrmnn+QB0psS5ON3cz4NEdt5RSk6NBfw5Zn5fMjVsK+MXrJ7j/5XKMMRhj+PYzh8hMiOIrl65gwGuobu2d7aYqpeapkBZnqZnzf68qobNvgB88f4RDNe1sX53JO6da+d6Hz6AwLQ6AiqYuCtJiZ7mlSqn5SIP+HBPtcvLDj2+gJDuR7z53mD/ur2FlVjwf3pRHU5cbgJNNXcDiKUynlAofTe/MQSLC5y5azoM3n82yjDi+9aG1RDgdZCZEEeNycqJRB3OVUpOjPf057JJVmVxiV+IE62KwNC3W7ukrpdTEaU9/nilMi6NCg75SapI06M8zS9NjOd3cg8eru20ppSZOg/48U5gWh9vjpaatZ7abopSahzTozzNL7amaujJXKTUZGvTnmcC5+kopNVEhBX0RuVxEjohIuYjcNcLzS0XkJRHZLyKviEjesOcTRaRSRP4jXA1frJYkRhMZ4dCevlJqUsYN+iLiBO4HrgBKgBtEpGTYafcCDxtj1gN3A98Z9vw/A69OvbnK4RCWpsZS0ag9faXUxIXS098ClBtjjhtj3MCjwDXDzikBdtiPXw58XkTOwtos/U9Tb64CWJoWpz19pdSkhBL0c4HTAT9X2scC7QOutx9fBySISJqIOID7gDvH+gARuVVESkWktKGhIbSWL2JF6bGcbO7Cq9M2lVITFK6B3DuBi0RkD3ARUAV4gC8AzxhjKsd6sTHmAWPMZmPM5owMrSkznqVpcfT2e6nr0GqbSqmJCaUMQxWQH/Bznn3MzxhTjd3TF5F44MPGmFYRORe4QES+AMQDkSLSaYwJGgxWofPP4GnsJjspZpZbo5SaT0Lp6e8CVohIkYhEAp8Ango8QUTS7VQOwFeBBwGMMTcZYwqMMYVYdwMPa8CfusG5+jqYq5SamHGDvjFmALgdeB44BDxujDkgIneLyNX2aRcDR0TkKNag7T3T1F4F5CTH4HIKFTqYq5SaoJCqbBpjngGeGXbsGwGPnwCeGOc9HgIemnALVRCnQ8hP1WqbSqmJ09LK81RhWhxH6zp4vbyRqtYeOvsGuHFrAVERztlumlJqDtOgP08tS49jx+F6bvz5W/5jmQnRfHB99iy2Sik112nQn6c+f/Fy1uUmkZkYRWZCNFf8+6u8V92mQV8pNSYN+vNUenwU124cXCO3IjOB96raZrFFSqn5QKtsLhDrchM5WN2OMbpKVyk1Og36C8S63CSautzUtusqXaXU6DToLxBrcxIBeK+qfZZbopSayzToLxBrshMRgQPVmtdXSo1Og/4CERsZwbL0OO3pK6XGpEF/AVmXm6Q9faXUmDToLyDrcpKoaeulqbNvtpuilJqjNOgvIL7B3APVgymeH71UxqcefHu2mqSUmmM06C8ga3OSgMGgX9fey/0vl/Pnow2cbtaKnEopDfoLSlKsi/zUGN6z8/o/feUYbo8XgD8f1W0olVIa9BectdlJHKhqo6ath9+8fYqPnZVPXkoMrxzRoK+U0qC/4KzLTaSiqZvvP3cEr9dw+/ZiLl6VwevHGnEPeEN6D2MMNW0909xSpdRsCCnoi8jlInJERMpFJGi7QxFZKiIvich+EXlFRPLs4xtE5A0ROWA/9/FwfwE11NpcK6//+z1VfHRzPvmpsVy8MpNut4fSiuaQ3uOZd2u54HsvU6clHZRacMYN+iLiBO4HrgBKgBtEpGTYafdi7X+7Hrgb+I59vBv4K2PMWuBy4Icikhyuxqtgvhk8Lqdw+/ZiAM5dnkak08ErIeb191W2MuA1HGvonLZ2KqVmRyg9/S1AuTHmuDHGDTwKXDPsnBJgh/34Zd/zxpijxpgy+3E1UA9khKPhamSZCdGsykrg5vMKyU2OASAuKoKzi1L4c4h5/fJ6K9hXtmiKR6mFJpSgnwucDvi50j4WaB9wvf34OiBBRNICTxCRLUAkcGxyTVWhevYrF/BPV64ZcuyilRkcqeugunX8QK5BX6mFK1wDuXcCF4nIHuAioArw+J4UkWzgEeCvjTFBo4kicquIlIpIaUODzjKZKodDEJEhxy5elQnAq+OkeHr7PZxuseb0V+rcfqUWnFCCfhWQH/Bznn3MzxhTbYy53hizEfiafawVQEQSgaeBrxlj3hzpA4wxDxhjNhtjNmdkaPZnOqzIjCc7KXrcqZvHG7rw7cOiPX2lFp5Qgv4uYIWIFIlIJPAJ4KnAE0QkXUR87/VV4EH7eCTwe6xB3ifC12w1USLCxasy2FneyOvljbxzqoUjtR14vEN32iq3B29LshOpbNGevlILzbhB3xgzANwOPA8cAh43xhwQkbtF5Gr7tIuBIyJyFMgC7rGPfwy4ELhZRPbafzaE+0uo0Ly/JIuOvgFu/PlbXP+T1/nAD1/lp6+UDzmnvL4Th8AFK9Opbe8NeW6/Ump+CGljdGPMM8Azw459I+DxE0BQT94Y8yvgV1NsowqTS1Zl8syXL6C9t5+efg/ffvoQr5Y1cvv2Ff5zjtV3kp8ay/KMeLwGatt6KUiLncVWK6XCKaSgrxYGEaHEnscPsLOskYffPElvv4dolxOwevrFGfHkpVjTPU+3dGvQV2oB0TIMi9jWZWm4B7zsr7QKtA14vJxo7KI4M578FCvQa15fqYVFg/4idnZhCgBvn2gC4HRLD26Pl+WZ8SxJisYhOoNHqYVGg/4ilhwbyeolCbx1wqrJ41uUVZwZj8vpIDspRoO+UguMBv1FbmtRKrtPttDv8Q4J+gB5KTG6+YpSC4wG/UVuS1Ea3W4PB6rbKa/vJDMhisRoFwB5KbHa01dqgdGgv8idXTSY1y+v7/D38sHq6dd19NI34Bnt5UqpeUaD/iKXmRDNsow43jrezLGGrqCgbwzUtGpdfaUWCg36iq1FqfylrJHOvoEhQT8/1TdtU1M8Si0UGvQVW4pS/RuoF2cM7ekD/qqbSqn5T4O+YkvR4NYHgT39JYnROB2iC7SUWkA06Ctyk2PIS4khITqCjIQo//EIp4PspGhN7yi1gGjtHQXAJ87Op6atN2jzlXydtqnUgqJBXwEMqbQZKC8lhlfLdDczpRYKTe+oMeWlxFLX3kdvv87VV2oh0KCvxuSbwVPd2kNzl5vvPXeY/95dGbb3//2eSt61q3wqpaafpnfUmHxz9e974SivHmmgo2+A3OQYPnxW3pTfu9s9wN//bj8XrszgwZvPnvL7KaXGF1JPX0QuF5EjIlIuIneN8PxSEXlJRPaLyCsikhfw3KdEpMz+86lwNl5NP19P/+n9NWxdlsbN5xVS1dpDdevUB3d3VbQw4DW8faKZAY9uy6jUTBg36IuIE7gfuAIoAW4QkZJhp92Ltfn5euBu4Dv2a1OBbwJbgS3AN0UkJXzNV9MtOymaf752HY9/7lx+/qnNfMTu4e+qaJ7ye79xzKrj39k3wLtVmuJRaiaE0tPfApQbY44bY9zAo8A1w84pAXbYj18OeP4DwAvGmGZjTAvwAnD51JutZoqI8H/OWcqWolQAVi9JIC7SOaGg3zfgoa49uH7PG8eb/IvB3jjeFJ4GK6XGFErQzwVOB/xcaR8LtA+43n58HZAgImkhvlbNIxFOB5uWplBa0RLya/79xTIuve/PtPX0+4+19/bzbmUrV65bwqqsBH+vfzQer5l0m5VSg8I1e+dO4CIR2QNcBFQBIc/xE5FbRaRUREobGnRO+Fx3dmEqR+o6aOvuH/9kYMfhejr7BvjDvmr/sV0nmvEaOGd5GucuT6O0ogX3wMh5/XdOtbDlnhe5/+XysLRfqcUslKBfBeQH/JxnH/MzxlQbY643xmwEvmYfaw3ltfa5DxhjNhtjNmdkZEzwK6iZdnZhKsbA7lPjp3jq23s5XNsBwOOlgzd9rx9rIjLCwaaCFM5ZlkZPv4d9la1Br/9LWQM3/ddbNHe7uf/lcho7+8L3RZRahEIJ+ruAFSJSJCKRwCeApwJPEJF0EfG911eBB+3HzwOXiUiKPYB7mX1MzWMb8pNxOYW3T4yf4vlLWSMAH96Ux/7KNg7VtAPWIO5ZBSlEu5ycsywVEXi9fGiK55l3a/j0Q7tYmhbLo589h95+Dz975Vj4v5BSi8i4Qd8YMwDcjhWsDwGPG2MOiMjdInK1fdrFwBEROQpkAffYr20G/hnrwrELuNs+puaxmEgn63KTKA1hMPe18kbS4iL5pytX43IKj5eepqXLzaHads5dblX3TI6NpCQ7kTeON/pf99KhOm7/zTusz0vmsc+dy9ZlaVy/KY9H3jxJbZtu6qLUZIWU0zfGPGOMWWmMWW6M8QX0bxhjnrIfP2GMWWGf8xljTF/Aax80xhTbf34xPV9DzbQthansr2wbszyDMYa/lDWyrTidtPgoLitZwu/3VPFqWQPGwHnLB0s6n7ssjXdOtdLb7+F0czd/9/g+1mQn8sgtW0iKsfbs/cqlK/B4zai5/QGPl1sfLg3pYqTUYqVlGNSkbC60Nl7Zdzo4D+9zuLaDxs4+LliRDsBHN+fR2t3PvX86QozLyfq8ZP+55y5Pwz3g5c3jTdz+m3fwGsNPbzqL2MjBReP5qbF8/Ox8Ht11itPNwTX+K5q6+NPBOn6/J2jYSCll06CvJmXzUmuNXenJ0fP6f7Grc16wIsP/3+ykaE4397C5MIXIiMF/fluKUnE6hDse38e+yjZ+8JEzKUiLDXrP27cXIyL8eEdZ0HPHG7oA2DvGhUipxU6DvpqUlLhIVmTG8/aJ0VMpfylrpDgzniVJ0QA4HeJf0Xve8vQh5yZEu1iXm0RTl5tbzi/i8nVLRnzP7KQYPnhGNjsOB0/tPdFoBf3DtR30uEOvCjrg8WoZCLVoaNBXk3Z2USrvnGwZceFUb7+Ht080+1M7PjduLWBLYSofPCM76DU3bS3gg2dk84+Xrx7zc9dkJ9DY2UdLl3vIcV9P3+M1Eyrr8FcPvs3Xfv9eyOcrNZ9p0FeTtjE/mY6+AX8PO1BpRQt9A96goJ+dFMPjnz93xNTNxzbnc/9Nm4akfUayIisBgLL6ziHHTzR2sSwjDoA9p0JfMXy0rpPnD9bineZVv8YY6jt05pGaXRr01aStzUkC4EB1cK/6L2UNuJzC1oBN18NlhV2vp6y+Y8jx442dbF6aQkFqbMh5fa/X0NLtprW7n4P2GoLp8uKhes79zg7e0+JyIWnv7edbTx2g2z0w201ZUDToq0krzozH5ZQRg+Vr5Y1sKkghLir8WzbkJscQF+mkrG6wp9/W009jp5tlGfFsyE9mz6nQgn5bT78/PbWzvHGcs6fmWEPnmFNO1VCvlzfx0OsV7JpAnSc1Pg36atIiIxyszErgYPXQoN/ZN8Chmna22pU5w01EKM5KGNLTr7BTTEXpcWzIT6a2vTekRVxNAeMCO8cp+jZV9e3W8pXnDtRSPuwuRQVrsEtuNHZo6Y1w0qCvpqQkO5GD1e0YM5gP33+6Fa+BTUunb+uEFZnxHA3o6R9vtB4vz4hjY4E1/3/v6fF7iE12YFmeEcfbJ5roG5i+vYDrOnrJSIgiOsLJT7ScxLga7HLcWm8pvDToqylZm5NIU5ebuvbB/zF323P3N+ZPX9BfmRVPQ0cfrd1WT/1EQxcOsRZwleQkEul0hJTiabZ7+lefmUtvvzfktNBkNLT3sSw9jhu2FPDk3uoRF5ipQb6efoP29MNKg76akrW51mDuwZrBwcl3TrWwIjOepFjXtH3uisyhM3iONXaRlxJLVISTqAgnJTmJ7AlhMLfRDvofXL8Eh0xvXr+uo5fMxGhuvXAZDoEHXj0+bZ+1EPiCvfb0w0uDvpqS1Uus4Hugysrre72GPadb2VQwvbtirsiyZvAcrbNy4ycaBqdrglUJ9N3KtnEXXTV3WkG/IDWO9XnJ0xb0jTHUt/eRlRDFkqRoPnJWHo+VntYpnGOo9wd99zhnqonQoK+mJCHaRWFaLAfswdzjjV20dvdz1jTm82HoDB5jDCcauyhKHwz6GwuS6en3cKRu7AHTpq4+EqMjiIxwsK04jX2VbXT0WpvDdLsHeGzXqTGLyoHVI/3hi0fp7Bt9amFH3wA9/R4yE6MA+NyFy3EPePldaWWoX3nSut0D1I+wXeVc5+vpa3onvDToqykryUn0T9t8x14UtWlp8lgvmTIRoTgznrL6Dmrbe+np97AsI97/vG88YbwcfVOXm/R4KxBvK07H4zW8dbyZxs4+bnjgTf7xv9/lFzsrRn29x2v4yqN7+OGLZfxkjKmYvpk7WYlWSYrC9DhWZsXz5gzsDXzfn45y5Y9eo38elZrweo0/raPpnfDSoK+mbG1OEqeau2nv7WfPqRYSoyNYlh4//gunaEVWAmV1nZywyy8sC+jp56fGkBoX6b8Ijaaps4+0+EgANhWkEBXh4IndlXzkp69zpK6DZelxPPJGxahpop+8XM7rx5ooTIvlwZ0nRtwAHvD3tDMSovzHthalsftky7QH40M17TR29k1oX+PZ1trTT7/HkBAdQXO3W2sjhZEGfTVlJdmJAByqbmf3yRY2LU3B4ZBp/9wVmfHUd/T5B2wD0zsiwsWrMvjjvhqO1I6e4mnucpMaZwX9aJeTswtTee5ALW09/fz6M+dw1xWrqW7r5YWDdUGvfftEM//24lGu2ZDDw5/eisdr+OGLwdU/YTA/7evpA2xdlkq32zPtK3R9axhePBT8HeYqX0qnJDsRYwZnWamp06CvpmxtjhX03zzeTFl957QP4vqstGvw/OlALTEuJ0sCAirA165cQ2JMBF95dM+o8++bOt2kxQ/2vj9+dj5n5ifzxG3ncdbSFC5dk0VeSgy/eL1iyOtautx85dE9FKTGcs91Z1BifirXAAAgAElEQVSQFstNW5fyeOlpjjV0MpzvDiAzoKe/xV689tYYlUqnqrffQ7W9SO3FQ3VD1lNMRFffwKRfOxn+oG//22oIc4rH6zX86wtHZ2QXturWHg7XTm+Jj4kIKeiLyOUickREykXkrhGeLxCRl0Vkj4jsF5Er7eMuEfmliLwrIodE5Kvh/gJq9mUkRJEeH8lju05hDNM+iOvjm8Gzr7KNwvS4oLuLtPgovvfh9Ryu7eBfXzga9HqPXXcnze7pA3zozBye/OI2ltvjA06H8KlzC3n7RLO/xlC3e4DP/Wo3jZ19/MeNm4i3S03cvr2Y6AgH9z5/JOiz6jv6iI10+s8FyEyIZllGHG9NY17/lL0WYEthKiebuke8II2nq2+Ac77zEr9+61S4mzcq36ymNfZdZLhn8Jxs7uZHL5Xx3Hs1YX3fkdzz9CG+8Ot3pv1zQjVu0BcRJ3A/cAVQAtwgIiXDTvs61t65G7E2Tv+JffyjQJQx5gzgLOBzIlIYnqaruUJEKMlJorqtF4fAmfnTO4jrk5MUQ2ykE2DIdM1Al67J4oYtBTzw6vGg4Nra7cZrGBL0R/KxzfnEuJw8tLOCbvcAn35oF6UVzdz3sQ2ss9cpAKTHR/HZC5fx7Hu1QVU+69p7yUyIQmTohWlrURqlFSOXpw4HXwXUWy4oAuCFg/UTfo93q9ro6B3gufdqw9q2sQSmdyD8pRh8i/pmIm10uLZ9Ts1ACqWnvwUoN8YcN8a4gUeBa4adY4BE+3ESUB1wPE5EIoAYwA3MnfscFTa+/zlXZiUM6c1OJ4dD/BU3Awdxh/v6B9ewNDWWO363b8iAoO9/+NSA9M5IkmJdXL8plyf3VXPzg7usXP7HN3D1mTlB537mgmXERjr532FbNtZ39JE5LP0EcM6yVDr6BoLqF01UVWsP2+99JWj84mSTFfTPKUpjXW4iL42R1z/R2DVidVLflphvVzRPaHOaqWjo6CPG5aTQ/nsNd3qntcealts0zUHfPeCloqmbjt6BOTMYHUrQzwVOB/xcaR8L9C3gkyJSCTwDfMk+/gTQBdQAp4B7jTFBCUwRuVVESkWktKEheEckNff58vozldrxKbZX5o7W0weIi4rgC5cUU9nS4093wGDKIH2cnj7AzecV4h7wsutkM/d97Eyu2TD8fwFLfFQEK7MShtQFAmv2TmA+38dXevqtE1NL8Tz3Xi3HG7v489GhPfkTjd2kxLpIinXxvjVZ7D7V4q83NNw9Tx/iM7/cFZS731/ZhogVwN6cYjtDZV0ko4iLdBLtcoS9p9/WbQX96e7pVzR1+e/i2uwLzWwL10DuDcBDxpg84ErgERFxYN0leIAcoAi4Q0SWDX+xMeYBY8xmY8zmjIyMMDVJzaQN+clEOIRtxenjnxxGK+28ftE4U0SX2xeFiqbBDV8Ge/rjB/0VWQl87co1/PSms7huY964bTo6bFFYfUffkJk7PkuSolmaFjtkMHdneSNfeXTPhFI+rxyxgv17VUPvGCoau/y95fetycIY2HF45BRPWX0HjZ1uyodtTrOvspVLV2cSFeHgz0dmplPW0NFHRryVDstIiAr7XH1feme6e/qBv8vWeRT0q4D8gJ/z7GOBbgEeBzDGvAFEA+nAjcBzxph+Y0w9sBPYPNVGq7knPzWWnXdt54pR9radLh9cn80nzynwp5dGU5hmB/3GwZ5+U5cVSNLixk7v+Hz2wmWj7t0baGVWAk1dbn+g6uwboNvtGbGnD7C1KJVdFc14vYayug4+/8huntxbTU1bT0jt6nYP8NZx66IxfPrnyaYuiuzvvjYnkSWJ0bx0KDjo9/Z7/AXgAheMNXX2UdnSw9mFqWxdlsarZTMT9Os7ev2rl9Pjo6YtvTPdPf3APR9au+dP0N8FrBCRIhGJxBqofWrYOaeASwFEZA1W0G+wj2+3j8cB5wCHw9N0NddkJUYHDVROt7yUWP7l2jPG3WIxNS6ShKiIIT39Jju9kxLmwnC+qaS+3r5vuuZIPX2wUjyt3f28eaKJW35ZSpe9U1Rg5dKxvHGsCbfHy9aiVI43dvnLSPimay61g76I8L6STF4tawgqLXGyqRvfjcWbxwfvOvZXWheR9XnJXLgineMNXVS2TH91UF9PH6yg39gR3uDcOkPpnfKGwI1+5sZag3GDvjFmALgdeB44hDVL54CI3C0iV9un3QF8VkT2Ab8FbjZWYvB+IF5EDmBdPH5hjNk/HV9EqbGICIXpcUP2823q6iMl1kWEM7zLVVbZReh8vTxfCYZRe/rLrPn6tz68m9r2Xv7fNesAaBihGNuv3zrJH/ZVDzn2ypEGYiOd/PU2a4aOb1D4ZJMVnAvTB/cj3r46k263J2ilsm8q56qsBN483uTP6++rbEUEzshL4qKVVur11aPTu8NYb7+H9t4B/+rl6UzvtHS7p23mFEBZXYd/vKmla2709EOaZmGMeQZrgDbw2DcCHh8Eto3wuk6saZtKzbrC9Dj/TBQYuho3nDITokiMjvAXe/PNOR9p9g5Ydyu5yTFUtfbww49vYFtxOv/3f98bsaf/01eO0drdz7bidFLjIjHG8PKRes5bnu6vd/RedTtbl6X572oCVyqfmWedc6CqnfOWD46/+HLPN24t4JtPHaC8vpMVWQnsr2yjOCOe+KgIijPjyU6K5tWjDdy4tWDSv5/6jl4+8tM3AEiJiyQ11sVfbyviQvui4pvemJlg/b7S46P8pRjCdYH2pXeMsQJ/+jgzuCbD4zUcb+ziug25HG/omlc5faUWhMK0WCpbunEPWFPnGoetxg0XEWFlVgJlvqDv6+knjv5Zd1y2kruvWcu1G3NJi4vE6ZCgsster6GuvZfOvgF+9mdr561jDV1UtvRw8aoMMhOiyUyI4oCd1/eVX/Cld8BasJaTFM17wzazP9bQSW5yDJesygTw9/b3V7ay3r5QiAgXrshg57HGKU0/fOdkC6eau1meEUdidASlJ1uG7C3gy9/7e/rxkWEvxRCYX5+uFM/pZuvf2saCZESgrXuepHeUWigK0+LwGjht56Sbu9zjLsyarJVLrGmbxliBOsblJGGM9QvXb8rjr84tBKz1BxnxUUE9/cauPqsIWVQEv3y9gtq2Xv+snYtXWb3kM3KTeNcX9Ju6SI2LJClm6JjF2tykoAHfYw2dFGfGk58aQ05SNG8eb6a6rZfGTjcb8gcXoF24MoOO3oER5/OHypf2uv+mTTxyy1auPjOHvadb/WkWX08/ML0D4Z2r39bT7/+7b5qmev2+u6eVSxJIinFpT1+pmeabuuhbsBRYYTPcVmbG09bTT31Hn3/O+UQGuTMTo/xF2nx8dWL+7rKVeI3h318q45UjDazIjCcvxcrbr81N4lhDJ93uASoauylMiw1673U5SRxv7KLLrv/v9RqO1XexPCMeEeGcZWm8ebyJvXZZal9PH+D84nQcAq8enfwsnrL6TvJSYoiNtC6CZy1NobNvwD/wXd8xdAzEl3oJ56rW1m63v9TGdPX0fbu6FWfGkxzjmlezd5RaEHy57RON3Qx4vLT29JMa4nTNiVq5ZHAGT117L1kJI+fzR5OZEB208UmNHfTPLkzlxi0FPF56mrdONHHJ6kz/OWfkJuE1VjnliqYu/1TVQOtyrcqVh+w9EGrs/QiWZ1rnnrMsjaYuN//zTiUup7A6O8H/2qRYFxvyk3n63ZpJD4Aerevwr6QG/AX6fIPLDR19iOAfb/EF/dHq7/T2e3juvZqQC8J5vYa2nn7/AGtz1+gXk47efj790K5J7WdcXt9JVmIUidEukmIjadH0jlIzKyXWRUJ0BBWNXbR092MMpE9XT9+etnmktsOafjhGPn8kY/X0lyRF88XtxUQ6HfR7DBevHFzQuC7XWq+wq6KFmrZe/91NIF+9IF+K55jdI/X1fM9ZZq0SfulwPWuyE4mKcA55/afPL+JYQ1fQLKJQDHi8HG/sYkXW4IVkaVosaXGRvHPSurNo6OgjLS7SP2jrS++MNoPnodcr+Pyv3glaBT2ajr4BvGawEzDWAq13q9rYcbiel49MvGZReX0HxfbFLSXWteBW5Co154kIRelxVDR1Da7Gnaacfnp8FGlxkZTVdU6qp5+VEE1zl9s/6AxWTz/S6SA1NpLMhGhuu3g5mQlRbC5M9Z+zJDGatLhInnnXqh45UtDPTIgiPT6K9+ypnb7pmr4AlZ8aQ25yDDA42yfQleuyWb0kgR++eHTCG8CcbunBPeAd0tMXETYWpAT09HvJCPh9xUVFEONyjpreeXKvdfEJtTfum66ZHh9FUoxrzPSOb43F8FXK4zHGWDOg7DIhmt5RapYUpllB31d/JtTVuJOxIiuePadb6HJ7xpy5MxLf+YGDl7VtPWQlRflLSH9pezGv37V9yMI0EWFdbpJ/UdVIOX3rnER/T7+8vpOkGJd/YFNE/GsH1uclBb3e4RDuuGwVFU3d/M87E9vj1zejKbCnD1Ze/0SjdTFu6OgbssMYQHpC5Ig9/aN1Hf40VXWIK5h9wTc51vrOY/X0fSm1iQb9mrZeutweltsXt+TYSP/FZrZp0FeLSmFaLFUtPdTaPbjpGsgFa6GTL+WQNcGg7zs/cPvFmrZeshNj/D+LyIjz1n0pHhi5pw/WYG5ZfSe9/R6ONXSyPCNuyEDzRSszEBm9gN771mRyZn4yP3qpfNQNakYSOLgZaFOBdUfxzsmWIatxfTLiR16g9eTeKhwCEQ6hqjXEoN8zGPRT4yJHLUAHUDfJoO/7nr47mqQYF+29A9O6ECxUGvTVolKYbk3b9E05nK4pmzC0N5s5iYFcGJzjD1Db3suSpPHf5ww7Z58WF0li9MglJtblJuLxGo7UdnCsocufz/e5+swcXvy7i4ZsNh9IRLjzspVUtfbw2K7TI54zkrK6DnKTY4LKb6/Pswr27T7VQkNnX9CdUXp8VFB6xxjDk3ur2VacTm5KDNWtwSuY7/zdPr44bAMTX487KSaS1LjIMdM7vp5+fUcf7b2hp2fKh13cku1SH2Pl9Rs7+2ak/LIGfbWo+Hq+u0+2IGLddk8XXzkGmHhP35/esRdoGWOsnn4IQX9tjhX0l46Q2hl+zuvHmmjo6AvqeYtI0IVguPOL09lSlMqPd4Te2y+r7wz6LICYSCclOYm8fLiefo8J6umnJ0QFzd5551QLlS09XLshl5ykGKpH6OnvPtkStKagLaCnnxY/dtCva+/F5bTugCbS2y+v7yAldjBllmL/OxsrxXPXf+/nmvt3hvwZk6VBXy0qvimMh2raSY21Vr5Ol5WZg0E/Y4I9/bS4KBwyWHTNN6gbSk8/LyWG9Pgo/wyi0c5JinHx5F6rYO54AX4kIsJtFy2noaOPv4RQj8fj9Q1ujvxZmwpSOGxvAjM8p58RH0VLt3vIwPGTe6uJinBw2doscpKDg/6Ax0tlSzd17b1D0iq+nL41jhFFS3c/3lHSLjVtvWy0p5ROLOhbFzdfyizJ7umPtkBrwOPlrePNM7LrnAZ9taikxLpIjI7Aa6Zv5o5PUqyLzIQool0OEqMntpuY02HVkfeVYvClGULp6YsIj33uHP7h8tVjnrMuN9EfZJePEojHc/6KdJJjXfxx//jTNytbuukb8I56MdoUMH4wvDhdekLUkFIM/R4vf9xfw/tKskiIdpGbHE1de++Qi0JNWy/9HsOA1wwZD2jt7ic+KgKX00FqXCQee97+cP0eLw2dfWwpTCXS6fBPbR2PMSbojibZXhXdNsoMnner2ujoG+C85WkhfcZUaNBXi4pv2iZM7yCuz6olCSyZZMnprMRof09/cI5+zFgv8VueET/uRW2dneKJdDrITwntfYdzOR1cvnYJLxysCyrXPJyv/EJx1mg9/cFebnBP3/ouvrz+a+WNNHe5ucbesjInOQavGTrw7asyCgy5C2jtcftLU/j+DYw0g6ehow9jIDclhqL0uKCeflVrDzvLg+9w6jv6aO3uZ1XAxc2XRmwdpbzy68esPQzOXaZBX6mw8+X1p3O6ps9dV6zm29edManXZiYMLtCqsYNZTgg9/VCttQd8C9Njp1S98qr1OXS5Pf46QKM5Wm/dVYyU0wfITY7xj30EBf2ABVp17b3c+/wRkmJcXGwXiMux1xUEDuYG7p3gu1MCq7ftG1j1XRhHyuv7ZngtSYymODN+SG18gG8/fYhPP7QraK2C7+5p1ZLBWVS+nv5o5ZV3ljeyJjtxWgoADqdBXy06vqqTM9HTX5uTxHmT3EIyM3GwFENtWw8RDglrUFhn72s8mXx+oHOWpZIWF8kf9teMeV55XSfZSdGjzigSETYVpBDjcgbN7vGVYnjpUD0f+vFrnGjs4t6Pnulfo5Cb4gv6gz36U83d+IZsAo+3dLv9A6uDQT942mbgCujlmfGcbu723830e7y8erSBvgFv0B3AYXvdwOqAgfzEGBciI+f0e/s9lJ5smZHUDmjQV4tQkb2pyHTn9KcqMyGKpi5r8LKmrZesxOiwDjwXpsWRlxLD2QEreicjwung8nVL2HGonm5716+RjDZzJ9BX3reC731kfVA6zBf0H3nzJFEuB//zhfN4f0mW//kcO+0VOFe/orGLZRnxRLscQ3r6rT39/oFV393eSOkd32t8PX2vwb8Jz66KZjrsgnXDK5Yeqe0gKzGKlIB/X06HkBjtGrG88jsnW3APeNlWPIeCvohcLiJHRKRcRO4a4fkCEXlZRPaIyH4RuTLgufUi8oaIHBCRd0UkfPenSk1Cob+nP/230lPh216xoaOP2rbQ5uhPhMMhvPr3l/DX2wqn/F5Xrc+hp98z4v67YBU5CyxLMJrVSxK52s7TB4qLiqAoPY5txWk8+cXzWb1k6J7IMZFOUuMig3r6hWmx5CTFDNlvuK27359uSYmz/jtSeeW69l6iIhwkx7ootu+GfL36V4404HIKMS4nB6qHbkZ/qLYjqH1gTREdqae/81gjToewpWhmgv64UwpExIm17eH7gUpgl4g8Ze+W5fN1rG0UfyoiJVi7bBWKSATwK+D/GGP2iUgaMDcKUKhFqyQnkY+elTekUNlc5JvBUm8H/TU5Y2/+PhmOMN05bClKJSMhij/ur+ZDIwTtqtYeevo9rBxlEDcUL/zthWOOPeQkR/uDvjGGk03dbCtOp7ff68/1G2No7RnM6UdFWPscjJTTr7EvtCLCsow4RAaD/o7D9WwtSqO338OBgA1p+j1ejtV3cuGK4JTeaPV3dpY3cWZeUlBKa7qE0tPfApQbY44bY9zAo8A1w84xgO9fZBLgm791GbDfGLMPwBjTZIwJfc22UtMgKsLJDz56Jvmpoy9emgt8Pf269l6q23rIHmW7xbnA6RA+eEY2Lx9poLMvOMVTVu+ruTP5oD/eYLO1QMsK7g0dffT0e1iaFkt2UrS/p9/ZZ5VCSI4ZTL2kxY9cf6fOTqkBRLuc5KfEUt7QyenmbsrrO7lkdSZrcxI5WN3un+d/orELt8c7pBy1T9II9Xfae/vZX9nKtkmO+0xGKEE/FwhcZ11pHwv0LeCTIlKJ1cv/kn18JWBE5HkReUdE/mGK7VVq0fD19MvqOujtD21h1my6an027gEvLx2qC3ruSK09XTNj7PTOVAQu0Kqwp2suTYsjOzmG+o4++j3ewYVZsYODyVYphuCB3Jr2niHrIooz4zlW38mOw1YKa/vqTNbmJtHl9vhnCvmKv63KGiG9M8LuWW8fb8ZrGLJf8XQL10DuDcBDxpg84ErgERFxYKWPzgdusv97nYhcOvzFInKriJSKSGlDw+R35FFqIUmLt1bl7j1tpQ+yQ5yjP1s2FqSQFOPitbLguetvn2hiWXrckGAbbrnJMXT0DdDe2+8PwktTY8lJisYYazaOvwRDTGDQjwrK6RtjqGvrY0ni0KB/vLGLFw/VUZQeR1F6nH+tg69M9ZHaDiIc4t+QJlBKbHB6Z+exRqIiHGwsmP6VuD6hBP0qID/g5zz7WKBbgMcBjDFvANFAOtZdwavGmEZjTDfWXcCm4R9gjHnAGLPZGLM5I2Nu51mVmilOh5AeH8X+Sqt2zFzv6TsdwrnL0nj9WNOQXaz6PV7ePtE87SmMwbn6PZxq6sbpEHJTYsi2j9e09QaUVQ5I74xQdK25y43bM/TuqjgjHveAl7+UNfo3kF+RFU+k0+HP6x+u7WBZRlzQxjNgpXfae/uHlIR4vbyJswtTiXYFnz9dQgn6u4AVIlIkIpHAJ4Cnhp1zCrgUQETWYAX9BuB54AwRibUHdS8CDqKUCklWYrR/gVYoJRhm23nFaVS19nAqYEOTfadb6XJ7pn1KYk6y9fupbu2hoqmL3OQYXE6Hf0FbTVuPf8vClMD0Try1lWHghSpwYZZPYKmK7fYWlS6ng1VLEjhQNdjTH2nmDlh3F8ZYWzACtHS5OVLXwbkzND/fZ9ygb4wZAG7HCuCHsGbpHBCRu0Xkavu0O4DPisg+4LfAzcbSAvwr1oVjL/COMebp6fgiSi1Evry+Q4JXqc5Fvtz0zvIm/7HXyhsRGdyGcbr4dvuqau3lVHO3v8podsBqXV9OPTDNlBYXSb/H0N47OAAduDDLx7fGIC7SyZaiwbUNa3MSOVDdRltPP1WtPUOqqwbyzRjy3W3ss+/gZjK1AyFM2QQwxjyDlZoJPPaNgMcHgW2jvPZXWNM2lVITlGn3NDMSonBNoVTCTFmeEUdWYhSvH2vkxq0FgJXCOCM3aVrLWIO1gMvlFKun39jF1RusqaPxUREkREdQ09ZDpte6cCbFDB3IBSul4zvu7+kHBP2kGBe5yTFsyE8eslvZ2twkHt112l+GYs0IM3dgMOi3dLspJI69p1sRsfYSmEkzMzFUKTUpvp5+qIXWZpuIcN7ydF492oDXa+jp97DndAu3nL9s2j/b4RCyk2I4WN1Oe++AfxEeDE7njHQ6iI10Dsm5+4J+U2efvxhfbVuvdXc1bAHfrz+zdcgFAwbLWTyx29o6ctT0jr/omt3TP93Kisz4GZuf7zP3uw5KLWK+eeJzeY7+cOctT6PJzle/XdFMv8fMWImBnORodlU0A4M1lgCyk625+q09/UNm7sDIpRhq23rJSIgKWhtQmB43pLwCWEHeIVYaKyE6YtSxl8DyysYY9p5uZcMM1M8fToO+UnOYr6efnTyPgr49S+f1Y028Xt5IZIRjyvV9QpWTHEO321r/GbhzWHZSjH/2TtKwNJOv8F7gDB5ra8rQ7q5iIp0UZ8ZjDKxZkjhqGe3kgN2zTjf30NLdPyObpgwngSPWc8HmzZtNaWnpbDdDqTnh3co2PvQfr/FPV67m1guXz3ZzQnbxD15meUY8NW29JMW4+O2t50z5Pfv7+6msrKS3N3gvXJ/2nn7/gGxu8uA+Bu29/bT3DBDpFERkyKC4MYaq1l6SYiJIsCuA1rX3TqiqaXOXm263h/go56hjF77PSYyJIMIhNHf1k5U4+bGa7OxskpMHLxoistsYs3m812lOX6k5rCgjjrU5iWydoWJc4XJecTq/f6eKnn4Pd162MizvWVlZSUJCAoWFhaP2ppu6+qhq6cHldLAmezC33tLl5nRLNw4REqIjhqR+ALxVbaTGRfrn+nur2kgJ+Hk8DR191LT1kJscM+aFwlS3+cs6R3W5WZsz+p3BWHp6eqiqqhoS9EOl6R2l5rD4qAie/vIFs5IGmIpty9PpsWvPh2tRVm9vL2lpaWMGyUi71xw4uwbwb27uNWbE8tQRTmHAXjTl8Ro8xhDhDD0Yx0c5ERHixhmUdTqsz+l2e4hxOScV8AGio6Pp759c7UoN+kqpsDtnmZXDT4iK4Ax7h65wGC9I+lIlUc7hQX/w55GCfnSEk7aefjp6+/07YU0k7RITGcG6nMRxV9Y6HcKAx0tPv4fYyMmvwp3sxQI06CulpkFafBRnF6awfU3mlLZinCiX04FDhKhhwTcwgEeMEPTzUmKIinBwsqnbX5/H5ZhYuwMDcUVFBTt27Ag6xylCt9uDMYaYYUH/S1/6UtD5Pueff/6E2jIWzekrpabFI7dsxTGFHulkOB3Ciqz4oF66wyFEOBwMeL2jpHccFKXHcbyhy7+5umsC6Z3hfEF/+/btQz/H4cBrrIHm4T39H//4x5P+vInQnr5SalpEu5xBufWZEBXhHPFi4wvizlF68C478Lc21HHLxz7EpZdcxBe+8AW8Xi+f+cxnuOiii7jiiisA2LlzJ9u2bePiiy/mscceC3qvBx54gEceeYRLLx1aVNjpEKpOn+JT113OR66/jnPOOYcTJ04AVm/e4/Fw2WWXUVVVxfPPP8/f/M3fTOl3MRLt6Sul5pX/94cDHBy2RWEoevs9eLyG6EgnZ+Qm8c0PrQ06JzLCwaZVS3n++T+RmhDDJz/5Se677z4yMzP5+c9/jtdr5fu/+tWv8uSTT5Kenu4/FujWW29l2bJl/Mu//MuQ4767jI62Fv7njdfYvXs33/ve9/jZz35mPe908m//9m/cdttttLe38/TT4S9VpkFfKbUoOETwYBgvadPR1sJtt91Ga2srFRUVrFixgvPOO896D/suwRhDenr6kGOh8AX9krXriIiIYMOGDZSXlw85Z+3atfT09PCBD3yAuLjguvxTpUFfKTWvjNRDD0VDRy81bb2syU4cc2bOb37zG6699lpuvvlmbrrpJs4880zefPNNrrrqKrxeLw6HAxGhqamJtLQ0/7FALpcLjyd4Z1jfIPLRwwfxeDzs27eP5cuHLrp79tlnWbNmDS+++CKf/exn/ReXcNGcvlJqUUiJjSQvJXbcqZjbt2/nvvvu49prr6Wrq4vExERqamq48MILueqqqwD4zne+w4c+9CEuueQSfve73wW9x7p169i5cycf//jHhxxPiI4gLS6SJVlZXHvttXz5y1/mH/5hcBfZjo4Ovv/97/Pd736X7373u9xxxx1h+LE2nP4AAAfOSURBVOZDaRkGpdS8cOjQIdasWTPbzZiyiooKvv71r/OrX02t4vzw34eWYVBKqRnQ1tbGNddcM+TYk08+SVKStSjtiiuuoKenx//cf/7nf85o+4bToK+UUlOQlJTEK6+8Murzzz77bNCxqfbypyKknL6IXC4iR0SkXETuGuH5AhF5WUT2iMh+EblyhOc7ReTOcDVcKbX4zLV09GyZyu9h3KAvIk7gfuAKoAS4QURKhp32day9czdibZz+k2HP/ysQfLlTSqkQRUdH09TUpIEfq/icy+Ua/8QRhJLe2QKUG2OOA4jIo8A1wMGAcwzgq2OaBFT7nhCRa4ETQNekWqiUUkBeXh6VlZU0NDTMdlPmhOzs7Em9LpSgnwucDvi5Etg67JxvAX8SkS8BccD7AEQkHvhH4P3AqKkdEbkVuBWgoKAgxKYrpRYTl8tFUVHRbDdj3gvXPP0bgIeMMXnAlcAjIuLAuhj8mzGmc6wXG2MeMMZsNsZszsjICFOTlFJKDRdKT78KyA/4Oc8+FugW4HIAY8wbIhINpGPdEXxERL4PJANeEek1xvzHlFuulFJqwsZdnCUiEcBR4FKsYL8LuNEYcyDgnGeBx4wxD4nIGuAlINcEvLmIfAvoNMbcO87nNQAnJ/Ad0oHGCZw/W+ZDO7WN4TMf2qltDJ+50M6lxphxUyXj9vSNMQMicjvwPOAEHjTGHBCRu4FSY8xTwB3Af4nI32IN6t5sJjnEHkqjA4lIaSir0GbbfGintjF85kM7tY3hM1/aCSEuzjLGPAM8M+zYNwIeHwS2jfMe35pE+5RSSoWRFlxTSqlFZCEE/QdmuwEhmg/t1DaGz3xop7YxfOZLO+delU2llFLTZyH09JVSSoVoXgf98QrBTfNn59tF5g6KyAER+Yp9/FsiUiUie+0/Vwa85qt2W4+IyAdm4nuISIWIvGu3pdQ+lioiL4hImf3fFPu4iMiP7HbsF5FNAe/zKfv8MhH5VJjbuCrg97VXRNpF5G9m+3cpIg+KSL2IvBdwLGy/OxE5y/67KbdfO95OfqG28Qcicthux+9FJNk+XigiPQG/z5+N15bRvm+Y2hm2v18RKRKRt+zjj4lIZJja+FhA+ypEZK99fNZ+l1NmjJmXf7Cmjx4DlgGRwD6gZAY/PxvYZD9OwFrLUIK1CvnOEc4vsdsYBRTZbXdO9/cAKoD0Yce+D9xlP74L+J79+EqswngCnAO8ZR9PBY7b/02xH6dM499rLbB0tn+XwIXAJuC96fjdAW/b54r92ivC1MbLgAj78fcC2lgYeN6w9xmxLaN93zC1M2x/v8DjwCfsxz8DbgtHG4c9fx/wjdn+XU71z3zu6fsLwRlj3ICvENyMMMbUGGPesR93AIew6hSN5hrgUWNMnzHmBFCO9R1m43tcA/zSfvxL4NqA4w8by5tAsohkAx8AXjDGNBtjWoAXsFdgT4NLgWPGmLEW6M3I79IY8yrQPMJnT/l3Zz+XaIx501hR4OGA95pSG40xfzLGDNg/vom1in5U47RltO875XaOYUJ/v3ZPejv/f3vn8hpFEMThr0DNIaioSBBBjBLPKjnkED0GFQ34QCJC1HgR9CAevOR/8CQoiCJIFPGFuQmKeFRJiC98JPEW4gYCmoMXH+Wha6U3ZDcJ25OdZeuDIUPtbu+vaiY10zW93XC/Gp2VNNp3HAXuVGpjKWJZLfWc9OeaCK5S0s0MEdkM7ABemumcda1vRF24cnqz9kMJk+ENSZjYDqBFVSdt/xvQUmONMT2U/mPlKZaQLnYbbT9LrQB9lE5r3iph3YsXIrLLbJW0lPM3FSmO7zrge3ShyyKWu4CCqo5GtrzFckHUc9LPBRJmEn0AnFfVGeAKsBXYDkwSuoS1pFNVdxLWQzgrIrvjF+1uJBdDuKwO2w0UV5rOWyxLyFPs5kJE+oHfwICZJoFNGta9uADcFpFV5T4/mwz8zfXxncUxSm9G8hbLBVPPSX8hE8FliogsJyT8AVV9CKCqBVX9o6p/gWuELmklvZn6oaoT9ncKeGR6CtYNLXZHp2qpMWIvMKyqBdOcq1gaqWI3QWnZJalWETkJ7AeOW4LByiXTtj9EqI9vm0dLOX+rJuHxnSaU05bNsifB2j0E3I205yqWi6Gek/5roM2e2q8glAUGl+rLrcZ3Hfioqpcie7yywUGgOBJgEOgRkSYRaQXaCA98MvNDRJpFZGVxn/CA7721XxxFcgJ4HGnslUAH8MO6o0+ALhFZY13wLrOlpuRuKk+xjEgSO3ttRkQ67FzqjdqqChHZA1wEulX1Z2RfL2ElPERkCyFuX+fRUs7fFDqTHF+7qD0HjmShk7A+yCdV/V+2yVssF0Utnh6n2ggjJr4QrrL9S/zdnYTu2VtgxLZ9wC3gndkHgQ3RZ/pN62eikRpZ+UEY5fDGtg/Ftgk10GfAKPAUWGt2ISyNOW4+tEdt9REeqI0BpzKIZzPhjm11ZKtpLAkXoEngF6E2ezpl7IB2QqIbBy5jP5ZMoHGMUPsunpdX7b2H7TwYAYaBA/NpKedvIp3Jjq+d66/M93tAUwqNZr8JnJn13prFstrNf5HrOI7TQNRzecdxHMdZJJ70HcdxGghP+o7jOA2EJ33HcZwGwpO+4zhOA+FJ33Ecp4HwpO84jtNAeNJ3HMdpIP4BPRu5V+okJU4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xl4XNWZ4P/vW6WttO+yVsu2vMnG2EbY7F4IBAPBgaxAJqGzkI3udALTgUn/kgwZkkmH9NBJE3roDE1CdwI03Ql0cCCAMQ6YxTJewHiRbMu29n3fSlXn98e9VSrtJam0v5/n8UPp1q2qU7J577nvOec9YoxBKaXUwuCY6QYopZSaPhr0lVJqAdGgr5RSC4gGfaWUWkA06Cul1AKiQV8ppRYQDfpKKbWAaNBXSqkFRIO+UkotIGEz3YDBUlNTTX5+/kw3Qyml5pQDBw7UG2PSxjpv1gX9/Px8iouLZ7oZSik1p4jI2WDO0/SOUkotIBr0lVJqAdGgr5RSC4gGfaWUWkA06Cul1AIyZtAXkcdEpFZE3h/heRGRn4lIqYgcEZGNAc99TkRK7D+fC2XDlVJKjV8wPf3HgetGeX4HsNz+cyfwCICIJAPfAzYDm4DviUjSZBqrlFJqcsacp2+M2Ssi+aOcshP4tbH2XXxLRBJFJBPYCrxkjGkEEJGXsC4ev51so4fT0+fhH14uITkmgqToCJJjIijMiicjPmrAecYYjle3sSIjDqdDpqIpSik1a4VicVY2cD7g53L72EjHhxCRO7HuEsjLy5tQI1o63Ty69zR93v49f8Odws712Xxly1IWp8TwhyOV/N/XTnO8uo3LC1L42ac3kBIbOaHPU0qpuWhWrMg1xjwKPApQVFQ0oZ3a0+OjKHlgB209fTR19FLf3sNzhyp5qvg8zxwoJyUmgoaOXpanx/KVLcv4lzfOcOPPX+fh2zeyMU+zTkqphSEUQb8CyA34Occ+VoGV4gk8vicEnzciESE+Kpz4qHAWp8Rw0eJk/urq5fzqzbMcr2rlk0W5bF+VjsMh3Lguk6/+2wE+9X/f5Ic3X8AninIHvFdvn5eXPqhh26o0oiNmxbVRKaUmLRTR7DngLhF5EmvQtsUYUyUiLwI/DBi8vRa4LwSfNy4psZF865oVQ46vzU7gD3ddydd/8y7f/o8jJEZHcE1hBgB9Hi9/9duDvHC0msLMeP75c0VkJ7qmu+lKKRVywUzZ/C3wJrBSRMpF5Asi8hUR+Yp9yi7gNFAK/DPwNQB7APcHwH77z/2+Qd3ZIiE6nEc/exEXZCfwl799lwNnm/B6Dff8+2FeOFrN7ZvzON/UyU0/f523TzfMdHOVUmrSxJp0M3sUFRWZ6a6yWd/ew8ce2Udrl5vLC1L5w5Eq/vuHV/L1bQWcqmvnS78q5lxjJ/942wauW5s5rW1TSqlgiMgBY0zRWOfpilwgNTaSX/3FJhwi/OFIFV/ftoyvbysAYFlaLL/7+uWsyIjjfz1/DLfHO8OtVUqpidOgb8tPjeG3d17CTz6+jnuuXTnguQRXOHdfu4Lypi6eO1Q5Qy1USqnJ06AfYEVGHJ8oykVk6KKt7avSWbUojl/sKcXrnV0pMaWUCpYG/SCJCF/bVsCpug7+9EH1TDdHKaUmRIP+ONxwQSb5KdE8/OopZtsAuFJKBUOD/jg4HcJXty7jvYoW9pbUz3RzlFJq3DToj9PNG3LITIjikT2lM90UpZQaNw364xQR5uDWTXm8dbqRuraemW6OUkqNiwb9Cbh6dToAr56oneGWKKXU+GjQn4DCzHgWxUex+5gGfaXU3KJBfwJEhO2r0/lzSR09fZ6Zbo5SSgVNg/4EXb0qnY5eD++cmVU15JRSalQa9CfosmWpRIY52H1cUzxKqblDg/4EuSKcXLYshVeO1epCLaXUnKFBfxK2r87gXGMnp+o6ZropSikVFA36k7B9lTV1c/fxmhluiVJKBSeooC8i14nICREpFZF7h3l+sYi8IiJHRGSPiOQEPPd3InJURI6JyM9kuBKWc1R2ootVi+J4RaduKqXmiGC2S3QCDwM7gELgVhEpHHTag8CvjTHrgPuBH9mvvQy4HFgHrAUuBraErPWzwNWr0yk+20RTR+9MN0UppcYUTE9/E1BqjDltjOkFngR2DjqnENhtP3414HkDRAERQCQQDsyrXMiN67LwGsPPd2stHqXU7BdM0M8Gzgf8XG4fC3QYuMV+fDMQJyIpxpg3sS4CVfafF40xxybX5NlldWY8n744j1+9Wcbx6taZbo5SSo0qVAO59wBbROQgVvqmAvCISAGwGsjBulBsF5ErB79YRO4UkWIRKa6rqwtRk6bP33x4JXFRYXz32aM6fVMpNasFE/QrgNyAn3PsY37GmEpjzC3GmA3Ad+xjzVi9/reMMe3GmHbgj8Clgz/AGPOoMabIGFOUlpY2wa8yc5JiIvibD6/inTONPKt76CqlZrFggv5+YLmILBGRCODTwHOBJ4hIqoj43us+4DH78TmsO4AwEQnHuguYV+kdn09dnMuFOQk8sOsYbd3umW6OUkoNa8ygb4zpA+4CXsQK2E8bY46KyP0icpN92lbghIicBDKAB+zjzwCngPew8v6HjTH/FdqvMDs4HcL9O9dS397D/3v9zEw3RymlhiWzLQddVFRkiouLZ7oZE3bro29R1dLFq/dsZR4tSVBKzXIicsAYUzTWeboiN8R2rs+irKGT9ypaBhzv6OnjxaPVM9QqpZSyaNAPsR1rMwl3Cs8NGtD96Z9O8uUnDnCium2GWqaUUhr0Qy4hOpwtK9L4ryOVeLxW6qy+vYffvHMWgIPnmmayeUqpBU6D/hT4yIVZ1LT2+DdY+eWfz9Db5yU6wsnBc80z3Dql1EIWNtMNmI+uKczAFe7kucOVrFoUxxNvlnHjuixau90cOq9BXyk1czToT4HoiDCuKczgj+9XkRgdTkevh69vK+CP71fx2skS2rrdxEWFz3QzlVILkKZ3pshNF2bR3Onmn147xXVrFrFyURwb8pIwBt4rbxn7DZRSagpo0J8iV61II8EVjjFw1/YCANbnJAJwUFM8SqkZoumdKRIR5uDr25ZR2dzN2uwEwJrZszQtRgdzlVIzRoP+FLrzqmVDjq3PTWTvyTqMMbpiVyk17TS9M8025CVR395LeVPXTDdFKbUAadCfZhtyrby+Tt1USs0EDfrTbOWiOKLCHZrXV0rNCA360yzc6eCC7AQOnddyDEqp6adBfwZsyEvi/cpWevu8M90UpdQCo0F/BqzPTaS3z8uxKt1IXSk1vTToz4ANedZgbvFZTfEopaZXUEFfRK4TkRMiUioi9w7z/GIReUVEjojIHhHJCXguT0T+JCLHROQDEckPXfPnpswEF8vSYthzonamm6KUWmDGDPoi4gQeBnYAhcCtIlI46LQHgV8bY9YB9wM/Cnju18BPjDGrgU2ARjpg28p03j7dSGdv30w3RSm1gATT098ElBpjThtjeoEngZ2DzikEdtuPX/U9b18cwowxLwEYY9qNMZ0hafkct31VOr0eL/tKG2a6KUqpBSSYoJ8NnA/4udw+FugwcIv9+GYgTkRSgBVAs4j8p4gcFJGf2HcOC15RfjIxEU5e1RSPUmoahWog9x5gi4gcBLYAFYAHq7bPlfbzFwNLgTsGv1hE7hSRYhEprqurC1GTZreIMAdXLE9lzwmrDo9SSk2HYIJ+BZAb8HOOfczPGFNpjLnFGLMB+I59rBnrruCQnRrqA34PbBz8AcaYR40xRcaYorS0tAl+lbln28p0Kpq7KKltn+mmKKUWiGCC/n5guYgsEZEI4NPAc4EniEiqiPje6z7gsYDXJoqIL5JvBz6YfLPnh60r0wHYfVxTPEqp6TFm0Ld76HcBLwLHgKeNMUdF5H4Ruck+bStwQkROAhnAA/ZrPVipnVdE5D1AgH8O+beYoxYlRFGYGc+rGvSVUtMkqHr6xphdwK5Bx74b8PgZ4JkRXvsSsG4SbZzXtq1K459eO01rt5t43TdXKTXFdEXuDNu2Mh2P1/B6Sf1MN0UptQBo0J9h63MTSXCF89IHNTPdFKXUAqBBf4aFOR18dH0Wzx2u5Hi1FmBTSk0tDfqzwDevWUF8VBjf/f3RUefsP3+kigNapE0pNQka9GeBxOgIvn3dKt4pa+T3hyqGPedUXTt/9eRBfr67ZJpbp5SaTzTozxKfLMrlwtxEHnj+OK3d7iHP/90Lx/F4DWcbtHSRUmriNOjPEg6H8IOda2jo6OGhlwb25ovLGnnxaA1J0eGcb+ykz6M7bimlJkaD/iyyLieR2zbl8S/7zvDwq6UYYzDG8MNdx0iPi+QbVy+nz2uobO6e6aYqpeaooBZnqenz/91YSHtPHz958QTHqlrZviqdd8818+OPXUB+SgwAZQ0d5KVEz3BLlVJzkQb9WSYq3MlDn1pPYWY8//uF4/zhSBUrMmL52MYcGjp6ATjb0AEsnMJ0SqnQ0fTOLCQifHnLMh6742KWpsXw/Y+sIczpID0uEle4kzP1OpirlJoY7enPYttWprPNrsQJ1sVgcUq03dNXSqnx057+HJOfEkOZBn2l1ARp0J9jFqdGc76xC49Xd9tSSo2fBv05Jj8lhl6Pl6qWrpluilJqDtKgP8cstqdq6spcpdREaNCfYwLn6iul1HgFFfRF5DoROSEipSJy7zDPLxaRV0TkiIjsEZGcQc/Hi0i5iPxjqBq+UC2KjyIizKE9faXUhIwZ9EXECTwM7AAKgVtFpHDQaQ8CvzbGrAPuB3406PkfAHsn31zlcAiLk6Mpq9eevlJq/ILp6W8CSo0xp40xvcCTwM5B5xQCu+3HrwY+LyIXYW2W/qfJN1cBLE6J0Z6+UmpCggn62cD5gJ/L7WOBDgO32I9vBuJEJEVEHMBPgXtG+wARuVNEikWkuK6uLriWL2BLUqM529iBV6dtKqXGKVQDufcAW0TkILAFqAA8wNeAXcaY8tFebIx51BhTZIwpSkvTmjJjWZwSQ7fbS02bVttUSo1PMGUYKoDcgJ9z7GN+xphK7J6+iMQCHzPGNIvIpcCVIvI1IBaIEJF2Y8yQwWAVPP8MnvpOMhNcM9wapdRcEkxPfz+wXESWiEgE8GngucATRCTVTuUA3Ac8BmCMud0Yk2eMyce6G/i1BvzJ65+rr4O5SqnxGTPoG2P6gLuAF4FjwNPGmKMicr+I3GSfthU4ISInsQZtH5ii9iogK9FFuFMo08FcpdQ4BVVl0xizC9g16Nh3Ax4/Azwzxns8Djw+7haqIZwOITdZq20qpcZPSyvPUfkpMZysaWNfaT0VzV209/Rx2+Y8IsOcM900pdQspkF/jlqaGsPu47Xc9su3/cfS46K4YV3mDLZKKTXbadCfo76ydRlrsxNIj48kPS6KHf+wl/crWzToK6VGpUF/jkqNjeSjG/rXyC1Pj+P9ipYZbJFSai7QKpvzxNrseD6obMUYXaWrlBqZBv15Ym12Ag0dvVS36ipdpdTINOjPE2uy4gF4v6J1hluilJrNNOjPE6sz4xGBo5Wa11dKjUyD/jwRHRHG0tQY7ekrpUalQX8eWZudoD19pdSoNOjPI2uzEqhq6aahvWemm6KUmqU06M8jvsHco5X9KZ6fvVLC5x57Z6aapJSaZTTozyNrshKA/qBf09rNw6+W8trJOs43akVOpZQG/XklITqc3GQX79t5/Uf2nKLX4wXgtZO6DaVSSoP+vLMmM4GjFS1UtXTxm3fO8cmLcslJcrHnhAZ9pZQG/XlnbXY8ZQ2d/N0LJ/B6DXdtL2DryjT2naqnt88b1HsYY6hq6ZriliqlZkJQQV9ErhOREyJSKiJDtjsUkcUi8oqIHBGRPSKSYx9fLyJvishR+7lPhfoLqIHWZFt5/d8drOATRbnkJkezdUU6nb0eissag3qPXe9Vc+WPX6VGSzooNe+MGfRFxAk8DOwACoFbRaRw0GkPYu1/uw64H/iRfbwT+KwxZg1wHfCQiCSGqvFqKN8MnnCncNf2AgAuXZZChNPBniDz+ofLm+nzGk7VtU9ZO5VSMyOYnv4moNQYc9oY0ws8CewcdE4hsNt+/KrveWPMSWNMif24EqgF0kLRcDW89LgoVmbEccdl+WQnugCIiQzj4iVJvBZkXr+01gr25U2a4lFqvgkm6GcD5wN+LrePBToM3GI/vhmIE5GUwBNEZBMQAZyaWFNVsP74jSv5H9evHnBsy4o0TtS0Udk8diDXoK/U/BWqgdx7gC0ichDYAlQAHt+TIpIJPAH8hTFmyGiiiNwpIsUiUlxXp7NMJsvhEERkwLGtK9MB2DtGiqfb7eF8kzWnv1zn9is17wQT9CuA3ICfc+xjfsaYSmPMLcaYDcB37GPNACISDzwPfMcY89ZwH2CMedQYU2SMKUpL0+zPVFieHktmQtSYUzdP13Xg24dFe/pKzT/BBP39wHIRWSIiEcCngecCTxCRVBHxvdd9wGP28Qjgd1iDvM+ErtlqvESErSvTeKO0nn2l9bx7rokT1W14vAN32iq1B28LM+Mpb9KevlLzzZhB3xjTB9wFvAgcA542xhwVkftF5Cb7tK3ACRE5CWQAD9jHPwlcBdwhIofsP+tD/SVUcK4pzKCtp4/bfvk2t/xiHx9+aC+P7CkdcE5pbTsOgStXpFLd2h303H6l1NwQ1MboxphdwK5Bx74b8PgZYEhP3hjzr8C/TrKNKkS2rUxn119dSWu3my63hx8+f4y9JfXctX25/5xTte3kJkezLC0Wr4Hqlm7yUqJnsNVKqVAKKuir+UFEKLTn8QO8UVLPr986S7fbQ1S4E7B6+gVpseQkWdM9zzd1atBXah7RMgwL2OalKfT2eTlSbhVo6/N4OVPfQUF6LLlJVqDXvL5S84sG/QXs4vwkAN450wDA+aYuej1elqXHsighCofoDB6l5hsN+gtYYnQEqxbF8fYZqyaPb1FWQXos4U4HmQkuDfpKzTMa9Be4zUuSOXC2CbfHOyDoA+QkuXTzFaXmGQ36C9ymJSl09no4WtlKaW076XGRxEeFA5CTFK09faXmGQ36C9zFS/rz+qW1bf5ePlg9/Zq2bnr6PCO9XCk1x2jQX+DS46JYmhbD26cbOVXXMSToGwNVzVpXX6n5QoO+YvOSZP5cUk97T9+AoJ+b7Ju2qSkepeYLDfqKTUuS/RuoF6QN7OkD/qqbSqm5T4O+YtOS/q0PAnv6i+KjcDpEF2gpNY9o0FdkJ7rISXIRFxVGWlyk/3iY00FmQpSmd5SaR7T2jgLg0xfnUtXSPWTzlVydtqnUvKJBXwEMqLQZKCfJxd4S3c1MqflC0ztqVDlJ0dS09tDt1rn6Ss0HGvTVqHwzeCqbu2js6OXHLxznPw6Uh+z9f3ewnPfsKp9Kqamn6R01Kt9c/Z++dJK9J+po6+kjO9HFxy7KmfR7d/b28d///QhXrUjjsTsunvT7KaXGFlRPX0SuE5ETIlIqIvcO8/xiEXlFRI6IyB4RyQl47nMiUmL/+VwoG6+mnq+n//yRKjYvTeGOy/KpaO6isnnyg7v7y5ro8xreOdNIn0e3ZVRqOowZ9EXECTwM7AAKgVtFpHDQaQ9ibX6+Drgf+JH92mTge8BmYBPwPRFJCl3z1VTLTIjiBx9dy9NfvpRffq6Ij9s9/P1ljZN+7zdPWXX823v6eK9CUzxKTYdgevqbgFJjzGljTC/wJLBz0DmFwG778asBz38YeMkY02iMaQJeAq6bfLPVdBER/tsli9m0JBmAVYviiIlwjivo9/R5qGkdWr/nzdMN/sVgb55uCE2DlVKjCiboZwPnA34ut48FOgzcYj++GYgTkZQgX6vmkDCng42Lkyguawr6Nf/wcglX//Q1Wrrc/mOt3W7eK2/m+rWLWJkR5+/1j8TjNRNus1KqX6hm79wDbBGRg8AWoAIIeo6fiNwpIsUiUlxXp3PCZ7uL85M5UdNGS6d77JOB3cdrae/p478OV/qP7T/TiNfAJctSuHRZCsVlTfT2DZ/Xf/dcE5seeJmHXy0NSfuVWsiCCfoVQG7Azzn2MT9jTKUx5hZjzAbgO/ax5mBea5/7qDGmyBhTlJaWNs6voKbbxfnJGAMHzo2d4qlt7eZ4dRsATxf33/TtO9VARJiDjXlJXLI0hS63h8PlzUNe/+eSOm7/57dp7Ozl4VdLqW/vCd0XUWoBCibo7weWi8gSEYkAPg08F3iCiKSKiO+97gMesx+/CFwrIkn2AO619jE1h63PTSTcKbxzZuwUz59L6gH42MYcjpS3cKyqFbAGcS/KSyIq3MklS5MRgX2lA1M8u96r4vOP72dxSjRPfukSut0e/mnPqdB/IaUWkDGDvjGmD7gLK1gfA542xhwVkftF5Cb7tK3ACRE5CWQAD9ivbQR+gHXh2A/cbx9Tc5grwsna7ASKgxjMfb20npSYCP7H9asIdwpPF5+nqaOXY9WtXLrMqu6ZGB1BYWY8b56u97/ulWM13PWbd1mXk8hTX76UzUtTuGVjDk+8dZbqFt3URamJCiqnb4zZZYxZYYxZZozxBfTvGmOesx8/Y4xZbp/zRWNMT8BrHzPGFNh//mVqvoaabpvykzlS3jJqeQZjDH8uqefyglRSYiO5tnARvztYwd6SOoyBy5b1l3S+dGkK755rptvt4XxjJ996+jCrM+N54gubSHBZe/Z+4+rleLxmxNx+n8fLnb8uDupipNRCpWUY1IQU5Vsbrxw+PzQP73O8uo369h6uXJ4KwCeKcmjudPPgn07gCneyLifRf+6ly1Lo7fPy1ukG7vrNu3iN4ZHbLyI6on/ReG5yNJ+6OJcn95/jfOPQGv9lDR386YMafndwyLCRUsqmQV9NSNFia41d8dmR8/p/tqtzXrk8zf/fzIQozjd2UZSfRERY/z+/TUuScTqEu58+zOHyFn7y8QvJS4ke8p53bS9ARPj57pIhz52u6wDg0CgXIqUWOg36akKSYiJYnh7LO2dGTqX8uaSegvRYFiVEAeB0iH9F72XLUgecGxcVztrsBBo6evnCFUu4bu2iYd8zM8HFDRdksvv40Km9Z+qtoH+8uo2u3uCrgvZ5vFoGQi0YGvTVhF28JJl3zzYNu3Cq2+3hnTON/tSOz22b89iUn8wNF2QOec3tm/O44YJMvn3dqlE/d3VmHPXtPTR19A447uvpe7xmXGUdPvvYO3znd+8Hfb5Sc5kGfTVhG3ITaevp8/ewAxWXNdHT5x0S9DMTXDz9lUuHTd18siiXh2/fOCDtM5zlGXEAlNS2Dzh+pr6DpWkxABw8F/yK4ZM17bz4QTXeKV71a4yhtk1nHqmZpUFfTdiarAQAjlYO7VX/uaSOcKewOWDT9VBZbtfrKaltG3D8dH07RYuTyEuODjqv7/Uamjp7ae5084G9hmCqvHyslkt/tJv3tbhcUFq73Xz/uaN09vbNdFPmFQ36asIK0mMJd8qwwfL10no25iURExn6LRuyE13ERDgpqenv6bd0ualv72VpWizrcxM5eC64oN/S5fanp94orR/j7Mk5Vdc+6pRTNdC+0gYe31fG/nHUeVJj06CvJiwizMGKjDg+qBwY9Nt7+jhW1cpmuzJnqIkIBRlxA3r6ZXaKaUlqDOtzE6lu7Q5qEVdDwLjAG2MUfZus2lZr+coLR6spHXSXooaqs0tu1Ldp6Y1Q0qCvJqUwM54PKlsxpj8ffuR8M14DGxdP3dYJy9NjORnQ0z9dbz1elhbDhjxr/v+h82P3EBvswLIsLYZ3zjTQ0zd1ewHXtHWTFhdJVJiTX2g5iTHV2eW4td5SaGnQV5OyJiueho5ealr7/8c8YM/d35A7dUF/RUYsdW09NHdaPfUzdR04xFrAVZgVT4TTEVSKp9Hu6d90YTbdbm/QaaGJqGvtYWlqDLduyuPZQ5XDLjBT/Xw9/Trt6YeUBn01KWuyrcHcD6r6ByffPdfE8vRYEqLDp+xzl6cPnMFzqr6DnKRoIsOcRIY5KcyK52AQg7n1dtC/Yd0iHDK1ef2atm7S46O486qlOAQe3Xt6yj5rPvAFe+3ph5YGfTUpqxZZwfdohZXX93oNB883szFvanfFXJ5hzeA5WWPlxs/U9U/XBKsS6HvlLWMuumpst4J+XnIM63ISpyzoG2Oobe0hIy6SRQlRfPyiHJ4qPq9TOEdR6w/6vWOcqcZDg76alLiocPJTojlqD+aeru+gudPNRVOYz4eBM3iMMZyp72BJan/Q35CXSJfbw4ma0QdMGzp6iI8KIyLMweUFKRwub6Gt29ocprO3j6f2nxu1qBxYPdKHXj5Je8/IUwvbevrocntIj48E4MtXLaO3z8u/F5cH+5UnrLO3j9phtquc7Xw9fU3vhJYGfTVphVnx/mmb79qLojYuThztJZMmIhSkx1JS20Z1azddbg9L02L9z/vGE8bK0Td09JIaawXiywtS8XgNb59upL69h1sffYtv/8d7/MsbZSO+3uM1fOPJgzz0cgm/GGUqpm/mTka8VZIiPzWGFRmxvDUNewP/9E8nuf5nr+OeQ6UmvF7jT+toeie0NOirSVuTlcC5xk5au90cPNdEfFQYS1Njx37hJC3PiKOkpp0zdvmFpQE9/dxkF8kxEf6L0Ega2ntIiY0AYGNeEpFhDp45UM7HH9nHiZo2lqbG8MSbZSOmiX7xain7TjWQnxLNY2+cGXYDeMDf006Li/Qf27wkhQNnm6Y8GB+raqW+vWdc+xrPtOYuN26PIS4qjMbOXq2NFEIa9NWkFWbGA3CsspUDZ5vYuDgJh0Om/HOXp8dS29bjH7ANTO+ICFtXpvGHw1WcqB45xdPY0UtyjBX0o8KdXJyfzAtHq2npcvNvX7yEe3esorKlm5c+qBny2nfONPJ/Xj7JzvVZ/Przm/F4DQ+9PLT6J/Tnp309fYDNS5Pp7PVM+Qpd3xqGl48N/Q6zlS+lU5gZjzH9s6zU5GnQV5O2JssK+m+dbqSktn3KB3F9Vtg1eP50tBpXuJNFAQEV4DvXrybeFcY3njw44vz7hvZeUmL7e9+fujiXC3MTeearl3HR4iSuXp1BTpKLf9lXNuB1TR29fOPJg+QlR/PAzReQlxLN7Zu19OWTAAAgAElEQVQX83TxeU7VtTOY7w4gPaCnv8levPb2KJVKJ6vb7aHSXqT28rGaAespxqOjp2/Cr50If9C3/23VhTjF4/Ua/v6lk9OyC1tlcxfHq6e2xMd4BBX0ReQ6ETkhIqUicu8wz+eJyKsiclBEjojI9fbxcBH5lYi8JyLHROS+UH8BNfPS4iJJjY3gqf3nMIYpH8T18c3gOVzeQn5qzJC7i5TYSH78sXUcr27j7186OeT1HrvuTord0wf4yIVZPPv1y1lmjw84HcLnLs3nnTON/hpDnb19fPlfD1Df3sM/3raRWLvUxF3bC4gKc/DgiyeGfFZtWw/REU7/uQDpcVEsTYvh7SnM65+z1wJsyk/mbEPnsBeksXT09HHJj17h394+F+rmjcg3q2m1fRcZ6hk8Zxs7+dkrJbzwflVI33c4Dzx/jK/927tT/jnBGjPoi4gTeBjYARQCt4pI4aDT/hZr79wNWBun/8I+/gkg0hhzAXAR8GURyQ9N09VsISIUZiVQ2dKNQ+DC3KkdxPXJSnARHeEEGDBdM9DVqzO4dVMej+49PSS4Nnf24jUMCPrD+WRRLq5wJ4+/UUZnbx+ff3w/xWWN/PST61lrr1MASI2N5EtXLeWP71cPqfJZ09pNelwkIgMvTJuXpFBcNnx56lDwVUD9wpVLAHjpg9pxv8d7FS20dffxwvvVIW3baALTOxD6Ugy+RX3TkTY6Xt06q2YgBdPT3wSUGmNOG2N6gSeBnYPOMUC8/TgBqAw4HiMiYYAL6AVmz32OChnf/5wrMuIG9GanksMh/oqbgYO4g/3tDatZnBzN3f9+eMCAoO9/+OSA9M5wEqLDuWVjNs8eruSOx/ZbufxPreemC7OGnPvFK5cSHeHk94O2bKxt6yF9UPoJ4JKlybT19A2pXzReFc1dbH9wz5Dxi7MNVtC/ZEkKa7PjeWWUvP6Z+o5hq5P6tsR8p6xxXJvTTEZdWw+ucCf59t9rqNM7zV3WtNyGKQ76vX1eyho6aevumzWD0cEE/WzgfMDP5faxQN8HPiMi5cAu4C/t488AHUAVcA540BgzJIEpIneKSLGIFNfVDd0RSc1+vrz+dKV2fArslbkj9fQBYiLD+Nq2AsqbuvzpDuhPGaSO0dMHuOOyfHr7vOw/28hPP3khO9cP/l/AEhsZxoqMuAF1gcCavROYz/fxlZ5++8zkUjwvvF/N6foOXjs5sCd/pr6TpOhwEqLD+dDqDA6ca/LXGxrsgeeP8cVf7R+Suz9S3oKIFcDemmQ7g2VdJCOJiXASFe4IeU+/pdMK+lPd0y9r6PDfxbXYF5qZFqqB3FuBx40xOcD1wBMi4sC6S/AAWcAS4G4RWTr4xcaYR40xRcaYorS0tBA1SU2n9bmJhDmEywtSxz45hFbYef0lY0wRXWZfFMoa+jd86e/pjx30l2fE8Z3rV/PI7Rdx84acMdt0ctCisNq2ngEzd3wWJUSxOCV6wGDuG6X1fOPJg+NK+ew5YQX79ysG3jGU1Xf4e8sfWp2BMbD7+PApnpLaNurbeykdtDnN4fJmrl6VTmSYg9dOTE+nrK6th7RYKx2WFhcZ8rn6vvTOVPf0A3+XzXMo6FcAuQE/59jHAn0BeBrAGPMmEAWkArcBLxhj3MaYWuANoGiyjVazT25yNG/cu50dI+xtO1VuWJfJZy7J86eXRpKfYgf9+v6efkOHFUhSYkZP7/h86aqlI+7dG2hFRhwNHb3+QNXe00dnr2fYnj7A5iXJ7C9rxOs1lNS08ZUnDvDsoUqqWrqCaldnbx9vn7YuGoOnf55t6GCJ/d3XZMWzKD6KV44NDfrdbo+/AFzggrGG9h7Km7q4OD+ZzUtT2FsyPUG/tq3bv3o5NTZyytI7U93TD9zzoblz7gT9/cByEVkiIhFYA7XPDTrnHHA1gIisxgr6dfbx7fbxGOAS4Hhomq5mm4z4qCEDlVMtJyma//XRC8bcYjE5JoK4yLABPf0GO72TFOLCcL6ppL7evm+65nA9fbBSPM2dbt4608AXflVMh71TVGDl0tG8eaqBXo+XzUuSOV3f4S8j4ZuuudgO+iLChwrT2VtSN6S0xNmGTnw3Fm+d7r/rOFJuXUTW5SRy1fJUTtd1UN409dVBfT19sIJ+fVtog3PzNKV3SusCN/qZHWsNxgz6xpg+4C7gReAY1iydoyJyv4jcZJ92N/AlETkM/Ba4w1iJwYeBWBE5inXx+BdjzJGp+CJKjUZEyE+NGbCfb0NHD0nR4YQ5Q7tcZaVdhM7Xy/OVYBixp7/Umq9/568PUN3azf/cuRaAumGKsf3b22f5r8OVA47tOVFHdISTv7jcmqHjGxQ+22AF5/zU/v2It69Kp7PXM2Slsm8q58qMON463eDP6x8ub0YELshJYMsKK/W69+TU7jDW7fbQ2t3nX708lemdps7eKZs5BVBS0+Yfb2rqmB09/aCmWRhjdmEN0AYe+27A4w+Ay4d5XTvWtE2lZlx+aox/JgoMXI0bSulxkcRHhfmLvfnmnA83ewesu5XsRBcVzV089Kn1XF6Qyv/3+/eH7ek/sucUzZ1uLi9IJTkmAmMMr56o5bJlqf56R+9XtrJ5aYr/riZwpfKFOdY5RytauWxZ//iLL/d82+Y8vvfcUUpr21meEceR8hYK0mKJjQyjID2WzIQo9p6s47bNeRP+/dS2dfPxR94EICkmguTocP7i8iVcZV9UfNMb0+Os31dqbKS/FEOoLtC+9I4xVuBPHWMG10R4vIbT9R3cvD6b03Udcyqnr9S8kJ8STXlTJ7191tS5+kGrcUNFRFiREUeJL+j7evrxI3/W3deu4P6da/johmxSYiJwOmRI2WWv11DT2k17Tx//9Jq189apug7Km7rYujKN9Lgo0uMiOWrn9X3lF3zpHbAWrGUlRPH+oM3sT9W1k53oYtvKdAB/b/9IeTPr7AuFiHDV8jTeOFU/qemH755t4lxjJ8vSYoiPCqP4bNOAvQV8+Xt/Tz82IuSlGALz61OV4jnfaP1b25CXiAi0dM6R9I5S80V+SgxeA+ftnHRjR++YC7MmasUia9qmMVagdoU7iRtl/cItG3P47KX5gLX+IC02ckhPv76jxypCFhnGr/aVUd3S7Z+1s3Wl1Uu+IDuB93xBv6GD5JgIElwDxyzWZCcMGfA9VddOQXosuckushKieOt0I5Ut3dS397I+t38B2lUr0mjr7ht2Pn+wfGmvh2/fyBNf2MxNF2Zx6HyzP83i6+kHpncgtHP1W7rc/r/7himq1++7e1qxKI4EV7j29JWabr6pi74FS4EVNkNtRXosLV1uatt6/HPOxzPInR4f6S/S5uOrE/Ota1fgNYZ/eKWEPSfqWJ4eS06Slbdfk53Aqbp2Onv7KKvvJD8lesh7r81K4HR9Bx12/X+v13CqtoNlabGICJcsTeGt0w0csstS+3r6AFcUpOIQ2Hty4rN4SmrbyUlyER1hXQQvWpxEe0+ff+C7tm3gGIgv9RLKVa3Nnb3+UhtT1dP37epWkB5Loit8Ts3eUWpe8OW2z9R30ufx0tzlJjnI6ZrjtWJR/wyemtZuMuKGz+ePJD0uasjGJ1V20L84P5nbNuXxdPF53j7TwLZV6f5zLshOwGuscsplDR3+qaqB1mZblSuP2XsgVNn7ESxLt869ZGkKDR29/Oe75YQ7hVWZcf7XJkSHsz43keffq5rwAOjJmjb/SmrAX6DPN7hc19aDCP7xFl/QH6n+TrfbwwvvVwVdEM7rNbR0uf0DrI0dI19M2rrdfP7x/RPaz7i0tp2M+Ejio8JJiI6gSdM7Sk2vpOhw4qLCKKvvoKnTjTGQOlU9fXva5onqNmv64Sj5/OGM1tNflBDF17cXEOF04PYYtq7oX9C4Nttar7C/rImqlm7/3U0gX70gX4rnlN0j9fV8L1lqrRJ+5XgtqzPjiQxzDnj9569Ywqm6jiGziILR5/Fyur6D5Rn9F5LFKdGkxETw7lnrzqKurYeUmAj/oK0vvTPSDJ7H95XxlX99d8gq6JG09fThNf2dgNEWaL1X0cLu47W8emL8NYtKa9sosC9uSdHh825FrlKznoiwJDWGsoaO/tW4U5TTT42NJCUmgpKa9gn19DPiomjs6PUPOoPV049wOkiOjiA9Loqvbl1GelwkRfnJ/nMWxUeREhPBrves6pHDBf30uEhSYyN5357a6Zuu6QtQuckushNdQP9sn0DXr81k1aI4Hnr55Lg3gDnf1EVvn3dAT19E2JCXFNDT7yYt4PcVExmGK9w5Ynrn2UPWxSfY3rhvumZqbCQJrvBR0zu+NRaDVymPxRhjzYCyy4RoekepGZKfYgV9X/2ZYFfjTsTyjFgOnm+io9cz6syd4fjODxy8rG7pIiMh0l9C+i+3F7Dv3u0DFqaJCGuzE/yLqobL6VvnxPt7+qW17SS4wv0DmyLiXzuwLidhyOsdDuHua1dS1tDJf747vj1+fTOaAnv6YOX1z9RbF+O6tp4BO4wBpMZFDNvTP1nT5k9TVQa5gtkXfBOjre88Wk/fl1Ibb9Cvaummo9fDMvvilhgd4b/YzDQN+mpByU+JpqKpi2q7BzdVA7lgLXTypRwyxhn0fecHbr9Y1dJNZrzL/7OIDDtv3ZfigeF7+mAN5pbUttPt9nCqrp1laTEDBpq3rEhDZOQCeh9anc6FuYn87JXSETeoGU7g4GagjXnWHcW7Z5sGrMb1SYsdfoHWs4cqcAiEOYSK5iCDfld/0E+OiRixAB1AzQSDvu97+u5oElzhtHb3TelCsGBp0FcLSn6qNW3TN+VwqqZswsDebPoEBnKhf44/QHVrN4sSxn6fC+ycfUpMBPFRw5eYWJsdj8drOFHdxqm6Dn8+3+emC7N4+VtbBmw2H0hEuOfaFVQ0d/HU/vPDnjOckpo2shNdQ8pvr8uxCvYdONdEXXvPkDuj1NjIIekdYwzPHqrk8oJUspNcVDYPXcF8z78f5uuDNjDx9bgTXBEkx0SMmt7x9fRr23po7Q4+PVM66OKWaJf6GC2vX9/eMy3llzXoqwXF1/M9cLYJEeu2e6r4yjHA+Hv6/vSOvUDLGGP19IMI+muyrKC/eJjUzuBz9p1qoK6tZ0jPW0SGXAgGu6IglU1Lkvn57uB7+yW17UM+C8AV4aQwK55Xj9fi9pghPf3UuMghs3fePddEeVMXH12fTVaCi8phevoHzjYNWVPQEtDTT4kdPejXtHYT7rTugMbT2y+tbSMpuj9llmT/OxstxXPvfxxh58NvBP0ZE6VBXy0ovimMx6paSY62Vr5OlRXp/UE/bZw9/ZSYSBzSX3TNN6gbTE8/J8lFamykfwbRSOckuMJ59pBVMHesAD8cEeGrW5ZR19bDn4Oox+Px+gY3h/+sjXlJHLc3gRmc00+LjaSps3fAwPGzhyqJDHNw7ZoMshKHBv0+j5fypk5qWrsHpFV8OX1rHCOSpk433hHSLlUt3Wywp5SOL+hbFzdfyizB7umPtECrz+Pl7dON07LrnAZ9taAkRYcTHxWG10zdzB2fhOhw0uMiiQp3EB81vt3EnA6rjryvFIMvzRBMT19EeOrLl/A3160a9Zy12fH+ILtshEA8liuWp5IYHc4fjow9fbO8qZOePu+IF6ONAeMHg4vTpcZFDijF4PZ4+cORKj5UmEFcVDjZiVHUtHYPuChUtXTj9hj6vGbAeEBzp5vYyDDCnQ6SYyLw2PP2B3N7vNS197ApP5kIp8M/tXUsxpghdzSJ9qrolhFm8LxX0UJbTx+XLUsJ6jMmQ4O+WlB80zZhagdxfVYuimPRBEtOZ8RH+Xv6/XP0XaO9xG9ZWuyYF7W1doonwukgNym49x0s3OngujWLeOmDmiHlmgfzlV8oyBipp9/fyx3a07e+iy+v/3ppPY0dvey0t6zMSnThNQMHvn1VRoEBdwHNXb3+0hS+fwPDzeCpa+vBGMhOcrEkNWZIT7+iuYs3Sofe4dS29dDc6WZlwMXNl0ZsHqG88r5T1h4Gly7VoK9UyPny+lM5XdPn3h2r+OHNF0zotelx/Qu0quxglhVETz9Ya+wB3/zU6ElVr7xxXRYdvR5/HaCRnKy17iqGy+kDZCe6/GMfQ4J+wAKtmtZuHnzxBAmucLbaBeKy7HUFgYO5gXsn+O6UwOpt+wZWfRfG4fL6vhlei+KjKEiPHVAbH+CHzx/j84/vH7JWwXf3tHJR/ywqX09/pPLKb5TWszozfkoKAA6mQV8tOL6qk9PR01+TlcBlE9xCMj2+vxRDdUsXYQ4JaVBYa+9rPJF8fqBLliaTEhPBfx2pGvW80pp2MhOiRpxRJCJszEvCFe4cMrvHV4rhlWO1fOTnr3OmvoMHP3Ghf41CdpIv6Pf36M81duIbsgk83tTZ6x9Y7Q/6Q6dtBq6AXpYey/nGTv/djNvjZe/JOnr6vEPuAI7b6wZWBQzkx7vCERk+p9/t9lB8tmlaUjugQV8tQEvsTUWmOqc/WelxkTR0WIOXVS3dZMRHhXTgOT8lhpwkFxcHrOidiDCng+vWLmL3sVo67V2/hjPSzJ1A3/jQcn788XVD0mG+oP/EW2eJDHfwn1+7jGsKM/zPZ9lpr8C5+mX1HSxNiyUq3DGgp9/c5fYPrPru9oZL7/he4+vpew3+TXj2lzXSZhesG1yx9ER1GxnxkSQF/PtyOoT4qPBhyyu/e7aJ3j4vlxfMoqAvIteJyAkRKRWRe4d5Pk9EXhWRgyJyRESuD3hunYi8KSJHReQ9EQnd/alSE5Dv7+lP/a30ZPi2V6xr66G6Jbg5+uPhcAh7//s2/uLy/Em/143rsuhye4bdfxesImeBZQlGsmpRPDfZefpAMZFhLEmN4fKCFJ79+hWsWjRwT2RXhJPkmIghPf38lGiyElwD9htu6XT70y1JMdZ/hyuvXNPaTWSYg8TocArsuyFfr37PiTrCnYIr3MnRyoGb0R+rbhvSPrCmiA7X03/jVD1Oh7BpyfQE/TGnFIiIE2vbw2uAcmC/iDxn75bl87dY2yg+IiKFWLts5YtIGPCvwH8zxhwWkRRgdhSgUAtWYVY8n7goZ0ChstnIN4Ol1g76q7NG3/x9IhwhunPYtCSZtLhI/nCkko8ME7QrmrvocntYMcIgbjBe+uZVo449ZCVG+YO+MYazDZ1cXpBKt9vrz/UbY2ju6s/pR4ZZ+xwMl9Ovsi+0IsLStBhE+oP+7uO1bF6SQrfbw9GADWncHi+natu5avnQlN5I9XfeKG3gwpyEISmtqRJMT38TUGqMOW2M6QWeBHYOOscAvn+RCYBv/ta1wBFjzGEAY0yDMSb4NdtKTYHIMCc/+cSF5CaPvHhpNvD19Gtau6ls6SJzhO0WZwOnQ7jhgkxePVFHe8/QFE9Jra/mzsSD/liDzdYCLSu417X10OX2sDglmsyEKH9Pv73HKoWQ6OpPvaTEDl9/p8ZOqQFEhTvJTYqmtK6d842dlNa2s21VOmuy4vmgstU/z/9MfQe9Hu+ActQ+CcPU32ntdnOkvJnLJzjuMxHBBP1sIHCddbl9LND3gc+ISDlWL/8v7eMrACMiL4rIuyLyN5Nsr1ILhq+nX1LTRrc7uIVZM+nGdZn09nl55VjNkOdOVNvTNdNGT+9MRuACrTJ7uubilBgyE13UtvXg9nj7F2ZF9w8mW6UYhg7kVrV2DVgXUZAey6nadnYft1JY21elsyY7gY5ej3+mkK/428qMYdI7w+ye9c7pRryGAfsVT7VQDeTeCjxujMkBrgeeEBEHVvroCuB2+783i8jVg18sIneKSLGIFNfVTXxHHqXmk5RYa1XuofNW+iAzyDn6M2VDXhIJrnBeLxk6d/2dMw0sTY0ZEGxDLTvRRVtPH63dbn8QXpwcTVZCFMZYs3H8JRhcgUE/ckhO3xhDTUsPi+IHBv3T9R28fKyGJakxLEmN8a918JWpPlHdRphD/BvSBEqKHpreeeNUPZFhDjbkTf1KXJ9ggn4FkBvwc459LNAXgKcBjDFvAlFAKtZdwV5jTL0xphPrLmDj4A8wxjxqjCkyxhSlpc3uPKtS08XpEFJjIzlSbtWOme09fadDuHRpCvtONQzYxcrt8fLOmcYpT2H0z9Xv4lxDJ06HkJ3kItM+XtXSHVBWOSC9M0zRtcaOXno9A++uCtJi6e3z8ueSev8G8sszYolwOvx5/ePVbSxNixmy8QxY6Z3WbveAkhD7Shu4OD+ZqPCh50+VYIL+fmC5iCwRkQjg08Bzg845B1wNICKrsYJ+HfAicIGIRNuDuluAD1BKBSUjPsq/QCuYEgwz7bKCFCqauzgXsKHJ4fPNdPR6pnxKYlai9fupbO6irKGD7EQX4U6Hf0FbVUuXf8vCpMD0Tqy1lWHghSpwYZZPYKmK7fYWleFOBysXxXG0or+nP9zMHbDuLoyxtmAEaOro5URNG5dO0/x8nzGDvjGmD7gLK4Afw5qlc1RE7heRm+zT7ga+JCKHgd8CdxhLE/D3WBeOQ8C7xpjnp+KLKDUf+fL6Dhm6SnU28uWm3yht8B97vbQekf5tGKeKb7eviuZuzjV2+quMZgas1vXl1APTTCkxEbg9htbu/gHowIVZPr41BjERTjYt6V/bsCYrnqOVLbR0ualo7hpQXTWQb8aQ727jsH0HN52pHQhiyiaAMWYXVmom8Nh3Ax5/AFw+wmv/FWvaplJqnNLtnmZaXCThkyiVMF2WpcWQER/JvlP13LY5D7BSGBdkJ0xpGWuwFnCFO8Xq6dd3cNN6a+pobGQYcVFhVLV0ke61LpwJroEDuWCldHzH/T39gKCf4AonO9HF+tzEAbuVrclO4Mn95/1lKFYPM3MH+oN+U2cv+cRw6HwzItZeAtNpeiaGKqUmxNfTD7bQ2kwTES5blsrek3V4vYYut4eD55v4whVLp/yzHQ4hM8HFB5WttHb3+RfhQf90zging+gI54Ccuy/oN7T3+IvxVbd0W3dXgxbw/dsXNw+4YEB/OYtnDlhbR46Y3vEXXbN7+uebWZ4eO23z831mf9dBqQXMN098Ns/RH+yyZSk02Pnqd8oacXvMtJUYyEqMYn9ZI9BfYwkgM9Gaq9/c5R4wcweGL8VQ3dJNWlzkkLUB+akxA8orgBXkHWKlseKiwkYcewksr2yM4dD5ZtZPQ/38wTToKzWL+Xr6mYlzKOjbs3T2nWpgX2k9EWGOSdf3CVZWoovOXmv9Z+DOYZkJLv/snYRBaSZf4b3AGTzW1pTB3V25IpwUpMdiDKxeFD9iGe3EgN2zzjd20dTpnpZNUwaTwBHr2aCoqMgUFxfPdDOUmhXeK2/hI//4Ov/j+lXcedWymW5O0Lb+5FWWpcWSGObmphXRQzZFmSqtXW7/gGx2Yv8+Bq3dblq7+ohwCiIyYFDcGENFczcJrjDi7AqgNa3d46pq2tjRS2evh9hI54hjF77PiXeFEeYQGjvcZMRPfKwmMzOTxMT+i4aIHDDGFI31Os3pKzWLLUmLYU1WPJunqRhXqFxWkMrv3q3g/m0pFCzJJzttenq0DR09VDR1Ee50sDqzP7fe1NHL+aZOHCLERYUNSP0AeCtaSI6J8M/191a0kBTw81jq2nqoaukiO9E16oXCVLb4yzpHdvSyJmvkO4PRdHV1UVFRMSDoB0vTO0rNYrGRYTz/V1fOSBpgMi5flkqX20NilJPEuKGrU6dKhN1rDpxdA/g3N/caM2x56jCn0GcvmvJ4DR5jCHMGH4xjI52ICDFjDMo6HdbndPZ6cIU7JxTwAaKionC7J1a7UoO+UirkLllq5fAdAtHTODvFlyqJdA4O+v0/Dxf0o8KctHS5aet2+3fCGk/axRURxtqs+DFX1jodQp/HS5fbQ3TExFfhTvRiARr0lVJTICU2kovzk4iaRG92IsKdDhwiRA4KvoEBPGyYoJ+T5CIyzMHZhk5/fZ5wx/jCo+97Pv744/zyl7+krKyMz3zmMwPOcYrQ2evBGINrUND/67/+azye4YsQb926lb6+kTeoGQ8N+kqpKfHEFzYPKHcwHZwOYXlG7JCtMB0OIcwO4sOndxwsSY0h3OmgprUbr9frTwmFUpjDgdeePDO4p//QQw/hdE59DR4N+kqpKTGdvfzKykq2bdvGFVdcwTf/6i/BGL74xS+yZcsWduzYAcCRA2/zuZs/zE07ruWpp54a8h5v/Hkvd3/pNv7687ex77VXePGPu7jqqqu47LLLeOGFFwD4/e9/zyWXXMK2bdt47bXXOHToEFu2bGHz5s388Ic/HLOdvgvOf7vpGu784hcoKiriD3/4A9Dfm7/nnnt4/vnnqa6u5pprrhmx9z9ROntHKTXl/ud/HeWDQdsKjldhVjzf+8iaYZ9LTU3lpZdeIiwsjM985jP89Kc/JT09nV/+8pd4vVaO/u9/+H0e+n+/4aKVi4kOH76/2+d288KuXXT2uPnoDR9m9+7deL1eduzYwbXXXssDDzzA3r17cblceL1eenp62LNnDyLCtm3b+OY3vznqd/AF/eamBu6//35SUlK49tprufHGG/3n/OAHP2DHjh0kJiby4IMPhrz3r0FfKTXnNTQ08NWvfpXm5mbKyspYvnw5l112GQAOO60jQFJyCk6H+I8NtnHjRiLCHDQ3tnDs2DE+9KEPAVBbW0tdXR2LFy/G5XL53/fMmTPcfffddHZ2cuLECWprh98j2McX9JOTk8nLs2oTDQ7qLpeLa665hr1793LhhRdO7BcyCg36SqkpN1IPPVR+85vf8NGPfpQ77riD22+/nQsvvJC33nqLG2+8Ea/Xi8PhwOEQmpsaCcuM9x8bzHcsNTWVCy64gBdffBGn04nb7cbpdHLu3Dm6u7uJiorC6/XyyCOP8O1vf5utW7dyxRVXMNZiV98gcktzM+Xl5SQnJw9J31RVVbF3717y8/PZs2cPW7duDc0vydeGkL6bUkrNgO3bt/PZzwy8bpsAAAhWSURBVH6W3//+9wDEx8dTVVXFVVddRWxsLLt27eJ//+hH3POl24lxRfGVr3yFT33qUyO+n8Ph4Fvf+hZXX301IkJhYSEPP/ww9913H1u2bCEmJobvfe973HDDDdx1110UFhYSETF2FdG4qDDS4iJJT0vl+9//PocOHeK73/3ugHO+8Y1v8OCDD7J48WJ27tzJ5s2bJ/fLGUTLMCilpsyxY8dYvXr1TDdj1rniiit4/fXXJ/Ueg3+3WoZBKaVG0NLSws6dOwcce/bZZ0lISAj5Z9133328+eab/p+/+tWvhvwzxkODvlJqwUlISGDPnj3T8lk/+tGPhhwbLbU01YKapy8i14nICREpFZF7h3k+T0ReFZGDInJERK4f5vl2EbknVA1XSs0Nsy2FPB9M5nc6ZtAXESfwMLADKARuFZHCQaf9LdbeuRuwNk7/xaDn/x7444RbqZSak8LDw+nu7p7pZsw73d3dhIdPbLVzMOmdTUCpMeY0gIg8CewEPgg4xwC+OqYJQKXvCRH5KHAG6JhQC5VSc1ZqaiplZWUz3Yx5KTMzc0KvCyboZwPnA34uBwbPIfo+8CcR+UsgBvgQgIjEAt8GrgFGTO2IyJ3AnYB/wYJSau5LTEycUM13NXVCVXvnVuBxY0wOcD3whIg4sC4G/8cY0z7ai40xjxpjiowxRWlpaSFqklJKqcGC6elXALkBP+fYxwJ9AbgOwBjzpohEAalYdwQfF5G/AxIBr4h0G2P+cdItV0opNW5jLs4SkTDgJHA1VrDfD9xmjDkacM4fgaeMMY+LyGrgFSDbBLy5iHwfaDfGPDjG59UBZ8fxHVKB+nGcP1PmQju1jaEzF9qpbQyd2dDOxcaYMVMlY/b0jTF9InIX8CLgBB4zxhwVkfuBYmPMc8DdwD+LyDexBnXvMBOcUxRMowOJSHEwq9Bm2lxop7YxdOZCO7WNoTNX2glBLs4yxuwCdg069t2Axx8Al4/xHt+fQPuUUkqFkG6iopRSC8h8CPqPznQDgjQX2qltDJ250E5tY+jMlXbOviqbSimlps586OkrpZQK0pwO+mMVgpviz861i8x9ICJHReQb9vHvi0iFiByy/1wf8Jr77LaeEJEPT8f3EJEyEXnPbkuxfSxZRF4SkRL7v0n2cRGRn9ntOCIiGwPe53P2+SUi8rkQt3FlwO/rkIi0ishfz/TvUkQeE5FaEXk/4FjIfncicpH9d1Nqv3bcu4iP0MafiMhxux2/E5FE+3i+iHQF/D7/aay2jPR9Q9TOkP39isgSEXnbPv6UiIy9o0lwbXwqoH1lInLIPj5jv8tJM8bMyT9Y00dPAUuBCOAwUDiNn58JbLQfx2GtZSjEWoV8zzDnF9ptjASW2G13TvX3AMqA1EHH/g641358L/Bj+/H1WIXxBLgEeNs+ngyctv+bZD9OmsK/12pg8Uz/LoGrgI3A+1PxuwPesc8V+7U7QtTGa4Ew+/GPA9qYH3jeoPcZti0jfd//v71zeZGjiuLwd0DNIhhfSAiCGCWuVbLIInGhEB9o4gsZEaLGjaKL4MLNQP6DuBIMiGIi8RUfODuNIroalQzxRdTM6Cq0E0jUCIIa/bm4p8PtZqpnhrrVXU2fD4q5c6r71u+cqj5V91bVvYV0Ftu/wFvAlJf3A0+W0Ni3fh+wd9SxrLuM85X++YHgJP0NdAeCGwqSOpLmvPwHcJw0TlEVO4E3JP0l6WdgnuTDKPzYCRzw8gHgnsx+UIlZ4FIz2wDcBhyRdEbSr8AR/A3sBrgVWJA06AW9ocRS0mfAmSW2XTt2vm6dpFmlLHAwq6uWRkkfSjrn/86S3qKvZBktVf7W1jmAVe1fv5K+BXi7js5BGn0bDwKvD6pjGLGsyzgn/aUGghuUdBvDzK4BbgQ+d9PT3rR+OWvCVelt2g+RBsM7amlgO4D1kjpe/gVYP2KNOVP0/rDaFEsoF7urvNykVoDd9A5rvtHSvBefmtk2tw3SUuVvKUrs3yuA37ITXROx3AYsSjqR2doWyxUxzkm/FVgaSfQdYI+ks8ALwHXADUCH1CQcJVsl3USaD+EpM7s5X+lXI614hMv7YXcAh93Utlj20KbYLYWZTQPngENu6gBXK8178Qzwmpmtq/p+Pw342+r928dD9F6MtC2WK2ack/5KBoJrFDO7kJTwD0l6F0DSoqR/Jf0HvEhqkg7S26gfkk7631PAe65n0Zuh3eboqVFqzLgDmJO06JpbFUunVOxO0tvtUlSrmT0K3AU87AkG7y457eWjpP7x65fRUuVvbQru39Ok7rQL+uxF8HrvA97MtLcqlqthnJP+l8Amv2t/EalbYGZYG/c+vpeA45Key+z5zAb3At0nAWaAKTNbY2YbgU2kGz6N+WFma83s4m6ZdIPvW6+/+xTJI8D7mcZdltgC/O7N0Q+A7WZ2mTfBt7utND1XU22KZUaR2Pm6s2a2xY+lXVldtTCz24FngR2S/szsV1qaCQ8zu5YUt5+W0VLlbwmdRfavn9Q+AR5oQidpfpDvJZ3vtmlbLFfFKO4el1pIT0z8SDrLTg9521tJzbOvgWO+3Am8Cnzj9hlgQ/adadf6A9mTGk35QXrK4StfvuvWTeoD/Rg4AXwEXO52I02NueA+bM7q2k26oTYPPNZAPNeSrtguyWwjjSXpBNQB/iH1zT5eMnbAZlKiWwCex1+WLKBxntT33T0u9/tn7/fj4BgwB9y9nJYqfwvpLLZ//Vj/wn0/DKwpodHtrwBP9H12ZLGsu8QbuUEQBBPEOHfvBEEQBKskkn4QBMEEEUk/CIJggoikHwRBMEFE0g+CIJggIukHQRBMEJH0gyAIJohI+kEQBBPE/1JR2J7l3cWOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import torch.utils.data as Data\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam #optimizer of keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "class GAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels) #shape of image\n",
    "        self.latent_dim = 100\n",
    "        self.x = []\n",
    "        self.y = np.zeros((31, 1), dtype=np.int)\n",
    "        self.y = list(self.y)\n",
    "        for i in range(31):\n",
    "            self.y[i] = []\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5) #optimizer of gan\n",
    "\n",
    "        # Build and compile the discriminator,only to keras\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=(self.latent_dim,))  #Input():用来实例化一个keras张量\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        validity = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, validity)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=self.img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (X_test, _) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = X_train / 127.5 - 1.\n",
    "\n",
    "        X_train = np.expand_dims(X_train, axis=3)  #expand_dims用于扩充数组形状\n",
    "        print(np.shape(X_train))\n",
    "        X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "        # X_test = X_test / 127.5 - 1.\n",
    "        X_test = np.expand_dims(X_test, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        global_step=0\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for index in range(nb_batches):\n",
    "                global_step += 1\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "\n",
    "                # Select a random batch of images\n",
    "                imgs = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "                # Generate a batch of new images\n",
    "                gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "                # Train the discriminator\n",
    "                d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Generator\n",
    "                # ---------------------\n",
    "\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "                # Train the generator (to have the discriminator label samples as valid)\n",
    "                g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "                # Plot the progress\n",
    "                print(\"epoch:%d step:%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch,global_step, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                sampleSize = 10000\n",
    "                # If at save interval => save generated image samples\n",
    "                if global_step % sample_interval == 0:\n",
    "                    s = self.metrics(global_step, X_test, sampleSize)\n",
    "        for i in range(len(s)):\n",
    "            self.y[i] = [float(j) / max(self.y[i]) for j in self.y[i]]#对值进行归一化处理\n",
    "\n",
    "        for i in range(len(s)):\n",
    "            font1={'size':8}\n",
    "\n",
    "            plt.plot(self.x, self.y[i], label=labels_name[i])\n",
    "            plt.legend(loc='lower right',prop=font1)\n",
    "            plt.savefig('saved_models_gan/{}.png'.format(labels_name[i]))\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "    def metrics(self, epoch, X_test, sampleSize):\n",
    "        self.x.append(epoch)\n",
    "        r, c = 10, sampleSize // 10\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "#         sampled_labels = np.array([num for _ in range(r) for num in range(c)])\n",
    "        gen_imgs = self.generator.predict([noise])\n",
    "        x_dataset = MyDataset(X_test[:sampleSize])\n",
    "        # print(x_dataset[0].shape)\n",
    "        x_real_loader = Data.DataLoader(dataset=x_dataset, batch_size=2000, shuffle=True)\n",
    "        x_fake_dataset = MyDataset(gen_imgs)\n",
    "        x_fake_loader = Data.DataLoader(dataset=x_fake_dataset, batch_size=2000, shuffle=True)\n",
    "        s = compute_score_raw(x_real_loader, x_fake_loader, 256, '/real/', './fake', conv_model='tfgan',\n",
    "                              workers=int(1))\n",
    "        real_images = tf.convert_to_tensor(X_test)  # real images\n",
    "        # MNIST_CLASSIFIER_FROZEN_GRAPH = '.\\classify_mnist_graph_def.pb'\n",
    "        gen_imgs = np.array(gen_imgs)\n",
    "        eval_images = tf.convert_to_tensor(gen_imgs)\n",
    "        eval_score = utils.mnist_score(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH)  # IS score\n",
    "        frechet_distance = utils.mnist_frechet_distance(real_images, eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH)\n",
    "        mnist_score, f_distance = sess.run([eval_score, frechet_distance])\n",
    "        # print(mnist_score)\n",
    "        # print(f_distance)\n",
    "        # s[14]=mnist_score\n",
    "        # s[16]=f_distance\n",
    "        s[17] = mnist_score\n",
    "        s[18] = f_distance\n",
    "        print('IS socre: %f' % mnist_score)\n",
    "        print('FID: %f' % f_distance)\n",
    "\n",
    "        for i in range(len(s)):\n",
    "            print(i, \"=\", s[i])\n",
    "        for i in range(len(s)):\n",
    "            self.y[i].append(s[i])\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('epoch:' + str(epoch))\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('%.8f' % (i) for i in s)\n",
    "        f.writelines('\\n')\n",
    "        return s\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    gan = GAN()\n",
    "    gan.train(epochs=20, batch_size=64, sample_interval=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
