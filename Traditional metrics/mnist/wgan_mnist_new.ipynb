{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*-coding:utf-8-*-\n",
    "from __future__ import print_function, division\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "import models.util\n",
    "import models.utilss\n",
    "import tensorflow.contrib.gan as tfgan\n",
    "num_images_to_eval = 500\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, imgs, transform=None):\n",
    "        # super().__init__()\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.imgs[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = torch.from_numpy(img)\n",
    "        return img\n",
    "\n",
    "\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import ot\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.models as models\n",
    "\n",
    "from scipy import linalg\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def giveName(iter):  # 7 digit name.\n",
    "    ans = str(iter)\n",
    "    return ans.zfill(7)\n",
    "\n",
    "def make_dataset(dataset, dataroot, imageSize):\n",
    "    \"\"\"\n",
    "    :param dataset: must be in 'cifar10 | lsun | imagenet | folder | lfw | fake'\n",
    "    :return: pytorch dataset for DataLoader to utilize\n",
    "    \"\"\"\n",
    "    if dataset in ['imagenet', 'folder', 'lfw']:\n",
    "        print(os.getcwd() + dataroot)  # 鍑芥暟鐨勪綔鐢ㄦ槸鐢ㄤ簬杩斿洖褰撳墠宸ヤ綔鐩綍\n",
    "        # folder dataset\n",
    "        # dataset = dset.ImageFolder(root=dataroot,\n",
    "        dataset = dset.ImageFolder(root=os.getcwd() + dataroot,\n",
    "                                   transform=transforms.Compose([\n",
    "                                       transforms.Resize(imageSize),\n",
    "                                       # transforms.CenterCrop(imageSize),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(\n",
    "                                           (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                   ]))\n",
    "    elif dataset == 'lsun':\n",
    "        dataset = dset.LSUN(db_path=dataroot, classes=['bedroom_train'],\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.Resize(imageSize),\n",
    "                                transforms.CenterCrop(imageSize),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(\n",
    "                                    (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                            ]))\n",
    "    elif dataset == 'cifar10':\n",
    "        dataset = dset.CIFAR10(root=dataroot, download=True,\n",
    "                               transform=transforms.Compose([\n",
    "                                   transforms.Resize(imageSize),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize(\n",
    "                                       (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                               ]))\n",
    "    elif dataset == 'celeba':\n",
    "        dataset = dset.ImageFolder(root=dataroot,\n",
    "                                   transform=transforms.Compose([\n",
    "                                       transforms.CenterCrop(138),\n",
    "                                       transforms.Resize(imageSize),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(\n",
    "                                           (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                   ]))\n",
    "    else:\n",
    "        raise Exception('--dataset must be in cifar10 | lsun | imagenet | folder | lfw | fake')\n",
    "    assert dataset\n",
    "    return dataset\n",
    "\n",
    "MNIST_CLASSIFIER_FROZEN_GRAPH = './classify_mnist_graph_def.pb'\n",
    "INPUT_TENSOR = 'inputs:0'\n",
    "OUTPUT_TENSOR = 'logits:0'\n",
    "# CONV_TENSOR = 'fc3/Relu:0'\n",
    "CONV_TENSOR = 'fc4/BiasAdd:0'\n",
    "class ConvNetFeatureSaver(object):\n",
    "    def __init__(self, model='cnn', workers=4, batchSize=64):\n",
    "        '''\n",
    "        model: inception_v3, vgg13, vgg16, vgg19, resnet18, resnet34,\n",
    "               resnet50, resnet101, or resnet152\n",
    "        '''\n",
    "        self.model = model\n",
    "        self.batch_size = batchSize\n",
    "        self.workers = workers\n",
    "        if self.model.find('tfgan') >= 0:\n",
    "            print('tfgan')\n",
    "\n",
    "        elif self.model.find('vgg') >= 0:\n",
    "            self.vgg = getattr(models, model)(pretrained=True).cuda().eval()\n",
    "            self.trans = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                                     (0.229, 0.224, 0.225)),\n",
    "            ])\n",
    "        elif self.model.find('resnet') >= 0:\n",
    "            resnet = getattr(models, model)(pretrained=True)\n",
    "            resnet.cuda().eval()\n",
    "            resnet_feature = nn.Sequential(resnet.conv1, resnet.bn1,\n",
    "                                           resnet.relu,\n",
    "                                           resnet.maxpool, resnet.layer1,\n",
    "                                           resnet.layer2, resnet.layer3,\n",
    "                                           resnet.layer4).cuda().eval()\n",
    "            self.resnet = resnet\n",
    "            self.resnet_feature = resnet_feature\n",
    "            self.trans = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                                     (0.229, 0.224, 0.225)),\n",
    "            ])\n",
    "        elif self.model == 'inception' or self.model == 'inception_v3':\n",
    "            inception = models.inception_v3(\n",
    "                pretrained=True, transform_input=False).cuda().eval()\n",
    "            inception_feature = nn.Sequential(inception.Conv2d_1a_3x3,\n",
    "                                              inception.Conv2d_2a_3x3,\n",
    "                                              inception.Conv2d_2b_3x3,\n",
    "                                              nn.MaxPool2d(3, 2),\n",
    "                                              inception.Conv2d_3b_1x1,\n",
    "                                              inception.Conv2d_4a_3x3,\n",
    "                                              nn.MaxPool2d(3, 2),\n",
    "                                              inception.Mixed_5b,\n",
    "                                              inception.Mixed_5c,\n",
    "                                              inception.Mixed_5d,\n",
    "                                              inception.Mixed_6a,\n",
    "                                              inception.Mixed_6b,\n",
    "                                              inception.Mixed_6c,\n",
    "                                              inception.Mixed_6d,\n",
    "                                              inception.Mixed_7a,\n",
    "                                              inception.Mixed_7b,\n",
    "                                              inception.Mixed_7c,\n",
    "                                              ).cuda().eval()\n",
    "            self.inception = inception\n",
    "            self.inception_feature = inception_feature\n",
    "            self.trans = transforms.Compose([\n",
    "                transforms.Resize(299),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ])\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def save(self, imgFolder, dataloader, save2disk=False):\n",
    "        feature_pixl, feature_conv, feature_smax, feature_logit = [], [], [], []\n",
    "\n",
    "        for img in dataloader:\n",
    "            with torch.no_grad():\n",
    "                input = img.cuda()\n",
    "                if self.model == 'tfgan':\n",
    "                    gen_imgs = np.array(img)\n",
    "                    eval_images = tf.convert_to_tensor(gen_imgs)\n",
    "                    flogit = BEGAN.util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, OUTPUT_TENSOR)\n",
    "                    fconv = BEGAN.util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, CONV_TENSOR)\n",
    "                    flogit,fconv=tf.Session().run([flogit,fconv])\n",
    "\n",
    "                    flogit=torch.from_numpy(flogit)\n",
    "                    fconv=torch.from_numpy(fconv)\n",
    "                elif self.model == 'vgg' or self.model == 'vgg16':\n",
    "                    print(self.vgg.features(input).shape)\n",
    "                    fconv = self.vgg.features(input).view(input.size(0), -1)  # 鐩稿綋浜巖eshape\n",
    "                    flogit = self.vgg.classifier(fconv)\n",
    "                    # flogit = self.vgg.logitifier(fconv)\n",
    "                elif self.model.find('resnet') >= 0:\n",
    "                    fconv = self.resnet_feature(\n",
    "                        input).mean(3).mean(2).squeeze()\n",
    "                    flogit = self.resnet.fc(fconv)\n",
    "                elif self.model == 'inception' or self.model == 'inception_v3':\n",
    "                    fconv = self.inception_feature(\n",
    "                        input).mean(3).mean(2).squeeze()\n",
    "                    flogit = self.inception.fc(fconv)\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "                fsmax = F.softmax(flogit)\n",
    "                '''\n",
    "                鎬诲叡鏈夊洓涓┖闂达細1.feature_pixl 2.feature_conv 3.feature_logit 4.feature_smax\n",
    "                '''\n",
    "                feature_pixl.append(img)\n",
    "                feature_conv.append(fconv.data.cpu())\n",
    "                feature_logit.append(flogit.data.cpu())\n",
    "                feature_smax.append(fsmax.data.cpu())\n",
    "\n",
    "        feature_pixl = torch.cat(feature_pixl, 0).to('cpu')\n",
    "        feature_conv = torch.cat(feature_conv, 0).to('cpu')\n",
    "        feature_logit = torch.cat(feature_logit, 0).to('cpu')\n",
    "        feature_smax = torch.cat(feature_smax, 0).to('cpu')\n",
    "\n",
    "        return feature_pixl, feature_conv, feature_logit, feature_smax\n",
    "\n",
    "    # return feature_pixl, feature_conv, feature_logit, feature_smax\n",
    "\n",
    "\n",
    "def distance(X, Y, sqrt):\n",
    "    nX = X.size(0)\n",
    "    nY = Y.size(0)\n",
    "    X = X.view(nX, -1)\n",
    "    X2 = (X * X).sum(1).resize_(nX, 1)\n",
    "    Y = Y.view(nY, -1)\n",
    "    Y2 = (Y * Y).sum(1).resize_(nY, 1)\n",
    "\n",
    "    M = torch.zeros(nX, nY)\n",
    "    M.copy_(X2.expand(nX, nY) + Y2.expand(nY, nX).transpose(0, 1) -\n",
    "            2 * torch.mm(X, Y.transpose(0, 1)))\n",
    "\n",
    "    del X, X2, Y, Y2\n",
    "\n",
    "    if sqrt:\n",
    "        M = ((M + M.abs()) / 2).sqrt()\n",
    "\n",
    "    return M\n",
    "\n",
    "\n",
    "def wasserstein(M, sqrt):\n",
    "    if sqrt:\n",
    "        M = M.abs().sqrt()\n",
    "    emd = ot.emd2([], [], M.numpy())\n",
    "\n",
    "    return emd\n",
    "\n",
    "\n",
    "class Score_knn:\n",
    "    acc = 0\n",
    "    acc_real = 0\n",
    "    acc_fake = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    ft = 0\n",
    "\n",
    "\n",
    "def knn(Mxx, Mxy, Myy, k, sqrt):\n",
    "    n0 = Mxx.size(0)\n",
    "    n1 = Myy.size(0)\n",
    "    label = torch.cat((torch.ones(n0), torch.zeros(n1)))\n",
    "    M = torch.cat((torch.cat((Mxx, Mxy), 1), torch.cat(\n",
    "        (Mxy.transpose(0, 1), Myy), 1)), 0)\n",
    "    if sqrt:\n",
    "        M = M.abs().sqrt()\n",
    "    INFINITY = float('inf')\n",
    "    val, idx = (M + torch.diag(INFINITY * torch.ones(n0 + n1))\n",
    "                ).topk(k, 0, False)\n",
    "\n",
    "    count = torch.zeros(n0 + n1)\n",
    "    for i in range(0, k):\n",
    "        count = count + label.index_select(0, idx[i])\n",
    "    pred = torch.ge(count, (float(k) / 2) * torch.ones(n0 + n1)).float()\n",
    "\n",
    "    s = Score_knn()\n",
    "    s.tp = (pred * label).sum()\n",
    "    s.fp = (pred * (1 - label)).sum()\n",
    "    s.fn = ((1 - pred) * label).sum()\n",
    "    s.tn = ((1 - pred) * (1 - label)).sum()\n",
    "    s.precision = s.tp / (s.tp + s.fp + 1e-10)\n",
    "    s.recall = s.tp / (s.tp + s.fn + 1e-10)\n",
    "    s.acc_t = s.tp / (s.tp + s.fn)\n",
    "    s.acc_f = s.tn / (s.tn + s.fp)\n",
    "    s.acc = torch.eq(label, pred).float().mean()\n",
    "    s.k = k\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "def mmd(Mxx, Mxy, Myy, sigma):\n",
    "    scale = Mxx.mean()\n",
    "    Mxx = torch.exp(-Mxx / (scale * 2 * sigma * sigma))\n",
    "    Mxy = torch.exp(-Mxy / (scale * 2 * sigma * sigma))\n",
    "    Myy = torch.exp(-Myy / (scale * 2 * sigma * sigma))\n",
    "    mmd = math.sqrt(Mxx.mean() + Myy.mean() - 2 * Mxy.mean())\n",
    "\n",
    "    return mmd\n",
    "\n",
    "\n",
    "def entropy_score(X, Y, epsilons):\n",
    "    Mxy = distance(X, Y, False)\n",
    "    scores = []\n",
    "    for epsilon in epsilons:\n",
    "        scores.append(ent(Mxy.t(), epsilon))\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "def ent(M, epsilon):\n",
    "    n0 = M.size(0)\n",
    "    n1 = M.size(1)\n",
    "    neighbors = M.lt(epsilon).float()\n",
    "    sums = neighbors.sum(0).repeat(n0, 1)\n",
    "    sums[sums.eq(0)] = 1\n",
    "    neighbors = neighbors.div(sums)\n",
    "    probs = neighbors.sum(1) / n1\n",
    "    rem = 1 - probs.sum()\n",
    "    if rem < 0:\n",
    "        rem = 0\n",
    "    probs = torch.cat((probs, rem * torch.ones(1)), 0)\n",
    "    e = {}\n",
    "    e['probs'] = probs\n",
    "    probs = probs[probs.gt(0)]\n",
    "    e['ent'] = -probs.mul(probs.log()).sum()\n",
    "\n",
    "    return e\n",
    "\n",
    "\n",
    "eps = 1e-20\n",
    "\n",
    "\n",
    "def inception_score(X):\n",
    "    kl = X * ((X + eps).log() - (X.mean(0) + eps).log().expand_as(X))\n",
    "    score = np.exp(kl.sum(1).mean())\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def mode_score(X, Y):\n",
    "    kl1 = X * ((X + eps).log() - (X.mean(0) + eps).log().expand_as(X))\n",
    "    kl2 = X.mean(0) * ((X.mean(0) + eps).log() - (Y.mean(0) + eps).log())\n",
    "    score = np.exp(kl1.sum(1).mean() - kl2.sum())\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def fid(X, Y):\n",
    "    m = X.mean(0)\n",
    "    m_w = Y.mean(0)\n",
    "    X_np = X.numpy()\n",
    "    Y_np = Y.numpy()\n",
    "\n",
    "    C = np.cov(X_np.transpose())\n",
    "    C_w = np.cov(Y_np.transpose())\n",
    "    C_C_w_sqrt = linalg.sqrtm(C.dot(C_w), True).real\n",
    "\n",
    "    score = m.dot(m) + m_w.dot(m_w) - 2 * m_w.dot(m) + \\\n",
    "            np.trace(C + C_w - 2 * C_C_w_sqrt)\n",
    "    return np.sqrt(score)\n",
    "\n",
    "\n",
    "class Score:\n",
    "    emd = 0\n",
    "    mmd = 0\n",
    "    knn = None\n",
    "\n",
    "\n",
    "def compute_score(real, fake, k=1, sigma=1, sqrt=True):\n",
    "    Mxx = distance(real, real, False)\n",
    "    Mxy = distance(real, fake, False)\n",
    "    Myy = distance(fake, fake, False)\n",
    "\n",
    "    s = Score()\n",
    "    s.emd = wasserstein(Mxy, sqrt)\n",
    "    s.mmd = mmd(Mxx, Mxy, Myy, sigma)\n",
    "    s.knn = knn(Mxx, Mxy, Myy, k, sqrt)\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "'''\n",
    "鍙傛暟璇存槑锛?dataset:鐪熷疄鏁版嵁闆嗙殑path\n",
    "imageSize:鍥剧墖鐨勫ぇ灏?dataroot_real:鐪熷疄鏁版嵁鎵€鍦ㄧ殑path\n",
    "batchSize\n",
    "saveFolder_r:鐪熷疄鏁版嵁鐨勪繚瀛樹綅缃?conv_model:鍗风Н妯″瀷\n",
    "'''\n",
    "\n",
    "\n",
    "def compute_score_raw(real_dataloader, fake_dataloader, batchSize, saveFolder_r, saveFolder_f, conv_model='resnet34',\n",
    "                      workers=4):\n",
    "    convnet_feature_saver = ConvNetFeatureSaver(model=conv_model,\n",
    "                                                batchSize=batchSize, workers=workers)\n",
    "    print(saveFolder_r)\n",
    "    print(saveFolder_f)\n",
    "    feature_r = convnet_feature_saver.save(saveFolder_r, real_dataloader, False)\n",
    "    feature_f = convnet_feature_saver.save(saveFolder_f, fake_dataloader, False)\n",
    "\n",
    "    # 4 feature spaces and 7 scores + incep + modescore + fid\n",
    "    score = np.zeros(2 * 7 + 5)\n",
    "    for i in range(0, 2):\n",
    "        print('compute score in space: ' + str(i))\n",
    "        Mxx = distance(feature_r[i], feature_r[i], False)\n",
    "        Mxy = distance(feature_r[i], feature_f[i], False)\n",
    "        Myy = distance(feature_f[i], feature_f[i], False)\n",
    "\n",
    "        score[i * 7] = wasserstein(Mxy, True)\n",
    "        score[i * 7 + 1] = mmd(Mxx, Mxy, Myy, 1)\n",
    "        tmp = knn(Mxx, Mxy, Myy, 1, False)\n",
    "        score[(i * 7 + 2):(i * 7 + 7)] = \\\n",
    "            tmp.acc, tmp.acc_t, tmp.acc_f, tmp.precision, tmp.recall\n",
    "\n",
    "\n",
    "    score[14] = inception_score(feature_f[3])\n",
    "    score[15] = mode_score(feature_r[3], feature_f[3])\n",
    "    score[16] = fid(feature_r[3], feature_f[3])\n",
    "\n",
    "    return score\n",
    "labels_name=['w_pixl','mmd_pixl','acc_pixl','acc_t_pixl','acc_f_pixl','acc_precision_pixl','acc_recall_pixl',\n",
    "             'w_conv','mmd_conv','acc_conv','acc_t_conv','acc_f_conv','acc_precision_conv','acc_recall_conv',\n",
    "             'is','mode_score','fid' ,'tf_is','tf_fid']\n",
    "if not os.path.isdir('saved_models_{}'.format('wgan')):\n",
    "    os.mkdir('saved_models_{}'.format('wgan'))\n",
    "f = open('saved_models_{}/log_collapse1.txt'.format('wgan'), mode='w')\n",
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'WGAN'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-09c3a2b71e5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/huangdengrong/GAN-Research-New/GAN-ZOO-Metrics/GAN-ZOO-Tradition-Metrics/models/ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mWGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"concat_v2\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'WGAN'"
     ]
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "from __future__ import division\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from models.ops import *\n",
    "from models.utils import *\n",
    "\n",
    "class WGAN(object):\n",
    "    def __init__(self, sess, epoch, batch_size, z_dim, dataset_name, checkpoint_dir, result_dir, log_dir):\n",
    "        self.sess = sess\n",
    "        self.dataset_name = dataset_name\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.result_dir = result_dir\n",
    "        self.log_dir = log_dir\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.model_name = \"WGAN\"     # name for checkpoint\n",
    "\n",
    "        # 加载mnist数据集并且指定各参数\n",
    "        if dataset_name == 'mnist' or dataset_name == 'fashion-mnist':\n",
    "            # parameters\n",
    "            self.input_height = 28\n",
    "            self.input_width = 28\n",
    "            self.output_height = 28\n",
    "            self.output_width = 28\n",
    "\n",
    "            self.z_dim = z_dim         # dimension of noise-vector\n",
    "            self.c_dim = 1\n",
    "\n",
    "            # WGAN parameter\n",
    "            self.disc_iters = 1     # The number of critic iterations for one-step of generator\n",
    "\n",
    "            # train\n",
    "            self.learning_rate = 0.0002\n",
    "            self.beta1 = 0.5\n",
    "\n",
    "            # test\n",
    "            self.sample_num = 64  # number of generated images to be saved\n",
    "\n",
    "            # load mnist, data_X为mnist数据图片归一化结果，data_y为加上标签的数组记录。\n",
    "            def load_mnist():\n",
    "                (trX, trY), (teX, teY) = mnist.load_data()\n",
    "                trX = np.expand_dims(trX, axis=3)\n",
    "                teX = np.expand_dims(teX, axis=3)\n",
    "\n",
    "                X = np.concatenate((trX, teX), axis=0)\n",
    "                y = np.concatenate((trY, teY), axis=0).astype(np.int)\n",
    "                seed = 547\n",
    "                np.random.seed(seed)\n",
    "                np.random.shuffle(X)\n",
    "                np.random.seed(seed)\n",
    "                np.random.shuffle(y)\n",
    "\n",
    "                y_vec = np.zeros((len(y), 10), dtype=np.float)\n",
    "                for i, label in enumerate(y):\n",
    "                    y_vec[i, y[i]] = 1.0\n",
    "\n",
    "                return X / 255., y_vec\n",
    "\n",
    "            # load mnist\n",
    "            self.data_X, self.data_y = load_mnist()\n",
    "\n",
    "            # get number of batches for a single epoch\n",
    "            self.num_batches = len(self.data_X) // self.batch_size\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    # 判别器函数(64,input_height,input_width,c_dim)-->(64,1)\n",
    "    def discriminator(self, x, is_training=True, reuse=False):\n",
    "        # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n",
    "        # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n",
    "        with tf.variable_scope(\"discriminator\", reuse=reuse):\n",
    "\n",
    "            net = lrelu(conv2d(x, 64, 4, 4, 2, 2, name='d_conv1'))\n",
    "            net = lrelu(bn(conv2d(net, 128, 4, 4, 2, 2, name='d_conv2'), is_training=is_training, scope='d_bn2'))\n",
    "            net = tf.reshape(net, [self.batch_size, -1])\n",
    "            net = lrelu(bn(linear(net, 1024, scope='d_fc3'), is_training=is_training, scope='d_bn3'))\n",
    "            out_logit = linear(net, 1, scope='d_fc4')\n",
    "            out = tf.nn.sigmoid(out_logit)\n",
    "\n",
    "            return out, out_logit, net\n",
    "\n",
    "    # 生成器函数，对于不同的数据集判别器有不同的网络(64,z_dim)-->(64,output_height,output_width,c_dim)\n",
    "    def generator(self, z, is_training=True, reuse=False):\n",
    "        # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n",
    "        # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n",
    "        with tf.variable_scope(\"generator\", reuse=reuse):\n",
    "            net = tf.nn.relu(bn(linear(z, 1024, scope='g_fc1'), is_training=is_training, scope='g_bn1'))\n",
    "            net = tf.nn.relu(bn(linear(net, 128 * 7 * 7, scope='g_fc2'), is_training=is_training, scope='g_bn2'))\n",
    "            net = tf.reshape(net, [self.batch_size, 7, 7, 128])\n",
    "            net = tf.nn.relu(\n",
    "                bn(deconv2d(net, [self.batch_size, 14, 14, 64], 4, 4, 2, 2, name='g_dc3'), is_training=is_training,\n",
    "                   scope='g_bn3'))\n",
    "\n",
    "            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name='g_dc4'))\n",
    "\n",
    "            return out\n",
    "\n",
    "    def build_model(self):\n",
    "        # some parameters\n",
    "        image_dims = [self.input_height, self.input_width, self.c_dim]\n",
    "        bs = self.batch_size\n",
    "\n",
    "        \"\"\" Graph Input \"\"\"\n",
    "        # images\n",
    "        self.inputs = tf.placeholder(tf.float32, [bs] + image_dims, name='real_images')\n",
    "\n",
    "        # noises\n",
    "        self.z = tf.placeholder(tf.float32, [bs, self.z_dim], name='z')\n",
    "\n",
    "        \"\"\" Loss Function \"\"\"\n",
    "\n",
    "        # output of D for real images\n",
    "        D_real, D_real_logits, _ = self.discriminator(self.inputs, is_training=True, reuse=False)\n",
    "\n",
    "        # output of D for fake images\n",
    "        G = self.generator(self.z, is_training=True, reuse=False)\n",
    "        D_fake, D_fake_logits, _ = self.discriminator(G, is_training=True, reuse=True)\n",
    "\n",
    "        # get loss for discriminator\n",
    "        # 对于D_loss,L(D) = E[D(x)] - E[D(G(z))], 如果min的话就取负号就OK，本处正是这么处理的,我感觉可也可以不取负号，本处影响不大\n",
    "        d_loss_real = - tf.reduce_mean(D_real)\n",
    "        d_loss_fake = tf.reduce_mean(D_fake)\n",
    "\n",
    "        # 未加判别器sigmoid，可测试使用,结果差距并不是很明显\n",
    "        # d_loss_real = - tf.reduce_mean(D_real_logits)\n",
    "        # d_loss_fake = tf.reduce_mean(D_fake_logits)\n",
    "\n",
    "        self.d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "        # get loss for generator\n",
    "        # 对于G_loss,L(G) = E[D(G(z))]\n",
    "        self.g_loss = - d_loss_fake\n",
    "\n",
    "        \"\"\" Training \"\"\"\n",
    "        # divide trainable variables into a group for D and a group for G\n",
    "        t_vars = tf.trainable_variables()\n",
    "        d_vars = [var for var in t_vars if 'd_' in var.name]\n",
    "        g_vars = [var for var in t_vars if 'g_' in var.name]\n",
    "\n",
    "        # optimizers\n",
    "        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "            self.d_optim = tf.train.AdamOptimizer(self.learning_rate, beta1=self.beta1) \\\n",
    "                      .minimize(self.d_loss, var_list=d_vars)\n",
    "            self.g_optim = tf.train.AdamOptimizer(self.learning_rate*5, beta1=self.beta1) \\\n",
    "                      .minimize(self.g_loss, var_list=g_vars)\n",
    "\n",
    "        # weight clipping\n",
    "        self.clip_D = [p.assign(tf.clip_by_value(p, -0.01, 0.01)) for p in d_vars]\n",
    "\n",
    "        \"\"\"\" Testing \"\"\"\n",
    "        # for test\n",
    "        self.fake_images = self.generator(self.z, is_training=False, reuse=True)\n",
    "\n",
    "        \"\"\" Summary \"\"\"\n",
    "        d_loss_real_sum = tf.summary.scalar(\"d_loss_real\", d_loss_real)\n",
    "        d_loss_fake_sum = tf.summary.scalar(\"d_loss_fake\", d_loss_fake)\n",
    "        d_loss_sum = tf.summary.scalar(\"d_loss\", self.d_loss)\n",
    "        g_loss_sum = tf.summary.scalar(\"g_loss\", self.g_loss)\n",
    "\n",
    "        # final summary operations\n",
    "        self.g_sum = tf.summary.merge([d_loss_fake_sum, g_loss_sum])\n",
    "        self.d_sum = tf.summary.merge([d_loss_real_sum, d_loss_sum])\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        # initialize all variables\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        # graph inputs for visualize training results\n",
    "        self.sample_z = np.random.uniform(-1, 1, size=(self.batch_size , self.z_dim))\n",
    "\n",
    "        counter=0\n",
    "        for epoch in range(0, self.epoch):\n",
    "\n",
    "            # get batch data\n",
    "            for idx in range(0, self.num_batches):\n",
    "                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "                batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n",
    "\n",
    "                # update D network\n",
    "                _, _, summary_str, d_loss = self.sess.run([self.d_optim, self.clip_D, self.d_sum, self.d_loss],\n",
    "                                               feed_dict={self.inputs: batch_images, self.z: batch_z})\n",
    "\n",
    "\n",
    "                # update G network\n",
    "                # 检查更新生成器利用WGAN设置参数\n",
    "                if (counter - 1) % self.disc_iters == 0:\n",
    "                    _, summary_str, g_loss = self.sess.run([self.g_optim, self.g_sum, self.g_loss], feed_dict={self.z: batch_z})\n",
    "\n",
    "                # display training status\n",
    "                counter += 1\n",
    "                print(\"Epoch: [%2d] [%4d/%4d] , d_loss: %.8f, g_loss: %.8f\" \\\n",
    "                      % (epoch, idx, self.num_batches, d_loss, g_loss))\n",
    "\n",
    "                sampleSize = 5000\n",
    "                # If at save interval => save generated image samples\n",
    "                if counter % sample_interval == 0:\n",
    "                    s = self.metrics(counter, teX, sampleSize)\n",
    "        for i in range(len(s)):\n",
    "            self.y[i] = [float(j) / max(self.y[i]) for j in self.y[i]]#瀵瑰€艰繘琛屽綊涓€鍖栧鐞?\n",
    "        for i in range(len(s)):\n",
    "            font1={'size':8}\n",
    "\n",
    "            plt.plot(self.x, self.y[i], label=labels_name[i])\n",
    "            plt.legend(loc='lower right',prop=font1)\n",
    "            plt.savefig('saved_models_wgan/{}.png'.format(labels_name[i]))\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "    def metrics(self, epoch, X_test, sampleSize):\n",
    "        self.x.append(epoch)\n",
    "        batch_nb = sampleSize // self.batch_size\n",
    "        z_sample = np.random.uniform(-1, 1, size=(sampleSize, self.z_dim))\n",
    "        for idx in range(batch_nb):\n",
    "            batch_z = z_sample[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "            samples = self.sess.run(self.fake_images, feed_dict={self.z: batch_z})\n",
    "            if idx == 0:\n",
    "                gen_imgs = samples\n",
    "            else:\n",
    "                gen_imgs = np.concatenate((gen_imgs, samples), axis=0)\n",
    "        x_dataset = MyDataset(X_test[:sampleSize])\n",
    "        # print(x_dataset[0].shape)\n",
    "        x_real_loader = Data.DataLoader(dataset=x_dataset, batch_size=sampleSize, shuffle=True)\n",
    "        x_fake_dataset = MyDataset(gen_imgs)\n",
    "        x_fake_loader = Data.DataLoader(dataset=x_fake_dataset, batch_size=sampleSize, shuffle=True)\n",
    "        s = compute_score_raw(x_real_loader, x_fake_loader, 256, '/real/', './fake', conv_model='tfgan',\n",
    "                              workers=int(1))\n",
    "        real_images = tf.convert_to_tensor(X_test)  # real images\n",
    "        # MNIST_CLASSIFIER_FROZEN_GRAPH = '.\\classify_mnist_graph_def.pb'\n",
    "        gen_imgs = np.array(gen_imgs)\n",
    "        eval_images = tf.convert_to_tensor(gen_imgs)\n",
    "        eval_score = BEGAN.utilss.mnist_score(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH)  # IS score\n",
    "        frechet_distance = BEGAN.utilss.mnist_frechet_distance(real_images, eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH)\n",
    "        mnist_score, f_distance = sess.run([eval_score, frechet_distance])\n",
    "        # print(mnist_score)\n",
    "        # print(f_distance)\n",
    "        # s[14]=mnist_score\n",
    "        # s[16]=f_distance\n",
    "        s[17] = mnist_score\n",
    "        s[18] = f_distance\n",
    "        print('IS socre: %f' % mnist_score)\n",
    "        print('FID: %f' % f_distance)\n",
    "\n",
    "        for i in range(len(s)):\n",
    "            print(i, \"=\", s[i])\n",
    "        for i in range(len(s)):\n",
    "            self.y[i].append(s[i])\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('epoch:' + str(epoch))\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('%.8f' % (i) for i in s)\n",
    "        f.writelines('\\n')\n",
    "        return s\n",
    "    def samples(self,sample_num):\n",
    "        batch_nb=sample_num//self.batch_size\n",
    "        z_sample = np.random.uniform(-1, 1, size=(sample_num, self.z_dim))\n",
    "        for idx in range(batch_nb):\n",
    "            batch_z = z_sample[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "            samples = self.sess.run(self.fake_images, feed_dict={self.z: batch_z})\n",
    "            if idx == 0:\n",
    "                all_samples = samples\n",
    "            else:\n",
    "                all_samples = np.concatenate((all_samples, samples), axis=0)\n",
    "        print(np.array(all_samples).shape)\n",
    "\n",
    "    def visualize_results(self, epoch,counter):\n",
    "        tot_num_samples = self.batch_size\n",
    "        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n",
    "\n",
    "        \"\"\" random condition, random noise \"\"\"\n",
    "\n",
    "        z_sample = np.random.uniform(-1, 1, size=(self.batch_size, self.z_dim))\n",
    "\n",
    "        samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample})\n",
    "\n",
    "        save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n",
    "                    check_folder('/home/ubuntu/soft/huangdengrong/GAN/code/GAN_NEW/mode_anomaly/results/'  + self.model_dir) + '/' + self.model_name + '_epoch%03d'\n",
    "                    % epoch + '_step%d'%counter+'_test_all_classes.png')\n",
    "\n",
    "    @property\n",
    "    def model_dir(self):\n",
    "        return \"{}_{}_{}_{}\".format(\n",
    "            self.model_name, self.dataset_name,\n",
    "            self.batch_size, self.z_dim)\n",
    "\n",
    "def main():\n",
    "\n",
    "    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "        # declare instance for GAN\n",
    "\n",
    "\n",
    "        gan =WGAN(sess,epoch=50,\n",
    "                            batch_size=100,\n",
    "                            z_dim=62,\n",
    "                            dataset_name='mnist',\n",
    "                            checkpoint_dir='checkpoint',\n",
    "                            result_dir='resluts',\n",
    "                            log_dir='logs')\n",
    "\n",
    "\n",
    "        # build graph\n",
    "        gan.build_model()\n",
    "\n",
    "        # show network architecture\n",
    "        show_all_variables()\n",
    "\n",
    "        # launch the graph in a session\n",
    "        gan.train()\n",
    "        print(\" [*] Training finished!\")\n",
    "\n",
    "        # visualize learned generator\n",
    "        # gan.visualize_results(args.epoch-1)\n",
    "        # print(\" [*] Testing finished!\")\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
