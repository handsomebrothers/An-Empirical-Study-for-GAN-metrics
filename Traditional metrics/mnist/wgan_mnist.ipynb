{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 16)        160       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 100,097\n",
      "Trainable params: 99,649\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 64)        131136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 1)         1025      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,028,673\n",
      "Trainable params: 1,028,289\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:5[D loss: 0.999911] [G loss: 1.000173]\n",
      "epoch:0 step:10[D loss: 0.999918] [G loss: 1.000176]\n",
      "epoch:0 step:15[D loss: 0.999924] [G loss: 1.000182]\n",
      "epoch:0 step:20[D loss: 0.999918] [G loss: 1.000174]\n",
      "epoch:0 step:25[D loss: 0.999920] [G loss: 1.000173]\n",
      "epoch:0 step:30[D loss: 0.999918] [G loss: 1.000175]\n",
      "epoch:0 step:35[D loss: 0.999922] [G loss: 1.000171]\n",
      "epoch:0 step:40[D loss: 0.999922] [G loss: 1.000172]\n",
      "epoch:0 step:45[D loss: 0.999922] [G loss: 1.000173]\n",
      "epoch:0 step:50[D loss: 0.999923] [G loss: 1.000172]\n",
      "epoch:0 step:55[D loss: 0.999926] [G loss: 1.000175]\n",
      "epoch:0 step:60[D loss: 0.999927] [G loss: 1.000168]\n",
      "epoch:0 step:65[D loss: 0.999927] [G loss: 1.000159]\n",
      "epoch:0 step:70[D loss: 0.999927] [G loss: 1.000156]\n",
      "epoch:0 step:75[D loss: 0.999928] [G loss: 1.000150]\n",
      "epoch:0 step:80[D loss: 0.999933] [G loss: 1.000145]\n",
      "epoch:0 step:85[D loss: 0.999935] [G loss: 1.000135]\n",
      "epoch:0 step:90[D loss: 0.999940] [G loss: 1.000131]\n",
      "epoch:0 step:95[D loss: 0.999939] [G loss: 1.000118]\n",
      "epoch:0 step:100[D loss: 0.999940] [G loss: 1.000118]\n",
      "epoch:0 step:105[D loss: 0.999945] [G loss: 1.000112]\n",
      "epoch:0 step:110[D loss: 0.999945] [G loss: 1.000107]\n",
      "epoch:0 step:115[D loss: 0.999947] [G loss: 1.000105]\n",
      "epoch:0 step:120[D loss: 0.999947] [G loss: 1.000099]\n",
      "epoch:0 step:125[D loss: 0.999952] [G loss: 1.000094]\n",
      "epoch:0 step:130[D loss: 0.999956] [G loss: 1.000090]\n",
      "epoch:0 step:135[D loss: 0.999955] [G loss: 1.000088]\n",
      "epoch:0 step:140[D loss: 0.999960] [G loss: 1.000082]\n",
      "epoch:0 step:145[D loss: 0.999961] [G loss: 1.000077]\n",
      "epoch:0 step:150[D loss: 0.999961] [G loss: 1.000074]\n",
      "epoch:0 step:155[D loss: 0.999964] [G loss: 1.000072]\n",
      "epoch:0 step:160[D loss: 0.999965] [G loss: 1.000070]\n",
      "epoch:0 step:165[D loss: 0.999965] [G loss: 1.000072]\n",
      "epoch:0 step:170[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:0 step:175[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:0 step:180[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:0 step:185[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:0 step:190[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:0 step:195[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:0 step:200[D loss: 0.999974] [G loss: 1.000067]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "WARNING:tensorflow:From /home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/contrib/gan/python/eval/python/classifier_metrics_impl.py:185: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute score in space: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/ot/lp/__init__.py:211: UserWarning: numItermax reached before optimality. Try to increase numItermax.\n",
      "  check_result(result_code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute score in space: 1\n",
      "IS socre: 2.201110\n",
      "FID: 203.362289\n",
      "0 = 21.994444998741265\n",
      "1 = 0.5043019951191835\n",
      "2 = 1.0\n",
      "3 = 1.0\n",
      "4 = 1.0\n",
      "5 = 1.0\n",
      "6 = 1.0\n",
      "7 = 15.359890721940966\n",
      "8 = 0.2682075615240085\n",
      "9 = 0.9940000176429749\n",
      "10 = 0.9900000095367432\n",
      "11 = 0.9980000257492065\n",
      "12 = 0.9979838728904724\n",
      "13 = 0.9900000095367432\n",
      "14 = 2.2011094093322754\n",
      "15 = 7.577450275421143\n",
      "16 = 0.5610085725784302\n",
      "17 = 2.2011098861694336\n",
      "18 = 203.36228942871094\n",
      "epoch:0 step:205[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:0 step:210[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:0 step:215[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:0 step:220[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:0 step:225[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:0 step:230[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:0 step:235[D loss: 0.999985] [G loss: 1.000071]\n",
      "epoch:0 step:240[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:0 step:245[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:0 step:250[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:0 step:255[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:0 step:260[D loss: 0.999992] [G loss: 1.000072]\n",
      "epoch:0 step:265[D loss: 0.999991] [G loss: 1.000071]\n",
      "epoch:0 step:270[D loss: 0.999985] [G loss: 1.000075]\n",
      "epoch:0 step:275[D loss: 0.999991] [G loss: 1.000084]\n",
      "epoch:0 step:280[D loss: 0.999990] [G loss: 1.000083]\n",
      "epoch:0 step:285[D loss: 0.999990] [G loss: 1.000087]\n",
      "epoch:0 step:290[D loss: 0.999987] [G loss: 1.000092]\n",
      "epoch:0 step:295[D loss: 0.999993] [G loss: 1.000096]\n",
      "epoch:0 step:300[D loss: 0.999985] [G loss: 1.000099]\n",
      "epoch:0 step:305[D loss: 0.999988] [G loss: 1.000107]\n",
      "epoch:0 step:310[D loss: 0.999994] [G loss: 1.000098]\n",
      "epoch:0 step:315[D loss: 0.999990] [G loss: 1.000110]\n",
      "epoch:0 step:320[D loss: 0.999987] [G loss: 1.000114]\n",
      "epoch:0 step:325[D loss: 0.999984] [G loss: 1.000123]\n",
      "epoch:0 step:330[D loss: 0.999978] [G loss: 1.000129]\n",
      "epoch:0 step:335[D loss: 0.999991] [G loss: 1.000138]\n",
      "epoch:0 step:340[D loss: 0.999986] [G loss: 1.000131]\n",
      "epoch:0 step:345[D loss: 0.999980] [G loss: 1.000138]\n",
      "epoch:0 step:350[D loss: 0.999975] [G loss: 1.000147]\n",
      "epoch:0 step:355[D loss: 0.999977] [G loss: 1.000142]\n",
      "epoch:0 step:360[D loss: 0.999979] [G loss: 1.000142]\n",
      "epoch:0 step:365[D loss: 0.999982] [G loss: 1.000149]\n",
      "epoch:0 step:370[D loss: 0.999971] [G loss: 1.000146]\n",
      "epoch:0 step:375[D loss: 0.999970] [G loss: 1.000147]\n",
      "epoch:0 step:380[D loss: 0.999969] [G loss: 1.000145]\n",
      "epoch:0 step:385[D loss: 0.999973] [G loss: 1.000133]\n",
      "epoch:0 step:390[D loss: 0.999966] [G loss: 1.000130]\n",
      "epoch:0 step:395[D loss: 0.999970] [G loss: 1.000139]\n",
      "epoch:0 step:400[D loss: 0.999972] [G loss: 1.000130]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 2.498651\n",
      "FID: 175.884384\n",
      "0 = 16.549756172656917\n",
      "1 = 0.2762478951766666\n",
      "2 = 0.9989500045776367\n",
      "3 = 0.9979000091552734\n",
      "4 = 1.0\n",
      "5 = 1.0\n",
      "6 = 0.9979000091552734\n",
      "7 = 14.623620009851507\n",
      "8 = 0.24736758957645152\n",
      "9 = 0.9907000064849854\n",
      "10 = 0.9847000241279602\n",
      "11 = 0.9966999888420105\n",
      "12 = 0.9966599345207214\n",
      "13 = 0.9847000241279602\n",
      "14 = 2.4986515045166016\n",
      "15 = 7.890643119812012\n",
      "16 = 0.5173807144165039\n",
      "17 = 2.4986512660980225\n",
      "18 = 175.88438415527344\n",
      "epoch:0 step:405[D loss: 0.999970] [G loss: 1.000127]\n",
      "epoch:0 step:410[D loss: 0.999969] [G loss: 1.000132]\n",
      "epoch:0 step:415[D loss: 0.999970] [G loss: 1.000125]\n",
      "epoch:0 step:420[D loss: 0.999972] [G loss: 1.000123]\n",
      "epoch:0 step:425[D loss: 0.999968] [G loss: 1.000121]\n",
      "epoch:0 step:430[D loss: 0.999976] [G loss: 1.000123]\n",
      "epoch:0 step:435[D loss: 0.999971] [G loss: 1.000125]\n",
      "epoch:0 step:440[D loss: 0.999970] [G loss: 1.000129]\n",
      "epoch:0 step:445[D loss: 0.999970] [G loss: 1.000132]\n",
      "epoch:0 step:450[D loss: 0.999972] [G loss: 1.000123]\n",
      "epoch:0 step:455[D loss: 0.999972] [G loss: 1.000116]\n",
      "epoch:0 step:460[D loss: 0.999972] [G loss: 1.000122]\n",
      "epoch:0 step:465[D loss: 0.999971] [G loss: 1.000119]\n",
      "epoch:0 step:470[D loss: 0.999968] [G loss: 1.000115]\n",
      "epoch:0 step:475[D loss: 0.999973] [G loss: 1.000108]\n",
      "epoch:0 step:480[D loss: 0.999973] [G loss: 1.000108]\n",
      "epoch:0 step:485[D loss: 0.999969] [G loss: 1.000111]\n",
      "epoch:0 step:490[D loss: 0.999973] [G loss: 1.000105]\n",
      "epoch:0 step:495[D loss: 0.999971] [G loss: 1.000110]\n",
      "epoch:0 step:500[D loss: 0.999971] [G loss: 1.000106]\n",
      "epoch:0 step:505[D loss: 0.999972] [G loss: 1.000104]\n",
      "epoch:0 step:510[D loss: 0.999970] [G loss: 1.000110]\n",
      "epoch:0 step:515[D loss: 0.999964] [G loss: 1.000112]\n",
      "epoch:0 step:520[D loss: 0.999974] [G loss: 1.000105]\n",
      "epoch:0 step:525[D loss: 0.999973] [G loss: 1.000104]\n",
      "epoch:0 step:530[D loss: 0.999971] [G loss: 1.000094]\n",
      "epoch:0 step:535[D loss: 0.999973] [G loss: 1.000092]\n",
      "epoch:0 step:540[D loss: 0.999968] [G loss: 1.000092]\n",
      "epoch:0 step:545[D loss: 0.999970] [G loss: 1.000095]\n",
      "epoch:0 step:550[D loss: 0.999967] [G loss: 1.000095]\n",
      "epoch:0 step:555[D loss: 0.999971] [G loss: 1.000090]\n",
      "epoch:0 step:560[D loss: 0.999968] [G loss: 1.000088]\n",
      "epoch:0 step:565[D loss: 0.999969] [G loss: 1.000089]\n",
      "epoch:0 step:570[D loss: 0.999974] [G loss: 1.000091]\n",
      "epoch:0 step:575[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:0 step:580[D loss: 0.999969] [G loss: 1.000084]\n",
      "epoch:0 step:585[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:0 step:590[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:0 step:595[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:0 step:600[D loss: 0.999974] [G loss: 1.000083]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 2.388757\n",
      "FID: 175.930481\n",
      "0 = 14.51401376380922\n",
      "1 = 0.18667356830281376\n",
      "2 = 0.9910500049591064\n",
      "3 = 0.9824000000953674\n",
      "4 = 0.9997000098228455\n",
      "5 = 0.9996947050094604\n",
      "6 = 0.9824000000953674\n",
      "7 = 14.575447838306491\n",
      "8 = 0.2427214612125477\n",
      "9 = 0.990149974822998\n",
      "10 = 0.983299970626831\n",
      "11 = 0.996999979019165\n",
      "12 = 0.996958315372467\n",
      "13 = 0.983299970626831\n",
      "14 = 2.3887581825256348\n",
      "15 = 7.898094654083252\n",
      "16 = 0.5472201108932495\n",
      "17 = 2.3887572288513184\n",
      "18 = 175.93048095703125\n",
      "epoch:0 step:605[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:0 step:610[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:0 step:615[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:0 step:620[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:0 step:625[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:0 step:630[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:0 step:635[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:0 step:640[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:0 step:645[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:0 step:650[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:0 step:655[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:0 step:660[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:0 step:665[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:0 step:670[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:0 step:675[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:0 step:680[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:0 step:685[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:0 step:690[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:0 step:695[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:0 step:700[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:0 step:705[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:0 step:710[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:0 step:715[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:0 step:720[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:0 step:725[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:0 step:730[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:0 step:735[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:0 step:740[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:0 step:745[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:750[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:0 step:755[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:0 step:760[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:0 step:765[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:0 step:770[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:0 step:775[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:0 step:780[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:0 step:785[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:0 step:790[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:0 step:795[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:0 step:800[D loss: 0.999974] [G loss: 1.000072]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 2.416820\n",
      "FID: 177.243530\n",
      "0 = 14.210642739200573\n",
      "1 = 0.14899380490525935\n",
      "2 = 0.9881500005722046\n",
      "3 = 0.9764000177383423\n",
      "4 = 0.9998999834060669\n",
      "5 = 0.9998975992202759\n",
      "6 = 0.9764000177383423\n",
      "7 = 14.635731031060242\n",
      "8 = 0.24556736432483808\n",
      "9 = 0.9896500110626221\n",
      "10 = 0.9829000234603882\n",
      "11 = 0.996399998664856\n",
      "12 = 0.9963507056236267\n",
      "13 = 0.9829000234603882\n",
      "14 = 2.4168200492858887\n",
      "15 = 7.812044143676758\n",
      "16 = 0.5370557904243469\n",
      "17 = 2.4168200492858887\n",
      "18 = 177.2435302734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:805[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:0 step:810[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:0 step:815[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:0 step:820[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:0 step:825[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:0 step:830[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:0 step:835[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:840[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:0 step:845[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:0 step:850[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:0 step:855[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:0 step:860[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:0 step:865[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:0 step:870[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:0 step:875[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:0 step:880[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:0 step:885[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:0 step:890[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:0 step:895[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:0 step:900[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:0 step:905[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:0 step:910[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:0 step:915[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:0 step:920[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:0 step:925[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:0 step:930[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:0 step:935[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:0 step:940[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:0 step:945[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:0 step:950[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:0 step:955[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:0 step:960[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:0 step:965[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:0 step:970[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:0 step:975[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:0 step:980[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:0 step:985[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:0 step:990[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:0 step:995[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:0 step:1000[D loss: 0.999972] [G loss: 1.000072]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 2.569166\n",
      "FID: 165.328506\n",
      "0 = 14.010246629571945\n",
      "1 = 0.13795738441250774\n",
      "2 = 0.9861000180244446\n",
      "3 = 0.9728999733924866\n",
      "4 = 0.9993000030517578\n",
      "5 = 0.9992809891700745\n",
      "6 = 0.9728999733924866\n",
      "7 = 14.371870368552257\n",
      "8 = 0.24283930528672387\n",
      "9 = 0.9859499931335449\n",
      "10 = 0.9785000085830688\n",
      "11 = 0.993399977684021\n",
      "12 = 0.993300199508667\n",
      "13 = 0.9785000085830688\n",
      "14 = 2.569166898727417\n",
      "15 = 7.852322578430176\n",
      "16 = 0.5214062929153442\n",
      "17 = 2.5691661834716797\n",
      "18 = 165.32850646972656\n",
      "epoch:0 step:1005[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:0 step:1010[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:0 step:1015[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:0 step:1020[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:0 step:1025[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:0 step:1030[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:0 step:1035[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:0 step:1040[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:0 step:1045[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:0 step:1050[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:0 step:1055[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:0 step:1060[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:0 step:1065[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:0 step:1070[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:0 step:1075[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:0 step:1080[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:0 step:1085[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:0 step:1090[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:0 step:1095[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:0 step:1100[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:0 step:1105[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:0 step:1110[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:0 step:1115[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:0 step:1120[D loss: 0.999966] [G loss: 1.000065]\n",
      "epoch:0 step:1125[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:0 step:1130[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:0 step:1135[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:0 step:1140[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:0 step:1145[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:0 step:1150[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:0 step:1155[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:0 step:1160[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:0 step:1165[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:0 step:1170[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:1175[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:0 step:1180[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:0 step:1185[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:0 step:1190[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:0 step:1195[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:0 step:1200[D loss: 0.999973] [G loss: 1.000069]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 2.814789\n",
      "FID: 145.892746\n",
      "0 = 14.007869838094766\n",
      "1 = 0.14766411331472162\n",
      "2 = 0.9846500158309937\n",
      "3 = 0.9702000021934509\n",
      "4 = 0.9991000294685364\n",
      "5 = 0.9990732073783875\n",
      "6 = 0.9702000021934509\n",
      "7 = 13.873207548046086\n",
      "8 = 0.22820423788069\n",
      "9 = 0.982450008392334\n",
      "10 = 0.9742000102996826\n",
      "11 = 0.9907000064849854\n",
      "12 = 0.9905439615249634\n",
      "13 = 0.9742000102996826\n",
      "14 = 2.8147926330566406\n",
      "15 = 7.787703514099121\n",
      "16 = 0.49936777353286743\n",
      "17 = 2.814788579940796\n",
      "18 = 145.8927459716797\n",
      "epoch:0 step:1205[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:0 step:1210[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:0 step:1215[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:0 step:1220[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:0 step:1225[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:0 step:1230[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:0 step:1235[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:0 step:1240[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:0 step:1245[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:0 step:1250[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:0 step:1255[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:0 step:1260[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:0 step:1265[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:1270[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:0 step:1275[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:1280[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:0 step:1285[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:0 step:1290[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:0 step:1295[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:0 step:1300[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:0 step:1305[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:0 step:1310[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:0 step:1315[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:0 step:1320[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:0 step:1325[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:0 step:1330[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:0 step:1335[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:0 step:1340[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:0 step:1345[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:0 step:1350[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:0 step:1355[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:0 step:1360[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:1365[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:0 step:1370[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:0 step:1375[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:0 step:1380[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:0 step:1385[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:0 step:1390[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:0 step:1395[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:0 step:1400[D loss: 0.999972] [G loss: 1.000068]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 3.255608\n",
      "FID: 124.407120\n",
      "0 = 14.578809089660671\n",
      "1 = 0.14018392266289575\n",
      "2 = 0.9904000163078308\n",
      "3 = 0.9825000166893005\n",
      "4 = 0.9983000159263611\n",
      "5 = 0.998272716999054\n",
      "6 = 0.9825000166893005\n",
      "7 = 13.208030797028517\n",
      "8 = 0.2132324833713702\n",
      "9 = 0.9757000207901001\n",
      "10 = 0.965399980545044\n",
      "11 = 0.9860000014305115\n",
      "12 = 0.985705554485321\n",
      "13 = 0.965399980545044\n",
      "14 = 3.255615234375\n",
      "15 = 7.60625696182251\n",
      "16 = 0.4759279191493988\n",
      "17 = 3.255608320236206\n",
      "18 = 124.40711975097656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:1405[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:0 step:1410[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:0 step:1415[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:0 step:1420[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:0 step:1425[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:0 step:1430[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:0 step:1435[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:0 step:1440[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:0 step:1445[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:0 step:1450[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:0 step:1455[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:0 step:1460[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:0 step:1465[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:0 step:1470[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:0 step:1475[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:0 step:1480[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:0 step:1485[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:0 step:1490[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:0 step:1495[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:0 step:1500[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:0 step:1505[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:0 step:1510[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:0 step:1515[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:0 step:1520[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:0 step:1525[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:0 step:1530[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:0 step:1535[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:0 step:1540[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:0 step:1545[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:0 step:1550[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:0 step:1555[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:1560[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:0 step:1565[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:0 step:1570[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:0 step:1575[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:0 step:1580[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:0 step:1585[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:0 step:1590[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:0 step:1595[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:0 step:1600[D loss: 0.999973] [G loss: 1.000064]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 3.400613\n",
      "FID: 120.241913\n",
      "0 = 14.143955757617983\n",
      "1 = 0.09295443897533741\n",
      "2 = 0.98294997215271\n",
      "3 = 0.9710000157356262\n",
      "4 = 0.9948999881744385\n",
      "5 = 0.994775116443634\n",
      "6 = 0.9710000157356262\n",
      "7 = 13.163886200797533\n",
      "8 = 0.21322465641809404\n",
      "9 = 0.9739999771118164\n",
      "10 = 0.9660999774932861\n",
      "11 = 0.9818999767303467\n",
      "12 = 0.9816094040870667\n",
      "13 = 0.9660999774932861\n",
      "14 = 3.4006187915802\n",
      "15 = 8.009578704833984\n",
      "16 = 0.435800164937973\n",
      "17 = 3.400613307952881\n",
      "18 = 120.24191284179688\n",
      "epoch:0 step:1605[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:0 step:1610[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:0 step:1615[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:0 step:1620[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:0 step:1625[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:0 step:1630[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:0 step:1635[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:0 step:1640[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:1645[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:0 step:1650[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:0 step:1655[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:0 step:1660[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:0 step:1665[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:0 step:1670[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:0 step:1675[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:0 step:1680[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:1685[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:0 step:1690[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:0 step:1695[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:0 step:1700[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:0 step:1705[D loss: 0.999969] [G loss: 1.000055]\n",
      "epoch:0 step:1710[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:0 step:1715[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:0 step:1720[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:0 step:1725[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:0 step:1730[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:0 step:1735[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:0 step:1740[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:1745[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:0 step:1750[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:0 step:1755[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:0 step:1760[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:0 step:1765[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:0 step:1770[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:1775[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:0 step:1780[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:0 step:1785[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:0 step:1790[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:0 step:1795[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:0 step:1800[D loss: 0.999968] [G loss: 1.000064]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 3.636202\n",
      "FID: 107.052452\n",
      "0 = 14.419522389602596\n",
      "1 = 0.0953493391041088\n",
      "2 = 0.9823499917984009\n",
      "3 = 0.9764999747276306\n",
      "4 = 0.9882000088691711\n",
      "5 = 0.9880602955818176\n",
      "6 = 0.9764999747276306\n",
      "7 = 12.76853304662698\n",
      "8 = 0.20322327803920376\n",
      "9 = 0.9674000144004822\n",
      "10 = 0.9603999853134155\n",
      "11 = 0.974399983882904\n",
      "12 = 0.9740365147590637\n",
      "13 = 0.9603999853134155\n",
      "14 = 3.63621187210083\n",
      "15 = 8.283880233764648\n",
      "16 = 0.404558926820755\n",
      "17 = 3.636201858520508\n",
      "18 = 107.05245208740234\n",
      "epoch:0 step:1805[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:0 step:1810[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:0 step:1815[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:0 step:1820[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:0 step:1825[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:0 step:1830[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:0 step:1835[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:0 step:1840[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:0 step:1845[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:1850[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:0 step:1855[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:0 step:1860[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:0 step:1865[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:0 step:1870[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:0 step:1875[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:0 step:1880[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:0 step:1885[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:0 step:1890[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:0 step:1895[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:0 step:1900[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:0 step:1905[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:0 step:1910[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:0 step:1915[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:0 step:1920[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:0 step:1925[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:0 step:1930[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:0 step:1935[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:0 step:1940[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:0 step:1945[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:1950[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:0 step:1955[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:0 step:1960[D loss: 0.999965] [G loss: 1.000059]\n",
      "epoch:0 step:1965[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:0 step:1970[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:0 step:1975[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:0 step:1980[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:0 step:1985[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:0 step:1990[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:0 step:1995[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:0 step:2000[D loss: 0.999970] [G loss: 1.000072]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 3.810636\n",
      "FID: 104.957138\n",
      "0 = 14.204062060117723\n",
      "1 = 0.07952766095590075\n",
      "2 = 0.9811499714851379\n",
      "3 = 0.9767000079154968\n",
      "4 = 0.9855999946594238\n",
      "5 = 0.985470712184906\n",
      "6 = 0.9767000079154968\n",
      "7 = 12.781607201385544\n",
      "8 = 0.20274522932392475\n",
      "9 = 0.9664000272750854\n",
      "10 = 0.9620000123977661\n",
      "11 = 0.97079998254776\n",
      "12 = 0.9705407619476318\n",
      "13 = 0.9620000123977661\n",
      "14 = 3.810645580291748\n",
      "15 = 8.528308868408203\n",
      "16 = 0.3769015073776245\n",
      "17 = 3.810635805130005\n",
      "18 = 104.95713806152344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:2005[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:0 step:2010[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:0 step:2015[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:0 step:2020[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:0 step:2025[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:0 step:2030[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:0 step:2035[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:0 step:2040[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:0 step:2045[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:0 step:2050[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:0 step:2055[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:2060[D loss: 0.999963] [G loss: 1.000070]\n",
      "epoch:0 step:2065[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:0 step:2070[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:0 step:2075[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:2080[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:0 step:2085[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:0 step:2090[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:0 step:2095[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:0 step:2100[D loss: 0.999965] [G loss: 1.000064]\n",
      "epoch:0 step:2105[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:0 step:2110[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:0 step:2115[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:0 step:2120[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:0 step:2125[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:0 step:2130[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:0 step:2135[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:0 step:2140[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:0 step:2145[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:0 step:2150[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:0 step:2155[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:0 step:2160[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:2165[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:0 step:2170[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:0 step:2175[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:0 step:2180[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:0 step:2185[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:0 step:2190[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:2195[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:0 step:2200[D loss: 0.999973] [G loss: 1.000066]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.247875\n",
      "FID: 88.069839\n",
      "0 = 15.339826007223119\n",
      "1 = 0.1470557703374423\n",
      "2 = 0.9799000024795532\n",
      "3 = 0.9886000156402588\n",
      "4 = 0.9711999893188477\n",
      "5 = 0.9716925621032715\n",
      "6 = 0.9886000156402588\n",
      "7 = 12.156764898097466\n",
      "8 = 0.1899633713601022\n",
      "9 = 0.9577000141143799\n",
      "10 = 0.9544000029563904\n",
      "11 = 0.9610000252723694\n",
      "12 = 0.960740864276886\n",
      "13 = 0.9544000029563904\n",
      "14 = 4.24788761138916\n",
      "15 = 8.74505615234375\n",
      "16 = 0.3367290198802948\n",
      "17 = 4.247874736785889\n",
      "18 = 88.06983947753906\n",
      "epoch:0 step:2205[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:0 step:2210[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:0 step:2215[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:0 step:2220[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:0 step:2225[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:0 step:2230[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:0 step:2235[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:0 step:2240[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:0 step:2245[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:0 step:2250[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:0 step:2255[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:2260[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:0 step:2265[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:0 step:2270[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:0 step:2275[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:0 step:2280[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:0 step:2285[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:2290[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:0 step:2295[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:0 step:2300[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:0 step:2305[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:0 step:2310[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:0 step:2315[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:0 step:2320[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:0 step:2325[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:0 step:2330[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:0 step:2335[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:2340[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:0 step:2345[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:0 step:2350[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:0 step:2355[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:2360[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:0 step:2365[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:0 step:2370[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:0 step:2375[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:2380[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:0 step:2385[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:0 step:2390[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:0 step:2395[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:2400[D loss: 0.999973] [G loss: 1.000070]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 3.640616\n",
      "FID: 117.467560\n",
      "0 = 14.329211878299768\n",
      "1 = 0.1743492287901266\n",
      "2 = 0.9839000105857849\n",
      "3 = 0.9794999957084656\n",
      "4 = 0.9883000254631042\n",
      "5 = 0.9881961345672607\n",
      "6 = 0.9794999957084656\n",
      "7 = 13.224038813304881\n",
      "8 = 0.21538129662482539\n",
      "9 = 0.9728500247001648\n",
      "10 = 0.9696999788284302\n",
      "11 = 0.9760000109672546\n",
      "12 = 0.9758478403091431\n",
      "13 = 0.9696999788284302\n",
      "14 = 3.6406242847442627\n",
      "15 = 8.505741119384766\n",
      "16 = 0.3884308934211731\n",
      "17 = 3.6406161785125732\n",
      "18 = 117.46755981445312\n",
      "epoch:0 step:2405[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:0 step:2410[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:0 step:2415[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:0 step:2420[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:0 step:2425[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:0 step:2430[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:0 step:2435[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:0 step:2440[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:0 step:2445[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:0 step:2450[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:0 step:2455[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:2460[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:2465[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:0 step:2470[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:2475[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:0 step:2480[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:0 step:2485[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:0 step:2490[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:0 step:2495[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:0 step:2500[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:0 step:2505[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:0 step:2510[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:2515[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:0 step:2520[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:0 step:2525[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:0 step:2530[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:0 step:2535[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:0 step:2540[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:2545[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:0 step:2550[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:0 step:2555[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:0 step:2560[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:0 step:2565[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:0 step:2570[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:0 step:2575[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:0 step:2580[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:0 step:2585[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:0 step:2590[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:0 step:2595[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:0 step:2600[D loss: 0.999971] [G loss: 1.000065]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.370550\n",
      "FID: 90.165634\n",
      "0 = 14.631407206392343\n",
      "1 = 0.0706381145892715\n",
      "2 = 0.9761499762535095\n",
      "3 = 0.9876999855041504\n",
      "4 = 0.9646000266075134\n",
      "5 = 0.9653992652893066\n",
      "6 = 0.9876999855041504\n",
      "7 = 12.269922429609295\n",
      "8 = 0.1954083016997204\n",
      "9 = 0.9571999907493591\n",
      "10 = 0.95660001039505\n",
      "11 = 0.9577999711036682\n",
      "12 = 0.9577493071556091\n",
      "13 = 0.95660001039505\n",
      "14 = 4.370569705963135\n",
      "15 = 8.858282089233398\n",
      "16 = 0.3179851770401001\n",
      "17 = 4.37054967880249\n",
      "18 = 90.16563415527344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:2605[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:0 step:2610[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:0 step:2615[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:0 step:2620[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:0 step:2625[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:2630[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:0 step:2635[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:0 step:2640[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:0 step:2645[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:0 step:2650[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:0 step:2655[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:0 step:2660[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:0 step:2665[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:0 step:2670[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:2675[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:2680[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:0 step:2685[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:2690[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:0 step:2695[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:0 step:2700[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:0 step:2705[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:0 step:2710[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:0 step:2715[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:0 step:2720[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:0 step:2725[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:0 step:2730[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:0 step:2735[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:0 step:2740[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:0 step:2745[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:0 step:2750[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:0 step:2755[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:0 step:2760[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:0 step:2765[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:2770[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:0 step:2775[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:0 step:2780[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:0 step:2785[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:0 step:2790[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:0 step:2795[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:0 step:2800[D loss: 0.999971] [G loss: 1.000060]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.289988\n",
      "FID: 92.352501\n",
      "0 = 14.50082484865192\n",
      "1 = 0.07202107057614177\n",
      "2 = 0.9760500192642212\n",
      "3 = 0.9853000044822693\n",
      "4 = 0.9667999744415283\n",
      "5 = 0.9674030542373657\n",
      "6 = 0.9853000044822693\n",
      "7 = 12.319457640695632\n",
      "8 = 0.19731064084530184\n",
      "9 = 0.9564499855041504\n",
      "10 = 0.9545999765396118\n",
      "11 = 0.958299994468689\n",
      "12 = 0.9581451416015625\n",
      "13 = 0.9545999765396118\n",
      "14 = 4.29000997543335\n",
      "15 = 8.564167022705078\n",
      "16 = 0.3504053056240082\n",
      "17 = 4.289987564086914\n",
      "18 = 92.35250091552734\n",
      "epoch:0 step:2805[D loss: 0.999969] [G loss: 1.000057]\n",
      "epoch:0 step:2810[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:0 step:2815[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:0 step:2820[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:0 step:2825[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:0 step:2830[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:0 step:2835[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:0 step:2840[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:0 step:2845[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:0 step:2850[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:0 step:2855[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:0 step:2860[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:0 step:2865[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:0 step:2870[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:0 step:2875[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:0 step:2880[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:0 step:2885[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:0 step:2890[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:0 step:2895[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:2900[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:0 step:2905[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:0 step:2910[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:0 step:2915[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:0 step:2920[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:0 step:2925[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:0 step:2930[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:0 step:2935[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:0 step:2940[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:2945[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:0 step:2950[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:0 step:2955[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:0 step:2960[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:0 step:2965[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:0 step:2970[D loss: 0.999964] [G loss: 1.000064]\n",
      "epoch:0 step:2975[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:2980[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:0 step:2985[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:0 step:2990[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:0 step:2995[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:0 step:3000[D loss: 0.999969] [G loss: 1.000067]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.215624\n",
      "FID: 91.417809\n",
      "0 = 14.473758460950927\n",
      "1 = 0.06775155277513854\n",
      "2 = 0.9750499725341797\n",
      "3 = 0.9855999946594238\n",
      "4 = 0.9645000100135803\n",
      "5 = 0.965233564376831\n",
      "6 = 0.9855999946594238\n",
      "7 = 12.312134308206963\n",
      "8 = 0.1952105446781501\n",
      "9 = 0.9574999809265137\n",
      "10 = 0.9570000171661377\n",
      "11 = 0.9580000042915344\n",
      "12 = 0.9579579830169678\n",
      "13 = 0.9570000171661377\n",
      "14 = 4.215638637542725\n",
      "15 = 8.587922096252441\n",
      "16 = 0.3591659963130951\n",
      "17 = 4.21562385559082\n",
      "18 = 91.41780853271484\n",
      "epoch:0 step:3005[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:0 step:3010[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:0 step:3015[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:0 step:3020[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:0 step:3025[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:0 step:3030[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:0 step:3035[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:0 step:3040[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:0 step:3045[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:0 step:3050[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:3055[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:0 step:3060[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:3065[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:0 step:3070[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:0 step:3075[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:0 step:3080[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:0 step:3085[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:0 step:3090[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:0 step:3095[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:0 step:3100[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:3105[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:0 step:3110[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:0 step:3115[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:0 step:3120[D loss: 0.999966] [G loss: 1.000065]\n",
      "epoch:0 step:3125[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:0 step:3130[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:0 step:3135[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:3140[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:0 step:3145[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:0 step:3150[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:0 step:3155[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:0 step:3160[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:0 step:3165[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:0 step:3170[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:0 step:3175[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:0 step:3180[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:3185[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:0 step:3190[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:0 step:3195[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:0 step:3200[D loss: 0.999973] [G loss: 1.000067]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.213793\n",
      "FID: 90.133461\n",
      "0 = 14.636832191705752\n",
      "1 = 0.07316320611276361\n",
      "2 = 0.9754499793052673\n",
      "3 = 0.9883000254631042\n",
      "4 = 0.9625999927520752\n",
      "5 = 0.9635370969772339\n",
      "6 = 0.9883000254631042\n",
      "7 = 12.21989094830749\n",
      "8 = 0.19589025874003607\n",
      "9 = 0.9543499946594238\n",
      "10 = 0.9534000158309937\n",
      "11 = 0.955299973487854\n",
      "12 = 0.9552149176597595\n",
      "13 = 0.9534000158309937\n",
      "14 = 4.213807106018066\n",
      "15 = 8.584261894226074\n",
      "16 = 0.3535621464252472\n",
      "17 = 4.2137932777404785\n",
      "18 = 90.13346099853516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:3205[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:0 step:3210[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:0 step:3215[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:0 step:3220[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:0 step:3225[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:0 step:3230[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:0 step:3235[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:0 step:3240[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:0 step:3245[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:0 step:3250[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:0 step:3255[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:0 step:3260[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:0 step:3265[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:0 step:3270[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:0 step:3275[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:0 step:3280[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:0 step:3285[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:0 step:3290[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:0 step:3295[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:0 step:3300[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:0 step:3305[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:0 step:3310[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:3315[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:0 step:3320[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:0 step:3325[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:0 step:3330[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:0 step:3335[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:0 step:3340[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:0 step:3345[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:0 step:3350[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:0 step:3355[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:0 step:3360[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:0 step:3365[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:0 step:3370[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:0 step:3375[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:0 step:3380[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:0 step:3385[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:0 step:3390[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:0 step:3395[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:0 step:3400[D loss: 0.999973] [G loss: 1.000065]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.082144\n",
      "FID: 91.962234\n",
      "0 = 14.642113120937312\n",
      "1 = 0.07150361682840566\n",
      "2 = 0.9782000184059143\n",
      "3 = 0.9883000254631042\n",
      "4 = 0.9681000113487244\n",
      "5 = 0.9687316417694092\n",
      "6 = 0.9883000254631042\n",
      "7 = 12.310735727655912\n",
      "8 = 0.19629513555592742\n",
      "9 = 0.9529500007629395\n",
      "10 = 0.9523000121116638\n",
      "11 = 0.9535999894142151\n",
      "12 = 0.9535396099090576\n",
      "13 = 0.9523000121116638\n",
      "14 = 4.082160472869873\n",
      "15 = 8.288410186767578\n",
      "16 = 0.38766512274742126\n",
      "17 = 4.082144260406494\n",
      "18 = 91.96223449707031\n",
      "epoch:0 step:3405[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:0 step:3410[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:0 step:3415[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:0 step:3420[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:0 step:3425[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:0 step:3430[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:0 step:3435[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:3440[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:0 step:3445[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:0 step:3450[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:0 step:3455[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:3460[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:0 step:3465[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:0 step:3470[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:0 step:3475[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:0 step:3480[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:0 step:3485[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:0 step:3490[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:0 step:3495[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:0 step:3500[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:0 step:3505[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:0 step:3510[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:0 step:3515[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:0 step:3520[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:0 step:3525[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:0 step:3530[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:0 step:3535[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:0 step:3540[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:0 step:3545[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:0 step:3550[D loss: 0.999966] [G loss: 1.000065]\n",
      "epoch:0 step:3555[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:0 step:3560[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:0 step:3565[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:0 step:3570[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:0 step:3575[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:0 step:3580[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:3585[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:3590[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:0 step:3595[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:0 step:3600[D loss: 0.999972] [G loss: 1.000060]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 3.423022\n",
      "FID: 115.273384\n",
      "0 = 14.599095270299904\n",
      "1 = 0.1395113612371609\n",
      "2 = 0.9854000210762024\n",
      "3 = 0.9830999970436096\n",
      "4 = 0.9876999855041504\n",
      "5 = 0.9876431822776794\n",
      "6 = 0.9830999970436096\n",
      "7 = 13.1223567695498\n",
      "8 = 0.2146738941484442\n",
      "9 = 0.9677000045776367\n",
      "10 = 0.9645000100135803\n",
      "11 = 0.9708999991416931\n",
      "12 = 0.9707125425338745\n",
      "13 = 0.9645000100135803\n",
      "14 = 3.423032283782959\n",
      "15 = 7.591618061065674\n",
      "16 = 0.4800073802471161\n",
      "17 = 3.4230220317840576\n",
      "18 = 115.27338409423828\n",
      "epoch:0 step:3605[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:0 step:3610[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:3615[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:0 step:3620[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:0 step:3625[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:0 step:3630[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:0 step:3635[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:0 step:3640[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:0 step:3645[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:0 step:3650[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:0 step:3655[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:0 step:3660[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:0 step:3665[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:0 step:3670[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:0 step:3675[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:3680[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:0 step:3685[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:0 step:3690[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:0 step:3695[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:0 step:3700[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:0 step:3705[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:0 step:3710[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:0 step:3715[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:0 step:3720[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:0 step:3725[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:0 step:3730[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:0 step:3735[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:0 step:3740[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:0 step:3745[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:0 step:3750[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:0 step:3755[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:0 step:3760[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:0 step:3765[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:0 step:3770[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:0 step:3775[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:0 step:3780[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:0 step:3785[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:0 step:3790[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:0 step:3795[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:0 step:3800[D loss: 0.999966] [G loss: 1.000066]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.074319\n",
      "FID: 91.264320\n",
      "0 = 14.65786753282544\n",
      "1 = 0.05923618351925828\n",
      "2 = 0.9750499725341797\n",
      "3 = 0.9865000247955322\n",
      "4 = 0.9635999798774719\n",
      "5 = 0.9644148945808411\n",
      "6 = 0.9865000247955322\n",
      "7 = 12.287333703672854\n",
      "8 = 0.19578312439869888\n",
      "9 = 0.9538000226020813\n",
      "10 = 0.9538000226020813\n",
      "11 = 0.9538000226020813\n",
      "12 = 0.9538000226020813\n",
      "13 = 0.9538000226020813\n",
      "14 = 4.074337482452393\n",
      "15 = 8.409224510192871\n",
      "16 = 0.37822476029396057\n",
      "17 = 4.074318885803223\n",
      "18 = 91.26432037353516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:3805[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:0 step:3810[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:0 step:3815[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:0 step:3820[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:0 step:3825[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:0 step:3830[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:0 step:3835[D loss: 0.999966] [G loss: 1.000064]\n",
      "epoch:0 step:3840[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:3845[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:0 step:3850[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:3855[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:0 step:3860[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:0 step:3865[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:0 step:3870[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:0 step:3875[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:0 step:3880[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:0 step:3885[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:0 step:3890[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:0 step:3895[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:0 step:3900[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:0 step:3905[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:3910[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:0 step:3915[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:0 step:3920[D loss: 0.999967] [G loss: 1.000059]\n",
      "epoch:0 step:3925[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:3930[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:0 step:3935[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:0 step:3940[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:3945[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:3950[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:0 step:3955[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:0 step:3960[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:0 step:3965[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:0 step:3970[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:0 step:3975[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:0 step:3980[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:0 step:3985[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:0 step:3990[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:0 step:3995[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:0 step:4000[D loss: 0.999967] [G loss: 1.000060]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 3.984662\n",
      "FID: 92.026268\n",
      "0 = 14.839704105138768\n",
      "1 = 0.06555255342423369\n",
      "2 = 0.9755499958992004\n",
      "3 = 0.989300012588501\n",
      "4 = 0.9617999792098999\n",
      "5 = 0.9628223776817322\n",
      "6 = 0.989300012588501\n",
      "7 = 12.384198192882558\n",
      "8 = 0.19663644294398877\n",
      "9 = 0.9551500082015991\n",
      "10 = 0.9549999833106995\n",
      "11 = 0.955299973487854\n",
      "12 = 0.9552865624427795\n",
      "13 = 0.9549999833106995\n",
      "14 = 3.9846749305725098\n",
      "15 = 8.360342025756836\n",
      "16 = 0.39034557342529297\n",
      "17 = 3.984661817550659\n",
      "18 = 92.0262680053711\n",
      "epoch:0 step:4005[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:0 step:4010[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:0 step:4015[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:0 step:4020[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:0 step:4025[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:0 step:4030[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:0 step:4035[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:0 step:4040[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:0 step:4045[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:0 step:4050[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:0 step:4055[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:4060[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:0 step:4065[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:0 step:4070[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:0 step:4075[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:0 step:4080[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:0 step:4085[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:0 step:4090[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:0 step:4095[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:0 step:4100[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:0 step:4105[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:0 step:4110[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:0 step:4115[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:0 step:4120[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:0 step:4125[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:0 step:4130[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:0 step:4135[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:0 step:4140[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:0 step:4145[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:0 step:4150[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:0 step:4155[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:0 step:4160[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:0 step:4165[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:4170[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:0 step:4175[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:0 step:4180[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:4185[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:0 step:4190[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:0 step:4195[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:0 step:4200[D loss: 0.999974] [G loss: 1.000068]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 3.900789\n",
      "FID: 95.824883\n",
      "0 = 14.677687066698073\n",
      "1 = 0.0720450669812345\n",
      "2 = 0.9746500253677368\n",
      "3 = 0.9868999719619751\n",
      "4 = 0.9624000191688538\n",
      "5 = 0.9632991552352905\n",
      "6 = 0.9868999719619751\n",
      "7 = 12.535024511849885\n",
      "8 = 0.20107081569257834\n",
      "9 = 0.9571999907493591\n",
      "10 = 0.9555000066757202\n",
      "11 = 0.958899974822998\n",
      "12 = 0.9587597846984863\n",
      "13 = 0.9555000066757202\n",
      "14 = 3.900801658630371\n",
      "15 = 8.251948356628418\n",
      "16 = 0.3997698724269867\n",
      "17 = 3.9007885456085205\n",
      "18 = 95.82488250732422\n",
      "epoch:0 step:4205[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:0 step:4210[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:0 step:4215[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:0 step:4220[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:0 step:4225[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:0 step:4230[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:0 step:4235[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:0 step:4240[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:0 step:4245[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:0 step:4250[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:4255[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:4260[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:0 step:4265[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:0 step:4270[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:0 step:4275[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:0 step:4280[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:0 step:4285[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:0 step:4290[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:0 step:4295[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:0 step:4300[D loss: 0.999966] [G loss: 1.000068]\n",
      "epoch:0 step:4305[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:0 step:4310[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:0 step:4315[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:0 step:4320[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:0 step:4325[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:0 step:4330[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:0 step:4335[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:4340[D loss: 0.999966] [G loss: 1.000066]\n",
      "epoch:0 step:4345[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:0 step:4350[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:0 step:4355[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:0 step:4360[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:0 step:4365[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:0 step:4370[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:0 step:4375[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:0 step:4380[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:0 step:4385[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:0 step:4390[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:0 step:4395[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:0 step:4400[D loss: 0.999973] [G loss: 1.000061]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.031829\n",
      "FID: 90.426216\n",
      "0 = 14.59679515986449\n",
      "1 = 0.06711958180302954\n",
      "2 = 0.9737499952316284\n",
      "3 = 0.9866999983787537\n",
      "4 = 0.9607999920845032\n",
      "5 = 0.9617896676063538\n",
      "6 = 0.9866999983787537\n",
      "7 = 12.325018000817296\n",
      "8 = 0.1939318879889408\n",
      "9 = 0.953499972820282\n",
      "10 = 0.9531000256538391\n",
      "11 = 0.9538999795913696\n",
      "12 = 0.9538630843162537\n",
      "13 = 0.9531000256538391\n",
      "14 = 4.031843185424805\n",
      "15 = 8.424792289733887\n",
      "16 = 0.3779675364494324\n",
      "17 = 4.031829357147217\n",
      "18 = 90.42621612548828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:4405[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:0 step:4410[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:4415[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:0 step:4420[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:0 step:4425[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:0 step:4430[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:0 step:4435[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:0 step:4440[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:0 step:4445[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:0 step:4450[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:0 step:4455[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:4460[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:0 step:4465[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:0 step:4470[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:4475[D loss: 0.999966] [G loss: 1.000062]\n",
      "epoch:0 step:4480[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:0 step:4485[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:0 step:4490[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:0 step:4495[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:0 step:4500[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:0 step:4505[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:0 step:4510[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:0 step:4515[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:0 step:4520[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:0 step:4525[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:0 step:4530[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:0 step:4535[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:0 step:4540[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:0 step:4545[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:0 step:4550[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:0 step:4555[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:0 step:4560[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:0 step:4565[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:0 step:4570[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:0 step:4575[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:0 step:4580[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:0 step:4585[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:0 step:4590[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:0 step:4595[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:0 step:4600[D loss: 0.999974] [G loss: 1.000067]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 3.930760\n",
      "FID: 93.450424\n",
      "0 = 14.66811919832234\n",
      "1 = 0.08211549338675614\n",
      "2 = 0.972599983215332\n",
      "3 = 0.9865999817848206\n",
      "4 = 0.9585999846458435\n",
      "5 = 0.9597276449203491\n",
      "6 = 0.9865999817848206\n",
      "7 = 12.4328752530575\n",
      "8 = 0.1976700970168191\n",
      "9 = 0.9562000036239624\n",
      "10 = 0.9559000134468079\n",
      "11 = 0.9564999938011169\n",
      "12 = 0.9564738869667053\n",
      "13 = 0.9559000134468079\n",
      "14 = 3.9307751655578613\n",
      "15 = 8.135346412658691\n",
      "16 = 0.40465185046195984\n",
      "17 = 3.930760145187378\n",
      "18 = 93.45042419433594\n",
      "epoch:0 step:4605[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:0 step:4610[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:0 step:4615[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:0 step:4620[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:0 step:4625[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:0 step:4630[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:0 step:4635[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:0 step:4640[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:0 step:4645[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:0 step:4650[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:0 step:4655[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:0 step:4660[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:0 step:4665[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:0 step:4670[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:0 step:4675[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:0 step:4680[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:0 step:4685[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:1 step:4690[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:1 step:4695[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:1 step:4700[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:1 step:4705[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:1 step:4710[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:1 step:4715[D loss: 0.999966] [G loss: 1.000058]\n",
      "epoch:1 step:4720[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:1 step:4725[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:1 step:4730[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:1 step:4735[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:1 step:4740[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:1 step:4745[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:1 step:4750[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:1 step:4755[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:1 step:4760[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:1 step:4765[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:1 step:4770[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:1 step:4775[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:1 step:4780[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:1 step:4785[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:1 step:4790[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:1 step:4795[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:1 step:4800[D loss: 0.999975] [G loss: 1.000072]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.373618\n",
      "FID: 77.631462\n",
      "0 = 16.16556883163453\n",
      "1 = 0.17806439623587908\n",
      "2 = 0.9677500128746033\n",
      "3 = 0.9954000115394592\n",
      "4 = 0.9401000142097473\n",
      "5 = 0.9432389140129089\n",
      "6 = 0.9954000115394592\n",
      "7 = 11.706501013922722\n",
      "8 = 0.1775226379787493\n",
      "9 = 0.9449499845504761\n",
      "10 = 0.9451000094413757\n",
      "11 = 0.9448000192642212\n",
      "12 = 0.944816529750824\n",
      "13 = 0.9451000094413757\n",
      "14 = 4.373636722564697\n",
      "15 = 8.597787857055664\n",
      "16 = 0.34055209159851074\n",
      "17 = 4.373618125915527\n",
      "18 = 77.63146209716797\n",
      "epoch:1 step:4805[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:1 step:4810[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:1 step:4815[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:1 step:4820[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:1 step:4825[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:1 step:4830[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:1 step:4835[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:1 step:4840[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:1 step:4845[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:1 step:4850[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:1 step:4855[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:1 step:4860[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:1 step:4865[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:1 step:4870[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:1 step:4875[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:1 step:4880[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:1 step:4885[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:1 step:4890[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:1 step:4895[D loss: 0.999964] [G loss: 1.000054]\n",
      "epoch:1 step:4900[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:1 step:4905[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:1 step:4910[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:1 step:4915[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:1 step:4920[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:1 step:4925[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:1 step:4930[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:1 step:4935[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:1 step:4940[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:1 step:4945[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:1 step:4950[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:1 step:4955[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:1 step:4960[D loss: 0.999978] [G loss: 1.000049]\n",
      "epoch:1 step:4965[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:1 step:4970[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:1 step:4975[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:1 step:4980[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:1 step:4985[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:1 step:4990[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:1 step:4995[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:1 step:5000[D loss: 0.999972] [G loss: 1.000063]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.207862\n",
      "FID: 82.814278\n",
      "0 = 14.709851299715039\n",
      "1 = 0.06048088168889176\n",
      "2 = 0.9692500233650208\n",
      "3 = 0.9889000058174133\n",
      "4 = 0.9495999813079834\n",
      "5 = 0.9515058398246765\n",
      "6 = 0.9889000058174133\n",
      "7 = 12.025983759641667\n",
      "8 = 0.18669208671419155\n",
      "9 = 0.9474999904632568\n",
      "10 = 0.9466000199317932\n",
      "11 = 0.9484000205993652\n",
      "12 = 0.9483069777488708\n",
      "13 = 0.9466000199317932\n",
      "14 = 4.207877159118652\n",
      "15 = 8.584832191467285\n",
      "16 = 0.35607603192329407\n",
      "17 = 4.20786190032959\n",
      "18 = 82.81427764892578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:5005[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:1 step:5010[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:1 step:5015[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:1 step:5020[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:1 step:5025[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:1 step:5030[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:1 step:5035[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:1 step:5040[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:1 step:5045[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:1 step:5050[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:1 step:5055[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:1 step:5060[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:1 step:5065[D loss: 0.999985] [G loss: 1.000047]\n",
      "epoch:1 step:5070[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:1 step:5075[D loss: 0.999966] [G loss: 1.000056]\n",
      "epoch:1 step:5080[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:1 step:5085[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:1 step:5090[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:1 step:5095[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:1 step:5100[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:1 step:5105[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:1 step:5110[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:1 step:5115[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:1 step:5120[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:1 step:5125[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:1 step:5130[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:1 step:5135[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:1 step:5140[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:1 step:5145[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:1 step:5150[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:1 step:5155[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:1 step:5160[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:1 step:5165[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:1 step:5170[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:1 step:5175[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:1 step:5180[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:1 step:5185[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:1 step:5190[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:1 step:5195[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:1 step:5200[D loss: 0.999974] [G loss: 1.000066]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.145778\n",
      "FID: 84.575157\n",
      "0 = 14.689628755998614\n",
      "1 = 0.06443832689970165\n",
      "2 = 0.9698500037193298\n",
      "3 = 0.9878000020980835\n",
      "4 = 0.9519000053405762\n",
      "5 = 0.9535669684410095\n",
      "6 = 0.9878000020980835\n",
      "7 = 12.070664602577795\n",
      "8 = 0.18764998477129693\n",
      "9 = 0.9491000175476074\n",
      "10 = 0.9478999972343445\n",
      "11 = 0.9502999782562256\n",
      "12 = 0.9501804113388062\n",
      "13 = 0.9478999972343445\n",
      "14 = 4.145792484283447\n",
      "15 = 8.492095947265625\n",
      "16 = 0.3625148832798004\n",
      "17 = 4.145777702331543\n",
      "18 = 84.57515716552734\n",
      "epoch:1 step:5205[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:1 step:5210[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:1 step:5215[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:1 step:5220[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:1 step:5225[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:1 step:5230[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:1 step:5235[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:1 step:5240[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:1 step:5245[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:1 step:5250[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:1 step:5255[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:1 step:5260[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:1 step:5265[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:1 step:5270[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:1 step:5275[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:1 step:5280[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:1 step:5285[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:1 step:5290[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:1 step:5295[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:1 step:5300[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:1 step:5305[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:1 step:5310[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:1 step:5315[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:1 step:5320[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:1 step:5325[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:1 step:5330[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:1 step:5335[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:1 step:5340[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:1 step:5345[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:1 step:5350[D loss: 0.999966] [G loss: 1.000069]\n",
      "epoch:1 step:5355[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:1 step:5360[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:1 step:5365[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:1 step:5370[D loss: 0.999965] [G loss: 1.000070]\n",
      "epoch:1 step:5375[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:1 step:5380[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:1 step:5385[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:1 step:5390[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:1 step:5395[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:1 step:5400[D loss: 0.999971] [G loss: 1.000059]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.251612\n",
      "FID: 81.393463\n",
      "0 = 14.728369078874488\n",
      "1 = 0.0630289582198515\n",
      "2 = 0.9681000113487244\n",
      "3 = 0.9889000058174133\n",
      "4 = 0.9473000168800354\n",
      "5 = 0.949404776096344\n",
      "6 = 0.9889000058174133\n",
      "7 = 11.942950150239565\n",
      "8 = 0.18344499770898154\n",
      "9 = 0.9473000168800354\n",
      "10 = 0.9480999708175659\n",
      "11 = 0.9465000033378601\n",
      "12 = 0.946585476398468\n",
      "13 = 0.9480999708175659\n",
      "14 = 4.251626968383789\n",
      "15 = 8.670869827270508\n",
      "16 = 0.3421168327331543\n",
      "17 = 4.251612186431885\n",
      "18 = 81.39346313476562\n",
      "epoch:1 step:5405[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:1 step:5410[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:1 step:5415[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:1 step:5420[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:1 step:5425[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:1 step:5430[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:1 step:5435[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:1 step:5440[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:1 step:5445[D loss: 0.999983] [G loss: 1.000054]\n",
      "epoch:1 step:5450[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:1 step:5455[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:1 step:5460[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:1 step:5465[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:1 step:5470[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:1 step:5475[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:1 step:5480[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:1 step:5485[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:1 step:5490[D loss: 0.999983] [G loss: 1.000055]\n",
      "epoch:1 step:5495[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:1 step:5500[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:1 step:5505[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:1 step:5510[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:1 step:5515[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:1 step:5520[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:1 step:5525[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:1 step:5530[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:1 step:5535[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:1 step:5540[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:1 step:5545[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:1 step:5550[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:1 step:5555[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:1 step:5560[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:1 step:5565[D loss: 0.999964] [G loss: 1.000063]\n",
      "epoch:1 step:5570[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:1 step:5575[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:1 step:5580[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:1 step:5585[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:1 step:5590[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:1 step:5595[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:1 step:5600[D loss: 0.999974] [G loss: 1.000064]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.230264\n",
      "FID: 82.091675\n",
      "0 = 14.638600814819306\n",
      "1 = 0.061057613056207674\n",
      "2 = 0.9670500159263611\n",
      "3 = 0.9886999726295471\n",
      "4 = 0.9453999996185303\n",
      "5 = 0.9476660490036011\n",
      "6 = 0.9886999726295471\n",
      "7 = 11.975247621071379\n",
      "8 = 0.18406713612648684\n",
      "9 = 0.946399986743927\n",
      "10 = 0.9480000138282776\n",
      "11 = 0.9448000192642212\n",
      "12 = 0.9449760913848877\n",
      "13 = 0.9480000138282776\n",
      "14 = 4.2302775382995605\n",
      "15 = 8.62955379486084\n",
      "16 = 0.34688320755958557\n",
      "17 = 4.230263710021973\n",
      "18 = 82.0916748046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:5605[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:1 step:5610[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:1 step:5615[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:1 step:5620[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:1 step:5625[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:1 step:5630[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:1 step:5635[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:1 step:5640[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:1 step:5645[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:1 step:5650[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:1 step:5655[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:1 step:5660[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:1 step:5665[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:1 step:5670[D loss: 0.999966] [G loss: 1.000060]\n",
      "epoch:1 step:5675[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:1 step:5680[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:1 step:5685[D loss: 0.999983] [G loss: 1.000038]\n",
      "epoch:1 step:5690[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:1 step:5695[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:1 step:5700[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:1 step:5705[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:1 step:5710[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:1 step:5715[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:1 step:5720[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:1 step:5725[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:1 step:5730[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:1 step:5735[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:1 step:5740[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:1 step:5745[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:1 step:5750[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:1 step:5755[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:1 step:5760[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:1 step:5765[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:1 step:5770[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:1 step:5775[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:1 step:5780[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:1 step:5785[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:1 step:5790[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:1 step:5795[D loss: 0.999988] [G loss: 1.000049]\n",
      "epoch:1 step:5800[D loss: 0.999986] [G loss: 1.000051]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.437826\n",
      "FID: 76.857773\n",
      "0 = 15.32385644707683\n",
      "1 = 0.10072213738474073\n",
      "2 = 0.9590499997138977\n",
      "3 = 0.9932000041007996\n",
      "4 = 0.9248999953269958\n",
      "5 = 0.9297013878822327\n",
      "6 = 0.9932000041007996\n",
      "7 = 11.730952538406848\n",
      "8 = 0.17653916466369793\n",
      "9 = 0.9430999755859375\n",
      "10 = 0.9420999884605408\n",
      "11 = 0.944100022315979\n",
      "12 = 0.9439879655838013\n",
      "13 = 0.9420999884605408\n",
      "14 = 4.437844276428223\n",
      "15 = 8.695219039916992\n",
      "16 = 0.3262042999267578\n",
      "17 = 4.437826156616211\n",
      "18 = 76.85777282714844\n",
      "epoch:1 step:5805[D loss: 0.999969] [G loss: 1.000051]\n",
      "epoch:1 step:5810[D loss: 0.999963] [G loss: 1.000063]\n",
      "epoch:1 step:5815[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:1 step:5820[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:1 step:5825[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:1 step:5830[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:1 step:5835[D loss: 0.999989] [G loss: 1.000052]\n",
      "epoch:1 step:5840[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:1 step:5845[D loss: 0.999992] [G loss: 1.000065]\n",
      "epoch:1 step:5850[D loss: 0.999972] [G loss: 1.000049]\n",
      "epoch:1 step:5855[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:1 step:5860[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:1 step:5865[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:1 step:5870[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:1 step:5875[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:1 step:5880[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:1 step:5885[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:1 step:5890[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:1 step:5895[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:1 step:5900[D loss: 0.999972] [G loss: 1.000053]\n",
      "epoch:1 step:5905[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:1 step:5910[D loss: 0.999974] [G loss: 1.000045]\n",
      "epoch:1 step:5915[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:1 step:5920[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:1 step:5925[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:1 step:5930[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:1 step:5935[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:1 step:5940[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:1 step:5945[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:1 step:5950[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:1 step:5955[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:1 step:5960[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:1 step:5965[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:1 step:5970[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:1 step:5975[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:1 step:5980[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:1 step:5985[D loss: 0.999970] [G loss: 1.000051]\n",
      "epoch:1 step:5990[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:1 step:5995[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:1 step:6000[D loss: 0.999966] [G loss: 1.000068]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.089357\n",
      "FID: 86.954536\n",
      "0 = 14.471016281986177\n",
      "1 = 0.06652910424566798\n",
      "2 = 0.9697999954223633\n",
      "3 = 0.9855999946594238\n",
      "4 = 0.9539999961853027\n",
      "5 = 0.955409049987793\n",
      "6 = 0.9855999946594238\n",
      "7 = 12.181311696517499\n",
      "8 = 0.1905914402171446\n",
      "9 = 0.9494500160217285\n",
      "10 = 0.9488999843597412\n",
      "11 = 0.949999988079071\n",
      "12 = 0.9499449133872986\n",
      "13 = 0.9488999843597412\n",
      "14 = 4.089374542236328\n",
      "15 = 8.427717208862305\n",
      "16 = 0.37352654337882996\n",
      "17 = 4.089357376098633\n",
      "18 = 86.95453643798828\n",
      "epoch:1 step:6005[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:1 step:6010[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:1 step:6015[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:1 step:6020[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:1 step:6025[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:1 step:6030[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:1 step:6035[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:1 step:6040[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:1 step:6045[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:1 step:6050[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:1 step:6055[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:1 step:6060[D loss: 0.999969] [G loss: 1.000054]\n",
      "epoch:1 step:6065[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:1 step:6070[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:1 step:6075[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:1 step:6080[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:1 step:6085[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:1 step:6090[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:1 step:6095[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:1 step:6100[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:1 step:6105[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:1 step:6110[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:1 step:6115[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:1 step:6120[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:1 step:6125[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:1 step:6130[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:1 step:6135[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:1 step:6140[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:1 step:6145[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:1 step:6150[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:1 step:6155[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:1 step:6160[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:1 step:6165[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:1 step:6170[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:1 step:6175[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:1 step:6180[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:1 step:6185[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:1 step:6190[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:1 step:6195[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:1 step:6200[D loss: 0.999972] [G loss: 1.000062]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.473014\n",
      "FID: 72.237793\n",
      "0 = 15.807458969306944\n",
      "1 = 0.13809600318577736\n",
      "2 = 0.9548500180244446\n",
      "3 = 0.9948999881744385\n",
      "4 = 0.9147999882698059\n",
      "5 = 0.921118438243866\n",
      "6 = 0.9948999881744385\n",
      "7 = 11.56117832201724\n",
      "8 = 0.17267284745061715\n",
      "9 = 0.9405500292778015\n",
      "10 = 0.9422000050544739\n",
      "11 = 0.9388999938964844\n",
      "12 = 0.939100980758667\n",
      "13 = 0.9422000050544739\n",
      "14 = 4.473034858703613\n",
      "15 = 8.57223129272461\n",
      "16 = 0.3326660990715027\n",
      "17 = 4.473013877868652\n",
      "18 = 72.23779296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:6205[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:1 step:6210[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:1 step:6215[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:1 step:6220[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:1 step:6225[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:1 step:6230[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:1 step:6235[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:1 step:6240[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:1 step:6245[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:1 step:6250[D loss: 0.999989] [G loss: 1.000037]\n",
      "epoch:1 step:6255[D loss: 0.999988] [G loss: 1.000039]\n",
      "epoch:1 step:6260[D loss: 0.999986] [G loss: 1.000038]\n",
      "epoch:1 step:6265[D loss: 0.999963] [G loss: 1.000070]\n",
      "epoch:1 step:6270[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:1 step:6275[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:1 step:6280[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:1 step:6285[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:1 step:6290[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:1 step:6295[D loss: 0.999977] [G loss: 1.000045]\n",
      "epoch:1 step:6300[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:1 step:6305[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:1 step:6310[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:1 step:6315[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:1 step:6320[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:1 step:6325[D loss: 0.999981] [G loss: 1.000043]\n",
      "epoch:1 step:6330[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:1 step:6335[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:1 step:6340[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:1 step:6345[D loss: 0.999960] [G loss: 1.000076]\n",
      "epoch:1 step:6350[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:1 step:6355[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:1 step:6360[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:1 step:6365[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:1 step:6370[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:1 step:6375[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:1 step:6380[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:1 step:6385[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:1 step:6390[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:1 step:6395[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:1 step:6400[D loss: 0.999982] [G loss: 1.000056]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.460033\n",
      "FID: 72.976227\n",
      "0 = 15.987215782594644\n",
      "1 = 0.14999655083823327\n",
      "2 = 0.9468500018119812\n",
      "3 = 0.994700014591217\n",
      "4 = 0.8989999890327454\n",
      "5 = 0.9078214764595032\n",
      "6 = 0.994700014591217\n",
      "7 = 11.58222465035915\n",
      "8 = 0.17565370806985944\n",
      "9 = 0.941349983215332\n",
      "10 = 0.9430999755859375\n",
      "11 = 0.9395999908447266\n",
      "12 = 0.9398106336593628\n",
      "13 = 0.9430999755859375\n",
      "14 = 4.460056304931641\n",
      "15 = 8.518953323364258\n",
      "16 = 0.3421861231327057\n",
      "17 = 4.460032939910889\n",
      "18 = 72.97622680664062\n",
      "epoch:1 step:6405[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:1 step:6410[D loss: 0.999991] [G loss: 1.000035]\n",
      "epoch:1 step:6415[D loss: 1.000011] [G loss: 1.000017]\n",
      "epoch:1 step:6420[D loss: 1.000019] [G loss: 1.000009]\n",
      "epoch:1 step:6425[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:1 step:6430[D loss: 0.999953] [G loss: 1.000058]\n",
      "epoch:1 step:6435[D loss: 0.999969] [G loss: 1.000051]\n",
      "epoch:1 step:6440[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:1 step:6445[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:1 step:6450[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:1 step:6455[D loss: 0.999971] [G loss: 1.000052]\n",
      "epoch:1 step:6460[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:1 step:6465[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:1 step:6470[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:1 step:6475[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:1 step:6480[D loss: 0.999964] [G loss: 1.000065]\n",
      "epoch:1 step:6485[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:1 step:6490[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:1 step:6495[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:1 step:6500[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:1 step:6505[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:1 step:6510[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:1 step:6515[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:1 step:6520[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:1 step:6525[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:1 step:6530[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:1 step:6535[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:1 step:6540[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:1 step:6545[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:1 step:6550[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:1 step:6555[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:1 step:6560[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:1 step:6565[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:1 step:6570[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:1 step:6575[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:1 step:6580[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:1 step:6585[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:1 step:6590[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:1 step:6595[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:1 step:6600[D loss: 0.999970] [G loss: 1.000064]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.262944\n",
      "FID: 81.318710\n",
      "0 = 14.626630818557738\n",
      "1 = 0.05116013253869612\n",
      "2 = 0.9666000008583069\n",
      "3 = 0.9890999794006348\n",
      "4 = 0.944100022315979\n",
      "5 = 0.9465071558952332\n",
      "6 = 0.9890999794006348\n",
      "7 = 11.947451607167777\n",
      "8 = 0.18358303606953263\n",
      "9 = 0.948199987411499\n",
      "10 = 0.9477999806404114\n",
      "11 = 0.9485999941825867\n",
      "12 = 0.9485588669776917\n",
      "13 = 0.9477999806404114\n",
      "14 = 4.262956619262695\n",
      "15 = 8.479384422302246\n",
      "16 = 0.3549967408180237\n",
      "17 = 4.262943744659424\n",
      "18 = 81.31871032714844\n",
      "epoch:1 step:6605[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:1 step:6610[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:1 step:6615[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:1 step:6620[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:1 step:6625[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:1 step:6630[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:1 step:6635[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:1 step:6640[D loss: 0.999965] [G loss: 1.000062]\n",
      "epoch:1 step:6645[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:1 step:6650[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:1 step:6655[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:1 step:6660[D loss: 0.999979] [G loss: 1.000046]\n",
      "epoch:1 step:6665[D loss: 0.999988] [G loss: 1.000048]\n",
      "epoch:1 step:6670[D loss: 0.999989] [G loss: 1.000046]\n",
      "epoch:1 step:6675[D loss: 0.999979] [G loss: 1.000044]\n",
      "epoch:1 step:6680[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:1 step:6685[D loss: 0.999963] [G loss: 1.000063]\n",
      "epoch:1 step:6690[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:1 step:6695[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:1 step:6700[D loss: 0.999967] [G loss: 1.000062]\n",
      "epoch:1 step:6705[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:1 step:6710[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:1 step:6715[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:1 step:6720[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:1 step:6725[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:1 step:6730[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:1 step:6735[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:1 step:6740[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:1 step:6745[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:1 step:6750[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:1 step:6755[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:1 step:6760[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:1 step:6765[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:1 step:6770[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:1 step:6775[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:1 step:6780[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:1 step:6785[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:1 step:6790[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:1 step:6795[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:1 step:6800[D loss: 0.999975] [G loss: 1.000066]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.016295\n",
      "FID: 87.146950\n",
      "0 = 14.44434902448657\n",
      "1 = 0.08846182121435797\n",
      "2 = 0.9711499810218811\n",
      "3 = 0.9850000143051147\n",
      "4 = 0.9573000073432922\n",
      "5 = 0.9584509134292603\n",
      "6 = 0.9850000143051147\n",
      "7 = 12.224522495770527\n",
      "8 = 0.19166951661133405\n",
      "9 = 0.9531000256538391\n",
      "10 = 0.9503999948501587\n",
      "11 = 0.9557999968528748\n",
      "12 = 0.955560028553009\n",
      "13 = 0.9503999948501587\n",
      "14 = 4.016312599182129\n",
      "15 = 8.194263458251953\n",
      "16 = 0.3969223201274872\n",
      "17 = 4.016294956207275\n",
      "18 = 87.1469497680664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:6805[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:1 step:6810[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:1 step:6815[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:1 step:6820[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:1 step:6825[D loss: 0.999985] [G loss: 1.000050]\n",
      "epoch:1 step:6830[D loss: 0.999985] [G loss: 1.000039]\n",
      "epoch:1 step:6835[D loss: 0.999985] [G loss: 1.000066]\n",
      "epoch:1 step:6840[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:1 step:6845[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:1 step:6850[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:1 step:6855[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:1 step:6860[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:1 step:6865[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:1 step:6870[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:1 step:6875[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:1 step:6880[D loss: 0.999979] [G loss: 1.000043]\n",
      "epoch:1 step:6885[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:1 step:6890[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:1 step:6895[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:1 step:6900[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:1 step:6905[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:1 step:6910[D loss: 0.999964] [G loss: 1.000067]\n",
      "epoch:1 step:6915[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:1 step:6920[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:1 step:6925[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:1 step:6930[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:1 step:6935[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:1 step:6940[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:1 step:6945[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:1 step:6950[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:1 step:6955[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:1 step:6960[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:1 step:6965[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:1 step:6970[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:1 step:6975[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:1 step:6980[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:1 step:6985[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:1 step:6990[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:1 step:6995[D loss: 0.999980] [G loss: 1.000054]\n",
      "epoch:1 step:7000[D loss: 0.999981] [G loss: 1.000053]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.220850\n",
      "FID: 80.800255\n",
      "0 = 14.744547982215868\n",
      "1 = 0.06988650658163605\n",
      "2 = 0.9649500250816345\n",
      "3 = 0.988099992275238\n",
      "4 = 0.9417999982833862\n",
      "5 = 0.9443753957748413\n",
      "6 = 0.988099992275238\n",
      "7 = 11.893175136733067\n",
      "8 = 0.18953333464354252\n",
      "9 = 0.9458000063896179\n",
      "10 = 0.9445000290870667\n",
      "11 = 0.9470999836921692\n",
      "12 = 0.9469621181488037\n",
      "13 = 0.9445000290870667\n",
      "14 = 4.220869541168213\n",
      "15 = 7.9894938468933105\n",
      "16 = 0.39476531744003296\n",
      "17 = 4.220849514007568\n",
      "18 = 80.80025482177734\n",
      "epoch:1 step:7005[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:1 step:7010[D loss: 0.999972] [G loss: 1.000053]\n",
      "epoch:1 step:7015[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:1 step:7020[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:1 step:7025[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:1 step:7030[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:1 step:7035[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:1 step:7040[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:1 step:7045[D loss: 0.999967] [G loss: 1.000059]\n",
      "epoch:1 step:7050[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:1 step:7055[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:1 step:7060[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:1 step:7065[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:1 step:7070[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:1 step:7075[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:1 step:7080[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:1 step:7085[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:1 step:7090[D loss: 0.999970] [G loss: 1.000052]\n",
      "epoch:1 step:7095[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:1 step:7100[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:1 step:7105[D loss: 0.999981] [G loss: 1.000055]\n",
      "epoch:1 step:7110[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:1 step:7115[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:1 step:7120[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:1 step:7125[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:1 step:7130[D loss: 0.999964] [G loss: 1.000060]\n",
      "epoch:1 step:7135[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:1 step:7140[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:1 step:7145[D loss: 0.999967] [G loss: 1.000058]\n",
      "epoch:1 step:7150[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:1 step:7155[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:1 step:7160[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:1 step:7165[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:1 step:7170[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:1 step:7175[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:1 step:7180[D loss: 0.999985] [G loss: 1.000060]\n",
      "epoch:1 step:7185[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:1 step:7190[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:1 step:7195[D loss: 0.999962] [G loss: 1.000050]\n",
      "epoch:1 step:7200[D loss: 0.999981] [G loss: 1.000061]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.428847\n",
      "FID: 73.802528\n",
      "0 = 14.819650122737917\n",
      "1 = 0.06447993790057957\n",
      "2 = 0.956849992275238\n",
      "3 = 0.9905999898910522\n",
      "4 = 0.9230999946594238\n",
      "5 = 0.9279625415802002\n",
      "6 = 0.9905999898910522\n",
      "7 = 11.669868590307285\n",
      "8 = 0.17641825227140492\n",
      "9 = 0.9402499794960022\n",
      "10 = 0.942300021648407\n",
      "11 = 0.9381999969482422\n",
      "12 = 0.9384523630142212\n",
      "13 = 0.942300021648407\n",
      "14 = 4.428866386413574\n",
      "15 = 8.506515502929688\n",
      "16 = 0.34833285212516785\n",
      "17 = 4.428847312927246\n",
      "18 = 73.80252838134766\n",
      "epoch:1 step:7205[D loss: 0.999984] [G loss: 1.000051]\n",
      "epoch:1 step:7210[D loss: 0.999971] [G loss: 1.000047]\n",
      "epoch:1 step:7215[D loss: 0.999988] [G loss: 1.000055]\n",
      "epoch:1 step:7220[D loss: 0.999988] [G loss: 1.000038]\n",
      "epoch:1 step:7225[D loss: 1.000005] [G loss: 1.000051]\n",
      "epoch:1 step:7230[D loss: 0.999960] [G loss: 1.000060]\n",
      "epoch:1 step:7235[D loss: 0.999964] [G loss: 1.000068]\n",
      "epoch:1 step:7240[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:1 step:7245[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:1 step:7250[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:1 step:7255[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:1 step:7260[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:1 step:7265[D loss: 0.999982] [G loss: 1.000040]\n",
      "epoch:1 step:7270[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:1 step:7275[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:1 step:7280[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:1 step:7285[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:1 step:7290[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:1 step:7295[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:1 step:7300[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:1 step:7305[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:1 step:7310[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:1 step:7315[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:1 step:7320[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:1 step:7325[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:1 step:7330[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:1 step:7335[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:1 step:7340[D loss: 0.999964] [G loss: 1.000064]\n",
      "epoch:1 step:7345[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:1 step:7350[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:1 step:7355[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:1 step:7360[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:1 step:7365[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:1 step:7370[D loss: 0.999982] [G loss: 1.000051]\n",
      "epoch:1 step:7375[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:1 step:7380[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:1 step:7385[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:1 step:7390[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:1 step:7395[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:1 step:7400[D loss: 0.999971] [G loss: 1.000054]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.203947\n",
      "FID: 80.540092\n",
      "0 = 14.571638863801967\n",
      "1 = 0.054412148600135275\n",
      "2 = 0.9668999910354614\n",
      "3 = 0.9876999855041504\n",
      "4 = 0.9460999965667725\n",
      "5 = 0.9482526779174805\n",
      "6 = 0.9876999855041504\n",
      "7 = 11.962770177185565\n",
      "8 = 0.18684910011064598\n",
      "9 = 0.9465000033378601\n",
      "10 = 0.9449999928474426\n",
      "11 = 0.9480000138282776\n",
      "12 = 0.9478435516357422\n",
      "13 = 0.9449999928474426\n",
      "14 = 4.203963279724121\n",
      "15 = 8.170660018920898\n",
      "16 = 0.3873891830444336\n",
      "17 = 4.203947067260742\n",
      "18 = 80.54009246826172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:7405[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:1 step:7410[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:1 step:7415[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:1 step:7420[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:1 step:7425[D loss: 0.999974] [G loss: 1.000046]\n",
      "epoch:1 step:7430[D loss: 0.999987] [G loss: 1.000052]\n",
      "epoch:1 step:7435[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:1 step:7440[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:1 step:7445[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:1 step:7450[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:1 step:7455[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:1 step:7460[D loss: 0.999982] [G loss: 1.000058]\n",
      "epoch:1 step:7465[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:1 step:7470[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:1 step:7475[D loss: 0.999969] [G loss: 1.000055]\n",
      "epoch:1 step:7480[D loss: 0.999967] [G loss: 1.000057]\n",
      "epoch:1 step:7485[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:1 step:7490[D loss: 0.999982] [G loss: 1.000034]\n",
      "epoch:1 step:7495[D loss: 0.999982] [G loss: 1.000037]\n",
      "epoch:1 step:7500[D loss: 0.999985] [G loss: 1.000040]\n",
      "epoch:1 step:7505[D loss: 0.999976] [G loss: 1.000043]\n",
      "epoch:1 step:7510[D loss: 0.999971] [G loss: 1.000051]\n",
      "epoch:1 step:7515[D loss: 1.000013] [G loss: 1.000030]\n",
      "epoch:1 step:7520[D loss: 0.999982] [G loss: 1.000062]\n",
      "epoch:1 step:7525[D loss: 0.999972] [G loss: 1.000046]\n",
      "epoch:1 step:7530[D loss: 0.999959] [G loss: 1.000059]\n",
      "epoch:1 step:7535[D loss: 0.999973] [G loss: 1.000047]\n",
      "epoch:1 step:7540[D loss: 0.999969] [G loss: 1.000047]\n",
      "epoch:1 step:7545[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:1 step:7550[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:1 step:7555[D loss: 0.999977] [G loss: 1.000053]\n",
      "epoch:1 step:7560[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:1 step:7565[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:1 step:7570[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:1 step:7575[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:1 step:7580[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:1 step:7585[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:1 step:7590[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:1 step:7595[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:1 step:7600[D loss: 0.999967] [G loss: 1.000064]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.445543\n",
      "FID: 72.931473\n",
      "0 = 15.556478194713627\n",
      "1 = 0.13056297326264676\n",
      "2 = 0.9526000022888184\n",
      "3 = 0.992900013923645\n",
      "4 = 0.9122999906539917\n",
      "5 = 0.9188413619995117\n",
      "6 = 0.992900013923645\n",
      "7 = 11.560595179271687\n",
      "8 = 0.17321325703513496\n",
      "9 = 0.9357500076293945\n",
      "10 = 0.9387999773025513\n",
      "11 = 0.932699978351593\n",
      "12 = 0.9331080317497253\n",
      "13 = 0.9387999773025513\n",
      "14 = 4.44556188583374\n",
      "15 = 8.261029243469238\n",
      "16 = 0.36545127630233765\n",
      "17 = 4.44554328918457\n",
      "18 = 72.93147277832031\n",
      "epoch:1 step:7605[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:1 step:7610[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:1 step:7615[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:1 step:7620[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:1 step:7625[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:1 step:7630[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:1 step:7635[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:1 step:7640[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:1 step:7645[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:1 step:7650[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:1 step:7655[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:1 step:7660[D loss: 0.999980] [G loss: 1.000045]\n",
      "epoch:1 step:7665[D loss: 0.999981] [G loss: 1.000048]\n",
      "epoch:1 step:7670[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:1 step:7675[D loss: 0.999981] [G loss: 1.000056]\n",
      "epoch:1 step:7680[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:1 step:7685[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:1 step:7690[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:1 step:7695[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:1 step:7700[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:1 step:7705[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:1 step:7710[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:1 step:7715[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:1 step:7720[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:1 step:7725[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:1 step:7730[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:1 step:7735[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:1 step:7740[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:1 step:7745[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:1 step:7750[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:1 step:7755[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:1 step:7760[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:1 step:7765[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:1 step:7770[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:1 step:7775[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:1 step:7780[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:1 step:7785[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:1 step:7790[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:1 step:7795[D loss: 0.999973] [G loss: 1.000041]\n",
      "epoch:1 step:7800[D loss: 0.999973] [G loss: 1.000058]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 3.674273\n",
      "FID: 101.584549\n",
      "0 = 14.390778044605254\n",
      "1 = 0.14077750519610113\n",
      "2 = 0.9787999987602234\n",
      "3 = 0.9835000038146973\n",
      "4 = 0.9740999937057495\n",
      "5 = 0.9743412137031555\n",
      "6 = 0.9835000038146973\n",
      "7 = 12.734514586591711\n",
      "8 = 0.20823291901767615\n",
      "9 = 0.9567999839782715\n",
      "10 = 0.9549000263214111\n",
      "11 = 0.9587000012397766\n",
      "12 = 0.9585424661636353\n",
      "13 = 0.9549000263214111\n",
      "14 = 3.6742868423461914\n",
      "15 = 7.920523643493652\n",
      "16 = 0.4402349889278412\n",
      "17 = 3.6742734909057617\n",
      "18 = 101.58454895019531\n",
      "epoch:1 step:7805[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:1 step:7810[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:1 step:7815[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:1 step:7820[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:1 step:7825[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:1 step:7830[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:1 step:7835[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:1 step:7840[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:1 step:7845[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:1 step:7850[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:1 step:7855[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:1 step:7860[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:1 step:7865[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:1 step:7870[D loss: 0.999978] [G loss: 1.000048]\n",
      "epoch:1 step:7875[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:1 step:7880[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:1 step:7885[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:1 step:7890[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:1 step:7895[D loss: 0.999990] [G loss: 1.000031]\n",
      "epoch:1 step:7900[D loss: 0.999972] [G loss: 1.000051]\n",
      "epoch:1 step:7905[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:1 step:7910[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:1 step:7915[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:1 step:7920[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:1 step:7925[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:1 step:7930[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:1 step:7935[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:1 step:7940[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:1 step:7945[D loss: 0.999966] [G loss: 1.000068]\n",
      "epoch:1 step:7950[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:1 step:7955[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:1 step:7960[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:1 step:7965[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:1 step:7970[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:1 step:7975[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:1 step:7980[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:1 step:7985[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:1 step:7990[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:1 step:7995[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:1 step:8000[D loss: 0.999969] [G loss: 1.000055]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.236896\n",
      "FID: 80.799103\n",
      "0 = 14.469123516845674\n",
      "1 = 0.0808949562697832\n",
      "2 = 0.9654499888420105\n",
      "3 = 0.9857000112533569\n",
      "4 = 0.9452000260353088\n",
      "5 = 0.947333037853241\n",
      "6 = 0.9857000112533569\n",
      "7 = 11.94639371789691\n",
      "8 = 0.18417849656627158\n",
      "9 = 0.9437500238418579\n",
      "10 = 0.9430000185966492\n",
      "11 = 0.9445000290870667\n",
      "12 = 0.9444166421890259\n",
      "13 = 0.9430000185966492\n",
      "14 = 4.236916542053223\n",
      "15 = 8.45717716217041\n",
      "16 = 0.3622548580169678\n",
      "17 = 4.23689603805542\n",
      "18 = 80.79910278320312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:8005[D loss: 0.999980] [G loss: 1.000051]\n",
      "epoch:1 step:8010[D loss: 0.999986] [G loss: 1.000031]\n",
      "epoch:1 step:8015[D loss: 0.999998] [G loss: 1.000042]\n",
      "epoch:1 step:8020[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:1 step:8025[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:1 step:8030[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:1 step:8035[D loss: 0.999971] [G loss: 1.000048]\n",
      "epoch:1 step:8040[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:1 step:8045[D loss: 0.999971] [G loss: 1.000052]\n",
      "epoch:1 step:8050[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:1 step:8055[D loss: 0.999982] [G loss: 1.000046]\n",
      "epoch:1 step:8060[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:1 step:8065[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:1 step:8070[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:1 step:8075[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:1 step:8080[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:1 step:8085[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:1 step:8090[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:1 step:8095[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:1 step:8100[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:1 step:8105[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:1 step:8110[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:1 step:8115[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:1 step:8120[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:1 step:8125[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:1 step:8130[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:1 step:8135[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:1 step:8140[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:1 step:8145[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:1 step:8150[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:1 step:8155[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:1 step:8160[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:1 step:8165[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:1 step:8170[D loss: 0.999989] [G loss: 1.000050]\n",
      "epoch:1 step:8175[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:1 step:8180[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:1 step:8185[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:1 step:8190[D loss: 0.999989] [G loss: 1.000040]\n",
      "epoch:1 step:8195[D loss: 0.999983] [G loss: 1.000038]\n",
      "epoch:1 step:8200[D loss: 0.999959] [G loss: 1.000079]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.090618\n",
      "FID: 84.182152\n",
      "0 = 14.626612302541723\n",
      "1 = 0.06693906763344382\n",
      "2 = 0.9653000235557556\n",
      "3 = 0.9879999756813049\n",
      "4 = 0.9426000118255615\n",
      "5 = 0.9450927972793579\n",
      "6 = 0.9879999756813049\n",
      "7 = 12.058748601627311\n",
      "8 = 0.18970904810777994\n",
      "9 = 0.9458000063896179\n",
      "10 = 0.9456999897956848\n",
      "11 = 0.945900022983551\n",
      "12 = 0.9458891749382019\n",
      "13 = 0.9456999897956848\n",
      "14 = 4.090631008148193\n",
      "15 = 8.02865219116211\n",
      "16 = 0.40145060420036316\n",
      "17 = 4.090617656707764\n",
      "18 = 84.1821517944336\n",
      "epoch:1 step:8205[D loss: 0.999960] [G loss: 1.000070]\n",
      "epoch:1 step:8210[D loss: 0.999959] [G loss: 1.000074]\n",
      "epoch:1 step:8215[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:1 step:8220[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:1 step:8225[D loss: 0.999994] [G loss: 1.000052]\n",
      "epoch:1 step:8230[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:1 step:8235[D loss: 0.999966] [G loss: 1.000060]\n",
      "epoch:1 step:8240[D loss: 0.999966] [G loss: 1.000060]\n",
      "epoch:1 step:8245[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:1 step:8250[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:1 step:8255[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:1 step:8260[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:1 step:8265[D loss: 0.999968] [G loss: 1.000059]\n",
      "epoch:1 step:8270[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:1 step:8275[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:1 step:8280[D loss: 0.999978] [G loss: 1.000048]\n",
      "epoch:1 step:8285[D loss: 0.999977] [G loss: 1.000044]\n",
      "epoch:1 step:8290[D loss: 0.999985] [G loss: 1.000045]\n",
      "epoch:1 step:8295[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:1 step:8300[D loss: 0.999978] [G loss: 1.000046]\n",
      "epoch:1 step:8305[D loss: 0.999984] [G loss: 1.000036]\n",
      "epoch:1 step:8310[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:1 step:8315[D loss: 0.999973] [G loss: 1.000046]\n",
      "epoch:1 step:8320[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:1 step:8325[D loss: 0.999968] [G loss: 1.000057]\n",
      "epoch:1 step:8330[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:1 step:8335[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:1 step:8340[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:1 step:8345[D loss: 0.999977] [G loss: 1.000053]\n",
      "epoch:1 step:8350[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:1 step:8355[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:1 step:8360[D loss: 0.999966] [G loss: 1.000056]\n",
      "epoch:1 step:8365[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:1 step:8370[D loss: 0.999968] [G loss: 1.000052]\n",
      "epoch:1 step:8375[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:1 step:8380[D loss: 0.999981] [G loss: 1.000052]\n",
      "epoch:1 step:8385[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:1 step:8390[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:1 step:8395[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:1 step:8400[D loss: 0.999983] [G loss: 1.000060]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.119553\n",
      "FID: 83.342995\n",
      "0 = 14.61614582576753\n",
      "1 = 0.05579134125884096\n",
      "2 = 0.9629999995231628\n",
      "3 = 0.9886000156402588\n",
      "4 = 0.9373999834060669\n",
      "5 = 0.9404489994049072\n",
      "6 = 0.9886000156402588\n",
      "7 = 12.013295908749132\n",
      "8 = 0.19008256624037195\n",
      "9 = 0.9430000185966492\n",
      "10 = 0.9406999945640564\n",
      "11 = 0.9452999830245972\n",
      "12 = 0.9450471997261047\n",
      "13 = 0.9406999945640564\n",
      "14 = 4.119568824768066\n",
      "15 = 7.949578762054443\n",
      "16 = 0.4031934142112732\n",
      "17 = 4.119553089141846\n",
      "18 = 83.3429946899414\n",
      "epoch:1 step:8405[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:1 step:8410[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:1 step:8415[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:1 step:8420[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:1 step:8425[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:1 step:8430[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:1 step:8435[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:1 step:8440[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:1 step:8445[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:1 step:8450[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:1 step:8455[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:1 step:8460[D loss: 0.999981] [G loss: 1.000056]\n",
      "epoch:1 step:8465[D loss: 0.999982] [G loss: 1.000050]\n",
      "epoch:1 step:8470[D loss: 0.999983] [G loss: 1.000045]\n",
      "epoch:1 step:8475[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:1 step:8480[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:1 step:8485[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:1 step:8490[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:1 step:8495[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:1 step:8500[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:1 step:8505[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:1 step:8510[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:1 step:8515[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:1 step:8520[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:1 step:8525[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:1 step:8530[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:1 step:8535[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:1 step:8540[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:1 step:8545[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:1 step:8550[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:1 step:8555[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:1 step:8560[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:1 step:8565[D loss: 0.999987] [G loss: 1.000035]\n",
      "epoch:1 step:8570[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:1 step:8575[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:1 step:8580[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:1 step:8585[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:1 step:8590[D loss: 0.999982] [G loss: 1.000047]\n",
      "epoch:1 step:8595[D loss: 0.999977] [G loss: 1.000049]\n",
      "epoch:1 step:8600[D loss: 0.999973] [G loss: 1.000060]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.065670\n",
      "FID: 85.897736\n",
      "0 = 14.363080097007733\n",
      "1 = 0.06926368925116276\n",
      "2 = 0.9696499705314636\n",
      "3 = 0.9840999841690063\n",
      "4 = 0.9552000164985657\n",
      "5 = 0.956458330154419\n",
      "6 = 0.9840999841690063\n",
      "7 = 12.11480959788563\n",
      "8 = 0.1903651984153096\n",
      "9 = 0.9489499926567078\n",
      "10 = 0.9477999806404114\n",
      "11 = 0.9501000046730042\n",
      "12 = 0.9499849677085876\n",
      "13 = 0.9477999806404114\n",
      "14 = 4.065684795379639\n",
      "15 = 8.162347793579102\n",
      "16 = 0.39185631275177\n",
      "17 = 4.065669536590576\n",
      "18 = 85.89773559570312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:8605[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:1 step:8610[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:1 step:8615[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:1 step:8620[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:1 step:8625[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:1 step:8630[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:1 step:8635[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:1 step:8640[D loss: 0.999980] [G loss: 1.000052]\n",
      "epoch:1 step:8645[D loss: 0.999994] [G loss: 1.000028]\n",
      "epoch:1 step:8650[D loss: 0.999991] [G loss: 1.000033]\n",
      "epoch:1 step:8655[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:1 step:8660[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:1 step:8665[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:1 step:8670[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:1 step:8675[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:1 step:8680[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:1 step:8685[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:1 step:8690[D loss: 0.999989] [G loss: 1.000041]\n",
      "epoch:1 step:8695[D loss: 0.999991] [G loss: 1.000041]\n",
      "epoch:1 step:8700[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:1 step:8705[D loss: 0.999964] [G loss: 1.000062]\n",
      "epoch:1 step:8710[D loss: 0.999964] [G loss: 1.000064]\n",
      "epoch:1 step:8715[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:1 step:8720[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:1 step:8725[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:1 step:8730[D loss: 0.999985] [G loss: 1.000047]\n",
      "epoch:1 step:8735[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:1 step:8740[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:1 step:8745[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:1 step:8750[D loss: 0.999968] [G loss: 1.000047]\n",
      "epoch:1 step:8755[D loss: 0.999963] [G loss: 1.000064]\n",
      "epoch:1 step:8760[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:1 step:8765[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:1 step:8770[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:1 step:8775[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:1 step:8780[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:1 step:8785[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:1 step:8790[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:1 step:8795[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:1 step:8800[D loss: 0.999975] [G loss: 1.000056]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.273245\n",
      "FID: 79.011253\n",
      "0 = 14.670542990732232\n",
      "1 = 0.06383612107579772\n",
      "2 = 0.9535999894142151\n",
      "3 = 0.9883999824523926\n",
      "4 = 0.9187999963760376\n",
      "5 = 0.9240837693214417\n",
      "6 = 0.9883999824523926\n",
      "7 = 11.801600041937863\n",
      "8 = 0.18385491159376427\n",
      "9 = 0.9388499855995178\n",
      "10 = 0.9390000104904175\n",
      "11 = 0.9387000203132629\n",
      "12 = 0.9387183785438538\n",
      "13 = 0.9390000104904175\n",
      "14 = 4.273269176483154\n",
      "15 = 8.133646011352539\n",
      "16 = 0.38087722659111023\n",
      "17 = 4.273245334625244\n",
      "18 = 79.0112533569336\n",
      "epoch:1 step:8805[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:1 step:8810[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:1 step:8815[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:1 step:8820[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:1 step:8825[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:1 step:8830[D loss: 0.999972] [G loss: 1.000051]\n",
      "epoch:1 step:8835[D loss: 0.999972] [G loss: 1.000048]\n",
      "epoch:1 step:8840[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:1 step:8845[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:1 step:8850[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:1 step:8855[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:1 step:8860[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:1 step:8865[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:1 step:8870[D loss: 0.999992] [G loss: 1.000036]\n",
      "epoch:1 step:8875[D loss: 0.999965] [G loss: 1.000054]\n",
      "epoch:1 step:8880[D loss: 0.999986] [G loss: 1.000036]\n",
      "epoch:1 step:8885[D loss: 0.999982] [G loss: 1.000047]\n",
      "epoch:1 step:8890[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:1 step:8895[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:1 step:8900[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:1 step:8905[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:1 step:8910[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:1 step:8915[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:1 step:8920[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:1 step:8925[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:1 step:8930[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:1 step:8935[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:1 step:8940[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:1 step:8945[D loss: 0.999979] [G loss: 1.000060]\n",
      "epoch:1 step:8950[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:1 step:8955[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:1 step:8960[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:1 step:8965[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:1 step:8970[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:1 step:8975[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:1 step:8980[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:1 step:8985[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:1 step:8990[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:1 step:8995[D loss: 0.999965] [G loss: 1.000059]\n",
      "epoch:1 step:9000[D loss: 0.999976] [G loss: 1.000051]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.321126\n",
      "FID: 76.972000\n",
      "0 = 14.523034225368576\n",
      "1 = 0.05467659977864838\n",
      "2 = 0.9573500156402588\n",
      "3 = 0.988099992275238\n",
      "4 = 0.9265999794006348\n",
      "5 = 0.9308525919914246\n",
      "6 = 0.988099992275238\n",
      "7 = 11.71616018657686\n",
      "8 = 0.1802706998243168\n",
      "9 = 0.9389500021934509\n",
      "10 = 0.9386000037193298\n",
      "11 = 0.939300000667572\n",
      "12 = 0.9392575025558472\n",
      "13 = 0.9386000037193298\n",
      "14 = 4.321149826049805\n",
      "15 = 8.312858581542969\n",
      "16 = 0.3667755126953125\n",
      "17 = 4.321126461029053\n",
      "18 = 76.97200012207031\n",
      "epoch:1 step:9005[D loss: 0.999972] [G loss: 1.000049]\n",
      "epoch:1 step:9010[D loss: 0.999967] [G loss: 1.000059]\n",
      "epoch:1 step:9015[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:1 step:9020[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:1 step:9025[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:1 step:9030[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:1 step:9035[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:1 step:9040[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:1 step:9045[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:1 step:9050[D loss: 0.999970] [G loss: 1.000053]\n",
      "epoch:1 step:9055[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:1 step:9060[D loss: 0.999971] [G loss: 1.000048]\n",
      "epoch:1 step:9065[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:1 step:9070[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:1 step:9075[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:1 step:9080[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:1 step:9085[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:1 step:9090[D loss: 0.999972] [G loss: 1.000051]\n",
      "epoch:1 step:9095[D loss: 0.999973] [G loss: 1.000039]\n",
      "epoch:1 step:9100[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:1 step:9105[D loss: 0.999988] [G loss: 1.000041]\n",
      "epoch:1 step:9110[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:1 step:9115[D loss: 0.999981] [G loss: 1.000039]\n",
      "epoch:1 step:9120[D loss: 0.999996] [G loss: 1.000057]\n",
      "epoch:1 step:9125[D loss: 0.999985] [G loss: 1.000041]\n",
      "epoch:1 step:9130[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:1 step:9135[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:1 step:9140[D loss: 0.999962] [G loss: 1.000065]\n",
      "epoch:1 step:9145[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:1 step:9150[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:1 step:9155[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:1 step:9160[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:1 step:9165[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:1 step:9170[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:1 step:9175[D loss: 0.999993] [G loss: 1.000031]\n",
      "epoch:1 step:9180[D loss: 1.000006] [G loss: 1.000009]\n",
      "epoch:1 step:9185[D loss: 1.000001] [G loss: 1.000000]\n",
      "epoch:1 step:9190[D loss: 0.999997] [G loss: 1.000025]\n",
      "epoch:1 step:9195[D loss: 0.999974] [G loss: 1.000047]\n",
      "epoch:1 step:9200[D loss: 0.999987] [G loss: 1.000036]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 3.942801\n",
      "FID: 89.176842\n",
      "0 = 14.254789877605365\n",
      "1 = 0.09455399673059564\n",
      "2 = 0.9700499773025513\n",
      "3 = 0.9837999939918518\n",
      "4 = 0.9563000202178955\n",
      "5 = 0.9574695825576782\n",
      "6 = 0.9837999939918518\n",
      "7 = 12.265059126341393\n",
      "8 = 0.196482700469691\n",
      "9 = 0.945900022983551\n",
      "10 = 0.9427000284194946\n",
      "11 = 0.9491000175476074\n",
      "12 = 0.948772132396698\n",
      "13 = 0.9427000284194946\n",
      "14 = 3.942816972732544\n",
      "15 = 7.9489665031433105\n",
      "16 = 0.4171971380710602\n",
      "17 = 3.942800760269165\n",
      "18 = 89.17684173583984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:9205[D loss: 0.999954] [G loss: 1.000060]\n",
      "epoch:1 step:9210[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:1 step:9215[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:1 step:9220[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:1 step:9225[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:1 step:9230[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:1 step:9235[D loss: 0.999978] [G loss: 1.000048]\n",
      "epoch:1 step:9240[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:1 step:9245[D loss: 1.000014] [G loss: 1.000058]\n",
      "epoch:1 step:9250[D loss: 0.999968] [G loss: 1.000044]\n",
      "epoch:1 step:9255[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:1 step:9260[D loss: 0.999975] [G loss: 1.000044]\n",
      "epoch:1 step:9265[D loss: 0.999980] [G loss: 1.000045]\n",
      "epoch:1 step:9270[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:1 step:9275[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:1 step:9280[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:1 step:9285[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:1 step:9290[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:1 step:9295[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:1 step:9300[D loss: 0.999979] [G loss: 1.000047]\n",
      "epoch:1 step:9305[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:1 step:9310[D loss: 0.999985] [G loss: 1.000058]\n",
      "epoch:1 step:9315[D loss: 0.999989] [G loss: 1.000039]\n",
      "epoch:1 step:9320[D loss: 0.999990] [G loss: 1.000041]\n",
      "epoch:1 step:9325[D loss: 0.999968] [G loss: 1.000055]\n",
      "epoch:1 step:9330[D loss: 0.999991] [G loss: 1.000045]\n",
      "epoch:1 step:9335[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:1 step:9340[D loss: 0.999977] [G loss: 1.000044]\n",
      "epoch:1 step:9345[D loss: 0.999968] [G loss: 1.000036]\n",
      "epoch:1 step:9350[D loss: 0.999964] [G loss: 1.000060]\n",
      "epoch:1 step:9355[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:1 step:9360[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:1 step:9365[D loss: 0.999990] [G loss: 1.000055]\n",
      "epoch:1 step:9370[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:2 step:9375[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:2 step:9380[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:2 step:9385[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:2 step:9390[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:2 step:9395[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:2 step:9400[D loss: 0.999969] [G loss: 1.000058]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.418724\n",
      "FID: 75.837738\n",
      "0 = 15.026256974983228\n",
      "1 = 0.10270401538699121\n",
      "2 = 0.9523500204086304\n",
      "3 = 0.9919999837875366\n",
      "4 = 0.9126999974250793\n",
      "5 = 0.9191142320632935\n",
      "6 = 0.9919999837875366\n",
      "7 = 11.612386201381701\n",
      "8 = 0.1782738181060442\n",
      "9 = 0.9351000189781189\n",
      "10 = 0.9336000084877014\n",
      "11 = 0.9366000294685364\n",
      "12 = 0.9364092350006104\n",
      "13 = 0.9336000084877014\n",
      "14 = 4.418747425079346\n",
      "15 = 8.134115219116211\n",
      "16 = 0.36946964263916016\n",
      "17 = 4.418724060058594\n",
      "18 = 75.83773803710938\n",
      "epoch:2 step:9405[D loss: 0.999971] [G loss: 1.000046]\n",
      "epoch:2 step:9410[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:2 step:9415[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:2 step:9420[D loss: 0.999976] [G loss: 1.000048]\n",
      "epoch:2 step:9425[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:2 step:9430[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:2 step:9435[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:2 step:9440[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:2 step:9445[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:2 step:9450[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:2 step:9455[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:2 step:9460[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:2 step:9465[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:2 step:9470[D loss: 0.999986] [G loss: 1.000065]\n",
      "epoch:2 step:9475[D loss: 0.999986] [G loss: 1.000054]\n",
      "epoch:2 step:9480[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:2 step:9485[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:2 step:9490[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:2 step:9495[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:2 step:9500[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:2 step:9505[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:2 step:9510[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:2 step:9515[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:2 step:9520[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:2 step:9525[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:2 step:9530[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:2 step:9535[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:2 step:9540[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:2 step:9545[D loss: 0.999988] [G loss: 1.000046]\n",
      "epoch:2 step:9550[D loss: 0.999986] [G loss: 1.000058]\n",
      "epoch:2 step:9555[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:2 step:9560[D loss: 0.999967] [G loss: 1.000055]\n",
      "epoch:2 step:9565[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:2 step:9570[D loss: 0.999970] [G loss: 1.000050]\n",
      "epoch:2 step:9575[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:2 step:9580[D loss: 0.999972] [G loss: 1.000051]\n",
      "epoch:2 step:9585[D loss: 0.999964] [G loss: 1.000058]\n",
      "epoch:2 step:9590[D loss: 0.999966] [G loss: 1.000054]\n",
      "epoch:2 step:9595[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:2 step:9600[D loss: 0.999967] [G loss: 1.000054]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.314385\n",
      "FID: 77.645782\n",
      "0 = 14.346146664237953\n",
      "1 = 0.06313856073642854\n",
      "2 = 0.9624500274658203\n",
      "3 = 0.9857000112533569\n",
      "4 = 0.9391999840736389\n",
      "5 = 0.9419015645980835\n",
      "6 = 0.9857000112533569\n",
      "7 = 11.806838794553313\n",
      "8 = 0.18217308183678138\n",
      "9 = 0.9398999810218811\n",
      "10 = 0.9406999945640564\n",
      "11 = 0.9391000270843506\n",
      "12 = 0.939197301864624\n",
      "13 = 0.9406999945640564\n",
      "14 = 4.314404010772705\n",
      "15 = 8.376487731933594\n",
      "16 = 0.37167108058929443\n",
      "17 = 4.314384937286377\n",
      "18 = 77.64578247070312\n",
      "epoch:2 step:9605[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:2 step:9610[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:2 step:9615[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:2 step:9620[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:2 step:9625[D loss: 0.999977] [G loss: 1.000043]\n",
      "epoch:2 step:9630[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:2 step:9635[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:2 step:9640[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:2 step:9645[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:2 step:9650[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:2 step:9655[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:2 step:9660[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:2 step:9665[D loss: 0.999985] [G loss: 1.000044]\n",
      "epoch:2 step:9670[D loss: 0.999979] [G loss: 1.000044]\n",
      "epoch:2 step:9675[D loss: 0.999978] [G loss: 1.000033]\n",
      "epoch:2 step:9680[D loss: 0.999972] [G loss: 1.000046]\n",
      "epoch:2 step:9685[D loss: 0.999982] [G loss: 1.000036]\n",
      "epoch:2 step:9690[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:2 step:9695[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:2 step:9700[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:2 step:9705[D loss: 0.999978] [G loss: 1.000050]\n",
      "epoch:2 step:9710[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:2 step:9715[D loss: 0.999974] [G loss: 1.000048]\n",
      "epoch:2 step:9720[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:2 step:9725[D loss: 0.999990] [G loss: 1.000046]\n",
      "epoch:2 step:9730[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:2 step:9735[D loss: 0.999966] [G loss: 1.000057]\n",
      "epoch:2 step:9740[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:2 step:9745[D loss: 0.999986] [G loss: 1.000052]\n",
      "epoch:2 step:9750[D loss: 0.999989] [G loss: 1.000034]\n",
      "epoch:2 step:9755[D loss: 1.000001] [G loss: 1.000007]\n",
      "epoch:2 step:9760[D loss: 0.999971] [G loss: 1.000052]\n",
      "epoch:2 step:9765[D loss: 0.999965] [G loss: 1.000059]\n",
      "epoch:2 step:9770[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:2 step:9775[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:2 step:9780[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:2 step:9785[D loss: 0.999972] [G loss: 1.000046]\n",
      "epoch:2 step:9790[D loss: 0.999977] [G loss: 1.000028]\n",
      "epoch:2 step:9795[D loss: 0.999984] [G loss: 1.000046]\n",
      "epoch:2 step:9800[D loss: 0.999968] [G loss: 1.000066]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.249875\n",
      "FID: 79.486832\n",
      "0 = 14.853001117277186\n",
      "1 = 0.07515725497963732\n",
      "2 = 0.9527000188827515\n",
      "3 = 0.989799976348877\n",
      "4 = 0.9156000018119812\n",
      "5 = 0.9214298725128174\n",
      "6 = 0.989799976348877\n",
      "7 = 11.811482449150102\n",
      "8 = 0.18483589884448298\n",
      "9 = 0.9366999864578247\n",
      "10 = 0.9381999969482422\n",
      "11 = 0.9351999759674072\n",
      "12 = 0.9353938102722168\n",
      "13 = 0.9381999969482422\n",
      "14 = 4.249894618988037\n",
      "15 = 8.063809394836426\n",
      "16 = 0.39253655076026917\n",
      "17 = 4.249875068664551\n",
      "18 = 79.48683166503906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:9805[D loss: 0.999988] [G loss: 1.000035]\n",
      "epoch:2 step:9810[D loss: 0.999987] [G loss: 1.000045]\n",
      "epoch:2 step:9815[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:2 step:9820[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:2 step:9825[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:2 step:9830[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:2 step:9835[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:2 step:9840[D loss: 0.999960] [G loss: 1.000076]\n",
      "epoch:2 step:9845[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:2 step:9850[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:2 step:9855[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:2 step:9860[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:2 step:9865[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:2 step:9870[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:2 step:9875[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:2 step:9880[D loss: 0.999972] [G loss: 1.000046]\n",
      "epoch:2 step:9885[D loss: 0.999974] [G loss: 1.000047]\n",
      "epoch:2 step:9890[D loss: 0.999972] [G loss: 1.000043]\n",
      "epoch:2 step:9895[D loss: 0.999977] [G loss: 1.000036]\n",
      "epoch:2 step:9900[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:2 step:9905[D loss: 0.999979] [G loss: 1.000045]\n",
      "epoch:2 step:9910[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:2 step:9915[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:2 step:9920[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:2 step:9925[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:2 step:9930[D loss: 0.999975] [G loss: 1.000036]\n",
      "epoch:2 step:9935[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:2 step:9940[D loss: 0.999964] [G loss: 1.000053]\n",
      "epoch:2 step:9945[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:2 step:9950[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:2 step:9955[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:2 step:9960[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:2 step:9965[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:2 step:9970[D loss: 0.999966] [G loss: 1.000067]\n",
      "epoch:2 step:9975[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:2 step:9980[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:2 step:9985[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:2 step:9990[D loss: 0.999968] [G loss: 1.000056]\n",
      "epoch:2 step:9995[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:2 step:10000[D loss: 0.999974] [G loss: 1.000056]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.327815\n",
      "FID: 75.839249\n",
      "0 = 14.827653313541367\n",
      "1 = 0.08292160045060071\n",
      "2 = 0.9505000114440918\n",
      "3 = 0.9909999966621399\n",
      "4 = 0.9100000262260437\n",
      "5 = 0.9167437553405762\n",
      "6 = 0.9909999966621399\n",
      "7 = 11.646288052523124\n",
      "8 = 0.17894058897474713\n",
      "9 = 0.9345499873161316\n",
      "10 = 0.9372000098228455\n",
      "11 = 0.9319000244140625\n",
      "12 = 0.9322590231895447\n",
      "13 = 0.9372000098228455\n",
      "14 = 4.327832221984863\n",
      "15 = 8.29964828491211\n",
      "16 = 0.370874285697937\n",
      "17 = 4.32781457901001\n",
      "18 = 75.83924865722656\n",
      "epoch:2 step:10005[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:2 step:10010[D loss: 0.999981] [G loss: 1.000055]\n",
      "epoch:2 step:10015[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:2 step:10020[D loss: 0.999982] [G loss: 1.000066]\n",
      "epoch:2 step:10025[D loss: 0.999989] [G loss: 1.000057]\n",
      "epoch:2 step:10030[D loss: 0.999986] [G loss: 1.000055]\n",
      "epoch:2 step:10035[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:2 step:10040[D loss: 0.999964] [G loss: 1.000078]\n",
      "epoch:2 step:10045[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:2 step:10050[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:2 step:10055[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:2 step:10060[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:2 step:10065[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:2 step:10070[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:2 step:10075[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:2 step:10080[D loss: 0.999983] [G loss: 1.000040]\n",
      "epoch:2 step:10085[D loss: 0.999979] [G loss: 1.000040]\n",
      "epoch:2 step:10090[D loss: 0.999991] [G loss: 1.000047]\n",
      "epoch:2 step:10095[D loss: 0.999984] [G loss: 1.000041]\n",
      "epoch:2 step:10100[D loss: 0.999977] [G loss: 1.000045]\n",
      "epoch:2 step:10105[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:2 step:10110[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:2 step:10115[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:2 step:10120[D loss: 0.999976] [G loss: 1.000050]\n",
      "epoch:2 step:10125[D loss: 0.999993] [G loss: 1.000056]\n",
      "epoch:2 step:10130[D loss: 1.000012] [G loss: 1.000066]\n",
      "epoch:2 step:10135[D loss: 0.999954] [G loss: 1.000070]\n",
      "epoch:2 step:10140[D loss: 0.999956] [G loss: 1.000065]\n",
      "epoch:2 step:10145[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:2 step:10150[D loss: 0.999972] [G loss: 1.000044]\n",
      "epoch:2 step:10155[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:2 step:10160[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:2 step:10165[D loss: 0.999986] [G loss: 1.000045]\n",
      "epoch:2 step:10170[D loss: 0.999970] [G loss: 1.000052]\n",
      "epoch:2 step:10175[D loss: 0.999986] [G loss: 1.000056]\n",
      "epoch:2 step:10180[D loss: 0.999963] [G loss: 1.000061]\n",
      "epoch:2 step:10185[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:2 step:10190[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:2 step:10195[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:2 step:10200[D loss: 0.999981] [G loss: 1.000049]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.482036\n",
      "FID: 70.557510\n",
      "0 = 14.767560200548155\n",
      "1 = 0.07744377680995004\n",
      "2 = 0.9491000175476074\n",
      "3 = 0.9901000261306763\n",
      "4 = 0.9081000089645386\n",
      "5 = 0.9150646924972534\n",
      "6 = 0.9901000261306763\n",
      "7 = 11.462959935522058\n",
      "8 = 0.16946349306163808\n",
      "9 = 0.934499979019165\n",
      "10 = 0.935699999332428\n",
      "11 = 0.9333000183105469\n",
      "12 = 0.9334596991539001\n",
      "13 = 0.935699999332428\n",
      "14 = 4.482056140899658\n",
      "15 = 8.618319511413574\n",
      "16 = 0.3354710340499878\n",
      "17 = 4.4820356369018555\n",
      "18 = 70.55751037597656\n",
      "epoch:2 step:10205[D loss: 0.999980] [G loss: 1.000052]\n",
      "epoch:2 step:10210[D loss: 0.999982] [G loss: 1.000030]\n",
      "epoch:2 step:10215[D loss: 0.999978] [G loss: 1.000050]\n",
      "epoch:2 step:10220[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:2 step:10225[D loss: 0.999981] [G loss: 1.000040]\n",
      "epoch:2 step:10230[D loss: 0.999991] [G loss: 1.000064]\n",
      "epoch:2 step:10235[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:2 step:10240[D loss: 0.999962] [G loss: 1.000081]\n",
      "epoch:2 step:10245[D loss: 0.999968] [G loss: 1.000056]\n",
      "epoch:2 step:10250[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:2 step:10255[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:2 step:10260[D loss: 0.999979] [G loss: 1.000060]\n",
      "epoch:2 step:10265[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:2 step:10270[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:2 step:10275[D loss: 0.999987] [G loss: 1.000070]\n",
      "epoch:2 step:10280[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:2 step:10285[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:2 step:10290[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:2 step:10295[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:2 step:10300[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:2 step:10305[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:2 step:10310[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:2 step:10315[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:2 step:10320[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:2 step:10325[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:2 step:10330[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:2 step:10335[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:2 step:10340[D loss: 0.999980] [G loss: 1.000054]\n",
      "epoch:2 step:10345[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:2 step:10350[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:2 step:10355[D loss: 0.999968] [G loss: 1.000059]\n",
      "epoch:2 step:10360[D loss: 0.999974] [G loss: 1.000045]\n",
      "epoch:2 step:10365[D loss: 0.999977] [G loss: 1.000044]\n",
      "epoch:2 step:10370[D loss: 0.999976] [G loss: 1.000050]\n",
      "epoch:2 step:10375[D loss: 0.999985] [G loss: 1.000032]\n",
      "epoch:2 step:10380[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:2 step:10385[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:2 step:10390[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:2 step:10395[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:2 step:10400[D loss: 0.999969] [G loss: 1.000060]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.485824\n",
      "FID: 71.838966\n",
      "0 = 15.702738893127457\n",
      "1 = 0.15589482948679784\n",
      "2 = 0.9397500157356262\n",
      "3 = 0.9937999844551086\n",
      "4 = 0.885699987411499\n",
      "5 = 0.8968504667282104\n",
      "6 = 0.9937999844551086\n",
      "7 = 11.444446240079417\n",
      "8 = 0.17179938300202924\n",
      "9 = 0.933650016784668\n",
      "10 = 0.9368000030517578\n",
      "11 = 0.9304999709129333\n",
      "12 = 0.9309350848197937\n",
      "13 = 0.9368000030517578\n",
      "14 = 4.485844135284424\n",
      "15 = 8.592341423034668\n",
      "16 = 0.33413562178611755\n",
      "17 = 4.485823631286621\n",
      "18 = 71.8389663696289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:10405[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:2 step:10410[D loss: 0.999977] [G loss: 1.000044]\n",
      "epoch:2 step:10415[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:2 step:10420[D loss: 0.999976] [G loss: 1.000045]\n",
      "epoch:2 step:10425[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:2 step:10430[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:2 step:10435[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:2 step:10440[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:2 step:10445[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:2 step:10450[D loss: 0.999976] [G loss: 1.000045]\n",
      "epoch:2 step:10455[D loss: 0.999978] [G loss: 1.000049]\n",
      "epoch:2 step:10460[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:2 step:10465[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:2 step:10470[D loss: 0.999982] [G loss: 1.000053]\n",
      "epoch:2 step:10475[D loss: 1.000003] [G loss: 1.000030]\n",
      "epoch:2 step:10480[D loss: 1.000013] [G loss: 1.000010]\n",
      "epoch:2 step:10485[D loss: 1.000013] [G loss: 1.000013]\n",
      "epoch:2 step:10490[D loss: 0.999972] [G loss: 1.000025]\n",
      "epoch:2 step:10495[D loss: 0.999965] [G loss: 1.000048]\n",
      "epoch:2 step:10500[D loss: 0.999988] [G loss: 1.000047]\n",
      "epoch:2 step:10505[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:2 step:10510[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:2 step:10515[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:2 step:10520[D loss: 1.000014] [G loss: 1.000079]\n",
      "epoch:2 step:10525[D loss: 0.999994] [G loss: 1.000078]\n",
      "epoch:2 step:10530[D loss: 1.000016] [G loss: 1.000053]\n",
      "epoch:2 step:10535[D loss: 0.999953] [G loss: 1.000074]\n",
      "epoch:2 step:10540[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:2 step:10545[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:2 step:10550[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:2 step:10555[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:2 step:10560[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:2 step:10565[D loss: 0.999976] [G loss: 1.000050]\n",
      "epoch:2 step:10570[D loss: 0.999980] [G loss: 1.000041]\n",
      "epoch:2 step:10575[D loss: 0.999971] [G loss: 1.000051]\n",
      "epoch:2 step:10580[D loss: 0.999984] [G loss: 1.000056]\n",
      "epoch:2 step:10585[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:2 step:10590[D loss: 0.999986] [G loss: 1.000063]\n",
      "epoch:2 step:10595[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:2 step:10600[D loss: 0.999974] [G loss: 1.000039]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.274915\n",
      "FID: 77.958923\n",
      "0 = 14.649546886062595\n",
      "1 = 0.06523079319788765\n",
      "2 = 0.948199987411499\n",
      "3 = 0.9894999861717224\n",
      "4 = 0.9068999886512756\n",
      "5 = 0.914003312587738\n",
      "6 = 0.9894999861717224\n",
      "7 = 11.814674651467817\n",
      "8 = 0.18331368369947107\n",
      "9 = 0.9389500021934509\n",
      "10 = 0.9416999816894531\n",
      "11 = 0.9362000226974487\n",
      "12 = 0.9365490078926086\n",
      "13 = 0.9416999816894531\n",
      "14 = 4.274939060211182\n",
      "15 = 8.159812927246094\n",
      "16 = 0.39040449261665344\n",
      "17 = 4.2749152183532715\n",
      "18 = 77.95892333984375\n",
      "epoch:2 step:10605[D loss: 0.999973] [G loss: 1.000041]\n",
      "epoch:2 step:10610[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:2 step:10615[D loss: 0.999979] [G loss: 1.000032]\n",
      "epoch:2 step:10620[D loss: 0.999999] [G loss: 1.000069]\n",
      "epoch:2 step:10625[D loss: 0.999971] [G loss: 1.000089]\n",
      "epoch:2 step:10630[D loss: 0.999965] [G loss: 1.000089]\n",
      "epoch:2 step:10635[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:2 step:10640[D loss: 0.999963] [G loss: 1.000076]\n",
      "epoch:2 step:10645[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:2 step:10650[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:2 step:10655[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:2 step:10660[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:2 step:10665[D loss: 0.999977] [G loss: 1.000053]\n",
      "epoch:2 step:10670[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:2 step:10675[D loss: 0.999971] [G loss: 1.000050]\n",
      "epoch:2 step:10680[D loss: 0.999978] [G loss: 1.000039]\n",
      "epoch:2 step:10685[D loss: 0.999976] [G loss: 1.000040]\n",
      "epoch:2 step:10690[D loss: 0.999978] [G loss: 1.000050]\n",
      "epoch:2 step:10695[D loss: 0.999978] [G loss: 1.000041]\n",
      "epoch:2 step:10700[D loss: 0.999968] [G loss: 1.000054]\n",
      "epoch:2 step:10705[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:2 step:10710[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:2 step:10715[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:2 step:10720[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:2 step:10725[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:2 step:10730[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:2 step:10735[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:2 step:10740[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:2 step:10745[D loss: 0.999971] [G loss: 1.000050]\n",
      "epoch:2 step:10750[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:2 step:10755[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:2 step:10760[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:2 step:10765[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:2 step:10770[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:2 step:10775[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:2 step:10780[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:2 step:10785[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:2 step:10790[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:2 step:10795[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:2 step:10800[D loss: 0.999983] [G loss: 1.000062]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.229246\n",
      "FID: 81.031563\n",
      "0 = 14.423379214429866\n",
      "1 = 0.045791826816564574\n",
      "2 = 0.9541500210762024\n",
      "3 = 0.9873999953269958\n",
      "4 = 0.9208999872207642\n",
      "5 = 0.9258321523666382\n",
      "6 = 0.9873999953269958\n",
      "7 = 11.88336275539395\n",
      "8 = 0.18637766309507492\n",
      "9 = 0.9412000179290771\n",
      "10 = 0.9419999718666077\n",
      "11 = 0.9404000043869019\n",
      "12 = 0.9404951930046082\n",
      "13 = 0.9419999718666077\n",
      "14 = 4.229264736175537\n",
      "15 = 8.097065925598145\n",
      "16 = 0.39428892731666565\n",
      "17 = 4.229245662689209\n",
      "18 = 81.03156280517578\n",
      "epoch:2 step:10805[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:2 step:10810[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:2 step:10815[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:2 step:10820[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:2 step:10825[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:2 step:10830[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:2 step:10835[D loss: 0.999978] [G loss: 1.000049]\n",
      "epoch:2 step:10840[D loss: 0.999966] [G loss: 1.000068]\n",
      "epoch:2 step:10845[D loss: 0.999969] [G loss: 1.000055]\n",
      "epoch:2 step:10850[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:2 step:10855[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:2 step:10860[D loss: 0.999986] [G loss: 1.000047]\n",
      "epoch:2 step:10865[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:2 step:10870[D loss: 0.999972] [G loss: 1.000049]\n",
      "epoch:2 step:10875[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:2 step:10880[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:2 step:10885[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:2 step:10890[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:2 step:10895[D loss: 0.999966] [G loss: 1.000059]\n",
      "epoch:2 step:10900[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:2 step:10905[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:2 step:10910[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:2 step:10915[D loss: 0.999980] [G loss: 1.000046]\n",
      "epoch:2 step:10920[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:2 step:10925[D loss: 0.999986] [G loss: 1.000035]\n",
      "epoch:2 step:10930[D loss: 1.000021] [G loss: 1.000064]\n",
      "epoch:2 step:10935[D loss: 1.000018] [G loss: 1.000051]\n",
      "epoch:2 step:10940[D loss: 1.000009] [G loss: 1.000037]\n",
      "epoch:2 step:10945[D loss: 0.999978] [G loss: 1.000098]\n",
      "epoch:2 step:10950[D loss: 0.999959] [G loss: 1.000063]\n",
      "epoch:2 step:10955[D loss: 0.999961] [G loss: 1.000062]\n",
      "epoch:2 step:10960[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:2 step:10965[D loss: 0.999972] [G loss: 1.000053]\n",
      "epoch:2 step:10970[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:2 step:10975[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:2 step:10980[D loss: 0.999980] [G loss: 1.000032]\n",
      "epoch:2 step:10985[D loss: 0.999971] [G loss: 1.000047]\n",
      "epoch:2 step:10990[D loss: 0.999993] [G loss: 1.000029]\n",
      "epoch:2 step:10995[D loss: 1.000005] [G loss: 1.000020]\n",
      "epoch:2 step:11000[D loss: 1.000003] [G loss: 1.000028]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.253438\n",
      "FID: 77.131439\n",
      "0 = 14.434598537492752\n",
      "1 = 0.050706074163074884\n",
      "2 = 0.9519000053405762\n",
      "3 = 0.9878000020980835\n",
      "4 = 0.9160000085830688\n",
      "5 = 0.9216271638870239\n",
      "6 = 0.9878000020980835\n",
      "7 = 11.762665187978719\n",
      "8 = 0.17915464257398006\n",
      "9 = 0.9376999735832214\n",
      "10 = 0.9395999908447266\n",
      "11 = 0.9358000159263611\n",
      "12 = 0.9360430240631104\n",
      "13 = 0.9395999908447266\n",
      "14 = 4.253453731536865\n",
      "15 = 8.293037414550781\n",
      "16 = 0.37572479248046875\n",
      "17 = 4.253438472747803\n",
      "18 = 77.13143920898438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:11005[D loss: 1.000003] [G loss: 1.000057]\n",
      "epoch:2 step:11010[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:2 step:11015[D loss: 0.999985] [G loss: 1.000041]\n",
      "epoch:2 step:11020[D loss: 0.999974] [G loss: 1.000038]\n",
      "epoch:2 step:11025[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:2 step:11030[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:2 step:11035[D loss: 0.999963] [G loss: 1.000085]\n",
      "epoch:2 step:11040[D loss: 0.999964] [G loss: 1.000062]\n",
      "epoch:2 step:11045[D loss: 0.999964] [G loss: 1.000066]\n",
      "epoch:2 step:11050[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:2 step:11055[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:2 step:11060[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:2 step:11065[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:2 step:11070[D loss: 0.999976] [G loss: 1.000050]\n",
      "epoch:2 step:11075[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:2 step:11080[D loss: 0.999981] [G loss: 1.000044]\n",
      "epoch:2 step:11085[D loss: 0.999985] [G loss: 1.000040]\n",
      "epoch:2 step:11090[D loss: 1.000003] [G loss: 0.999989]\n",
      "epoch:2 step:11095[D loss: 1.000026] [G loss: 0.999975]\n",
      "epoch:2 step:11100[D loss: 1.000052] [G loss: 0.999984]\n",
      "epoch:2 step:11105[D loss: 1.000066] [G loss: 0.999964]\n",
      "epoch:2 step:11110[D loss: 0.999958] [G loss: 1.000028]\n",
      "epoch:2 step:11115[D loss: 0.999937] [G loss: 1.000037]\n",
      "epoch:2 step:11120[D loss: 0.999961] [G loss: 1.000049]\n",
      "epoch:2 step:11125[D loss: 0.999946] [G loss: 1.000070]\n",
      "epoch:2 step:11130[D loss: 0.999964] [G loss: 1.000053]\n",
      "epoch:2 step:11135[D loss: 0.999969] [G loss: 1.000054]\n",
      "epoch:2 step:11140[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:2 step:11145[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:2 step:11150[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:2 step:11155[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:2 step:11160[D loss: 0.999982] [G loss: 1.000050]\n",
      "epoch:2 step:11165[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:2 step:11170[D loss: 0.999983] [G loss: 1.000039]\n",
      "epoch:2 step:11175[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:2 step:11180[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:2 step:11185[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:2 step:11190[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:2 step:11195[D loss: 0.999966] [G loss: 1.000066]\n",
      "epoch:2 step:11200[D loss: 0.999972] [G loss: 1.000056]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.297520\n",
      "FID: 77.533600\n",
      "0 = 14.434048821210862\n",
      "1 = 0.057112210434271206\n",
      "2 = 0.95455002784729\n",
      "3 = 0.9872999787330627\n",
      "4 = 0.9218000173568726\n",
      "5 = 0.9266072511672974\n",
      "6 = 0.9872999787330627\n",
      "7 = 11.742793034267487\n",
      "8 = 0.18154149785915696\n",
      "9 = 0.9399499893188477\n",
      "10 = 0.9409999847412109\n",
      "11 = 0.9388999938964844\n",
      "12 = 0.9390280246734619\n",
      "13 = 0.9409999847412109\n",
      "14 = 4.297539234161377\n",
      "15 = 8.500804901123047\n",
      "16 = 0.35649681091308594\n",
      "17 = 4.297519683837891\n",
      "18 = 77.53359985351562\n",
      "epoch:2 step:11205[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:2 step:11210[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:2 step:11215[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:2 step:11220[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:2 step:11225[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:2 step:11230[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:2 step:11235[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:2 step:11240[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:2 step:11245[D loss: 0.999966] [G loss: 1.000055]\n",
      "epoch:2 step:11250[D loss: 0.999963] [G loss: 1.000058]\n",
      "epoch:2 step:11255[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:2 step:11260[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:2 step:11265[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:2 step:11270[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:2 step:11275[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:2 step:11280[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:2 step:11285[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:2 step:11290[D loss: 0.999974] [G loss: 1.000042]\n",
      "epoch:2 step:11295[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:2 step:11300[D loss: 0.999977] [G loss: 1.000046]\n",
      "epoch:2 step:11305[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:2 step:11310[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:2 step:11315[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:2 step:11320[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:2 step:11325[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:2 step:11330[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:2 step:11335[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:2 step:11340[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:2 step:11345[D loss: 0.999983] [G loss: 1.000045]\n",
      "epoch:2 step:11350[D loss: 0.999987] [G loss: 1.000058]\n",
      "epoch:2 step:11355[D loss: 0.999994] [G loss: 1.000072]\n",
      "epoch:2 step:11360[D loss: 0.999997] [G loss: 1.000039]\n",
      "epoch:2 step:11365[D loss: 0.999975] [G loss: 1.000045]\n",
      "epoch:2 step:11370[D loss: 0.999969] [G loss: 1.000049]\n",
      "epoch:2 step:11375[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:2 step:11380[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:2 step:11385[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:2 step:11390[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:2 step:11395[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:2 step:11400[D loss: 0.999974] [G loss: 1.000047]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 3.716721\n",
      "FID: 99.169731\n",
      "0 = 14.29906984462737\n",
      "1 = 0.13127366715442737\n",
      "2 = 0.9711499810218811\n",
      "3 = 0.982200026512146\n",
      "4 = 0.960099995136261\n",
      "5 = 0.96096271276474\n",
      "6 = 0.982200026512146\n",
      "7 = 12.571364801633386\n",
      "8 = 0.20449572016334355\n",
      "9 = 0.9529500007629395\n",
      "10 = 0.9520000219345093\n",
      "11 = 0.9538999795913696\n",
      "12 = 0.9538122415542603\n",
      "13 = 0.9520000219345093\n",
      "14 = 3.7167305946350098\n",
      "15 = 7.917844295501709\n",
      "16 = 0.4406920075416565\n",
      "17 = 3.716721296310425\n",
      "18 = 99.16973114013672\n",
      "epoch:2 step:11405[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:2 step:11410[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:2 step:11415[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:2 step:11420[D loss: 0.999978] [G loss: 1.000040]\n",
      "epoch:2 step:11425[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:2 step:11430[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:2 step:11435[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:2 step:11440[D loss: 0.999963] [G loss: 1.000070]\n",
      "epoch:2 step:11445[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:2 step:11450[D loss: 0.999977] [G loss: 1.000047]\n",
      "epoch:2 step:11455[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:2 step:11460[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:2 step:11465[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:2 step:11470[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:2 step:11475[D loss: 0.999969] [G loss: 1.000053]\n",
      "epoch:2 step:11480[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:2 step:11485[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:2 step:11490[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:2 step:11495[D loss: 0.999978] [G loss: 1.000041]\n",
      "epoch:2 step:11500[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:2 step:11505[D loss: 0.999987] [G loss: 1.000040]\n",
      "epoch:2 step:11510[D loss: 0.999987] [G loss: 1.000047]\n",
      "epoch:2 step:11515[D loss: 0.999991] [G loss: 1.000042]\n",
      "epoch:2 step:11520[D loss: 0.999989] [G loss: 1.000059]\n",
      "epoch:2 step:11525[D loss: 0.999967] [G loss: 1.000051]\n",
      "epoch:2 step:11530[D loss: 0.999965] [G loss: 1.000063]\n",
      "epoch:2 step:11535[D loss: 0.999961] [G loss: 1.000061]\n",
      "epoch:2 step:11540[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:2 step:11545[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:2 step:11550[D loss: 0.999987] [G loss: 1.000042]\n",
      "epoch:2 step:11555[D loss: 0.999977] [G loss: 1.000042]\n",
      "epoch:2 step:11560[D loss: 0.999984] [G loss: 1.000035]\n",
      "epoch:2 step:11565[D loss: 0.999982] [G loss: 1.000036]\n",
      "epoch:2 step:11570[D loss: 0.999966] [G loss: 1.000049]\n",
      "epoch:2 step:11575[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:2 step:11580[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:2 step:11585[D loss: 0.999985] [G loss: 1.000065]\n",
      "epoch:2 step:11590[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:2 step:11595[D loss: 0.999964] [G loss: 1.000061]\n",
      "epoch:2 step:11600[D loss: 0.999971] [G loss: 1.000069]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.296980\n",
      "FID: 77.836876\n",
      "0 = 14.536161034631668\n",
      "1 = 0.06609315551779041\n",
      "2 = 0.9491000175476074\n",
      "3 = 0.9890999794006348\n",
      "4 = 0.9090999960899353\n",
      "5 = 0.9158333539962769\n",
      "6 = 0.9890999794006348\n",
      "7 = 11.741047211015225\n",
      "8 = 0.1830175570211189\n",
      "9 = 0.9376000165939331\n",
      "10 = 0.9381999969482422\n",
      "11 = 0.9369999766349792\n",
      "12 = 0.9370754957199097\n",
      "13 = 0.9381999969482422\n",
      "14 = 4.296998023986816\n",
      "15 = 8.291275978088379\n",
      "16 = 0.3714748024940491\n",
      "17 = 4.296979904174805\n",
      "18 = 77.83687591552734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:11605[D loss: 0.999966] [G loss: 1.000065]\n",
      "epoch:2 step:11610[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:2 step:11615[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:2 step:11620[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:2 step:11625[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:2 step:11630[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:2 step:11635[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:2 step:11640[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:2 step:11645[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:2 step:11650[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:2 step:11655[D loss: 0.999980] [G loss: 1.000043]\n",
      "epoch:2 step:11660[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:2 step:11665[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:2 step:11670[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:2 step:11675[D loss: 0.999981] [G loss: 1.000041]\n",
      "epoch:2 step:11680[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:2 step:11685[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:2 step:11690[D loss: 0.999982] [G loss: 1.000045]\n",
      "epoch:2 step:11695[D loss: 0.999972] [G loss: 1.000051]\n",
      "epoch:2 step:11700[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:2 step:11705[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:2 step:11710[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:2 step:11715[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:2 step:11720[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:2 step:11725[D loss: 0.999982] [G loss: 1.000072]\n",
      "epoch:2 step:11730[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:2 step:11735[D loss: 0.999966] [G loss: 1.000058]\n",
      "epoch:2 step:11740[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:2 step:11745[D loss: 0.999997] [G loss: 1.000022]\n",
      "epoch:2 step:11750[D loss: 0.999995] [G loss: 1.000018]\n",
      "epoch:2 step:11755[D loss: 0.999968] [G loss: 1.000042]\n",
      "epoch:2 step:11760[D loss: 0.999969] [G loss: 1.000038]\n",
      "epoch:2 step:11765[D loss: 0.999974] [G loss: 1.000042]\n",
      "epoch:2 step:11770[D loss: 0.999974] [G loss: 1.000032]\n",
      "epoch:2 step:11775[D loss: 0.999962] [G loss: 1.000054]\n",
      "epoch:2 step:11780[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:2 step:11785[D loss: 0.999981] [G loss: 1.000047]\n",
      "epoch:2 step:11790[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:2 step:11795[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:2 step:11800[D loss: 0.999973] [G loss: 1.000052]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.461231\n",
      "FID: 75.270126\n",
      "0 = 14.638163330125838\n",
      "1 = 0.077316680178429\n",
      "2 = 0.9499499797821045\n",
      "3 = 0.9907000064849854\n",
      "4 = 0.9092000126838684\n",
      "5 = 0.9160425066947937\n",
      "6 = 0.9907000064849854\n",
      "7 = 11.60912379971743\n",
      "8 = 0.17733451382284737\n",
      "9 = 0.9370999932289124\n",
      "10 = 0.9388999938964844\n",
      "11 = 0.9352999925613403\n",
      "12 = 0.9355320930480957\n",
      "13 = 0.9388999938964844\n",
      "14 = 4.461252212524414\n",
      "15 = 8.636146545410156\n",
      "16 = 0.33914339542388916\n",
      "17 = 4.461231231689453\n",
      "18 = 75.27012634277344\n",
      "epoch:2 step:11805[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:2 step:11810[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:2 step:11815[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:2 step:11820[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:2 step:11825[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:2 step:11830[D loss: 0.999971] [G loss: 1.000051]\n",
      "epoch:2 step:11835[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:2 step:11840[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:2 step:11845[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:2 step:11850[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:2 step:11855[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:2 step:11860[D loss: 0.999988] [G loss: 1.000057]\n",
      "epoch:2 step:11865[D loss: 0.999994] [G loss: 1.000066]\n",
      "epoch:2 step:11870[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:2 step:11875[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:2 step:11880[D loss: 0.999967] [G loss: 1.000059]\n",
      "epoch:2 step:11885[D loss: 0.999988] [G loss: 1.000050]\n",
      "epoch:2 step:11890[D loss: 1.000000] [G loss: 1.000043]\n",
      "epoch:2 step:11895[D loss: 0.999985] [G loss: 1.000036]\n",
      "epoch:2 step:11900[D loss: 0.999994] [G loss: 1.000035]\n",
      "epoch:2 step:11905[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:2 step:11910[D loss: 0.999999] [G loss: 1.000063]\n",
      "epoch:2 step:11915[D loss: 0.999967] [G loss: 1.000043]\n",
      "epoch:2 step:11920[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:2 step:11925[D loss: 0.999958] [G loss: 1.000065]\n",
      "epoch:2 step:11930[D loss: 0.999967] [G loss: 1.000062]\n",
      "epoch:2 step:11935[D loss: 0.999962] [G loss: 1.000057]\n",
      "epoch:2 step:11940[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:2 step:11945[D loss: 0.999984] [G loss: 1.000032]\n",
      "epoch:2 step:11950[D loss: 0.999981] [G loss: 1.000044]\n",
      "epoch:2 step:11955[D loss: 0.999973] [G loss: 1.000046]\n",
      "epoch:2 step:11960[D loss: 0.999968] [G loss: 1.000051]\n",
      "epoch:2 step:11965[D loss: 0.999969] [G loss: 1.000045]\n",
      "epoch:2 step:11970[D loss: 0.999971] [G loss: 1.000043]\n",
      "epoch:2 step:11975[D loss: 0.999980] [G loss: 1.000051]\n",
      "epoch:2 step:11980[D loss: 0.999977] [G loss: 1.000031]\n",
      "epoch:2 step:11985[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:2 step:11990[D loss: 0.999980] [G loss: 1.000037]\n",
      "epoch:2 step:11995[D loss: 0.999971] [G loss: 1.000048]\n",
      "epoch:2 step:12000[D loss: 0.999978] [G loss: 1.000050]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 3.817069\n",
      "FID: 94.916252\n",
      "0 = 14.20673637518882\n",
      "1 = 0.1397900696770778\n",
      "2 = 0.9715499877929688\n",
      "3 = 0.9825999736785889\n",
      "4 = 0.9605000019073486\n",
      "5 = 0.9613540768623352\n",
      "6 = 0.9825999736785889\n",
      "7 = 12.46321756427289\n",
      "8 = 0.1983969699589785\n",
      "9 = 0.9563999772071838\n",
      "10 = 0.9528999924659729\n",
      "11 = 0.9599000215530396\n",
      "12 = 0.9596173167228699\n",
      "13 = 0.9528999924659729\n",
      "14 = 3.8170793056488037\n",
      "15 = 8.271720886230469\n",
      "16 = 0.40908151865005493\n",
      "17 = 3.8170690536499023\n",
      "18 = 94.91625213623047\n",
      "epoch:2 step:12005[D loss: 0.999987] [G loss: 1.000036]\n",
      "epoch:2 step:12010[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:2 step:12015[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:2 step:12020[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:2 step:12025[D loss: 0.999962] [G loss: 1.000073]\n",
      "epoch:2 step:12030[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:2 step:12035[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:2 step:12040[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:2 step:12045[D loss: 0.999970] [G loss: 1.000053]\n",
      "epoch:2 step:12050[D loss: 0.999969] [G loss: 1.000053]\n",
      "epoch:2 step:12055[D loss: 0.999982] [G loss: 1.000052]\n",
      "epoch:2 step:12060[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:2 step:12065[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:2 step:12070[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:2 step:12075[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:2 step:12080[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:2 step:12085[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:2 step:12090[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:2 step:12095[D loss: 0.999983] [G loss: 1.000055]\n",
      "epoch:2 step:12100[D loss: 0.999997] [G loss: 1.000029]\n",
      "epoch:2 step:12105[D loss: 0.999996] [G loss: 1.000052]\n",
      "epoch:2 step:12110[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:2 step:12115[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:2 step:12120[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:2 step:12125[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:2 step:12130[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:2 step:12135[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:2 step:12140[D loss: 0.999975] [G loss: 1.000083]\n",
      "epoch:2 step:12145[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:2 step:12150[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:2 step:12155[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:2 step:12160[D loss: 0.999981] [G loss: 1.000056]\n",
      "epoch:2 step:12165[D loss: 0.999965] [G loss: 1.000058]\n",
      "epoch:2 step:12170[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:2 step:12175[D loss: 0.999976] [G loss: 1.000035]\n",
      "epoch:2 step:12180[D loss: 0.999983] [G loss: 1.000016]\n",
      "epoch:2 step:12185[D loss: 0.999985] [G loss: 1.000032]\n",
      "epoch:2 step:12190[D loss: 0.999988] [G loss: 1.000016]\n",
      "epoch:2 step:12195[D loss: 0.999979] [G loss: 1.000017]\n",
      "epoch:2 step:12200[D loss: 1.000058] [G loss: 0.999972]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.365789\n",
      "FID: 74.979553\n",
      "0 = 14.283887022733701\n",
      "1 = 0.058893074970491906\n",
      "2 = 0.9539999961853027\n",
      "3 = 0.98580002784729\n",
      "4 = 0.9222000241279602\n",
      "5 = 0.9268522262573242\n",
      "6 = 0.98580002784729\n",
      "7 = 11.631413165605084\n",
      "8 = 0.17502277770988883\n",
      "9 = 0.9391999840736389\n",
      "10 = 0.9391000270843506\n",
      "11 = 0.939300000667572\n",
      "12 = 0.9392878413200378\n",
      "13 = 0.9391000270843506\n",
      "14 = 4.365808010101318\n",
      "15 = 8.677665710449219\n",
      "16 = 0.3360515236854553\n",
      "17 = 4.36578893661499\n",
      "18 = 74.97955322265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:12205[D loss: 1.000075] [G loss: 0.999938]\n",
      "epoch:2 step:12210[D loss: 1.000029] [G loss: 0.999949]\n",
      "epoch:2 step:12215[D loss: 0.999952] [G loss: 1.000020]\n",
      "epoch:2 step:12220[D loss: 0.999969] [G loss: 1.000033]\n",
      "epoch:2 step:12225[D loss: 0.999966] [G loss: 1.000043]\n",
      "epoch:2 step:12230[D loss: 0.999957] [G loss: 1.000079]\n",
      "epoch:2 step:12235[D loss: 0.999961] [G loss: 1.000074]\n",
      "epoch:2 step:12240[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:2 step:12245[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:2 step:12250[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:2 step:12255[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:2 step:12260[D loss: 0.999960] [G loss: 1.000071]\n",
      "epoch:2 step:12265[D loss: 0.999987] [G loss: 1.000058]\n",
      "epoch:2 step:12270[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:2 step:12275[D loss: 0.999984] [G loss: 1.000059]\n",
      "epoch:2 step:12280[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:2 step:12285[D loss: 0.999976] [G loss: 1.000044]\n",
      "epoch:2 step:12290[D loss: 0.999963] [G loss: 1.000060]\n",
      "epoch:2 step:12295[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:2 step:12300[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:2 step:12305[D loss: 0.999965] [G loss: 1.000064]\n",
      "epoch:2 step:12310[D loss: 0.999979] [G loss: 1.000049]\n",
      "epoch:2 step:12315[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:2 step:12320[D loss: 0.999965] [G loss: 1.000070]\n",
      "epoch:2 step:12325[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:2 step:12330[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:2 step:12335[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:2 step:12340[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:2 step:12345[D loss: 0.999978] [G loss: 1.000041]\n",
      "epoch:2 step:12350[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:2 step:12355[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:2 step:12360[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:2 step:12365[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:2 step:12370[D loss: 0.999966] [G loss: 1.000064]\n",
      "epoch:2 step:12375[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:2 step:12380[D loss: 0.999965] [G loss: 1.000064]\n",
      "epoch:2 step:12385[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:2 step:12390[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:2 step:12395[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:2 step:12400[D loss: 0.999972] [G loss: 1.000058]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.451894\n",
      "FID: 74.078812\n",
      "0 = 14.551247301435456\n",
      "1 = 0.07585901419399585\n",
      "2 = 0.9453499913215637\n",
      "3 = 0.989799976348877\n",
      "4 = 0.9009000062942505\n",
      "5 = 0.908990740776062\n",
      "6 = 0.989799976348877\n",
      "7 = 11.522351585960399\n",
      "8 = 0.17510483190382525\n",
      "9 = 0.9330000281333923\n",
      "10 = 0.935699999332428\n",
      "11 = 0.9302999973297119\n",
      "12 = 0.9306743741035461\n",
      "13 = 0.935699999332428\n",
      "14 = 4.451916217803955\n",
      "15 = 8.658406257629395\n",
      "16 = 0.3355303704738617\n",
      "17 = 4.4518938064575195\n",
      "18 = 74.07881164550781\n",
      "epoch:2 step:12405[D loss: 0.999974] [G loss: 1.000048]\n",
      "epoch:2 step:12410[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:2 step:12415[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:2 step:12420[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:2 step:12425[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:2 step:12430[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:2 step:12435[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:2 step:12440[D loss: 0.999964] [G loss: 1.000068]\n",
      "epoch:2 step:12445[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:2 step:12450[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:2 step:12455[D loss: 0.999967] [G loss: 1.000058]\n",
      "epoch:2 step:12460[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:2 step:12465[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:2 step:12470[D loss: 0.999961] [G loss: 1.000061]\n",
      "epoch:2 step:12475[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:2 step:12480[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:2 step:12485[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:2 step:12490[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:2 step:12495[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:2 step:12500[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:2 step:12505[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:2 step:12510[D loss: 0.999967] [G loss: 1.000059]\n",
      "epoch:2 step:12515[D loss: 0.999974] [G loss: 1.000044]\n",
      "epoch:2 step:12520[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:2 step:12525[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:2 step:12530[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:2 step:12535[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:2 step:12540[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:2 step:12545[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:2 step:12550[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:2 step:12555[D loss: 0.999980] [G loss: 1.000042]\n",
      "epoch:2 step:12560[D loss: 0.999974] [G loss: 1.000047]\n",
      "epoch:2 step:12565[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:2 step:12570[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:2 step:12575[D loss: 0.999996] [G loss: 1.000031]\n",
      "epoch:2 step:12580[D loss: 1.000007] [G loss: 1.000024]\n",
      "epoch:2 step:12585[D loss: 0.999985] [G loss: 1.000041]\n",
      "epoch:2 step:12590[D loss: 0.999966] [G loss: 1.000055]\n",
      "epoch:2 step:12595[D loss: 0.999958] [G loss: 1.000073]\n",
      "epoch:2 step:12600[D loss: 0.999968] [G loss: 1.000063]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.360329\n",
      "FID: 77.089134\n",
      "0 = 14.374655496025074\n",
      "1 = 0.06475942252982561\n",
      "2 = 0.9576500058174133\n",
      "3 = 0.9887999892234802\n",
      "4 = 0.9265000224113464\n",
      "5 = 0.9308105111122131\n",
      "6 = 0.9887999892234802\n",
      "7 = 11.76195087974067\n",
      "8 = 0.1781008787721419\n",
      "9 = 0.9416499733924866\n",
      "10 = 0.9441999793052673\n",
      "11 = 0.9391000270843506\n",
      "12 = 0.9394090175628662\n",
      "13 = 0.9441999793052673\n",
      "14 = 4.360347270965576\n",
      "15 = 8.654664993286133\n",
      "16 = 0.34414175152778625\n",
      "17 = 4.3603291511535645\n",
      "18 = 77.0891342163086\n",
      "epoch:2 step:12605[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:2 step:12610[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:2 step:12615[D loss: 0.999982] [G loss: 1.000047]\n",
      "epoch:2 step:12620[D loss: 0.999991] [G loss: 1.000047]\n",
      "epoch:2 step:12625[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:2 step:12630[D loss: 0.999975] [G loss: 1.000045]\n",
      "epoch:2 step:12635[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:2 step:12640[D loss: 0.999961] [G loss: 1.000068]\n",
      "epoch:2 step:12645[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:2 step:12650[D loss: 0.999980] [G loss: 1.000054]\n",
      "epoch:2 step:12655[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:2 step:12660[D loss: 0.999980] [G loss: 1.000044]\n",
      "epoch:2 step:12665[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:2 step:12670[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:2 step:12675[D loss: 0.999988] [G loss: 1.000041]\n",
      "epoch:2 step:12680[D loss: 0.999963] [G loss: 1.000068]\n",
      "epoch:2 step:12685[D loss: 0.999963] [G loss: 1.000063]\n",
      "epoch:2 step:12690[D loss: 0.999980] [G loss: 1.000045]\n",
      "epoch:2 step:12695[D loss: 0.999981] [G loss: 1.000042]\n",
      "epoch:2 step:12700[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:2 step:12705[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:2 step:12710[D loss: 0.999977] [G loss: 1.000038]\n",
      "epoch:2 step:12715[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:2 step:12720[D loss: 0.999968] [G loss: 1.000050]\n",
      "epoch:2 step:12725[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:2 step:12730[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:2 step:12735[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:2 step:12740[D loss: 0.999980] [G loss: 1.000046]\n",
      "epoch:2 step:12745[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:2 step:12750[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:2 step:12755[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:2 step:12760[D loss: 0.999963] [G loss: 1.000081]\n",
      "epoch:2 step:12765[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:2 step:12770[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:2 step:12775[D loss: 0.999968] [G loss: 1.000053]\n",
      "epoch:2 step:12780[D loss: 0.999972] [G loss: 1.000042]\n",
      "epoch:2 step:12785[D loss: 0.999967] [G loss: 1.000055]\n",
      "epoch:2 step:12790[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:2 step:12795[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:2 step:12800[D loss: 0.999971] [G loss: 1.000063]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.356216\n",
      "FID: 75.432739\n",
      "0 = 14.348828560400056\n",
      "1 = 0.07557798831746737\n",
      "2 = 0.9508000016212463\n",
      "3 = 0.9865999817848206\n",
      "4 = 0.9150000214576721\n",
      "5 = 0.9206793308258057\n",
      "6 = 0.9865999817848206\n",
      "7 = 11.647046247255764\n",
      "8 = 0.1764922280694215\n",
      "9 = 0.9362499713897705\n",
      "10 = 0.9394999742507935\n",
      "11 = 0.9330000281333923\n",
      "12 = 0.9334326982498169\n",
      "13 = 0.9394999742507935\n",
      "14 = 4.356236934661865\n",
      "15 = 8.65748405456543\n",
      "16 = 0.34323418140411377\n",
      "17 = 4.356215953826904\n",
      "18 = 75.4327392578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:12805[D loss: 0.999965] [G loss: 1.000058]\n",
      "epoch:2 step:12810[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:2 step:12815[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:2 step:12820[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:2 step:12825[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:2 step:12830[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:2 step:12835[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:2 step:12840[D loss: 0.999973] [G loss: 1.000048]\n",
      "epoch:2 step:12845[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:2 step:12850[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:2 step:12855[D loss: 1.000007] [G loss: 0.999990]\n",
      "epoch:2 step:12860[D loss: 0.999962] [G loss: 1.000065]\n",
      "epoch:2 step:12865[D loss: 0.999991] [G loss: 1.000040]\n",
      "epoch:2 step:12870[D loss: 1.000000] [G loss: 1.000040]\n",
      "epoch:2 step:12875[D loss: 1.000010] [G loss: 1.000019]\n",
      "epoch:2 step:12880[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:2 step:12885[D loss: 0.999964] [G loss: 1.000088]\n",
      "epoch:2 step:12890[D loss: 0.999964] [G loss: 1.000059]\n",
      "epoch:2 step:12895[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:2 step:12900[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:2 step:12905[D loss: 0.999994] [G loss: 1.000054]\n",
      "epoch:2 step:12910[D loss: 0.999986] [G loss: 1.000078]\n",
      "epoch:2 step:12915[D loss: 0.999987] [G loss: 1.000060]\n",
      "epoch:2 step:12920[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:2 step:12925[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:2 step:12930[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:2 step:12935[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:2 step:12940[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:2 step:12945[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:2 step:12950[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:2 step:12955[D loss: 0.999980] [G loss: 1.000044]\n",
      "epoch:2 step:12960[D loss: 0.999984] [G loss: 1.000038]\n",
      "epoch:2 step:12965[D loss: 0.999987] [G loss: 1.000019]\n",
      "epoch:2 step:12970[D loss: 0.999973] [G loss: 1.000047]\n",
      "epoch:2 step:12975[D loss: 0.999999] [G loss: 1.000002]\n",
      "epoch:2 step:12980[D loss: 0.999994] [G loss: 1.000017]\n",
      "epoch:2 step:12985[D loss: 0.999991] [G loss: 1.000024]\n",
      "epoch:2 step:12990[D loss: 0.999989] [G loss: 1.000061]\n",
      "epoch:2 step:12995[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:2 step:13000[D loss: 0.999969] [G loss: 1.000061]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.354060\n",
      "FID: 75.709579\n",
      "0 = 14.757175284290266\n",
      "1 = 0.08757607014378194\n",
      "2 = 0.9465500116348267\n",
      "3 = 0.9915000200271606\n",
      "4 = 0.9016000032424927\n",
      "5 = 0.9097164869308472\n",
      "6 = 0.9915000200271606\n",
      "7 = 11.600671177721043\n",
      "8 = 0.1773049333078614\n",
      "9 = 0.9343000054359436\n",
      "10 = 0.9345999956130981\n",
      "11 = 0.9340000152587891\n",
      "12 = 0.9340395927429199\n",
      "13 = 0.9345999956130981\n",
      "14 = 4.3540778160095215\n",
      "15 = 8.461612701416016\n",
      "16 = 0.35241276025772095\n",
      "17 = 4.354060173034668\n",
      "18 = 75.70957946777344\n",
      "epoch:2 step:13005[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:2 step:13010[D loss: 0.999962] [G loss: 1.000087]\n",
      "epoch:2 step:13015[D loss: 0.999963] [G loss: 1.000049]\n",
      "epoch:2 step:13020[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:2 step:13025[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:2 step:13030[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:2 step:13035[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:2 step:13040[D loss: 0.999977] [G loss: 1.000038]\n",
      "epoch:2 step:13045[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:2 step:13050[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:2 step:13055[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:2 step:13060[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:2 step:13065[D loss: 0.999964] [G loss: 1.000047]\n",
      "epoch:2 step:13070[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:2 step:13075[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:2 step:13080[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:2 step:13085[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:2 step:13090[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:2 step:13095[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:2 step:13100[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:2 step:13105[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:2 step:13110[D loss: 0.999967] [G loss: 1.000059]\n",
      "epoch:2 step:13115[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:2 step:13120[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:2 step:13125[D loss: 0.999959] [G loss: 1.000075]\n",
      "epoch:2 step:13130[D loss: 0.999987] [G loss: 1.000056]\n",
      "epoch:2 step:13135[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:2 step:13140[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:2 step:13145[D loss: 0.999982] [G loss: 1.000043]\n",
      "epoch:2 step:13150[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:2 step:13155[D loss: 0.999985] [G loss: 1.000041]\n",
      "epoch:2 step:13160[D loss: 0.999976] [G loss: 1.000038]\n",
      "epoch:2 step:13165[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:2 step:13170[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:2 step:13175[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:2 step:13180[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:2 step:13185[D loss: 0.999965] [G loss: 1.000056]\n",
      "epoch:2 step:13190[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:2 step:13195[D loss: 0.999976] [G loss: 1.000048]\n",
      "epoch:2 step:13200[D loss: 0.999972] [G loss: 1.000048]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.289224\n",
      "FID: 79.309662\n",
      "0 = 14.14544429464339\n",
      "1 = 0.05414420420167622\n",
      "2 = 0.9595500230789185\n",
      "3 = 0.9848999977111816\n",
      "4 = 0.9341999888420105\n",
      "5 = 0.9373750686645508\n",
      "6 = 0.9848999977111816\n",
      "7 = 11.818526723706707\n",
      "8 = 0.18235588759008997\n",
      "9 = 0.9376999735832214\n",
      "10 = 0.9409000277519226\n",
      "11 = 0.934499979019165\n",
      "12 = 0.9349165558815002\n",
      "13 = 0.9409000277519226\n",
      "14 = 4.289241790771484\n",
      "15 = 8.606063842773438\n",
      "16 = 0.3517078757286072\n",
      "17 = 4.289224147796631\n",
      "18 = 79.30966186523438\n",
      "epoch:2 step:13205[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:2 step:13210[D loss: 0.999987] [G loss: 1.000053]\n",
      "epoch:2 step:13215[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:2 step:13220[D loss: 0.999964] [G loss: 1.000062]\n",
      "epoch:2 step:13225[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:2 step:13230[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:2 step:13235[D loss: 0.999976] [G loss: 1.000050]\n",
      "epoch:2 step:13240[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:2 step:13245[D loss: 0.999985] [G loss: 1.000055]\n",
      "epoch:2 step:13250[D loss: 0.999978] [G loss: 1.000037]\n",
      "epoch:2 step:13255[D loss: 0.999976] [G loss: 1.000047]\n",
      "epoch:2 step:13260[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:2 step:13265[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:2 step:13270[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:2 step:13275[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:2 step:13280[D loss: 0.999992] [G loss: 1.000014]\n",
      "epoch:2 step:13285[D loss: 0.999971] [G loss: 1.000038]\n",
      "epoch:2 step:13290[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:2 step:13295[D loss: 0.999979] [G loss: 1.000038]\n",
      "epoch:2 step:13300[D loss: 0.999975] [G loss: 1.000045]\n",
      "epoch:2 step:13305[D loss: 0.999962] [G loss: 1.000072]\n",
      "epoch:2 step:13310[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:2 step:13315[D loss: 0.999961] [G loss: 1.000067]\n",
      "epoch:2 step:13320[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:2 step:13325[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:2 step:13330[D loss: 0.999997] [G loss: 1.000066]\n",
      "epoch:2 step:13335[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:2 step:13340[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:2 step:13345[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:2 step:13350[D loss: 0.999967] [G loss: 1.000085]\n",
      "epoch:2 step:13355[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:2 step:13360[D loss: 0.999978] [G loss: 1.000045]\n",
      "epoch:2 step:13365[D loss: 0.999981] [G loss: 1.000046]\n",
      "epoch:2 step:13370[D loss: 0.999988] [G loss: 1.000031]\n",
      "epoch:2 step:13375[D loss: 1.000009] [G loss: 0.999989]\n",
      "epoch:2 step:13380[D loss: 1.000005] [G loss: 1.000023]\n",
      "epoch:2 step:13385[D loss: 0.999992] [G loss: 1.000032]\n",
      "epoch:2 step:13390[D loss: 0.999943] [G loss: 1.000060]\n",
      "epoch:2 step:13395[D loss: 0.999950] [G loss: 1.000070]\n",
      "epoch:2 step:13400[D loss: 0.999966] [G loss: 1.000057]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.343694\n",
      "FID: 77.179741\n",
      "0 = 14.256728053236072\n",
      "1 = 0.05072957857919052\n",
      "2 = 0.9472000002861023\n",
      "3 = 0.9865999817848206\n",
      "4 = 0.907800018787384\n",
      "5 = 0.9145346879959106\n",
      "6 = 0.9865999817848206\n",
      "7 = 11.690770120310754\n",
      "8 = 0.179777703242109\n",
      "9 = 0.9376999735832214\n",
      "10 = 0.9387000203132629\n",
      "11 = 0.9366999864578247\n",
      "12 = 0.9368263483047485\n",
      "13 = 0.9387000203132629\n",
      "14 = 4.343713283538818\n",
      "15 = 8.500072479248047\n",
      "16 = 0.35585474967956543\n",
      "17 = 4.34369421005249\n",
      "18 = 77.17974090576172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:13405[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:2 step:13410[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:2 step:13415[D loss: 0.999991] [G loss: 1.000029]\n",
      "epoch:2 step:13420[D loss: 0.999959] [G loss: 1.000075]\n",
      "epoch:2 step:13425[D loss: 0.999969] [G loss: 1.000055]\n",
      "epoch:2 step:13430[D loss: 0.999962] [G loss: 1.000073]\n",
      "epoch:2 step:13435[D loss: 0.999964] [G loss: 1.000061]\n",
      "epoch:2 step:13440[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:2 step:13445[D loss: 0.999976] [G loss: 1.000045]\n",
      "epoch:2 step:13450[D loss: 0.999984] [G loss: 1.000043]\n",
      "epoch:2 step:13455[D loss: 0.999966] [G loss: 1.000062]\n",
      "epoch:2 step:13460[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:2 step:13465[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:2 step:13470[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:2 step:13475[D loss: 0.999981] [G loss: 1.000051]\n",
      "epoch:2 step:13480[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:2 step:13485[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:2 step:13490[D loss: 0.999975] [G loss: 1.000038]\n",
      "epoch:2 step:13495[D loss: 0.999977] [G loss: 1.000045]\n",
      "epoch:2 step:13500[D loss: 0.999965] [G loss: 1.000054]\n",
      "epoch:2 step:13505[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:2 step:13510[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:2 step:13515[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:2 step:13520[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:2 step:13525[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:2 step:13530[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:2 step:13535[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:2 step:13540[D loss: 0.999982] [G loss: 1.000043]\n",
      "epoch:2 step:13545[D loss: 0.999992] [G loss: 1.000043]\n",
      "epoch:2 step:13550[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:2 step:13555[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:2 step:13560[D loss: 0.999962] [G loss: 1.000062]\n",
      "epoch:2 step:13565[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:2 step:13570[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:2 step:13575[D loss: 0.999980] [G loss: 1.000042]\n",
      "epoch:2 step:13580[D loss: 0.999965] [G loss: 1.000058]\n",
      "epoch:2 step:13585[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:2 step:13590[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:2 step:13595[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:2 step:13600[D loss: 0.999987] [G loss: 1.000048]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.464284\n",
      "FID: 72.938034\n",
      "0 = 14.602995871496143\n",
      "1 = 0.07161106910174926\n",
      "2 = 0.9421499967575073\n",
      "3 = 0.9901000261306763\n",
      "4 = 0.8942000269889832\n",
      "5 = 0.9034583568572998\n",
      "6 = 0.9901000261306763\n",
      "7 = 11.535593068194396\n",
      "8 = 0.17448523971085098\n",
      "9 = 0.9344000220298767\n",
      "10 = 0.9376999735832214\n",
      "11 = 0.9311000108718872\n",
      "12 = 0.9315517544746399\n",
      "13 = 0.9376999735832214\n",
      "14 = 4.464303016662598\n",
      "15 = 8.501520156860352\n",
      "16 = 0.3483717739582062\n",
      "17 = 4.464284420013428\n",
      "18 = 72.93803405761719\n",
      "epoch:2 step:13605[D loss: 0.999964] [G loss: 1.000058]\n",
      "epoch:2 step:13610[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:2 step:13615[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:2 step:13620[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:2 step:13625[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:2 step:13630[D loss: 0.999988] [G loss: 1.000068]\n",
      "epoch:2 step:13635[D loss: 0.999983] [G loss: 1.000049]\n",
      "epoch:2 step:13640[D loss: 0.999981] [G loss: 1.000056]\n",
      "epoch:2 step:13645[D loss: 0.999987] [G loss: 1.000056]\n",
      "epoch:2 step:13650[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:2 step:13655[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:2 step:13660[D loss: 1.000000] [G loss: 1.000025]\n",
      "epoch:2 step:13665[D loss: 1.000002] [G loss: 1.000024]\n",
      "epoch:2 step:13670[D loss: 0.999984] [G loss: 1.000040]\n",
      "epoch:2 step:13675[D loss: 0.999963] [G loss: 1.000042]\n",
      "epoch:2 step:13680[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:2 step:13685[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:2 step:13690[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:2 step:13695[D loss: 0.999986] [G loss: 1.000072]\n",
      "epoch:2 step:13700[D loss: 0.999962] [G loss: 1.000080]\n",
      "epoch:2 step:13705[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:2 step:13710[D loss: 0.999967] [G loss: 1.000082]\n",
      "epoch:2 step:13715[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:2 step:13720[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:2 step:13725[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:2 step:13730[D loss: 0.999968] [G loss: 1.000059]\n",
      "epoch:2 step:13735[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:2 step:13740[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:2 step:13745[D loss: 0.999969] [G loss: 1.000044]\n",
      "epoch:2 step:13750[D loss: 0.999983] [G loss: 1.000043]\n",
      "epoch:2 step:13755[D loss: 0.999964] [G loss: 1.000045]\n",
      "epoch:2 step:13760[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:2 step:13765[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:2 step:13770[D loss: 0.999971] [G loss: 1.000047]\n",
      "epoch:2 step:13775[D loss: 0.999972] [G loss: 1.000049]\n",
      "epoch:2 step:13780[D loss: 0.999975] [G loss: 1.000039]\n",
      "epoch:2 step:13785[D loss: 0.999985] [G loss: 1.000030]\n",
      "epoch:2 step:13790[D loss: 0.999984] [G loss: 1.000018]\n",
      "epoch:2 step:13795[D loss: 1.000000] [G loss: 1.000056]\n",
      "epoch:2 step:13800[D loss: 1.000007] [G loss: 1.000040]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.171013\n",
      "FID: 84.326851\n",
      "0 = 14.219675718975047\n",
      "1 = 0.07858749819816684\n",
      "2 = 0.963100016117096\n",
      "3 = 0.9843000173568726\n",
      "4 = 0.9419000148773193\n",
      "5 = 0.944263219833374\n",
      "6 = 0.9843000173568726\n",
      "7 = 12.02530994334225\n",
      "8 = 0.19006186933579033\n",
      "9 = 0.9434999823570251\n",
      "10 = 0.9445000290870667\n",
      "11 = 0.9424999952316284\n",
      "12 = 0.9426147937774658\n",
      "13 = 0.9445000290870667\n",
      "14 = 4.171029090881348\n",
      "15 = 8.286699295043945\n",
      "16 = 0.3857733905315399\n",
      "17 = 4.171013355255127\n",
      "18 = 84.32685089111328\n",
      "epoch:2 step:13805[D loss: 1.000023] [G loss: 1.000070]\n",
      "epoch:2 step:13810[D loss: 0.999983] [G loss: 1.000078]\n",
      "epoch:2 step:13815[D loss: 1.000000] [G loss: 1.000054]\n",
      "epoch:2 step:13820[D loss: 0.999973] [G loss: 1.000103]\n",
      "epoch:2 step:13825[D loss: 0.999959] [G loss: 1.000076]\n",
      "epoch:2 step:13830[D loss: 0.999960] [G loss: 1.000077]\n",
      "epoch:2 step:13835[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:2 step:13840[D loss: 0.999969] [G loss: 1.000051]\n",
      "epoch:2 step:13845[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:2 step:13850[D loss: 0.999988] [G loss: 1.000036]\n",
      "epoch:2 step:13855[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:2 step:13860[D loss: 1.000019] [G loss: 0.999998]\n",
      "epoch:2 step:13865[D loss: 1.000039] [G loss: 1.000000]\n",
      "epoch:2 step:13870[D loss: 0.999972] [G loss: 1.000049]\n",
      "epoch:2 step:13875[D loss: 1.000046] [G loss: 0.999947]\n",
      "epoch:2 step:13880[D loss: 0.999959] [G loss: 1.000049]\n",
      "epoch:2 step:13885[D loss: 0.999990] [G loss: 1.000004]\n",
      "epoch:2 step:13890[D loss: 0.999927] [G loss: 1.000050]\n",
      "epoch:2 step:13895[D loss: 0.999949] [G loss: 1.000039]\n",
      "epoch:2 step:13900[D loss: 0.999954] [G loss: 1.000063]\n",
      "epoch:2 step:13905[D loss: 0.999967] [G loss: 1.000054]\n",
      "epoch:2 step:13910[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:2 step:13915[D loss: 0.999986] [G loss: 1.000031]\n",
      "epoch:2 step:13920[D loss: 0.999969] [G loss: 1.000047]\n",
      "epoch:2 step:13925[D loss: 0.999987] [G loss: 1.000040]\n",
      "epoch:2 step:13930[D loss: 1.000063] [G loss: 1.000011]\n",
      "epoch:2 step:13935[D loss: 0.999956] [G loss: 1.000102]\n",
      "epoch:2 step:13940[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:2 step:13945[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:2 step:13950[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:2 step:13955[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:2 step:13960[D loss: 0.999966] [G loss: 1.000067]\n",
      "epoch:2 step:13965[D loss: 0.999985] [G loss: 1.000048]\n",
      "epoch:2 step:13970[D loss: 0.999963] [G loss: 1.000061]\n",
      "epoch:2 step:13975[D loss: 0.999980] [G loss: 1.000051]\n",
      "epoch:2 step:13980[D loss: 0.999968] [G loss: 1.000057]\n",
      "epoch:2 step:13985[D loss: 0.999986] [G loss: 1.000054]\n",
      "epoch:2 step:13990[D loss: 0.999979] [G loss: 1.000047]\n",
      "epoch:2 step:13995[D loss: 0.999998] [G loss: 1.000034]\n",
      "epoch:2 step:14000[D loss: 1.000008] [G loss: 1.000046]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.620978\n",
      "FID: 69.239235\n",
      "0 = 15.110037256622313\n",
      "1 = 0.11856037861520337\n",
      "2 = 0.9362000226974487\n",
      "3 = 0.9943000078201294\n",
      "4 = 0.8780999779701233\n",
      "5 = 0.8907901644706726\n",
      "6 = 0.9943000078201294\n",
      "7 = 11.327972730326636\n",
      "8 = 0.16925831283822887\n",
      "9 = 0.9312999844551086\n",
      "10 = 0.9373000264167786\n",
      "11 = 0.9253000020980835\n",
      "12 = 0.9261857867240906\n",
      "13 = 0.9373000264167786\n",
      "14 = 4.621004104614258\n",
      "15 = 8.608449935913086\n",
      "16 = 0.3223614990711212\n",
      "17 = 4.620978355407715\n",
      "18 = 69.2392349243164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:14005[D loss: 0.999989] [G loss: 1.000057]\n",
      "epoch:2 step:14010[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:2 step:14015[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:2 step:14020[D loss: 0.999988] [G loss: 1.000003]\n",
      "epoch:2 step:14025[D loss: 0.999987] [G loss: 1.000015]\n",
      "epoch:2 step:14030[D loss: 0.999975] [G loss: 1.000039]\n",
      "epoch:2 step:14035[D loss: 0.999969] [G loss: 1.000051]\n",
      "epoch:2 step:14040[D loss: 0.999972] [G loss: 1.000038]\n",
      "epoch:2 step:14045[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:2 step:14050[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:2 step:14055[D loss: 0.999993] [G loss: 1.000054]\n",
      "epoch:3 step:14060[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:3 step:14065[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:3 step:14070[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:3 step:14075[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:3 step:14080[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:3 step:14085[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:3 step:14090[D loss: 0.999974] [G loss: 1.000039]\n",
      "epoch:3 step:14095[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:3 step:14100[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:3 step:14105[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:3 step:14110[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:3 step:14115[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:3 step:14120[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:3 step:14125[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:3 step:14130[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:3 step:14135[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:3 step:14140[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:3 step:14145[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:3 step:14150[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:3 step:14155[D loss: 0.999980] [G loss: 1.000041]\n",
      "epoch:3 step:14160[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:3 step:14165[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:3 step:14170[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:3 step:14175[D loss: 0.999980] [G loss: 1.000051]\n",
      "epoch:3 step:14180[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:3 step:14185[D loss: 0.999982] [G loss: 1.000045]\n",
      "epoch:3 step:14190[D loss: 0.999973] [G loss: 1.000044]\n",
      "epoch:3 step:14195[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:3 step:14200[D loss: 0.999973] [G loss: 1.000054]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.304894\n",
      "FID: 82.119705\n",
      "0 = 14.143337010049839\n",
      "1 = 0.08408438472134576\n",
      "2 = 0.9623500108718872\n",
      "3 = 0.9824000000953674\n",
      "4 = 0.942300021648407\n",
      "5 = 0.9445245862007141\n",
      "6 = 0.9824000000953674\n",
      "7 = 11.865396128594858\n",
      "8 = 0.18360024298691305\n",
      "9 = 0.9449499845504761\n",
      "10 = 0.9415000081062317\n",
      "11 = 0.9484000205993652\n",
      "12 = 0.9480414986610413\n",
      "13 = 0.9415000081062317\n",
      "14 = 4.30491304397583\n",
      "15 = 8.68820858001709\n",
      "16 = 0.3429042100906372\n",
      "17 = 4.304893970489502\n",
      "18 = 82.11970520019531\n",
      "epoch:3 step:14205[D loss: 0.999980] [G loss: 1.000044]\n",
      "epoch:3 step:14210[D loss: 0.999985] [G loss: 1.000044]\n",
      "epoch:3 step:14215[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:3 step:14220[D loss: 0.999982] [G loss: 1.000052]\n",
      "epoch:3 step:14225[D loss: 0.999985] [G loss: 1.000052]\n",
      "epoch:3 step:14230[D loss: 0.999995] [G loss: 1.000068]\n",
      "epoch:3 step:14235[D loss: 1.000005] [G loss: 1.000039]\n",
      "epoch:3 step:14240[D loss: 0.999960] [G loss: 1.000066]\n",
      "epoch:3 step:14245[D loss: 0.999963] [G loss: 1.000062]\n",
      "epoch:3 step:14250[D loss: 0.999967] [G loss: 1.000058]\n",
      "epoch:3 step:14255[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:3 step:14260[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:3 step:14265[D loss: 0.999970] [G loss: 1.000045]\n",
      "epoch:3 step:14270[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:3 step:14275[D loss: 0.999969] [G loss: 1.000057]\n",
      "epoch:3 step:14280[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:3 step:14285[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:3 step:14290[D loss: 0.999973] [G loss: 1.000035]\n",
      "epoch:3 step:14295[D loss: 0.999973] [G loss: 1.000038]\n",
      "epoch:3 step:14300[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:3 step:14305[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:3 step:14310[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:3 step:14315[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:3 step:14320[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:3 step:14325[D loss: 0.999980] [G loss: 1.000042]\n",
      "epoch:3 step:14330[D loss: 1.000001] [G loss: 1.000046]\n",
      "epoch:3 step:14335[D loss: 0.999966] [G loss: 1.000065]\n",
      "epoch:3 step:14340[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:3 step:14345[D loss: 0.999979] [G loss: 1.000046]\n",
      "epoch:3 step:14350[D loss: 0.999989] [G loss: 1.000036]\n",
      "epoch:3 step:14355[D loss: 0.999990] [G loss: 1.000019]\n",
      "epoch:3 step:14360[D loss: 0.999968] [G loss: 1.000023]\n",
      "epoch:3 step:14365[D loss: 0.999970] [G loss: 1.000034]\n",
      "epoch:3 step:14370[D loss: 0.999987] [G loss: 1.000020]\n",
      "epoch:3 step:14375[D loss: 0.999967] [G loss: 1.000052]\n",
      "epoch:3 step:14380[D loss: 0.999968] [G loss: 1.000040]\n",
      "epoch:3 step:14385[D loss: 0.999966] [G loss: 1.000064]\n",
      "epoch:3 step:14390[D loss: 0.999972] [G loss: 1.000049]\n",
      "epoch:3 step:14395[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:3 step:14400[D loss: 0.999971] [G loss: 1.000054]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.283350\n",
      "FID: 79.873199\n",
      "0 = 14.258282586574493\n",
      "1 = 0.06768641973110726\n",
      "2 = 0.955299973487854\n",
      "3 = 0.9850999712944031\n",
      "4 = 0.9254999756813049\n",
      "5 = 0.929690420627594\n",
      "6 = 0.9850999712944031\n",
      "7 = 11.807211356067688\n",
      "8 = 0.18600311403846667\n",
      "9 = 0.9388999938964844\n",
      "10 = 0.9408000111579895\n",
      "11 = 0.9369999766349792\n",
      "12 = 0.9372385144233704\n",
      "13 = 0.9408000111579895\n",
      "14 = 4.283371925354004\n",
      "15 = 8.378740310668945\n",
      "16 = 0.3708072900772095\n",
      "17 = 4.283350467681885\n",
      "18 = 79.87319946289062\n",
      "epoch:3 step:14405[D loss: 0.999975] [G loss: 1.000044]\n",
      "epoch:3 step:14410[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:3 step:14415[D loss: 0.999993] [G loss: 1.000024]\n",
      "epoch:3 step:14420[D loss: 0.999981] [G loss: 1.000035]\n",
      "epoch:3 step:14425[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:3 step:14430[D loss: 1.000032] [G loss: 1.000039]\n",
      "epoch:3 step:14435[D loss: 1.000015] [G loss: 1.000029]\n",
      "epoch:3 step:14440[D loss: 1.000015] [G loss: 1.000039]\n",
      "epoch:3 step:14445[D loss: 0.999953] [G loss: 1.000055]\n",
      "epoch:3 step:14450[D loss: 0.999957] [G loss: 1.000059]\n",
      "epoch:3 step:14455[D loss: 0.999964] [G loss: 1.000068]\n",
      "epoch:3 step:14460[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:3 step:14465[D loss: 0.999987] [G loss: 1.000052]\n",
      "epoch:3 step:14470[D loss: 0.999981] [G loss: 1.000040]\n",
      "epoch:3 step:14475[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:3 step:14480[D loss: 0.999983] [G loss: 1.000017]\n",
      "epoch:3 step:14485[D loss: 0.999991] [G loss: 1.000070]\n",
      "epoch:3 step:14490[D loss: 0.999966] [G loss: 1.000050]\n",
      "epoch:3 step:14495[D loss: 1.000001] [G loss: 1.000025]\n",
      "epoch:3 step:14500[D loss: 0.999986] [G loss: 1.000048]\n",
      "epoch:3 step:14505[D loss: 0.999991] [G loss: 1.000014]\n",
      "epoch:3 step:14510[D loss: 1.000011] [G loss: 1.000039]\n",
      "epoch:3 step:14515[D loss: 0.999965] [G loss: 1.000088]\n",
      "epoch:3 step:14520[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:3 step:14525[D loss: 0.999986] [G loss: 1.000092]\n",
      "epoch:3 step:14530[D loss: 0.999955] [G loss: 1.000105]\n",
      "epoch:3 step:14535[D loss: 0.999967] [G loss: 1.000101]\n",
      "epoch:3 step:14540[D loss: 0.999971] [G loss: 1.000095]\n",
      "epoch:3 step:14545[D loss: 0.999962] [G loss: 1.000097]\n",
      "epoch:3 step:14550[D loss: 0.999962] [G loss: 1.000093]\n",
      "epoch:3 step:14555[D loss: 0.999965] [G loss: 1.000074]\n",
      "epoch:3 step:14560[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:3 step:14565[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:3 step:14570[D loss: 0.999977] [G loss: 1.000045]\n",
      "epoch:3 step:14575[D loss: 0.999972] [G loss: 1.000046]\n",
      "epoch:3 step:14580[D loss: 0.999984] [G loss: 1.000034]\n",
      "epoch:3 step:14585[D loss: 0.999984] [G loss: 1.000006]\n",
      "epoch:3 step:14590[D loss: 0.999971] [G loss: 1.000036]\n",
      "epoch:3 step:14595[D loss: 0.999969] [G loss: 1.000050]\n",
      "epoch:3 step:14600[D loss: 0.999972] [G loss: 1.000051]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.139042\n",
      "FID: 88.256401\n",
      "0 = 14.060379428863522\n",
      "1 = 0.10364049900966872\n",
      "2 = 0.9617999792098999\n",
      "3 = 0.9818000197410583\n",
      "4 = 0.9417999982833862\n",
      "5 = 0.944038450717926\n",
      "6 = 0.9818000197410583\n",
      "7 = 12.13408064324858\n",
      "8 = 0.1928213320893298\n",
      "9 = 0.9453499913215637\n",
      "10 = 0.9452999830245972\n",
      "11 = 0.9453999996185303\n",
      "12 = 0.9453945159912109\n",
      "13 = 0.9452999830245972\n",
      "14 = 4.1390604972839355\n",
      "15 = 8.475879669189453\n",
      "16 = 0.37050700187683105\n",
      "17 = 4.139042377471924\n",
      "18 = 88.25640106201172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:14605[D loss: 0.999992] [G loss: 1.000054]\n",
      "epoch:3 step:14610[D loss: 0.999972] [G loss: 1.000043]\n",
      "epoch:3 step:14615[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:3 step:14620[D loss: 0.999965] [G loss: 1.000059]\n",
      "epoch:3 step:14625[D loss: 0.999966] [G loss: 1.000077]\n",
      "epoch:3 step:14630[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:3 step:14635[D loss: 0.999966] [G loss: 1.000057]\n",
      "epoch:3 step:14640[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:3 step:14645[D loss: 0.999976] [G loss: 1.000047]\n",
      "epoch:3 step:14650[D loss: 0.999975] [G loss: 1.000044]\n",
      "epoch:3 step:14655[D loss: 0.999963] [G loss: 1.000064]\n",
      "epoch:3 step:14660[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:3 step:14665[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:3 step:14670[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:3 step:14675[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:3 step:14680[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:3 step:14685[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:3 step:14690[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:3 step:14695[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:3 step:14700[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:3 step:14705[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:3 step:14710[D loss: 0.999985] [G loss: 1.000046]\n",
      "epoch:3 step:14715[D loss: 0.999987] [G loss: 1.000046]\n",
      "epoch:3 step:14720[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:3 step:14725[D loss: 0.999967] [G loss: 1.000062]\n",
      "epoch:3 step:14730[D loss: 0.999958] [G loss: 1.000071]\n",
      "epoch:3 step:14735[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:3 step:14740[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:3 step:14745[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:3 step:14750[D loss: 0.999984] [G loss: 1.000040]\n",
      "epoch:3 step:14755[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:3 step:14760[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:3 step:14765[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:3 step:14770[D loss: 0.999968] [G loss: 1.000056]\n",
      "epoch:3 step:14775[D loss: 0.999986] [G loss: 1.000048]\n",
      "epoch:3 step:14780[D loss: 0.999986] [G loss: 1.000019]\n",
      "epoch:3 step:14785[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:3 step:14790[D loss: 0.999973] [G loss: 1.000046]\n",
      "epoch:3 step:14795[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:3 step:14800[D loss: 1.000005] [G loss: 1.000029]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.608607\n",
      "FID: 70.285545\n",
      "0 = 14.550303102445593\n",
      "1 = 0.07560322093258236\n",
      "2 = 0.9379000067710876\n",
      "3 = 0.9907000064849854\n",
      "4 = 0.8851000070571899\n",
      "5 = 0.8960745334625244\n",
      "6 = 0.9907000064849854\n",
      "7 = 11.392836092805801\n",
      "8 = 0.1681304862676536\n",
      "9 = 0.9304500222206116\n",
      "10 = 0.9355000257492065\n",
      "11 = 0.9254000186920166\n",
      "12 = 0.9261459112167358\n",
      "13 = 0.9355000257492065\n",
      "14 = 4.6086273193359375\n",
      "15 = 8.877144813537598\n",
      "16 = 0.311381995677948\n",
      "17 = 4.608607292175293\n",
      "18 = 70.2855453491211\n",
      "epoch:3 step:14805[D loss: 0.999994] [G loss: 1.000047]\n",
      "epoch:3 step:14810[D loss: 1.000007] [G loss: 1.000036]\n",
      "epoch:3 step:14815[D loss: 1.000034] [G loss: 1.000033]\n",
      "epoch:3 step:14820[D loss: 0.999959] [G loss: 1.000043]\n",
      "epoch:3 step:14825[D loss: 0.999953] [G loss: 1.000062]\n",
      "epoch:3 step:14830[D loss: 0.999960] [G loss: 1.000063]\n",
      "epoch:3 step:14835[D loss: 0.999965] [G loss: 1.000063]\n",
      "epoch:3 step:14840[D loss: 0.999964] [G loss: 1.000050]\n",
      "epoch:3 step:14845[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:3 step:14850[D loss: 0.999986] [G loss: 1.000039]\n",
      "epoch:3 step:14855[D loss: 0.999982] [G loss: 1.000053]\n",
      "epoch:3 step:14860[D loss: 0.999994] [G loss: 1.000018]\n",
      "epoch:3 step:14865[D loss: 0.999980] [G loss: 1.000042]\n",
      "epoch:3 step:14870[D loss: 0.999971] [G loss: 1.000048]\n",
      "epoch:3 step:14875[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:3 step:14880[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:3 step:14885[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:3 step:14890[D loss: 0.999984] [G loss: 1.000019]\n",
      "epoch:3 step:14895[D loss: 0.999966] [G loss: 1.000049]\n",
      "epoch:3 step:14900[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:3 step:14905[D loss: 0.999972] [G loss: 1.000048]\n",
      "epoch:3 step:14910[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:3 step:14915[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:3 step:14920[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:3 step:14925[D loss: 0.999965] [G loss: 1.000062]\n",
      "epoch:3 step:14930[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:3 step:14935[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:3 step:14940[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:3 step:14945[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:3 step:14950[D loss: 0.999976] [G loss: 1.000048]\n",
      "epoch:3 step:14955[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:3 step:14960[D loss: 0.999989] [G loss: 1.000048]\n",
      "epoch:3 step:14965[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:3 step:14970[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:3 step:14975[D loss: 0.999988] [G loss: 1.000073]\n",
      "epoch:3 step:14980[D loss: 0.999959] [G loss: 1.000077]\n",
      "epoch:3 step:14985[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:3 step:14990[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:3 step:14995[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:3 step:15000[D loss: 0.999967] [G loss: 1.000070]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.597364\n",
      "FID: 71.391281\n",
      "0 = 14.438116290092466\n",
      "1 = 0.08869599001829061\n",
      "2 = 0.9431999921798706\n",
      "3 = 0.988099992275238\n",
      "4 = 0.8982999920845032\n",
      "5 = 0.9066801071166992\n",
      "6 = 0.988099992275238\n",
      "7 = 11.364138776981855\n",
      "8 = 0.1699951715344637\n",
      "9 = 0.932449996471405\n",
      "10 = 0.9354000091552734\n",
      "11 = 0.9294999837875366\n",
      "12 = 0.9299135208129883\n",
      "13 = 0.9354000091552734\n",
      "14 = 4.59738826751709\n",
      "15 = 8.889723777770996\n",
      "16 = 0.3029778003692627\n",
      "17 = 4.59736442565918\n",
      "18 = 71.39128112792969\n",
      "epoch:3 step:15005[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:3 step:15010[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:3 step:15015[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:3 step:15020[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:3 step:15025[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:3 step:15030[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:3 step:15035[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:3 step:15040[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:3 step:15045[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:3 step:15050[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:3 step:15055[D loss: 0.999989] [G loss: 1.000039]\n",
      "epoch:3 step:15060[D loss: 0.999986] [G loss: 1.000031]\n",
      "epoch:3 step:15065[D loss: 0.999982] [G loss: 1.000018]\n",
      "epoch:3 step:15070[D loss: 0.999961] [G loss: 1.000060]\n",
      "epoch:3 step:15075[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:3 step:15080[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:3 step:15085[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:3 step:15090[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:3 step:15095[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:3 step:15100[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:3 step:15105[D loss: 0.999968] [G loss: 1.000059]\n",
      "epoch:3 step:15110[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:3 step:15115[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:3 step:15120[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:3 step:15125[D loss: 0.999967] [G loss: 1.000048]\n",
      "epoch:3 step:15130[D loss: 0.999974] [G loss: 1.000037]\n",
      "epoch:3 step:15135[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:3 step:15140[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:3 step:15145[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:3 step:15150[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:3 step:15155[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:3 step:15160[D loss: 0.999997] [G loss: 1.000024]\n",
      "epoch:3 step:15165[D loss: 1.000010] [G loss: 1.000034]\n",
      "epoch:3 step:15170[D loss: 1.000015] [G loss: 1.000047]\n",
      "epoch:3 step:15175[D loss: 0.999984] [G loss: 1.000014]\n",
      "epoch:3 step:15180[D loss: 0.999962] [G loss: 1.000054]\n",
      "epoch:3 step:15185[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:3 step:15190[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:3 step:15195[D loss: 0.999976] [G loss: 1.000040]\n",
      "epoch:3 step:15200[D loss: 0.999989] [G loss: 1.000041]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.244510\n",
      "FID: 84.327545\n",
      "0 = 14.295706612777732\n",
      "1 = 0.09440132228765762\n",
      "2 = 0.9612500071525574\n",
      "3 = 0.9825999736785889\n",
      "4 = 0.9398999810218811\n",
      "5 = 0.9423611760139465\n",
      "6 = 0.9825999736785889\n",
      "7 = 12.0453039434314\n",
      "8 = 0.1879213684689261\n",
      "9 = 0.942300021648407\n",
      "10 = 0.9434000253677368\n",
      "11 = 0.9412000179290771\n",
      "12 = 0.9413290619850159\n",
      "13 = 0.9434000253677368\n",
      "14 = 4.244529724121094\n",
      "15 = 8.573593139648438\n",
      "16 = 0.3598145544528961\n",
      "17 = 4.244510173797607\n",
      "18 = 84.32754516601562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:15205[D loss: 1.000032] [G loss: 1.000060]\n",
      "epoch:3 step:15210[D loss: 1.000014] [G loss: 1.000068]\n",
      "epoch:3 step:15215[D loss: 1.000038] [G loss: 1.000064]\n",
      "epoch:3 step:15220[D loss: 0.999960] [G loss: 1.000071]\n",
      "epoch:3 step:15225[D loss: 0.999944] [G loss: 1.000087]\n",
      "epoch:3 step:15230[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:3 step:15235[D loss: 0.999964] [G loss: 1.000059]\n",
      "epoch:3 step:15240[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:3 step:15245[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:3 step:15250[D loss: 0.999973] [G loss: 1.000030]\n",
      "epoch:3 step:15255[D loss: 0.999977] [G loss: 1.000038]\n",
      "epoch:3 step:15260[D loss: 0.999989] [G loss: 1.000013]\n",
      "epoch:3 step:15265[D loss: 0.999997] [G loss: 1.000023]\n",
      "epoch:3 step:15270[D loss: 0.999973] [G loss: 1.000046]\n",
      "epoch:3 step:15275[D loss: 0.999994] [G loss: 1.000018]\n",
      "epoch:3 step:15280[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:3 step:15285[D loss: 0.999985] [G loss: 1.000019]\n",
      "epoch:3 step:15290[D loss: 0.999984] [G loss: 1.000048]\n",
      "epoch:3 step:15295[D loss: 0.999959] [G loss: 1.000082]\n",
      "epoch:3 step:15300[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:3 step:15305[D loss: 1.000030] [G loss: 1.000057]\n",
      "epoch:3 step:15310[D loss: 0.999988] [G loss: 1.000087]\n",
      "epoch:3 step:15315[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:3 step:15320[D loss: 0.999957] [G loss: 1.000091]\n",
      "epoch:3 step:15325[D loss: 0.999962] [G loss: 1.000102]\n",
      "epoch:3 step:15330[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:3 step:15335[D loss: 0.999963] [G loss: 1.000081]\n",
      "epoch:3 step:15340[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:3 step:15345[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:3 step:15350[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:3 step:15355[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:3 step:15360[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:3 step:15365[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:3 step:15370[D loss: 0.999969] [G loss: 1.000048]\n",
      "epoch:3 step:15375[D loss: 0.999979] [G loss: 1.000041]\n",
      "epoch:3 step:15380[D loss: 0.999970] [G loss: 1.000047]\n",
      "epoch:3 step:15385[D loss: 0.999965] [G loss: 1.000054]\n",
      "epoch:3 step:15390[D loss: 0.999978] [G loss: 1.000050]\n",
      "epoch:3 step:15395[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:3 step:15400[D loss: 0.999972] [G loss: 1.000055]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.385545\n",
      "FID: 77.496498\n",
      "0 = 14.286701006269476\n",
      "1 = 0.05984185039005285\n",
      "2 = 0.9447000026702881\n",
      "3 = 0.9868000149726868\n",
      "4 = 0.9025999903678894\n",
      "5 = 0.9101641774177551\n",
      "6 = 0.9868000149726868\n",
      "7 = 11.691419850182548\n",
      "8 = 0.18334001904637007\n",
      "9 = 0.9339500069618225\n",
      "10 = 0.9368000030517578\n",
      "11 = 0.9311000108718872\n",
      "12 = 0.9314904808998108\n",
      "13 = 0.9368000030517578\n",
      "14 = 4.385566711425781\n",
      "15 = 8.463808059692383\n",
      "16 = 0.3539762794971466\n",
      "17 = 4.385544776916504\n",
      "18 = 77.49649810791016\n",
      "epoch:3 step:15405[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:3 step:15410[D loss: 0.999983] [G loss: 1.000039]\n",
      "epoch:3 step:15415[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:3 step:15420[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:3 step:15425[D loss: 0.999971] [G loss: 1.000050]\n",
      "epoch:3 step:15430[D loss: 0.999978] [G loss: 1.000048]\n",
      "epoch:3 step:15435[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:3 step:15440[D loss: 0.999968] [G loss: 1.000059]\n",
      "epoch:3 step:15445[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:3 step:15450[D loss: 0.999991] [G loss: 1.000054]\n",
      "epoch:3 step:15455[D loss: 0.999985] [G loss: 1.000060]\n",
      "epoch:3 step:15460[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:3 step:15465[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:3 step:15470[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:3 step:15475[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:3 step:15480[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:3 step:15485[D loss: 0.999980] [G loss: 1.000045]\n",
      "epoch:3 step:15490[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:3 step:15495[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:3 step:15500[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:3 step:15505[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:3 step:15510[D loss: 0.999963] [G loss: 1.000066]\n",
      "epoch:3 step:15515[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:3 step:15520[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:3 step:15525[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:3 step:15530[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:3 step:15535[D loss: 0.999977] [G loss: 1.000038]\n",
      "epoch:3 step:15540[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:3 step:15545[D loss: 0.999999] [G loss: 1.000026]\n",
      "epoch:3 step:15550[D loss: 0.999989] [G loss: 1.000044]\n",
      "epoch:3 step:15555[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:3 step:15560[D loss: 0.999966] [G loss: 1.000064]\n",
      "epoch:3 step:15565[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:3 step:15570[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:3 step:15575[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:3 step:15580[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:3 step:15585[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:3 step:15590[D loss: 0.999965] [G loss: 1.000063]\n",
      "epoch:3 step:15595[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:3 step:15600[D loss: 0.999978] [G loss: 1.000069]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.670513\n",
      "FID: 66.790733\n",
      "0 = 14.804391188621521\n",
      "1 = 0.1047331980702162\n",
      "2 = 0.9351000189781189\n",
      "3 = 0.9922000169754028\n",
      "4 = 0.878000020980835\n",
      "5 = 0.8905044198036194\n",
      "6 = 0.9922000169754028\n",
      "7 = 11.212251612961287\n",
      "8 = 0.16468076920191405\n",
      "9 = 0.927049994468689\n",
      "10 = 0.9298999905586243\n",
      "11 = 0.9241999983787537\n",
      "12 = 0.9246296286582947\n",
      "13 = 0.9298999905586243\n",
      "14 = 4.67053747177124\n",
      "15 = 8.924283027648926\n",
      "16 = 0.30117321014404297\n",
      "17 = 4.670512676239014\n",
      "18 = 66.79073333740234\n",
      "epoch:3 step:15605[D loss: 1.000013] [G loss: 1.000008]\n",
      "epoch:3 step:15610[D loss: 0.999986] [G loss: 1.000065]\n",
      "epoch:3 step:15615[D loss: 1.000068] [G loss: 0.999996]\n",
      "epoch:3 step:15620[D loss: 1.000000] [G loss: 1.000073]\n",
      "epoch:3 step:15625[D loss: 1.000023] [G loss: 1.000023]\n",
      "epoch:3 step:15630[D loss: 1.000046] [G loss: 0.999998]\n",
      "epoch:3 step:15635[D loss: 0.999948] [G loss: 1.000041]\n",
      "epoch:3 step:15640[D loss: 0.999963] [G loss: 1.000052]\n",
      "epoch:3 step:15645[D loss: 0.999961] [G loss: 1.000065]\n",
      "epoch:3 step:15650[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:3 step:15655[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:3 step:15660[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:3 step:15665[D loss: 0.999986] [G loss: 1.000030]\n",
      "epoch:3 step:15670[D loss: 0.999970] [G loss: 1.000039]\n",
      "epoch:3 step:15675[D loss: 0.999970] [G loss: 1.000041]\n",
      "epoch:3 step:15680[D loss: 1.000011] [G loss: 1.000021]\n",
      "epoch:3 step:15685[D loss: 1.000036] [G loss: 1.000000]\n",
      "epoch:3 step:15690[D loss: 1.000050] [G loss: 1.000036]\n",
      "epoch:3 step:15695[D loss: 0.999991] [G loss: 1.000012]\n",
      "epoch:3 step:15700[D loss: 1.000001] [G loss: 1.000057]\n",
      "epoch:3 step:15705[D loss: 0.999962] [G loss: 1.000084]\n",
      "epoch:3 step:15710[D loss: 0.999959] [G loss: 1.000071]\n",
      "epoch:3 step:15715[D loss: 0.999950] [G loss: 1.000104]\n",
      "epoch:3 step:15720[D loss: 0.999967] [G loss: 1.000041]\n",
      "epoch:3 step:15725[D loss: 0.999967] [G loss: 1.000048]\n",
      "epoch:3 step:15730[D loss: 0.999958] [G loss: 1.000069]\n",
      "epoch:3 step:15735[D loss: 0.999967] [G loss: 1.000058]\n",
      "epoch:3 step:15740[D loss: 0.999966] [G loss: 1.000068]\n",
      "epoch:3 step:15745[D loss: 0.999967] [G loss: 1.000053]\n",
      "epoch:3 step:15750[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:3 step:15755[D loss: 0.999974] [G loss: 1.000048]\n",
      "epoch:3 step:15760[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:3 step:15765[D loss: 0.999988] [G loss: 1.000050]\n",
      "epoch:3 step:15770[D loss: 1.000010] [G loss: 1.000014]\n",
      "epoch:3 step:15775[D loss: 1.000009] [G loss: 0.999981]\n",
      "epoch:3 step:15780[D loss: 1.000027] [G loss: 0.999974]\n",
      "epoch:3 step:15785[D loss: 1.000097] [G loss: 0.999949]\n",
      "epoch:3 step:15790[D loss: 1.000095] [G loss: 0.999968]\n",
      "epoch:3 step:15795[D loss: 0.999985] [G loss: 0.999938]\n",
      "epoch:3 step:15800[D loss: 0.999930] [G loss: 1.000044]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.464414\n",
      "FID: 74.886292\n",
      "0 = 14.285977033472053\n",
      "1 = 0.05581270415641465\n",
      "2 = 0.949400007724762\n",
      "3 = 0.9853000044822693\n",
      "4 = 0.9135000109672546\n",
      "5 = 0.9192946553230286\n",
      "6 = 0.9853000044822693\n",
      "7 = 11.613698898708863\n",
      "8 = 0.1778493655961599\n",
      "9 = 0.9366000294685364\n",
      "10 = 0.9391000270843506\n",
      "11 = 0.9340999722480774\n",
      "12 = 0.9344278573989868\n",
      "13 = 0.9391000270843506\n",
      "14 = 4.4644365310668945\n",
      "15 = 8.714261054992676\n",
      "16 = 0.3339794874191284\n",
      "17 = 4.464414119720459\n",
      "18 = 74.88629150390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:15805[D loss: 0.999946] [G loss: 1.000048]\n",
      "epoch:3 step:15810[D loss: 0.999950] [G loss: 1.000057]\n",
      "epoch:3 step:15815[D loss: 0.999961] [G loss: 1.000058]\n",
      "epoch:3 step:15820[D loss: 0.999958] [G loss: 1.000050]\n",
      "epoch:3 step:15825[D loss: 0.999980] [G loss: 1.000052]\n",
      "epoch:3 step:15830[D loss: 0.999980] [G loss: 1.000043]\n",
      "epoch:3 step:15835[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:3 step:15840[D loss: 0.999979] [G loss: 1.000033]\n",
      "epoch:3 step:15845[D loss: 0.999993] [G loss: 1.000050]\n",
      "epoch:3 step:15850[D loss: 0.999974] [G loss: 1.000026]\n",
      "epoch:3 step:15855[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:3 step:15860[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:3 step:15865[D loss: 0.999984] [G loss: 1.000056]\n",
      "epoch:3 step:15870[D loss: 0.999966] [G loss: 1.000081]\n",
      "epoch:3 step:15875[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:3 step:15880[D loss: 0.999966] [G loss: 1.000077]\n",
      "epoch:3 step:15885[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:3 step:15890[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:3 step:15895[D loss: 0.999967] [G loss: 1.000057]\n",
      "epoch:3 step:15900[D loss: 0.999976] [G loss: 1.000045]\n",
      "epoch:3 step:15905[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:3 step:15910[D loss: 0.999968] [G loss: 1.000059]\n",
      "epoch:3 step:15915[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:3 step:15920[D loss: 0.999969] [G loss: 1.000049]\n",
      "epoch:3 step:15925[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:3 step:15930[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:3 step:15935[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:3 step:15940[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:3 step:15945[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:3 step:15950[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:3 step:15955[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:3 step:15960[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:3 step:15965[D loss: 0.999964] [G loss: 1.000065]\n",
      "epoch:3 step:15970[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:3 step:15975[D loss: 0.999970] [G loss: 1.000051]\n",
      "epoch:3 step:15980[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:3 step:15985[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:3 step:15990[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:3 step:15995[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:3 step:16000[D loss: 0.999972] [G loss: 1.000054]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.575476\n",
      "FID: 71.522438\n",
      "0 = 14.126952674531964\n",
      "1 = 0.05087037701421486\n",
      "2 = 0.9488499760627747\n",
      "3 = 0.9837999939918518\n",
      "4 = 0.9139000177383423\n",
      "5 = 0.9195252060890198\n",
      "6 = 0.9837999939918518\n",
      "7 = 11.461433728456539\n",
      "8 = 0.1732531693514079\n",
      "9 = 0.9335500001907349\n",
      "10 = 0.9351999759674072\n",
      "11 = 0.9319000244140625\n",
      "12 = 0.9321240186691284\n",
      "13 = 0.9351999759674072\n",
      "14 = 4.57550048828125\n",
      "15 = 8.822516441345215\n",
      "16 = 0.3150465190410614\n",
      "17 = 4.575476169586182\n",
      "18 = 71.5224380493164\n",
      "epoch:3 step:16005[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:3 step:16010[D loss: 0.999965] [G loss: 1.000063]\n",
      "epoch:3 step:16015[D loss: 0.999971] [G loss: 1.000051]\n",
      "epoch:3 step:16020[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:3 step:16025[D loss: 0.999991] [G loss: 1.000035]\n",
      "epoch:3 step:16030[D loss: 0.999972] [G loss: 1.000047]\n",
      "epoch:3 step:16035[D loss: 1.000004] [G loss: 1.000033]\n",
      "epoch:3 step:16040[D loss: 1.000006] [G loss: 1.000033]\n",
      "epoch:3 step:16045[D loss: 1.000012] [G loss: 1.000021]\n",
      "epoch:3 step:16050[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:3 step:16055[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:3 step:16060[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:3 step:16065[D loss: 0.999986] [G loss: 1.000050]\n",
      "epoch:3 step:16070[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:3 step:16075[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:3 step:16080[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:3 step:16085[D loss: 0.999965] [G loss: 1.000063]\n",
      "epoch:3 step:16090[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:3 step:16095[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:3 step:16100[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:3 step:16105[D loss: 0.999984] [G loss: 1.000061]\n",
      "epoch:3 step:16110[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:3 step:16115[D loss: 0.999980] [G loss: 1.000042]\n",
      "epoch:3 step:16120[D loss: 0.999989] [G loss: 1.000040]\n",
      "epoch:3 step:16125[D loss: 0.999970] [G loss: 1.000051]\n",
      "epoch:3 step:16130[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:3 step:16135[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:3 step:16140[D loss: 0.999964] [G loss: 1.000069]\n",
      "epoch:3 step:16145[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:3 step:16150[D loss: 0.999983] [G loss: 1.000060]\n",
      "epoch:3 step:16155[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:3 step:16160[D loss: 0.999965] [G loss: 1.000072]\n",
      "epoch:3 step:16165[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:3 step:16170[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:3 step:16175[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:3 step:16180[D loss: 0.999993] [G loss: 1.000039]\n",
      "epoch:3 step:16185[D loss: 0.999992] [G loss: 1.000039]\n",
      "epoch:3 step:16190[D loss: 1.000006] [G loss: 1.000023]\n",
      "epoch:3 step:16195[D loss: 0.999999] [G loss: 1.000030]\n",
      "epoch:3 step:16200[D loss: 1.000002] [G loss: 1.000048]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.267497\n",
      "FID: 79.320610\n",
      "0 = 14.362896303129158\n",
      "1 = 0.06968493674999694\n",
      "2 = 0.9554499983787537\n",
      "3 = 0.9873999953269958\n",
      "4 = 0.9235000014305115\n",
      "5 = 0.928094744682312\n",
      "6 = 0.9873999953269958\n",
      "7 = 11.784379363083833\n",
      "8 = 0.1842713533447703\n",
      "9 = 0.9361500144004822\n",
      "10 = 0.9380999803543091\n",
      "11 = 0.9341999888420105\n",
      "12 = 0.9344556331634521\n",
      "13 = 0.9380999803543091\n",
      "14 = 4.267517566680908\n",
      "15 = 8.346990585327148\n",
      "16 = 0.37594977021217346\n",
      "17 = 4.267496585845947\n",
      "18 = 79.32061004638672\n",
      "epoch:3 step:16205[D loss: 0.999994] [G loss: 1.000055]\n",
      "epoch:3 step:16210[D loss: 0.999977] [G loss: 1.000047]\n",
      "epoch:3 step:16215[D loss: 0.999954] [G loss: 1.000068]\n",
      "epoch:3 step:16220[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:3 step:16225[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:3 step:16230[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:3 step:16235[D loss: 0.999970] [G loss: 1.000051]\n",
      "epoch:3 step:16240[D loss: 0.999979] [G loss: 1.000046]\n",
      "epoch:3 step:16245[D loss: 0.999980] [G loss: 1.000046]\n",
      "epoch:3 step:16250[D loss: 0.999987] [G loss: 1.000040]\n",
      "epoch:3 step:16255[D loss: 0.999973] [G loss: 1.000047]\n",
      "epoch:3 step:16260[D loss: 0.999991] [G loss: 1.000033]\n",
      "epoch:3 step:16265[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:3 step:16270[D loss: 0.999997] [G loss: 1.000006]\n",
      "epoch:3 step:16275[D loss: 0.999971] [G loss: 1.000046]\n",
      "epoch:3 step:16280[D loss: 0.999959] [G loss: 1.000079]\n",
      "epoch:3 step:16285[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:3 step:16290[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:3 step:16295[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:3 step:16300[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:3 step:16305[D loss: 0.999984] [G loss: 1.000071]\n",
      "epoch:3 step:16310[D loss: 0.999985] [G loss: 1.000047]\n",
      "epoch:3 step:16315[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:3 step:16320[D loss: 0.999981] [G loss: 1.000073]\n",
      "epoch:3 step:16325[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:3 step:16330[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:3 step:16335[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:3 step:16340[D loss: 0.999985] [G loss: 1.000069]\n",
      "epoch:3 step:16345[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:3 step:16350[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:3 step:16355[D loss: 0.999981] [G loss: 1.000046]\n",
      "epoch:3 step:16360[D loss: 0.999963] [G loss: 1.000049]\n",
      "epoch:3 step:16365[D loss: 0.999974] [G loss: 1.000039]\n",
      "epoch:3 step:16370[D loss: 0.999981] [G loss: 1.000040]\n",
      "epoch:3 step:16375[D loss: 0.999967] [G loss: 1.000056]\n",
      "epoch:3 step:16380[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:3 step:16385[D loss: 0.999974] [G loss: 1.000048]\n",
      "epoch:3 step:16390[D loss: 0.999967] [G loss: 1.000049]\n",
      "epoch:3 step:16395[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:3 step:16400[D loss: 0.999973] [G loss: 1.000060]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.236958\n",
      "FID: 83.906601\n",
      "0 = 13.996661326885224\n",
      "1 = 0.10640834901506697\n",
      "2 = 0.963699996471405\n",
      "3 = 0.9797999858856201\n",
      "4 = 0.9476000070571899\n",
      "5 = 0.949234664440155\n",
      "6 = 0.9797999858856201\n",
      "7 = 11.967351969969267\n",
      "8 = 0.18816923869661215\n",
      "9 = 0.9424999952316284\n",
      "10 = 0.9417999982833862\n",
      "11 = 0.9431999921798706\n",
      "12 = 0.9431203603744507\n",
      "13 = 0.9417999982833862\n",
      "14 = 4.2369771003723145\n",
      "15 = 8.579639434814453\n",
      "16 = 0.35684099793434143\n",
      "17 = 4.236958026885986\n",
      "18 = 83.90660095214844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:16405[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:3 step:16410[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:3 step:16415[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:3 step:16420[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:3 step:16425[D loss: 0.999974] [G loss: 1.000047]\n",
      "epoch:3 step:16430[D loss: 0.999995] [G loss: 1.000024]\n",
      "epoch:3 step:16435[D loss: 0.999990] [G loss: 1.000038]\n",
      "epoch:3 step:16440[D loss: 0.999961] [G loss: 1.000048]\n",
      "epoch:3 step:16445[D loss: 0.999974] [G loss: 1.000045]\n",
      "epoch:3 step:16450[D loss: 0.999978] [G loss: 1.000032]\n",
      "epoch:3 step:16455[D loss: 0.999979] [G loss: 1.000037]\n",
      "epoch:3 step:16460[D loss: 0.999968] [G loss: 1.000057]\n",
      "epoch:3 step:16465[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:3 step:16470[D loss: 0.999985] [G loss: 1.000041]\n",
      "epoch:3 step:16475[D loss: 0.999988] [G loss: 1.000044]\n",
      "epoch:3 step:16480[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:3 step:16485[D loss: 0.999964] [G loss: 1.000056]\n",
      "epoch:3 step:16490[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:3 step:16495[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:3 step:16500[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:3 step:16505[D loss: 0.999985] [G loss: 1.000045]\n",
      "epoch:3 step:16510[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:3 step:16515[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:3 step:16520[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:3 step:16525[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:3 step:16530[D loss: 0.999968] [G loss: 1.000049]\n",
      "epoch:3 step:16535[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:3 step:16540[D loss: 0.999985] [G loss: 1.000055]\n",
      "epoch:3 step:16545[D loss: 0.999999] [G loss: 1.000036]\n",
      "epoch:3 step:16550[D loss: 1.000002] [G loss: 1.000031]\n",
      "epoch:3 step:16555[D loss: 0.999964] [G loss: 1.000041]\n",
      "epoch:3 step:16560[D loss: 0.999965] [G loss: 1.000056]\n",
      "epoch:3 step:16565[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:3 step:16570[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:3 step:16575[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:3 step:16580[D loss: 0.999978] [G loss: 1.000045]\n",
      "epoch:3 step:16585[D loss: 0.999992] [G loss: 1.000067]\n",
      "epoch:3 step:16590[D loss: 0.999994] [G loss: 1.000036]\n",
      "epoch:3 step:16595[D loss: 1.000042] [G loss: 1.000000]\n",
      "epoch:3 step:16600[D loss: 0.999958] [G loss: 1.000061]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.558820\n",
      "FID: 72.120430\n",
      "0 = 14.022406533622757\n",
      "1 = 0.060345715483348654\n",
      "2 = 0.9538999795913696\n",
      "3 = 0.9837999939918518\n",
      "4 = 0.9240000247955322\n",
      "5 = 0.9282883405685425\n",
      "6 = 0.9837999939918518\n",
      "7 = 11.437651584911327\n",
      "8 = 0.1722200571286416\n",
      "9 = 0.9369000196456909\n",
      "10 = 0.940500020980835\n",
      "11 = 0.9333000183105469\n",
      "12 = 0.9337767958641052\n",
      "13 = 0.940500020980835\n",
      "14 = 4.558840274810791\n",
      "15 = 8.966456413269043\n",
      "16 = 0.3016584515571594\n",
      "17 = 4.5588202476501465\n",
      "18 = 72.12042999267578\n",
      "epoch:3 step:16605[D loss: 0.999962] [G loss: 1.000058]\n",
      "epoch:3 step:16610[D loss: 0.999955] [G loss: 1.000053]\n",
      "epoch:3 step:16615[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:3 step:16620[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:3 step:16625[D loss: 0.999977] [G loss: 1.000042]\n",
      "epoch:3 step:16630[D loss: 0.999981] [G loss: 1.000043]\n",
      "epoch:3 step:16635[D loss: 0.999978] [G loss: 1.000032]\n",
      "epoch:3 step:16640[D loss: 0.999975] [G loss: 1.000033]\n",
      "epoch:3 step:16645[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:3 step:16650[D loss: 0.999965] [G loss: 1.000058]\n",
      "epoch:3 step:16655[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:3 step:16660[D loss: 0.999975] [G loss: 1.000036]\n",
      "epoch:3 step:16665[D loss: 0.999971] [G loss: 1.000044]\n",
      "epoch:3 step:16670[D loss: 0.999977] [G loss: 1.000049]\n",
      "epoch:3 step:16675[D loss: 0.999970] [G loss: 1.000046]\n",
      "epoch:3 step:16680[D loss: 0.999976] [G loss: 1.000050]\n",
      "epoch:3 step:16685[D loss: 0.999979] [G loss: 1.000043]\n",
      "epoch:3 step:16690[D loss: 0.999972] [G loss: 1.000030]\n",
      "epoch:3 step:16695[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:3 step:16700[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:3 step:16705[D loss: 0.999965] [G loss: 1.000057]\n",
      "epoch:3 step:16710[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:3 step:16715[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:3 step:16720[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:3 step:16725[D loss: 0.999964] [G loss: 1.000056]\n",
      "epoch:3 step:16730[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:3 step:16735[D loss: 0.999972] [G loss: 1.000047]\n",
      "epoch:3 step:16740[D loss: 0.999981] [G loss: 1.000047]\n",
      "epoch:3 step:16745[D loss: 0.999977] [G loss: 1.000042]\n",
      "epoch:3 step:16750[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:3 step:16755[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:3 step:16760[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:3 step:16765[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:3 step:16770[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:3 step:16775[D loss: 0.999982] [G loss: 1.000051]\n",
      "epoch:3 step:16780[D loss: 0.999982] [G loss: 1.000062]\n",
      "epoch:3 step:16785[D loss: 1.000003] [G loss: 1.000054]\n",
      "epoch:3 step:16790[D loss: 1.000002] [G loss: 1.000047]\n",
      "epoch:3 step:16795[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:3 step:16800[D loss: 0.999987] [G loss: 1.000082]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.564333\n",
      "FID: 72.498070\n",
      "0 = 14.460131404686013\n",
      "1 = 0.07949167762236661\n",
      "2 = 0.9466000199317932\n",
      "3 = 0.989799976348877\n",
      "4 = 0.9034000039100647\n",
      "5 = 0.9110824465751648\n",
      "6 = 0.989799976348877\n",
      "7 = 11.415113966882256\n",
      "8 = 0.17354466332286533\n",
      "9 = 0.9361000061035156\n",
      "10 = 0.9379000067710876\n",
      "11 = 0.9343000054359436\n",
      "12 = 0.9345356822013855\n",
      "13 = 0.9379000067710876\n",
      "14 = 4.564352512359619\n",
      "15 = 8.875255584716797\n",
      "16 = 0.3052118122577667\n",
      "17 = 4.564333438873291\n",
      "18 = 72.4980697631836\n",
      "epoch:3 step:16805[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:3 step:16810[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:3 step:16815[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:3 step:16820[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:3 step:16825[D loss: 0.999964] [G loss: 1.000089]\n",
      "epoch:3 step:16830[D loss: 0.999955] [G loss: 1.000091]\n",
      "epoch:3 step:16835[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:3 step:16840[D loss: 0.999975] [G loss: 1.000082]\n",
      "epoch:3 step:16845[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:3 step:16850[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:3 step:16855[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:3 step:16860[D loss: 0.999981] [G loss: 1.000026]\n",
      "epoch:3 step:16865[D loss: 1.000015] [G loss: 0.999956]\n",
      "epoch:3 step:16870[D loss: 1.000004] [G loss: 0.999958]\n",
      "epoch:3 step:16875[D loss: 1.000001] [G loss: 0.999971]\n",
      "epoch:3 step:16880[D loss: 0.999983] [G loss: 1.000021]\n",
      "epoch:3 step:16885[D loss: 1.000037] [G loss: 1.000050]\n",
      "epoch:3 step:16890[D loss: 1.000049] [G loss: 0.999976]\n",
      "epoch:3 step:16895[D loss: 1.000040] [G loss: 1.000024]\n",
      "epoch:3 step:16900[D loss: 0.999919] [G loss: 1.000067]\n",
      "epoch:3 step:16905[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:3 step:16910[D loss: 0.999956] [G loss: 1.000072]\n",
      "epoch:3 step:16915[D loss: 0.999962] [G loss: 1.000074]\n",
      "epoch:3 step:16920[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:3 step:16925[D loss: 0.999961] [G loss: 1.000061]\n",
      "epoch:3 step:16930[D loss: 0.999962] [G loss: 1.000090]\n",
      "epoch:3 step:16935[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:3 step:16940[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:3 step:16945[D loss: 0.999963] [G loss: 1.000069]\n",
      "epoch:3 step:16950[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:3 step:16955[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:3 step:16960[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:3 step:16965[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:3 step:16970[D loss: 0.999980] [G loss: 1.000041]\n",
      "epoch:3 step:16975[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:3 step:16980[D loss: 0.999974] [G loss: 1.000046]\n",
      "epoch:3 step:16985[D loss: 0.999963] [G loss: 1.000060]\n",
      "epoch:3 step:16990[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:3 step:16995[D loss: 0.999971] [G loss: 1.000048]\n",
      "epoch:3 step:17000[D loss: 0.999973] [G loss: 1.000056]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.338950\n",
      "FID: 79.957352\n",
      "0 = 13.989787817764258\n",
      "1 = 0.07377734178518952\n",
      "2 = 0.9613999724388123\n",
      "3 = 0.9807000160217285\n",
      "4 = 0.9420999884605408\n",
      "5 = 0.9442518949508667\n",
      "6 = 0.9807000160217285\n",
      "7 = 11.787940154349824\n",
      "8 = 0.18229835134692962\n",
      "9 = 0.9391999840736389\n",
      "10 = 0.9398999810218811\n",
      "11 = 0.9384999871253967\n",
      "12 = 0.9385859966278076\n",
      "13 = 0.9398999810218811\n",
      "14 = 4.3389668464660645\n",
      "15 = 8.736227989196777\n",
      "16 = 0.3431518077850342\n",
      "17 = 4.338949680328369\n",
      "18 = 79.95735168457031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:17005[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:3 step:17010[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:3 step:17015[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:3 step:17020[D loss: 0.999966] [G loss: 1.000053]\n",
      "epoch:3 step:17025[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:3 step:17030[D loss: 0.999970] [G loss: 1.000049]\n",
      "epoch:3 step:17035[D loss: 0.999969] [G loss: 1.000057]\n",
      "epoch:3 step:17040[D loss: 0.999965] [G loss: 1.000060]\n",
      "epoch:3 step:17045[D loss: 0.999981] [G loss: 1.000059]\n",
      "epoch:3 step:17050[D loss: 0.999961] [G loss: 1.000063]\n",
      "epoch:3 step:17055[D loss: 0.999958] [G loss: 1.000065]\n",
      "epoch:3 step:17060[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:3 step:17065[D loss: 0.999964] [G loss: 1.000067]\n",
      "epoch:3 step:17070[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:3 step:17075[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:3 step:17080[D loss: 0.999961] [G loss: 1.000065]\n",
      "epoch:3 step:17085[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:3 step:17090[D loss: 0.999970] [G loss: 1.000050]\n",
      "epoch:3 step:17095[D loss: 0.999968] [G loss: 1.000059]\n",
      "epoch:3 step:17100[D loss: 0.999973] [G loss: 1.000048]\n",
      "epoch:3 step:17105[D loss: 0.999977] [G loss: 1.000032]\n",
      "epoch:3 step:17110[D loss: 0.999969] [G loss: 1.000051]\n",
      "epoch:3 step:17115[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:3 step:17120[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:3 step:17125[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:3 step:17130[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:3 step:17135[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:3 step:17140[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:3 step:17145[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:3 step:17150[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:3 step:17155[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:3 step:17160[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:3 step:17165[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:3 step:17170[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:3 step:17175[D loss: 0.999966] [G loss: 1.000069]\n",
      "epoch:3 step:17180[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:3 step:17185[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:3 step:17190[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:3 step:17195[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:3 step:17200[D loss: 0.999983] [G loss: 1.000051]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.714798\n",
      "FID: 66.735512\n",
      "0 = 14.577747815227516\n",
      "1 = 0.08593680641588008\n",
      "2 = 0.9434499740600586\n",
      "3 = 0.9897000193595886\n",
      "4 = 0.8971999883651733\n",
      "5 = 0.9059038758277893\n",
      "6 = 0.9897000193595886\n",
      "7 = 11.163748710691939\n",
      "8 = 0.16427924960904774\n",
      "9 = 0.9274500012397766\n",
      "10 = 0.930400013923645\n",
      "11 = 0.9244999885559082\n",
      "12 = 0.9249428510665894\n",
      "13 = 0.930400013923645\n",
      "14 = 4.714821815490723\n",
      "15 = 8.914063453674316\n",
      "16 = 0.29919499158859253\n",
      "17 = 4.7147979736328125\n",
      "18 = 66.73551177978516\n",
      "epoch:3 step:17205[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:3 step:17210[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:3 step:17215[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:3 step:17220[D loss: 0.999985] [G loss: 1.000067]\n",
      "epoch:3 step:17225[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:3 step:17230[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:3 step:17235[D loss: 0.999960] [G loss: 1.000084]\n",
      "epoch:3 step:17240[D loss: 0.999965] [G loss: 1.000061]\n",
      "epoch:3 step:17245[D loss: 0.999973] [G loss: 1.000041]\n",
      "epoch:3 step:17250[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:3 step:17255[D loss: 0.999977] [G loss: 1.000043]\n",
      "epoch:3 step:17260[D loss: 0.999990] [G loss: 1.000016]\n",
      "epoch:3 step:17265[D loss: 1.000022] [G loss: 0.999992]\n",
      "epoch:3 step:17270[D loss: 0.999976] [G loss: 1.000030]\n",
      "epoch:3 step:17275[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:3 step:17280[D loss: 0.999964] [G loss: 1.000032]\n",
      "epoch:3 step:17285[D loss: 0.999960] [G loss: 1.000037]\n",
      "epoch:3 step:17290[D loss: 0.999969] [G loss: 1.000047]\n",
      "epoch:3 step:17295[D loss: 0.999965] [G loss: 1.000052]\n",
      "epoch:3 step:17300[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:3 step:17305[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:3 step:17310[D loss: 0.999965] [G loss: 1.000061]\n",
      "epoch:3 step:17315[D loss: 0.999969] [G loss: 1.000050]\n",
      "epoch:3 step:17320[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:3 step:17325[D loss: 0.999964] [G loss: 1.000054]\n",
      "epoch:3 step:17330[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:3 step:17335[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:3 step:17340[D loss: 0.999969] [G loss: 1.000057]\n",
      "epoch:3 step:17345[D loss: 0.999958] [G loss: 1.000075]\n",
      "epoch:3 step:17350[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:3 step:17355[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:3 step:17360[D loss: 0.999991] [G loss: 1.000044]\n",
      "epoch:3 step:17365[D loss: 0.999964] [G loss: 1.000060]\n",
      "epoch:3 step:17370[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:3 step:17375[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:3 step:17380[D loss: 0.999985] [G loss: 1.000040]\n",
      "epoch:3 step:17385[D loss: 0.999979] [G loss: 1.000035]\n",
      "epoch:3 step:17390[D loss: 0.999996] [G loss: 1.000018]\n",
      "epoch:3 step:17395[D loss: 0.999960] [G loss: 1.000061]\n",
      "epoch:3 step:17400[D loss: 0.999965] [G loss: 1.000068]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.680624\n",
      "FID: 68.033958\n",
      "0 = 14.540654013299955\n",
      "1 = 0.08287054942336848\n",
      "2 = 0.9447000026702881\n",
      "3 = 0.9865999817848206\n",
      "4 = 0.9028000235557556\n",
      "5 = 0.9103155732154846\n",
      "6 = 0.9865999817848206\n",
      "7 = 11.292104979896553\n",
      "8 = 0.16613944429013733\n",
      "9 = 0.9305499792098999\n",
      "10 = 0.9333000183105469\n",
      "11 = 0.9277999997138977\n",
      "12 = 0.9281949400901794\n",
      "13 = 0.9333000183105469\n",
      "14 = 4.6806535720825195\n",
      "15 = 8.854888916015625\n",
      "16 = 0.30610960721969604\n",
      "17 = 4.680624485015869\n",
      "18 = 68.0339584350586\n",
      "epoch:3 step:17405[D loss: 0.999958] [G loss: 1.000057]\n",
      "epoch:3 step:17410[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:3 step:17415[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:3 step:17420[D loss: 0.999983] [G loss: 1.000034]\n",
      "epoch:3 step:17425[D loss: 0.999983] [G loss: 1.000045]\n",
      "epoch:3 step:17430[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:3 step:17435[D loss: 0.999986] [G loss: 1.000056]\n",
      "epoch:3 step:17440[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:3 step:17445[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:3 step:17450[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:3 step:17455[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:3 step:17460[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:3 step:17465[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:3 step:17470[D loss: 0.999981] [G loss: 1.000055]\n",
      "epoch:3 step:17475[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:3 step:17480[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:3 step:17485[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:3 step:17490[D loss: 0.999964] [G loss: 1.000069]\n",
      "epoch:3 step:17495[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:3 step:17500[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:3 step:17505[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:3 step:17510[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:3 step:17515[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:3 step:17520[D loss: 0.999970] [G loss: 1.000052]\n",
      "epoch:3 step:17525[D loss: 0.999983] [G loss: 1.000039]\n",
      "epoch:3 step:17530[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:3 step:17535[D loss: 0.999981] [G loss: 1.000040]\n",
      "epoch:3 step:17540[D loss: 1.000010] [G loss: 1.000038]\n",
      "epoch:3 step:17545[D loss: 0.999987] [G loss: 1.000046]\n",
      "epoch:3 step:17550[D loss: 1.000015] [G loss: 1.000016]\n",
      "epoch:3 step:17555[D loss: 1.000011] [G loss: 1.000081]\n",
      "epoch:3 step:17560[D loss: 1.000029] [G loss: 1.000025]\n",
      "epoch:3 step:17565[D loss: 0.999962] [G loss: 1.000101]\n",
      "epoch:3 step:17570[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:3 step:17575[D loss: 0.999955] [G loss: 1.000071]\n",
      "epoch:3 step:17580[D loss: 0.999954] [G loss: 1.000087]\n",
      "epoch:3 step:17585[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:3 step:17590[D loss: 0.999987] [G loss: 1.000070]\n",
      "epoch:3 step:17595[D loss: 0.999993] [G loss: 1.000075]\n",
      "epoch:3 step:17600[D loss: 0.999972] [G loss: 1.000085]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.345427\n",
      "FID: 77.212128\n",
      "0 = 14.473682074642198\n",
      "1 = 0.0763516383426859\n",
      "2 = 0.9552500247955322\n",
      "3 = 0.988099992275238\n",
      "4 = 0.9223999977111816\n",
      "5 = 0.927183985710144\n",
      "6 = 0.988099992275238\n",
      "7 = 11.72058278385404\n",
      "8 = 0.17753976081064538\n",
      "9 = 0.9391999840736389\n",
      "10 = 0.9415000081062317\n",
      "11 = 0.9369000196456909\n",
      "12 = 0.9371889233589172\n",
      "13 = 0.9415000081062317\n",
      "14 = 4.345451354980469\n",
      "15 = 8.665263175964355\n",
      "16 = 0.34894365072250366\n",
      "17 = 4.345426559448242\n",
      "18 = 77.21212768554688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:17605[D loss: 0.999950] [G loss: 1.000073]\n",
      "epoch:3 step:17610[D loss: 0.999958] [G loss: 1.000075]\n",
      "epoch:3 step:17615[D loss: 0.999965] [G loss: 1.000075]\n",
      "epoch:3 step:17620[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:3 step:17625[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:3 step:17630[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:3 step:17635[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:3 step:17640[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:3 step:17645[D loss: 0.999985] [G loss: 1.000020]\n",
      "epoch:3 step:17650[D loss: 1.000003] [G loss: 0.999993]\n",
      "epoch:3 step:17655[D loss: 1.000007] [G loss: 1.000019]\n",
      "epoch:3 step:17660[D loss: 0.999979] [G loss: 1.000026]\n",
      "epoch:3 step:17665[D loss: 0.999982] [G loss: 1.000031]\n",
      "epoch:3 step:17670[D loss: 1.000009] [G loss: 1.000008]\n",
      "epoch:3 step:17675[D loss: 1.000006] [G loss: 1.000025]\n",
      "epoch:3 step:17680[D loss: 1.000029] [G loss: 1.000009]\n",
      "epoch:3 step:17685[D loss: 0.999944] [G loss: 1.000111]\n",
      "epoch:3 step:17690[D loss: 0.999952] [G loss: 1.000075]\n",
      "epoch:3 step:17695[D loss: 0.999957] [G loss: 1.000076]\n",
      "epoch:3 step:17700[D loss: 0.999957] [G loss: 1.000077]\n",
      "epoch:3 step:17705[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:3 step:17710[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:3 step:17715[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:3 step:17720[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:3 step:17725[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:3 step:17730[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:3 step:17735[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:3 step:17740[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:3 step:17745[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:3 step:17750[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:3 step:17755[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:3 step:17760[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:3 step:17765[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:3 step:17770[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:3 step:17775[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:3 step:17780[D loss: 0.999983] [G loss: 1.000045]\n",
      "epoch:3 step:17785[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:3 step:17790[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:3 step:17795[D loss: 0.999980] [G loss: 1.000044]\n",
      "epoch:3 step:17800[D loss: 0.999969] [G loss: 1.000067]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.477483\n",
      "FID: 74.470436\n",
      "0 = 14.41580600233081\n",
      "1 = 0.0759061433077581\n",
      "2 = 0.9492999911308289\n",
      "3 = 0.9858999848365784\n",
      "4 = 0.9126999974250793\n",
      "5 = 0.9186545014381409\n",
      "6 = 0.9858999848365784\n",
      "7 = 11.502243902671374\n",
      "8 = 0.17384012588050524\n",
      "9 = 0.935949981212616\n",
      "10 = 0.9376000165939331\n",
      "11 = 0.9343000054359436\n",
      "12 = 0.9345160722732544\n",
      "13 = 0.9376000165939331\n",
      "14 = 4.477504253387451\n",
      "15 = 8.783303260803223\n",
      "16 = 0.3172912895679474\n",
      "17 = 4.477482795715332\n",
      "18 = 74.4704360961914\n",
      "epoch:3 step:17805[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:3 step:17810[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:3 step:17815[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:3 step:17820[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:3 step:17825[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:3 step:17830[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:3 step:17835[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:3 step:17840[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:3 step:17845[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:3 step:17850[D loss: 0.999967] [G loss: 1.000053]\n",
      "epoch:3 step:17855[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:3 step:17860[D loss: 0.999966] [G loss: 1.000065]\n",
      "epoch:3 step:17865[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:3 step:17870[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:3 step:17875[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:3 step:17880[D loss: 0.999963] [G loss: 1.000063]\n",
      "epoch:3 step:17885[D loss: 0.999983] [G loss: 1.000054]\n",
      "epoch:3 step:17890[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:3 step:17895[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:3 step:17900[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:3 step:17905[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:3 step:17910[D loss: 0.999980] [G loss: 1.000054]\n",
      "epoch:3 step:17915[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:3 step:17920[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:3 step:17925[D loss: 0.999993] [G loss: 1.000036]\n",
      "epoch:3 step:17930[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:3 step:17935[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:3 step:17940[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:3 step:17945[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:3 step:17950[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:3 step:17955[D loss: 0.999974] [G loss: 1.000043]\n",
      "epoch:3 step:17960[D loss: 1.000007] [G loss: 1.000005]\n",
      "epoch:3 step:17965[D loss: 1.000001] [G loss: 0.999974]\n",
      "epoch:3 step:17970[D loss: 0.999946] [G loss: 1.000056]\n",
      "epoch:3 step:17975[D loss: 0.999966] [G loss: 1.000050]\n",
      "epoch:3 step:17980[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:3 step:17985[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:3 step:17990[D loss: 0.999987] [G loss: 1.000027]\n",
      "epoch:3 step:17995[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:3 step:18000[D loss: 0.999968] [G loss: 1.000069]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.390841\n",
      "FID: 78.913887\n",
      "0 = 14.087520426797857\n",
      "1 = 0.06416301749946171\n",
      "2 = 0.9538999795913696\n",
      "3 = 0.9825000166893005\n",
      "4 = 0.9253000020980835\n",
      "5 = 0.9293416738510132\n",
      "6 = 0.9825000166893005\n",
      "7 = 11.76278842480186\n",
      "8 = 0.1787159403116358\n",
      "9 = 0.9365500211715698\n",
      "10 = 0.9387000203132629\n",
      "11 = 0.9344000220298767\n",
      "12 = 0.9346808791160583\n",
      "13 = 0.9387000203132629\n",
      "14 = 4.390861511230469\n",
      "15 = 8.736324310302734\n",
      "16 = 0.3358917534351349\n",
      "17 = 4.390840530395508\n",
      "18 = 78.91388702392578\n",
      "epoch:3 step:18005[D loss: 0.999972] [G loss: 1.000049]\n",
      "epoch:3 step:18010[D loss: 0.999995] [G loss: 1.000021]\n",
      "epoch:3 step:18015[D loss: 1.000005] [G loss: 1.000051]\n",
      "epoch:3 step:18020[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:3 step:18025[D loss: 0.999985] [G loss: 1.000055]\n",
      "epoch:3 step:18030[D loss: 0.999963] [G loss: 1.000079]\n",
      "epoch:3 step:18035[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:3 step:18040[D loss: 0.999963] [G loss: 1.000060]\n",
      "epoch:3 step:18045[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:3 step:18050[D loss: 0.999981] [G loss: 1.000045]\n",
      "epoch:3 step:18055[D loss: 0.999999] [G loss: 0.999984]\n",
      "epoch:3 step:18060[D loss: 1.000027] [G loss: 1.000009]\n",
      "epoch:3 step:18065[D loss: 1.000044] [G loss: 0.999981]\n",
      "epoch:3 step:18070[D loss: 0.999986] [G loss: 1.000040]\n",
      "epoch:3 step:18075[D loss: 0.999950] [G loss: 1.000054]\n",
      "epoch:3 step:18080[D loss: 0.999960] [G loss: 1.000029]\n",
      "epoch:3 step:18085[D loss: 0.999961] [G loss: 1.000070]\n",
      "epoch:3 step:18090[D loss: 0.999970] [G loss: 1.000053]\n",
      "epoch:3 step:18095[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:3 step:18100[D loss: 0.999985] [G loss: 1.000048]\n",
      "epoch:3 step:18105[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:3 step:18110[D loss: 0.999986] [G loss: 1.000041]\n",
      "epoch:3 step:18115[D loss: 0.999963] [G loss: 1.000069]\n",
      "epoch:3 step:18120[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:3 step:18125[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:3 step:18130[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:3 step:18135[D loss: 0.999987] [G loss: 1.000068]\n",
      "epoch:3 step:18140[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:3 step:18145[D loss: 0.999960] [G loss: 1.000061]\n",
      "epoch:3 step:18150[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:3 step:18155[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:3 step:18160[D loss: 0.999972] [G loss: 1.000047]\n",
      "epoch:3 step:18165[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:3 step:18170[D loss: 0.999987] [G loss: 1.000020]\n",
      "epoch:3 step:18175[D loss: 0.999970] [G loss: 1.000048]\n",
      "epoch:3 step:18180[D loss: 0.999978] [G loss: 1.000029]\n",
      "epoch:3 step:18185[D loss: 0.999975] [G loss: 1.000038]\n",
      "epoch:3 step:18190[D loss: 0.999982] [G loss: 1.000021]\n",
      "epoch:3 step:18195[D loss: 0.999979] [G loss: 1.000042]\n",
      "epoch:3 step:18200[D loss: 0.999980] [G loss: 1.000056]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.525068\n",
      "FID: 75.058983\n",
      "0 = 14.118826615428933\n",
      "1 = 0.05288561573282881\n",
      "2 = 0.948199987411499\n",
      "3 = 0.9857000112533569\n",
      "4 = 0.9107000231742859\n",
      "5 = 0.9169302582740784\n",
      "6 = 0.9857000112533569\n",
      "7 = 11.552247805452323\n",
      "8 = 0.17751021449826684\n",
      "9 = 0.932449996471405\n",
      "10 = 0.9330999851226807\n",
      "11 = 0.9318000078201294\n",
      "12 = 0.9318885207176208\n",
      "13 = 0.9330999851226807\n",
      "14 = 4.525089263916016\n",
      "15 = 8.754293441772461\n",
      "16 = 0.32110732793807983\n",
      "17 = 4.5250678062438965\n",
      "18 = 75.0589828491211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:18205[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:3 step:18210[D loss: 0.999983] [G loss: 1.000050]\n",
      "epoch:3 step:18215[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:3 step:18220[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:3 step:18225[D loss: 0.999991] [G loss: 1.000039]\n",
      "epoch:3 step:18230[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:3 step:18235[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:3 step:18240[D loss: 0.999990] [G loss: 1.000029]\n",
      "epoch:3 step:18245[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:3 step:18250[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:3 step:18255[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:3 step:18260[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:3 step:18265[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:3 step:18270[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:3 step:18275[D loss: 0.999985] [G loss: 1.000049]\n",
      "epoch:3 step:18280[D loss: 0.999988] [G loss: 1.000044]\n",
      "epoch:3 step:18285[D loss: 0.999965] [G loss: 1.000049]\n",
      "epoch:3 step:18290[D loss: 0.999965] [G loss: 1.000053]\n",
      "epoch:3 step:18295[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:3 step:18300[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:3 step:18305[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:3 step:18310[D loss: 0.999974] [G loss: 1.000045]\n",
      "epoch:3 step:18315[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:3 step:18320[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:3 step:18325[D loss: 0.999992] [G loss: 1.000042]\n",
      "epoch:3 step:18330[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:3 step:18335[D loss: 0.999962] [G loss: 1.000063]\n",
      "epoch:3 step:18340[D loss: 0.999965] [G loss: 1.000053]\n",
      "epoch:3 step:18345[D loss: 0.999993] [G loss: 1.000018]\n",
      "epoch:3 step:18350[D loss: 0.999991] [G loss: 1.000047]\n",
      "epoch:3 step:18355[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:3 step:18360[D loss: 0.999968] [G loss: 1.000048]\n",
      "epoch:3 step:18365[D loss: 0.999966] [G loss: 1.000077]\n",
      "epoch:3 step:18370[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:3 step:18375[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:3 step:18380[D loss: 0.999961] [G loss: 1.000065]\n",
      "epoch:3 step:18385[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:3 step:18390[D loss: 0.999967] [G loss: 1.000055]\n",
      "epoch:3 step:18395[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:3 step:18400[D loss: 0.999970] [G loss: 1.000077]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.618667\n",
      "FID: 70.784859\n",
      "0 = 14.154205579996084\n",
      "1 = 0.0671684060577506\n",
      "2 = 0.9457499980926514\n",
      "3 = 0.9848999977111816\n",
      "4 = 0.9065999984741211\n",
      "5 = 0.9133821725845337\n",
      "6 = 0.9848999977111816\n",
      "7 = 11.326605884265923\n",
      "8 = 0.16996080676042863\n",
      "9 = 0.9294000267982483\n",
      "10 = 0.9325000047683716\n",
      "11 = 0.9262999892234802\n",
      "12 = 0.9267541170120239\n",
      "13 = 0.9325000047683716\n",
      "14 = 4.618684768676758\n",
      "15 = 8.949384689331055\n",
      "16 = 0.2933114171028137\n",
      "17 = 4.618666648864746\n",
      "18 = 70.78485870361328\n",
      "epoch:3 step:18405[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:3 step:18410[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:3 step:18415[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:3 step:18420[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:3 step:18425[D loss: 0.999971] [G loss: 1.000049]\n",
      "epoch:3 step:18430[D loss: 0.999980] [G loss: 1.000033]\n",
      "epoch:3 step:18435[D loss: 0.999975] [G loss: 1.000036]\n",
      "epoch:3 step:18440[D loss: 0.999962] [G loss: 1.000061]\n",
      "epoch:3 step:18445[D loss: 0.999970] [G loss: 1.000047]\n",
      "epoch:3 step:18450[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:3 step:18455[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:3 step:18460[D loss: 0.999977] [G loss: 1.000024]\n",
      "epoch:3 step:18465[D loss: 0.999983] [G loss: 1.000040]\n",
      "epoch:3 step:18470[D loss: 0.999986] [G loss: 1.000058]\n",
      "epoch:3 step:18475[D loss: 0.999998] [G loss: 1.000037]\n",
      "epoch:3 step:18480[D loss: 1.000006] [G loss: 1.000047]\n",
      "epoch:3 step:18485[D loss: 1.000010] [G loss: 1.000040]\n",
      "epoch:3 step:18490[D loss: 1.000033] [G loss: 1.000029]\n",
      "epoch:3 step:18495[D loss: 0.999965] [G loss: 1.000093]\n",
      "epoch:3 step:18500[D loss: 0.999994] [G loss: 1.000068]\n",
      "epoch:3 step:18505[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:3 step:18510[D loss: 0.999951] [G loss: 1.000076]\n",
      "epoch:3 step:18515[D loss: 0.999954] [G loss: 1.000080]\n",
      "epoch:3 step:18520[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:3 step:18525[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:3 step:18530[D loss: 0.999974] [G loss: 1.000048]\n",
      "epoch:3 step:18535[D loss: 0.999993] [G loss: 1.000021]\n",
      "epoch:3 step:18540[D loss: 0.999999] [G loss: 0.999998]\n",
      "epoch:3 step:18545[D loss: 1.000040] [G loss: 0.999964]\n",
      "epoch:3 step:18550[D loss: 1.000056] [G loss: 0.999982]\n",
      "epoch:3 step:18555[D loss: 1.000034] [G loss: 0.999981]\n",
      "epoch:3 step:18560[D loss: 1.000027] [G loss: 1.000044]\n",
      "epoch:3 step:18565[D loss: 1.000017] [G loss: 0.999979]\n",
      "epoch:3 step:18570[D loss: 1.000016] [G loss: 1.000013]\n",
      "epoch:3 step:18575[D loss: 0.999924] [G loss: 1.000054]\n",
      "epoch:3 step:18580[D loss: 0.999947] [G loss: 1.000070]\n",
      "epoch:3 step:18585[D loss: 0.999963] [G loss: 1.000049]\n",
      "epoch:3 step:18590[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:3 step:18595[D loss: 0.999980] [G loss: 1.000045]\n",
      "epoch:3 step:18600[D loss: 0.999983] [G loss: 1.000070]\n",
      "tfgan\n",
      "/real/\n",
      "./fake\n",
      "compute score in space: 0\n",
      "compute score in space: 1\n",
      "IS socre: 4.234660\n",
      "FID: 84.124878\n",
      "0 = 13.993739968824384\n",
      "1 = 0.08807963075919024\n",
      "2 = 0.9577000141143799\n",
      "3 = 0.9815999865531921\n",
      "4 = 0.9337999820709229\n",
      "5 = 0.9368200302124023\n",
      "6 = 0.9815999865531921\n",
      "7 = 11.972898386776441\n",
      "8 = 0.19084302597195893\n",
      "9 = 0.9380999803543091\n",
      "10 = 0.9398000240325928\n",
      "11 = 0.9363999962806702\n",
      "12 = 0.936615526676178\n",
      "13 = 0.9398000240325928\n",
      "14 = 4.234679698944092\n",
      "15 = 8.390087127685547\n",
      "16 = 0.37041687965393066\n",
      "17 = 4.2346601486206055\n",
      "18 = 84.1248779296875\n",
      "epoch:3 step:18605[D loss: 0.999965] [G loss: 1.000060]\n",
      "epoch:3 step:18610[D loss: 0.999990] [G loss: 1.000088]\n",
      "epoch:3 step:18615[D loss: 1.000057] [G loss: 1.000079]\n",
      "epoch:3 step:18620[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:3 step:18625[D loss: 0.999942] [G loss: 1.000133]\n",
      "epoch:3 step:18630[D loss: 0.999966] [G loss: 1.000085]\n",
      "epoch:3 step:18635[D loss: 0.999962] [G loss: 1.000089]\n",
      "epoch:3 step:18640[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:3 step:18645[D loss: 0.999966] [G loss: 1.000066]\n",
      "epoch:3 step:18650[D loss: 0.999992] [G loss: 1.000035]\n",
      "epoch:3 step:18655[D loss: 0.999950] [G loss: 1.000062]\n",
      "epoch:3 step:18660[D loss: 0.999970] [G loss: 1.000044]\n",
      "epoch:3 step:18665[D loss: 0.999977] [G loss: 1.000053]\n",
      "epoch:3 step:18670[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:3 step:18675[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:3 step:18680[D loss: 0.999988] [G loss: 1.000080]\n",
      "epoch:3 step:18685[D loss: 0.999997] [G loss: 1.000042]\n",
      "epoch:3 step:18690[D loss: 1.000017] [G loss: 1.000026]\n",
      "epoch:3 step:18695[D loss: 0.999964] [G loss: 1.000035]\n",
      "epoch:3 step:18700[D loss: 0.999981] [G loss: 1.000052]\n",
      "epoch:3 step:18705[D loss: 1.000010] [G loss: 0.999987]\n",
      "epoch:3 step:18710[D loss: 0.999988] [G loss: 0.999982]\n",
      "epoch:3 step:18715[D loss: 0.999980] [G loss: 1.000007]\n",
      "epoch:3 step:18720[D loss: 0.999966] [G loss: 1.000022]\n",
      "epoch:3 step:18725[D loss: 0.999951] [G loss: 1.000058]\n",
      "epoch:3 step:18730[D loss: 0.999972] [G loss: 1.000051]\n",
      "epoch:3 step:18735[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:3 step:18740[D loss: 0.999988] [G loss: 1.000045]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#-*-coding:utf-8-*-\n",
    "from __future__ import print_function, division\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "import util\n",
    "import utils\n",
    "import tensorflow.contrib.gan as tfgan\n",
    "num_images_to_eval = 500\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, imgs, transform=None):\n",
    "        # super().__init__()\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.imgs[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = torch.from_numpy(img)\n",
    "        return img\n",
    "\n",
    "\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import ot\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.models as models\n",
    "\n",
    "from scipy import linalg\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def giveName(iter):  # 7 digit name.\n",
    "    ans = str(iter)\n",
    "    return ans.zfill(7)\n",
    "\n",
    "def make_dataset(dataset, dataroot, imageSize):\n",
    "    \"\"\"\n",
    "    :param dataset: must be in 'cifar10 | lsun | imagenet | folder | lfw | fake'\n",
    "    :return: pytorch dataset for DataLoader to utilize\n",
    "    \"\"\"\n",
    "    if dataset in ['imagenet', 'folder', 'lfw']:\n",
    "        print(os.getcwd() + dataroot)  # 函数的作用是用于返回当前工作目录\n",
    "        # folder dataset\n",
    "        # dataset = dset.ImageFolder(root=dataroot,\n",
    "        dataset = dset.ImageFolder(root=os.getcwd() + dataroot,\n",
    "                                   transform=transforms.Compose([\n",
    "                                       transforms.Resize(imageSize),\n",
    "                                       # transforms.CenterCrop(imageSize),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(\n",
    "                                           (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                   ]))\n",
    "    elif dataset == 'lsun':\n",
    "        dataset = dset.LSUN(db_path=dataroot, classes=['bedroom_train'],\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.Resize(imageSize),\n",
    "                                transforms.CenterCrop(imageSize),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(\n",
    "                                    (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                            ]))\n",
    "    elif dataset == 'cifar10':\n",
    "        dataset = dset.CIFAR10(root=dataroot, download=True,\n",
    "                               transform=transforms.Compose([\n",
    "                                   transforms.Resize(imageSize),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize(\n",
    "                                       (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                               ]))\n",
    "    elif dataset == 'celeba':\n",
    "        dataset = dset.ImageFolder(root=dataroot,\n",
    "                                   transform=transforms.Compose([\n",
    "                                       transforms.CenterCrop(138),\n",
    "                                       transforms.Resize(imageSize),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(\n",
    "                                           (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                   ]))\n",
    "    else:\n",
    "        raise Exception('--dataset must be in cifar10 | lsun | imagenet | folder | lfw | fake')\n",
    "    assert dataset\n",
    "    return dataset\n",
    "\n",
    "MNIST_CLASSIFIER_FROZEN_GRAPH = './classify_mnist_graph_def.pb'\n",
    "INPUT_TENSOR = 'inputs:0'\n",
    "OUTPUT_TENSOR = 'logits:0'\n",
    "# CONV_TENSOR = 'fc3/Relu:0'\n",
    "CONV_TENSOR = 'fc4/BiasAdd:0'\n",
    "class ConvNetFeatureSaver(object):\n",
    "    def __init__(self, model='cnn', workers=4, batchSize=64):\n",
    "        '''\n",
    "        model: inception_v3, vgg13, vgg16, vgg19, resnet18, resnet34,\n",
    "               resnet50, resnet101, or resnet152\n",
    "        '''\n",
    "        self.model = model\n",
    "        self.batch_size = batchSize\n",
    "        self.workers = workers\n",
    "        if self.model.find('tfgan') >= 0:\n",
    "            print('tfgan')\n",
    "\n",
    "        elif self.model.find('vgg') >= 0:\n",
    "            self.vgg = getattr(models, model)(pretrained=True).cuda().eval()\n",
    "            self.trans = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                                     (0.229, 0.224, 0.225)),\n",
    "            ])\n",
    "        elif self.model.find('resnet') >= 0:\n",
    "            resnet = getattr(models, model)(pretrained=True)\n",
    "            resnet.cuda().eval()\n",
    "            resnet_feature = nn.Sequential(resnet.conv1, resnet.bn1,\n",
    "                                           resnet.relu,\n",
    "                                           resnet.maxpool, resnet.layer1,\n",
    "                                           resnet.layer2, resnet.layer3,\n",
    "                                           resnet.layer4).cuda().eval()\n",
    "            self.resnet = resnet\n",
    "            self.resnet_feature = resnet_feature\n",
    "            self.trans = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                                     (0.229, 0.224, 0.225)),\n",
    "            ])\n",
    "        elif self.model == 'inception' or self.model == 'inception_v3':\n",
    "            inception = models.inception_v3(\n",
    "                pretrained=True, transform_input=False).cuda().eval()\n",
    "            inception_feature = nn.Sequential(inception.Conv2d_1a_3x3,\n",
    "                                              inception.Conv2d_2a_3x3,\n",
    "                                              inception.Conv2d_2b_3x3,\n",
    "                                              nn.MaxPool2d(3, 2),\n",
    "                                              inception.Conv2d_3b_1x1,\n",
    "                                              inception.Conv2d_4a_3x3,\n",
    "                                              nn.MaxPool2d(3, 2),\n",
    "                                              inception.Mixed_5b,\n",
    "                                              inception.Mixed_5c,\n",
    "                                              inception.Mixed_5d,\n",
    "                                              inception.Mixed_6a,\n",
    "                                              inception.Mixed_6b,\n",
    "                                              inception.Mixed_6c,\n",
    "                                              inception.Mixed_6d,\n",
    "                                              inception.Mixed_7a,\n",
    "                                              inception.Mixed_7b,\n",
    "                                              inception.Mixed_7c,\n",
    "                                              ).cuda().eval()\n",
    "            self.inception = inception\n",
    "            self.inception_feature = inception_feature\n",
    "            self.trans = transforms.Compose([\n",
    "                transforms.Resize(299),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ])\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def save(self, imgFolder, dataloader, save2disk=False):\n",
    "        feature_pixl, feature_conv, feature_smax, feature_logit = [], [], [], []\n",
    "\n",
    "        for img in dataloader:\n",
    "            with torch.no_grad():\n",
    "                input = img.cuda()\n",
    "                if self.model == 'tfgan':\n",
    "                    gen_imgs = np.array(img)\n",
    "                    eval_images = tf.convert_to_tensor(gen_imgs)\n",
    "                    flogit = util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, OUTPUT_TENSOR)\n",
    "                    fconv = util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, CONV_TENSOR)\n",
    "                    flogit,fconv=tf.Session().run([flogit,fconv])\n",
    "\n",
    "                    flogit=torch.from_numpy(flogit)\n",
    "                    fconv=torch.from_numpy(fconv)\n",
    "                elif self.model == 'vgg' or self.model == 'vgg16':\n",
    "                    print(self.vgg.features(input).shape)\n",
    "                    fconv = self.vgg.features(input).view(input.size(0), -1)  # 相当于reshape\n",
    "                    flogit = self.vgg.classifier(fconv)\n",
    "                    # flogit = self.vgg.logitifier(fconv)\n",
    "                elif self.model.find('resnet') >= 0:\n",
    "                    fconv = self.resnet_feature(\n",
    "                        input).mean(3).mean(2).squeeze()\n",
    "                    flogit = self.resnet.fc(fconv)\n",
    "                elif self.model == 'inception' or self.model == 'inception_v3':\n",
    "                    fconv = self.inception_feature(\n",
    "                        input).mean(3).mean(2).squeeze()\n",
    "                    flogit = self.inception.fc(fconv)\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "                fsmax = F.softmax(flogit)\n",
    "                '''\n",
    "                总共有四个空间：1.feature_pixl 2.feature_conv 3.feature_logit 4.feature_smax\n",
    "                '''\n",
    "                feature_pixl.append(img)\n",
    "                feature_conv.append(fconv.data.cpu())\n",
    "                feature_logit.append(flogit.data.cpu())\n",
    "                feature_smax.append(fsmax.data.cpu())\n",
    "\n",
    "        feature_pixl = torch.cat(feature_pixl, 0).to('cpu')\n",
    "        feature_conv = torch.cat(feature_conv, 0).to('cpu')\n",
    "        feature_logit = torch.cat(feature_logit, 0).to('cpu')\n",
    "        feature_smax = torch.cat(feature_smax, 0).to('cpu')\n",
    "\n",
    "        return feature_pixl, feature_conv, feature_logit, feature_smax\n",
    "\n",
    "    # return feature_pixl, feature_conv, feature_logit, feature_smax\n",
    "\n",
    "\n",
    "def distance(X, Y, sqrt):\n",
    "    nX = X.size(0)\n",
    "    nY = Y.size(0)\n",
    "    X = X.view(nX, -1)\n",
    "    X2 = (X * X).sum(1).resize_(nX, 1)\n",
    "    Y = Y.view(nY, -1)\n",
    "    Y2 = (Y * Y).sum(1).resize_(nY, 1)\n",
    "\n",
    "    M = torch.zeros(nX, nY)\n",
    "    M.copy_(X2.expand(nX, nY) + Y2.expand(nY, nX).transpose(0, 1) -\n",
    "            2 * torch.mm(X, Y.transpose(0, 1)))\n",
    "\n",
    "    del X, X2, Y, Y2\n",
    "\n",
    "    if sqrt:\n",
    "        M = ((M + M.abs()) / 2).sqrt()\n",
    "\n",
    "    return M\n",
    "\n",
    "\n",
    "def wasserstein(M, sqrt):\n",
    "    if sqrt:\n",
    "        M = M.abs().sqrt()\n",
    "    emd = ot.emd2([], [], M.numpy())\n",
    "\n",
    "    return emd\n",
    "\n",
    "\n",
    "class Score_knn:\n",
    "    acc = 0\n",
    "    acc_real = 0\n",
    "    acc_fake = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    ft = 0\n",
    "\n",
    "\n",
    "def knn(Mxx, Mxy, Myy, k, sqrt):\n",
    "    n0 = Mxx.size(0)\n",
    "    n1 = Myy.size(0)\n",
    "    label = torch.cat((torch.ones(n0), torch.zeros(n1)))\n",
    "    M = torch.cat((torch.cat((Mxx, Mxy), 1), torch.cat(\n",
    "        (Mxy.transpose(0, 1), Myy), 1)), 0)\n",
    "    if sqrt:\n",
    "        M = M.abs().sqrt()\n",
    "    INFINITY = float('inf')\n",
    "    val, idx = (M + torch.diag(INFINITY * torch.ones(n0 + n1))\n",
    "                ).topk(k, 0, False)\n",
    "\n",
    "    count = torch.zeros(n0 + n1)\n",
    "    for i in range(0, k):\n",
    "        count = count + label.index_select(0, idx[i])\n",
    "    pred = torch.ge(count, (float(k) / 2) * torch.ones(n0 + n1)).float()\n",
    "\n",
    "    s = Score_knn()\n",
    "    s.tp = (pred * label).sum()\n",
    "    s.fp = (pred * (1 - label)).sum()\n",
    "    s.fn = ((1 - pred) * label).sum()\n",
    "    s.tn = ((1 - pred) * (1 - label)).sum()\n",
    "    s.precision = s.tp / (s.tp + s.fp + 1e-10)\n",
    "    s.recall = s.tp / (s.tp + s.fn + 1e-10)\n",
    "    s.acc_t = s.tp / (s.tp + s.fn)\n",
    "    s.acc_f = s.tn / (s.tn + s.fp)\n",
    "    s.acc = torch.eq(label, pred).float().mean()\n",
    "    s.k = k\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "def mmd(Mxx, Mxy, Myy, sigma):\n",
    "    scale = Mxx.mean()\n",
    "    Mxx = torch.exp(-Mxx / (scale * 2 * sigma * sigma))\n",
    "    Mxy = torch.exp(-Mxy / (scale * 2 * sigma * sigma))\n",
    "    Myy = torch.exp(-Myy / (scale * 2 * sigma * sigma))\n",
    "    mmd = math.sqrt(Mxx.mean() + Myy.mean() - 2 * Mxy.mean())\n",
    "\n",
    "    return mmd\n",
    "\n",
    "\n",
    "def entropy_score(X, Y, epsilons):\n",
    "    Mxy = distance(X, Y, False)\n",
    "    scores = []\n",
    "    for epsilon in epsilons:\n",
    "        scores.append(ent(Mxy.t(), epsilon))\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "def ent(M, epsilon):\n",
    "    n0 = M.size(0)\n",
    "    n1 = M.size(1)\n",
    "    neighbors = M.lt(epsilon).float()\n",
    "    sums = neighbors.sum(0).repeat(n0, 1)\n",
    "    sums[sums.eq(0)] = 1\n",
    "    neighbors = neighbors.div(sums)\n",
    "    probs = neighbors.sum(1) / n1\n",
    "    rem = 1 - probs.sum()\n",
    "    if rem < 0:\n",
    "        rem = 0\n",
    "    probs = torch.cat((probs, rem * torch.ones(1)), 0)\n",
    "    e = {}\n",
    "    e['probs'] = probs\n",
    "    probs = probs[probs.gt(0)]\n",
    "    e['ent'] = -probs.mul(probs.log()).sum()\n",
    "\n",
    "    return e\n",
    "\n",
    "\n",
    "eps = 1e-20\n",
    "\n",
    "\n",
    "def inception_score(X):\n",
    "    kl = X * ((X + eps).log() - (X.mean(0) + eps).log().expand_as(X))\n",
    "    score = np.exp(kl.sum(1).mean())\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def mode_score(X, Y):\n",
    "    kl1 = X * ((X + eps).log() - (X.mean(0) + eps).log().expand_as(X))\n",
    "    kl2 = X.mean(0) * ((X.mean(0) + eps).log() - (Y.mean(0) + eps).log())\n",
    "    score = np.exp(kl1.sum(1).mean() - kl2.sum())\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def fid(X, Y):\n",
    "    m = X.mean(0)\n",
    "    m_w = Y.mean(0)\n",
    "    X_np = X.numpy()\n",
    "    Y_np = Y.numpy()\n",
    "\n",
    "    C = np.cov(X_np.transpose())\n",
    "    C_w = np.cov(Y_np.transpose())\n",
    "    C_C_w_sqrt = linalg.sqrtm(C.dot(C_w), True).real\n",
    "\n",
    "    score = m.dot(m) + m_w.dot(m_w) - 2 * m_w.dot(m) + \\\n",
    "            np.trace(C + C_w - 2 * C_C_w_sqrt)\n",
    "    return np.sqrt(score)\n",
    "\n",
    "\n",
    "class Score:\n",
    "    emd = 0\n",
    "    mmd = 0\n",
    "    knn = None\n",
    "\n",
    "\n",
    "def compute_score(real, fake, k=1, sigma=1, sqrt=True):\n",
    "    Mxx = distance(real, real, False)\n",
    "    Mxy = distance(real, fake, False)\n",
    "    Myy = distance(fake, fake, False)\n",
    "\n",
    "    s = Score()\n",
    "    s.emd = wasserstein(Mxy, sqrt)\n",
    "    s.mmd = mmd(Mxx, Mxy, Myy, sigma)\n",
    "    s.knn = knn(Mxx, Mxy, Myy, k, sqrt)\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "'''\n",
    "参数说明：\n",
    "dataset:真实数据集的path\n",
    "imageSize:图片的大小\n",
    "dataroot_real:真实数据所在的path\n",
    "batchSize\n",
    "saveFolder_r:真实数据的保存位置\n",
    "conv_model:卷积模型\n",
    "'''\n",
    "\n",
    "\n",
    "def compute_score_raw(real_dataloader, fake_dataloader, batchSize, saveFolder_r, saveFolder_f, conv_model='resnet34',\n",
    "                      workers=4):\n",
    "    convnet_feature_saver = ConvNetFeatureSaver(model=conv_model,\n",
    "                                                batchSize=batchSize, workers=workers)\n",
    "    print(saveFolder_r)\n",
    "    print(saveFolder_f)\n",
    "    feature_r = convnet_feature_saver.save(saveFolder_r, real_dataloader, False)\n",
    "    feature_f = convnet_feature_saver.save(saveFolder_f, fake_dataloader, False)\n",
    "\n",
    "    # 4 feature spaces and 7 scores + incep + modescore + fid\n",
    "    score = np.zeros(2 * 7 + 5)\n",
    "    for i in range(0, 2):\n",
    "        print('compute score in space: ' + str(i))\n",
    "        Mxx = distance(feature_r[i], feature_r[i], False)\n",
    "        Mxy = distance(feature_r[i], feature_f[i], False)\n",
    "        Myy = distance(feature_f[i], feature_f[i], False)\n",
    "\n",
    "        score[i * 7] = wasserstein(Mxy, True)\n",
    "        score[i * 7 + 1] = mmd(Mxx, Mxy, Myy, 1)\n",
    "        tmp = knn(Mxx, Mxy, Myy, 1, False)\n",
    "        score[(i * 7 + 2):(i * 7 + 7)] = \\\n",
    "            tmp.acc, tmp.acc_t, tmp.acc_f, tmp.precision, tmp.recall\n",
    "\n",
    "\n",
    "    score[14] = inception_score(feature_f[3])\n",
    "    score[15] = mode_score(feature_r[3], feature_f[3])\n",
    "    score[16] = fid(feature_r[3], feature_f[3])\n",
    "\n",
    "    return score\n",
    "labels_name=['w_pixl','mmd_pixl','acc_pixl','acc_t_pixl','acc_f_pixl','acc_precision_pixl','acc_recall_pixl',\n",
    "             'w_conv','mmd_conv','acc_conv','acc_t_conv','acc_f_conv','acc_precision_conv','acc_recall_conv',\n",
    "             'is','mode_score','fid' ,'tf_is','tf_fid']\n",
    "if not os.path.isdir('saved_models_{}'.format('acgan')):\n",
    "    os.mkdir('saved_models_{}'.format('acgan'))\n",
    "f = open('saved_models_{}/log_collapse1.txt'.format('acgan'), mode='w')\n",
    "import torch.utils.data as Data\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class WGAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "        self.x = []\n",
    "        self.y = np.zeros((31, 1), dtype=np.int)\n",
    "        self.y = list(self.y)\n",
    "        for i in range(31):\n",
    "            self.y[i] = []\n",
    "\n",
    "        # Following parameter and optimizer set as recommended in paper\n",
    "        self.n_critic = 5\n",
    "        self.clip_value = 0.01\n",
    "        optimizer = RMSprop(lr=0.00005)\n",
    "\n",
    "        # Build and compile the critic\n",
    "        self.critic = self.build_critic()\n",
    "        self.critic.compile(loss=self.wasserstein_loss,\n",
    "                            optimizer=optimizer,\n",
    "                            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.critic.trainable = False\n",
    "\n",
    "        # The critic takes generated images as input and determines validity\n",
    "        valid = self.critic(img)\n",
    "\n",
    "        # The combined model  (stacked generator and critic)\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss=self.wasserstein_loss,\n",
    "                              optimizer=optimizer,\n",
    "                              metrics=['accuracy'])\n",
    "\n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((7, 7, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=4, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=4, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=4, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_critic(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(16, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (X_test, _) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "        # X_test = X_test / 127.5 - 1.\n",
    "        X_test = np.expand_dims(X_test, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = -np.ones((batch_size, 1))\n",
    "        fake = np.ones((batch_size, 1))\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "\n",
    "            for index in range(nb_batches):\n",
    "                for _ in range(self.n_critic):\n",
    "                    global_step += 1\n",
    "                    imgs = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                    # ---------------------\n",
    "                    #  Train Discriminator\n",
    "                    # ---------------------\n",
    "\n",
    "                    # Select a random batch of images\n",
    "                    # idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "                    # imgs = X_train[idx]\n",
    "\n",
    "                    # Sample noise as generator input\n",
    "                    noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "                    # Generate a batch of new images\n",
    "                    gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "                    # Train the critic\n",
    "                    d_loss_real = self.critic.train_on_batch(imgs, valid)\n",
    "                    d_loss_fake = self.critic.train_on_batch(gen_imgs, fake)\n",
    "                    d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
    "\n",
    "                    # Clip critic weights\n",
    "                    for l in self.critic.layers:\n",
    "                        weights = l.get_weights()\n",
    "                        weights = [np.clip(w, -self.clip_value, self.clip_value) for w in weights]\n",
    "                        l.set_weights(weights)\n",
    "\n",
    "                    # ---------------------\n",
    "                    #  Train Generator\n",
    "                    # ---------------------\n",
    "\n",
    "                g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "                # Plot the progress\n",
    "                print(\"epoch:%d step:%d[D loss: %f] [G loss: %f]\" % (epoch,global_step, 1 - d_loss[0], 1 - g_loss[0]))\n",
    "\n",
    "                sampleSize = 10000\n",
    "                # If at save interval => save generated image samples\n",
    "                if global_step % sample_interval == 0:\n",
    "                    s = self.metrics(global_step, X_test, sampleSize)\n",
    "        for i in range(len(s)):\n",
    "            self.y[i] = [float(j) / max(self.y[i]) for j in self.y[i]]#对值进行归一化处理\n",
    "\n",
    "        for i in range(len(s)):\n",
    "            font1={'size':8}\n",
    "\n",
    "            plt.plot(self.x, self.y[i], label=labels_name[i])\n",
    "            plt.legend(loc='lower right',prop=font1)\n",
    "            plt.savefig('saved_models_acgan/{}.png'.format(labels_name[i]))\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "    def metrics(self, epoch, X_test, sampleSize):\n",
    "        self.x.append(epoch)\n",
    "        r, c = 10, sampleSize // 10\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "#         sampled_labels = np.array([num for _ in range(r) for num in range(c)])\n",
    "        gen_imgs = self.generator.predict([noise])\n",
    "        x_dataset = MyDataset(X_test[:sampleSize])\n",
    "        # print(x_dataset[0].shape)\n",
    "        x_real_loader = Data.DataLoader(dataset=x_dataset, batch_size=2000, shuffle=True)\n",
    "        x_fake_dataset = MyDataset(gen_imgs)\n",
    "        x_fake_loader = Data.DataLoader(dataset=x_fake_dataset, batch_size=2000, shuffle=True)\n",
    "        s = compute_score_raw(x_real_loader, x_fake_loader, 256, '/real/', './fake', conv_model='tfgan',\n",
    "                              workers=int(1))\n",
    "        real_images = tf.convert_to_tensor(X_test)  # real images\n",
    "        # MNIST_CLASSIFIER_FROZEN_GRAPH = '.\\classify_mnist_graph_def.pb'\n",
    "        gen_imgs = np.array(gen_imgs)\n",
    "        eval_images = tf.convert_to_tensor(gen_imgs)\n",
    "        eval_score = utils.mnist_score(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH)  # IS score\n",
    "        frechet_distance = utils.mnist_frechet_distance(real_images, eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH)\n",
    "        mnist_score, f_distance = sess.run([eval_score, frechet_distance])\n",
    "        # print(mnist_score)\n",
    "        # print(f_distance)\n",
    "        # s[14]=mnist_score\n",
    "        # s[16]=f_distance\n",
    "        s[17] = mnist_score\n",
    "        s[18] = f_distance\n",
    "        print('IS socre: %f' % mnist_score)\n",
    "        print('FID: %f' % f_distance)\n",
    "\n",
    "        for i in range(len(s)):\n",
    "            print(i, \"=\", s[i])\n",
    "        for i in range(len(s)):\n",
    "            self.y[i].append(s[i])\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('epoch:' + str(epoch))\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('%.8f' % (i) for i in s)\n",
    "        f.writelines('\\n')\n",
    "        return s\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    wgan = WGAN()\n",
    "    wgan.train(epochs=4, batch_size=64, sample_interval=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
